file_path,api_count,code
setup.py,1,"b'# Lint as: python3\n""""""tensorflow/datasets is a library of datasets ready to use with TensorFlow.\n\ntensorflow/datasets is a library of public datasets ready to use with\nTensorFlow. Each dataset definition contains the logic necessary to download and\nprepare the dataset, as well as to read it into a model using the\n`tf.data.Dataset` API.\n\nUsage outside of TensorFlow is also supported.\n\nSee the README on GitHub for further documentation.\n""""""\n\nimport datetime\nimport itertools\nimport os\nimport sys\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nnightly = False\nif \'--nightly\' in sys.argv:\n  nightly = True\n  sys.argv.remove(\'--nightly\')\n\nproject_name = \'tensorflow-datasets\'\n\n# To enable importing version.py directly, we add its path to sys.path.\nversion_path = os.path.join(\n    os.path.dirname(__file__), \'tensorflow_datasets\')\nsys.path.append(version_path)\nfrom version import __version__  # pytype: disable=import-error  # pylint: disable=g-import-not-at-top\n\nif nightly:\n  project_name = \'tfds-nightly\'\n  datestring = (os.environ.get(\'TFDS_NIGHTLY_TIMESTAMP\') or\n                datetime.datetime.now().strftime(\'%Y%m%d%H%M\'))\n  __version__ += \'dev%s\' % datestring\n\nDOCLINES = __doc__.split(\'\\n\')\n\nREQUIRED_PKGS = [\n    \'absl-py\',\n    \'attrs>=18.1.0\',\n    \'dill\',  # TODO(tfds): move to TESTS_REQUIRE.\n    \'future\',\n    \'numpy\',\n    \'promise\',\n    \'protobuf>=3.6.1\',\n    \'requests>=2.19.0\',\n    \'six\',\n    \'tensorflow-metadata\',\n    \'termcolor\',\n    \'tqdm\',\n    \'wrapt\',\n    # Python 2 backports\n    \'bz2file;python_version<""3""\',\n    \'functools32;python_version<""3""\',\n    \'futures;python_version<""3""\',\n    # shutil.disk_usage was introduced in Python 3.3, use psutil instead.\n    \'psutil;python_version<""3.3""\',\n    # enum introduced in Python 3.4\n    \'enum34;python_version<""3.4""\'\n]\n\nTESTS_REQUIRE = [\n    \'jupyter\',\n    \'mako\',\n    \'pytest\',\n    \'pytest-xdist\',\n    \'tensorflow-data-validation\',\n    # Python 2 backports\n    \'mock;python_version<""3""\',\n    # TODO(b/142892342): Re-enable\n    # \'tensorflow-docs @ git+https://github.com/tensorflow/docs#egg=tensorflow-docs\',  # pylint: disable=line-too-long\n]\n\n# Static files needed by datasets.\nDATASET_FILES = [\n    \'image_classification/caltech101_labels.txt\',\n    \'image_classification/categories_places365.txt\',\n    \'image_classification/cbis_ddsm_calc_distributions.txt\',\n    \'image_classification/cbis_ddsm_calc_types.txt\',\n    \'image_classification/cbis_ddsm_mass_margins.txt\',\n    \'image_classification/cbis_ddsm_mass_shapes.txt\',\n    \'image_classification/cbis_ddsm_patch_labels.txt\',\n    \'image_classification/dtd_key_attributes.txt\',\n    \'image_classification/food-101_classes.txt\',\n    \'image_classification/imagenet_resized_labels.txt\',\n    \'image_classification/imagenet2012_labels.txt\',\n    \'image_classification/imagenet2012_validation_labels.txt\',\n    \'image_classification/imagenette_labels.txt\',\n    \'image_classification/imagewang_labels.txt\',\n    \'image_classification/inaturalist_labels.txt\',\n    \'image_classification/inaturalist_supercategories.txt\',\n    \'image_classification/plant_leaves_urls.txt\',\n    \'image_classification/plantae_k_urls.txt\',\n    \'image_classification/quickdraw_labels.txt\',\n    \'image_classification/sun397_labels.txt\',\n    \'image_classification/sun397_tfds_te.txt\',\n    \'image_classification/sun397_tfds_tr.txt\',\n    \'image_classification/sun397_tfds_va.txt\',\n    \'image_classification/vgg_face2_labels.txt\',\n    \'object_detection/open_images_classes_all.txt\',\n    \'object_detection/open_images_classes_boxable.txt\',\n    \'object_detection/open_images_classes_trainable.txt\',\n    \'url_checksums/*\',\n    \'video/ucf101_labels.txt\',\n]\n\n# Extra dependencies required by specific datasets\nDATASET_EXTRAS = {\n    # In alphabetical order\n    \'aflw2k3d\': [\'scipy\'],\n    \'c4\': [\'apache_beam\', \'langdetect\', \'nltk\', \'tldextract\'],\n    \'cats_vs_dogs\': [\'matplotlib\'],\n    \'colorectal_histology\': [\'Pillow\'],\n    \'common_voice\': [\'pydub\'],  # and ffmpeg installed\n    \'eurosat\': [\'scikit-image\',],\n    \'groove\': [\'pretty_midi\', \'pydub\'],\n    \'imagenet2012_corrupted\': [\n        # This includes pre-built source; you may need to use an alternative\n        # route to install OpenCV\n        \'opencv-python==3.4.0.14\',\n        \'scikit-image\',\n        \'scipy\'\n    ],\n    \'librispeech\': [\'pydub\'],  # and ffmpeg installed\n    # sklearn version required to avoid conflict with librosa from\n    # https://github.com/scikit-learn/scikit-learn/issues/14485\n    \'nsynth\': [\'crepe>=0.0.11\', \'librosa\', \'scikit-learn==0.20.3\'],\n    \'pet_finder\': [\'pandas\'],\n    \'robonet\': [\'h5py\'],  # and ffmpeg installed\n    \'svhn\': [\'scipy\'],\n    \'the300w_lp\': [\'scipy\'],\n    \'duke_ultrasound\': [\'scipy\'],\n    \'wider_face\': [\'Pillow\'],\n    \'wikipedia\': [\'mwparserfromhell\', \'apache_beam\'],\n    \'lsun\': [\'tensorflow-io\'],\n}\n\n\n# Those datasets have dependencies which conflict with the rest of TFDS, so\n# running them in an isolated environements.\n# See `./oss_scripts/oss_tests.sh` for the isolated test.\nISOLATED_DATASETS = (\'nsynth\', \'lsun\')\n\n# Extra dataset deps are required for the tests\nall_dataset_extras = list(itertools.chain.from_iterable(\n    deps for ds_name, deps in DATASET_EXTRAS.items()\n    if ds_name not in ISOLATED_DATASETS\n))\n\n\nEXTRAS_REQUIRE = {\n    \'matplotlib\': [\'matplotlib\'],\n    \'tensorflow\': [\'tensorflow>=1.15.0\'],\n    \'tensorflow_gpu\': [\'tensorflow-gpu>=1.15.0\'],\n    \'tensorflow-data-validation\': [\'tensorflow-data-validation\'],\n\n    # Tests dependencies are installed in ./oss_scripts/oss_pip_install.sh\n    # and run in ./oss_scripts/oss_tests.sh\n    \'tests\': TESTS_REQUIRE + all_dataset_extras,\n}\nEXTRAS_REQUIRE.update(DATASET_EXTRAS)\n\nsetup(\n    name=project_name,\n    version=__version__,\n    description=DOCLINES[0],\n    long_description=\'\\n\'.join(DOCLINES[2:]),\n    author=\'Google Inc.\',\n    author_email=\'packages@tensorflow.org\',\n    url=\'https://github.com/tensorflow/datasets\',\n    download_url=\'https://github.com/tensorflow/datasets/tags\',\n    license=\'Apache 2.0\',\n    packages=find_packages(),\n    package_data={\n        \'tensorflow_datasets\': DATASET_FILES + [\n            \'scripts/documentation/templates/*\',\n        ],\n    },\n    scripts=[],\n    install_requires=REQUIRED_PKGS,\n    extras_require=EXTRAS_REQUIRE,\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n    ],\n    keywords=\'tensorflow machine learning datasets\',\n)\n'"
tensorflow_datasets/__init__.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# pylint: disable=line-too-long\n""""""`tensorflow_datasets` (`tfds`) defines a collection of datasets ready-to-use with TensorFlow.\n\nEach dataset is defined as a `tfds.core.DatasetBuilder`, which encapsulates\nthe logic to download the dataset and construct an input pipeline, as well as\ncontains the dataset documentation (version, splits, number of examples, etc.).\n\nThe main library entrypoints are:\n\n* `tfds.builder`: fetch a `tfds.core.DatasetBuilder` by name\n* `tfds.load`: convenience method to construct a builder, download the data, and\n  create an input pipeline, returning a `tf.data.Dataset`.\n\nDocumentation:\n\n* These API docs\n* [Available datasets](https://www.tensorflow.org/datasets/catalog/overview)\n* [Colab tutorial](https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb)\n* [Add a dataset](https://www.tensorflow.org/datasets/add_dataset)\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: enable=line-too-long\n# pylint: disable=g-import-not-at-top,g-bad-import-order,wrong-import-position\n\n# Ensure TensorFlow is importable and its version is sufficiently recent. This\n# needs to happen before anything else, since the imports below will try to\n# import tensorflow, too.\nfrom tensorflow_datasets.core import tf_compat\ntf_compat.ensure_tf_install()\n\n# Imports for registration\n# pylint: disable=g-import-not-at-top\nfrom tensorflow_datasets import audio\nfrom tensorflow_datasets import image\nfrom tensorflow_datasets import image_classification\nfrom tensorflow_datasets import object_detection\nfrom tensorflow_datasets import question_answering\nfrom tensorflow_datasets import structured\nfrom tensorflow_datasets import summarization\nfrom tensorflow_datasets import text\nfrom tensorflow_datasets import translate\nfrom tensorflow_datasets import video\n\n\n# Public API to create and generate a dataset\nfrom tensorflow_datasets.public_api import *  # pylint: disable=wildcard-import\n\n# __all__ for import * as well as documentation\nfrom tensorflow_datasets import public_api  # pylint: disable=g-bad-import-order\n__all__ = public_api.__all__\n\n'"
tensorflow_datasets/import_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test import.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets as tfds  # pylint: disable=unused-import\nfrom tensorflow_datasets import testing\n\n\nclass ImportTest(testing.TestCase):\n\n  def test_import(self):\n    pass\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/import_testing_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.import_testing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\nclass ImportTestingTest(tf.test.TestCase):\n\n  def test_testing_imported(self):\n    self.assertIsNotNone(tfds.testing)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_datasets/public_api.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Public API of tfds, without the registered dataset.""""""\n\n# pylint: disable=unused-import,g-import-not-at-top,g-bad-import-order,wrong-import-position\nfrom tensorflow_datasets.core import tf_compat\ntf_compat.ensure_tf_install()\n\nfrom tensorflow_datasets import core\nfrom tensorflow_datasets.core import download\nfrom tensorflow_datasets.core import decode\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core import units\nfrom tensorflow_datasets.core import visualization\nfrom tensorflow_datasets.core.dataset_utils import as_numpy\nfrom tensorflow_datasets.core.download import GenerateMode\nfrom tensorflow_datasets.core.registered import builder\nfrom tensorflow_datasets.core.registered import builder_cls\nfrom tensorflow_datasets.core.registered import list_builders\nfrom tensorflow_datasets.core.registered import load\nfrom tensorflow_datasets.core.splits import Split\nfrom tensorflow_datasets.core.utils.gcs_utils import is_dataset_on_gcs\nfrom tensorflow_datasets.core.utils.read_config import ReadConfig\nfrom tensorflow_datasets.core.utils.tqdm_utils import disable_progress_bar\nfrom tensorflow_datasets.core.visualization import show_examples\nfrom tensorflow_datasets.core.visualization import show_statistics\nfrom tensorflow_datasets.version import __version__\n\nwith core.registered.skip_registration():\n  # We import testing namespace but without registering the tests datasets\n  # (e.g. DummyMnist,...).\n  from tensorflow_datasets import testing\n\n\n__all__ = [\n    ""core"",\n    ""as_numpy"",\n    ""decode"",\n    ""download"",\n    ""features"",\n    ""units"",\n    ""GenerateMode"",\n    ""builder"",\n    ""builder_cls"",\n    ""list_builders"",\n    ""load"",\n    ""ReadConfig"",\n    ""Split"",\n    ""testing"",\n    ""disable_progress_bar"",\n    ""is_dataset_on_gcs"",\n    ""show_examples"",\n    ""show_statistics"",\n    ""visualization"",\n    ""__version__"",\n]\n'"
tensorflow_datasets/version.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Version info (development version).\n\nAll users importing TFDS from `tfds-nightly` or synced to head will see\nthe `-nightly` suffix.\n\nThis file is replaced by `version_stable.py` for stable releases\n(`tensorflow-datasets`) on PyPI.\n""""""\n\n# We follow Semantic Versioning (https://semver.org/)\n_MAJOR_VERSION = \'3\'\n_MINOR_VERSION = \'1\'\n_PATCH_VERSION = \'0\'\n\n__version__ = \'.\'.join([\n    _MAJOR_VERSION,\n    _MINOR_VERSION,\n    _PATCH_VERSION,\n]) + \'-nightly\'\n'"
tensorflow_datasets/version_stable.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Version info (stable version).\n\nThis file overwrites `version.py` for stable releases.\n""""""\n\n# We follow Semantic Versioning (https://semver.org/)\n_MAJOR_VERSION = \'3\'\n_MINOR_VERSION = \'1\'\n_PATCH_VERSION = \'0\'\n\n__version__ = \'.\'.join([\n    _MAJOR_VERSION,\n    _MINOR_VERSION,\n    _PATCH_VERSION,\n])\n'"
tensorflow_datasets/audio/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Audio datasets.""""""\n\nfrom tensorflow_datasets.audio.commonvoice import CommonVoice\nfrom tensorflow_datasets.audio.commonvoice import CommonVoiceConfig\nfrom tensorflow_datasets.audio.crema_d import CremaD\nfrom tensorflow_datasets.audio.dementiabank import Dementiabank\nfrom tensorflow_datasets.audio.groove import Groove\nfrom tensorflow_datasets.audio.librispeech import Librispeech\nfrom tensorflow_datasets.audio.librispeech import LibrispeechConfig\nfrom tensorflow_datasets.audio.libritts import Libritts\nfrom tensorflow_datasets.audio.ljspeech import Ljspeech\nfrom tensorflow_datasets.audio.nsynth import Nsynth\nfrom tensorflow_datasets.audio.savee import Savee\nfrom tensorflow_datasets.audio.speech_commands import SpeechCommands\nfrom tensorflow_datasets.audio.tedlium import Tedlium\nfrom tensorflow_datasets.audio.voxceleb import Voxceleb\nfrom tensorflow_datasets.audio.voxforge import Voxforge\n'"
tensorflow_datasets/audio/commonvoice.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Mozilla Common Voice Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DOWNLOAD_URL = ""https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-1/{}.tar.gz""\n_SPLITS = {\n    tfds.Split.TRAIN: ""train"",\n    tfds.Split.TEST: ""test"",\n    tfds.Split.VALIDATION: ""validated""\n}\n_GENDER_CLASSES = [""male"", ""female"", ""other""]\n\n# OrderedDict to keep collection order constant (en is the default config)\n_LANGUAGE_ACCENTS = collections.OrderedDict([\n    (""en"", [\n        ""canada"", ""us"", ""indian"", ""philippines"", ""england"", ""scotland"", ""other"",\n        ""australia"", ""hongkong"", ""african"", ""newzealand"", ""wales"", ""ireland"",\n        ""malaysia"", ""bermuda"", ""singapore"", ""southatlandtic""\n    ]),\n    (""de"", [\n        ""germany"", ""switzerland"", ""austria"", ""other"", ""liechtenstein"", ""france"",\n        ""netherlands"", ""united_kingdom"", ""hungary"", ""poland""\n    ]),\n    (""fr"", [\n        ""france"", ""switzerland"", ""belgium"", ""algeria"", ""canada"", ""other"",\n        ""germany"", ""tunisia"", ""senegal"", ""united_states"",\n        ""st_pierre_et_miquelon"", ""monaco"", ""mayotte"", ""cote_d_ivoire"",\n        ""guadeloupe"", ""martinique"", ""reunion"", ""portugal"", ""netherlands""\n    ]),\n    (""cy"", [""united_kingdom"", ""other""]),\n    (""br"", [""other""]),\n    (""cv"", []),\n    (""tr"", [""other""]),\n    (""tt"", []),\n    (""ky"", [""other""]),\n    (""ga-IE"", [""other"", ""ulaidh"", ""connachta""]),\n    (""kab"", [""other""]),\n    (""ca"",\n     [""northwestern"", ""central"", ""other"", ""valencian"", ""balearic"", ""northern""]),\n    (""zh-TW"", [""other""]),\n    (""sl"", [""other""]),\n    (""it"", [""other""]),\n    (""nl"", [""netherlands"", ""belgium"", ""other""]),\n    (""cnh"", [""other""]),\n    (""eo"", [""internacia"", ""other""]),\n])\n\n\nclass CommonVoiceConfig(tfds.core.BuilderConfig):\n  """"""Configuration Class for Mozilla CommonVoice Dataset.""""""\n\n  @tfds.core.api_utils.disallow_positional_args\n  def __init__(self, language, accents=None, **kwargs):\n    """"""Constructs CommonVoiceConfig.\n\n    Args:\n     language: `str`, one of [ca, nl, br, de, sl, cy, en, kab, tt, zh-TW, eo,\n       it, fr, ga-IE, tr, ky, cnh, cv]. Language Code of the Dataset to be used.\n     accents: `list[str]`, labels for the accents of the language\n     **kwargs: keywords arguments forwarded to super\n    """"""\n    if language not in _LANGUAGE_ACCENTS:\n      raise ValueError(""language must be one of {}. Not: {}"".format(\n          list(_LANGUAGE_ACCENTS.keys()), language))\n    self.language = language\n    self.accents = accents\n\n    kwargs.setdefault(""name"", language)\n    kwargs.setdefault(""description"", ""Language Code: %s"" % language)\n    kwargs.setdefault(""version"", tfds.core.Version(""1.0.0""))\n    super(CommonVoiceConfig, self).__init__(**kwargs)\n\n\nclass CommonVoice(tfds.core.GeneratorBasedBuilder):\n  """"""Mozilla Common Voice Dataset.""""""\n  BUILDER_CONFIGS = [\n      CommonVoiceConfig(language=l, accents=a)\n      for l, a in _LANGUAGE_ACCENTS.items()\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        description=(""Mozilla Common Voice Dataset""),\n        builder=self,\n        features=tfds.features.FeaturesDict({\n            ""client_id"":\n                tfds.features.Text(),\n            ""upvotes"":\n                tf.int32,\n            ""downvotes"":\n                tf.int32,\n            ""age"":\n                tfds.features.Text(),\n            ""gender"":\n                tfds.features.ClassLabel(names=_GENDER_CLASSES),\n            ""accent"":\n                tfds.features.ClassLabel(names=self.builder_config.accents),\n            ""sentence"":\n                tfds.features.Text(),\n            ""voice"":\n                tfds.features.Audio(),\n        }),\n        homepage=""https://voice.mozilla.org/en/datasets"",\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_path = dl_manager.download_and_extract(\n        _DOWNLOAD_URL.format(self.builder_config.language))\n    clip_folder = os.path.join(dl_path, ""clips"")\n    return [\n        tfds.core.SplitGenerator(  # pylint: disable=g-complex-comprehension\n            name=k,\n            gen_kwargs={\n                ""audio_path"": clip_folder,\n                ""label_path"": os.path.join(dl_path, ""%s.tsv"" % v)\n            },\n        ) for k, v in _SPLITS.items()\n    ]\n\n  def _generate_examples(self, audio_path, label_path):\n    """"""Generate Voice samples and statements given the data paths.\n\n    Args:\n      audio_path: str, path to audio storage folder\n      label_path: str, path to the label files\n\n    Yields:\n      example: The example `dict`\n    """"""\n    with tf.io.gfile.GFile(label_path) as file_:\n      dataset = csv.DictReader(file_, delimiter=""\\t"")\n      for i, row in enumerate(dataset):\n        file_path = os.path.join(audio_path, ""%s.mp3"" % row[""path""])\n        if tf.io.gfile.exists(file_path):\n          yield i, {\n              ""client_id"": row[""client_id""],\n              ""voice"": file_path,\n              ""sentence"": row[""sentence""],\n              ""upvotes"": int(row[""up_votes""]) if row[""up_votes""] else 0,\n              ""downvotes"": int(row[""down_votes""]) if row[""down_votes""] else 0,\n              ""age"": row[""age""],\n              ""gender"": row[""gender""] if row[""gender""] else -1,\n              ""accent"": row[""accent""] if row[""accent""] else -1\n          }\n'"
tensorflow_datasets/audio/commonvoice_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Mozilla CommonVoice Dataset Builder UnitTest.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.audio import commonvoice\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass CommonVoiceTest(tfds_test.DatasetBuilderTestCase):\n  """"""CommonVoice Tester Class.""""""\n  # Don\'t test all configs to avoid timeout\n  BUILDER_CONFIG_NAMES_TO_TEST = [""en"", ""cv""]\n  DATASET_CLASS = commonvoice.CommonVoice\n  SPLITS = {""train"": 2, ""test"": 1, ""validation"": 3}\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/audio/crema_d.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CREMA-D dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{cao2014crema,\n  title={{CREMA-D}: Crowd-sourced emotional multimodal actors dataset},\n  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},\n  journal={IEEE transactions on affective computing},\n  volume={5},\n  number={4},\n  pages={377--390},\n  year={2014},\n  publisher={IEEE}\n}\n""""""\n\n_DESCRIPTION = """"""\nCREMA-D is an audio-visual data set for emotion recognition. The data set\nconsists of facial and vocal emotional expressions in sentences spoken in a\nrange of basic emotional states (happy, sad, anger, fear, disgust, and neutral).\n7,442 clips of 91 actors with diverse ethnic backgrounds were collected.\nThis release contains only the audio stream from the original audio-visual\nrecording.\nThe samples are splitted between train, validation and testing so that samples \nfrom each speaker belongs to exactly one split.\n""""""\n\n_HOMEPAGE = \'https://github.com/CheyneyComputerScience/CREMA-D\'\n\n_CHECKSUMS_URL = \'https://storage.googleapis.com/tfds-data/manual_checksums/crema_d.txt\'\nSUMMARY_TABLE_URL = \'https://raw.githubusercontent.com/CheyneyComputerScience/CREMA-D/master/processedResults/summaryTable.csv\'\nWAV_DATA_URL = \'https://media.githubusercontent.com/media/CheyneyComputerScience/CREMA-D/master/AudioWAV/\'\nLABELS = [\'NEU\', \'HAP\', \'SAD\', \'ANG\', \'FEA\', \'DIS\']\n\n\ndef _compute_split_boundaries(split_probs, n_items):\n  """"""Computes boundary indices for each of the splits in split_probs.\n\n  Args:\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    n_items: Number of items we want to split.\n\n  Returns:\n    The item indices of boundaries between different splits. For the above\n    example and n_items=100, these will be\n    [(\'train\', 0, 60), (\'dev\', 60, 80), (\'test\', 80, 100)].\n  """"""\n  if len(split_probs) > n_items:\n    raise ValueError(\'Not enough items for the splits. There are {splits} \'\n                     \'splits while there are only {items} items\'.format(\n                         splits=len(split_probs), items=n_items))\n  total_probs = sum(p for name, p in split_probs)\n  if abs(1 - total_probs) > 1E-8:\n    raise ValueError(\'Probs should sum up to 1. probs={}\'.format(split_probs))\n  split_boundaries = []\n  sum_p = 0.0\n  for name, p in split_probs:\n    prev = sum_p\n    sum_p += p\n    split_boundaries.append((name, int(prev * n_items), int(sum_p * n_items)))\n\n  # Guard against rounding errors.\n  split_boundaries[-1] = (split_boundaries[-1][0], split_boundaries[-1][1],\n                          n_items)\n\n  return split_boundaries\n\n\ndef _get_inter_splits_by_group(items_and_groups, split_probs, split_number):\n  """"""Split items to train/dev/test, so all items in group go into same split.\n\n  Each group contains all the samples from the same speaker ID. The samples are\n  splitted between train, validation and testing so that samples from each\n  speaker belongs to exactly one split.\n\n  Args:\n    items_and_groups: Sequence of (item_id, group_id) pairs.\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    split_number: Generated splits should change with split_number.\n\n  Returns:\n    Dictionary that looks like {split name -> set(ids)}.\n  """"""\n  groups = sorted(set(group_id for item_id, group_id in items_and_groups))\n  rng = np.random.RandomState(split_number)\n  rng.shuffle(groups)\n\n  split_boundaries = _compute_split_boundaries(split_probs, len(groups))\n  group_id_to_split = {}\n  for split_name, i_start, i_end in split_boundaries:\n    for i in range(i_start, i_end):\n      group_id_to_split[groups[i]] = split_name\n\n  split_to_ids = collections.defaultdict(set)\n  for item_id, group_id in items_and_groups:\n    split = group_id_to_split[group_id]\n    split_to_ids[split].add(item_id)\n\n  return split_to_ids\n\n\nclass CremaD(tfds.core.GeneratorBasedBuilder):\n  """"""The audio part of CREMA-D dataset for emotion recognition.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(file_format=\'wav\', sample_rate=16000),\n            \'label\': tfds.features.ClassLabel(names=list(LABELS)),\n            \'speaker_id\': tf.string\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        homepage=_HOMEPAGE,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_manager.download_checksums(_CHECKSUMS_URL)\n    csv_path = dl_manager.download({\'summary_table\': SUMMARY_TABLE_URL})\n    all_wav_files = []\n    speaker_ids = []\n    wav_names = []\n    # These are file names which do do not exist in the github\n    bad_files = set([\'FileName\', \'1040_ITH_SAD_XX\', \'1006_TIE_NEU_XX\',\n                     \'1013_WSI_DIS_XX\', \'1017_IWW_FEA_XX\'])\n    with tf.io.gfile.GFile(csv_path[\'summary_table\']) as f:\n      for line in f:\n        wav_name = line.strip().split(\',\')[1].replace(\'""\', \'\')\n        if (not wav_name) or (wav_name in bad_files):\n          continue\n        wav_path = os.path.join(WAV_DATA_URL, \'%s.wav\' % wav_name)\n        all_wav_files.append(wav_path)\n        speaker_ids.append(wav_name.split(\'_\')[0])\n        wav_names.append(wav_name)\n    all_wav_files = dl_manager.download({\'all_files\': all_wav_files})\n    all_wav_files = list(zip(all_wav_files[\'all_files\'], wav_names))\n    wav_and_speaker_ids = list(zip(all_wav_files, speaker_ids))\n    split_probs = [(\'train\', 0.7), (\'validation\', 0.1), (\'test\', 0.2)]\n    splits = _get_inter_splits_by_group(wav_and_speaker_ids, split_probs, 0)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'file_paths_and_names\': splits[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'file_paths_and_names\': splits[\'validation\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'file_paths_and_names\': splits[\'test\']},\n        ),\n    ]\n\n  def _generate_examples(self, file_paths_and_names):\n    """"""Yields examples.""""""\n    for file_path, file_name in file_paths_and_names:\n      speaker_id = file_name.split(\'_\')[0]\n      label = file_name.split(\'_\')[2]\n      example = {\'audio\': file_path, \'label\': label, \'speaker_id\': speaker_id}\n      yield file_name, example\n'"
tensorflow_datasets/audio/crema_d_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for CREMA-D dataset builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import crema_d\n\n\nclass CremaDTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = crema_d.CremaD\n  SPLITS = {\n      \'train\': 2,\n      \'validation\': 1,\n      \'test\': 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'summary_table\':\n          \'summary_table.csv\',\n      \'all_files\': [\n          \'1000_AA_HAP_XX.wav\', \'1001_AA_HAP_XX.wav\',\n          \'1002_AA_ANG_XX.wav\', \'1003_AA_FEA_XX.wav\',\n      ]\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/audio/dementiabank.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DementiaBank dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport textwrap\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{boller2005dementiabank,\n  title={Dementiabank database guide},\n  author={Boller, Francois and Becker, James},\n  journal={University of Pittsburgh},\n  year={2005}\n}\n""""""\n\n_DESCRIPTION = """"""\nDementiaBank is a medical domain task. It contains 117 people diagnosed with\nAlzheimer Disease, and 93 healthy people, reading a description of an image, and\nthe task is to classify these groups.\nThis release contains only the audio part of this dataset, without the text\nfeatures.\n""""""\n\n_CONTROL_FOLDER = \'dementia/English/Pitt/Control/cookie\'\n_DEMENTIA_FOLDER = \'dementia/English/Pitt/Dementia/cookie\'\n\n\ndef _compute_split_boundaries(split_probs, n_items):\n  """"""Computes boundary indices for each of the splits in split_probs.\n\n  Args:\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    n_items: Number of items we want to split.\n\n  Returns:\n    The item indices of boundaries between different splits. For the above\n    example and n_items=100, these will be\n    [(\'train\', 0, 60), (\'dev\', 60, 80), (\'test\', 80, 100)].\n  """"""\n  if len(split_probs) > n_items:\n    raise ValueError(\'Not enough items for the splits. There are {splits} \'\n                     \'splits while there are only {items} items\'.format(\n                         splits=len(split_probs), items=n_items))\n  total_probs = sum(p for name, p in split_probs)\n  if abs(1 - total_probs) > 1E-8:\n    raise ValueError(\'Probs should sum up to 1. probs={}\'.format(split_probs))\n  split_boundaries = []\n  sum_p = 0.0\n  for name, p in split_probs:\n    prev = sum_p\n    sum_p += p\n    split_boundaries.append((name, int(prev * n_items), int(sum_p * n_items)))\n\n  # Guard against rounding errors.\n  split_boundaries[-1] = (split_boundaries[-1][0], split_boundaries[-1][1],\n                          n_items)\n\n  return split_boundaries\n\n\ndef _get_inter_splits_by_group(items_and_groups, split_probs, split_number):\n  """"""Split items to train/dev/test, so all items in group go into same split.\n\n  Each group contains all the samples from the same speaker ID. The samples are\n  splitted so that all each speaker belongs to exactly one split.\n\n  Args:\n    items_and_groups: Sequence of (item_id, group_id) pairs.\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    split_number: Generated splits should change with split_number.\n\n  Returns:\n    Dictionary that looks like {split name -> set(ids)}.\n  """"""\n  groups = sorted(set(group_id for item_id, group_id in items_and_groups))\n  rng = np.random.RandomState(split_number)\n  rng.shuffle(groups)\n\n  split_boundaries = _compute_split_boundaries(split_probs, len(groups))\n  group_id_to_split = {}\n  for split_name, i_start, i_end in split_boundaries:\n    for i in range(i_start, i_end):\n      group_id_to_split[groups[i]] = split_name\n\n  split_to_ids = collections.defaultdict(list)\n  for item_id, group_id in items_and_groups:\n    split = group_id_to_split[group_id]\n    split_to_ids[split].append(item_id)\n\n  return split_to_ids\n\n\nclass Dementiabank(tfds.core.GeneratorBasedBuilder):\n  """"""The DementiaBank dataset for voice classification of Dementia.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = textwrap.dedent(""""""\n  manual dir should contain 2 folders with mp3 files:\n\n  * {}\n  * {}\n\n  Which were downloaded from https://media.talkbank.org/dementia/English/Pitt/\n  This dataset requires registration for downloading.\n  """""".format(_CONTROL_FOLDER, _DEMENTIA_FOLDER))\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(file_format=\'mp3\', sample_rate=44100),\n            \'label\': tfds.features.ClassLabel(names=[\'dementia\', \'control\']),\n            \'speaker_id\': tf.string,\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        homepage=\'https://dementia.talkbank.org/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    control_folder = os.path.join(dl_manager.manual_dir, _CONTROL_FOLDER)\n    dementia_folder = os.path.join(dl_manager.manual_dir, _DEMENTIA_FOLDER)\n    examples_and_speaker_ids = []\n    for fname in tf.io.gfile.glob(\'{}/*.mp3\'.format(control_folder)):\n      _, short_name = os.path.split(fname)\n      speaker_id, _ = short_name.split(\'-\')\n      example = {\'audio\': fname, \'label\': \'control\', \'speaker_id\': speaker_id}\n      examples_and_speaker_ids.append((example, speaker_id))\n    for fname in tf.io.gfile.glob(\'{}/*.mp3\'.format(dementia_folder)):\n      _, short_name = os.path.split(fname)\n      speaker_id, _ = short_name.split(\'-\')\n      example = {\'audio\': fname, \'label\': \'dementia\', \'speaker_id\': speaker_id}\n      examples_and_speaker_ids.append((example, speaker_id))\n    split_probs = [(\'train\', 0.7), (\'validation\', 0.1), (\'test\', 0.2)]\n    splits = _get_inter_splits_by_group(examples_and_speaker_ids, split_probs,\n                                        0)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'examples\': splits[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'examples\': splits[\'validation\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'examples\': splits[\'test\']},\n        ),\n    ]\n\n  def _generate_examples(self, examples):\n    """"""Yields examples.""""""\n    for example in examples:\n      _, key = os.path.split(example[\'audio\'])\n      yield key, example\n'"
tensorflow_datasets/audio/dementiabank_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for DementiaBank dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import dementiabank\n\n\nclass DementiabankTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = dementiabank.Dementiabank\n  SPLITS = {\n      \'train\': 3,\n      \'validation\': 1,\n      \'test\': 1,\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/audio/groove.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Groove Midi Dataset (GMD).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport copy\nimport csv\nimport io\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nThe Groove MIDI Dataset (GMD) is composed of 13.6 hours of aligned MIDI and\n(synthesized) audio of human-performed, tempo-aligned expressive drumming\ncaptured on a Roland TD-11 V-Drum electronic drum kit.\n""""""\n\n_CITATION = """"""\n@inproceedings{groove2019,\n    Author = {Jon Gillick and Adam Roberts and Jesse Engel and Douglas Eck and David Bamman},\n    Title = {Learning to Groove with Inverse Sequence Transformations},\n    Booktitle\t= {International Conference on Machine Learning (ICML)}\n    Year = {2019},\n}\n""""""\n\n_PRIMARY_STYLES = [\n    ""afrobeat"", ""afrocuban"", ""blues"", ""country"", ""dance"", ""funk"", ""gospel"",\n    ""highlife"", ""hiphop"", ""jazz"", ""latin"", ""middleeastern"", ""neworleans"", ""pop"",\n    ""punk"", ""reggae"", ""rock"", ""soul""]\n\n_TIME_SIGNATURES = [""3-4"", ""4-4"", ""5-4"", ""5-8"", ""6-8""]\n\n_DOWNLOAD_URL = ""https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0.zip""\n_DOWNLOAD_URL_MIDI_ONLY = ""https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip""\n\n\nclass GrooveConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Groove Dataset.""""""\n\n  def __init__(self, split_bars=None, include_audio=True, audio_rate=16000,\n               **kwargs):\n    """"""Constructs a GrooveConfig.\n\n    Args:\n      split_bars: int, number of bars to include per example using a sliding\n        window across the raw data, or will not split if None.\n      include_audio: bool, whether to include audio in the examples. If True,\n        examples with missing audio will be excluded.\n      audio_rate: int, sample rate to use for audio.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name_parts = [(""%dbar"" % split_bars) if split_bars else ""full""]\n    if include_audio:\n      name_parts.append(""%dhz"" % audio_rate)\n    else:\n      name_parts.append(""midionly"")\n\n    v2 = tfds.core.Version(\n        ""2.0.1"", ""New split API (https://tensorflow.org/datasets/splits)"")\n    super(GrooveConfig, self).__init__(\n        name=""-"".join(name_parts), version=v2, **kwargs)\n    self.split_bars = split_bars\n    self.include_audio = include_audio\n    self.audio_rate = audio_rate\n\n\nclass Groove(tfds.core.GeneratorBasedBuilder):\n  """"""The Groove MIDI Dataset (GMD) of drum performances.""""""\n\n  BUILDER_CONFIGS = [\n      GrooveConfig(\n          include_audio=False,\n          description=""Groove dataset without audio, unsplit.""\n      ),\n      GrooveConfig(\n          include_audio=True,\n          description=""Groove dataset with audio, unsplit.""\n      ),\n      GrooveConfig(\n          include_audio=False,\n          split_bars=2,\n          description=""Groove dataset without audio, split into 2-bar chunks.""\n      ),\n      GrooveConfig(\n          include_audio=True,\n          split_bars=2,\n          description=""Groove dataset with audio, split into 2-bar chunks.""\n      ),\n      GrooveConfig(\n          include_audio=False,\n          split_bars=4,\n          description=""Groove dataset without audio, split into 4-bar chunks.""\n      ),\n  ]\n\n  def _info(self):\n    features_dict = {\n        ""id"": tf.string,\n        ""drummer"":\n            tfds.features.ClassLabel(\n                names=[""drummer%d"" % i for i in range(1, 11)]),\n        ""type"": tfds.features.ClassLabel(names=[""beat"", ""fill""]),\n        ""bpm"": tf.int32,\n        ""time_signature"": tfds.features.ClassLabel(names=_TIME_SIGNATURES),\n        ""style"": {\n            ""primary"": tfds.features.ClassLabel(names=_PRIMARY_STYLES),\n            ""secondary"": tf.string,\n        },\n        ""midi"": tf.string\n    }\n    if self.builder_config.include_audio:\n      features_dict[""audio""] = tfds.features.Audio(\n          dtype=tf.float32, sample_rate=self.builder_config.audio_rate)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features_dict),\n        homepage=""https://g.co/magenta/groove-dataset"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns splits.""""""\n    # Download data.\n    data_dir = os.path.join(\n        dl_manager.download_and_extract(\n            _DOWNLOAD_URL if self._builder_config.include_audio else\n            _DOWNLOAD_URL_MIDI_ONLY),\n        ""groove"")\n\n    rows = collections.defaultdict(list)\n    with tf.io.gfile.GFile(os.path.join(data_dir, ""info.csv"")) as f:\n      reader = csv.DictReader(f)\n      for row in reader:\n        rows[row[""split""]].append(row)\n\n    return [\n        tfds.core.SplitGenerator(  # pylint: disable=g-complex-comprehension\n            name=split,\n            gen_kwargs={""rows"": split_rows, ""data_dir"": data_dir})\n        for split, split_rows in rows.items()]\n\n  def _generate_examples(self, rows, data_dir):\n    split_bars = self._builder_config.split_bars\n    for row in rows:\n      split_genre = row[""style""].split(""/"")\n      with tf.io.gfile.GFile(\n          os.path.join(data_dir, row[""midi_filename""]), ""rb"") as midi_f:\n        midi = midi_f.read()\n      audio = None\n      if self._builder_config.include_audio:\n        if not row[""audio_filename""]:\n          # Skip examples with no audio.\n          logging.warning(""Skipping example with no audio: %s"", row[""id""])\n          continue\n        wav_path = os.path.join(data_dir, row[""audio_filename""])\n        audio = _load_wav(wav_path, self._builder_config.audio_rate)\n\n      example = {\n          ""id"": row[""id""],\n          ""drummer"": row[""drummer""],\n          ""type"": row[""beat_type""],\n          ""bpm"": int(row[""bpm""]),\n          ""time_signature"": row[""time_signature""],\n          ""style"": {\n              ""primary"": split_genre[0],\n              ""secondary"": split_genre[1] if len(split_genre) == 2 else """"\n          },\n      }\n      if not split_bars:\n        # Yield full example.\n        example[""midi""] = midi\n        if audio is not None:\n          example[""audio""] = audio\n        yield example[""id""], example\n      else:\n        # Yield split examples.\n        bpm = int(row[""bpm""])\n        beats_per_bar = int(row[""time_signature""].split(""-"")[0])\n        bar_duration = 60 / bpm * beats_per_bar\n        audio_rate = self._builder_config.audio_rate\n\n        pm = tfds.core.lazy_imports.pretty_midi.PrettyMIDI(io.BytesIO(midi))\n        total_duration = pm.get_end_time()\n\n        # Pad final bar if at least half filled.\n        total_bars = int(round(total_duration / bar_duration))\n        total_frames = int(total_bars * bar_duration * audio_rate)\n        if audio is not None and len(audio) < total_frames:\n          audio = np.pad(audio, [0, total_frames - len(audio)], ""constant"")\n\n        for i in range(total_bars - split_bars + 1):\n          time_range = [i * bar_duration, (i + split_bars) * bar_duration]\n\n          # Split MIDI.\n          pm_split = copy.deepcopy(pm)\n          pm_split.adjust_times(time_range, [0, split_bars * bar_duration])\n          pm_split.time_signature_changes = pm.time_signature_changes\n          midi_split = io.BytesIO()\n          pm_split.write(midi_split)\n          example[""midi""] = midi_split.getvalue()\n\n          # Split audio.\n          if audio is not None:\n            example[""audio""] = audio[\n                int(time_range[0] * audio_rate):\n                int(time_range[1] * audio_rate)]\n\n          example[""id""] += "":%03d"" % i\n          yield example[""id""], example\n\n\ndef _load_wav(path, sample_rate):\n  with tf.io.gfile.GFile(path, ""rb"") as audio_f:\n    audio_segment = tfds.core.lazy_imports.pydub.AudioSegment.from_file(\n        audio_f, format=""wav"").set_channels(1).set_frame_rate(sample_rate)\n  audio = np.array(audio_segment.get_array_of_samples()).astype(np.float32)\n  # Convert from int to float representation.\n  audio /= 2**(8 * audio_segment.sample_width)\n  return audio\n'"
tensorflow_datasets/audio/groove_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Groove dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import groove\n\n\nclass GrooveFullTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = groove.Groove\n  BUILDER_CONFIG_NAMES_TO_TEST = [""full-16000hz""]\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 1,\n  }\n  DL_EXTRACT_RESULT = ""..""\n\n\nclass GrooveFullMidiOnlyTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = groove.Groove\n  BUILDER_CONFIG_NAMES_TO_TEST = [""full-midionly""]\n  SPLITS = {\n      ""train"": 3,\n      ""test"": 1,\n  }\n  DL_EXTRACT_RESULT = ""..""\n\n\nclass Groove2BarTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = groove.Groove\n  BUILDER_CONFIG_NAMES_TO_TEST = [""2bar-16000hz""]\n  SPLITS = {\n      ""train"": 5,  # 3, 2\n      ""test"": 1,\n  }\n  DL_EXTRACT_RESULT = ""..""\n\n\nclass Groove2BarMidiOnlyTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = groove.Groove\n  BUILDER_CONFIG_NAMES_TO_TEST = [""2bar-midionly""]\n  SPLITS = {\n      ""train"": 6,  # 3, 2, 1\n      ""test"": 1,\n  }\n  DL_EXTRACT_RESULT = ""..""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/librispeech.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Librispeech dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nLibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87\n""""""\n\n_URL = ""http://www.openslr.org/12""\n_DL_URL = ""http://www.openslr.org/resources/12/""\n_DL_URLS = {\n    ""dev_clean"": _DL_URL + ""dev-clean.tar.gz"",\n    ""dev_other"": _DL_URL + ""dev-other.tar.gz"",\n    ""test_clean"": _DL_URL + ""test-clean.tar.gz"",\n    ""test_other"": _DL_URL + ""test-other.tar.gz"",\n    ""train_clean100"": _DL_URL + ""train-clean-100.tar.gz"",\n    ""train_clean360"": _DL_URL + ""train-clean-360.tar.gz"",\n    ""train_other500"": _DL_URL + ""train-other-500.tar.gz"",\n}\n\n\nclass LibrispeechConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Librispeech.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""Constructs a LibrispeechConfig.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the text feature.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name = kwargs.get(""name"")\n    if name is None:\n      name = (text_encoder_config.name if text_encoder_config else ""plain_text"")\n    kwargs[""name""] = name\n\n    description = kwargs.get(""description"")\n    if description is None:\n      if text_encoder_config:\n        description = ""Transcriptions use the %s"" % (\n            text_encoder_config.encoder_cls.__name__)\n      else:\n        description = ""Transcriptions are in plain text.""\n    kwargs[""description""] = description\n\n    super(LibrispeechConfig, self).__init__(**kwargs)\n    self.text_encoder_config = text_encoder_config\n\n\ndef _make_builder_configs():\n  """"""Make built-in Librispeech BuilderConfigs.\n\n  Uses 3 text encodings (plain_text, subwords with 8k vocab, subwords with 32k\n  vocab).\n\n  Returns:\n    `list<tfds.audio.LibrispeechConfig>`\n  """"""\n  text_encoder_configs = [\n      None,\n      tfds.features.text.TextEncoderConfig(\n          name=""subwords8k"",\n          encoder_cls=tfds.features.text.SubwordTextEncoder,\n          vocab_size=2**13),\n      tfds.features.text.TextEncoderConfig(\n          name=""subwords32k"",\n          encoder_cls=tfds.features.text.SubwordTextEncoder,\n          vocab_size=2**15),\n  ]\n  configs = []\n  for text_encoder_config in text_encoder_configs:\n    config = LibrispeechConfig(\n        version=tfds.core.Version(""1.1.0""),\n        text_encoder_config=text_encoder_config)\n    configs.append(config)\n  return configs\n\n\nclass Librispeech(tfds.core.BeamBasedBuilder):\n  """"""Librispeech dataset.""""""\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""speech"":\n                tfds.features.Audio(sample_rate=16000),\n            ""text"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""speaker_id"":\n                tf.int64,\n            ""chapter_id"":\n                tf.int64,\n            ""id"":\n                tf.string,\n        }),\n        supervised_keys=(""speech"", ""text""),\n        homepage=_URL,\n        citation=_CITATION,\n        metadata=tfds.core.MetadataDict(sample_rate=16000,),\n    )\n\n  def _vocab_text_gen(self, dirs):\n    for directory in dirs:\n      for _, example in _generate_librispeech_examples(directory):\n        yield example[""text""]\n\n  def _populate_metadata(self, dirs):\n    # All dirs contain the same metadata.\n    directory = list(dirs.values())[0]\n    self.info.metadata[""speakers""] = self._read_metadata_file(\n        os.path.join(directory, ""LibriSpeech/SPEAKERS.TXT""),\n        [""speaker_id"", ""gender"", ""subset"", ""minutes"", ""name""])\n    self.info.metadata[""chapters""] = self._read_metadata_file(\n        os.path.join(directory, ""LibriSpeech/CHAPTERS.TXT""), [\n            ""chapter_id"", ""speaker_id"", ""minutes"", ""subset"", ""project_id"",\n            ""book_id"", ""chapter_title"", ""project_title""\n        ])\n\n  def _read_metadata_file(self, path, field_names):\n    metadata = {}\n    with tf.io.gfile.GFile(path) as f:\n      for line in f:\n        if line.startswith("";""):\n          continue\n        fields = line.split(""|"", len(field_names))\n        metadata[int(fields[0])] = {\n            k: v.strip() for k, v in zip(field_names[1:], fields[1:])\n        }\n    return metadata\n\n  def _split_generators(self, dl_manager):\n    extracted_dirs = dl_manager.download_and_extract(_DL_URLS)\n    # Generate vocabulary from training data if SubwordTextEncoder configured.\n    all_train_dirs = [\n        v for k, v in extracted_dirs.items() if k.startswith(""train"")\n    ]\n    self.info.features[""text""].maybe_build_from_corpus(\n        self._vocab_text_gen(all_train_dirs))\n    self._populate_metadata(extracted_dirs)\n    splits = [tfds.core.SplitGenerator(name=k, gen_kwargs={""directory"": v})\n              for k, v in extracted_dirs.items()]\n    return splits\n\n  def _build_pcollection(self, pipeline, directory):\n    """"""Generates examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n    return (pipeline\n            | beam.Create([directory])\n            | beam.FlatMap(_generate_librispeech_examples)\n            | beam.Reshuffle())\n\n\ndef _generate_librispeech_examples(directory):\n  """"""Generate examples from a Librispeech directory.""""""\n  transcripts_glob = os.path.join(directory, ""LibriSpeech"", ""*/*/*/*.txt"")\n  for transcript_file in tf.io.gfile.glob(transcripts_glob):\n    path = os.path.dirname(transcript_file)\n    with tf.io.gfile.GFile(os.path.join(path, transcript_file)) as f:\n      for line in f:\n        line = line.strip()\n        key, transcript = line.split("" "", 1)\n        audio_file = ""%s.flac"" % key\n        speaker_id, chapter_id = [int(el) for el in key.split(""-"")[:2]]\n        example = {\n            ""id"": key,\n            ""speaker_id"": speaker_id,\n            ""chapter_id"": chapter_id,\n            ""speech"": os.path.join(path, audio_file),\n            ""text"": transcript\n        }\n        yield key, example\n'"
tensorflow_datasets/audio/librispeech_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for librispeech dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import librispeech\n\n\nclass LibrispeechTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = librispeech.Librispeech\n  BUILDER_CONFIG_NAMES_TO_TEST = [""plain_text"", ""subwords8k""]\n  SPLITS = {\n      ""train_clean100"": 2,\n      ""train_clean360"": 2,\n      ""train_other500"": 2,\n      ""test_clean"": 2,\n      ""test_other"": 2,\n      ""dev_clean"": 2,\n      ""dev_other"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_clean100"": ""train-clean-100"",\n      ""train_clean360"": ""train-clean-360"",\n      ""train_other500"": ""train-other-500"",\n      ""test_clean"": ""test-clean"",\n      ""test_other"": ""test-other"",\n      ""dev_clean"": ""dev-clean"",\n      ""dev_other"": ""dev-other"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/libritts.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""LibriTTS dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\nimport tarfile\n\nimport six\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{zen2019libritts,\n  title = {LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech},\n  author = {H. Zen and V. Dang and R. Clark and Y. Zhang and R. J. Weiss and Y. Jia and Z. Chen and Y. Wu},\n  booktitle = {Proc. Interspeech},\n  month = sep,\n  year = {2019},\n  doi = {10.21437/Interspeech.2019-2441},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nLibriTTS is a multi-speaker English corpus of approximately 585 hours of read\nEnglish speech at 24kHz sampling rate, prepared by Heiga Zen with the assistance\nof Google Speech and Google Brain team members. The LibriTTS corpus is designed\nfor TTS research. It is derived from the original materials (mp3 audio files\nfrom LibriVox and text files from Project Gutenberg) of the LibriSpeech corpus.\nThe main differences from the LibriSpeech corpus are listed below:\n\n1. The audio files are at 24kHz sampling rate.\n2. The speech is split at sentence breaks.\n3. Both original and normalized texts are included.\n4. Contextual information (e.g., neighbouring sentences) can be extracted.\n5. Utterances with significant background noise are excluded.\n""""""\n\n_URL = ""http://www.openslr.org/60""\n_DL_URL = ""http://www.openslr.org/resources/60/""\n_DL_URLS = {\n    ""dev_clean"": _DL_URL + ""dev-clean.tar.gz"",\n    ""dev_other"": _DL_URL + ""dev-other.tar.gz"",\n    ""test_clean"": _DL_URL + ""test-clean.tar.gz"",\n    ""test_other"": _DL_URL + ""test-other.tar.gz"",\n    ""train_clean100"": _DL_URL + ""train-clean-100.tar.gz"",\n    ""train_clean360"": _DL_URL + ""train-clean-360.tar.gz"",\n    ""train_other500"": _DL_URL + ""train-other-500.tar.gz"",\n}\n\n\nclass Libritts(tfds.core.BeamBasedBuilder):\n  """"""LibriTTS dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.1"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""speech"": tfds.features.Audio(\n                file_format=""wav"", sample_rate=24000),\n            ""text_original"": tfds.features.Text(),\n            ""text_normalized"": tfds.features.Text(),\n            ""speaker_id"": tf.int64,\n            ""chapter_id"": tf.int64,\n            ""id"": tf.string,\n        }),\n        supervised_keys=(""text_normalized"", ""speech""),\n        homepage=_URL,\n        citation=_CITATION,\n        metadata=tfds.core.MetadataDict(sample_rate=24000,),\n    )\n\n  def _populate_metadata(self, archive_paths):\n    # All archives contain the same metadata.\n    archive_path = list(archive_paths.values())[0]\n\n    speaker_info = {}\n    with tf.io.gfile.GFile(archive_path, ""rb"") as f:\n      tarf = tarfile.open(mode=""r:gz"", fileobj=f)\n      speakers_tsv = tarf.extractfile(""LibriTTS/speakers.tsv"")\n      for n, line in enumerate(speakers_tsv):\n        # Skip the first line which is just a header.\n        if n == 0:\n          continue\n        fields = line.decode(""utf-8"").strip().split(""\\t"")\n        if len(fields) == 3:\n          # Some lines are missing the final field, so leave it blank.\n          fields.append("""")\n        id_str, gender, subset, name = fields\n        speaker_info[int(id_str)] = {\n            ""gender"": gender,\n            ""subset"": subset,\n            ""name"": name,\n        }\n    self.info.metadata[""speakers""] = speaker_info\n\n  def _split_generators(self, dl_manager):\n    archives = dl_manager.download(_DL_URLS)\n    self._populate_metadata(archives)\n    splits = [\n        tfds.core.SplitGenerator(name=k, gen_kwargs={""archive_path"": v})\n        for k, v in archives.items()\n    ]\n    return splits\n\n  def _build_pcollection(self, pipeline, archive_path):\n    """"""Generates examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n    return (pipeline\n            | beam.Create([archive_path])\n            | beam.FlatMap(_extract_libritts_data)\n            | beam.Reshuffle()\n            | ""merge_transcripts_and_audio"" >> beam.CombinePerKey(_merge_dicts))\n\n\ndef _generate_transcripts(transcript_csv_file):\n  """"""Generates partial examples from transcript CSV file.""""""\n  for line in transcript_csv_file:\n    key, text_original, text_normalized = line.decode(""utf-8"").split(""\\t"")\n    speaker_id, chapter_id = [int(el) for el in key.split(""_"")[:2]]\n    example = {\n        ""text_normalized"": text_normalized,\n        ""text_original"": text_original,\n        ""speaker_id"": speaker_id,\n        ""chapter_id"": chapter_id,\n        ""id"": key,\n    }\n    yield key, example\n\n\ndef _extract_libritts_data(archive_path):\n  """"""Generate partial audio or transcript examples from a LibriTTS archive.""""""\n  for path, contents in tfds.core.download.extractor.iter_tar(archive_path):\n    if path.endswith("".trans.tsv""):\n      for key, example in _generate_transcripts(contents):\n        yield key, example\n    elif path.endswith("".wav""):\n      key = six.ensure_text(os.path.splitext(os.path.basename(path))[0])\n      memfile = io.BytesIO(contents.read())\n      example = {""speech"": memfile}\n      yield key, example\n\n\ndef _merge_dicts(dicts):\n  merged = {}\n  for d in dicts:\n    merged.update(d)\n  return merged\n'"
tensorflow_datasets/audio/libritts_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for libritts dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import libritts\n\n\nclass LibriTTSTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = libritts.Libritts\n  SPLITS = {\n      ""train_clean100"": 2,\n      ""train_clean360"": 2,\n      ""train_other500"": 2,\n      ""test_clean"": 2,\n      ""test_other"": 2,\n      ""dev_clean"": 2,\n      ""dev_other"": 2,\n  }\n  DL_DOWNLOAD_RESULT = {\n      ""train_clean100"": ""train-clean-100.tar.gz"",\n      ""train_clean360"": ""train-clean-360.tar.gz"",\n      ""train_other500"": ""train-other-500.tar.gz"",\n      ""test_clean"": ""test-clean.tar.gz"",\n      ""test_other"": ""test-other.tar.gz"",\n      ""dev_clean"": ""dev-clean.tar.gz"",\n      ""dev_other"": ""dev-other.tar.gz"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/ljspeech.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""LJSpeech dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@misc{ljspeech17,\n  author       = {Keith Ito},\n  title        = {The LJ Speech Dataset},\n  howpublished = {\\\\url{https://keithito.com/LJ-Speech-Dataset/}},\n  year         = 2017\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThis is a public domain speech dataset consisting of 13,100 short audio clips of\na single speaker reading passages from 7 non-fiction books. A transcription is\nprovided for each clip. Clips vary in length from 1 to 10 seconds and have a\ntotal length of approximately 24 hours.\n\nThe texts were published between 1884 and 1964, and are in the public domain.\nThe audio was recorded in 2016-17 by the LibriVox project and is also in the\npublic domain.\n""""""\n\n_URL = ""https://keithito.com/LJ-Speech-Dataset/""\n_DL_URL = ""https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2""\n\n\nclass Ljspeech(tfds.core.GeneratorBasedBuilder):\n  """"""LJSpeech dataset.""""""\n\n  VERSION = tfds.core.Version(""1.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""id"": tf.string,\n            ""speech"": tfds.features.Audio(sample_rate=22050),\n            ""text"": tfds.features.Text(),\n            ""text_normalized"": tfds.features.Text(),\n        }),\n        supervised_keys=(""text_normalized"", ""speech""),\n        homepage=_URL,\n        citation=_CITATION,\n        metadata=tfds.core.MetadataDict(sample_rate=22050),\n    )\n\n  def _split_generators(self, dl_manager):\n    extracted_dir = dl_manager.download_and_extract(_DL_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""directory"": extracted_dir},\n        ),\n    ]\n\n  def _generate_examples(self, directory):\n    """"""Yields examples.""""""\n    metadata_path = os.path.join(directory, ""LJSpeech-1.1"", ""metadata.csv"")\n    with tf.io.gfile.GFile(metadata_path) as f:\n      for line in f:\n        line = line.strip()\n        key, transcript, transcript_normalized = line.split(""|"")\n        wav_path = os.path.join(directory, ""LJSpeech-1.1"", ""wavs"",\n                                ""%s.wav"" % key)\n        example = {\n            ""id"": key,\n            ""speech"": wav_path,\n            ""text"": transcript,\n            ""text_normalized"": transcript_normalized,\n        }\n        yield key, example\n'"
tensorflow_datasets/audio/ljspeech_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for ljspeech dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import ljspeech\n\n\nclass LJSpeechTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = ljspeech.Ljspeech\n  SPLITS = {\n      ""train"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/nsynth.py,14,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""NSynth Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nThe NSynth Dataset is an audio dataset containing ~300k musical notes, each\nwith a unique pitch, timbre, and envelope. Each note is annotated with three\nadditional pieces of information based on a combination of human evaluation\nand heuristic algorithms: Source, Family, and Qualities.\n""""""\n\n_FULL_DESCRIPTION = """"""\\\nFull NSynth Dataset is split into train, valid, and test sets, with no\ninstruments overlapping between the train set and the valid/test sets.\n""""""\n\n_GANSYNTH_DESCRIPTION = """"""\\\nNSynth Dataset limited to acoustic instruments in the MIDI pitch interval\n[24, 84]. Uses alternate splits that have overlap in instruments (but not exact\nnotes) between the train set and valid/test sets. This variant was originally\nintroduced in the ICLR 2019 GANSynth paper (https://arxiv.org/abs/1902.08710).\n""""""\n\n_F0_AND_LOUDNESS_ADDENDUM = """"""\\\nThis version additionally contains estimates for F0 using CREPE\n(Kim et al., 2018) and A-weighted perceptual loudness in decibels. Both signals\nare provided at a frame rate of 250Hz.\n""""""\n\n# From http://proceedings.mlr.press/v70/engel17a.html\n_CITATION = """"""\\\n@InProceedings{pmlr-v70-engel17a,\n  title = \t {Neural Audio Synthesis of Musical Notes with {W}ave{N}et Autoencoders},\n  author = \t {Jesse Engel and Cinjon Resnick and Adam Roberts and Sander Dieleman and Mohammad Norouzi and Douglas Eck and Karen Simonyan},\n  booktitle = \t {Proceedings of the 34th International Conference on Machine Learning},\n  pages = \t {1068--1077},\n  year = \t {2017},\n  editor = \t {Doina Precup and Yee Whye Teh},\n  volume = \t {70},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {International Convention Centre, Sydney, Australia},\n  month = \t {06--11 Aug},\n  publisher = \t {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v70/engel17a/engel17a.pdf},\n  url = \t {http://proceedings.mlr.press/v70/engel17a.html},\n}\n""""""\n\n_NUM_SECS = 4\n_AUDIO_RATE = 16000  # 16 kHz\n_F0_AND_LOUDNESS_RATE = 250  # 250 Hz\n_CREPE_FRAME_SIZE = 1024\n_LD_N_FFT = 2048\n_LD_RANGE = 120.0\n_REF_DB = 20.7  # White noise, amplitude=1.0, n_fft=2048\n\n_INSTRUMENT_FAMILIES = [\n    ""bass"", ""brass"", ""flute"", ""guitar"", ""keyboard"", ""mallet"", ""organ"", ""reed"",\n    ""string"", ""synth_lead"", ""vocal""\n]\n_INSTRUMENT_SOURCES = [""acoustic"", ""electronic"", ""synthetic""]\n_QUALITIES = [\n    ""bright"", ""dark"", ""distortion"", ""fast_decay"", ""long_release"", ""multiphonic"",\n    ""nonlinear_env"", ""percussive"", ""reverb"", ""tempo-synced""\n]\n\n_BASE_DOWNLOAD_PATH = ""http://download.magenta.tensorflow.org/datasets/nsynth/nsynth-""\n\n_SPLITS = [""train"", ""valid"", ""test""]\n\n\nclass NsynthConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for NSynth Dataset.""""""\n\n  def __init__(self,\n               gansynth_subset=False,\n               estimate_f0_and_loudness=False,\n               **kwargs):\n    """"""Constructs a NsynthConfig.\n\n    Args:\n      gansynth_subset: bool, whether to use the subset of the dataset introduced\n        in the ICLR 2019 GANSynth paper (Engel, et al. 2018). This subset uses\n        acoustic-only instrument sources and limits the pitches to the interval\n        [24, 84]. The train and test splits are also modified so that\n        instruments (but not specific notes) overlap between them. See\n        https://arxiv.org/abs/1902.08710 for more details.\n      estimate_f0_and_loudness: bool, whether to estimate fundamental frequency\n        (F0) and loudness for the audio (at 250 Hz) and add them to the set of\n        features.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name_parts = []\n    if gansynth_subset:\n      name_parts.append(""gansynth_subset"")\n    else:\n      name_parts.append(""full"")\n    if estimate_f0_and_loudness:\n      name_parts.append(""f0_and_loudness"")\n    v230 = tfds.core.Version(\n        ""2.3.0"", ""New `loudness_db` feature in decibels (unormalized)."")\n    v231 = tfds.core.Version(\n        ""2.3.1"", ""F0 computed with normalization fix in CREPE."")\n    v232 = tfds.core.Version(\n        ""2.3.2"", ""Use Audio feature."")\n    super(NsynthConfig, self).__init__(\n        name=""."".join(name_parts),\n        version=v232,\n        supported_versions=[v231, v230],\n        **kwargs)\n    self.gansynth_subset = gansynth_subset\n    self.estimate_f0_and_loudness = estimate_f0_and_loudness\n\n\nclass Nsynth(tfds.core.BeamBasedBuilder):\n  """"""A large-scale and high-quality dataset of annotated musical notes.""""""\n  BUILDER_CONFIGS = [\n      NsynthConfig(description=_FULL_DESCRIPTION),\n      NsynthConfig(gansynth_subset=True, description=_GANSYNTH_DESCRIPTION),\n      NsynthConfig(\n          gansynth_subset=True,\n          estimate_f0_and_loudness=True,\n          description=_GANSYNTH_DESCRIPTION + _F0_AND_LOUDNESS_ADDENDUM),\n  ]\n\n  def _info(self):\n    features = {\n        ""id"":\n            tf.string,\n        ""audio"":\n            tfds.features.Audio(\n                shape=(_AUDIO_RATE * _NUM_SECS,),\n                dtype=tf.float32,\n                sample_rate=_AUDIO_RATE,\n            ),\n        ""pitch"":\n            tfds.features.ClassLabel(num_classes=128),\n        ""velocity"":\n            tfds.features.ClassLabel(num_classes=128),\n        ""instrument"": {\n            # We read the list of labels in _split_generators.\n            ""label"": tfds.features.ClassLabel(num_classes=1006),\n            ""family"": tfds.features.ClassLabel(names=_INSTRUMENT_FAMILIES),\n            ""source"": tfds.features.ClassLabel(names=_INSTRUMENT_SOURCES),\n        },\n        ""qualities"": {quality: tf.bool for quality in _QUALITIES},\n    }\n    if self.builder_config.estimate_f0_and_loudness:\n      f0_and_ld_shape = (_F0_AND_LOUDNESS_RATE * _NUM_SECS,)\n      features[""f0""] = {\n          ""hz"":\n              tfds.features.Tensor(shape=f0_and_ld_shape, dtype=tf.float32),\n          ""midi"":\n              tfds.features.Tensor(shape=f0_and_ld_shape, dtype=tf.float32),\n          ""confidence"":\n              tfds.features.Tensor(shape=f0_and_ld_shape, dtype=tf.float32)\n      }\n      features[""loudness""] = {\n          ""db"": tfds.features.Tensor(shape=f0_and_ld_shape, dtype=tf.float32)\n      }\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        homepage=""https://g.co/magenta/nsynth-dataset"",\n        citation=_CITATION,\n        metadata=tfds.core.BeamMetadataDict(sample_rate=_AUDIO_RATE,),\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns splits.""""""\n\n    dl_urls = {}\n    dl_urls[""examples""] = {\n        split: _BASE_DOWNLOAD_PATH + ""%s.tfrecord.tar"" % split\n        for split in _SPLITS\n    }\n    dl_urls[""instrument_labels""] = (\n        _BASE_DOWNLOAD_PATH + ""instrument_labels.txt"")\n    if self.builder_config.gansynth_subset:\n      dl_urls[""gansynth_splits""] = (_BASE_DOWNLOAD_PATH + ""gansynth_splits.csv"")\n    dl_paths = dl_manager.download_and_extract(dl_urls)\n\n    with tf.io.gfile.GFile(dl_paths[""instrument_labels""]) as f:\n      instrument_labels = f.read().strip().splitlines()\n    self.info.features[""instrument""][""label""].names = instrument_labels\n\n    split_ids = {s: set() for s in _SPLITS}\n    split_dirs = {s: [dl_paths[""examples""][s]] for s in _SPLITS}\n    if self.builder_config.gansynth_subset:\n      # Generator needs to see all original splits for each new split.\n      split_dirs = {s: dl_paths[""examples""].values() for s in _SPLITS}\n      with tf.io.gfile.GFile(dl_paths[""gansynth_splits""]) as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n          split_ids[row[""split""]].add(row[""id""])\n\n    return [\n        tfds.core.SplitGenerator(  # pylint: disable=g-complex-comprehension\n            name=split,\n            gen_kwargs={\n                ""tfrecord_dirs"": split_dirs[split],\n                ""ids"": split_ids[split],\n                ""split"": split,\n            })\n        for split in _SPLITS\n    ]\n\n  def _build_pcollection(self, pipeline, tfrecord_dirs, ids, split):\n    """"""Build PCollection of examples for split.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _emit_base_example(ex):\n      """"""Maps an input example to a TFDS example.""""""\n      beam.metrics.Metrics.counter(split, ""base-examples"").inc()\n      features = ex.features.feature\n      id_ = features[""note_str""].bytes_list.value[0]\n      return id_, {\n          ""id"":\n              id_,\n          ""audio"":\n              np.array(features[""audio""].float_list.value, dtype=np.float32),\n          ""pitch"":\n              features[""pitch""].int64_list.value[0],\n          ""velocity"":\n              features[""velocity""].int64_list.value[0],\n          ""instrument"": {\n              ""label"":\n                  tf.compat.as_text(\n                      features[""instrument_str""].bytes_list.value[0]),\n              ""family"":\n                  tf.compat.as_text(\n                      features[""instrument_family_str""].bytes_list.value[0]),\n              ""source"":\n                  tf.compat.as_text(\n                      features[""instrument_source_str""].bytes_list.value[0])\n          },\n          ""qualities"": {\n              q: features[""qualities""].int64_list.value[i]\n              for (i, q) in enumerate(_QUALITIES)\n          }\n      }\n\n    def _in_split(id_ex, split_ids):\n      unused_id, ex = id_ex\n      if not split_ids or tf.compat.as_text(ex[""id""]) in split_ids:\n        beam.metrics.Metrics.counter(split, ""in-split"").inc()\n        return True\n      return False\n\n    def _estimate_f0(id_ex):\n      """"""Estimate the fundamental frequency using CREPE and add to example.""""""\n      id_, ex = id_ex\n      beam.metrics.Metrics.counter(split, ""estimate-f0"").inc()\n\n      audio = ex[""audio""]\n\n      # Copied from magenta/ddsp/spectral_ops.py\n      # Pad end so that `num_frames = _NUM_SECS * _F0_AND_LOUDNESS_RATE`.\n      hop_size = _AUDIO_RATE / _F0_AND_LOUDNESS_RATE\n      n_samples = len(audio)\n      n_frames = _NUM_SECS * _F0_AND_LOUDNESS_RATE\n      n_samples_padded = (n_frames - 1) * hop_size + _CREPE_FRAME_SIZE\n      n_padding = (n_samples_padded - n_samples)\n      assert n_padding % 1 == 0\n      audio = np.pad(audio, (0, int(n_padding)), mode=""constant"")\n      crepe_step_size = 1000 / _F0_AND_LOUDNESS_RATE  # milliseconds\n\n      _, f0_hz, f0_confidence, _ = tfds.core.lazy_imports.crepe.predict(\n          audio,\n          sr=_AUDIO_RATE,\n          viterbi=True,\n          step_size=crepe_step_size,\n          center=False,\n          verbose=0)\n      f0_midi = tfds.core.lazy_imports.librosa.core.hz_to_midi(f0_hz)\n      # Set -infs introduced by hz_to_midi to 0.\n      f0_midi[f0_midi == -np.inf] = 0\n      # Set nans to 0 in confidence.\n      f0_confidence = np.nan_to_num(f0_confidence)\n      ex = dict(ex)\n      ex[""f0""] = {\n          ""hz"": f0_hz.astype(np.float32),\n          ""midi"": f0_midi.astype(np.float32),\n          ""confidence"": f0_confidence.astype(np.float32),\n      }\n      return id_, ex\n\n    def _calc_loudness(id_ex):\n      """"""Compute loudness, add to example (ref is white noise, amplitude=1).""""""\n      id_, ex = id_ex\n      beam.metrics.Metrics.counter(split, ""compute-loudness"").inc()\n\n      audio = ex[""audio""]\n\n      # Copied from magenta/ddsp/spectral_ops.py\n      # Get magnitudes.\n      hop_size = int(_AUDIO_RATE // _F0_AND_LOUDNESS_RATE)\n\n      # Add padding to the end\n      n_samples_initial = int(audio.shape[-1])\n      n_frames = int(np.ceil(n_samples_initial / hop_size))\n      n_samples_final = (n_frames - 1) * hop_size + _LD_N_FFT\n      pad = n_samples_final - n_samples_initial\n      audio = np.pad(audio, ((0, pad),), ""constant"")\n\n      librosa = tfds.core.lazy_imports.librosa\n      spectra = librosa.stft(\n          audio, n_fft=_LD_N_FFT, hop_length=hop_size, center=False).T\n\n      # Compute power\n      amplitude = np.abs(spectra)\n      amin = 1e-20  # Avoid log(0) instabilities.\n      power_db = np.log10(np.maximum(amin, amplitude))\n      power_db *= 20.0\n\n      # Perceptual weighting.\n      frequencies = librosa.fft_frequencies(sr=_AUDIO_RATE, n_fft=_LD_N_FFT)\n      a_weighting = librosa.A_weighting(frequencies)[np.newaxis, :]\n      loudness = power_db + a_weighting\n\n      # Set dynamic range.\n      loudness -= _REF_DB\n      loudness = np.maximum(loudness, -_LD_RANGE)\n\n      # Average over frequency bins.\n      mean_loudness_db = np.mean(loudness, axis=-1)\n\n      ex = dict(ex)\n      ex[""loudness""] = {""db"": mean_loudness_db.astype(np.float32)}\n      return id_, ex\n\n    examples = (\n        pipeline\n        | beam.Create([os.path.join(dir_, ""*"") for dir_ in tfrecord_dirs])\n        | beam.io.tfrecordio.ReadAllFromTFRecord(\n            coder=beam.coders.ProtoCoder(tf.train.Example))\n        | beam.Map(_emit_base_example)\n        | beam.Filter(_in_split, split_ids=ids))\n    if self.builder_config.estimate_f0_and_loudness:\n      examples = (\n          examples\n          | beam.Reshuffle()\n          | beam.Map(_estimate_f0)\n          | beam.Map(_calc_loudness))\n\n    return examples\n'"
tensorflow_datasets/audio/nsynth_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Nsynth Dataset Builder test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.audio import nsynth\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass NsynthFullTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = nsynth.Nsynth\n  # Make test run faster by using fewer output shards.\n  nsynth._SPLIT_SHARDS = {""train"": 1, ""valid"": 1, ""test"": 1,}\n  BUILDER_CONFIG_NAMES_TO_TEST = [""full""]\n  SPLITS = {""train"": 3, ""test"": 3, ""valid"": 3}\n  DL_EXTRACT_RESULT = {\n      ""examples"": {\n          ""train"": ""train"",\n          ""test"": ""test"",\n          ""valid"": ""valid"",\n      },\n      ""instrument_labels"": ""nsynth-instrument_labels.txt""\n  }\n\n\nclass GANsynthTest(NsynthFullTest):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""gansynth_subset""]\n  SPLITS = {""train"": 2, ""test"": 1, ""valid"": 1}\n  DL_EXTRACT_RESULT = dict(NsynthFullTest.DL_EXTRACT_RESULT)\n  DL_EXTRACT_RESULT[""gansynth_splits""] = ""gansynth_splits.csv""\n\n\nclass GANsynthWithF0AndLoudnessTest(GANsynthTest):\n  MOCK_OUT_FORBIDDEN_OS_FUNCTIONS = False\n  BUILDER_CONFIG_NAMES_TO_TEST = [""gansynth_subset.f0_and_loudness""]\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/audio/savee.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SAVEE dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport re\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nLABEL_MAP = {\n    \'a\': \'anger\',\n    \'d\': \'disgust\',\n    \'f\': \'fear\',\n    \'h\': \'happiness\',\n    \'n\': \'neutral\',\n    \'sa\': \'sadness\',\n    \'su\': \'surprise\',\n}\n\nSPEAKERS = [\'DC\', \'JE\', \'JK\', \'KL\']\n\n_CITATION = """"""\n@inproceedings{Vlasenko_combiningframe,\nauthor = {Vlasenko, Bogdan and Schuller, Bjorn and Wendemuth, Andreas and Rigoll, Gerhard},\nyear = {2007},\nmonth = {01},\npages = {2249-2252},\ntitle = {Combining frame and turn-level information for robust recognition of emotions within speech},\njournal = {Proceedings of Interspeech}\n}\n""""""\n\n_DESCRIPTION = """"""\nSAVEE (Surrey Audio-Visual Expressed Emotion) is an emotion recognition\ndataset. It consists of recordings from 4 male actors in 7 different emotions,\n480 British English utterances in total. The sentences were chosen from the\nstandard TIMIT corpus and phonetically-balanced for each emotion.\nThis release contains only the audio stream from the original audio-visual\nrecording.\nThe data is split so that the training set consists of 2 speakers, and both the\nvalidation and test set consists of samples from 1 speaker, respectively.\n""""""\n\n\ndef _compute_split_boundaries(split_probs, n_items):\n  """"""Computes boundary indices for each of the splits in split_probs.\n\n  Args:\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    n_items: Number of items we want to split.\n\n  Returns:\n    The item indices of boundaries between different splits. For the above\n    example and n_items=100, these will be\n    [(\'train\', 0, 60), (\'dev\', 60, 80), (\'test\', 80, 100)].\n  """"""\n  if len(split_probs) > n_items:\n    raise ValueError(\'Not enough items for the splits. There are {splits} \'\n                     \'splits while there are only {items} items\'.format(\n                         splits=len(split_probs), items=n_items))\n  total_probs = sum(p for name, p in split_probs)\n  if abs(1 - total_probs) > 1E-8:\n    raise ValueError(\'Probs should sum up to 1. probs={}\'.format(split_probs))\n  split_boundaries = []\n  sum_p = 0.0\n  for name, p in split_probs:\n    prev = sum_p\n    sum_p += p\n    split_boundaries.append((name, int(prev * n_items), int(sum_p * n_items)))\n\n  # Guard against rounding errors.\n  split_boundaries[-1] = (split_boundaries[-1][0], split_boundaries[-1][1],\n                          n_items)\n\n  return split_boundaries\n\n\ndef _get_inter_splits_by_group(items_and_groups, split_probs, split_number):\n  """"""Split items to train/dev/test, so all items in group go into same split.\n\n  Each group contains all the samples from the same speaker ID. The samples are\n  splitted so that all each speaker belongs to exactly one split.\n\n  Args:\n    items_and_groups: Sequence of (item_id, group_id) pairs.\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    split_number: Generated splits should change with split_number.\n\n  Returns:\n    Dictionary that looks like {split name -> set(ids)}.\n  """"""\n  groups = sorted(set(group_id for item_id, group_id in items_and_groups))\n  rng = np.random.RandomState(split_number)\n  rng.shuffle(groups)\n\n  split_boundaries = _compute_split_boundaries(split_probs, len(groups))\n  group_id_to_split = {}\n  for split_name, i_start, i_end in split_boundaries:\n    for i in range(i_start, i_end):\n      group_id_to_split[groups[i]] = split_name\n\n  split_to_ids = collections.defaultdict(set)\n  for item_id, group_id in items_and_groups:\n    split = group_id_to_split[group_id]\n    split_to_ids[split].add(item_id)\n\n  return split_to_ids\n\n\nclass Savee(tfds.core.GeneratorBasedBuilder):\n  """"""The audio part of SAVEE dataset for emotion recognition.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  manual_dir should contain the file AudioData.zip. This file should be under\n  Data/Zip/AudioData.zip in the dataset folder provided upon registration.\n  You need to register at\n  http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Register.html in\n  order to get the link to download the dataset.\n  """"""\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(file_format=\'wav\', sample_rate=44100),\n            \'label\': tfds.features.ClassLabel(names=list(LABEL_MAP.values())),\n            \'speaker_id\': tf.string\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        homepage=\'http://kahlan.eps.surrey.ac.uk/savee/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    zip_path = os.path.join(dl_manager.manual_dir, \'AudioData.zip\')\n    if not tf.io.gfile.exists(zip_path):\n      raise AssertionError(\n          \'SAVEE requires manual download of the data. Please download \'\n          \'the audio data and place it into: {}\'.format(zip_path))\n    # Need to extract instead of reading directly from archive since reading\n    # audio files from zip archive is not supported.\n    extract_path = dl_manager.extract(zip_path)\n\n    items_and_groups = []\n    for fname in tf.io.gfile.glob(\'{}/AudioData/*/*.wav\'.format(extract_path)):\n      folder, _ = os.path.split(fname)\n      _, speaker_id = os.path.split(folder)\n      items_and_groups.append((fname, speaker_id))\n\n    split_probs = [(\'train\', 0.6), (\'validation\', 0.2), (\'test\', 0.2)]\n    splits = _get_inter_splits_by_group(items_and_groups, split_probs, 0)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'file_names\': splits[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'file_names\': splits[\'validation\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'file_names\': splits[\'test\']},\n        ),\n    ]\n\n  def _generate_examples(self, file_names):\n    """"""Yields examples.""""""\n    for fname in file_names:\n      folder, wavname = os.path.split(fname)\n      _, speaker_id = os.path.split(folder)\n      label_abbrev = re.match(\'^([a-zA-Z]+)\', wavname).group(1)  # pytype: disable=attribute-error\n      label = LABEL_MAP[label_abbrev]\n      key = \'{}_{}\'.format(speaker_id, wavname.split(\'.\')[0])\n      yield key, {\'audio\': fname, \'label\': label, \'speaker_id\': speaker_id}\n'"
tensorflow_datasets/audio/savee_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for SAVEE dataset builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import savee\n\n\nclass SaveeTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = savee.Savee\n  SPLITS = {\n      ""train"": 8,\n      ""validation"": 4,\n      ""test"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/speech_commands.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SpeechCommands dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\n\nfrom tensorflow_datasets.core import lazy_imports_lib\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{speechcommandsv2,\n   author = {{Warden}, P.},\n    title = ""{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}"",\n  journal = {ArXiv e-prints},\n  archivePrefix = ""arXiv"",\n  eprint = {1804.03209},\n  primaryClass = ""cs.CL"",\n  keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n    year = 2018,\n    month = apr,\n    url = {https://arxiv.org/abs/1804.03209},\n}\n""""""\n\n_DESCRIPTION = """"""\nAn audio dataset of spoken words designed to help train and evaluate keyword\nspotting systems. Its primary goal is to provide a way to build and test small\nmodels that detect when a single word is spoken, from a set of ten target words,\nwith as few false positives as possible from background noise or unrelated\nspeech. Note that in the train and validation set, the label ""unknown"" is much\nmore prevalent than the labels of the target words or background noise.\nOne difference from the release version is the handling of silent segments.\nWhile in the test set the silence segments are regular 1 second files, in the\ntraining they are provided as long segments under ""background_noise"" folder.\nHere we split these background noise into 1 second clips, and also keep one of\nthe files for the validation set.\n""""""\n\n_DOWNLOAD_PATH = \'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\'\n_TEST_DOWNLOAD_PATH_ = \'http://download.tensorflow.org/data/speech_commands_test_set_v0.02.tar.gz\'\n\n_SPLITS = [\'train\', \'valid\', \'test\']\n\nWORDS = [\'down\', \'go\', \'left\', \'no\', \'off\', \'on\', \'right\', \'stop\', \'up\', \'yes\']\nSILENCE = \'_silence_\'\nUNKNOWN = \'_unknown_\'\nBACKGROUND_NOISE = \'_background_noise_\'\nSAMPLE_RATE = 16000\n\n\nclass SpeechCommands(tfds.core.GeneratorBasedBuilder):\n  """"""The Speech Commands dataset for keyword detection.""""""\n\n  VERSION = tfds.core.Version(\'0.0.2\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(\n                file_format=\'wav\', sample_rate=SAMPLE_RATE),\n            \'label\': tfds.features.ClassLabel(names=WORDS + [SILENCE, UNKNOWN])\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        # Homepage of the dataset for documentation\n        homepage=\'https://arxiv.org/abs/1804.03209\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    dl_path, dl_test_path = dl_manager.download(\n        [_DOWNLOAD_PATH, _TEST_DOWNLOAD_PATH_])\n\n    train_paths, validation_paths = self._split_archive(\n        dl_manager.iter_archive(dl_path))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'archive\': dl_manager.iter_archive(dl_path),\n                        \'file_list\': train_paths},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'archive\': dl_manager.iter_archive(dl_path),\n                        \'file_list\': validation_paths},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'archive\': dl_manager.iter_archive(dl_test_path),\n                        \'file_list\': None},\n        ),\n    ]\n\n  def _generate_examples(self, archive, file_list):\n    """"""Yields examples.""""""\n    for path, file_obj in archive:\n      if file_list is not None and path not in file_list:\n        continue\n      relpath, wavname = os.path.split(path)\n      _, word = os.path.split(relpath)\n      example_id = \'{}_{}\'.format(word, wavname)\n      if word in WORDS:\n        label = word\n      elif word == SILENCE or word == BACKGROUND_NOISE:\n        # The main tar file already contains all of the test files, except for\n        # the silence ones. In fact it does not contain silence files at all.\n        # So for the test set we take the silence files from the test tar file,\n        # while for train and validation we build them from the\n        # _background_noise_ folder.\n        label = SILENCE\n      else:\n        # Note that in the train and validation there are a lot more _unknown_\n        # labels than any of the other ones.\n        label = UNKNOWN\n\n      if word == BACKGROUND_NOISE:\n        # Special handling of background noise. We need to cut these files to\n        # many small files with 1 seconds length, and transform it to silence.\n        audio_samples = np.array(\n            lazy_imports_lib.lazy_imports.pydub.AudioSegment.from_file(\n                file_obj, format=\'wav\').get_array_of_samples())\n\n        for start in range(0,\n                           len(audio_samples) - SAMPLE_RATE, SAMPLE_RATE // 2):\n          audio_segment = audio_samples[start:start + SAMPLE_RATE]\n          cur_id = \'{}_{}\'.format(example_id, start)\n          example = {\'audio\': audio_segment, \'label\': label}\n          yield cur_id, example\n      else:\n        try:\n          example = {\n              \'audio\':\n                  np.array(\n                      lazy_imports_lib.lazy_imports.pydub.AudioSegment\n                      .from_file(file_obj,\n                                 format=\'wav\').get_array_of_samples()),\n              \'label\':\n                  label,\n          }\n          yield example_id, example\n        except lazy_imports_lib.lazy_imports.pydub.exceptions.CouldntDecodeError:\n          pass\n\n  def _split_archive(self, train_archive):\n    train_paths = []\n    for path, file_obj in train_archive:\n      if \'testing_list.txt\' in path:\n        train_test_paths = file_obj.read().strip().splitlines()\n        train_test_paths = [p.decode(\'ascii\') for p in train_test_paths]\n      elif \'validation_list.txt\' in path:\n        validation_paths = file_obj.read().strip().splitlines()\n        validation_paths = [p.decode(\'ascii\') for p in validation_paths]\n      elif path.endswith(\'.wav\'):\n        train_paths.append(path)\n\n    # Original validation files did include silence - we add them manually here\n    validation_paths.append(\n        os.path.join(BACKGROUND_NOISE, \'running_tap.wav\'))\n\n    # The paths for the train set is just whichever paths that do not exist in\n    # either the test or validation splits.\n    train_paths = (\n        set(train_paths) - set(validation_paths) - set(train_test_paths))\n\n    return train_paths, validation_paths\n'"
tensorflow_datasets/audio/speech_commands_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TODO(speech_commands): Add a description here.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import speech_commands\n\n\nclass SpeechCommandsTest(testing.DatasetBuilderTestCase):\n  # TODO(speech_commands):\n  DATASET_CLASS = speech_commands.SpeechCommands\n  SPLITS = {\n      ""train"": 4,  # Number of fake train example\n      ""validation"": 3,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n\n  DL_EXTRACT_RESULT = [""train.tar.gz"", ""test.tar.gz""]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/tedlium.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TED-LIUM speech recognition dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nimport numpy as np\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\nclass TedliumReleaseConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for a release of the TED-LIUM dataset.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, url, download_url, split_paths, citation, **kwargs):\n    super(TedliumReleaseConfig,\n          self).__init__(version=tfds.core.Version(""1.0.1""), **kwargs)\n    self.url = url\n    self.download_url = download_url\n    # List of split, path pairs containing the relative path within the\n    # extracted tarball to the data for each split.\n    self.split_paths = split_paths\n    self.citation = citation\n\n\ndef _make_builder_configs():\n  """"""Creates builder configs for all supported Tedlium dataset releases.""""""\n  release1 = TedliumReleaseConfig(\n      name=""release1"",\n      description=""""""\\\n        The TED-LIUM corpus is English-language TED talks, with transcriptions,\n        sampled at 16kHz. It contains about 118 hours of speech.\n\n        This is the TED-LIUM corpus release 1,\n        licensed under Creative Commons BY-NC-ND 3.0\n        (http://creativecommons.org/licenses/by-nc-nd/3.0/deed.en).\n        """""",\n      citation=""""""\\\n        @inproceedings{rousseau2012tedlium,\n          title={TED-LIUM: an Automatic Speech Recognition dedicated corpus},\n          author={Rousseau, Anthony and Del{\\\\\'e}glise, Paul and Est{\\\\`e}ve, Yannick},\n          booktitle={Conference on Language Resources and Evaluation (LREC)},\n          pages={125--129},\n          year={2012}\n        }\n        """""",\n      url=""https://www.openslr.org/7/"",\n      download_url=""http://www.openslr.org/resources/7/TEDLIUM_release1.tar.gz"",\n      split_paths=[(tfds.Split.TRAIN, os.path.join(""TEDLIUM_release1"",\n                                                   ""train"")),\n                   (tfds.Split.VALIDATION,\n                    os.path.join(""TEDLIUM_release1"", ""dev"")),\n                   (tfds.Split.TEST, os.path.join(""TEDLIUM_release1"", ""test""))])\n\n  release2 = TedliumReleaseConfig(\n      name=""release2"",\n      description=""""""\\\n        This is the TED-LIUM corpus release 2,\n        licensed under Creative Commons BY-NC-ND 3.0\n        (http://creativecommons.org/licenses/by-nc-nd/3.0/deed.en).\n\n        All talks and text are property of TED Conferences LLC.\n\n        The TED-LIUM corpus was made from audio talks and their transcriptions\n        available on the TED website. We have prepared and filtered these data\n        in order to train acoustic models to participate to the International\n        Workshop on Spoken Language Translation 2011 (the LIUM English/French\n        SLT system reached the first rank in the SLT task).\n\n        Contains 1495 talks and transcripts.\n        """""",\n      citation=""""""\\\n        @inproceedings{rousseau2014tedlium2,\n          title={Enhancing the {TED-LIUM} Corpus with Selected Data for Language Modeling and More {TED} Talks},\n          author={Rousseau, Anthony and Del{\\\\\'e}glise, Paul and Est{\\\\`e}ve, Yannick},\n          booktitle={Conference on Language Resources and Evaluation (LREC)},\n          year={2014}\n        }\n        """""",\n      url=""https://www.openslr.org/19/"",\n      download_url=""http://www.openslr.org/resources/19/TEDLIUM_release2.tar.gz"",\n      split_paths=[(tfds.Split.TRAIN, os.path.join(""TEDLIUM_release2"",\n                                                   ""train"")),\n                   (tfds.Split.VALIDATION,\n                    os.path.join(""TEDLIUM_release2"", ""dev"")),\n                   (tfds.Split.TEST, os.path.join(""TEDLIUM_release2"", ""test""))])\n\n  release3 = TedliumReleaseConfig(\n      name=""release3"",\n      description=""""""\\\n        This is the TED-LIUM corpus release 3, licensed under Creative Commons\n        BY-NC-ND 3.0.\n\n        All talks and text are property of TED Conferences LLC.\n\n        This new TED-LIUM release was made through a collaboration between the\n        Ubiqus company and the LIUM (University of Le Mans, France)\n\n        Contents:\n\n        - 2351 audio talks in NIST sphere format (SPH), including talks from\n          TED-LIUM 2: be careful, same talks but not same audio files (only\n          these audio file must be used with the TED-LIUM 3 STM files)\n        - 452 hours of audio\n        - 2351 aligned automatic transcripts in STM format\n        - TEDLIUM 2 dev and test data: 19 TED talks in SPH format with\n          corresponding manual transcriptions (cf. \'legacy\' distribution below).\n        - Dictionary with pronunciations (159848 entries), same file as the one\n          included in TED-LIUM 2\n        - Selected monolingual data for language modeling from WMT12 publicly\n          available corpora: these files come from the TED-LIUM 2 release, but\n          have been modified to get a tokenization more relevant for English\n          language\n\n        Two corpus distributions:\n        - the legacy one, on which the dev and test datasets are the same as in\n          TED-LIUM 2 (and TED-LIUM 1).\n        - the \'speaker adaptation\' one, especially designed for experiments on\n          speaker adaptation.\n        """""",\n      citation=""""""\\\n        @inproceedings{hernandez2018tedlium3,\n          title={TED-LIUM 3: twice as much data and corpus repartition for experiments on speaker adaptation},\n          author={Hernandez, Fran{\\\\c{c}}ois and Nguyen, Vincent and Ghannay, Sahar and Tomashenko, Natalia and Est{\\\\`e}ve, Yannick},\n          booktitle={International Conference on Speech and Computer},\n          pages={198--208},\n          year={2018},\n          organization={Springer}\n        }\n        """""",\n      url=""https://www.openslr.org/51/"",\n      download_url=tfds.download.Resource(\n          url=""http://www.openslr.org/resources/51/TEDLIUM_release-3.tgz"",\n          # The blessed tarball linked above contains some invalid symlinks (for\n          # the speaker_adaptation splits) which TAR_STREAM conveniently skips\n          # over, avoiding exceptions on parts of the dataset we don\'t need.\n          extract_method=tfds.download.ExtractMethod.TAR_STREAM),\n      split_paths=[\n          (tfds.Split.VALIDATION,\n           os.path.join(""TEDLIUM_release-3"", ""legacy"", ""dev"")),\n          (tfds.Split.TEST, os.path.join(""TEDLIUM_release-3"", ""legacy"",\n                                         ""test"")),\n          # The legacy/train directory contains symlinks to ""data"",\n          # which are skipped by extraction (see above).\n          # Work around this by manually dereferencing the links here.\n          (tfds.Split.TRAIN, os.path.join(""TEDLIUM_release-3"", ""data""))\n      ])\n\n  return [release1, release2, release3]\n\n\nclass Tedlium(tfds.core.BeamBasedBuilder):\n  """"""TED-LIUM speech recognition dataset.""""""\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=self.builder_config.description,\n        features=tfds.features.FeaturesDict({\n            ""speech"":\n                tfds.features.Audio(sample_rate=16000),\n            ""text"":\n                tfds.features.Text(),\n            ""speaker_id"":\n                tf.string,\n            ""gender"":\n                tfds.features.ClassLabel(names=[""unknown"", ""female"", ""male""]),\n            ""id"":\n                tf.string,\n        }),\n        supervised_keys=(""speech"", ""text""),\n        homepage=self.builder_config.url,\n        citation=self.builder_config.citation,\n        metadata=tfds.core.MetadataDict(sample_rate=16000,),\n    )\n\n  def _split_generators(self, dl_manager):\n    extracted_dir = dl_manager.download_and_extract(\n        self.builder_config.download_url)\n    splits = []\n    for split, path in self.builder_config.split_paths:\n      kwargs = {""directory"": os.path.join(extracted_dir, path)}\n      splits.append(tfds.core.SplitGenerator(name=split, gen_kwargs=kwargs))\n    return splits\n\n  def _build_pcollection(self, pipeline, directory):\n    beam = tfds.core.lazy_imports.apache_beam\n    stm_files = tf.io.gfile.glob(os.path.join(directory, ""stm"", ""*stm""))\n    return (pipeline\n            | beam.Create(stm_files)\n            | beam.FlatMap(_generate_examples_from_stm_file))\n\n\ndef _generate_examples_from_stm_file(stm_path):\n  """"""Generate examples from a TED-LIUM stm file.""""""\n  stm_dir = os.path.dirname(stm_path)\n  sph_dir = os.path.join(os.path.dirname(stm_dir), ""sph"")\n  with tf.io.gfile.GFile(stm_path) as f:\n    for line in f:\n      line = line.strip()\n      fn, channel, speaker, start, end, label, transcript = line.split("" "", 6)\n      transcript = _maybe_trim_suffix(transcript)\n\n      audio_file = ""%s.sph"" % fn\n      samples = _extract_audio_segment(\n          os.path.join(sph_dir, audio_file), int(channel), float(start),\n          float(end))\n\n      key = ""-"".join([speaker, start, end, label])\n      example = {\n          ""speech"": samples,\n          ""text"": transcript,\n          ""speaker_id"": speaker,\n          ""gender"": _parse_gender(label),\n          ""id"": key,\n      }\n      yield key, example\n\n\ndef _maybe_trim_suffix(transcript):\n  # stm files for the TEDLIUM release 1 train split contain a key (enclosed in\n  # parens) at the end.\n  splits = transcript.rsplit("" "", 1)\n  transcript = splits[0]\n  if len(splits) > 1:\n    suffix = splits[-1]\n    if not suffix.startswith(""(""):\n      transcript += "" "" + suffix\n  return transcript\n\n\ndef _parse_gender(label_str):\n  """"""Parse gender string from STM ""<label>"" field.""""""\n  gender = re.split("",|_"", label_str)[-1][:-1]\n  # Fix inconsistencies in the data.\n  if not gender:\n    gender = -1  # Missing label.\n  elif gender == ""<NA"":  # In TEDLIUM release 3 training data.\n    gender = -1  # Missing label.\n  elif gender == ""F"":\n    gender = ""female""\n  elif gender == ""M"":\n    gender = ""male""\n  return gender\n\n\ndef _extract_audio_segment(sph_path, channel, start_sec, end_sec):\n  """"""Extracts segment of audio samples (as an ndarray) from the given path.""""""\n  with tf.io.gfile.GFile(sph_path, ""rb"") as f:\n    segment = tfds.core.lazy_imports.pydub.AudioSegment.from_file(\n        f, format=""nistsphere"")\n  # The dataset only contains mono audio.\n  assert segment.channels == 1\n  assert channel == 1\n  start_ms = int(start_sec * 1000)\n  end_ms = int(end_sec * 1000)\n  segment = segment[start_ms:end_ms]\n  samples = np.array(segment.get_array_of_samples())\n  return samples\n'"
tensorflow_datasets/audio/tedlium_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tedlium dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import tedlium\nimport tensorflow_datasets.public_api as tfds\n\n\nclass TedliumTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = tedlium.Tedlium\n  BUILDER_CONFIG_NAMES_TO_TEST = [""release1""]\n  SPLITS = {\n      tfds.Split.TRAIN: 4,\n      tfds.Split.TEST: 1,\n      tfds.Split.VALIDATION: 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/audio/voxceleb.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The audio part of VoxCeleb dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@InProceedings{Nagrani17,\n\tauthor       = ""Nagrani, A. and Chung, J.~S. and Zisserman, A."",\n\ttitle        = ""VoxCeleb: a large-scale speaker identification dataset"",\n\tbooktitle    = ""INTERSPEECH"",\n\tyear         = ""2017"",\n}\n""""""\n\n_DESCRIPTION = """"""\nAn large scale dataset for speaker identification. This data is collected from\nover 1,251 speakers, with over 150k samples in total.\nThis release contains the audio part of the voxceleb1.1 dataset.\n""""""\n\n_HOMEPAGE = \'http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html\'\n\nIDEN_SPLITS_URL = \'http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\'\nNUM_CLASSES = 1252\n\n\nclass Voxceleb(tfds.core.GeneratorBasedBuilder):\n  """"""The VoxCeleb dataset for speaker identification.""""""\n\n  VERSION = tfds.core.Version(\'1.1.1\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\n  manual_dir should contain the file vox_dev_wav.zip. The instructions for\n  downloading this file are found in {}. This dataset requires registration.\n  """""".format(_HOMEPAGE)\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(file_format=\'wav\', sample_rate=16000),\n            \'label\': tfds.features.ClassLabel(num_classes=NUM_CLASSES),\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        homepage=_HOMEPAGE,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    zip_path = os.path.join(dl_manager.manual_dir, \'vox_dev_wav.zip\')\n    if not tf.io.gfile.exists(zip_path):\n      raise AssertionError(\n          \'VoxCeleb requires manual download of the data. Please download \'\n          \'the audio data and place it into: {}\'.format(zip_path))\n    # Need to extract instead of reading directly from archive since reading\n    # audio files from zip archive is not supported.\n    extract_path = dl_manager.extract(zip_path)\n\n    # Download the file defining the train/validation/test split on speakers.\n    iden_splits_path = dl_manager.download({\'iden_split\': IDEN_SPLITS_URL})\n    iden_splits = self._calculate_splits(iden_splits_path[\'iden_split\'])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'extract_path\': extract_path,\n                \'file_names\': iden_splits[\'train\']\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'extract_path\': extract_path,\n                \'file_names\': iden_splits[\'validation\']\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'extract_path\': extract_path,\n                \'file_names\': iden_splits[\'test\']\n            },\n        ),\n    ]\n\n  def _generate_examples(self, extract_path, file_names):\n    """"""Yields examples.""""""\n    for file_name in file_names:\n      full_name = os.path.join(extract_path, \'wav\', file_name)\n      if not tf.io.gfile.exists(full_name):\n        continue\n      speaker, _, _ = file_name[:-len(\'.wav\')].split(\'/\')\n      speaker_id = int(speaker[3:])\n      example = {\'audio\': full_name, \'label\': speaker_id}\n      yield file_name, example\n\n  def _calculate_splits(self, iden_splits_path):\n    """"""Read the train/dev/test splits from VoxCeleb\'s iden_split.txt file.""""""\n    data_splits = collections.defaultdict(set)\n    with tf.io.gfile.GFile(iden_splits_path) as f:\n      for line in f:\n        group, path = line.strip().split()\n        split_name = {1: \'train\', 2: \'validation\', 3: \'test\'}[int(group)]\n        data_splits[split_name].add(path.strip())\n    return data_splits\n'"
tensorflow_datasets/audio/voxceleb_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for VoxCeleb dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import voxceleb\n\n\nclass VoxcelebTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = voxceleb.Voxceleb\n  SPLITS = {\n      \'train\': 2,\n      \'validation\': 1,\n      \'test\': 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'iden_split\': \'iden_split.txt\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/audio/voxforge.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""VoxForge dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport datetime\nimport os\nimport textwrap\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{maclean2018voxforge,\n  title={Voxforge},\n  author={MacLean, Ken},\n  journal={Ken MacLean.[Online]. Available: http://www.voxforge.org/home.[Acedido em 2012]},\n  year={2018}\n}\n""""""\n\n_LAST_DATE = datetime.date(2020, 1, 1)\n\n_DESCRIPTION = """"""\nVoxForge is a language classification dataset. It consists of user submitted\naudio clips submitted to the website. In this release, data from 6 languages\nis collected - English, Spanish, French, German, Russian, and Italian.\nSince the website is constantly updated, and for the sake of reproducibility,\nthis release contains only recordings submitted prior to {}.\nThe samples are splitted between train, validation and testing so that samples\nfrom each speaker belongs to exactly one split.\n"""""".format(_LAST_DATE.isoformat())\n\n_HOMEPAGE = \'http://www.voxforge.org/\'\n\n\n_URLS_LIST_FILE = \'https://storage.googleapis.com/tfds-data/downloads/voxforge/voxforge_urls.txt\'\n\nLABELS = [\'de\', \'en\', \'es\', \'fr\', \'it\', \'ru\']\n\n\ndef _compute_split_boundaries(split_probs, n_items):\n  """"""Computes boundary indices for each of the splits in split_probs.\n\n  Args:\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    n_items: Number of items we want to split.\n\n  Returns:\n    The item indices of boundaries between different splits. For the above\n    example and n_items=100, these will be\n    [(\'train\', 0, 60), (\'dev\', 60, 80), (\'test\', 80, 100)].\n  """"""\n  if len(split_probs) > n_items:\n    raise ValueError(\'Not enough items for the splits. There are {splits} \'\n                     \'splits while there are only {items} items\'.format(\n                         splits=len(split_probs), items=n_items))\n  total_probs = sum(p for name, p in split_probs)\n  if abs(1 - total_probs) > 1E-8:\n    raise ValueError(\'Probs should sum up to 1. probs={}\'.format(split_probs))\n  split_boundaries = []\n  sum_p = 0.0\n  for name, p in split_probs:\n    prev = sum_p\n    sum_p += p\n    split_boundaries.append((name, int(prev * n_items), int(sum_p * n_items)))\n\n  # Guard against rounding errors.\n  split_boundaries[-1] = (split_boundaries[-1][0], split_boundaries[-1][1],\n                          n_items)\n\n  return split_boundaries\n\n\ndef _get_inter_splits_by_group(items_and_groups, split_probs, split_number):\n  """"""Split items to train/dev/test, so all items in group go into same split.\n\n  Each group contains all the samples from the same speaker ID. The samples are\n  splitted between train, validation and testing so that samples from each\n  speaker belongs to exactly one split.\n\n  Args:\n    items_and_groups: Sequence of (item_id, group_id) pairs.\n    split_probs: List of (split_name, prob), e.g. [(\'train\', 0.6), (\'dev\', 0.2),\n      (\'test\', 0.2)]\n    split_number: Generated splits should change with split_number.\n\n  Returns:\n    Dictionary that looks like {split name -> set(ids)}.\n  """"""\n  groups = sorted(set(group_id for item_id, group_id in items_and_groups))\n  rng = np.random.RandomState(split_number)\n  rng.shuffle(groups)\n\n  split_boundaries = _compute_split_boundaries(split_probs, len(groups))\n  group_id_to_split = {}\n  for split_name, i_start, i_end in split_boundaries:\n    for i in range(i_start, i_end):\n      group_id_to_split[groups[i]] = split_name\n\n  split_to_ids = collections.defaultdict(set)\n  for item_id, group_id in items_and_groups:\n    split = group_id_to_split[group_id]\n    split_to_ids[split].add(item_id)\n\n  return split_to_ids\n\n\nclass Voxforge(tfds.core.GeneratorBasedBuilder):\n  """"""A Language classification dataset based on the VoxForge website.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = textwrap.dedent(""""""\n  VoxForge requires manual download of the audio archives. The complete list of\n  archives can be found in {}. It can be downloaded using the following command:\n  wget -i voxforge_urls.txt -x\n  Note that downloading and building the dataset locally requires ~100GB disk\n  space (but only ~60GB will be used permanently).\n  """""".format(_URLS_LIST_FILE))\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'audio\': tfds.features.Audio(file_format=\'wav\', sample_rate=16000),\n            \'label\': tfds.features.ClassLabel(names=LABELS),\n            \'speaker_id\': tf.string\n        }),\n        supervised_keys=(\'audio\', \'label\'),\n        homepage=_HOMEPAGE,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    urls_list = dl_manager.download({\'urls_list\': _URLS_LIST_FILE})\n    archive_urls = []\n    with tf.io.gfile.GFile(urls_list[\'urls_list\']) as f:\n      for line in f:\n        archive_url = line.strip().replace(\'""\', \'\').replace(\'\\\'\', \'\')\n        archive_path = os.path.join(dl_manager.manual_dir, archive_url)\n        if not tf.io.gfile.exists(archive_path):\n          raise AssertionError(\n              \'VoxForge requires manual download. Path {} is missing\'.format(\n                  archive_path))\n        archive_urls.append(archive_path)\n\n    archives = archive_urls\n\n    archives_and_speaker_ids = []\n    for archive, archive_url in zip(archives, archive_urls):\n      _, archive_name = os.path.split(archive_url)\n      speaker_id = archive_name.split(\'-\')[0]\n      archives_and_speaker_ids.append((archive, speaker_id))\n\n    split_probs = [(\'train\', 0.7), (\'validation\', 0.1), (\'test\', 0.2)]\n    splits = _get_inter_splits_by_group(archives_and_speaker_ids, split_probs,\n                                        0)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'file_names\': splits[\'train\'],\n                        \'dl_manager\': dl_manager},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'file_names\': splits[\'validation\'],\n                        \'dl_manager\': dl_manager},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'file_names\': splits[\'test\'],\n                        \'dl_manager\': dl_manager},\n        ),\n    ]\n\n  def _generate_examples(self, file_names, dl_manager):\n    """"""Yields examples.""""""\n    for fname in file_names:\n      folder, archive_name = os.path.split(fname)\n      speaker_id = archive_name.split(\'-\')[0]\n      label_idx = folder.index(\'/Trunk\') - 2\n      label = folder[label_idx:label_idx + 2]\n      iter_archive = dl_manager.iter_archive(fname)\n      for wav_path, wav_obj in iter_archive:\n        if not wav_path.endswith(\'.wav\'):\n          continue\n        _, wav_name = os.path.split(wav_path)\n        key = \'{}_{}_{}\'.format(label, archive_name, wav_name[:-len(\'.wav\')])\n        yield key, {\'audio\': wav_obj, \'label\': label, \'speaker_id\': speaker_id}\n'"
tensorflow_datasets/audio/voxforge_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for VoxForge dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.audio import voxforge\n\n\nclass VoxforgeTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = voxforge.Voxforge\n  SPLITS = {\n      \'train\': 2,\n      \'validation\': 1,\n      \'test\': 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'urls_list\': \'urls_list.txt\',\n  }\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""API to define datasets.""""""\n# Ensure TensorFlow is importable and its version is sufficiently recent. This\n# needs to happen before anything else, since the imports below will try to\n# import tensorflow, too.\nfrom tensorflow_datasets.core import tf_compat\ntf_compat.ensure_tf_install()\n\nfrom tensorflow_datasets.core.api_utils import disallow_positional_args  # pylint:disable=g-import-not-at-top\n\nfrom tensorflow_datasets.core.constants import add_data_dir\n\nfrom tensorflow_datasets.core.dataset_builder import BeamBasedBuilder\nfrom tensorflow_datasets.core.dataset_builder import BuilderConfig\nfrom tensorflow_datasets.core.dataset_builder import DatasetBuilder\nfrom tensorflow_datasets.core.dataset_builder import GeneratorBasedBuilder\n\nfrom tensorflow_datasets.core.dataset_info import BeamMetadataDict\nfrom tensorflow_datasets.core.dataset_info import DatasetInfo\nfrom tensorflow_datasets.core.dataset_info import Metadata\nfrom tensorflow_datasets.core.dataset_info import MetadataDict\n\nfrom tensorflow_datasets.core.lazy_imports_lib import lazy_imports\n\nfrom tensorflow_datasets.core.splits import Split\nfrom tensorflow_datasets.core.splits import SplitDict\nfrom tensorflow_datasets.core.splits import SplitGenerator\nfrom tensorflow_datasets.core.splits import SplitInfo\nfrom tensorflow_datasets.core.splits import SubSplitInfo\n\nfrom tensorflow_datasets.core.tfrecords_reader import ReadInstruction\n\nfrom tensorflow_datasets.core.utils import Experiment\nfrom tensorflow_datasets.core.utils import gcs_path\nfrom tensorflow_datasets.core.utils import get_tfds_path\nfrom tensorflow_datasets.core.utils import Version\n\n\n__all__ = [\n    ""add_data_dir"",\n    ""BeamBasedBuilder"",\n    ""BeamMetadataDict"",\n    ""BuilderConfig"",\n    ""DatasetBuilder"",\n    ""DatasetInfo"",\n    ""disallow_positional_args"",\n    ""Experiment"",\n    ""GeneratorBasedBuilder"",\n    ""get_tfds_path"",\n    ""gcs_path"",\n    ""lazy_imports"",\n    ""Metadata"",\n    ""MetadataDict"",\n    ""ReadInstruction"",\n    ""SplitDict"",\n    ""SplitGenerator"",\n    ""SplitInfo"",\n    ""Version"",\n]\n'"
tensorflow_datasets/core/api_utils.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""API utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport inspect\nimport typing\nfrom typing import Any, Callable, List, Optional, TypeVar\n\nimport six\nimport wrapt\n\n__all__ = [\n    ""disallow_positional_args""\n]\n\nFn = TypeVar(""Fn"", bound=Callable[..., Any])\n\nREQUIRED_ARG = object()\n_POSITIONAL_ARG_ERR_MSG = (\n    ""Please use keyword arguments and not positional arguments. This enables ""\n    ""more flexible API development. Thank you!\\n""\n    ""Positional arguments passed to fn %s: %s."")\n\n\n# `disallow_positional_args` can be applied as a decorator `@decorator` or\n# as a decorator factory `@decorator(**options)`, so we\'re using\n# `@typing.overload` to define both signatures.\n@typing.overload\ndef disallow_positional_args(\n    wrapped: None = ...,\n    allowed: Optional[List[str]] = ...,\n) -> Callable[[Fn], Fn]:\n  ...\n@typing.overload\ndef disallow_positional_args(wrapped: Fn, allowed: None = ...) -> Fn:  # pylint: disable=g-wrong-blank-lines\n  ...\ndef disallow_positional_args(wrapped=None, allowed=None):  # pylint: disable=g-wrong-blank-lines\n  """"""Requires function to be called using keyword arguments.""""""\n  # See\n  # https://wrapt.readthedocs.io/en/latest/decorators.html#decorators-with-optional-arguments\n  # for decorator pattern.\n  if wrapped is None:\n    return functools.partial(disallow_positional_args, allowed=allowed)  # pytype: disable=bad-return-type\n\n  @wrapt.decorator\n  def disallow_positional_args_dec(fn, instance, args, kwargs):\n    ismethod = instance is not None\n    _check_no_positional(fn, args, ismethod, allowed=allowed)\n    _check_required(fn, kwargs)\n    return fn(*args, **kwargs)\n\n  return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\n\n\ndef _check_no_positional(fn, args, is_method=False, allowed=None):\n  allowed = set(allowed or [])\n  offset = int(is_method)\n  if args:\n    arg_names = getargspec(fn).args[offset:offset + len(args)]\n    if all([name in allowed for name in arg_names]):\n      return\n    raise ValueError(_POSITIONAL_ARG_ERR_MSG % (fn.__name__, str(arg_names)))\n\n\ndef _required_args(fn):\n  """"""Returns arguments of fn with default=REQUIRED_ARG.""""""\n  spec = getargspec(fn)\n  if not spec.defaults:\n    return []\n\n  arg_names = spec.args[-len(spec.defaults):]\n  return [name for name, val in zip(arg_names, spec.defaults)\n          if val is REQUIRED_ARG]\n\n\ndef _check_required(fn, kwargs):\n  required_args = _required_args(fn)\n  for arg in required_args:\n    if arg not in kwargs:\n      raise ValueError(""Argument %s is required."" % arg)\n\n\ndef getargspec(fn):\n  if six.PY3:\n    spec = inspect.getfullargspec(fn)\n  else:\n    spec = inspect.getargspec(fn)  # pylint: disable=deprecated-method\n  return spec\n'"
tensorflow_datasets/core/api_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.api_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import api_utils\n\n\nclass ApiUtilsTest(testing.TestCase):\n\n  def test_disallow_positional_args(self):\n\n    @api_utils.disallow_positional_args\n    def fn(a, b, c=api_utils.REQUIRED_ARG, d=4):\n      return (a, b, c, d)\n\n    self.assertEqual([""a"", ""b"", ""c"", ""d""], api_utils.getargspec(fn).args)\n    self.assertEqual((1, 2, 3, 4), fn(a=1, b=2, c=3))\n    predicate = ""use keyword""\n    with self.assertRaisesWithPredicateMatch(ValueError, predicate):\n      fn(1, 2, 3)\n    with self.assertRaisesWithPredicateMatch(ValueError, predicate):\n      fn(1, b=2, c=3)\n    with self.assertRaisesWithPredicateMatch(ValueError, ""is required""):\n      fn(a=1, b=2)\n\n  def test_disallow_positional_args_with_exceptions(self):\n\n    @api_utils.disallow_positional_args(allowed=[""a""])\n    def fn(a, b, c=api_utils.REQUIRED_ARG, d=4):\n      return (a, b, c, d)\n\n    self.assertEqual([""a"", ""b"", ""c"", ""d""], api_utils.getargspec(fn).args)\n    self.assertEqual((1, 2, 3, 4), fn(a=1, b=2, c=3))\n    predicate = ""use keyword""\n    with self.assertRaisesWithPredicateMatch(ValueError, predicate):\n      fn(1, 2, 3)\n    self.assertEqual((1, 2, 3, 4), fn(1, b=2, c=3))\n\n  def test_disallow_positional_args_method(self):\n\n    class A(object):\n\n      def __init__(self):\n        self.e = 5\n\n      @api_utils.disallow_positional_args\n      def fn(self, a, b, c=api_utils.REQUIRED_ARG, d=4):\n        return (a, b, c, d, self.e)\n\n    obj = A()\n    fn = obj.fn\n\n    self.assertEqual((1, 2, 3, 4, 5), fn(a=1, b=2, c=3))\n    predicate = ""use keyword""\n    with self.assertRaisesWithPredicateMatch(ValueError, predicate):\n      fn(1, 2, 3)\n    with self.assertRaisesWithPredicateMatch(ValueError, predicate):\n      fn(1, b=2, c=3)\n    with self.assertRaisesWithPredicateMatch(ValueError, ""is required""):\n      fn(a=1, b=2)\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/constants.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Default values for some parameters of the API when no values are passed.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# IMPORTANT: when changing values here, update docstrings.\n\nimport os\n\n# Github base URL\nSRC_BASE_URL = \'https://github.com/tensorflow/datasets/tree/master/\'\n\n# Directory where to store processed datasets.\nDATA_DIR = os.path.join(\'~\', \'tensorflow_datasets\')\n\n# Suffix of files / directories which aren\'t finished downloading / extracting.\nINCOMPLETE_SUFFIX = \'.incomplete\'\n\n# Note: GCS constants are defined in `core/utils/gcs_utils.py`\n\n\n_registered_data_dir = set()\n\n\ndef add_data_dir(data_dir):\n  """"""Registers a new default `data_dir` to search for datasets.\n\n  When a `tfds.core.DatasetBuilder` is created with `data_dir=None`, TFDS\n  will look in all registered `data_dir` (including the default one) to\n  load existing datasets.\n\n  * An error is raised if a dataset can be loaded from more than 1 registered\n    data_dir.\n  * This only affects reading datasets. Generation always uses the\n    `data_dir` kwargs when specified or `tfds.core.constant.DATA_DIR` otherwise.\n\n  Args:\n    data_dir: New data_dir to register.\n  """"""\n  _registered_data_dir.add(data_dir)\n\n\ndef list_data_dirs():\n  """"""Return the list of all registered `data_dir`.""""""\n  all_data_dirs = _registered_data_dir | {DATA_DIR}\n  return sorted(os.path.expanduser(d) for d in all_data_dirs)\n\n\n'"
tensorflow_datasets/core/dataset_builder.py,50,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DatasetBuilder base class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport functools\nimport inspect\nimport itertools\nimport os\nimport sys\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import constants\nfrom tensorflow_datasets.core import download\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core import naming\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.core import splits as splits_lib\nfrom tensorflow_datasets.core import tfrecords_reader\nfrom tensorflow_datasets.core import tfrecords_writer\nfrom tensorflow_datasets.core import units\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import gcs_utils\nfrom tensorflow_datasets.core.utils import read_config as read_config_lib\n\nimport termcolor\n\n\nFORCE_REDOWNLOAD = download.GenerateMode.FORCE_REDOWNLOAD\nREUSE_CACHE_IF_EXISTS = download.GenerateMode.REUSE_CACHE_IF_EXISTS\nREUSE_DATASET_IF_EXISTS = download.GenerateMode.REUSE_DATASET_IF_EXISTS\n\nGCS_HOSTED_MSG = """"""\\\nDataset %s is hosted on GCS. It will automatically be downloaded to your\nlocal data directory. If you\'d instead prefer to read directly from our public\nGCS bucket (recommended if you\'re running on GCP), you can instead pass\n`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n""""""\n\n\n# Some tests are still running under Python 2, so internally we still whitelist\n# Py2 temporary.\n_is_py2_download_and_prepare_disabled = True\n\n\nclass BuilderConfig(object):\n  """"""Base class for `DatasetBuilder` data configuration.\n\n  DatasetBuilder subclasses with data configuration options should subclass\n  `BuilderConfig` and add their own properties.\n  """"""\n\n  @api_utils.disallow_positional_args\n  def __init__(self, name, version=None, supported_versions=None,\n               description=None):\n    self._name = name\n    self._version = version\n    self._supported_versions = supported_versions or []\n    self._description = description\n\n  @property\n  def name(self):\n    return self._name\n\n  @property\n  def version(self):\n    return self._version\n\n  @property\n  def supported_versions(self):\n    return self._supported_versions\n\n  @property\n  def description(self):\n    return self._description\n\n  def __repr__(self):\n    return ""<{cls_name} name={name}, version={version}>"".format(\n        cls_name=type(self).__name__,\n        name=self.name,\n        version=self.version or ""None"")\n\n\n@six.add_metaclass(registered.RegisteredDataset)\nclass DatasetBuilder(object):\n  """"""Abstract base class for all datasets.\n\n  `DatasetBuilder` has 3 key methods:\n\n    * `tfds.DatasetBuilder.info`: documents the dataset, including feature\n      names, types, and shapes, version, splits, citation, etc.\n    * `tfds.DatasetBuilder.download_and_prepare`: downloads the source data\n      and writes it to disk.\n    * `tfds.DatasetBuilder.as_dataset`: builds an input pipeline using\n      `tf.data.Dataset`s.\n\n  **Configuration**: Some `DatasetBuilder`s expose multiple variants of the\n  dataset by defining a `tfds.core.BuilderConfig` subclass and accepting a\n  config object (or name) on construction. Configurable datasets expose a\n  pre-defined set of configurations in `tfds.DatasetBuilder.builder_configs`.\n\n  Typical `DatasetBuilder` usage:\n\n  ```python\n  mnist_builder = tfds.builder(""mnist"")\n  mnist_info = mnist_builder.info\n  mnist_builder.download_and_prepare()\n  datasets = mnist_builder.as_dataset()\n\n  train_dataset, test_dataset = datasets[""train""], datasets[""test""]\n  assert isinstance(train_dataset, tf.data.Dataset)\n\n  # And then the rest of your input pipeline\n  train_dataset = train_dataset.repeat().shuffle(1024).batch(128)\n  train_dataset = train_dataset.prefetch(2)\n  features = tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next()\n  image, label = features[\'image\'], features[\'label\']\n  ```\n  """"""\n\n  # Name of the dataset, filled by metaclass based on class name.\n  name = None\n\n  # Semantic version of the dataset (ex: tfds.core.Version(\'1.2.0\'))\n  VERSION = None\n\n  # List dataset versions which can be loaded using current code.\n  # Data can only be prepared with canonical VERSION or above.\n  SUPPORTED_VERSIONS = []\n\n  # Named configurations that modify the data generated by download_and_prepare.\n  BUILDER_CONFIGS = []\n\n  # Set to True for datasets that are under active development and should not\n  # be available through tfds.{load, builder} or documented in overview.md.\n  IN_DEVELOPMENT = False\n\n  # Must be set for datasets that use \'manual_dir\' functionality - the ones\n  # that require users to do additional steps to download the data\n  # (this is usually due to some external regulations / rules).\n  #\n  # This field should contain a string with user instructions, including\n  # the list of files that should be present. It will be\n  # displayed in the dataset documentation.\n  MANUAL_DOWNLOAD_INSTRUCTIONS = None\n\n\n  @api_utils.disallow_positional_args\n  def __init__(self, data_dir=None, config=None, version=None):\n    """"""Constructs a DatasetBuilder.\n\n    Callers must pass arguments as keyword arguments.\n\n    Args:\n      data_dir: `str`, directory to read/write data. Defaults to\n        ""~/tensorflow_datasets"".\n      config: `tfds.core.BuilderConfig` or `str` name, optional configuration\n        for the dataset that affects the data generated on disk. Different\n        `builder_config`s will have their own subdirectories and versions.\n      version: `str`. Optional version at which to load the dataset. An error is\n        raised if specified version cannot be satisfied. Eg: \'1.2.3\', \'1.2.*\'.\n        The special value ""experimental_latest"" will use the highest version,\n        even if not default. This is not recommended unless you know what you\n        are doing, as the version could be broken.\n    """"""\n    # For pickling:\n    self._original_state = dict(data_dir=data_dir, config=config,\n                                version=version)\n    # To do the work:\n    self._builder_config = self._create_builder_config(config)\n    # Extract code version (VERSION or config)\n    if not self._builder_config and not self.VERSION:\n      raise AssertionError(\n          ""DatasetBuilder {} does not have a defined version. Please add a ""\n          ""`VERSION = tfds.core.Version(\'x.y.z\')` to the class."".format(\n              self.name))\n    self._version = self._pick_version(version)\n    # Compute the base directory (for download) and dataset/version directory.\n    self._data_dir_root, self._data_dir = self._build_data_dir(data_dir)\n    if tf.io.gfile.exists(self._data_dir):\n      self.info.read_from_directory(self._data_dir)\n    else:  # Use the code version (do not restore data)\n      self.info.initialize_from_bucket()\n\n  def __getstate__(self):\n    return self._original_state\n\n  def __setstate__(self, state):\n    self.__init__(**state)\n\n  @utils.memoized_property\n  def canonical_version(self):\n    if self._builder_config:\n      return self._builder_config.version\n    else:\n      return self.VERSION\n\n  @utils.memoized_property\n  def supported_versions(self):\n    if self._builder_config:\n      return self._builder_config.supported_versions\n    else:\n      return self.SUPPORTED_VERSIONS\n\n  @utils.memoized_property\n  def versions(self):\n    """"""Versions (canonical + availables), in preference order.""""""\n    return [\n        utils.Version(v) if isinstance(v, six.string_types) else v\n        for v in [self.canonical_version] + self.supported_versions\n    ]\n\n  def _pick_version(self, requested_version):\n    """"""Returns utils.Version instance, or raise AssertionError.""""""\n    if requested_version == ""experimental_latest"":\n      return max(self.versions)\n    for version in self.versions:\n      if requested_version is None or version.match(requested_version):\n        return version\n    available_versions = [str(v) for v in self.versions]\n    msg = ""Dataset {} cannot be loaded at version {}, only: {}."".format(\n        self.name, requested_version, "", "".join(available_versions))\n    raise AssertionError(msg)\n\n  @property\n  def version(self):\n    return self._version\n\n  @property\n  def data_dir(self):\n    return self._data_dir\n\n  @utils.memoized_property\n  def info(self):\n    """"""`tfds.core.DatasetInfo` for this builder.""""""\n    # Ensure .info hasn\'t been called before versioning is set-up\n    # Otherwise, backward compatibility cannot be guaranteed as some code will\n    # depend on the code version instead of the restored data version\n    if not getattr(self, ""_version"", None):\n      # Message for developper creating new dataset. Will trigger if they are\n      # using .info in the constructor before calling super().__init__\n      raise AssertionError(\n          ""Info should not been called before version has been defined. ""\n          ""Otherwise, the created .info may not match the info version from ""\n          ""the restored dataset."")\n    return self._info()\n\n  @api_utils.disallow_positional_args\n  def download_and_prepare(self, download_dir=None, download_config=None):\n    """"""Downloads and prepares dataset for reading.\n\n    Args:\n      download_dir: `str`, directory where downloaded files are stored.\n        Defaults to ""~/tensorflow-datasets/downloads"".\n      download_config: `tfds.download.DownloadConfig`, further configuration for\n        downloading and preparing dataset.\n\n    Raises:\n      IOError: if there is not enough disk space available.\n    """"""\n\n    download_config = download_config or download.DownloadConfig()\n    data_exists = tf.io.gfile.exists(self._data_dir)\n    if data_exists and download_config.download_mode == REUSE_DATASET_IF_EXISTS:\n      logging.info(""Reusing dataset %s (%s)"", self.name, self._data_dir)\n      return\n\n    # Disable `download_and_prepare` (internally, we are still\n    # allowing Py2 for the `dataset_builder_tests.py` & cie\n    if _is_py2_download_and_prepare_disabled and six.PY2:\n      raise NotImplementedError(\n          ""TFDS has droped `builder.download_and_prepare` support for ""\n          ""Python 2. Please update you code to Python 3."")\n\n    if self.version.tfds_version_to_prepare:\n      available_to_prepare = "", "".join(str(v) for v in self.versions\n                                       if not v.tfds_version_to_prepare)\n      raise AssertionError(\n          ""The version of the dataset you are trying to use ({}:{}) can only ""\n          ""be generated using TFDS code synced @ {} or earlier. Either sync to ""\n          ""that version of TFDS to first prepare the data or use another ""\n          ""version of the dataset (available for `download_and_prepare`: ""\n          ""{})."".format(\n              self.name, self.version, self.version.tfds_version_to_prepare,\n              available_to_prepare))\n\n    # Only `cls.VERSION` or `experimental_latest` versions can be generated.\n    # Otherwise, users may accidentally generate an old version using the\n    # code from newer versions.\n    installable_versions = {\n        str(v) for v in (self.canonical_version, max(self.versions))\n    }\n    if str(self.version) not in installable_versions:\n      msg = (\n          ""The version of the dataset you are trying to use ({}) is too ""\n          ""old for this version of TFDS so cannot be generated.""\n      ).format(self.info.full_name)\n      if self.version.tfds_version_to_prepare:\n        msg += (\n            ""{} can only be generated using TFDS code synced @ {} or earlier ""\n            ""Either sync to that version of TFDS to first prepare the data or ""\n            ""use another version of the dataset. ""\n        ).format(self.version, self.version.tfds_version_to_prepare)\n      else:\n        msg += (\n            ""Either sync to a previous version of TFDS to first prepare the ""\n            ""data or use another version of the dataset. ""\n        )\n      msg += ""Available for `download_and_prepare`: {}"".format(\n          list(sorted(installable_versions)))\n      raise ValueError(msg)\n\n    # Currently it\'s not possible to overwrite the data because it would\n    # conflict with versioning: If the last version has already been generated,\n    # it will always be reloaded and data_dir will be set at construction.\n    if data_exists:\n      raise ValueError(\n          ""Trying to overwrite an existing dataset {} at {}. A dataset with ""\n          ""the same version {} already exists. If the dataset has changed, ""\n          ""please update the version number."".format(self.name, self._data_dir,\n                                                     self.version))\n\n    logging.info(""Generating dataset %s (%s)"", self.name, self._data_dir)\n    if not utils.has_sufficient_disk_space(\n        self.info.dataset_size + self.info.download_size,\n        directory=self._data_dir_root):\n      raise IOError(\n          ""Not enough disk space. Needed: {} (download: {}, generated: {})""\n          .format(\n              units.size_str(self.info.dataset_size + self.info.download_size),\n              units.size_str(self.info.download_size),\n              units.size_str(self.info.dataset_size),\n          ))\n    self._log_download_bytes()\n\n    dl_manager = self._make_download_manager(\n        download_dir=download_dir,\n        download_config=download_config)\n\n    # Create a tmp dir and rename to self._data_dir on successful exit.\n    with utils.incomplete_dir(self._data_dir) as tmp_data_dir:\n      # Temporarily assign _data_dir to tmp_data_dir to avoid having to forward\n      # it to every sub function.\n      with utils.temporary_assignment(self, ""_data_dir"", tmp_data_dir):\n        if (download_config.try_download_gcs and\n            gcs_utils.is_dataset_on_gcs(self.info.full_name)):\n          logging.warning(GCS_HOSTED_MSG, self.name)\n          gcs_utils.download_gcs_dataset(self.info.full_name, self._data_dir)\n          self.info.read_from_directory(self._data_dir)\n        else:\n          self._download_and_prepare(\n              dl_manager=dl_manager,\n              download_config=download_config)\n\n          # NOTE: If modifying the lines below to put additional information in\n          # DatasetInfo, you\'ll likely also want to update\n          # DatasetInfo.read_from_directory to possibly restore these attributes\n          # when reading from package data.\n\n          # Skip statistics computation if tfdv isn\'t present\n          try:\n            import tensorflow_data_validation  # pylint: disable=g-import-not-at-top,import-outside-toplevel,unused-import  # pytype: disable=import-error\n            skip_stats_computation = False\n          except ImportError:\n            skip_stats_computation = True\n\n          splits = list(self.info.splits.values())\n          statistics_already_computed = bool(\n              splits and splits[0].statistics.num_examples)\n          # Update DatasetInfo metadata by computing statistics from the data.\n          if (skip_stats_computation or\n              download_config.compute_stats == download.ComputeStatsMode.SKIP or\n              download_config.compute_stats == download.ComputeStatsMode.AUTO\n              and statistics_already_computed\n             ):\n            logging.info(\n                ""Skipping computing stats for mode %s."",\n                download_config.compute_stats)\n          else:  # Mode is forced or stats do not exists yet\n            logging.info(""Computing statistics."")\n            self.info.compute_dynamic_properties()\n          self.info.download_size = dl_manager.downloaded_size\n          # Write DatasetInfo to disk, even if we haven\'t computed statistics.\n          self.info.write_to_directory(self._data_dir)\n    self._log_download_done()\n\n  @api_utils.disallow_positional_args\n  def as_dataset(\n      self,\n      split=None,\n      batch_size=None,\n      shuffle_files=False,\n      decoders=None,\n      read_config=None,\n      as_supervised=False,\n  ):\n    # pylint: disable=line-too-long\n    """"""Constructs a `tf.data.Dataset`.\n\n    Callers must pass arguments as keyword arguments.\n\n    The output types vary depending on the parameters. Examples:\n\n    ```python\n    builder = tfds.builder(\'imdb_reviews\')\n    builder.download_and_prepare()\n\n    # Default parameters: Returns the dict of tf.data.Dataset\n    ds_all_dict = builder.as_dataset()\n    assert isinstance(ds_all_dict, dict)\n    print(ds_all_dict.keys())  # ==> [\'test\', \'train\', \'unsupervised\']\n\n    assert isinstance(ds_all_dict[\'test\'], tf.data.Dataset)\n    # Each dataset (test, train, unsup.) consists of dictionaries\n    # {\'label\': <tf.Tensor: .. dtype=int64, numpy=1>,\n    #  \'text\': <tf.Tensor: .. dtype=string, numpy=b""I\'ve watched the movie .."">}\n    # {\'label\': <tf.Tensor: .. dtype=int64, numpy=1>,\n    #  \'text\': <tf.Tensor: .. dtype=string, numpy=b\'If you love Japanese ..\'>}\n\n    # With as_supervised: tf.data.Dataset only contains (feature, label) tuples\n    ds_all_supervised = builder.as_dataset(as_supervised=True)\n    assert isinstance(ds_all_supervised, dict)\n    print(ds_all_supervised.keys())  # ==> [\'test\', \'train\', \'unsupervised\']\n\n    assert isinstance(ds_all_supervised[\'test\'], tf.data.Dataset)\n    # Each dataset (test, train, unsup.) consists of tuples (text, label)\n    # (<tf.Tensor: ... dtype=string, numpy=b""I\'ve watched the movie .."">,\n    #  <tf.Tensor: ... dtype=int64, numpy=1>)\n    # (<tf.Tensor: ... dtype=string, numpy=b""If you love Japanese .."">,\n    #  <tf.Tensor: ... dtype=int64, numpy=1>)\n\n    # Same as above plus requesting a particular split\n    ds_test_supervised = builder.as_dataset(as_supervised=True, split=\'test\')\n    assert isinstance(ds_test_supervised, tf.data.Dataset)\n    # The dataset consists of tuples (text, label)\n    # (<tf.Tensor: ... dtype=string, numpy=b""I\'ve watched the movie .."">,\n    #  <tf.Tensor: ... dtype=int64, numpy=1>)\n    # (<tf.Tensor: ... dtype=string, numpy=b""If you love Japanese .."">,\n    #  <tf.Tensor: ... dtype=int64, numpy=1>)\n    ```\n\n    Args:\n      split: Which split of the data to load (e.g. `\'train\'`, `\'test\'`\n        `[\'train\', \'test\']`, `\'train[80%:]\'`,...). See our\n        [split API guide](https://www.tensorflow.org/datasets/splits).\n        If `None`, will return all splits in a `Dict[Split, tf.data.Dataset]`.\n      batch_size: `int`, batch size. Note that variable-length features will\n        be 0-padded if `batch_size` is set. Users that want more custom behavior\n        should use `batch_size=None` and use the `tf.data` API to construct a\n        custom pipeline. If `batch_size == -1`, will return feature\n        dictionaries of the whole dataset with `tf.Tensor`s instead of a\n        `tf.data.Dataset`.\n      shuffle_files: `bool`, whether to shuffle the input files. Defaults to\n        `False`.\n      decoders: Nested dict of `Decoder` objects which allow to customize the\n        decoding. The structure should match the feature structure, but only\n        customized feature keys need to be present. See\n        [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n        for more info.\n      read_config: `tfds.ReadConfig`, Additional options to configure the\n        input pipeline (e.g. seed, num parallel reads,...).\n      as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n        will have a 2-tuple structure `(input, label)` according to\n        `builder.info.supervised_keys`. If `False`, the default,\n        the returned `tf.data.Dataset` will have a dictionary with all the\n        features.\n\n    Returns:\n      `tf.data.Dataset`, or if `split=None`, `dict<key: tfds.Split, value:\n      tfds.data.Dataset>`.\n\n      If `batch_size` is -1, will return feature dictionaries containing\n      the entire dataset in `tf.Tensor`s instead of a `tf.data.Dataset`.\n    """"""\n    # pylint: enable=line-too-long\n    logging.info(""Constructing tf.data.Dataset for split %s, from %s"",\n                 split, self._data_dir)\n    if not tf.io.gfile.exists(self._data_dir):\n      raise AssertionError(\n          (""Dataset %s: could not find data in %s. Please make sure to call ""\n           ""dataset_builder.download_and_prepare(), or pass download=True to ""\n           ""tfds.load() before trying to access the tf.data.Dataset object.""\n          ) % (self.name, self._data_dir_root))\n\n    # By default, return all splits\n    if split is None:\n      split = {s: s for s in self.info.splits}\n\n    read_config = read_config or read_config_lib.ReadConfig()\n\n    # Create a dataset for each of the given splits\n    build_single_dataset = functools.partial(\n        self._build_single_dataset,\n        shuffle_files=shuffle_files,\n        batch_size=batch_size,\n        decoders=decoders,\n        read_config=read_config,\n        as_supervised=as_supervised,\n    )\n    datasets = utils.map_nested(build_single_dataset, split, map_tuple=True)\n    return datasets\n\n  def _build_single_dataset(\n      self,\n      split,\n      shuffle_files,\n      batch_size,\n      decoders,\n      read_config,\n      as_supervised,\n  ):\n    """"""as_dataset for a single split.""""""\n    wants_full_dataset = batch_size == -1\n    if wants_full_dataset:\n      batch_size = self.info.splits.total_num_examples or sys.maxsize\n\n    # Build base dataset\n    ds = self._as_dataset(\n        split=split,\n        shuffle_files=shuffle_files,\n        decoders=decoders,\n        read_config=read_config,\n    )\n    # Auto-cache small datasets which are small enough to fit in memory.\n    if self._should_cache_ds(\n        split=split,\n        shuffle_files=shuffle_files,\n        read_config=read_config\n    ):\n      ds = ds.cache()\n\n    if batch_size:\n      # Use padded_batch so that features with unknown shape are supported.\n      ds = ds.padded_batch(\n          batch_size, tf.compat.v1.data.get_output_shapes(ds))\n\n    if as_supervised:\n      if not self.info.supervised_keys:\n        raise ValueError(\n            ""as_supervised=True but %s does not support a supervised ""\n            ""(input, label) structure."" % self.name)\n      input_f, target_f = self.info.supervised_keys\n      ds = ds.map(lambda fs: (fs[input_f], fs[target_f]),\n                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n\n    # If shuffling is True and seeds not set, allow pipeline to be\n    # non-deterministic\n    # This code should probably be moved inside tfreader, such as\n    # all the tf.data.Options are centralized in a single place.\n    if (shuffle_files and\n        read_config.options.experimental_deterministic is None and\n        read_config.shuffle_seed is None):\n      options = tf.data.Options()\n      options.experimental_deterministic = False\n      ds = ds.with_options(options)\n    # If shuffle is False, keep the default value (deterministic), which\n    # allow the user to overwritte it.\n\n    if wants_full_dataset:\n      return tf.data.experimental.get_single_element(ds)\n    return ds\n\n  def _should_cache_ds(self, split, shuffle_files, read_config):\n    """"""Returns True if TFDS should auto-cache the dataset.""""""\n    # The user can explicitly opt-out from auto-caching\n    if not read_config.try_autocache:\n      return False\n\n    # Skip datasets with unknown size.\n    # Even by using heuristic with `download_size` and\n    # `MANUAL_DOWNLOAD_INSTRUCTIONS`, it wouldn\'t catch datasets which hardcode\n    # the non-processed data-dir, nor DatasetBuilder not based on tf-record.\n    if not self.info.dataset_size:\n      return False\n\n    # Do not cache big datasets\n    # Instead of using the global size, we could infer the requested bytes:\n    # `self.info.splits[split].num_bytes`\n    # The info is available for full splits, and could be approximated\n    # for subsplits `train[:50%]`.\n    # However if the user is creating multiple small splits from a big\n    # dataset, those could adds up and fill up the entire RAM.\n    # 250 MiB is arbitrary picked. For comparison, Cifar10 is about 150 MiB.\n    if self.info.dataset_size > 250 * units.MiB:\n      return False\n\n    # We do not want to cache data which has more than one shards when\n    # shuffling is enabled, as this would effectivelly disable shuffling.\n    # An exception is for single shard (as shuffling is a no-op).\n    # Another exception is if reshuffle is disabled (shuffling already cached)\n    num_shards = len(self.info.splits[split].file_instructions)\n    if (shuffle_files and\n        # Shuffling only matter when reshuffle is True or None (default)\n        read_config.shuffle_reshuffle_each_iteration is not False and  # pylint: disable=g-bool-id-comparison\n        num_shards > 1):\n      return False\n\n    # If the dataset satisfy all the right conditions, activate autocaching.\n    return True\n\n  def _relative_data_dir(self, with_version=True):\n    """"""Relative path of this dataset in data_dir.""""""\n    builder_data_dir = self.name\n    builder_config = self._builder_config\n    if builder_config:\n      builder_data_dir = os.path.join(builder_data_dir, builder_config.name)\n    if not with_version:\n      return builder_data_dir\n\n    version_data_dir = os.path.join(builder_data_dir, str(self._version))\n    return version_data_dir\n\n  def _build_data_dir(self, given_data_dir):\n    """"""Return the data directory for the current version.\n\n    Args:\n      given_data_dir: `Optional[str]`, root `data_dir` passed as\n        `__init__` argument.\n\n    Returns:\n      data_dir_root: `str`, The root dir containing all datasets, downloads,...\n      data_dir: `str`, The version data_dir\n        (e.g. `<data_dir_root>/<ds_name>/<config>/<version>`)\n    """"""\n    builder_dir = self._relative_data_dir(with_version=False)\n    version_dir = self._relative_data_dir(with_version=True)\n\n    # If the data dir is explicitly given, no need to search everywhere.\n    if given_data_dir:\n      default_data_dir = os.path.expanduser(given_data_dir)\n      all_data_dirs = [default_data_dir]\n    else:\n      default_data_dir = os.path.expanduser(constants.DATA_DIR)\n      all_data_dirs = constants.list_data_dirs()\n\n    all_version_dirs = set()\n    requested_version_dirs = {}\n    for data_dir_root in all_data_dirs:\n      # List all existing versions\n      all_version_dirs.update(\n          _list_all_version_dirs(os.path.join(data_dir_root, builder_dir)))\n      # Check for existance of the requested dir\n      requested_version_dir = os.path.join(data_dir_root, version_dir)\n      if requested_version_dir in all_version_dirs:\n        requested_version_dirs[data_dir_root] = requested_version_dir\n\n    if len(requested_version_dirs) > 1:\n      raise ValueError(\n          ""Dataset was found in more than one directory: {}. Please resolve ""\n          ""the ambiguity by explicitly specifying `data_dir=`.""\n          """".format(requested_version_dirs))\n    elif len(requested_version_dirs) == 1:  # The dataset is found once\n      return next(iter(requested_version_dirs.items()))\n\n    # No dataset found, use default directory\n    data_dir = os.path.join(default_data_dir, version_dir)\n    if all_version_dirs:\n      logging.warning(\n          ""Found a different version of the requested dataset:\\n""\n          ""%s\\n""\n          ""Using %s instead."",\n          ""\\n"".join(sorted(all_version_dirs)),\n          data_dir\n      )\n    return default_data_dir, data_dir\n\n  def _log_download_done(self):\n    msg = (""Dataset {name} downloaded and prepared to {data_dir}. ""\n           ""Subsequent calls will reuse this data."").format(\n               name=self.name,\n               data_dir=self._data_dir,\n           )\n    termcolor.cprint(msg, attrs=[""bold""])\n\n  def _log_download_bytes(self):\n    # Print is intentional: we want this to always go to stdout so user has\n    # information needed to cancel download/preparation if needed.\n    # This comes right before the progress bar.\n    termcolor.cprint(\n        ""Downloading and preparing dataset {} (download: {}, generated: {}, ""\n        ""total: {}) to {}..."".format(\n            self.info.full_name,\n            units.size_str(self.info.download_size),\n            units.size_str(self.info.dataset_size),\n            units.size_str(self.info.download_size + self.info.dataset_size),\n            self._data_dir,\n        ), attrs=[""bold""])\n\n  @abc.abstractmethod\n  def _info(self):\n    """"""Construct the DatasetInfo object. See `DatasetInfo` for details.\n\n    Warning: This function is only called once and the result is cached for all\n    following .info() calls.\n\n    Returns:\n      dataset_info: (DatasetInfo) The dataset information\n    """"""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def _download_and_prepare(self, dl_manager, download_config=None):\n    """"""Downloads and prepares dataset for reading.\n\n    This is the internal implementation to overwrite called when user calls\n    `download_and_prepare`. It should download all required data and generate\n    the pre-processed datasets files.\n\n    Args:\n      dl_manager: (DownloadManager) `DownloadManager` used to download and cache\n        data.\n      download_config: `DownloadConfig`, Additional options.\n    """"""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def _as_dataset(\n      self, split, decoders=None, read_config=None, shuffle_files=False):\n    """"""Constructs a `tf.data.Dataset`.\n\n    This is the internal implementation to overwrite called when user calls\n    `as_dataset`. It should read the pre-processed datasets files and generate\n    the `tf.data.Dataset` object.\n\n    Args:\n      split: `tfds.Split` which subset of the data to read.\n      decoders: Nested structure of `Decoder` object to customize the dataset\n        decoding.\n      read_config: `tfds.ReadConfig`\n      shuffle_files: `bool`, whether to shuffle the input files. Optional,\n        defaults to `False`.\n\n    Returns:\n      `tf.data.Dataset`\n    """"""\n    raise NotImplementedError\n\n  def _make_download_manager(self, download_dir, download_config):\n    """"""Creates a new download manager object.""""""\n    download_dir = download_dir or os.path.join(self._data_dir_root,\n                                                ""downloads"")\n    extract_dir = (download_config.extract_dir or\n                   os.path.join(download_dir, ""extracted""))\n\n    # Use manual_dir only if MANUAL_DOWNLOAD_INSTRUCTIONS are set.\n    if self.MANUAL_DOWNLOAD_INSTRUCTIONS:\n      manual_dir = (\n          download_config.manual_dir or os.path.join(download_dir, ""manual""))\n    else:\n      manual_dir = None\n\n    return download.DownloadManager(\n        dataset_name=self.name,\n        download_dir=download_dir,\n        extract_dir=extract_dir,\n        manual_dir=manual_dir,\n        manual_dir_instructions=utils.dedent(self.MANUAL_DOWNLOAD_INSTRUCTIONS),\n        force_download=(download_config.download_mode == FORCE_REDOWNLOAD),\n        force_extraction=(download_config.download_mode == FORCE_REDOWNLOAD),\n        force_checksums_validation=download_config.force_checksums_validation,\n        register_checksums=download_config.register_checksums,\n    )\n\n  @property\n  def builder_config(self):\n    """"""`tfds.core.BuilderConfig` for this builder.""""""\n    return self._builder_config\n\n  def _create_builder_config(self, builder_config):\n    """"""Create and validate BuilderConfig object.""""""\n    if builder_config is None and self.BUILDER_CONFIGS:\n      builder_config = self.BUILDER_CONFIGS[0]\n      logging.info(""No config specified, defaulting to first: %s/%s"", self.name,\n                   builder_config.name)\n    if not builder_config:\n      return None\n    if isinstance(builder_config, six.string_types):\n      name = builder_config\n      builder_config = self.builder_configs.get(name)\n      if builder_config is None:\n        raise ValueError(""BuilderConfig %s not found. Available: %s"" %\n                         (name, list(self.builder_configs.keys())))\n    name = builder_config.name\n    if not name:\n      raise ValueError(""BuilderConfig must have a name, got %s"" % name)\n    is_custom = name not in self.builder_configs\n    if is_custom:\n      logging.warning(""Using custom data configuration %s"", name)\n    else:\n      if builder_config is not self.builder_configs[name]:\n        raise ValueError(\n            ""Cannot name a custom BuilderConfig the same as an available ""\n            ""BuilderConfig. Change the name. Available BuilderConfigs: %s"" %\n            (list(self.builder_configs.keys())))\n      if not builder_config.version:\n        raise ValueError(""BuilderConfig %s must have a version"" % name)\n      if not builder_config.description:\n        raise ValueError(""BuilderConfig %s must have a description"" % name)\n    return builder_config\n\n  @utils.classproperty\n  @classmethod\n  @utils.memoize()\n  def builder_configs(cls):\n    """"""Pre-defined list of configurations for this builder class.""""""\n    config_dict = {config.name: config for config in cls.BUILDER_CONFIGS}\n    if len(config_dict) != len(cls.BUILDER_CONFIGS):\n      names = [config.name for config in cls.BUILDER_CONFIGS]\n      raise ValueError(\n          ""Names in BUILDER_CONFIGS must not be duplicated. Got %s"" % names)\n    return config_dict\n\n\ndef _list_all_version_dirs(root_dir):\n  """"""Lists all dataset versions present on disk.""""""\n  if not tf.io.gfile.exists(root_dir):\n    return []\n\n  def _is_version_valid(version):\n    try:\n      return utils.Version(version) and True\n    except ValueError:  # Invalid version (ex: incomplete data dir)\n      return False\n\n  return [  # Return all version dirs\n      os.path.join(root_dir, version)\n      for version in tf.io.gfile.listdir(root_dir)\n      if _is_version_valid(version)\n  ]\n\n\nclass FileAdapterBuilder(DatasetBuilder):\n  """"""Base class for datasets with data generation based on file adapter.""""""\n\n  @utils.memoized_property\n  def _example_specs(self):\n    return self.info.features.get_serialized_info()\n\n  @property\n  def _tfrecords_reader(self):\n    return tfrecords_reader.Reader(self._data_dir, self._example_specs)\n\n  @abc.abstractmethod\n  def _split_generators(self, dl_manager):\n    """"""Specify feature dictionary generators and dataset splits.\n\n    This function returns a list of `SplitGenerator`s defining how to generate\n    data and what splits to use.\n\n    Example:\n\n      return[\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TRAIN,\n              gen_kwargs={\'file\': \'train_data.zip\'},\n          ),\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs={\'file\': \'test_data.zip\'},\n          ),\n      ]\n\n    The above code will first call `_generate_examples(file=\'train_data.zip\')`\n    to write the train data, then `_generate_examples(file=\'test_data.zip\')` to\n    write the test data.\n\n    Datasets are typically split into different subsets to be used at various\n    stages of training and evaluation.\n\n    Note that for datasets without a `VALIDATION` split, you can use a\n    fraction of the `TRAIN` data for evaluation as you iterate on your model\n    so as not to overfit to the `TEST` data.\n\n    For downloads and extractions, use the given `download_manager`.\n    Note that the `DownloadManager` caches downloads, so it is fine to have each\n    generator attempt to download the source data.\n\n    A good practice is to download all data in this function, and then\n    distribute the relevant parts to each split with the `gen_kwargs` argument\n\n    Args:\n      dl_manager: (DownloadManager) Download manager to download the data\n\n    Returns:\n      `list<SplitGenerator>`.\n    """"""\n    raise NotImplementedError()\n\n  @abc.abstractmethod\n  def _prepare_split(self, split_generator, **kwargs):\n    """"""Generate the examples and record them on disk.\n\n    Args:\n      split_generator: `SplitGenerator`, Split generator to process\n      **kwargs: Additional kwargs forwarded from _download_and_prepare (ex:\n        beam pipeline)\n    """"""\n    raise NotImplementedError()\n\n  def _make_split_generators_kwargs(self, prepare_split_kwargs):\n    """"""Get kwargs for `self._split_generators()` from `prepare_split_kwargs`.""""""\n    del prepare_split_kwargs\n    return {}\n\n  def _download_and_prepare(self, dl_manager, **prepare_split_kwargs):\n    if not tf.io.gfile.exists(self._data_dir):\n      tf.io.gfile.makedirs(self._data_dir)\n\n    # Generating data for all splits\n    split_dict = splits_lib.SplitDict(dataset_name=self.name)\n    split_generators_kwargs = self._make_split_generators_kwargs(\n        prepare_split_kwargs)\n    for split_generator in self._split_generators(\n        dl_manager, **split_generators_kwargs):\n      if str(split_generator.split_info.name).lower() == ""all"":\n        raise ValueError(\n            ""`all` is a special split keyword corresponding to the ""\n            ""union of all splits, so cannot be used as key in ""\n            ""._split_generator().""\n        )\n\n      logging.info(""Generating split %s"", split_generator.split_info.name)\n      split_dict.add(split_generator.split_info)\n\n      # Prepare split will record examples associated to the split\n      self._prepare_split(split_generator, **prepare_split_kwargs)\n\n    # Update the info object with the splits.\n    self.info.update_splits_if_different(split_dict)\n\n  def _as_dataset(\n      self,\n      split=splits_lib.Split.TRAIN,\n      decoders=None,\n      read_config=None,\n      shuffle_files=False):\n    ds = self._tfrecords_reader.read(\n        name=self.name,\n        instructions=split,\n        split_infos=self.info.splits.values(),\n        read_config=read_config,\n        shuffle_files=shuffle_files,\n    )\n    decode_fn = functools.partial(\n        self.info.features.decode_example, decoders=decoders)\n    ds = ds.map(decode_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return ds\n\n\nclass GeneratorBasedBuilder(FileAdapterBuilder):\n  """"""Base class for datasets with data generation based on dict generators.\n\n  `GeneratorBasedBuilder` is a convenience class that abstracts away much\n  of the data writing and reading of `DatasetBuilder`. It expects subclasses to\n  implement generators of feature dictionaries across the dataset splits\n  `_split_generators`. See the method docstrings for details.\n\n  """"""\n\n  @abc.abstractmethod\n  def _generate_examples(self, **kwargs):\n    """"""Default function generating examples for each `SplitGenerator`.\n\n    This function preprocess the examples from the raw data to the preprocessed\n    dataset files.\n    This function is called once for each `SplitGenerator` defined in\n    `_split_generators`. The examples yielded here will be written on\n    disk.\n\n    Args:\n      **kwargs: `dict`, Arguments forwarded from the SplitGenerator.gen_kwargs\n\n    Yields:\n      key: `str` or `int`, a unique deterministic example identification key.\n        * Unique: An error will be raised if two examples are yield with the\n          same key.\n        * Deterministic: When generating the dataset twice, the same example\n          should have the same key.\n        Good keys can be the image id, or line number if examples are extracted\n        from a text file.\n        The key will be hashed and sorted to shuffle examples deterministically,\n        such as generating the dataset multiple times keep examples in the\n        same order.\n      example: `dict<str feature_name, feature_value>`, a feature dictionary\n        ready to be encoded and written to disk. The example will be\n        encoded with `self.info.features.encode_example({...})`.\n    """"""\n    raise NotImplementedError()\n\n  def _download_and_prepare(self, dl_manager, download_config):\n    # Extract max_examples_per_split and forward it to _prepare_split\n    super(GeneratorBasedBuilder, self)._download_and_prepare(\n        dl_manager=dl_manager,\n        max_examples_per_split=download_config.max_examples_per_split,\n    )\n\n  def _prepare_split(self, split_generator, max_examples_per_split):\n    generator = self._generate_examples(**split_generator.gen_kwargs)\n    split_info = split_generator.split_info\n    if max_examples_per_split is not None:\n      logging.warning(""Splits capped at %s examples max."",\n                      max_examples_per_split)\n      generator = itertools.islice(generator, max_examples_per_split)\n    fname = ""{}-{}.tfrecord"".format(self.name, split_generator.name)\n    fpath = os.path.join(self._data_dir, fname)\n    writer = tfrecords_writer.Writer(self._example_specs, fpath,\n                                     hash_salt=split_generator.name)\n    for key, record in utils.tqdm(generator, unit="" examples"",\n                                  total=split_info.num_examples, leave=False):\n      example = self.info.features.encode_example(record)\n      writer.write(key, example)\n    shard_lengths, total_size = writer.finalize()\n    split_generator.split_info.shard_lengths.extend(shard_lengths)\n    split_generator.split_info.num_bytes = total_size\n\n\nclass BeamBasedBuilder(FileAdapterBuilder):\n  """"""Beam based Builder.""""""\n\n  def __init__(self, *args, **kwargs):\n    super(BeamBasedBuilder, self).__init__(*args, **kwargs)\n    self._beam_writers = {}  # {split: beam_writer} mapping.\n\n  def _make_split_generators_kwargs(self, prepare_split_kwargs):\n    # Pass `pipeline` into `_split_generators()` from `prepare_split_kwargs` if\n    # it\'s in the call signature of `_split_generators()`.\n    # This allows for global preprocessing in beam.\n    split_generators_kwargs = {}\n    split_generators_arg_names = (\n        inspect.getargspec(self._split_generators).args if six.PY2 else  # pylint: disable=deprecated-method  # pytype: disable=wrong-arg-types\n        inspect.signature(self._split_generators).parameters.keys())\n    if ""pipeline"" in split_generators_arg_names:\n      split_generators_kwargs[""pipeline""] = prepare_split_kwargs[""pipeline""]\n    return split_generators_kwargs\n\n  @abc.abstractmethod\n  def _build_pcollection(self, pipeline, **kwargs):\n    """"""Build the beam pipeline examples for each `SplitGenerator`.\n\n    This function extracts examples from the raw data with parallel transforms\n    in a Beam pipeline. It is called once for each `SplitGenerator` defined in\n    `_split_generators`. The examples from the PCollection will be\n    encoded and written to disk.\n\n    Warning: When running in a distributed setup, make sure that the data\n    which will be read (download_dir, manual_dir,...) and written (data_dir)\n    can be accessed by the workers jobs. The data should be located in a\n    shared filesystem, like GCS.\n\n    Example:\n\n    ```\n    def _build_pcollection(pipeline, extracted_dir):\n      return (\n          pipeline\n          | beam.Create(gfile.io.listdir(extracted_dir))\n          | beam.Map(_process_file)\n      )\n    ```\n\n    Args:\n      pipeline: `beam.Pipeline`, root Beam pipeline\n      **kwargs: Arguments forwarded from the SplitGenerator.gen_kwargs\n\n    Returns:\n      pcollection: `PCollection`, an Apache Beam PCollection containing the\n        example to send to `self.info.features.encode_example(...)`.\n    """"""\n    raise NotImplementedError()\n\n  def _download_and_prepare(self, dl_manager, download_config):\n    # Create the Beam pipeline and forward it to _prepare_split\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n\n    if not download_config.beam_runner and not download_config.beam_options:\n      raise ValueError(\n          ""The dataset you\'re trying to generate is using Apache Beam. Beam""\n          ""datasets are usually very large and should be generated separately.""\n          ""Please have a look at""\n          ""https://www.tensorflow.org/datasets/beam_datasets#generating_a_beam_dataset""\n          ""for instructions.""\n      )\n\n    beam_options = (download_config.beam_options or\n                    beam.options.pipeline_options.PipelineOptions())\n    # Beam type checking assumes transforms multiple outputs are of same type,\n    # which is not our case. Plus it doesn\'t handle correctly all types, so we\n    # are better without it.\n    beam_options.view_as(\n        beam.options.pipeline_options.TypeOptions).pipeline_type_check = False\n    # Use a single pipeline for all splits\n    with beam.Pipeline(\n        runner=download_config.beam_runner,\n        options=beam_options,\n    ) as pipeline:\n      # TODO(tfds): Should eventually try to add support to\n      # download_config.max_examples_per_split\n      super(BeamBasedBuilder, self)._download_and_prepare(\n          dl_manager,\n          pipeline=pipeline,\n      )\n\n    # Update `info.splits` with number of shards and shard lengths.\n    split_dict = self.info.splits\n    for split_name, beam_writer in self._beam_writers.items():\n      logging.info(""Retrieving shard lengths for %s..."", split_name)\n      shard_lengths, total_size = beam_writer.finalize()\n      split_info = split_dict[split_name]\n      split_info.shard_lengths.extend(shard_lengths)\n      split_info.num_shards = len(shard_lengths)\n      split_info.num_bytes = total_size\n    logging.info(""Updating split info..."")\n    self.info.update_splits_if_different(split_dict)\n\n  def _prepare_split(self, split_generator, pipeline):\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n\n    if not tf.io.gfile.exists(self._data_dir):\n      tf.io.gfile.makedirs(self._data_dir)\n\n    split_name = split_generator.split_info.name\n    output_prefix = naming.filename_prefix_for_split(\n        self.name, split_name)\n    output_prefix = os.path.join(self._data_dir, output_prefix)\n\n    # To write examples to disk:\n    fname = ""{}-{}.tfrecord"".format(self.name, split_name)\n    fpath = os.path.join(self._data_dir, fname)\n    beam_writer = tfrecords_writer.BeamWriter(\n        self._example_specs, fpath, hash_salt=split_name)\n    self._beam_writers[split_name] = beam_writer\n\n    encode_example = self.info.features.encode_example\n\n    # Note: We need to wrap the pipeline in a PTransform to avoid re-using the\n    # same label names for each split\n    @beam.ptransform_fn\n    def _build_pcollection(pipeline):\n      """"""PTransformation which build a single split.""""""\n      # Encode the PCollection\n      pcoll_examples = self._build_pcollection(\n          pipeline, **split_generator.gen_kwargs)\n      pcoll_examples |= ""Encode"" >> beam.Map(\n          lambda key_ex: (key_ex[0], encode_example(key_ex[1])))\n      return beam_writer.write_from_pcollection(pcoll_examples)\n\n    # Add the PCollection to the pipeline\n    _ = pipeline | split_name >> _build_pcollection()   # pylint: disable=no-value-for-parameter\n'"
tensorflow_datasets/core/dataset_builder_beam_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.dataset_builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport apache_beam as beam\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import download\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core import splits as splits_lib\nfrom tensorflow_datasets.core import utils\n\n\ntf.enable_v2_behavior()\n\n\nclass DummyBeamDataset(dataset_builder.BeamBasedBuilder):\n\n  VERSION = utils.Version(""1.0.0"")\n\n  def _info(self):\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({\n            ""image"": features.Image(shape=(16, 16, 1)),\n            ""label"": features.ClassLabel(names=[""dog"", ""cat""]),\n            ""id"": tf.int32,\n        }),\n        supervised_keys=(""x"", ""x""),\n        metadata=dataset_info.BeamMetadataDict(),\n    )\n\n  def _split_generators(self, dl_manager):\n    del dl_manager\n    return [\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TRAIN,\n            gen_kwargs=dict(num_examples=1000),\n        ),\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TEST,\n            gen_kwargs=dict(num_examples=725),\n        ),\n    ]\n\n  def _compute_metadata(self, examples, num_examples):\n    self.info.metadata[""label_sum_%d"" % num_examples] = (\n        examples\n        | beam.Map(lambda x: x[1][""label""])\n        | beam.CombineGlobally(sum))\n    self.info.metadata[""id_mean_%d"" % num_examples] = (\n        examples\n        | beam.Map(lambda x: x[1][""id""])\n        | beam.CombineGlobally(beam.combiners.MeanCombineFn()))\n\n  def _build_pcollection(self, pipeline, num_examples):\n    """"""Generate examples as dicts.""""""\n    examples = (\n        pipeline\n        | beam.Create(range(num_examples))\n        | beam.Map(_gen_example)\n    )\n    self._compute_metadata(examples, num_examples)\n    return examples\n\n\ndef _gen_example(x):\n  return (x, {\n      ""image"": (np.ones((16, 16, 1)) * x % 255).astype(np.uint8),\n      ""label"": x % 2,\n      ""id"": x,\n  })\n\n\nclass CommonPipelineDummyBeamDataset(DummyBeamDataset):\n\n  def _split_generators(self, dl_manager, pipeline):\n    del dl_manager\n\n    examples = (\n        pipeline\n        | beam.Create(range(1000))\n        | beam.Map(_gen_example)\n    )\n\n    return [\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TRAIN,\n            gen_kwargs=dict(examples=examples, num_examples=1000),\n        ),\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TEST,\n            gen_kwargs=dict(examples=examples, num_examples=725),\n        ),\n    ]\n\n  def _build_pcollection(self, pipeline, examples, num_examples):\n    """"""Generate examples as dicts.""""""\n    del pipeline\n    examples |= beam.Filter(lambda x: x[0] < num_examples)\n    self._compute_metadata(examples, num_examples)\n    return examples\n\n\nclass FaultyS3DummyBeamDataset(DummyBeamDataset):\n\n  VERSION = utils.Version(""1.0.0"")\n\n\nclass BeamBasedBuilderTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(BeamBasedBuilderTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n\n  @classmethod\n  def tearDownClass(cls):\n    dataset_builder._is_py2_download_and_prepare_disabled = True\n    super(BeamBasedBuilderTest, cls).tearDownClass()\n\n  def test_download_prepare_raise(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = DummyBeamDataset(data_dir=tmp_dir)\n      with self.assertRaisesWithPredicateMatch(ValueError, ""using Apache Beam""):\n        builder.download_and_prepare()\n\n  def _assertBeamGeneration(self, dl_config, dataset_cls, dataset_name):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = dataset_cls(data_dir=tmp_dir)\n      builder.download_and_prepare(download_config=dl_config)\n\n      data_dir = os.path.join(tmp_dir, dataset_name, ""1.0.0"")\n      self.assertEqual(data_dir, builder._data_dir)\n\n      # Check number of shards\n      self._assertShards(\n          data_dir,\n          pattern=""%s-test.tfrecord-{:05}-of-{:05}"" % dataset_name,\n          # Liquid sharding is not guaranteed to always use the same number.\n          num_shards=builder.info.splits[""test""].num_shards,\n      )\n      self._assertShards(\n          data_dir,\n          pattern=""%s-train.tfrecord-{:05}-of-{:05}"" % dataset_name,\n          num_shards=1,\n      )\n\n      datasets = dataset_utils.as_numpy(builder.as_dataset())\n\n      def get_id(ex):\n        return ex[""id""]\n\n      self._assertElemsAllEqual(\n          sorted(list(datasets[""test""]), key=get_id),\n          sorted([_gen_example(i)[1] for i in range(725)], key=get_id),\n      )\n      self._assertElemsAllEqual(\n          sorted(list(datasets[""train""]), key=get_id),\n          sorted([_gen_example(i)[1] for i in range(1000)], key=get_id),\n      )\n\n      self.assertDictEqual(\n          builder.info.metadata,\n          {\n              ""label_sum_1000"": 500, ""id_mean_1000"": 499.5,\n              ""label_sum_725"": 362, ""id_mean_725"": 362.0,\n          }\n      )\n\n  def _assertShards(self, data_dir, pattern, num_shards):\n    self.assertTrue(num_shards)\n    shards_filenames = [\n        pattern.format(i, num_shards) for i in range(num_shards)\n    ]\n    self.assertTrue(all(\n        tf.io.gfile.exists(os.path.join(data_dir, f)) for f in shards_filenames\n    ))\n\n  def _assertElemsAllEqual(self, nested_lhs, nested_rhs):\n    """"""assertAllEqual applied to a list of nested elements.""""""\n    for dict_lhs, dict_rhs in zip(nested_lhs, nested_rhs):\n      flat_lhs = tf.nest.flatten(dict_lhs)\n      flat_rhs = tf.nest.flatten(dict_rhs)\n      for lhs, rhs in zip(flat_lhs, flat_rhs):\n        self.assertAllEqual(lhs, rhs)\n\n\n  def _get_dl_config_if_need_to_run(self):\n    return download.DownloadConfig(\n        beam_options=beam.options.pipeline_options.PipelineOptions(),\n    )\n\n  def test_download_prepare(self):\n    dl_config = self._get_dl_config_if_need_to_run()\n    if not dl_config:\n      return\n    self._assertBeamGeneration(\n        dl_config, DummyBeamDataset, ""dummy_beam_dataset"")\n    self._assertBeamGeneration(\n        dl_config, CommonPipelineDummyBeamDataset,\n        ""common_pipeline_dummy_beam_dataset"")\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/dataset_builder_notfdv_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Test dataset builder without TFDV.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\ntf.compat.v1.enable_eager_execution()\n\n\nclass BuilderNoStatsTest(tfds.testing.TestCase):\n\n  def test_no_tfdv_dir(self):\n    with tfds.testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = tfds.testing.DummyMnist(data_dir=tmp_dir)\n      builder.download_and_prepare()  # tfdv not present. Statistics skipped.\n\n      # Statistics skipped\n      num_examples = int(builder.info.splits[\'train\'].statistics.num_examples)\n      self.assertEqual(num_examples, 0)\n\n\nif __name__ == \'__main__\':\n  tfds.testing.test_main()\n'"
tensorflow_datasets/core/dataset_builder_test.py,31,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.dataset_builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nfrom absl.testing import absltest\nimport dill\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import constants\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import download\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.core import splits as splits_lib\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import read_config as read_config_lib\n\ntf.enable_v2_behavior()\n\nDummyDatasetSharedGenerator = testing.DummyDatasetSharedGenerator\n\n\nclass DummyBuilderConfig(dataset_builder.BuilderConfig):\n\n  def __init__(self, increment=0, **kwargs):\n    super(DummyBuilderConfig, self).__init__(**kwargs)\n    self.increment = increment\n\n\nclass DummyDatasetWithConfigs(dataset_builder.GeneratorBasedBuilder):\n\n  BUILDER_CONFIGS = [\n      DummyBuilderConfig(\n          name=""plus1"",\n          version=utils.Version(""0.0.1""),\n          description=""Add 1 to the records"",\n          increment=1),\n      DummyBuilderConfig(\n          name=""plus2"",\n          version=utils.Version(""0.0.2""),\n          supported_versions=[utils.Version(""0.0.1"")],\n          description=""Add 2 to the records"",\n          increment=2),\n  ]\n\n  def _split_generators(self, dl_manager):\n    del dl_manager\n    return [\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TRAIN,\n            gen_kwargs={""range_"": range(20)},\n        ),\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TEST,\n            gen_kwargs={""range_"": range(20, 30)},\n        ),\n    ]\n\n  def _info(self):\n\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({""x"": tf.int64}),\n        supervised_keys=(""x"", ""x""),\n    )\n\n  def _generate_examples(self, range_):\n    for i in range_:\n      x = i\n      if self.builder_config:\n        x += self.builder_config.increment\n      yield i, {""x"": x}\n\n\nclass InvalidSplitDataset(DummyDatasetWithConfigs):\n\n  def _split_generators(self, _):\n    return [\n        splits_lib.SplitGenerator(\n            name=""all"",  # Error: ALL cannot be used as Split key\n        )\n    ]\n\n\nclass DatasetBuilderTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(DatasetBuilderTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n    cls.builder = DummyDatasetSharedGenerator(\n        data_dir=os.path.join(tempfile.gettempdir(), ""tfds""))\n    cls.builder.download_and_prepare()\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_load(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      dataset = registered.load(\n          name=""dummy_dataset_with_configs"",\n          data_dir=tmp_dir,\n          download=True,\n          split=splits_lib.Split.TRAIN)\n      data = list(dataset_utils.as_numpy(dataset))\n      self.assertEqual(20, len(data))\n      self.assertLess(data[0][""x""], 30)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_determinism(self):\n    ds = self.builder.as_dataset(\n        split=splits_lib.Split.TRAIN, shuffle_files=False)\n    ds_values = list(dataset_utils.as_numpy(ds))\n\n    # Ensure determinism. If this test fail, this mean that numpy random\n    # module isn\'t always determinist (maybe between version, architecture,\n    # ...), and so our datasets aren\'t guaranteed either.\n    l = list(range(20))\n    np.random.RandomState(42).shuffle(l)\n    self.assertEqual(l, [\n        0, 17, 15, 1, 8, 5, 11, 3, 18, 16, 13, 2, 9, 19, 4, 12, 7, 10, 14, 6\n    ])\n\n    # Ensure determinism. If this test fails, this mean the dataset are not\n    # deterministically generated.\n    self.assertEqual(\n        [e[""x""] for e in ds_values],\n        [6, 16, 19, 12, 14, 18, 5, 13, 15, 4, 10, 17, 0, 8, 3, 1, 9, 7, 11,\n         2],\n    )\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_load_from_gcs(self):\n    from tensorflow_datasets.image_classification import mnist  # pylint:disable=import-outside-toplevel,g-import-not-at-top\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      with absltest.mock.patch.object(\n          mnist.MNIST, ""_download_and_prepare"",\n          side_effect=NotImplementedError):\n        # Make sure the dataset cannot be generated.\n        with self.assertRaises(NotImplementedError):\n          registered.load(\n              name=""mnist"",\n              data_dir=tmp_dir)\n        # Enable GCS access so that dataset will be loaded from GCS.\n        with self.gcs_access():\n          _, info = registered.load(\n              name=""mnist"",\n              data_dir=tmp_dir,\n              with_info=True)\n      self.assertSetEqual(\n          set([""dataset_info.json"",\n               ""image.image.json"",\n               ""mnist-test.tfrecord-00000-of-00001"",\n               ""mnist-train.tfrecord-00000-of-00001"",\n              ]),\n          set(tf.io.gfile.listdir(os.path.join(tmp_dir, ""mnist/3.0.1""))))\n\n      self.assertEqual(set(info.splits.keys()), set([""train"", ""test""]))\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_multi_split(self):\n    ds_train, ds_test = self.builder.as_dataset(\n        split=[""train"", ""test""],\n        shuffle_files=False)\n\n    data = list(dataset_utils.as_numpy(ds_train))\n    self.assertEqual(20, len(data))\n\n    data = list(dataset_utils.as_numpy(ds_test))\n    self.assertEqual(10, len(data))\n\n  def test_build_data_dir(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = DummyDatasetSharedGenerator(data_dir=tmp_dir)\n      self.assertEqual(str(builder.info.version), ""1.0.0"")\n      builder_data_dir = os.path.join(tmp_dir, builder.name)\n      version_dir = os.path.join(builder_data_dir, ""1.0.0"")\n\n      # The dataset folder contains multiple other versions\n      tf.io.gfile.makedirs(os.path.join(builder_data_dir, ""14.0.0.invalid""))\n      tf.io.gfile.makedirs(os.path.join(builder_data_dir, ""10.0.0""))\n      tf.io.gfile.makedirs(os.path.join(builder_data_dir, ""9.0.0""))\n      tf.io.gfile.makedirs(os.path.join(builder_data_dir, ""0.1.0""))\n\n      # The builder\'s version dir is chosen\n      self.assertEqual(builder._build_data_dir(tmp_dir)[1], version_dir)\n\n  def test_get_data_dir_with_config(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      config_name = ""plus1""\n      builder = DummyDatasetWithConfigs(config=config_name, data_dir=tmp_dir)\n\n      builder_data_dir = os.path.join(tmp_dir, builder.name, config_name)\n      version_data_dir = os.path.join(builder_data_dir, ""0.0.1"")\n\n      tf.io.gfile.makedirs(version_data_dir)\n      self.assertEqual(builder._build_data_dir(tmp_dir)[1], version_data_dir)\n\n  def test_config_construction(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      self.assertSetEqual(\n          set([""plus1"", ""plus2""]),\n          set(DummyDatasetWithConfigs.builder_configs.keys()))\n      plus1_config = DummyDatasetWithConfigs.builder_configs[""plus1""]\n      builder = DummyDatasetWithConfigs(config=""plus1"", data_dir=tmp_dir)\n      self.assertIs(plus1_config, builder.builder_config)\n      builder = DummyDatasetWithConfigs(config=plus1_config, data_dir=tmp_dir)\n      self.assertIs(plus1_config, builder.builder_config)\n      self.assertIs(builder.builder_config,\n                    DummyDatasetWithConfigs.BUILDER_CONFIGS[0])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_with_configs(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder1 = DummyDatasetWithConfigs(config=""plus1"", data_dir=tmp_dir)\n      builder2 = DummyDatasetWithConfigs(config=""plus2"", data_dir=tmp_dir)\n      # Test that builder.builder_config is the correct config\n      self.assertIs(builder1.builder_config,\n                    DummyDatasetWithConfigs.builder_configs[""plus1""])\n      self.assertIs(builder2.builder_config,\n                    DummyDatasetWithConfigs.builder_configs[""plus2""])\n      builder1.download_and_prepare()\n      builder2.download_and_prepare()\n      data_dir1 = os.path.join(tmp_dir, builder1.name, ""plus1"", ""0.0.1"")\n      data_dir2 = os.path.join(tmp_dir, builder2.name, ""plus2"", ""0.0.2"")\n      # Test that subdirectories were created per config\n      self.assertTrue(tf.io.gfile.exists(data_dir1))\n      self.assertTrue(tf.io.gfile.exists(data_dir2))\n      # 1 train shard, 1 test shard, plus metadata files\n      self.assertGreater(len(tf.io.gfile.listdir(data_dir1)), 2)\n      self.assertGreater(len(tf.io.gfile.listdir(data_dir2)), 2)\n\n      # Test that the config was used and they didn\'t collide.\n      splits_list = [""train"", ""test""]\n      for builder, incr in [(builder1, 1), (builder2, 2)]:\n        train_data, test_data = [   # pylint: disable=g-complex-comprehension\n            [el[""x""] for el in   # pylint: disable=g-complex-comprehension\n             dataset_utils.as_numpy(builder.as_dataset(split=split))]\n            for split in splits_list\n        ]\n\n        self.assertEqual(20, len(train_data))\n        self.assertEqual(10, len(test_data))\n        self.assertCountEqual(\n            [incr + el for el in range(30)],\n            train_data + test_data\n        )\n\n  def test_read_config(self):\n    is_called = []\n    def interleave_sort(lists):\n      is_called.append(True)\n      return lists\n\n    read_config = read_config_lib.ReadConfig(\n        experimental_interleave_sort_fn=interleave_sort,\n    )\n    read_config.options.experimental_stats.prefix = ""tfds_prefix""\n    ds = self.builder.as_dataset(\n        split=""train"",\n        read_config=read_config,\n        shuffle_files=True,\n    )\n\n    # Check that the ReadConfig options are properly set\n    self.assertEqual(ds.options().experimental_stats.prefix, ""tfds_prefix"")\n\n    # The instruction function should have been called\n    self.assertEqual(is_called, [True])\n\n  def test_with_supported_version(self):\n    DummyDatasetWithConfigs(config=""plus1"", version=""0.0.1"")\n\n  def test_latest_experimental_version(self):\n    builder1 = DummyDatasetSharedGenerator()\n    self.assertEqual(str(builder1._version), ""1.0.0"")\n    builder2 = DummyDatasetSharedGenerator(version=""experimental_latest"")\n    self.assertEqual(str(builder2._version), ""2.0.0"")\n\n  def test_with_unsupported_version(self):\n    expected = ""Dataset dummy_dataset_with_configs cannot be loaded at version""\n    with self.assertRaisesWithPredicateMatch(AssertionError, expected):\n      DummyDatasetWithConfigs(config=""plus1"", version=""0.0.2"")\n    with self.assertRaisesWithPredicateMatch(AssertionError, expected):\n      DummyDatasetWithConfigs(config=""plus1"", version=""0.1.*"")\n\n  def test_previous_supported_version(self):\n    default_builder = DummyDatasetSharedGenerator()\n    self.assertEqual(str(default_builder.info.version), ""1.0.0"")\n    older_builder = DummyDatasetSharedGenerator(version=""0.0.*"")\n    self.assertEqual(str(older_builder.info.version), ""0.0.9"")\n\n  def test_generate_old_versions(self):\n\n    class MultiVersionDataset(dataset_builder.GeneratorBasedBuilder):\n\n      VERSION = utils.Version(""1.0.0"")\n      SUPPORTED_VERSIONS = [\n          utils.Version(""2.0.0""),\n          utils.Version(""1.9.0""),  # Cannot be generated\n          utils.Version(""0.0.8""),  # Cannot be generated\n      ]\n\n      def _info(self):\n        return dataset_info.DatasetInfo(builder=self)\n\n      def _split_generators(self, dl_manager):\n        return []\n\n      def _generate_examples(self):\n        yield """", {}\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = MultiVersionDataset(version=""0.0.8"", data_dir=tmp_dir)\n      with self.assertRaisesWithPredicateMatch(ValueError, ""0.0.8) is too old""):\n        builder.download_and_prepare()\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = MultiVersionDataset(version=""1.9.0"", data_dir=tmp_dir)\n      with self.assertRaisesWithPredicateMatch(ValueError, ""1.9.0) is too old""):\n        builder.download_and_prepare()\n\n    # `experimental_latest` version can be installed\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = MultiVersionDataset(version=""2.0.0"", data_dir=tmp_dir)\n      builder.download_and_prepare()\n\n  def test_invalid_split_dataset(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      with self.assertRaisesWithPredicateMatch(\n          ValueError, ""`all` is a special""):\n        # Raise error during .download_and_prepare()\n        registered.load(\n            name=""invalid_split_dataset"",\n            data_dir=tmp_dir,\n        )\n\n\nclass DatasetBuilderMultiDirTest(testing.TestCase):\n  """"""Tests for multi-dir.""""""\n\n  @classmethod\n  def setUpClass(cls):\n    super(DatasetBuilderMultiDirTest, cls).setUpClass()\n    cls.builder = DummyDatasetSharedGenerator()\n    cls.version_dir = os.path.normpath(cls.builder.info.full_name)\n\n  def setUp(self):\n    super(DatasetBuilderMultiDirTest, self).setUp()\n    # Sanity check to make sure that no dir is registered\n    self.assertEmpty(constants._registered_data_dir)\n    # Create a new temp dir\n    self.other_data_dir = os.path.join(self.get_temp_dir(), ""other_dir"")\n    # Overwrite the default data_dir (as files get created)\n    self._original_data_dir = constants.DATA_DIR\n    constants.DATA_DIR = os.path.join(self.get_temp_dir(), ""default_dir"")\n    self.default_data_dir = constants.DATA_DIR\n\n  def tearDown(self):\n    super(DatasetBuilderMultiDirTest, self).tearDown()\n    # Restore to the default `_registered_data_dir`\n    constants._registered_data_dir = set()\n    # Clear-up existing dirs\n    if tf.io.gfile.exists(self.other_data_dir):\n      tf.io.gfile.rmtree(self.other_data_dir)\n    if tf.io.gfile.exists(self.default_data_dir):\n      tf.io.gfile.rmtree(self.default_data_dir)\n    # Restore the orgininal data dir\n    constants.DATA_DIR = self._original_data_dir\n\n  def assertBuildDataDir(self, build_data_dir_out, root_dir):\n    data_dir_root, data_dir = build_data_dir_out\n    self.assertEqual(data_dir_root, root_dir)\n    self.assertEqual(data_dir, os.path.join(root_dir, self.version_dir))\n\n  def test_default(self):\n    # No data_dir is passed\n    # -> use default path is used.\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(None), self.default_data_dir)\n\n  def test_explicitly_passed(self):\n    # When a dir is explictly passed, use it.\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(self.other_data_dir), self.other_data_dir)\n\n  def test_default_multi_dir(self):\n    # No data_dir is passed\n    # Multiple data_dirs are registered\n    # -> use default path\n    constants.add_data_dir(self.other_data_dir)\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(None), self.default_data_dir)\n\n  def test_default_multi_dir_old_version_exists(self):\n    # No data_dir is passed\n    # Multiple data_dirs are registered\n    # Data dir contains old versions\n    # -> use default path\n    constants.add_data_dir(self.other_data_dir)\n    tf.io.gfile.makedirs(os.path.join(\n        self.other_data_dir, ""dummy_dataset_shared_generator"", ""0.1.0""))\n    tf.io.gfile.makedirs(os.path.join(\n        self.other_data_dir, ""dummy_dataset_shared_generator"", ""0.2.0""))\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(None), self.default_data_dir)\n\n  def test_default_multi_dir_version_exists(self):\n    # No data_dir is passed\n    # Multiple data_dirs are registered\n    # Data found\n    # -> Re-load existing data\n    constants.add_data_dir(self.other_data_dir)\n    tf.io.gfile.makedirs(os.path.join(\n        self.other_data_dir, ""dummy_dataset_shared_generator"", ""1.0.0""))\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(None), self.other_data_dir)\n\n  def test_default_multi_dir_duplicate(self):\n    # If two data dirs contains the dataset, raise an error...\n    constants.add_data_dir(self.other_data_dir)\n    tf.io.gfile.makedirs(os.path.join(\n        self.default_data_dir, ""dummy_dataset_shared_generator"", ""1.0.0""))\n    tf.io.gfile.makedirs(os.path.join(\n        self.other_data_dir, ""dummy_dataset_shared_generator"", ""1.0.0""))\n    with self.assertRaisesRegex(ValueError, ""found in more than one directory""):\n      self.builder._build_data_dir(None)\n\n  def test_expicit_multi_dir(self):\n    # If two data dirs contains the same version\n    # Data dir is explicitly passed\n    constants.add_data_dir(self.other_data_dir)\n    tf.io.gfile.makedirs(os.path.join(\n        self.default_data_dir, ""dummy_dataset_shared_generator"", ""1.0.0""))\n    tf.io.gfile.makedirs(os.path.join(\n        self.other_data_dir, ""dummy_dataset_shared_generator"", ""1.0.0""))\n    self.assertBuildDataDir(\n        self.builder._build_data_dir(self.other_data_dir), self.other_data_dir)\n\n\nclass BuilderPickleTest(testing.TestCase):\n\n  def test_load_dump(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n    builder2 = dill.loads(dill.dumps(builder))\n    self.assertEqual(builder.name, builder2.name)\n    self.assertEqual(builder.version, builder2.version)\n\n\nclass BuilderRestoreGcsTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(BuilderRestoreGcsTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n\n  @classmethod\n  def tearDownClass(cls):\n    dataset_builder._is_py2_download_and_prepare_disabled = True\n    super(BuilderRestoreGcsTest, cls).tearDownClass()\n\n  def setUp(self):\n    super(BuilderRestoreGcsTest, self).setUp()\n\n    def load_mnist_dataset_info(self):\n      mnist_info_path = os.path.join(\n          utils.tfds_dir(),\n          ""testing/test_data/dataset_info/mnist/3.0.1"",\n      )\n      mnist_info_path = os.path.normpath(mnist_info_path)\n      self.read_from_directory(mnist_info_path)\n\n    patcher = absltest.mock.patch.object(\n        dataset_info.DatasetInfo,\n        ""initialize_from_bucket"",\n        new=load_mnist_dataset_info\n    )\n    patcher.start()\n    self.patch_gcs = patcher\n    self.addCleanup(patcher.stop)\n\n    patcher = absltest.mock.patch.object(\n        dataset_info.DatasetInfo, ""compute_dynamic_properties"",\n    )\n    self.compute_dynamic_property = patcher.start()\n    self.addCleanup(patcher.stop)\n\n  def test_stats_restored_from_gcs(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      self.assertEqual(builder.info.splits[""train""].statistics.num_examples, 20)\n      self.assertFalse(self.compute_dynamic_property.called)\n\n      builder.download_and_prepare()\n\n      # Statistics shouldn\'t have been recomputed\n      self.assertEqual(builder.info.splits[""train""].statistics.num_examples, 20)\n      self.assertFalse(self.compute_dynamic_property.called)\n\n  def test_stats_not_restored_gcs_overwritten(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # If split are different that the one restored, stats should be recomputed\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      self.assertEqual(builder.info.splits[""train""].statistics.num_examples, 20)\n      self.assertFalse(self.compute_dynamic_property.called)\n\n      dl_config = download.DownloadConfig(max_examples_per_split=5)\n      builder.download_and_prepare(download_config=dl_config)\n\n      # Statistics should have been recomputed (split different from the\n      # restored ones)\n      self.assertTrue(self.compute_dynamic_property.called)\n\n  def test_gcs_not_exists(self):\n    # By disabling the patch, and because DummyMnist is not on GCS, we can\n    # simulate a new dataset starting from scratch\n    self.patch_gcs.stop()\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      # No dataset_info restored, so stats are empty\n      self.assertEqual(builder.info.splits.total_num_examples, 0)\n      self.assertFalse(self.compute_dynamic_property.called)\n\n      builder.download_and_prepare()\n\n      # Statistics should have been recomputed\n      self.assertTrue(self.compute_dynamic_property.called)\n    self.patch_gcs.start()\n\n  def test_skip_stats(self):\n    # Test when stats do not exists yet and compute_stats=\'skip\'\n\n    # By disabling the patch, and because DummyMnist is not on GCS, we can\n    # simulate a new dataset starting from scratch\n    self.patch_gcs.stop()\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # No dataset_info restored, so stats are empty\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      self.assertEqual(builder.info.splits, {})\n      self.assertFalse(self.compute_dynamic_property.called)\n\n      download_config = download.DownloadConfig(\n          compute_stats=download.ComputeStatsMode.SKIP,\n      )\n      builder.download_and_prepare(download_config=download_config)\n\n      # Statistics computation should have been skipped\n      self.assertEqual(builder.info.splits[""train""].statistics.num_examples, 0)\n      self.assertFalse(self.compute_dynamic_property.called)\n    self.patch_gcs.start()\n\n  def test_force_stats(self):\n    # Test when stats already exists but compute_stats=\'force\'\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # No dataset_info restored, so stats are empty\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      self.assertEqual(builder.info.splits.total_num_examples, 40)\n      self.assertFalse(self.compute_dynamic_property.called)\n\n      download_config = download.DownloadConfig(\n          compute_stats=download.ComputeStatsMode.FORCE,\n      )\n      builder.download_and_prepare(download_config=download_config)\n\n      # Statistics computation should have been recomputed\n      self.assertTrue(self.compute_dynamic_property.called)\n\n\nclass DatasetBuilderReadTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(DatasetBuilderReadTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n    cls._tfds_tmp_dir = testing.make_tmp_dir()\n    builder = DummyDatasetSharedGenerator(data_dir=cls._tfds_tmp_dir)\n    builder.download_and_prepare()\n\n  @classmethod\n  def tearDownClass(cls):\n    super(DatasetBuilderReadTest, cls).tearDownClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = True\n    testing.rm_tmp_dir(cls._tfds_tmp_dir)\n\n  def setUp(self):\n    super(DatasetBuilderReadTest, self).setUp()\n    self.builder = DummyDatasetSharedGenerator(data_dir=self._tfds_tmp_dir)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_all_splits(self):\n    splits = dataset_utils.as_numpy(\n        self.builder.as_dataset(batch_size=-1))\n    self.assertSetEqual(set(splits.keys()),\n                        set([splits_lib.Split.TRAIN, splits_lib.Split.TEST]))\n\n    # Test that enum and string both access same object\n    self.assertIs(splits[""train""], splits[splits_lib.Split.TRAIN])\n    self.assertIs(splits[""test""], splits[splits_lib.Split.TEST])\n\n    train_data = splits[splits_lib.Split.TRAIN][""x""]\n    test_data = splits[splits_lib.Split.TEST][""x""]\n    self.assertEqual(20, len(train_data))\n    self.assertEqual(10, len(test_data))\n    self.assertEqual(sum(range(30)), int(train_data.sum() + test_data.sum()))\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_with_batch_size(self):\n    items = list(dataset_utils.as_numpy(self.builder.as_dataset(\n        split=""train+test"", batch_size=10)))\n    # 3 batches of 10\n    self.assertEqual(3, len(items))\n    x1, x2, x3 = items[0][""x""], items[1][""x""], items[2][""x""]\n    self.assertEqual(10, x1.shape[0])\n    self.assertEqual(10, x2.shape[0])\n    self.assertEqual(10, x3.shape[0])\n    self.assertEqual(sum(range(30)), int(x1.sum() + x2.sum() + x3.sum()))\n\n    # By default batch_size is None and won\'t add a batch dimension\n    ds = self.builder.as_dataset(split=splits_lib.Split.TRAIN)\n    self.assertEqual(0, len(tf.compat.v1.data.get_output_shapes(ds)[""x""]))\n    # Setting batch_size=1 will add an extra batch dimension\n    ds = self.builder.as_dataset(split=splits_lib.Split.TRAIN, batch_size=1)\n    self.assertEqual(1, len(tf.compat.v1.data.get_output_shapes(ds)[""x""]))\n    # Setting batch_size=2 will add an extra batch dimension\n    ds = self.builder.as_dataset(split=splits_lib.Split.TRAIN, batch_size=2)\n    self.assertEqual(1, len(tf.compat.v1.data.get_output_shapes(ds)[""x""]))\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_supervised_keys(self):\n    x, _ = dataset_utils.as_numpy(self.builder.as_dataset(\n        split=splits_lib.Split.TRAIN, as_supervised=True, batch_size=-1))\n    self.assertEqual(x.shape[0], 20)\n\n  def test_autocache(self):\n    # All the following should cache\n\n    # Default should cache as dataset is small and has a single shard\n    self.assertTrue(self.builder._should_cache_ds(\n        split=""train"",\n        shuffle_files=True,\n        read_config=read_config_lib.ReadConfig(),\n    ))\n\n    # Multiple shards should cache when shuffling is disabled\n    self.assertTrue(self.builder._should_cache_ds(\n        split=""train+test"",\n        shuffle_files=False,\n        read_config=read_config_lib.ReadConfig(),\n    ))\n\n    # Multiple shards should cache when re-shuffling is disabled\n    self.assertTrue(self.builder._should_cache_ds(\n        split=""train+test"",\n        shuffle_files=True,\n        read_config=read_config_lib.ReadConfig(\n            shuffle_reshuffle_each_iteration=False),\n    ))\n\n    # Sub-split API can cache if only a single shard is selected.\n    self.assertTrue(self.builder._should_cache_ds(\n        split=""train+test[:0]"",\n        shuffle_files=True,\n        read_config=read_config_lib.ReadConfig(),\n    ))\n\n    # All the following should NOT cache\n\n    # Default should not cache if try_autocache is disabled\n    self.assertFalse(self.builder._should_cache_ds(\n        split=""train"",\n        shuffle_files=True,\n        read_config=read_config_lib.ReadConfig(try_autocache=False),\n    ))\n\n    # Multiple shards should not cache when shuffling is enabled\n    self.assertFalse(self.builder._should_cache_ds(\n        split=""train+test"",\n        shuffle_files=True,\n        read_config=read_config_lib.ReadConfig(),\n    ))\n\n\n\n\nclass NestedSequenceBuilder(dataset_builder.GeneratorBasedBuilder):\n  """"""Dataset containing nested sequences.""""""\n\n  VERSION = utils.Version(""0.0.1"")\n\n  def _info(self):\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({\n            ""frames"": features.Sequence({\n                ""coordinates"": features.Sequence(\n                    features.Tensor(shape=(2,), dtype=tf.int32)\n                ),\n            }),\n        }),\n    )\n\n  def _split_generators(self, dl_manager):\n    del dl_manager\n    return [\n        splits_lib.SplitGenerator(\n            name=splits_lib.Split.TRAIN,\n            gen_kwargs={},\n        ),\n    ]\n\n  def _generate_examples(self):\n    ex0 = [\n        [[0, 1], [2, 3], [4, 5]],\n        [],\n        [[6, 7]]\n    ]\n    ex1 = []\n    ex2 = [\n        [[10, 11]],\n        [[12, 13], [14, 15]],\n    ]\n    for i, ex in enumerate([ex0, ex1, ex2]):\n      yield i, {""frames"": {""coordinates"": ex}}\n\n\nclass NestedSequenceBuilderTest(testing.TestCase):\n  """"""Test of the NestedSequenceBuilder.""""""\n\n  @classmethod\n  def setUpClass(cls):\n    super(NestedSequenceBuilderTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n\n  @classmethod\n  def tearDownClass(cls):\n    dataset_builder._is_py2_download_and_prepare_disabled = True\n    super(NestedSequenceBuilderTest, cls).tearDownClass()\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_nested_sequence(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      ds_train, ds_info = registered.load(\n          name=""nested_sequence_builder"",\n          data_dir=tmp_dir,\n          split=""train"",\n          with_info=True,\n          shuffle_files=False)\n      ex0, ex1, ex2 = [\n          ex[""frames""][""coordinates""]\n          for ex in dataset_utils.as_numpy(ds_train)\n      ]\n      self.assertAllEqual(ex0, tf.ragged.constant([\n          [[0, 1], [2, 3], [4, 5]],\n          [],\n          [[6, 7]],\n      ], inner_shape=(2,)))\n      self.assertAllEqual(ex1, tf.ragged.constant([], ragged_rank=1))\n      self.assertAllEqual(ex2, tf.ragged.constant([\n          [[10, 11]],\n          [[12, 13], [14, 15]],\n      ], inner_shape=(2,)))\n\n      self.assertEqual(\n          ds_info.features.dtype,\n          {""frames"": {""coordinates"": tf.int32}},\n      )\n      self.assertEqual(\n          ds_info.features.shape,\n          {""frames"": {""coordinates"": (None, None, 2)}},\n      )\n      nested_tensor_info = ds_info.features.get_tensor_info()\n      self.assertEqual(\n          nested_tensor_info[""frames""][""coordinates""].sequence_rank,\n          2,\n      )\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/dataset_info.py,10,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DatasetInfo records the information we know about a dataset.\n\nThis includes things that we know about the dataset statically, i.e.:\n - schema\n - description\n - canonical location\n - does it have validation and tests splits\n - size\n - etc.\n\nThis also includes the things that can and should be computed once we\'ve\nprocessed the dataset as well:\n - number of examples (in each split)\n - feature statistics (in each split)\n - etc.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport json\nimport os\nimport posixpath\nimport tempfile\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core import naming\nfrom tensorflow_datasets.core import splits as splits_lib\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.features import top_level_feature\nfrom tensorflow_datasets.core.proto import dataset_info_pb2\nfrom tensorflow_datasets.core.utils import gcs_utils\n\nfrom google.protobuf import json_format\n\n\n# Name of the file to output the DatasetInfo protobuf object.\nDATASET_INFO_FILENAME = ""dataset_info.json""\nLICENSE_FILENAME = ""LICENSE""\n\nINFO_STR = """"""tfds.core.DatasetInfo(\n    name=\'{name}\',\n    version={version},\n    description=\'{description}\',\n    homepage=\'{homepage}\',\n    features={features},\n    total_num_examples={total_num_examples},\n    splits={splits},\n    supervised_keys={supervised_keys},\n    citation={citation},\n    redistribution_info={redistribution_info},\n)\n""""""\n\n\n# TODO(tfds): Do we require to warn the user about the peak memory used while\n# constructing the dataset?\nclass DatasetInfo(object):\n  """"""Information about a dataset.\n\n  `DatasetInfo` documents datasets, including its name, version, and features.\n  See the constructor arguments and properties for a full list.\n\n  Note: Not all fields are known on construction and may be updated later\n  by `compute_dynamic_properties`. For example: the min and max values of a\n  feature is typically updated during data generation (i.e. on calling\n  builder.download_and_prepare()`).\n  """"""\n\n  @api_utils.disallow_positional_args\n  def __init__(self,\n               builder,\n               description=None,\n               features=None,\n               supervised_keys=None,\n               homepage=None,\n               citation=None,\n               metadata=None,\n               redistribution_info=None):\n    """"""Constructs DatasetInfo.\n\n    Args:\n      builder: `DatasetBuilder`, dataset builder for this info.\n      description: `str`, description of this dataset.\n      features: `tfds.features.FeaturesDict`, Information on the feature dict\n        of the `tf.data.Dataset()` object from the `builder.as_dataset()`\n        method.\n      supervised_keys: `tuple` of `(input_key, target_key)`, Specifies the\n        input feature and the label for supervised learning, if applicable for\n        the dataset. The keys correspond to the feature names to select in\n        `info.features`. When calling `tfds.core.DatasetBuilder.as_dataset()`\n        with `as_supervised=True`, the `tf.data.Dataset` object will yield\n        the (input, target) defined here.\n      homepage: `str`, optional, the homepage for this dataset.\n      citation: `str`, optional, the citation to use for this dataset.\n      metadata: `tfds.core.Metadata`, additonal object which will be\n        stored/restored with the dataset. This allows for storing additional\n        information with the dataset.\n      redistribution_info: `dict`, optional, information needed for\n        redistribution, as specified in `dataset_info_pb2.RedistributionInfo`.\n        The content of the `license` subfield will automatically be written to a\n        LICENSE file stored with the dataset.\n    """"""\n    self._builder = builder\n\n    self._info_proto = dataset_info_pb2.DatasetInfo(\n        name=builder.name,\n        description=utils.dedent(description),\n        version=str(builder._version),  # pylint: disable=protected-access\n        citation=utils.dedent(citation),\n        redistribution_info=dataset_info_pb2.RedistributionInfo(\n            license=utils.dedent(redistribution_info.pop(""license"")),\n            **redistribution_info) if redistribution_info else None)\n\n    if homepage:\n      self._info_proto.location.urls[:] = [homepage]\n\n    if features:\n      if not isinstance(features, top_level_feature.TopLevelFeature):\n        raise ValueError(\n            ""DatasetInfo.features only supports FeaturesDict or Sequence at ""\n            ""the top-level. Got {}"".format(features))\n      features._set_top_level()  # pylint: disable=protected-access\n    self._features = features\n    self._splits = splits_lib.SplitDict(self._builder.name)\n    if supervised_keys is not None:\n      assert isinstance(supervised_keys, tuple)\n      assert len(supervised_keys) == 2\n      self._info_proto.supervised_keys.input = supervised_keys[0]\n      self._info_proto.supervised_keys.output = supervised_keys[1]\n\n    if metadata and not isinstance(metadata, Metadata):\n      raise ValueError(\n          ""Metadata should be a `tfds.core.Metadata` instance. Received ""\n          ""{}"".format(metadata))\n    self._metadata = metadata\n\n    # Is this object initialized with both the static and the dynamic data?\n    self._fully_initialized = False\n\n  @property\n  def as_proto(self):\n    return self._info_proto\n\n  @property\n  def name(self):\n    return self.as_proto.name\n\n  @property\n  def full_name(self):\n    """"""Full canonical name: (<dataset_name>/<config_name>/<version>).""""""\n    names = [self._builder.name]\n    if self._builder.builder_config:\n      names.append(self._builder.builder_config.name)\n    names.append(str(self.version))\n    return posixpath.join(*names)\n\n  @property\n  def description(self):\n    return self.as_proto.description\n\n  @property\n  def version(self):\n    return self._builder.version\n\n  @property\n  def homepage(self):\n    urls = self.as_proto.location.urls\n    tfds_homepage = ""https://www.tensorflow.org/datasets/catalog/{}"".format(\n        self.name)\n    return urls and urls[0] or tfds_homepage\n\n  @property\n  def citation(self):\n    return self.as_proto.citation\n\n  @property\n  def data_dir(self):\n    return self._builder.data_dir\n\n  @property\n  def dataset_size(self):\n    """"""Generated dataset files size, in bytes.""""""\n    # For old datasets, maybe empty.\n    return sum(split.num_bytes for split in self.splits.values())\n\n  @property\n  def download_size(self):\n    """"""Downloaded files size, in bytes.""""""\n    # Fallback to deprecated `size_in_bytes` if `download_size` is empty.\n    return self.as_proto.download_size or self.as_proto.size_in_bytes\n\n  @download_size.setter\n  def download_size(self, size):\n    self.as_proto.download_size = size\n\n  @property\n  def features(self):\n    return self._features\n\n  @property\n  def metadata(self):\n    return self._metadata\n\n  @property\n  def supervised_keys(self):\n    if not self.as_proto.HasField(""supervised_keys""):\n      return None\n    supervised_keys = self.as_proto.supervised_keys\n    return (supervised_keys.input, supervised_keys.output)\n\n  @property\n  def redistribution_info(self):\n    return self.as_proto.redistribution_info\n\n  @property\n  def splits(self):\n    return self._splits.copy()\n\n  def update_splits_if_different(self, split_dict):\n    """"""Overwrite the splits if they are different from the current ones.\n\n    * If splits aren\'t already defined or different (ex: different number of\n      shards), then the new split dict is used. This will trigger stats\n      computation during download_and_prepare.\n    * If splits are already defined in DatasetInfo and similar (same names and\n      shards): keep the restored split which contains the statistics (restored\n      from GCS or file)\n\n    Args:\n      split_dict: `tfds.core.SplitDict`, the new split\n    """"""\n    assert isinstance(split_dict, splits_lib.SplitDict)\n\n    # If splits are already defined and identical, then we do not update\n    if self._splits and splits_lib.check_splits_equals(\n        self._splits, split_dict):\n      return\n\n    self._set_splits(split_dict)\n\n  def _set_splits(self, split_dict):\n    """"""Split setter (private method).""""""\n    # Update the dictionary representation.\n    # Use from/to proto for a clean copy\n    self._splits = split_dict.copy()\n\n    # Update the proto\n    del self.as_proto.splits[:]  # Clear previous\n    for split_info in split_dict.to_proto():\n      self.as_proto.splits.add().CopyFrom(split_info)\n\n  @property\n  def initialized(self):\n    """"""Whether DatasetInfo has been fully initialized.""""""\n    return self._fully_initialized\n\n  def _dataset_info_path(self, dataset_info_dir):\n    return os.path.join(dataset_info_dir, DATASET_INFO_FILENAME)\n\n  def _license_path(self, dataset_info_dir):\n    return os.path.join(dataset_info_dir, LICENSE_FILENAME)\n\n  def compute_dynamic_properties(self):\n    self._compute_dynamic_properties(self._builder)\n    self._fully_initialized = True\n\n  def _compute_dynamic_properties(self, builder):\n    """"""Update from the DatasetBuilder.""""""\n    # Fill other things by going over the dataset.\n    splits = self.splits\n    for split_info in utils.tqdm(\n        splits.values(), desc=""Computing statistics..."", unit="" split""):\n      try:\n        split_name = split_info.name\n        # Fill DatasetFeatureStatistics.\n        dataset_feature_statistics, schema = get_dataset_feature_statistics(\n            builder, split_name)\n\n        # Add the statistics to this split.\n        split_info.statistics.CopyFrom(dataset_feature_statistics)\n\n        # Set the schema at the top-level since this is independent of the\n        # split.\n        self.as_proto.schema.CopyFrom(schema)\n\n      except tf.errors.InvalidArgumentError:\n        # This means there is no such split, even though it was specified in the\n        # info, the least we can do is to log this.\n        logging.error((""%s\'s info() property specifies split %s, but it ""\n                       ""doesn\'t seem to have been generated. Please ensure ""\n                       ""that the data was downloaded for this split and re-run ""\n                       ""download_and_prepare.""), self.name, split_name)\n        raise\n\n    # Set splits to trigger proto update in setter\n    self._set_splits(splits)\n\n  @property\n  def as_json(self):\n    return json_format.MessageToJson(self.as_proto, sort_keys=True)\n\n  def write_to_directory(self, dataset_info_dir):\n    """"""Write `DatasetInfo` as JSON to `dataset_info_dir`.""""""\n    # Save the metadata from the features (vocabulary, labels,...)\n    if self.features:\n      self.features.save_metadata(dataset_info_dir)\n\n    # Save any additional metadata\n    if self.metadata is not None:\n      self.metadata.save_metadata(dataset_info_dir)\n\n    if self.redistribution_info.license:\n      with tf.io.gfile.GFile(self._license_path(dataset_info_dir), ""w"") as f:\n        f.write(self.redistribution_info.license)\n\n    with tf.io.gfile.GFile(self._dataset_info_path(dataset_info_dir), ""w"") as f:\n      f.write(self.as_json)\n\n  def read_from_directory(self, dataset_info_dir):\n    """"""Update DatasetInfo from the JSON file in `dataset_info_dir`.\n\n    This function updates all the dynamically generated fields (num_examples,\n    hash, time of creation,...) of the DatasetInfo.\n\n    This will overwrite all previous metadata.\n\n    Args:\n      dataset_info_dir: `str` The directory containing the metadata file. This\n        should be the root directory of a specific dataset version.\n    """"""\n    if not dataset_info_dir:\n      raise ValueError(\n          ""Calling read_from_directory with undefined dataset_info_dir."")\n    logging.info(""Load dataset info from %s"", dataset_info_dir)\n\n    json_filename = self._dataset_info_path(dataset_info_dir)\n\n    # Load the metadata from disk\n    parsed_proto = read_from_json(json_filename)\n\n    # Update splits\n    split_dict = splits_lib.SplitDict.from_proto(self.name, parsed_proto.splits)\n    self._set_splits(split_dict)\n\n    # Restore the feature metadata (vocabulary, labels names,...)\n    if self.features:\n      self.features.load_metadata(dataset_info_dir)\n\n    if self.metadata is not None:\n      self.metadata.load_metadata(dataset_info_dir)\n\n    # Update fields which are not defined in the code. This means that\n    # the code will overwrite fields which are present in\n    # dataset_info.json.\n    for field_name, field in self.as_proto.DESCRIPTOR.fields_by_name.items():\n      field_value = getattr(self._info_proto, field_name)\n      field_value_restored = getattr(parsed_proto, field_name)\n\n      try:\n        is_defined = self._info_proto.HasField(field_name)\n      except ValueError:\n        is_defined = bool(field_value)\n\n      try:\n        is_defined_in_restored = parsed_proto.HasField(field_name)\n      except ValueError:\n        is_defined_in_restored = bool(field_value_restored)\n\n      # If field is defined in code, we ignore the value\n      if is_defined:\n        if field_value != field_value_restored:\n          logging.info(\n              ""Field info.%s from disk and from code do not match. Keeping ""\n              ""the one from code."", field_name)\n        continue\n      # If the field is also not defined in JSON file, we do nothing\n      if not is_defined_in_restored:\n        continue\n      # Otherwise, we restore the dataset_info.json value\n      if field.type == field.TYPE_MESSAGE:\n        field_value.MergeFrom(field_value_restored)\n      else:\n        setattr(self._info_proto, field_name, field_value_restored)\n\n    if self._builder._version != self.version:  # pylint: disable=protected-access\n      raise AssertionError(\n          ""The constructed DatasetInfo instance and the restored proto version ""\n          ""do not match. Builder version: {}. Proto version: {}"".format(\n              self._builder._version, self.version))  # pylint: disable=protected-access\n\n    # Mark as fully initialized.\n    self._fully_initialized = True\n\n  def initialize_from_bucket(self):\n    """"""Initialize DatasetInfo from GCS bucket info files.""""""\n    # In order to support Colab, we use the HTTP GCS API to access the metadata\n    # files. They are copied locally and then loaded.\n    tmp_dir = tempfile.mkdtemp(""tfds"")\n    data_files = gcs_utils.gcs_dataset_info_files(self.full_name)\n    if not data_files:\n      return\n    logging.info(""Load pre-computed DatasetInfo (eg: splits, num examples,...) ""\n                 ""from GCS: %s"", self.full_name)\n    for fname in data_files:\n      out_fname = os.path.join(tmp_dir, os.path.basename(fname))\n      gcs_utils.download_gcs_file(fname, out_fname)\n    self.read_from_directory(tmp_dir)\n\n  def __repr__(self):\n    splits_pprint = _indent(""\\n"".join([""{""] + [\n        ""    \'{}\': {},"".format(k, split.num_examples)\n        for k, split in sorted(self.splits.items())\n    ] + [""}""]))\n    features_pprint = _indent(repr(self.features))\n    citation_pprint = _indent(\'""""""{}""""""\'.format(self.citation.strip()))\n    return INFO_STR.format(\n        name=self.name,\n        version=self.version,\n        description=self.description,\n        total_num_examples=self.splits.total_num_examples,\n        features=features_pprint,\n        splits=splits_pprint,\n        citation=citation_pprint,\n        homepage=self.homepage,\n        supervised_keys=self.supervised_keys,\n        # Proto add a \\n that we strip.\n        redistribution_info=str(self.redistribution_info).strip())\n\n\ndef _indent(content):\n  """"""Add indentation to all lines except the first.""""""\n  lines = content.split(""\\n"")\n  return ""\\n"".join([lines[0]] + [""    "" + l for l in lines[1:]])\n\n\ndef _populate_shape(shape_or_dict, prefix, schema_features):\n  """"""Populates shape in the schema.""""""\n  if isinstance(shape_or_dict, (tuple, list)):\n    feature_name = ""/"".join(prefix)\n    if shape_or_dict and feature_name in schema_features:\n      schema_feature = schema_features[feature_name]\n      schema_feature.ClearField(""shape"")\n      for dim in shape_or_dict:\n        # We denote `None`s as -1 in the shape proto.\n        schema_feature.shape.dim.add().size = -1 if dim is None else dim\n    return\n  for name, val in shape_or_dict.items():\n    prefix.append(name)\n    _populate_shape(val, prefix, schema_features)\n    prefix.pop()\n\n\ndef get_dataset_feature_statistics(builder, split):\n  """"""Calculate statistics for the specified split.""""""\n  tfdv = lazy_imports_lib.lazy_imports.tensorflow_data_validation\n  # TODO(epot): Avoid hardcoding file format.\n  filetype_suffix = ""tfrecord""\n  if filetype_suffix not in [""tfrecord"", ""csv""]:\n    raise ValueError(\n        ""Cannot generate statistics for filetype {}"".format(filetype_suffix))\n  filepattern = naming.filepattern_for_dataset_split(\n      builder.name, split, builder.data_dir, filetype_suffix)\n  # Avoid generating a large number of buckets in rank histogram\n  # (default is 1000).\n  stats_options = tfdv.StatsOptions(num_top_values=10,\n                                    num_rank_histogram_buckets=10)\n  if filetype_suffix == ""csv"":\n    statistics = tfdv.generate_statistics_from_csv(\n        filepattern, stats_options=stats_options)\n  else:\n    statistics = tfdv.generate_statistics_from_tfrecord(\n        filepattern, stats_options=stats_options)\n  schema = tfdv.infer_schema(statistics)\n  schema_features = {feature.name: feature for feature in schema.feature}\n  # Override shape in the schema.\n  for feature_name, feature in builder.info.features.items():\n    _populate_shape(feature.shape, [feature_name], schema_features)\n\n  # Remove legacy field.\n  if getattr(schema, ""generate_legacy_feature_spec"", None) is not None:\n    schema.ClearField(""generate_legacy_feature_spec"")\n  return statistics.datasets[0], schema\n\n\ndef read_from_json(json_filename):\n  """"""Read JSON-formatted proto into DatasetInfo proto.""""""\n  with tf.io.gfile.GFile(json_filename) as f:\n    dataset_info_json_str = f.read()\n  # Parse it back into a proto.\n  parsed_proto = json_format.Parse(dataset_info_json_str,\n                                   dataset_info_pb2.DatasetInfo())\n  return parsed_proto\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Metadata(dict):\n  """"""Abstract base class for DatasetInfo metadata container.\n\n  `builder.info.metadata` allows the dataset to expose additional general\n  information about the dataset which are not specific to a feature or\n  individual example.\n\n  To implement the interface, overwrite `save_metadata` and\n  `load_metadata`.\n\n  See `tfds.core.MetadataDict` for a simple implementation that acts as a\n  dict that saves data to/from a JSON file.\n  """"""\n\n  @abc.abstractmethod\n  def save_metadata(self, data_dir):\n    """"""Save the metadata.""""""\n    raise NotImplementedError()\n\n  @abc.abstractmethod\n  def load_metadata(self, data_dir):\n    """"""Restore the metadata.""""""\n    raise NotImplementedError()\n\n\nclass MetadataDict(Metadata, dict):\n  """"""A `tfds.core.Metadata` object that acts as a `dict`.\n\n  By default, the metadata will be serialized as JSON.\n  """"""\n\n  def _build_filepath(self, data_dir):\n    return os.path.join(data_dir, ""metadata.json"")\n\n  def save_metadata(self, data_dir):\n    """"""Save the metadata.""""""\n    with tf.io.gfile.GFile(self._build_filepath(data_dir), ""w"") as f:\n      json.dump(self, f)\n\n  def load_metadata(self, data_dir):\n    """"""Restore the metadata.""""""\n    self.clear()\n    with tf.io.gfile.GFile(self._build_filepath(data_dir), ""r"") as f:\n      self.update(json.load(f))\n\n\nclass BeamMetadataDict(MetadataDict):\n  """"""A `tfds.core.Metadata` object supporting Beam-generated datasets.""""""\n\n  def __init__(self, *args, **kwargs):\n    super(BeamMetadataDict, self).__init__(*args, **kwargs)\n    self._tempdir = tempfile.mkdtemp(""tfds_beam_metadata"")\n\n  def _temp_filepath(self, key):\n    return os.path.join(self._tempdir, ""%s.json"" % key)\n\n  def __setitem__(self, key, item):\n    """"""Creates write sink for beam PValues or sets value of key in `dict`.\n\n    If the item is a PValue, it is expected to contain exactly one element,\n    which will be written out as a temporary JSON file once the beam pipeline\n    runs. These outputs will be loaded and stored in a single JSON when\n    `save_metadata` is called after the pipeline completes.\n\n    Args:\n      key: hashable type, the key for the item.\n      item: `beam.pvalue.PValue` or other, the metadata value.\n    """"""\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n    if isinstance(item, beam.pvalue.PValue):\n      if key in self:\n        raise ValueError(""Already added PValue with key: %s"" % key)\n      logging.info(""Lazily adding metadata item with Beam: %s"", key)\n      def _to_json(item_list):\n        if len(item_list) != 1:\n          raise ValueError(\n              ""Each metadata PValue must contain a single element. Got %d."" %\n              len(item_list))\n        item = item_list[0]\n        return json.dumps(item)\n      _ = (item\n           | ""metadata_%s_tolist"" % key >> beam.combiners.ToList()\n           | ""metadata_%s_tojson"" % key >> beam.Map(_to_json)\n           | ""metadata_%s_write"" % key >> beam.io.WriteToText(\n               self._temp_filepath(key),\n               num_shards=1,\n               shard_name_template=""""))\n    super(BeamMetadataDict, self).__setitem__(key, item)\n\n  def save_metadata(self, data_dir):\n    """"""Save the metadata inside the beam job.""""""\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n    for key, item in self.items():\n      if isinstance(item, beam.pvalue.PValue):\n        with tf.io.gfile.GFile(self._temp_filepath(key), ""r"") as f:\n          self[key] = json.load(f)\n    tf.io.gfile.rmtree(self._tempdir)\n    super(BeamMetadataDict, self).save_metadata(data_dir)\n'"
tensorflow_datasets/core/dataset_info_test.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.dataset_info.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport tempfile\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.image_classification import mnist\n\nfrom google.protobuf import text_format\nfrom tensorflow_metadata.proto.v0 import schema_pb2\n\ntf.enable_v2_behavior()\n\n_TFDS_DIR = py_utils.tfds_dir()\n_INFO_DIR = os.path.join(_TFDS_DIR, ""testing"", ""test_data"", ""dataset_info"",\n                         ""mnist"", ""3.0.1"")\n_INFO_DIR_UNLABELED = os.path.join(_TFDS_DIR, ""testing"", ""test_data"",\n                                   ""dataset_info"", ""mnist_unlabeled"", ""3.0.1"")\n_NON_EXISTENT_DIR = os.path.join(_TFDS_DIR, ""non_existent_dir"")\n\n\nDummyDatasetSharedGenerator = testing.DummyDatasetSharedGenerator\n\n\nclass RandomShapedImageGenerator(DummyDatasetSharedGenerator):\n\n  def _info(self):\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({""im"": features.Image()}),\n        supervised_keys=(""im"", ""im""),\n        metadata=dataset_info.MetadataDict(),\n    )\n\n  def _generate_examples(self, range_):\n    self.info.metadata[""some_key""] = 123\n\n    for i in range_:\n      height = np.random.randint(5, high=10)\n      width = np.random.randint(5, high=10)\n      yield i, {\n          ""im"":\n              np.random.randint(\n                  0, 255, size=(height, width, 3), dtype=np.uint8)\n      }\n\n\nclass DatasetInfoTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(DatasetInfoTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n    cls._tfds_tmp_dir = testing.make_tmp_dir()\n    cls._builder = DummyDatasetSharedGenerator(data_dir=cls._tfds_tmp_dir)\n\n  @classmethod\n  def tearDownClass(cls):\n    super(DatasetInfoTest, cls).tearDownClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = True\n    testing.rm_tmp_dir(cls._tfds_tmp_dir)\n\n  def test_undefined_dir(self):\n    with self.assertRaisesWithPredicateMatch(ValueError,\n                                             ""undefined dataset_info_dir""):\n      info = dataset_info.DatasetInfo(builder=self._builder)\n      info.read_from_directory(None)\n\n  def test_non_existent_dir(self):\n    # The error messages raised by Windows is different from Unix.\n    if os.name == ""nt"":\n      err = ""The system cannot find the path specified""\n    else:\n      err = ""No such file or dir""\n    info = dataset_info.DatasetInfo(builder=self._builder)\n    with self.assertRaisesWithPredicateMatch(\n        tf.errors.NotFoundError, err):\n      info.read_from_directory(_NON_EXISTENT_DIR)\n\n  def test_reading(self):\n    info = dataset_info.DatasetInfo(builder=self._builder)\n    info.read_from_directory(_INFO_DIR)\n\n    # Assert that we read the file and initialized DatasetInfo.\n    self.assertTrue(info.initialized)\n    self.assertEqual(""dummy_dataset_shared_generator"", info.name)\n    self.assertEqual(""dummy_dataset_shared_generator/1.0.0"", info.full_name)\n\n    # Test splits are initialized properly.\n    split_dict = info.splits\n\n    # Assert they are the correct number.\n    self.assertTrue(len(split_dict), 2)\n\n    # Assert on what they are\n    self.assertIn(""train"", split_dict)\n    self.assertIn(""test"", split_dict)\n\n    # Assert that this is computed correctly.\n    self.assertEqual(40, info.splits.total_num_examples)\n    self.assertEqual(11594722, info.dataset_size)\n\n    self.assertEqual(""image"", info.supervised_keys[0])\n    self.assertEqual(""label"", info.supervised_keys[1])\n\n  def test_reading_empty_properties(self):\n    info = dataset_info.DatasetInfo(builder=self._builder)\n    info.read_from_directory(_INFO_DIR_UNLABELED)\n\n    # Assert supervised_keys has not been set\n    self.assertEqual(None, info.supervised_keys)\n\n  def test_writing(self):\n    # First read in stuff.\n    mnist_builder = mnist.MNIST(\n        data_dir=tempfile.mkdtemp(dir=self.get_temp_dir()))\n\n    info = dataset_info.DatasetInfo(\n        builder=mnist_builder, features=mnist_builder.info.features)\n    info.read_from_directory(_INFO_DIR)\n\n    # Read the json file into a string.\n    with tf.io.gfile.GFile(info._dataset_info_path(_INFO_DIR)) as f:\n      existing_json = json.load(f)\n\n    # Now write to a temp directory.\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      info.write_to_directory(tmp_dir)\n\n      # Read the newly written json file into a string.\n      with tf.io.gfile.GFile(info._dataset_info_path(tmp_dir)) as f:\n        new_json = json.load(f)\n\n      # Read the newly written LICENSE file into a string.\n      with tf.io.gfile.GFile(info._license_path(tmp_dir)) as f:\n        license_ = f.read()\n\n    # Assert what was read and then written and read again is the same.\n    self.assertEqual(existing_json, new_json)\n\n    # Assert correct license was written.\n    self.assertEqual(existing_json[""redistributionInfo""][""license""], license_)\n\n    if six.PY3:\n      # Only test on Python 3 to avoid u\'\' formatting issues\n      self.assertEqual(repr(info), INFO_STR)\n\n  def test_restore_after_modification(self):\n    # Create a DatasetInfo\n    info = dataset_info.DatasetInfo(\n        builder=self._builder,\n        description=""A description"",\n        supervised_keys=(""input"", ""output""),\n        homepage=""http://some-location"",\n        citation=""some citation"",\n        redistribution_info={""license"": ""some license""}\n    )\n    info.download_size = 456\n    info.as_proto.splits.add(name=""train"", num_bytes=512)\n    info.as_proto.splits.add(name=""validation"", num_bytes=64)\n    info.as_proto.schema.feature.add()\n    info.as_proto.schema.feature.add()  # Add dynamic statistics\n    info.download_checksums = {\n        ""url1"": ""some checksum"",\n        ""url2"": ""some other checksum"",\n    }\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # Save it\n      info.write_to_directory(tmp_dir)\n\n      # If fields are not defined, then everything is restored from disk\n      restored_info = dataset_info.DatasetInfo(builder=self._builder)\n      restored_info.read_from_directory(tmp_dir)\n      self.assertEqual(info.as_proto, restored_info.as_proto)\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # Save it\n      info.write_to_directory(tmp_dir)\n\n      # If fields are defined, then the code version is kept\n      restored_info = dataset_info.DatasetInfo(\n          builder=self._builder,\n          supervised_keys=(""input (new)"", ""output (new)""),\n          homepage=""http://some-location-new"",\n          citation=""some citation (new)"",\n          redistribution_info={""license"": ""some license (new)""}\n      )\n      restored_info.download_size = 789\n      restored_info.as_proto.splits.add(name=""validation"", num_bytes=288)\n      restored_info.as_proto.schema.feature.add()\n      restored_info.as_proto.schema.feature.add()\n      restored_info.as_proto.schema.feature.add()\n      restored_info.as_proto.schema.feature.add()  # Add dynamic statistics\n      restored_info.download_checksums = {\n          ""url2"": ""some other checksum (new)"",\n          ""url3"": ""some checksum (new)"",\n      }\n\n      restored_info.read_from_directory(tmp_dir)\n\n      # Even though restored_info has been restored, informations defined in\n      # the code overwrite informations from the json file.\n      self.assertEqual(restored_info.description, ""A description"")\n      self.assertEqual(\n          restored_info.supervised_keys, (""input (new)"", ""output (new)""))\n      self.assertEqual(restored_info.homepage, ""http://some-location-new"")\n      self.assertEqual(restored_info.citation, ""some citation (new)"")\n      self.assertEqual(restored_info.redistribution_info.license,\n                       ""some license (new)"")\n      self.assertEqual(restored_info.download_size, 789)\n      self.assertEqual(restored_info.dataset_size, 576)\n      self.assertEqual(len(restored_info.as_proto.schema.feature), 4)\n      self.assertEqual(restored_info.download_checksums, {\n          ""url2"": ""some other checksum (new)"",\n          ""url3"": ""some checksum (new)"",\n      })\n\n  def test_reading_from_gcs_bucket(self):\n    # The base TestCase prevents GCS access, so we explicitly ask it to restore\n    # access here.\n    with self.gcs_access():\n      mnist_builder = mnist.MNIST(\n          data_dir=tempfile.mkdtemp(dir=self.get_temp_dir()))\n      info = dataset_info.DatasetInfo(builder=mnist_builder)\n      info = mnist_builder.info\n\n      # A nominal check to see if we read it.\n      self.assertTrue(info.initialized)\n      self.assertEqual(10000, info.splits[""test""].num_examples)\n\n  def test_str_smoke(self):\n    info = mnist.MNIST(data_dir=""/tmp/some_dummy_dir"").info\n    _ = str(info)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_statistics_generation(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = DummyDatasetSharedGenerator(data_dir=tmp_dir)\n      builder.download_and_prepare()\n\n      # Overall\n      self.assertEqual(30, builder.info.splits.total_num_examples)\n\n      # Per split.\n      test_split = builder.info.splits[""test""].get_proto()\n      train_split = builder.info.splits[""train""].get_proto()\n      expected_schema = text_format.Parse(""""""\n      feature {\n        name: ""x""\n        type: INT\n        presence {\n          min_fraction: 1.0\n          min_count: 1\n        }\n        shape {\n          dim {\n            size: 1\n          }\n        }\n      }"""""", schema_pb2.Schema())\n      self.assertEqual(train_split.statistics.num_examples, 20)\n      self.assertLen(train_split.statistics.features, 1)\n      self.assertEqual(\n          train_split.statistics.features[0].path.step[0], ""x"")\n      self.assertLen(\n          train_split.statistics.features[0].num_stats.common_stats.\n          num_values_histogram.buckets, 10)\n      self.assertLen(\n          train_split.statistics.features[0].num_stats.histograms, 2)\n\n      self.assertEqual(test_split.statistics.num_examples, 10)\n      self.assertLen(test_split.statistics.features, 1)\n      self.assertEqual(\n          test_split.statistics.features[0].path.step[0], ""x"")\n      self.assertLen(\n          test_split.statistics.features[0].num_stats.common_stats.\n          num_values_histogram.buckets, 10)\n      self.assertLen(\n          test_split.statistics.features[0].num_stats.histograms, 2)\n      self.assertEqual(builder.info.as_proto.schema, expected_schema)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_schema_generation_variable_sizes(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = RandomShapedImageGenerator(data_dir=tmp_dir)\n      builder.download_and_prepare()\n\n      expected_schema = text_format.Parse(\n          """"""\nfeature {\n  name: ""im""\n  type: BYTES\n  presence {\n    min_fraction: 1.0\n    min_count: 1\n  }\n  shape {\n    dim {\n      size: -1\n    }\n    dim {\n      size: -1\n    }\n    dim {\n      size: 3\n    }\n  }\n}"""""", schema_pb2.Schema())\n      self.assertEqual(builder.info.as_proto.schema, expected_schema)\n\n  def test_metadata(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = RandomShapedImageGenerator(data_dir=tmp_dir)\n      builder.download_and_prepare()\n      # Metadata should have been created\n      self.assertEqual(builder.info.metadata, {""some_key"": 123})\n\n      # Metadata should have been restored\n      builder2 = RandomShapedImageGenerator(data_dir=tmp_dir)\n      self.assertEqual(builder2.info.metadata, {""some_key"": 123})\n\n  def test_updates_on_bucket_info(self):\n\n    info = dataset_info.DatasetInfo(builder=self._builder,\n                                    description=""won\'t be updated"")\n    # No statistics in the above.\n    self.assertEqual(0, info.splits.total_num_examples)\n    self.assertEqual(0, len(info.as_proto.schema.feature))\n\n    # Partial update will happen here.\n    info.read_from_directory(_INFO_DIR)\n\n    # Assert that description (things specified in the code) didn\'t change\n    # but statistics are updated.\n    self.assertEqual(""won\'t be updated"", info.description)\n\n    # These are dynamically computed, so will be updated.\n    self.assertEqual(40, info.splits.total_num_examples)\n    self.assertEqual(2, len(info.as_proto.schema.feature))\n\n\nINFO_STR = """"""tfds.core.DatasetInfo(\n    name=\'mnist\',\n    version=3.0.1,\n    description=\'The MNIST database of handwritten digits.\',\n    homepage=\'https://storage.googleapis.com/cvdf-datasets/mnist/\',\n    features=FeaturesDict({\n        \'image\': Image(shape=(28, 28, 1), dtype=tf.uint8),\n        \'label\': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n    }),\n    total_num_examples=40,\n    splits={\n        \'test\': 20,\n        \'train\': 20,\n    },\n    supervised_keys=(\'image\', \'label\'),\n    citation=\\""\\""\\""@article{lecun2010mnist,\n      title={MNIST handwritten digit database},\n      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n      volume={2},\n      year={2010}\n    }\\""\\""\\"",\n    redistribution_info=license: ""test license"",\n)\n""""""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/dataset_registered_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.registered.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets as tfds\n\n\nclass ListBuilderTest(tfds.testing.TestCase):\n  """"""Ensure that the tests datasets are not registered.""""""\n\n  def test_list_builder(self):\n    test_datasets = {\n        tfds.testing.DummyMnist.name,\n        tfds.testing.DummyDatasetSharedGenerator.name,\n    }\n    registered_datasets = set(tfds.list_builders())\n    # The tests datasets should not be present in the registered datasets\n    self.assertEmpty(test_datasets & registered_datasets)\n\nif __name__ == ""__main__"":\n  tfds.testing.test_main()\n'"
tensorflow_datasets/core/dataset_utils.py,49,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for dealing with tf.data.Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport itertools\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import tf_compat\nfrom tensorflow_datasets.core import utils\n\n\ndef build_dataset(instruction_dicts,\n                  dataset_from_file_fn,\n                  shuffle_files=False,\n                  parallel_reads=64):\n  """"""Constructs a `tf.data.Dataset` from TFRecord files.\n\n  Args:\n    instruction_dicts: `list` of {\'filepath\':, \'mask\':, \'offset_mask\':}\n      containing the information about which files and which examples to use.\n      The boolean mask will be repeated and zipped with the examples from\n      filepath.\n    dataset_from_file_fn: function returning a `tf.data.Dataset` given a\n      filename.\n    shuffle_files: `bool`, Whether to shuffle the input filenames.\n    parallel_reads: `int`, how many files to read in parallel.\n\n  Returns:\n    `tf.data.Dataset`\n  """"""\n\n  # First case: All examples are taken (No value skipped)\n  if _no_examples_skipped(instruction_dicts):\n    # Only use the filenames as instruction\n    instruction_ds = tf.data.Dataset.from_tensor_slices([\n        d[""filepath""] for d in instruction_dicts\n    ])\n    build_ds_from_instruction = dataset_from_file_fn\n  # Second case: Use the instructions to read the examples\n  else:\n    instruction_ds = _build_instruction_ds(instruction_dicts)\n    build_ds_from_instruction = functools.partial(\n        _build_ds_from_instruction,\n        ds_from_file_fn=dataset_from_file_fn,\n    )\n\n  # If shuffle is True, we shuffle the instructions/shards\n  if shuffle_files:\n    instruction_ds = instruction_ds.shuffle(len(instruction_dicts))\n\n  # Use interleave to parallel read files and decode records\n  ds = instruction_ds.interleave(\n      build_ds_from_instruction,\n      cycle_length=parallel_reads,\n      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  return ds\n\n\ndef _no_examples_skipped(list_of_dict):\n  """"""Return True if no examples are skipped (mask are only True).""""""\n  return all(itertools.chain.from_iterable([d[""mask""] for d in list_of_dict]))\n\n\ndef _build_instruction_ds(instructions):\n  """"""Create a dataset containing individual instruction for each shard.\n\n  Each instruction is a dict:\n  ```\n  {\n      ""filepath"": tf.Tensor(shape=(), dtype=tf.string),\n      ""mask_offset"": tf.Tensor(shape=(), dtype=tf.int64),\n      ""mask"": tf.Tensor(shape=(100,), dtype=tf.bool),\n  }\n  ```\n\n  Args:\n    instructions: `list[dict]`, the list of instruction dict\n\n  Returns:\n    instruction_ds: The dataset containing the instruction. The dataset size is\n      the number of shard.\n  """"""\n  # Transpose the list[dict] into dict[list]\n  tensor_inputs = {\n      # offset_mask need to be converted to int64 explicitly\n      k: np.array(vals, dtype=np.int64) if k == ""mask_offset"" else list(vals)\n      for k, vals in utils.zip_dict(*instructions)\n  }\n  return tf.data.Dataset.from_tensor_slices(tensor_inputs)\n\n\ndef _build_mask_ds(mask, mask_offset):\n  """"""Build the mask dataset to indicate which element to skip.\n\n  Args:\n    mask: `tf.Tensor`, binary mask to apply to all following elements. This\n      mask should have a length 100.\n    mask_offset: `tf.Tensor`, Integer specifying from how much the mask\n      should be shifted for the first element.\n\n  Returns:\n    mask_ds: `tf.data.Dataset`, a dataset returning False for examples to skip\n      and True for examples to keep.\n  """"""\n  mask_ds = tf.data.Dataset.from_tensor_slices(mask)\n  mask_ds = mask_ds.repeat()\n  mask_ds = mask_ds.skip(mask_offset)\n  return mask_ds\n\n\ndef _build_ds_from_instruction(instruction, ds_from_file_fn):\n  """"""Map an instruction to a real datasets for one particular shard.\n\n  Args:\n    instruction: A `dict` of `tf.Tensor` containing the instruction to load\n      the particular shard (filename, mask,...)\n    ds_from_file_fn: `fct`, function which returns the dataset associated to\n      the filename\n\n  Returns:\n    dataset: `tf.data.Dataset`, The shard loaded from the instruction\n  """"""\n  # Create the example and mask ds for this particular shard\n  examples_ds = ds_from_file_fn(instruction[""filepath""])\n  mask_ds = _build_mask_ds(\n      mask_offset=instruction[""mask_offset""],\n      mask=instruction[""mask""],\n  )\n\n  # Zip the mask and real examples\n  ds = tf.data.Dataset.zip((examples_ds, mask_ds))\n  # Filter according to the mask (only keep True)\n  ds = ds.filter(lambda example, mask: mask)\n  # Only keep the examples\n  ds = ds.map(lambda example, mask: example)\n  return ds\n\n\ndef _eager_dataset_iterator(dataset):\n  for item in dataset:\n    flat = tf.nest.flatten(item)\n    flat = [t if isinstance(t, tf.RaggedTensor) else t.numpy() for t in flat]\n    yield tf.nest.pack_sequence_as(item, flat)\n\n\ndef _graph_dataset_iterator(ds_iter, graph=None):\n  """"""Constructs a Python generator from a tf.data.Iterator.""""""\n  with utils.maybe_with_graph(graph, create_if_none=False):\n    init = ds_iter.initializer\n    ds_item = ds_iter.get_next()\n  with utils.nogpu_session(graph) as sess:\n    sess.run(init)\n    while True:\n      try:\n        yield sess.run(ds_item)\n      except tf.errors.OutOfRangeError:\n        break\n\n\n@api_utils.disallow_positional_args(allowed=[""dataset""])\ndef as_numpy(dataset, graph=None):\n  """"""Converts a `tf.data.Dataset` to an iterable of NumPy arrays.\n\n  `as_numpy` converts a possibly nested structure of `tf.data.Dataset`s\n  and `tf.Tensor`s to iterables of NumPy arrays and NumPy arrays, respectively.\n\n  Note that because TensorFlow has support for ragged tensors and NumPy has\n  no equivalent representation,\n  [`tf.RaggedTensor`s](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor)\n  are left as-is for the user to deal with them (e.g. using `to_list()`).\n  In TF 1 (i.e. graph mode), `tf.RaggedTensor`s are returned as\n  `tf.ragged.RaggedTensorValue`s.\n\n  Example:\n\n  ```\n  ds = tfds.load(name=""mnist"", split=""train"")\n  ds_numpy = tfds.as_numpy(ds)  # Convert `tf.data.Dataset` to Python generator\n  for ex in ds_numpy:\n    # `{\'image\': np.array(shape=(28, 28, 1)), \'labels\': np.array(shape=())}`\n    print(ex)\n  ```\n\n  Args:\n    dataset: a possibly nested structure of `tf.data.Dataset`s and/or\n      `tf.Tensor`s.\n    graph: `tf.Graph`, optional, explicitly set the graph to use.\n\n  Returns:\n    A structure matching `dataset` where `tf.data.Dataset`s are converted to\n    generators of NumPy arrays and `tf.Tensor`s are converted to NumPy arrays.\n  """"""\n  nested_ds = dataset\n  del dataset\n\n  # Flatten\n  flat_ds = tf.nest.flatten(nested_ds)\n  flat_np = []\n\n  # Type check for Tensors and Datasets\n  for ds_el in flat_ds:\n    types = [type(el) for el in flat_ds]\n    types = tf.nest.pack_sequence_as(nested_ds, types)\n    if not (\n        isinstance(ds_el, (tf.Tensor, tf.RaggedTensor)) or\n        tf_compat.is_dataset(ds_el)):\n      raise ValueError(""Arguments to as_numpy must be tf.Tensors or ""\n                       ""tf.data.Datasets. Got: %s"" % types)\n\n  if tf.executing_eagerly():\n    # Eager mode\n    for ds_el in flat_ds:\n      if isinstance(ds_el, tf.Tensor):\n        np_el = ds_el.numpy()\n      elif isinstance(ds_el, tf.RaggedTensor):\n        np_el = ds_el\n      elif tf_compat.is_dataset(ds_el):\n        np_el = _eager_dataset_iterator(ds_el)\n      else:\n        assert False\n      flat_np.append(np_el)\n  else:\n    # Graph mode\n\n    # First create iterators for datasets\n    with utils.maybe_with_graph(graph, create_if_none=False):\n      ds_iters = [\n          tf.compat.v1.data.make_initializable_iterator(ds_el)\n          for ds_el in flat_ds if tf_compat.is_dataset(ds_el)\n      ]\n    ds_iters = [_graph_dataset_iterator(ds_iter, graph) for ds_iter in ds_iters]\n\n    # Then create numpy arrays for tensors\n    with utils.nogpu_session(graph) as sess:  # Shared session for tf.Tensor\n      # Calling sess.run once so that randomness is shared.\n      np_arrays = sess.run([tensor for tensor in flat_ds\n                            if not tf_compat.is_dataset(tensor)])\n\n    # Merge the dataset iterators and np arrays\n    iter_ds = iter(ds_iters)\n    iter_array = iter(np_arrays)\n    flat_np = [\n        next(iter_ds) if tf_compat.is_dataset(ds_el) else next(iter_array)\n        for ds_el in flat_ds\n    ]\n\n  # Nest\n  return tf.nest.pack_sequence_as(nested_ds, flat_np)\n\n\ndef dataset_shape_is_fully_defined(ds):\n  output_shapes = tf.compat.v1.data.get_output_shapes(ds)\n  return all([ts.is_fully_defined() for ts in tf.nest.flatten(output_shapes)])\n\n\ndef features_shape_is_fully_defined(features):\n  return all([tf.TensorShape(info.shape).is_fully_defined() for info in\n              tf.nest.flatten(features.get_tensor_info())])\n'"
tensorflow_datasets/core/dataset_utils_test.py,17,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.dataset_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_utils\n\ntf.enable_v2_behavior()\n\n\ndef _create_dataset(rng):\n  return tf.data.Dataset.from_tensor_slices(list(rng))\n\n\nclass DatasetAsNumPyTest(testing.TestCase):\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_singleton_tensor(self):\n    t = tf.random.normal((10, 10))\n    np_t = dataset_utils.as_numpy(t)\n    self.assertEqual((10, 10), np_t.shape)\n    self.assertEqual(np.float32, np_t.dtype)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_nested_tensors(self):\n    t1 = tf.random.normal((10, 10))\n    t2 = tf.random.normal((10, 20))\n    nest_tup = (t1, t2)\n    np_t1, np_t2 = dataset_utils.as_numpy(nest_tup)\n    self.assertEqual((10, 10), np_t1.shape)\n    self.assertEqual(np.float32, np_t1.dtype)\n    self.assertEqual((10, 20), np_t2.shape)\n    self.assertEqual(np.float32, np_t2.dtype)\n\n    nest_dict = {""foo"": t1, ""bar"": {""zoo"": t2}}\n    np_nest_dict = dataset_utils.as_numpy(nest_dict)\n    np_t1 = np_nest_dict[""foo""]\n    np_t2 = np_nest_dict[""bar""][""zoo""]\n    self.assertEqual((10, 10), np_t1.shape)\n    self.assertEqual(np.float32, np_t1.dtype)\n    self.assertEqual((10, 20), np_t2.shape)\n    self.assertEqual(np.float32, np_t2.dtype)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_singleton_dataset(self):\n    ds = _create_dataset(range(10))\n    np_ds = dataset_utils.as_numpy(ds)\n    self.assertEqual(list(range(10)), [int(el) for el in list(np_ds)])\n\n  def test_with_graph(self):\n    with tf.Graph().as_default():\n      with tf.Graph().as_default() as g:\n        ds = _create_dataset(range(10))\n      np_ds = dataset_utils.as_numpy(ds, graph=g)\n      self.assertEqual(list(range(10)), [int(el) for el in list(np_ds)])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_singleton_dataset_with_nested_elements(self):\n    ds = _create_dataset(range(10))\n    ds = ds.map(lambda el: {""a"": el, ""b"": el + 1, ""c"": (el + 2, el + 3)})\n    np_ds = dataset_utils.as_numpy(ds)\n    for i, el in enumerate(np_ds):\n      self.assertEqual(i, el[""a""])\n      self.assertEqual(i + 1, el[""b""])\n      self.assertEqual(i + 2, el[""c""][0])\n      self.assertEqual(i + 3, el[""c""][1])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_nested_dataset_sequential_access(self):\n    ds1 = _create_dataset(range(10))\n    ds2 = _create_dataset(range(10, 20))\n    np_ds = dataset_utils.as_numpy((ds1, {""a"": ds2}))\n    np_ds1 = np_ds[0]\n    np_ds2 = np_ds[1][""a""]\n\n    self.assertEqual(list(range(10)), [int(el) for el in list(np_ds1)])\n    self.assertEqual(list(range(10, 20)), [int(el) for el in list(np_ds2)])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_nested_dataset_simultaneous_access(self):\n    ds1 = _create_dataset(range(10))\n    ds2 = _create_dataset(range(10, 20))\n    np_ds = dataset_utils.as_numpy((ds1, {""a"": ds2}))\n    np_ds1 = np_ds[0]\n    np_ds2 = np_ds[1][""a""]\n\n    for i1, i2 in zip(np_ds1, np_ds2):\n      self.assertEqual(i2, int(i1) + 10)\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_nested_dataset_nested_elements(self):\n    ds1 = _create_dataset(range(10))\n    ds1 = ds1.map(lambda el: {""a"": el, ""b"": el + 1, ""c"": (el + 2, el + 3)})\n    ds2 = _create_dataset(range(10, 20))\n    np_ds = dataset_utils.as_numpy((ds1, {""a"": ds2}))\n    np_ds1 = np_ds[0]\n    np_ds2 = np_ds[1][""a""]\n\n    for i, (el1, el2) in enumerate(zip(np_ds1, np_ds2)):\n      self.assertEqual(i + 10, el2)\n      self.assertEqual(i, el1[""a""])\n      self.assertEqual(i + 1, el1[""b""])\n      self.assertEqual(i + 2, el1[""c""][0])\n      self.assertEqual(i + 3, el1[""c""][1])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_tensors_match(self):\n    t = tf.random.uniform(\n        shape=(50, 3),\n        maxval=1000,\n        dtype=tf.int32,\n    )\n\n    ds = dataset_utils.as_numpy({""a"": t, ""b"": t})\n    # sess.run() should be called a single time for all input. Otherwise input\n    # and target may not match\n    self.assertAllEqual(ds[""a""], ds[""b""])\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_ragged_tensors(self):\n    rt = tf.ragged.constant([\n        [1, 2, 3],\n        [],\n        [4, 5],\n    ])\n    rt = dataset_utils.as_numpy(rt)\n\n    if not tf.executing_eagerly():\n      # Output of `sess.run(rt)` is a `RaggedTensorValue` object\n      self.assertIsInstance(rt, tf.compat.v1.ragged.RaggedTensorValue)\n    else:\n      self.assertIsInstance(rt, tf.RaggedTensor)\n\n    self.assertAllEqual(rt, tf.ragged.constant([\n        [1, 2, 3],\n        [],\n        [4, 5],\n    ]))\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_ragged_tensors_ds(self):\n    def _gen_ragged_tensors():\n      # Yield the (flat_values, rowids)\n      yield ([0, 1, 2, 3], [0, 0, 0, 2])  # ex0\n      yield ([], [])  # ex1\n      yield ([4, 5, 6], [0, 1, 1])  # ex2\n    ds = tf.data.Dataset.from_generator(\n        _gen_ragged_tensors,\n        output_types=(tf.int64, tf.int64),\n        output_shapes=((None,), (None,))\n    )\n    ds = ds.map(tf.RaggedTensor.from_value_rowids)\n\n    rt0, rt1, rt2 = list(dataset_utils.as_numpy(ds))\n    self.assertAllEqual(rt0, [\n        [0, 1, 2],\n        [],\n        [3,],\n    ])\n    self.assertAllEqual(rt1, [])\n    self.assertAllEqual(rt2, [[4], [5, 6]])\n\n\nclass DatasetOffsetTest(testing.TestCase):\n  """"""Test that the offset functions are working properly.""""""\n\n  def test_build_mask_ds(self):\n\n    mask = [True] * 15 + [False] * 85\n\n    # No offset\n    ds = dataset_utils._build_mask_ds(mask=mask, mask_offset=0)\n    mask_values = list(dataset_utils.as_numpy(ds.take(300)))\n    self.assertEqual(mask_values, mask * 3)\n\n    # Skip the first 30 elements (remainders from previous shard)\n    ds = dataset_utils._build_mask_ds(mask=mask, mask_offset=30)\n    mask_values = list(dataset_utils.as_numpy(ds.take(370)))\n    self.assertEqual(mask_values, mask[30:] + mask * 3)\n\n  def test_no_examples_skipped(self):\n\n    self.assertTrue(dataset_utils._no_examples_skipped([\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 5,\n            ""mask"": [True] * 100,\n        },\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 60,\n            ""mask"": [True] * 100,\n        },\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 0,\n            ""mask"": [True] * 100,\n        },\n    ]))\n    self.assertFalse(dataset_utils._no_examples_skipped([\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 5,\n            ""mask"": [True] * 100,\n        },\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 60,\n            ""mask"": [True] * 99 + [False],  # Single example skipped here\n        },\n        {\n            ""filepath"": ""some_path"",\n            ""mask_offset"": 0,\n            ""mask"": [True] * 100,\n        },\n    ]))\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/example_parser.py,25,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""To deserialize bytes (Example) to tf.Example.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import utils\n\n\nclass ExampleParser(object):\n  """"""To parse Examples.""""""\n\n  def __init__(self, example_specs):\n    self._example_specs = example_specs\n    self._flat_example_specs = utils.flatten_nest_dict(self._example_specs)\n\n  def _build_feature_specs(self):\n    """"""Returns the `tf.train.Example` feature specification.\n\n    Returns:\n      The `dict` of `tf.io.FixedLenFeature`, `tf.io.VarLenFeature`, ...\n    """"""\n    # Convert individual fields into tf.train.Example compatible format\n    def build_single_spec(k, v):\n      with utils.try_reraise(\n          ""Specification error for feature {} ({}): "".format(k, v)):\n        return _to_tf_example_spec(v)\n\n    return {\n        k: build_single_spec(k, v) for k, v in self._flat_example_specs.items()\n    }\n\n  def parse_example(self, serialized_example):\n    """"""Deserialize a single `tf.train.Example` proto.\n\n    Usage:\n    ```\n    ds = tf.data.TFRecordDataset(filepath)\n    ds = ds.map(file_adapter.parse_example)\n    ```\n\n    Args:\n      serialized_example: `tf.Tensor`, the `tf.string` tensor containing the\n        serialized proto to decode.\n\n    Returns:\n      example: A nested `dict` of `tf.Tensor` values. The structure and tensors\n        shape/dtype match the  `example_specs` provided at construction.\n    """"""\n    nested_feature_specs = self._build_feature_specs()\n\n    # Because of RaggedTensor specs, feature_specs can be a 2-level nested dict,\n    # so have to wrap `tf.io.parse_single_example` between\n    # `flatten_nest_dict`/`pack_as_nest_dict`.\n    # {\n    #     \'video/image\': tf.io.FixedLenSequenceFeature(...),\n    #     \'video/object/bbox\': {\n    #         \'ragged_flat_values\': tf.io.FixedLenSequenceFeature(...),\n    #         \'ragged_row_lengths_0\', tf.io.FixedLenSequenceFeature(...),\n    #     },\n    # }\n    flat_feature_specs = utils.flatten_nest_dict(nested_feature_specs)\n    example = tf.io.parse_single_example(\n        serialized=serialized_example,\n        features=flat_feature_specs,\n    )\n    example = utils.pack_as_nest_dict(example, nested_feature_specs)\n\n    example = {\n        k: _deserialize_single_field(example_data, tensor_info)\n        for k, (example_data, tensor_info)\n        in utils.zip_dict(example, self._flat_example_specs)\n    }\n    # Reconstruct all nesting\n    example = utils.pack_as_nest_dict(example, self._example_specs)\n    return example\n\n\ndef _deserialize_single_field(example_data, tensor_info):\n  """"""Reconstruct the serialized field.""""""\n  # Ragged tensor case:\n  if tensor_info.sequence_rank > 1:\n    example_data = _dict_to_ragged(example_data, tensor_info)\n\n  # Restore shape if possible. TF Example flattened it.\n  elif tensor_info.shape.count(None) < 2:\n    shape = [-1 if i is None else i for i in tensor_info.shape]\n    example_data = tf.reshape(example_data, shape)\n\n  # Restore dtype\n  if example_data.dtype != tensor_info.dtype:\n    example_data = tf.dtypes.cast(example_data, tensor_info.dtype)\n  return example_data\n\n\ndef _dict_to_ragged(example_data, tensor_info):\n  """"""Reconstruct the ragged tensor from the row ids.""""""\n  return tf.RaggedTensor.from_nested_row_lengths(\n      flat_values=example_data[""ragged_flat_values""],\n      nested_row_lengths=[\n          example_data[""ragged_row_lengths_{}"".format(k)]\n          for k in range(tensor_info.sequence_rank - 1)\n      ],\n  )\n\n\ndef _to_tf_example_spec(tensor_info):\n  """"""Convert a `TensorInfo` into a feature proto object.""""""\n  # Convert the dtype\n\n  # TODO(b/119937875): TF Examples proto only support int64, float32 and string\n  # This create limitation like float64 downsampled to float32, bool converted\n  # to int64 which is space ineficient, no support for complexes or quantized\n  # It seems quite space inefficient to convert bool to int64\n  if tensor_info.dtype.is_integer or tensor_info.dtype.is_bool:\n    dtype = tf.int64\n  elif tensor_info.dtype.is_floating:\n    dtype = tf.float32\n  elif tensor_info.dtype == tf.string:\n    dtype = tf.string\n  else:\n    # TFRecord only support 3 types\n    raise NotImplementedError(\n        ""Serialization not implemented for dtype {}"".format(tensor_info))\n\n  # Convert the shape\n\n  # Select the feature proto type in function of the unknown shape\n  if all(s is not None for s in tensor_info.shape):\n    return tf.io.FixedLenFeature(  # All shaped defined\n        shape=tensor_info.shape,\n        dtype=dtype,\n        default_value=tensor_info.default_value,\n    )\n  elif (tensor_info.shape.count(None) == 1 and tensor_info.shape[0] is None):\n    return tf.io.FixedLenSequenceFeature(  # First shape undefined\n        shape=tensor_info.shape[1:],\n        dtype=dtype,\n        allow_missing=True,\n        default_value=tensor_info.default_value,\n    )\n  elif tensor_info.sequence_rank > 1:  # RaggedTensor\n    # Decoding here should match encoding from `_add_ragged_fields` in\n    # `example_serializer.py`\n    tf_specs = {  # pylint: disable=g-complex-comprehension\n        ""ragged_row_lengths_{}"".format(k): tf.io.FixedLenSequenceFeature(  # pylint: disable=g-complex-comprehension\n            shape=(),\n            dtype=tf.int64,\n            allow_missing=True,\n        )\n        for k in range(tensor_info.sequence_rank - 1)\n    }\n    tf_specs[""ragged_flat_values""] = tf.io.FixedLenSequenceFeature(\n        shape=tensor_info.shape[tensor_info.sequence_rank:],\n        dtype=dtype,\n        allow_missing=True,\n        default_value=tensor_info.default_value,\n    )\n    return tf_specs\n  else:\n    raise NotImplementedError(\n        ""Tensor with a unknown dimension not at the first position not ""\n        ""supported: {}"".format(tensor_info))\n'"
tensorflow_datasets/core/example_serializer.py,17,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""To serialize Dict or sequence to Example.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.features import feature as feature_lib\n\n\nclass ExampleSerializer(object):\n  """"""To serialize examples.""""""\n\n  def __init__(self, example_specs):\n    """"""Constructor.\n\n    Args:\n      example_specs: Nested `dict` of `tfds.features.TensorInfo`, corresponding\n        to the structure of data to write/read.\n    """"""\n    self._example_specs = example_specs\n    self._flat_example_specs = utils.flatten_nest_dict(self._example_specs)\n\n  def serialize_example(self, example):\n    """"""Serialize the given example.\n\n    Args:\n      example: Nested `dict` containing the input to serialize. The input\n        structure and values dtype/shape must match the `example_specs`\n        provided at construction.\n\n    Returns:\n      serialize_proto: `str`, the serialized `tf.train.Example` proto\n    """"""\n    example = utils.flatten_nest_dict(example)\n    example = _dict_to_tf_example(example, self._flat_example_specs)\n    return example.SerializeToString()\n\n\ndef _dict_to_tf_example(example_dict, tensor_info_dict):\n  """"""Builds tf.train.Example from (string -> int/float/str list) dictionary.\n\n  Args:\n    example_dict: `dict`, dict of values, tensor,...\n    tensor_info_dict: `dict` of `tfds.feature.TensorInfo`\n\n  Returns:\n    example_proto: `tf.train.Example`, the encoded example proto.\n  """"""\n  def run_with_reraise(fn, k, example_data, tensor_info):\n    with utils.try_reraise(\n        ""Error while serializing feature `{}`: `{}`: "".format(k, tensor_info)):\n      return fn(example_data, tensor_info)\n\n  if tensor_info_dict:\n    # Add the RaggedTensor fields for the nested sequences\n    # Nested sequences are encoded as {\'flat_values\':, \'row_lengths\':}, so need\n    # to flatten the example nested dict again.\n    # Ex:\n    # Input: {\'objects/tokens\': [[0, 1, 2], [], [3, 4]]}\n    # Output: {\n    #     \'objects/tokens/flat_values\': [0, 1, 2, 3, 4],\n    #     \'objects/tokens/row_lengths_0\': [3, 0, 2],\n    # }\n    example_dict = utils.flatten_nest_dict({\n        k: run_with_reraise(_add_ragged_fields, k, example_data, tensor_info)\n        for k, (example_data, tensor_info)\n        in utils.zip_dict(example_dict, tensor_info_dict)\n    })\n    example_dict = {\n        k: run_with_reraise(_item_to_tf_feature, k, item, tensor_info)\n        for k, (item, tensor_info) in example_dict.items()\n    }\n  else:\n    # TODO(epot): The following code is only executed in tests and could be\n    # cleanned-up, as TensorInfo is always passed to _item_to_tf_feature.\n    example_dict = {\n        k: run_with_reraise(_item_to_tf_feature, k, example_data, None)\n        for k, example_data in example_dict.items()\n    }\n\n  return tf.train.Example(features=tf.train.Features(feature=example_dict))\n\n\ndef _is_string(item):\n  """"""Check if the object contains string or bytes.""""""\n  if isinstance(item, (six.binary_type, six.string_types)):\n    return True\n  elif (isinstance(item, (tuple, list)) and all(_is_string(x) for x in item)):\n    return True\n  elif (isinstance(item, np.ndarray) and  # binary or unicode\n        (item.dtype.kind in (""U"", ""S"") or item.dtype == object)):\n    return True\n  return False\n\n\ndef _item_to_np_array(item, dtype, shape):\n  """"""Single item to a np.array.""""""\n  original_item = item\n  item = np.array(item, dtype=dtype.as_numpy_dtype)\n  utils.assert_shape_match(item.shape, shape)\n  if dtype == tf.string and not _is_string(original_item):\n    raise ValueError(\n        ""Unsuported value: {}\\nCould not convert to bytes list."".format(item))\n  return item\n\n\ndef _item_to_tf_feature(item, tensor_info):\n  """"""Single item to a tf.train.Feature.""""""\n  v = _item_to_np_array(item, shape=tensor_info.shape, dtype=tensor_info.dtype)\n\n  # Check that the shape is expected\n  utils.assert_shape_match(v.shape, tensor_info.shape)\n  if tensor_info.dtype == tf.string and not _is_string(v):\n    raise ValueError(\n        ""Unsuported value: {}\\nCould not convert to bytes list."".format(item))\n\n  # Convert boolean to integer (tf.train.Example does not support bool)\n  if v.dtype == np.bool_:\n    v = v.astype(int)\n\n  v = v.flatten()  # Convert v into a 1-d array\n  if np.issubdtype(v.dtype, np.integer):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=v))\n  elif np.issubdtype(v.dtype, np.floating):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=v))\n  elif tensor_info.dtype == tf.string:\n    v = [tf.compat.as_bytes(x) for x in v]\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=v))\n  else:\n    raise ValueError(\n        ""Unsuported value: {}.\\n""\n        ""tf.train.Feature does not support type {}. ""\n        ""This may indicate that one of the FeatureConnectors received an ""\n        ""unsupported value as input."".format(repr(v), repr(type(v)))\n    )\n\n\nRaggedExtraction = collections.namedtuple(""RaggedExtraction"", [\n    ""nested_list"",\n    ""flat_values"",\n    ""nested_row_lengths"",\n    ""curr_ragged_rank"",\n    ""tensor_info"",\n])\n\n\ndef _add_ragged_fields(example_data, tensor_info):\n  """"""Optionally convert the ragged data into flat/row_lengths fields.\n\n  Example:\n\n  ```\n  example_data = [\n      [1, 2, 3],\n      [],\n      [4, 5]\n  ]\n  tensor_info = TensorInfo(shape=(None, None,), sequence_rank=2, ...)\n  out = _add_ragged_fields(example_data, tensor_info)\n  out == {\n      \'ragged_flat_values\': ([0, 1, 2, 3, 4, 5], TensorInfo(shape=(), ...)),\n      \'ragged_row_length_0\': ([3, 0, 2], TensorInfo(shape=(None,), ...))\n  }\n  ```\n\n  If `example_data` isn\'t ragged, `example_data` and `tensor_info` are\n  forwarded as-is.\n\n  Args:\n    example_data: Data to optionally convert to ragged data.\n    tensor_info: TensorInfo associated with the given data.\n\n  Returns:\n    A tuple(example_data, tensor_info) if the tensor isn\'t ragged, or a dict of\n      tuple(example_data, tensor_info) if the tensor is ragged.\n  """"""\n  # Step 1: Extract the ragged tensor info\n  if tensor_info.sequence_rank:\n    # If the input is ragged, extract the nested values.\n    # 1-level sequences are converted as numpy and stacked.\n    # If the sequence is empty, a np.empty(shape=(0, ...)) array is returned.\n    example_data, nested_row_lengths = _extract_ragged_attributes(\n        example_data, tensor_info)\n\n  # Step 2: Format the ragged tensor data as dict\n  # No sequence or 1-level sequence, forward the data.\n  # Could eventually handle multi-level sequences with static lengths\n  # in a smarter way.\n  if tensor_info.sequence_rank < 2:\n    return (example_data, tensor_info)\n  # Multiple level sequence:\n  else:\n    tensor_info_length = feature_lib.TensorInfo(shape=(None,), dtype=tf.int64)\n    ragged_attr_dict = {\n        ""ragged_row_lengths_{}"".format(i): (length, tensor_info_length)\n        for i, length in enumerate(nested_row_lengths)\n    }\n    tensor_info_flat = feature_lib.TensorInfo(\n        shape=(None,) + tensor_info.shape[tensor_info.sequence_rank:],\n        dtype=tensor_info.dtype,\n    )\n    ragged_attr_dict[""ragged_flat_values""] = (example_data, tensor_info_flat)\n    return ragged_attr_dict\n\n\ndef _extract_ragged_attributes(nested_list, tensor_info):\n  """"""Extract the values for the tf.RaggedTensor __init__.\n\n  This extract the ragged tensor attributes which allow reconstruct the\n  ragged tensor with `tf.RaggedTensor.from_nested_row_lengths`.\n\n  Args:\n    nested_list: A nested list containing the ragged tensor values\n    tensor_info: The specs of the ragged tensor\n\n  Returns:\n    flat_values: The flatten values of the ragged tensor. All values from each\n      list will be converted to np.array and stacked together.\n    nested_row_lengths: The row lengths for each ragged dimensions.\n  """"""\n  assert tensor_info.sequence_rank, ""{} is not ragged."".format(tensor_info)\n\n  flat_values = []\n  nested_row_lengths = [[] for _ in range(tensor_info.sequence_rank)]\n  # Reccursivelly append to `flat_values`, `nested_row_lengths`\n  _fill_ragged_attribute(RaggedExtraction(\n      nested_list=nested_list,\n      flat_values=flat_values,\n      nested_row_lengths=nested_row_lengths,\n      curr_ragged_rank=0,\n      tensor_info=tensor_info,\n  ))\n  if not flat_values:  # The full sequence is empty\n    flat_values = np.empty(\n        shape=(0,) + tensor_info.shape[tensor_info.sequence_rank:],\n        dtype=tensor_info.dtype.as_numpy_dtype,\n    )\n  else:  # Otherwise, merge all flat values together, some might be empty\n    flat_values = np.stack(flat_values)\n  return flat_values, nested_row_lengths[1:]\n\n\ndef _fill_ragged_attribute(ext):\n  """"""Recurse the nested_list from the given RaggedExtraction.\n\n  Args:\n    ext: RaggedExtraction tuple containing the input/outputs\n\n  Returns:\n    None, the function mutate instead `ext.nested_row_lengths` and\n      `ext.flat_values` lists.\n  """"""\n  # Register the current sequence length.\n  # Could be 0 in case of empty list or an np.empty(shape=(0, ...)).\n  curr_sequence_length = len(ext.nested_list)\n  ext.nested_row_lengths[ext.curr_ragged_rank].append(curr_sequence_length)\n  # Sanity check if sequence is static, but should have been catched before\n  # by `Sequence.encode_example`\n  expected_sequence_length = ext.tensor_info.shape[ext.curr_ragged_rank]\n  if (expected_sequence_length is not None and\n      expected_sequence_length != curr_sequence_length):\n    raise ValueError(\n        ""Received length {} do not match the expected one {} from {}."".format(\n            curr_sequence_length, expected_sequence_length, ext.tensor_info))\n\n  if ext.curr_ragged_rank < ext.tensor_info.sequence_rank - 1:\n    # If there are additional Sequence dimension, recurse 1 level deeper.\n    for sub_list in ext.nested_list:\n      _fill_ragged_attribute(ext._replace(\n          nested_list=sub_list,\n          curr_ragged_rank=ext.curr_ragged_rank + 1,\n      ))\n  else:\n    # Otherwise, we reached the max level deep, so add the current items\n    for item in ext.nested_list:\n      item = _item_to_np_array(  # Normalize the item\n          item,\n          dtype=ext.tensor_info.dtype,\n          # We only check the non-ragged shape\n          shape=ext.tensor_info.shape[ext.tensor_info.sequence_rank:],\n      )\n      ext.flat_values.append(item)\n'"
tensorflow_datasets/core/example_serializer_test.py,19,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.example_serializer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import example_serializer\nfrom tensorflow_datasets.core.features import feature as feature_lib\nfrom tensorflow_datasets.core.utils import py_utils\n\n\nclass ExampleSerializerTest(testing.SubTestCase):\n\n  def assertRaggedFieldEqual(self, dict1, dict2):\n    self.assertIsInstance(dict1, dict)\n    self.assertIsInstance(dict2, dict)\n    self.assertEqual(set(dict1.keys()), set(dict2.keys()))\n    for k, (field1, field2) in py_utils.zip_dict(dict1, dict2):\n      with self._subTest(k):\n        # Compare the example_data\n        self.assertAllEqual(field1[0], field2[0])\n        # Compare the tensor_info\n        self.assertEqual(field1[1], field2[1])\n\n  def test_ragged_dict_to_tf_example(self):\n    example_data = {\n        \'input\': [[1, 2, 3], [], [4, 5]],\n    }\n    tensor_info = {\n        \'input\': feature_lib.TensorInfo(\n            shape=(None, None,),\n            dtype=tf.int64,\n            sequence_rank=2,\n        ),\n    }\n    ex_proto = example_serializer._dict_to_tf_example(example_data, tensor_info)\n    feature = ex_proto.features.feature\n    self.assertEqual(\n        [1, 2, 3, 4, 5],\n        list(feature[\'input/ragged_flat_values\'].int64_list.value),\n    )\n    self.assertEqual(\n        [3, 0, 2],\n        list(feature[\'input/ragged_row_lengths_0\'].int64_list.value),\n    )\n\n  def test_ragged_dict_to_tf_example_empty(self):\n    example_data = {\n        \'input\': [],\n    }\n    tensor_info = {\n        \'input\': feature_lib.TensorInfo(\n            shape=(None, None,),\n            dtype=tf.int64,\n            sequence_rank=2,\n        ),\n    }\n    ex_proto = example_serializer._dict_to_tf_example(example_data, tensor_info)\n    feature = ex_proto.features.feature\n    self.assertEqual(\n        [], list(feature[\'input/ragged_flat_values\'].int64_list.value),\n    )\n    self.assertEqual(\n        [], list(feature[\'input/ragged_row_lengths_0\'].int64_list.value),\n    )\n\n  def test_add_ragged_fields(self):\n    # Nested `Sequence(Sequence(tf.int64))`\n    example_data = [\n        [1, 2, 3],\n        [],\n        [4, 5],\n    ]\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, None,), dtype=tf.int64, sequence_rank=2)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertRaggedFieldEqual(out, {\n        \'ragged_flat_values\': (\n            np.array([1, 2, 3, 4, 5]),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n        \'ragged_row_lengths_0\': (\n            [3, 0, 2],\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n    })\n\n  def test_add_ragged_fields_np(self):\n    # List of np.array.\n    example_data = [\n        np.array([1, 2, 3], dtype=np.int64),\n        np.array([], dtype=np.int64),\n        np.array([4, 5], dtype=np.int64),\n    ]\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, None,), dtype=tf.int64, sequence_rank=2)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertRaggedFieldEqual(out, {\n        \'ragged_flat_values\': (\n            np.array([1, 2, 3, 4, 5]),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n        \'ragged_row_lengths_0\': (\n            [3, 0, 2],\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n    })\n\n  def test_add_ragged_fields_empty_np(self):\n    # List of np.array.\n    example_data = [\n        np.array([], dtype=np.int64),\n        np.array([], dtype=np.int64),\n    ]\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, None,), dtype=tf.int64, sequence_rank=2)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertRaggedFieldEqual(out, {\n        \'ragged_flat_values\': (\n            np.zeros(shape=(0,), dtype=np.int64),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n        \'ragged_row_lengths_0\': (\n            [0, 0],\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n    })\n\n  def test_add_ragged_fields_empty(self):\n    # List of empty values\n    example_data = [\n        [],\n        [],\n        []\n    ]\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, None,), dtype=tf.int64, sequence_rank=2)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertRaggedFieldEqual(out, {\n        \'ragged_flat_values\': (\n            np.zeros(shape=(0,), dtype=np.int64),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n        \'ragged_row_lengths_0\': (\n            [0, 0, 0],\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n    })\n\n  def test_add_ragged_fields_all_empty(self):\n    # Empty list\n    example_data = []\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, None,), dtype=tf.int64, sequence_rank=2)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertRaggedFieldEqual(out, {\n        \'ragged_flat_values\': (\n            np.zeros(shape=(0,), dtype=np.int64),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n        \'ragged_row_lengths_0\': (\n            np.zeros(shape=(0,), dtype=np.int64),\n            feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        ),\n    })\n\n  def test_add_ragged_fields_single_level_sequence(self):\n    # Single level sequence\n    example_data = [\n        [1, 2],\n        [2, 3],\n        [4, 5],\n    ]\n    tensor_info = feature_lib.TensorInfo(\n        shape=(None, 2,), dtype=tf.int64, sequence_rank=1)\n    out = example_serializer._add_ragged_fields(example_data, tensor_info)\n    self.assertAllEqual(out[0], [\n        [1, 2],\n        [2, 3],\n        [4, 5],\n    ])\n    self.assertEqual(out[1], tensor_info)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/hashing.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Stable hashing function using md5.\n\nNote that the properties we are looking at here are:\n 1- Good distribution of hashes (random uniformity);\n 2- Speed;\n 3- Availability as portable library, giving the same hash independently of\n platform.\n\nCrypto level hashing is not a requirement.\n\nA bit of history:\n - CityHash was first used. However the C implementation used complex\n instructions and was hard to compile on some platforms.\n - Siphash was chosen as a replacement, because although being slower,\n it has a simpler implementation and it has a pure Python implementation, making\n it easier to distribute TFDS on Windows or MAC. However, the used library\n (reference C implementation wrapped using cffi) crashed the python interpreter\n on py3 with tf1.13.\n - So md5, although being slower that the two above works everywhere and is\n still faster than a pure python implementation of siphash.\n\nChanging the hash function should be done thoughfully, as it would change the\norder of datasets (and thus sets of records when using slicing API). If done,\nall datasets would need to have their major version bumped.\n\nNote that if we were to find a dataset for which two different keys give the\nsame hash (collision), a solution could be to append the key to its hash.\n\nThe split name is being used as salt to avoid having the same keys in two splits\nresult in same order.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nfrom typing import Union\n\nimport six\nimport tensorflow.compat.v2 as tf\n\n\nHashKey = Union[str, bytes, int]\n\n\ndef _to_bytes(data):\n  if not isinstance(data, (six.string_types, bytes)):\n    data = str(data)\n  elif isinstance(data, str):\n    # For windows compatibility, we normalize the key in case a\n    # filepath is passed as key (\'path\\\\to\\\\file\' -> \'path/to/file\')\n    data = data.replace(\'\\\\\', \'/\')\n  return tf.compat.as_bytes(data)\n\n\nclass Hasher(object):\n  """"""Hasher: to initialize a md5 with salt.""""""\n\n  def __init__(self, salt):\n    self._md5 = hashlib.md5(_to_bytes(salt))\n\n  def hash_key(self, key: HashKey) -> int:\n    """"""Returns 128 bits hash of given key.\n\n    Args:\n      key (bytes, string or anything convertible to a string): key to be hashed.\n        If the key is a string, it will be encoded to bytes using utf-8.\n        If the key is neither a string nor bytes, it will be converted to a str,\n          then to bytes.\n        This means that `""1""` (str) and `1` (int) will have the same hash. The\n        intent of the hash being to shuffle keys, it is recommended that all\n        keys of a given set to shuffle use a single type.\n\n    Returns:\n      128 bits integer, hash of key.\n    """"""\n    md5 = self._md5.copy()\n    md5.update(_to_bytes(key))\n    return int(md5.hexdigest(), 16)\n'"
tensorflow_datasets/core/hashing_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.hashing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import hashing\n\n\nclass HashingTest(testing.TestCase):\n\n  def test_ints(self):\n    hasher = hashing.Hasher(salt=\'\')\n    res = hasher.hash_key(0)\n    self.assertEqual(res, 276215275525073243129443018166533317850)\n    res = hasher.hash_key(123455678901234567890)\n    self.assertEqual(res, 6876359009333865997613257802033240610)\n\n  def test_ascii(self):\n    hasher = hashing.Hasher(salt=\'\')\n    res = hasher.hash_key(\'foo\')\n    self.assertEqual(res, 229609063533823256041787889330700985560)\n\n  def test_backslash(self):\n    hasher = hashing.Hasher(salt=\'\')\n    res2 = hasher.hash_key(\'x/y\')\n    res1 = hasher.hash_key(\'x\\\\y\')\n    self.assertEqual(res1, res2)\n    self.assertEqual(res1, 122546703782554533059483853573887619473)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/lazy_imports_lib.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Lazy imports for heavy dependencies.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\n\nfrom tensorflow_datasets.core.utils import py_utils as utils\n\n\ndef _try_import(module_name):\n  """"""Try importing a module, with an informative error message on failure.""""""\n  try:\n    mod = importlib.import_module(module_name)\n    return mod\n  except ImportError:\n    err_msg = (""Failed importing {name}. This likely means that the dataset ""\n               ""requires additional dependencies that have to be ""\n               ""manually installed (usually with `pip install {name}`). See ""\n               ""setup.py extras_require."").format(name=module_name)\n    utils.reraise(suffix=err_msg)\n\n\nclass LazyImporter(object):\n  """"""Lazy importer for heavy dependencies.\n\n  Some datasets require heavy dependencies for data generation. To allow for\n  the default installation to remain lean, those heavy dependencies are\n  lazily imported here.\n  """"""\n\n  @utils.classproperty\n  @classmethod\n  def apache_beam(cls):\n    return _try_import(""apache_beam"")\n\n  @utils.classproperty\n  @classmethod\n  def crepe(cls):\n    return _try_import(""crepe"")\n\n  @utils.classproperty\n  @classmethod\n  def cv2(cls):\n    return _try_import(""cv2"")  # pylint: disable=unreachable\n\n  @utils.classproperty\n  @classmethod\n  def h5py(cls):\n    return _try_import(""h5py"")\n\n  @utils.classproperty\n  @classmethod\n  def langdetect(cls):\n    return _try_import(""langdetect"")\n\n  @utils.classproperty\n  @classmethod\n  def librosa(cls):\n    return _try_import(""librosa"")\n\n  @utils.classproperty\n  @classmethod\n  def matplotlib(cls):\n    _try_import(""matplotlib.pyplot"")\n    return _try_import(""matplotlib"")\n\n  @utils.classproperty\n  @classmethod\n  def mwparserfromhell(cls):\n    return _try_import(""mwparserfromhell"")\n\n  @utils.classproperty\n  @classmethod\n  def nltk(cls):\n    return _try_import(""nltk"")\n\n  @utils.classproperty\n  @classmethod\n  def pandas(cls):\n    return _try_import(""pandas"")\n\n  @utils.classproperty\n  @classmethod\n  def PIL_Image(cls):  # pylint: disable=invalid-name\n    # TiffImagePlugin need to be activated explicitly on some systems\n    # https://github.com/python-pillow/Pillow/blob/5.4.x/src/PIL/Image.py#L407\n    _try_import(""PIL.TiffImagePlugin"")\n    return _try_import(""PIL.Image"")\n\n  @utils.classproperty\n  @classmethod\n  def pretty_midi(cls):\n    return _try_import(""pretty_midi"")\n\n  @utils.classproperty\n  @classmethod\n  def pydub(cls):\n    return _try_import(""pydub"")\n\n  @utils.classproperty\n  @classmethod\n  def scipy(cls):\n    _try_import(""scipy.io"")\n    _try_import(""scipy.ndimage"")\n    return _try_import(""scipy"")\n\n  @utils.classproperty\n  @classmethod\n  def skimage(cls):\n    _try_import(""skimage.color"")\n    _try_import(""skimage.filters"")\n    _try_import(""skimage.external.tifffile"")\n    return _try_import(""skimage"")\n\n  @utils.classproperty\n  @classmethod\n  def tensorflow_data_validation(cls):\n    return _try_import(""tensorflow_data_validation"")\n\n  @utils.classproperty\n  @classmethod\n  def tensorflow_io(cls):\n    return _try_import(""tensorflow_io"")\n\n  @utils.classproperty\n  @classmethod\n  def tldextract(cls):\n    return _try_import(""tldextract"")\n\n  @utils.classproperty\n  @classmethod\n  def os(cls):\n    """"""For testing purposes only.""""""\n    return _try_import(""os"")\n\n  @utils.classproperty\n  @classmethod\n  def test_foo(cls):\n    """"""For testing purposes only.""""""\n    return _try_import(""test_foo"")\n\n\nlazy_imports = LazyImporter  # pylint: disable=invalid-name\n'"
tensorflow_datasets/core/lazy_imports_lib_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.lazy_imports.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport six\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets import testing\n\n\nclass LazyImportsTest(testing.TestCase, parameterized.TestCase):\n\n  # The following deps are not in the test list because the datasets that\n  # require them need to have their tests run in isolation:\n  # * crepe (NSynth)\n  # * librosa (NSynth)\n  @parameterized.parameters(\n      ""cv2"",\n      ""langdetect"",\n      ""matplotlib"",\n      ""mwparserfromhell"",\n      ""nltk"",\n      ""os"",\n      ""pandas"",\n      ""pretty_midi"",\n      ""pydub"",\n      ""scipy"",\n      ""skimage"",\n      ""tldextract"",\n  )\n  def test_import(self, module_name):\n    if module_name == ""nltk"" and six.PY2:  # sklearn do not support Python2\n      return\n    # TODO(rsepassi): Re-enable skimage on Py3 (b/129964829)\n    if module_name == ""skimage"" and six.PY3:\n      return\n    getattr(tfds.core.lazy_imports, module_name)\n\n  def test_bad_import(self):\n    with self.assertRaisesWithPredicateMatch(ImportError, ""extras_require""):\n      _ = tfds.core.lazy_imports.test_foo\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/naming.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for file names.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\n_first_cap_re = re.compile(""(.)([A-Z][a-z0-9]+)"")\n_all_cap_re = re.compile(""([a-z0-9])([A-Z])"")\n\n\ndef camelcase_to_snakecase(name):\n  """"""Convert camel-case string to snake-case.""""""\n  s1 = _first_cap_re.sub(r""\\1_\\2"", name)\n  return _all_cap_re.sub(r""\\1_\\2"", s1).lower()\n\n\ndef snake_to_camelcase(name):\n  """"""Convert snake-case string to camel-case string.""""""\n  return """".join(n.capitalize() for n in name.split(""_""))\n\n\ndef filename_prefix_for_name(name):\n  if os.path.basename(name) != name:\n    raise ValueError(""Should be a dataset name, not a path: %s"" % name)\n  return camelcase_to_snakecase(name)\n\n\ndef filename_prefix_for_split(name, split):\n  if os.path.basename(name) != name:\n    raise ValueError(""Should be a dataset name, not a path: %s"" % name)\n  return ""%s-%s"" % (filename_prefix_for_name(name), split)\n\n\ndef sharded_filenames(filename_prefix, num_shards):\n  """"""Sharded filenames given prefix and number of shards.""""""\n  shard_suffix = ""%05d-of-%05d""\n  return [\n      ""%s-%s"" % (filename_prefix, shard_suffix % (i, num_shards))\n      for i in range(num_shards)\n  ]\n\n\ndef filepattern_for_dataset_split(dataset_name, split, data_dir,\n                                  filetype_suffix=None):\n  prefix = filename_prefix_for_split(dataset_name, split)\n  if filetype_suffix:\n    prefix += "".%s"" % filetype_suffix\n  filepath = os.path.join(data_dir, prefix)\n  return ""%s*"" % filepath\n\n\ndef filenames_for_dataset_split(\n    dataset_name, split, num_shards, filetype_suffix=None):\n  prefix = filename_prefix_for_split(dataset_name, split)\n  if filetype_suffix:\n    prefix += "".%s"" % filetype_suffix\n  return sharded_filenames(prefix, num_shards)\n\n\ndef filepaths_for_dataset_split(dataset_name, split, num_shards, data_dir,\n                                filetype_suffix=None):\n  filenames = filenames_for_dataset_split(\n      dataset_name=dataset_name,\n      split=split,\n      num_shards=num_shards,\n      filetype_suffix=filetype_suffix,\n  )\n  filepaths = [os.path.join(data_dir, fname) for fname in filenames]\n  return filepaths\n'"
tensorflow_datasets/core/naming_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests tensorflow_datasets.core.naming.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import naming\nfrom tensorflow_datasets.core import splits\n\n\nclass NamingTest(parameterized.TestCase, testing.TestCase):\n\n  @parameterized.parameters(\n      (""HelloWorld"", ""hello_world""),\n      (""FooBARBaz"", ""foo_bar_baz""),\n      (""FooBar123"", ""foo_bar123""),\n      (""FooBar123Baz"", ""foo_bar123_baz""),\n      (""FooBar123baz"", ""foo_bar123baz""),\n  )\n  def test_camelcase_to_snakecase(self, camel, snake):\n    self.assertEqual(snake, naming.camelcase_to_snakecase(camel))\n\n  @parameterized.parameters(\n      (""HelloWorld"", ""hello_world""),\n      (""FooBar123"", ""foo_bar123""),\n      (""FooBar123Baz"", ""foo_bar123_baz""),\n      (""FooBar123baz"", ""foo_bar123baz""),\n  )\n  def test_snake_to_camelcase(self, camel, snake):\n    self.assertEqual(naming.snake_to_camelcase(snake), camel)\n    # camelcase_to_snakecase is a no-op if the name is already snake_case.\n    self.assertEqual(naming.camelcase_to_snakecase(snake), snake)\n\n  def test_sharded_filenames(self):\n    prefix = ""/tmp/foo""\n    num_shards = 2\n    expected = [\n        ""/tmp/foo-00000-of-00002"",\n        ""/tmp/foo-00001-of-00002"",\n    ]\n    self.assertEqual(expected, naming.sharded_filenames(prefix, num_shards))\n\n  @parameterized.parameters(\n      (""foo"", ""foo-train""),\n      (""Foo"", ""foo-train""),\n      (""FooBar"", ""foo_bar-train""),\n  )\n  def test_filename_prefix_for_split(self, prefix, expected):\n    split = splits.Split.TRAIN\n    self.assertEqual(expected, naming.filename_prefix_for_split(prefix, split))\n\n  def test_filenames_for_dataset_split(self):\n    self.assertEqual([\n        ""foo-train-00000-of-00002"",\n        ""foo-train-00001-of-00002"",\n    ], naming.filenames_for_dataset_split(\n        dataset_name=""foo"",\n        split=splits.Split.TRAIN,\n        num_shards=2))\n\n  def test_filepaths_for_dataset_split(self):\n    self.assertEqual([\n        ""/tmp/bar/foo-train-00000-of-00002"",\n        ""/tmp/bar/foo-train-00001-of-00002"",\n    ],\n                     naming.filepaths_for_dataset_split(\n                         dataset_name=""foo"",\n                         split=splits.Split.TRAIN,\n                         num_shards=2,\n                         data_dir=""/tmp/bar/""))\n\n  def test_filepaths_for_dataset_split_with_suffix(self):\n    self.assertEqual([\n        ""/tmp/bar/foo-train.bar-00000-of-00002"",\n        ""/tmp/bar/foo-train.bar-00001-of-00002"",\n    ],\n                     naming.filepaths_for_dataset_split(\n                         dataset_name=""foo"",\n                         split=splits.Split.TRAIN,\n                         num_shards=2,\n                         data_dir=""/tmp/bar/"",\n                         filetype_suffix=""bar""))\n\n  def test_filepattern_for_dataset_split(self):\n    self.assertEqual(""/tmp/bar/foo-test*"",\n                     naming.filepattern_for_dataset_split(\n                         dataset_name=""foo"",\n                         split=splits.Split.TEST,\n                         data_dir=""/tmp/bar/""))\n    self.assertEqual(""/tmp/bar/foo-test.bar*"",\n                     naming.filepattern_for_dataset_split(\n                         dataset_name=""foo"",\n                         split=splits.Split.TEST,\n                         filetype_suffix=""bar"",\n                         data_dir=""/tmp/bar/""))\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/registered.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Access registered datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport contextlib\nimport inspect\nimport posixpath\nimport re\nfrom typing import Any, Callable, Iterable, Iterator, List, Optional, Type\n\nfrom absl import flags\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import constants\nfrom tensorflow_datasets.core import naming\nfrom tensorflow_datasets.core.utils import gcs_utils\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.core.utils import version\n\n\nFLAGS = flags.FLAGS\n\n__all__ = [\n    ""RegisteredDataset"",\n    ""list_builders"",\n    ""builder"",\n    ""load"",\n]\n\n\n# Cannot use real typing due to circular dependencies. Could this be fixed ?\nDatasetBuilder = Any\n\nPredicateFn = Callable[[Type[DatasetBuilder]], bool]\n\n\n# Internal registry containing <str registered_name, DatasetBuilder subclass>\n_DATASET_REGISTRY = {}\n\n# Internal registry containing:\n# <str snake_cased_name, abstract DatasetBuilder subclass>\n_ABSTRACT_DATASET_REGISTRY = {}\n\n# Datasets that are under active development and which we can\'t therefore load.\n# <str snake_cased_name, in development DatasetBuilder subclass>\n_IN_DEVELOPMENT_REGISTRY = {}\n\n\n_NAME_STR_ERR = """"""\\\nParsing builder name string {} failed.\nThe builder name string must be of the following format:\n  dataset_name[/config_name][:version][/kwargs]\n\n  Where:\n\n    * dataset_name and config_name are string following python variable naming.\n    * version is of the form x.y.z where {{x,y,z}} can be any digit or *.\n    * kwargs is a comma list separated of arguments and values to pass to\n      builder.\n\n  Examples:\n    my_dataset\n    my_dataset:1.2.*\n    my_dataset/config1\n    my_dataset/config1:1.*.*\n    my_dataset/config1/arg1=val1,arg2=val2\n    my_dataset/config1:1.2.3/right=True,foo=bar,rate=1.2\n""""""\n\n_DATASET_NOT_FOUND_ERR = """"""\\\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - dataset class is not in development, i.e. if IN_DEVELOPMENT=True\n    - the module defining the dataset class is imported\n""""""\n\n\n# Regex matching \'dataset/config:1.*.*/arg=123\'\n_NAME_REG = re.compile(\n    r""^""\n    r""(?P<dataset_name>\\w+)""\n    r""(/(?P<config>[\\w\\-\\.]+))?""\n    r""(:(?P<version>(\\d+|\\*)(\\.(\\d+|\\*)){2}))?""\n    r""(/(?P<kwargs>(\\w+=\\w+)(,\\w+=[^,]+)*))?""\n    r""$"")\n\n\n# Regex matching \'dataset/config/1.3.0\'\n_FULL_NAME_REG = re.compile(r""^{ds_name}/({config_name}/)?{version}$"".format(\n    ds_name=r""\\w+"",\n    config_name=r""[\\w\\-\\.]+"",\n    version=r""[0-9]+\\.[0-9]+\\.[0-9]+"",\n))\n\n\n_skip_registration = False\n\n\n@contextlib.contextmanager\ndef skip_registration():\n  """"""Context manager within which dataset builders are not registered.""""""\n  global _skip_registration\n  try:\n    _skip_registration = True\n    yield\n  finally:\n    _skip_registration = False\n\n\nclass DatasetNotFoundError(ValueError):\n  """"""The requested Dataset was not found.""""""\n\n  def __init__(self, name, is_abstract=False, in_development=False):\n    all_datasets_str = ""\\n\\t- "".join([""""] + list_builders())\n    if is_abstract:\n      error_string = (""Dataset %s is an abstract class so cannot be created. ""\n                      ""Please make sure to instantiate all abstract methods.\\n""\n                      ""%s"") % (name, _DATASET_NOT_FOUND_ERR)\n    elif in_development:\n      error_string = (""Dataset %s is under active development and is not ""\n                      ""available yet.\\n"") % name\n    else:\n      error_string = (""Dataset %s not found. Available datasets:%s\\n""\n                      ""%s"") % (name, all_datasets_str, _DATASET_NOT_FOUND_ERR)\n    ValueError.__init__(self, error_string)\n\n\nclass RegisteredDataset(abc.ABCMeta):\n  """"""Subclasses will be registered and given a `name` property.""""""\n\n  def __new__(cls, cls_name, bases, class_dict):\n    name = naming.camelcase_to_snakecase(cls_name)\n    class_dict[""name""] = name\n    builder_cls = super(RegisteredDataset, cls).__new__(  # pylint: disable=too-many-function-args,redefined-outer-name\n        cls, cls_name, bases, class_dict)\n\n    if py_utils.is_notebook():  # On Colab/Jupyter, we allow overwriting\n      pass\n    elif name in _DATASET_REGISTRY:\n      raise ValueError(""Dataset with name %s already registered."" % name)\n    elif name in _IN_DEVELOPMENT_REGISTRY:\n      raise ValueError(\n          ""Dataset with name %s already registered as in development."" % name)\n    elif name in _ABSTRACT_DATASET_REGISTRY:\n      raise ValueError(\n          ""Dataset with name %s already registered as abstract."" % name)\n\n    if _skip_registration:\n      pass  # Skip dataset registration within the contextmanager\n    elif inspect.isabstract(builder_cls):\n      _ABSTRACT_DATASET_REGISTRY[name] = builder_cls\n    elif class_dict.get(""IN_DEVELOPMENT""):\n      _IN_DEVELOPMENT_REGISTRY[name] = builder_cls\n    else:\n      _DATASET_REGISTRY[name] = builder_cls\n    return builder_cls\n\n\ndef list_builders():\n  """"""Returns the string names of all `tfds.core.DatasetBuilder`s.""""""\n  return sorted(list(_DATASET_REGISTRY))\n\n\ndef builder_cls(name: str):\n  """"""Fetches a `tfds.core.DatasetBuilder` class by string name.\n\n  Args:\n    name: `str`, the registered name of the `DatasetBuilder` (the class name\n      as camel or snake case: `MyDataset` or `my_dataset`).\n\n  Returns:\n    A `tfds.core.DatasetBuilder` class.\n\n  Raises:\n    DatasetNotFoundError: if `name` is unrecognized.\n  """"""\n  name, kwargs = _dataset_name_and_kwargs_from_name_str(name)\n  if kwargs:\n    raise ValueError(\n        ""`builder_cls` only accept the `dataset_name` without config, ""\n        ""version or arguments. Got: name=\'{}\', kwargs={}"".format(name, kwargs))\n\n  if name in _ABSTRACT_DATASET_REGISTRY:\n    raise DatasetNotFoundError(name, is_abstract=True)\n  if name in _IN_DEVELOPMENT_REGISTRY:\n    raise DatasetNotFoundError(name, in_development=True)\n  if name not in _DATASET_REGISTRY:\n    raise DatasetNotFoundError(name)\n  return _DATASET_REGISTRY[name]\n\n\ndef builder(name, **builder_init_kwargs):\n  """"""Fetches a `tfds.core.DatasetBuilder` by string name.\n\n  Args:\n    name: `str`, the registered name of the `DatasetBuilder` (the class name\n      as camel or snake case: `MyDataset` or `my_dataset`).\n      This can be either `\'dataset_name\'` or\n      `\'dataset_name/config_name\'` for datasets with `BuilderConfig`s.\n      As a convenience, this string may contain comma-separated keyword\n      arguments for the builder. For example `\'foo_bar/a=True,b=3\'` would use\n      the `FooBar` dataset passing the keyword arguments `a=True` and `b=3`\n      (for builders with configs, it would be `\'foo_bar/zoo/a=True,b=3\'` to\n      use the `\'zoo\'` config and pass to the builder keyword arguments `a=True`\n      and `b=3`).\n    **builder_init_kwargs: `dict` of keyword arguments passed to the\n      `DatasetBuilder`. These will override keyword arguments passed in `name`,\n      if any.\n\n  Returns:\n    A `tfds.core.DatasetBuilder`.\n\n  Raises:\n    DatasetNotFoundError: if `name` is unrecognized.\n  """"""\n  name, builder_kwargs = _dataset_name_and_kwargs_from_name_str(name)\n  builder_kwargs.update(builder_init_kwargs)\n  with py_utils.try_reraise(\n      prefix=""Failed to construct dataset {}"".format(name)):\n    return builder_cls(name)(**builder_kwargs)\n\n\n@api_utils.disallow_positional_args(allowed=[""name""])\ndef load(name,\n         split=None,\n         data_dir=None,\n         batch_size=None,\n         shuffle_files=False,\n         download=True,\n         as_supervised=False,\n         decoders=None,\n         read_config=None,\n         with_info=False,\n         builder_kwargs=None,\n         download_and_prepare_kwargs=None,\n         as_dataset_kwargs=None,\n         try_gcs=False):\n  # pylint: disable=line-too-long\n  """"""Loads the named dataset into a `tf.data.Dataset`.\n\n  If `split=None` (the default), returns all splits for the dataset. Otherwise,\n  returns the specified split.\n\n  `load` is a convenience method that fetches the `tfds.core.DatasetBuilder` by\n  string name, optionally calls `DatasetBuilder.download_and_prepare`\n  (if `download=True`), and then calls `DatasetBuilder.as_dataset`.\n  This is roughly equivalent to:\n\n  ```\n  builder = tfds.builder(name, data_dir=data_dir, **builder_kwargs)\n  if download:\n    builder.download_and_prepare(**download_and_prepare_kwargs)\n  ds = builder.as_dataset(\n      split=split, as_supervised=as_supervised, **as_dataset_kwargs)\n  if with_info:\n    return ds, builder.info\n  return ds\n  ```\n\n  If you\'d like NumPy arrays instead of `tf.data.Dataset`s or `tf.Tensor`s,\n  you can pass the return value to `tfds.as_numpy`.\n\n  Callers must pass arguments as keyword arguments.\n\n  **Warning**: calling this function might potentially trigger the download\n  of hundreds of GiB to disk. Refer to the `download` argument.\n\n  Args:\n    name: `str`, the registered name of the `DatasetBuilder` (the snake case\n      version of the class name). This can be either `""dataset_name""` or\n      `""dataset_name/config_name""` for datasets with `BuilderConfig`s.\n      As a convenience, this string may contain comma-separated keyword\n      arguments for the builder. For example `""foo_bar/a=True,b=3""` would use\n      the `FooBar` dataset passing the keyword arguments `a=True` and `b=3`\n      (for builders with configs, it would be `""foo_bar/zoo/a=True,b=3""` to\n      use the `""zoo""` config and pass to the builder keyword arguments `a=True`\n      and `b=3`).\n    split: Which split of the data to load (e.g. `\'train\'`, `\'test\'`\n      `[\'train\', \'test\']`, `\'train[80%:]\'`,...). See our\n      [split API guide](https://www.tensorflow.org/datasets/splits).\n      If `None`, will return all splits in a `Dict[Split, tf.data.Dataset]`\n    data_dir: `str` (optional), directory to read/write data.\n      Defaults to ""~/tensorflow_datasets"".\n    batch_size: `int`, if set, add a batch dimension to examples. Note that\n      variable length features will be 0-padded. If\n      `batch_size=-1`, will return the full dataset as `tf.Tensor`s.\n    shuffle_files: `bool`, whether to shuffle the input files.\n      Defaults to `False`.\n    download: `bool` (optional), whether to call\n      `tfds.core.DatasetBuilder.download_and_prepare`\n      before calling `tf.DatasetBuilder.as_dataset`. If `False`, data is\n      expected to be in `data_dir`. If `True` and the data is already in\n      `data_dir`, `download_and_prepare` is a no-op.\n    as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n      will have a 2-tuple structure `(input, label)` according to\n      `builder.info.supervised_keys`. If `False`, the default,\n      the returned `tf.data.Dataset` will have a dictionary with all the\n      features.\n    decoders: Nested dict of `Decoder` objects which allow to customize the\n      decoding. The structure should match the feature structure, but only\n      customized feature keys need to be present. See\n      [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n      for more info.\n    read_config: `tfds.ReadConfig`, Additional options to configure the\n      input pipeline (e.g. seed, num parallel reads,...).\n    with_info: `bool`, if True, tfds.load will return the tuple\n      (tf.data.Dataset, tfds.core.DatasetInfo) containing the info associated\n      with the builder.\n    builder_kwargs: `dict` (optional), keyword arguments to be passed to the\n      `tfds.core.DatasetBuilder` constructor. `data_dir` will be passed\n      through by default.\n    download_and_prepare_kwargs: `dict` (optional) keyword arguments passed to\n      `tfds.core.DatasetBuilder.download_and_prepare` if `download=True`. Allow\n      to control where to download and extract the cached data. If not set,\n      cache_dir and manual_dir will automatically be deduced from data_dir.\n    as_dataset_kwargs: `dict` (optional), keyword arguments passed to\n      `tfds.core.DatasetBuilder.as_dataset`.\n    try_gcs: `bool`, if True, tfds.load will see if the dataset exists on\n      the public GCS bucket before building it locally.\n\n  Returns:\n    ds: `tf.data.Dataset`, the dataset requested, or if `split` is None, a\n      `dict<key: tfds.Split, value: tfds.data.Dataset>`. If `batch_size=-1`,\n      these will be full datasets as `tf.Tensor`s.\n    ds_info: `tfds.core.DatasetInfo`, if `with_info` is True, then `tfds.load`\n      will return a tuple `(ds, ds_info)` containing dataset information\n      (version, features, splits, num_examples,...). Note that the `ds_info`\n      object documents the entire dataset, regardless of the `split` requested.\n      Split-specific information is available in `ds_info.splits`.\n  """"""\n  # pylint: enable=line-too-long\n\n  name, name_builder_kwargs = _dataset_name_and_kwargs_from_name_str(name)\n  name_builder_kwargs.update(builder_kwargs or {})\n  builder_kwargs = name_builder_kwargs\n\n  # Set data_dir\n  if try_gcs and gcs_utils.is_dataset_on_gcs(name):\n    data_dir = gcs_utils.gcs_path(""datasets"")\n  elif data_dir is None:\n    data_dir = constants.DATA_DIR\n\n  dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)\n  if download:\n    download_and_prepare_kwargs = download_and_prepare_kwargs or {}\n    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n\n  if as_dataset_kwargs is None:\n    as_dataset_kwargs = {}\n  as_dataset_kwargs = dict(as_dataset_kwargs)\n  as_dataset_kwargs.setdefault(""split"", split)\n  as_dataset_kwargs.setdefault(""as_supervised"", as_supervised)\n  as_dataset_kwargs.setdefault(""batch_size"", batch_size)\n  as_dataset_kwargs.setdefault(""decoders"", decoders)\n  as_dataset_kwargs.setdefault(""shuffle_files"", shuffle_files)\n  as_dataset_kwargs.setdefault(""read_config"", read_config)\n\n  ds = dbuilder.as_dataset(**as_dataset_kwargs)\n  if with_info:\n    return ds, dbuilder.info\n  return ds\n\n\ndef _dataset_name_and_kwargs_from_name_str(name_str):\n  """"""Extract kwargs from name str.""""""\n  res = _NAME_REG.match(name_str)\n  if not res:\n    raise ValueError(_NAME_STR_ERR.format(name_str))\n  name = res.group(""dataset_name"")\n  # Normalize the name to accept CamelCase\n  name = naming.camelcase_to_snakecase(name)\n  kwargs = _kwargs_str_to_kwargs(res.group(""kwargs""))\n  try:\n    for attr in [""config"", ""version""]:\n      val = res.group(attr)\n      if val is None:\n        continue\n      if attr in kwargs:\n        raise ValueError(""Dataset %s: cannot pass %s twice."" % (name, attr))\n      kwargs[attr] = val\n    return name, kwargs\n  except:\n    logging.error(_NAME_STR_ERR.format(name_str))   # pylint: disable=logging-format-interpolation\n    raise\n\n\ndef _kwargs_str_to_kwargs(kwargs_str):\n  if not kwargs_str:\n    return {}\n  kwarg_strs = kwargs_str.split("","")\n  kwargs = {}\n  for kwarg_str in kwarg_strs:\n    kwarg_name, kwarg_val = kwarg_str.split(""="")\n    kwargs[kwarg_name] = _cast_to_pod(kwarg_val)\n  return kwargs\n\n\ndef _cast_to_pod(val):\n  """"""Try cast to int, float, bool, str, in that order.""""""\n  bools = {""True"": True, ""False"": False}\n  if val in bools:\n    return bools[val]\n  try:\n    return int(val)\n  except ValueError:\n    try:\n      return float(val)\n    except ValueError:\n      return tf.compat.as_text(val)\n\n\ndef _get_all_versions(\n    current_version: version.Version,\n    extra_versions: Iterable[version.Version],\n    current_version_only: bool,\n) -> Iterable[str]:\n  """"""Returns the list of all current versions.""""""\n  # Merge current version with all extra versions\n  version_list = [current_version]\n  if current_version_only:\n    version_list.extend(extra_versions)\n  # Filter datasets which do not have a version (version is `None`) as they\n  # should not be instantiated directly (e.g wmt_translate)\n  return {str(v) for v in version_list if v}\n\n\ndef _iter_single_full_names(\n    builder_name: str,\n    builder_cls: Type[DatasetBuilder],  # pylint: disable=redefined-outer-name\n    current_version_only: bool,\n) -> Iterator[str]:\n  """"""Iterate over a single builder full names.""""""\n  if builder_cls.BUILDER_CONFIGS:\n    for config in builder_cls.BUILDER_CONFIGS:\n      for v in _get_all_versions(\n          config.version,\n          config.supported_versions,\n          current_version_only=current_version_only,\n      ):\n        yield posixpath.join(builder_name, config.name, v)\n  else:\n    for v in _get_all_versions(\n        builder_cls.VERSION,\n        builder_cls.SUPPORTED_VERSIONS,\n        current_version_only=current_version_only\n    ):\n      yield posixpath.join(builder_name, v)\n\n\ndef _iter_full_names(\n    predicate_fn: Optional[PredicateFn],\n    current_version_only: bool,\n) -> Iterator[str]:\n  """"""Yield all registered datasets full_names (see `list_full_names`).""""""\n  for builder_name, builder_cls in _DATASET_REGISTRY.items():  # pylint: disable=redefined-outer-name\n    # Only keep requested datasets\n    if predicate_fn is not None and not predicate_fn(builder_cls):\n      continue\n    for full_name in _iter_single_full_names(\n        builder_name,\n        builder_cls,\n        current_version_only=current_version_only,\n    ):\n      yield full_name\n\n\ndef list_full_names(\n    predicate_fn: Optional[PredicateFn] = None,\n    current_version_only: bool = False,\n) -> List[str]:\n  """"""Lists all registered datasets full_names.\n\n  Args:\n    predicate_fn: `Callable[[Type[DatasetBuilder]], bool]`, if set, only\n      returns the dataset names which satisfy the predicate.\n    current_version_only: If True, only returns the current version.\n\n  Returns:\n    The list of all registered dataset full names.\n  """"""\n  return sorted(_iter_full_names(\n      predicate_fn=predicate_fn,\n      current_version_only=current_version_only,\n  ))\n\n\ndef single_full_names(\n    builder_name: str,\n    current_version_only: bool = True,\n) -> List[str]:\n  """"""Returns the list `[\'ds/c0/v0\',...]` or `[\'ds/v\']` for a single builder.""""""\n  return sorted(_iter_single_full_names(\n      builder_name,\n      _DATASET_REGISTRY[builder_name],\n      current_version_only=current_version_only,\n  ))\n\n\ndef is_full_name(full_name: str) -> bool:\n  """"""Returns whether the string pattern match `ds/config/1.2.3` or `ds/1.2.3`.\n\n  Args:\n    full_name: String to check.\n\n  Returns:\n    `bool`.\n  """"""\n  return bool(_FULL_NAME_REG.match(full_name))\n'"
tensorflow_datasets/core/registered_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.registered.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport mock\nimport six\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.core import splits\nfrom tensorflow_datasets.core.utils import py_utils\n\n\n@six.add_metaclass(registered.RegisteredDataset)\nclass EmptyDatasetBuilder(object):\n\n  def __init__(self, **kwargs):\n    self.kwargs = kwargs\n    self.download_called = False\n    self.as_dataset_called = False\n\n  def download_and_prepare(self, **kwargs):\n    self.download_called = True\n    self.download_kwargs = kwargs\n\n  def as_dataset(self, **kwargs):\n    self.as_dataset_called = True\n    self.as_dataset_kwargs = kwargs\n    return self\n\n\nclass UnregisteredBuilder(EmptyDatasetBuilder):\n\n  @abc.abstractproperty\n  def an_abstract_property(self):\n    pass\n\n\nclass InDevelopmentDatasetBuilder(EmptyDatasetBuilder):\n\n  IN_DEVELOPMENT = True\n\n\nclass RegisteredTest(testing.TestCase):\n\n  def test_registered(self):\n    name = ""empty_dataset_builder""\n    self.assertEqual(name, EmptyDatasetBuilder.name)\n    self.assertIsInstance(registered.builder(name), EmptyDatasetBuilder)\n    self.assertIn(name, registered.list_builders())\n\n    nonexistent = ""nonexistent_foobar_dataset""\n    with self.assertRaisesWithPredicateMatch(ValueError, ""not found""):\n      registered.builder(nonexistent)\n    # Prints registered datasets\n    with self.assertRaisesWithPredicateMatch(ValueError, name):\n      registered.builder(nonexistent)\n\n  def test_registered_cls(self):\n    name = ""empty_dataset_builder""\n    self.assertIs(registered.builder_cls(name), EmptyDatasetBuilder)\n\n    nonexistent = ""nonexistent_foobar_dataset""\n    with self.assertRaisesWithPredicateMatch(ValueError, ""not found""):\n      registered.builder_cls(nonexistent)\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, ""`builder_cls` only accept the `dataset_name`""):\n      name_with_kwargs = ""empty_dataset_builder/config:1.0.0""\n      registered.builder_cls(name_with_kwargs)\n\n  def test_abstract(self):\n    name = ""unregistered_builder""\n    self.assertEqual(name, UnregisteredBuilder.name)\n    self.assertNotIn(name, registered.list_builders())\n\n    with self.assertRaisesWithPredicateMatch(ValueError, ""an abstract class""):\n      registered.builder(name)\n\n  def test_in_development(self):\n    name = ""in_development_dataset_builder""\n    self.assertEqual(name, InDevelopmentDatasetBuilder.name)\n    self.assertNotIn(name, registered.list_builders())\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError,\n        (""Dataset %s is under active development and is not available yet.""\n        ) % name):\n      registered.builder(name)\n\n  def test_builder_with_kwargs(self):\n    name = ""empty_dataset_builder""\n    name_with_kwargs = name + ""/k1=1,k2=1.,k3=foo,k4=True,k5=False""\n    builder = registered.builder(name_with_kwargs, data_dir=""bar"")\n    expectations = [(""k1"", 1), (""k2"", 1.), (""k3"", u""foo""), (""k4"", True),\n                    (""k5"", False)]\n    for k, v in expectations:\n      self.assertEqual(type(builder.kwargs[k]), type(v))\n      self.assertEqual(builder.kwargs[k], v)\n\n  def test_builder_fullname(self):\n    fullname = ""empty_dataset_builder/conf1-attr:1.0.1/k1=1,k2=2""\n    builder = registered.builder(fullname, data_dir=""bar"")\n    expected = {""k1"": 1, ""k2"": 2, ""version"": ""1.0.1"",\n                ""config"": ""conf1-attr"", ""data_dir"": ""bar""}\n    self.assertEqual(expected, builder.kwargs)\n\n  def test_builder_camel_case(self):\n    fullname = ""EmptyDatasetBuilder""\n    builder = registered.builder(fullname)\n    self.assertIsInstance(builder, EmptyDatasetBuilder)\n\n  def test_load(self):\n    name = ""empty_dataset_builder/k1=1""\n    data_dir = ""foo""\n    as_dataset_kwargs = dict(a=1, b=2)\n\n    # EmptyDatasetBuilder returns self from as_dataset\n    builder = registered.load(\n        name=name, split=splits.Split.TEST, data_dir=data_dir,\n        download=False, as_dataset_kwargs=as_dataset_kwargs)\n    self.assertTrue(builder.as_dataset_called)\n    self.assertFalse(builder.download_called)\n    self.assertEqual(splits.Split.TEST,\n                     builder.as_dataset_kwargs.pop(""split""))\n    self.assertEqual(None, builder.as_dataset_kwargs.pop(""batch_size""))\n    self.assertFalse(builder.as_dataset_kwargs.pop(""as_supervised""))\n    self.assertFalse(builder.as_dataset_kwargs.pop(""decoders""))\n    self.assertIsNone(builder.as_dataset_kwargs.pop(""read_config""))\n    self.assertFalse(builder.as_dataset_kwargs.pop(""shuffle_files""))\n    self.assertEqual(builder.as_dataset_kwargs, as_dataset_kwargs)\n    self.assertEqual(dict(data_dir=data_dir, k1=1), builder.kwargs)\n\n    builder = registered.load(\n        name, split=splits.Split.TRAIN, data_dir=data_dir,\n        download=True, as_dataset_kwargs=as_dataset_kwargs)\n    self.assertTrue(builder.as_dataset_called)\n    self.assertTrue(builder.download_called)\n\n    # Tests for different batch_size\n    # By default batch_size=None\n    builder = registered.load(\n        name=name, split=splits.Split.TEST, data_dir=data_dir)\n    self.assertEqual(None, builder.as_dataset_kwargs.pop(""batch_size""))\n    # Setting batch_size=1\n    builder = registered.load(\n        name=name, split=splits.Split.TEST, data_dir=data_dir,\n        batch_size=1)\n    self.assertEqual(1, builder.as_dataset_kwargs.pop(""batch_size""))\n\n  def test_load_all_splits(self):\n    name = ""empty_dataset_builder""\n    # EmptyDatasetBuilder returns self from as_dataset\n    builder = registered.load(name=name, data_dir=""foo"")\n    self.assertTrue(builder.as_dataset_called)\n    self.assertEqual(None, builder.as_dataset_kwargs.pop(""split""))\n\n  def test_load_with_config(self):\n    data_dir = ""foo""\n    name = ""empty_dataset_builder/bar/k1=1""\n    # EmptyDatasetBuilder returns self from as_dataset\n    builder = registered.load(name=name, split=splits.Split.TEST,\n                              data_dir=data_dir)\n    expected = dict(data_dir=data_dir, k1=1, config=""bar"")\n    self.assertEqual(expected, builder.kwargs)\n\n    name = ""empty_dataset_builder/bar""\n    builder = registered.load(name=name, split=splits.Split.TEST,\n                              data_dir=data_dir)\n    self.assertEqual(dict(data_dir=data_dir, config=""bar""),\n                     builder.kwargs)\n\n  def test_notebook_overwrite_dataset(self):\n    """"""Redefining the same builder twice is possible on colab.""""""\n\n    with mock.patch.object(py_utils, ""is_notebook"", lambda: True):\n      name = ""colab_builder""\n      self.assertNotIn(name, registered.list_builders())\n\n      @six.add_metaclass(registered.RegisteredDataset)\n      class ColabBuilder(object):\n        pass\n\n      self.assertIn(name, registered.list_builders())\n      self.assertIsInstance(registered.builder(name), ColabBuilder)\n      old_colab_class = ColabBuilder\n\n      @six.add_metaclass(registered.RegisteredDataset)  # pylint: disable=function-redefined\n      class ColabBuilder(object):\n        pass\n\n      self.assertIsInstance(registered.builder(name), ColabBuilder)\n      self.assertNotIsInstance(registered.builder(name), old_colab_class)\n\n  def test_duplicate_dataset(self):\n    """"""Redefining the same builder twice should raises error.""""""\n\n    @six.add_metaclass(registered.RegisteredDataset)  # pylint: disable=unused-variable\n    class DuplicateBuilder(object):\n      pass\n\n    with self.assertRaisesWithPredicateMatch(ValueError, ""already registered""):\n      @six.add_metaclass(registered.RegisteredDataset)  # pylint: disable=function-redefined\n      class DuplicateBuilder(object):\n        pass\n\n  def test_is_full_name(self):\n    """"""Test for `is_full_name`.""""""\n    self.assertFalse(registered.is_full_name(""ds/config/1.0.2/other""))\n    self.assertFalse(registered.is_full_name(""ds/config/1.0.2/""))\n    self.assertFalse(registered.is_full_name(""ds/config/1.2""))\n    self.assertFalse(registered.is_full_name(""ds/config""))\n    self.assertFalse(registered.is_full_name(""ds/1.2.*""))\n\n    self.assertTrue(registered.is_full_name(""ds/config/1.0.2""))\n    self.assertTrue(registered.is_full_name(""ds/1.0.2""))\n    self.assertTrue(registered.is_full_name(""ds_with_number123/1.0.2""))\n\n  def test_skip_regitration(self):\n    """"""Test `skip_registration()`.""""""\n\n    with registered.skip_registration():\n\n      @six.add_metaclass(registered.RegisteredDataset)\n      class SkipRegisteredDataset(object):\n        pass\n\n    name = ""skip_registered_dataset""\n    self.assertEqual(name, SkipRegisteredDataset.name)\n    self.assertNotIn(name, registered.list_builders())\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/shuffle.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""To shuffle records (stable).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport os\nimport struct\nimport uuid\n\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import hashing\n\n# Approximately how much data to store in memory before writing to disk.\n# If the amount of data to shuffle is < MAX_MEM_BUFFER_SIZE, no intermediary\n# data is written to disk.\nMAX_MEM_BUFFER_SIZE = 1000 << 20  # 1GB\n\n# If data to shuffle is too large for memory. Records are split among 1K\n# buckets stored on disk, then each bucket is sorted in memory.\n# For a dataset split of about 1TB, each bucket is going to\n# be about 1GB. Larger datasets will likely be handled by Beam.\n#\n# Increasing the number of buckets would decrease the size of each bucket.\n# Current implementation relies on having one open file per bucket.\n# Windows has a limit of ~2K open files per process (Linux ~32K); so increasing\n# the number of buckets might warrant some changes in implementation.\nBUCKETS_NUMBER = 1000  # Number of buckets to pre-sort and hold generated data.\n\nHKEY_SIZE = 128  # Hash of keys is 128 bits (md5).\nHKEY_SIZE_BYTES = HKEY_SIZE // 8\n\n\nclass DuplicatedKeysError(Exception):\n\n  def __init__(self, item1, item2):\n    super(DuplicatedKeysError, self).__init__()\n    self.item1 = item1\n    self.item2 = item2\n\n\ndef _hkey_to_bytes(hkey):\n  """"""Converts 128 bits integer hkey to binary representation.""""""\n  max_int64 = 0xFFFFFFFFFFFFFFFF\n  return struct.pack(\'=QQ\', (hkey >> 64) & max_int64, hkey & max_int64)\n\n\ndef _read_hkey(buff):\n  """"""Reads from fobj and returns hkey (128 bites integer).""""""\n  a, b = struct.unpack(\'=QQ\', buff)\n  return (a << 64) | b\n\n\ndef get_bucket_number(hkey, shards_number):\n  """"""Returns bucket (shard) number (int) for given hashed key (int).""""""\n  # We purposely do not use modulo (%) to keep global order across shards.\n  # floor(key * shards_number / HKEYS_NUMBER), with HKEYS_NUMBER = 2**HKEY_SIZE.\n  return math.trunc((hkey * shards_number)>>HKEY_SIZE)\n\n\nclass _Bucket(object):\n  """"""Holds (key, binary value) tuples to disk, fast.\n\n  Bucket instances are designed to be used either:\n    1. Many buckets are written in parallel, then they are read one by one. When\n    reading, the data can be fully loaded in memory to be sorted.\n    This is how buckets are currently used in Shuffler.\n    2. Buckets are being written one at a time (or on different machines/jobs).\n    Before writing the data, it is sorted in memory. Many bucket are read in\n    parallel.\n    This is not currently used, but could be if we decide do parallelize the\n    writing of final sharded tfrecord files.\n\n  File format (assuming a key of 16 bytes):\n    key1 (16 bytes) | size1 (8 bytes) | data1 (size1 bytes) |\n    key2 (16 bytes) | size2 (8 bytes) | data2 (size2 bytes) |\n    ...\n  """"""\n\n  def __init__(self, path):\n    """"""Initialize a _Bucket instance.\n\n    Args:\n      path (str): path to bucket file, where to write to or read from.\n    """"""\n    self._path = path\n    self._fobj = None\n    self._length = 0\n    self._size = 0\n\n  @property\n  def size(self):\n    return self._size\n\n  def __len__(self):\n    return self._length\n\n  def add(self, key, data):\n    """"""Adds (key, data) to bucket.\n\n    Args:\n      key (int): the key.\n      data (binary): the data.\n    """"""\n    if not self._fobj:\n      tf.io.gfile.makedirs(os.path.dirname(self._path))\n      self._fobj = tf.io.gfile.GFile(self._path, mode=\'wb\')\n    data_size = len(data)\n    self._fobj.write(_hkey_to_bytes(key))\n    # http://docs.python.org/3/library/struct.html#byte-order-size-and-alignment\n    # The equal sign (""="") is important here, has it guarantees the standard\n    # size (Q: 8 bytes) is used, as opposed to native size, which can differ\n    # from one platform to the other. This way we know exactly 8 bytes have been\n    # written, and we can read that same amount of bytes later.\n    # We do not specify endianess (platform dependent), but this is OK since the\n    # temporary files are going to be written and read by the same platform.\n    self._fobj.write(struct.pack(\'=Q\', data_size))\n    self._fobj.write(data)\n    self._length += 1\n    self._size += data_size\n\n  def flush(self):\n    if self._fobj:\n      self._fobj.flush()\n      self._fobj.close()\n\n  def read_values(self):\n    """"""Yields (hkey, data) tuples stored in bucket.""""""\n    self.flush()\n    path = self._path\n    if not tf.io.gfile.exists(path):\n      # In case bucket was created but nothing was ever added.\n      # This is likely to happen if the number of buckets is large compared to\n      # the number of generated examples.\n      return\n    with tf.io.gfile.GFile(path, \'rb\') as fobj:\n      while True:\n        buff = fobj.read(HKEY_SIZE_BYTES)\n        if not buff:\n          break\n        hkey = _read_hkey(buff)\n        size_bytes = fobj.read(8)\n        size = struct.unpack(\'=Q\', size_bytes)[0]\n        data = fobj.read(size)\n        yield hkey, data\n\n  def del_file(self):\n    if tf.io.gfile.exists(self._path):\n      tf.io.gfile.remove(self._path)\n\n\nclass Shuffler(object):\n  """"""Stores data in temp buckets, restitute it shuffled.""""""\n\n  def __init__(self, dirpath, hash_salt):\n    """"""Initialize Shuffler.\n\n    Args:\n      dirpath (string): directory in which to store temporary files.\n      hash_salt (string or bytes): salt to hash keys.\n    """"""\n    grp_name = uuid.uuid4()\n    self._hasher = hashing.Hasher(hash_salt)\n    self._buckets = []\n    for i in range(BUCKETS_NUMBER):\n      path = os.path.join(dirpath, \'bucket_%s_%03d.tmp\' % (grp_name, i))\n      self._buckets.append(_Bucket(path))\n    self._read_only = False\n    self._total_bytes = 0\n    # To keep data in memory until enough data has been gathered.\n    self._in_memory = True\n    self._mem_buffer = []\n\n  @property\n  def size(self):\n    """"""Return total size in bytes of records (not keys).""""""\n    return self._total_bytes\n\n  @property\n  def bucket_lengths(self):\n    if self._in_memory:\n      return [len(self._mem_buffer)]\n    return [len(b) for b in self._buckets]\n\n  def _add_to_bucket(self, hkey, data):\n    bucket_number = get_bucket_number(hkey, BUCKETS_NUMBER)\n    self._buckets[bucket_number].add(hkey, data)\n\n  def _add_to_mem_buffer(self, hkey, data):\n    self._mem_buffer.append((hkey, data))\n    if self._total_bytes > MAX_MEM_BUFFER_SIZE:\n      for hkey, data  in self._mem_buffer:\n        self._add_to_bucket(hkey, data)\n      self._mem_buffer = None\n      self._in_memory = False\n\n  def add(self, key, data):\n    """"""Add (key, data) to shuffler.""""""\n    if self._read_only:\n      raise AssertionError(\'add() cannot be called after __iter__.\')\n    if not isinstance(data, six.binary_type):\n      raise AssertionError(\'Only bytes (not %s) can be stored in Shuffler!\' % (\n          type(data)))\n    hkey = self._hasher.hash_key(key)\n    self._total_bytes += len(data)\n    if self._in_memory:\n      self._add_to_mem_buffer(hkey, data)\n    else:\n      self._add_to_bucket(hkey, data)\n\n  def __iter__(self):\n    self._read_only = True\n    previous_hkey = None\n    previous_data = None\n    iterator = self._iter_mem() if self._in_memory else self._iter_buckets()\n    for hkey, data in iterator:\n      if hkey == previous_hkey:\n        raise DuplicatedKeysError(data, previous_data)\n      previous_hkey = hkey\n      yield data\n      previous_data = data\n\n  def _iter_mem(self):\n    for hkey, data in sorted(self._mem_buffer):\n      yield hkey, data\n\n  def _iter_buckets(self):\n    for bucket in self._buckets:\n      bucket_data = sorted(bucket.read_values())\n      bucket.del_file()\n      for hkey, data in bucket_data:\n        yield hkey, data\n'"
tensorflow_datasets/core/shuffle_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.shuffle.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nfrom absl.testing.absltest import mock\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import shuffle\n\n_ITEMS = [\n    (1, b\'The\'),\n    (2, b\'quick \'),\n    (3, b\'brown\'),\n    (4, b\' fox \'),\n    (5, b\'jumps\'),\n    (\'6\', b\'over\'),\n    (b\'7\', b\' the \'),\n    (8, b\'lazy\'),\n    (9, b\' dog.\'),\n]\n\n_ORDERED_ITEMS_SPLIT1 = [\n    b\' fox \',\n    b\'The\',\n    b\'over\',\n    b\'quick \',\n    b\'lazy\',\n    b\'jumps\',\n    b\' the \',\n    b\' dog.\',\n    b\'brown\',\n]\n\n_ORDERED_ITEMS_SPLIT2 = [\n    b\' dog.\',\n    b\'quick \',\n    b\'jumps\',\n    b\' fox \',\n    b\' the \',\n    b\'brown\',\n    b\'over\',\n    b\'lazy\',\n    b\'The\',\n]\n\n_TOTAL_SIZE = sum(len(rec) for rec in _ORDERED_ITEMS_SPLIT1)\n\n\nclass GetShardTest(testing.TestCase):\n\n  @mock.patch.object(shuffle, \'HKEY_SIZE\', 10)  # 1024 keys.\n  def test_order(self):\n    shards_number = 10\n    shards = [shuffle.get_bucket_number(k, shards_number) for k in range(1024)]\n    # Check max(shard_x) < min(shard_y) if x < y.\n    previous_shard = 0\n    for shard in shards:\n      self.assertGreaterEqual(shard, previous_shard)\n      previous_shard = shard\n    # Check distribution: all shards are used.\n    counts = collections.Counter(shards)\n    self.assertEqual(len(counts), shards_number)\n    # And all shards contain same number of elements (102 or 102 in that case).\n    self.assertEqual(len(set(counts.values())), 2)\n\n\nclass ShuffleTest(testing.TestCase):\n\n  def _test_items(self, salt, expected_order):\n    shuffler = shuffle.Shuffler(self.get_temp_dir(), salt)\n    for key, item in _ITEMS:\n      shuffler.add(key, item)\n    self.assertEqual(shuffler.size, _TOTAL_SIZE)\n    if not shuffler._in_memory:  # Check size of temporary bucket files\n      expected_size = (16 + 8) * len(_ITEMS) + sum(len(t[1]) for t in _ITEMS)\n      size = 0\n      for bucket in shuffler._buckets:\n        if not bucket._fobj:\n          continue\n        bucket._fobj.close()\n        size += len(open(bucket._path, \'rb\').read())\n      self.assertEqual(size, expected_size)\n    # Check records can be read as expected:\n    records = list(iter(shuffler))\n    self.assertEqual(records, expected_order)\n\n  def test_all_mem(self):\n    self._test_items(\'split1\', _ORDERED_ITEMS_SPLIT1)\n    self._test_items(\'split2\', _ORDERED_ITEMS_SPLIT2)\n\n  @mock.patch.object(shuffle, \'MAX_MEM_BUFFER_SIZE\', 0)\n  def test_disk(self):\n    self._test_items(\'split1\', _ORDERED_ITEMS_SPLIT1)\n    self._test_items(\'split2\', _ORDERED_ITEMS_SPLIT2)\n\n  def test_nonbytes(self):\n    shuffler = shuffle.Shuffler(self.get_temp_dir(), \'split1\')\n    with self.assertRaisesWithPredicateMatch(AssertionError, \'Only bytes\'):\n      shuffler.add(1, u\'a\')\n    with self.assertRaisesWithPredicateMatch(AssertionError, \'Only bytes\'):\n      shuffler.add(1, 123)\n\n  def test_duplicate_key(self):\n    shuffler = shuffle.Shuffler(self.get_temp_dir(), \'split1\')\n    shuffler.add(1, b\'a\')\n    shuffler.add(2, b\'b\')\n    shuffler.add(1, b\'c\')\n    iterator = iter(shuffler)\n    self.assertEqual(next(iterator), b\'a\')\n    with self.assertRaises(shuffle.DuplicatedKeysError):\n      next(iterator)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/splits.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Splits related API.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport typing\nfrom typing import List, Union\n\nfrom tensorflow_datasets.core import proto\nfrom tensorflow_datasets.core import tfrecords_reader\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import shard_utils\n\n\n@utils.as_proto_cls(proto.SplitInfo)\nclass SplitInfo(object):\n  """"""Wraps `proto.SplitInfo` with an additional property.""""""\n\n  @property\n  def num_examples(self) -> int:\n    if self.shard_lengths:  # pytype: disable=attribute-error\n      return sum(int(sl) for sl in self.shard_lengths)  # pytype: disable=attribute-error\n    return int(self.statistics.num_examples)  # pytype: disable=attribute-error\n\n  @property\n  def num_shards(self) -> int:\n    if self.shard_lengths:\n      return len(self.shard_lengths)\n    return self._ProtoCls__proto.num_shards\n\n  def __repr__(self) -> str:\n    num_examples = self.num_examples or ""unknown""\n    return ""<tfds.core.SplitInfo num_examples=%s>"" % str(num_examples)\n\n  @property\n  def file_instructions(self) -> List[shard_utils.FileInstruction]:\n    """"""Returns the list of dict(filename, take, skip).\n\n    This allows for creating your own `tf.data.Dataset` using the low-level\n    TFDS values.\n\n    Example:\n\n    ```\n    file_instructions = info.splits[\'train[75%:]\'].file_instructions\n    instruction_ds = tf.data.Dataset.from_generator(\n        lambda: file_instructions,\n        output_types={\n            \'filename\': tf.string,\n            \'take\': tf.int64,\n            \'skip\': tf.int64,\n        },\n    )\n    ds = instruction_ds.interleave(\n        lambda f: tf.data.TFRecordDataset(\n            f[\'filename\']).skip(f[\'skip\']).take(f[\'take\'])\n    )\n    ```\n\n    When `skip=0` and `take=-1`, the full shard will be read, so the `ds.skip`\n    and `ds.take` could be skipped.\n\n    Returns:\n      A `dict(filename, take, skip)`\n    """"""\n    # `self._dataset_name` is assigned in `SplitDict.add()`.\n    return tfrecords_reader.make_file_instructions(\n        name=self._dataset_name,\n        split_infos=[self],\n        instruction=str(self.name),\n    )\n\n  @property\n  def filenames(self) -> List[str]:\n    """"""Returns the list of filenames.""""""\n    return sorted(f.filename for f in self.file_instructions)\n\n\nclass SubSplitInfo(object):\n  """"""Wrapper around a sub split info.\n\n  This class expose info on the subsplit:\n\n  ```\n  ds, info = tfds.load(..., split=\'train[75%:]\', with_info=True)\n  info.splits[\'train[75%:]\'].num_examples\n  ```\n\n  """"""\n\n  def __init__(self, file_instructions: List[shard_utils.FileInstruction]):\n    """"""Constructor.\n\n    Args:\n      file_instructions: List[FileInstruction]\n    """"""\n    self._file_instructions = file_instructions\n\n  @property\n  def num_examples(self) -> int:\n    """"""Returns the number of example in the subsplit.""""""\n    return sum(f.num_examples for f in self._file_instructions)\n\n  @property\n  def file_instructions(self) -> List[shard_utils.FileInstruction]:\n    """"""Returns the list of dict(filename, take, skip).""""""\n    return self._file_instructions\n\n  @property\n  def filenames(self) -> List[str]:\n    """"""Returns the list of filenames.""""""\n    return sorted(f.filename for f in self.file_instructions)\n\n\n# TODO(epot): `: tfds.Split` type should be `Union[str, Split]`\nclass Split(str):\n  # pylint: disable=line-too-long\n  """"""`Enum` for dataset splits.\n\n  Datasets are typically split into different subsets to be used at various\n  stages of training and evaluation.\n\n  * `TRAIN`: the training data.\n  * `VALIDATION`: the validation data. If present, this is typically used as\n    evaluation data while iterating on a model (e.g. changing hyperparameters,\n    model architecture, etc.).\n  * `TEST`: the testing data. This is the data to report metrics on. Typically\n    you do not want to use this during model iteration as you may overfit to it.\n\n  See the\n  [guide on splits](https://github.com/tensorflow/datasets/tree/master/docs/splits.md)\n  for more information.\n  """"""\n\n  def __repr__(self) -> str:\n    return ""{}({})"".format(type(self).__name__, super(Split, self).__repr__())  # pytype: disable=wrong-arg-types\n\n\nSplit.TRAIN = Split(""train"")\nSplit.TEST = Split(""test"")\nSplit.VALIDATION = Split(""validation"")\n\nif typing.TYPE_CHECKING:\n  # For type checking, `tfds.Split` is an alias for `str` with additional\n  # `.TRAIN`, `.TEST`,... attributes. All strings are valid split type.\n  Split = Union[Split, str]\n\n\nclass SplitDict(utils.NonMutableDict):\n  """"""Split info object.""""""\n\n  def __init__(self, dataset_name):\n    super(SplitDict, self).__init__(error_msg=""Split {key} already present"")\n    self._dataset_name = dataset_name\n\n  def __getitem__(self, key):\n    # 1st case: The key exists: `info.splits[\'train\']`\n    if str(key) in self:\n      return super(SplitDict, self).__getitem__(str(key))\n    # 2nd case: Uses instructions: `info.splits[\'train[50%]\']`\n    else:\n      instructions = tfrecords_reader.make_file_instructions(\n          name=self._dataset_name,\n          split_infos=self.values(),\n          instruction=key,\n      )\n      return SubSplitInfo(instructions)\n\n  def __setitem__(self, key, value):\n    raise ValueError(""Cannot add elem. Use .add() instead."")\n\n  def add(self, split_info):\n    """"""Add the split info.""""""\n    if split_info.name in self:\n      raise ValueError(""Split {} already present"".format(split_info.name))\n    # Forward the dataset name required to build file instructions:\n    # info.splits[\'train\'].file_instructions\n    # Use `object.__setattr__`, because ProtoCls forbid new fields assignement.\n    object.__setattr__(split_info, ""_dataset_name"", self._dataset_name)\n    super(SplitDict, self).__setitem__(split_info.name, split_info)\n\n  @classmethod\n  def from_proto(cls, dataset_name, repeated_split_infos):\n    """"""Returns a new SplitDict initialized from the `repeated_split_infos`.""""""\n    split_dict = cls(dataset_name)\n    for split_info_proto in repeated_split_infos:\n      split_info = SplitInfo()\n      split_info.CopyFrom(split_info_proto)\n      split_dict.add(split_info)\n    return split_dict\n\n  def to_proto(self):\n    """"""Returns a list of SplitInfo protos that we have.""""""\n    # Return the proto.SplitInfo, sorted by name\n    return sorted((s.get_proto() for s in self.values()), key=lambda s: s.name)\n\n  @property\n  def total_num_examples(self):\n    """"""Return the total number of examples.""""""\n    return sum(s.num_examples for s in self.values())\n\n  def copy(self):\n    return SplitDict.from_proto(self._dataset_name, self.to_proto())\n\n\ndef check_splits_equals(splits1, splits2):\n  """"""Check two split dicts have same name, shard_lengths and num_shards.""""""\n  if set(splits1) ^ set(splits2):  # Name intersection should be null\n    return False\n  for _, (split1, split2) in utils.zip_dict(splits1, splits2):\n    if (split1.num_shards != split2.num_shards or\n        split1.shard_lengths != split2.shard_lengths):\n      return False\n  return True\n\n\nclass SplitGenerator(object):\n  """"""Defines the split information for the generator.\n\n  This should be used as returned value of\n  `GeneratorBasedBuilder._split_generators`.\n  See `GeneratorBasedBuilder._split_generators` for more info and example\n  of usage.\n  """"""\n\n  def __init__(self, name, gen_kwargs=None):\n    """"""Constructs a `SplitGenerator`.\n\n    Args:\n      name: `str`, name of the Split for which the generator will\n        create the examples.\n      gen_kwargs: `dict`, kwargs to forward to the _generate_examples() method\n        of the builder.\n    """"""\n    self.name = name\n    self.gen_kwargs = gen_kwargs or {}\n    self.split_info = SplitInfo(name=str(name))\n'"
tensorflow_datasets/core/splits_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the Split API.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import proto\nfrom tensorflow_datasets.core import splits\nfrom tensorflow_datasets.core.utils import shard_utils\nimport tensorflow_datasets.public_api as tfds\n\nRANGE_TRAIN = list(range(0, 2000))\nRANGE_TEST = list(range(3000, 3200))\nRANGE_VAL = list(range(6000, 6010))\n\n\nclass SplitDictTest(testing.TestCase):\n\n  def test_num_shards(self):\n    sd = splits.SplitDict(""ds_name"")\n    sd.add(tfds.core.SplitInfo(name=""train"", shard_lengths=[1, 2, 3]))\n    self.assertEqual(sd[""train""].num_shards, 3)\n\n    # When both values are set, shard_lengths has priority.\n    sd = splits.SplitDict(""ds_name"")\n    sd.add(tfds.core.SplitInfo(name=""train"", num_shards=3, shard_lengths=[1,]))\n    self.assertEqual(sd[""train""].num_shards, 1)\n\n    # With legacy mode, use legacy value\n    sd = splits.SplitDict(""ds_name"")\n    sd.add(tfds.core.SplitInfo(name=""train"", num_shards=3))\n    self.assertEqual(sd[""train""].num_shards, 3)\n\n\nclass SplitsDictTest(testing.TestCase):\n\n  @property\n  def split_dict(self):\n    sd = splits.SplitDict(""ds_name"")\n    sd.add(tfds.core.SplitInfo(name=""train"", num_shards=10))\n    sd.add(tfds.core.SplitInfo(name=""test"", num_shards=1))\n    return sd\n\n  # .add is implicitly tested, since s was created by calling .add\n  def test_get(self):\n    s = self.split_dict[""train""]\n    self.assertEqual(""train"", s.name)\n    self.assertEqual(10, s.num_shards)\n\n  def test_from_proto(self):\n    sd = splits.SplitDict.from_proto(\n        ""ds_name"", [proto.SplitInfo(name=""validation"", num_shards=5)])\n    self.assertIn(""validation"", sd)\n    self.assertNotIn(""train"", sd)\n    self.assertNotIn(""test"", sd)\n\n  def test_to_proto(self):\n    sd = self.split_dict\n    sdp = sd.to_proto()\n\n    self.assertEqual(""test"", sdp[0].name)\n    self.assertEqual(1, sdp[0].num_shards)\n\n    self.assertEqual(""train"", sdp[1].name)\n    self.assertEqual(10, sdp[1].num_shards)\n\n  def test_bool(self):\n    sd = splits.SplitDict(""ds_name"")\n    self.assertFalse(sd)  # Empty split is False\n    sd.add(tfds.core.SplitInfo(name=""train"", num_shards=10))\n    self.assertTrue(sd)  # Non-empty split is True\n\n  def test_check_splits_equals(self):\n    s1 = splits.SplitDict(""ds_name"")\n    s1.add(tfds.core.SplitInfo(name=""train"", num_shards=10))\n    s1.add(tfds.core.SplitInfo(name=""test"", num_shards=3))\n\n    s2 = splits.SplitDict(""ds_name"")\n    s2.add(tfds.core.SplitInfo(name=""train"", num_shards=10))\n    s2.add(tfds.core.SplitInfo(name=""test"", num_shards=3))\n\n    s3 = splits.SplitDict(""ds_name"")\n    s3.add(tfds.core.SplitInfo(name=""train"", num_shards=10))\n    s3.add(tfds.core.SplitInfo(name=""test"", num_shards=3))\n    s3.add(tfds.core.SplitInfo(name=""valid"", num_shards=0))\n\n    s4 = splits.SplitDict(""ds_name"")\n    s4.add(tfds.core.SplitInfo(name=""train"", num_shards=11))\n    s4.add(tfds.core.SplitInfo(name=""test"", num_shards=3))\n\n    self.assertTrue(splits.check_splits_equals(s1, s1))\n    self.assertTrue(splits.check_splits_equals(s1, s2))\n    self.assertFalse(splits.check_splits_equals(s1, s3))  # Not same names\n    self.assertFalse(splits.check_splits_equals(s1, s4))  # Nb of shards !=\n\n  def test_split_overwrite(self):\n    s1 = splits.SplitDict(""ds_name"")\n    s1.add(tfds.core.SplitInfo(name=""train"", shard_lengths=[15]))\n\n    s2 = splits.SplitDict(""ds_name"")\n    s2.add(tfds.core.SplitInfo(name=""train"", shard_lengths=[15]))\n\n    self.assertTrue(splits.check_splits_equals(s1, s2))\n\n    # Modifying num_shards should also modify the underlying proto\n    s2[""train""].shard_lengths = [5, 5, 5]\n    self.assertEqual(s2[""train""].shard_lengths, [5, 5, 5])\n    self.assertEqual(s2[""train""].get_proto().shard_lengths, [5, 5, 5])\n    self.assertFalse(splits.check_splits_equals(s1, s2))\n\n\nclass SplitsTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(SplitsTest, cls).setUpClass()\n    dataset_builder._is_py2_download_and_prepare_disabled = False\n    cls._builder = testing.DummyDatasetSharedGenerator(\n        data_dir=testing.make_tmp_dir())\n    cls._builder.download_and_prepare()\n\n  def test_sub_split_num_examples(self):\n    s = self._builder.info.splits\n    self.assertEqual(s[""train[75%:]""].num_examples, 5)\n    self.assertEqual(s[""train[:75%]""].num_examples, 15)\n    self.assertEqual(\n        s[""train""].num_examples,\n        s[""train[75%:]""].num_examples + s[""train[:75%]""].num_examples,\n    )\n\n    self.assertEqual(s[""test[75%:]""].num_examples, 2)\n    self.assertEqual(s[""test[:75%]""].num_examples, 8)\n    self.assertEqual(\n        s[""test""].num_examples,\n        s[""test[75%:]""].num_examples + s[""test[:75%]""].num_examples,\n    )\n\n  def test_sub_split_file_instructions(self):\n    fi = self._builder.info.splits[""train[75%:]""].file_instructions\n    self.assertEqual(fi, [shard_utils.FileInstruction(\n        filename=""dummy_dataset_shared_generator-train.tfrecord-00000-of-00001"",\n        skip=15,\n        take=-1,\n        num_examples=5,\n    )])\n\n  def test_split_file_instructions(self):\n    fi = self._builder.info.splits[""train""].file_instructions\n    self.assertEqual(fi, [shard_utils.FileInstruction(\n        filename=""dummy_dataset_shared_generator-train.tfrecord-00000-of-00001"",\n        skip=0,\n        take=-1,\n        num_examples=20,\n    )])\n\n  def test_sub_split_filenames(self):\n    self.assertEqual(self._builder.info.splits[""train""].filenames, [\n        ""dummy_dataset_shared_generator-train.tfrecord-00000-of-00001"",\n    ])\n    self.assertEqual(self._builder.info.splits[""train[75%:]""].filenames, [\n        ""dummy_dataset_shared_generator-train.tfrecord-00000-of-00001"",\n    ])\n\n  def test_sub_split_wrong_key(self):\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, ""Unknown split \\""unknown\\""""):\n      _ = self._builder.info.splits[""unknown""]\n\n  def test_split_enum(self):\n    self.assertEqual(repr(splits.Split.TRAIN), ""Split(\'train\')"")\n    self.assertIsInstance(splits.Split.TRAIN, splits.Split)\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/tf_compat.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TensorFlow compatibility utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=g-import-not-at-top,g-direct-tensorflow-import\n\nimport distutils.version\n\nfrom absl import logging\nimport six\n\n\n_ensure_tf_install_called = False\n\n\n# Ensure TensorFlow is importable and its version is sufficiently recent. This\n# needs to happen before anything else, since the imports below will try to\n# import tensorflow, too.\ndef ensure_tf_install():  # pylint: disable=g-statement-before-imports\n  """"""Attempt to import tensorflow, and ensure its version is sufficient.\n\n  Raises:\n    ImportError: if either tensorflow is not importable or its version is\n    inadequate.\n  """"""\n  # Only check the first time.\n  global _ensure_tf_install_called\n  if _ensure_tf_install_called:\n    return\n  _ensure_tf_install_called = True\n\n  try:\n    import tensorflow.compat.v2 as tf  # pylint: disable=import-outside-toplevel\n  except ImportError:\n    # Print more informative error message, then reraise.\n    print(""\\n\\nFailed to import TensorFlow. Please note that TensorFlow is not ""\n          ""installed by default when you install TensorFlow Datasets. This is ""\n          ""so that users can decide whether to install the GPU-enabled ""\n          ""TensorFlow package. To use TensorFlow Datasets, please install the ""\n          ""most recent version of TensorFlow, by following instructions at ""\n          ""https://tensorflow.org/install.\\n\\n"")\n    raise\n\n  tf_version = distutils.version.LooseVersion(tf.__version__)\n  v_1_15 = distutils.version.LooseVersion(""1.15.0"")\n  if tf_version < v_1_15:\n    raise ImportError(\n        ""This version of TensorFlow Datasets requires TensorFlow ""\n        ""version >= {required}; Detected an installation of version {present}. ""\n        ""Please upgrade TensorFlow to proceed."".format(\n            required=""1.15.0"",\n            present=tf.__version__))\n\n  if six.PY2:\n    logging.warning(""TFDS is going to drop Python 2 support. Please ""\n                    ""update to Python 3."")\n\n\ndef is_dataset(ds):\n  """"""Whether ds is a Dataset. Compatible across TF versions.""""""\n  import tensorflow.compat.v2 as tf  # pylint: disable=import-outside-toplevel\n  return isinstance(ds, (tf.data.Dataset, tf.compat.v1.data.Dataset))\n'"
tensorflow_datasets/core/tfrecords_reader.py,22,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Defined Reader and ReadInstruction to read tfrecord files.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport math\nimport os\nimport re\nfrom typing import Any, Callable, Dict, Iterable, List, Sequence, Union\n\nimport attr\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import example_parser\nfrom tensorflow_datasets.core import naming\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import read_config as read_config_lib\nfrom tensorflow_datasets.core.utils import shard_utils\n\nSplitInfo = Any\n\n# Should be: Callable[[Tensor], Nested[Tensor]]\nParseFn = Callable[[Any], Any]\n\n\n_BUFFER_SIZE = 8<<20  # 8 MiB per file.\n\n_SUB_SPEC_RE = re.compile(r\'\'\'\n^\n (?P<split>\\w+)\n (\\[\n  ((?P<from>-?\\d+)\n   (?P<from_pct>%)?)?\n  :\n  ((?P<to>-?\\d+)\n   (?P<to_pct>%)?)?\n \\])?\n$\n\'\'\', re.X)\n\n_ADDITION_SEP_RE = re.compile(r\'\\s*\\+\\s*\')\n\n\ndef _get_dataset_from_filename(filename_skip_take, do_skip, do_take):\n  """"""Returns a tf.data.Dataset instance from given (filename, skip, take).""""""\n  filename, skip, take = (filename_skip_take[\'filename\'],\n                          filename_skip_take[\'skip\'],\n                          filename_skip_take[\'take\'],)\n\n  # Explictly use DatasetV1 for backward compatibility:\n  # * isinstance(ds, tf.data.Dataset)\n  # * ds.make_one_shot_iterator()\n  ds = tf.data.TFRecordDataset(filename, buffer_size=_BUFFER_SIZE)\n  if do_skip:\n    ds = ds.skip(skip)\n  if do_take:\n    ds = ds.take(take)\n  return ds\n\n\ndef make_file_instructions(\n    name: str,\n    split_infos: Iterable[SplitInfo],\n    instruction: Union[\'ReadInstruction\', str],\n) -> List[shard_utils.FileInstruction]:\n  """"""Returns instructions of the split dict.\n\n  Args:\n    name: Name of the dataset.\n    split_infos: Dataset splits information\n    instruction: `ReadInstruction` or `str`\n\n  Returns:\n    file_intructions: FileInstructions instance\n  """"""\n  name2shard_lengths = {\n      info.name: info.shard_lengths for info in split_infos\n  }\n  name2len = {\n      name: sum(lengths) for name, lengths in name2shard_lengths.items()\n  }\n  if not isinstance(instruction, ReadInstruction):\n    instruction = ReadInstruction.from_spec(instruction)\n  # Create the absolute instruction (per split)\n  absolute_instructions = instruction.to_absolute(name2len)\n\n  return _make_file_instructions_from_absolutes(\n      name=name,\n      name2shard_lengths=name2shard_lengths,\n      absolute_instructions=absolute_instructions,\n  )\n\n\ndef _make_file_instructions_from_absolutes(\n    name: str,\n    name2shard_lengths: Dict[str, List[int]],\n    absolute_instructions: \'ReadInstruction\',\n) -> List[shard_utils.FileInstruction]:\n  """"""Returns the files instructions from the absolute instructions list.""""""\n  # For each split, return the files instruction (skip/take)\n  file_instructions = []\n  for abs_instr in absolute_instructions:\n    shard_lengths = name2shard_lengths[abs_instr.splitname]\n    if not shard_lengths:\n      raise ValueError(\n          \'Shard empty. This might means that dataset hasn\\\'t been generated \'\n          \'yet and info not restored from GCS, or that legacy dataset is used.\')\n    filenames = naming.filenames_for_dataset_split(\n        dataset_name=name,\n        split=abs_instr.splitname,\n        num_shards=len(shard_lengths),\n        filetype_suffix=\'tfrecord\')\n    from_ = 0 if abs_instr.from_ is None else abs_instr.from_\n    to = sum(shard_lengths) if abs_instr.to is None else abs_instr.to\n    single_file_instructions = shard_utils.get_file_instructions(\n        from_, to, filenames, shard_lengths)\n    file_instructions.extend(single_file_instructions)\n  return file_instructions\n\n\ndef _read_files(\n    file_instructions: Sequence[shard_utils.FileInstruction],\n    parse_fn: ParseFn,\n    read_config: read_config_lib.ReadConfig,\n    shuffle_files: bool,\n) -> tf.data.Dataset:\n  """"""Returns tf.data.Dataset for given file instructions.\n\n  Args:\n    file_instructions: the information on the files to read including\n      `ds.skip().take()`\n    parse_fn: function used to parse each record.\n    read_config: Additional options to configure the\n      input pipeline (e.g. seed, num parallel reads,...).\n    shuffle_files: Defaults to False. True to shuffle input files.\n\n  Returns:\n    The dataset object.\n  """"""\n  # Eventually apply a transformation to the instruction function.\n  # This allow the user to have direct control over the interleave order.\n  if read_config.experimental_interleave_sort_fn is not None:\n    file_instructions = read_config.experimental_interleave_sort_fn(\n        file_instructions)\n\n  do_skip = any(f.skip > 0 for f in file_instructions)\n  do_take = any(f.take > -1 for f in file_instructions)\n\n  # Transpose the list[dict] into dict[list]\n  tensor_inputs = {\n      # skip/take need to be converted to int64 explicitly\n      k: list(vals) if k == \'filename\' else np.array(vals, dtype=np.int64)\n      for k, vals in utils.zip_dict(*[f.asdict() for f in file_instructions])\n  }\n\n  cycle_length = read_config.interleave_cycle_length\n  block_length = read_config.interleave_block_length\n\n  instruction_ds = tf.data.Dataset.from_tensor_slices(tensor_inputs)\n\n  # On distributed environement, we can shard per-file if a\n  # `tf.distribute.InputContext` object is provided (e.g. from\n  # `experimental_distribute_datasets_from_function`)\n  if (read_config.input_context and\n      read_config.input_context.num_input_pipelines > 1):\n    if len(file_instructions) < read_config.input_context.num_input_pipelines:\n      raise ValueError(\n          \'Cannot shard the pipeline with given `input_context`.\'\n          \'`num_shards={}` but `num_input_pipelines={}`. \'\n          \'This means that some workers won\\\'t read any data. \'\n          \'To shard the data, you may want to use the subsplit API \'\n          \'instead: https://www.tensorflow.org/datasets/splits\'.format(\n              len(file_instructions),\n              read_config.input_context.num_input_pipelines)\n      )\n    instruction_ds = instruction_ds.shard(\n        num_shards=read_config.input_context.num_input_pipelines,\n        index=read_config.input_context.input_pipeline_id,\n    )\n\n  # If shuffle is True, we shuffle the instructions/shards\n  if shuffle_files:\n    instruction_ds = instruction_ds.shuffle(\n        len(file_instructions),\n        seed=read_config.shuffle_seed,\n        reshuffle_each_iteration=read_config.shuffle_reshuffle_each_iteration,\n    )\n\n  ds = instruction_ds.interleave(\n      functools.partial(_get_dataset_from_filename,\n                        do_skip=do_skip, do_take=do_take),\n      cycle_length=cycle_length,\n      block_length=block_length,\n      num_parallel_calls=tf.data.experimental.AUTOTUNE,\n  )\n\n  # If the number of examples read in the tf-record is known, we forward\n  # the information to the tf.data.Dataset object.\n  # Check the `tf.data.experimental` for backward compatibility with TF <= 2.1\n  if (not read_config.input_context and  # TODO(epot): Restore cardinality\n      hasattr(tf.data.experimental, \'assert_cardinality\')):\n    # TODO(b/154963426): Replace by per-shard cardinality (warning if\n    # `experimental_interleave_sort_fn` is set).\n    cardinality = sum(f.num_examples for f in file_instructions)\n    ds = ds.apply(tf.data.experimental.assert_cardinality(cardinality))\n\n  ds = ds.with_options(read_config.options)  # Additional users options\n\n  # TODO(pierrot): `parse_example` uses\n  # `tf.io.parse_single_example`. It might be faster to use `parse_example`,\n  # after batching.\n  # https://www.tensorflow.org/api_docs/python/tf/io/parse_example\n  return ds.map(parse_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n\nclass Reader(object):\n  """"""Build a tf.data.Dataset object out of Instruction instance(s).\n\n  This class should not typically be exposed to the TFDS user.\n  """"""\n\n  def __init__(self, path, example_specs):\n    """"""Initializes Reader.\n\n    Args:\n      path (str): path where tfrecords are stored.\n      example_specs: spec to build ExampleParser.\n    """"""\n    self._path = path\n    self._parser = example_parser.ExampleParser(example_specs)\n\n  def read(\n      self,\n      name,\n      instructions,\n      split_infos,\n      read_config,\n      shuffle_files,\n  ):\n    """"""Returns tf.data.Dataset instance(s).\n\n    Args:\n      name (str): name of the dataset.\n      instructions (ReadInstruction, List[], Dict[]): instruction(s) to read.\n        Instructions can be string and will then be passed to the Instruction\n        constructor as it.\n      split_infos (list of SplitInfo proto): the available splits for dataset.\n      read_config: `tfds.ReadConfig`, the input pipeline options\n      shuffle_files (bool): If True, input files are shuffled before being read.\n\n    Returns:\n       a single tf.data.Dataset instance if instruction is a single\n       ReadInstruction instance. Otherwise a dict/list of tf.data.Dataset\n       corresponding to given instructions param shape.\n    """"""\n    def _read_instruction_to_ds(instruction):\n      file_instructions = make_file_instructions(name, split_infos, instruction)\n      return self.read_files(\n          file_instructions,\n          read_config=read_config,\n          shuffle_files=shuffle_files,\n      )\n\n    return tf.nest.map_structure(_read_instruction_to_ds, instructions)\n\n  def read_files(\n      self,\n      file_instructions: Sequence[shard_utils.FileInstruction],\n      read_config: read_config_lib.ReadConfig,\n      shuffle_files: bool,\n  ) -> tf.data.Dataset:\n    """"""Returns single tf.data.Dataset instance for the set of file instructions.\n\n    Args:\n      file_instructions: The files information.\n        The filenames contains the relative path, not absolute.\n        skip/take indicates which example read in the shard: `ds.skip().take()`\n      read_config: The input pipeline options\n      shuffle_files: If True, input files are shuffled before being read.\n\n    Returns:\n       a tf.data.Dataset instance.\n    """"""\n    if not file_instructions:\n      msg = \'Instruction {} corresponds to no data!\'.format(\n          file_instructions)\n      raise AssertionError(msg)\n\n    # Prepend path to filename\n    file_instructions = [\n        f.replace(filename=os.path.join(self._path, f.filename))\n        for f in file_instructions\n    ]\n    ds = _read_files(\n        file_instructions=file_instructions,\n        read_config=read_config,\n        parse_fn=self._parser.parse_example,\n        shuffle_files=shuffle_files,\n    )\n    return ds\n\n\n@attr.s(frozen=True)\nclass _AbsoluteInstruction(object):\n  """"""A machine friendly slice: defined absolute positive boundaries.""""""\n  splitname = attr.ib()  # : str\n  from_ = attr.ib()  # uint (starting index).\n  to = attr.ib()  # uint (ending index).\n\n\n@attr.s(frozen=True)\nclass _RelativeInstruction(object):\n  """"""Represents a single parsed slicing instruction, can use % and negatives.""""""\n  splitname = attr.ib()  # : str\n  # starting index, or None if no lower boundary.\n  from_ = attr.ib()  # : Optional[int]\n  # ending index, or None if no upper boundary.\n  to = attr.ib()  # : Optional[int]\n  unit = attr.ib(validator=attr.validators.in_([\'%\', \'abs\']))  # : str\n  rounding = attr.ib(validator=attr.validators.in_([  # : str\n      \'closest\', \'pct1_dropremainder\']))\n\n  @from_.validator\n  @to.validator\n  def check_boundary_pct(self, unused_attribute, value):\n    if self.unit == \'%\' and value is not None and abs(value) > 100:\n      raise AssertionError(\'Percent slice boundaries must be > -100 and < 100.\')\n\n\ndef _str_to_relative_instruction(spec):\n  """"""Returns ReadInstruction for given string.""""""\n  res = _SUB_SPEC_RE.match(spec)\n  if not res:\n    raise AssertionError(\'Unrecognized instruction format: %s\' % spec)\n  unit = \'%\' if res.group(\'from_pct\') or res.group(\'to_pct\') else \'abs\'\n  return ReadInstruction(\n      split_name=res.group(\'split\'),\n      rounding=\'closest\',\n      from_=int(res.group(\'from\')) if res.group(\'from\') else None,\n      to=int(res.group(\'to\')) if res.group(\'to\') else None,\n      unit=unit,\n      )\n\n\ndef _pct_to_abs_pct1(boundary, num_examples):\n  # Using math.trunc here, since -99.5% should give -99%, not -100%.\n  if num_examples < 100:\n    msg = (\'Using ""pct1_dropremainder"" rounding on a split with less than 100 \'\n           \'elements is forbidden: it always results in an empty dataset.\')\n    raise AssertionError(msg)\n  return boundary * math.trunc(num_examples / 100.)\n\n\ndef _pct_to_abs_closest(boundary, num_examples):\n  return int(round(boundary * num_examples / 100.))\n\n\ndef _rel_to_abs_instr(rel_instr, name2len):\n  """"""Returns _AbsoluteInstruction instance for given RelativeInstruction.\n\n  Args:\n    rel_instr: RelativeInstruction instance.\n    name2len: dict {split_name: num_examples}.\n  """"""\n  pct_to_abs = (_pct_to_abs_closest if rel_instr.rounding == \'closest\'\n                else _pct_to_abs_pct1)\n  split = rel_instr.splitname\n  if split not in name2len:\n    raise ValueError(\'Unknown split ""{}"". Should be one of {}.\'.format(\n        split, list(name2len)))\n  num_examples = name2len[split]\n  from_ = rel_instr.from_\n  to = rel_instr.to\n  if rel_instr.unit == \'%\':\n    from_ = 0 if from_ is None else pct_to_abs(from_, num_examples)\n    to = num_examples if to is None else pct_to_abs(to, num_examples)\n  else:\n    from_ = 0 if from_ is None else from_\n    to = num_examples if to is None else to\n  if abs(from_) > num_examples or abs(to) > num_examples:\n    msg = \'Requested slice [%s:%s] incompatible with %s examples.\' % (\n        from_ or \'\', to or \'\', num_examples)\n    raise AssertionError(msg)\n  if from_ < 0:\n    from_ = num_examples + from_\n  elif from_ == 0:\n    from_ = None\n  if to < 0:\n    to = num_examples + to\n  elif to == num_examples:\n    to = None\n  return _AbsoluteInstruction(split, from_, to)\n\n\nclass ReadInstruction(object):\n  """"""Reading instruction for a dataset.\n\n  Examples of usage:\n\n  ```\n  # The following lines are equivalent:\n  ds = tfds.load(\'mnist\', split=\'test[:33%]\')\n  ds = tfds.load(\'mnist\', split=tfds.core.ReadInstruction.from_spec(\n      \'test[:33%]\'))\n  ds = tfds.load(\'mnist\', split=tfds.core.ReadInstruction(\n      \'test\', to=33, unit=\'%\'))\n  ds = tfds.load(\'mnist\', split=tfds.core.ReadInstruction(\n      \'test\', from_=0, to=33, unit=\'%\'))\n\n  # The following lines are equivalent:\n  ds = tfds.load(\'mnist\', split=\'test[:33%]+train[1:-1]\')\n  ds = tfds.load(\'mnist\', split=tfds.core.ReadInstruction.from_spec(\n      \'test[:33%]+train[1:-1]\'))\n  ds = tfds.load(\'mnist\', split=(\n      tfds.core.ReadInstruction(\'test\', to=33, unit=\'%\') +\n      tfds.core.ReadInstruction(\'train\', from_=1, to=-1, unit=\'abs\')))\n\n  # 10-fold validation:\n  tests = tfds.load(\n      \'mnist\',\n      [tfds.core.ReadInstruction(\'train\', from_=k, to=k+10, unit=\'%\')\n       for k in range(0, 100, 10)])\n  trains = tfds.load(\n      \'mnist\',\n      [tfds.core.ReadInstruction(\'train\', to=k, unit=\'%\') +\n       tfds.core.ReadInstruction(\'train\', from_=k+10, unit=\'%\')\n       for k in range(0, 100, 10)])\n  ```\n\n  """"""\n\n  def _init(self, relative_instructions):\n    # Private initializer.\n    self._relative_instructions = relative_instructions\n\n  @classmethod\n  def _read_instruction_from_relative_instructions(cls, relative_instructions):\n    """"""Returns ReadInstruction obj initialized with relative_instructions.""""""\n    # Use __new__ to bypass __init__ used by public API and not conveniant here.\n    result = cls.__new__(cls)\n    result._init(relative_instructions)  # pylint: disable=protected-access\n    return result\n\n  @api_utils.disallow_positional_args(allowed=[\'split_name\'])\n  def __init__(\n      self,\n      split_name,\n      rounding=\'closest\',\n      from_=None,\n      to=None,\n      unit=None,\n  ):\n    """"""Initialize ReadInstruction.\n\n    Args:\n      split_name (str): name of the split to read. Eg: \'train\'.\n      rounding (str): The rounding behaviour to use when percent slicing is\n        used. Ignored when slicing with absolute indices.\n        Possible values:\n         - \'closest\' (default): The specified percentages are rounded to the\n           closest value. Use this if you want specified percents to be as\n           much exact as possible.\n         - \'pct1_dropremainder\': the specified percentages are treated as\n           multiple of 1%. Use this option if you want consistency. Eg:\n             len(5%) == 5 * len(1%).\n           Using this option, one might not be able to use the full set of\n           examples, if the number of those is not a multiple of 100.\n      from_ (int):\n      to (int): alternative way of specifying slicing boundaries. If any of\n        {from_, to, unit} argument is used, slicing cannot be specified as\n        string.\n      unit (str): optional, one of:\n        \'%\': to set the slicing unit as percents of the split size.\n        \'abs\': to set the slicing unit as absolute numbers.\n    """"""\n    # Unit is optional only if the full dataset is read, otherwise, will\n    # `_RelativeInstruction` validator will fail.\n    if from_ is None and to is None and unit is None:\n      unit = \'%\'\n    # This constructor is not always called. See factory method\n    # `_read_instruction_from_relative_instructions`. Common init instructions\n    # MUST be placed in the _init method.\n    self._init(\n        [_RelativeInstruction(split_name, from_, to, unit, rounding)])\n\n  @classmethod\n  def from_spec(cls, spec):\n    """"""Creates a ReadInstruction instance out of a string spec.\n\n    Args:\n      spec (str): split(s) + optional slice(s) to read. A slice can be\n            specified, using absolute numbers (int) or percentages (int). E.g.\n              `test`: test split.\n              `test + validation`: test split + validation split.\n              `test[10:]`: test split, minus its first 10 records.\n              `test[:10%]`: first 10% records of test split.\n              `test[:-5%]+train[40%:60%]`: first 95% of test + middle 20% of\n                                           train.\n\n    Returns:\n      ReadInstruction instance.\n    """"""\n    spec = str(spec)  # Need to convert to str in case of `Split` instance.\n    subs = _ADDITION_SEP_RE.split(spec)\n    if not subs:\n      raise AssertionError(\'No instructions could be built out of %s\' % spec)\n    instruction = _str_to_relative_instruction(subs[0])\n    return sum([_str_to_relative_instruction(sub) for sub in subs[1:]],\n               instruction)\n\n  def __add__(self, other):\n    """"""Returns a new ReadInstruction obj, result of appending other to self.""""""\n    if not isinstance(other, ReadInstruction):\n      msg = \'ReadInstruction can only be added to another ReadInstruction obj.\'\n      raise AssertionError(msg)\n    other_ris = other._relative_instructions  # pylint: disable=protected-access\n    if self._relative_instructions[0].rounding != other_ris[0].rounding:\n      raise AssertionError(\'It is forbidden to sum ReadInstruction instances \'\n                           \'with different rounding values.\')\n    return self._read_instruction_from_relative_instructions(\n        self._relative_instructions + other_ris)\n\n  def __str__(self):\n    return \'ReadInstruction(%s)\' % self._relative_instructions\n\n  def to_absolute(self, name2len):\n    """"""Translate instruction into a list of absolute instructions.\n\n    Those absolute instructions are then to be added together.\n\n    Args:\n      name2len: dict associating split names to number of examples.\n\n    Returns:\n      list of _AbsoluteInstruction instances (corresponds to the + in spec).\n    """"""\n    return [_rel_to_abs_instr(rel_instr, name2len)\n            for rel_instr in self._relative_instructions]\n'"
tensorflow_datasets/core/tfrecords_reader_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.tfrecords_reader.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport itertools\nimport os\n\nfrom absl.testing import absltest\nimport six\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import example_parser\nfrom tensorflow_datasets.core import splits\nfrom tensorflow_datasets.core import tfrecords_reader\nfrom tensorflow_datasets.core import tfrecords_writer\nfrom tensorflow_datasets.core.utils import read_config as read_config_lib\nfrom tensorflow_datasets.core.utils import shard_utils\n\n\n# Skip the cardinality test for backward compatibility with TF <= 2.1.\n_SKIP_CARDINALITY_TEST = not hasattr(tf.data.experimental, \'assert_cardinality\')\n\n\ndef _write_tfrecord_from_shard_spec(shard_spec, get):\n  """"""Write tfrecord shard given shard_spec and buckets to read data from.\n\n  Args:\n    shard_spec: _ShardSpec, the spec for shard to write.\n    get: callable taking the shard index (of bucket) and returning iterator over\n      its elements.\n  """"""\n  iterators = []\n  for instruction in shard_spec.file_instructions:\n    iterator = get(int(instruction.filename))\n    skip, take = instruction.skip, instruction.take\n    stop = skip+take if take > 0 else None\n    iterators.append(itertools.islice(iterator, skip, stop))\n  tfrecords_writer._write_tfrecord(shard_spec.path, itertools.chain(*iterators))\n\n\nclass GetDatasetFilesTest(testing.TestCase):\n\n  NAME2SHARD_LENGTHS = {\n      \'train\': [3, 2, 3, 2, 3],  # 13 examples.\n  }\n\n  PATH_PATTERN = \'mnist-train.tfrecord-0000%d-of-00005\'\n\n  def _get_files(self, instruction):\n    file_instructions = tfrecords_reader._make_file_instructions_from_absolutes(\n        name=\'mnist\',\n        name2shard_lengths=self.NAME2SHARD_LENGTHS,\n        absolute_instructions=[instruction],\n    )\n    return file_instructions\n\n  def test_no_skip_no_take(self):\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', None, None)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % i, skip=0, take=-1, num_examples=n)\n        for i, n in enumerate([3, 2, 3, 2, 3])\n    ])\n\n  def test_skip(self):\n    # One file is not taken, one file is partially taken.\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 4, None)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 1, skip=1, take=-1, num_examples=1),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 2, skip=0, take=-1, num_examples=3),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 3, skip=0, take=-1, num_examples=2),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 4, skip=0, take=-1, num_examples=3),\n    ])\n\n  def test_take(self):\n    # Two files are not taken, one file is partially taken.\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', None, 6)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 0, skip=0, take=-1, num_examples=3),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 1, skip=0, take=-1, num_examples=2),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 2, skip=0, take=1, num_examples=1),\n    ])\n\n  def test_skip_take1(self):\n    # A single shard with both skip and take.\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 1, 2)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 0, skip=1, take=1, num_examples=1),\n    ])\n\n  def test_skip_take2(self):\n    # 2 elements in across two shards are taken in middle.\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 7, 9)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 2, skip=2, take=-1, num_examples=1),\n        shard_utils.FileInstruction(\n            filename=self.PATH_PATTERN % 3, skip=0, take=1, num_examples=1),\n    ])\n\n  def test_touching_boundaries(self):\n    # Nothing to read.\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 0, 0)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [])\n\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', None, 0)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [])\n\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 3, 3)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [])\n\n    instruction = tfrecords_reader._AbsoluteInstruction(\'train\', 13, None)\n    files = self._get_files(instruction)\n    self.assertEqual(files, [])\n\n  def test_missing_shard_lengths(self):\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Shard empty.\'):\n      split_info = [\n          splits.SplitInfo(name=\'train\', shard_lengths=[]),\n      ]\n      tfrecords_reader.make_file_instructions(\'mnist\', split_info, \'train\')\n\n\nclass ReadInstructionTest(testing.TestCase):\n\n  def setUp(self):\n    super(ReadInstructionTest, self).setUp()\n    self.splits = {\n        \'train\': 200,\n        \'test\': 101,\n        \'validation\': 30,\n    }\n\n  def check_from_ri(self, ri, expected):\n    res = ri.to_absolute(self.splits)\n    expected_result = []\n    for split_name, from_, to_ in expected:\n      expected_result.append(tfrecords_reader._AbsoluteInstruction(\n          split_name, from_, to_))\n    self.assertEqual(res, expected_result)\n    return ri\n\n  def check_from_spec(self, spec, expected):\n    ri = tfrecords_reader.ReadInstruction.from_spec(spec)\n    return self.check_from_ri(ri, expected)\n\n  def assertRaises(self, spec, msg, exc_cls=AssertionError):\n    with self.assertRaisesWithPredicateMatch(exc_cls, msg):\n      ri = tfrecords_reader.ReadInstruction.from_spec(spec)\n      ri.to_absolute(self.splits)\n\n  def test_valid(self):\n    # Simple split:\n    ri = self.check_from_spec(\'train\', [(\'train\', None, None)])\n    self.assertEqual(\n        str(ri),\n        (""ReadInstruction([""\n         ""_RelativeInstruction(splitname=\'train\', from_=None, to=None, ""\n         ""unit=\'abs\', rounding=\'closest\')])""))\n    self.check_from_spec(\'test\', [(\'test\', None, None)])\n    # Addition of splits:\n    self.check_from_spec(\'train+test\', [\n        (\'train\', None, None),\n        (\'test\', None, None),\n    ])\n    # Absolute slicing:\n    self.check_from_spec(\'train[0:0]\', [(\'train\', None, 0)])\n    self.check_from_spec(\'train[:10]\', [(\'train\', None, 10)])\n    self.check_from_spec(\'train[0:10]\', [(\'train\', None, 10)])\n    self.check_from_spec(\'train[-10:]\', [(\'train\', 190, None)])\n    self.check_from_spec(\'train[-100:-50]\', [(\'train\', 100, 150)])\n    self.check_from_spec(\'train[-10:200]\', [(\'train\', 190, None)])\n    self.check_from_spec(\'train[10:-10]\', [(\'train\', 10, 190)])\n    self.check_from_spec(\'train[42:99]\', [(\'train\', 42, 99)])\n    # Percent slicing, closest rounding:\n    self.check_from_spec(\'train[:10%]\', [(\'train\', None, 20)])\n    self.check_from_spec(\'train[90%:]\', [(\'train\', 180, None)])\n    self.check_from_spec(\'train[-1%:]\', [(\'train\', 198, None)])\n    ri = self.check_from_spec(\'test[:99%]\', [(\'test\', None, 100)])\n    self.assertEqual(\n        str(ri),\n        (""ReadInstruction([_RelativeInstruction(splitname=\'test\', from_=None,""\n         "" to=99, unit=\'%\', rounding=\'closest\')])""))\n    # No overlap:\n    self.check_from_spec(\'test[100%:]\', [(\'test\', 101, None)])\n    # Percent slicing, pct1_dropremainder rounding:\n    ri = tfrecords_reader.ReadInstruction(\'train\', to=20, unit=\'%\',\n                                          rounding=\'pct1_dropremainder\')\n    self.check_from_ri(ri, [(\'train\', None, 40)])\n    # test split has 101 examples.\n    ri = tfrecords_reader.ReadInstruction(\'test\', to=100, unit=\'%\',\n                                          rounding=\'pct1_dropremainder\')\n    self.check_from_ri(ri, [(\'test\', None, 100)])\n    # No overlap using \'pct1_dropremainder\' rounding:\n    ri1 = tfrecords_reader.ReadInstruction(\'test\', to=99, unit=\'%\',\n                                           rounding=\'pct1_dropremainder\')\n    ri2 = tfrecords_reader.ReadInstruction(\'test\', from_=100, unit=\'%\',\n                                           rounding=\'pct1_dropremainder\')\n    self.check_from_ri(ri1, [(\'test\', None, 99)])\n    self.check_from_ri(ri2, [(\'test\', 100, None)])\n    # Empty:\n    # Slices resulting in empty datasets are valid with \'closest\' rounding:\n    self.check_from_spec(\'validation[:1%]\', [(\'validation\', None, 0)])\n\n  def test_add(self):\n    ri1 = tfrecords_reader.ReadInstruction.from_spec(\'train[10:20]\')\n    ri2 = tfrecords_reader.ReadInstruction.from_spec(\'test[10:20]\')\n    ri3 = tfrecords_reader.ReadInstruction.from_spec(\'train[1:5]\')\n    ri = ri1 + ri2 + ri3\n    self.assertEqual(\n        str(ri),\n        (""ReadInstruction([""\n         ""_RelativeInstruction(splitname=\'train\', from_=10, to=20, unit=\'abs\',""\n         "" rounding=\'closest\'), ""\n         ""_RelativeInstruction(splitname=\'test\', from_=10, to=20, unit=\'abs\',""\n         "" rounding=\'closest\'), ""\n         ""_RelativeInstruction(splitname=\'train\', from_=1, to=5, unit=\'abs\',""\n         "" rounding=\'closest\')])""))\n\n  def test_add_invalid(self):\n    # Mixed rounding:\n    ri1 = tfrecords_reader.ReadInstruction(\'test\', unit=\'%\', to=10,\n                                           rounding=\'pct1_dropremainder\')\n    ri2 = tfrecords_reader.ReadInstruction(\'test\', unit=\'%\', from_=90,\n                                           rounding=\'closest\')\n    with self.assertRaisesWithPredicateMatch(AssertionError,\n                                             \'different rounding\'):\n      unused_ = ri1 + ri2\n\n  def test_invalid_rounding(self):\n    with self.assertRaisesWithPredicateMatch(ValueError, \'rounding\'):\n      tfrecords_reader.ReadInstruction(\'test\', unit=\'%\', rounding=\'unexisting\')\n\n  def test_invalid_unit(self):\n    with self.assertRaisesWithPredicateMatch(ValueError, \'unit\'):\n      tfrecords_reader.ReadInstruction(\'test\', unit=\'kg\', rounding=\'closest\')\n\n  def test_invalid_spec(self):\n    # Invalid format:\n    self.assertRaises(\'validation[:250%:2]\',\n                      \'Unrecognized instruction format: validation[:250%:2]\')\n    # Unexisting split:\n    self.assertRaises(\'imaginary\',\n                      \'Unknown split ""imaginary""\',\n                      exc_cls=ValueError)\n    # Invalid boundaries abs:\n    self.assertRaises(\'validation[:31]\',\n                      \'incompatible with 30 examples\')\n    # Invalid boundaries %:\n    self.assertRaises(\'validation[:250%]\',\n                      \'Percent slice boundaries must be > -100 and < 100\')\n    self.assertRaises(\'validation[-101%:]\',\n                      \'Percent slice boundaries must be > -100 and < 100\')\n    # pct1_dropremainder with < 100 examples\n    with self.assertRaisesWithPredicateMatch(\n        AssertionError, \'with less than 100 elements is forbidden\'):\n      ri = tfrecords_reader.ReadInstruction(\'validation\', to=99, unit=\'%\',\n                                            rounding=\'pct1_dropremainder\')\n      ri.to_absolute(self.splits)\n\n\nclass ReaderTest(testing.TestCase):\n\n  def setUp(self):\n    super(ReaderTest, self).setUp()\n    with absltest.mock.patch.object(example_parser,\n                                    \'ExampleParser\', testing.DummyParser):\n      self.reader = tfrecords_reader.Reader(self.tmp_dir, \'some_spec\')\n      self.reader.read = functools.partial(\n          self.reader.read,\n          read_config=read_config_lib.ReadConfig(),\n          shuffle_files=False,\n      )\n\n  def _write_tfrecord(self, split_name, shards_number, records):\n    path = os.path.join(self.tmp_dir, \'mnist-%s.tfrecord\' % split_name)\n    num_examples = len(records)\n    with absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                                    return_value=shards_number):\n      shard_specs = tfrecords_writer._get_shard_specs(\n          num_examples, 0, [num_examples], path)\n    serialized_records = [six.b(rec) for rec in records]\n    for shard_spec in shard_specs:\n      _write_tfrecord_from_shard_spec(\n          shard_spec, lambda unused_i: iter(serialized_records))\n    return splits.SplitInfo(\n        name=split_name,\n        shard_lengths=[int(s.examples_number) for s in shard_specs],\n    )\n\n  def test_nodata_instruction(self):\n    # Given instruction corresponds to no data.\n    with self.assertRaisesWithPredicateMatch(AssertionError,\n                                             \'corresponds to no data!\'):\n      train_info = splits.SplitInfo(name=\'train\', shard_lengths=[2, 3, 2, 3, 2])\n      self.reader.read(\'mnist\', \'train[0:0]\', [train_info])\n\n  def test_noskip_notake(self):\n    train_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    ds = self.reader.read(\'mnist\', \'train\', [train_info])\n    read_data = list(tfds.as_numpy(ds))\n    self.assertEqual(read_data, [six.b(l) for l in \'abcdefghijkl\'])\n\n    if not _SKIP_CARDINALITY_TEST:\n      # Check that the cardinality is correctly set.\n      self.assertEqual(\n          tf.data.experimental.cardinality(ds).numpy(), len(read_data))\n\n  def test_overlap(self):\n    train_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    ds = self.reader.read(\'mnist\', \'train+train[:2]\', [train_info])\n    read_data = list(tfds.as_numpy(ds))\n    self.assertEqual(read_data, [six.b(l) for l in \'abcdefghijklab\'])\n\n    if not _SKIP_CARDINALITY_TEST:\n      # Check that the cardinality is correctly set.\n      self.assertEqual(\n          tf.data.experimental.cardinality(ds).numpy(), len(read_data))\n\n  def test_complex(self):\n    train_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    test_info = self._write_tfrecord(\'test\', 3, \'mnopqrs\')\n    self.assertEqual(train_info.name, \'train\')\n    self.assertEqual(test_info.name, \'test\')\n    self.assertEqual(train_info.shard_lengths, [2, 3, 2, 3, 2])  # 12 ex.\n    self.assertEqual(test_info.shard_lengths, [2, 3, 2])  # 7 ex.\n    split_info = [train_info, test_info]\n    ds = self.reader.read(\'mnist\', \'train[1:-1]+test[:-50%]\', split_info)\n    read_data = list(tfds.as_numpy(ds))\n    self.assertEqual(read_data, [six.b(l) for l in \'bcdefghijkmno\'])\n\n    if not _SKIP_CARDINALITY_TEST:\n      # Check that the cardinality is correctly set.\n      self.assertEqual(\n          tf.data.experimental.cardinality(ds).numpy(), len(read_data))\n\n  def test_shuffle_files(self):\n    train_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    ds = self.reader.read(\'mnist\', \'train\', [train_info],\n                          shuffle_files=True)\n    shards = [  # The shards of the dataset:\n        [b\'a\', b\'b\'],\n        [b\'c\', b\'d\', b\'e\'],\n        [b\'f\', b\'g\'],\n        [b\'h\', b\'i\', b\'j\'],\n        [b\'k\', b\'l\'],\n    ]\n    # The various orders in which the dataset can be read:\n    expected_permutations = [tuple(sum(shard, []))\n                             for shard in itertools.permutations(shards)]\n    ds = ds.batch(12).repeat(100)\n    read_data = set(tuple(e) for e in tfds.as_numpy(ds))\n    for batch in read_data:\n      self.assertIn(batch, expected_permutations)\n    # There are theoritically 5! (=120) different arrangements, but we would\n    # need too many repeats to be sure to get them.\n    self.assertGreater(len(set(read_data)), 10)\n\n  def test_shuffle_deterministic(self):\n    split_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    read_config = read_config_lib.ReadConfig(\n        shuffle_seed=123,\n    )\n    ds = self.reader.read(\n        \'mnist\', \'train\', [split_info],\n        read_config=read_config,\n        shuffle_files=True)\n    ds_values = list(tfds.as_numpy(ds))\n\n    # Check that shuffle=True with a seed provides deterministic results.\n    self.assertEqual(ds_values, [\n        b\'a\', b\'b\', b\'k\', b\'l\', b\'h\', b\'i\', b\'j\', b\'c\', b\'d\', b\'e\', b\'f\', b\'g\'\n    ])\n\n  def test_4fold(self):\n    train_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    instructions = [\n        tfrecords_reader.ReadInstruction(\'train\', from_=k, to=k+25, unit=\'%\')\n        for k in range(0, 100, 25)]\n    tests = self.reader.read(\'mnist\', instructions, [train_info])\n    instructions = [\n        (tfrecords_reader.ReadInstruction(\'train\', to=k, unit=\'%\') +\n         tfrecords_reader.ReadInstruction(\'train\', from_=k+25, unit=\'%\'))\n        for k in range(0, 100, 25)]\n    trains = self.reader.read(\'mnist\', instructions, [train_info])\n    read_tests = [list(r) for r in tfds.as_numpy(tests)]\n    read_trains = [list(r) for r in tfds.as_numpy(trains)]\n    self.assertEqual(read_tests, [[b\'a\', b\'b\', b\'c\'],\n                                  [b\'d\', b\'e\', b\'f\'],\n                                  [b\'g\', b\'h\', b\'i\'],\n                                  [b\'j\', b\'k\', b\'l\']])\n    self.assertEqual(read_trains, [\n        [b\'d\', b\'e\', b\'f\', b\'g\', b\'h\', b\'i\', b\'j\', b\'k\', b\'l\'],\n        [b\'a\', b\'b\', b\'c\', b\'g\', b\'h\', b\'i\', b\'j\', b\'k\', b\'l\'],\n        [b\'a\', b\'b\', b\'c\', b\'d\', b\'e\', b\'f\', b\'j\', b\'k\', b\'l\'],\n        [b\'a\', b\'b\', b\'c\', b\'d\', b\'e\', b\'f\', b\'g\', b\'h\', b\'i\']])\n\n  def test_read_files(self):\n    self._write_tfrecord(\'train\', 4, \'abcdefghijkl\')\n    fname_pattern = \'mnist-train.tfrecord-0000%d-of-00004\'\n    ds = self.reader.read_files(\n        [\n            shard_utils.FileInstruction(\n                filename=fname_pattern % 1, skip=0, take=-1, num_examples=3),\n            shard_utils.FileInstruction(\n                filename=fname_pattern % 3, skip=1, take=1, num_examples=1),\n        ],\n        read_config=read_config_lib.ReadConfig(),\n        shuffle_files=False,\n    )\n    read_data = list(tfds.as_numpy(ds))\n    self.assertEqual(read_data, [six.b(l) for l in \'defk\'])\n\n  def test_input_context(self):\n    split_info = self._write_tfrecord(\'train\', 5, \'abcdefghijkl\')\n    self.assertEqual(split_info.shard_lengths, [2, 3, 2, 3, 2])\n\n    def read(num_workers, index):\n      return list(tfds.as_numpy(self.reader.read(\n          \'mnist\',\n          \'train\',\n          split_infos=[split_info],\n          read_config=read_config_lib.ReadConfig(\n              input_context=tf.distribute.InputContext(\n                  num_input_pipelines=num_workers,\n                  input_pipeline_id=index,\n              ),\n          ),\n          # Workers should read a deterministic subset of the examples, even\n          # if examples within one worker may be shuffled.\n          shuffle_files=True,\n      )))\n\n    def _b(bytes_str):\n      if six.PY2:\n        return list(bytes_str)\n      # Convert to List[bytes] (rather than List[int])\n      return [bytes([b]) for b in bytes_str]\n\n    # Read all the data (single pipeline)\n    self.assertCountEqual(read(num_workers=1, index=0), _b(b\'abcdefghijkl\'))\n    # Read part of the data (workers should not overlapp)\n    self.assertCountEqual(read(num_workers=3, index=0), _b(b\'abhij\'))  # 0, 3\n    self.assertCountEqual(read(num_workers=3, index=1), _b(b\'cdekl\'))  # 1, 4\n    self.assertEqual(read(num_workers=3, index=2), _b(b\'fg\'))  # Shards 2\n    # If num_workers == num_shards, then a single shard is read\n    self.assertEqual(read(num_workers=5, index=1), _b(b\'cde\'))  # Shard 1\n    # If num_workers > num_shards, raise error\n    with self.assertRaisesRegexp(ValueError, \'Cannot shard the pipeline\'):\n      read(num_workers=6, index=0)\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/tfrecords_writer.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""To write records into sharded tfrecord files.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport itertools\nimport json\nimport os\n\nfrom typing import Any, Iterable, List, Tuple\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import example_parser\nfrom tensorflow_datasets.core import example_serializer\nfrom tensorflow_datasets.core import hashing\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core import shuffle\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import shard_utils\n\n# TODO(tfds): Should be `TreeDict[FeatureValue]`\nExample = Any\n\nMIN_SHARD_SIZE = 64<<20  # 64 MiB\nMAX_SHARD_SIZE = 1024<<20  # 2 GiB\n\n# TFRECORD overheads.\n# https://github.com/tensorflow/tensorflow/blob/27325fabed898880fa1b33a04d4b125a6ef4bbc8/tensorflow/core/lib/io/record_writer.h#L104\nTFRECORD_REC_OVERHEAD = 16\n\n# Number of temp buckets for beam writer.\n# 100K buckets at 1G per bucket gives us ~100TB. Each bucket can go bigger, as\n# long as it can hold in memory. So if each bucket goes to 5GB, that\'s 500TB.\n# It seems reasonable to require 10GB of RAM per worker to handle a 1PB split.\n_BEAM_NUM_TEMP_SHARDS = int(100e3)\n\n# Spec to write a final tfrecord shard.\n_ShardSpec = collections.namedtuple(""_ShardSpec"", [\n    # Index of shard.\n    ""shard_index"",\n    # The path where to write shard.\n    ""path"",\n    # Number of examples in shard\n    ""examples_number"",\n    # Reading instructions (List[FileInstruction]).\n    ""file_instructions"",\n])\n\n\ndef _raise_error_for_duplicated_keys(example1, example2, example_specs):\n  """"""Log information about the examples and raise an AssertionError.""""""\n  msg = ""Two records share the same hashed key!""\n  logging.error(msg)\n  parser = example_parser.ExampleParser(example_specs)\n  ex1 = parser.parse_example(example1)\n  ex2 = parser.parse_example(example2)\n  logging.error(""1st example: %s"", ex1)\n  logging.error(""2nd example: %s"", ex2)\n  raise AssertionError(msg)\n\n\ndef _get_shard_specs(\n    num_examples: int,\n    total_size: int,\n    bucket_lengths: List[int],\n    path: str,\n) -> List[_ShardSpec]:\n  """"""Returns list of _ShardSpec instances, corresponding to shards to write.\n\n  Args:\n    num_examples: int, number of examples in split.\n    total_size: int (bytes), sum of example sizes.\n    bucket_lengths: list of ints, number of examples in each bucket.\n    path: string, path to tfrecord. `-xxxxx-of-xxxxx` will be added.\n  """"""\n  num_shards = _get_number_shards(total_size, num_examples)\n  shard_boundaries = _get_shard_boundaries(num_examples, num_shards)\n  shard_specs = []\n  bucket_indexes = [str(i) for i in range(len(bucket_lengths))]\n  from_ = 0\n  for shard_index, to in enumerate(shard_boundaries):\n    # Read the bucket indexes\n    file_instructions = shard_utils.get_file_instructions(\n        from_, to, bucket_indexes, bucket_lengths)\n    shard_specs.append(_ShardSpec(\n        shard_index=shard_index,\n        path=""%s-%05d-of-%05d"" % (path, shard_index, num_shards),\n        examples_number=to-from_,\n        file_instructions=file_instructions,\n    ))\n    from_ = to\n  return shard_specs\n\n\ndef _get_shard_boundaries(\n    num_examples: int,\n    number_of_shards: int,\n) -> List[int]:\n  if num_examples == 0:\n    raise AssertionError(""No examples were yielded."")\n  if num_examples < number_of_shards:\n    raise AssertionError(""num_examples ({}) < number_of_shards ({})"".format(\n        num_examples, number_of_shards))\n  return [\n      int(round(num_examples * (float(i)/number_of_shards)))\n      for i in range(1, number_of_shards+1)\n  ]\n\n\ndef _write_tfrecord(\n    path: str,\n    iterator: Iterable[bytes],\n):\n  """"""Write single (non sharded) TFrecord file from iterator.""""""\n  with tf.io.TFRecordWriter(path) as writer:\n    for serialized_example in iterator:\n      writer.write(serialized_example)\n    writer.flush()\n\n\ndef _get_number_shards(\n    total_size: int,\n    num_examples: int,\n) -> int:\n  """"""Returns number of shards for num_examples of total_size in bytes.\n\n  Each shard should be at least 128MB.\n  A pod has 16*16=256 TPU devices containing 1024 TPU chips (2048 cores).\n  So if the dataset is large enough, we want the number of shards to be a\n  multiple of 1024, but with shards as big as possible.\n  If the dataset is too small, we want the number of shards to be a power\n  of two so it distributes better on smaller TPU configs (8, 16, 32, ... cores).\n\n  Args:\n    total_size: the size of the data (serialized, not couting any overhead).\n    num_examples: the number of records in the data.\n\n  Returns:\n    number of shards to use.\n  """"""\n  total_size += num_examples * TFRECORD_REC_OVERHEAD\n  max_shards_number = total_size // MIN_SHARD_SIZE\n  min_shards_number = total_size // MAX_SHARD_SIZE\n  if min_shards_number <= 1024 <= max_shards_number and num_examples >= 1024:\n    return 1024\n  elif min_shards_number > 1024:\n    i = 2\n    while True:\n      n = 1024 * i\n      if n >= min_shards_number and num_examples >= n:\n        return n\n      i += 1\n  else:\n    for n in [512, 256, 128, 64, 32, 16, 8, 4, 2]:\n      if min_shards_number <= n <= max_shards_number and num_examples >= n:\n        return n\n  return 1\n\n\nclass Writer(object):\n  """"""Shuffles and writes Examples to sharded TFRecord files.\n\n  The number of shards is computed automatically.\n\n  """"""\n\n  def __init__(self, example_specs, path, hash_salt):\n    self._example_specs = example_specs\n    self._serializer = example_serializer.ExampleSerializer(example_specs)\n    self._shuffler = shuffle.Shuffler(os.path.dirname(path), hash_salt)\n    self._num_examples = 0\n    self._path = path\n\n  def write(self, key, example):\n    """"""Writes given Example.\n\n    The given example is not directly written to the tfrecord file, but to a\n    temporary file (or memory). The finalize() method does write the tfrecord\n    files.\n\n    Args:\n      key (int|bytes): the key associated with the example. Used for shuffling.\n      example: the Example to write to the tfrecord file.\n    """"""\n    serialized_example = self._serializer.serialize_example(example)\n    self._shuffler.add(key, serialized_example)\n    self._num_examples += 1\n\n  def finalize(self):\n    """"""Effectively writes examples to the tfrecord files.""""""\n    print(""Shuffling and writing examples to %s"" % self._path)\n    shard_specs = _get_shard_specs(self._num_examples, self._shuffler.size,\n                                   self._shuffler.bucket_lengths, self._path)\n    # Here we just loop over the examples, and don\'t use the instructions, just\n    # the final number of examples in every shard. Instructions could be used to\n    # parallelize, but one would need to be careful not to sort buckets twice.\n    examples_generator = iter(utils.tqdm(\n        self._shuffler, total=self._num_examples, unit="" examples"",\n        leave=False))\n    try:\n      for shard_spec in shard_specs:\n        iterator = itertools.islice(\n            examples_generator, 0, shard_spec.examples_number)\n        _write_tfrecord(shard_spec.path, iterator)\n    except shuffle.DuplicatedKeysError as err:\n      _raise_error_for_duplicated_keys(err.item1, err.item2,\n                                       self._example_specs)\n    shard_lengths = [int(spec.examples_number) for spec in shard_specs]\n    logging.info(""Done writing %s. Shard lengths: %s"",\n                 self._path, shard_lengths)\n    return shard_lengths, self._shuffler.size\n\n\n# Make a long out of int. Necessary for Beam on Py2.\nif six.PY2:\n  _long_for_py2 = long  # pylint: disable=invalid-name,undefined-variable\nelse:\n  _long_for_py2 = lambda int_val: int_val\n\n\nclass BeamWriter(object):\n  """"""Shuffles / writes Examples beam collection to sharded TFRecord files.\n\n  The given examples are not directly writen to the final tfrecord file, but to\n  temporary files.\n  """"""\n  _OUTPUT_TAG_BUCKETS_LEN_SIZE = ""tag_buckets_len_size""\n\n  def __init__(self, example_specs, path, hash_salt):\n    """"""Init BeamWriter.\n\n    Args:\n      example_specs:\n      path: str, path where to write tfrecord file. Eg:\n        ""/foo/mnist-train.tfrecord"".\n        The suffix (eg: `.00000-of-00004` will be added by the BeamWriter.\n        Note that file ""{path}.shard_lengths.json"" is also created. It contains\n          a list with the number of examples in each final shard. Eg:\n          ""[10,11,10,11]"".\n      hash_salt: string, the salt to use for hashing of keys.\n    """"""\n    self._original_state = dict(example_specs=example_specs, path=path,\n                                hash_salt=hash_salt)\n    self._path = path\n    self._split_info_path = ""%s.split_info.json"" % path\n    self._serializer = example_serializer.ExampleSerializer(example_specs)\n    self._example_specs = example_specs\n    self._hasher = hashing.Hasher(hash_salt)\n    self._split_info = None\n\n  def __getstate__(self):\n    return self._original_state\n\n  def __setstate__(self, state):\n    self.__init__(**state)\n\n  def _serialize_shard(\n      self,\n      key_example: Tuple[hashing.HashKey, Example],\n  ) -> Tuple[int, Tuple[int, bytes]]:\n    """"""Returns (shard#, (hkey, serialized_example)).""""""\n    key, example = key_example\n    serialized_example = self._serializer.serialize_example(example)\n    hkey = self._hasher.hash_key(key)\n    bucketid = shuffle.get_bucket_number(hkey, _BEAM_NUM_TEMP_SHARDS)\n    hkey = _long_for_py2(hkey)\n    bucketid = _long_for_py2(bucketid)\n    return (bucketid, (hkey, serialized_example))\n\n  def _sort_bucket(self, bucketid_examples):\n    """"""Sort the examples in bucket, emits total size and len on side.""""""\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n    bucketid, examples = bucketid_examples\n    examples = sorted(examples)  # We know by design it fits in memory.\n    for i in range(len(examples)-1):\n      if examples[i][0] == examples[i+1][0]:\n        _raise_error_for_duplicated_keys(examples[i][1], examples[i+1][1],\n                                         self._example_specs)\n    examples = [ex[1] for ex in examples]\n    total_size = sum(len(ex) for ex in examples)\n    yield beam.pvalue.TaggedOutput(self._OUTPUT_TAG_BUCKETS_LEN_SIZE,\n                                   (bucketid, (len(examples), total_size)))\n    yield (bucketid, examples)\n\n  def _get_boundaries_per_bucket_shard(self, shard_len_sizes):\n    """"""Yields `(bucketid, (shard_path, from, to))` tuples.\n\n    Meaning that buckets[bucketid][from:to] examples should go in shard_path.\n\n    Args:\n      shard_len_sizes: dict where the key is the id of the bucket and the value\n        is a tuple (len, size) of the corresponding bucket. len is the number of\n        examples in the bucket and size is the total size in bytes of the\n        elements in that bucket. Buckets with no elements are not mentioned.\n    """"""\n    if not shard_len_sizes:\n      raise AssertionError(""Not a single example present in the PCollection!"")\n    total_num_examples = 0\n    total_size = 0\n    bucket2length = {}\n    for bucket_index, (length, size) in shard_len_sizes.items():\n      total_num_examples += length\n      total_size += size\n      bucket2length[bucket_index] = length\n    bucket_lengths = [bucket2length.get(i, 0)\n                      for i in range(max(bucket2length.keys()) + 1)]\n    shard_specs = _get_shard_specs(\n        total_num_examples, total_size, bucket_lengths, self._path)\n    with tf.io.gfile.GFile(self._split_info_path, ""w"") as json_f:\n      json_f.write(json.dumps(\n          {\n              ""total_size"": total_size,\n              ""shard_lengths"": [\n                  int(shard.examples_number) for shard in shard_specs]\n          }))\n    for shard_spec in shard_specs:\n      for instruction in shard_spec.file_instructions:\n        bucketid = int(instruction.filename)\n        from_ = instruction.skip\n        take = instruction.take\n        to = from_ + take if take >= 0 else None\n        yield (bucketid, (shard_spec.path, from_, to))\n\n  def _emits_examples_per_shard(self, bucketid_data):\n    """"""Split examples of a bucket given list of instructions applying to it.""""""\n    bucketid, data = bucketid_data\n    examples = list(itertools.chain(*data[""examples""]))\n    for shardpath, from_, to in data[""boundaries""]:\n      yield (shardpath, (bucketid, examples[from_:to]))\n\n  def _write_final_shard(self, shardid_examples):\n    shard_path, examples_by_bucket = shardid_examples\n    examples = list(itertools.chain(*[\n        ex[1] for ex in sorted(examples_by_bucket)]))\n    _write_tfrecord(shard_path, examples)\n\n  def write_from_pcollection(self, examples_pcollection):\n    """"""Returns PTransform to write (key, example) PCollection to tfrecords.""""""\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n    # Here bucket designates a temporary shard, to help differenciate between\n    # temporary and final shards.\n    buckets, buckets_len_size = (\n        examples_pcollection\n        # (key, example)\n        | ""SerializeBucketize"" >> beam.Map(self._serialize_shard)\n        # (bucket_id, (hkey, serialized_example))\n        | ""GroupByBucket"" >> beam.GroupByKey()\n        # (bucket_id, [(hkey0, serialized0), ...])\n        | ""SortBucketsGetSizeLen"" >> (\n            beam.ParDo(self._sort_bucket)\n            .with_outputs(self._OUTPUT_TAG_BUCKETS_LEN_SIZE, main=""buckets"")))\n        # buckets = (bucketid, [serialized0, serialized1, ...])\n        # buckets_len_size = (bucketid, (num_examples_bucket, bucket_byte_size))\n\n    boundaries = (\n        buckets_len_size\n        | ""CombineBucketsSizes"" >> beam.transforms.combiners.ToDict()\n        # {bucketid: (num_examples_bucket, bucket_byte_size)}\n        | ""GetBoundaries""  >> beam.ParDo(\n            self._get_boundaries_per_bucket_shard))\n        # (bucketid, (shard_path, from, to)\n\n    return (\n        {""examples"": buckets, ""boundaries"": boundaries}\n        # {\n        #     ""examples"": (bucketid, [serialized0, serialized1, ...])\n        #     ""boundaries"": (bucketid, (shard_path, from, to)\n        # }\n        | ""GroupBucketsAndBoundaries"" >> beam.CoGroupByKey()\n        # (bucketid, {\n        #     ""examples"": [[serialized0, serialized1, ...]],\n        #     ""boundaries"": [(shard_path, from, to), ...],\n        # })\n        | ""GetExamplesPerShard"" >> beam.FlatMap(self._emits_examples_per_shard)\n        # (shard_path, (bucketid, serialized_list[from_:to]))\n        | ""GroupShards"" >> beam.GroupByKey()\n        # (shard_path, [(bucketid, serialized_list[from_:to]), ...])\n        # bucketid allows to sort the serialized examples\n        | ""WriteFinalShards"" >> beam.Map(self._write_final_shard))\n\n  def finalize(self):\n    """"""Deletes tmp directory and returns shard_lengths and total_size.""""""\n    if self._split_info is None:\n      with tf.io.gfile.GFile(self._split_info_path, ""r"") as json_f:\n        self._split_info = json.loads(json_f.read())\n      tf.io.gfile.remove(self._split_info_path)\n    return self._split_info[""shard_lengths""], self._split_info[""total_size""]\n'"
tensorflow_datasets/core/tfrecords_writer_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.tfrecords_writer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl.testing import absltest\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import example_parser\nfrom tensorflow_datasets.core import example_serializer\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core import tfrecords_writer\nfrom tensorflow_datasets.core.tfrecords_writer import _ShardSpec\nfrom tensorflow_datasets.core.utils import shard_utils\n\n\nclass GetShardSpecsTest(testing.TestCase):\n  # Here we don\'t need to test all possible reading configs, as this is tested\n  # by shard_utils.py.\n\n  @absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                              absltest.mock.Mock(return_value=6))\n  def test_1bucket_6shards(self):\n    specs = tfrecords_writer._get_shard_specs(\n        num_examples=8, total_size=16, bucket_lengths=[8],\n        path=\'/bar.tfrecord\')\n    self.assertEqual(specs, [\n        # Shard#, path, from_bucket, examples_number, reading instructions.\n        _ShardSpec(0, \'/bar.tfrecord-00000-of-00006\', 1, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=0, take=1, num_examples=1),\n        ]),\n        _ShardSpec(1, \'/bar.tfrecord-00001-of-00006\', 2, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=1, take=2, num_examples=2),\n        ]),\n        _ShardSpec(2, \'/bar.tfrecord-00002-of-00006\', 1, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=3, take=1, num_examples=1),\n        ]),\n        _ShardSpec(3, \'/bar.tfrecord-00003-of-00006\', 1, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=4, take=1, num_examples=1),\n        ]),\n        _ShardSpec(4, \'/bar.tfrecord-00004-of-00006\', 2, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=5, take=2, num_examples=2),\n        ]),\n        _ShardSpec(5, \'/bar.tfrecord-00005-of-00006\', 1, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=7, take=-1, num_examples=1),\n        ]),\n    ])\n\n  @absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                              absltest.mock.Mock(return_value=2))\n  def test_4buckets_2shards(self):\n    specs = tfrecords_writer._get_shard_specs(\n        num_examples=8, total_size=16, bucket_lengths=[2, 3, 0, 3],\n        path=\'/bar.tfrecord\')\n    self.assertEqual(specs, [\n        # Shard#, path, examples_number, reading instructions.\n        _ShardSpec(0, \'/bar.tfrecord-00000-of-00002\', 4, [\n            shard_utils.FileInstruction(\n                filename=\'0\', skip=0, take=-1, num_examples=2),\n            shard_utils.FileInstruction(\n                filename=\'1\', skip=0, take=2, num_examples=2),\n        ]),\n        _ShardSpec(1, \'/bar.tfrecord-00001-of-00002\', 4, [\n            shard_utils.FileInstruction(\n                filename=\'1\', skip=2, take=-1, num_examples=1),\n            shard_utils.FileInstruction(\n                filename=\'3\', skip=0, take=-1, num_examples=3),\n        ]),\n    ])\n\n\nclass GetNumberShardsTest(testing.TestCase):\n\n  def test_imagenet_train(self):\n    size = 137<<30  # 137 GiB\n    num_examples = 1281167\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 1024)\n\n  def test_imagenet_evaluation(self):\n    size = 6300 * (1<<20)  # 6.3 GiB\n    num_examples = 50000\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 64)\n\n  def test_verylarge_few_examples(self):\n    size = 52<<30  # 52 GiB\n    num_examples = 512\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 512)\n\n  def test_xxl(self):\n    size = 10<<40  # 10 TiB\n    num_examples = 10**9  # 1G\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 11264)\n\n  def test_xs(self):\n    size = 100<<20  # 100 MiB\n    num_examples = 100 * 10**3  # 100K\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 1)\n\n  def test_m(self):\n    size = 400<<20  # 499 MiB\n    num_examples = 200 * 10**3  # 200K\n    n = tfrecords_writer._get_number_shards(size, num_examples)\n    self.assertEqual(n, 4)\n\n\ndef _read_records(path):\n  """"""Returns (files_names, list_of_records_in_each_file).\n\n  Args:\n    path: path to tfrecord, omitting suffix.\n  """"""\n  paths = sorted(tf.io.gfile.glob(\'%s-*-of-*\' % path))\n  fnames = [os.path.basename(p) for p in paths]\n  all_recs = [list(dataset_utils.as_numpy(tf.data.TFRecordDataset(fpath)))\n              for fpath in paths]\n  return fnames, all_recs\n\n\nclass WriterTest(testing.TestCase):\n\n  EMPTY_SPLIT_ERROR = \'No examples were yielded.\'\n  TOO_SMALL_SPLIT_ERROR = \'num_examples (1) < number_of_shards (2)\'\n\n  @absltest.mock.patch.object(\n      example_serializer, \'ExampleSerializer\', testing.DummySerializer)\n  def _write(self, to_write, path, salt=\'\'):\n    writer = tfrecords_writer.Writer(\'some spec\', path, hash_salt=salt)\n    for key, record in to_write:\n      writer.write(key, record)\n    return writer.finalize()\n\n  def test_write(self):\n    """"""Writes 8 records in 5 shards.\n\n    Number of records is evenly distributed (2-1-2-1-2).\n    """"""\n    path = os.path.join(self.tmp_dir, \'foo.tfrecord\')\n    to_write = [\n        (1, b\'a\'), (2, b\'b\'),\n        (3, b\'c\'),\n        (4, b\'d\'), (5, b\'e\'),\n        (6, b\'f\'),\n        (7, b\'g\'), (8, b\'hi\'),\n    ]\n    with absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                                    return_value=5):\n      shards_length, total_size = self._write(to_write, path)\n    self.assertEqual(shards_length, [2, 1, 2, 1, 2])\n    self.assertEqual(total_size, 9)\n    written_files, all_recs = _read_records(path)\n    self.assertEqual(written_files,\n                     [\'foo.tfrecord-0000%s-of-00005\' % i for i in range(5)])\n    self.assertEqual(all_recs, [\n        [b\'f\', b\'g\'], [b\'d\'], [b\'a\', b\'b\'], [b\'hi\'], [b\'e\', b\'c\'],\n    ])\n\n  @absltest.mock.patch.object(\n      example_parser, \'ExampleParser\', testing.DummyParser)\n  def test_write_duplicated_keys(self):\n    path = os.path.join(self.tmp_dir, \'foo.tfrecord\')\n    to_write = [(1, b\'a\'), (2, b\'b\'), (1, b\'c\')]\n    with absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                                    return_value=1):\n      with self.assertRaisesWithPredicateMatch(\n          AssertionError, \'Two records share the same hashed key!\'):\n        self._write(to_write, path)\n\n  def test_empty_split(self):\n    path = os.path.join(self.tmp_dir, \'foo.tfrecord\')\n    to_write = []\n    with absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                                    return_value=1):\n      with self.assertRaisesWithPredicateMatch(\n          AssertionError, self.EMPTY_SPLIT_ERROR):\n        self._write(to_write, path)\n\n  def test_too_small_split(self):\n    path = os.path.join(self.tmp_dir, \'foo.tfrecord\')\n    to_write = [(1, b\'a\')]\n    with absltest.mock.patch.object(tfrecords_writer, \'_get_number_shards\',\n                                    return_value=2):\n      with self.assertRaisesWithPredicateMatch(\n          AssertionError, self.TOO_SMALL_SPLIT_ERROR):\n        self._write(to_write, path)\n\n\nclass TfrecordsWriterBeamTest(WriterTest):\n\n  EMPTY_SPLIT_ERROR = \'Not a single example present in the PCollection!\'\n\n  @absltest.mock.patch.object(\n      example_serializer, \'ExampleSerializer\', testing.DummySerializer)\n  def _write(self, to_write, path, salt=\'\'):\n    beam = lazy_imports_lib.lazy_imports.apache_beam\n    writer = tfrecords_writer.BeamWriter(\'some spec\', path, salt)\n    # Here we need to disable type check as `beam.Create` is not capable of\n    # inferring the type of the PCollection elements.\n    options = beam.options.pipeline_options.PipelineOptions(\n        pipeline_type_check=False)\n    with beam.Pipeline(options=options) as pipeline:\n      @beam.ptransform_fn\n      def _build_pcollection(pipeline):\n        pcollection = pipeline | \'Start\' >> beam.Create(to_write)\n        return writer.write_from_pcollection(pcollection)\n\n      _ = pipeline | \'test\' >> _build_pcollection()  # pylint: disable=no-value-for-parameter\n    return writer.finalize()\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/units.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Defines convenience constants/functions for converting various units.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# The constants below are used for conveniently defining memory quantities.\n# pylint: disable=invalid-name\nKiB = 2**10\nMiB = 2**20\nGiB = 2**30\nTiB = 2**40\nPiB = 2**50\n\n_NAME_LIST = [(""PiB"", PiB), (""TiB"", TiB), (""GiB"", GiB), (""MiB"", MiB),\n              (""KiB"", KiB)]\n\n\ndef size_str(size_in_bytes):\n  """"""Returns a human readable size string.\n\n  If size_in_bytes is None, then returns ""Unknown size"".\n\n  For example `size_str(1.5 * tfds.units.GiB) == ""1.50 GiB""`.\n\n  Args:\n    size_in_bytes: `int` or `None`, the size, in bytes, that we want to\n      format as a human-readable size string.\n  """"""\n  if not size_in_bytes:\n    return ""Unknown size""\n\n  size_in_bytes = float(size_in_bytes)\n  for (name, size_bytes) in _NAME_LIST:\n    value = size_in_bytes / size_bytes\n    if value >= 1.0:\n      return ""{:.2f} {}"".format(value, name)\n  return ""{} {}"".format(int(size_in_bytes), ""bytes"")\n\n\n# pylint: enable=invalid-name\n'"
tensorflow_datasets/core/units_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.units.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import units\n\n\nclass UnitsTest(testing.TestCase):\n\n  def test_none(self):\n    self.assertEqual(""Unknown size"", units.size_str(None))\n\n  def test_normal_sizes(self):\n    self.assertEqual(""1.50 PiB"", units.size_str(1.5 * units.PiB))\n    self.assertEqual(""1.50 TiB"", units.size_str(1.5 * units.TiB))\n    self.assertEqual(""1.50 GiB"", units.size_str(1.5 * units.GiB))\n    self.assertEqual(""1.50 MiB"", units.size_str(1.5 * units.MiB))\n    self.assertEqual(""1.50 KiB"", units.size_str(1.5 * units.KiB))\n\n  def test_bytes(self):\n    self.assertEqual(""150 bytes"", units.size_str(150))\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Image datasets.""""""\n\nfrom tensorflow_datasets.image.abstract_reasoning import AbstractReasoning\nfrom tensorflow_datasets.image.aflw2k3d import Aflw2k3d\nfrom tensorflow_datasets.image.arc import ARC\nfrom tensorflow_datasets.image.binarized_mnist import BinarizedMNIST\nfrom tensorflow_datasets.image.celeba import CelebA\nfrom tensorflow_datasets.image.celebahq import CelebAHq\nfrom tensorflow_datasets.image.cityscapes import Cityscapes\nfrom tensorflow_datasets.image.clevr import CLEVR\nfrom tensorflow_datasets.image.coil100 import Coil100\nfrom tensorflow_datasets.image.div2k import Div2k\nfrom tensorflow_datasets.image.downsampled_imagenet import DownsampledImagenet\nfrom tensorflow_datasets.image.dsprites import Dsprites\nfrom tensorflow_datasets.image.duke_ultrasound import DukeUltrasound\nfrom tensorflow_datasets.image.flic import Flic\nfrom tensorflow_datasets.image.lost_and_found import LostAndFound\nfrom tensorflow_datasets.image.lsun import Lsun\nfrom tensorflow_datasets.image.nyu_depth_v2 import NyuDepthV2\nfrom tensorflow_datasets.image.scene_parse_150 import SceneParse150\nfrom tensorflow_datasets.image.shapes3d import Shapes3d\nfrom tensorflow_datasets.image.the300w_lp import The300wLp\n\n# Legacy aliases\nfrom tensorflow_datasets.image_classification.beans import Beans\nfrom tensorflow_datasets.image_classification.bigearthnet import Bigearthnet\nfrom tensorflow_datasets.image_classification.binary_alpha_digits import BinaryAlphaDigits\nfrom tensorflow_datasets.image_classification.caltech import Caltech101\nfrom tensorflow_datasets.image_classification.caltech_birds import CaltechBirds2010\nfrom tensorflow_datasets.image_classification.cars196 import Cars196\nfrom tensorflow_datasets.image_classification.cassava import Cassava\nfrom tensorflow_datasets.image_classification.cats_vs_dogs import CatsVsDogs\nfrom tensorflow_datasets.image_classification.cbis_ddsm import CuratedBreastImagingDDSM\nfrom tensorflow_datasets.image_classification.chexpert import Chexpert\nfrom tensorflow_datasets.image_classification.cifar import Cifar10\nfrom tensorflow_datasets.image_classification.cifar import Cifar100\nfrom tensorflow_datasets.image_classification.cifar10_1 import Cifar10_1\nfrom tensorflow_datasets.image_classification.cifar10_corrupted import Cifar10Corrupted\nfrom tensorflow_datasets.image_classification.citrus import CitrusLeaves\nfrom tensorflow_datasets.image_classification.cmaterdb import Cmaterdb\nfrom tensorflow_datasets.image_classification.colorectal_histology import ColorectalHistology\nfrom tensorflow_datasets.image_classification.colorectal_histology import ColorectalHistologyLarge\nfrom tensorflow_datasets.image_classification.cycle_gan import CycleGAN\nfrom tensorflow_datasets.image_classification.deep_weeds import DeepWeeds\nfrom tensorflow_datasets.image_classification.diabetic_retinopathy_detection import DiabeticRetinopathyDetection\nfrom tensorflow_datasets.image_classification.dmlab import Dmlab\nfrom tensorflow_datasets.image_classification.dtd import Dtd\nfrom tensorflow_datasets.image_classification.eurosat import Eurosat\nfrom tensorflow_datasets.image_classification.flowers import TFFlowers\nfrom tensorflow_datasets.image_classification.food101 import Food101\nfrom tensorflow_datasets.image_classification.geirhos_conflict_stimuli import GeirhosConflictStimuli\nfrom tensorflow_datasets.image_classification.horses_or_humans import HorsesOrHumans\nfrom tensorflow_datasets.image_classification.image_folder import ImageLabelFolder\nfrom tensorflow_datasets.image_classification.imagenet import Imagenet2012\nfrom tensorflow_datasets.image_classification.imagenet2012_corrupted import Imagenet2012Corrupted\nfrom tensorflow_datasets.image_classification.imagenet2012_subset import Imagenet2012Subset\nfrom tensorflow_datasets.image_classification.imagenet_resized import ImagenetResized\nfrom tensorflow_datasets.image_classification.imagenette import Imagenette\nfrom tensorflow_datasets.image_classification.imagewang import Imagewang\nfrom tensorflow_datasets.image_classification.inaturalist import INaturalist2017\nfrom tensorflow_datasets.image_classification.lfw import LFW\nfrom tensorflow_datasets.image_classification.malaria import Malaria\nfrom tensorflow_datasets.image_classification.mnist import EMNIST\nfrom tensorflow_datasets.image_classification.mnist import FashionMNIST\nfrom tensorflow_datasets.image_classification.mnist import KMNIST\nfrom tensorflow_datasets.image_classification.mnist import MNIST\nfrom tensorflow_datasets.image_classification.mnist_corrupted import MNISTCorrupted\nfrom tensorflow_datasets.image_classification.omniglot import Omniglot\nfrom tensorflow_datasets.image_classification.oxford_flowers102 import OxfordFlowers102\nfrom tensorflow_datasets.image_classification.oxford_iiit_pet import OxfordIIITPet\nfrom tensorflow_datasets.image_classification.patch_camelyon import PatchCamelyon\nfrom tensorflow_datasets.image_classification.pet_finder import PetFinder\nfrom tensorflow_datasets.image_classification.places365_small import Places365Small\nfrom tensorflow_datasets.image_classification.plant_leaves import PlantLeaves\nfrom tensorflow_datasets.image_classification.plant_village import PlantVillage\nfrom tensorflow_datasets.image_classification.plantae_k import PlantaeK\nfrom tensorflow_datasets.image_classification.quickdraw import QuickdrawBitmap\nfrom tensorflow_datasets.image_classification.resisc45 import Resisc45\nfrom tensorflow_datasets.image_classification.rock_paper_scissors import RockPaperScissors\nfrom tensorflow_datasets.image_classification.smallnorb import Smallnorb\nfrom tensorflow_datasets.image_classification.so2sat import So2sat\nfrom tensorflow_datasets.image_classification.stanford_dogs import StanfordDogs\nfrom tensorflow_datasets.image_classification.stanford_online_products import StanfordOnlineProducts\nfrom tensorflow_datasets.image_classification.sun import Sun397\nfrom tensorflow_datasets.image_classification.svhn import SvhnCropped\nfrom tensorflow_datasets.image_classification.uc_merced import UcMerced\nfrom tensorflow_datasets.image_classification.vgg_face2 import VggFace2\nfrom tensorflow_datasets.image_classification.visual_domain_decathlon import VisualDomainDecathlon\n'"
tensorflow_datasets/image/abstract_reasoning.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""AbstractReasoning data set.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{pmlr-v80-barrett18a,\n  title = \t {Measuring abstract reasoning in neural networks},\n  author = \t {Barrett, David and Hill, Felix and Santoro, Adam and Morcos, Ari and Lillicrap, Timothy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {511--520},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Stockholmsmassan, Stockholm Sweden},\n  month = \t {10--15 Jul},\n  publisher = \t {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/barrett18a/barrett18a.pdf},\n  url = \t {http://proceedings.mlr.press/v80/barrett18a.html},\n  abstract = \t {Whether neural networks can learn abstract reasoning or whether\\\nthey merely rely on superficial statistics is a topic of recent debate. Here, \\\nwe propose a dataset and challenge designed to probe abstract reasoning, \\\ninspired by a well-known human IQ test. To succeed at this challenge, models \\\nmust cope with various generalisation \'regimes\' in which the training data and \\\ntest questions differ in clearly-defined ways. We show that popular models \\\nsuch as ResNets perform poorly, even when the training and test sets differ \\\nonly minimally, and we present a novel architecture, with structure designed \\\nto encourage reasoning, that does significantly better. When we vary the way \\\nin which the test questions and training data differ, we find that our model \\\nis notably proficient at certain forms of generalisation, but notably weak at \\\nothers. We further show that the model\'s ability to generalise improves \\\nmarkedly if it is trained to predict symbolic explanations for its answers. \\\nAltogether, we introduce and explore ways to both measure and induce stronger \\\nabstract reasoning in neural networks. Our freely-available dataset should \\\nmotivate further progress in this direction.}\n}\n""""""\n\n_URL = (""https://github.com/deepmind/abstract-reasoning-matrices"")\n\n_DESCRIPTION = """"""\\\nProcedurally Generated Matrices (PGM) data from the paper Measuring Abstract \\\nReasoning in Neural Networks, Barrett, Hill, Santoro et al. 2018. The goal is \\\nto infer the correct answer from the context panels based on abstract \\\nreasoning.\n\nTo use this data set, please download all the *.tar.gz files from the data set \\\npage and place them in ~/tensorflow_datasets/abstract_reasoning/.\n\n$R$ denotes the set of relation types (progression, XOR, OR, AND, \\\nconsistent union), $O$ denotes the object types (shape, line), and $A$ denotes \\\nthe attribute types (size, colour, position, number). The structure of a \\\nmatrix, $S$, is the set of triples $S={[r, o, a]}$ that determine the \\\nchallenge posed by a particular matrix.\n""""""\n\n_DESCRIPTION_NEUTRAL = r""""""The structures encoding the matrices in both the \\\ntraining and testing sets contain any triples $[r, o, a]$ for $r \\\\in R$, \\\n$o \\\\in O$, and $a \\\\in A$. Training and testing sets are disjoint, with \\\nseparation occurring at the level of the input variables (i.e. pixel \\\nmanifestations).""""""\n\n_DESCRIPTION_INTERPOLATION = r""""""As in the neutral split, $S$ consisted of any \\\ntriples $[r, o, a]$. For interpolation, in the training set, when the \\\nattribute was ""colour"" or ""size"" (i.e., the ordered attributes), the values of \\\nthe attributes were restricted to even-indexed members of a discrete set, \\\nwhereas in the test set only odd-indexed values were permitted. Note that all \\\n$S$ contained some triple $[r, o, a]$ with the colour or size attribute . \\\nThus, generalisation is required for every question in the test set.""""""\n\n_DESCRIPTION_EXTRAPOLATION = r""""""Same as in interpolation, but the values of \\\nthe attributes were restricted to the lower half of the discrete set during \\\ntraining, whereas in the test set they took values in the upper half.""""""\n\n_DESCRIPTION_ATTR_REL_PAIRS = r""""""All $S$ contained at least two triples, \\\n$([r_1,o_1,a_1],[r_2,o_2,a_2]) = (t_1, t_2)$, of which 400 are viable. We \\\nrandomly allocated 360 to the training set and 40 to the test set. Members \\\n$(t_1, t_2)$ of the 40 held-out pairs did not occur together in structures $S$ \\\nin the training set, and all structures $S$ had at least one such pair \\\n$(t_1, t_2)$ as a subset.""""""\n\n_DESCRIPTION_ATTR_RELS = r""""""In our dataset, there are 29 possible unique \\\ntriples $[r,o,a]$. We allocated seven of these for the test set, at random, \\\nbut such that each of the attributes was represented exactly once in this set. \\\nThese held-out triples never occurred in questions in the training set, and \\\nevery $S$ in the test set contained at least one of them.""""""\n\n_DESCRIPTION_ATTR_PAIRS = r""""""$S$ contained at least two triples. There are 20 \\\n(unordered) viable pairs of attributes $(a_1, a_2)$ such that for some \\\n$r_i, o_i, ([r_1,o_1,a_1],[r_2,o_2,a_2])$ is a viable triple pair \\\n$([r_1,o_1,a_1],[r_2,o_2,a_2]) = (t_1, t_2)$. We allocated 16 of these pairs \\\nfor training and four for testing. For a pair $(a_1, a_2)$ in the test set, \\\n$S$ in the training set contained triples with $a_1$ or $a_2$. In the test \\\nset, all $S$ contained triples with $a_1$ and $a_2$.""""""\n\n_DESCRIPTION_ATTR_SHAPE_COLOR = r""""""Held-out attribute shape-colour. $S$ in \\\nthe training set contained no triples with $o$=shape and $a$=colour. \\\nAll structures governing puzzles in the test set contained at least one triple \\\nwith $o$=shape and $a$=colour.""""""\n\n_DESCRIPTION_ATTR_LINE_TYPE = r""""""Held-out attribute line-type. $S$ in \\\nthe training set contained no triples with $o$=line and $a$=type. \\\nAll structures governing puzzles in the test set contained at least one triple \\\nwith $o$=line and $a$=type.""""""\n\n\nclass AbstractReasoningConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for AbstractReasoning.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, split_type=""neutral"", **kwargs):\n    """"""BuilderConfig for AbstractReasoning.\n\n    Args:\n      split_type: String with split_type to use. Should be one of [""neutral"",\n        ""interpolation"", ""extrapolation"", ""attr.rel.pairs"", ""attr.rels"",\n        ""attrs.pairs"", ""attrs.shape.color"", ""attrs.line.type"",].\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    v100 = tfds.core.Version(\n        ""1.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n    super(AbstractReasoningConfig, self).__init__(\n        version=v100,\n        **kwargs)\n    self.split_type = split_type\n\n\nclass AbstractReasoning(tfds.core.BeamBasedBuilder):\n  """"""Abstract reasoning dataset.""""""\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Data can be downloaded from\n  https://console.cloud.google.com/storage/browser/ravens-matrices\n  Please put all the tar.gz files in manual_dir.\n  """"""\n\n  BUILDER_CONFIGS = [\n      AbstractReasoningConfig(\n          name=""neutral"",\n          description=_DESCRIPTION_NEUTRAL,\n      ),\n      AbstractReasoningConfig(\n          name=""interpolation"",\n          description=_DESCRIPTION_INTERPOLATION,\n          split_type=""interpolation"",\n      ),\n      AbstractReasoningConfig(\n          name=""extrapolation"",\n          description=_DESCRIPTION_EXTRAPOLATION,\n          split_type=""extrapolation"",\n      ),\n      AbstractReasoningConfig(\n          name=""attr.rel.pairs"",\n          description=_DESCRIPTION_ATTR_REL_PAIRS,\n          split_type=""attr.rel.pairs"",\n      ),\n      AbstractReasoningConfig(\n          name=""attr.rels"",\n          description=_DESCRIPTION_ATTR_RELS,\n          split_type=""attr.rels"",\n      ),\n      AbstractReasoningConfig(\n          name=""attrs.pairs"",\n          description=_DESCRIPTION_ATTR_PAIRS,\n          split_type=""attrs.pairs"",\n      ),\n      AbstractReasoningConfig(\n          name=""attrs.shape.color"",\n          description=_DESCRIPTION_ATTR_SHAPE_COLOR,\n          split_type=""attrs.shape.color"",\n      ),\n      AbstractReasoningConfig(\n          name=""attrs.line.type"",\n          description=_DESCRIPTION_ATTR_LINE_TYPE,\n          split_type=""attrs.line.type"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""context"": tfds.features.Video(shape=(8, 160, 160, 1)),\n            ""answers"": tfds.features.Video(shape=(8, 160, 160, 1)),\n            ""target"":\n                tfds.features.ClassLabel(num_classes=8),\n            ""meta_target"":\n                tfds.features.Tensor(shape=[12], dtype=tf.int64),\n            ""relation_structure_encoded"":\n                tfds.features.Tensor(shape=[4, 12], dtype=tf.int64),\n            ""filename"":\n                tfds.features.Text(),\n        }),\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.manual_dir\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""folder"": path,\n                ""split"": ""train"",\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""folder"": path,\n                ""split"": ""val"",\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""folder"": path,\n                ""split"": ""test"",\n            }),\n    ]\n\n  def _build_pcollection(self, pipeline, folder, split):\n    """"""Generate examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    split_type = self.builder_config.split_type\n    filename = os.path.join(folder, ""{}.tar.gz"".format(split_type))\n\n    def _extract_data(inputs):\n      """"""Extracts files from the tar archives.""""""\n      filename, split = inputs\n      for name, fobj in tfds.download.iter_archive(\n          filename, tfds.download.ExtractMethod.TAR_STREAM):\n        split_name = name.split(""_"")\n        if len(split_name) > 2 and split_name[2] == split:\n          yield [name, fobj.read()]\n\n    def _process_example(inputs):\n      filename, data_string = inputs\n      buf = six.BytesIO(data_string)\n      buf.seek(0)\n      data = np.load(buf)\n      # Extract the images and convert to uint8. The reshape is required, see\n      # https://github.com/deepmind/abstract-reasoning-matrices.\n      all_images = np.uint8(data[""image""].reshape(16, 160, 160, 1))\n      return filename, {\n          ""relation_structure_encoded"": data[""relation_structure_encoded""],\n          ""target"": data[""target""],\n          ""meta_target"": data[""meta_target""],\n          ""context"": all_images[:8],\n          ""answers"": all_images[8:],\n          ""filename"": filename,\n      }\n\n    # Beam might fuse together the _extract_data and _process_example which\n    # defeats the purpose of parallel processing. As a result, we reshard by\n    # doing a GroupByKey on random keys, and then flattening again.\n    def _add_random_keys(inputs):\n      key = str(random.randrange(10**10))\n      return key, inputs\n\n    def _remove_keys(inputs):\n      _, rows = inputs\n      for row in rows:\n        yield row\n\n    return (pipeline\n            | beam.Create([(filename, split)])\n            | beam.FlatMap(_extract_data)\n            | beam.Map(_add_random_keys)\n            | beam.GroupByKey()\n            | beam.FlatMap(_remove_keys)\n            | beam.Map(_process_example))\n'"
tensorflow_datasets/image/abstract_reasoning_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""AbstractReasoning dataset test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image import abstract_reasoning\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass AbstractReasoningTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = abstract_reasoning.AbstractReasoning\n  SPLITS = {""train"": 5, ""validation"": 5, ""test"": 5}\n  DL_EXTRACT_RESULT = [\n      ""neutral.tar.gz"",\n      ""interpolation.tar.gz"",\n      ""extrapolation.tar.gz"",\n      ""attr.rel.pairs.tar.gz"",\n      ""attr.rels.tar.gz"",\n      ""attrs.pairs.tar.gz"",\n      ""attrs.shape.color.tar.gz"",\n      ""attrs.line.type.tar.gz"",\n  ]\n  # The configs only differ in the data contained in the files.\n  BUILDER_CONFIG_NAMES_TO_TEST = [""neutral""]\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image/aflw2k3d.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""AFLW2000-3D Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nAFLW2000-3D is a dataset of 2000 images that have been annotated with image-level\n68-point 3D facial landmarks.\nThis dataset is typically used for evaluation of 3D facial landmark detection\nmodels. The head poses are very diverse and often hard to be detected by a \ncnn-based face detector.\nThe 2D landmarks are skipped in this dataset, since some of the data are not\nconsistent to 21 points, as the original paper mentioned.\n""""""\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/ZhuLLSL15,\n  author    = {Xiangyu Zhu and\n               Zhen Lei and\n               Xiaoming Liu and\n               Hailin Shi and\n               Stan Z. Li},\n  title     = {Face Alignment Across Large Poses: {A} 3D Solution},\n  journal   = {CoRR},\n  volume    = {abs/1511.07212},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1511.07212},\n  archivePrefix = {arXiv},\n  eprint    = {1511.07212},\n  timestamp = {Mon, 13 Aug 2018 16:48:23 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuLLSL15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n\nclass Aflw2k3d(tfds.core.GeneratorBasedBuilder):\n  """"""AFLW2000-3D dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(\n                    shape=(450, 450, 3), encoding_format=""jpeg""),\n            ""landmarks_68_3d_xy_normalized"":\n                tfds.features.Tensor(shape=(68, 2), dtype=tf.float32),\n            ""landmarks_68_3d_z"":\n                tfds.features.Tensor(shape=(68, 1), dtype=tf.float32),\n        }),\n        homepage=\n        ""http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    extracted_path = dl_manager.download_and_extract(\n        ""http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/Database/AFLW2000-3D.zip""\n    )\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""image_dir_path"": os.path.join(extracted_path, ""AFLW2000""),\n            }),\n    ]\n\n  def _generate_examples(self, image_dir_path):\n    image_files = tf.io.gfile.glob(\n        pattern=os.path.join(image_dir_path, ""image0*.jpg""))\n    label_files = [s.replace(""jpg"", ""mat"") for s in image_files]\n\n    for image_file, label_file in zip(image_files, label_files):\n      with tf.io.gfile.GFile(label_file, ""rb"") as f:\n        mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n      landmarks_68_3d_xyz = mat[""pt3d_68""].T.astype(np.float32)\n      landmarks_68_3d_xy_normalized = landmarks_68_3d_xyz[..., 0:2] / 450.0\n      landmarks_68_3d_z = landmarks_68_3d_xyz[..., 2:]\n      yield os.path.basename(image_file), {\n          ""image"": image_file,\n          ""landmarks_68_3d_xy_normalized"": landmarks_68_3d_xy_normalized,\n          ""landmarks_68_3d_z"": landmarks_68_3d_z,\n      }\n'"
tensorflow_datasets/image/aflw2k3d_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for AFLW2000-3D dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import aflw2k3d\nimport tensorflow_datasets.public_api as tfds\n\n\nclass Aflw2k3dTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = aflw2k3d.Aflw2k3d\n  SPLITS = {\n      tfds.Split.TRAIN: 2,\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image/arc.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""ARC dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{chollet_francois_2019,\n  title     = {The Measure of Intelligence},\n  url       = {https://arxiv.org/abs/1911.01547},\n  journal   = {arXiv.org},\n  author    = {Francois Chollet},\n  year      = {2019},\n  month     = {Nov}\n}\n""""""\n\n_DESCRIPTION = """"""\nARC can be seen as a general artificial intelligence benchmark, as a program\nsynthesis benchmark, or as a psychometric intelligence test. It is targeted at\nboth humans and artificially intelligent systems that aim at emulating a\nhuman-like form of general fluid intelligence.\n""""""\n\n_BASE_URL = ""https://github.com/fchollet/ARC/""\n\n\nclass ARCConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for ARC.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, version, commit, **kwargs):\n    """"""BuilderConfig for ARC.\n\n    Args:\n      version (string): version as string.\n      commit: github.com/fchollet/ARC commit to use (defaults to ""master"").\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(ARCConfig, self).__init__(\n        version=tfds.core.Version(version), **kwargs)\n    self.commit = commit\n    self.download_url = ""{}zipball/{}"".format(_BASE_URL, self.commit)\n    self.download_resource = tfds.download.Resource(\n        url=self.download_url, extract_method=tfds.download.ExtractMethod.ZIP)\n\n\nclass ARC(tfds.core.GeneratorBasedBuilder):\n  """"""The Abstraction and Reasoning Corpus (ARC).""""""\n\n  BUILDER_CONFIGS = [\n      ARCConfig(\n          name=""2019-12-06"",\n          version=""1.0.0"",\n          description=""ARC commit bd9e2c9 from 2019-12-06"",\n          commit=""bd9e2c934c83d00251b7b4781ffc38cd167c885f""),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            # Grids are of varying size\n            ""task_id"":\n                tfds.features.Text(),\n            ""train"":\n                tfds.features.Sequence({\n                    ""input"":\n                        tfds.features.Sequence(\n                            tfds.features.Sequence(tf.int32)),\n                    ""output"":\n                        tfds.features.Sequence(\n                            tfds.features.Sequence(tf.int32)),\n                }),\n            ""test"":\n                tfds.features.Sequence({\n                    ""input"":\n                        tfds.features.Sequence(\n                            tfds.features.Sequence(tf.int32)),\n                    ""output"":\n                        tfds.features.Sequence(\n                            tfds.features.Sequence(tf.int32)),\n                })\n        }),\n        # If there\'s a common (input, target) tuple from the features,\n        # specify them here. They\'ll be used if as_supervised=True in\n        # builder.as_dataset.\n        supervised_keys=None,\n        # Homepage of the dataset for documentation\n        homepage=_BASE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Downloads the data, defines the splits and returns SplitGenerators.""""""\n\n    # dl_manager is a tfds.download.DownloadManager that can be used to\n    # download and extract URLs\n    extracted_dir = dl_manager.download_and_extract(\n        self.builder_config.download_resource)\n    extract_subdir = [\n        path for path in tf.io.gfile.listdir(extracted_dir)\n        if path.startswith(""fchollet-ARC-"")\n    ]\n    if len(extract_subdir) != 1:\n      raise ValueError(""Unexpected ARC archive format"")\n    data_dir = os.path.join(extracted_dir, extract_subdir[0], ""data"")\n    train_dir = os.path.join(data_dir, ""training"")\n    test_dir = os.path.join(data_dir, ""evaluation"")\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN, gen_kwargs={\n                ""directory"": train_dir,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST, gen_kwargs={\n                ""directory"": test_dir,\n            }),\n    ]\n\n  def _generate_examples(self, directory):\n    """"""Yields (key, example) tuples from the dataset.""""""\n    json_filepaths = tf.io.gfile.glob(os.path.join(directory, ""*.json""))\n    for json_path in sorted(json_filepaths):\n      with tf.io.gfile.GFile(json_path) as f:\n        task = json.load(f)\n      task_id = os.path.basename(json_path)[:-len("".json"")]\n      yield task_id, {\n          ""task_id"": task_id,\n          ""train"": task[""train""],\n          ""test"": task[""test""],\n      }\n'"
tensorflow_datasets/image/arc_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the ARC dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import arc\n\n\nclass ArcTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = arc.ARC\n  SPLITS = {\n      ""train"": 10,  # Number of fake train example\n      ""test"": 5,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/binarized_mnist.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BinarizedMNIST.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.image_classification import mnist\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{salakhutdinov2008quantitative,\ntitle={On the quantitative analysis of deep belief networks},\nauthor={Salakhutdinov, Ruslan and Murray, Iain},\nbooktitle={Proceedings of the 25th international conference on Machine learning},\npages={872--879},\nyear={2008},\norganization={ACM}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nA specific binarization of the MNIST images originally used in\n(Salakhutdinov & Murray, 2008). This dataset is frequently used to evaluate\ngenerative models of images, so labels are not provided.\n""""""\n\n_URL = ""http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/""\n_TRAIN_DATA_FILENAME = ""binarized_mnist_train.amat""\n_VALID_DATA_FILENAME = ""binarized_mnist_valid.amat""\n_TEST_DATA_FILENAME = ""binarized_mnist_test.amat""\n\n\nclass BinarizedMNIST(tfds.core.GeneratorBasedBuilder):\n  """"""A specific binarization of the MNIST dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(\n                shape=mnist.MNIST_IMAGE_SHAPE)}),\n        homepage=\n        ""http://www.dmi.usherb.ca/~larocheh/mlpython/_modules/datasets/binarized_mnist.html"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    filenames = {\n        ""train_data"": _TRAIN_DATA_FILENAME,\n        ""validation_data"": _VALID_DATA_FILENAME,\n        ""test_data"": _TEST_DATA_FILENAME,\n    }\n    files = dl_manager.download(\n        {k: urllib.parse.urljoin(_URL, v) for k, v in filenames.items()})\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                data_path=files[""train_data""],\n            )),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(\n                data_path=files[""validation_data""],\n            )),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                data_path=files[""test_data""],\n            )),\n    ]\n\n  def _generate_examples(self, data_path):\n    """"""Generate Binarized MNIST examples as dicts.\n\n    Args:\n      data_path (str): Path to the data files\n\n    Yields:\n      Generator yielding the next examples\n    """"""\n    with tf.io.gfile.GFile(data_path, ""rb"") as f:\n      images = (np.loadtxt(f, delimiter="" "", dtype=np.uint8)\n                .reshape((-1,) + mnist.MNIST_IMAGE_SHAPE))\n    for index, image in enumerate(images):\n      yield index, {""image"": image}\n'"
tensorflow_datasets/image/binarized_mnist_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for binarized_mnist dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import binarized_mnist\n\n\n# testing/binarized_mnist.py generates fake input data\n\n\nclass MNISTTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = binarized_mnist.BinarizedMNIST\n  SPLITS = {\n      ""train"": 10,\n      ""validation"": 2,\n      ""test"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_data"": binarized_mnist._TRAIN_DATA_FILENAME,\n      ""validation_data"": binarized_mnist._VALID_DATA_FILENAME,\n      ""test_data"": binarized_mnist._TEST_DATA_FILENAME,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/celeba.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CelebA dataset.\n\nLarge-scale CelebFaces Attributes (CelebA) Dataset\n\nDeep Learning Face Attributes in the Wild\nZiwei Liu and Ping Luo and Xiaogang Wang and Xiaoou Tang\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\nIMG_ALIGNED_DATA = (""https://drive.google.com/uc?export=download&""\n                    ""id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"")\nEVAL_LIST = (""https://drive.google.com/uc?export=download&""\n             ""id=0B7EVK8r0v71pY0NSMzRuSXJEVkk"")\n# Landmark coordinates: left_eye, right_eye etc.\nLANDMARKS_DATA = (""https://drive.google.com/uc?export=download&""\n                  ""id=0B7EVK8r0v71pd0FJY3Blby1HUTQ"")\n\n# Attributes in the image (Eyeglasses, Mustache etc).\nATTR_DATA = (""https://drive.google.com/uc?export=download&""\n             ""id=0B7EVK8r0v71pblRyaVFSWGxPY0U"")\n\nLANDMARK_HEADINGS = (""lefteye_x lefteye_y righteye_x righteye_y ""\n                     ""nose_x nose_y leftmouth_x leftmouth_y rightmouth_x ""\n                     ""rightmouth_y"").split()\nATTR_HEADINGS = (\n    ""5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs ""\n    ""Big_Lips Big_Nose Black_Hair Blond_Hair Blurry Brown_Hair ""\n    ""Bushy_Eyebrows Chubby Double_Chin Eyeglasses Goatee Gray_Hair ""\n    ""Heavy_Makeup High_Cheekbones Male Mouth_Slightly_Open Mustache ""\n    ""Narrow_Eyes No_Beard Oval_Face Pale_Skin Pointy_Nose Receding_Hairline ""\n    ""Rosy_Cheeks Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings ""\n    ""Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young""\n).split()\n\n\n_CITATION = """"""\\\n@inproceedings{conf/iccv/LiuLWT15,\n  added-at = {2018-10-09T00:00:00.000+0200},\n  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},\n  biburl = {https://www.bibsonomy.org/bibtex/250e4959be61db325d2f02c1d8cd7bfbb/dblp},\n  booktitle = {ICCV},\n  crossref = {conf/iccv/2015},\n  ee = {http://doi.ieeecomputersociety.org/10.1109/ICCV.2015.425},\n  interhash = {3f735aaa11957e73914bbe2ca9d5e702},\n  intrahash = {50e4959be61db325d2f02c1d8cd7bfbb},\n  isbn = {978-1-4673-8391-2},\n  keywords = {dblp},\n  pages = {3730-3738},\n  publisher = {IEEE Computer Society},\n  timestamp = {2018-10-11T11:43:28.000+0200},\n  title = {Deep Learning Face Attributes in the Wild.},\n  url = {http://dblp.uni-trier.de/db/conf/iccv/iccv2015.html#LiuLWT15},\n  year = 2015\n}\n""""""\n\n_DESCRIPTION = """"""\\\nCelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset\\\n with more than 200K celebrity images, each with 40 attribute annotations. The \\\nimages in this dataset cover large pose variations and background clutter. \\\nCelebA has large diversities, large quantities, and rich annotations, including\\\n\n - 10,177 number of identities,\n - 202,599 number of face images, and\n - 5 landmark locations, 40 binary attributes annotations per image.\n\nThe dataset can be employed as the training and test sets for the following \\\ncomputer vision tasks: face attribute recognition, face detection, and landmark\\\n (or facial part) localization.\n""""""\n\n\nclass CelebA(tfds.core.GeneratorBasedBuilder):\n  """"""CelebA dataset. Aligned and cropped. With metadata.""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.1"", ""New split API (https://tensorflow.org/datasets/splits)"")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""2.0.0""),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(\n                    shape=(218, 178, 3), encoding_format=""jpeg""),\n            ""landmarks"": {name: tf.int64 for name in LANDMARK_HEADINGS},\n            # Attributes could be some special MultiLabel FeatureConnector\n            ""attributes"": {\n                name: tf.bool for name in ATTR_HEADINGS\n            },\n        }),\n        homepage=""http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    downloaded_dirs = dl_manager.download({\n        ""img_align_celeba"": IMG_ALIGNED_DATA,\n        ""list_eval_partition"": EVAL_LIST,\n        ""list_attr_celeba"": ATTR_DATA,\n        ""landmarks_celeba"": LANDMARKS_DATA,\n    })\n\n    # Load all images in memory (~1 GiB)\n    # Use split to convert: `img_align_celeba/000005.jpg` -> `000005.jpg`\n    all_images = {\n        os.path.split(k)[-1]: img for k, img in\n        dl_manager.iter_archive(downloaded_dirs[""img_align_celeba""])\n    }\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""file_id"": 0,\n                ""downloaded_dirs"": downloaded_dirs,\n                ""downloaded_images"": all_images,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""file_id"": 1,\n                ""downloaded_dirs"": downloaded_dirs,\n                ""downloaded_images"": all_images,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""file_id"": 2,\n                ""downloaded_dirs"": downloaded_dirs,\n                ""downloaded_images"": all_images,\n            })\n    ]\n\n  def _process_celeba_config_file(self, file_path):\n    """"""Unpack the celeba config file.\n\n    The file starts with the number of lines, and a header.\n    Afterwards, there is a configuration for each file: one per line.\n\n    Args:\n      file_path: Path to the file with the configuration.\n\n    Returns:\n      keys: names of the attributes\n      values: map from the file name to the list of attribute values for\n              this file.\n    """"""\n    with tf.io.gfile.GFile(file_path) as f:\n      data_raw = f.read()\n    lines = data_raw.split(""\\n"")\n\n    keys = lines[1].strip().split()\n    values = {}\n    # Go over each line (skip the last one, as it is empty).\n    for line in lines[2:-1]:\n      row_values = line.strip().split()\n      # Each row start with the \'file_name\' and then space-separated values.\n      values[row_values[0]] = [int(v) for v in row_values[1:]]\n    return keys, values\n\n  def _generate_examples(self, file_id, downloaded_dirs, downloaded_images):\n    """"""Yields examples.""""""\n\n    img_list_path = downloaded_dirs[""list_eval_partition""]\n    landmarks_path = downloaded_dirs[""landmarks_celeba""]\n    attr_path = downloaded_dirs[""list_attr_celeba""]\n\n    with tf.io.gfile.GFile(img_list_path) as f:\n      files = [\n          line.split()[0]\n          for line in f.readlines()\n          if int(line.split()[1]) == file_id\n      ]\n\n    attributes = self._process_celeba_config_file(attr_path)\n    landmarks = self._process_celeba_config_file(landmarks_path)\n\n    for file_name in sorted(files):\n      record = {\n          ""image"": downloaded_images[file_name],\n          ""landmarks"": {\n              k: v for k, v in zip(landmarks[0], landmarks[1][file_name])\n          },\n          ""attributes"": {\n              # atributes value are either 1 or -1, so convert to bool\n              k: v > 0 for k, v in zip(attributes[0], attributes[1][file_name])\n          },\n      }\n      yield file_name, record\n'"
tensorflow_datasets/image/celeba_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.image.celeba.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import celeba\n\n\nclass CelebATest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = celeba.CelebA\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""img_align_celeba"": ""img_align_celeba.zip"",\n      ""list_eval_partition"": ""list_eval_partition.txt"",\n      ""list_attr_celeba"": ""list_attr_celeba.txt"",\n      ""landmarks_celeba"": ""list_landmarks_align_celeba.txt"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/celebahq.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Celeba-HQ dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1710-10196,\n  author    = {Tero Karras and\n               Timo Aila and\n               Samuli Laine and\n               Jaakko Lehtinen},\n  title     = {Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  journal   = {CoRR},\n  volume    = {abs/1710.10196},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1710.10196},\n  archivePrefix = {arXiv},\n  eprint    = {1710.10196},\n  timestamp = {Mon, 13 Aug 2018 16:46:42 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-10196},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nHigh-quality version of the CELEBA\ndataset, consisting of 30000 images in 1024 x 1024 resolution.\n\nWARNING: This dataset currently requires you to prepare images on your own.\n""""""\n\n\nclass CelebaHQConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CelebaHQ.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, resolution, **kwargs):\n    """"""BuilderConfig for SQUAD.\n\n    Args:\n      resolution: Resolution of the image. Values supported: powers of 2 up to\n        1024.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    v2 = tfds.core.Version(\n        ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n    super(CelebaHQConfig, self).__init__(\n        name=""%d"" % resolution,\n        description=(""CelebaHQ images in %d x %d resolution"" %\n                     (resolution, resolution)),\n        version=v2,\n        **kwargs)\n    self.resolution = resolution\n    self.file_name = ""data%dx%d.tar"" % (resolution, resolution)\n\n\nclass CelebAHq(tfds.core.GeneratorBasedBuilder):\n  """"""Celeba_HQ Dataset.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  manual_dir should contain multiple tar files with images (data2x2.tar,\n  data4x4.tar .. data1024x1024.tar).\n  Detailed instructions are here:\n  https://github.com/tkarras/progressive_growing_of_gans#preparing-datasets-for-training\n  """"""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  BUILDER_CONFIGS = [\n      CelebaHQConfig(resolution=1024),\n      CelebaHQConfig(resolution=512),\n      CelebaHQConfig(resolution=256),\n      CelebaHQConfig(resolution=128),\n      CelebaHQConfig(resolution=64),\n      CelebaHQConfig(resolution=32),\n      CelebaHQConfig(resolution=16),\n      CelebaHQConfig(resolution=8),\n      CelebaHQConfig(resolution=4),\n      CelebaHQConfig(resolution=2),\n      CelebaHQConfig(resolution=1),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(\n                    shape=(self.builder_config.resolution,\n                           self.builder_config.resolution, 3),\n                    encoding_format=""png""),\n            ""image/filename"":\n                tfds.features.Text(),\n        },),\n        homepage=""https://github.com/tkarras/progressive_growing_of_gans"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    image_tar_file = os.path.join(dl_manager.manual_dir,\n                                  self.builder_config.file_name)\n    if not tf.io.gfile.exists(image_tar_file):\n      # The current celebahq generation code depends on a concrete version of\n      # pillow library and cannot be easily ported into tfds.\n      msg = ""You must download the dataset files manually and place them in: ""\n      msg += dl_manager.manual_dir\n      msg += "" as .tar files. See testing/test_data/fake_examples/celeb_a_hq ""\n      raise AssertionError(msg)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""archive"": dl_manager.iter_archive(image_tar_file)},\n        )\n    ]\n\n  def _generate_examples(self, archive):\n    for fname, fobj in archive:\n      record = {""image"": fobj, ""image/filename"": fname}\n      yield fname, record\n'"
tensorflow_datasets/image/celebahq_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.image.celebahq.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image import celebahq\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass CelebAHQTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = celebahq.CelebAHq\n  BUILDER_CONFIG_NAMES_TO_TEST = [""512""]\n\n  SPLITS = {\n      ""train"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image/cityscapes.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Cityscapes Datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import api_utils\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = \'\'\'\\\n@inproceedings{Cordts2016Cityscapes,\n  title={The Cityscapes Dataset for Semantic Urban Scene Understanding},\n  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},\n  booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2016}\n}\n\'\'\'\n\n_DESCRIPTION = \'\'\'\\\n  Cityscapes is a dataset consisting of diverse urban street scenes across 50 different cities\n  at varying times of the year as well as ground truths for several vision tasks including\n  semantic segmentation, instance level segmentation (TODO), and stereo pair disparity inference.\n\n\n  For segmentation tasks (default split, accessible via \'cityscapes/semantic_segmentation\'), Cityscapes provides\n  dense pixel level annotations for 5000 images at 1024 * 2048 resolution pre-split into training (2975),\n  validation (500) and test (1525) sets. Label annotations for segmentation tasks span across 30+ classes\n  commonly encountered during driving scene perception. Detailed label information may be found here:\n  https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py#L52-L99\n\n  Cityscapes also provides coarse grain segmentation annotations (accessible via \'cityscapes/semantic_segmentation_extra\')\n  for 19998 images in a \'train_extra\' split which may prove useful for pretraining / data-heavy models.\n\n\n  Besides segmentation, cityscapes also provides stereo image pairs and ground truths for disparity inference\n  tasks on both the normal and extra splits (accessible via \'cityscapes/stereo_disparity\' and\n  \'cityscapes/stereo_disparity_extra\' respectively).\n\n  Ingored examples:\n  - For \'cityscapes/stereo_disparity_extra\':\n    - troisdorf_000000_000073_{*} images (no disparity map present)\n\n  WARNING: this dataset requires users to setup a login and password in order to get the files.\n\'\'\'\n\n\nclass CityscapesConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Cityscapes.\n\n    Args:\n      right_images (bool): Enables right images for stereo image tasks.\n      segmentation_labels (bool): Enables image segmentation labels.\n      disparity_maps (bool): Enables disparity maps.\n      train_extra_split (bool): Enables train_extra split. This automatically\n          enables coarse grain segmentations, if segmentation labels are used.\n  """"""\n\n  @api_utils.disallow_positional_args\n  def __init__(self, right_images=False, segmentation_labels=True,\n               disparity_maps=False, train_extra_split=False, **kwargs):\n    super(CityscapesConfig, self).__init__(version=\'1.0.0\', **kwargs)\n\n    self.right_images = right_images\n    self.segmentation_labels = segmentation_labels\n    self.disparity_maps = disparity_maps\n    self.train_extra_split = train_extra_split\n\n    self.ignored_ids = set()\n\n    # Setup required zips and their root dir names\n    self.zip_root = {}\n    self.zip_root[\'images_left\'] = (\n        \'leftImg8bit_trainvaltest.zip\', \'leftImg8bit\')\n\n    if self.train_extra_split:\n      self.zip_root[\'images_left/extra\'] = (\n          \'leftImg8bit_trainextra.zip\', \'leftImg8bit\')\n\n    if self.right_images:\n      self.zip_root[\'images_right\'] = (\n          \'rightImg8bit_trainvaltest.zip\', \'rightImg8bit\')\n      if self.train_extra_split:\n        self.zip_root[\'images_right/extra\'] = (\n            \'rightImg8bit_trainextra.zip\', \'rightImg8bit\')\n\n    if self.segmentation_labels:\n      if not self.train_extra_split:\n        self.zip_root[\'segmentation_labels\'] = (\n            \'gtFine_trainvaltest.zip\', \'gtFine\')\n        self.label_suffix = \'gtFine_labelIds\'\n      else:\n        # The \'train extra\' split only has coarse labels unlike train and val.\n        # Therefore, for consistency across splits, we also enable coarse labels\n        # using the train_extra_split flag.\n        self.zip_root[\'segmentation_labels\'] = (\'gtCoarse.zip\', \'gtCoarse\')\n        self.zip_root[\'segmentation_labels/extra\'] = (\n            \'gtCoarse.zip\', \'gtCoarse\')\n        self.label_suffix = \'gtCoarse_labelIds\'\n\n    if self.disparity_maps:\n      self.zip_root[\'disparity_maps\'] = (\n          \'disparity_trainvaltest.zip\', \'disparity\')\n      if self.train_extra_split:\n        self.zip_root[\'disparity_maps/extra\'] = (\n            \'disparity_trainextra.zip\', \'disparity\')\n        # No disparity for this file\n        self.ignored_ids.add(\'troisdorf_000000_000073\')\n\n\nclass Cityscapes(tfds.core.GeneratorBasedBuilder):\n  """"""Base class for Cityscapes datasets.""""""\n\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  You have to download files from https://www.cityscapes-dataset.com/login/\n  (This dataset requires registration).\n  For basic config (semantic_segmentation) you must download\n  \'leftImg8bit_trainvaltest.zip\' and \'gtFine_trainvaltest.zip\'.\n  Other configs do require additional files - please see code for more details.\n  """"""\n\n  BUILDER_CONFIGS = [\n      CityscapesConfig(\n          name=\'semantic_segmentation\',\n          description=\'Cityscapes semantic segmentation dataset.\',\n          right_images=False,\n          segmentation_labels=True,\n          disparity_maps=False,\n          train_extra_split=False,\n      ),\n      CityscapesConfig(\n          name=\'semantic_segmentation_extra\',\n          description=\'Cityscapes semantic segmentation dataset with train_extra split and coarse labels.\',  # pylint: disable=line-too-long\n          right_images=False,\n          segmentation_labels=True,\n          disparity_maps=False,\n          train_extra_split=True,\n      ),\n      CityscapesConfig(\n          name=\'stereo_disparity\',\n          description=\'Cityscapes stereo image and disparity maps dataset.\',\n          right_images=True,\n          segmentation_labels=False,\n          disparity_maps=True,\n          train_extra_split=False,\n      ),\n      CityscapesConfig(\n          name=\'stereo_disparity_extra\',\n          description=\'Cityscapes stereo image and disparity maps dataset with train_extra split.\',  # pylint: disable=line-too-long\n          right_images=True,\n          segmentation_labels=False,\n          disparity_maps=True,\n          train_extra_split=True,\n      ),\n  ]\n\n  def _info(self):\n    # Enable features as necessary\n    features = {}\n    features[\'image_id\'] = tfds.features.Text()\n    features[\'image_left\'] = tfds.features.Image(\n        shape=(1024, 2048, 3), encoding_format=\'png\')\n\n    if self.builder_config.right_images:\n      features[\'image_right\'] = tfds.features.Image(\n          shape=(1024, 2048, 3), encoding_format=\'png\')\n\n    if self.builder_config.segmentation_labels:\n      features[\'segmentation_label\'] = tfds.features.Image(\n          shape=(1024, 2048, 1), encoding_format=\'png\')\n\n    if self.builder_config.disparity_maps:\n      features[\'disparity_map\'] = tfds.features.Image(\n          shape=(1024, 2048, 1), encoding_format=\'png\')\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        homepage=\'https://www.cityscapes-dataset.com\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    paths = {}\n    for split, (zip_file, _) in self.builder_config.zip_root.items():\n      paths[split] = os.path.join(dl_manager.manual_dir, zip_file)\n\n    if any(not tf.io.gfile.exists(z) for z in paths.values()):\n      msg = \'You must download the dataset files manually and place them in: \'\n      msg += \', \'.join(paths.values())\n      raise AssertionError(msg)\n\n    for split, (_, zip_root) in self.builder_config.zip_root.items():\n      paths[split] = os.path.join(dl_manager.extract(paths[split]), zip_root)\n\n    splits = [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                feat_dir: os.path.join(path, \'train\')\n                for feat_dir, path in paths.items()\n                if not feat_dir.endswith(\'/extra\')\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                feat_dir: os.path.join(path, \'val\')\n                for feat_dir, path in paths.items()\n                if not feat_dir.endswith(\'/extra\')\n            },\n        ),\n    ]\n\n    # Test split does not exist in coarse dataset\n    if not self.builder_config.train_extra_split:\n      splits.append(tfds.core.SplitGenerator(\n          name=tfds.Split.TEST,\n          gen_kwargs={\n              feat_dir: os.path.join(path, \'test\')\n              for feat_dir, path in paths.items()\n              if not feat_dir.endswith(\'/extra\')\n          },\n      ))\n    else:\n      splits.append(tfds.core.SplitGenerator(\n          name=\'train_extra\',\n          gen_kwargs={\n              feat_dir.replace(\'/extra\', \'\'): os.path.join(path, \'train_extra\')\n              for feat_dir, path in paths.items()\n              if feat_dir.endswith(\'/extra\')\n          },\n      ))\n    return splits\n\n  def _generate_examples(self, **paths):\n    left_imgs_root = paths[\'images_left\']\n    for city_id in tf.io.gfile.listdir(left_imgs_root):\n      paths_city_root = {feat_dir: os.path.join(path, city_id)\n                         for feat_dir, path in paths.items()}\n\n      left_city_root = paths_city_root[\'images_left\']\n      for left_img in tf.io.gfile.listdir(left_city_root):\n        left_img_path = os.path.join(left_city_root, left_img)\n        image_id = _get_left_image_id(left_img)\n\n        if image_id in self.builder_config.ignored_ids:\n          continue\n\n        features = {\n            \'image_id\': image_id,\n            \'image_left\': left_img_path,\n        }\n\n        if self.builder_config.right_images:\n          features[\'image_right\'] = os.path.join(\n              paths_city_root[\'images_right\'],\n              \'{}_rightImg8bit.png\'.format(image_id))\n\n        if self.builder_config.segmentation_labels:\n          features[\'segmentation_label\'] = os.path.join(\n              paths_city_root[\'segmentation_labels\'],\n              \'{}_{}.png\'.format(\n                  image_id, self.builder_config.label_suffix))\n\n        if self.builder_config.disparity_maps:\n          features[\'disparity_map\'] = os.path.join(\n              paths_city_root[\'disparity_maps\'],\n              \'{}_disparity.png\'.format(image_id))\n\n        yield image_id, features\n\n# Helper functions\n\nLEFT_IMAGE_FILE_RE = re.compile(r\'([a-z\\-]+)_(\\d+)_(\\d+)_leftImg8bit\\.png\')\n\n\ndef _get_left_image_id(left_image):\n  """"""Returns the id of an image file.\n\n  Used to associate an image file with its corresponding label.\n  Example:\n    \'bonn_000001_000019_leftImg8bit\' -> \'bonn_000001_000019\'\n\n  Args:\n    left_image: name of the image file.\n\n  Returns:\n    Id of the image (see example above).\n  """"""\n  match = LEFT_IMAGE_FILE_RE.match(left_image)\n  return \'{}_{}_{}\'.format(*match.groups())\n'"
tensorflow_datasets/image/cityscapes_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Cityscapes dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import cityscapes\n\n\nclass CityscapesSegmentationTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cityscapes.Cityscapes\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'semantic_segmentation\']\n  SPLITS = {\n      \'train\': 3,\n      \'validation\': 1,\n      \'test\': 2,\n  }\n\n\nclass CityscapesSegmentationExtraTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cityscapes.Cityscapes\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'semantic_segmentation_extra\']\n  SPLITS = {\n      \'train\': 3,\n      \'train_extra\': 4,\n      \'validation\': 1,\n  }\n\n\nclass CityscapesStereoDisparityTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cityscapes.Cityscapes\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'stereo_disparity\']\n  SPLITS = {\n      \'train\': 3,\n      \'validation\': 1,\n      \'test\': 2,\n  }\n\n\nclass CityscapesStereoDisparityExtraTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cityscapes.Cityscapes\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'stereo_disparity_extra\']\n  SPLITS = {\n      \'train\': 3,\n      \'train_extra\': 4,\n      \'validation\': 1,\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image/clevr.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CLEVR dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = """"""\\\nCLEVR is a diagnostic dataset that tests a range of visual reasoning abilities.\nIt contains minimal biases and has detailed annotations describing the kind of\nreasoning each question requires.\n""""""\n\n\n_CITATION = """"""\\\n@inproceedings{johnson2017clevr,\n  title={{CLEVR}: A diagnostic dataset for compositional language and elementary visual reasoning},\n  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2017}\n}\n""""""\n\n_BASE_URL = ""https://cs.stanford.edu/people/jcjohns/clevr/""\n_DOWNLOAD_URL = ""https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip""\n\n\nclass CLEVR(tfds.core.GeneratorBasedBuilder):\n  """"""CLEVR dataset.""""""\n\n  VERSION = tfds.core.Version(""3.1.0"", ""Add question/answer text."")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""3.0.0""),\n  ]\n\n  def _info(self):\n    features = {\n        ""image"": tfds.features.Image(),\n        ""file_name"": tfds.features.Text(),\n        ""objects"": tfds.features.Sequence({\n            ""color"": tfds.features.ClassLabel(names=[""gray"", ""blue"",\n                                                     ""brown"", ""yellow"",\n                                                     ""red"", ""green"",\n                                                     ""purple"", ""cyan""]),\n            ""material"": tfds.features.ClassLabel(names=[""rubber"", ""metal""]),\n            ""shape"": tfds.features.ClassLabel(names=[""cube"", ""sphere"",\n                                                     ""cylinder""]),\n            ""size"": tfds.features.ClassLabel(names=[""small"", ""large""]),\n            ""rotation"": tfds.features.Tensor(shape=(), dtype=tf.float32),\n            ""3d_coords"": tfds.features.Tensor(shape=(3,), dtype=tf.float32),\n            ""pixel_coords"": tfds.features.Tensor(shape=(3,),\n                                                 dtype=tf.float32),\n        })\n    }\n    if self.version > ""3.0.0"":\n      features[""question_answer""] = tfds.features.Sequence({\n          ""question"": tfds.features.Text(),\n          ""answer"": tfds.features.Text(),\n      })\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        homepage=_BASE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns splits.""""""\n    path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n\n    images_path_dir = os.path.join(path, ""CLEVR_v1.0/images"")\n    questions_path_dir = os.path.join(path, ""CLEVR_v1.0/questions"")\n    scenes_path_dir = os.path.join(path, ""CLEVR_v1.0/scenes"")\n\n    splits = []\n    for split_name in [""train"", ""val"", ""test""]:\n      name_map = {\n          ""train"": tfds.Split.TRAIN,\n          ""val"": tfds.Split.VALIDATION,\n          ""test"": tfds.Split.TEST,\n      }\n      splits.append(tfds.core.SplitGenerator(\n          name=name_map[split_name],\n          gen_kwargs={\n              ""images_dir_path"": os.path.join(images_path_dir, split_name),\n              ""question_file"": os.path.join(\n                  questions_path_dir,\n                  ""CLEVR_{}_questions.json"".format(split_name)),\n              ""scenes_description_file"": os.path.join(\n                  scenes_path_dir, ""CLEVR_{}_scenes.json"".format(split_name)),\n              },\n          ))\n\n    return splits\n\n  def _generate_examples(\n      self, images_dir_path, question_file, scenes_description_file):\n    image_paths = sorted([os.path.join(images_dir_path, filename)\n                          for filename in tf.io.gfile.listdir(images_dir_path)])\n\n    with tf.io.gfile.GFile(question_file) as f:\n      questions_json = json.load(f)\n    questions = collections.defaultdict(list)\n    for q in questions_json[""questions""]:\n      questions[q[""image_filename""]].append({\n          ""question"": q[""question""],\n          ""answer"": q.get(""answer"", """"),  # Test set do not have answer.\n      })\n\n    if tf.io.gfile.exists(scenes_description_file):\n      with tf.io.gfile.GFile(scenes_description_file) as f:\n        scenes_json = json.load(f)\n    else:\n      # if annotation file does not exist, we create empty annotations\n      scenes_json = {""scenes"": [{""objects"": []}] * len(image_paths)}\n\n    attrs = [""color"", ""material"", ""shape"", ""size"",\n             ""rotation"", ""pixel_coords"", ""3d_coords""]\n    for image_path, scene in zip(image_paths, scenes_json[""scenes""]):\n      objects = scene[""objects""]\n      fname = os.path.basename(image_path)\n      record = {\n          ""image"": image_path,\n          ""file_name"": fname,\n          ""question_answer"": questions[fname],\n          ""objects"": [{attr: obj[attr] for attr in attrs} for obj in objects]  # pylint: disable=g-complex-comprehension\n      }\n      yield fname, record\n'"
tensorflow_datasets/image/clevr_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for CLEVR dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image.clevr import CLEVR\n\n\nclass CLEVRTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = CLEVR\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 5,\n      ""validation"": 5,\n      ""test"": 5,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/coil100.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for COIL-100 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = ""http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-100/coil-100.zip""\n\n_DESCRIPTION = (""""""The dataset contains 7200 color images of 100 objects\n(72 images per object). The objects have a wide variety of complex geometric and reflectance characteristics.\nThe objects were placed on a motorized turntable against a black background.\nThe turntable was rotated through 360 degrees to vary object pose with respect to a fxed color camera.\nImages of the objects were taken at pose intervals of\t5 degrees.This corresponds to\n72 poses per object"""""")\n\n_LABELS = [str(x) for x in range(0, 360, 5)]\n\n_IMAGE_SHAPE = (128, 128, 3)\n\n_CITATION = """"""\\\n@article{nene1996columbia,\n  title={Columbia object image library (coil-20)},\n  author={Nene, Sameer A and Nayar, Shree K and Murase, Hiroshi and others},\n  year={1996},\n  publisher={Technical report CUCS-005-96}\n}\n""""""\n\n\nclass Coil100(tfds.core.GeneratorBasedBuilder):\n  """"""COIL-100 Image Dataset Class.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  UNSTABLE = ""Unable to download on secured networks(eg. University Network)""\n\n  def _info(self):\n    """"""Define Dataset Info.""""""\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(names=_LABELS),\n            ""object_id"": tfds.features.Text()\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=\n        ""http://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Define Splits.""""""\n    path = dl_manager.download_and_extract(_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""data_dir_path"": os.path.join(path, ""coil-100"")\n            },\n        ),\n    ]\n\n  def _generate_examples(self, data_dir_path):\n    """"""Generate images and labels for splits.""""""\n    for file_name in tf.io.gfile.listdir(data_dir_path):\n      if file_name.endswith("".png""):\n        image = os.path.join(data_dir_path, file_name)\n        label = file_name.split(""_"")[2].split(""."")[0]\n        object_id = file_name.split(""_"")[0]\n        yield file_name, {\n            ""image"": image,\n            ""label"": label,\n            ""object_id"": object_id,\n        }\n'"
tensorflow_datasets/image/coil100_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Coil-100 Test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import coil100\n\n\nclass Coil100Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = coil100.Coil100\n  SPLITS = {\n      ""train"": 5,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/div2k.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DIV2K dataset: DIVerse 2K resolution high quality images.\n\nAs used for the challenges @ NTIRE (CVPR 2017 and CVPR 2018)\nand @ PIRM (ECCV 2018)\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@InProceedings{Agustsson_2017_CVPR_Workshops,\n\tauthor = {Agustsson, Eirikur and Timofte, Radu},\n\ttitle = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},\n\tbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n    url = ""http://www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf"",\n\tmonth = {July},\n\tyear = {2017}\n} \n""""""\n\n_DESCRIPTION = """"""\nDIV2K dataset: DIVerse 2K resolution high quality images as used for the challenges @ NTIRE (CVPR 2017 and CVPR 2018) and @ PIRM (ECCV 2018)\n""""""\n\n_DL_URL = ""https://data.vision.ee.ethz.ch/cvl/DIV2K/""\n\n_DL_URLS = {\n    ""train_hr"": _DL_URL + ""DIV2K_train_HR.zip"",\n    ""valid_hr"": _DL_URL + ""DIV2K_valid_HR.zip"",\n    ""train_bicubic_x2"": _DL_URL + ""DIV2K_train_LR_bicubic_X2.zip"",\n    ""train_unknown_x2"": _DL_URL + ""DIV2K_train_LR_unknown_X2.zip"",\n    ""valid_bicubic_x2"": _DL_URL + ""DIV2K_valid_LR_bicubic_X2.zip"",\n    ""valid_unknown_x2"": _DL_URL + ""DIV2K_valid_LR_unknown_X2.zip"",\n    ""train_bicubic_x3"": _DL_URL + ""DIV2K_train_LR_bicubic_X3.zip"",\n    ""train_unknown_x3"": _DL_URL + ""DIV2K_train_LR_unknown_X3.zip"",\n    ""valid_bicubic_x3"": _DL_URL + ""DIV2K_valid_LR_bicubic_X3.zip"",\n    ""valid_unknown_x3"": _DL_URL + ""DIV2K_valid_LR_unknown_X3.zip"",\n    ""train_bicubic_x4"": _DL_URL + ""DIV2K_train_LR_bicubic_X4.zip"",\n    ""train_unknown_x4"": _DL_URL + ""DIV2K_train_LR_unknown_X4.zip"",\n    ""valid_bicubic_x4"": _DL_URL + ""DIV2K_valid_LR_bicubic_X4.zip"",\n    ""valid_unknown_x4"": _DL_URL + ""DIV2K_valid_LR_unknown_X4.zip"",\n    ""train_bicubic_x8"": _DL_URL + ""DIV2K_train_LR_x8.zip"",\n    ""valid_bicubic_x8"": _DL_URL + ""DIV2K_valid_LR_x8.zip"",\n    ""train_realistic_mild_x4"": _DL_URL + ""DIV2K_train_LR_mild.zip"",\n    ""valid_realistic_mild_x4"": _DL_URL + ""DIV2K_valid_LR_mild.zip"",\n    ""train_realistic_difficult_x4"": _DL_URL + ""DIV2K_train_LR_difficult.zip"",\n    ""valid_realistic_difficult_x4"": _DL_URL + ""DIV2K_valid_LR_difficult.zip"",\n    ""train_realistic_wild_x4"": _DL_URL + ""DIV2K_train_LR_wild.zip"",\n    ""valid_realistic_wild_x4"": _DL_URL + ""DIV2K_valid_LR_wild.zip"",\n}\n\n_DATA_OPTIONS = [\n    ""bicubic_x2"", ""bicubic_x3"", ""bicubic_x4"", ""bicubic_x8"", ""unknown_x2"",\n    ""unknown_x3"", ""unknown_x4"", ""realistic_mild_x4"", ""realistic_difficult_x4"",\n    ""realistic_wild_x4""\n]\n\n\nclass Div2kConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Div2k.""""""\n\n  def __init__(self, name, **kwargs):\n    """"""Constructs a Div2kConfig.""""""\n    if name not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n\n    description = kwargs.get(""description"", ""Uses %s data."" % name)\n    kwargs[""description""] = description\n\n    super(Div2kConfig, self).__init__(name=name, **kwargs)\n    self.data = name\n    self.download_urls = {\n        ""train_lr_url"": _DL_URLS[""train_"" + self.data],\n        ""valid_lr_url"": _DL_URLS[""valid_"" + self.data],\n        ""train_hr_url"": _DL_URLS[""train_hr""],\n        ""valid_hr_url"": _DL_URLS[""valid_hr""],\n    }\n\n\ndef _make_builder_configs():\n  configs = []\n  for data in _DATA_OPTIONS:\n    configs.append(Div2kConfig(version=tfds.core.Version(""2.0.0""), name=data))\n  return configs\n\n\nclass Div2k(tfds.core.GeneratorBasedBuilder):\n  """"""DIV2K dataset: DIVerse 2K resolution high quality images.""""""\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""lr"": tfds.features.Image(),\n            ""hr"": tfds.features.Image(),\n        }),\n        supervised_keys=(""lr"", ""hr""),\n        homepage=_DL_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    print(""EXTRACTING"", self.builder_config.download_urls)\n    extracted_paths = dl_manager.download_and_extract(\n        self.builder_config.download_urls)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""lr_path"": extracted_paths[""train_lr_url""],\n                ""hr_path"": os.path.join(extracted_paths[""train_hr_url""],\n                                        ""DIV2K_train_HR""),\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""lr_path"": extracted_paths[""valid_lr_url""],\n                ""hr_path"": os.path.join(extracted_paths[""valid_hr_url""],\n                                        ""DIV2K_valid_HR""),\n            }),\n    ]\n\n  def _generate_examples(self, lr_path, hr_path):\n    """"""Yields examples.""""""\n    for root, _, files in tf.io.gfile.walk(lr_path):\n      for file_path in files:\n        # Select only png files.\n        if file_path.endswith("".png""):\n          yield file_path, {\n              ""lr"": os.path.join(root, file_path),\n              # Extract the image id from the filename: ""0001x2.png""\n              ""hr"": os.path.join(hr_path, file_path[:4] + "".png"")\n          }\n'"
tensorflow_datasets/image/div2k_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for div2k dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import div2k\n\n\nclass Div2kTestBicubicX(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = div2k.Div2k\n  BUILDER_CONFIG_NAMES_TO_TEST = [""bicubic_x2""]\n  SPLITS = {\n      ""train"": 1,\n      ""validation"": 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""train_hr_url"": """",\n      ""valid_hr_url"": """",\n      ""train_lr_url"": ""DIV2K_train_LR_bicubic_X2"",\n      ""valid_lr_url"": ""DIV2K_valid_LR_bicubic_X2"",\n  }\n\n\nclass Div2kTestUnknownX(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = div2k.Div2k\n  BUILDER_CONFIG_NAMES_TO_TEST = [""unknown_x2""]\n  SPLITS = {\n      ""train"": 1,\n      ""validation"": 1,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""train_hr_url"": """",\n      ""valid_hr_url"": """",\n      ""train_lr_url"": ""DIV2K_train_LR_unknown_X2"",\n      ""valid_lr_url"": ""DIV2K_valid_LR_unknown_X2"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/downsampled_imagenet.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Downsampled Imagenet dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/OordKK16,\n  author    = {A{\\""{a}}ron van den Oord and\n               Nal Kalchbrenner and\n               Koray Kavukcuoglu},\n  title     = {Pixel Recurrent Neural Networks},\n  journal   = {CoRR},\n  volume    = {abs/1601.06759},\n  year      = {2016},\n  url       = {http://arxiv.org/abs/1601.06759},\n  archivePrefix = {arXiv},\n  eprint    = {1601.06759},\n  timestamp = {Mon, 13 Aug 2018 16:46:29 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/OordKK16},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nDataset with images of 2 resolutions (see config name for information on the resolution).\nIt is used for density estimation and generative modeling experiments.\n\nFor resized ImageNet for supervised learning ([link](https://patrykchrabaszcz.github.io/Imagenet32/)) see `imagenet_resized`.\n""""""\n\n_DL_URL = ""http://image-net.org/small/""\n\n_DATA_OPTIONS = [""32x32"", ""64x64""]\n\n\nclass DownsampledImagenetConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Downsampled Imagenet.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, data=None, **kwargs):\n    """"""Constructs a DownsampledImagenetConfig.\n\n    Args:\n      data: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if data not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n\n    super(DownsampledImagenetConfig, self).__init__(**kwargs)\n    self.data = data\n\n\nclass DownsampledImagenet(tfds.core.GeneratorBasedBuilder):\n  """"""Downsampled Imagenet dataset.""""""\n\n  BUILDER_CONFIGS = [\n      DownsampledImagenetConfig(  # pylint: disable=g-complex-comprehension\n          name=config_name,\n          description=(\n              ""A dataset consisting of Train and Validation images of "" +\n              config_name + "" resolution.""),\n          version=tfds.core.Version(\n              ""2.0.0"",\n              ""New split API (https://tensorflow.org/datasets/splits)""),\n          data=config_name,\n      ) for config_name in _DATA_OPTIONS\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(encoding_format=""jpeg""),\n        }),\n        supervised_keys=None,\n        homepage=""http://image-net.org/small/download.php"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    train_url = _DL_URL + ""train_"" + self.builder_config.name + "".tar""\n    valid_url = _DL_URL + ""valid_"" + self.builder_config.name + "".tar""\n\n    train_path, valid_path = dl_manager.download([\n        train_url,\n        valid_url,\n    ])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(train_path),\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(valid_path),\n            }),\n    ]\n\n  def _generate_examples(self, archive):\n    for fname, fobj in archive:\n      record = {\n          ""image"": fobj,\n      }\n      yield fname, record\n'"
tensorflow_datasets/image/downsampled_imagenet_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for downsampled_imagenet dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import downsampled_imagenet\nimport tensorflow_datasets.public_api as tfds\n\n\nclass DownsampledImagenetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = downsampled_imagenet.DownsampledImagenet\n  BUILDER_CONFIG_NAMES_TO_TEST = [""32x32"", ""64x64""]\n\n  SPLITS = {\n      tfds.Split.TRAIN: 2,\n      tfds.Split.VALIDATION: 2,\n  }\n\n  DL_EXTRACT_RESULT = [\n      ""train_32x32.tar"",\n      ""valid_32x32.tar"",\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/dsprites.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""dSprites dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six import moves\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@misc{dsprites17,\nauthor = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},\ntitle = {dSprites: Disentanglement testing Sprites dataset},\nhowpublished= {https://github.com/deepmind/dsprites-dataset/},\nyear = ""2017"",\n}\n""""""\n\n_URL = (""https://github.com/deepmind/dsprites-dataset/blob/master/""\n        ""dsprites_ndarray_co1sh3sc6or40x32y32_64x64.hdf5?raw=true"")\n\n_DESCRIPTION = """"""\\\ndSprites is a dataset of 2D shapes procedurally generated from 6 ground truth\nindependent latent factors. These factors are *color*, *shape*, *scale*,\n*rotation*, *x* and *y* positions of a sprite.\n\nAll possible combinations of these latents are present exactly once,\ngenerating N = 737280 total images.\n\n### Latent factor values\n\n*   Color: white\n*   Shape: square, ellipse, heart\n*   Scale: 6 values linearly spaced in [0.5, 1]\n*   Orientation: 40 values in [0, 2 pi]\n*   Position X: 32 values in [0, 1]\n*   Position Y: 32 values in [0, 1]\n\nWe varied one latent at a time (starting from Position Y, then Position X, etc),\nand sequentially stored the images in fixed order.\nHence the order along the first dimension is fixed and allows you to map back to\nthe value of the latents corresponding to that image.\n\nWe chose the latents values deliberately to have the smallest step changes\nwhile ensuring that all pixel outputs were different. No noise was added.\n""""""\n\n\nclass Dsprites(tfds.core.GeneratorBasedBuilder):\n  """"""dSprites data set.""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""2.1.0""),\n  ]\n\n  def _info(self):\n    features_dict = {\n        ""image"": tfds.features.Image(shape=(64, 64, 1)),\n        ""label_shape"": tfds.features.ClassLabel(num_classes=3),\n        ""label_scale"": tfds.features.ClassLabel(num_classes=6),\n        ""label_orientation"": tfds.features.ClassLabel(num_classes=40),\n        ""label_x_position"": tfds.features.ClassLabel(num_classes=32),\n        ""label_y_position"": tfds.features.ClassLabel(num_classes=32),\n        ""value_shape"": tfds.features.Tensor(shape=[], dtype=tf.float32),\n        ""value_scale"": tfds.features.Tensor(shape=[], dtype=tf.float32),\n        ""value_orientation"": tfds.features.Tensor(shape=[], dtype=tf.float32),\n        ""value_x_position"": tfds.features.Tensor(shape=[], dtype=tf.float32),\n        ""value_y_position"": tfds.features.Tensor(shape=[], dtype=tf.float32),\n    }\n    if self.version > ""2.0.0"":\n      features_dict[""id""] = tfds.features.Text()\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features_dict),\n        homepage=""https://github.com/deepmind/dsprites-dataset"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    filepath = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(filepath=filepath)),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Generates examples for the dSprites data set.\n\n    Args:\n      filepath: path to the dSprites hdf5 file.\n\n    Yields:\n      Dictionaries with images, latent classes, and latent values.\n    """"""\n    # Simultaneously iterating through the different data sets in the hdf5\n    # file is >100x slower and the data set is small (26.7MB). Hence, we first\n    # load everything into memory before yielding the samples.\n    with tfds.core.lazy_imports.h5py.File(filepath, ""r"") as h5dataset:\n      image_array = np.array(h5dataset[""imgs""])\n      class_array = np.array(h5dataset[""latents""][""classes""])\n      values_array = np.array(h5dataset[""latents""][""values""])\n\n    for i, (image, classes, values) in enumerate(moves.zip(\n        image_array, class_array, values_array)):\n      record = dict(\n          image=np.expand_dims(image, -1),\n          label_shape=classes[1],\n          label_scale=classes[2],\n          label_orientation=classes[3],\n          label_x_position=classes[4],\n          label_y_position=classes[5],\n          value_shape=values[1],\n          value_scale=values[2],\n          value_orientation=values[3],\n          value_x_position=values[4],\n          value_y_position=values[5])\n      if self.version > ""2.0.0"":\n        record[""id""] = ""{:06d}"".format(i)\n      yield i, record\n'"
tensorflow_datasets/image/dsprites_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""dSprites dataset test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image import dsprites\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass DspritesTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = dsprites.Dsprites\n  SPLITS = {""train"": 5}\n  DL_EXTRACT_RESULT = ""dsprites_ndarray_co1sh3sc6or40x32y32_64x64.hdf5""\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image/duke_ultrasound.py,20,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DAS beamformed phantom images and paired clinical post-processed images.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1908-05782,\n  author    = {Ouwen Huang and\n               Will Long and\n               Nick Bottenus and\n               Gregg E. Trahey and\n               Sina Farsiu and\n               Mark L. Palmeri},\n  title     = {MimickNet, Matching Clinical Post-Processing Under Realistic Black-Box\n               Constraints},\n  journal   = {CoRR},\n  volume    = {abs/1908.05782},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1908.05782},\n  archivePrefix = {arXiv},\n  eprint    = {1908.05782},\n  timestamp = {Mon, 19 Aug 2019 13:21:03 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1908-05782},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}""""""\n\n_DESCRIPTION = """"""\\\nDukeUltrasound is an ultrasound dataset collected at Duke University with a \nVerasonics c52v probe. It contains delay-and-sum (DAS) beamformed data \nas well as data post-processed with Siemens Dynamic TCE for speckle \nreduction, contrast enhancement and improvement in conspicuity of \nanatomical structures. These data were collected with support from the\nNational Institute of Biomedical Imaging and Bioengineering under Grant \nR01-EB026574 and National Institutes of Health under Grant 5T32GM007171-44.\nA usage example is avalible \n[here](https://colab.research.google.com/drive/1R_ARqpWoiHcUQWg1Fxwyx-ZkLi0IZ5qs).""""""\n\n_DATA_URL = {\n    \'phantom_data\': \'https://research.repository.duke.edu/downloads/vt150j912\',\n    \'mark_data\': \'https://research.repository.duke.edu/downloads/4x51hj56d\'\n}\n\n_DEFAULT_SPLITS = {\n    \'train\': \'https://research.repository.duke.edu/downloads/tt44pn391\',\n    \'test\': \'https://research.repository.duke.edu/downloads/zg64tm441\',\n    \'validation\': \'https://research.repository.duke.edu/downloads/dj52w535x\',\n    \'MARK\': \'https://research.repository.duke.edu/downloads/wd375w77v\',\n    \'A\': \'https://research.repository.duke.edu/downloads/nc580n18d\',\n    \'B\': \'https://research.repository.duke.edu/downloads/7h149q56p\'\n}\n\n\nclass DukeUltrasound(tfds.core.GeneratorBasedBuilder):\n  """"""DAS beamformed phantom images and paired post-processed images.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def __init__(self, custom_csv_splits=None, **kwargs):\n    """"""custom_csv_splits is a dictionary of { \'name\': \'csvpaths\'}.""""""\n    super(DukeUltrasound, self).__init__(**kwargs)\n    self.custom_csv_splits = custom_csv_splits if custom_csv_splits else {}\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'das\': {\n                \'dB\': tfds.features.Tensor(shape=(None,), dtype=tf.float32),\n                \'real\': tfds.features.Tensor(shape=(None,), dtype=tf.float32),\n                \'imag\': tfds.features.Tensor(shape=(None,), dtype=tf.float32)\n            },\n            \'dtce\': tfds.features.Tensor(shape=(None,), dtype=tf.float32),\n            \'f0_hz\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'voltage\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'focus_cm\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'height\': tfds.features.Tensor(shape=(), dtype=tf.uint32),\n            \'width\': tfds.features.Tensor(shape=(), dtype=tf.uint32),\n            \'initial_radius\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'final_radius\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'initial_angle\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'final_angle\': tfds.features.Tensor(shape=(), dtype=tf.float32),\n            \'probe\': tfds.features.Tensor(shape=(), dtype=tf.string),\n            \'scanner\': tfds.features.Tensor(shape=(), dtype=tf.string),\n            \'target\': tfds.features.Tensor(shape=(), dtype=tf.string),\n            \'timestamp_id\': tfds.features.Tensor(shape=(), dtype=tf.uint32),\n            \'harmonic\': tfds.features.Tensor(shape=(), dtype=tf.bool)\n        }),\n        supervised_keys=(\'das/dB\', \'dtce\'),\n        homepage=\'https://github.com/ouwen/mimicknet\',\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    downloads = _DEFAULT_SPLITS.copy()\n    downloads.update(_DATA_URL)\n    dl_paths = dl_manager.download_and_extract(downloads)\n    splits = [\n        tfds.core.SplitGenerator(  # pylint:disable=g-complex-comprehension\n            name=name,\n            gen_kwargs={\n                \'datapath\': {\n                    \'mark_data\': dl_paths[\'mark_data\'],\n                    \'phantom_data\': dl_paths[\'phantom_data\']\n                },\n                \'csvpath\': dl_paths[name]\n            }) for name, _ in _DEFAULT_SPLITS.items()\n    ]\n\n    for name, csv_path in self.custom_csv_splits.items():\n      splits.append(\n          tfds.core.SplitGenerator(\n              name=name,\n              gen_kwargs={\n                  \'datapath\': dl_paths[\'data\'],\n                  \'csvpath\': csv_path\n              }))\n\n    return splits\n\n  def _generate_examples(self, datapath, csvpath):\n    with tf.io.gfile.GFile(csvpath) as f:\n      reader = csv.DictReader(f)\n      for row in reader:\n        data_key = \'mark_data\' if row[\'target\'] == \'mark\' else \'phantom_data\'\n\n        filepath = os.path.join(datapath[data_key], row[\'filename\'])\n        matfile = tfds.core.lazy_imports.scipy.io.loadmat(\n            tf.io.gfile.GFile(filepath, \'rb\'))\n\n        iq = np.abs(np.reshape(matfile[\'iq\'], -1))\n        iq = iq / iq.max()\n        iq = 20 * np.log10(iq)\n\n        yield row[\'filename\'], {\n            \'das\': {\n                \'dB\': iq.astype(np.float32),\n                \'real\': np.reshape(matfile[\'iq\'], -1).real.astype(np.float32),\n                \'imag\': np.reshape(matfile[\'iq\'], -1).imag.astype(np.float32)\n            },\n            \'dtce\': np.reshape(matfile[\'dtce\'], -1).astype(np.float32),\n            \'f0_hz\': row[\'f0\'],\n            \'voltage\': row[\'v\'],\n            \'focus_cm\': row[\'focus_cm\'],\n            \'height\': row[\'axial_samples\'],\n            \'width\': row[\'lateral_samples\'],\n            \'initial_radius\': row[\'initial_radius\'],\n            \'final_radius\': row[\'final_radius\'],\n            \'initial_angle\': row[\'initial_angle\'],\n            \'final_angle\': row[\'final_angle\'],\n            \'probe\': row[\'probe\'],\n            \'scanner\': row[\'scanner\'],\n            \'target\': row[\'target\'],\n            \'timestamp_id\': row[\'timestamp_id\'],\n            \'harmonic\': row[\'harm\']\n        }\n'"
tensorflow_datasets/image/duke_ultrasound_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""DAS beamformed phantom images and paired clinical post-processed images test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import duke_ultrasound\n\n\nclass DukeUltrasoundTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = duke_ultrasound.DukeUltrasound\n  OVERLAPPING_SPLITS = [""A"", ""B"", ""TRAIN""]\n\n  SPLITS = {""train"": 1, ""test"": 1, ""validation"": 1, ""MARK"": 1, ""A"": 1, ""B"": 1}\n\n  DL_EXTRACT_RESULT = {\n      ""mark_data"": ""data"",\n      ""phantom_data"": ""data"",\n      ""train"": ""train.csv"",\n      ""test"": ""test.csv"",\n      ""validation"": ""validation.csv"",\n      ""A"": ""train.csv"",\n      ""B"": ""train.csv"",\n      ""MARK"": ""mark.csv""\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/flic.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Frames Labeled In Cinema (FLIC).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""@inproceedings{modec13,\n    title={MODEC: Multimodal Decomposable Models for Human Pose Estimation},\n    author={Sapp, Benjamin and Taskar, Ben},\n    booktitle={In Proc. CVPR},\n    year={2013},\n  }\n""""""\n\n_DESCRIPTION = """"""\nFrom the paper: We collected a 5003 image dataset automatically from popular\nHollywood movies. The images were obtained by running a state-of-the-art person\ndetector on every tenth frame of 30 movies. People detected with high confidence\n(roughly 20K candidates) were then sent to the crowdsourcing marketplace Amazon\nMechanical Turk to obtain groundtruthlabeling. Each image was annotated by five\nTurkers for $0.01 each to label 10 upperbody joints. The median-of-five labeling\nwas taken in each image to be robust to outlier annotation. Finally, images were\nrejected manually by us if the person was occluded or severely non-frontal. We\nset aside 20% (1016 images) of the data for testing.\n""""""\n\n_DATA_OPTIONS = [""small"", ""full""]\n\n_HOMEPAGE_URL = ""https://bensapp.github.io/flic-dataset.html""\n\n_URL_SUBSET = ""https://drive.google.com/uc?id=0B4K3PZp8xXDJN0Fpb0piVjQ3Y3M&export=download""\n_URL_SUPERSET = ""https://drive.google.com/uc?id=0B4K3PZp8xXDJd2VwblhhOVBfMDg&export=download""\n\n\ndef _normalize_bbox(raw_bbox, img_path):\n  """"""Normalize torsobox bbox values.""""""\n  with tf.io.gfile.GFile(img_path, ""rb"") as fp:\n    img = tfds.core.lazy_imports.PIL_Image.open(fp)\n    width, height = img.size\n\n  return tfds.features.BBox(\n      ymin=raw_bbox[1] / height,\n      ymax=raw_bbox[3] / height,\n      xmin=raw_bbox[0] / width,\n      xmax=raw_bbox[2] / width,\n  )\n\n\nclass FlicConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for FLIC.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, data, **kwargs):\n    """"""Constructs a FlicConfig.""""""\n    if data not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n\n    descriptions = {\n        ""small"": ""5003 examples used in CVPR13 MODEC paper."",\n        ""full"":\n            ""20928 examples, a superset of FLIC consisting of more difficult ""\n            ""examples.""\n    }\n    description = kwargs.get(""description"", ""Uses %s"" % descriptions[data])\n    kwargs[""description""] = description\n\n    super(FlicConfig, self).__init__(**kwargs)\n    self.data = data\n    self.url = _URL_SUBSET if data == ""small"" else _URL_SUPERSET\n    self.dir = ""FLIC"" if data == ""small"" else ""FLIC-full""\n\n\ndef _make_builder_configs():\n  configs = []\n  for data in _DATA_OPTIONS:\n    configs.append(\n        FlicConfig(name=data, version=tfds.core.Version(""2.0.0""), data=data))\n  return configs\n\n\nclass Flic(tfds.core.GeneratorBasedBuilder):\n  """"""Frames Labeled In Cinema (FLIC).""""""\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(\n                    shape=(480, 720, 3), encoding_format=""jpeg""),\n            ""poselet_hit_idx"":\n                tfds.features.Sequence(tf.uint16),\n            ""moviename"":\n                tfds.features.Text(),\n            ""xcoords"":\n                tfds.features.Sequence(tf.float64),\n            ""ycoords"":\n                tfds.features.Sequence(tf.float64),\n            ""currframe"":\n                tfds.features.Tensor(shape=(), dtype=tf.float64),\n            ""torsobox"":\n                tfds.features.BBoxFeature(),\n        }),\n        homepage=_HOMEPAGE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    extract_path = dl_manager.download_and_extract(self.builder_config.url)\n\n    mat_path = os.path.join(extract_path, self.builder_config.dir,\n                            ""examples.mat"")\n    with tf.io.gfile.GFile(mat_path, ""rb"") as f:\n      data = tfds.core.lazy_imports.scipy.io.loadmat(\n          f, struct_as_record=True, squeeze_me=True, mat_dtype=True)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""extract_path"": extract_path,\n                ""data"": data,\n                ""selection_column"": 7,  # indicates train split selection\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""extract_path"": extract_path,\n                ""data"": data,\n                ""selection_column"": 8,  # indicates test split selection\n            },\n        ),\n    ]\n\n  def _generate_examples(self, extract_path, data, selection_column):\n    """"""Yields examples.""""""\n    for u_id, example in enumerate(data[""examples""]):\n      if example[selection_column]:\n        img_path = os.path.join(extract_path, self.builder_config.dir, ""images"",\n                                example[3])\n        yield u_id, {\n            ""image"": img_path,\n            ""poselet_hit_idx"": example[0],\n            ""moviename"": example[1],\n            ""xcoords"": example[2][0],\n            ""ycoords"": example[2][1],\n            ""currframe"": example[5],\n            ""torsobox"": _normalize_bbox(example[6], img_path),\n        }\n'"
tensorflow_datasets/image/flic_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for FLIC dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import flic\n\n\nclass FlicTestSmall(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = flic.Flic\n  BUILDER_CONFIG_NAMES_TO_TEST = [""small""]\n  SPLITS = {\n      ""train"": 1,\n      ""test"": 1,\n  }\n\n\nclass FlicTestFull(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = flic.Flic\n  BUILDER_CONFIG_NAMES_TO_TEST = [""full""]\n  SPLITS = {\n      ""train"": 1,\n      ""test"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/lost_and_found.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Lost and Found Road Hazard Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom os import path\nimport re\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\n@inproceedings{pinggera2016lost,\n  title={Lost and found: detecting small road hazards for self-driving vehicles},\n  author={Pinggera, Peter and Ramos, Sebastian and Gehrig, Stefan and Franke, Uwe and Rother, Carsten and Mester, Rudolf},\n  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n  year={2016}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe LostAndFound Dataset addresses the problem of detecting unexpected small obstacles on\nthe road often caused by lost cargo. The dataset comprises 112 stereo video sequences\nwith 2104 annotated frames (picking roughly every tenth frame from the recorded data).\n\nThe dataset is designed analogous to the \'Cityscapes\' dataset. The datset provides:\n- stereo image pairs in either 8 or 16 bit color resolution\n- precomputed disparity maps\n- coarse semantic labels for objects and street\n\nDescriptions of the labels are given here: http://www.6d-vision.com/laf_table.pdf\n""""""\n\n\nclass LostAndFoundConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for \'Lost and Found\'.\n\n    Args:\n      right_images (bool): Enables right images for stereo image tasks.\n      segmentation_labels (bool): Enables image segmentation labels.\n      instance_ids (bool): Enables instance-id labels.\n      disparity_maps (bool): Enables disparity maps.\n      use_16bit (bool): Loads 16 bit (rgb) images instead of 8bit.\n  """"""\n\n  def __init__(self,\n               right_images=False,\n               segmentation_labels=False,\n               instance_ids=False,\n               disparity_maps=False,\n               use_16bit=False,\n               **kwargs):\n    super(LostAndFoundConfig, self).__init__(**kwargs)\n\n    self.features = [\'image_left\']\n    if right_images:\n      self.features.append(\'image_right\')\n    if segmentation_labels:\n      self.features.append(\'segmentation_label\')\n    if instance_ids:\n      self.features.append(\'instance_id\')\n    if disparity_maps:\n      self.features.append(\'disparity_map\')\n\n    self.left_image_string = \'leftImg{}bit\'.format(\'16\' if use_16bit else \'8\')\n    self.right_image_string = \'rightImg{}bit\'.format(\'16\' if use_16bit else \'8\')\n\n\nclass LostAndFound(tfds.core.GeneratorBasedBuilder):\n  """"""Lost and Found Road Hazard Dataset.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  BUILDER_CONFIGS = [\n      LostAndFoundConfig(\n          name=\'semantic_segmentation\',\n          description=\'Lost and Found semantic segmentation dataset.\',\n          version=\'1.0.0\',\n          right_images=False,\n          segmentation_labels=True,\n          instance_ids=False,\n          disparity_maps=False,\n          use_16bit=False,\n      ),\n      LostAndFoundConfig(\n          name=\'stereo_disparity\',\n          description=\'Lost and Found stereo images and disparity maps.\',\n          version=\'1.0.0\',\n          right_images=True,\n          segmentation_labels=False,\n          instance_ids=False,\n          disparity_maps=True,\n          use_16bit=False,\n      ),\n      LostAndFoundConfig(\n          name=\'full\',\n          description=\'Full Lost and Found dataset.\',\n          version=\'1.0.0\',\n          right_images=True,\n          segmentation_labels=True,\n          instance_ids=True,\n          disparity_maps=True,\n          use_16bit=False,\n      ),\n      LostAndFoundConfig(\n          name=\'full_16bit\',\n          description=\'Full Lost and Found dataset.\',\n          version=\'1.0.0\',\n          right_images=True,\n          segmentation_labels=True,\n          instance_ids=True,\n          disparity_maps=True,\n          use_16bit=True,\n      )\n  ]\n\n  def _info(self):\n    possible_features = {\n        \'image_left\':\n            tfds.features.Image(shape=(1024, 2048, 3), encoding_format=\'png\'),\n        \'image_right\':\n            tfds.features.Image(shape=(1024, 2048, 3), encoding_format=\'png\'),\n        \'segmentation_label\':\n            tfds.features.Image(shape=(1024, 2048, 1), encoding_format=\'png\'),\n        \'instance_id\':\n            tfds.features.Image(shape=(1024, 2048, 1), encoding_format=\'png\'),\n        \'disparity_map\':\n            tfds.features.Image(shape=(1024, 2048, 1), encoding_format=\'png\')\n    }\n    features = {\n        feat: possible_features[feat] for feat in self.builder_config.features\n    }\n    features[\'image_id\'] = tfds.features.Text()\n    features = tfds.features.FeaturesDict(features)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=features,\n        # Homepage of the dataset for documentation\n        homepage=\'http://www.6d-vision.com/lostandfounddataset\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    base_url = \'http://www.dhbw-stuttgart.de/~sgehrig/lostAndFoundDataset/{}.zip\'\n\n    # For each feature, this is the name of the zipfile and\n    # root-directory in the archive\n    zip_file_names = {\n        \'image_left\': self.builder_config.left_image_string,\n        \'image_right\': self.builder_config.right_image_string,\n        \'segmentation_label\': \'gtCoarse\',\n        \'instance_id\': \'gtCoarse\',\n        \'disparity_map\': \'disparity\'\n    }\n\n    download_urls = {\n        feat: base_url.format(zip_file_names[feat])\n        for feat in self.builder_config.features\n    }\n    # Split download and extract in two functions such that mock-data can\n    # replace the result of the download function and is still used as input to\n    # extract. Therefore, fake_data can be compressed zip archives.\n    dl_paths = dl_manager.extract(dl_manager.download(download_urls))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\n                feat: path.join(dl_paths[feat], zip_file_names[feat], \'train\')\n                for feat in self.builder_config.features\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\n                feat: path.join(dl_paths[feat], zip_file_names[feat], \'test\')\n                for feat in self.builder_config.features\n            },\n        )\n    ]\n\n  def _generate_examples(self, **paths):\n    """"""Yields examples.""""""\n    # different file-suffixes dependent on the feature to load\n    file_suffix = {\n        \'image_left\': self.builder_config.left_image_string,\n        \'image_right\': self.builder_config.right_image_string,\n        \'segmentation_label\': \'gtCoarse_labelIds\',\n        \'instance_id\': \'gtCoarse_instanceIds\',\n        \'disparity_map\': \'disparity\'\n    }\n\n    for scene_id in tf.io.gfile.listdir(paths[\'image_left\']):\n      paths_city_root = {\n          feat: path.join(feat_dir, scene_id)\n          for feat, feat_dir in paths.items()\n      }\n\n      left_city_root = paths_city_root[\'image_left\']\n      for left_img in tf.io.gfile.listdir(left_city_root):\n        image_id = _get_id_from_left_image(left_img)\n\n        features = {\n            feat: path.join(paths_city_root[feat],\n                            \'{}_{}.png\'.format(image_id, file_suffix[feat]))\n            for feat in paths\n        }\n        features[\'image_id\'] = image_id\n\n        yield image_id, features\n\n\n# Helper functions\n\nLEFT_IMAGE_FILE_RE = re.compile(r\'(.+)_leftImg(?:8|16)bit\\.png\')\n\n\ndef _get_id_from_left_image(left_image):\n  """"""Returns the id of an image file.\n\n  Used to associate an image file\n  with its corresponding label.\n  Example:\n    \'bonn_000001_000019_leftImg8bit\' -> \'bonn_000001_000019\'\n\n  Args:\n    left_image: left image file name.\n\n  Returns:\n    id of the image.\n  """"""\n  return LEFT_IMAGE_FILE_RE.match(left_image).group(1)\n'"
tensorflow_datasets/image/lost_and_found_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for LostAndFound dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import lost_and_found\n\n\nclass LostAndFoundTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = lost_and_found.LostAndFound\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'semantic_segmentation\', \'full\']\n  SPLITS = {\n      \'train\': 4,  # Number of fake train example\n      \'test\': 2,  # Number of fake test example\n  }\n  # files as generated by fake data functions in testing/lost_and_found.py\n  DL_EXTRACT_RESULT = {\n      \'image_left\': \'leftImg8bit.zip\',\n      \'image_right\': \'rightImg8bit.zip\',\n      \'disparity_map\': \'disparity.zip\',\n      \'segmentation_label\': \'gtCoarse.zip\',\n      \'instance_id\': \'gtCoarse.zip\'\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image/lsun.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""LSUN dataset.\n\nLarge scene understanding dataset.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\nLSUN_URL = ""http://dl.yf.io/lsun/scenes/%s_%s_lmdb.zip""\n\n_CITATION = """"""\\\n@article{journals/corr/YuZSSX15,\n  added-at = {2018-08-13T00:00:00.000+0200},\n  author = {Yu, Fisher and Zhang, Yinda and Song, Shuran and Seff, Ari and Xiao, Jianxiong},\n  biburl = {https://www.bibsonomy.org/bibtex/2446d4ffb99a5d7d2ab6e5417a12e195f/dblp},\n  ee = {http://arxiv.org/abs/1506.03365},\n  interhash = {3e9306c4ce2ead125f3b2ab0e25adc85},\n  intrahash = {446d4ffb99a5d7d2ab6e5417a12e195f},\n  journal = {CoRR},\n  keywords = {dblp},\n  timestamp = {2018-08-14T15:08:59.000+0200},\n  title = {LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop.},\n  url = {http://dblp.uni-trier.de/db/journals/corr/corr1506.html#YuZSSX15},\n  volume = {abs/1506.03365},\n  year = 2015\n}\n""""""\n\n\n# From http://dl.yf.io/lsun/categories.txt minus ""test""\n_CATEGORIES = [\n    ""classroom"",\n    ""bedroom"",\n    ""bridge"",\n    ""church_outdoor"",\n    ""conference_room"",\n    ""dining_room"",\n    ""kitchen"",\n    ""living_room"",\n    ""restaurant"",\n    ""tower"",\n]\n\n\ndef _make_lmdb_dataset(path):\n  return tfds.core.lazy_imports.tensorflow_io.IODataset.from_lmdb(path)\n\n\nclass Lsun(tfds.core.GeneratorBasedBuilder):\n  """"""Lsun dataset.""""""\n\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(  # pylint: disable=g-complex-comprehension\n          name=category,\n          description=""Images of category %s"" % category,\n          version=tfds.core.Version(\n              ""3.0.0"",\n              ""New split API (https://tensorflow.org/datasets/splits)""),\n      ) for category in _CATEGORIES\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""Large scale images showing different objects ""\n                     ""from given categories like bedroom, tower etc.""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(encoding_format=""jpeg""),\n        }),\n        homepage=""https://www.yf.io/p/lsun"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    extracted_dirs = dl_manager.download_and_extract({\n        ""train"": LSUN_URL % (self.builder_config.name, ""train""),\n        ""val"": LSUN_URL % (self.builder_config.name, ""val"")\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""extracted_dir"": extracted_dirs[""train""],\n                ""file_path"": ""%s_%s_lmdb"" % (self.builder_config.name, ""train"")\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""extracted_dir"": extracted_dirs[""val""],\n                ""file_path"": ""%s_%s_lmdb"" % (self.builder_config.name, ""val"")\n            }),\n    ]\n\n  def _generate_examples(self, extracted_dir, file_path):\n    with tf.Graph().as_default():\n      path = os.path.join(extracted_dir, file_path, ""data.mdb"")\n      dataset = _make_lmdb_dataset(path)\n      for i, (_, jpeg_image) in enumerate(tfds.as_numpy(dataset)):\n        record = {""image"": io.BytesIO(jpeg_image)}\n        yield i, record\n'"
tensorflow_datasets/image/lsun_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.image.lsun.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import lsun\n\n\nclass LsunTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = lsun.Lsun\n  BUILDER_CONFIG_NAMES_TO_TEST = [""classroom""]\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 1,\n  }\n\n  DL_EXTRACT_RESULT = {""train"": """", ""val"": """"}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/nyu_depth_v2.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""NYU Depth V2 Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\\\n@inproceedings{Silberman:ECCV12,\n  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},\n  title     = {Indoor Segmentation and Support Inference from RGBD Images},\n  booktitle = {ECCV},\n  year      = {2012}\n}\n@inproceedings{icra_2019_fastdepth,\n  author    = {Wofk, Diana and Ma, Fangchang and Yang, Tien-Ju and Karaman, Sertac and Sze, Vivienne},\n  title     = {FastDepth: Fast Monocular Depth Estimation on Embedded Systems},\n  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},\n  year      = {2019}\n}\n""""""\n\n\n_DESCRIPTION = """"""\\\nThe NYU-Depth V2 data set is comprised of video sequences from a variety of\nindoor scenes as recorded by both the RGB and Depth cameras from the\nMicrosoft Kinect.\n""""""\n\n\n_URL = \'http://datasets.lids.mit.edu/fastdepth/data/nyudepthv2.tar.gz\'\n\n\nclass NyuDepthV2(tfds.core.GeneratorBasedBuilder):\n  """"""NYU Depth V2 Dataset.""""""\n\n  VERSION = tfds.core.Version(\'0.0.1\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(shape=(480, 640, 3)),\n            \'depth\': tfds.features.Tensor(shape=(480, 640), dtype=tf.float16),\n        }),\n        supervised_keys=(\'image\', \'depth\'),\n        homepage=\'https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    base_path = dl_manager.download_and_extract(_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'root_dir\': os.path.join(base_path, \'nyudepthv2\', \'train\')\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'root_dir\': os.path.join(base_path, \'nyudepthv2\', \'val\')\n            },\n        ),\n    ]\n\n  def _generate_examples(self, root_dir):\n    """"""Yields examples.""""""\n    h5py = tfds.core.lazy_imports.h5py\n    for directory in tf.io.gfile.listdir(root_dir):\n      for file_name in tf.io.gfile.listdir(os.path.join(root_dir, directory)):\n        with h5py.File(os.path.join(root_dir, directory, file_name), \'r\') as f:\n          yield directory + \'_\' + file_name, {\n              \'image\': np.transpose(f[\'rgb\'], (1, 2, 0)),\n              \'depth\': f[\'depth\'][:].astype(\'float16\')\n          }\n'"
tensorflow_datasets/image/nyu_depth_v2_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for NYU Depth V2 Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image import nyu_depth_v2\nimport tensorflow_datasets.public_api as tfds\n\n\nclass NyuDepthV2Test(tfds.testing.DatasetBuilderTestCase):\n  DATASET_CLASS = nyu_depth_v2.NyuDepthV2\n  SPLITS = {""train"": 2, ""validation"": 1}\n\n\nif __name__ == ""__main__"":\n  tfds.testing.test_main()\n'"
tensorflow_datasets/image/scene_parse_150.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""MIT Scene Parsing Benchmark (SceneParse150).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{zhou2017scene,\ntitle={Scene Parsing through ADE20K Dataset},\nauthor={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},\nbooktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\nyear={2017}\n}\n""""""\n\n_DESCRIPTION = """"""\nScene parsing is to segment and parse an image into different image regions\nassociated with semantic categories, such as sky, road, person, and bed.\nMIT Scene Parsing Benchmark (SceneParse150) provides a standard training and\nevaluation platform for the algorithms of scene parsing.\n""""""\n\n_TRAIN_URL = {\n    ""images"":\n        ""http://placeschallenge.csail.mit.edu/data/ChallengeData2017/images.tar"",\n    ""annotations"":\n        ""http://placeschallenge.csail.mit.edu/data/ChallengeData2017/annotations_instance.tar""\n}\n\n\nclass SceneParse150(tfds.core.GeneratorBasedBuilder):\n  """"""MIT Scene Parsing Benchmark dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(encoding_format=""jpeg""),\n            ""annotation"": tfds.features.Image(encoding_format=""png"")\n        }),\n        supervised_keys=(""image"", ""annotation""),\n        homepage=""http://sceneparsing.csail.mit.edu/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_paths = dl_manager.download_and_extract({\n        ""images"": _TRAIN_URL[""images""],\n        ""annotations"": _TRAIN_URL[""annotations""],\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""images_dir_path"":\n                    os.path.join(dl_paths[""images""], ""images/training""),\n                ""annotations_dir_path"":\n                    os.path.join(dl_paths[""annotations""],\n                                 ""annotations_instance/training"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""images_dir_path"":\n                    os.path.join(dl_paths[""images""], ""images/validation""),\n                ""annotations_dir_path"":\n                    os.path.join(dl_paths[""annotations""],\n                                 ""annotations_instance/validation"")\n            },\n        ),\n    ]\n\n  def _generate_examples(self, images_dir_path, annotations_dir_path):\n    for image_file in tf.io.gfile.listdir(images_dir_path):\n      # get the filename\n      image_id = os.path.split(image_file)[1].split(""."")[0]\n      yield image_id, {\n          ""image"":\n              os.path.join(images_dir_path, ""{}.jpg"".format(image_id)),\n          ""annotation"":\n              os.path.join(annotations_dir_path, ""{}.png"".format(image_id))\n      }\n'"
tensorflow_datasets/image/scene_parse_150_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for MIT Scene Parsing Benchmark (SceneParse150).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import scene_parse_150\n\n\nclass SceneParse150Test(testing.DatasetBuilderTestCase):\n\n  DATASET_CLASS = scene_parse_150.SceneParse150\n\n  SPLITS = {\n      ""train"": 3,\n      ""test"": 3,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""images"": ""images"",\n      ""annotations"": ""annotations"",\n      ""test"": ""test"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image/shapes3d.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Shapes3D dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six import moves\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@misc{3dshapes18,\n  title={3D Shapes Dataset},\n  author={Burgess, Chris and Kim, Hyunjik},\n  howpublished={https://github.com/deepmind/3dshapes-dataset/},\n  year={2018}\n}\n""""""\n\n_URL = (""https://storage.googleapis.com/3d-shapes/3dshapes.h5"")\n\n_DESCRIPTION = """"""\\\n3dshapes is a dataset of 3D shapes procedurally generated from 6 ground truth\nindependent latent factors. These factors are *floor colour*, *wall colour*, *object colour*,\n*scale*, *shape* and *orientation*.\n\nAll possible combinations of these latents are present exactly once, generating N = 480000 total images.\n\n### Latent factor values\n\n*   floor hue: 10 values linearly spaced in [0, 1]\n*   wall hue: 10 values linearly spaced in [0, 1]\n*   object hue: 10 values linearly spaced in [0, 1]\n*   scale: 8 values linearly spaced in [0, 1]\n*   shape: 4 values in [0, 1, 2, 3]\n*   orientation: 15 values linearly spaced in [-30, 30]\n\nWe varied one latent at a time (starting from orientation, then shape, etc), and sequentially stored the images in fixed order in the `images` array. The corresponding values of the factors are stored in the same order in the `labels` array.\n""""""\n\n\nclass Shapes3d(tfds.core.GeneratorBasedBuilder):\n  """"""Shapes3d data set.""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(shape=(64, 64, 3)),\n            ""label_floor_hue"":\n                tfds.features.ClassLabel(num_classes=10),\n            ""label_wall_hue"":\n                tfds.features.ClassLabel(num_classes=10),\n            ""label_object_hue"":\n                tfds.features.ClassLabel(num_classes=10),\n            ""label_scale"":\n                tfds.features.ClassLabel(num_classes=8),\n            ""label_shape"":\n                tfds.features.ClassLabel(num_classes=4),\n            ""label_orientation"":\n                tfds.features.ClassLabel(num_classes=15),\n            ""value_floor_hue"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n            ""value_wall_hue"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n            ""value_object_hue"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n            ""value_scale"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n            ""value_shape"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n            ""value_orientation"":\n                tfds.features.Tensor(shape=[], dtype=tf.float32),\n        }),\n        homepage=""https://github.com/deepmind/3d-shapes"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    filepath = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(filepath=filepath)),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Generate examples for the Shapes3d dataset.\n\n    Args:\n      filepath: path to the Shapes3d hdf5 file.\n\n    Yields:\n      Dictionaries with images and the different labels.\n    """"""\n    # Simultaneously iterating through the different data sets in the hdf5\n    # file will be slow with a single file. Instead, we first load everything\n    # into memory before yielding the samples.\n    with tfds.core.lazy_imports.h5py.File(filepath, ""r"") as h5dataset:\n      image_array = np.array(h5dataset[""images""])\n      # The \'label\' data set in the hdf5 file actually contains the float values\n      # and not the class labels.\n      values_array = np.array(h5dataset[""labels""])\n\n    # We need to calculate the class labels from the float values in the file.\n    labels_array = np.zeros_like(values_array, dtype=np.int64)\n    for i in range(values_array.shape[1]):\n      labels_array[:, i] = _discretize(values_array[:, i])  # pylint: disable=unsupported-assignment-operation\n\n    for i, (image, labels, values) in enumerate(moves.zip(\n        image_array, labels_array, values_array)):\n      record = {\n          ""image"": image,\n          ""label_floor_hue"": labels[0],\n          ""label_wall_hue"": labels[1],\n          ""label_object_hue"": labels[2],\n          ""label_scale"": labels[3],\n          ""label_shape"": labels[4],\n          ""label_orientation"": labels[5],\n          ""value_floor_hue"": values[0],\n          ""value_wall_hue"": values[1],\n          ""value_object_hue"": values[2],\n          ""value_scale"": values[3],\n          ""value_shape"": values[4],\n          ""value_orientation"": values[5],\n      }\n      yield i, record\n\n\ndef _discretize(a):\n  """"""Discretizes array values to class labels.""""""\n  arr = np.asarray(a)\n  index = np.argsort(arr)\n  inverse_index = np.zeros(arr.size, dtype=np.intp)\n  inverse_index[index] = np.arange(arr.size, dtype=np.intp)\n  arr = arr[index]\n  obs = np.r_[True, arr[1:] != arr[:-1]]\n  return obs.cumsum()[inverse_index] - 1\n'"
tensorflow_datasets/image/shapes3d_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Shapes3D dataset test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image import shapes3d\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass Shapes3dTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = shapes3d.Shapes3d\n  SPLITS = {""train"": 5}\n  DL_EXTRACT_RESULT = ""3dshapes.h5""\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image/the300w_lp.py,13,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""300W-LP Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DATASET_URL = ""https://drive.google.com/uc?export=download&id=0B7OEHD3T4eCkVGs0TkhUWFN6N1k""\n\n_PROJECT_URL = ""http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm""\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/ZhuLLSL15,\n  author    = {Xiangyu Zhu and\n               Zhen Lei and\n               Xiaoming Liu and\n               Hailin Shi and\n               Stan Z. Li},\n  title     = {Face Alignment Across Large Poses: {A} 3D Solution},\n  journal   = {CoRR},\n  volume    = {abs/1511.07212},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1511.07212},\n  archivePrefix = {arXiv},\n  eprint    = {1511.07212},\n  timestamp = {Mon, 13 Aug 2018 16:48:23 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuLLSL15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\\\n300W-LP Dataset is expanded from 300W, which standardises multiple alignment \\\ndatabases with 68 landmarks, including AFW, LFPW, HELEN, IBUG and XM2VTS. With \\\n300W, 300W-LP adopt the proposed face profiling to generate 61,225 samples \\\nacross large poses (1,786 from IBUG, 5,207 from AFW, 16,556 from LFPW and \\\n37,676 from HELEN, XM2VTS is not used).\n\nThe dataset can be employed as the training set for the following computer \\\nvision tasks: face attribute recognition and landmark (or facial part) \\\nlocaization.\n""""""\n\n\nclass The300wLp(tfds.core.GeneratorBasedBuilder):\n  """"""300W-LP dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(\n                    shape=(450, 450, 3), encoding_format=""jpeg""),\n            ""landmarks_origin"":\n                tfds.features.Tensor(shape=(68, 2), dtype=tf.float32),\n            ""landmarks_2d"":\n                tfds.features.Tensor(shape=(68, 2), dtype=tf.float32),\n            ""landmarks_3d"":\n                tfds.features.Tensor(shape=(68, 2), dtype=tf.float32),\n            ""roi"":\n                tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n            ""illum_params"":\n                tfds.features.Tensor(shape=(10,), dtype=tf.float32),\n            ""color_params"":\n                tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n            ""tex_params"":\n                tfds.features.Tensor(shape=(199,), dtype=tf.float32),\n            ""shape_params"":\n                tfds.features.Tensor(shape=(199,), dtype=tf.float32),\n            ""exp_params"":\n                tfds.features.Tensor(shape=(29,), dtype=tf.float32),\n            ""pose_params"":\n                tfds.features.Tensor(shape=(7,), dtype=tf.float32)\n        }),\n        homepage=_PROJECT_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    extracted_path = dl_manager.download_and_extract(_DATASET_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""image_dir_path"": os.path.join(extracted_path, ""300W_LP""),\n            }),\n    ]\n\n  def _generate_examples(self, image_dir_path):\n    """"""Yields examples.""""""\n    image_files = tf.io.gfile.glob(\n        pattern=os.path.join(image_dir_path, ""[!Code]*[!_Flip]/[!_]*.jpg""))\n    label_files = [s.replace(""jpg"", ""mat"") for s in image_files]\n    landmark_files = [\n        s.replace(""300W_LP"", ""300W_LP/landmarks"").replace("".jpg"", ""_pts.mat"")\n        for s in image_files\n    ]\n    for image_file, label_file, landmark_file in zip(image_files, label_files,\n                                                     landmark_files):\n      with tf.io.gfile.GFile(label_file, ""rb"") as f:\n        mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n      pt2d_origin = mat[""pt2d""].T\n      pt2d_origin = (pt2d_origin / 450.0).astype(np.float32)\n      roi = mat[""roi""].reshape(4).astype(np.float32)\n      illum_params = mat[""Illum_Para""].reshape([-1]).astype(np.float32)\n      color_params = mat[""Color_Para""].reshape([-1]).astype(np.float32)\n      tex_params = mat[""Tex_Para""].reshape([-1]).astype(np.float32)\n      shape_params = mat[""Shape_Para""].reshape([-1]).astype(np.float32)\n      exp_params = mat[""Exp_Para""].reshape([-1]).astype(np.float32)\n      pose_params = mat[""Pose_Para""].reshape([-1]).astype(np.float32)\n      with tf.io.gfile.GFile(landmark_file, ""rb"") as f:\n        ldm_mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n        pt2d = (ldm_mat[""pts_2d""] / 450.0).astype(np.float32)\n        pt3d = (ldm_mat[""pts_3d""] / 450.0).astype(np.float32)\n      record = {\n          ""image"": image_file,\n          ""landmarks_origin"": pt2d_origin,\n          ""landmarks_2d"": pt2d,\n          ""landmarks_3d"": pt3d,\n          ""roi"": roi,\n          ""illum_params"": illum_params,\n          ""color_params"": color_params,\n          ""tex_params"": tex_params,\n          ""shape_params"": shape_params,\n          ""exp_params"": exp_params,\n          ""pose_params"": pose_params\n      }\n      yield os.path.basename(image_file), record\n'"
tensorflow_datasets/image/the300w_lp_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for 300W-LP dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image import the300w_lp\n\n\nclass The300wLpTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = the300w_lp.The300wLp\n  SPLITS = {\n      ""train"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Image Classification datasets.""""""\n\nfrom tensorflow_datasets.image_classification.beans import Beans\nfrom tensorflow_datasets.image_classification.bigearthnet import Bigearthnet\nfrom tensorflow_datasets.image_classification.binary_alpha_digits import BinaryAlphaDigits\nfrom tensorflow_datasets.image_classification.caltech import Caltech101\nfrom tensorflow_datasets.image_classification.caltech_birds import CaltechBirds2010\nfrom tensorflow_datasets.image_classification.cars196 import Cars196\nfrom tensorflow_datasets.image_classification.cassava import Cassava\nfrom tensorflow_datasets.image_classification.cats_vs_dogs import CatsVsDogs\nfrom tensorflow_datasets.image_classification.cbis_ddsm import CuratedBreastImagingDDSM\nfrom tensorflow_datasets.image_classification.chexpert import Chexpert\nfrom tensorflow_datasets.image_classification.cifar import Cifar10\nfrom tensorflow_datasets.image_classification.cifar import Cifar100\nfrom tensorflow_datasets.image_classification.cifar10_1 import Cifar10_1\nfrom tensorflow_datasets.image_classification.cifar10_corrupted import Cifar10Corrupted\nfrom tensorflow_datasets.image_classification.citrus import CitrusLeaves\nfrom tensorflow_datasets.image_classification.cmaterdb import Cmaterdb\nfrom tensorflow_datasets.image_classification.colorectal_histology import ColorectalHistology\nfrom tensorflow_datasets.image_classification.colorectal_histology import ColorectalHistologyLarge\nfrom tensorflow_datasets.image_classification.cycle_gan import CycleGAN\nfrom tensorflow_datasets.image_classification.deep_weeds import DeepWeeds\nfrom tensorflow_datasets.image_classification.diabetic_retinopathy_detection import DiabeticRetinopathyDetection\nfrom tensorflow_datasets.image_classification.dmlab import Dmlab\nfrom tensorflow_datasets.image_classification.dtd import Dtd\nfrom tensorflow_datasets.image_classification.eurosat import Eurosat\nfrom tensorflow_datasets.image_classification.flowers import TFFlowers\nfrom tensorflow_datasets.image_classification.food101 import Food101\nfrom tensorflow_datasets.image_classification.geirhos_conflict_stimuli import GeirhosConflictStimuli\nfrom tensorflow_datasets.image_classification.horses_or_humans import HorsesOrHumans\nfrom tensorflow_datasets.image_classification.image_folder import ImageLabelFolder\nfrom tensorflow_datasets.image_classification.imagenet import Imagenet2012\nfrom tensorflow_datasets.image_classification.imagenet2012_corrupted import Imagenet2012Corrupted\nfrom tensorflow_datasets.image_classification.imagenet2012_subset import Imagenet2012Subset\nfrom tensorflow_datasets.image_classification.imagenet_resized import ImagenetResized\nfrom tensorflow_datasets.image_classification.imagenette import Imagenette\nfrom tensorflow_datasets.image_classification.imagewang import Imagewang\nfrom tensorflow_datasets.image_classification.inaturalist import INaturalist2017\nfrom tensorflow_datasets.image_classification.lfw import LFW\nfrom tensorflow_datasets.image_classification.malaria import Malaria\nfrom tensorflow_datasets.image_classification.mnist import EMNIST\nfrom tensorflow_datasets.image_classification.mnist import FashionMNIST\nfrom tensorflow_datasets.image_classification.mnist import KMNIST\nfrom tensorflow_datasets.image_classification.mnist import MNIST\nfrom tensorflow_datasets.image_classification.mnist_corrupted import MNISTCorrupted\nfrom tensorflow_datasets.image_classification.omniglot import Omniglot\nfrom tensorflow_datasets.image_classification.oxford_flowers102 import OxfordFlowers102\nfrom tensorflow_datasets.image_classification.oxford_iiit_pet import OxfordIIITPet\nfrom tensorflow_datasets.image_classification.patch_camelyon import PatchCamelyon\nfrom tensorflow_datasets.image_classification.pet_finder import PetFinder\nfrom tensorflow_datasets.image_classification.places365_small import Places365Small\nfrom tensorflow_datasets.image_classification.plant_leaves import PlantLeaves\nfrom tensorflow_datasets.image_classification.plant_village import PlantVillage\nfrom tensorflow_datasets.image_classification.plantae_k import PlantaeK\nfrom tensorflow_datasets.image_classification.quickdraw import QuickdrawBitmap\nfrom tensorflow_datasets.image_classification.resisc45 import Resisc45\nfrom tensorflow_datasets.image_classification.rock_paper_scissors import RockPaperScissors\nfrom tensorflow_datasets.image_classification.smallnorb import Smallnorb\nfrom tensorflow_datasets.image_classification.so2sat import So2sat\nfrom tensorflow_datasets.image_classification.stanford_dogs import StanfordDogs\nfrom tensorflow_datasets.image_classification.stanford_online_products import StanfordOnlineProducts\nfrom tensorflow_datasets.image_classification.stl10 import Stl10\nfrom tensorflow_datasets.image_classification.sun import Sun397\nfrom tensorflow_datasets.image_classification.svhn import SvhnCropped\nfrom tensorflow_datasets.image_classification.uc_merced import UcMerced\nfrom tensorflow_datasets.image_classification.vgg_face2 import VggFace2\nfrom tensorflow_datasets.image_classification.visual_domain_decathlon import VisualDomainDecathlon\n'"
tensorflow_datasets/image_classification/beans.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Beans leaf dataset with images of diseased and health leaves.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@ONLINE {beansdata,\n    author=""Makerere AI Lab"",\n    title=""Bean disease dataset"",\n    month=""January"",\n    year=""2020"",\n    url=""https://github.com/AI-Lab-Makerere/ibean/""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nBeans is a dataset of images of beans taken in the field using smartphone\ncameras. It consists of 3 classes: 2 disease classes and the healthy class.\nDiseases depicted include Angular Leaf Spot and Bean Rust. Data was annotated\nby experts from the National Crops Resources Research Institute (NaCRRI) in\nUganda and collected by the Makerere AI research lab.\n""""""\n\n_TRAIN_URL = ""https://storage.googleapis.com/ibeans/train.zip""\n_VALIDATION_URL = ""https://storage.googleapis.com/ibeans/validation.zip""\n_TEST_URL = ""https://storage.googleapis.com/ibeans/test.zip""\n\n_IMAGE_SIZE = 500\n_IMAGE_SHAPE = (_IMAGE_SIZE, _IMAGE_SIZE, 3)\n\n_LABELS = [""angular_leaf_spot"", ""bean_rust"", ""healthy""]\n\n\nclass Beans(tfds.core.GeneratorBasedBuilder):\n  """"""Beans plant leaf images dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds. features.ClassLabel(names=_LABELS)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/AI-Lab-Makerere/ibean/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    train_path, val_path, test_path = dl_manager.download(\n        [_TRAIN_URL, _VALIDATION_URL, _TEST_URL])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(train_path)},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(val_path)},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(test_path)},\n        ),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Yields examples.""""""\n    for fname, fobj in archive:\n      if not fname.endswith("".jpg""):\n        continue\n      label = fname.split(os.path.sep)[-2]\n      record = {\n          ""image"": fobj,\n          ""label"": label,\n      }\n      yield fname, record\n\n'"
tensorflow_datasets/image_classification/beans_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Beans dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import beans\nimport tensorflow_datasets.testing as tfds_test\n\nbeans._IMAGE_SHAPE = (None, None, 3)  # pylint: disable=protected-access\n\n\nclass BeansTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = beans.Beans\n\n  SPLITS = {\n      \'train\': 3,\n      \'test\': 3,\n      \'validation\': 3,\n  }\n\n  DL_EXTRACT_RESULT = [\'beans_train.zip\', \'beans_validation.zip\',\n                       \'beans_test.zip\']\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n\n'"
tensorflow_datasets/image_classification/bigearthnet.py,16,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BigEarthNet remote sensing dataset of Sentinel-2 image patches.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport json\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{Sumbul2019BigEarthNetAL,\n  title={BigEarthNet: A Large-Scale Benchmark Archive For Remote Sensing Image Understanding},\n  author={Gencer Sumbul and Marcela Charfuelan and Beg{\\""u}m Demir and Volker Markl},\n  journal={CoRR},\n  year={2019},\n  volume={abs/1902.06148}\n}""""""\n\n_DESCRIPTION = """"""\\\nThe BigEarthNet is a new large-scale Sentinel-2 benchmark archive, consisting of\n590,326 Sentinel-2 image patches. The image patch size on the ground is\n1.2 x 1.2 km with variable image size depending on the channel resolution.\nThis is a multi-label dataset with 43 imbalanced labels.\n\nTo construct the BigEarthNet, 125 Sentinel-2\ntiles acquired between June 2017 and May 2018 over the 10 countries (Austria,\nBelgium, Finland, Ireland, Kosovo, Lithuania, Luxembourg, Portugal, Serbia,\nSwitzerland) of Europe were initially selected. All the tiles were\natmospherically corrected by the Sentinel-2 Level 2A product generation and\nformatting tool (sen2cor). Then, they were divided into 590,326 non-overlapping\nimage patches. Each image patch was annotated by the multiple land-cover classes\n(i.e., multi-labels) that were provided from the CORINE Land Cover database of\nthe year 2018 (CLC 2018).\n\nBands and pixel resolution in meters:\n\n* B01: Coastal aerosol; 60m\n* B02: Blue; 10m\n* B03: Green; 10m\n* B04: Red; 10m\n* B05: Vegetation red edge; 20m\n* B06: Vegetation red edge; 20m\n* B07: Vegetation red edge; 20m\n* B08: NIR; 10m\n* B09: Water vapor; 60m\n* B11: SWIR; 20m\n* B12: SWIR; 20m\n* B8A: Narrow NIR; 20m\n\nLicense: Community Data License Agreement - Permissive, Version 1.0.\n\nURL: http://bigearth.net/\n""""""\n\n_LABELS = [\n    \'Agro-forestry areas\', \'Airports\',\n    \'Annual crops associated with permanent crops\', \'Bare rock\',\n    \'Beaches, dunes, sands\', \'Broad-leaved forest\', \'Burnt areas\',\n    \'Coastal lagoons\', \'Complex cultivation patterns\', \'Coniferous forest\',\n    \'Construction sites\', \'Continuous urban fabric\',\n    \'Discontinuous urban fabric\', \'Dump sites\', \'Estuaries\',\n    \'Fruit trees and berry plantations\', \'Green urban areas\',\n    \'Industrial or commercial units\', \'Inland marshes\', \'Intertidal flats\',\n    \'Land principally occupied by agriculture, with significant areas of \'\n    \'natural vegetation\', \'Mineral extraction sites\', \'Mixed forest\',\n    \'Moors and heathland\', \'Natural grassland\', \'Non-irrigated arable land\',\n    \'Olive groves\', \'Pastures\', \'Peatbogs\', \'Permanently irrigated land\',\n    \'Port areas\', \'Rice fields\', \'Road and rail networks and associated land\',\n    \'Salines\', \'Salt marshes\', \'Sclerophyllous vegetation\', \'Sea and ocean\',\n    \'Sparsely vegetated areas\', \'Sport and leisure facilities\',\n    \'Transitional woodland/shrub\', \'Vineyards\', \'Water bodies\', \'Water courses\'\n]\n\n_DATA_OPTIONS = [\'rgb\', \'all\']\n\n_ZIP_FILE = \'http://bigearth.net/downloads/BigEarthNet-v1.0.tar.gz\'\n_ZIP_SUBIDR = \'BigEarthNet-v1.0\'\n\n# To clip and rescale the RGB channels for the JPEG images visualizatoin.\n# This is not the maximal value.\n# Sample observed max value was about 17800, while the sample observed mean\n# was about 400 with a standard deviation of about 200.\n# Adhoc selection of the upper max value to be mean + 7*std.\n_OPTICAL_MAX_VALUE = 2000.\n\n\nclass BigearthnetConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Bigearthnet.""""""\n\n  def __init__(self, selection=None, **kwargs):\n    """"""Constructs a BigearthnetConfig.\n\n    Args:\n      selection: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if selection not in _DATA_OPTIONS:\n      raise ValueError(\'selection must be one of %s\' % _DATA_OPTIONS)\n\n    v100 = tfds.core.Version(\n        \'1.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n    super(BigearthnetConfig, self).__init__(\n        version=v100,\n        **kwargs)\n    self.selection = selection\n\n\nclass Bigearthnet(tfds.core.BeamBasedBuilder):\n  """"""Bigearthnet remote sensing dataset of Sentinel-2 image patches.""""""\n\n  BUILDER_CONFIGS = [\n      BigearthnetConfig(\n          selection=\'rgb\',\n          name=\'rgb\',\n          description=\'Sentinel-2 RGB channels\'),\n      BigearthnetConfig(\n          selection=\'all\',\n          name=\'all\',\n          description=\'13 Sentinel-2 channels\'),\n  ]\n\n  def _info(self):\n    metadata_dict = tfds.features.FeaturesDict({\n        \'acquisition_date\': tfds.features.Text(),\n        \'coordinates\': {\n            \'lrx\': tf.int64,\n            \'lry\': tf.int64,\n            \'ulx\': tf.int64,\n            \'uly\': tf.int64,\n        },\n        \'projection\': tfds.features.Text(),\n        \'tile_source\': tfds.features.Text(),\n    })\n    if self.builder_config.selection == \'rgb\':\n      features = tfds.features.FeaturesDict({\n          \'image\':\n              tfds.features.Image(shape=[120, 120, 3]),\n          \'labels\':\n              tfds.features.Sequence(tfds.features.ClassLabel(names=_LABELS)),\n          \'filename\':\n              tfds.features.Text(),\n          \'metadata\':\n              metadata_dict,\n      })\n      supervised_keys = (\'image\', \'labels\')\n    elif self.builder_config.selection == \'all\':\n      features = tfds.features.FeaturesDict({\n          \'B01\':\n              tfds.features.Tensor(shape=[20, 20], dtype=tf.float32),\n          \'B02\':\n              tfds.features.Tensor(shape=[120, 120], dtype=tf.float32),\n          \'B03\':\n              tfds.features.Tensor(shape=[120, 120], dtype=tf.float32),\n          \'B04\':\n              tfds.features.Tensor(shape=[120, 120], dtype=tf.float32),\n          \'B05\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'B06\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'B07\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'B08\':\n              tfds.features.Tensor(shape=[120, 120], dtype=tf.float32),\n          \'B09\':\n              tfds.features.Tensor(shape=[20, 20], dtype=tf.float32),\n          \'B11\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'B12\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'B8A\':\n              tfds.features.Tensor(shape=[60, 60], dtype=tf.float32),\n          \'labels\':\n              tfds.features.Sequence(tfds.features.ClassLabel(names=_LABELS)),\n          \'filename\':\n              tfds.features.Text(),\n          \'metadata\':\n              metadata_dict,\n      })\n      supervised_keys = None\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=features,\n        supervised_keys=supervised_keys,\n        homepage=\'http://bigearth.net\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download(_ZIP_FILE)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'archive_path\': dl_path,\n            },\n        ),\n    ]\n\n  def _build_pcollection(self, pipeline, archive_path):\n    """"""Generates examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n    selection = self.builder_config.selection\n\n    return (pipeline\n            | \'ArchivePath\' >> beam.Create([archive_path])\n            | \'ReadArchive\' >> beam.FlatMap(_read_archive, selection)\n            | \'Reshuffle\' >> beam.transforms.Reshuffle()\n            | \'ProcessExamples\' >> beam.Map(_process_example, selection))\n\n\ndef _read_archive(archive_path, selection):\n  """"""Yields non-processed examples out of archive.""""""\n  example = {}\n  read_band_files = 0\n  for fpath, fobj in tfds.core.download.extractor.iter_tar_stream(\n      archive_path):\n    read_band_files += 1\n    _, patch_name, fname = fpath.split(os.path.sep)\n    if fname.endswith(\'_labels_metadata.json\'):\n      example[\'metadata\'] = fobj.read()\n    elif fname.endswith(\'.tif\'):\n      band = fname[-7:-4]\n      if selection != \'rgb\' or (\n          selection == \'rgb\' and band in {\'B02\', \'B03\', \'B04\'}):\n        example[band] = fobj.read()\n        example.setdefault(\'bands\', []).append(band)\n    else:\n      raise AssertionError(\'Unexpected file: %s\' % fpath)\n    if read_band_files == 13:\n      example[\'filename\'] = patch_name\n      yield example\n      example = {}\n      read_band_files = 0\n\n\ndef _process_example(example, selection):\n  example = example.copy()\n  example[\'metadata\'] = json.loads(example[\'metadata\'])\n  example[\'labels\'] = example[\'metadata\'].pop(\'labels\')\n  for band in example.pop(\'bands\') or []:\n    example[band] = _load_tif(example[band])\n  if selection == \'rgb\':\n    _create_rgb_image(example)\n  return example[\'filename\'], example\n\n\ndef _create_rgb_image(d):\n  """"""Creates and rescales RGB image.""""""\n  img = np.stack([d.pop(\'B04\'), d.pop(\'B03\'), d.pop(\'B02\')], axis=2)\n  img = img / _OPTICAL_MAX_VALUE * 255.0\n  d[\'image\'] = np.clip(img, 0, 255).astype(np.uint8)\n\n\ndef _load_tif(data):\n  """"""Loads TIF file and returns as float32 numpy array.""""""\n  img = tfds.core.lazy_imports.PIL_Image.open(io.BytesIO(data))\n  img = np.array(img.getdata()).reshape(img.size).astype(np.float32)\n  return img\n'"
tensorflow_datasets/image_classification/bigearthnet_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Bigearthnet data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import bigearthnet\n\n\nclass BigearthnetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = bigearthnet.Bigearthnet\n  SPLITS = {\n      ""train"": 1,\n  }\n  DL_EXTRACT_RESULT = ""BigEarthNet-v1.0.tar.gz""\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/binary_alpha_digits.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TensorFlow dataset for Binary Alphadigits.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport six.moves.urllib as urllib\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = \'https://cs.nyu.edu/~roweis/data/\'\n\n_DESCRIPTION = (""Binary 20x16 digits of \'0\' through \'9\' and capital \'A\' ""\n                ""through \'Z\'. 39 examples of each class."")\n\n_IMAGE_SHAPE = (20, 16, 1)\n\n_NAMES = [\n    \'0\', \'1\', \'2\', \'3\', \'4\', \'5\', \'6\', \'7\', \'8\', \'9\', \'A\', \'B\', \'C\', \'D\', \'E\',\n    \'F\', \'G\', \'H\', \'I\', \'J\', \'K\', \'L\', \'M\', \'N\', \'O\', \'P\', \'Q\', \'R\', \'S\', \'T\',\n    \'U\', \'V\', \'W\', \'X\', \'Y\', \'Z\'\n]\n\n_CITATION = """"""\\\n\n""""""\n\n\nclass BinaryAlphaDigits(tfds.core.GeneratorBasedBuilder):\n  """"""Binary alphadigits dataset.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    """"""Define the Dataset info.""""""\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(shape=_IMAGE_SHAPE),\n            \'label\': tfds.features.ClassLabel(names=_NAMES),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Define Splits for training data.""""""\n\n    path = dl_manager.download(\n        {\'train\': urllib.parse.urljoin(_URL, \'binaryalphadigs.mat\')})\n\n    return [\n        tfds.core.SplitGenerator(\n            name=\'train\',\n            gen_kwargs={\n                \'data_dir_path\': path[\'train\'],\n            },\n        )\n    ]\n\n  def _generate_examples(self, data_dir_path):\n    """"""Generate Splits for training data.""""""\n\n    with tf.io.gfile.GFile(data_dir_path, \'rb\') as f:\n      mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n    for i in range(len(mat[\'dat\'])):\n      label = mat[\'classlabels\'][0][i].item()\n      for j in range(len(mat[\'dat\'][i])):\n        image = mat[\'dat\'][i][j].reshape(20, 16, 1)\n        yield \'%d_%d\'%(i, j), {\'label\': label, \'image\': image}\n'"
tensorflow_datasets/image_classification/binary_alpha_digits_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets.image_classification import binary_alpha_digits\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass BinaryAlphaDigitsTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = binary_alpha_digits.BinaryAlphaDigits\n  SPLITS = {\n      ""train"": 2,\n  }\n\n  DL_EXTRACT_RESULT = {""train"": ""binaryalphadigs.mat""}\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/caltech.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Caltech images dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{FeiFei2004LearningGV,\n  title={Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories},\n  author={Li Fei-Fei and Rob Fergus and Pietro Perona},\n  journal={Computer Vision and Pattern Recognition Workshop},\n  year={2004},\n}\n""""""\n_DESCRIPTION = """"""\\\nCaltech-101 consists of pictures of objects belonging to 101 classes, plus\none `background clutter` class. Each image is labelled with a single object.\nEach class contains roughly 40 to 800 images, totalling around 9k images.\nImages are of variable sizes, with typical edge lengths of 200-300 pixels.\nThis version contains image-level labels only. The original dataset also\ncontains bounding boxes.\n""""""\n_LABELS_FNAME = ""image_classification/caltech101_labels.txt""\n_URL = ""http://www.vision.caltech.edu/Image_Datasets/Caltech101/""\n_IMAGES_FNAME = ""101_ObjectCategories.tar.gz""\n_TRAIN_POINTS_PER_CLASS = 30\n\n\nclass Caltech101(tfds.core.GeneratorBasedBuilder):\n  """"""Caltech-101.""""""\n\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names_file=names_file),\n            ""image/file_name"": tfds.features.Text(),  # E.g. \'image_0001.jpg\'.\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION\n        )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download_and_extract(os.path.join(_URL, _IMAGES_FNAME))\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""images_dir_path"": path,\n                ""is_train_split"": True,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""images_dir_path"": path,\n                ""is_train_split"": False,\n            }),\n    ]\n\n  def _generate_examples(self, images_dir_path, is_train_split):\n    """"""Generates images and labels given the image directory path.\n\n    As is usual for this dataset, 30 random examples from each class are added\n    to the train split, and the remainder are added to the test split.\n\n    Args:\n      images_dir_path: path to the directory where the images are stored.\n      is_train_split: bool, if true, generates the train split, else generates\n        the test split.\n\n    Yields:\n      The image path, and its corresponding label and filename.\n\n    Raises:\n      ValueError: If too few points are present to create the train set for any\n        class.\n    """"""\n    # Sets random seed so the random partitioning of files is the same when\n    # called for the train and test splits.\n    numpy_original_state = np.random.get_state()\n    np.random.seed(1234)\n\n    parent_dir = tf.io.gfile.listdir(images_dir_path)[0]\n    walk_dir = os.path.join(images_dir_path, parent_dir)\n    dirs = tf.io.gfile.listdir(walk_dir)\n\n    for d in dirs:\n      # Each directory contains all the images from a single class.\n      if tf.io.gfile.isdir(os.path.join(walk_dir, d)):\n        for full_path, _, fnames in tf.io.gfile.walk(os.path.join(walk_dir, d)):\n\n          # _TRAIN_POINTS_PER_CLASS datapoints are sampled for the train split,\n          # the others constitute the test split.\n          if _TRAIN_POINTS_PER_CLASS > len(fnames):\n            raise ValueError(""Fewer than {} ({}) points in class {}"".format(\n                _TRAIN_POINTS_PER_CLASS, len(fnames), d))\n          train_fnames = np.random.choice(fnames, _TRAIN_POINTS_PER_CLASS,\n                                          replace=False)\n          test_fnames = set(fnames).difference(train_fnames)\n          fnames_to_emit = train_fnames if is_train_split else test_fnames\n\n          for image_file in fnames_to_emit:\n            if image_file.endswith("".jpg""):\n              image_path = os.path.join(full_path, image_file)\n              record = {\n                  ""image"": image_path,\n                  ""label"": d.lower(),\n                  ""image/file_name"": image_file,\n              }\n              yield ""%s/%s"" % (d, image_file), record\n    # Resets the seeds to their previous states.\n    np.random.set_state(numpy_original_state)\n'"
tensorflow_datasets/image_classification/caltech_birds.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Caltech birds dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport re\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nCaltech-UCSD Birds 200 (CUB-200) is an image dataset with photos \nof 200 bird species (mostly North American). The total number of \ncategories of birds is 200 and there are 6033 images in the 2010 \ndataset and 11,788 images in the 2011 dataset.\nAnnotations include bounding boxes, segmentation labels.\n""""""\n\n_URL = (""http://www.vision.caltech.edu/visipedia/CUB-200.html"")\n_CITATION = """"""\\\n@techreport{WelinderEtal2010,\nAuthor = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},\nInstitution = {California Institute of Technology},\nNumber = {CNS-TR-2010-001},\nTitle = {{Caltech-UCSD Birds 200}},\nYear = {2010}\n}\n""""""\n_NAME_RE = re.compile(r""((\\w*)/)*(\\d*).(\\w*)/(\\w*.jpg)$"")\n\n\nclass CaltechBirds2010(tfds.core.GeneratorBasedBuilder):\n  """"""Caltech Birds 2010 dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  @property\n  def _caltech_birds_info(self):\n    return CaltechBirdsInfo(\n        name=self.name,\n        images_url=""http://www.vision.caltech.edu/visipedia-data/CUB-200/images.tgz"",\n        split_url=""http://www.vision.caltech.edu/visipedia-data/CUB-200/lists.tgz"",\n        annotations_url=""http://www.vision.caltech.edu/visipedia-data/CUB-200/annotations.tgz"",\n    )\n\n  def _info(self):\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            # Images are of varying size\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(num_classes=200),\n            ""label_name"": tfds.features.Text(),\n            ""bbox"": tfds.features.BBoxFeature(),\n            ""segmentation_mask"": tfds.features.Image(shape=(None, None, 1)),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n\n    download_path = dl_manager.download([\n        self._caltech_birds_info.split_url,\n        self._caltech_birds_info.annotations_url,\n        self._caltech_birds_info.images_url,\n    ])\n    extracted_path = dl_manager.download_and_extract([\n        self._caltech_birds_info.split_url,\n        self._caltech_birds_info.annotations_url\n    ])\n\n    train_path = os.path.join(extracted_path[0], ""lists/train.txt"")\n    test_path = os.path.join(extracted_path[0], ""lists/test.txt"")\n\n    with tf.io.gfile.GFile(train_path) as f:\n      train_list = f.read().splitlines()\n\n    with tf.io.gfile.GFile(test_path) as f:\n      test_list = f.read().splitlines()\n\n    attributes = collections.defaultdict(list)\n\n    for root, _, files in tf.io.gfile.walk(extracted_path[1]):\n      # Parsing the .mat files which have the image annotations\n      for fname in files:\n        if fname.endswith("".mat""):\n          path = os.path.join(root, fname)\n          with tf.io.gfile.GFile(path, ""rb"") as f:\n            mat = tfds.core.lazy_imports.scipy.io.loadmat(\n                f, squeeze_me=True, variable_names=[""bbox"", ""seg""])\n          attributes[fname.split(""."")[0]].append(mat[""bbox""])\n          attributes[fname.split(""."")[0]].append(mat[""seg""])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(download_path[2]),\n                ""file_names"": train_list,\n                ""annotations"": attributes,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(download_path[2]),\n                ""file_names"": test_list,\n                ""annotations"": attributes,\n            }),\n    ]\n\n  def _get_bounding_box_values(self, bbox_annotations, img_width, img_height):\n    """"""Function to get normalized bounding box values.\n\n    Args:\n      bbox_annotations: list of bbox values in kitti format\n      img_width: image width\n      img_height: image height\n\n    Returns:\n      Normalized bounding box xmin, ymin, xmax, ymax values\n    """"""\n\n    ymin = bbox_annotations[""top""] / img_height\n    xmin = bbox_annotations[""left""] / img_width\n    ymax = bbox_annotations[""bottom""] / img_height\n    xmax = bbox_annotations[""right""] / img_width\n\n    return ymin, xmin, ymax, xmax\n\n  def _generate_examples(self, archive, file_names, annotations):\n    """"""Generate birds images, labels and bounding box given the directory path.\n\n    Args:\n        archive: object that iterates over the zip\n        file_names : list of train/test image file names obtained from mat file\n        annotations : dict of image file names and bbox attributes, segmentation\n          labels\n\n    Yields:\n        Image path, Image file name, its corresponding label and\n        bounding box values\n    """"""\n\n    for fname, fobj in archive:\n      fname = fname.replace(""\\\\"", ""/"")  # For windows compatibility\n      res = _NAME_RE.match(fname)\n\n      # Checking if filename is present in respective train/test list\n\n      if not res or ""/"".join(fname.split(""/"")[-2:]) not in file_names:\n        continue\n      matches = res.groups()\n      label_name = matches[-2].lower()  # pytype: disable=attribute-error\n      label_key = int(matches[-3]) - 1\n      file_name = matches[-1].split(""."")[0]  # pytype: disable=attribute-error\n      segmentation_mask = annotations[file_name][1]\n\n      height, width = segmentation_mask.shape\n\n      bbox = self._get_bounding_box_values(annotations[file_name][0], width,\n                                           height)\n\n      yield fname, {\n          ""image"":\n              fobj,\n          ""image/filename"":\n              fname,\n          ""label"":\n              label_key,\n          ""label_name"":\n              label_name,\n          ""bbox"":\n              tfds.features.BBox(\n                  ymin=min(bbox[0], 1.0),\n                  xmin=min(bbox[1], 1.0),\n                  ymax=min(bbox[2], 1.0),\n                  xmax=min(bbox[3], 1.0)),\n          ""segmentation_mask"":\n              segmentation_mask[:, :, np.newaxis],\n      }\n\n\nclass CaltechBirds2011(CaltechBirds2010):\n  """"""Caltech Birds 2011 dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  @property\n  def _caltech_birds_info(self):\n    return CaltechBirdsInfo(\n        name=self.name,\n        images_url=""http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz"",\n        split_url=None,\n        annotations_url=""http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/segmentations.tgz""\n    )\n\n  def _info(self):\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            # Images are of varying size\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(num_classes=200),\n            ""label_name"": tfds.features.Text(),\n            ""bbox"": tfds.features.BBoxFeature(),\n            ""segmentation_mask"": tfds.features.Image(shape=(None, None, 1)),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n\n    download_path = dl_manager.download([\n        self._caltech_birds_info.images_url,\n    ])\n\n    extracted_path = dl_manager.download_and_extract([\n        self._caltech_birds_info.images_url,\n        self._caltech_birds_info.annotations_url\n    ])\n\n    image_names_path = os.path.join(extracted_path[0],\n                                    ""CUB_200_2011/images.txt"")\n    split_path = os.path.join(extracted_path[0],\n                              ""CUB_200_2011/train_test_split.txt"")\n    bbox_path = os.path.join(extracted_path[0],\n                             ""CUB_200_2011/bounding_boxes.txt"")\n\n    train_list, test_list = [], []\n    attributes = collections.defaultdict(list)\n\n    with tf.io.gfile.GFile(split_path) as f, tf.io.gfile.GFile(\n        image_names_path) as f1, tf.io.gfile.GFile(bbox_path) as f2:\n      for line, line1, line2 in zip(f, f1, f2):\n        img_idx, val = line.split()\n        idx, img_name = line1.split()\n        res = _NAME_RE.match(img_name)\n        matches = res.groups()\n        attributes[matches[-1].split(""."")[0]].append(line2.split()[1:])  # pytype: disable=attribute-error\n        if img_idx == idx:\n          if int(val) == 1:\n            train_list.append(img_name)\n          else:\n            test_list.append(img_name)\n\n    for root, _, files in tf.io.gfile.walk(extracted_path[1]):\n      for fname in files:\n        if fname.endswith("".png""):\n          with tf.io.gfile.GFile(os.path.join(root, fname), ""rb"") as png_f:\n            mask = tfds.core.lazy_imports.cv2.imdecode(\n                np.fromstring(png_f.read(), dtype=np.uint8), flags=0)\n          attributes[fname.split(""."")[0]].append(mask)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(download_path[0]),\n                ""file_names"": train_list,\n                ""annotations"": attributes,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(download_path[0]),\n                ""file_names"": test_list,\n                ""annotations"": attributes,\n            }),\n    ]\n\n  def _get_bounding_box_values(self, bbox_annotations, img_width, img_height):\n    """"""Gets normalized bounding box values (Conversion to KITTI format).\n\n    Args:\n      bbox_annotations: list of bbox values in kitti format\n      img_width: image width\n      img_height: image height\n\n    Returns:\n      Normalized bounding box xmin, ymin, xmax, ymax values\n    """"""\n    xmin = float(bbox_annotations[0]) / img_width\n    ymin = float(bbox_annotations[1]) / img_height\n    xmax = (float(bbox_annotations[0]) + float(bbox_annotations[2])) / img_width\n    ymax = (float(bbox_annotations[1]) +\n            float(bbox_annotations[3])) / img_height\n\n    return ymin, xmin, ymax, xmax\n\n\nclass CaltechBirdsInfo(\n    collections.namedtuple(\n        ""_CaltechBirdsInfo"",\n        [""name"", ""images_url"", ""split_url"", ""annotations_url""])):\n  """"""Contains the information necessary to generate a Caltech Birds dataset.\n\n    Args:\n        name (str): name of dataset.\n        images_url (str): images URL.\n        split_url (str): train/test split file URL.\n        annotations_url (str): annotation folder URL.\n  """"""\n'"
tensorflow_datasets/image_classification/caltech_birds_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import caltech_birds\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass CaltechBirdsTest(tfds_test.DatasetBuilderTestCase):\n\n  DATASET_CLASS = caltech_birds.CaltechBirds2010\n\n  SPLITS = {  # No. of train and test samples\n      \'train\': 9,\n      \'test\': 6,\n  }\n\n  DL_EXTRACT_RESULT = [\'Lists.tgz\', \'Annotations.tgz\', \'Images.tar.gz\']\n\n\nclass CaltechBirds2011Test(tfds_test.DatasetBuilderTestCase):\n\n  DATASET_CLASS = caltech_birds.CaltechBirds2011\n\n  SPLITS = {  # No. of train and test samples\n      \'train\': 6,\n      \'test\': 4,\n  }\n\n  DL_EXTRACT_RESULT = [\n      \'extracted/TAR_GZ.CUB_200_2011.tar.gz\', \'extracted/segmentations.tgz\'\n  ]\n\n  DL_DOWNLOAD_RESULT = [\n      \'CUB_200_2011.tar.gz\'\n  ]\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/caltech_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Caltech data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import caltech\n\n\nclass Caltech101Test(testing.DatasetBuilderTestCase):\n\n  DATASET_CLASS = caltech.Caltech101\n\n  SPLITS = {\n      \'train\': 3,\n      \'test\': 3,\n  }\n\n  def setUp(self):\n    super(Caltech101Test, self).setUp()\n    caltech._TRAIN_POINTS_PER_CLASS = 1\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cars196.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for Cars196 Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport six.moves.urllib as urllib\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = \'http://imagenet.stanford.edu/internal/car196/\'\n_EXTRA_URL = \'https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\'\n\n_DESCRIPTION = (\n    \'The Cars dataset contains 16,185 images of 196 classes of cars. The data \'\n    \'is split into 8,144 training images and 8,041 testing images, where each \'\n    \'class has been split roughly in a 50-50 split. Classes are typically at \'\n    \'the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 \'\n    \'coupe.\')\n\n_NAMES = [\n    \'AM General Hummer SUV 2000\', \'Acura RL Sedan 2012\', \'Acura TL Sedan 2012\',\n    \'Acura TL Type-S 2008\', \'Acura TSX Sedan 2012\', \'Acura Integra Type R 2001\',\n    \'Acura ZDX Hatchback 2012\', \'Aston Martin V8 Vantage Convertible 2012\',\n    \'Aston Martin V8 Vantage Coupe 2012\',\n    \'Aston Martin Virage Convertible 2012\', \'Aston Martin Virage Coupe 2012\',\n    \'Audi RS 4 Convertible 2008\', \'Audi A5 Coupe 2012\', \'Audi TTS Coupe 2012\',\n    \'Audi R8 Coupe 2012\', \'Audi V8 Sedan 1994\', \'Audi 100 Sedan 1994\',\n    \'Audi 100 Wagon 1994\', \'Audi TT Hatchback 2011\', \'Audi S6 Sedan 2011\',\n    \'Audi S5 Convertible 2012\', \'Audi S5 Coupe 2012\', \'Audi S4 Sedan 2012\',\n    \'Audi S4 Sedan 2007\', \'Audi TT RS Coupe 2012\',\n    \'BMW ActiveHybrid 5 Sedan 2012\', \'BMW 1 Series Convertible 2012\',\n    \'BMW 1 Series Coupe 2012\', \'BMW 3 Series Sedan 2012\',\n    \'BMW 3 Series Wagon 2012\', \'BMW 6 Series Convertible 2007\',\n    \'BMW X5 SUV 2007\', \'BMW X6 SUV 2012\', \'BMW M3 Coupe 2012\',\n    \'BMW M5 Sedan 2010\', \'BMW M6 Convertible 2010\', \'BMW X3 SUV 2012\',\n    \'BMW Z4 Convertible 2012\',\n    \'Bentley Continental Supersports Conv. Convertible 2012\',\n    \'Bentley Arnage Sedan 2009\', \'Bentley Mulsanne Sedan 2011\',\n    \'Bentley Continental GT Coupe 2012\', \'Bentley Continental GT Coupe 2007\',\n    \'Bentley Continental Flying Spur Sedan 2007\',\n    \'Bugatti Veyron 16.4 Convertible 2009\', \'Bugatti Veyron 16.4 Coupe 2009\',\n    \'Buick Regal GS 2012\', \'Buick Rainier SUV 2007\', \'Buick Verano Sedan 2012\',\n    \'Buick Enclave SUV 2012\', \'Cadillac CTS-V Sedan 2012\',\n    \'Cadillac SRX SUV 2012\', \'Cadillac Escalade EXT Crew Cab 2007\',\n    \'Chevrolet Silverado 1500 Hybrid Crew Cab 2012\',\n    \'Chevrolet Corvette Convertible 2012\', \'Chevrolet Corvette ZR1 2012\',\n    \'Chevrolet Corvette Ron Fellows Edition Z06 2007\',\n    \'Chevrolet Traverse SUV 2012\', \'Chevrolet Camaro Convertible 2012\',\n    \'Chevrolet HHR SS 2010\', \'Chevrolet Impala Sedan 2007\',\n    \'Chevrolet Tahoe Hybrid SUV 2012\', \'Chevrolet Sonic Sedan 2012\',\n    \'Chevrolet Express Cargo Van 2007\', \'Chevrolet Avalanche Crew Cab 2012\',\n    \'Chevrolet Cobalt SS 2010\', \'Chevrolet Malibu Hybrid Sedan 2010\',\n    \'Chevrolet TrailBlazer SS 2009\',\n    \'Chevrolet Silverado 2500HD Regular Cab 2012\',\n    \'Chevrolet Silverado 1500 Classic Extended Cab 2007\',\n    \'Chevrolet Express Van 2007\', \'Chevrolet Monte Carlo Coupe 2007\',\n    \'Chevrolet Malibu Sedan 2007\', \'Chevrolet Silverado 1500 Extended Cab 2012\',\n    \'Chevrolet Silverado 1500 Regular Cab 2012\', \'Chrysler Aspen SUV 2009\',\n    \'Chrysler Sebring Convertible 2010\',\n    \'Chrysler Town and Country Minivan 2012\', \'Chrysler 300 SRT-8 2010\',\n    \'Chrysler Crossfire Convertible 2008\',\n    \'Chrysler PT Cruiser Convertible 2008\', \'Daewoo Nubira Wagon 2002\',\n    \'Dodge Caliber Wagon 2012\', \'Dodge Caliber Wagon 2007\',\n    \'Dodge Caravan Minivan 1997\', \'Dodge Ram Pickup 3500 Crew Cab 2010\',\n    \'Dodge Ram Pickup 3500 Quad Cab 2009\', \'Dodge Sprinter Cargo Van 2009\',\n    \'Dodge Journey SUV 2012\', \'Dodge Dakota Crew Cab 2010\',\n    \'Dodge Dakota Club Cab 2007\', \'Dodge Magnum Wagon 2008\',\n    \'Dodge Challenger SRT8 2011\', \'Dodge Durango SUV 2012\',\n    \'Dodge Durango SUV 2007\', \'Dodge Charger Sedan 2012\',\n    \'Dodge Charger SRT-8 2009\', \'Eagle Talon Hatchback 1998\',\n    \'FIAT 500 Abarth 2012\', \'FIAT 500 Convertible 2012\',\n    \'Ferrari FF Coupe 2012\', \'Ferrari California Convertible 2012\',\n    \'Ferrari 458 Italia Convertible 2012\', \'Ferrari 458 Italia Coupe 2012\',\n    \'Fisker Karma Sedan 2012\', \'Ford F-450 Super Duty Crew Cab 2012\',\n    \'Ford Mustang Convertible 2007\', \'Ford Freestar Minivan 2007\',\n    \'Ford Expedition EL SUV 2009\', \'Ford Edge SUV 2012\',\n    \'Ford Ranger SuperCab 2011\', \'Ford GT Coupe 2006\',\n    \'Ford F-150 Regular Cab 2012\', \'Ford F-150 Regular Cab 2007\',\n    \'Ford Focus Sedan 2007\', \'Ford E-Series Wagon Van 2012\',\n    \'Ford Fiesta Sedan 2012\', \'GMC Terrain SUV 2012\', \'GMC Savana Van 2012\',\n    \'GMC Yukon Hybrid SUV 2012\', \'GMC Acadia SUV 2012\',\n    \'GMC Canyon Extended Cab 2012\', \'Geo Metro Convertible 1993\',\n    \'HUMMER H3T Crew Cab 2010\', \'HUMMER H2 SUT Crew Cab 2009\',\n    \'Honda Odyssey Minivan 2012\', \'Honda Odyssey Minivan 2007\',\n    \'Honda Accord Coupe 2012\', \'Honda Accord Sedan 2012\',\n    \'Hyundai Veloster Hatchback 2012\', \'Hyundai Santa Fe SUV 2012\',\n    \'Hyundai Tucson SUV 2012\', \'Hyundai Veracruz SUV 2012\',\n    \'Hyundai Sonata Hybrid Sedan 2012\', \'Hyundai Elantra Sedan 2007\',\n    \'Hyundai Accent Sedan 2012\', \'Hyundai Genesis Sedan 2012\',\n    \'Hyundai Sonata Sedan 2012\', \'Hyundai Elantra Touring Hatchback 2012\',\n    \'Hyundai Azera Sedan 2012\', \'Infiniti G Coupe IPL 2012\',\n    \'Infiniti QX56 SUV 2011\', \'Isuzu Ascender SUV 2008\', \'Jaguar XK XKR 2012\',\n    \'Jeep Patriot SUV 2012\', \'Jeep Wrangler SUV 2012\', \'Jeep Liberty SUV 2012\',\n    \'Jeep Grand Cherokee SUV 2012\', \'Jeep Compass SUV 2012\',\n    \'Lamborghini Reventon Coupe 2008\', \'Lamborghini Aventador Coupe 2012\',\n    \'Lamborghini Gallardo LP 570-4 Superleggera 2012\',\n    \'Lamborghini Diablo Coupe 2001\', \'Land Rover Range Rover SUV 2012\',\n    \'Land Rover LR2 SUV 2012\', \'Lincoln Town Car Sedan 2011\',\n    \'MINI Cooper Roadster Convertible 2012\',\n    \'Maybach Landaulet Convertible 2012\', \'Mazda Tribute SUV 2011\',\n    \'McLaren MP4-12C Coupe 2012\', \'Mercedes-Benz 300-Class Convertible 1993\',\n    \'Mercedes-Benz C-Class Sedan 2012\', \'Mercedes-Benz SL-Class Coupe 2009\',\n    \'Mercedes-Benz E-Class Sedan 2012\', \'Mercedes-Benz S-Class Sedan 2012\',\n    \'Mercedes-Benz Sprinter Van 2012\', \'Mitsubishi Lancer Sedan 2012\',\n    \'Nissan Leaf Hatchback 2012\', \'Nissan NV Passenger Van 2012\',\n    \'Nissan Juke Hatchback 2012\', \'Nissan 240SX Coupe 1998\',\n    \'Plymouth Neon Coupe 1999\', \'Porsche Panamera Sedan 2012\',\n    \'Ram C/V Cargo Van Minivan 2012\',\n    \'Rolls-Royce Phantom Drophead Coupe Convertible 2012\',\n    \'Rolls-Royce Ghost Sedan 2012\', \'Rolls-Royce Phantom Sedan 2012\',\n    \'Scion xD Hatchback 2012\', \'Spyker C8 Convertible 2009\',\n    \'Spyker C8 Coupe 2009\', \'Suzuki Aerio Sedan 2007\',\n    \'Suzuki Kizashi Sedan 2012\', \'Suzuki SX4 Hatchback 2012\',\n    \'Suzuki SX4 Sedan 2012\', \'Tesla Model S Sedan 2012\',\n    \'Toyota Sequoia SUV 2012\', \'Toyota Camry Sedan 2012\',\n    \'Toyota Corolla Sedan 2012\', \'Toyota 4Runner SUV 2012\',\n    \'Volkswagen Golf Hatchback 2012\', \'Volkswagen Golf Hatchback 1991\',\n    \'Volkswagen Beetle Hatchback 2012\', \'Volvo C30 Hatchback 2012\',\n    \'Volvo 240 Sedan 1993\', \'Volvo XC90 SUV 2007\',\n    \'smart fortwo Convertible 2012\',\n]\n\n_CITATION = """"""\\\n\n    @inproceedings{KrauseStarkDengFei-Fei_3DRR2013,\n  title = {3D Object Representations for Fine-Grained Categorization},\n  booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},\n  year = {2013},\n  address = {Sydney, Australia},\n  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}\n  }\n\n""""""\n\n\nclass Cars196(tfds.core.GeneratorBasedBuilder):\n  """"""Car Images dataset.""""""\n\n  VERSION = tfds.core.Version(\'2.0.0\')\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(\'2.1.0\'),\n  ]\n\n  def _info(self):\n    """"""Define the dataset info.""""""\n    features_dict = {\n        \'image\': tfds.features.Image(),\n        \'label\': tfds.features.ClassLabel(names=_NAMES),\n        \'bbox\': tfds.features.BBoxFeature(),\n    }\n    if self.version > \'2.0.0\':\n      features_dict[\'id\'] = tfds.features.Text()\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict(features_dict),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://ai.stanford.edu/~jkrause/cars/car_dataset.html\',\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Define the train and test split.""""""\n    output_files = dl_manager.download_and_extract({\n        \'train\': urllib.parse.urljoin(_URL, \'cars_train.tgz\'),\n        \'test\': urllib.parse.urljoin(_URL, \'cars_test.tgz\'),\n        \'extra\': _EXTRA_URL,\n        \'test_annos\':\n            urllib.parse.urljoin(_URL, \'cars_test_annos_withlabels.mat\'),\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=\'train\',\n            gen_kwargs={\n                \'split_name\':\n                    \'train\',\n                \'data_dir_path\':\n                    os.path.join(output_files[\'train\'], \'cars_train\'),\n                \'data_annotations_path\':\n                    os.path.join(output_files[\'extra\'],\n                                 os.path.join(\'devkit\',\n                                              \'cars_train_annos.mat\')),\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=\'test\',\n            gen_kwargs={\n                \'split_name\':\n                    \'test\',\n                \'data_dir_path\':\n                    os.path.join(output_files[\'test\'], \'cars_test\'),\n                \'data_annotations_path\': output_files[\'test_annos\'],\n            },\n        ),\n    ]\n\n  def _generate_examples(self, split_name, data_dir_path,\n                         data_annotations_path):\n    """"""Generate training and testing samples.""""""\n\n    image_dict = self.returnImageDict(data_dir_path)\n    bbox_dict = self.returnBbox(data_annotations_path, image_dict)\n    with tf.io.gfile.GFile(data_annotations_path, \'rb\') as f:\n      mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n    for example in mat[\'annotations\'][0]:\n      image_name = example[-1].item().split(\'.\')[0]\n      label = _NAMES[example[4].item() - 1]\n      image = image_dict[image_name]\n      bbox = bbox_dict[image_name]\n      features = {\n          \'label\': label,\n          \'image\': image,\n          \'bbox\': bbox,\n      }\n      if self.version > \'2.0.0\':\n        features[\'id\'] = image_name\n      yield image_name, features\n\n  def returnImageDict(self, path):\n    return {\n        filename.split(\'.\')[0]: os.path.join(path, filename)\n        for filename in tf.io.gfile.listdir(path)\n    }\n\n  def returnBbox(self, filename, image_dict):\n    bbox_dict = {}\n    with tf.io.gfile.GFile(filename, \'rb\') as f:\n      data = tfds.core.lazy_imports.scipy.io.loadmat(f)\n    for example in data[\'annotations\'][0]:\n      image_name = example[-1].item().split(\'.\')[0]\n      ymin = float(example[1].item())\n      xmin = float(example[0].item())\n      ymax = float(example[3].item())\n      xmax = float(example[2].item())\n      with tf.io.gfile.GFile(image_dict[image_name], \'rb\') as fp:\n        img = tfds.core.lazy_imports.PIL_Image.open(fp)\n        width, height = img.size\n      bbox_dict[image_name] = tfds.features.BBox(ymin / height, xmin / width,\n                                                 ymax / height, xmax / width)\n    return bbox_dict\n'"
tensorflow_datasets/image_classification/cars196_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets.image_classification import cars196\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass Cars196Test(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = cars196.Cars196\n  SPLITS = {\'train\': 2, \'test\': 2}\n\n  DL_EXTRACT_RESULT = {\n      \'train\': \'train\',\n      \'test\': \'test\',\n      \'extra\': \'extra\',\n      \'test_annos\': \'cars_test_annos_withlabels.mat\'\n  }\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/cassava.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Cassava leaf dataset with images of health and diseased leaves.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@misc{mwebaze2019icassava,\n    title={iCassava 2019Fine-Grained Visual Categorization Challenge},\n    author={Ernest Mwebaze and Timnit Gebru and Andrea Frome and Solomon Nsumba and Jeremy Tusubira},\n    year={2019},\n    eprint={1908.02900},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nCassava consists of leaf images for the cassava plant depicting healthy and\nfour (4) disease conditions; Cassava Mosaic Disease (CMD), Cassava Bacterial\nBlight (CBB), Cassava Greem Mite (CGM) and Cassava Brown Streak Disease (CBSD).\nDataset consists of a total of 9430 labelled images.\nThe 9430 labelled images are split into a training set (5656), a test set(1885)\nand a validation set (1889). The number of images per class are unbalanced with\nthe two disease classes CMD and CBSD having 72% of the images.\n""""""\n\n_BASE_URL = ""https://storage.googleapis.com/emcassavadata/cassavaleafdata.zip""\n_LABELS = [""cbb"", ""cbsd"", ""cgm"", ""cmd"", ""healthy""]\n\n\nclass Cassava(tfds.core.GeneratorBasedBuilder):\n  """"""Cassava leaf image dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),  # test-cbb-0.jpg\n            ""label"": tfds.features.ClassLabel(names=_LABELS)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://www.kaggle.com/c/cassava-disease/overview"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.download_and_extract(_BASE_URL)\n    train_path = os.path.join(path, ""cassavaleafdata/train"")\n    test_path = os.path.join(path, ""cassavaleafdata/test"")\n    validation_path = os.path.join(path, ""cassavaleafdata/validation"")\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""datapath"": train_path},\n        ),\n\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""datapath"": test_path},\n        ),\n\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""datapath"": validation_path},\n        ),\n    ]\n\n  def _generate_examples(self, datapath):\n    """"""Yields examples of cassava leaf images and labels.""""""\n    for label in tf.io.gfile.listdir(datapath):\n      for fpath in tf.io.gfile.glob(os.path.join(datapath, label, ""*.jpg"")):\n        fname = os.path.basename(fpath)\n        record = {\n            ""image"": fpath,\n            ""image/filename"": fname,\n            ""label"": label,\n        }\n        yield fname, record\n\n'"
tensorflow_datasets/image_classification/cassava_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for cassava leaf dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cassava\n\n\nclass CassavaTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cassava.Cassava\n  SPLITS = {\n      ""train"": 5,\n      ""test"": 5,\n      ""validation"": 5,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/image_classification/cats_vs_dogs.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Cats vs Dogs dataset.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@Inproceedings (Conference){asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization,\nauthor = {Elson, Jeremy and Douceur, John (JD) and Howell, Jon and Saul, Jared},\ntitle = {Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization},\nbooktitle = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\nyear = {2007},\nmonth = {October},\npublisher = {Association for Computing Machinery, Inc.},\nurl = {https://www.microsoft.com/en-us/research/publication/asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization/},\nedition = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n}\n""""""\n\n_URL = (""https://download.microsoft.com/download/3/E/1/3E1C3F21-""\n        ""ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"")\n_NUM_CORRUPT_IMAGES = 1738\n_DESCRIPTION = ((""A large set of images of cats and dogs.""\n                 ""There are %d corrupted images that are dropped."")\n                % _NUM_CORRUPT_IMAGES)\n\n_NAME_RE = re.compile(r""^PetImages[\\\\/](Cat|Dog)[\\\\/]\\d+\\.jpg$"")\n\n\nclass CatsVsDogs(tfds.core.GeneratorBasedBuilder):\n  """"""Cats vs Dogs.""""""\n\n  VERSION = tfds.core.Version(\n      ""4.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),  # eg \'PetImages/Dog/0.jpg\'\n            ""label"": tfds.features.ClassLabel(names=[""cat"", ""dog""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=\n        ""https://www.microsoft.com/en-us/download/details.aspx?id=54765"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(path),\n            }),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Generate Cats vs Dogs images and labels given a directory path.""""""\n    num_skipped = 0\n    for fname, fobj in archive:\n      res = _NAME_RE.match(fname)\n      if not res:  # README file, ...\n        continue\n      label = res.group(1).lower()\n      if tf.compat.as_bytes(""JFIF"") not in fobj.peek(10):\n        num_skipped += 1\n        continue\n      record = {\n          ""image"": fobj,\n          ""image/filename"": fname,\n          ""label"": label,\n      }\n      yield fname, record\n\n    if num_skipped != _NUM_CORRUPT_IMAGES:\n      raise ValueError(""Expected %d corrupt images, but found %d"" % (\n          _NUM_CORRUPT_IMAGES, num_skipped))\n    logging.warning(""%d images were corrupted and were skipped"", num_skipped)\n'"
tensorflow_datasets/image_classification/cats_vs_dogs_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cats_vs_dogs data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cats_vs_dogs\n\ncats_vs_dogs._NUM_CORRUPT_IMAGES = 0  # pylint: disable=protected-access\n\n\nclass CatsVsDogsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cats_vs_dogs.CatsVsDogs\n\n  SPLITS = {\n      \'train\': 4\n  }\n  DL_EXTRACT_RESULT = \'cats_vs_dogs.zip\'\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cbis_ddsm.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CBIS-DDSM mammography dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport re\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = """"""\\\nThe CBIS-DDSM (Curated Breast Imaging Subset of DDSM) is an updated and\nstandardized version of the Digital Database for Screening Mammography (DDSM).\nThe DDSM is a database of 2,620 scanned film mammography studies.\nIt contains normal, benign, and malignant cases with verified pathology\ninformation.\n\nThe default config is made of patches extracted from the original mammograms,\nfollowing the description from http://arxiv.org/abs/1708.09427, in order to\nframe the task to solve in a traditional image classification setting.\n\nBecause special software and libraries are needed to download and read the\nimages contained in the dataset, TFDS assumes that the user has downloaded the\noriginal DCIM files and converted them to PNG.\n\nThe following commands (or equivalent) should be used to generate the PNG files,\nin order to guarantee reproducible results:\n\n```\n  find $DATASET_DCIM_DIR -name \'*.dcm\' | \\\\\n  xargs -n1 -P8 -I{} bash -c \'f={}; dcmj2pnm $f | convert - ${f/.dcm/.png}\'\n```\n""""""\n\n_CITATION = """"""\\\n@misc{CBIS_DDSM_Citation,\n  doi = {10.7937/k9/tcia.2016.7o02s9cy},\n  url = {https://wiki.cancerimagingarchive.net/x/lZNXAQ},\n  author = {Sawyer-Lee,  Rebecca and Gimenez,  Francisco and Hoogi,  Assaf and Rubin,  Daniel},\n  title = {Curated Breast Imaging Subset of DDSM},\n  publisher = {The Cancer Imaging Archive},\n  year = {2016},\n}\n@article{TCIA_Citation,\n  author = {\n    K. Clark and B. Vendt and K. Smith and J. Freymann and J. Kirby and\n    P. Koppel and S. Moore and S. Phillips and D. Maffitt and M. Pringle and\n    L. Tarbox and F. Prior\n  },\n  title = {{The Cancer Imaging Archive (TCIA): Maintaining and Operating a\n  Public Information Repository}},\n  journal = {Journal of Digital Imaging},\n  volume = {26},\n  month = {December},\n  year = {2013},\n  pages = {1045-1057},\n}\n@article{DBLP:journals/corr/abs-1708-09427,\n  author    = {Li Shen},\n  title     = {End-to-end Training for Whole Image Breast Cancer Diagnosis using\n               An All Convolutional Design},\n  journal   = {CoRR},\n  volume    = {abs/1708.09427},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.09427},\n  archivePrefix = {arXiv},\n  eprint    = {1708.09427},\n  timestamp = {Mon, 13 Aug 2018 16:48:35 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-09427},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_CALC_TEST_CSV_URL = \'https://wiki.cancerimagingarchive.net/download/attachments/22516629/calc_case_description_test_set.csv?version=1&modificationDate=1506796343686&api=v2\'\n_CALC_TRAIN_CSV_URL = \'https://wiki.cancerimagingarchive.net/download/attachments/22516629/calc_case_description_train_set.csv?version=1&modificationDate=1506796349666&api=v2\'\n_MASS_TEST_CSV_URL = \'https://wiki.cancerimagingarchive.net/download/attachments/22516629/mass_case_description_test_set.csv?version=1&modificationDate=1506796343175&api=v2\'\n_MASS_TRAIN_CSV_URL = \'https://wiki.cancerimagingarchive.net/download/attachments/22516629/mass_case_description_train_set.csv?version=1&modificationDate=1506796355038&api=v2\'\n\n_IMAGE_VIEW_LABELS = (\n    \'CC\',\n    \'MLO\',\n)\n_BREAST_LABELS = (\n    \'LEFT\',\n    \'RIGHT\',\n)\n_BREAST_DENSITY_NUM_CLASSES = 4  # Original range: [1, 4]\n_PATHOLOGY_LABELS = (\n    \'BENIGN\',\n    \'BENIGN_WITHOUT_CALLBACK\',\n    \'MALIGNANT\',\n)\n_ASSESSMENT_NUM_CLASSES = 6  # Original range: [0, 5]\n_SUBTELTY_NUM_CLASSES = 6  # Original range: [0, 5]\n_DCIM_REGEX = re.compile(\n    r\'^.*/(?P<study>1.3.6.1.4.1.9590.100.1.2.[0-9.]+)/(?P<series>1.3.6.1.4.1.9590.100.1.2.[0-9.]+)/(?P<instance>.+).dcm$\'\n)\n\n\nclass CuratedBreastImagingDDSMConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CuratedBreastImagingDDSM.""""""\n\n  def __init__(self, image_size=None, patch_size=None, **kwargs):\n    kwargs[\'version\'] = tfds.core.Version(\n        \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n    super(CuratedBreastImagingDDSMConfig, self).__init__(**kwargs)\n    self.image_size = image_size\n    self.patch_size = patch_size\n\n\nclass CuratedBreastImagingDDSM(tfds.core.GeneratorBasedBuilder):\n  """"""Curated Breast Imaging Subset of DDSM.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  You can download the images from\n  https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\n  Please look at the source file (cbis_ddsm.py) to see the instructions\n  on how to convert them into png (using dcmj2pnm).\n  """"""\n\n  BUILDER_CONFIGS = [\n      CuratedBreastImagingDDSMConfig(\n          name=\'patches\',\n          description=(\'Patches containing both calsification and mass cases, \'\n                       \'plus pathces with no abnormalities. Designed as a \'\n                       \'traditional 5-class classification task.\'),\n          image_size=(1152, 896),  # Note: (height, width).\n          patch_size=(224, 224)),\n      CuratedBreastImagingDDSMConfig(\n          name=\'original-calc\',\n          description=(\'Original images of the calcification cases compressed \'\n                       \'in lossless PNG.\')),\n      CuratedBreastImagingDDSMConfig(\n          name=\'original-mass\',\n          description=(\'Original images of the mass cases compressed in \'\n                       \'lossless PNG.\')),\n  ]\n\n  def _info(self):\n    features_fn_map = {\n        \'original-calc\': self._get_features_original_calc,\n        \'original-mass\': self._get_features_original_mass,\n        \'patches\': self._get_features_patches\n    }\n    if self.builder_config.name not in features_fn_map:\n      raise ValueError(\'Builder config named {} not supported!\'.format(\n          self.builder_config.name))\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=features_fn_map[self.builder_config.name](),\n        homepage=\n        \'https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\',\n        citation=_CITATION)\n\n  def _get_features_original_base(self):\n    return {\n        \'id\': tfds.features.Text(),\n        \'breast\': tfds.features.ClassLabel(names=_BREAST_LABELS),\n        \'image\': tfds.features.Image(shape=(None, None, 1)),\n        \'view\': tfds.features.ClassLabel(names=_IMAGE_VIEW_LABELS),\n        \'patient\': tfds.features.Text(),\n        \'abnormalities\': {\n            \'id\': tfds.features.Tensor(shape=(), dtype=tf.int32),\n            \'mask\': tfds.features.Image(shape=(None, None, 1)),\n            \'assessment\':\n                tfds.features.ClassLabel(num_classes=_ASSESSMENT_NUM_CLASSES),\n            \'pathology\': tfds.features.ClassLabel(names=_PATHOLOGY_LABELS),\n            \'subtlety\':\n                tfds.features.ClassLabel(num_classes=_SUBTELTY_NUM_CLASSES),\n            # TODO(jpuigcerver): Include original crops when TFDS allows it.\n            # The problem seems to be in the compute statistics steps, since\n            # a given example may have crops of different sizes and this is\n            # not handled properly.\n            # \'crop\': tfds.features.Image(shape=(None, None, 1)),\n        }\n    }\n\n  def _get_features_original_calc(self):\n    features = self._get_features_original_base()\n    features[\'abnormalities\'].update({\n        \'calc_type\':\n            tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        \'image_classification\', \'cbis_ddsm_calc_types.txt\'))),\n        \'calc_distribution\':\n            tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        \'image_classification\',\n                        \'cbis_ddsm_calc_distributions.txt\'))),\n    })\n    features[\'abnormalities\'] = tfds.features.Sequence(\n        tfds.features.FeaturesDict(features[\'abnormalities\']))\n    return tfds.features.FeaturesDict(features)\n\n  def _get_features_original_mass(self):\n    features = self._get_features_original_base()\n    features[\'abnormalities\'].update({\n        \'mass_shape\':\n            tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        \'image_classification\', \'cbis_ddsm_mass_shapes.txt\'))),\n        \'mass_margins\':\n            tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        \'image_classification\', \'cbis_ddsm_mass_margins.txt\'))),\n    })\n    features[\'abnormalities\'] = tfds.features.Sequence(\n        tfds.features.FeaturesDict(features[\'abnormalities\']))\n    return tfds.features.FeaturesDict(features)\n\n  def _get_features_patches(self):\n    return tfds.features.FeaturesDict({\n        \'id\': tfds.features.Text(),\n        \'image\':\n            tfds.features.Image(shape=(None, None, 1), encoding_format=\'jpeg\'),\n        \'label\':\n            tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        \'image_classification\', \'cbis_ddsm_patch_labels.txt\'))),\n    })\n\n  def _split_generators(self, dl_manager):\n    if self.builder_config.name in [\'original-calc\', \'original-mass\']:\n      return self._split_generators_original(dl_manager)\n    elif self.builder_config.name == \'patches\':\n      return self._split_generators_patches(dl_manager)\n    else:\n      raise ValueError(\'Builder config named {} not supported!\'.format(\n          self.builder_config.name))\n\n  def _split_generators_original(self, dl_manager):\n    if self.builder_config.name == \'original-calc\':\n      test_url = _CALC_TEST_CSV_URL\n      train_url = _CALC_TRAIN_CSV_URL\n    elif self.builder_config.name == \'original-mass\':\n      test_url = _MASS_TEST_CSV_URL\n      train_url = _MASS_TRAIN_CSV_URL\n    else:\n      raise ValueError(\'Builder config named {} not supported!\'.format(\n          self.builder_config.name))\n\n    resources = {\'test\': test_url, \'train\': train_url}\n    resource_paths = dl_manager.download_and_extract(resources)\n    patients_data = _load_csv_files(dl_manager.manual_dir, resource_paths)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'generate_fn\': self._generate_examples_original,\n                \'patients_data\': patients_data,\n                \'yield_from_train_csv\': True,  # Yield train examples.\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'generate_fn\': self._generate_examples_original,\n                \'patients_data\': patients_data,\n                \'yield_from_train_csv\': False,  # Yield test examples.\n            },\n        ),\n    ]\n\n  def _split_generators_patches(self, dl_manager):\n    resources_urls = {\n        \'calc-test\': _CALC_TEST_CSV_URL,\n        \'calc-train\': _CALC_TRAIN_CSV_URL,\n        \'mass-test\': _MASS_TEST_CSV_URL,\n        \'mass-train\': _MASS_TRAIN_CSV_URL\n    }\n    resources = {\n        key: tfds.download.Resource(\n            url=url, extract_method=tfds.download.ExtractMethod.NO_EXTRACT)\n        for key, url in resources_urls.items()\n    }\n    resource_paths = dl_manager.download_and_extract(resources)\n    patients_data = _load_csv_files(dl_manager.manual_dir, resource_paths)\n\n    # Statistics about the resulting splits.\n    # Whole dataset:\n    #   Num patients: 1566, of which have malignant abnormalities: 48.0%\n    #   Num mamographies: 3103, of which have malignant abnormalities: 44.3%\n    #   Num abnormalities: 3568, of which are malignant: 40.8%\n    # Test split:\n    #   Num patients: 234, of which have malignant abnormalities: 47.0%\n    #   Num mamographies: 450, of which have malignant abnormalities: 44.2%\n    #   Num abnormalities: 538, of which are malignant: 39.8%\n    # Train split:\n    #   Num patients: 1197, of which have malignant abnormalities: 48.0%\n    #   Num mamographies: 2386, of which have malignant abnormalities: 44.1%\n    #   Num abnormalities: 2722, of which are malignant: 41.0%\n    # Validation split:\n    #   Num patients: 135, of which have malignant abnormalities: 49.6%\n    #   Num mamographies: 267, of which have malignant abnormalities: 46.4%\n    #   Num abnormalities: 308, of which are malignant: 41.2%\n    patients_test, patients_train, patients_valid = _split_patients(\n        patients_data)\n    patients_data_test = _select_patients_data(patients_data, patients_test)\n    patients_data_train = _select_patients_data(patients_data, patients_train)\n    patients_data_valid = _select_patients_data(patients_data, patients_valid)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'generate_fn\': self._generate_examples_patches,\n                \'patients_data\': patients_data_train,\n                \'image_size\': self.builder_config.image_size,\n                \'patch_size\': self.builder_config.patch_size,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'generate_fn\': self._generate_examples_patches,\n                \'patients_data\': patients_data_test,\n                \'image_size\': self.builder_config.image_size,\n                \'patch_size\': self.builder_config.patch_size,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'generate_fn\': self._generate_examples_patches,\n                \'patients_data\': patients_data_valid,\n                \'image_size\': self.builder_config.image_size,\n                \'patch_size\': self.builder_config.patch_size,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, generate_fn, **kwargs):\n    """"""Yields examples.""""""\n    return generate_fn(**kwargs)\n\n  def _generate_examples_original(self, patients_data, yield_from_train_csv):\n\n    def _include_example_in_split(example):\n      if yield_from_train_csv:\n        return example[\'csv_key\'] == \'train\'\n      else:\n        return example[\'csv_key\'] == \'test\'\n\n    for _, patient_examples in sorted(patients_data.items()):\n      for _, example in sorted(patient_examples.items()):\n        if _include_example_in_split(example):\n          record = {\n              \'id\': example[\'id\'],\n              \'patient\': example[\'patient\'],\n              \'image\': example[\'image\'],\n              \'view\': example[\'view\'],\n              \'breast\': example[\'breast\'],\n              # pylint: disable=g-complex-comprehension\n              \'abnormalities\': [{\n                  k: v for k, v in abnormality.items() if k not in [\'type\']\n              } for abnormality in example[\'abnormalities\']],\n              # pylint: enable=g-complex-comprehension\n          }\n          yield example[\'id\'], record\n\n  def _generate_examples_patches(self,\n                                 patients_data,\n                                 image_size=(1152, 896),\n                                 patch_size=(224, 224),\n                                 num_positive_patches_per_abnormality=10,\n                                 num_background_patches_per_image=10):\n    # Set random seed so that we always get the same patches in each split.\n    np.random.seed(0x12345 + len(patients_data))\n\n    for _, patient_examples in sorted(patients_data.items()):\n      for _, example in sorted(patient_examples.items()):\n        # Read the mammography image.\n        image = _read_image(example[\'image\'], image_size=image_size)\n        abnormalities_masks = [\n            _read_image(abnormality[\'mask\'], image_size=image.shape)\n            for abnormality in example[\'abnormalities\']\n        ]\n        abnormalities_areas = [np.sum(mask > 0) for mask in abnormalities_masks]\n        # Sample positive (abnormal) patches from the given mammography.\n        for abnormality, abnormality_mask, abnormality_area in zip(\n            example[\'abnormalities\'], abnormalities_masks, abnormalities_areas):\n          # Determine label for the given abnormality.\n          if abnormality[\'pathology\'].startswith(\'MALIGNANT\'):\n            benign_or_malignant = \'MALIGNANT\'\n          else:\n            benign_or_malignant = \'BENING\'\n          if abnormality[\'type\'] == \'calc\':\n            label = benign_or_malignant + \'_CALCIFICATION\'\n          elif abnormality[\'type\'] == \'mass\':\n            label = benign_or_malignant + \'_MASS\'\n          else:\n            raise ValueError(\'Unknown abnormality type: %r\' %\n                             abnormality[\'type\'])\n          # Sample positive patches from the given abnormality.\n          for k, patch in enumerate(\n              _sample_positive_patches(image, abnormality[\'mask\'],\n                                       abnormality_mask, abnormality_area,\n                                       patch_size,\n                                       num_positive_patches_per_abnormality)):\n            patch_id = (\'%s/abnorm_%s/patch_%d\' %\n                        (example[\'id\'], abnormality[\'id\'], k))\n            record = {\n                \'id\': patch_id,\n                # Note: TFDS needs the shape to be (?, ?, 1).\n                \'image\': np.expand_dims(patch, axis=-1),\n                \'label\': label,\n            }\n            yield patch_id, record\n\n        # Sample background patches from the given mammography.\n        for k, patch in enumerate(\n            _sample_negative_patches(image, example[\'image\'],\n                                     abnormalities_masks, abnormalities_areas,\n                                     patch_size,\n                                     num_background_patches_per_image)):\n          id_ = \'%s/background_%d\' % (example[\'id\'], k)\n          record = {\n              \'id\': id_,\n              # Note: TFDS needs the shape to be (?, ?, 1).\n              \'image\': np.expand_dims(patch, axis=-1),\n              \'label\': \'BACKGROUND\',\n          }\n          yield id_, record\n\n\ndef _load_csv_files(manual_dir, dictionary_of_csv_files):\n  """"""Load the ground-truth data from the given dictionary of CSV files.\n\n  Args:\n    manual_dir: Path of the directory containing the images.\n    dictionary_of_csv_files: Dictionary containing the key and filepath of each\n      CSV file to load.\n\n  Returns:\n    A dictionary containing the ground-truth loaded from the CSV files.\n  """"""\n  # Data maps patients -> examples -> list of abnormalities\n  data = {}\n  for csv_key, csv_path in sorted(dictionary_of_csv_files.items()):\n    with tf.io.gfile.GFile(csv_path, \'r\') as f:\n      csv_reader = csv.DictReader(f)\n      for i, row in enumerate(csv_reader, 2):\n        row = {k: v.strip() for k, v in row.items()}  # Strip all cells.\n        # Construct example ID from the study and series IDs.\n        example_id = _DCIM_REGEX.sub(r\'\\g<study>/\\g<series>\',\n                                     row[\'image file path\'])\n        # Get path to the\n        for key in [\n            \'image file path\', \'ROI mask file path\', \'cropped image file path\'\n        ]:\n          row[key] = row[key].replace(\'.dcm\', \'.png\')\n          row[key] = os.path.join(manual_dir, *row[key].split(\'/\'))\n          if not tf.io.gfile.exists(row[key]):\n            raise ValueError(\'Error processing line %d from csv file %s: \'\n                             \'Image %r does not exist!\' %\n                             (i, csv_path, row[key]))\n\n        mask_file_path = row[\'ROI mask file path\']\n        crop_file_path = row[\'cropped image file path\']\n        full_image = _read_image(row[\'image file path\'])\n        mask_image = _read_image(mask_file_path)\n        crop_image = _read_image(crop_file_path)\n        if full_image.shape == crop_image.shape:\n          # TODO(jpuigcerver): THIS ASSUMES THAT THE CROP/MASK COLUMNS ARE JUST\n          # REVERSED. I\'ve checked that this is the case for a couple of rows,\n          # but this issue happens a lot across all CSV files. Contact the\n          # owners of the dataset to ask about this problem.\n          mask_file_path, crop_file_path = crop_file_path, mask_file_path\n        elif full_image.shape != mask_image.shape:\n          # TODO(jpuigcerver): Contact the owners of the dataset to ask about\n          # this problem.\n          logging.error(\n              \'Error processing line %d from csv file %s: No suitable mask for \'\n              \'the given image (expected size: %r, candidate sizes: %r). \'\n              \'This abnormality will NOT be included in the dataset.\', i,\n              csv_path, full_image.shape, [mask_image.shape, crop_image.shape])\n          continue\n\n        abnormality = {\n            \'id\': int(row[\'abnormality id\']),\n            \'mask\': mask_file_path,\n            \'assessment\': row[\'assessment\'],\n            \'pathology\': row[\'pathology\'],\n            \'subtlety\': row[\'subtlety\'],\n        }\n        if \'calc type\' in row and \'calc distribution\' in row:\n          abnormality[\'type\'] = \'calc\'\n          abnormality[\'calc_type\'] = row[\'calc type\']\n          abnormality[\'calc_distribution\'] = row[\'calc distribution\']\n        elif \'mass shape\' in row and \'mass margins\' in row:\n          abnormality[\'type\'] = \'mass\'\n          abnormality[\'mass_shape\'] = row[\'mass shape\']\n          abnormality[\'mass_margins\'] = row[\'mass margins\']\n        else:\n          raise ValueError(\'CSV file is missing required columns.\')\n\n        example = {\n            \'id\': example_id,\n            \'breast\': row[\'left or right breast\'],\n            \'patient\': row[\'patient_id\'],\n            \'image\': row[\'image file path\'],\n            \'view\': row[\'image view\'],\n            \'abnormalities\': [abnormality],\n            # Note: Useful to know whether the example is from train or test.\n            \'csv_key\': csv_key,\n        }\n        _append_example_to_data(data, example)\n\n  return data\n\n\ndef _append_example_to_data(data, example):\n  """"""Append the given example to the data dictionary.""""""\n  example_id = example[\'id\']\n  patient_id = example[\'patient\']\n  if patient_id in data:\n    if example_id in data[example[\'patient\']]:\n      assert example_id == data[patient_id][example_id][\'id\']\n      assert patient_id == data[patient_id][example_id][\'patient\']\n      assert example[\'breast\'] == data[patient_id][example_id][\'breast\']\n      assert example[\'image\'] == data[patient_id][example_id][\'image\']\n      assert example[\'view\'] == data[patient_id][example_id][\'view\']\n      data[patient_id][example_id][\'abnormalities\'].extend(\n          example[\'abnormalities\'])\n    else:\n      data[example[\'patient\']][example[\'id\']] = example\n  else:\n    data[example[\'patient\']] = {example[\'id\']: example}\n\n\ndef _split_patients(data,\n                    test_fraction=0.15,\n                    train_fraction=0.765,\n                    valid_fraction=0.085):\n  """"""Split the patients in the data dictionary into test, train and valid sets.""""""\n  assert test_fraction > 0 and train_fraction > 0 and valid_fraction > 0\n  assert np.abs(test_fraction + train_fraction + valid_fraction - 1.0) < 1e-9\n  all_patient_ids = sorted(list(data.keys()))\n  np.random.seed(seed=0x12345)  # To make sure we always get the same splits.\n  np.random.shuffle(all_patient_ids)\n  cutoff_test = int(test_fraction * len(all_patient_ids))\n  patients_test = all_patient_ids[:cutoff_test]\n  cutoff_train = cutoff_test + int(train_fraction * len(all_patient_ids))\n  patients_train = all_patient_ids[cutoff_test:cutoff_train]\n  patients_valid = all_patient_ids[cutoff_train:]\n  return set(patients_test), set(patients_train), set(patients_valid)\n\n\ndef _select_patients_data(data, patient_ids):\n  return {k: v for k, v in data.items() if k in patient_ids}\n\n\ndef _read_image(filepath, image_size=None):\n  """"""Read an image and optionally resize it (size must be: height, width).""""""\n  cv2 = tfds.core.lazy_imports.cv2\n  with tf.io.gfile.GFile(filepath, \'rb\') as f:\n    image = cv2.imdecode(\n        np.fromstring(f.read(), dtype=np.uint8), flags=cv2.IMREAD_GRAYSCALE)\n    if image_size:\n      # Note: cv2.resize actually expects (width, size).\n      image = cv2.resize(image, (image_size[1], image_size[0]))\n      assert image.shape == image_size\n    return image\n\n\ndef _get_breast_mask(image, min_breast_color_threshold=0.05):\n  """"""Get the binary mask of the breast region of the image.""""""\n  cv2 = tfds.core.lazy_imports.cv2\n  threshold = int(image.max() * min_breast_color_threshold)\n  _, image_binary = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n  _, contours, _ = cv2.findContours(image_binary, cv2.RETR_LIST,\n                                    cv2.CHAIN_APPROX_SIMPLE)\n  contours_areas = [cv2.contourArea(cont) for cont in contours]\n  biggest_contour_idx = np.argmax(contours_areas)\n  return cv2.drawContours(\n      np.zeros_like(image_binary), contours, biggest_contour_idx, 255,\n      cv2.FILLED)\n\n\ndef _get_roi_from_mask(mask):\n  cv2 = tfds.core.lazy_imports.cv2\n  _, contours, _ = cv2.findContours(mask, cv2.RETR_LIST,\n                                    cv2.CHAIN_APPROX_SIMPLE)\n  contours_areas = [cv2.contourArea(cont) for cont in contours]\n  biggest_contour_idx = np.argmax(contours_areas)\n  return contours[biggest_contour_idx]\n\n\ndef _patch_overlaps_any_abnormality_above_threshold(y, x, patch_size,\n                                                    abnormalities_masks,\n                                                    abnormalities_areas,\n                                                    min_overlap_threshold):\n  """"""Return True if the given patch overlaps significantly with any abnormality.\n\n  Given a patch and a single abnormality, the overlap between the two is\n  significant if, and only if, the relative area of the intersection of the two\n  w.r.t. the area of the patch is above `min_overlap_threshold` OR the\n  area of the intersection w.r.t. the total abnormality area is above\n  `min_overlap_threshold`.\n\n  Args:\n    y: Top-most coordinate of the patch.\n    x: Left-most coordinate of the patch.\n    patch_size: Tuple with (height, width) of the patch.\n    abnormalities_masks: List with the binary mask of each abnormality.\n    abnormalities_areas: List with the total area of each abnormality.\n    min_overlap_threshold:\n\n  Returns:\n    Returns True if the above condition is met for any of the given\n    abnormalities, or False otherwise.\n  """"""\n  patch_area = patch_size[0] * patch_size[1]\n  for abnorm_mask, abnorm_area in zip(abnormalities_masks, abnormalities_areas):\n    abnorm_in_patch_area = np.sum(\n        abnorm_mask[y:(y + patch_size[0]), x:(x + patch_size[1])] > 0)\n    abnorm_in_patch_wrt_patch = abnorm_in_patch_area / patch_area\n    abnorm_in_patch_wrt_abnorm = abnorm_in_patch_area / abnorm_area\n    if (abnorm_in_patch_wrt_patch > min_overlap_threshold or\n        abnorm_in_patch_wrt_abnorm > min_overlap_threshold):\n      return True\n  return False\n\n\ndef _sample_positive_patches(image,\n                             abnormality_filepath,\n                             abnormality_mask,\n                             abnormality_area,\n                             patch_size,\n                             number_of_patches=10,\n                             min_overlap_threshold=0.90,\n                             max_number_of_trials_per_threshold=100):\n  """"""Sample random patches from the image overlapping with the given abnormality.\n\n  The abnormal area of the patch with respect to either (a) the total area of\n  the patch, or (b) the total area of the abnormality, must be at least\n  `min_overlap_threshold` (i.e. 90% by default).\n\n  After `max_number_of_trials_per_threshold` samples, if not enough patches\n  meeting this requirement have been generated, the `min_overlap_threshold` is\n  reduced by 5%. This procedure is repeated until min_overlap_threshold < 0.1\n  (which should not happen ever, if the dataset is correct).\n\n  Args:\n    image: Image to patch from.\n    abnormality_filepath: Only used for logging.\n    abnormality_mask: Binary mask of the abnormality in the image.\n    abnormality_area: Precomputed area of the abnormality.\n    patch_size: Size of the patch to extract.\n    number_of_patches: Number of patches to sample around the abnormality ROI.\n    min_overlap_threshold: Minimum relative area of the patch overlapping with\n      the abnormality.\n    max_number_of_trials_per_threshold: Maximum number of random samples to try\n      before reducing the `min_overlap_threshold` by 5%.\n\n  Yields:\n    The patch cropped from the input image.\n  """"""\n  cv2 = tfds.core.lazy_imports.cv2\n\n  # The paper trying to be reproduced states that 90% of the are of each\n  # positive patch should correspond to abnormal tissue. Thus if the total area\n  # of abnormality is smaller than 0.9 * patch_area, we are certain that no\n  # patch can meet this requirement. This happens indeed quite often.\n  #\n  # However, in a piece of code release by the authors of the paper\n  # (https://github.com/yuyuyu123456/CBIS-DDSM/blob/bf3abc6ac2890b9b51eb5125e00056e39295fa44/ddsm_train/sample_patches_combined.py#L26)\n  # the authors accept a patch if the total area of abnormality in the patch is\n  # greater than 75% OR if 75% of the total abnormal area is in the patch.\n  # In addition, they reduce the overlapping threholds every 1000 trials to\n  # handle some corner casses.\n\n  abnormality_roi = _get_roi_from_mask(abnormality_mask)\n  abnorm_x, abnorm_y, abnorm_w, abnorm_h = cv2.boundingRect(abnormality_roi)\n\n  number_of_yielded_patches = 0\n  while min_overlap_threshold > 0.1:\n    # Determine the region where random samples should be sampled from.\n    max_h, min_h = max(abnorm_h, patch_size[0]), min(abnorm_h, patch_size[0])\n    max_w, min_w = max(abnorm_w, patch_size[1]), min(abnorm_w, patch_size[1])\n    min_y = abnorm_y - int((1.0 - min_overlap_threshold) * max_h)\n    min_x = abnorm_x - int((1.0 - min_overlap_threshold) * max_w)\n    max_y = abnorm_y + abnorm_h - int(min_overlap_threshold * min_h)\n    max_x = abnorm_x + abnorm_w - int(min_overlap_threshold * min_w)\n    # Ensure that all sampled batches are within the image.\n    min_y = max(min_y, 0)\n    min_x = max(min_x, 0)\n    max_y = max(min(max_y, image.shape[0] - patch_size[0] - 1), min_y)\n    max_x = max(min(max_x, image.shape[1] - patch_size[1] - 1), min_x)\n    # Cap the number of trials if the sampling region is too small.\n    effective_range_size = max_number_of_trials_per_threshold\n    if (max_y - min_y + 1) * (max_x - min_x + 1) < effective_range_size:\n      logging.debug(\n          \'The sampling region for patches of size %r with \'\n          \'min_overlap_threshold=%f contains less possible patches than \'\n          \'max_number_of_trials_per_threshold=%d, in abnormality %s\',\n          patch_size, min_overlap_threshold, max_number_of_trials_per_threshold,\n          abnormality_filepath)\n      effective_range_size = (max_y - min_y + 1) * (max_x - min_x + 1)\n\n    for _ in range(effective_range_size):\n      patch_y = np.random.randint(min_y, max_y + 1)\n      patch_x = np.random.randint(min_x, max_x + 1)\n      if _patch_overlaps_any_abnormality_above_threshold(\n          patch_y, patch_x, patch_size, [abnormality_mask],\n          [abnormality_area], min_overlap_threshold):\n        number_of_yielded_patches += 1\n        yield image[patch_y:(patch_y + patch_size[0]), patch_x:(patch_x +\n                                                                patch_size[1])]\n      # If we have yielded all requested patches return.\n      if number_of_yielded_patches >= number_of_patches:\n        return\n    # We failed to produce patches with the minimum overlapping requirements.\n    # Reduce those requirements and try again.\n    min_overlap_threshold = min_overlap_threshold * 0.95\n    logging.debug(\n        \'Overlapping constraints relaxed to min_overlap_threshold=%f while \'\n        \'sampling positive patches for the abnormality %s\',\n        min_overlap_threshold, abnormality_filepath)\n\n  # This should not happen ever.\n  raise ValueError(\n      \'Only %d positive patches of size %r could be sampled satisfying the \'\n      \'current conditions (min. relative overlapping area = %f) for the \'\n      \'abnormality %s\' % (number_of_yielded_patches, patch_size,\n                          min_overlap_threshold, abnormality_filepath))\n\n\ndef _sample_negative_patches(image,\n                             image_filepath,\n                             abnormalities_masks,\n                             abnormalities_areas,\n                             patch_size,\n                             number_of_patches=10,\n                             min_breast_overlap_threshold=0.75,\n                             max_abnorm_overlap_threshold=0.35,\n                             max_number_of_trials_per_threshold=100):\n  """"""Sample background patches from the image.\n\n  The relative area of breast tissue in the patch must be, at least,\n  `min_breast_overlap_threshold` of the total patch area. This is to prevent\n  too easy negative examples.\n\n  Similarly, the relative area of the abnormal tissue in the patch must be,\n  at most, `max_abnorm_overlap_threshold`\n\n  The relative area of the patch must overlap with the breast tissue with,\n  at least, `min_breast_overlap_threshold` (relative) pixels.\n  In addition, it must also overlap with abnormal tissue with, at most,\n  `max_abnorm_overlap_threshold` (relative) pixels.\n\n  Args:\n    image: Image to patch from.\n    image_filepath: Only used for logging.\n    abnormalities_masks: List of binary mask of each abnormality in the image.\n    abnormalities_areas: List of precomputed area of each abnormality.\n    patch_size: Size of the patch to extract.\n    number_of_patches: Number of negative patches to sample from the image.\n    min_breast_overlap_threshold: Minimum (relative) number of breast pixels in\n      the patch.\n    max_abnorm_overlap_threshold: Maximum (relative) number of abnormal pixels\n      in the patch.\n    max_number_of_trials_per_threshold: Maximum number of random samples to try\n      before reducing the `min_breast_overlap_threshold` by 5% and increasing\n      the `max_abnorm_overlap_threshold` by 5%.\n\n  Yields:\n    The patch cropped from the input image.\n  """"""\n  cv2 = tfds.core.lazy_imports.cv2\n\n  breast_mask = _get_breast_mask(image)\n\n  def patch_overlapping_breast_is_feasible(y, x):\n    """"""Return True if the patch contains enough breast pixels.""""""\n    breast_in_patch = breast_mask[y:(y + patch_size[0]), x:(x + patch_size[1])]\n    return (np.sum(breast_in_patch > 0) /\n            (patch_size[0] * patch_size[1]) > min_breast_overlap_threshold)\n\n  breast_roi = _get_roi_from_mask(breast_mask)\n  breast_x, breast_y, breast_w, breast_h = cv2.boundingRect(breast_roi)\n  number_of_yielded_patches = 0\n  while (min_breast_overlap_threshold > 0.1 and\n         max_abnorm_overlap_threshold < 0.9):\n    # Determine the region where random samples should be sampled from.\n    max_h, min_h = max(breast_h, patch_size[0]), min(breast_h, patch_size[0])\n    max_w, min_w = max(breast_w, patch_size[1]), min(breast_w, patch_size[1])\n    min_y = breast_y - int((1.0 - min_breast_overlap_threshold) * max_h)\n    min_x = breast_x - int((1.0 - min_breast_overlap_threshold) * max_w)\n    max_y = breast_y + breast_h - int(min_breast_overlap_threshold * min_h)\n    max_x = breast_x + breast_w - int(min_breast_overlap_threshold * min_w)\n    # Ensure that all sampled batches are within the image.\n    min_y = max(min_y, 0)\n    min_x = max(min_x, 0)\n    max_y = max(min(max_y, image.shape[0] - patch_size[0] - 1), min_y)\n    max_x = max(min(max_x, image.shape[1] - patch_size[1] - 1), min_x)\n    # Cap the number of trials if the sampling region is too small.\n    effective_range_size = max_number_of_trials_per_threshold\n    if (max_y - min_y + 1) * (max_x - min_x + 1) < effective_range_size:\n      logging.debug(\n          \'The sampling region for negative patches of size %r with \'\n          \'min_breast_overlap_threshold=%f contains less possible patches \'\n          \'than max_number_of_trials_per_threshold=%d, in mammography %s\',\n          patch_size, min_breast_overlap_threshold,\n          max_number_of_trials_per_threshold, image_filepath)\n      effective_range_size = (max_y - min_y + 1) * (max_x - min_x + 1)\n    for _ in range(effective_range_size):\n      patch_y = np.random.randint(min_y, max_y + 1)\n      patch_x = np.random.randint(min_x, max_x + 1)\n      if (patch_overlapping_breast_is_feasible(patch_y, patch_x) and\n          not _patch_overlaps_any_abnormality_above_threshold(\n              patch_y, patch_x, patch_size, abnormalities_masks,\n              abnormalities_areas, max_abnorm_overlap_threshold)):\n        number_of_yielded_patches += 1\n        yield image[patch_y:(patch_y + patch_size[0]), patch_x:(patch_x +\n                                                                patch_size[1])]\n      # If we have yielded all requested patches return.\n      if number_of_yielded_patches >= number_of_patches:\n        return\n    # We failed to produce patches with the given overlapping requirements.\n    # Relaxate the requirements and try again.\n    min_breast_overlap_threshold = min_breast_overlap_threshold * 0.95\n    max_abnorm_overlap_threshold = max_abnorm_overlap_threshold * 1.05\n    logging.debug(\n        \'Overlapping constraints relaxed to min_breast_overlap_threshold=%f \'\n        \'and max_abnorm_overlap_threshold=%f while sampling negative \'\n        \'patches for the mammography %s\', min_breast_overlap_threshold,\n        max_abnorm_overlap_threshold,\n        image_filepath)  # Filepath to the abnormality mask image.\n\n  # This should not happen ever.\n  raise ValueError(\n      \'Only %d negative patches of size %r could be sampled satisfying the \'\n      \'current conditions (min. relative overlapping area with breast = %f, \'\n      \'max. relative overlapping area with abnormalities = %f) for the \'\n      \'mammography %s\' %\n      (number_of_yielded_patches, patch_size, min_breast_overlap_threshold,\n       max_abnorm_overlap_threshold, image_filepath))\n'"
tensorflow_datasets/image_classification/cbis_ddsm_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cbis_ddsm dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cbis_ddsm\n\n\nclass CuratedBreastImagingDDSMOriginalCalcTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cbis_ddsm.CuratedBreastImagingDDSM\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'original-calc\']\n  SPLITS = {\n      \'train\': 3,  # Abnormalities: 7\n      \'test\': 2,   # Abnormalities: 4\n  }\n  DL_EXTRACT_RESULT = {\n      \'test\': \'calc_case_description_test_set.csv\',\n      \'train\': \'calc_case_description_train_set.csv\',\n  }\n\n\nclass CuratedBreastImagingDDSMOriginalMassTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cbis_ddsm.CuratedBreastImagingDDSM\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'original-mass\']\n  SPLITS = {\n      \'train\': 3,  # Abnormalities: 10\n      \'test\': 2,   # Abnormalities: 4\n  }\n  DL_EXTRACT_RESULT = {\n      \'test\': \'mass_case_description_test_set.csv\',\n      \'train\': \'mass_case_description_train_set.csv\',\n  }\n\n\nclass CuratedBreastImagingDDSMPatchesTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cbis_ddsm.CuratedBreastImagingDDSM\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'patches\']\n  SPLITS = {\n      # Total patches = [(10 + 4 + 7 + 4) + (3 + 2 + 3 + 2)] * 10\n      \'train\': 280,\n      \'validation\': 40,\n      \'test\': 30,\n  }\n  DL_EXTRACT_RESULT = {\n      \'calc-test\': \'calc_case_description_test_set.csv\',\n      \'calc-train\': \'calc_case_description_train_set.csv\',\n      \'mass-test\': \'mass_case_description_test_set.csv\',\n      \'mass-train\': \'mass_case_description_train_set.csv\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/chexpert.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Chexpert.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = """"""\\\nCheXpert is a large dataset of chest X-rays and competition for automated chest \nx-ray interpretation, which features uncertainty labels and radiologist-labeled \nreference standard evaluation sets. It consists of 224,316 chest radiographs \nof 65,240 patients, where the chest radiographic examinations and the associated \nradiology reports were retrospectively collected from Stanford Hospital. Each \nreport was labeled for the presence of 14 observations as positive, negative, \nor uncertain. We decided on the 14 observations based on the prevalence in the \nreports and clinical relevance.\n\nThe CheXpert dataset must be downloaded separately after reading and agreeing \nto a Research Use Agreement. To do so, please follow the instructions on the \nwebsite, https://stanfordmlgroup.github.io/competitions/chexpert/.\n""""""\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1901-07031,\n  author    = {Jeremy Irvin and Pranav Rajpurkar and Michael Ko and Yifan Yu and Silviana Ciurea{-}Ilcus and Chris Chute and Henrik Marklund and Behzad Haghgoo and Robyn L. Ball and Katie Shpanskaya and Jayne Seekins and David A. Mong and Safwan S. Halabi and Jesse K. Sandberg and Ricky Jones and David B. Larson and Curtis P. Langlotz and Bhavik N. Patel and Matthew P. Lungren and Andrew Y. Ng},\n  title     = {CheXpert: {A} Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison},\n  journal   = {CoRR},\n  volume    = {abs/1901.07031},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1901.07031},\n  archivePrefix = {arXiv},\n  eprint    = {1901.07031},\n  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-07031},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n# Path to images and category labels in data dir\n_DATA_DIR = ""CheXpert-v1.0-small""\n_TRAIN_DIR = os.path.join(_DATA_DIR, ""train"")\n_VALIDATION_DIR = os.path.join(_DATA_DIR, ""valid"")\n_TRAIN_LABELS_FNAME = os.path.join(_DATA_DIR, ""train.csv"")\n_VALIDATION_LABELS_FNAME = os.path.join(_DATA_DIR, ""valid.csv"")\n\n# Labels per category\n_LABELS = collections.OrderedDict({\n    ""-1.0"": ""uncertain"",\n    ""1.0"": ""positive"",\n    ""0.0"": ""negative"",\n    """": ""unmentioned"",\n})\n\n\nclass Chexpert(tfds.core.GeneratorBasedBuilder):\n  """"""CheXpert 2019.""""""\n\n  VERSION = tfds.core.Version(""3.1.0"")\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  You must register and agree to user agreement on the dataset page:\n  https://stanfordmlgroup.github.io/competitions/chexpert/\n  Afterwards, you have to put the CheXpert-v1.0-small directory in the\n  manual_dir. It should contain subdirectories: train/ and valid/ with images\n  and also train.csv and valid.csv files.\n  """"""\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""name"": tfds.features.Text(),  # patient info\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.Sequence(\n                tfds.features.ClassLabel(names=_LABELS.values())),\n            ""image_view"": tfds.features.ClassLabel(names=[\n                ""frontal"", ""lateral""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://stanfordmlgroup.github.io/competitions/chexpert/"",\n        citation=_CITATION\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.manual_dir\n    train_path = os.path.join(path, _TRAIN_DIR)\n    val_path = os.path.join(path, _VALIDATION_DIR)\n\n    if not tf.io.gfile.exists(train_path) or not tf.io.gfile.exists(val_path):\n      msg = (""You must download the dataset folder from CheXpert""\n             ""website manually and place it into %s."" % path)\n      raise AssertionError(msg)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""imgs_path"": path,  # Relative img path is provided in csv\n                ""csv_path"": os.path.join(path, _TRAIN_LABELS_FNAME)\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""imgs_path"": path,\n                ""csv_path"": os.path.join(path, _VALIDATION_LABELS_FNAME)\n            },\n        ),\n    ]\n\n  def _generate_examples(self, imgs_path, csv_path):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(csv_path) as csv_f:\n      reader = csv.DictReader(csv_f)\n      # Get keys for each label from csv\n      label_keys = reader.fieldnames[5:]\n      for row in reader:\n        # Get image based on indicated path in csv\n        name = row[""Path""]\n        labels = [_LABELS[row[key]] for key in label_keys]\n        image_view = row[""Frontal/Lateral""].lower()\n        yield name, {\n            ""name"": name,\n            ""image"": os.path.join(imgs_path, name),\n            ""label"": labels,\n            ""image_view"": image_view,\n        }\n'"
tensorflow_datasets/image_classification/chexpert_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for chexpert dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import chexpert\n\n\nclass ChexpertTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = chexpert.Chexpert\n  SPLITS = {\n      ""train"": 2,\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cifar.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CIFAR datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# Shared constants\n_CIFAR_IMAGE_SIZE = 32\n_CIFAR_IMAGE_SHAPE = (_CIFAR_IMAGE_SIZE, _CIFAR_IMAGE_SIZE, 3)\n\n\n_CITATION = """"""\\\n@TECHREPORT{Krizhevsky09learningmultiple,\n    author = {Alex Krizhevsky},\n    title = {Learning multiple layers of features from tiny images},\n    institution = {},\n    year = {2009}\n}\n""""""\n\n\nclass Cifar10(tfds.core.GeneratorBasedBuilder):\n  """"""CIFAR-10.""""""\n\n  VERSION = tfds.core.Version(""3.0.2"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""The CIFAR-10 dataset consists of 60000 32x32 colour ""\n                     ""images in 10 classes, with 6000 images per class. There ""\n                     ""are 50000 training images and 10000 test images.""),\n        features=tfds.features.FeaturesDict({\n            ""id"": tfds.features.Text(),\n            ""image"": tfds.features.Image(shape=_CIFAR_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(num_classes=10),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://www.cs.toronto.edu/~kriz/cifar.html"",\n        citation=_CITATION,\n    )\n\n  @property\n  def _cifar_info(self):\n    return CifarInfo(\n        name=self.name,\n        url=""https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz"",\n        train_files=[\n            ""data_batch_1.bin"", ""data_batch_2.bin"", ""data_batch_3.bin"",\n            ""data_batch_4.bin"", ""data_batch_5.bin""\n        ],\n        test_files=[""test_batch.bin""],\n        prefix=""cifar-10-batches-bin/"",\n        label_files=[""batches.meta.txt""],\n        label_keys=[""label""],\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    cifar_path = dl_manager.download_and_extract(self._cifar_info.url)\n    cifar_info = self._cifar_info\n\n    cifar_path = os.path.join(cifar_path, cifar_info.prefix)\n\n    # Load the label names\n    for label_key, label_file in zip(cifar_info.label_keys,\n                                     cifar_info.label_files):\n      labels_path = os.path.join(cifar_path, label_file)\n      with tf.io.gfile.GFile(labels_path) as label_f:\n        label_names = [name for name in label_f.read().split(""\\n"") if name]\n      self.info.features[label_key].names = label_names\n\n    # Define the splits\n    def gen_filenames(filenames):\n      for f in filenames:\n        yield os.path.join(cifar_path, f)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""split_prefix"": ""train_"",\n                ""filepaths"": gen_filenames(cifar_info.train_files)\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""split_prefix"": ""test_"",\n                ""filepaths"": gen_filenames(cifar_info.test_files)\n            }),\n    ]\n\n  def _generate_examples(self, split_prefix, filepaths):\n    """"""Generate CIFAR examples as dicts.\n\n    Shared across CIFAR-{10, 100}. Uses self._cifar_info as\n    configuration.\n\n    Args:\n      split_prefix (str): Prefix that identifies the split (e.g. ""tr"" or ""te"").\n      filepaths (list[str]): The files to use to generate the data.\n\n    Yields:\n      The cifar examples, as defined in the dataset info features.\n    """"""\n    label_keys = self._cifar_info.label_keys\n    index = 0  # Using index as key since data is always loaded in same order.\n    for path in filepaths:\n      for labels, np_image in _load_data(path, len(label_keys)):\n        record = dict(zip(label_keys, labels))\n        # Note: ""id"" is only provided for the user convenience. To shuffle the\n        # dataset we use `index`, so that the sharding is compatible with\n        # earlier versions.\n        record[""id""] = ""{}{:05d}"".format(split_prefix, index)\n        record[""image""] = np_image\n        yield index, record\n        index += 1\n\n\nclass Cifar100(Cifar10):\n  """"""CIFAR-100 dataset.""""""\n\n  VERSION = tfds.core.Version(""3.0.2"")\n\n  @property\n  def _cifar_info(self):\n    return CifarInfo(\n        name=self.name,\n        url=""https://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz"",\n        train_files=[""train.bin""],\n        test_files=[""test.bin""],\n        prefix=""cifar-100-binary/"",\n        label_files=[""coarse_label_names.txt"", ""fine_label_names.txt""],\n        label_keys=[""coarse_label"", ""label""],\n    )\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""This dataset is just like the CIFAR-10, except it has ""\n                     ""100 classes containing 600 images each. There are 500 ""\n                     ""training images and 100 testing images per class. The ""\n                     ""100 classes in the CIFAR-100 are grouped into 20 ""\n                     ""superclasses. Each image comes with a \\""fine\\"" label ""\n                     ""(the class to which it belongs) and a \\""coarse\\"" label ""\n                     ""(the superclass to which it belongs).""),\n        features=tfds.features.FeaturesDict({\n            ""id"": tfds.features.Text(),\n            ""image"": tfds.features.Image(shape=_CIFAR_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(num_classes=100),\n            ""coarse_label"": tfds.features.ClassLabel(num_classes=20),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://www.cs.toronto.edu/~kriz/cifar.html"",\n        citation=_CITATION,\n    )\n\n\nclass CifarInfo(collections.namedtuple(""_CifarInfo"", [\n    ""name"",\n    ""url"",\n    ""prefix"",\n    ""train_files"",\n    ""test_files"",\n    ""label_files"",\n    ""label_keys"",\n])):\n  """"""Contains the information necessary to generate a CIFAR dataset.\n\n  Attributes:\n    name (str): name of dataset.\n    url (str): data URL.\n    prefix (str): path prefix within the downloaded and extracted file to look\n      for `train_files` and `test_files`.\n    train_files (list<str>): name of training files within `prefix`.\n    test_files (list<str>): name of test files within `prefix`.\n    label_files (list<str>): names of the label files in the data.\n    label_keys (list<str>): names of the label keys in the data.\n  """"""\n\n\ndef _load_data(path, labels_number=1):\n  """"""Yields (labels, np_image) tuples.""""""\n  with tf.io.gfile.GFile(path, ""rb"") as f:\n    data = f.read()\n  offset = 0\n  max_offset = len(data) - 1\n  while offset < max_offset:\n    labels = np.frombuffer(data, dtype=np.uint8, count=labels_number,\n                           offset=offset).reshape((labels_number,))\n    # 1 byte per label, 1024 * 3 = 3072 bytes for the image.\n    offset += labels_number\n    img = (np.frombuffer(data, dtype=np.uint8, count=3072, offset=offset)\n           .reshape((3, _CIFAR_IMAGE_SIZE, _CIFAR_IMAGE_SIZE))\n           .transpose((1, 2, 0))\n          )\n    offset += 3072\n    yield labels, img\n'"
tensorflow_datasets/image_classification/cifar10_1.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Cifar-10.1 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\\\n@article{recht2018cifar10.1,\n  author = {Benjamin Recht and Rebecca Roelofs and Ludwig Schmidt and Vaishaal Shankar},\n  title = {Do CIFAR-10 Classifiers Generalize to CIFAR-10?},\n  year = {2018},\n  note = {\\\\url{https://arxiv.org/abs/1806.00451}},\n}\n\n@article{torralba2008tinyimages, \n  author = {Antonio Torralba and Rob Fergus and William T. Freeman}, \n  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, \n  title = {80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition}, \n  year = {2008}, \n  volume = {30}, \n  number = {11}, \n  pages = {1958-1970}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe CIFAR-10.1 dataset is a new test set for CIFAR-10. CIFAR-10.1 contains roughly 2,000 new test images \nthat were sampled after multiple years of research on the original CIFAR-10 dataset. The data collection \nfor CIFAR-10.1 was designed to minimize distribution shift relative to the original dataset. We describe \nthe creation of CIFAR-10.1 in the paper ""Do CIFAR-10 Classifiers Generalize to CIFAR-10?"". \nThe images in CIFAR-10.1 are a subset of the TinyImages dataset. \nThere are currently two versions of the CIFAR-10.1 dataset: v4 and v6.\n""""""\n\n_DL_URL_IMAGES = ""https://github.com/modestyachts/CIFAR-10.1/blob/master/datasets/cifar10.1_{}_data.npy?raw=true""\n_DL_URL_LABELS = ""https://github.com/modestyachts/CIFAR-10.1/blob/master/datasets/cifar10.1_{}_labels.npy?raw=true""\n\n_DATA_OPTIONS = [""v4"", ""v6""]\n\n\nclass Cifar10_1Config(tfds.core.BuilderConfig):  # pylint: disable=invalid-name\n  """"""BuilderConfig for Cifar-10.1.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, data=None, **kwargs):\n    """"""Constructs a Cifar10_1Config.\n\n    Args:\n      data: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if data not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n    kwargs.setdefault(""name"", data)\n    super(Cifar10_1Config, self).__init__(**kwargs)\n    self.data = data\n\n\nclass Cifar10_1(tfds.core.GeneratorBasedBuilder):  # pylint: disable=invalid-name\n  """"""Cifar-10.1 dataset.""""""\n\n  BUILDER_CONFIGS = [\n      Cifar10_1Config(\n          description=(\n              ""It is the first version of our dataset on which we tested any classifier. As mentioned above, this ""\n              ""makes the v4 dataset independent of the classifiers we evaluate. The numbers reported in the main ""\n              ""sections of our paper use this version of the dataset. It was built from the top 25 TinyImages ""\n              ""keywords for each class, which led to a slight class imbalance. The largest difference is that ships ""\n              ""make up only 8% of the test set instead of 10%. v4 contains 2,021 images.""\n          ),\n          version=tfds.core.Version(""1.0.0""),\n          data=""v4"",\n      ),\n      Cifar10_1Config(\n          description=(\n              ""It is derived from a slightly improved keyword allocation that is exactly class balanced. This version ""\n              ""of the dataset corresponds to the results in Appendix D of our paper. v6 contains 2,000 images.""\n          ),\n          version=tfds.core.Version(""1.0.0""),\n          data=""v6"",\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=(32, 32, 3)),\n            ""label"": tfds.features.ClassLabel(num_classes=10),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/modestyachts/CIFAR-10.1"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    image_url = _DL_URL_IMAGES.format(self.builder_config.data)\n    label_url = _DL_URL_LABELS.format(self.builder_config.name)\n\n    image_path, label_path = dl_manager.download([\n        image_url,\n        label_url,\n    ])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""image_path"": image_path,\n                ""label_path"": label_path,\n            }),\n    ]\n\n  def _generate_examples(self, image_path, label_path):\n    with tf.io.gfile.GFile(image_path, ""rb"") as f:\n      images = np.load(f)\n    with tf.io.gfile.GFile(label_path, ""rb"") as f:\n      labels = np.load(f)\n    for i, (image, label) in enumerate(zip(images, labels)):\n      record = {\n          ""image"": image,\n          ""label"": label,\n      }\n      yield i, record\n'"
tensorflow_datasets/image_classification/cifar10_1_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cifar10_1 dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cifar10_1\nimport tensorflow_datasets.public_api as tfds\n\n\nclass Cifar10_1Test(testing.DatasetBuilderTestCase):  # pylint: disable=invalid-name\n  DATASET_CLASS = cifar10_1.Cifar10_1\n  BUILDER_CONFIG_NAMES_TO_TEST = [""v4""]\n\n  SPLITS = {\n      tfds.Split.TEST: 10,\n  }\n\n  DL_EXTRACT_RESULT = [\n      ""cifar10.1_v4_data.npy"",\n      ""cifar10.1_v4_labels.npy"",\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cifar10_corrupted.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Corrupted Cifar10 Dataset.\n\nCifar10Corrupted is a dataset generated by adding 15 common corruptions + 4\nextra corruptions to the test images in the Cifar10 dataset. This dataset wraps\nthe corrupted Cifar10 test images uploaded by the original authors.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nCifar10Corrupted is a dataset generated by adding 15 common corruptions + 4\nextra corruptions to the test images in the Cifar10 dataset. This dataset wraps\nthe corrupted Cifar10 test images uploaded by the original authors.\n""""""\n\n_CITATION = """"""\\\n@inproceedings{\n  hendrycks2018benchmarking,\n  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\n  author={Dan Hendrycks and Thomas Dietterich},\n  booktitle={International Conference on Learning Representations},\n  year={2019},\n  url={https://openreview.net/forum?id=HJz6tiCqYm},\n}\n""""""\n\n_CIFAR_IMAGE_SIZE = (32, 32, 3)\n_CIFAR_CLASSES = 10\n_DOWNLOAD_URL = \'https://zenodo.org/record/2535967/files/CIFAR-10-C.tar\'\n_CORRUPTIONS_TO_FILENAMES = {\n    \'gaussian_noise\': \'gaussian_noise.npy\',\n    \'shot_noise\': \'shot_noise.npy\',\n    \'impulse_noise\': \'impulse_noise.npy\',\n    \'defocus_blur\': \'defocus_blur.npy\',\n    \'frosted_glass_blur\': \'glass_blur.npy\',\n    \'motion_blur\': \'motion_blur.npy\',\n    \'zoom_blur\': \'zoom_blur.npy\',\n    \'snow\': \'snow.npy\',\n    \'frost\': \'frost.npy\',\n    \'fog\': \'fog.npy\',\n    \'brightness\': \'brightness.npy\',\n    \'contrast\': \'contrast.npy\',\n    \'elastic\': \'elastic_transform.npy\',\n    \'pixelate\': \'pixelate.npy\',\n    \'jpeg_compression\': \'jpeg_compression.npy\',\n    \'gaussian_blur\': \'gaussian_blur.npy\',\n    \'saturate\': \'saturate.npy\',\n    \'spatter\': \'spatter.npy\',\n    \'speckle_noise\': \'speckle_noise.npy\',\n}\n_CORRUPTIONS, _FILENAMES = zip(*sorted(_CORRUPTIONS_TO_FILENAMES.items()))\n_DIRNAME = \'CIFAR-10-C\'\n_LABELS_FILENAME = \'labels.npy\'\n\nBENCHMARK_CORRUPTIONS = [\n    \'gaussian_noise\',\n    \'shot_noise\',\n    \'impulse_noise\',\n    \'defocus_blur\',\n    \'frosted_glass_blur\',\n    \'motion_blur\',\n    \'zoom_blur\',\n    \'snow\',\n    \'frost\',\n    \'fog\',\n    \'brightness\',\n    \'contrast\',\n    \'elastic\',\n    \'pixelate\',\n    \'jpeg_compression\',\n]\n\nEXTRA_CORRUPTIONS = [\n    \'gaussian_blur\',\n    \'saturate\',\n    \'spatter\',\n    \'speckle_noise\',\n]\n\n\nclass Cifar10CorruptedConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Cifar10Corrupted.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, corruption_type, severity, **kwargs):\n    """"""Constructor.\n\n    Args:\n      corruption_type: string, must be one of the items in _CORRUPTIONS.\n      severity: integer, bewteen 1 and 5.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(Cifar10CorruptedConfig, self).__init__(**kwargs)\n    self.corruption = corruption_type\n    self.severity = severity\n\n\ndef _make_builder_configs():\n  """"""Construct a list of BuilderConfigs.\n\n  Construct a list of 95 Cifar10CorruptedConfig objects, corresponding to\n  the 15 corruption types + 4 extra corruptions and 5 severities.\n\n  Returns:\n    A list of 95 Cifar10CorruptedConfig objects.\n  """"""\n  config_list = []\n  v1 = tfds.core.Version(\n      \'1.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n  for corruption in _CORRUPTIONS:\n    for severity in range(1, 6):\n      config_list.append(\n          Cifar10CorruptedConfig(\n              name=corruption + \'_\' + str(severity),\n              version=v1,\n              description=\'Corruption method: \' + corruption +\n              \', severity level: \' + str(severity),\n              corruption_type=corruption,\n              severity=severity,\n          ))\n  return config_list\n\n\nclass Cifar10Corrupted(tfds.core.GeneratorBasedBuilder):\n  """"""Corrupted Cifar10 dataset.""""""\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    """"""Returns basic information of dataset.\n\n    Returns:\n      tfds.core.DatasetInfo.\n    """"""\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(shape=_CIFAR_IMAGE_SIZE),\n            \'label\': tfds.features.ClassLabel(num_classes=_CIFAR_CLASSES),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://github.com/hendrycks/robustness\',\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Return the test split of Cifar10.\n\n    Args:\n      dl_manager: download manager object.\n\n    Returns:\n      test split.\n    """"""\n    path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'data_dir\': os.path.join(path, _DIRNAME)})\n    ]\n\n  def _generate_examples(self, data_dir):\n    """"""Generate corrupted Cifar10 test data.\n\n    Apply corruptions to the raw images according to self.corruption_type.\n\n    Args:\n      data_dir: root directory of downloaded dataset\n\n    Yields:\n      dictionary with image file and label.\n    """"""\n    corruption = self.builder_config.corruption\n    severity = self.builder_config.severity\n\n    images_file = os.path.join(data_dir, _CORRUPTIONS_TO_FILENAMES[corruption])\n    labels_file = os.path.join(data_dir, _LABELS_FILENAME)\n\n    with tf.io.gfile.GFile(labels_file, mode=\'rb\') as f:\n      labels = np.load(f)\n\n    num_images = labels.shape[0] // 5\n    # Labels are stacked 5 times so we can just read the first iteration\n    labels = labels[:num_images]\n\n    with tf.io.gfile.GFile(images_file, mode=\'rb\') as f:\n      images = np.load(f)\n\n    # Slice images corresponding to correct severity level\n    images = images[(severity - 1) * num_images:severity * num_images]\n\n    for i, (image, label) in enumerate(zip(images, labels)):\n      yield i, {\n          \'image\': image,\n          \'label\': label,\n      }\n'"
tensorflow_datasets/image_classification/cifar10_corrupted_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for corrupted Cifar10.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cifar10_corrupted\n\n\nclass Cifar10CorruptedTest(testing.DatasetBuilderTestCase):\n\n  BUILDER_CONFIG_NAMES_TO_TEST = [\n      ""elastic_1"", ""elastic_4"", ""elastic_5"",\n  ]\n\n  DATASET_CLASS = cifar10_corrupted.Cifar10Corrupted\n  SPLITS = {\n      ""test"": 10,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cifar_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cifar dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cifar\n\n\n# testing/cifar.py generates fake input data\n\n\nclass Cifar10Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cifar.Cifar10\n  SPLITS = {\n      ""train"": 10,\n      ""test"": 2,\n  }\n\n\nclass Cifar100Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cifar.Cifar100\n  SPLITS = {\n      ""train"": 10,\n      ""test"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/citrus.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Healthy and unhealthy citrus fruits and leaves dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{rauf2019citrus,\n  title={A citrus fruits and leaves dataset for detection and classification of\ncitrus diseases through machine learning},\n  author={Rauf, Hafiz Tayyab and Saleem, Basharat Ali and Lali, M Ikram Ullah\nand Khan, Muhammad Attique and Sharif, Muhammad and Bukhari, Syed Ahmad Chan},\n  journal={Data in brief},\n  volume={26},\n  pages={104340},\n  year={2019},\n  publisher={Elsevier}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe original citrus dataset contains 759 images of healthy and unhealthy citrus\nfruits and leaves. However, for now we only export 594 images of citrus leaves\nwith the following labels: Black Spot, Canker, Greening, and Healthy. The\nexported images are in PNG format and have 256x256 pixels.\n\nNOTE: Leaf images with Melanose label were dropped due to very small count and\nother non-leaf images being present in the same directory.\n\nDataset URL: https://data.mendeley.com/datasets/3f83gxmv57/2\nLicense: http://creativecommons.org/licenses/by/4.0\n""""""\n\n_URL = ""https://data.mendeley.com/datasets/3f83gxmv57/2/files/6f809085-8c29-49f7-afbc-f90854fd45dc/Citrus.zip""\n_LEAVES_LABELS = [""Black spot"", ""canker"", ""greening"", ""healthy""]\n\n\nclass CitrusLeaves(tfds.core.GeneratorBasedBuilder):\n  """"""Subset of the citrus dataset with just leaves.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(names=_LEAVES_LABELS)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://data.mendeley.com/datasets/3f83gxmv57/2"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN, gen_kwargs={""datapath"": path})\n    ]\n\n  def _generate_examples(self, datapath):\n    """"""Yields examples based on the passed split index.""""""\n    for label in _LEAVES_LABELS:\n      # The real dataset has spaces in directories (label names), which causes\n      # fake data test to fail due objfs not handling whitespace in paths. The\n      # solution is to replace spaces with underscores in fake data directories\n      # and then not care whether a character is a space or an underscore.\n      fuzzy_label = label.replace("" "", ""[_ ]"")\n      glob_path = os.path.join(datapath, ""Citrus/Leaves"", fuzzy_label, ""*.png"")\n      for fpath in tf.io.gfile.glob(glob_path):\n        fname = os.path.basename(fpath)\n        record = {\n            ""image"": fpath,\n            ""image/filename"": fname,\n            ""label"": label,\n        }\n        yield ""{}/{}"".format(label, fname), record\n'"
tensorflow_datasets/image_classification/citrus_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for citrus dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import citrus\n\n\nclass CitrusLeavesTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = citrus.CitrusLeaves\n  SPLITS = {""train"": 4}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/cmaterdb.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CMATERdb dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# CMATERdb constants\n_CMATERDB_IMAGE_SIZE = 32\n_CMATERDB_IMAGE_SHAPE = (_CMATERDB_IMAGE_SIZE, _CMATERDB_IMAGE_SIZE, 3)\n# GitHub npz mirror of https://code.google.com/archive/p/cmaterdb/\n_CMATERDB_TRAINING_URL = (\n    ""https://raw.githubusercontent.com/prabhuomkar/CMATERdb/master/""\n    ""datasets/{type}-numerals/training-images.npz"")\n_CMATERDB_TESTING_URL = (\n    ""https://raw.githubusercontent.com/prabhuomkar/CMATERdb/master/""\n    ""datasets/{type}-numerals/testing-images.npz"")\n\n_CITATION = """"""\\\n@article{Das:2012:GAB:2161007.2161320,\n  author = {Das, Nibaran and Sarkar, Ram and Basu, Subhadip and Kundu, Mahantapas \n            and Nasipuri, Mita and Basu, Dipak Kumar},\n  title = {A Genetic Algorithm Based Region Sampling for Selection of Local Features \n          in Handwritten Digit Recognition Application},\n  journal = {Appl. Soft Comput.},\n  issue_date = {May, 2012},\n  volume = {12},\n  number = {5},\n  month = may,\n  year = {2012},\n  issn = {1568-4946},\n  pages = {1592--1606},\n  numpages = {15},\n  url = {http://dx.doi.org/10.1016/j.asoc.2011.11.030},\n  doi = {10.1016/j.asoc.2011.11.030},\n  acmid = {2161320},\n  publisher = {Elsevier Science Publishers B. V.},\n  address = {Amsterdam, The Netherlands, The Netherlands},\n  keywords = {Feature selection, Genetic algorithm, N-Quality consensus, \n  Optimal local regions, Region sampling, Variable sized local regions},\n}\n@article{Das:2012:SFC:2240301.2240421,\n  author = {Das, Nibaran and Reddy, Jagan Mohan and Sarkar, Ram and Basu, Subhadip and Kundu, \n            Mahantapas and Nasipuri, Mita and Basu, Dipak Kumar},\n  title = {A Statistical-topological Feature Combination for Recognition of Handwritten Numerals},\n  journal = {Appl. Soft Comput.},\n  issue_date = {August, 2012},\n  volume = {12},\n  number = {8},\n  month = aug,\n  year = {2012},\n  issn = {1568-4946},\n  pages = {2486--2495},\n  numpages = {10},\n  url = {http://dx.doi.org/10.1016/j.asoc.2012.03.039},\n  doi = {10.1016/j.asoc.2012.03.039},\n  acmid = {2240421},\n  publisher = {Elsevier Science Publishers B. V.},\n  address = {Amsterdam, The Netherlands, The Netherlands},\n  keywords = {Character recognition, Feature combination, MPCA, PCA, SVM, Statistical, Topological},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThis dataset contains images of -\n  Handwritten Bangla numerals - balanced dataset of total 6000 Bangla numerals (32x32 RGB coloured, 6000 images), each having 600 images per class(per digit). \n  Handwritten Devanagari numerals - balanced dataset of total 3000 Devanagari numerals (32x32 RGB coloured, 3000 images), each having 300 images per class(per digit). \n  Handwritten Telugu numerals - balanced dataset of total 3000 Telugu numerals (32x32 RGB coloured, 3000 images), each having 300 images per class(per digit). \n\nCMATERdb is the pattern recognition database repository created at the \'Center for Microprocessor Applications for Training Education and Research\' (CMATER) research lab, Jadavpur University, India.\n""""""\n\n\nclass CmaterdbConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CMATERdb Config.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, **kwargs):\n    """"""BuilderConfig for CMATERdb examples.\n\n    Args:\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(CmaterdbConfig, self).__init__(**kwargs)\n\n\nclass Cmaterdb(tfds.core.GeneratorBasedBuilder):\n  """"""CMATERdb dataset.""""""\n\n  BUILDER_CONFIGS = [\n      CmaterdbConfig(\n          name=""bangla"",\n          description=""CMATERdb Bangla Numerals"",\n          version=""1.0.0"",\n      ),\n      CmaterdbConfig(\n          name=""devanagari"",\n          description=""CMATERdb Devangari Numerals"",\n          version=""1.0.0"",\n      ),\n      CmaterdbConfig(\n          name=""telugu"",\n          description=""CMATERdb Telugu Numerals"",\n          version=""1.0.0"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_CMATERDB_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(num_classes=10),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://code.google.com/archive/p/cmaterdb/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # Download the CMATERdb dataset by mentioned numeral\n    train_path, test_path = dl_manager.download([\n        _CMATERDB_TRAINING_URL.format(type=self.builder_config.name),\n        _CMATERDB_TESTING_URL.format(type=self.builder_config.name),\n    ])\n\n    # CMATERdb (mirrored) provides TRAIN and TEST splits,\n    # not a VALIDATION split, so we only\n    # write the TRAIN and TEST splits to disk.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(data_path=train_path),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(data_path=test_path),\n        ),\n    ]\n\n  def _generate_examples(self, data_path):\n    """"""Generate CMATERdb examples as dicts.\n\n    Args:\n      data_path (str): Path to the data files\n\n    Yields:\n      Generator yielding the next examples\n    """"""\n    with tf.io.gfile.GFile(data_path, mode=""rb"") as f:\n      data = np.load(f)\n\n    data = list(zip(data[""images""], data[""labels""]))\n    for index, (image, label) in enumerate(data):\n      yield index, {\n          ""image"": image,\n          ""label"": label,\n      }\n'"
tensorflow_datasets/image_classification/cmaterdb_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for CMATERdb dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cmaterdb\n\n\nclass CmaterdbTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cmaterdb.Cmaterdb\n  BUILDER_CONFIG_NAMES_TO_TEST = [""bangla""]\n  SPLITS = {\n      ""train"": 20,\n      ""test"": 10,\n  }\n  DL_EXTRACT_RESULT = [\n      ""training-images.npz"",\n      ""testing-images.npz"",\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/colorectal_histology.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Texture tiles from colorectal cancer histology.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\n_URL = ""https://zenodo.org/record/53169#.XGZemKwzbmG""\n_TILES_DL_URL = ""https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip""\n_LARGE_DL_URL = ""https://zenodo.org/record/53169/files/Kather_texture_2016_larger_images_10.zip""\n\n_TILES_SUBDIR = ""Kather_texture_2016_image_tiles_5000""\n_LARGE_SUBDIR = ""Kather_texture_2016_larger_images_10""\n\n_CLASS_NAMES = (\n    ""tumor"",\n    ""stroma"",\n    ""complex"",\n    ""lympho"",\n    ""debris"",\n    ""mucosa"",\n    ""adipose"",\n    ""empty"",\n)\n_TILES_SIZE = 150\n_LARGE_SIZE = 5000\n\n_CITATION = """"""\\\n@article{kather2016multi,\n  title={Multi-class texture analysis in colorectal cancer histology},\n  author={Kather, Jakob Nikolas and Weis, Cleo-Aron and Bianconi, Francesco and Melchers, Susanne M and Schad, Lothar R and Gaiser, Timo and Marx, Alexander and Z{\\""o}llner, Frank Gerrit},\n  journal={Scientific reports},\n  volume={6},\n  pages={27988},\n  year={2016},\n  publisher={Nature Publishing Group}\n}\n""""""\n\n\ndef _class_subdir(class_index, class_name):\n  return ""%02d_%s"" % (class_index + 1, class_name.upper())\n\n\ndef _load_tif(path):\n  with tf.io.gfile.GFile(path, ""rb"") as fp:\n    image = tfds.core.lazy_imports.PIL_Image.open(fp)\n  return np.array(image)\n\n\nclass ColorectalHistology(tfds.core.GeneratorBasedBuilder):\n  """"""Biological 8-class classification problem.""""""\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(\n            ""Classification of textures in colorectal cancer histology. ""\n            ""Each example is a 150 x 150 x 3 RGB image of one of 8 classes.""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=(_TILES_SIZE,) * 2 + (3,)),\n            ""label"": tfds.features.ClassLabel(\n                names=_CLASS_NAMES),\n            ""filename"": tfds.features.Text(),\n        }),\n        homepage=_URL,\n        citation=_CITATION,\n        supervised_keys=(""image"", ""label""),\n    )\n\n  def _split_generators(self, dl_manager):\n    folder = dl_manager.download_and_extract(_TILES_DL_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(root_dir=folder),\n        ),\n    ]\n\n  def _generate_examples(self, root_dir):\n    root_dir = os.path.join(root_dir, _TILES_SUBDIR)\n    for i, class_name in enumerate(_CLASS_NAMES):\n      class_dir = os.path.join(root_dir, _class_subdir(i, class_name))\n      fns = tf.io.gfile.listdir(class_dir)\n\n      for fn in sorted(fns):\n        image = _load_tif(os.path.join(class_dir, fn))\n        record = {\n            ""image"": image,\n            ""label"": class_name,\n            ""filename"": fn,\n        }\n        yield ""%s/%s"" % (class_name, fn), record\n\n\nclass ColorectalHistologyLarge(tfds.core.GeneratorBasedBuilder):\n  """"""10 Large 5000 x 5000 colorectal histology images without labels.""""""\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(\n            ""10 large 5000 x 5000 textured colorectal cancer histology images""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=(_LARGE_SIZE,)*2 + (3,)),\n            ""filename"": tfds.features.Text(),\n        }),\n        homepage=_URL,\n        citation=_CITATION\n    )\n\n  def _split_generators(self, dl_manager):\n    folder = dl_manager.download_and_extract(_LARGE_DL_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(folder=folder)\n        )\n    ]\n\n  def _generate_examples(self, folder):\n    folder = os.path.join(folder, _LARGE_SUBDIR)\n    for fn in tf.io.gfile.listdir(folder):\n      image = _load_tif(os.path.join(folder, fn))\n      record = dict(image=image, filename=fn)\n      yield fn, record\n'"
tensorflow_datasets/image_classification/colorectal_histology_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for colorectal_histology dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import colorectal_histology\n\n# testing/colorectal_histology.py generates fake input data\n\nnum_classes = len(colorectal_histology._CLASS_NAMES)  # pylint: disable=protected-access\n\n\nclass ColorectalHistologyTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = colorectal_histology.ColorectalHistology\n  SPLITS = {\n      ""train"": 2 * num_classes,\n  }\n\n\nclass ColorectalHistologyLargeTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = colorectal_histology.ColorectalHistologyLarge\n  SPLITS = {\n      ""test"": 1,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/corruptions.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Common corruptions to images.\n\nDefine 15+4 common image corruptions: Gaussian noise, shot noise, impulse_noise,\ndefocus blur, frosted glass blur, zoom blur, fog, brightness, contrast, elastic,\npixelate, jpeg compression, frost, snow, and motion blur.\n\n4 extra corruptions: gaussian blur, saturate, spatter, and speckle noise.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport subprocess\nimport tempfile\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n# To be populated by download_manager\nFROST_FILENAMES = []\n\n\ndef _imagemagick_bin():\n  return \'imagemagick\'  # pylint: disable=unreachable\n\n\n# /////////////// Corruption Helpers ///////////////\n\n\ndef around_and_astype(x):\n  """"""Round a numpy array, and convert to uint8.\n\n  Args:\n    x: numpy array.\n\n  Returns:\n    numpy array with dtype uint8.\n  """"""\n  return np.around(x).astype(np.uint8)\n\n\ndef disk(radius, alias_blur=0.1, dtype=np.float32):\n  """"""Generating a Gaussian blurring kernel with disk shape.\n\n  Generating a Gaussian blurring kernel with disk shape using cv2 API.\n\n  Args:\n    radius: integer, radius of blurring kernel.\n    alias_blur: float, standard deviation of Gaussian blurring.\n    dtype: data type of kernel\n\n  Returns:\n    cv2 object of the Gaussian blurring kernel.\n  """"""\n  if radius <= 8:\n    length = np.arange(-8, 8 + 1)\n    ksize = (3, 3)\n  else:\n    length = np.arange(-radius, radius + 1)\n    ksize = (5, 5)\n  x_axis, y_axis = np.meshgrid(length, length)\n  aliased_disk = np.array((x_axis**2 + y_axis**2) <= radius**2, dtype=dtype)\n  aliased_disk /= np.sum(aliased_disk)\n  # supersample disk to antialias\n  return tfds.core.lazy_imports.cv2.GaussianBlur(\n      aliased_disk, ksize=ksize, sigmaX=alias_blur)\n\n\ndef clipped_zoom(img, zoom_factor):\n  """"""Zoom image with clipping.\n\n  Zoom the central part of the image and clip extra pixels.\n\n  Args:\n    img: numpy array, uncorrupted image.\n    zoom_factor: numpy array, a sequence of float numbers for zoom factor.\n\n  Returns:\n    numpy array, zoomed image after clipping.\n  """"""\n  h = img.shape[0]\n  ch = int(np.ceil(h / float(zoom_factor)))\n  top_h = (h - ch) // 2\n\n  w = img.shape[1]\n  cw = int(np.ceil(w / float(zoom_factor)))\n  top_w = (w - cw) // 2\n\n  img = tfds.core.lazy_imports.scipy.ndimage.zoom(\n      img[top_h:top_h + ch, top_w:top_w + cw], (zoom_factor, zoom_factor, 1),\n      order=1)\n\n  # trim off any extra pixels\n  trim_top_h = (img.shape[0] - h) // 2\n  trim_top_w = (img.shape[1] - w) // 2\n\n  return img[trim_top_h:trim_top_h + h, trim_top_w:trim_top_w + w]\n\n\ndef plasma_fractal(mapsize=512, wibbledecay=3):\n  """"""Generate a heightmap using diamond-square algorithm.\n\n  Modification of the algorithm in\n  https://github.com/FLHerne/mapgen/blob/master/diamondsquare.py\n\n  Args:\n    mapsize: side length of the heightmap, must be a power of two.\n    wibbledecay: integer, decay factor.\n\n  Returns:\n    numpy 2d array, side length \'mapsize\', of floats in [0,255].\n  """"""\n  if mapsize & (mapsize - 1) != 0:\n    raise ValueError(\'mapsize must be a power of two.\')\n  maparray = np.empty((mapsize, mapsize), dtype=np.float_)\n  maparray[0, 0] = 0\n  stepsize = mapsize\n  wibble = 100\n\n  def wibbledmean(array):\n    return array / 4 + wibble * np.random.uniform(-wibble, wibble, array.shape)\n\n  def fillsquares():\n    """"""For each square, calculate middle value as mean of points + wibble.""""""\n    cornerref = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n    squareaccum = cornerref + np.roll(cornerref, shift=-1, axis=0)\n    squareaccum += np.roll(squareaccum, shift=-1, axis=1)\n    maparray[stepsize // 2:mapsize:stepsize,\n             stepsize // 2:mapsize:stepsize] = wibbledmean(squareaccum)\n\n  def filldiamonds():\n    """"""For each diamond, calculate middle value as meanof points + wibble.""""""\n    mapsize = maparray.shape[0]\n    drgrid = maparray[stepsize // 2:mapsize:stepsize,\n                      stepsize // 2:mapsize:stepsize]\n    ulgrid = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n    ldrsum = drgrid + np.roll(drgrid, 1, axis=0)\n    lulsum = ulgrid + np.roll(ulgrid, -1, axis=1)\n    ltsum = ldrsum + lulsum\n    maparray[0:mapsize:stepsize,\n             stepsize // 2:mapsize:stepsize] = wibbledmean(ltsum)\n    tdrsum = drgrid + np.roll(drgrid, 1, axis=1)\n    tulsum = ulgrid + np.roll(ulgrid, -1, axis=0)\n    ttsum = tdrsum + tulsum\n    maparray[stepsize // 2:mapsize:stepsize,\n             0:mapsize:stepsize] = wibbledmean(ttsum)\n\n  while stepsize >= 2:\n    fillsquares()\n    filldiamonds()\n    stepsize //= 2\n    wibble /= wibbledecay\n\n  maparray -= maparray.min()\n  return maparray / maparray.max()\n\n\n# /////////////// End Corruption Helpers ///////////////\n\n# /////////////// Corruptions ///////////////\n\n\ndef gaussian_noise(x, severity=1):\n  """"""Gaussian noise corruption to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added Gaussian noise.\n  """"""\n  c = [.08, .12, 0.18, 0.26, 0.38][severity - 1]\n  x = np.array(x) / 255.\n  x_clip = np.clip(x + np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef shot_noise(x, severity=1):\n  """"""Shot noise corruption to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added shot noise.\n  """"""\n  c = [60, 25, 12, 5, 3][severity - 1]\n  x = np.array(x) / 255.\n  x_clip = np.clip(np.random.poisson(x * c) / float(c), 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef impulse_noise(x, severity=1):\n  """"""Impulse noise corruption to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added impulse noise.\n  """"""\n  c = [.03, .06, .09, 0.17, 0.27][severity - 1]\n  x = tfds.core.lazy_imports.skimage.util.random_noise(\n      np.array(x) / 255., mode=\'s&p\', amount=c)\n  x_clip = np.clip(x, 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef defocus_blur(x, severity=1):\n  """"""Defocus blurring to images.\n\n  Apply defocus blurring to images using Gaussian kernel.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied defocus blur.\n  """"""\n  c = [(3, 0.1), (4, 0.5), (6, 0.5), (8, 0.5), (10, 0.5)][severity - 1]\n  x = np.array(x) / 255.\n  kernel = disk(radius=c[0], alias_blur=c[1])\n  channels = []\n  for d in range(3):\n    channels.append(tfds.core.lazy_imports.cv2.filter2D(x[:, :, d], -1, kernel))\n  channels = np.array(channels).transpose((1, 2, 0))  # 3x224x224 -> 224x224x3\n  x_clip = np.clip(channels, 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef glass_blur(x, severity=1):\n  """"""Frosted glass blurring to images.\n\n  Apply frosted glass blurring to images by shuffling pixels locally.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied frosted glass blur.\n  """"""\n  # sigma, max_delta, iterations\n  c = [(0.7, 1, 2), (0.9, 2, 1), (1, 2, 3), (1.1, 3, 2),\n       (1.5, 4, 2)][severity - 1]\n  x = np.uint8(\n      tfds.core.lazy_imports.skimage.filters.gaussian(\n          np.array(x) / 255., sigma=c[0], multichannel=True) * 255)\n\n  # locally shuffle pixels\n  for _ in range(c[2]):\n    for h in range(x.shape[0] - c[1], c[1], -1):\n      for w in range(x.shape[1] - c[1], c[1], -1):\n        dx, dy = np.random.randint(-c[1], c[1], size=(2,))\n        h_prime, w_prime = h + dy, w + dx\n        # swap\n        x[h, w], x[h_prime, w_prime] = x[h_prime, w_prime], x[h, w]\n  x_clip = np.clip(\n      tfds.core.lazy_imports.skimage.filters.gaussian(\n          x / 255., sigma=c[0], multichannel=True), 0, 1)\n  x_clip *= 255\n  return around_and_astype(x_clip)\n\n\ndef zoom_blur(x, severity=1):\n  """"""Zoom blurring to images.\n\n  Applying zoom blurring to images by zooming the central part of the images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied zoom blur.\n  """"""\n  c = [\n      np.arange(1, 1.11, 0.01),\n      np.arange(1, 1.16, 0.01),\n      np.arange(1, 1.21, 0.02),\n      np.arange(1, 1.26, 0.02),\n      np.arange(1, 1.31, 0.03)\n  ][severity - 1]\n  x = (np.array(x) / 255.).astype(np.float32)\n  out = np.zeros_like(x)\n  for zoom_factor in c:\n    out += clipped_zoom(x, zoom_factor)\n  x = (x + out) / (len(c) + 1)\n  x_clip = np.clip(x, 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef fog(x, severity=1):\n  """"""Fog corruption to images.\n\n  Adding fog to images. Fog is generated by diamond-square algorithm.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added fog.\n  """"""\n  c = [(1.5, 2), (2., 2), (2.5, 1.7), (2.5, 1.5), (3., 1.4)][severity - 1]\n  x = np.array(x) / 255.\n  max_val = x.max()\n  mapsize = 512\n  shape = x.shape\n  max_length = max(shape[0], shape[1])\n  if max_length > mapsize:\n    mapsize = 2**int(np.ceil(np.log2(float(max_length))))\n  tmp = plasma_fractal(mapsize=mapsize, wibbledecay=c[1])\n  tmp = tmp[:x.shape[0], :x.shape[1]]\n  tmp = tmp[..., np.newaxis]\n  x += c[0] * tmp\n  x_clip = np.clip(x * max_val / (max_val + c[0]), 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef brightness(x, severity=1):\n  """"""Change brightness of images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Changed brightness.\n  """"""\n  c = [.1, .2, .3, .4, .5][severity - 1]\n\n  x = np.array(x) / 255.\n  x = tfds.core.lazy_imports.skimage.color.rgb2hsv(x)\n  x[:, :, 2] = np.clip(x[:, :, 2] + c, 0, 1)\n  x = tfds.core.lazy_imports.skimage.color.hsv2rgb(x)\n  x_clip = np.clip(x, 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef contrast(x, severity=1):\n  """"""Change contrast of images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Changed contrast.\n  """"""\n  c = [0.4, .3, .2, .1, .05][severity - 1]\n\n  x = np.array(x) / 255.\n  means = np.mean(x, axis=(0, 1), keepdims=True)\n  x_clip = np.clip((x - means) * c + means, 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef elastic_transform(x, severity=1):\n  """"""Conduct elastic transform to images.\n\n  Elastic transform is performed on small patches of the images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied elastic transform.\n  """"""\n  c = [(244 * 2, 244 * 0.7, 244 * 0.1), (244 * 2, 244 * 0.08, 244 * 0.2),\n       (244 * 0.05, 244 * 0.01, 244 * 0.02),\n       (244 * 0.07, 244 * 0.01, 244 * 0.02),\n       (244 * 0.12, 244 * 0.01, 244 * 0.02)][severity - 1]\n\n  image = np.array(x, dtype=np.float32) / 255.\n  shape = image.shape\n  shape_size = shape[:2]\n\n  # random affine\n  center_square = np.float32(shape_size) // 2\n  square_size = min(shape_size) // 3\n  pts1 = np.float32([\n      center_square + square_size,\n      [center_square[0] + square_size, center_square[1] - square_size],\n      center_square - square_size\n  ])\n  pts2 = pts1 + np.random.uniform(\n      -c[2], c[2], size=pts1.shape).astype(np.float32)\n  affine_trans = tfds.core.lazy_imports.cv2.getAffineTransform(pts1, pts2)\n  image = tfds.core.lazy_imports.cv2.warpAffine(\n      image,\n      affine_trans,\n      shape_size[::-1],\n      borderMode=tfds.core.lazy_imports.cv2.BORDER_REFLECT_101)\n\n  dx = (tfds.core.lazy_imports.skimage.filters.gaussian(\n      np.random.uniform(-1, 1, size=shape[:2]),\n      c[1],\n      mode=\'reflect\',\n      truncate=3) * c[0]).astype(np.float32)\n  dy = (tfds.core.lazy_imports.skimage.filters.gaussian(\n      np.random.uniform(-1, 1, size=shape[:2]),\n      c[1],\n      mode=\'reflect\',\n      truncate=3) * c[0]).astype(np.float32)\n  dx, dy = dx[..., np.newaxis], dy[..., np.newaxis]\n\n  x, y, z = np.meshgrid(\n      np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n  indices = np.reshape(y + dy,\n                       (-1, 1)), np.reshape(x + dx,\n                                            (-1, 1)), np.reshape(z, (-1, 1))\n  x_clip = np.clip(\n      tfds.core.lazy_imports.scipy.ndimage.interpolation.map_coordinates(\n          image, indices, order=1, mode=\'reflect\').reshape(shape), 0, 1) * 255\n  return around_and_astype(x_clip)\n\n\ndef pixelate(x, severity=1):\n  """"""Pixelate images.\n\n  Conduct pixelating corruptions to images by first shrinking the images and\n  then resizing to original size.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied pixelating\n    corruption.\n  """"""\n  c = [0.6, 0.5, 0.4, 0.3, 0.25][severity - 1]\n  shape = x.shape\n  x = tfds.core.lazy_imports.PIL_Image.fromarray(x.astype(np.uint8))\n  x = x.resize((int(shape[1] * c), int(shape[0] * c)))\n  x = x.resize((shape[1], shape[0]))\n  return np.asarray(x)\n\n\ndef jpeg_compression(x, severity=1):\n  """"""Conduct jpeg compression to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied jpeg compression.\n  """"""\n  c = [25, 18, 15, 10, 7][severity - 1]\n  x = tfds.core.lazy_imports.PIL_Image.fromarray(x.astype(np.uint8))\n  output = io.BytesIO()\n  x.save(output, \'JPEG\', quality=c)\n  output.seek(0)\n  x = tfds.core.lazy_imports.PIL_Image.open(output)\n  return np.asarray(x)\n\n\ndef frost(x, severity=1):\n  """"""Apply frost to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied frost.\n  """"""\n  c = [(1, 0.4), (0.8, 0.6), (0.7, 0.7), (0.65, 0.7), (0.6, 0.75)][severity - 1]\n  filename = FROST_FILENAMES[np.random.randint(5)]\n  with tempfile.NamedTemporaryFile() as im_frost:\n    tf.io.gfile.copy(filename, im_frost.name, overwrite=True)\n    frost_img = tfds.core.lazy_imports.cv2.imread(im_frost.name)\n  # randomly crop and convert to rgb\n  x_start, y_start = np.random.randint(\n      0, frost_img.shape[0] - 224), np.random.randint(0,\n                                                      frost_img.shape[1] - 224)\n  frost_img = frost_img[x_start:x_start + 224, y_start:y_start + 224][...,\n                                                                      [2, 1, 0]]\n\n  x = np.clip(c[0] * np.array(x) + c[1] * frost_img, 0, 255)\n\n  return around_and_astype(x)\n\n\ndef snow(x, severity=1):\n  """"""Apply snow to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied snow.\n  """"""\n  cv2 = tfds.core.lazy_imports.cv2\n  PIL_Image = tfds.core.lazy_imports.PIL_Image  # pylint: disable=invalid-name\n  c = [(0.1, 0.3, 3, 0.5, 10, 4, 0.8), (0.2, 0.3, 2, 0.5, 12, 4, 0.7),\n       (0.55, 0.3, 4, 0.9, 12, 8, 0.7), (0.55, 0.3, 4.5, 0.85, 12, 8, 0.65),\n       (0.55, 0.3, 2.5, 0.85, 12, 12, 0.55)][severity - 1]\n\n  x = np.array(x, dtype=np.float32) / 255.\n  snow_layer = np.random.normal(\n      size=x.shape[:2], loc=c[0], scale=c[1])  # [:2] for monochrome\n\n  snow_layer = clipped_zoom(snow_layer[..., np.newaxis], c[2])\n  snow_layer[snow_layer < c[3]] = 0\n\n  snow_layer = PIL_Image.fromarray(\n      (np.clip(snow_layer.squeeze(), 0, 1) * 255).astype(np.uint8), mode=\'L\')\n\n  with tempfile.NamedTemporaryFile() as im_input:\n    with tempfile.NamedTemporaryFile() as im_output:\n      snow_layer.save(im_input.name, format=\'PNG\')\n\n      convert_bin = _imagemagick_bin()\n      radius = c[4]\n      sigma = c[5]\n      angle = np.random.uniform(-135, -45)\n\n      subprocess.check_output([\n          convert_bin, \'-motion-blur\', \'{}x{}+{}\'.format(radius, sigma, angle),\n          im_input.name, im_output.name\n      ])\n\n      with open(im_output.name, \'rb\') as f:\n        output = f.read()\n\n  snow_layer = cv2.imdecode(\n      np.fromstring(output, np.uint8), cv2.IMREAD_UNCHANGED) / 255.\n  snow_layer = snow_layer[..., np.newaxis]\n\n  x = c[6] * x + (1 - c[6]) * np.maximum(\n      x,\n      cv2.cvtColor(x, cv2.COLOR_RGB2GRAY).reshape(224, 224, 1) * 1.5 + 0.5)\n  x = np.clip(x + snow_layer + np.rot90(snow_layer, k=2), 0, 1) * 255\n\n  return around_and_astype(x)\n\n\ndef motion_blur(x, severity=1):\n  """"""Apply motion blur to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied motion blur.\n  """"""\n  c = [(10, 3), (15, 5), (15, 8), (15, 12), (20, 15)][severity - 1]\n\n  x = tfds.core.lazy_imports.PIL_Image.fromarray(x.astype(np.uint8))\n\n  with tempfile.NamedTemporaryFile() as im_input:\n    with tempfile.NamedTemporaryFile() as im_output:\n      x.save(im_input.name, format=\'PNG\')\n\n      convert_bin = _imagemagick_bin()\n      radius = c[0]\n      sigma = c[1]\n      angle = np.random.uniform(-45, -45)\n\n      subprocess.check_output([\n          convert_bin, \'-motion-blur\', \'{}x{}+{}\'.format(radius, sigma, angle),\n          im_input.name, im_output.name\n      ])\n\n      with open(im_output.name, \'rb\') as f:\n        output = f.read()\n\n  x = tfds.core.lazy_imports.cv2.imdecode(\n      np.fromstring(output, np.uint8),\n      tfds.core.lazy_imports.cv2.IMREAD_UNCHANGED)\n\n  if x.shape != (224, 224):\n    x = np.clip(x[..., [2, 1, 0]], 0, 255)  # BGR to RGB\n  else:  # greyscale to RGB\n    x = np.clip(np.array([x, x, x]).transpose((1, 2, 0)), 0, 255)\n\n  return around_and_astype(x)\n\n\n# /////////////// Extra Corruptions ///////////////\n\n\ndef gaussian_blur(x, severity=1):\n  """"""Apply gaussian blur to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied gaussian blur.\n  """"""\n  c = [1, 2, 3, 4, 6][severity - 1]\n\n  x = tfds.core.lazy_imports.skimage.filters.gaussian(\n      np.array(x) / 255., sigma=c, multichannel=True)\n  x = np.clip(x, 0, 1) * 255\n\n  return around_and_astype(x)\n\n\ndef saturate(x, severity=1):\n  """"""Increase saturation of images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied saturation.\n  """"""\n  c = [(0.3, 0), (0.1, 0), (2, 0), (5, 0.1), (20, 0.2)][severity - 1]\n\n  x = np.array(x) / 255.\n  x = tfds.core.lazy_imports.skimage.color.rgb2hsv(x)\n  x[:, :, 1] = np.clip(x[:, :, 1] * c[0] + c[1], 0, 1)\n  x = tfds.core.lazy_imports.skimage.color.hsv2rgb(x)\n  x = np.clip(x, 0, 1) * 255\n\n  return around_and_astype(x)\n\n\ndef spatter(x, severity=1):\n  """"""Apply spatter to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied spatter.\n  """"""\n  cv2 = tfds.core.lazy_imports.cv2\n  skimage = tfds.core.lazy_imports.skimage\n  c = [(0.65, 0.3, 4, 0.69, 0.6, 0), (0.65, 0.3, 3, 0.68, 0.6, 0),\n       (0.65, 0.3, 2, 0.68, 0.5, 0), (0.65, 0.3, 1, 0.65, 1.5, 1),\n       (0.67, 0.4, 1, 0.65, 1.5, 1)][severity - 1]\n  x = np.array(x, dtype=np.float32) / 255.\n\n  liquid_layer = np.random.normal(size=x.shape[:2], loc=c[0], scale=c[1])\n\n  liquid_layer = skimage.filters.gaussian(liquid_layer, sigma=c[2])\n  liquid_layer[liquid_layer < c[3]] = 0\n  if c[5] == 0:\n    liquid_layer = (liquid_layer * 255).astype(np.uint8)\n    dist = 255 - cv2.Canny(liquid_layer, 50, 150)\n    dist = cv2.distanceTransform(dist, cv2.DIST_L2, 5)\n    _, dist = cv2.threshold(dist, 20, 20, cv2.THRESH_TRUNC)\n    dist = cv2.blur(dist, (3, 3)).astype(np.uint8)\n    dist = cv2.equalizeHist(dist)\n    #     ker = np.array([[-1,-2,-3],[-2,0,0],[-3,0,1]], dtype=np.float32)\n    #     ker -= np.mean(ker)\n    ker = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n    dist = cv2.filter2D(dist, cv2.CVX_8U, ker)\n    dist = cv2.blur(dist, (3, 3)).astype(np.float32)\n\n    m = cv2.cvtColor(liquid_layer * dist, cv2.COLOR_GRAY2BGRA)\n    m /= np.max(m, axis=(0, 1))\n    m *= c[4]\n\n    # water is pale turqouise\n    color = np.concatenate(\n        (175 / 255. * np.ones_like(m[..., :1]), 238 / 255. *\n         np.ones_like(m[..., :1]), 238 / 255. * np.ones_like(m[..., :1])),\n        axis=2)\n\n    color = cv2.cvtColor(color, cv2.COLOR_BGR2BGRA)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2BGRA)\n\n    x = cv2.cvtColor(np.clip(x + m * color, 0, 1), cv2.COLOR_BGRA2BGR) * 255\n  else:\n    m = np.where(liquid_layer > c[3], 1, 0)\n    m = skimage.filters.gaussian(m.astype(np.float32), sigma=c[4])\n    m[m < 0.8] = 0\n    #         m = np.abs(m) ** (1/c[4])\n\n    # mud brown\n    color = np.concatenate(\n        (63 / 255. * np.ones_like(x[..., :1]), 42 / 255. *\n         np.ones_like(x[..., :1]), 20 / 255. * np.ones_like(x[..., :1])),\n        axis=2)\n\n    color *= m[..., np.newaxis]\n    x *= (1 - m[..., np.newaxis])\n\n    x = np.clip(x + color, 0, 1) * 255\n  return around_and_astype(x)\n\n\ndef speckle_noise(x, severity=1):\n  """"""Apply speckle noise to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Applied speckle noise.\n  """"""\n  c = [.15, .2, 0.35, 0.45, 0.6][severity - 1]\n\n  x = np.array(x) / 255.\n  x = np.clip(x + x * np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n  return around_and_astype(x)\n'"
tensorflow_datasets/image_classification/cycle_gan.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CycleGAN dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n# From https://arxiv.org/abs/1703.10593\n_CITATION = """"""\\\n@article{DBLP:journals/corr/ZhuPIE17,\n  author    = {Jun{-}Yan Zhu and\n               Taesung Park and\n               Phillip Isola and\n               Alexei A. Efros},\n  title     = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial\n               Networks},\n  journal   = {CoRR},\n  volume    = {abs/1703.10593},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1703.10593},\n  archivePrefix = {arXiv},\n  eprint    = {1703.10593},\n  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuPIE17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DL_URL = ""https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/""\n\n# ""ae_photos"" : Not added because trainA and trainB are missing.\n_DATA_OPTIONS = [\n    ""apple2orange"", ""summer2winter_yosemite"", ""horse2zebra"", ""monet2photo"",\n    ""cezanne2photo"", ""ukiyoe2photo"", ""vangogh2photo"", ""maps"", ""cityscapes"",\n    ""facades"", ""iphone2dslr_flower""\n]\n\n_DL_URLS = {name: _DL_URL + name + "".zip"" for name in _DATA_OPTIONS}\n\n\nclass CycleGANConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CycleGAN.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, data=None, **kwargs):\n    """"""Constructs a CycleGANConfig.\n\n    Args:\n      data: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if data not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n\n    super(CycleGANConfig, self).__init__(**kwargs)\n    self.data = data\n\n\nclass CycleGAN(tfds.core.GeneratorBasedBuilder):\n  """"""CycleGAN dataset.""""""\n\n  BUILDER_CONFIGS = [\n      CycleGANConfig(  # pylint: disable=g-complex-comprehension\n          name=config_name,\n          description=(""A dataset consisting of images from two classes A and ""\n                       ""B (For example: horses/zebras, apple/orange,...)""),\n          version=tfds.core.Version(\n              ""2.0.0"",\n              ""New split API (https://tensorflow.org/datasets/splits)""),\n          data=config_name,\n      ) for config_name in _DATA_OPTIONS\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=self.builder_config.description,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names=[""A"", ""B""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=\n        ""https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    url = _DL_URLS[self.builder_config.name]\n    data_dirs = dl_manager.download_and_extract(url)\n\n    path_to_dataset = os.path.join(data_dirs, tf.io.gfile.listdir(data_dirs)[0])\n\n    train_a_path = os.path.join(path_to_dataset, ""trainA"")\n    train_b_path = os.path.join(path_to_dataset, ""trainB"")\n    test_a_path = os.path.join(path_to_dataset, ""testA"")\n    test_b_path = os.path.join(path_to_dataset, ""testB"")\n\n    return [\n        tfds.core.SplitGenerator(\n            name=""trainA"",\n            gen_kwargs={\n                ""path"": train_a_path,\n                ""label"": ""A"",\n            }),\n        tfds.core.SplitGenerator(\n            name=""trainB"",\n            gen_kwargs={\n                ""path"": train_b_path,\n                ""label"": ""B"",\n            }),\n        tfds.core.SplitGenerator(\n            name=""testA"",\n            gen_kwargs={\n                ""path"": test_a_path,\n                ""label"": ""A"",\n            }),\n        tfds.core.SplitGenerator(\n            name=""testB"",\n            gen_kwargs={\n                ""path"": test_b_path,\n                ""label"": ""B"",\n            }),\n    ]\n\n  def _generate_examples(self, path, label):\n    images = tf.io.gfile.listdir(path)\n\n    for image in images:\n      record = {\n          ""image"": os.path.join(path, image),\n          ""label"": label,\n      }\n      yield image, record\n'"
tensorflow_datasets/image_classification/cycle_gan_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cycle_gan dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import cycle_gan\n\n\nclass CycleGANTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cycle_gan.CycleGAN\n  BUILDER_CONFIG_NAMES_TO_TEST = [""horse2zebra""]\n  SPLITS = {\n      ""trainA"": 2,\n      ""testA"": 2,\n      ""trainB"": 2,\n      ""testB"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/deep_weeds.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for DeepWeeds dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = ""https://nextcloud.qriscloud.org.au/index.php/s/a3KxPawpqkiorST/download""\n_URL_LABELS = ""https://raw.githubusercontent.com/AlexOlsen/DeepWeeds/master/labels/labels.csv""\n\n_DESCRIPTION = (\n    """"""The DeepWeeds dataset consists of 17,509 images capturing eight different weed species native to Australia """"""\n    """"""in situ with neighbouring flora.The selected weed species are local to pastoral grasslands across the state of Queensland.""""""\n    """"""The images were collected from weed infestations at the following sites across Queensland: ""Black River"", ""Charters Towers"", """"""\n    """""" ""Cluden"", ""Douglas"", ""Hervey Range"", ""Kelso"", ""McKinlay"" and ""Paluma"".""""""\n)\n\n_IMAGE_SHAPE = (256, 256, 3)\n\n_CITATION = """"""\\\n @article{DeepWeeds2019,\n  author = {Alex Olsen and\n    Dmitry A. Konovalov and\n    Bronson Philippa and\n    Peter Ridd and\n    Jake C. Wood and\n    Jamie Johns and\n    Wesley Banks and\n    Benjamin Girgenti and\n    Owen Kenny and\n    James Whinney and\n    Brendan Calvert and\n    Mostafa {Rahimi Azghadi} and\n    Ronald D. White},\n  title = {{DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning}},\n  journal = {Scientific Reports},\n  year = 2019,\n  number = 2058,\n  month = 2,\n  volume = 9,\n  issue = 1,\n  day = 14,\n  url = ""https://doi.org/10.1038/s41598-018-38343-3"",\n  doi = ""10.1038/s41598-018-38343-3""\n}\n""""""\n\n\nclass DeepWeeds(tfds.core.GeneratorBasedBuilder):\n  """"""DeepWeeds Image Dataset Class.""""""\n\n  VERSION = tfds.core.Version(""2.0.0"", ""Fixes wrong labels in V1."")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(\n          ""1.0.0"",\n          tfds_version_to_prepare=""c28a63fa9d9fb9ba3cced7052ea243e8884f9bf1""),\n  ]\n\n  def _info(self):\n    """"""Define Dataset Info.""""""\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(num_classes=9),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/AlexOlsen/DeepWeeds"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Define Splits.""""""\n    # The file is in ZIP format, but URL doesn\'t mention it.\n    paths = dl_manager.download_and_extract({\n        ""image"": tfds.download.Resource(\n            url=_URL,\n            extract_method=tfds.download.ExtractMethod.ZIP),\n        ""label"": _URL_LABELS})\n\n    return [\n        tfds.core.SplitGenerator(\n            name=""train"",\n            gen_kwargs={\n                ""data_dir_path"": paths[""image""],\n                ""label_path"": paths[""label""],\n            },\n        ),\n    ]\n\n  def _generate_examples(self, data_dir_path, label_path):\n    """"""Generate images and labels for splits.""""""\n\n    with tf.io.gfile.GFile(label_path) as f:\n      # Convert to list to reuse the iterator multiple times\n      reader = list(csv.DictReader(f))\n\n    # Extract the mapping int -> str and save the label name string to the\n    # feature\n    label_id_to_name = {int(row[""Label""]): row[""Species""] for row in reader}\n    self.info.features[""label""].names = [\n        v for _, v in sorted(label_id_to_name.items())\n    ]\n\n    filename_to_label = {row[""Filename""]: row[""Species""] for row in reader}\n    for file_name in tf.io.gfile.listdir(data_dir_path):\n      yield file_name, {\n          ""image"": os.path.join(data_dir_path, file_name),\n          ""label"": filename_to_label[file_name]\n      }\n'"
tensorflow_datasets/image_classification/deep_weeds_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets.image_classification import deep_weeds\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass DeepWeedsTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = deep_weeds.DeepWeeds\n  SPLITS = {\n      ""train"": 9,\n  }\n  DL_EXTRACT_RESULT = {\n      ""image"": ""images"",\n      ""label"": ""labels.csv"",\n  }\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/diabetic_retinopathy_detection.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""https://www.kaggle.com/c/diabetic-retinopathy-detection/data.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport io\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\\\n@ONLINE {kaggle-diabetic-retinopathy,\n    author = ""Kaggle and EyePacs"",\n    title  = ""Kaggle Diabetic Retinopathy Detection"",\n    month  = ""jul"",\n    year   = ""2015"",\n    url    = ""https://www.kaggle.com/c/diabetic-retinopathy-detection/data""\n}\n""""""\n_URL_TEST_LABELS = ""https://storage.googleapis.com/kaggle-forum-message-attachments/90528/2877/retinopathy_solution.csv""\n_BTGRAHAM_DESCRIPTION_PATTERN = (\n    ""Images have been preprocessed as the winner of the Kaggle competition did ""\n    ""in 2015: first they are resized so that the radius of an eyeball is ""\n    ""{} pixels, then they are cropped to 90% of the radius, and finally they ""\n    ""are encoded with 72 JPEG quality."")\n\n\nclass DiabeticRetinopathyDetectionConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for DiabeticRetinopathyDetection.""""""\n\n  def __init__(self, target_pixels=None, **kwargs):\n    """"""BuilderConfig for DiabeticRetinopathyDetection.\n\n    Args:\n      target_pixels: If given, rescale the images so that the total number of\n        pixels is roughly this value.\n      **kwargs: keyword arguments forward to super.\n    """"""\n    super(DiabeticRetinopathyDetectionConfig, self).__init__(\n        version=tfds.core.Version(\n            ""3.0.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self._target_pixels = target_pixels\n\n  @property\n  def target_pixels(self):\n    return self._target_pixels\n\n\nclass DiabeticRetinopathyDetection(tfds.core.GeneratorBasedBuilder):\n  """"""Diabetic retinopathy detection.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  You have to download this dataset from Kaggle.\n  https://www.kaggle.com/c/diabetic-retinopathy-detection/data\n  After downloading, unpack the test.zip file into test/ directory in manual_dir\n  and sample.zip to sample/. Also unpack the sampleSubmissions.csv and\n  trainLabels.csv.\n  """"""\n\n  BUILDER_CONFIGS = [\n      DiabeticRetinopathyDetectionConfig(\n          name=""original"",\n          description=""Images at their original resolution and quality.""),\n      DiabeticRetinopathyDetectionConfig(\n          name=""1M"",\n          description=""Images have roughly 1,000,000 pixels, at 72 quality."",\n          target_pixels=1000000),\n      DiabeticRetinopathyDetectionConfig(\n          name=""250K"",\n          description=""Images have roughly 250,000 pixels, at 72 quality."",\n          target_pixels=250000),\n      DiabeticRetinopathyDetectionConfig(\n          name=""btgraham-300"",\n          description=_BTGRAHAM_DESCRIPTION_PATTERN.format(300),\n          target_pixels=300),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""A large set of high-resolution retina images taken under ""\n        ""a variety of imaging conditions."",\n        features=tfds.features.FeaturesDict({\n            ""name"": tfds.features.Text(),  # patient ID + eye. eg: ""4_left"".\n            ""image"": tfds.features.Image(),\n            # From 0 (no DR - saine) to 4 (Proliferative DR). -1 means no label.\n            ""label"": tfds.features.ClassLabel(num_classes=5),\n        }),\n        homepage=""https://www.kaggle.com/c/diabetic-retinopathy-detection/data"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    # TODO(pierrot): implement download using kaggle API.\n    # TODO(pierrot): implement extraction of multiple files archives.\n    path = dl_manager.manual_dir\n    test_labels_path = dl_manager.download(_URL_TEST_LABELS)\n    if tf.io.gfile.isdir(test_labels_path):\n      # While testing: download() returns the dir containing the tests files.\n      test_labels_path = os.path.join(test_labels_path,\n                                      ""retinopathy_solution.csv"")\n    return [\n        tfds.core.SplitGenerator(\n            name=""sample"",  # 10 images, to do quicktests using dataset.\n            gen_kwargs={\n                ""images_dir_path"": os.path.join(path, ""sample""),\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""train"",\n            gen_kwargs={\n                ""images_dir_path"": os.path.join(path, ""train""),\n                ""csv_path"": os.path.join(path, ""trainLabels.csv""),\n                # CSV of the train split does not have the ""Usage"" column.\n                # 35,126 examples.\n                ""csv_usage"": None,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""validation"",\n            gen_kwargs={\n                ""images_dir_path"": os.path.join(path, ""test""),\n                ""csv_path"": test_labels_path,\n                # Validation split corresponds to the public leaderboard data.\n                # 10,906 examples.\n                ""csv_usage"": ""Public"",\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""test"",\n            gen_kwargs={\n                ""images_dir_path"": os.path.join(path, ""test""),\n                ""csv_path"": test_labels_path,\n                # Test split corresponds to the public leaderboard data.\n                # 42,670 examples.\n                ""csv_usage"": ""Private"",\n            },\n        ),\n    ]\n\n  def _generate_examples(self, images_dir_path, csv_path=None, csv_usage=None):\n    """"""Yields Example instances from given CSV.\n\n    Args:\n      images_dir_path: path to dir in which images are stored.\n      csv_path: optional, path to csv file with two columns: name of image and\n        label. If not provided, just scan image directory, don\'t set labels.\n      csv_usage: optional, subset of examples from the csv file to use based on\n        the ""Usage"" column from the csv.\n    """"""\n    if csv_path:\n      with tf.io.gfile.GFile(csv_path) as csv_f:\n        reader = csv.DictReader(csv_f)\n        data = [(row[""image""], int(row[""level""]))\n                for row in reader\n                if csv_usage is None or row[""Usage""] == csv_usage]\n    else:\n      data = [(fname[:-5], -1)\n              for fname in tf.io.gfile.listdir(images_dir_path)\n              if fname.endswith("".jpeg"")]\n    for name, label in data:\n      image_filepath = ""%s/%s.jpeg"" % (images_dir_path, name)\n      record = {\n          ""name"": name,\n          ""image"": self._process_image(image_filepath),\n          ""label"": label,\n      }\n      yield name, record\n\n  def _process_image(self, filepath):\n    with tf.io.gfile.GFile(filepath, mode=""rb"") as image_fobj:\n      if self.builder_config.name.startswith(""btgraham""):\n        return _btgraham_processing(\n            image_fobj=image_fobj,\n            filepath=filepath,\n            target_pixels=self.builder_config.target_pixels,\n            crop_to_radius=True)\n      else:\n        return _resize_image_if_necessary(\n            image_fobj=image_fobj,\n            target_pixels=self.builder_config.target_pixels)\n\n\ndef _resize_image_if_necessary(image_fobj, target_pixels=None):\n  """"""Resize an image to have (roughly) the given number of target pixels.\n\n  Args:\n    image_fobj: File object containing the original image.\n    target_pixels: If given, number of pixels that the image must have.\n\n  Returns:\n    A file object.\n  """"""\n  if target_pixels is None:\n    return image_fobj\n\n  cv2 = tfds.core.lazy_imports.cv2\n  # Decode image using OpenCV2.\n  image = cv2.imdecode(\n      np.fromstring(image_fobj.read(), dtype=np.uint8), flags=3)\n  # Get image height and width.\n  height, width, _ = image.shape\n  actual_pixels = height * width\n  if actual_pixels > target_pixels:\n    factor = np.sqrt(target_pixels / actual_pixels)\n    image = cv2.resize(image, dsize=None, fx=factor, fy=factor)\n  # Encode the image with quality=72 and store it in a BytesIO object.\n  _, buff = cv2.imencode("".jpg"", image, [int(cv2.IMWRITE_JPEG_QUALITY), 72])\n  return io.BytesIO(buff.tostring())\n\n\ndef _btgraham_processing(\n    image_fobj, filepath, target_pixels, crop_to_radius=False):\n  """"""Process an image as the winner of the 2015 Kaggle competition.\n\n  Args:\n    image_fobj: File object containing the original image.\n    filepath: Filepath of the image, for logging purposes only.\n    target_pixels: The number of target pixels for the radius of the image.\n    crop_to_radius: If True, crop the borders of the image to remove gray areas.\n\n  Returns:\n    A file object.\n  """"""\n  cv2 = tfds.core.lazy_imports.cv2\n  # Decode image using OpenCV2.\n  image = cv2.imdecode(\n      np.fromstring(image_fobj.read(), dtype=np.uint8), flags=3)\n  # Process the image.\n  image = _scale_radius_size(image, filepath, target_radius_size=target_pixels)\n  image = _subtract_local_average(image, target_radius_size=target_pixels)\n  image = _mask_and_crop_to_radius(\n      image, target_radius_size=target_pixels, radius_mask_ratio=0.9,\n      crop_to_radius=crop_to_radius)\n  # Encode the image with quality=72 and store it in a BytesIO object.\n  _, buff = cv2.imencode("".jpg"", image, [int(cv2.IMWRITE_JPEG_QUALITY), 72])\n  return io.BytesIO(buff.tostring())\n\n\ndef _scale_radius_size(image, filepath, target_radius_size):\n  """"""Scale the input image so that the radius of the eyeball is the given.""""""\n  cv2 = tfds.core.lazy_imports.cv2\n  x = image[image.shape[0] // 2, :, :].sum(axis=1)\n  r = (x > x.mean() / 10.0).sum() / 2.0\n  if r < 1.0:\n    # Some images in the dataset are corrupted, causing the radius heuristic to\n    # fail. In these cases, just assume that the radius is the height of the\n    # original image.\n    logging.info(""Radius of image \\""%s\\"" could not be determined."", filepath)\n    r = image.shape[0] / 2.0\n  s = target_radius_size / r\n  return cv2.resize(image, dsize=None, fx=s, fy=s)\n\n\ndef _subtract_local_average(image, target_radius_size):\n  cv2 = tfds.core.lazy_imports.cv2\n  image_blurred = cv2.GaussianBlur(image, (0, 0), target_radius_size / 30)\n  image = cv2.addWeighted(image, 4, image_blurred, -4, 128)\n  return image\n\n\ndef _mask_and_crop_to_radius(\n    image, target_radius_size, radius_mask_ratio=0.9, crop_to_radius=False):\n  """"""Mask and crop image to the given radius ratio.""""""\n  cv2 = tfds.core.lazy_imports.cv2\n  mask = np.zeros(image.shape)\n  center = (image.shape[1]//2, image.shape[0]//2)\n  radius = int(target_radius_size * radius_mask_ratio)\n  cv2.circle(mask, center=center, radius=radius, color=(1, 1, 1), thickness=-1)\n  image = image * mask + (1 - mask) * 128\n  if crop_to_radius:\n    x_max = min(image.shape[1] // 2 + radius, image.shape[1])\n    x_min = max(image.shape[1] // 2 - radius, 0)\n    y_max = min(image.shape[0] // 2 + radius, image.shape[0])\n    y_min = max(image.shape[0] // 2 - radius, 0)\n    image = image[y_min:y_max, x_min:x_max, :]\n  return image\n'"
tensorflow_datasets/image_classification/diabetic_retinopathy_detection_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for diabetic_retinopathy_detection dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import diabetic_retinopathy_detection\n\n\nclass DiabeticRetinopathyDetectionTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = diabetic_retinopathy_detection.DiabeticRetinopathyDetection\n  SPLITS = {  # Expected number of examples on each split.\n      ""sample"": 4,\n      ""train"": 12,\n      ""validation"": 6,\n      ""test"": 6,\n  }\n  OVERLAPPING_SPLITS = [""sample""]  # contains examples from other examples\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/dmlab.py,12,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dmlab dataset.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\n\nimport os\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_URL = ""https://storage.googleapis.com/akolesnikov-dmlab-tfds/dmlab.tar.gz""\n\n\nclass Dmlab(tfds.core.GeneratorBasedBuilder):\n  """"""Dmlab dataset.""""""\n\n  VERSION = tfds.core.Version(""2.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(r""""""\n        The Dmlab dataset contains frames observed by the agent acting in the\n        DeepMind Lab environment, which are annotated by the distance between\n        the agent and various objects present in the environment. The goal is to\n        is to evaluate the ability of a visual model to reason about distances\n        from the visual input in 3D environments. The Dmlab dataset consists of\n        360x480 color images in 6 classes. The classes are\n        {close, far, very far} x {positive reward, negative reward}\n        respectively.""""""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=(360, 480, 3),\n                                         encoding_format=""jpeg""),\n            ""filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(num_classes=6),\n        }),\n        homepage=""https://github.com/google-research/task_adaptation"",\n        citation=r""""""@article{zhai2019visual,\n        title={The Visual Task Adaptation Benchmark},\n        author={Xiaohua Zhai and Joan Puigcerver and Alexander Kolesnikov and\n               Pierre Ruyssen and Carlos Riquelme and Mario Lucic and\n               Josip Djolonga and Andre Susano Pinto and Maxim Neumann and\n               Alexey Dosovitskiy and Lucas Beyer and Olivier Bachem and\n               Michael Tschannen and Marcin Michalski and Olivier Bousquet and\n               Sylvain Gelly and Neil Houlsby},\n                              year={2019},\n                              eprint={1910.04867},\n                              archivePrefix={arXiv},\n                              primaryClass={cs.CV},\n                              url = {https://arxiv.org/abs/1910.04867}\n                          }"""""",\n        supervised_keys=(""image"", ""label"")\n    )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download_and_extract(_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""images_dir_path"": path,\n                ""split_name"": ""train"",\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""images_dir_path"": path,\n                ""split_name"": ""validation"",\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""images_dir_path"": path,\n                ""split_name"": ""test"",\n            }),\n    ]\n\n  def _parse_single_image(self, example_proto):\n    """"""Parses single video from the input tfrecords.\n\n    Args:\n      example_proto: tfExample proto with a single video.\n\n    Returns:\n      dict with all frames, positions and actions.\n    """"""\n\n    feature_map = {\n        ""image"": tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n        ""filename"": tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n        ""label"": tf.io.FixedLenFeature(shape=[], dtype=tf.int64),\n    }\n\n    parse_single = tf.io.parse_single_example(example_proto, feature_map)\n\n    return parse_single\n\n  def _generate_examples(self, images_dir_path, split_name):\n    path_glob = os.path.join(images_dir_path,\n                             ""dmlab-{}.tfrecord*"".format(split_name))\n    files = tf.io.gfile.glob(path_glob)\n\n    logging.info(""Reading data from %s."", "","".join(files))\n    with tf.Graph().as_default():\n      ds = tf.data.TFRecordDataset(files)\n      ds = ds.map(\n          self._parse_single_image,\n          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n      iterator = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\n      with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.global_variables_initializer())\n        try:\n          while True:\n            result = sess.run(iterator)\n            yield result[""filename""], {\n                ""image"": io.BytesIO(result[""image""]),\n                ""filename"": result[""filename""],\n                ""label"": result[""label""],\n            }\n\n        except tf.errors.OutOfRangeError:\n          return\n'"
tensorflow_datasets/image_classification/dmlab_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for DMlab dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import dmlab\n\n\nclass DmlabDatasetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = dmlab.Dmlab\n\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 2,\n      ""validation"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/dtd.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Describable Textures Dataset (DTD).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{cimpoi14describing,\nAuthor    = {M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and A. Vedaldi},\nTitle     = {Describing Textures in the Wild},\nBooktitle = {Proceedings of the {IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})},\nYear      = {2014}}\n""""""\n_DESCRIPTION = """"""\\\nThe Describable Textures Dataset (DTD) is an evolving collection of textural\nimages in the wild, annotated with a series of human-centric attributes,\ninspired by the perceptual properties of textures. This data is made available\nto the computer vision community for research purposes.\n\nThe ""label"" of each example is its ""key attribute"" (see the official website).\nThe official release of the dataset defines a 10-fold cross-validation\npartition. Our TRAIN/TEST/VALIDATION splits are those of the first fold.\n""""""\n_URL = ""https://www.robots.ox.ac.uk/~vgg/data/dtd/index.html""\n_DATA_URL = ""https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz""\n\n\nclass Dtd(tfds.core.GeneratorBasedBuilder):\n  """"""Describable Textures Dataset (DTD).""""""\n\n  VERSION = tfds.core.Version(""3.0.1"")\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(\n        os.path.join(""image_classification"", ""dtd_key_attributes.txt""))\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""file_name"": tfds.features.Text(),\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names_file=names_file),\n        }),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    # Note: The file extension is .tar.gz, but it is actually a .tar file.\n    data_path = dl_manager.download_and_extract(\n        tfds.download.Resource(\n            url=_DATA_URL, extract_method=tfds.download.ExtractMethod.TAR))\n    # Note: DTD defines 10-fold CV partitions. Our TRAIN/TEST/VALIDATION are\n    # those of the first fold.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(data_path=data_path, split_name=""train1"")),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(data_path=data_path, split_name=""test1"")),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(data_path=data_path, split_name=""val1"")),\n    ]\n\n  def _generate_examples(self, data_path, split_name):\n    with tf.io.gfile.GFile(\n        os.path.join(data_path, ""dtd"", ""labels"", split_name + "".txt""),\n        ""r"") as split_file:\n      for line in split_file:\n        fname = line.strip()\n        label = os.path.split(fname)[0]\n        record = {\n            ""file_name"": fname,\n            ""image"": os.path.join(data_path, ""dtd"", ""images"", fname),\n            ""label"": label,\n        }\n        yield fname, record\n'"
tensorflow_datasets/image_classification/dtd_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for DTD image data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import dtd\n\n\nclass DtdTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = dtd.Dtd\n  SPLITS = {\n      \'test\': 3,\n      \'train\': 2,\n      \'validation\': 1,\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/eurosat.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Eurosat remote sensing benchmarking dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{helber2017eurosat,\n    title={EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},\n    author={Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth},\n    year={2017},\n    eprint={1709.00029},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nEuroSAT dataset is based on Sentinel-2 satellite images covering 13 spectral\nbands and consisting of 10 classes with 27000 labeled and\ngeo-referenced samples.\n\nTwo datasets are offered:\n- rgb: Contains only the optical R, G, B frequency bands encoded as JPEG image.\n- all: Contains all 13 bands in the original value range (float32).\n\nURL: https://github.com/phelber/eurosat\n""""""\n\n_LABELS = [\n    \'AnnualCrop\', \'Forest\', \'HerbaceousVegetation\', \'Highway\', \'Industrial\',\n    \'Pasture\', \'PermanentCrop\', \'Residential\', \'River\', \'SeaLake\'\n]\n\n_URL = \'https://github.com/phelber/eurosat\'\n\n_DATA_OPTIONS = [\'rgb\', \'all\']\n\n\nclass EurosatConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for eurosat.""""""\n\n  def __init__(self, selection=None, download_url=None, subdir=None, **kwargs):\n    """"""Constructs a EurosatConfig.\n\n    Args:\n      selection: `str`, one of `_DATA_OPTIONS`.\n      download_url: `str`, download URL to the zip file.\n      subdir: `str`, subdir within the zip file.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if selection not in _DATA_OPTIONS:\n      raise ValueError(\'selection must be one of %s\' % _DATA_OPTIONS)\n\n    super(EurosatConfig, self).__init__(version=tfds.core.Version(\'2.0.0\'),\n                                        **kwargs)\n    self.selection = selection\n    self.download_url = download_url\n    self.subdir = subdir\n\n\nclass Eurosat(tfds.core.GeneratorBasedBuilder):\n  """"""Eurosat remote sensing benchmarking dataset.""""""\n\n  BUILDER_CONFIGS = [\n      EurosatConfig(\n          selection=\'rgb\',\n          name=\'rgb\',\n          download_url=\'http://madm.dfki.de/files/sentinel/EuroSAT.zip\',\n          subdir=\'2750\',\n          description=\'Sentinel-2 RGB channels\'),\n      EurosatConfig(\n          selection=\'all\',\n          name=\'all\',\n          download_url=\'http://madm.dfki.de/files/sentinel/EuroSATallBands.zip\',\n          subdir=\'ds/images/remote_sensing/otherDatasets/sentinel_2/tif\',\n          description=\'13 Sentinel-2 channels\'),\n  ]\n\n  def _info(self):\n    if self.builder_config.selection == \'rgb\':\n      features = tfds.features.FeaturesDict({\n          \'image\': tfds.features.Image(shape=[64, 64, 3]),\n          \'label\': tfds.features.ClassLabel(names=_LABELS),\n          \'filename\': tfds.features.Text(),\n      })\n      supervised_keys = (\'image\', \'label\')\n    elif self.builder_config.selection == \'all\':\n      features = tfds.features.FeaturesDict({\n          \'sentinel2\':\n              tfds.features.Tensor(shape=[64, 64, 13], dtype=tf.float32),\n          \'label\':\n              tfds.features.ClassLabel(names=_LABELS),\n          \'filename\':\n              tfds.features.Text(),\n      })\n      supervised_keys = (\'sentinel2\', \'label\')\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=features,\n        supervised_keys=supervised_keys,\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.download_and_extract(self.builder_config.download_url)\n    path = os.path.join(path, self.builder_config.subdir)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'path\': path,\n                \'selection\': self.builder_config.selection\n            },\n        ),\n    ]\n\n  def _generate_examples(self, path, selection):\n    """"""Yields examples.""""""\n    for filename in tf.io.gfile.glob(os.path.join(path, \'*\', \'*\')):\n      label = os.path.split(filename)[-1].split(\'_\')[0]\n      if selection == \'rgb\':\n        record = {\n            \'image\': filename,\n            \'label\': label,\n            \'filename\': os.path.basename(filename)\n        }\n      else:\n        record = {\n            \'sentinel2\': _extract_channels(filename),\n            \'label\': label,\n            \'filename\': os.path.basename(filename)\n        }\n      yield filename, record\n\n\ndef _extract_channels(filename):\n  with tf.io.gfile.GFile(filename, \'rb\') as f:\n    arr = tfds.core.lazy_imports.skimage.external.tifffile.imread(\n        io.BytesIO(f.read()))\n\n  arr = arr.astype(\'float32\')\n  return arr\n'"
tensorflow_datasets/image_classification/eurosat_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Eurosat data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import eurosat\n\n\nclass EurosatTest(testing.DatasetBuilderTestCase):\n  # TODO(mnn): Re-enable Py3 test (b/129964829)\n  # None implies testing all BUILDER_CONFIGS, while [] implies no tests.\n  BUILDER_CONFIG_NAMES_TO_TEST = None if six.PY2 else []\n\n\n  DATASET_CLASS = eurosat.Eurosat\n  SPLITS = {\n      ""train"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/flowers.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Flowers dataset.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@ONLINE {tfflowers,\nauthor = ""The TensorFlow Team"",\ntitle = ""Flowers"",\nmonth = ""jan"",\nyear = ""2019"",\nurl = ""http://download.tensorflow.org/example_images/flower_photos.tgz"" }\n""""""\n\n_URL = ""http://download.tensorflow.org/example_images/flower_photos.tgz""\n\n\nclass TFFlowers(tfds.core.GeneratorBasedBuilder):\n  """"""Flowers dataset.""""""\n\n  VERSION = tfds.core.Version(""3.0.1"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""A large set of images of flowers"",\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(\n                names=[""dandelion"", ""daisy"", ""tulips"", ""sunflowers"", ""roses""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://www.tensorflow.org/tutorials/load_data/images"",\n        citation=_CITATION\n        )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""images_dir_path"": dl_manager.iter_archive(path)\n            }),\n    ]\n\n  def _generate_examples(self, images_dir_path):\n    """"""Generate flower images and labels given the image directory path.\n\n    Args:\n      images_dir_path: path to the directory where the images are stored.\n\n    Yields:\n      The image path and its corresponding label.\n    """"""\n    for fname, fobj in images_dir_path:\n      if fname.endswith("".jpg""):\n        image_dir, image_file = os.path.split(fname)\n        d = os.path.basename(image_dir)\n        record = {""image"": fobj, ""label"": d.lower()}\n        yield ""%s/%s"" % (d, image_file), record\n'"
tensorflow_datasets/image_classification/flowers_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for flowers data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import flowers\n\n\nclass TFFlowersTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = flowers.TFFlowers\n\n  SPLITS = {\n      \'train\': 5\n  }\n\n  DL_DOWNLOAD_RESULT = \'flower_photos.tgz\'\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/food101.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for Food-101 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_BASE_URL = ""http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz""\n\n_DESCRIPTION = (\n    ""This dataset consists of 101 food categories, with 101\'000 images. For ""\n    ""each class, 250 manually reviewed test images are provided as well as 750""\n    "" training images. On purpose, the training images were not cleaned, and ""\n    ""thus still contain some amount of noise. This comes mostly in the form of""\n    "" intense colors and sometimes wrong labels. All images were rescaled to ""\n    ""have a maximum side length of 512 pixels."")\n\n_LABELS_FNAME = ""image_classification/food-101_classes.txt""\n\n_CITATION = """"""\\\n @inproceedings{bossard14,\n  title = {Food-101 -- Mining Discriminative Components with Random Forests},\n  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},\n  booktitle = {European Conference on Computer Vision},\n  year = {2014}\n}\n""""""\n\n\nclass Food101(tfds.core.GeneratorBasedBuilder):\n  """"""Food-101 Images dataset.""""""\n\n  VERSION = tfds.core.Version(""2.0.0"")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(\n          ""1.0.0"",\n          tfds_version_to_prepare=""8cea22f06d74d5848608fe7ac6d6faac7bc05b55""),\n      tfds.core.Version(""2.1.0""),\n  ]\n\n  def _info(self):\n    """"""Define Dataset Info.""""""\n\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    features_dict = {\n        ""image"": tfds.features.Image(),\n        ""label"": tfds.features.ClassLabel(names_file=names_file),\n    }\n    if self.version > ""2.0.0"":\n      features_dict[""id""] = tfds.features.Text()\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict(features_dict),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://www.vision.ee.ethz.ch/datasets_extra/food-101/"",\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Define Splits.""""""\n\n    dl_path = dl_manager.download_and_extract(_BASE_URL)\n    meta_path = os.path.join(dl_path, ""food-101"", ""meta"")\n    image_dir_path = os.path.join(dl_path, ""food-101"", ""images"")\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""json_file_path"": os.path.join(meta_path, ""train.json""),\n                ""image_dir_path"": image_dir_path\n            },\n        ),\n\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""json_file_path"": os.path.join(meta_path, ""test.json""),\n                ""image_dir_path"": image_dir_path\n            },\n        ),\n    ]\n\n  def _generate_examples(self, json_file_path, image_dir_path):\n    """"""Generate images and labels for splits.""""""\n    with tf.io.gfile.GFile(json_file_path) as f:\n      data = json.loads(f.read())\n    for label, images in data.items():\n      for image_name in images:\n        image = os.path.join(image_dir_path, image_name + "".jpg"")\n        features = {""image"": image, ""label"": label}\n        if self.version > ""2.0.0"":\n          features[""id""] = image_name\n        yield image_name, features\n'"
tensorflow_datasets/image_classification/food101_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets.image_classification import food101\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass Food101Test(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = food101.Food101\n  SPLITS = {\n      ""train"": 4,\n      ""validation"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/geirhos_conflict_stimuli.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Geirhos conflict stimulus set.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{\n  geirhos2018imagenettrained,\n  title={ImageNet-trained {CNN}s are biased towards texture; increasing shape\n         bias improves accuracy and robustness.},\n  author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and\n          Matthias Bethge and Felix A. Wichmann and Wieland Brendel},\n  booktitle={International Conference on Learning Representations},\n  year={2019},\n  url={https://openreview.net/forum?id=Bygh9j09KX},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nShape/texture conflict stimuli from ""ImageNet-trained CNNs are biased towards \\\ntexture; increasing shape bias improves accuracy and robustness.""\n\nNote that, although the dataset source contains images with matching shape and\ntexture and we include them here, they are ignored for most evaluations in the\noriginal paper.\n""""""\n\n_BASE_URL = ""https://github.com/rgeirhos/texture-vs-shape""\n_DOWNLOAD_URL = ""https://github.com/rgeirhos/texture-vs-shape/archive/1b69c6a445c3348927139edb30a5134521fd4b03.zip""\n_IMAGENET_MAPPING_URL = ""https://raw.githubusercontent.com/rgeirhos/generalisation-humans-DNNs/5bbe08f6821e1eb2bdbe98acebf3586d36be00ab/16-class-ImageNet/MSCOCO_to_ImageNet_category_mapping.txt""\n_DATA_DIR_PATH = ""texture-vs-shape-1b69c6a445c3348927139edb30a5134521fd4b03/stimuli/style-transfer-preprocessed-512""\n\n_CLASSES = [\n    ""airplane"", ""bear"", ""bicycle"", ""bird"", ""boat"", ""bottle"", ""car"", ""cat"",\n    ""chair"", ""clock"", ""dog"", ""elephant"", ""keyboard"", ""knife"", ""oven"", ""truck""\n]\n_IMAGENET_LABELS_FNAME = ""image_classification/imagenet2012_labels.txt""\n\n\nclass GeirhosConflictStimuli(tfds.core.GeneratorBasedBuilder):\n  """"""Shape/Texture conflict .""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    """"""Define dataset info.""""""\n\n    imagenet_names_file = tfds.core.get_tfds_path(_IMAGENET_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""shape_label"": tfds.features.ClassLabel(names=_CLASSES),\n            ""shape_imagenet_labels"": tfds.features.Sequence(\n                tfds.features.ClassLabel(names_file=imagenet_names_file)),\n            ""texture_label"": tfds.features.ClassLabel(names=_CLASSES),\n            ""texture_imagenet_labels"": tfds.features.Sequence(\n                tfds.features.ClassLabel(names_file=imagenet_names_file)),\n            ""file_name"": tfds.features.Text(),\n        }),\n        supervised_keys=(""image"", ""shape_label""),\n        homepage=_BASE_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Define splits.""""""\n\n    dl_paths = dl_manager.download_and_extract({\n        ""texture_vs_shape"": tfds.download.Resource(\n            url=_DOWNLOAD_URL, extract_method=tfds.download.ExtractMethod.ZIP),\n        ""imagenet_mapping"": _IMAGENET_MAPPING_URL\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""data_dir_path"": os.path.join(\n                    dl_paths[""texture_vs_shape""], _DATA_DIR_PATH),\n                ""imagenet_mapping_path"": dl_paths[""imagenet_mapping""]\n            },\n        ),\n    ]\n\n  def _generate_examples(self, data_dir_path, imagenet_mapping_path):\n    """"""Generate images and labels for splits.""""""\n    # Read ImageNet mapping.\n    imagenet_names = set(self.info.features[""shape_imagenet_labels""].names)\n\n    with tf.io.gfile.GFile(imagenet_mapping_path) as f:\n      mapping_txt = f.read()\n    mapping = {}\n    for match in re.finditer(r""([a-z]+)\\s*=\\s*\\[([^\\]]+)\\]"", mapping_txt):\n      mapping[match.group(1)] = list(sorted(imagenet_names.intersection(\n          re.sub(r""\\s"", """", match.group(2)).split("",""))))\n\n    # Process images.\n    for shape_class_name in tf.io.gfile.listdir(data_dir_path):\n      class_dir_path = os.path.join(data_dir_path, shape_class_name)\n      for image_name in tf.io.gfile.listdir(class_dir_path):\n        image = os.path.join(class_dir_path, image_name)\n        texture_class_name = re.search(""-([a-z]+)"", image_name).group(1)  # pytype: disable=attribute-error\n        yield image_name, {\n            ""image"": image,\n            ""file_name"": image_name,\n            ""shape_label"": shape_class_name,\n            ""shape_imagenet_labels"": mapping[shape_class_name],\n            ""texture_label"": texture_class_name,\n            ""texture_imagenet_labels"": mapping[texture_class_name]\n        }\n'"
tensorflow_datasets/image_classification/geirhos_conflict_stimuli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Geirhos conflict stimuli.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import geirhos_conflict_stimuli\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass GeirhosConflictStimuliTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = geirhos_conflict_stimuli.GeirhosConflictStimuli\n  SPLITS = {\n      \'test\': 2\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'texture_vs_shape\': \'texture_vs_shape\',\n      \'imagenet_mapping\': \'mapping.txt\'\n  }\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/horses_or_humans.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Horses or Humans dataset.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@ONLINE {horses_or_humans,\nauthor = ""Laurence Moroney"",\ntitle = ""Horses or Humans Dataset"",\nmonth = ""feb"",\nyear = ""2019"",\nurl = ""http://laurencemoroney.com/horses-or-humans-dataset""\n}\n""""""\n\n_TRAIN_URL = ""https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip""\n_TEST_URL = ""https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip""\n\n_IMAGE_SIZE = 300\n_IMAGE_SHAPE = (_IMAGE_SIZE, _IMAGE_SIZE, 3)\n\n_NAME_RE = re.compile(r""^(humans|horses)(?:/|\\\\)[\\w-]*\\.png$"")\n\n\nclass HorsesOrHumans(tfds.core.GeneratorBasedBuilder):\n  """"""Horses or Humans dataset.""""""\n\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""A large set of images of horses and humans."",\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(\n                names=[""horses"", ""humans""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://laurencemoroney.com/horses-or-humans-dataset"",\n        citation=_CITATION\n        )\n\n  def _split_generators(self, dl_manager):\n    train_path, test_path = dl_manager.download([_TRAIN_URL, _TEST_URL])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(train_path)\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(test_path)\n            }),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Generate horses or humans images and labels given the directory path.\n\n    Args:\n      archive: object that iterates over the zip.\n\n    Yields:\n      The image path and its corresponding label.\n    """"""\n\n    for fname, fobj in archive:\n      res = _NAME_RE.match(fname)\n      if not res:  # if anything other than .png; skip\n        continue\n      label = res.group(1).lower()\n      record = {\n          ""image"": fobj,\n          ""label"": label,\n      }\n      yield fname, record\n'"
tensorflow_datasets/image_classification/horses_or_humans_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for horses or humans data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import horses_or_humans\nimport tensorflow_datasets.testing as tfds_test\n\nhorses_or_humans._IMAGE_SHAPE = (None, None, 3)  # pylint: disable=protected-access\n\n\nclass HorsesOrHumansTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = horses_or_humans.HorsesOrHumans\n\n  SPLITS = {\n      \'train\': 2,\n      \'test\': 2,\n  }\n\n  DL_EXTRACT_RESULT = [\'hoh_train.zip\', \'hoh_test.zip\']\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/image_folder.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""FileFolder datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\nSUPPORTED_IMAGE_FORMAT = ("".jpg"", "".jpeg"", "".png"")\n\n\nclass ImageLabelFolder(tfds.core.GeneratorBasedBuilder):\n  """"""Generic image classification dataset created from manual directory.\n\n  The data directory should have the following structure:\n\n  ```\n  path/to/manual_dir/<dataset_name>/\n    split_name/  # Ex: \'train\'\n      label1/  # Ex: \'airplane\' or \'0015\'\n        xxx.png\n        xxy.png\n        xxz.png\n      label2/\n        xxx.png\n        xxy.png\n        xxz.png\n    split_name/  # Ex: \'test\'\n      ...\n  ```\n\n  To use it:\n\n  ```\n  builder = tfds.image.ImageLabelFolder(\'<dataset_name>\')\n  dl_config = tfds.download.DownloadConfig(manual_dir=\'path/to/manual_dir/\')\n  builder.download_and_prepare(download_config=dl_config)\n  print(builder.info)  # Splits, num examples,... automatically extracted\n  ds = builder.as_dataset(split=\'split_name\', shuffle_files=True)\n  ```\n\n  Or with load:\n\n  ```\n  dl_config = tfds.download.DownloadConfig(manual_dir=\'path/to/manual_dir/\')\n  tfds.load(\n      \'image_label_folder\',\n      split=\'split_name\'\n      builder_kwargs=dict(dataset_name=\'<dataset_name>\'),\n      download_and_prepare_kwargs=dict(download_config=dl_config),\n  )\n  ```\n\n  """"""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = ""This is a \'template\' dataset.""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  # TODO(epot): Image shape should be automatically deduced\n\n  def __init__(self, dataset_name=""image_label_folder"", **kwargs):\n    self.name = dataset_name\n    super(ImageLabelFolder, self).__init__(**kwargs)\n\n  def _info(self):\n    if not self._data_dir:\n      logging.warning(\n          ""ImageLabelFolder.info is only complete once the data has been ""\n          ""generated. Please call .download_and_prepare() before calling ""\n          "".info. The .info.features won\'t be computed."")\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""Generic image classification dataset."",\n        # Generic features before the data is generated\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(num_classes=None),\n        }),\n        supervised_keys=(""image"", ""label""),\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators from the folder names.""""""\n    # At data creation time, parse the folder to deduce number of splits,\n    # labels, image size,\n\n    # The splits correspond to the high level folders\n    split_names = list_folders(dl_manager.manual_dir)\n\n    # Extract all label names and associated images\n    split_label_images = {}  # dict[split_name][label_name] = list(img_paths)\n    for split_name in split_names:\n      split_dir = os.path.join(dl_manager.manual_dir, split_name)\n      split_label_images[split_name] = {\n          label_name: list_imgs(os.path.join(split_dir, label_name))\n          for label_name in list_folders(split_dir)\n      }\n\n    # Merge all label names from all splits to get the final list of labels\n    # Sorted list for determinism\n    labels = [split.keys() for split in split_label_images.values()]\n    labels = list(sorted(set(itertools.chain(*labels))))\n\n    # Could improve the automated encoding format detection\n    # Extract the list of all image paths\n    image_paths = [\n        image_paths\n        for label_images in split_label_images.values()\n        for image_paths in label_images.values()\n    ]\n    if any(f.lower().endswith("".png"") for f in itertools.chain(*image_paths)):\n      encoding_format = ""png""\n    else:\n      encoding_format = ""jpeg""\n\n    # Update the info.features. Those info will be automatically resored when\n    # the dataset is re-created\n    self.info.features[""image""].set_encoding_format(encoding_format)\n    self.info.features[""label""].names = labels\n\n    # Define the splits\n    return [\n        tfds.core.SplitGenerator(\n            name=split_name,\n            gen_kwargs=dict(label_images=label_images,),\n        ) for split_name, label_images in split_label_images.items()\n    ]\n\n  def _generate_examples(self, label_images):\n    """"""Generate example for each image in the dict.""""""\n\n    for label, image_paths in label_images.items():\n      for image_path in image_paths:\n        key = ""%s/%s"" % (label, os.path.basename(image_path))\n        yield key, {\n            ""image"": image_path,\n            ""label"": label,\n        }\n\n\ndef list_folders(root_dir):\n  return [\n      f for f in tf.io.gfile.listdir(root_dir)\n      if tf.io.gfile.isdir(os.path.join(root_dir, f))\n  ]\n\n\ndef list_imgs(root_dir):\n  return [\n      os.path.join(root_dir, f)\n      for f in tf.io.gfile.listdir(root_dir)\n      if any(f.lower().endswith(ext) for ext in SUPPORTED_IMAGE_FORMAT)\n  ]\n'"
tensorflow_datasets/image_classification/image_folder_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for ImageLabelFolder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.image_classification import image_folder\n\n\nclass ImageLabelFolderTest(testing.DatasetBuilderTestCase):\n  """"""Test for ImageLabelFolder.""""""\n  DATASET_CLASS = functools.partial(\n      image_folder.ImageLabelFolder, dataset_name=""image_folder_data"")\n  # The above construct forces us to disable those checks:\n  MOCK_OUT_FORBIDDEN_OS_FUNCTIONS = False\n  SPLITS = {\n      ""train"": 2,  # Number of examples.\n      ""test"": 6,\n  }\n\n  def test_info(self):\n    pass\n\n  def test_registered(self):\n    self.assertIn(""image_label_folder"", registered.list_builders(),\n                  ""Dataset was not registered."")\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagenet.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Imagenet datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\nimport tarfile\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = \'\'\'\\\nILSVRC 2012, aka ImageNet is an image dataset organized according to the\nWordNet hierarchy. Each meaningful concept in WordNet, possibly described by\nmultiple words or word phrases, is called a ""synonym set"" or ""synset"". There are\nmore than 100,000 synsets in WordNet, majority of them are nouns (80,000+). In\nImageNet, we aim to provide on average 1000 images to illustrate each synset.\nImages of each concept are quality-controlled and human-annotated. In its\ncompletion, we hope ImageNet will offer tens of millions of cleanly sorted\nimages for most of the concepts in the WordNet hierarchy.\n\nNote that labels were never publicly released for the test set, so we only\ninclude splits for the training and validation sets here.\n\'\'\'\n\n# Web-site is asking to cite paper from 2015.\n# http://www.image-net.org/challenges/LSVRC/2012/index#cite\n_CITATION = \'\'\'\\\n@article{ILSVRC15,\nAuthor = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},\nTitle = {{ImageNet Large Scale Visual Recognition Challenge}},\nYear = {2015},\njournal   = {International Journal of Computer Vision (IJCV)},\ndoi = {10.1007/s11263-015-0816-y},\nvolume={115},\nnumber={3},\npages={211-252}\n}\n\'\'\'\n\n_LABELS_FNAME = \'image_classification/imagenet2012_labels.txt\'\n\n# This file contains the validation labels, in the alphabetic order of\n# corresponding image names (and not in the order they have been added to the\n# tar file).\n_VALIDATION_LABELS_FNAME = \'image_classification/imagenet2012_validation_labels.txt\'\n\n\n# From https://github.com/cytsai/ilsvrc-cmyk-image-list\nCMYK_IMAGES = [\n    \'n01739381_1309.JPEG\',\n    \'n02077923_14822.JPEG\',\n    \'n02447366_23489.JPEG\',\n    \'n02492035_15739.JPEG\',\n    \'n02747177_10752.JPEG\',\n    \'n03018349_4028.JPEG\',\n    \'n03062245_4620.JPEG\',\n    \'n03347037_9675.JPEG\',\n    \'n03467068_12171.JPEG\',\n    \'n03529860_11437.JPEG\',\n    \'n03544143_17228.JPEG\',\n    \'n03633091_5218.JPEG\',\n    \'n03710637_5125.JPEG\',\n    \'n03961711_5286.JPEG\',\n    \'n04033995_2932.JPEG\',\n    \'n04258138_17003.JPEG\',\n    \'n04264628_27969.JPEG\',\n    \'n04336792_7448.JPEG\',\n    \'n04371774_5854.JPEG\',\n    \'n04596742_4225.JPEG\',\n    \'n07583066_647.JPEG\',\n    \'n13037406_4650.JPEG\',\n]\n\nPNG_IMAGES = [\'n02105855_2933.JPEG\']\n\n\nclass Imagenet2012(tfds.core.GeneratorBasedBuilder):\n  """"""Imagenet 2012, aka ILSVRC 2012.""""""\n\n  VERSION = tfds.core.Version(\n      \'5.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  manual_dir should contain two files: ILSVRC2012_img_train.tar and\n  ILSVRC2012_img_val.tar.\n  You need to register on http://www.image-net.org/download-images in order\n  to get the link to download the dataset.\n  """"""\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(encoding_format=\'jpeg\'),\n            \'label\': tfds.features.ClassLabel(names_file=names_file),\n            \'file_name\': tfds.features.Text(),  # Eg: \'n15075141_54.JPEG\'\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'http://image-net.org/\',\n        citation=_CITATION,\n    )\n\n  @staticmethod\n  def _get_validation_labels(val_path):\n    """"""Returns labels for validation.\n\n    Args:\n      val_path: path to TAR file containing validation images. It is used to\n      retrieve the name of pictures and associate them to labels.\n\n    Returns:\n      dict, mapping from image name (str) to label (str).\n    """"""\n    labels_path = tfds.core.get_tfds_path(_VALIDATION_LABELS_FNAME)\n    with tf.io.gfile.GFile(labels_path) as labels_f:\n      # `splitlines` to remove trailing `\\r` in Windows\n      labels = labels_f.read().strip().splitlines()\n    with tf.io.gfile.GFile(val_path, \'rb\') as tar_f_obj:\n      tar = tarfile.open(mode=\'r:\', fileobj=tar_f_obj)\n      images = sorted(tar.getnames())\n    return dict(zip(images, labels))\n\n  def _split_generators(self, dl_manager):\n    train_path = os.path.join(dl_manager.manual_dir, \'ILSVRC2012_img_train.tar\')\n    val_path = os.path.join(dl_manager.manual_dir, \'ILSVRC2012_img_val.tar\')\n    # We don\'t import the original test split, as it doesn\'t include labels.\n    # These were never publicly released.\n    if not tf.io.gfile.exists(train_path) or not tf.io.gfile.exists(val_path):\n      raise AssertionError(\n          \'ImageNet requires manual download of the data. Please download \'\n          \'the train and val set and place them into: {}, {}\'.format(\n              train_path, val_path))\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(train_path),\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(val_path),\n                \'validation_labels\': self._get_validation_labels(val_path),\n            },\n        ),\n    ]\n\n  def _fix_image(self, image_fname, image):\n    """"""Fix image color system and format starting from v 3.0.0.""""""\n    if self.version < \'3.0.0\':\n      return image\n    if image_fname in CMYK_IMAGES:\n      image = io.BytesIO(tfds.core.utils.jpeg_cmyk_to_rgb(image.read()))\n    elif image_fname in PNG_IMAGES:\n      image = io.BytesIO(tfds.core.utils.png_to_jpeg(image.read()))\n    return image\n\n  def _generate_examples(self, archive, validation_labels=None):\n    """"""Yields examples.""""""\n    if validation_labels:  # Validation split\n      for key, example in self._generate_examples_validation(archive,\n                                                             validation_labels):\n        yield key, example\n    # Training split. Main archive contains archives names after a synset noun.\n    # Each sub-archive contains pictures associated to that synset.\n    for fname, fobj in archive:\n      label = fname[:-4]  # fname is something like \'n01632458.tar\'\n      # TODO(b/117643231): in py3, the following lines trigger tarfile module\n      # to call `fobj.seekable()`, which Gfile doesn\'t have. We should find an\n      # alternative, as this loads ~150MB in RAM.\n      fobj_mem = io.BytesIO(fobj.read())\n      for image_fname, image in tfds.download.iter_archive(\n          fobj_mem, tfds.download.ExtractMethod.TAR_STREAM):\n        image = self._fix_image(image_fname, image)\n        record = {\n            \'file_name\': image_fname,\n            \'image\': image,\n            \'label\': label,\n        }\n        yield image_fname, record\n\n  def _generate_examples_validation(self, archive, labels):\n    for fname, fobj in archive:\n      record = {\n          \'file_name\': fname,\n          \'image\': fobj,\n          \'label\': labels[fname],\n      }\n      yield fname, record\n'"
tensorflow_datasets/image_classification/imagenet2012_corrupted.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Corrupted ImageNet2012 dataset.\n\nApply common corruptions to the images in ImageNet2012 dataset.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.image_classification import corruptions\nfrom tensorflow_datasets.image_classification.imagenet import Imagenet2012\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nImagenet2012Corrupted is a dataset generated by adding common corruptions to the\nimages in the ImageNet dataset. In the original paper, there are 15 + 4\ndifferent corruptions, and each has 5 levels of severity. We also implement the 4 extra\ncorruptions gaussian blur, saturate, spatter, and speckle noise. The randomness\nis fixed so that regeneration is deterministic.\n""""""\n\n_CITATION = """"""\\\n@inproceedings{\n  hendrycks2018benchmarking,\n  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\n  author={Dan Hendrycks and Thomas Dietterich},\n  booktitle={International Conference on Learning Representations},\n  year={2019},\n  url={https://openreview.net/forum?id=HJz6tiCqYm},\n}\n""""""\n\n_LABELS_FNAME = \'image_classification/imagenet2012_labels.txt\'\n\n# This file contains the validation labels, in the alphabetic order of\n# corresponding image names (and not in the order they have been added to the\n# tar file).\n_VALIDATION_LABELS_FNAME = \'image_classification/imagenet2012_validation_labels.txt\'\n\n_FROST_FILEBASE = \'https://raw.githubusercontent.com/hendrycks/robustness/master/ImageNet-C/imagenet_c/imagenet_c/frost/\'\n_FROST_FILENAMES = [\n    _FROST_FILEBASE + f for f in [\n        \'frost1.png\', \'frost2.png\', \'frost3.png\', \'frost4.jpg\', \'frost5.jpg\',\n        \'frost6.jpg\'\n    ]\n]\n\nBENCHMARK_CORRUPTIONS = [\n    \'gaussian_noise\',\n    \'shot_noise\',\n    \'impulse_noise\',\n    \'defocus_blur\',\n    \'glass_blur\',\n    \'motion_blur\',\n    \'zoom_blur\',\n    \'snow\',\n    \'frost\',\n    \'fog\',\n    \'brightness\',\n    \'contrast\',\n    \'elastic_transform\',\n    \'pixelate\',\n    \'jpeg_compression\',\n]\n\nEXTRA_CORRUPTIONS = [\'gaussian_blur\', \'saturate\', \'spatter\', \'speckle_noise\']\n\n_IMAGE_SIZE = 224\n_CROP_PADDING = 32\n\n\nclass Imagenet2012CorruptedConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Imagenet2012Corrupted.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, corruption_type=None, severity=1, **kwargs):\n    """"""BuilderConfig for Imagenet2012Corrupted.\n\n    Args:\n      corruption_type: string, must be one of the items in BENCHMARK_CORRUPTIONS\n        + EXTRA_CORRUPTIONS.\n      severity: integer, bewteen 1 and 5.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(Imagenet2012CorruptedConfig, self).__init__(**kwargs)\n    self.corruption_type = corruption_type\n    self.severity = severity\n\n\n_VERSION = tfds.core.Version(\'3.1.0\')\n\n# Version history:\n# 3.1.0: Implement missing corruptions. Fix crop/resize ordering, file encoding\n# 0.0.1: Initial dataset.\n\n\ndef _make_builder_configs():\n  """"""Construct a list of BuilderConfigs.\n\n  Construct a list of 95 Imagenet2012CorruptedConfig objects, corresponding to\n  the 15 + 4 corruption types, with each type having 5 severities.\n\n  Returns:\n    A list of 95 Imagenet2012CorruptedConfig objects.\n  """"""\n  config_list = []\n  for each_corruption in BENCHMARK_CORRUPTIONS + EXTRA_CORRUPTIONS:\n    for each_severity in range(1, 6):\n      name_str = each_corruption + \'_\' + str(each_severity)\n      description_str = \'corruption type = \' + each_corruption + \', severity = \'\n      description_str += str(each_severity)\n      config_list.append(\n          Imagenet2012CorruptedConfig(\n              name=name_str,\n              version=_VERSION,\n              description=description_str,\n              corruption_type=each_corruption,\n              severity=each_severity,\n          ))\n  return config_list\n\n\ndef _decode_and_center_crop(image_bytes):\n  """"""Crops to center of image with padding then scales image size.""""""\n  shape = tf.image.extract_jpeg_shape(image_bytes)\n  image_height = shape[0]\n  image_width = shape[1]\n\n  padded_center_crop_size = tf.cast(\n      ((_IMAGE_SIZE / (_IMAGE_SIZE + _CROP_PADDING)) *\n       tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32)\n\n  offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n  offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n  crop_window = tf.stack([\n      offset_height, offset_width, padded_center_crop_size,\n      padded_center_crop_size\n  ])\n  image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n  image = tf.image.resize([image], [_IMAGE_SIZE, _IMAGE_SIZE],\n                          method=tf.image.ResizeMethod.BICUBIC)[0]\n  image = tf.cast(image, tf.int32)\n\n  return image\n\n\nclass Imagenet2012Corrupted(Imagenet2012):\n  """"""Corrupted ImageNet2012 dataset.""""""\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    """"""Basic information of the dataset.\n\n    Returns:\n      tfds.core.DatasetInfo.\n    """"""\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\':\n                tfds.features.Image(\n                    shape=(_IMAGE_SIZE, _IMAGE_SIZE, 3),\n                    encoding_format=\'jpeg\'),\n            \'label\':\n                tfds.features.ClassLabel(names_file=names_file),\n            \'file_name\':\n                tfds.features.Text(),  # Eg: \'n15075141_54.JPEG\'\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://openreview.net/forum?id=HJz6tiCqYm\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Filter out training split as ImageNet-C is a testing benchmark.""""""\n    splits = super(Imagenet2012Corrupted, self)._split_generators(dl_manager)\n\n    corruptions.FROST_FILENAMES = dl_manager.download(_FROST_FILENAMES)\n    return [s for s in splits if s.name != tfds.Split.TRAIN]\n\n  def _generate_examples(self, archive, validation_labels=None):\n    """"""Generate corrupted imagenet validation data.\n\n    Apply corruptions to the raw images according to self.corruption_type.\n\n    Args:\n      archive: an iterator for the raw dataset.\n      validation_labels: a dict that maps the file names to imagenet labels.\n\n    Yields:\n      dictionary with the file name, an image file objective, and label of each\n      imagenet validation data.\n    """"""\n    # Get the current random seeds.\n    numpy_st0 = np.random.get_state()\n    # Set new random seeds.\n    np.random.seed(135)\n    logging.warning(\'Overwriting cv2 RNG seed.\')\n    tfds.core.lazy_imports.cv2.setRNGSeed(357)\n\n    gen_fn = super(Imagenet2012Corrupted, self)._generate_examples\n    for key, example in gen_fn(archive, validation_labels):\n      with tf.Graph().as_default():\n        tf_img = _decode_and_center_crop(example[\'image\'].read())\n        image_np = tfds.as_numpy(tf_img)\n      example[\'image\'] = self._get_corrupted_example(image_np)\n\n      yield key, example\n    # Reset the seeds back to their original values.\n    np.random.set_state(numpy_st0)\n\n  def _get_corrupted_example(self, x):\n    """"""Return corrupted images.\n\n    Args:\n      x: numpy array, uncorrupted image.\n\n    Returns:\n      numpy array, corrupted images.\n    """"""\n    corruption_type = self.builder_config.corruption_type\n    severity = self.builder_config.severity\n    x = np.clip(x, 0, 255)\n\n    return {\n        \'gaussian_noise\': corruptions.gaussian_noise,\n        \'shot_noise\': corruptions.shot_noise,\n        \'impulse_noise\': corruptions.impulse_noise,\n        \'defocus_blur\': corruptions.defocus_blur,\n        \'glass_blur\': corruptions.glass_blur,\n        \'motion_blur\': corruptions.motion_blur,\n        \'zoom_blur\': corruptions.zoom_blur,\n        \'snow\': corruptions.snow,\n        \'frost\': corruptions.frost,\n        \'fog\': corruptions.fog,\n        \'brightness\': corruptions.brightness,\n        \'contrast\': corruptions.contrast,\n        \'elastic_transform\': corruptions.elastic_transform,\n        \'pixelate\': corruptions.pixelate,\n        \'jpeg_compression\': corruptions.jpeg_compression,\n        \'gaussian_blur\': corruptions.gaussian_blur,\n        \'saturate\': corruptions.saturate,\n        \'spatter\': corruptions.spatter,\n        \'speckle_noise\': corruptions.speckle_noise,\n    }[corruption_type](x, severity)\n'"
tensorflow_datasets/image_classification/imagenet2012_corrupted_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for corrupted_imagenet.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagenet2012_corrupted\n\n\nclass Imagenet2012CorruptedTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [  # pylint: disable=g-long-ternary\n      ""gaussian_noise_1"", ""shot_noise_2"", ""impulse_noise_3"", ""defocus_blur_4"",\n      ""glass_blur_5"", ""motion_blur_1"", ""zoom_blur_2"", ""snow_3"", ""frost_4"",\n      ""fog_5"", ""brightness_1"", ""contrast_2"", ""elastic_transform_3"",\n      ""pixelate_4"", ""jpeg_compression_5"", ""gaussian_blur_1"", ""saturate_2"",\n      ""spatter_3"", ""speckle_noise_4""\n  ] if six.PY2 else []  # TODO(rsepassi): Re-enable Py3 test (b/129964829)\n\n  DATASET_CLASS = imagenet2012_corrupted.Imagenet2012Corrupted\n  SPLITS = {  # Expected number of examples on the train/validation splits.\n      ""validation"": 10,\n  }\n  DL_EXTRACT_RESULT = [\n      ""ILSVRC2012_img_train.tar"",\n      ""ILSVRC2012_img_val.tar"",\n  ]\n  DL_DOWNLOAD_RESULT = [\n      ""frost1.png"", ""frost2.png"", ""frost3.png"", ""frost4.jpg"", ""frost5.jpg"",\n      ""frost6.jpg""\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagenet2012_subset.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Imagenet subset datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.image_classification.imagenet import Imagenet2012\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = \'\'\'\\\nImagenet2012Subset is a subset of original ImageNet ILSVRC 2012 dataset.\nThe dataset share the *same* validation set as the original ImageNet ILSVRC 2012\ndataset. However, the training set is subsampled in a label balanced fashion.\nIn `1pct` configuration, 1%, or 12811, images are sampled, most classes have\nthe same number of images (average 12.8), some classes randomly have 1 more\nexample than others; and in `10pct` configuration, ~10%, or 128116, most classes\nhave the same number of images (average 128), and some classes randomly have 1\nmore example than others.\n\nThis is supposed to be used as a benchmark for semi-supervised learning, and\nhas been originally used in SimCLR paper (https://arxiv.org/abs/2002.05709).\n\'\'\'\n\n_CITATION = \'\'\'\\\n@article{chen2020simple,\n  title={A Simple Framework for Contrastive Learning of Visual Representations},\n  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},\n  journal={arXiv preprint arXiv:2002.05709},\n  year={2020}\n}\n@article{ILSVRC15,\n  Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},\n  Title = {{ImageNet Large Scale Visual Recognition Challenge}},\n  Year = {2015},\n  journal   = {International Journal of Computer Vision (IJCV)},\n  doi = {10.1007/s11263-015-0816-y},\n  volume={115},\n  number={3},\n  pages={211-252}\n}\n\'\'\'\n\n# pylint: disable=line-too-long\n_LABELS_FNAME = \'image_classification/imagenet2012_labels.txt\'\nSUBSET2FILES = {\n    \'1pct\': \'https://raw.githubusercontent.com/google-research/simclr/master/imagenet_subsets/1percent.txt\',\n    \'10pct\': \'https://raw.githubusercontent.com/google-research/simclr/master/imagenet_subsets/10percent.txt\'\n}\n\n\nclass Imagenet2012Subset(Imagenet2012):\n  """"""Class balanced subset of Imagenet 2012 dataset.""""""\n\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(  # pylint: disable=g-complex-comprehension\n          name=subset_size,\n          description=\'{} of total ImageNet training set.\'.format(subset_size),\n          version=tfds.core.Version(\n              \'5.0.0\', \'\'),\n      ) for subset_size in SUBSET2FILES\n  ]\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(),\n            \'label\': tfds.features.ClassLabel(names_file=names_file),\n            \'file_name\': tfds.features.Text(),  # Eg: \'n15075141_54.JPEG\'\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'http://image-net.org/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    train_path = os.path.join(dl_manager.manual_dir, \'ILSVRC2012_img_train.tar\')\n    val_path = os.path.join(dl_manager.manual_dir, \'ILSVRC2012_img_val.tar\')\n\n    # We don\'t import the original test split, as it doesn\'t include labels.\n    # These were never publicly released.\n    if not tf.io.gfile.exists(train_path) or not tf.io.gfile.exists(val_path):\n      raise AssertionError(\n          \'ImageNet requires manual download of the data. Please download \'\n          \'the train and val set and place them into: {}, {}\'.format(\n              train_path, val_path))\n\n    # Download and load subset file.\n    subset_file = dl_manager.download(SUBSET2FILES[self.builder_config.name])\n    if isinstance(subset_file, list):  # it will only be a list during testing,\n      subset_file = subset_file[0]     # where the first entry is 1percent.txt.\n    with tf.io.gfile.GFile(subset_file) as fp:\n      subset = set(fp.read().splitlines())  # remove trailing `\\r` in Windows\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(train_path),\n                \'subset\': subset,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(val_path),\n                \'validation_labels\': self._get_validation_labels(val_path),\n            },\n        ),\n    ]\n\n  def _generate_examples(self, archive, subset=None, validation_labels=None):\n    """"""Yields examples.""""""\n    if validation_labels:  # Validation split\n      for key, example in self._generate_examples_validation(archive,\n                                                             validation_labels):\n        yield key, example\n    # Training split. Main archive contains archives names after a synset noun.\n    # Each sub-archive contains pictures associated to that synset.\n    for fname, fobj in archive:\n      label = fname[:-4]  # fname is something like \'n01632458.tar\'\n      # TODO(b/117643231): in py3, the following lines trigger tarfile module\n      # to call `fobj.seekable()`, which Gfile doesn\'t have. We should find an\n      # alternative, as this loads ~150MB in RAM.\n      fobj_mem = io.BytesIO(fobj.read())\n      for image_fname, image in tfds.download.iter_archive(\n          fobj_mem, tfds.download.ExtractMethod.TAR_STREAM):\n        image = self._fix_image(image_fname, image)\n        if subset is None or image_fname in subset:  # filtering using subset.\n          record = {\n              \'file_name\': image_fname,\n              \'image\': image,\n              \'label\': label,\n          }\n          yield image_fname, record\n\n'"
tensorflow_datasets/image_classification/imagenet2012_subset_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for imagenet2012_subset dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagenet2012_subset\n\n\nimagenet2012_subset.Imagenet2012Subset.PNG_IMAGES = [""n01440764_1.JPEG""]\nimagenet2012_subset.Imagenet2012Subset.CMYK_IMAGES = [\n    ""n01440764_2.JPEG"",\n    ""n01440764_3.JPEG"",\n]\n\n\nclass Imagenet2012SubsetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagenet2012_subset.Imagenet2012Subset\n  BUILDER_CONFIG_NAMES_TO_TEST = [""1pct""]\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 1,\n      ""validation"": 10,\n  }\n  DL_EXTRACT_RESULT = [\n      ""1percent.txt"",\n      ""ILSVRC2012_img_train.tar"",\n      ""ILSVRC2012_img_val.tar"",\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagenet_resized.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Resized imagenet to 8x8, 16x16, 32x32.\n\nThis is not to be confused with `downsampled_imagenet` which is a unsupervised\ndataset used for generative modeling.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport itertools\nimport numpy as np\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""@article{chrabaszcz2017downsampled,\n  title={A downsampled variant of imagenet as an alternative to the cifar datasets},\n  author={Chrabaszcz, Patryk and Loshchilov, Ilya and Hutter, Frank},\n  journal={arXiv preprint arXiv:1707.08819},\n  year={2017}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThis dataset consists of the ImageNet dataset resized to {size}x{size}.\nThe images here are the ones provided by Chrabaszcz et. al. using the box resize method.\n\nFor [downsampled ImageNet](http://image-net.org/small/download.php) for unsupervised learning see `downsampled_imagenet`.\n\nWARNING: The integer labels used are defined by the authors and do not match\nthose from the other ImageNet datasets provided by Tensorflow datasets.\nSee the original [label list](https://github.com/PatrykChrabaszcz/Imagenet32_Scripts/blob/master/map_clsloc.txt),\nand the [labels used by this dataset](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/imagenet_resized_labels.txt).\nAdditionally, the original authors 1 index there labels which we convert to\n0 indexed by subtracting one.\n""""""\n\n_LABELS_FNAME = \'image_classification/imagenet_resized_labels.txt\'\n_URL_PREFIX = \'http://www.image-net.org/image/downsample/\'\n\n\nclass ImagenetResizedConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Imagenet Resized.""""""\n\n  def __init__(self, size, **kwargs):\n    super(ImagenetResizedConfig, self).__init__(\n        version=tfds.core.Version(\'0.1.0\'), **kwargs)\n    self.size = size\n\n\ndef _make_builder_configs():\n  configs = []\n  for size in [8, 16, 32, 64]:\n    configs.append(\n        ImagenetResizedConfig(\n            name=\'%dx%d\' % (size, size),\n            size=size,\n            description=_DESCRIPTION.format(size=size)))\n  return configs\n\n\nclass ImagenetResized(tfds.core.GeneratorBasedBuilder):\n  """"""Imagenet Resized dataset.""""""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    size = self.builder_config.size\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=self.builder_config.description,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(shape=(size, size, 3)),\n            \'label\': tfds.features.ClassLabel(names_file=names_file)\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://patrykchrabaszcz.github.io/Imagenet32/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    size = self.builder_config.size\n\n    if size in [8, 16, 32]:\n      train_path, val_path = dl_manager.download([\n          \'%s/Imagenet%d_train_npz.zip\' % (_URL_PREFIX, size),\n          \'%s/Imagenet%d_val_npz.zip\' % (_URL_PREFIX, size)\n      ])\n      train_paths = [train_path]\n    elif size == 64:\n      # 64x64 uses more than one file due to its size.\n      train1_path, train2_path, val_path = dl_manager.download([\n          \'%s/Imagenet64_train_part1_npz.zip\' % (_URL_PREFIX),\n          \'%s/Imagenet64_train_part2_npz.zip\' % (_URL_PREFIX),\n          \'%s/Imagenet64_val_npz.zip\' % (_URL_PREFIX)\n      ])\n      train_paths = [train1_path, train2_path]\n    else:\n      raise ValueError(\'Size not implemented!\')\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'archive\':\n                    itertools.chain(*[\n                        dl_manager.iter_archive(train_path)\n                        for train_path in train_paths\n                    ]),\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(val_path),\n            },\n        ),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Yields examples.""""""\n    for fname, fobj in archive:\n      content = fobj.read()\n      if content:\n        fobj_mem = io.BytesIO(content)\n        data = np.load(fobj_mem, allow_pickle=False)\n        size = self.builder_config.size\n        for i, (image, label) in enumerate(zip(data[\'data\'], data[\'labels\'])):\n          record = {\n              # The data is packed flat as CHW where as most image datasets\n              # in tensorflow are HWC. We reshape to recover CHW, then transpose\n              # to put back into HWC.\n              \'image\': np.reshape(image, (3, size, size)).transpose(1, 2, 0),\n              # Labels in the original dataset are 1 indexed so we subtract 1\n              # here.\n              \'label\': label - 1,\n          }\n          yield fname + str(i), record\n'"
tensorflow_datasets/image_classification/imagenet_resized_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagenet_resized\n\n\nclass ImagenetResizedTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [\n      ""8x8"",\n  ]\n  DATASET_CLASS = imagenet_resized.ImagenetResized\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 1,\n  }\n\n  DL_EXTRACT_RESULT = [""Imagenet8_train_npz.zip"", ""Imagenet8_val_npz.zip""]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagenet_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for imagenet dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagenet\n\n\nimagenet.Imagenet2012.PNG_IMAGES = [""n01440764_1.JPEG""]\nimagenet.Imagenet2012.CMYK_IMAGES = [\n    ""n01440764_2.JPEG"",\n    ""n01440764_3.JPEG"",\n]\n\n\nclass Imagenet2012Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagenet.Imagenet2012\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 100,\n      ""validation"": 10,\n  }\n  DL_EXTRACT_RESULT = [\n      ""ILSVRC2012_img_train.tar"",\n      ""ILSVRC2012_img_val.tar"",\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagenette.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Imagenette: a subset of 10 easily classified classes from Imagenet.\n\n(tench, English springer, cassette player, chain saw, church, French horn,\ngarbage truck, gas pump, golf ball, parachute)\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{imagenette,\n  author    = ""Jeremy Howard"",\n  title     = ""imagenette"",\n  url       = ""https://github.com/fastai/imagenette/""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nImagenette is a subset of 10 easily classified classes from the Imagenet\ndataset. It was originally prepared by Jeremy Howard of FastAI. The objective\nbehind putting together a small version of the Imagenet dataset was mainly\nbecause running new ideas/algorithms/experiments on the whole Imagenet take a\nlot of time.\n\nThis version of the dataset allows researchers/practitioners to quickly try out\nideas and share with others. The dataset comes in three variants:\n\n  * Full size\n  * 320 px\n  * 160 px\n\nNote: The v2 config correspond to the new 70/30 train/valid split (released\nin Dec 6 2019).\n""""""\n\n_LABELS_FNAME = ""image_classification/imagenette_labels.txt""\n_URL_PREFIX = ""https://s3.amazonaws.com/fast-ai-imageclas/""\n\n\nclass ImagenetteConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Imagenette.""""""\n\n  def __init__(self, size, base, **kwargs):\n    super(ImagenetteConfig, self).__init__(\n        # `320px-v2`,...\n        name=size + (""-v2"" if base == ""imagenette2"" else """"),\n        description=""{} variant."".format(size),\n        version=tfds.core.Version(""0.1.0""),\n        **kwargs)\n    # e.g. `imagenette2-320.tgz`\n    self.dirname = base + {\n        ""full-size"": """",\n        ""320px"": ""-320"",\n        ""160px"": ""-160"",\n    }[size]\n\n\ndef _make_builder_configs():\n  configs = []\n  for base in [""imagenette2"", ""imagenette""]:\n    for size in [""full-size"", ""320px"", ""160px""]:\n      configs.append(ImagenetteConfig(base=base, size=size))\n  return configs\n\n\nclass Imagenette(tfds.core.GeneratorBasedBuilder):\n  """"""A smaller subset of 10 easily classified classes from Imagenet.""""""\n\n  VERSION = tfds.core.Version(""0.1.1"")\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(encoding_format=""jpeg""),\n            ""label"": tfds.features.ClassLabel(names_file=names_file)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/fastai/imagenette"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dirname = self.builder_config.dirname\n    url = _URL_PREFIX + ""{}.tgz"".format(dirname)\n    path = dl_manager.download_and_extract(url)\n    train_path = os.path.join(path, dirname, ""train"")\n    val_path = os.path.join(path, dirname, ""val"")\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""datapath"": train_path,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""datapath"": val_path,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, datapath):\n    """"""Yields examples.""""""\n    for label in tf.io.gfile.listdir(datapath):\n      for fpath in tf.io.gfile.glob(os.path.join(datapath, label, ""*.JPEG"")):\n        fname = os.path.basename(fpath)\n        record = {\n            ""image"": fpath,\n            ""label"": label,\n        }\n        yield fname, record\n'"
tensorflow_datasets/image_classification/imagenette_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for imagenette: a subset of 10 easily classified classes from Imagenet.\n\n (tench, English springer, cassette player, chain saw, church,\nFrench horn, garbage truck, gas pump, golf ball, parachute).\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagenette\n\n\nclass ImagenetteTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagenette.Imagenette\n  SPLITS = {\n      ""train"": 4,  # Number of fake train example\n      ""validation"": 4,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/imagewang.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# -*- coding: utf-8 -*-\n""""""Imagewang contains Imagenette and Imagewoof combined.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{imagewang,\n  author    = ""Jeremy Howard"",\n  title     = ""Imagewang"",\n  url       = ""https://github.com/fastai/imagenette/""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nImagewang contains Imagenette and Imagewoof combined\nImage\xe7\xbd\x91 (pronounced ""Imagewang""; \xe7\xbd\x91 means ""net"" in Chinese) contains Imagenette\nand Imagewoof combined, but with some twists that make it into a tricky\nsemi-supervised unbalanced classification problem:\n\n* The validation set is the same as Imagewoof (i.e. 30% of Imagewoof images);\n  there are no Imagenette images in the validation set (they\'re all in the\n  training set)\n* Only 10% of Imagewoof images are in the training set!\n* The remaining are in the unsup (""unsupervised"") directory, and you can not\n  use their labels in training!\n* It\'s even hard to type and hard to say!\n\nThe dataset comes in three variants:\n\n  * Full size\n  * 320 px\n  * 160 px\n\nThis dataset consists of the Imagenette dataset {size} variant.\n""""""\n\n_DESCRIPTION_SHORT = """"""\\\nImagewang contains Imagenette and Imagewoof combined.\n""""""\n\n_LABELS_FNAME = ""image_classification/imagewang_labels.txt""\n_URL_PREFIX = ""https://s3.amazonaws.com/fast-ai-imageclas""\n_SIZES = [""full-size"", ""320px"", ""160px""]\n\n_SIZE_TO_DIRNAME = {\n    ""full-size"": ""imagewang"",\n    ""320px"": ""imagewang-320"",\n    ""160px"": ""imagewang-160""\n}\n\n\nclass ImagewangConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Imagewang.""""""\n\n  def __init__(self, size, **kwargs):\n    super(ImagewangConfig, self).__init__(\n        version=tfds.core.Version(""2.0.0""), **kwargs)\n    self.size = size\n\n\ndef _make_builder_configs():\n  configs = []\n  for size in _SIZES:\n    configs.append(\n        ImagewangConfig(name=size, size=size, description=_DESCRIPTION_SHORT))\n  return configs\n\n\nclass Imagewang(tfds.core.GeneratorBasedBuilder):\n  """"""Imagewang contains Imagenette and Imagewoof combined.""""""\n\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names_file=names_file)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/fastai/imagenette"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    size = self.builder_config.size\n    if size in _SIZES:\n      size_str = """" if size == ""full-size"" else ""-"" + size[:-2]\n      url = ""/"".join([_URL_PREFIX, ""imagewang%s.tgz"" % size_str])\n      path = dl_manager.download_and_extract(url)\n      train_path = os.path.join(path, _SIZE_TO_DIRNAME[size], ""train"")\n      val_path = os.path.join(path, _SIZE_TO_DIRNAME[size], ""val"")\n    else:\n      raise ValueError(""size must be one of %s"" % _SIZES)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""datapath"": train_path,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""datapath"": val_path,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, datapath):\n    """"""Yields examples.""""""\n    for label in tf.io.gfile.listdir(datapath):\n      for fpath in tf.io.gfile.glob(os.path.join(datapath, label, ""*.JPEG"")):\n        fname = os.path.basename(fpath)\n        record = {\n            ""image"": fpath,\n            ""label"": label,\n        }\n        yield fname, record\n'"
tensorflow_datasets/image_classification/imagewang_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Imagewang.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import imagewang\n\n\nclass ImagewangFullSizeTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagewang.Imagewang\n  BUILDER_CONFIG_NAMES_TO_TEST = [""full-size""]\n  SPLITS = {\n      ""train"": 4,\n      ""validation"": 4,\n  }\n\n\nclass Imagewang320Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagewang.Imagewang\n  BUILDER_CONFIG_NAMES_TO_TEST = [""320px""]\n  SPLITS = {\n      ""train"": 4,\n      ""validation"": 4,\n  }\n\n\nclass Imagewang160Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imagewang.Imagewang\n  BUILDER_CONFIG_NAMES_TO_TEST = [""160px""]\n  SPLITS = {\n      ""train"": 4,\n      ""validation"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/inaturalist.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""INaturalist datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport six.moves.urllib as urllib\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nThis dataset contains a total of 5,089 categories, across 579,184 training\nimages and 95,986 validation images. For the training set, the distribution of\nimages per category follows the observation frequency of that category by the\niNaturalist community.\n\nAlthough the original dataset contains some images with bounding boxes,\ncurrently, only image-level annotations are provided (single label/image).\nIn addition, the organizers have not published the test labels, so we only\nprovide the test images (label = -1).\n""""""\n_CITATION = """"""\\\n@InProceedings{Horn_2018_CVPR,\nauthor = {\nVan Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen\nand Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},\ntitle = {The INaturalist Species Classification and Detection Dataset},\nbooktitle = {\nThe IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\nmonth = {June},\nyear = {2018}\n}\n""""""\n_URL = ""http://www.vision.caltech.edu/~gvanhorn/datasets/inaturalist/fgvc4_competition/""\n\n\nclass INaturalist2017(tfds.core.GeneratorBasedBuilder):\n  """"""Dataset from the INaturalist Competition 2017.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    """"""Define the dataset info.""""""\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""id"": tfds.features.Text(),\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        ""image_classification"", ""inaturalist_labels.txt""))),\n            ""supercategory"": tfds.features.ClassLabel(\n                names_file=tfds.core.get_tfds_path(\n                    os.path.join(\n                        ""image_classification"",\n                        ""inaturalist_supercategories.txt""))),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/visipedia/inat_comp/tree/master/2017"",\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    output_files = dl_manager.download_and_extract({\n        ""trainval_images"":\n            tfds.download.Resource(\n                url=urllib.parse.urljoin(_URL, ""train_val_images.tar.gz""),\n                extract_method=tfds.download.ExtractMethod.NO_EXTRACT),\n        ""trainval_annos"":\n            urllib.parse.urljoin(_URL, ""train_val2017.zip""),\n        ""test_images"":\n            tfds.download.Resource(\n                url=urllib.parse.urljoin(_URL, ""test2017.tar.gz""),\n                extract_method=tfds.download.ExtractMethod.NO_EXTRACT),\n\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                images_archive=dl_manager.iter_archive(\n                    output_files[""trainval_images""]),\n                annon_file=os.path.join(output_files[""trainval_annos""],\n                                        ""train2017.json""),\n            ),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(\n                images_archive=dl_manager.iter_archive(\n                    output_files[""trainval_images""]),\n                annon_file=os.path.join(output_files[""trainval_annos""],\n                                        ""val2017.json""),\n            ),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                images_archive=dl_manager.iter_archive(\n                    output_files[""test_images""]),\n                annon_file=None,\n            ),\n        ),\n    ]\n\n  def _generate_examples(self, images_archive, annon_file):\n    """"""Generate examples.""""""\n    if annon_file is not None:\n      # Training and validation images.\n      with tf.io.gfile.GFile(annon_file, ""r"") as f:\n        data = json.load(f)\n      # First read the annotations file, used to filter the contents of the\n      # tar.gz file when yielding examples.\n      key2data = {}\n      for image, annotation in zip(data[""images""], data[""annotations""]):\n        category_id = annotation[""category_id""]\n        category = data[""categories""][category_id][""name""]\n        supercategory = data[""categories""][category_id][""supercategory""]\n        key = os.path.basename(image[""file_name""]).split(""."")[0]\n        key2data[key] = {\n            ""id"": key,\n            ""label"": category,\n            ""supercategory"": supercategory,\n        }\n      # Read tar.gz file containing train & validation images and yield relevant\n      # examples.\n      for fpath, fobj in images_archive:\n        key = os.path.basename(fpath).split(""."")[0]\n        if key in key2data:\n          data = key2data[key].copy()\n          data[""image""] = fobj\n          yield key, data\n    else:\n      # Read tar.gz file containing all test images and yield all examples.\n      for fpath, fobj in images_archive:\n        key = os.path.basename(fpath).split(""."")[0]\n        # Note: test labels are not annotated, so just return -1 as labels.\n        yield key, {\n            ""id"": key,\n            ""image"": fobj,\n            ""label"": -1,\n            ""supercategory"": -1,\n        }\n'"
tensorflow_datasets/image_classification/inaturalist_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for INaturalist dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import inaturalist\n\n\nclass INaturalist2017Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = inaturalist.INaturalist2017\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 4,\n      ""validation"": 3,\n      ""test"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""test_images"": ""test2017.tar.gz"",\n      ""trainval_annos"": ""train_val2017"",\n      ""trainval_images"": ""train_val_images.tar.gz"",\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/lfw.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Labeled faces in wild.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = ""http://vis-www.cs.umass.edu/lfw/lfw.tgz""\n\nLFW_IMAGE_SHAPE = (250, 250, 3)\n\nLFW_CITATION = """"""\\\n@TechReport{LFWTech,\n    author = {Gary B. Huang and Manu Ramesh and Tamara Berg and Erik Learned-Miller},\n    title = {Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments},\n    institution = {University of Massachusetts, Amherst},\n    year = 2007,\n    number = {07-49},\n    month = {October}\n}\n""""""\n\n\nclass LFW(tfds.core.GeneratorBasedBuilder):\n  """"""LFW Class.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""""""Labeled Faces in the Wild:\n        A Database for Studying Face Recognition in\n        Unconstrained Environments""""""),\n        features=tfds.features.FeaturesDict({\n            ""label"": tfds.features.Text(),\n            ""image"": tfds.features.Image(shape=LFW_IMAGE_SHAPE),\n        }),\n        supervised_keys=(""label"", ""image""),\n        homepage=""http://vis-www.cs.umass.edu/lfw"",\n        citation=LFW_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download_and_extract(_URL)\n    path = os.path.join(path, ""lfw"")\n\n    # There is no train/test split predefined\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""data_path"": path,\n            }),\n    ]\n\n  def _generate_examples(self, data_path):\n    image_list = self.path_maker(data_path)\n    for label, path in image_list:\n      key = ""%s/%s"" % (label, os.path.basename(path))\n      yield key, {\n          ""label"": label,\n          ""image"": path,\n      }\n\n  def path_maker(self, path):\n    """"""Returns all images within path as tuples (label, path).""""""\n    path_list = []\n    dir_list = tf.io.gfile.listdir(path)\n    for directory in dir_list:\n      img_dir_path = os.path.join(path, directory)\n      if tf.io.gfile.isdir(img_dir_path):\n        img_list = tf.io.gfile.listdir(img_dir_path)\n        for img in img_list:\n          img_path = os.path.join(img_dir_path, img)\n          path_list.append([directory, img_path])\n    return path_list\n'"
tensorflow_datasets/image_classification/lfw_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""lfw test script.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import lfw\n\n\nclass LFWTest(testing.DatasetBuilderTestCase):\n  """"""Test Class.""""""\n  DATASET_CLASS = lfw.LFW\n\n  SPLITS = {\n      ""train"": 8,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/malaria.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for Malaria dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport fnmatch\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_URL = ""https://ceb.nlm.nih.gov/proj/malaria/cell_images.zip""\n\n_DESCRIPTION = (""""""The Malaria dataset contains a total of 27,558 cell images\nwith equal instances of parasitized and uninfected cells from the thin blood \nsmear slide images of segmented cells."""""")\n\n_NAMES = [""parasitized"", ""uninfected""]\n\n_IMAGE_SHAPE = (None, None, 3)\n\n_CITATION = """"""\\\n @article{rajaraman2018pre,\n  title={Pre-trained convolutional neural networks as feature extractors toward \n  improved malaria parasite detection in thin blood smear images},\n  author={Rajaraman, Sivaramakrishnan and Antani, Sameer K and Poostchi, Mahdieh\n  and Silamut, Kamolrat and Hossain, Md A and Maude, Richard J and Jaeger, \n  Stefan and Thoma, George R},\n  journal={PeerJ},\n  volume={6},\n  pages={e4568},\n  year={2018},\n  publisher={PeerJ Inc.}\n}\n""""""\n\n\nclass Malaria(tfds.core.GeneratorBasedBuilder):\n  """"""Malaria Cell Image Dataset Class.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    """"""Define Dataset Info.""""""\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(names=_NAMES),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://lhncbc.nlm.nih.gov/publication/pub9932"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Define Splits.""""""\n\n    path = dl_manager.download_and_extract(_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""data_dir_path"": os.path.join(path, ""cell_images""),\n            },\n        ),\n    ]\n\n  def _generate_examples(self, data_dir_path):\n    """"""Generate images and labels for splits.""""""\n    folder_names = [""Parasitized"", ""Uninfected""]\n\n    for folder in folder_names:\n      folder_path = os.path.join(data_dir_path, folder)\n      for file_name in tf.io.gfile.listdir(folder_path):\n        if fnmatch.fnmatch(file_name, ""*.png""):\n          image = os.path.join(folder_path, file_name)\n          label = folder.lower()\n          image_id = ""%s_%s"" % (folder, file_name)\n          yield image_id, {""image"": image, ""label"": label}\n'"
tensorflow_datasets/image_classification/malaria_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Malaria Dataset Test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import malaria\n\n\nclass MalariaTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = malaria.Malaria\n  SPLITS = {\n      ""train"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/mnist.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""MNIST, Fashion MNIST, KMNIST and EMNIST.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n# MNIST constants\n# CVDF mirror of http://yann.lecun.com/exdb/mnist/\n_MNIST_URL = ""https://storage.googleapis.com/cvdf-datasets/mnist/""\n_MNIST_TRAIN_DATA_FILENAME = ""train-images-idx3-ubyte.gz""\n_MNIST_TRAIN_LABELS_FILENAME = ""train-labels-idx1-ubyte.gz""\n_MNIST_TEST_DATA_FILENAME = ""t10k-images-idx3-ubyte.gz""\n_MNIST_TEST_LABELS_FILENAME = ""t10k-labels-idx1-ubyte.gz""\n_MNIST_IMAGE_SIZE = 28\nMNIST_IMAGE_SHAPE = (_MNIST_IMAGE_SIZE, _MNIST_IMAGE_SIZE, 1)\nMNIST_NUM_CLASSES = 10\n_TRAIN_EXAMPLES = 60000\n_TEST_EXAMPLES = 10000\n\n_MNIST_CITATION = """"""\\\n@article{lecun2010mnist,\n  title={MNIST handwritten digit database},\n  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n  volume={2},\n  year={2010}\n}\n""""""\n\n_FASHION_MNIST_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1708-07747,\n  author    = {Han Xiao and\n               Kashif Rasul and\n               Roland Vollgraf},\n  title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n               Algorithms},\n  journal   = {CoRR},\n  volume    = {abs/1708.07747},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.07747},\n  archivePrefix = {arXiv},\n  eprint    = {1708.07747},\n  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_K_MNIST_CITATION = """"""\\\n  @online{clanuwat2018deep,\n  author       = {Tarin Clanuwat and Mikel Bober-Irizar and Asanobu Kitamoto and Alex Lamb and Kazuaki Yamamoto and David Ha},\n  title        = {Deep Learning for Classical Japanese Literature},\n  date         = {2018-12-03},\n  year         = {2018},\n  eprintclass  = {cs.CV},\n  eprinttype   = {arXiv},\n  eprint       = {cs.CV/1812.01718},\n}\n""""""\n\n_EMNIST_CITATION = """"""\\\n@article{cohen_afshar_tapson_schaik_2017,\n    title={EMNIST: Extending MNIST to handwritten letters},\n    DOI={10.1109/ijcnn.2017.7966217},\n    journal={2017 International Joint Conference on Neural Networks (IJCNN)},\n    author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},\n    year={2017}\n}\n""""""\n\n\nclass MNIST(tfds.core.GeneratorBasedBuilder):\n  """"""MNIST.""""""\n  URL = _MNIST_URL\n\n  VERSION = tfds.core.Version(""3.0.1"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""The MNIST database of handwritten digits.""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=MNIST_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(num_classes=MNIST_NUM_CLASSES),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://yann.lecun.com/exdb/mnist/"",\n        citation=_MNIST_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # Download the full MNIST Database\n    filenames = {\n        ""train_data"": _MNIST_TRAIN_DATA_FILENAME,\n        ""train_labels"": _MNIST_TRAIN_LABELS_FILENAME,\n        ""test_data"": _MNIST_TEST_DATA_FILENAME,\n        ""test_labels"": _MNIST_TEST_LABELS_FILENAME,\n    }\n    mnist_files = dl_manager.download_and_extract(\n        {k: urllib.parse.urljoin(self.URL, v) for k, v in filenames.items()})\n\n    # MNIST provides TRAIN and TEST splits, not a VALIDATION split, so we only\n    # write the TRAIN and TEST splits to disk.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                num_examples=_TRAIN_EXAMPLES,\n                data_path=mnist_files[""train_data""],\n                label_path=mnist_files[""train_labels""],\n            )),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                num_examples=_TEST_EXAMPLES,\n                data_path=mnist_files[""test_data""],\n                label_path=mnist_files[""test_labels""],\n            )),\n    ]\n\n  def _generate_examples(self, num_examples, data_path, label_path):\n    """"""Generate MNIST examples as dicts.\n\n    Args:\n      num_examples (int): The number of example.\n      data_path (str): Path to the data files\n      label_path (str): Path to the labels\n\n    Yields:\n      Generator yielding the next examples\n    """"""\n    images = _extract_mnist_images(data_path, num_examples)\n    labels = _extract_mnist_labels(label_path, num_examples)\n    data = list(zip(images, labels))\n\n    # Using index as key since data is always loaded in same order.\n    for index, (image, label) in enumerate(data):\n      record = {""image"": image, ""label"": label}\n      yield index, record\n\n\nclass FashionMNIST(MNIST):\n  URL = ""http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/""\n\n  # TODO(afrozm): Try to inherit from MNIST\'s _info and mutate things as needed.\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""Fashion-MNIST is a dataset of Zalando\'s article images ""\n                     ""consisting of a training set of 60,000 examples and a ""\n                     ""test set of 10,000 examples. Each example is a 28x28 ""\n                     ""grayscale image, associated with a label from 10 ""\n                     ""classes.""),\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(shape=MNIST_IMAGE_SHAPE),\n            ""label"":\n                tfds.features.ClassLabel(names=[\n                    ""T-shirt/top"", ""Trouser"", ""Pullover"", ""Dress"", ""Coat"",\n                    ""Sandal"", ""Shirt"", ""Sneaker"", ""Bag"", ""Ankle boot""\n                ]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://github.com/zalandoresearch/fashion-mnist"",\n        citation=_FASHION_MNIST_CITATION,\n    )\n\n\nclass KMNIST(MNIST):\n  URL = ""http://codh.rois.ac.jp/kmnist/dataset/kmnist/""\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""Kuzushiji-MNIST is a drop-in replacement for the MNIST ""\n                     ""dataset (28x28 grayscale, 70,000 images), provided in ""\n                     ""the original MNIST format as well as a NumPy format. ""\n                     ""Since MNIST restricts us to 10 classes, we chose one ""\n                     ""character to represent each of the 10 rows of Hiragana ""\n                     ""when creating Kuzushiji-MNIST.""),\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(shape=MNIST_IMAGE_SHAPE),\n            ""label"":\n                tfds.features.ClassLabel(names=[\n                    ""o"", ""ki"", ""su"", ""tsu"", ""na"", ""ha"", ""ma"", ""ya"", ""re"", ""wo""\n                ]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://codh.rois.ac.jp/kmnist/index.html.en"",\n        citation=_K_MNIST_CITATION,\n    )\n\n\nclass EMNISTConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for EMNIST CONFIG.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, class_number, train_examples, test_examples, **kwargs):\n    """"""BuilderConfig for EMNIST class number.\n\n    Args:\n      class_number: There are six different splits provided in this dataset. And\n        have different class numbers.\n      train_examples: number of train examples\n      test_examples: number of test examples\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(EMNISTConfig, self).__init__(\n        version=tfds.core.Version(\n            ""3.0.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.class_number = class_number\n    self.train_examples = train_examples\n    self.test_examples = test_examples\n\n\nclass EMNIST(MNIST):\n  """"""Emnist dataset.""""""\n  URL = ""https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip""\n  VERSION = None  # Configs.\n\n  BUILDER_CONFIGS = [\n      EMNISTConfig(\n          name=""byclass"",\n          class_number=62,\n          train_examples=697932,\n          test_examples=116323,\n          description=""EMNIST ByClass"",\n\n      ),\n      EMNISTConfig(\n          name=""bymerge"",\n          class_number=47,\n          train_examples=697932,\n          test_examples=116323,\n          description=""EMNIST ByMerge"",\n      ),\n      EMNISTConfig(\n          name=""balanced"",\n          class_number=47,\n          train_examples=112800,\n          test_examples=18800,\n          description=""EMNIST Balanced"",\n      ),\n      EMNISTConfig(\n          name=""letters"",\n          class_number=37,\n          train_examples=88800,\n          test_examples=14800,\n          description=""EMNIST Letters"",\n      ),\n      EMNISTConfig(\n          name=""digits"",\n          class_number=10,\n          train_examples=240000,\n          test_examples=40000,\n          description=""EMNIST Digits"",\n      ),\n      EMNISTConfig(\n          name=""mnist"",\n          class_number=10,\n          train_examples=60000,\n          test_examples=10000,\n          description=""EMNIST MNIST"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(\n            ""The EMNIST dataset is a set of handwritten character digits ""\n            ""derived from the NIST Special Database 19 and converted to ""\n            ""a 28x28 pixel image format and dataset structure that directly ""\n            ""matches the MNIST dataset.\\n\\n""\n            ""Note: Like the original EMNIST data, images provided here are ""\n            ""inverted horizontally and rotated 90 anti-clockwise. You can use ""\n            ""`tf.transpose` within `ds.map` to convert the images to a ""\n            ""human-friendlier format.""),\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(shape=MNIST_IMAGE_SHAPE),\n            ""label"":\n                tfds.features.ClassLabel(\n                    num_classes=self.builder_config.class_number),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=(""https://www.nist.gov/itl/products-and-services/""\n                  ""emnist-dataset""),\n        citation=_EMNIST_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    filenames = {\n        ""train_data"":\n            ""emnist-{}-train-images-idx3-ubyte.gz"".format(\n                self.builder_config.name),\n        ""train_labels"":\n            ""emnist-{}-train-labels-idx1-ubyte.gz"".format(\n                self.builder_config.name),\n        ""test_data"":\n            ""emnist-{}-test-images-idx3-ubyte.gz"".format(\n                self.builder_config.name),\n        ""test_labels"":\n            ""emnist-{}-test-labels-idx1-ubyte.gz"".format(\n                self.builder_config.name),\n    }\n\n    dir_name = os.path.join(dl_manager.download_and_extract(self.URL), ""gzip"")\n    extracted = dl_manager.extract({\n        k: os.path.join(dir_name, fname) for k, fname in filenames.items()\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                num_examples=self.builder_config.train_examples,\n                data_path=extracted[""train_data""],\n                label_path=extracted[""train_labels""],\n            )),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                num_examples=self.builder_config.test_examples,\n                data_path=extracted[""test_data""],\n                label_path=extracted[""test_labels""],\n            ))\n    ]\n\n\ndef _extract_mnist_images(image_filepath, num_images):\n  with tf.io.gfile.GFile(image_filepath, ""rb"") as f:\n    f.read(16)  # header\n    buf = f.read(_MNIST_IMAGE_SIZE * _MNIST_IMAGE_SIZE * num_images)\n    data = np.frombuffer(\n        buf,\n        dtype=np.uint8,\n    ).reshape(num_images, _MNIST_IMAGE_SIZE, _MNIST_IMAGE_SIZE, 1)\n    return data\n\n\ndef _extract_mnist_labels(labels_filepath, num_labels):\n  with tf.io.gfile.GFile(labels_filepath, ""rb"") as f:\n    f.read(8)  # header\n    buf = f.read(num_labels)\n    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n    return labels\n'"
tensorflow_datasets/image_classification/mnist_corrupted.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Corrupted MNIST Dataset.\n\nMNISTCorrupted is a dataset generated by adding 15 corruptions to the test\nimages in the MNIST dataset. This dataset wraps the static, corrupted MNIST\ntest images uploaded by the original authors.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.image_classification import mnist\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nMNISTCorrupted is a dataset generated by adding 15 corruptions to the test\nimages in the MNIST dataset. This dataset wraps the static, corrupted MNIST\ntest images uploaded by the original authors\n""""""\n\n_CITATION = """"""\n@article{mu2019mnist,\n  title={MNIST-C: A Robustness Benchmark for Computer Vision},\n  author={Mu, Norman and Gilmer, Justin},\n  journal={arXiv preprint arXiv:1906.02337},\n  year={2019}\n}\n""""""\n\n_DOWNLOAD_URL = \'https://zenodo.org/record/3239543/files/mnist_c.zip\'\n_CORRUPTIONS = [\n    \'identity\',\n    \'shot_noise\',\n    \'impulse_noise\',\n    \'glass_blur\',\n    \'motion_blur\',\n    \'shear\',\n    \'scale\',\n    \'rotate\',\n    \'brightness\',\n    \'translate\',\n    \'stripe\',\n    \'fog\',\n    \'spatter\',\n    \'dotted_line\',\n    \'zigzag\',\n    \'canny_edges\',\n]\n_DIRNAME = \'mnist_c\'\n_TRAIN_IMAGES_FILENAME = \'train_images.npy\'\n_TEST_IMAGES_FILENAME = \'test_images.npy\'\n_TRAIN_LABELS_FILENAME = \'train_labels.npy\'\n_TEST_LABELS_FILENAME = \'test_labels.npy\'\n\n\nclass MNISTCorruptedConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for MNISTcorrupted.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, corruption_type, **kwargs):\n    """"""Constructor.\n\n    Args:\n      corruption_type: string, name of corruption from _CORRUPTIONS.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(MNISTCorruptedConfig, self).__init__(**kwargs)\n    self.corruption = corruption_type\n\n\ndef _make_builder_configs():\n  """"""Construct a list of BuilderConfigs.\n\n  Construct a list of 15 MNISTCorruptedConfig objects, corresponding to\n  the 15 corruption types.\n\n  Returns:\n    A list of 15 MNISTCorruptedConfig objects.\n  """"""\n  config_list = []\n  for corruption in _CORRUPTIONS:\n    config_list.append(\n        MNISTCorruptedConfig(\n            name=corruption,\n            version=tfds.core.Version(\n                \'1.0.0\',\n                \'New split API (https://tensorflow.org/datasets/splits)\'),\n            description=\'Corruption method: \' + corruption,\n            corruption_type=corruption,\n        ))\n  return config_list\n\n\nclass MNISTCorrupted(tfds.core.GeneratorBasedBuilder):\n  """"""Corrupted MNIST dataset.""""""\n  BUILDER_CONFIGS = _make_builder_configs()\n\n  def _info(self):\n    """"""Returns basic information of dataset.\n\n    Returns:\n      tfds.core.DatasetInfo.\n    """"""\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\':\n                tfds.features.Image(shape=mnist.MNIST_IMAGE_SHAPE),\n            \'label\':\n                tfds.features.ClassLabel(num_classes=mnist.MNIST_NUM_CLASSES),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://github.com/google-research/mnist-c\',\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    """"""Return the train, test split of MNIST-C.\n\n    Args:\n      dl_manager: download manager object.\n\n    Returns:\n      train split, test split.\n    """"""\n    path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'data_dir\': os.path.join(path, _DIRNAME),\n                \'is_train\': True\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'data_dir\': os.path.join(path, _DIRNAME),\n                \'is_train\': False\n            }),\n    ]\n\n  def _generate_examples(self, data_dir, is_train):\n    """"""Generate corrupted MNIST data.\n\n    Apply corruptions to the raw images according to self.corruption_type.\n\n    Args:\n      data_dir: root directory of downloaded dataset\n      is_train: whether to return train images or test images\n\n    Yields:\n      dictionary with image file and label.\n    """"""\n    corruption = self.builder_config.corruption\n\n    if is_train:\n      images_file = os.path.join(data_dir, corruption, _TRAIN_IMAGES_FILENAME)\n      labels_file = os.path.join(data_dir, corruption, _TRAIN_LABELS_FILENAME)\n    else:\n      images_file = os.path.join(data_dir, corruption, _TEST_IMAGES_FILENAME)\n      labels_file = os.path.join(data_dir, corruption, _TEST_LABELS_FILENAME)\n\n    with tf.io.gfile.GFile(labels_file, mode=\'rb\') as f:\n      labels = np.load(f)\n\n    with tf.io.gfile.GFile(images_file, mode=\'rb\') as f:\n      images = np.load(f)\n\n    for i, (image, label) in enumerate(zip(images, labels)):\n      yield i, {\n          \'image\': image,\n          \'label\': label,\n      }\n'"
tensorflow_datasets/image_classification/mnist_corrupted_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for corrupted MNIST.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import mnist_corrupted\n\n\nclass MNISTCorruptedTest(testing.DatasetBuilderTestCase):\n\n  BUILDER_CONFIG_NAMES_TO_TEST = [""dotted_line""]\n\n  DATASET_CLASS = mnist_corrupted.MNISTCorrupted\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/mnist_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for mnist dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import mnist\n\n\n# testing/mnist.py generates fake input data\n\nmnist._TRAIN_EXAMPLES = 10  # pylint: disable=protected-access\nmnist._TEST_EXAMPLES = 2  # pylint: disable=protected-access\n\n\nclass MNISTTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = mnist.MNIST\n  SPLITS = {\n      ""train"": 10,\n      ""test"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_data"": ""train-image"",\n      ""train_labels"": ""train-label"",\n      ""test_data"": ""test-image"",\n      ""test_labels"": ""test-label"",\n  }\n\n\nclass FashionMNISTTest(MNISTTest):\n  DATASET_CLASS = mnist.FashionMNIST\n\n\nclass KMNISTTest(MNISTTest):\n  DATASET_CLASS = mnist.KMNIST\n\n\nmnist.EMNIST.BUILDER_CONFIGS.extend([\n    mnist.EMNISTConfig(\n        name=""test"",\n        class_number=200,\n        train_examples=10,\n        test_examples=2,\n        description=""EMNIST test data config."",\n    ),\n])\n\n\nclass EMNISTTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = mnist.EMNIST\n  SPLITS = {\n      ""train"": 10,\n      ""test"": 2,\n  }\n  BUILDER_CONFIG_NAMES_TO_TEST = [""test""]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/omniglot.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Omniglot dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{lake2015human,\n  title={Human-level concept learning through probabilistic program induction},\n  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},\n  journal={Science},\n  volume={350},\n  number={6266},\n  pages={1332--1338},\n  year={2015},\n  publisher={American Association for the Advancement of Science}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nOmniglot data set for one-shot learning. This dataset contains 1623 different\nhandwritten characters from 50 different alphabets.\n""""""\n\n_BASE_URL = ""https://github.com/brendenlake/omniglot/""\n_DL_URL = _BASE_URL + ""raw/master/python/""\n_DL_URLS = {\n    ""train"": _DL_URL + ""images_background.zip"",\n    ""eval"": _DL_URL + ""images_evaluation.zip"",\n    ""small1"": _DL_URL + ""images_background_small1.zip"",\n    ""small2"": _DL_URL + ""images_background_small2.zip"",\n}\n\n_NUM_CLASSES = 1623\n_NUM_ALPHABETS = 50\n\n\nclass Omniglot(tfds.core.GeneratorBasedBuilder):\n  """"""Omniglot dataset.""""""\n\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"":\n                tfds.features.Image(shape=(105, 105, 3), encoding_format=""png""),\n            ""alphabet"":\n                tfds.features.ClassLabel(num_classes=_NUM_ALPHABETS),\n            ""alphabet_char_id"":\n                tf.int64,\n            ""label"":\n                tfds.features.ClassLabel(num_classes=_NUM_CLASSES),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_BASE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    extracted_dirs = dl_manager.download_and_extract(_DL_URLS)\n\n    # Get all alphabets and labels\n    alphabets, label_names = _get_names(extracted_dirs.values())\n    self.info.features[""alphabet""].names = sorted(alphabets)\n    self.info.features[""label""].names = label_names\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""directory"": extracted_dirs[""train""],\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""directory"": extracted_dirs[""eval""],\n            }),\n        tfds.core.SplitGenerator(\n            name=""small1"",\n            gen_kwargs={\n                ""directory"": extracted_dirs[""small1""],\n            }),\n        tfds.core.SplitGenerator(\n            name=""small2"",\n            gen_kwargs={\n                ""directory"": extracted_dirs[""small2""],\n            }),\n    ]\n\n  def _generate_examples(self, directory):\n    for example in _walk_omniglot_dir(directory):\n      alphabet, alphabet_char_id, label, image_path, image_id = example\n      record = {\n          ""image"": image_path,\n          ""alphabet"": alphabet,\n          ""alphabet_char_id"": alphabet_char_id,\n          ""label"": label,\n      }\n      yield image_id, record\n\n\ndef _walk_omniglot_dir(directory):\n  """"""Walk an Omniglot directory and yield examples.""""""\n  directory = os.path.join(directory, tf.io.gfile.listdir(directory)[0])\n  alphabets = sorted(tf.io.gfile.listdir(directory))\n  for alphabet in alphabets:\n    alphabet_dir = os.path.join(directory, alphabet)\n    characters = sorted(tf.io.gfile.listdir(alphabet_dir))\n    for character in characters:\n      character_id = int(character[len(""character""):]) - 1\n      character_dir = os.path.join(alphabet_dir, character)\n      images = tf.io.gfile.listdir(character_dir)\n      for image in images:\n        label, _ = image.split(""_"")\n        label = int(label) - 1\n        image_path = os.path.join(character_dir, image)\n        image_id = ""%s_%d_%s"" % (alphabet, character_id, image)\n        yield alphabet, character_id, label, image_path, image_id\n\n\ndef _get_names(dirs):\n  """"""Get alphabet and label names, union across all dirs.""""""\n  alphabets = set()\n  label_names = {}\n  for d in dirs:\n    for example in _walk_omniglot_dir(d):\n      alphabet, alphabet_char_id, label, _, _ = example\n      alphabets.add(alphabet)\n      label_name = ""%s_%d"" % (alphabet, alphabet_char_id)\n      if label in label_names:\n        assert label_names[label] == label_name\n      else:\n        label_names[label] = label_name\n  label_names = [label_names[k] for k in sorted(label_names)]\n  return alphabets, label_names\n'"
tensorflow_datasets/image_classification/oxford_flowers102.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Oxford 102 Category Flower Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_BASE_URL = ""https://www.robots.ox.ac.uk/~vgg/data/flowers/102/""\n\n_NAMES = [\n    ""pink primrose"", ""hard-leaved pocket orchid"", ""canterbury bells"",\n    ""sweet pea"", ""english marigold"", ""tiger lily"", ""moon orchid"",\n    ""bird of paradise"", ""monkshood"", ""globe thistle"", ""snapdragon"",\n    ""colt\'s foot"", ""king protea"", ""spear thistle"", ""yellow iris"",\n    ""globe-flower"", ""purple coneflower"", ""peruvian lily"", ""balloon flower"",\n    ""giant white arum lily"", ""fire lily"", ""pincushion flower"", ""fritillary"",\n    ""red ginger"", ""grape hyacinth"", ""corn poppy"", ""prince of wales feathers"",\n    ""stemless gentian"", ""artichoke"", ""sweet william"", ""carnation"",\n    ""garden phlox"", ""love in the mist"", ""mexican aster"", ""alpine sea holly"",\n    ""ruby-lipped cattleya"", ""cape flower"", ""great masterwort"", ""siam tulip"",\n    ""lenten rose"", ""barbeton daisy"", ""daffodil"", ""sword lily"", ""poinsettia"",\n    ""bolero deep blue"", ""wallflower"", ""marigold"", ""buttercup"", ""oxeye daisy"",\n    ""common dandelion"", ""petunia"", ""wild pansy"", ""primula"", ""sunflower"",\n    ""pelargonium"", ""bishop of llandaff"", ""gaura"", ""geranium"", ""orange dahlia"",\n    ""pink-yellow dahlia?"", ""cautleya spicata"", ""japanese anemone"",\n    ""black-eyed susan"", ""silverbush"", ""californian poppy"", ""osteospermum"",\n    ""spring crocus"", ""bearded iris"", ""windflower"", ""tree poppy"", ""gazania"",\n    ""azalea"", ""water lily"", ""rose"", ""thorn apple"", ""morning glory"",\n    ""passion flower"", ""lotus"", ""toad lily"", ""anthurium"", ""frangipani"",\n    ""clematis"", ""hibiscus"", ""columbine"", ""desert-rose"", ""tree mallow"",\n    ""magnolia"", ""cyclamen"", ""watercress"", ""canna lily"", ""hippeastrum"",\n    ""bee balm"", ""ball moss"", ""foxglove"", ""bougainvillea"", ""camellia"", ""mallow"",\n    ""mexican petunia"", ""bromelia"", ""blanket flower"", ""trumpet creeper"",\n    ""blackberry lily""\n]\n\n_CITATION = """"""\\\n@InProceedings{Nilsback08,\n   author = ""Nilsback, M-E. and Zisserman, A."",\n   title = ""Automated Flower Classification over a Large Number of Classes"",\n   booktitle = ""Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing"",\n   year = ""2008"",\n   month = ""Dec""\n}\n""""""\n\n_DESCRIPTION = """"""\nThe Oxford Flowers 102 dataset is a consistent of 102 flower categories commonly occurring\nin the United Kingdom. Each class consists of between 40 and 258 images. The images have\nlarge scale, pose and light variations. In addition, there are categories that have large\nvariations within the category and several very similar categories.\n\nThe dataset is divided into a training set, a validation set and a test set.\nThe training set and validation set each consist of 10 images per class (totalling 1020 images each).\nThe test set consists of the remaining 6149 images (minimum 20 per class).\n""""""\n\n\nclass OxfordFlowers102(tfds.core.GeneratorBasedBuilder):\n  """"""Oxford 102 category flower dataset.""""""\n\n  VERSION = tfds.core.Version(""2.1.1"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names=_NAMES),\n            ""file_name"": tfds.features.Text(),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_BASE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # Download images and annotations that come in separate archives.\n    # Note, that the extension of archives is .tar.gz even though the actual\n    # archives format is uncompressed tar.\n    dl_paths = dl_manager.download_and_extract({\n        ""images"": tfds.download.Resource(\n            url=os.path.join(_BASE_URL, ""102flowers.tgz""),\n            extract_method=tfds.download.ExtractMethod.TAR),\n        ""labels"": os.path.join(_BASE_URL, ""imagelabels.mat""),\n        ""setid"": os.path.join(_BASE_URL, ""setid.mat""),\n    })\n\n    gen_kwargs = dict(\n        images_dir_path=os.path.join(dl_paths[""images""], ""jpg""),\n        labels_path=dl_paths[""labels""],\n        setid_path=dl_paths[""setid""],\n    )\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(split_name=""trnid"", **gen_kwargs)),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(split_name=""tstid"", **gen_kwargs)),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(split_name=""valid"", **gen_kwargs)),\n    ]\n\n  def _generate_examples(self, images_dir_path, labels_path, setid_path,\n                         split_name):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(labels_path, ""rb"") as f:\n      labels = tfds.core.lazy_imports.scipy.io.loadmat(f)[""labels""][0]\n    with tf.io.gfile.GFile(setid_path, ""rb"") as f:\n      examples = tfds.core.lazy_imports.scipy.io.loadmat(f)[split_name][0]\n\n    for image_id in examples:\n      file_name = ""image_%05d.jpg"" % image_id\n      record = {\n          ""image"": os.path.join(images_dir_path, file_name),\n          ""label"": labels[image_id - 1] - 1,\n          ""file_name"": file_name,\n      }\n      yield file_name, record\n'"
tensorflow_datasets/image_classification/oxford_flowers102_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TODO(oxford_102_flowers): Add a description here.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import oxford_flowers102\n\n\nclass OxfordFlowers102Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = oxford_flowers102.OxfordFlowers102\n  SPLITS = {\n      ""train"": 3,\n      ""test"": 3,\n      ""validation"": 4,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""images"": ""images"",\n      ""labels"": ""imagelabels.mat"",\n      ""setid"": ""setid.mat"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/image_classification/oxford_iiit_pet.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Oxford-IIIT pet dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = """"""\\\nThe Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\nimages for each class. The images have large variations in scale, pose and\nlighting. All images have an associated ground truth annotation of breed.\n""""""\n\n\n_CITATION = """"""\\\n@InProceedings{parkhi12a,\n  author       = ""Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V."",\n  title        = ""Cats and Dogs"",\n  booktitle    = ""IEEE Conference on Computer Vision and Pattern Recognition"",\n  year         = ""2012"",\n}\n""""""\n\n_BASE_URL = ""http://www.robots.ox.ac.uk/~vgg/data/pets/data""\n\n_LABEL_CLASSES = [\n    ""Abyssinian"", ""american_bulldog"", ""american_pit_bull_terrier"",\n    ""basset_hound"", ""beagle"", ""Bengal"", ""Birman"", ""Bombay"", ""boxer"",\n    ""British_Shorthair"", ""chihuahua"", ""Egyptian_Mau"", ""english_cocker_spaniel"",\n    ""english_setter"", ""german_shorthaired"", ""great_pyrenees"", ""havanese"",\n    ""japanese_chin"", ""keeshond"", ""leonberger"", ""Maine_Coon"",\n    ""miniature_pinscher"", ""newfoundland"", ""Persian"", ""pomeranian"", ""pug"",\n    ""Ragdoll"", ""Russian_Blue"", ""saint_bernard"", ""samoyed"", ""scottish_terrier"",\n    ""shiba_inu"", ""Siamese"", ""Sphynx"", ""staffordshire_bull_terrier"",\n    ""wheaten_terrier"", ""yorkshire_terrier""\n]\n_SPECIES_CLASSES = [""Cat"", ""Dog""]\n\n\nclass OxfordIIITPet(tfds.core.GeneratorBasedBuilder):\n  """"""Oxford-IIIT pet dataset.""""""\n\n  VERSION = tfds.core.Version(""3.2.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names=_LABEL_CLASSES),\n            ""species"": tfds.features.ClassLabel(names=_SPECIES_CLASSES),\n            ""file_name"": tfds.features.Text(),\n            ""segmentation_mask"": tfds.features.Image(shape=(None, None, 1))\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://www.robots.ox.ac.uk/~vgg/data/pets/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns splits.""""""\n    # Download images and annotations that come in separate archives.\n    # Note, that the extension of archives is .tar.gz even though the actual\n    # archives format is uncompressed tar.\n    dl_paths = dl_manager.download_and_extract({\n        ""images"": tfds.download.Resource(\n            url=_BASE_URL + ""/images.tar.gz"",\n            extract_method=tfds.download.ExtractMethod.TAR),\n        ""annotations"": tfds.download.Resource(\n            url=_BASE_URL + ""/annotations.tar.gz"",\n            extract_method=tfds.download.ExtractMethod.TAR)\n    })\n\n    images_path_dir = os.path.join(dl_paths[""images""], ""images"")\n    annotations_path_dir = os.path.join(dl_paths[""annotations""], ""annotations"")\n\n    # Setup train and test splits\n    train_split = tfds.core.SplitGenerator(\n        name=""train"",\n        gen_kwargs={\n            ""images_dir_path"": images_path_dir,\n            ""annotations_dir_path"": annotations_path_dir,\n            ""images_list_file"": os.path.join(annotations_path_dir,\n                                             ""trainval.txt""),\n            },\n        )\n    test_split = tfds.core.SplitGenerator(\n        name=""test"",\n        gen_kwargs={\n            ""images_dir_path"": images_path_dir,\n            ""annotations_dir_path"": annotations_path_dir,\n            ""images_list_file"": os.path.join(annotations_path_dir,\n                                             ""test.txt"")\n            },\n        )\n\n    return [train_split, test_split]\n\n  def _generate_examples(self, images_dir_path, annotations_dir_path,\n                         images_list_file):\n    with tf.io.gfile.GFile(images_list_file, ""r"") as images_list:\n      for line in images_list:\n        image_name, label, species, _ = line.strip().split("" "")\n\n        trimaps_dir_path = os.path.join(annotations_dir_path, ""trimaps"")\n\n        trimap_name = image_name + "".png""\n        image_name += "".jpg""\n        label = int(label) - 1\n        species = int(species) - 1\n\n        record = {\n            ""image"": os.path.join(images_dir_path, image_name),\n            ""label"": int(label),\n            ""species"": species,\n            ""file_name"": image_name,\n            ""segmentation_mask"": os.path.join(trimaps_dir_path, trimap_name)\n        }\n        yield image_name, record\n'"
tensorflow_datasets/image_classification/oxford_iiit_pet_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for imagenet dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification.oxford_iiit_pet import OxfordIIITPet\n\n\nclass OxfordIIITPetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = OxfordIIITPet\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 5,\n      ""test"": 5,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""images"": ""."",\n      ""annotations"": ""."",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/patch_camelyon.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""PatchCamelyon images dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nThe PatchCamelyon benchmark is a new and challenging image classification\ndataset. It consists of 327.680 color images (96 x 96px) extracted from\nhistopathologic scans of lymph node sections. Each image is annoted with a\nbinary label indicating presence of metastatic tissue. PCam provides a new\nbenchmark for machine learning models: bigger than CIFAR10, smaller than\nImagenet, trainable on a single GPU.\n""""""\n_CITATION = """"""\\\n@misc{b_s_veeling_j_linmans_j_winkens_t_cohen_2018_2546921,\n  author       = {B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling},\n  title        = {Rotation Equivariant CNNs for Digital Pathology},\n  month        = sep,\n  year         = 2018,\n  doi          = {10.1007/978-3-030-00934-2_24},\n  url          = {https://doi.org/10.1007/978-3-030-00934-2_24}\n}\n""""""\n_URL = \'https://patchcamelyon.grand-challenge.org/\'\n\n\nclass PatchCamelyon(tfds.core.GeneratorBasedBuilder):\n  """"""PatchCamelyon.""""""\n\n  VERSION = tfds.core.Version(\n      \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'id\':\n                tfds.features.Text(),\n            \'image\':\n                tfds.features.Image(shape=(96, 96, 3), encoding_format=\'png\'),\n            \'label\':\n                tfds.features.ClassLabel(num_classes=2),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    base_url = \'https://zenodo.org/record/2546921/files/\'\n    resources = {\n        \'test_x\': base_url + \'camelyonpatch_level_2_split_test_x.h5.gz\',\n        \'test_y\': base_url + \'camelyonpatch_level_2_split_test_y.h5.gz\',\n        \'train_x\': base_url + \'camelyonpatch_level_2_split_train_x.h5.gz\',\n        \'train_y\': base_url + \'camelyonpatch_level_2_split_train_y.h5.gz\',\n        \'valid_x\': base_url + \'camelyonpatch_level_2_split_valid_x.h5.gz\',\n        \'valid_y\': base_url + \'camelyonpatch_level_2_split_valid_y.h5.gz\',\n    }\n    paths = dl_manager.download_and_extract(resources)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(split=\'test\', paths=paths)),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(split=\'train\', paths=paths)),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(split=\'valid\', paths=paths)),\n    ]\n\n  def _generate_examples(self, split, paths):\n    """"""Generates images and labels given the image directory path.\n\n    Args:\n      split: name of the split to generate examples for (test, train, valid).\n      paths: dictionary with the paths to the h5 files for each split.\n\n    Yields:\n      A dictionary with the image and the corresponding label.\n    """"""\n    h5py = tfds.core.lazy_imports.h5py\n\n    filepath_x = paths[split + \'_x\']\n    filepath_y = paths[split + \'_y\']\n    with h5py.File(filepath_x, \'r\') as f_x, h5py.File(filepath_y, \'r\') as f_y:\n      images = f_x[\'x\']\n      labels = f_y[\'y\']  # Note: Labels are in a N x 1 x 1 x 1 tensor.\n\n      for i, (image, label) in enumerate(zip(images, labels)):\n        label = label.flatten()[0]\n        id_ = \'%s_%d\' % (split, i)\n        record = {\'id\': id_, \'image\': image, \'label\': label}\n        yield id_, record\n'"
tensorflow_datasets/image_classification/patch_camelyon_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for camelyon_patch.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import patch_camelyon\n\n\nclass PatchCamelyonTest(testing.DatasetBuilderTestCase):\n\n  DATASET_CLASS = patch_camelyon.PatchCamelyon\n\n  SPLITS = {\n      \'train\': 5,\n      \'test\': 4,\n      \'validation\': 3,\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'train_x\': \'camelyonpatch_level_2_split_train_x.h5\',\n      \'train_y\': \'camelyonpatch_level_2_split_train_y.h5\',\n      \'test_x\': \'camelyonpatch_level_2_split_test_x.h5\',\n      \'test_y\': \'camelyonpatch_level_2_split_test_y.h5\',\n      \'valid_x\': \'camelyonpatch_level_2_split_valid_x.h5\',\n      \'valid_y\': \'camelyonpatch_level_2_split_valid_y.h5\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/pet_finder.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""PetFinder Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# petfinder: BibTeX citation\n_CITATION = """"""\n@ONLINE {kaggle-petfinder-adoption-prediction,\n    author = ""Kaggle and PetFinder.my"",\n    title  = ""PetFinder.my Adoption Prediction"",\n    month  = ""april"",\n    year   = ""2019"",\n    url    = ""https://www.kaggle.com/c/petfinder-adoption-prediction/data/""\n}\n""""""\n\n_URL = (""https://storage.googleapis.com/petfinder_dataset/"")\n_DATA_OPTIONS = [\n    ""test_metadata"", ""test_images"", ""test_sentiment"", ""train_metadata"",\n    ""train_images"", ""train_sentiment""\n]\n_LABEL_OPTIONS = [\n    ""test"", ""train"", ""breed_labels"", ""state_labels"", ""color_labels""\n]\n\n_DL_URLS = {name: _URL + name + "".zip"" for name in _DATA_OPTIONS}\n_DL_URLS.update({label: _URL + label + "".csv"" for label in _LABEL_OPTIONS})\n\n_INT_FEATS = [\n    ""Type"", ""Age"", ""Breed1"", ""Breed2"", ""Gender"", ""Color1"", ""Color2"", ""Color3"",\n    ""MaturitySize"", ""FurLength"", ""Vaccinated"", ""Dewormed"", ""Sterilized"",\n    ""Health"", ""Quantity"", ""Fee"", ""State"", ""VideoAmt""\n]\n_FLOAT_FEATS = [""PhotoAmt""]\n_OBJ_FEATS = [""name"", ""Type"", ""PetID"", ""RescurID""]\n_DESCRIPTION = ((\n    ""A large set of images of cats and dogs.""\n    ""Together with the metadata information of sentiment information.""))\n\n\nclass PetFinder(tfds.core.GeneratorBasedBuilder):\n  """"""Pet Finder.""""""\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""Dataset with images from 5 classes (see config name for ""\n        ""information on the specific class)"",\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""PetID"": tfds.features.Text(),\n            ""attributes"": {name: tf.int64 for name in _INT_FEATS},\n            ""label"": tfds.features.ClassLabel(num_classes=5),\n        }),\n        supervised_keys=(""attributes"", ""label""),\n        homepage=""https://www.kaggle.com/c/petfinder-adoption-prediction/data"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # petfinder: Downloads the data and defines the splits\n    # dl_manager is a tfds.download.DownloadManager that can be used to\n    # download and extract URLs\n    # dl_paths = dl_manager.download_kaggle_data(url)\n    dl_paths = dl_manager.download_and_extract(_DL_URLS)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""csv_name"": ""train.csv"",\n                ""csv_paths"": dl_paths[""train""],\n                ""img_paths"": dl_paths[""train_images""],\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""csv_name"": ""test.csv"",\n                ""csv_paths"": dl_paths[""test""],\n                ""img_paths"": dl_paths[""test_images""],\n            },\n        ),\n    ]\n\n  def _generate_examples(self, csv_name, csv_paths, img_paths):\n    """"""Yields examples.\n\n    Args:\n      csv_name: file name for the csv file used in the split\n      csv_paths: Path to csv files containing the label and attributes\n        information.\n      img_paths: Path to images.\n    """"""\n    pd = tfds.core.lazy_imports.pandas\n\n    if not tf.io.gfile.exists(csv_paths):\n      raise AssertionError(""{} not exist"".format(csv_name))\n    with tf.io.gfile.GFile(csv_paths) as csv_file:\n      dataframe = pd.read_csv(csv_file)\n    # add a dummy label for test set\n    if csv_name == ""test.csv"":\n      dataframe[""AdoptionSpeed""] = -1\n\n    images = tf.io.gfile.listdir(img_paths)\n    for image in images:\n      pet_id = image.split(""-"")[0]\n      image_path = os.path.join(img_paths, image)\n      attr_dict = dataframe.loc[dataframe[""PetID""] == pet_id]\n      record = {\n          ""image"": image_path,\n          ""image/filename"": image,\n          ""PetID"": pet_id,\n          ""attributes"": attr_dict[_INT_FEATS].to_dict(""records"")[0],\n          ""label"": attr_dict[""AdoptionSpeed""].values[0]\n      }\n      yield image, record\n'"
tensorflow_datasets/image_classification/pet_finder_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for PetFinder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import pet_finder\n\n\nclass PetFinderTest(testing.DatasetBuilderTestCase):\n  # petfinder:\n  DATASET_CLASS = pet_finder.PetFinder\n  SPLITS = {\n      \'train\': 2,  # Number of fake train example\n      \'test\': 2,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = {\n      \'train\': \'train.csv\',\n      \'train_images\': \'train_images\',\n      \'test\': \'test.csv\',\n      \'test_images\': \'test_images\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/places365_small.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Dataset class for Places365-Standard small(256x256) dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport csv\nimport os\nimport six.moves.urllib as urllib\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_BASE_URL = ""http://data.csail.mit.edu/places/places365/""\n_TRAIN_URL = ""train_256_places365standard.tar""\n_TEST_URL = ""test_256.tar""\n_VALID_URL = ""val_256.tar""\n_FILE_ANNOTATION_URL = ""filelist_places365-standard.tar""\n\n_IMAGE_SHAPE = (256, 256, 3)\n\n_DESCRIPTION = (\n    ""The Places365-Standard dataset contains 1.8 million train images from 365""\n    "" scene categories,which are used to train the Places365 CNNs.There are 50""\n    "" images per category in the validation set and 900 images per category in""\n    "" the testing set."")\n\n_LABELS_FNAME = ""image_classification/categories_places365.txt""\n\n_CITATION = """"""\\\n\n @article{zhou2017places,\n  title={Places: A 10 million Image Database for Scene Recognition},\n  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  year={2017},\n  publisher={IEEE}\n}\n\n""""""\n\n\nclass Places365Small(tfds.core.GeneratorBasedBuilder):\n  """"""Places365 Images dataset.""""""\n\n  VERSION = tfds.core.Version(""2.0.0"")\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(_DESCRIPTION),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(names_file=names_file),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://places2.csail.mit.edu/"",\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n    output_archives = dl_manager.download({\n        ""train"": urllib.parse.urljoin(_BASE_URL, _TRAIN_URL),\n        ""test"": urllib.parse.urljoin(_BASE_URL, _TEST_URL),\n        ""validation"": urllib.parse.urljoin(_BASE_URL, _VALID_URL),\n    })\n    annotation_path = dl_manager.download_and_extract(\n        urllib.parse.urljoin(_BASE_URL, _FILE_ANNOTATION_URL))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=""train"",\n            gen_kwargs={\n                ""archive"":\n                    dl_manager.iter_archive(output_archives[""train""]),\n                ""path_prefix"":\n                    ""data_256"",\n                ""annotation_path"":\n                    os.path.join(annotation_path,\n                                 ""places365_train_standard.txt""),\n                ""split_name"":\n                    ""train"",\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""test"",\n            gen_kwargs={\n                ""archive"":\n                    dl_manager.iter_archive(output_archives[""test""]),\n                ""path_prefix"":\n                    ""test_256"",\n                ""annotation_path"":\n                    os.path.join(annotation_path, ""places365_test.txt""),\n                ""split_name"":\n                    ""test"",\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""validation"",\n            gen_kwargs={\n                ""archive"":\n                    dl_manager.iter_archive(output_archives[""validation""]),\n                ""path_prefix"":\n                    ""val_256"",\n                ""annotation_path"":\n                    os.path.join(annotation_path, ""places365_val.txt""),\n                ""split_name"":\n                    ""validation"",\n            },\n        ),\n    ]\n\n  def _generate_examples(self, archive, path_prefix, split_name,\n                         annotation_path):\n    with tf.io.gfile.GFile(annotation_path) as f:\n      if split_name == ""test"":\n        # test split doesn\'t have labels assigned.\n        file_to_class = {x[0]: -1 for x in csv.reader(f, delimiter="" "")}\n      else:\n        file_to_class = {x[0]: int(x[1]) for x in csv.reader(f, delimiter="" "")}\n\n    for fname, fobj in archive:\n      fname = fname.replace(""\\\\"", ""/"")  # For windows compatibility\n      assert fname.startswith(path_prefix)\n      # The filenames in annotations for train start with ""/"" while the names\n      # for test and validation do not have a leading ""/"", so we chop\n      # differently.\n      chop = len(path_prefix) if split_name == ""train"" else len(path_prefix) + 1\n      key = fname[chop:]\n      class_id = file_to_class[key]\n      yield fname, {""image"": fobj, ""label"": class_id}\n'"
tensorflow_datasets/image_classification/places365_small_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets.image_classification import places365_small\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass Places365SmallTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = places365_small.Places365Small\n  SPLITS = {\'train\': 2, \'test\': 2, \'validation\': 2}\n\n  DL_DOWNLOAD_RESULT = {\n      \'train\': \'data_256.tar\',\n      \'test\': \'test_256.tar\',\n      \'validation\': \'val_256.tar\',\n  }\n  DL_EXTRACT_RESULT = \'annotation\'\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/plant_leaves.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Healthy and unhealthy plant leaves dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{,\n  author={Siddharth Singh Chouhan, Ajay Kaul, Uday Pratap Singh, Sanjeev\nJain},\n  title={A Database of Leaf Images: Practice towards Plant Conservation with\nPlant Pathology},\n  howpublished={Mendeley Data},\n  year={2019}\n}\n""""""\n\n_DESCRIPTION = """"""\nThis dataset consists of 4502 images of healthy and unhealthy plant leaves\ndivided into 22 categories by species and state of health. The images are in\nhigh resolution JPG format.\n\nThere are no files with label prefix 0000, therefore label encoding is shifted\nby one (e.g. file with label prefix 0001 gets encoded label 0).\n\nNote: Each image is a separate download. Some might rarely fail, therefore make\nsure to restart if that happens. An exception will be raised in case one of the\ndownloads repeatedly fails.\n\nDataset URL: https://data.mendeley.com/datasets/hb74ynkjcn/1\nLicense: http://creativecommons.org/licenses/by/4.0\n""""""\n\n# File name prefix to label mapping.\n_LABEL_MAPPING = [\n    (""0001"", ""Mango (P0) healthy""),\n    (""0002"", ""Arjun (P1) healthy""),\n    (""0003"", ""Alstonia Scholaris (P2) healthy""),\n    (""0004"", ""Gauva (P3) healthy""),\n    (""0005"", ""Jamun (P5) healthy""),\n    (""0006"", ""Jatropha (P6) healthy""),\n    (""0007"", ""Pongamia Pinnata (P7) healthy""),\n    (""0008"", ""Basil (P8) healthy""),\n    (""0009"", ""Pomegranate (P9) healthy""),\n    (""0010"", ""Lemon (P10) healthy""),\n    (""0011"", ""Chinar (P11) healthy""),\n    (""0012"", ""Mango (P0) diseased""),\n    (""0013"", ""Arjun (P1) diseased""),\n    (""0014"", ""Alstonia Scholaris (P2) diseased""),\n    (""0015"", ""Gauva (P3) diseased""),\n    (""0016"", ""Bael (P4) diseased""),\n    (""0017"", ""Jamun (P5) diseased""),\n    (""0018"", ""Jatropha (P6) diseased""),\n    (""0019"", ""Pongamia Pinnata (P7) diseased""),\n    (""0020"", ""Pomegranate (P9) diseased""),\n    (""0021"", ""Lemon (P10) diseased""),\n    (""0022"", ""Chinar (P11) diseased""),\n]\n_URLS_FNAME = ""image_classification/plant_leaves_urls.txt""\n_MAX_DOWNLOAD_RETRY = 10\n\n\nclass DownloadRetryLimitReachedError(Exception):\n  pass\n\n\nclass PlantLeaves(tfds.core.GeneratorBasedBuilder):\n  """"""Healthy and unhealthy plant leaves dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    labels = list(zip(*_LABEL_MAPPING))[1]\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(names=labels)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://data.mendeley.com/datasets/hb74ynkjcn/1"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # Batch download for this dataset is broken, therefore images have to be\n    # downloaded independently from a list of urls.\n    with tf.io.gfile.GFile(tfds.core.get_tfds_path(_URLS_FNAME)) as f:\n      name_to_url_map = {\n          os.path.basename(l.strip()): l.strip() for l in f.readlines()\n      }\n      retry_count = 0\n      image_files = {}\n      # We have to retry due to rare 504 HTTP errors. Downloads are cached,\n      # therefore this shouldn\'t cause successful downloads to be retried.\n      while True:\n        try:\n          image_files = dl_manager.download(name_to_url_map)\n          break\n        except tfds.download.DownloadError:\n          retry_count += 1\n          if retry_count == _MAX_DOWNLOAD_RETRY:\n            raise DownloadRetryLimitReachedError(\n                ""Retry limit reached. Try downloading the dataset again."")\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TRAIN,\n              gen_kwargs={""image_files"": image_files})\n      ]\n\n  def _generate_examples(self, image_files):\n    """"""Yields examples.""""""\n    label_map = {pattern: label for pattern, label in _LABEL_MAPPING}\n    regexp = re.compile(r""^(\\d\\d\\d\\d)_.*\\.JPG$"")\n    # Assigns labels to images based on label mapping.\n    for original_fname, fpath in image_files.items():\n      match = regexp.match(original_fname)\n      if match and match.group(1) in label_map:\n        label = label_map[match.group(1)]\n        record = {\n            ""image"": fpath,\n            ""image/filename"": original_fname,\n            ""label"": label,\n        }\n        yield original_fname, record\n'"
tensorflow_datasets/image_classification/plant_leaves_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for the PlantLeaves dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import plant_leaves\n\n\nclass PlantLeavesTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = plant_leaves.PlantLeaves\n  SPLITS = {""train"": 22}\n  # NOTE: Must match file names in the test directory.\n  DL_EXTRACT_RESULT = {\n      fname: fname for fname in\n      [""{0:04d}_1.JPG"".format(label_number) for label_number in range(1, 23)]\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/plant_village.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The PlantVillage dataset of healthy and unhealthy leaves.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{DBLP:journals/corr/HughesS15,\n  author    = {David P. Hughes and\n               Marcel Salath{\\\'{e}}},\n  title     = {An open access repository of images on plant health to enable the\n               development of mobile disease diagnostics through machine\n               learning and crowdsourcing},\n  journal   = {CoRR},\n  volume    = {abs/1511.08060},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1511.08060},\n  archivePrefix = {arXiv},\n  eprint    = {1511.08060},\n  timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/HughesS15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe PlantVillage dataset consists of 54303 healthy and unhealthy leaf images\ndivided into 38 categories by species and disease.\n\nNOTE: The original dataset is not available from the original source\n(plantvillage.org), therefore we get the unaugmented dataset from a paper that\nused that dataset and republished it. Moreover, we dropped images with\nBackground_without_leaves label, because these were not present in the original\ndataset.\n\nOriginal paper URL: https://arxiv.org/abs/1511.08060\nDataset URL: https://data.mendeley.com/datasets/tywbtsjrjv/1\n""""""\n\n_URL = ""https://data.mendeley.com/datasets/tywbtsjrjv/1/files/127d0761-7c63-46f0-b08e-d0d9f7cad9da/Plant_leaf_diseases_dataset_without_augmentation.zip""\n_LABELS = [\n    ""Apple___Apple_scab"",\n    ""Apple___Black_rot"",\n    ""Apple___Cedar_apple_rust"",\n    ""Apple___healthy"",\n    ""Blueberry___healthy"",\n    ""Cherry___healthy"",\n    ""Cherry___Powdery_mildew"",\n    ""Corn___Cercospora_leaf_spot Gray_leaf_spot"",\n    ""Corn___Common_rust"",\n    ""Corn___healthy"",\n    ""Corn___Northern_Leaf_Blight"",\n    ""Grape___Black_rot"",\n    ""Grape___Esca_(Black_Measles)"",\n    ""Grape___healthy"",\n    ""Grape___Leaf_blight_(Isariopsis_Leaf_Spot)"",\n    ""Orange___Haunglongbing_(Citrus_greening)"",\n    ""Peach___Bacterial_spot"",\n    ""Peach___healthy"",\n    ""Pepper,_bell___Bacterial_spot"",\n    ""Pepper,_bell___healthy"",\n    ""Potato___Early_blight"",\n    ""Potato___healthy"",\n    ""Potato___Late_blight"",\n    ""Raspberry___healthy"",\n    ""Soybean___healthy"",\n    ""Squash___Powdery_mildew"",\n    ""Strawberry___healthy"",\n    ""Strawberry___Leaf_scorch"",\n    ""Tomato___Bacterial_spot"",\n    ""Tomato___Early_blight"",\n    ""Tomato___healthy"",\n    ""Tomato___Late_blight"",\n    ""Tomato___Leaf_Mold"",\n    ""Tomato___Septoria_leaf_spot"",\n    ""Tomato___Spider_mites Two-spotted_spider_mite"",\n    ""Tomato___Target_Spot"",\n    ""Tomato___Tomato_mosaic_virus"",\n    ""Tomato___Tomato_Yellow_Leaf_Curl_Virus"",\n]\n\n\nclass PlantVillage(tfds.core.GeneratorBasedBuilder):\n  """"""The PlantVillage dataset of healthy and unhealthy leaves.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(names=_LABELS)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://arxiv.org/abs/1511.08060"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN, gen_kwargs={""datapath"": path})\n    ]\n\n  def _generate_examples(self, datapath):\n    """"""Yields examples.""""""\n    for label in _LABELS:\n      # The real dataset has spaces and commas in directories (label) names,\n      # which causes issues with objfs and fig. The solution is to replace these\n      # characters with underscores in fake data directories and then not care\n      # whether it\'s an underscore or that character.\n      fuzzy_label = label.replace("" "", ""[_ ]"").replace("","", ""[_,]"")\n      glob_path = os.path.join(\n          datapath, ""Plant_leave_diseases_dataset_without_augmentation"",\n          fuzzy_label, ""*.[jJ][pP][gG]"")\n      for fpath in tf.io.gfile.glob(glob_path):\n        fname = os.path.basename(fpath)\n        record = {\n            ""image"": fpath,\n            ""image/filename"": fname,\n            ""label"": label,\n        }\n        yield ""{}/{}"".format(label, fname), record\n'"
tensorflow_datasets/image_classification/plant_village_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for PlantVillage dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import plant_village\n\n\nclass PlantVillageTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = plant_village.PlantVillage\n  SPLITS = {""train"": 38}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/plantae_k.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Healthy and unhealthy plant leaves dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{,\n  author={Vippon Preet Kour, Sakshi Arora},\n  title={PlantaeK: A leaf database of native plants of Jammu and Kashmir},\n  howpublished={Mendeley Data},\n  year={2019}\n}\n""""""\n\n_DESCRIPTION = """"""\nThis dataset contains 2153 images of healthy and unhealthy plant leaves divided\n16 categories by species and state of health. The images are in high resolution\nJPG format.\n\nNote: Each image is a separate download. Some might rarely fail, therefore make\nsure to restart if that happens. An exception will be raised in case one of the\ndownloads repeatedly fails.\n\nDataset URL: https://data.mendeley.com/datasets/t6j2h22jpx/1\nLicense: http://creativecommons.org/licenses/by/4.0\n""""""\n\n# File name prefix to label mapping.\n_LABEL_MAPPING = [\n    (""apple_d"", ""APPLE DISEASED""),\n    (""apple_h"", ""APPLE HEALTHY""),\n    (""apricot_d"", ""APRICOT DISEASED""),\n    (""apricot_h"", ""APRICOT HEALTHY""),\n    (""cherry_d"", ""CHERRY DISEASED""),\n    (""cherry_h"", ""CHERRY HEALTHY""),\n    (""cranberry_d"", ""CRANBERRY DISEASED""),\n    (""cranberry_h"", ""CRANBERRY HEALTHY""),\n    (""grapes_d"", ""GRAPES DISEASED""),\n    (""grapes_h"", ""GRAPES HEALTHY""),\n    (""peach_d"", ""PEACH DISEASED""),\n    (""peach_h"", ""PEACH HEALTHY""),\n    (""pear_d"", ""PEAR DISEASED""),\n    (""pear_h"", ""PEAR HEALTHY""),\n    (""walnut_d"", ""WALNUT DISEASED""),\n    # There\'s a bug in file naming. walnut_h* files are still diseased.\n    (""walnut_h"", ""WALNUT DISEASED""),\n    (""walnut-h"", ""WALNUT HEALTHY""),\n]\n_URLS_FNAME = ""image_classification/plantae_k_urls.txt""\n_MAX_DOWNLOAD_RETRY = 10\n\n\nclass DownloadRetryLimitReachedError(Exception):\n  pass\n\n\nclass PlantaeK(tfds.core.GeneratorBasedBuilder):\n  """"""Healthy and unhealthy plant leaves dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    labels = sorted(set(list(zip(*_LABEL_MAPPING))[1]))\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(names=labels)\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""https://data.mendeley.com/datasets/t6j2h22jpx/1"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    # Batch download for this dataset is broken, therefore images have to be\n    # downloaded independently from a list of urls.\n    with tf.io.gfile.GFile(tfds.core.get_tfds_path(_URLS_FNAME)) as f:\n      name_to_url_map = {\n          os.path.basename(l.strip()): l.strip() for l in f.readlines()\n      }\n      retry_count = 0\n      image_files = {}\n      # We have to retry due to rare 504 HTTP errors. Downloads are cached,\n      # therefore this shouldn\'t cause successful downloads to be retried.\n      while True:\n        try:\n          image_files = dl_manager.download(name_to_url_map)\n          break\n        except tfds.download.DownloadError:\n          retry_count += 1\n          if retry_count == _MAX_DOWNLOAD_RETRY:\n            raise DownloadRetryLimitReachedError(\n                ""Retry limit reached. Try downloading the dataset again."")\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TRAIN,\n              gen_kwargs={""image_files"": image_files})\n      ]\n\n  def _generate_examples(self, image_files):\n    """"""Yields examples.""""""\n    label_map = {pattern: label for pattern, label in _LABEL_MAPPING}\n    regexp = re.compile(r""^(\\w+[-_][dh])\\d+\\.JPG$"")\n    # Assigns labels to images based on label mapping.\n    for original_fname, fpath in image_files.items():\n      match = regexp.match(original_fname)\n      if match and match.group(1) in label_map:\n        label = label_map[match.group(1)]\n        record = {\n            ""image"": fpath,\n            ""image/filename"": original_fname,\n            ""label"": label,\n        }\n        yield original_fname, record\n'"
tensorflow_datasets/image_classification/plantae_k_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for the PlantLeaves dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import plantae_k\n\n\nclass PlantaeKTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = plantae_k.PlantaeK\n  # See note below about the +1\n  SPLITS = {""train"": 16 + 1}\n  _LABEL_TAGS = [\n      ""apple_d"", ""apple_h"", ""apricot_d"", ""apricot_h"", ""cherry_d"", ""cherry_h"",\n      ""cranberry_d"", ""cranberry_h"", ""grapes_d"", ""grapes_h"", ""peach_d"",\n      ""peach_h"", ""pear_d"", ""pear_h"", ""walnut_d"", ""walnut_h"", ""walnut-h""\n  ]\n  # NOTE: Must match file names in the test directory. Due to bug in file naming\n  # we have to have both walnut_d and walnut_h for healthy walnut.\n  DL_EXTRACT_RESULT = {\n      fname: fname\n      for fname in [""{}1.JPG"".format(label_tag) for label_tag in _LABEL_TAGS]\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/quickdraw.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""QuickDraw dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# Shared constants\n_QUICKDRAW_IMAGE_SIZE = 28\n_QUICKDRAW_IMAGE_SHAPE = (_QUICKDRAW_IMAGE_SIZE, _QUICKDRAW_IMAGE_SIZE, 1)\n_QUICKDRAW_BASE_URL = ""https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap""  # pylint: disable=line-too-long\n_QUICKDRAW_LABELS_FNAME = ""image_classification/quickdraw_labels.txt""\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/HaE17,\n  author    = {David Ha and\n               Douglas Eck},\n  title     = {A Neural Representation of Sketch Drawings},\n  journal   = {CoRR},\n  volume    = {abs/1704.03477},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.03477},\n  archivePrefix = {arXiv},\n  eprint    = {1704.03477},\n  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/HaE17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_URL = ""https://github.com/googlecreativelab/quickdraw-dataset""\n\n\nclass QuickdrawBitmap(tfds.core.GeneratorBasedBuilder):\n  """"""Quickdraw bitmap dataset.\n\n  This is the version of the QuickDraw data in which 28x28 grayscale images\n  are generated from the raw vector information (i.e. the \'bitmap\' dataset, not\n  the \'raw\' or \'simplified drawings\' datasets).\n  """"""\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    labels_path = tfds.core.get_tfds_path(_QUICKDRAW_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(""The Quick Draw Dataset is a collection of 50 million ""\n                     ""drawings across 345 categories, contributed by players ""\n                     ""of the game Quick, Draw!. The bitmap dataset contains ""\n                     ""these drawings converted from vector format into 28x28 ""\n                     ""grayscale images""),\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_QUICKDRAW_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(names_file=labels_path),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION\n    )\n\n  def _split_generators(self, dl_manager):\n    # The QuickDraw bitmap repository is structured as one .npy file per label.\n    labels = self.info.features[""label""].names\n    urls = {label: ""{}/{}.npy"".format(_QUICKDRAW_BASE_URL, label)\n            for label in labels}\n\n    file_paths = dl_manager.download(urls)\n\n    # There is no predefined train/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""file_paths"": file_paths,\n            })\n    ]\n\n  def _generate_examples(self, file_paths):\n    """"""Generate QuickDraw bitmap examples.\n\n    Given a list of file paths with data for each class label, generate examples\n    in a random order.\n\n    Args:\n      file_paths: (dict of {str: str}) the paths to files containing the data,\n                  indexed by label.\n\n    Yields:\n      The QuickDraw examples, as defined in the dataset info features.\n    """"""\n    for label, path in sorted(file_paths.items(), key=lambda x: x[0]):\n      with tf.io.gfile.GFile(path, ""rb"") as f:\n        class_images = np.load(f)\n        for i, np_image in enumerate(class_images):\n          record = {\n              ""image"": np_image.reshape(_QUICKDRAW_IMAGE_SHAPE),\n              ""label"": label,\n          }\n          yield ""%s_%i"" % (label, i), record\n'"
tensorflow_datasets/image_classification/quickdraw_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Quickdraw data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import quickdraw\n\n\nclass QuickdrawTest(testing.DatasetBuilderTestCase):\n\n  DATASET_CLASS = quickdraw.QuickdrawBitmap\n  SPLITS = {\n      ""train"": 9,\n  }\n  DL_EXTRACT_RESULT = {\n      ""airplane"": ""airplane.npy"",\n      ""ambulance"": ""ambulance.npy"",\n      ""angel"": ""angel.npy"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/resisc45.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Remote Sensing Image Scene Classification (RESISC45) Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{Cheng_2017,\n   title={Remote Sensing Image Scene Classification: Benchmark and State of the Art},\n   volume={105},\n   ISSN={1558-2256},\n   url={http://dx.doi.org/10.1109/JPROC.2017.2675998},\n   DOI={10.1109/jproc.2017.2675998},\n   number={10},\n   journal={Proceedings of the IEEE},\n   publisher={Institute of Electrical and Electronics Engineers (IEEE)},\n   author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},\n   year={2017},\n   month={Oct},\n   pages={1865-1883}\n}""""""\n\n_DESCRIPTION = """"""\\\nRESISC45 dataset is a publicly available benchmark for Remote Sensing Image\nScene Classification (RESISC), created by Northwestern Polytechnical University\n(NWPU). This dataset contains 31,500 images, covering 45 scene classes with 700\nimages in each class.""""""\n\n_LABELS = [\n    \'airplane\', \'airport\', \'baseball_diamond\', \'basketball_court\', \'beach\',\n    \'bridge\', \'chaparral\', \'church\', \'circular_farmland\', \'cloud\',\n    \'commercial_area\', \'dense_residential\', \'desert\', \'forest\', \'freeway\',\n    \'golf_course\', \'ground_track_field\', \'harbor\', \'industrial_area\',\n    \'intersection\', \'island\', \'lake\', \'meadow\', \'medium_residential\',\n    \'mobile_home_park\', \'mountain\', \'overpass\', \'palace\', \'parking_lot\',\n    \'railway\', \'railway_station\', \'rectangular_farmland\', \'river\', \'roundabout\',\n    \'runway\', \'sea_ice\', \'ship\', \'snowberg\', \'sparse_residential\', \'stadium\',\n    \'storage_tank\', \'tennis_court\', \'terrace\', \'thermal_power_station\',\n    \'wetland\'\n]\n\n_URL = \'http://www.escience.cn/people/JunweiHan/NWPU-RESISC45.html\'\n\n\nclass Resisc45(tfds.core.GeneratorBasedBuilder):\n  """"""NWPU Remote Sensing Image Scene Classification (RESISC) Dataset.""""""\n\n  VERSION = tfds.core.Version(\'3.0.0\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Dataset can be downloaded from OneDrive:\n  https://1drv.ms/u/s!AmgKYzARBl5ca3HNaHIlzp_IXjs\n  After downloading the rar file, please extract it to the manual_dir.\n  """"""\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(shape=[256, 256, 3]),\n            \'label\': tfds.features.ClassLabel(names=_LABELS),\n            \'filename\': tfds.features.Text(),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = os.path.join(dl_manager.manual_dir, \'NWPU-RESISC45\')\n    if not tf.io.gfile.exists(path):\n      raise AssertionError(\'You must download the dataset manually from {}, \'\n                           \'extract it, and place it in {}.\'.format(\n                               _URL, dl_manager.manual_dir))\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'path\': path},\n        ),\n    ]\n\n  def _generate_examples(self, path):\n    """"""Yields examples.""""""\n    for label in tf.io.gfile.listdir(path):\n      for filename in tf.io.gfile.glob(os.path.join(path, label, \'*.jpg\')):\n        example = {\n            \'image\': filename,\n            \'label\': label,\n            \'filename\': os.path.basename(filename)\n        }\n        yield filename, example\n'"
tensorflow_datasets/image_classification/resisc45_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RESICS45.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import resisc45\n\n\nclass Resisc45Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = resisc45.Resisc45\n  SPLITS = {\n      ""train"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/rock_paper_scissors.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Rock, Paper, Scissors dataset.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@ONLINE {rps,\nauthor = ""Laurence Moroney"",\ntitle = ""Rock, Paper, Scissors Dataset"",\nmonth = ""feb"",\nyear = ""2019"",\nurl = ""http://laurencemoroney.com/rock-paper-scissors-dataset""\n}\n""""""\n\n_TRAIN_URL = ""https://storage.googleapis.com/download.tensorflow.org/data/rps.zip""\n_TEST_URL = ""https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip""\n\n_IMAGE_SIZE = 300\n_IMAGE_SHAPE = (_IMAGE_SIZE, _IMAGE_SIZE, 3)\n\n_NAME_RE = re.compile(\n    r""^(rps|rps-test-set)(?:/|\\\\)(rock|paper|scissors)(?:/|\\\\)[\\w-]*\\.png$""\n)\n\n\nclass RockPaperScissors(tfds.core.GeneratorBasedBuilder):\n  """"""Rock, Paper, Scissors dataset.""""""\n\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""Images of hands playing rock, paper, scissor game."",\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=_IMAGE_SHAPE),\n            ""label"": tfds.features.ClassLabel(\n                names=[""rock"", ""paper"", ""scissors""]),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://laurencemoroney.com/rock-paper-scissors-dataset"",\n        citation=_CITATION\n        )\n\n  def _split_generators(self, dl_manager):\n    train_path, test_path = dl_manager.download([_TRAIN_URL, _TEST_URL])\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(train_path),\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(test_path),\n            }),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Generate rock, paper or scissors images and labels given the directory path.\n\n    Args:\n      archive: object that iterates over the zip.\n\n    Yields:\n      The image path and its corresponding label.\n    """"""\n\n    for fname, fobj in archive:\n      res = _NAME_RE.match(fname)\n      if not res:  # if anything other than .png; skip\n        continue\n      label = res.group(2).lower()\n      record = {\n          ""image"": fobj,\n          ""label"": label,\n      }\n      yield fname, record\n'"
tensorflow_datasets/image_classification/rock_paper_scissors_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Rock, Paper, Scissors data module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import rock_paper_scissors\nimport tensorflow_datasets.testing as tfds_test\n\nrock_paper_scissors._IMAGE_SHAPE = (None, None, 3)  # pylint: disable=protected-access\n\n\nclass RockPaperScissorsTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = rock_paper_scissors.RockPaperScissors\n\n  SPLITS = {\n      \'train\': 3,\n      \'test\': 3,\n  }\n\n  DL_EXTRACT_RESULT = [\'rps_train.zip\', \'rps_test.zip\']\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/smallnorb.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Smallnorb dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six import moves\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = r""""""\\\n@article{LeCun2004LearningMF,\n  title={Learning methods for generic object recognition with invariance to pose and lighting},\n  author={Yann LeCun and Fu Jie Huang and L{\\\'e}on Bottou},\n  journal={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n  year={2004},\n  volume={2},\n  pages={II-104 Vol.2}\n}\n""""""\n\n_TRAINING_URL_TEMPLATE = (\n    ""https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/""\n    ""smallnorb-5x46789x9x18x6x2x96x96-training-{type}.mat.gz"")\n_TESTING_URL_TEMPLATE = (\n    ""https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/""\n    ""smallnorb-5x01235x9x18x6x2x96x96-testing-{type}.mat.gz"")\n\n_DESCRIPTION = r""""""\\\nThis database is intended for experiments in 3D object recognition from shape. It contains images of 50 toys belonging to 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. The objects were imaged by two cameras under 6 lighting conditions, 9 elevations (30 to 70 degrees every 5 degrees), and 18 azimuths (0 to 340 every 20 degrees).\n\nThe training set is composed of 5 instances of each category (instances 4, 6, 7, 8 and 9), and the test set of the remaining 5 instances (instances 0, 1, 2, 3, and 5).\n""""""\n\n\nclass Smallnorb(tfds.core.GeneratorBasedBuilder):\n  """"""Smallnorb data set.""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""2.1.0""),\n  ]\n\n  def _info(self):\n    features_dict = {\n        ""image"":\n            tfds.features.Image(shape=(96, 96, 1)),\n        ""image2"":\n            tfds.features.Image(shape=(96, 96, 1)),\n        ""label_category"":\n            tfds.features.ClassLabel(names=[\n                ""four-legged animals"",\n                ""human figures"",\n                ""airplanes"",\n                ""trucks"",\n                ""cars"",\n            ]),\n        ""instance"":\n            tfds.features.ClassLabel(num_classes=10),\n        ""label_elevation"":\n            tfds.features.ClassLabel(num_classes=9),\n        ""label_azimuth"":\n            tfds.features.ClassLabel(num_classes=18),\n        ""label_lighting"":\n            tfds.features.ClassLabel(num_classes=6),\n    }\n    if self.version > ""2.0.0"":\n      features_dict[""id""] = tfds.features.Text()\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features_dict),\n        homepage=""https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/"",\n        citation=_CITATION,\n        supervised_keys=(""image"", ""label_category""),\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns splits.""""""\n    filenames = {\n        ""training_dat"": _TRAINING_URL_TEMPLATE.format(type=""dat""),\n        ""training_cat"": _TRAINING_URL_TEMPLATE.format(type=""cat""),\n        ""training_info"": _TRAINING_URL_TEMPLATE.format(type=""info""),\n        ""testing_dat"": _TESTING_URL_TEMPLATE.format(type=""dat""),\n        ""testing_cat"": _TESTING_URL_TEMPLATE.format(type=""cat""),\n        ""testing_info"": _TESTING_URL_TEMPLATE.format(type=""info""),\n    }\n\n    files = dl_manager.download_and_extract(filenames)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                split_prefix=""train_"",\n                dat_path=files[""training_dat""],\n                cat_path=files[""training_cat""],\n                info_path=files[""training_info""])),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                split_prefix=""test_"",\n                dat_path=files[""testing_dat""],\n                cat_path=files[""testing_cat""],\n                info_path=files[""testing_info""])),\n    ]\n\n  def _generate_examples(self, split_prefix, dat_path, cat_path, info_path):\n    """"""Generate examples for the Smallnorb dataset.\n\n    Args:\n      split_prefix: Prefix that identifies the split.\n      dat_path: Path to dat file of the chunk.\n      cat_path: Path to cat file of the chunk.\n      info_path: Path to info file of the chunk.\n\n    Yields:\n      Dictionaries with images and the different labels.\n    """"""\n    dat_arr, cat_arr, info_arr = _load_chunk(dat_path, cat_path, info_path)\n\n    for i, (image, category, info_vec) in enumerate(moves.zip(\n        dat_arr, cat_arr, info_arr)):\n      record = {\n          ""image"": image[0],\n          ""image2"": image[1],\n          ""label_category"": category,\n          ""instance"": info_vec[0],\n          ""label_elevation"": info_vec[1],\n          ""label_azimuth"": info_vec[2],\n          ""label_lighting"": info_vec[3],\n      }\n      if self.version > ""2.0.0"":\n        record[""id""] = ""{}{:05d}"".format(split_prefix, i)\n      yield i, record\n\n\ndef _load_chunk(dat_path, cat_path, info_path):\n  """"""Loads a data chunk as specified by the paths.\n\n  Args:\n    dat_path: Path to dat file of the chunk.\n    cat_path: Path to cat file of the chunk.\n    info_path: Path to info file of the chunk.\n\n  Returns:\n    Tuple with the dat, cat, info_arrays.\n  """"""\n  dat_array = read_binary_matrix(dat_path)\n  # Even if the image is gray scale, we need to add an extra channel dimension\n  # to be compatible with tfds.features.Image.\n  dat_array = np.expand_dims(dat_array, -1)\n\n  cat_array = read_binary_matrix(cat_path)\n\n  info_array = read_binary_matrix(info_path)\n  info_array = np.copy(info_array)  # Make read-only buffer array writable.\n  # Azimuth values are 0, 2, 4, .., 34. We divide by 2 to get proper labels.\n  info_array[:, 2] = info_array[:, 2] / 2\n\n  return dat_array, cat_array, info_array\n\n\ndef read_binary_matrix(filename):\n  """"""Reads and returns binary formatted matrix stored in filename.\n\n  The file format is described on the data set page:\n  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/\n\n  Args:\n    filename: String with path to the file.\n\n  Returns:\n    Numpy array contained in the file.\n  """"""\n  with tf.io.gfile.GFile(filename, ""rb"") as f:\n    s = f.read()\n\n    # Data is stored in little-endian byte order.\n    int32_dtype = np.dtype(""int32"").newbyteorder(""<"")\n\n    # The first 4 bytes contain a magic code that specifies the data type.\n    magic = int(np.frombuffer(s, dtype=int32_dtype, count=1))\n    if magic == 507333717:\n      data_dtype = np.dtype(""uint8"")  # uint8 does not have a byte order.\n    elif magic == 507333716:\n      data_dtype = np.dtype(""int32"").newbyteorder(""<"")\n    else:\n      raise ValueError(""Invalid magic value for data type!"")\n\n    # The second 4 bytes contain an int32 with the number of dimensions of the\n    # stored array.\n    ndim = int(np.frombuffer(s, dtype=int32_dtype, count=1, offset=4))\n\n    # The next ndim x 4 bytes contain the shape of the array in int32.\n    dims = np.frombuffer(s, dtype=int32_dtype, count=ndim, offset=8)\n\n    # If the array has less than three dimensions, three int32 are still used to\n    # save the shape info (remaining int32 are simply set to 1). The shape info\n    # hence uses max(3, ndim) bytes.\n    bytes_used_for_shape_info = max(3, ndim) * 4\n\n    # The remaining bytes are the array.\n    data = np.frombuffer(\n        s, dtype=data_dtype, offset=8 + bytes_used_for_shape_info)\n  return data.reshape(tuple(dims))\n'"
tensorflow_datasets/image_classification/smallnorb_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Smallnorb dataset test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import smallnorb\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass SmallnorbTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = smallnorb.Smallnorb\n  SPLITS = {""train"": 5, ""test"": 5}\n  DL_EXTRACT_RESULT = {\n      ""training_dat"": ""smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat"",\n      ""training_cat"": ""smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat"",\n      ""training_info"": ""smallnorb-5x46789x9x18x6x2x96x96-training-info.mat"",\n      ""testing_dat"": ""smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat"",\n      ""testing_cat"": ""smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat"",\n      ""testing_info"": ""smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat"",\n  }\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/so2sat.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""So2SAT remote sensing dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nSo2Sat LCZ42 is a dataset consisting of co-registered synthetic aperture radar\nand multispectral optical image patches acquired by the Sentinel-1 and\nSentinel-2 remote sensing satellites, and the corresponding local climate zones\n(LCZ) label. The dataset is distributed over 42 cities across different\ncontinents and cultural regions of the world.\n\nThe full dataset (`all`) consists of 8 Sentinel-1 and 10 Sentinel-2 channels.\nAlternatively, one can select the `rgb` subset, which contains only the optical\nfrequency bands of Sentinel-2, rescaled and encoded as JPEG.\n\nDataset URL: http://doi.org/10.14459/2018MP1454690\nLicense: http://creativecommons.org/licenses/by/4.0\n""""""\n\n_LABELS = [\n    \'Compact high-rise\', \'Compact mid-rise\', \'Compact low-rise\',\n    \'Open high-rise\', \'Open mid-rise\', \'Open low-rise\', \'Lightweight low-rise\',\n    \'Large low-rise\', \'Sparsely built\', \'Heavy industry\', \'Dense trees\',\n    \'Scattered trees\', \'Bush or scrub\', \'Low plants\', \'Bare rock or paved\',\n    \'Bare soil or sand\', \'Water\'\n]\n\n_DATA_OPTIONS = [\'rgb\', \'all\']\n\n# Calibration for the optical RGB channels of Sentinel-2 in this dataset.\n_OPTICAL_CALIBRATION_FACTOR = 3.5 * 255.0\n\n\nclass So2satConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for so2sat.""""""\n\n  def __init__(self, selection=None, **kwargs):\n    """"""Constructs a So2satConfig.\n\n    Args:\n      selection: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if selection not in _DATA_OPTIONS:\n      raise ValueError(\'selection must be one of %s\' % _DATA_OPTIONS)\n\n    v2 = tfds.core.Version(\n        \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n    v2_1 = tfds.core.Version(\n        \'2.1.0\', \'Using updated optical channels calibration factor.\')\n    super(So2satConfig, self).__init__(version=v2_1,\n                                       supported_versions=[v2],\n                                       **kwargs)\n    self.selection = selection\n\n\nclass So2sat(tfds.core.GeneratorBasedBuilder):\n  """"""So2SAT remote sensing dataset.""""""\n\n  BUILDER_CONFIGS = [\n      So2satConfig(\n          selection=\'rgb\',\n          name=\'rgb\',\n          description=\'Sentinel-2 RGB channels\'),\n      So2satConfig(\n          selection=\'all\',\n          name=\'all\',\n          description=\'8 Sentinel-1 and 10 Sentinel-2 channels\'),\n  ]\n\n  def _info(self):\n    if self.builder_config.selection == \'rgb\':\n      features = tfds.features.FeaturesDict({\n          \'image\': tfds.features.Image(shape=[32, 32, 3]),\n          \'label\': tfds.features.ClassLabel(names=_LABELS),\n          \'sample_id\': tfds.features.Tensor(shape=(), dtype=tf.int64),\n      })\n      supervised_keys = (\'image\', \'label\')\n    elif self.builder_config.selection == \'all\':\n      features = tfds.features.FeaturesDict({\n          \'sentinel1\':\n              tfds.features.Tensor(shape=[32, 32, 8], dtype=tf.float32),\n          \'sentinel2\':\n              tfds.features.Tensor(shape=[32, 32, 10], dtype=tf.float32),\n          \'label\':\n              tfds.features.ClassLabel(names=_LABELS),\n          \'sample_id\':\n              tfds.features.Tensor(shape=(), dtype=tf.int64),\n      })\n      supervised_keys = None\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=features,\n        supervised_keys=supervised_keys,\n        homepage=\'http://doi.org/10.14459/2018MP1454690\',\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    paths = dl_manager.download({\n        \'train\': \'ftp://m1454690:m1454690@dataserv.ub.tum.de/training.h5\',\n        \'val\': \'ftp://m1454690:m1454690@dataserv.ub.tum.de/validation.h5\'\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'path\': paths[\'train\'],\n                \'selection\': self.builder_config.selection,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'path\': paths[\'val\'],\n                \'selection\': self.builder_config.selection,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, path, selection):\n    """"""Yields examples.""""""\n    with tfds.core.lazy_imports.h5py.File(path, \'r\') as fid:\n      sen1 = fid[\'sen1\']\n      sen2 = fid[\'sen2\']\n      label = fid[\'label\']\n      for i in range(len(sen1)):\n        if selection == \'rgb\':\n          record = {\n              \'image\': _create_rgb(sen2[i]),\n              \'label\': np.argmax(label[i]).astype(int),\n              \'sample_id\': i,\n          }\n        elif selection == \'all\':\n          record = {\n              \'sentinel1\': sen1[i].astype(np.float32),\n              \'sentinel2\': sen2[i].astype(np.float32),\n              \'label\': np.argmax(label[i]).astype(int),\n              \'sample_id\': i,\n          }\n        yield i, record\n\n\ndef _create_rgb(sen2_bands):\n  return np.clip(sen2_bands[..., [2, 1, 0]] * _OPTICAL_CALIBRATION_FACTOR, 0,\n                 255).astype(np.uint8)\n'"
tensorflow_datasets/image_classification/so2sat_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TODO(so2sat): Add a description here.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import so2sat\n\n\nclass So2satTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = so2sat.So2sat\n  SPLITS = {\n      ""train"": 5,  # Number of fake train example\n      ""validation"": 3,  # Number of fake validation example\n  }\n  DL_EXTRACT_RESULT = {\n      ""train"": ""./training.h5"",\n      ""val"": ""./validation.h5"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/stanford_dogs.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Stanford dogs dataset.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport re\nimport xml.etree.ElementTree as ET\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nThe Stanford Dogs dataset contains images of 120 breeds of dogs from around\nthe world. This dataset has been built using images and annotation from\nImageNet for the task of fine-grained image categorization. There are\n20,580 images, out of which 12,000 are used for training and 8580 for\ntesting. Class labels and bounding box annotations are provided\nfor all the 12,000 images.\n""""""\n\n_URL = (""http://vision.stanford.edu/aditya86/ImageNetDogs/main.html"")\n\n_CITATION = """"""\\\n@inproceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,\nauthor = ""Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and\n          Li Fei-Fei"",\ntitle = ""Novel Dataset for Fine-Grained Image Categorization"",\nbooktitle = ""First Workshop on Fine-Grained Visual Categorization,\n             IEEE Conference on Computer Vision and Pattern Recognition"",\nyear = ""2011"",\nmonth = ""June"",\naddress = ""Colorado Springs, CO"",\n}\n@inproceedings{imagenet_cvpr09,\n        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and\n                  Li, K. and Fei-Fei, L.},\n        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},\n        BOOKTITLE = {CVPR09},\n        YEAR = {2009},\n        BIBSOURCE = ""http://www.image-net.org/papers/imagenet_cvpr09.bib""}\n""""""\n\n_IMAGES_URL = ""http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar""\n_SPLIT_URL = ""http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar""\n_ANNOTATIONS_URL = ""http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar""\n_NAME_RE = re.compile(r""([\\w-]*[/\\\\])*([\\w]*.jpg)$"")\n\n\nclass StanfordDogs(tfds.core.GeneratorBasedBuilder):\n  """"""Stanford Dogs dataset.""""""\n\n  # Version 0.2.0: Fix non-deterministic label names\n  VERSION = tfds.core.Version(""0.2.0"")\n\n  def _info(self):\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            # Images are of varying size\n            ""image"":\n                tfds.features.Image(),\n            ""image/filename"":\n                tfds.features.Text(),\n            ""label"":\n                tfds.features.ClassLabel(num_classes=120),\n            # Multiple bounding box per image\n            ""objects"":\n                tfds.features.Sequence({\n                    ""bbox"": tfds.features.BBoxFeature(),\n                }),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION)\n\n  def _split_generators(self, dl_manager):\n\n    images_path = dl_manager.download(_IMAGES_URL)\n    split_path, annotation_path = dl_manager.download_and_extract(\n        [_SPLIT_URL, _ANNOTATIONS_URL])\n    xml_file_list = collections.defaultdict(str)\n\n    # Parsing the mat file which contains the list of train/test images\n    scipy = tfds.core.lazy_imports.scipy\n    def parse_mat_file(file_name):\n      with tf.io.gfile.GFile(file_name, ""rb"") as f:\n        parsed_mat_arr = scipy.io.loadmat(f, squeeze_me=True)\n      file_list = [\n          os.path.split(element)[-1] for element in parsed_mat_arr[""file_list""]\n      ]\n\n      return file_list, parsed_mat_arr\n\n    for fname in tf.io.gfile.listdir(split_path):\n      # Train-test split using train_list.mat and test_list.mat\n      full_file_name = os.path.join(split_path, fname)\n\n      if ""train"" in fname:\n        train_list, train_mat_arr = parse_mat_file(full_file_name)\n        label_names = set([  # Set to remove duplicates\n            os.path.split(element)[-2].lower()  # Extract path/label/img.jpg\n            for element in train_mat_arr[""file_list""]\n        ])\n      elif ""test"" in fname:\n        test_list, _ = parse_mat_file(full_file_name)\n\n    self.info.features[""label""].names = sorted(label_names)\n\n    for root, _, files in tf.io.gfile.walk(annotation_path):\n      # Parsing the XML file which have the image annotations\n      for fname in files:\n        annotation_file_name = os.path.join(root, fname)\n        with tf.io.gfile.GFile(annotation_file_name, ""rb"") as f:\n          xml_file_list[fname] = ET.parse(f)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(images_path),\n                ""file_names"": train_list,\n                ""annotation_files"": xml_file_list,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""archive"": dl_manager.iter_archive(images_path),\n                ""file_names"": test_list,\n                ""annotation_files"": xml_file_list,\n            })\n    ]\n\n  def _generate_examples(self, archive, file_names, annotation_files):\n    """"""Generate dog images, labels, bbox attributes given the directory path.\n\n    Args:\n      archive: object that iterates over the zip\n      file_names : list of train/test image file names obtained from mat file\n      annotation_files : dict of image file names and their xml object\n\n    Yields:\n      Image path, Image file name, its corresponding label and\n      bounding box values\n    """"""\n    bbox_attrib = [""xmin"", ""xmax"", ""ymin"", ""ymax"", ""width"", ""height""]\n\n    for fname, fobj in archive:\n      res = _NAME_RE.match(fname)\n      if not res or (os.path.split(fname)[-1] not in file_names):\n        continue\n\n      label = res.group(1)[:-1].lower()\n      file_name = res.group(2)\n      attributes = collections.defaultdict(list)\n      for element in annotation_files[file_name.split(""."")[0]].iter():\n        # Extract necessary Bbox attributes from XML file\n        if element.tag.strip() in bbox_attrib:\n          attributes[element.tag.strip()].append(float(element.text.strip()))\n\n      # BBox attributes in range of 0.0 to 1.0\n      def normalize_bbox(bbox_side, image_side):\n        return min(bbox_side / image_side, 1.0)\n\n      def build_box(attributes, n):\n        return tfds.features.BBox(\n            ymin=normalize_bbox(attributes[""ymin""][n], attributes[""height""][0]),\n            xmin=normalize_bbox(attributes[""xmin""][n], attributes[""width""][0]),\n            ymax=normalize_bbox(attributes[""ymax""][n], attributes[""height""][0]),\n            xmax=normalize_bbox(attributes[""xmax""][n], attributes[""width""][0]),\n        )\n\n      yield fname, {\n          ""image"": fobj,\n          ""image/filename"": fname,\n          ""label"": label,\n          ""objects"": [{\n              ""bbox"": build_box(attributes, n)\n          } for n in range(len(attributes[""xmin""]))]\n      }\n'"
tensorflow_datasets/image_classification/stanford_dogs_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import stanford_dogs\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass StanfordDogsTest(tfds_test.DatasetBuilderTestCase):\n\n  DATASET_CLASS = stanford_dogs.StanfordDogs\n\n  SPLITS = {  # No. of train and test samples\n      \'train\': 8,\n      \'test\': 3,\n  }\n\n  DL_DOWNLOAD_RESULT = \'Images.tar\'\n  DL_EXTRACT_RESULT = [\'list.tar\', \'Annotation.tar\']\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/stanford_online_products.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Stanford Online Products Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DOWNLOAD_LINK = ""ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip""\n_SPLITS = {tfds.Split.TRAIN: ""Ebay_train"", tfds.Split.TEST: ""Ebay_test""}\n\n_SUPER_CLASSES = [\n    ""bicycle"", ""cabinet"", ""chair"", ""coffee_maker"", ""fan"", ""kettle"", ""lamp"",\n    ""mug"", ""sofa"", ""stapler"", ""table"", ""toaster""\n]\n_CITATION = """"""\\\n@inproceedings{song2016deep,\n author    = {Song, Hyun Oh and Xiang, Yu and Jegelka, Stefanie and Savarese, Silvio},\n title     = {Deep Metric Learning via Lifted Structured Feature Embedding},\n booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n year      = {2016}\n}\n""""""\n\n\nclass StanfordOnlineProducts(tfds.core.GeneratorBasedBuilder):\n  """"""Stanford Online Products Dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        description=(""Stanford Online Products Dataset""),\n        builder=self,\n        citation=_CITATION,\n        homepage=""http://cvgl.stanford.edu/projects/lifted_struct/"",\n        features=tfds.features.FeaturesDict({\n            ""class_id"":\n                tfds.features.ClassLabel(num_classes=22634),\n            ""super_class_id/num"":\n                tfds.features.ClassLabel(num_classes=len(_SUPER_CLASSES)),\n            ""super_class_id"":\n                tfds.features.ClassLabel(names=_SUPER_CLASSES),\n            ""image"":\n                tfds.features.Image()\n        }))\n\n  def _split_generators(self, dl_manager):\n    dl_path = dl_manager.download_and_extract(_DOWNLOAD_LINK)\n    folder_path = os.path.join(dl_path, ""Stanford_Online_Products"")\n    return [  # pylint:disable=g-complex-comprehension\n        tfds.core.SplitGenerator(\n            name=k,\n            gen_kwargs={""file_path"": os.path.join(folder_path, ""%s.txt"" % v)})\n        for k, v in _SPLITS.items()\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Images of Product from the Data Directory.\n\n    Args:\n      file_path: str, path to the Ebay_(train/test/info).txt file. Having\n        Columns [\'class_id\', \'super_class_id\', \'path\']\n    Yields:\n      Dataset examples.\n    """"""\n    with tf.io.gfile.GFile(file_path, ""r"") as file_:\n      dataset = csv.DictReader(file_, delimiter="" "")\n      for i, row in enumerate(dataset):\n        yield i, {\n            ""class_id"": int(row[""class_id""]) - 1,\n            ""super_class_id/num"": int(row[""super_class_id""]) - 1,\n            ""super_class_id"": _SUPER_CLASSES[int(row[""super_class_id""]) - 1],\n            ""image"": os.path.join(os.path.dirname(file_path), row[""path""])\n        }\n'"
tensorflow_datasets/image_classification/stanford_online_products_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.image_classification import stanford_online_products\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass StanfordOnlineProductsTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = stanford_online_products.StanfordOnlineProducts\n  SPLITS = {""train"": 3, ""test"": 3}\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/image_classification/stl10.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Code to build STL-10 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{coates2011stl10,\n  title={{An Analysis of Single Layer Networks in Unsupervised Feature Learning}},\n  author={Coates, Adam and Ng, Andrew and Lee, Honglak},\n  booktitle={AISTATS},\n  year={2011},\n  note = {\\\\url{https://cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf}},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe STL-10 dataset is an image recognition dataset for developing unsupervised\nfeature learning, deep learning, self-taught learning algorithms. It is inspired\nby the CIFAR-10 dataset but with some modifications. In particular, each class\nhas fewer labeled training examples than in CIFAR-10, but a very large set of \nunlabeled examples is provided to learn image models prior to supervised\ntraining. The primary challenge is to make use of the unlabeled data (which\ncomes from a similar but different distribution from the labeled data) to build\na useful prior. All images were acquired from labeled examples on ImageNet.\n""""""\n\nURL = ""http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz""\nUNLABELLED = tfds.Split(""unlabelled"")\n\n\nclass Stl10(tfds.core.GeneratorBasedBuilder):\n  """"""STL-10 dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(shape=(96, 96, 3)),\n            ""label"": tfds.features.ClassLabel(num_classes=10),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=""http://ai.stanford.edu/~acoates/stl10/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    train_files = [""train_X.bin"", ""train_y.bin""]\n    test_files = [""test_X.bin"", ""test_y.bin""]\n    unlabeled_files = [""unlabeled_X.bin""]\n\n    stl10_path = dl_manager.download_and_extract(URL)\n    stl10_path = os.path.join(stl10_path, ""stl10_binary/"")\n\n    def gen_filenames(filenames):\n      for f in filenames:\n        yield os.path.join(stl10_path, f)\n\n    # Adds the class names to the feature description.\n    with tf.io.gfile.GFile(next(gen_filenames([""class_names.txt""])), ""r"") as f:\n      class_names = [l.strip(""\\n"") for l in f]\n    self.info.features[""label""].names = class_names\n\n    # Define the splits\n    splits = [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepaths"": gen_filenames(train_files)}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""filepaths"": gen_filenames(test_files)}),\n        tfds.core.SplitGenerator(\n            name=UNLABELLED,\n            gen_kwargs={""filepaths"": gen_filenames(unlabeled_files)}),\n    ]\n\n    return splits\n\n  def _generate_examples(self, filepaths):\n    """"""Generate STL-10 examples as dicts.\n\n    Args:\n      filepaths (list[str]): The files to use to generate the data.\n\n    Yields:\n      The STL-10 examples, as defined in the dataset info features.\n    """"""\n    filepaths = list(filepaths)\n    image_path = filepaths[0]\n    label_path = filepaths[1] if len(filepaths) > 1 else None\n\n    with tf.io.gfile.GFile(image_path, ""rb"") as f:\n      images = np.frombuffer(f.read(), dtype=np.uint8)\n      images = np.reshape(images, (-1, 3, 96, 96))\n      images = np.transpose(images, (0, 3, 2, 1))\n\n    if label_path:\n      with tf.io.gfile.GFile(label_path, ""rb"") as f:\n        labels = np.copy(np.frombuffer(f.read(), dtype=np.uint8))\n        # Switch to zero-based indexing.\n        labels -= 1\n    else:\n      labels = None\n\n    for index, image in enumerate(images):\n      yield index, {\n          ""image"": image,\n          ""label"": labels[index] if labels is not None else -1,\n      }\n'"
tensorflow_datasets/image_classification/stl10_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for STL10 dataset module.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import stl10\n\n\nclass Stl10Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = stl10.Stl10\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n      ""unlabelled"": 1,  # Number of fake train example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/sun.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SUN (Scene UNderstanding) datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import utils\nimport tensorflow_datasets.public_api as tfds\n\n\n_SUN397_CITATION = """"""\\\n@INPROCEEDINGS{Xiao:2010,\nauthor={J. {Xiao} and J. {Hays} and K. A. {Ehinger} and A. {Oliva} and A. {Torralba}},\nbooktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\ntitle={SUN database: Large-scale scene recognition from abbey to zoo},\nyear={2010},\nvolume={},\nnumber={},\npages={3485-3492},\nkeywords={computer vision;human factors;image classification;object recognition;visual databases;SUN database;large-scale scene recognition;abbey;zoo;scene categorization;computer vision;scene understanding research;scene category;object categorization;scene understanding database;state-of-the-art algorithms;human scene classification performance;finer-grained scene representation;Sun;Large-scale systems;Layout;Humans;Image databases;Computer vision;Anthropometry;Bridges;Legged locomotion;Spatial databases}, \ndoi={10.1109/CVPR.2010.5539970},\nISSN={1063-6919},\nmonth={June},}\n""""""\n_SUN397_DESCRIPTION = """"""\\\nThe database contains 108,753 images of 397 categories, used in the\nScene UNderstanding (SUN) benchmark. The number of images varies across\ncategories, but there are at least 100 images per category.\n\nSeveral configs of the dataset are made available through TFDS:\n- A custom (random) partition of the whole dataset with 76,128 training images,\n  10,875 validation images and 21,750 test images. Images have been resized to\n  have at most 120,000 pixels, and encoded as JPEG with quality of 72.\n- ""standard-part1-120k"", ""standard-part2-120k"", ..., ""standard-part10-120k"":\n  Each of the 10 official train/test partitions with 50 images per class in each\n  split. Images have been resized to have at most 120,000 pixels, and encoded\n  as JPEG with quality of 72.\n""""""\n_SUN397_URL = ""https://vision.princeton.edu/projects/2010/SUN/""\n\n# These images are badly encoded and cannot be decoded correctly (TF), or the\n# decoding is not deterministic (PIL).\n_SUN397_IGNORE_IMAGES = [\n    ""SUN397/c/church/outdoor/sun_bhenjvsvrtumjuri.jpg"",\n]\n\n_SUN397_BUILDER_CONFIG_DESCRIPTION_PATTERN = (\n    ""Train and test splits from the official partition number %d. ""\n    ""Images are resized to have at most %s pixels, and compressed with 72 JPEG ""\n    ""quality."")\n\n\ndef _decode_image(fobj, session, filename):\n  """"""Reads and decodes an image from a file object as a Numpy array.\n\n  The SUN dataset contains images in several formats (despite the fact that\n  all of them have .jpg extension). Some of them are:\n    - BMP (RGB)\n    - PNG (grayscale, RGBA, RGB interlaced)\n    - JPEG (RGB)\n    - GIF (1-frame RGB)\n  Since TFDS assumes that all images have the same number of channels, we\n  convert all of them to RGB.\n\n  Args:\n    fobj: File object to read from.\n    session: TF session used to decode the images.\n    filename: Filename of the original image in the archive.\n\n  Returns:\n    Numpy array with shape (height, width, channels).\n  """"""\n\n  buf = fobj.read()\n  image = tfds.core.lazy_imports.cv2.imdecode(\n      np.fromstring(buf, dtype=np.uint8), flags=3)  # Note: Converts to RGB.\n  if image is None:\n    logging.warning(\n        ""Image %s could not be decoded by OpenCV, falling back to TF"", filename)\n    try:\n      image = tf.image.decode_image(buf, channels=3)\n      image = session.run(image)\n    except tf.errors.InvalidArgumentError:\n      logging.fatal(""Image %s could not be decoded by Tensorflow"", filename)\n\n  # The GIF images contain a single frame.\n  if len(image.shape) == 4:  # rank=4 -> rank=3\n    image = image.reshape(image.shape[1:])\n\n  return image\n\n\ndef _encode_jpeg(image, quality=None):\n  cv2 = tfds.core.lazy_imports.cv2\n  extra_args = [[int(cv2.IMWRITE_JPEG_QUALITY), quality]] if quality else []\n  _, buff = cv2.imencode("".jpg"", image, *extra_args)\n  return io.BytesIO(buff.tostring())\n\n\ndef _process_image_file(\n    fobj, session, filename, quality=None, target_pixels=None):\n  """"""Process image files from the dataset.""""""\n  # We need to read the image files and convert them to JPEG, since some files\n  # actually contain GIF, PNG or BMP data (despite having a .jpg extension) and\n  # some encoding options that will make TF crash in general.\n  image = _decode_image(fobj, session, filename=filename)\n  # Get image height and width.\n  height, width, _ = image.shape\n  actual_pixels = height * width\n  if target_pixels and actual_pixels > target_pixels:\n    factor = np.sqrt(target_pixels / actual_pixels)\n    image = tfds.core.lazy_imports.cv2.resize(\n        image, dsize=None, fx=factor, fy=factor)\n  return _encode_jpeg(image, quality=quality)\n\n\nclass Sun397Config(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Sun 397 dataset.""""""\n\n  def __init__(\n      self, target_pixels=None, partition=None, quality=None, **kwargs):\n    self._target_pixels = target_pixels\n    self._partition = partition\n    self._quality = quality\n    super(Sun397Config, self).__init__(**kwargs)\n\n  @property\n  def target_pixels(self):\n    return self._target_pixels\n\n  @property\n  def partition(self):\n    return self._partition\n\n  @property\n  def quality(self):\n    return self._quality\n\n\ndef _generate_builder_configs():\n  """"""Return the BuilderConfig objects for the SUN397 dataset.""""""\n  version = tfds.core.Version(""4.0.0"")\n  builder_configs = [\n      # Images randomly split into train/valid/test splits (70%/10%/20%), and\n      # images resized to have at most 120,000 pixels.\n      Sun397Config(\n          name=""tfds"",\n          version=version,\n          target_pixels=120000,\n          description=(\n              ""TFDS partition with random train/validation/test splits with ""\n              ""70%/10%/20% of the images, respectively. Images are resized to ""\n              ""have at most 120,000 pixels, and are compressed with 72 JPEG ""\n              ""quality."")),\n  ]\n  # Configs for each of the standard partitions of the dataset.\n  for partition in range(1, 10 + 1):\n    description = _SUN397_BUILDER_CONFIG_DESCRIPTION_PATTERN % (partition,\n                                                                ""120,000"")\n    builder_configs.append(\n        Sun397Config(\n            name=""standard-part%d-120k"" % partition,\n            partition=partition,\n            target_pixels=120000,\n            version=version,\n            description=description))\n  return builder_configs\n\n\nclass Sun397(tfds.core.GeneratorBasedBuilder):\n  """"""Sun397 Scene Recognition Benchmark.""""""\n\n  BUILDER_CONFIGS = _generate_builder_configs()\n\n  def __init__(self, tfds_split_files=None, **kwargs):\n    super(Sun397, self).__init__(**kwargs)\n    # Note: Only used for tests, since the data is fake.\n    if not tfds_split_files:\n      tfds_split_files = {\n          ""tr"": ""sun397_tfds_tr.txt"",\n          ""te"": ""sun397_tfds_te.txt"",\n          ""va"": ""sun397_tfds_va.txt"",\n      }\n      for split, filename in tfds_split_files.items():\n        tfds_split_files[split] = tfds.core.get_tfds_path(\n            os.path.join(""image_classification"", filename))\n    self._tfds_split_files = tfds_split_files\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(\n        os.path.join(""image_classification"", ""sun397_labels.txt""))\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_SUN397_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""file_name"": tfds.features.Text(),\n            ""image"": tfds.features.Image(shape=(None, None, 3)),\n            ""label"": tfds.features.ClassLabel(names_file=names_file),\n        }),\n        homepage=_SUN397_URL,\n        citation=_SUN397_CITATION)\n\n  def _split_generators(self, dl_manager):\n    paths = dl_manager.download_and_extract({\n        ""images"": tfds.download.Resource(\n            url=_SUN397_URL + ""SUN397.tar.gz"",\n            extract_method=tfds.download.ExtractMethod.NO_EXTRACT),\n        ""partitions"": _SUN397_URL + ""download/Partitions.zip"",\n    })\n    if not isinstance(paths, dict):\n      # While testing download_and_extract() returns the dir containing the\n      # test files.\n      paths = {\n          ""images"": os.path.join(paths, ""SUN397.tar.gz""),\n          ""partitions"": os.path.join(paths, ""Partitions""),\n      }\n    images = tfds.download.Resource(\n        path=paths[""images""],\n        extract_method=tfds.download.ExtractMethod.TAR_GZ_STREAM)\n    if self.builder_config.name == ""tfds"":\n      subset_images = self._get_tfds_subsets_images()\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TRAIN,\n              gen_kwargs=dict(\n                  archive=dl_manager.iter_archive(images),\n                  subset_images=subset_images[""tr""])),\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs=dict(\n                  archive=dl_manager.iter_archive(images),\n                  subset_images=subset_images[""te""])),\n          tfds.core.SplitGenerator(\n              name=tfds.Split.VALIDATION,\n              gen_kwargs=dict(\n                  archive=dl_manager.iter_archive(images),\n                  subset_images=subset_images[""va""])),\n      ]\n    else:\n      subset_images = self._get_partition_subsets_images(paths[""partitions""])\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TRAIN,\n              gen_kwargs=dict(\n                  archive=dl_manager.iter_archive(images),\n                  subset_images=subset_images[""tr""])),\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs=dict(\n                  archive=dl_manager.iter_archive(images),\n                  subset_images=subset_images[""te""])),\n      ]\n\n  def _generate_examples(self, archive, subset_images):\n    prefix_len = len(""SUN397"")\n    with tf.Graph().as_default():\n      with utils.nogpu_session() as sess:\n        for filepath, fobj in archive:\n          # Note: all files in the tar.gz are in SUN397/...\n          filename = filepath[prefix_len:].replace(""\\\\"", ""/"")  # For windows\n          if filename in subset_images:\n            # Example:\n            # From filename: /c/car_interior/backseat/sun_aenygxwhhmjtisnf.jpg\n            # To class: /c/car_interior/backseat\n            label = ""/"".join(filename.split(""/"")[:-1])\n            image = _process_image_file(\n                fobj, sess, filename,\n                quality=self.builder_config.quality,\n                target_pixels=self.builder_config.target_pixels)\n            record = {\n                ""file_name"": filename,\n                ""image"": image,\n                ""label"": label,\n            }\n            yield filename, record\n\n  def _get_tfds_subsets_images(self):\n    splits_sets = {}\n    for split, filepath in self._tfds_split_files.items():\n      splits_sets[split] = self._load_image_set_from_file(filepath)\n    return splits_sets\n\n  def _get_partition_subsets_images(self, partitions_dir):\n    # Get the ID of all images in the dataset.\n    all_images = set()\n    for split_images in self._get_tfds_subsets_images().values():\n      all_images.update(split_images)\n    # Load the images in the training/test split of this partition.\n    filenames = {\n        ""tr"": ""Training_%02d.txt"" % self.builder_config.partition,\n        ""te"": ""Testing_%02d.txt"" % self.builder_config.partition\n    }\n    splits_sets = {}\n    for split, filename in filenames.items():\n      filepath = os.path.join(partitions_dir, filename)\n      splits_sets[split] = self._load_image_set_from_file(filepath)\n    # Put the remaining images in the dataset into the ""validation"" split.\n    splits_sets[""va""] = all_images - (splits_sets[""tr""] | splits_sets[""te""])\n    return splits_sets\n\n  def _load_image_set_from_file(self, filepath):\n    with tf.io.gfile.GFile(filepath, mode=""r"") as f:\n      return set([line.strip() for line in f])\n'"
tensorflow_datasets/image_classification/sun_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for SUN (Scene UNderstanding) datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import sun\n\n_EXAMPLE_DIR = os.path.join(\n    os.path.normpath(os.path.dirname(__file__) + \'/../\'), \'testing\',\n    \'test_data\', \'fake_examples\', \'sun397\')\n\n\n# Could use functools.partialmethod in Python3\noriginal_init = sun.Sun397.__init__\n\n\ndef new_init(self, tfds_split_files=None, **kwargs):\n  assert tfds_split_files is None\n  original_init(self, tfds_split_files={\n      \'tr\': os.path.join(_EXAMPLE_DIR, \'sun397_tfds_tr.txt\'),\n      \'te\': os.path.join(_EXAMPLE_DIR, \'sun397_tfds_te.txt\'),\n      \'va\': os.path.join(_EXAMPLE_DIR, \'sun397_tfds_va.txt\'),\n  }, **kwargs)\n\n\n# Patch init to add init arguments without changing the class.__name__ and\n# registration reguired to find the checksum file.\nsun.Sun397.__init__ = new_init\n\n\nclass Sun397StandardPartitionTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = sun.Sun397\n  EXAMPLE_DIR = _EXAMPLE_DIR\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'standard-part1-120k\']\n  SPLITS = {\n      \'train\': 4,\n      \'test\': 3,\n  }\n\n\nclass Sun397TfdsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = sun.Sun397\n  EXAMPLE_DIR = _EXAMPLE_DIR\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'tfds\']\n  SPLITS = {\n      \'train\': 4,\n      \'test\': 2,\n      \'validation\': 2,\n  }\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/svhn.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Street View House Numbers (SVHN) Dataset, cropped version.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\nURL = ""http://ufldl.stanford.edu/housenumbers/""\n\n\n_CITATION = """"""\\\n@article{Netzer2011,\nauthor = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},\nbooktitle = {Advances in Neural Information Processing Systems ({NIPS})},\ntitle = {Reading Digits in Natural Images with Unsupervised Feature Learning},\nyear = {2011}\n}\n""""""\n\n\nclass SvhnCropped(tfds.core.GeneratorBasedBuilder):\n  """"""Street View House Numbers (SVHN) Dataset, cropped version.""""""\n\n  VERSION = tfds.core.Version(\n      ""3.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""3.1.0""),\n  ]\n\n  def _info(self):\n    features_dict = {\n        ""image"": tfds.features.Image(shape=(32, 32, 3)),\n        ""label"": tfds.features.ClassLabel(num_classes=10),\n    }\n    if self.version > ""3.0.0"":\n      features_dict[""id""] = tfds.features.Text()\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(\n            ""The Street View House Numbers (SVHN) Dataset is an image digit ""\n            ""recognition dataset of over 600,000 digit images coming from ""\n            ""real world data. Images are cropped to 32x32.""),\n        features=tfds.features.FeaturesDict(features_dict),\n        supervised_keys=(""image"", ""label""),\n        homepage=URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n\n    output_files = dl_manager.download({\n        ""train"": urllib.parse.urljoin(URL, ""train_32x32.mat""),\n        ""test"": urllib.parse.urljoin(URL, ""test_32x32.mat""),\n        ""extra"": urllib.parse.urljoin(URL, ""extra_32x32.mat""),\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                split_prefix=""train_"",\n                filepath=output_files[""train""],\n            )),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                split_prefix=""test_"",\n                filepath=output_files[""test""],\n            )),\n        tfds.core.SplitGenerator(\n            name=""extra"",\n            gen_kwargs=dict(\n                split_prefix=""extra_"",\n                filepath=output_files[""extra""],\n            )),\n    ]\n\n  def _generate_examples(self, split_prefix, filepath):\n    """"""Generate examples as dicts.\n\n    Args:\n      split_prefix: `str` prefix that identifies the split.\n      filepath: `str` path of the file to process.\n\n    Yields:\n      Generator yielding the next samples\n    """"""\n    with tf.io.gfile.GFile(filepath, ""rb"") as f:\n      data = tfds.core.lazy_imports.scipy.io.loadmat(f)\n\n    # Maybe should shuffle ?\n\n    assert np.max(data[""y""]) <= 10  # Sanity check\n    assert np.min(data[""y""]) > 0\n\n    for i, (image, label) in enumerate(zip(\n        np.rollaxis(data[""X""], -1), data[""y""])):\n      label = label.reshape(())\n      record = {\n          ""image"": image,\n          ""label"": label % 10,  # digit 0 is saved as 0 (instead of 10)\n      }\n      if self.version > ""3.0.0"":\n        record[""id""] = ""{}{:06d}"".format(split_prefix, i)\n      yield i, record\n\n# TODO(tfds): Add the SvhnFull dataset\n'"
tensorflow_datasets/image_classification/svhn_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tfds.image.svhn.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import svhn\n\n\nclass SvhnTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = svhn.SvhnCropped\n  SPLITS = {  # Number of examples.\n      ""train"": 3,\n      ""test"": 2,\n      ""extra"": 1,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train"": ""train_32x32.mat"",\n      ""test"": ""test_32x32.mat"",\n      ""extra"": ""extra_32x32.mat"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/uc_merced.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""UC Merced: Small remote sensing dataset for land use classification.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{Nilsback08,\n   author = ""Yang, Yi and Newsam, Shawn"",\n   title = ""Bag-Of-Visual-Words and Spatial Extensions for Land-Use Classification"",\n   booktitle = ""ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM GIS)"",\n   year = ""2010"",\n}""""""\n\n_DESCRIPTION = """"""\\\nUC Merced is a 21 class land use remote sensing image dataset, with 100 images\nper class. The images were manually extracted from large images from the USGS\nNational Map Urban Area Imagery collection for various urban areas around the\ncountry. The pixel resolution of this public domain imagery is 0.3 m.\nEach image measures 256x256 pixels.""""""\n\n_URL = ""http://weegee.vision.ucmerced.edu/datasets/landuse.html""\n\n_LABELS = [\n    ""agricultural"",\n    ""airplane"",\n    ""baseballdiamond"",\n    ""beach"",\n    ""buildings"",\n    ""chaparral"",\n    ""denseresidential"",\n    ""forest"",\n    ""freeway"",\n    ""golfcourse"",\n    ""harbor"",\n    ""intersection"",\n    ""mediumresidential"",\n    ""mobilehomepark"",\n    ""overpass"",\n    ""parkinglot"",\n    ""river"",\n    ""runway"",\n    ""sparseresidential"",\n    ""storagetanks"",\n    ""tenniscourt"",\n]\n\n_ZIP_URL = ""http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip""\n_ZIP_SUBDIR = ""UCMerced_LandUse/Images""\n\n\nclass UcMerced(tfds.core.GeneratorBasedBuilder):\n  """"""Small 21 class remote sensing land use classification dataset.""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""label"": tfds.features.ClassLabel(names=_LABELS),\n            ""filename"": tfds.features.Text(),\n        }),\n        supervised_keys=(""image"", ""label""),\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    path = dl_manager.download_and_extract(_ZIP_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": os.path.join(path, _ZIP_SUBDIR)},\n        ),\n    ]\n\n  def _generate_examples(self, path):\n    """"""Yields examples.""""""\n    for label in tf.io.gfile.listdir(path):\n      for filename in tf.io.gfile.glob(os.path.join(path, label, ""*.tif"")):\n        image = _load_tif(filename)\n        filename = os.path.basename(filename)\n        record = {\n            ""image"": image,\n            ""label"": label,\n            ""filename"": filename,\n        }\n        yield filename, record\n\n\ndef _load_tif(path):\n  with tf.io.gfile.GFile(path, ""rb"") as fp:\n    image = tfds.core.lazy_imports.PIL_Image.open(fp)\n  return np.array(image)\n'"
tensorflow_datasets/image_classification/uc_merced_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the UC Merced dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import uc_merced\n\n\nclass UcMercedTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = uc_merced.UcMerced\n  SPLITS = {\n      ""train"": 5,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/image_classification/vgg_face2.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""VGGFace2 Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{Cao18,\nauthor = ""Cao, Q. and Shen, L. and Xie, W. and Parkhi, O. M. and Zisserman, A."",\ntitle  = ""VGGFace2: A dataset for recognising faces across pose and age"",\nbooktitle = ""International Conference on Automatic Face and Gesture \\\nRecognition"",\nyear  = ""2018""}""""""\n\n_DESCRIPTION = """"""\\\nVGGFace2 is a large-scale face recognition dataset. \\\nImages are downloaded from Google Image Search and have large variations \\\nin pose, age, illumination, ethnicity and profession. VGGFace2 contains images \\\nfrom identities spanning a wide range of different ethnicities, accents, \\\nprofessions and ages. All face images are captured ""in the wild"", with pose \\\nand emotion variations and different lighting and occlusion conditions. Face \\\ndistribution for different identities is varied, from 87 to 843, with an \\\naverage of 362 images for each subject.\n""""""\n\n\n_LABELS_FNAME = \'image_classification/vgg_face2_labels.txt\'\n\n\nclass VggFace2(tfds.core.GeneratorBasedBuilder):\n  """"""VGGFace2 - A large scale image dataset for face recognition.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  manual_dir should contain two files: vggface2_test.tar.gz and\n  vggface2_train.tar.gz.\n  You need to register on http://zeus.robots.ox.ac.uk/vgg_face2/signup/ in\n  order to get the link to download the dataset.\n  """"""\n\n  def _info(self):\n    names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(),\n            \'label\': tfds.features.ClassLabel(names_file=names_file),\n            \'file_name\': tfds.features.Text(),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        # Homepage of the dataset for documentation\n        homepage=\'http://zeus.robots.ox.ac.uk/vgg_face2/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    train_path = os.path.join(dl_manager.manual_dir, \'vggface2_train.tar.gz\')\n    test_path = os.path.join(dl_manager.manual_dir, \'vggface2_test.tar.gz\')\n    if not tf.io.gfile.exists(train_path) or not tf.io.gfile.exists(test_path):\n      raise AssertionError(\n          \'VGGFace2 requires manual download of the data. Please download \'\n          \'the train and test set and place them into: {}, {}\'.format(\n              train_path, test_path))\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(train_path),\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'archive\': dl_manager.iter_archive(test_path),\n            },\n        ),\n    ]\n\n  def _generate_examples(self, archive):\n    """"""Yields examples.""""""\n    for fname, fobj in archive:\n      fname = fname.replace(\'\\\\\', \'/\')  # For windows compatibility\n      if fname.startswith(\'train/\'):\n        file_name = fname[len(\'train/\'):]\n      else:\n        file_name = fname[len(\'test/\'):]\n      record = {\'file_name\': file_name, \'image\': fobj, \'label\': file_name[:7]}\n      yield fname, record\n'"
tensorflow_datasets/image_classification/vgg_face2_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for VGGFace2 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import vgg_face2\n\n\nclass VggFace2Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = vgg_face2.VggFace2\n  SPLITS = {\n      ""train"": 6,  # Number of fake train example\n      ""test"": 5,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/image_classification/visual_domain_decathlon.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Visual Domain Decathlon Datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_DESCRIPTION = """"""\\\nThis contains the 10 datasets used in the Visual Domain Decathlon, part of\nthe PASCAL in Detail Workshop Challenge (CVPR 2017).\nThe goal of this challenge is to solve simultaneously ten image classification\nproblems representative of very different visual domains.\n\nSome of the datasets included here are also available as separate datasets in\nTFDS. However, notice that images were preprocessed for the Visual Domain\nDecathlon (resized isotropically to have a shorter size of 72 pixels) and\nmight have different train/validation/test splits. Here we use the official\nsplits for the competition.\n""""""\n\n_CITATION = """"""\\\n@ONLINE{hakanbilensylvestrerebuffitomasjakab2017,\n    author = ""Hakan Bilen, Sylvestre Rebuffi, Tomas Jakab"",\n    title  = ""Visual Domain Decathlon"",\n    year   = ""2017"",\n    url    = ""https://www.robots.ox.ac.uk/~vgg/decathlon/""\n}\n""""""\n\n_URL_PREFIX_VGG = \'http://www.robots.ox.ac.uk/~vgg/share/\'\n_URL_PREFIX_IMAGENET = \'http://www.image-net.org/image/decathlon/\'\n_CONFIG_DESCRIPTION_PATTERN = (\n    \'Data based on ""{}"", with images resized isotropically to have a shorter \'\n    \'size of 72 pixels.\')\n\n\nclass VisualDomainDecathlonConfig(tfds.core.BuilderConfig):\n\n  def __init__(self, num_classes, **kwargs):\n    self.num_classes = num_classes\n    if \'version\' not in kwargs:\n      kwargs[\'version\'] = tfds.core.Version(\'1.2.0\')\n    super(VisualDomainDecathlonConfig, self).__init__(**kwargs)\n\n\ndef _get_builder_configs():\n  """"""Returns the list of builder configs for the dataset.""""""\n  configs = []\n  for short_name, full_name, num_classes in [\n      (\'aircraft\', \'Aircraft\', 100),\n      (\'cifar100\', \'CIFAR-100\', 100),\n      (\'daimlerpedcls\', \'Daimler Pedestrian Classification\', 2),\n      (\'dtd\', \'Describable Textures\', 47),\n      (\'gtsrb\', \'German Traffic Signs\', 43),\n      (\'imagenet12\', \'Imagenet\', 1000),\n      (\'omniglot\', \'Omniglot\', 1623),\n      (\'svhn\', \'Street View House Numbers\', 10),\n      (\'ucf101\', \'UCF101 Dynamic Images\', 101),\n      (\'vgg-flowers\', \'VGG-Flowers\', 102),\n  ]:\n    description = _CONFIG_DESCRIPTION_PATTERN.format(full_name)\n    configs.append(VisualDomainDecathlonConfig(name=short_name,\n                                               num_classes=num_classes,\n                                               description=description))\n  return configs\n\n\nclass VisualDomainDecathlon(tfds.core.GeneratorBasedBuilder):\n  """"""Visual Domain Decathlon Datasets.""""""\n\n  BUILDER_CONFIGS = _get_builder_configs()\n\n  def _info(self):\n    num_classes = self.builder_config.num_classes\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'name\': tfds.features.Text(),\n            \'image\': tfds.features.Image(shape=(None, None, 3),\n                                         encoding_format=\'jpeg\'),\n            \'label\': tfds.features.ClassLabel(num_classes=num_classes),\n        }),\n        supervised_keys=(\'image\', \'label\'),\n        homepage=\'https://www.robots.ox.ac.uk/~vgg/decathlon/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    if self.builder_config.name == \'imagenet12\':\n      devkit_path, images_archive = dl_manager.download_and_extract([\n          _URL_PREFIX_VGG + \'decathlon-1.0-devkit.tar.gz\',\n          tfds.download.Resource(\n              url=_URL_PREFIX_IMAGENET + \'decathlon-1.0-data-imagenet.tar\',\n              extract_method=tfds.download.ExtractMethod.NO_EXTRACT),\n      ])\n    else:\n      devkit_path, data_path = dl_manager.download_and_extract([\n          _URL_PREFIX_VGG + \'decathlon-1.0-devkit.tar.gz\',\n          _URL_PREFIX_VGG + \'decathlon-1.0-data.tar.gz\',\n      ])\n      images_archive = os.path.join(data_path,\n                                    self.builder_config.name + \'.tar\')\n    annotations_path = os.path.join(devkit_path, \'decathlon-1.0\', \'annotations\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                images_archive=images_archive,\n                annotations_path=annotations_path,\n                split=\'train\'),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(\n                images_archive=images_archive,\n                annotations_path=annotations_path,\n                split=\'test\'),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(\n                images_archive=images_archive,\n                annotations_path=annotations_path,\n                split=\'val\'),\n        ),\n    ]\n\n  def _generate_examples(self, images_archive, annotations_path, split):\n    """"""Yields examples.""""""\n    filename_to_label = _get_filename_to_label_map(\n        annotations_path=annotations_path,\n        dataset_name=self.builder_config.name,\n        split=split)\n    for image_fname, image_fobj in tfds.download.iter_archive(\n        path=images_archive, method=tfds.download.ExtractMethod.TAR_STREAM):\n      image_fname = image_fname.replace(\'\\\\\', \'/\')  # For windows compatibility\n      if image_fname in filename_to_label:\n        label = filename_to_label[image_fname]\n        example = {\n            \'name\': image_fname,\n            \'image\': image_fobj,\n            \'label\': label,\n        }\n        yield image_fname, example\n\n\ndef _get_filename_to_label_map(annotations_path, dataset_name, split):\n  """"""Returns a mapping from image filenames to labels, for the given split.""""""\n  filename_to_label = {}\n  if split == \'test\':\n    filepath = os.path.join(annotations_path,\n                            dataset_name + \'_test_stripped.json\')\n  else:\n    filepath = os.path.join(annotations_path, dataset_name + \'_%s.json\' % split)\n  prefix = \'data/\'\n  with tf.io.gfile.GFile(filepath, mode=\'r\') as f:\n    annotations = json.load(f)\n    if split == \'test\':\n      # For test, labels are unknown.\n      for example_info in annotations[\'images\']:\n        image_filename = example_info[\'file_name\']\n        image_filename = image_filename[len(prefix):]\n        filename_to_label[image_filename] = -1\n    else:\n      # Load a map from category ID to label index.\n      category_id_to_label = {}\n      for i, category_info in enumerate(annotations[\'categories\']):\n        category_id_to_label[category_info[\'id\']] = i\n      # Load a map from image ID to image filename.\n      image_id_to_filename = {}\n      for example_info in annotations[\'images\']:\n        image_id_to_filename[example_info[\'id\']] = example_info[\'file_name\']\n      # Load the map from image filename to label.\n      for example_info in annotations[\'annotations\']:\n        image_filename = image_id_to_filename[example_info[\'image_id\']]\n        image_filename = image_filename[len(prefix):]\n        label = category_id_to_label[example_info[\'category_id\']]\n        filename_to_label[image_filename] = label\n  return filename_to_label\n'"
tensorflow_datasets/image_classification/visual_domain_decathlon_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Visual Domain Decathlon datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.image_classification import visual_domain_decathlon\n\n\nclass VisualDomainDecathlonGenericTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = visual_domain_decathlon.VisualDomainDecathlon\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'aircraft\']\n  SPLITS = {\n      \'train\': 2,\n      \'test\': 1,\n      \'validation\': 1,\n  }\n  DL_EXTRACT_RESULT = [\'\', \'\']\n\n\nclass VisualDomainDecathlonImagenetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = visual_domain_decathlon.VisualDomainDecathlon\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'imagenet12\']\n  SPLITS = {\n      \'train\': 3,\n      \'test\': 2,\n      \'validation\': 1,\n  }\n  DL_EXTRACT_RESULT = [\'\', \'imagenet12.tar\']\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Object detection datasets.""""""\n\nfrom tensorflow_datasets.object_detection.coco import Coco\nfrom tensorflow_datasets.object_detection.kitti import Kitti\nfrom tensorflow_datasets.object_detection.open_images import OpenImagesV4\nfrom tensorflow_datasets.object_detection.open_images_challenge2019 import OpenImagesChallenge2019Detection\nfrom tensorflow_datasets.object_detection.voc import Voc\nfrom tensorflow_datasets.object_detection.waymo_open_dataset import WaymoOpenDataset\nfrom tensorflow_datasets.object_detection.wider_face import WiderFace\n'"
tensorflow_datasets/object_detection/coco.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""MS Coco Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport json\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/LinMBHPRDZ14,\n  author    = {Tsung{-}Yi Lin and\n               Michael Maire and\n               Serge J. Belongie and\n               Lubomir D. Bourdev and\n               Ross B. Girshick and\n               James Hays and\n               Pietro Perona and\n               Deva Ramanan and\n               Piotr Doll{\\\'{a}}r and\n               C. Lawrence Zitnick},\n  title     = {Microsoft {COCO:} Common Objects in Context},\n  journal   = {CoRR},\n  volume    = {abs/1405.0312},\n  year      = {2014},\n  url       = {http://arxiv.org/abs/1405.0312},\n  archivePrefix = {arXiv},\n  eprint    = {1405.0312},\n  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\nDESCRIPTION = """"""COCO is a large-scale object detection, segmentation, and\ncaptioning dataset. This version contains images, bounding boxes ""\nand labels for the {year} version.\nNote:\n * Some images from the train and validation sets don\'t have annotations.\n * Coco 2014 and 2017 uses the same images, but different train/val/test splits\n * The test split don\'t have any annotations (only images).\n * Coco defines 91 classes but the data only uses 80 classes.\n * Panotptic annotations defines defines 200 classes but only uses 133.\n""""""\n\n\nSplit = collections.namedtuple(\n    \'Split\', [\'name\', \'images\', \'annotations\', \'annotation_type\'])\n\n\nclass AnnotationType(object):\n  """"""Enum of the annotation format types.\n\n  Splits are annotated with different formats.\n  """"""\n  BBOXES = \'bboxes\'\n  PANOPTIC = \'panoptic\'\n  NONE = \'none\'\n\n\nclass CocoConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CocoConfig.""""""\n\n  def __init__(\n      self,\n      splits=None,\n      has_panoptic=False,\n      **kwargs):\n    super(CocoConfig, self).__init__(\n        version=tfds.core.Version(\'1.1.0\'),\n        **kwargs)\n    self.splits = splits\n    self.has_panoptic = has_panoptic\n\n\nclass Coco(tfds.core.GeneratorBasedBuilder):\n  """"""Base MS Coco dataset.""""""\n\n  BUILDER_CONFIGS = [\n      CocoConfig(\n          name=\'2014\',\n          description=DESCRIPTION.format(year=2014),\n          splits=[\n              Split(\n                  name=tfds.Split.TRAIN,\n                  images=\'train2014\',\n                  annotations=\'annotations_trainval2014\',\n                  annotation_type=AnnotationType.BBOXES,\n              ),\n              Split(\n                  name=tfds.Split.VALIDATION,\n                  images=\'val2014\',\n                  annotations=\'annotations_trainval2014\',\n                  annotation_type=AnnotationType.BBOXES,\n              ),\n              Split(\n                  name=tfds.Split.TEST,\n                  images=\'test2014\',\n                  annotations=\'image_info_test2014\',\n                  annotation_type=AnnotationType.NONE,\n              ),\n              # Coco2014 contains an extra test split\n              Split(\n                  name=\'test2015\',\n                  images=\'test2015\',\n                  annotations=\'image_info_test2015\',\n                  annotation_type=AnnotationType.NONE,\n              ),\n          ],\n      ),\n      CocoConfig(\n          name=\'2017\',\n          description=DESCRIPTION.format(year=2017),\n          splits=[\n              Split(\n                  name=tfds.Split.TRAIN,\n                  images=\'train2017\',\n                  annotations=\'annotations_trainval2017\',\n                  annotation_type=AnnotationType.BBOXES,\n              ),\n              Split(\n                  name=tfds.Split.VALIDATION,\n                  images=\'val2017\',\n                  annotations=\'annotations_trainval2017\',\n                  annotation_type=AnnotationType.BBOXES,\n              ),\n              Split(\n                  name=tfds.Split.TEST,\n                  images=\'test2017\',\n                  annotations=\'image_info_test2017\',\n                  annotation_type=AnnotationType.NONE,\n              ),\n          ],\n      ),\n      CocoConfig(\n          name=\'2017_panoptic\',\n          description=DESCRIPTION.format(year=2017),\n          has_panoptic=True,\n          splits=[\n              Split(\n                  name=tfds.Split.TRAIN,\n                  images=\'train2017\',\n                  annotations=\'panoptic_annotations_trainval2017\',\n                  annotation_type=AnnotationType.PANOPTIC,\n              ),\n              Split(\n                  name=tfds.Split.VALIDATION,\n                  images=\'val2017\',\n                  annotations=\'panoptic_annotations_trainval2017\',\n                  annotation_type=AnnotationType.PANOPTIC,\n              ),\n          ],\n      ),\n  ]\n\n  def _info(self):\n\n    features = {\n        # Images can have variable shape\n        \'image\': tfds.features.Image(encoding_format=\'jpeg\'),\n        \'image/filename\': tfds.features.Text(),\n        \'image/id\': tf.int64,\n    }\n    # Either uses panotptic or original annotations\n    if self.builder_config.has_panoptic:\n      features.update({\n          \'panoptic_image\': tfds.features.Image(encoding_format=\'png\'),\n          \'panoptic_image/filename\': tfds.features.Text(),\n          \'panoptic_objects\': tfds.features.Sequence({\n              \'id\': tf.int64,\n              # Coco has unique id for each annotation. The id can be used for\n              # mapping panoptic image to semantic segmentation label.\n              \'area\': tf.int64,\n              \'bbox\': tfds.features.BBoxFeature(),\n              # Coco2017 has 200 categories but only 133 are present in the\n              # dataset\n              \'label\': tfds.features.ClassLabel(num_classes=133),\n              \'is_crowd\': tf.bool,\n          }),\n      })\n    else:\n      features.update({\n          \'objects\': tfds.features.Sequence({\n              \'id\': tf.int64,\n              # Coco has unique id for each annotation. The id can be used for\n              # mapping panoptic image to semantic segmentation label.\n              \'area\': tf.int64,\n              \'bbox\': tfds.features.BBoxFeature(),\n              # Coco has 91 categories but only 80 are present in the dataset\n              \'label\': tfds.features.ClassLabel(num_classes=80),\n              \'is_crowd\': tf.bool,\n          }),\n      })\n    # More info could be added, like segmentation (as png mask), captions,\n    # person key-points, more metadata (original flickr url,...).\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=self.builder_config.description,\n        # More info could be added, like the segmentation (as png mask),\n        # captions, person key-points. For caption encoding, it would probably\n        # be better to have a separate class CocoCaption2014 to avoid poluting\n        # the main class with builder config for each encoder.\n        features=tfds.features.FeaturesDict(features),\n        homepage=\'http://cocodataset.org/#home\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    # Merge urls from all splits together\n    urls = {}\n    for split in self.builder_config.splits:\n      urls[\'{}_images\'.format(split.name)] = \'zips/{}.zip\'.format(split.images)\n      urls[\'{}_annotations\'.format(split.name)] = \'annotations/{}.zip\'.format(\n          split.annotations)\n\n    # DownloadManager memoize the url, so duplicate urls will only be downloaded\n    # once.\n    root_url = \'http://images.cocodataset.org/\'\n    extracted_paths = dl_manager.download_and_extract({\n        key: root_url + url for key, url in urls.items()\n    })\n\n    splits = []\n    for split in self.builder_config.splits:\n      image_dir = extracted_paths[\'{}_images\'.format(split.name)]\n      annotations_dir = extracted_paths[\'{}_annotations\'.format(split.name)]\n      if self.builder_config.has_panoptic:\n        panoptic_image_zip_path = os.path.join(\n            annotations_dir,\n            \'annotations\',\n            \'panoptic_{}.zip\'.format(split.images)\n        )\n        panoptic_dir = dl_manager.extract(panoptic_image_zip_path)\n        panoptic_dir = os.path.join(\n            panoptic_dir, \'panoptic_{}\'.format(split.images))\n      else:\n        panoptic_dir = None\n      splits.append(tfds.core.SplitGenerator(\n          name=split.name,\n          gen_kwargs=dict(\n              image_dir=image_dir,\n              annotation_dir=annotations_dir,\n              split_name=split.images,\n              annotation_type=split.annotation_type,\n              panoptic_dir=panoptic_dir,\n          ),\n      ))\n    return splits\n\n  def _generate_examples(\n      self,\n      image_dir,\n      annotation_dir,\n      split_name,\n      annotation_type,\n      panoptic_dir):\n    """"""Generate examples as dicts.\n\n    Args:\n      image_dir: `str`, directory containing the images\n      annotation_dir: `str`, directory containing annotations\n      split_name: `str`, <split_name><year> (ex: train2014, val2017)\n      annotation_type: `AnnotationType`, the annotation format (NONE, BBOXES,\n        PANOPTIC)\n      panoptic_dir: If annotation_type is PANOPTIC, contains the panoptic\n        image directory\n\n    Yields:\n      example key and data\n    """"""\n\n    if annotation_type == AnnotationType.BBOXES:\n      instance_filename = \'instances_{}.json\'\n    elif annotation_type == AnnotationType.PANOPTIC:\n      instance_filename = \'panoptic_{}.json\'\n    elif annotation_type == AnnotationType.NONE:  # No annotation for test sets\n      instance_filename = \'image_info_{}.json\'\n\n    # Load the annotations (label names, images metadata,...)\n    instance_path = os.path.join(\n        annotation_dir,\n        \'annotations\',\n        instance_filename.format(split_name),\n    )\n    coco_annotation = ANNOTATION_CLS[annotation_type](instance_path)\n    # Each category is a dict:\n    # {\n    #    \'id\': 51,  # From 1-91, some entry missing\n    #    \'name\': \'bowl\',\n    #    \'supercategory\': \'kitchen\',\n    # }\n    categories = coco_annotation.categories\n    # Each image is a dict:\n    # {\n    #     \'id\': 262145,\n    #     \'file_name\': \'COCO_train2017_000000262145.jpg\'\n    #     \'flickr_url\': \'http://farm8.staticflickr.com/7187/xyz.jpg\',\n    #     \'coco_url\': \'http://images.cocodataset.org/train2017/xyz.jpg\',\n    #     \'license\': 2,\n    #     \'date_captured\': \'2013-11-20 02:07:55\',\n    #     \'height\': 427,\n    #     \'width\': 640,\n    # }\n    images = coco_annotation.images\n\n    # TODO(b/121375022): ClassLabel names should also contains \'id\' and\n    # and \'supercategory\' (in addition to \'name\')\n    # Warning: As Coco only use 80 out of the 91 labels, the c[\'id\'] and\n    # dataset names ids won\'t match.\n    if self.builder_config.has_panoptic:\n      objects_key = \'panoptic_objects\'\n    else:\n      objects_key = \'objects\'\n    self.info.features[objects_key][\'label\'].names = [\n        c[\'name\'] for c in categories\n    ]\n    # TODO(b/121375022): Conversion should be done by ClassLabel\n    categories_id2name = {c[\'id\']: c[\'name\'] for c in categories}\n\n    # Iterate over all images\n    annotation_skipped = 0\n    for image_info in sorted(images, key=lambda x: x[\'id\']):\n      if annotation_type == AnnotationType.BBOXES:\n        # Each instance annotation is a dict:\n        # {\n        #     \'iscrowd\': 0,\n        #     \'bbox\': [116.95, 305.86, 285.3, 266.03],\n        #     \'image_id\': 480023,\n        #     \'segmentation\': [[312.29, 562.89, 402.25, ...]],\n        #     \'category_id\': 58,\n        #     \'area\': 54652.9556,\n        #     \'id\': 86,\n        # }\n        instances = coco_annotation.get_annotations(img_id=image_info[\'id\'])\n      elif annotation_type == AnnotationType.PANOPTIC:\n        # Each panoptic annotation is a dict:\n        # {\n        #     \'file_name\': \'000000037777.png\',\n        #     \'image_id\': 37777,\n        #     \'segments_info\': [\n        #         {\n        #             \'area\': 353,\n        #             \'category_id\': 52,\n        #             \'iscrowd\': 0,\n        #             \'id\': 6202563,\n        #             \'bbox\': [221, 179, 37, 27],\n        #         },\n        #         ...\n        #     ]\n        # }\n        panoptic_annotation = coco_annotation.get_annotations(\n            img_id=image_info[\'id\'])\n        instances = panoptic_annotation[\'segments_info\']\n      else:\n        instances = []  # No annotations\n\n      if not instances:\n        annotation_skipped += 1\n\n      def build_bbox(x, y, width, height):\n        # pylint: disable=cell-var-from-loop\n        # build_bbox is only used within the loop so it is ok to use image_info\n        return tfds.features.BBox(\n            ymin=y / image_info[\'height\'],\n            xmin=x / image_info[\'width\'],\n            ymax=(y + height) / image_info[\'height\'],\n            xmax=(x + width) / image_info[\'width\'],\n        )\n        # pylint: enable=cell-var-from-loop\n\n      example = {\n          \'image\': os.path.join(image_dir, split_name, image_info[\'file_name\']),\n          \'image/filename\': image_info[\'file_name\'],\n          \'image/id\': image_info[\'id\'],\n          objects_key: [{   # pylint: disable=g-complex-comprehension\n              \'id\': instance[\'id\'],\n              \'area\': instance[\'area\'],\n              \'bbox\': build_bbox(*instance[\'bbox\']),\n              \'label\': categories_id2name[instance[\'category_id\']],\n              \'is_crowd\': bool(instance[\'iscrowd\']),\n          } for instance in instances]\n      }\n      if self.builder_config.has_panoptic:\n        panoptic_filename = panoptic_annotation[\'file_name\']\n        panoptic_image_path = os.path.join(panoptic_dir, panoptic_filename)\n        example[\'panoptic_image\'] = panoptic_image_path\n        example[\'panoptic_image/filename\'] = panoptic_filename\n\n      yield image_info[\'file_name\'], example\n\n    logging.info(\n        \'%d/%d images do not contains any annotations\',\n        annotation_skipped,\n        len(images),\n    )\n\n\nclass CocoAnnotation(object):\n  """"""Coco annotation helper class.""""""\n\n  def __init__(self, annotation_path):\n    with tf.io.gfile.GFile(annotation_path) as f:\n      data = json.load(f)\n    self._data = data\n\n  @property\n  def categories(self):\n    """"""Return the category dicts, as sorted in the file.""""""\n    return self._data[\'categories\']\n\n  @property\n  def images(self):\n    """"""Return the image dicts, as sorted in the file.""""""\n    return self._data[\'images\']\n\n  def get_annotations(self, img_id):\n    """"""Return all annotations associated with the image id string.""""""\n    raise NotImplementedError  # AnotationType.NONE don\'t have annotations\n\n\nclass CocoAnnotationBBoxes(CocoAnnotation):\n  """"""Coco annotation helper class.""""""\n\n  def __init__(self, annotation_path):\n    super(CocoAnnotationBBoxes, self).__init__(annotation_path)\n\n    img_id2annotations = collections.defaultdict(list)\n    for a in self._data[\'annotations\']:\n      img_id2annotations[a[\'image_id\']].append(a)\n    self._img_id2annotations = {\n        k: list(sorted(v, key=lambda a: a[\'id\']))\n        for k, v in img_id2annotations.items()\n    }\n\n  def get_annotations(self, img_id):\n    """"""Return all annotations associated with the image id string.""""""\n    # Some images don\'t have any annotations. Return empty list instead.\n    return self._img_id2annotations.get(img_id, [])\n\n\nclass CocoAnnotationPanoptic(CocoAnnotation):\n  """"""Coco annotation helper class.""""""\n\n  def __init__(self, annotation_path):\n    super(CocoAnnotationPanoptic, self).__init__(annotation_path)\n    self._img_id2annotations = {\n        a[\'image_id\']: a for a in self._data[\'annotations\']\n    }\n\n  def get_annotations(self, img_id):\n    """"""Return all annotations associated with the image id string.""""""\n    return self._img_id2annotations[img_id]\n\n\nANNOTATION_CLS = {\n    AnnotationType.NONE: CocoAnnotation,\n    AnnotationType.BBOXES: CocoAnnotationBBoxes,\n    AnnotationType.PANOPTIC: CocoAnnotationPanoptic,\n}\n'"
tensorflow_datasets/object_detection/coco_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for coco dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import coco\nimport tensorflow_datasets.public_api as tfds\n\n\nclass Coco2014Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = coco.Coco\n  BUILDER_CONFIG_NAMES_TO_TEST = [""2014""]\n  SPLITS = {\n      tfds.Split.TRAIN: 5,\n      tfds.Split.VALIDATION: 2,\n      tfds.Split.TEST: 2,\n      ""test2015"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_images"": ""train_images"",\n      ""train_annotations"": ""trainval_annotations"",\n      ""validation_images"": ""val_images"",\n      ""validation_annotations"": ""trainval_annotations"",\n      ""test_images"": ""test_images"",\n      ""test_annotations"": ""test_annotations"",\n      ""test2015_images"": ""test2015_images"",\n      ""test2015_annotations"": ""test2015_annotations"",\n  }\n\n\nclass Coco2017Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = coco.Coco\n  BUILDER_CONFIG_NAMES_TO_TEST = [""2017""]\n  SPLITS = {\n      tfds.Split.TRAIN: 5,\n      tfds.Split.VALIDATION: 2,\n      tfds.Split.TEST: 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_images"": ""train_images"",\n      ""train_annotations"": ""trainval_annotations"",\n      ""validation_images"": ""val_images"",\n      ""validation_annotations"": ""trainval_annotations"",\n      ""test_images"": ""test_images"",\n      ""test_annotations"": ""test_annotations"",\n  }\n\n\nclass Coco2017PanopticTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = coco.Coco\n  BUILDER_CONFIG_NAMES_TO_TEST = [""2017_panoptic""]\n  SPLITS = {\n      tfds.Split.TRAIN: 3,\n      tfds.Split.VALIDATION: 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""train_images"": ""train_images"",\n      ""validation_images"": ""val_images"",\n      ""train_annotations"": ""panoptic_annotations_trainval2017"",\n      ""validation_annotations"": ""panoptic_annotations_trainval2017"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/kitti.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Kitti dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport os\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{Geiger2012CVPR,\n  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},\n  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},\n  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year = {2012}\n}\n""""""\n_DESCRIPTION = """"""\\\nKitti contains a suite of vision tasks built using an autonomous driving\nplatform. The full benchmark contains many tasks such as stereo, optical flow,\nvisual odometry, etc. This dataset contains the object detection dataset,\nincluding the monocular images and bounding boxes. The dataset contains 7481\ntraining images annotated with 3D bounding boxes. A full description of the\nannotations can be found in the readme of the object development kit readme on\nthe Kitti homepage.\n""""""\n_HOMEPAGE_URL = ""http://www.cvlibs.net/datasets/kitti/""\n_DATA_URL = ""https://s3.eu-central-1.amazonaws.com/avg-kitti""\n_IMAGES_FNAME = ""data_object_image_2.zip""\n_LABELS_FNAME = ""data_object_label_2.zip""\n_DEVKIT_FNAME = ""devkit_object.zip""\n_OBJECT_LABELS = [\n    ""Car"",\n    ""Van"",\n    ""Truck"",\n    ""Pedestrian"",\n    ""Person_sitting"",\n    ""Cyclist"",\n    ""Tram"",\n    ""Misc"",\n]\n# The percentage of trainset videos to put into validation and test sets.\n# The released test images do not have labels.\n_VALIDATION_SPLIT_PERCENT_VIDEOS = 10\n_TEST_SPLIT_PERCENT_VIDEOS = 10\n\n# Raw Kitti representation of a bounding box. Coordinates are in pixels,\n# measured from the top-left hand corner.\nRawBoundingBox = collections.namedtuple(""RawBoundingBox"",\n                                        [""top"", ""bottom"", ""left"", ""right""])\n\n\nclass Kitti(tfds.core.GeneratorBasedBuilder):\n  """"""Kitti dataset.""""""\n\n  VERSION = tfds.core.Version(""3.2.0"", ""Devkit updated."")\n  SUPPORTED_VERSIONS = [\n      tfds.core.Version(""3.1.0""),\n  ]\n\n  def _info(self):\n    # Annotation descriptions are in the object development kit.\n    annotations = {\n        ""type"": tfds.features.ClassLabel(names=_OBJECT_LABELS),\n        ""truncated"": tfds.features.Tensor(shape=(), dtype=tf.float32),\n        ""occluded"": tfds.features.ClassLabel(num_classes=4),\n        ""alpha"": tfds.features.Tensor(shape=(), dtype=tf.float32),\n        ""bbox"": tfds.features.BBoxFeature(),\n        ""dimensions"": tfds.features.Tensor(shape=(3,), dtype=tf.float32),\n        ""location"": tfds.features.Tensor(shape=(3,), dtype=tf.float32),\n        ""rotation_y"": tfds.features.Tensor(shape=(), dtype=tf.float32),\n    }\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/file_name"": tfds.features.Text(),  # E.g. ""000001.png"".\n            ""objects"": tfds.features.Sequence(annotations),\n        }),\n        homepage=_HOMEPAGE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    filenames = {\n        ""images"": _DATA_URL + ""/"" + _IMAGES_FNAME,\n        ""annotations"": _DATA_URL + ""/"" + _LABELS_FNAME,\n        ""devkit"": _DATA_URL + ""/"" + _DEVKIT_FNAME,\n    }\n    files = dl_manager.download(filenames)\n    train_images, validation_images, test_images = _build_splits(\n        dl_manager.iter_archive(files[""devkit""]))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""images"": dl_manager.iter_archive(files[""images""]),\n                ""annotations"": dl_manager.iter_archive(files[""annotations""]),\n                ""subdir"": ""training"",\n                ""image_ids"": train_images,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""images"": dl_manager.iter_archive(files[""images""]),\n                ""annotations"": dl_manager.iter_archive(files[""annotations""]),\n                ""subdir"": ""training"",\n                ""image_ids"": validation_images,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""images"": dl_manager.iter_archive(files[""images""]),\n                ""annotations"": dl_manager.iter_archive(files[""annotations""]),\n                ""subdir"": ""training"",\n                ""image_ids"": test_images,\n            }),\n    ]\n\n  def _generate_examples(self, images, annotations, subdir, image_ids):\n    """"""Yields images and annotations.\n\n    Args:\n      images: object that iterates over the archive of images.\n      annotations: object that iterates over the archive of annotations.\n      subdir: subdirectory from which to extract images and annotations, e.g.\n        training or testing.\n      image_ids: file ids for images in this split.\n\n    Yields:\n      A tuple containing the example\'s key, and the example.\n    """"""\n    cv2 = tfds.core.lazy_imports.cv2\n\n    all_annotations = dict()\n    for fpath, fobj in annotations:\n      prefix, ext = os.path.splitext(fpath)\n      if ext != "".txt"":\n        continue\n      if prefix.split(os.path.sep)[0] != subdir:\n        continue\n\n      # Key is the datapoint id. E.g. training/label_2/label_000016 -> 16.\n      all_annotations[int(prefix[-6:])] = _parse_kitti_annotations(fobj)\n\n    for fpath, fobj in images:\n      prefix, ext = os.path.splitext(fpath)\n      if ext != "".png"":\n        continue\n      if prefix.split(os.path.sep)[0] != subdir:\n        continue\n      image_id = int(prefix[-6:])\n      if image_id not in image_ids:\n        continue\n      annotations = all_annotations[image_id]\n      img = cv2.imdecode(np.fromstring(fobj.read(), dtype=np.uint8),\n                         cv2.IMREAD_COLOR)\n      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n      height, width, _ = img.shape\n      for obj in annotations:\n        obj[""bbox""] = _build_bounding_box(obj[""bbox_raw""], height, width)\n        del obj[""bbox_raw""]\n      _, fname = os.path.split(fpath)\n      record = {""image"": img, ""image/file_name"": fname, ""objects"": annotations}\n      yield fname, record\n\n\ndef _build_bounding_box(bbox, height, width):\n  """"""Builds and returns TFDS bounding box.\n\n  Args:\n    bbox: RawBoundingBox, bounding box in Kitti coordinates (origin top left).\n    height: Image height in pixels.\n    width: Image width in pixels.\n\n  Returns:\n    A TFDS BBox (origin bottom left).\n  """"""\n  return tfds.features.BBox(\n      ymin=(height - bbox.bottom) / height,\n      ymax=(height - bbox.top) / height,\n      xmin=bbox.left / width,\n      xmax=bbox.right / width,\n  )\n\n\ndef _parse_kitti_annotations(annotations_csv):\n  """"""Loads and parses the Kitti object annotations.\n\n  Args:\n    annotations_csv: csv file containing annotations for a single image.\n\n  Returns:\n    A list of labelled bounding boxes. Each bounding box is stored as a\n    dictionary of features.\n  """"""\n  annotations = []\n  for line in annotations_csv:\n    (obj_type, truncated, occluded, alpha, left, top, right, bottom, height,\n     width, length, x, y, z,\n     rotation_y) = list(csv.reader([line.decode()], delimiter="" ""))[0]\n    # DontCare objects lack annotations, so skip them.\n    if obj_type == ""DontCare"":\n      continue\n    annotations.append({\n        ""type"": obj_type,\n        ""truncated"": float(truncated),\n        ""occluded"": int(occluded),\n        ""alpha"": float(alpha),\n        ""bbox_raw"": RawBoundingBox(\n            top=float(top),\n            bottom=float(bottom),\n            left=float(left),\n            right=float(right)),\n        ""dimensions"": [float(v) for v in [height, width, length]],\n        ""location"": [float(v) for v in [x, y, z]],\n        ""rotation_y"": float(rotation_y),\n    })\n  return annotations\n\n\ndef _build_splits(devkit):\n  """"""Splits the train data into train/val/test by video.\n\n  Ensures that images from the same video do not traverse the splits.\n\n  Args:\n    devkit: object that iterates over the devkit archive.\n\n  Returns:\n    train_images: File ids for the training set images.\n    validation_images: File ids for the validation set images.\n    test_images: File ids for the test set images.\n  """"""\n  mapping_line_ids = None\n  mapping_lines = None\n  for fpath, fobj in devkit:\n    if fpath == os.path.join(""mapping"", ""train_rand.txt""):\n      # Converts 1-based line index to 0-based line index.\n      mapping_line_ids = [\n          int(x.strip()) - 1 for x in fobj.read().decode(""utf-8"").split("","")\n      ]\n    elif fpath == os.path.join(""mapping"", ""train_mapping.txt""):\n      mapping_lines = fobj.read().splitlines()\n      mapping_lines = [x.decode(""utf-8"") for x in mapping_lines]\n\n  assert mapping_line_ids\n  assert mapping_lines\n\n  video_to_image = collections.defaultdict(list)\n  for image_id, mapping_lineid in enumerate(mapping_line_ids):\n    line = mapping_lines[mapping_lineid]\n    video_id = line.split("" "")[1]\n    video_to_image[video_id].append(image_id)\n\n  # Sets numpy random state.\n  numpy_original_state = np.random.get_state()\n  np.random.seed(seed=123)\n\n  # Max 1 for testing.\n  num_test_videos = max(1,\n                        _TEST_SPLIT_PERCENT_VIDEOS * len(video_to_image) // 100)\n  num_validation_videos = max(\n      1,\n      _VALIDATION_SPLIT_PERCENT_VIDEOS * len(video_to_image) // 100)\n  test_videos = set(\n      np.random.choice(\n          sorted(list(video_to_image.keys())), num_test_videos, replace=False))\n  validation_videos = set(\n      np.random.choice(\n          sorted(list(set(video_to_image.keys()) - set(test_videos))),\n          num_validation_videos,\n          replace=False))\n  test_images = []\n  validation_images = []\n  train_images = []\n  for k, v in video_to_image.items():\n    if k in test_videos:\n      test_images.extend(v)\n    elif k in validation_videos:\n      validation_images.extend(v)\n    else:\n      train_images.extend(v)\n\n  # Resets numpy random state.\n  np.random.set_state(numpy_original_state)\n  return train_images, validation_images, test_images\n'"
tensorflow_datasets/object_detection/kitti_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests the data loading for Kitti.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import kitti\n\n\nclass KittiTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = kitti.Kitti\n  SPLITS = {\n      ""train"": 6,\n      ""validation"": 2,\n      ""test"": 2,\n  }\n  DL_EXTRACT_RESULT = {\n      ""images"": ""data_object_image_2.zip"",\n      ""annotations"": ""data_object_label_2.zip"",\n      ""devkit"": ""devkit_object.zip"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/open_images.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Open images datasets.\n\nhttps://storage.googleapis.com/openimages/web/index.html\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport functools\nimport io\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = \'\'\'\\\nOpen Images is a dataset of ~9M images that have been annotated with image-level\n labels and object bounding boxes.\n\nThe training set of V4 contains 14.6M bounding boxes for 600 object classes on\n1.74M images, making it the largest existing dataset with object location\nannotations. The boxes have been largely manually drawn by professional\nannotators to ensure accuracy and consistency. The images are very diverse and\noften contain complex scenes with several objects (8.4 per image on average).\nMoreover, the dataset is annotated with image-level labels spanning thousands of\nclasses.\n\'\'\'\n\n_CITATION = \'\'\'\\\n@article{OpenImages,\n  author = {Alina Kuznetsova and\n            Hassan Rom and\n            Neil Alldrin and\n            Jasper Uijlings and\n            Ivan Krasin and\n            Jordi Pont-Tuset and\n            Shahab Kamali and\n            Stefan Popov and\n            Matteo Malloci and\n            Tom Duerig and\n            Vittorio Ferrari},\n  title = {The Open Images Dataset V4: Unified image classification,\n           object detection, and visual relationship detection at scale},\n  year = {2018},\n  journal = {arXiv:1811.00982}\n}\n@article{OpenImages2,\n  author = {Krasin, Ivan and\n            Duerig, Tom and\n            Alldrin, Neil and\n            Ferrari, Vittorio\n            and Abu-El-Haija, Sami and\n            Kuznetsova, Alina and\n            Rom, Hassan and\n            Uijlings, Jasper and\n            Popov, Stefan and\n            Kamali, Shahab and\n            Malloci, Matteo and\n            Pont-Tuset, Jordi and\n            Veit, Andreas and\n            Belongie, Serge and\n            Gomes, Victor and\n            Gupta, Abhinav and\n            Sun, Chen and\n            Chechik, Gal and\n            Cai, David and\n            Feng, Zheyun and\n            Narayanan, Dhyanesh and\n            Murphy, Kevin},\n  title = {OpenImages: A public dataset for large-scale multi-label and\n           multi-class image classification.},\n  journal = {Dataset available from\n             https://storage.googleapis.com/openimages/web/index.html},\n  year={2017}\n}\n\'\'\'\n\n# Reading from .tar.gz is slower than extracting the gz and then reading from\n# tar. We still read from the tar because it\'s faster to read fewer files on\n# many network based FS.\n# pylint: disable=line-too-long\n_URLS = {\n    \'train_images\': [tfds.download.Resource(  # pylint:disable=g-complex-comprehension\n        url=\'http://open-images-dataset.s3.amazonaws.com/tar/train_%s.tar.gz\' % i_,\n        extract_method=tfds.download.ExtractMethod.GZIP)\n                     for i_ in \'0123456789abcdef\'],\n    \'test_images\': tfds.download.Resource(\n        url=\'http://open-images-dataset.s3.amazonaws.com/tar/test.tar.gz\',\n        extract_method=tfds.download.ExtractMethod.GZIP),\n    \'validation_images\': tfds.download.Resource(\n        url=\'http://open-images-dataset.s3.amazonaws.com/tar/validation.tar.gz\',\n        extract_method=tfds.download.ExtractMethod.GZIP),\n    \'train_human_labels\': \'https://storage.googleapis.com/openimages/2018_04/train/train-annotations-human-imagelabels.csv\',\n    \'train_machine_labels\': \'https://storage.googleapis.com/openimages/2018_04/train/train-annotations-machine-imagelabels.csv\',\n    \'test_human_labels\': \'https://storage.googleapis.com/openimages/2018_04/test/test-annotations-human-imagelabels.csv\',\n    \'test_machine_labels\': \'https://storage.googleapis.com/openimages/2018_04/test/test-annotations-machine-imagelabels.csv\',\n    \'validation_human_labels\': \'https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-human-imagelabels.csv\',\n    \'validation_machine_labels\': \'https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-machine-imagelabels.csv\',\n    \'train-annotations-bbox\': \'https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\',\n    \'test-annotations-bbox\': \'https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\',\n    \'validation-annotations-bbox\': \'https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv\',\n}\n# pylint: enable=line-too-long\n\n_Object = collections.namedtuple(\'Object\', [\'label\', \'confidence\', \'source\'])\n_Bbox = collections.namedtuple(\'Bbox\', [\n    \'label\', \'source\', \'bbox\', \'is_occluded\',\n    \'is_truncated\', \'is_group_of\', \'is_depiction\', \'is_inside\'])\n\nIMAGE_LEVEL_SOURCES = [\n    \'verification\', \'crowdsource-verification\',  # human labels\n    \'machine\',\n]\n\nBBOX_SOURCES = [\n    \'freeform\', \'xclick\',  # Manually drawn boxes.\n    \'activemil\',  # Machine generated, human controlled.\n]\n\n\nclass OpenImagesV4Config(tfds.core.BuilderConfig):\n  """"""BuilderConfig for OpenImagesV4.""""""\n\n  def __init__(self, target_pixels=None, **kwargs):\n    """"""BuilderConfig for OpenImagesV4.\n\n    Args:\n      target_pixels: If given, rescale the images so that the number of pixels\n        is roughly this value.\n      **kwargs: keyword arguments forward to super.\n    """"""\n    kwargs[\'version\'] = tfds.core.Version(\n        \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n    super(OpenImagesV4Config, self).__init__(**kwargs)\n    self._target_pixels = target_pixels\n\n  @property\n  def target_pixels(self):\n    return self._target_pixels\n\n\nclass OpenImagesV4(tfds.core.GeneratorBasedBuilder):\n  """"""Open Images v4.""""""\n\n  BUILDER_CONFIGS = [\n      OpenImagesV4Config(\n          name=\'original\',\n          description=\'Images at their original resolution and quality.\'),\n      OpenImagesV4Config(\n          name=\'300k\',\n          description=\'Images have roughly 300,000 pixels, at 72 JPEG quality.\',\n          target_pixels=300000),\n      OpenImagesV4Config(\n          name=\'200k\',\n          description=\'Images have roughly 200,000 pixels, at 72 JPEG quality.\',\n          target_pixels=200000)\n  ]\n\n  def _info(self):\n    source_class_label = tfds.features.ClassLabel(\n        names=IMAGE_LEVEL_SOURCES + BBOX_SOURCES)\n    all_class_label = tfds.features.ClassLabel(\n        names_file=tfds.core.get_tfds_path(os.path.join(\n            \'object_detection\', \'open_images_classes_all.txt\')))\n    trainable_class_label = tfds.features.ClassLabel(\n        names_file=tfds.core.get_tfds_path(os.path.join(\n            \'object_detection\', \'open_images_classes_trainable.txt\')))\n    boxable_class_label = tfds.features.ClassLabel(\n        names_file=tfds.core.get_tfds_path(os.path.join(\n            \'object_detection\', \'open_images_classes_boxable.txt\')))\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'image\': tfds.features.Image(),\n            \'image/filename\': tfds.features.Text(),  # eg \'226f0a1873b9bf8e.jpg\'\n            \'objects\': tfds.features.Sequence({\n                \'label\': all_class_label,\n                # Original data is 0, .1, ..., 1. We use 0, 1, 2, ..., 10.\n                \'confidence\': tf.int32,\n                \'source\': source_class_label,\n            }),\n            \'objects_trainable\': tfds.features.Sequence({\n                \'label\': trainable_class_label,\n                # Original data is 0, .1, ..., 1. We use 0, 1, 2, ..., 10.\n                \'confidence\': tf.int32,\n                \'source\': source_class_label,\n            }),\n            \'bobjects\': tfds.features.Sequence({\n                \'label\': boxable_class_label,\n                \'source\': source_class_label,\n                \'bbox\': tfds.features.BBoxFeature(),\n                # Following values can be: 1 (true), 0 (false) and -1 (unknown).\n                \'is_occluded\': tf.int8,\n                \'is_truncated\': tf.int8,\n                \'is_group_of\': tf.int8,\n                \'is_depiction\': tf.int8,\n                \'is_inside\': tf.int8,\n            }),\n        }),\n        homepage=\'https://storage.googleapis.com/openimages/web/index.html\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    paths = dl_manager.download_and_extract(_URLS)\n    # Load labels from CSVs:\n    def load(names):\n      csv_positions = [0] * len(names)\n      return functools.partial(_load_objects, [paths[name] for name in names],\n                               csv_positions)\n    train_objects = load([\'train_human_labels\', \'train_machine_labels\'])\n    test_objects = load([\'test_human_labels\', \'test_machine_labels\'])\n    validation_objects = load([\'validation_human_labels\',\n                               \'validation_machine_labels\'])\n    def load_boxes(name):\n      csv_positions = [0]\n      return functools.partial(_load_bboxes, paths[name], csv_positions)\n    train_bbox = load_boxes(\'train-annotations-bbox\')\n    test_bbox = load_boxes(\'test-annotations-bbox\')\n    validation_bbox = load_boxes(\'validation-annotations-bbox\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(archive_paths=paths[\'train_images\'],\n                            objects_getter=train_objects,\n                            bboxes_getter=train_bbox,\n                            prefixes=\'0123456789abcdef\'),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(archive_paths=[paths[\'test_images\']],\n                            objects_getter=test_objects,\n                            bboxes_getter=test_bbox),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(archive_paths=[paths[\'validation_images\']],\n                            objects_getter=validation_objects,\n                            bboxes_getter=validation_bbox),\n        ),\n    ]\n\n  def _generate_examples(self, archive_paths, objects_getter, bboxes_getter,\n                         prefixes=None):\n    """"""Yields examples.""""""\n    trainable_classes = set(\n        self.info.features[\'objects_trainable\'][\'label\'].names)\n    for i, archive_path in enumerate(archive_paths):\n      prefix = prefixes[i] if prefixes else None\n      objects = objects_getter(prefix)\n      bboxes = bboxes_getter(prefix)\n      logging.info(\'Opening archive %s ...\', archive_path)\n      archive = tfds.download.iter_archive(\n          archive_path, tfds.download.ExtractMethod.TAR_STREAM)\n      for fpath, fobj in archive:\n        fname = os.path.basename(fpath)\n        image_id = int(os.path.splitext(fname)[0], 16)\n        image_objects = [obj._asdict() for obj in objects.get(image_id, [])]\n        image_bboxes = [bbox._asdict() for bbox in bboxes.get(image_id, [])]\n        image_objects_trainable = [\n            obj for obj in image_objects if obj[\'label\'] in trainable_classes\n        ]\n        record = {\n            \'image\': _resize_image_if_necessary(\n                fobj, target_pixels=self.builder_config.target_pixels),\n            \'image/filename\': fname,\n            \'objects\': image_objects,\n            \'objects_trainable\': image_objects_trainable,\n            \'bobjects\': image_bboxes,\n        }\n        yield fname, record\n\n\ndef _resize_image_if_necessary(image_fobj, target_pixels=None):\n  """"""Resize an image to have (roughly) the given number of target pixels.\n\n  Args:\n    image_fobj: File object containing the original image.\n    target_pixels: If given, number of pixels that the image must have.\n\n  Returns:\n    A file object.\n  """"""\n  if target_pixels is None:\n    return image_fobj\n\n  cv2 = tfds.core.lazy_imports.cv2\n  # Decode image using OpenCV2.\n  image = cv2.imdecode(\n      np.fromstring(image_fobj.read(), dtype=np.uint8), flags=3)\n  # Get image height and width.\n  height, width, _ = image.shape\n  actual_pixels = height * width\n  if actual_pixels > target_pixels:\n    factor = np.sqrt(target_pixels / actual_pixels)\n    image = cv2.resize(image, dsize=None, fx=factor, fy=factor)\n  # Encode the image with quality=72 and store it in a BytesIO object.\n  _, buff = cv2.imencode(\'.jpg\', image, [int(cv2.IMWRITE_JPEG_QUALITY), 72])\n  return io.BytesIO(buff.tostring())\n\n\ndef _load_objects(csv_paths, csv_positions, prefix):\n  """"""Returns objects listed within given CSV files.""""""\n  logging.info(\'Loading CSVs %s from positions %s with prefix %s\',\n               csv_paths, csv_positions, prefix)\n  objects = collections.defaultdict(list)\n  for i, labels_path in enumerate(csv_paths):\n    with tf.io.gfile.GFile(labels_path) as csv_f:\n      if csv_positions[i] > 0:\n        csv_f.seek(csv_positions[i])\n      else:\n        csv_f.readline()  # Drop headers\n      reader = csv.reader(csv_f)\n      for image_id, source, label, confidence in reader:\n        if prefix and image_id[0] != prefix:\n          break\n        csv_positions[i] = csv_f.tell()\n        image_id = int(image_id, 16)\n        current_obj = _Object(label, int(float(confidence) * 10), source)\n        objects[image_id].append(current_obj)\n  return dict(objects)\n\n\ndef _load_bboxes(csv_path, csv_positions, prefix):\n  """"""Returns bounded boxes listed within given CSV file.""""""\n  logging.info(\'Loading CSVs %s from positions %s with prefix %s\',\n               csv_path, csv_positions, prefix)\n  boxes = collections.defaultdict(list)\n  with tf.io.gfile.GFile(csv_path) as csv_f:\n    if csv_positions[0] > 0:\n      csv_f.seek(csv_positions[0])\n    else:\n      csv_f.readline()  # Drop headers\n    reader = csv.reader(csv_f)\n    for (image_id, source, label, confidence, xmin, xmax, ymin, ymax,\n         is_occluded, is_truncated, is_group_of, is_depiction, is_inside,\n        ) in reader:\n      if prefix and image_id[0] != prefix:\n        break\n      csv_positions[0] = csv_f.tell()\n      image_id = int(image_id, 16)\n      del confidence  # always 1 in bounding boxes.\n      current_row = _Bbox(\n          label, source, tfds.features.BBox(\n              float(ymin), float(xmin), float(ymax), float(xmax)),\n          int(is_occluded), int(is_truncated),\n          int(is_group_of), int(is_depiction), int(is_inside))\n      boxes[image_id].append(current_row)\n  return dict(boxes)\n'"
tensorflow_datasets/object_detection/open_images_challenge2019.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Datasets of the Open Images Challange 2019.\n\nhttps://storage.googleapis.com/openimages/web/challenge2019.html\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nOpen Images is a collaborative release of ~9 million images annotated with\nimage-level labels, object bounding boxes, object segmentation masks, and\nvisual relationships. This uniquely large and diverse dataset is designed to\nspur state of the art advances in analyzing and understanding images.\n""""""\n_DESCRIPTION_DETECTION = """"""\\\nThis contains the data from thee Object Detection track of the competition.\nThe goal in this track is to predict a tight bounding box around all object\ninstances of 500 classes.\n\nThe images are annotated with positive image-level labels, indicating certain\nobject classes are present, and with negative image-level labels, indicating\ncertain classes are absent. In the competition, all other unannotated classes\nare excluded from evaluation in that image. For each positive image-level label\nin an image, every instance of that object class in the image was annotated.\n""""""\n_URL = ""https://storage.googleapis.com/openimages/web/challenge2019.html""\n\n_GOOGLE_URL_PREFIX = (\n    ""https://storage.googleapis.com/openimages/challenge_2019/challenge-2019-"")\n_FIGURE_EIGHT_BASE_URL = (\n    ""https://datasets.figure-eight.com/figure_eight_datasets/open-images/"")\n_TRAIN_IMAGES_URLS = [\n    ""{}zip_files_copy/train_{:02d}.zip"".format(_FIGURE_EIGHT_BASE_URL, n)\n    for n in range(9)\n]\n_VALIDATION_IMAGES_URL = (\n    _FIGURE_EIGHT_BASE_URL + ""zip_files_copy/validation.zip"")\n_TEST_IMAGES_URL = _FIGURE_EIGHT_BASE_URL + ""test_challenge.zip""\n_NUM_CLASSES = 500\n\n\nclass OpenImagesChallenge2019Config(tfds.core.BuilderConfig):\n  """"""BuilderConfig for OpenImages Challenge 2019 datasets.""""""\n\n  def __init__(self, target_pixels=None, **kwargs):\n    kwargs.setdefault(""version"", tfds.core.Version(""1.0.0""))\n    super(OpenImagesChallenge2019Config, self).__init__(**kwargs)\n    self._target_pixels = target_pixels\n\n  @property\n  def target_pixels(self):\n    return self._target_pixels\n\n\nclass _OpenImagesChallenge2019(tfds.core.BeamBasedBuilder):\n  """"""Base abstract class for Open Images Challenge 2019 datasets.""""""\n\n  BUILDER_CONFIGS = [\n      OpenImagesChallenge2019Config(\n          name=""200k"",\n          description=""Images have at most 200,000 pixels, at 72 JPEG quality."",\n          target_pixels=200000),\n      OpenImagesChallenge2019Config(\n          name=""300k"",\n          description=""Images have at most 300,000 pixels, at 72 JPEG quality."",\n          target_pixels=300000),\n  ]\n\n  @property\n  @abc.abstractmethod\n  def annotation_urls(self):\n    """"""Dictionary passed to the DownloadManager to download annotations.\n\n    An example:\n      {""test_annotations"": ""https://somewebpage.com/data/openimages/test.txt""}\n\n    Returns:\n      A dictionary whose values are the URLs to download the annotations of the\n      dataset, and the keys are some short string identifying the URL.\n      This dictionary is passed to the DownloadManager.\n    """"""\n\n  def _split_generators(self, dl_manager):\n    urls = {\n        ""train_images"": _TRAIN_IMAGES_URLS,\n        ""test_images"": [_TEST_IMAGES_URL],\n        ""validation_images"": [_VALIDATION_IMAGES_URL]\n    }\n    urls.update(self.annotation_urls)\n    paths = dl_manager.download(urls)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(paths=paths, split=""train""),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(paths=paths, split=""test""),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(paths=paths, split=""validation""),\n        ),\n    ]\n\n\nclass OpenImagesChallenge2019Detection(_OpenImagesChallenge2019):\n  """"""Dataset for the Detection Track.""""""\n\n  @property\n  def annotation_urls(self):\n    return {\n        ""train_image_label"":\n            _GOOGLE_URL_PREFIX + ""train-detection-human-imagelabels.csv"",\n        ""train_boxes"": _GOOGLE_URL_PREFIX + ""train-detection-bbox.csv"",\n        ""validation_image_label"":\n            _GOOGLE_URL_PREFIX + ""validation-detection-human-imagelabels.csv"",\n        ""validation_boxes"":\n            _GOOGLE_URL_PREFIX + ""validation-detection-bbox.csv"",\n        ""classes"": _GOOGLE_URL_PREFIX + ""classes-description-500.csv"",\n        ""hierarchy"": _GOOGLE_URL_PREFIX + ""label500-hierarchy.json"",\n    }\n\n  def _info(self):\n    label = tfds.features.ClassLabel(num_classes=_NUM_CLASSES)\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION + ""\\n\\n"" + _DESCRIPTION_DETECTION,\n        features=tfds.features.FeaturesDict({\n            ""id"": tfds.features.Text(),\n            ""image"": tfds.features.Image(),\n            # A sequence of image-level labels.\n            ""objects"": tfds.features.Sequence({\n                ""label"": label,\n                # All labels have been verified by humans.\n                #  - If confidence is 1.0, the object IS in the image.\n                #  - If confidence is 0.0, the object is NOT in the image.\n                ""confidence"": tf.float32,\n                ""source"": tfds.features.Text(),\n            }),\n            # A sequence of bounding boxes.\n            ""bobjects"": tfds.features.Sequence({\n                ""label"": label,\n                ""bbox"": tfds.features.BBoxFeature(),\n                ""is_group_of"": tf.bool,\n            }),\n        }),\n        homepage=_URL,\n    )\n\n  def _build_pcollection(self, pipeline, paths, split):\n    beam = tfds.core.lazy_imports.apache_beam\n    # We need to lazily import the oi_beam module (and thus, violate the\n    # ""imports only at the top"" rule), so that beam is only required during the\n    # generation of the dataset, and not to use the dataset itself (once built).\n    # See: https://www.tensorflow.org/datasets/beam_datasets.\n    import tensorflow_datasets.object_detection.open_images_challenge2019_beam as oi_beam  # pylint: disable=g-import-not-at-top,import-outside-toplevel\n\n    if split == ""test"":\n      # Note: annotations are not available for the test split.\n      generate_examples_kwargs = dict(\n          image_labels_filepath=None,\n          box_labels_filepath=None,\n          hierarchy_filepath=None,\n          classes_filepath=None,\n      )\n    else:\n      generate_examples_kwargs = dict(\n          image_labels_filepath=paths[""{}_image_label"".format(split)],\n          box_labels_filepath=paths[""{}_boxes"".format(split)],\n          hierarchy_filepath=paths[""hierarchy""],\n          classes_filepath=paths[""classes""],\n      )\n    # Fill class names after the data has been downloaded.\n    oi_beam.fill_class_names_in_tfds_info(paths[""classes""], self.info.features)\n    return (\n        pipeline | beam.Create(paths[""{}_images"".format(split)]) |\n        ""ReadImages"" >> beam.ParDo(oi_beam.ReadZipFn()) |\n        ""ProcessImages"" >> beam.ParDo(oi_beam.ProcessImageFn(\n            target_pixels=self.builder_config.target_pixels, jpeg_quality=72)) |\n        ""GenerateExamples"" >> beam.ParDo(\n            oi_beam.CreateDetectionExampleFn(**generate_examples_kwargs))\n    )\n'"
tensorflow_datasets/object_detection/open_images_challenge2019_beam.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes and functions to generate the OI Challenge 2019 dataset using Apache Beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport io\nimport json\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nbeam = tfds.core.lazy_imports.apache_beam\ncv2 = tfds.core.lazy_imports.cv2\n\nMetrics = beam.metrics.Metrics\n\n\nclass ReadZipFn(beam.DoFn):\n  """"""Iterates a zip file, yielding filenames and file contents.""""""\n\n  def process(self, zip_filepath):\n    for filename, file in tfds.download.iter_archive(\n        zip_filepath, tfds.download.ExtractMethod.ZIP):\n      if filename.endswith("".jpg""):\n        yield filename, file.read()\n\n\nclass ProcessImageFn(beam.DoFn):\n  """"""Resizes images, re-compresses them in JPEG and yields the result.""""""\n\n  def __init__(self, target_pixels, jpeg_quality=72):\n    self._target_pixels = target_pixels\n    self._jpeg_quality = [int(cv2.IMWRITE_JPEG_QUALITY), jpeg_quality]\n    self._images_failed = Metrics.counter(self.__class__, ""images_failed"")\n\n  def process(self, element):\n    filename, content = element\n    try:\n      image = cv2.imdecode(np.fromstring(content, dtype=np.uint8), flags=3)\n    except:\n      logging.info(""Exception raised while decoding image %s"", filename)\n      raise\n    if image is None:\n      self._images_failed.inc()\n      logging.info(""Image %s could not be decoded"", filename)\n    else:\n      # GIF images contain a single frame.\n      if len(image.shape) == 4:  # rank=4 -> rank=3\n        image = image.reshape(image.shape[1:])\n      # Get image height and width.\n      height, width, _ = image.shape\n      actual_pixels = height * width\n      # If necessary, resize the image to have at most self._target_pixels,\n      # keeping the aspect ratio.\n      if self._target_pixels and actual_pixels > self._target_pixels:\n        factor = np.sqrt(self._target_pixels / actual_pixels)\n        image = cv2.resize(image, dsize=None, fx=factor, fy=factor)\n      # Encode the image with quality=72 and store it in a BytesIO object.\n      _, buff = cv2.imencode("".jpg"", image, self._jpeg_quality)\n      yield filename, io.BytesIO(buff.tostring())\n\n\nclass CreateDetectionExampleFn(beam.DoFn):\n  """"""Creates TFDS examples for the Detection track.""""""\n\n  def __init__(self, image_labels_filepath, box_labels_filepath,\n               hierarchy_filepath, classes_filepath):\n    self._image_labels_filepath = image_labels_filepath\n    self._box_labels_filepath = box_labels_filepath\n    self._hierarchy_filepath = hierarchy_filepath\n    self._classes_filepath = classes_filepath\n    self._image2labels = None\n    self._image2boxes = None\n    self._hierarchy = None\n    self._mid2int = None\n\n  def start(self):\n    if self._image_labels_filepath:\n      self._image2labels = load_image_level_labels(self._image_labels_filepath)\n    if self._box_labels_filepath:\n      self._image2boxes = load_box_level_labels(self._box_labels_filepath)\n    if self._hierarchy_filepath:\n      self._hierarchy = load_class_hierarchy(self._hierarchy_filepath)\n    if self._classes_filepath:\n      class_descriptions = load_class_descriptions(self._classes_filepath)\n      self._mid2int = {mid: i for i, (mid, _) in enumerate(class_descriptions)}\n\n  def process(self, element):\n    filename, image_bytes = element\n    image_id = os.path.basename(filename).split(""."")[0]\n    # Image-level annotations.\n    objects = []\n    if self._image2labels:\n      for label, source, confidence in self._image2labels[image_id]:\n        objects.append({\n            ""label"": self._mid2int[label],\n            ""source"": source,\n            ""confidence"": confidence,\n        })\n    # Bounding box-level annotations.\n    bobjects = []\n    if self._image2boxes:\n      for annotation in self._image2boxes[image_id]:\n        label, xmin, xmax, ymin, ymax, is_group_of = annotation\n        bbox = tfds.features.BBox(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n        bobjects.append({\n            ""label"": self._mid2int[label],\n            ""bbox"": bbox,\n            ""is_group_of"": is_group_of,\n        })\n\n    yield image_id, {\n        ""id"": image_id,\n        ""image"": image_bytes,\n        ""objects"": objects,\n        ""bobjects"": bobjects,\n    }\n\n\ndef load_image_level_labels(filepath):\n  """"""Returns a dictionary mapping image IDs to a list of image-level labels.""""""\n  image2labels = collections.defaultdict(list)\n  with tf.io.gfile.GFile(filepath, ""r"") as csvfile:\n    reader = csv.reader(csvfile)\n    next(reader)  # Skip header.\n    for row in reader:\n      if len(row) == 3:\n        image_id, label, confidence = row\n        source = ""verification""\n      elif len(row) == 4:\n        image_id, source, label, confidence = row\n      image2labels[image_id].append((label, source, float(confidence)))\n  return image2labels\n\n\ndef load_box_level_labels(filepath):\n  """"""Returns a dictionary mapping image IDs to a list of bounding box annotations.""""""\n  image2boxes = collections.defaultdict(list)\n  with tf.io.gfile.GFile(filepath, ""r"") as csvfile:\n    reader = csv.reader(csvfile)\n    next(reader)  # Skip header.\n    for row in reader:\n      if len(row) == 7:\n        image_id, label, xmin_s, xmax_s, ymin_s, ymax_s, is_group_of_s = row\n      elif len(row) == 13:\n        image_id, label = row[0], row[2]\n        xmin_s, xmax_s, ymin_s, ymax_s = row[4:8]\n        is_group_of_s = row[10]\n      xmin, xmax, ymin, ymax = map(float, (xmin_s, xmax_s, ymin_s, ymax_s))\n      is_group_of = bool(int(is_group_of_s))\n      image2boxes[image_id].append((label, xmin, xmax, ymin, ymax, is_group_of))\n  return image2boxes\n\n\ndef load_class_hierarchy(filepath):\n  with tf.io.gfile.GFile(filepath, ""r"") as jsonfile:\n    return json.load(jsonfile)\n\n\ndef load_class_descriptions(filepath):\n  with tf.io.gfile.GFile(filepath, ""r"") as csvfile:\n    reader = csv.reader(csvfile)\n    # Note: this file doesn\'t have any header.\n    return [row for row in reader]\n\n\ndef fill_class_names_in_tfds_info(classes_filepath, tfds_info_features):\n  """"""Fills the class names in ClassLabel features.""""""\n  class_descriptions = load_class_descriptions(classes_filepath)\n  mids = [mid for mid, _ in class_descriptions]\n  tfds_info_features[""objects""][""label""].names = mids\n  tfds_info_features[""bobjects""][""label""].names = mids\n'"
tensorflow_datasets/object_detection/open_images_challenge2019_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for open_images_challenge2019.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import open_images_challenge2019\n\n_BASE_EXAMPLE_DIR = os.path.join(\n    os.path.dirname(os.path.dirname(__file__)),\n    ""testing"", ""test_data"", ""fake_examples"")\n\nopen_images_challenge2019._NUM_CLASSES = 6  # This is only done for testing!\n\n\nclass OpenImagesChallenge2019DetectionTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = open_images_challenge2019.OpenImagesChallenge2019Detection\n  BUILDER_CONFIG_NAMES_TO_TEST = [""200k""]\n  DL_DOWNLOAD_RESULT = {\n      ""train_images"": [""train_%02d.zip"" % i for i in range(9)],\n      ""test_images"": [""test.zip""],\n      ""validation_images"": [""validation.zip""],\n      ""train_image_label"":\n          ""challenge-2019-train-detection-human-imagelabels.csv"",\n      ""train_boxes"":\n          ""challenge-2019-train-detection-bbox.csv"",\n      ""validation_image_label"":\n          ""validation-detection-human-imagelabels.csv"",\n      ""validation_boxes"":\n          ""validation-detection-bbox.csv"",\n      ""classes"":\n          ""challenge-2019-classes-description-500.csv"",\n      ""hierarchy"":\n          ""challenge-2019-label500-hierarchy.json"",\n  }\n  EXAMPLE_DIR = os.path.join(\n      _BASE_EXAMPLE_DIR, ""open_images_challenge2019_detection"")\n\n  SPLITS = {  # Expected number of examples on each split.\n      ""train"": 15,\n      ""test"": 2,\n      ""validation"": 3,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/open_images_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for open_images dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import open_images\n\n\nclass OpenImagesV42012Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = open_images.OpenImagesV4\n  SPLITS = {  # Expected number of examples on each split.\n      \'train\': 512,\n      \'test\': 36,\n      \'validation\': 12,\n  }\n  DL_EXTRACT_RESULT = {\n      \'train_images\': [\'s3-tar_train_sha1_%s.tar\' % i\n                       for i in \'0123456789abcdef\'],\n      \'test_images\': \'s3-tar_test_sha2.tar\',\n      \'validation_images\': \'s3-tar_validation_sha3.tar\',\n      \'train_human_labels\': \'train-human-labels.csv\',\n      \'train_machine_labels\': \'train-machine-labels.csv\',\n      \'test_human_labels\': \'test-human-labels.csv\',\n      \'test_machine_labels\': \'test-machine-labels.csv\',\n      \'validation_human_labels\': \'validation-human-labels.csv\',\n      \'validation_machine_labels\': \'validation-machine-labels.csv\',\n      \'train-annotations-bbox\': \'train-annotations-bbox.csv\',\n      \'test-annotations-bbox\': \'test-annotations-bbox.csv\',\n      \'validation-annotations-bbox\': \'validation-annotations-bbox.csv\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/voc.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""PASCAL VOC datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport xml.etree.ElementTree\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_VOC_CITATION = """"""\\\n@misc{{pascal-voc-{year},\n\tauthor = ""Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A."",\n\ttitle = ""The {{PASCAL}} {{V}}isual {{O}}bject {{C}}lasses {{C}}hallenge {year} {{(VOC{year})}} {{R}}esults"",\n\thowpublished = ""http://www.pascal-network.org/challenges/VOC/voc{year}/workshop/index.html""}}\n""""""\n_VOC_DESCRIPTION = """"""\\\nThis dataset contains the data from the PASCAL Visual Object Classes Challenge\n{year}, a.k.a. VOC{year}, corresponding to the Classification and Detection\ncompetitions.\nA total of {num_images} images are included in this dataset, where each image\ncontains a set of objects, out of 20 different classes, making a total of\n{num_objects} annotated objects.\nIn the Classification competition, the goal is to predict the set of labels\ncontained in the image, while in the Detection competition the goal is to\npredict the bounding box and label of each individual object.\nWARNING: As per the official dataset, the test set of VOC2012 does not contain\nannotations.\n""""""\n_VOC_URL = ""http://host.robots.ox.ac.uk/pascal/VOC/voc{year}/""\n# Original site, it is down very often.\n# _VOC_DATA_URL = ""http://host.robots.ox.ac.uk/pascal/VOC/voc{year}/""\n# Data mirror:\n_VOC_DATA_URL = ""http://pjreddie.com/media/files/""\n_VOC_LABELS = (\n    ""aeroplane"",\n    ""bicycle"",\n    ""bird"",\n    ""boat"",\n    ""bottle"",\n    ""bus"",\n    ""car"",\n    ""cat"",\n    ""chair"",\n    ""cow"",\n    ""diningtable"",\n    ""dog"",\n    ""horse"",\n    ""motorbike"",\n    ""person"",\n    ""pottedplant"",\n    ""sheep"",\n    ""sofa"",\n    ""train"",\n    ""tvmonitor"",\n)\n_VOC_POSES = (\n    ""frontal"",\n    ""rear"",\n    ""left"",\n    ""right"",\n    ""unspecified"",\n)\n\n\ndef _get_example_objects(annon_filepath):\n  """"""Function to get all the objects from the annotation XML file.""""""\n  with tf.io.gfile.GFile(annon_filepath, ""r"") as f:\n    root = xml.etree.ElementTree.parse(f).getroot()\n\n    # Disable pytype to avoid attribute-error due to find returning\n    # Optional[Element]\n    # pytype: disable=attribute-error\n    size = root.find(""size"")\n    width = float(size.find(""width"").text)\n    height = float(size.find(""height"").text)\n\n    for obj in root.findall(""object""):\n      # Get object\'s label name.\n      label = obj.find(""name"").text.lower()\n      # Get objects\' pose name.\n      pose = obj.find(""pose"").text.lower()\n      is_truncated = (obj.find(""truncated"").text == ""1"")\n      is_difficult = (obj.find(""difficult"").text == ""1"")\n      bndbox = obj.find(""bndbox"")\n      xmax = float(bndbox.find(""xmax"").text)\n      xmin = float(bndbox.find(""xmin"").text)\n      ymax = float(bndbox.find(""ymax"").text)\n      ymin = float(bndbox.find(""ymin"").text)\n      yield {\n          ""label"": label,\n          ""pose"": pose,\n          ""bbox"": tfds.features.BBox(\n              ymin / height, xmin / width, ymax / height, xmax / width),\n          ""is_truncated"": is_truncated,\n          ""is_difficult"": is_difficult,\n      }\n    # pytype: enable=attribute-error\n\n\nclass VocConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Voc.""""""\n\n  def __init__(\n      self, year=None, filenames=None, has_test_annotations=True, **kwargs):\n    self.year = year\n    self.filenames = filenames\n    self.has_test_annotations = has_test_annotations\n    super(VocConfig, self).__init__(\n        name=year,\n        # Version history:\n        # 4.0.0: Added BuildConfig and 2012 version support, deprecate Voc2007.\n        # 3.0.0: S3 with new hashing function (different shuffle).\n        # 2.0.0: S3 (new shuffling, sharding and slicing mechanism).\n        version=tfds.core.Version(""4.0.0""),\n        **kwargs)\n\n\nclass Voc(tfds.core.GeneratorBasedBuilder):\n  """"""Pascal VOC 2007 or 2012.""""""\n\n  BUILDER_CONFIGS = [\n      VocConfig(\n          year=""2007"",\n          description=_VOC_DESCRIPTION.format(\n              year=2007, num_images=9963, num_objects=24640),\n          filenames={\n              ""trainval"": ""VOCtrainval_06-Nov-2007.tar"",\n              ""test"": ""VOCtest_06-Nov-2007.tar"",\n          },\n          has_test_annotations=True,\n      ),\n      VocConfig(\n          year=""2012"",\n          description=_VOC_DESCRIPTION.format(\n              year=2012, num_images=11540, num_objects=27450),\n          filenames={\n              ""trainval"": ""VOCtrainval_11-May-2012.tar"",\n              ""test"": ""VOC2012test.tar"",\n          },\n          has_test_annotations=False,\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=self.builder_config.description,\n        features=tfds.features.FeaturesDict({\n            ""image"": tfds.features.Image(),\n            ""image/filename"": tfds.features.Text(),\n            ""objects"": tfds.features.Sequence({\n                ""label"": tfds.features.ClassLabel(names=_VOC_LABELS),\n                ""bbox"": tfds.features.BBoxFeature(),\n                ""pose"": tfds.features.ClassLabel(names=_VOC_POSES),\n                ""is_truncated"": tf.bool,\n                ""is_difficult"": tf.bool,\n            }),\n            ""labels"": tfds.features.Sequence(\n                tfds.features.ClassLabel(names=_VOC_LABELS)),\n            ""labels_no_difficult"": tfds.features.Sequence(\n                tfds.features.ClassLabel(names=_VOC_LABELS)),\n        }),\n        homepage=_VOC_URL.format(year=self.builder_config.year),\n        citation=_VOC_CITATION.format(year=self.builder_config.year),\n    )\n\n  def _split_generators(self, dl_manager):\n    paths = dl_manager.download_and_extract({\n        k: os.path.join(_VOC_DATA_URL, v)\n        for k, v in self.builder_config.filenames.items()\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(data_path=paths[""test""], set_name=""test"")),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(data_path=paths[""trainval""], set_name=""train"")),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(data_path=paths[""trainval""], set_name=""val"")),\n    ]\n\n  def _generate_examples(self, data_path, set_name):\n    """"""Yields examples.""""""\n    set_filepath = os.path.join(\n        data_path,\n        os.path.normpath(""VOCdevkit/VOC{}/ImageSets/Main/{}.txt"".format(\n            self.builder_config.year, set_name)))\n    load_annotations = (\n        self.builder_config.has_test_annotations or set_name != ""test"")\n    with tf.io.gfile.GFile(set_filepath, ""r"") as f:\n      for line in f:\n        image_id = line.strip()\n        example = self._generate_example(data_path, image_id, load_annotations)\n        yield image_id, example\n\n  def _generate_example(self, data_path, image_id, load_annotations):\n    image_filepath = os.path.join(\n        data_path,\n        os.path.normpath(""VOCdevkit/VOC{}/JPEGImages/{}.jpg"".format(\n            self.builder_config.year, image_id)))\n    annon_filepath = os.path.join(\n        data_path,\n        os.path.normpath(""VOCdevkit/VOC{}/Annotations/{}.xml"".format(\n            self.builder_config.year, image_id)))\n    if load_annotations:\n      objects = list(_get_example_objects(annon_filepath))\n      # Use set() to remove duplicates\n      labels = sorted(set(obj[""label""] for obj in objects))\n      labels_no_difficult = sorted(set(\n          obj[""label""] for obj in objects if obj[""is_difficult""] == 0\n      ))\n    else:  # The test set of VOC2012 does not contain annotations\n      objects = []\n      labels = []\n      labels_no_difficult = []\n    return {\n        ""image"": image_filepath,\n        ""image/filename"": image_id + "".jpg"",\n        ""objects"": objects,\n        ""labels"": labels,\n        ""labels_no_difficult"": labels_no_difficult,\n    }\n'"
tensorflow_datasets/object_detection/voc_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for PASCAL VOC image data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import voc\n\n\nclass Voc2007Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = voc.Voc\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'2007\']\n  SPLITS = {\n      \'train\': 1,\n      \'validation\': 2,\n      \'test\': 3,\n  }\n  DL_EXTRACT_RESULT = {\n      \'trainval\': \'\',\n      \'test\': \'\',\n  }\n\n\nclass Voc2012Test(Voc2007Test):\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'2012\']\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/waymo_open_dataset.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Waymo Open Dataset. See waymo.com/open.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.proto import waymo_dataset_pb2 as open_dataset\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{waymo_open_dataset,\n  title = {Waymo Open Dataset: An autonomous driving dataset},\n  website = {url{https://www.waymo.com/open}},\n  year = {2020}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe Waymo Open Dataset is comprised of high resolution sensor data\ncollected by Waymo self-driving cars in a wide variety of conditions.\nThis data is licensed for non-commercial use.\n\nWARNING: this dataset requires additional authorization and registration.\nPlease look at tfds documentation for accessing GCS, and\nafterwards, please register via https://waymo.com/open/licensing/\n\nThis dataset is also available in pre-processed format, making it faster\nto load, if you select the correct data_dir:\ntfds.load(\'waymo_open_dataset\', \\\ndata_dir=\'gs://waymo_open_dataset_v_1_0_0_individual_files/tensorflow_datasets\')\n""""""\n\n_HOMEPAGE_URL = ""http://www.waymo.com/open/""\n_OBJECT_LABELS = [\n    ""TYPE_UNKNOWN"", ""TYPE_VEHICLE"", ""TYPE_PEDESTRIAN"", ""TYPE_SIGN"",\n    ""TYPE_CYCLIST""\n]\n\n\nclass WaymoOpenDataset(tfds.core.BeamBasedBuilder):\n  """"""Waymo Open Dataset.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n  _CLOUD_BUCKET = ""gs://waymo_open_dataset_v_1_0_0_individual_files/""\n\n  def _info(self):\n\n    # Annotation descriptions are in the object development kit.\n    annotations = {\n        ""type"": tfds.features.ClassLabel(names=_OBJECT_LABELS),\n        ""bbox"": tfds.features.BBoxFeature(),\n    }\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""context"": {\n                ""name"": tfds.features.Text()\n            },\n            ""timestamp_micros"": tf.int64,\n            ""camera_FRONT"": {\n                ""image"":\n                    tfds.features.Image(\n                        shape=(1280, 1920, 3), encoding_format=""jpeg""),\n                ""labels"":\n                    tfds.features.Sequence(annotations)\n            },\n            ""camera_FRONT_LEFT"": {\n                ""image"":\n                    tfds.features.Image(\n                        shape=(1280, 1920, 3), encoding_format=""jpeg""),\n                ""labels"":\n                    tfds.features.Sequence(annotations)\n            },\n            ""camera_SIDE_LEFT"": {\n                ""image"":\n                    tfds.features.Image(\n                        shape=(886, 1920, 3), encoding_format=""jpeg""),\n                ""labels"":\n                    tfds.features.Sequence(annotations)\n            },\n            ""camera_FRONT_RIGHT"": {\n                ""image"":\n                    tfds.features.Image(\n                        shape=(1280, 1920, 3), encoding_format=""jpeg""),\n                ""labels"":\n                    tfds.features.Sequence(annotations)\n            },\n            ""camera_SIDE_RIGHT"": {\n                ""image"":\n                    tfds.features.Image(\n                        shape=(886, 1920, 3), encoding_format=""jpeg""),\n                ""labels"":\n                    tfds.features.Sequence(annotations)\n            },\n        }),\n        homepage=_HOMEPAGE_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    # Training set\n    train_files = tf.io.gfile.glob(\n        os.path.join(self._CLOUD_BUCKET, ""training/segment*camera*""))\n    logging.info(""Train files: %s"", train_files)\n\n    # Validation set\n    validation_files = tf.io.gfile.glob(\n        os.path.join(self._CLOUD_BUCKET, ""validation/segment*camera*""))\n    logging.info(""Validation files: %s"", validation_files)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\n                ""tf_record_files"": train_files,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""tf_record_files"": validation_files,\n            }),\n    ]\n\n  def _build_pcollection(self, pipeline, tf_record_files):\n    """"""Generate examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _process_example(tf_record_file):\n      for image_and_annotation in _generate_images_and_annotations(\n          tf_record_file):\n        key = ""%s:%s"" % (image_and_annotation[""context""][""name""],\n                         image_and_annotation[""timestamp_micros""])\n        yield key, image_and_annotation\n\n    return (pipeline\n            | beam.Create(tf_record_files)\n            | beam.FlatMap(_process_example))\n\n\ndef _generate_images_and_annotations(tf_record_file):\n  """"""Yields the images and annotations from a given file.""""""\n  # Go through all frames\n  dataset = tf.data.TFRecordDataset(tf_record_file, compression_type="""")\n  for data in dataset:\n    frame = open_dataset.Frame()\n    frame.ParseFromString(bytearray(data.numpy()))  # pytype: disable=wrong-arg-types\n\n    image_and_annotation = {\n        ""context"": {\n            ""name"": frame.context.name\n        },\n        ""timestamp_micros"": frame.timestamp_micros\n    }\n\n    camera_calibration = {\n        calibration.name: calibration\n        for calibration in frame.context.camera_calibrations\n    }\n    camera_labels = {label.name: label for label in frame.camera_labels}\n\n    # Go through all 5 camera images in the frame\n    for frame_image in frame.images:\n      labels = None\n      if frame_image.name in camera_labels:\n        image_height = camera_calibration[frame_image.name].height\n        image_width = camera_calibration[frame_image.name].width\n        labels = _convert_labels(camera_labels[frame_image.name], image_width,\n                                 image_height)\n\n      camera_name = open_dataset.CameraName.Name.Name(frame_image.name)\n      image_and_annotation[""camera_"" + camera_name] = {\n          ""image"": io.BytesIO(frame_image.image),\n          ""labels"": labels\n      }\n\n    yield image_and_annotation\n\n\ndef _convert_labels(raw_labels, image_width, image_height):\n  return [{  # pylint: disable=g-complex-comprehension\n      ""type"": raw_label.type,\n      ""bbox"": _build_bounding_box(raw_label.box, image_width, image_height)\n  } for raw_label in raw_labels.labels]\n\n\ndef _build_bounding_box(open_dataset_box, image_width, image_height):\n  """"""Builds and returns TFDS bounding box.""""""\n\n  center_x = open_dataset_box.center_x\n  center_y = open_dataset_box.center_y\n  length = open_dataset_box.length\n  width = open_dataset_box.width\n\n  return tfds.features.BBox(\n      ymin=max((center_y - (width / 2)) / image_height, 0.0),\n      ymax=min((center_y + (width / 2)) / image_height, 1.0),\n      xmin=max((center_x - (length / 2)) / image_width, 0.0),\n      xmax=min((center_x + (length / 2)) / image_width, 1.0),\n  )\n'"
tensorflow_datasets/object_detection/waymo_open_dataset_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for waymo_open_dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import waymo_open_dataset\n\n\nclass WaymoOpenDatasetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = waymo_open_dataset.WaymoOpenDataset\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake test example\n  }\n\n  def setUp(self):\n    super(WaymoOpenDatasetTest, self).setUp()\n    self.builder._CLOUD_BUCKET = self.example_dir\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/object_detection/wider_face.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WIDER FACE Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_PROJECT_URL = \'http://shuoyang1213.me/WIDERFACE/\'\n\n_WIDER_TRAIN_URL = (\'https://drive.google.com/uc?export=download&\'\n                    \'id=0B6eKvaijfFUDQUUwd21EckhUbWs\')\n\n_WIDER_VAL_URL = (\'https://drive.google.com/uc?export=download&\'\n                  \'id=0B6eKvaijfFUDd3dIRmpvSk8tLUk\')\n\n_WIDER_TEST_URL = (\'https://drive.google.com/uc?export=download&\'\n                   \'id=0B6eKvaijfFUDbW4tdGpaYjgzZkU\')\n\n_WIDER_ANNOT_URL = (\'https://drive.google.com/uc?export=download&\'\n                    \'id=1sAl2oml7hK6aZRdgRjqQJsjV5CEr7nl4\')\n\n_CITATION = """"""\n@inproceedings{yang2016wider,\n\tAuthor = {Yang, Shuo and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},\n\tBooktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n\tTitle = {WIDER FACE: A Face Detection Benchmark},\n\tYear = {2016}}\n""""""\n\n_DESCRIPTION = """"""\nWIDER FACE dataset is a face detection benchmark dataset, of which images are \nselected from the publicly available WIDER dataset. We choose 32,203 images and \nlabel 393,703 faces with a high degree of variability in scale, pose and \nocclusion as depicted in the sample images. WIDER FACE dataset is organized \nbased on 61 event classes. For each event class, we randomly select 40%/10%/50% \ndata as training, validation and testing sets. We adopt the same evaluation \nmetric employed in the PASCAL VOC dataset. Similar to MALF and Caltech datasets,\nwe do not release bounding box ground truth for the test images. Users are \nrequired to submit final prediction files, which we shall proceed to evaluate.\n""""""\n\n\nclass WiderFace(tfds.core.GeneratorBasedBuilder):\n  """"""WIDER FACE Dataset.""""""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n    features = {\n        \'image\':\n            tfds.features.Image(encoding_format=\'jpeg\'),\n        \'image/filename\':\n            tfds.features.Text(),\n        \'faces\':\n            tfds.features.Sequence({\n                \'bbox\': tfds.features.BBoxFeature(),\n                \'blur\': tf.uint8,\n                \'expression\': tf.bool,\n                \'illumination\': tf.bool,\n                \'occlusion\': tf.uint8,\n                \'pose\': tf.bool,\n                \'invalid\': tf.bool,\n            }),\n    }\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        homepage=_PROJECT_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    extracted_dirs = dl_manager.download_and_extract({\n        \'wider_train\': _WIDER_TRAIN_URL,\n        \'wider_val\': _WIDER_VAL_URL,\n        \'wider_test\': _WIDER_TEST_URL,\n        \'wider_annot\': _WIDER_ANNOT_URL,\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'split\': \'train\',\n                \'extracted_dirs\': extracted_dirs\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'split\': \'val\',\n                \'extracted_dirs\': extracted_dirs\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'split\': \'test\',\n                \'extracted_dirs\': extracted_dirs\n            })\n    ]\n\n  def _generate_examples(self, split, extracted_dirs):\n    """"""Yields examples.""""""\n    pattern_fname = re.compile(r\'(.*.jpg)\\n\')\n    pattern_annot = re.compile(r\'(\\d+) (\\d+) (\\d+) (\\d+) (\\d+) \'\n                               r\'(\\d+) (\\d+) (\\d+) (\\d+) (\\d+) \\n\')\n    annot_dir = \'wider_face_split\'\n    annot_fname = (\'wider_face_test_filelist.txt\' if split == \'test\' else\n                   \'wider_face_\' + split + \'_bbx_gt.txt\')\n    annot_file = os.path.join(annot_dir, annot_fname)\n    image_dir = os.path.join(extracted_dirs[\'wider_\' + split], \'WIDER_\' + split,\n                             \'images\')\n    annot_dir = extracted_dirs[\'wider_annot\']\n    annot_path = os.path.join(annot_dir, annot_file)\n    with tf.io.gfile.GFile(annot_path, \'r\') as f:\n      while True:\n        # First read the file name.\n        line = f.readline()\n        match = pattern_fname.match(line)\n        if match is None:\n          break\n        fname = match.group(1)\n        image_fullpath = os.path.join(image_dir, fname)\n        faces = []\n        if split != \'test\':\n          # Train and val contain also face information.\n          with tf.io.gfile.GFile(image_fullpath, \'rb\') as fp:\n            image = tfds.core.lazy_imports.PIL_Image.open(fp)\n            width, height = image.size\n\n          # Read number of bounding boxes.\n          nbbox = int(f.readline())\n          if nbbox == 0:\n            # Cases with 0 bounding boxes, still have one line with all zeros.\n            # So we have to read it and discard it.\n            f.readline()\n          else:\n            for _ in range(nbbox):\n              line = f.readline()\n              match = pattern_annot.match(line)\n              if not match:\n                raise ValueError(\'Cannot parse: %s\' % image_fullpath)\n              (xmin, ymin, wbox, hbox, blur, expression, illumination, invalid,\n               occlusion, pose) = map(int, match.groups())\n              ymax = np.clip(ymin + hbox, a_min=0, a_max=height)\n              xmax = np.clip(xmin + wbox, a_min=0, a_max=width)\n              ymin = np.clip(ymin, a_min=0, a_max=height)\n              xmin = np.clip(xmin, a_min=0, a_max=width)\n              faces.append({\n                  \'bbox\':\n                      tfds.features.BBox(\n                          ymin=ymin / height,\n                          xmin=xmin / width,\n                          ymax=ymax / height,\n                          xmax=xmax / width),\n                  \'blur\':\n                      blur,\n                  \'expression\':\n                      expression,\n                  \'illumination\':\n                      illumination,\n                  \'occlusion\':\n                      occlusion,\n                  \'pose\':\n                      pose,\n                  \'invalid\':\n                      invalid,\n              })\n        record = {\n            \'image\': image_fullpath,\n            \'image/filename\': fname,\n            \'faces\': faces\n        }\n        yield fname, record\n'"
tensorflow_datasets/object_detection/wider_face_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for WIDER FACE dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.object_detection import wider_face\nimport tensorflow_datasets.public_api as tfds\n\n\nclass WiderFaceTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = wider_face.WiderFace\n  SPLITS = {\n      tfds.Split.TRAIN: 3,\n      tfds.Split.VALIDATION: 3,\n      tfds.Split.TEST: 3,\n  }\n  DL_EXTRACT_RESULT = {\n      \'wider_train\': \'wider_train\',\n      \'wider_val\': \'wider_val\',\n      \'wider_test\': \'wider_test\',\n      \'wider_annot\': \'wider_annot\',\n  }\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/proto/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Public API of the proto package.""""""\n# pylint: disable=g-import-not-at-top,g-importing-member, import-outside-toplevel\n\nfrom tensorflow_datasets.proto import waymo_dataset_generated_pb2 as waymo_dataset_pb2  # pylint: disable=line-too-long\n'"
tensorflow_datasets/proto/waymo_dataset_generated_pb2.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: waymo-open-dataset/waymo_open_dataset/dataset.proto\n# File was auto-generated:\n# pylint: skip-file\n\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'waymo-open-dataset/waymo_open_dataset/dataset.proto\',\n  package=\'waymo.open_dataset\',\n  syntax=\'proto2\',\n  serialized_options=None,\n  serialized_pb=b\'\\n3waymo-open-dataset/waymo_open_dataset/dataset.proto\\x12\\x12waymo.open_dataset\\""\\x8f\\x06\\n\\x05Label\\x12*\\n\\x03\\x62ox\\x18\\x01 \\x01(\\x0b\\x32\\x1d.waymo.open_dataset.Label.Box\\x12\\x34\\n\\x08metadata\\x18\\x02 \\x01(\\x0b\\x32\\"".waymo.open_dataset.Label.Metadata\\x12,\\n\\x04type\\x18\\x03 \\x01(\\x0e\\x32\\x1e.waymo.open_dataset.Label.Type\\x12\\n\\n\\x02id\\x18\\x04 \\x01(\\t\\x12M\\n\\x1a\\x64\\x65tection_difficulty_level\\x18\\x05 \\x01(\\x0e\\x32).waymo.open_dataset.Label.DifficultyLevel\\x12L\\n\\x19tracking_difficulty_level\\x18\\x06 \\x01(\\x0e\\x32).waymo.open_dataset.Label.DifficultyLevel\\x12\\x1f\\n\\x17num_lidar_points_in_box\\x18\\x07 \\x01(\\x05\\x1a\\xbf\\x01\\n\\x03\\x42ox\\x12\\x10\\n\\x08\\x63\\x65nter_x\\x18\\x01 \\x01(\\x01\\x12\\x10\\n\\x08\\x63\\x65nter_y\\x18\\x02 \\x01(\\x01\\x12\\x10\\n\\x08\\x63\\x65nter_z\\x18\\x03 \\x01(\\x01\\x12\\x0e\\n\\x06length\\x18\\x05 \\x01(\\x01\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\x01\\x12\\x0e\\n\\x06height\\x18\\x06 \\x01(\\x01\\x12\\x0f\\n\\x07heading\\x18\\x07 \\x01(\\x01\\""B\\n\\x04Type\\x12\\x10\\n\\x0cTYPE_UNKNOWN\\x10\\x00\\x12\\x0b\\n\\x07TYPE_3D\\x10\\x01\\x12\\x0b\\n\\x07TYPE_2D\\x10\\x02\\x12\\x0e\\n\\nTYPE_AA_2D\\x10\\x03\\x1aN\\n\\x08Metadata\\x12\\x0f\\n\\x07speed_x\\x18\\x01 \\x01(\\x01\\x12\\x0f\\n\\x07speed_y\\x18\\x02 \\x01(\\x01\\x12\\x0f\\n\\x07\\x61\\x63\\x63\\x65l_x\\x18\\x03 \\x01(\\x01\\x12\\x0f\\n\\x07\\x61\\x63\\x63\\x65l_y\\x18\\x04 \\x01(\\x01\\""`\\n\\x04Type\\x12\\x10\\n\\x0cTYPE_UNKNOWN\\x10\\x00\\x12\\x10\\n\\x0cTYPE_VEHICLE\\x10\\x01\\x12\\x13\\n\\x0fTYPE_PEDESTRIAN\\x10\\x02\\x12\\r\\n\\tTYPE_SIGN\\x10\\x03\\x12\\x10\\n\\x0cTYPE_CYCLIST\\x10\\x04\\""8\\n\\x0f\\x44ifficultyLevel\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\x0b\\n\\x07LEVEL_1\\x10\\x01\\x12\\x0b\\n\\x07LEVEL_2\\x10\\x02\\""2\\n\\x0ePolygon2dProto\\x12\\t\\n\\x01x\\x18\\x01 \\x03(\\x01\\x12\\t\\n\\x01y\\x18\\x02 \\x03(\\x01\\x12\\n\\n\\x02id\\x18\\x03 \\x01(\\t\\""\\x1b\\n\\x0bMatrixShape\\x12\\x0c\\n\\x04\\x64ims\\x18\\x01 \\x03(\\x05\\""O\\n\\x0bMatrixFloat\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x01 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12.\\n\\x05shape\\x18\\x02 \\x01(\\x0b\\x32\\x1f.waymo.open_dataset.MatrixShape\\""O\\n\\x0bMatrixInt32\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x01 \\x03(\\x05\\x42\\x02\\x10\\x01\\x12.\\n\\x05shape\\x18\\x02 \\x01(\\x0b\\x32\\x1f.waymo.open_dataset.MatrixShape\\""l\\n\\nCameraName\\""^\\n\\x04Name\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\t\\n\\x05\\x46RONT\\x10\\x01\\x12\\x0e\\n\\nFRONT_LEFT\\x10\\x02\\x12\\x0f\\n\\x0b\\x46RONT_RIGHT\\x10\\x03\\x12\\r\\n\\tSIDE_LEFT\\x10\\x04\\x12\\x0e\\n\\nSIDE_RIGHT\\x10\\x05\\""]\\n\\tLaserName\\""P\\n\\x04Name\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\x07\\n\\x03TOP\\x10\\x01\\x12\\t\\n\\x05\\x46RONT\\x10\\x02\\x12\\r\\n\\tSIDE_LEFT\\x10\\x03\\x12\\x0e\\n\\nSIDE_RIGHT\\x10\\x04\\x12\\x08\\n\\x04REAR\\x10\\x05\\""\\x1e\\n\\tTransform\\x12\\x11\\n\\ttransform\\x18\\x01 \\x03(\\x01\\""X\\n\\x08Velocity\\x12\\x0b\\n\\x03v_x\\x18\\x01 \\x01(\\x02\\x12\\x0b\\n\\x03v_y\\x18\\x02 \\x01(\\x02\\x12\\x0b\\n\\x03v_z\\x18\\x03 \\x01(\\x02\\x12\\x0b\\n\\x03w_x\\x18\\x04 \\x01(\\x01\\x12\\x0b\\n\\x03w_y\\x18\\x05 \\x01(\\x01\\x12\\x0b\\n\\x03w_z\\x18\\x06 \\x01(\\x01\\""\\xa3\\x03\\n\\x11\\x43\\x61meraCalibration\\x12\\x31\\n\\x04name\\x18\\x01 \\x01(\\x0e\\x32#.waymo.open_dataset.CameraName.Name\\x12\\x11\\n\\tintrinsic\\x18\\x02 \\x03(\\x01\\x12\\x30\\n\\textrinsic\\x18\\x03 \\x01(\\x0b\\x32\\x1d.waymo.open_dataset.Transform\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x05 \\x01(\\x05\\x12g\\n\\x19rolling_shutter_direction\\x18\\x06 \\x01(\\x0e\\x32\\x44.waymo.open_dataset.CameraCalibration.RollingShutterReadOutDirection\\""\\x8d\\x01\\n\\x1eRollingShutterReadOutDirection\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\x11\\n\\rTOP_TO_BOTTOM\\x10\\x01\\x12\\x11\\n\\rLEFT_TO_RIGHT\\x10\\x02\\x12\\x11\\n\\rBOTTOM_TO_TOP\\x10\\x03\\x12\\x11\\n\\rRIGHT_TO_LEFT\\x10\\x04\\x12\\x12\\n\\x0eGLOBAL_SHUTTER\\x10\\x05\\""\\xcd\\x01\\n\\x10LaserCalibration\\x12\\x30\\n\\x04name\\x18\\x01 \\x01(\\x0e\\x32\\"".waymo.open_dataset.LaserName.Name\\x12\\x19\\n\\x11\\x62\\x65\\x61m_inclinations\\x18\\x02 \\x03(\\x01\\x12\\x1c\\n\\x14\\x62\\x65\\x61m_inclination_min\\x18\\x03 \\x01(\\x01\\x12\\x1c\\n\\x14\\x62\\x65\\x61m_inclination_max\\x18\\x04 \\x01(\\x01\\x12\\x30\\n\\textrinsic\\x18\\x05 \\x01(\\x0b\\x32\\x1d.waymo.open_dataset.Transform\\""\\xf6\\x03\\n\\x07\\x43ontext\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x42\\n\\x13\\x63\\x61mera_calibrations\\x18\\x02 \\x03(\\x0b\\x32%.waymo.open_dataset.CameraCalibration\\x12@\\n\\x12laser_calibrations\\x18\\x03 \\x03(\\x0b\\x32$.waymo.open_dataset.LaserCalibration\\x12\\x30\\n\\x05stats\\x18\\x04 \\x01(\\x0b\\x32!.waymo.open_dataset.Context.Stats\\x1a\\xa4\\x02\\n\\x05Stats\\x12J\\n\\x13laser_object_counts\\x18\\x01 \\x03(\\x0b\\x32-.waymo.open_dataset.Context.Stats.ObjectCount\\x12K\\n\\x14\\x63\\x61mera_object_counts\\x18\\x05 \\x03(\\x0b\\x32-.waymo.open_dataset.Context.Stats.ObjectCount\\x12\\x13\\n\\x0btime_of_day\\x18\\x02 \\x01(\\t\\x12\\x10\\n\\x08location\\x18\\x03 \\x01(\\t\\x12\\x0f\\n\\x07weather\\x18\\x04 \\x01(\\t\\x1aJ\\n\\x0bObjectCount\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.waymo.open_dataset.Label.Type\\x12\\r\\n\\x05\\x63ount\\x18\\x02 \\x01(\\x05\\""\\xb1\\x01\\n\\nRangeImage\\x12\\x1e\\n\\x16range_image_compressed\\x18\\x02 \\x01(\\x0c\\x12$\\n\\x1c\\x63\\x61mera_projection_compressed\\x18\\x03 \\x01(\\x0c\\x12#\\n\\x1brange_image_pose_compressed\\x18\\x04 \\x01(\\x0c\\x12\\x38\\n\\x0brange_image\\x18\\x01 \\x01(\\x0b\\x32\\x1f.waymo.open_dataset.MatrixFloatB\\x02\\x18\\x01\\""\\x94\\x02\\n\\x0b\\x43\\x61meraImage\\x12\\x31\\n\\x04name\\x18\\x01 \\x01(\\x0e\\x32#.waymo.open_dataset.CameraName.Name\\x12\\r\\n\\x05image\\x18\\x02 \\x01(\\x0c\\x12+\\n\\x04pose\\x18\\x03 \\x01(\\x0b\\x32\\x1d.waymo.open_dataset.Transform\\x12.\\n\\x08velocity\\x18\\x04 \\x01(\\x0b\\x32\\x1c.waymo.open_dataset.Velocity\\x12\\x16\\n\\x0epose_timestamp\\x18\\x05 \\x01(\\x01\\x12\\x0f\\n\\x07shutter\\x18\\x06 \\x01(\\x01\\x12\\x1b\\n\\x13\\x63\\x61mera_trigger_time\\x18\\x07 \\x01(\\x01\\x12 \\n\\x18\\x63\\x61mera_readout_done_time\\x18\\x08 \\x01(\\x01\\""l\\n\\x0c\\x43\\x61meraLabels\\x12\\x31\\n\\x04name\\x18\\x01 \\x01(\\x0e\\x32#.waymo.open_dataset.CameraName.Name\\x12)\\n\\x06labels\\x18\\x02 \\x03(\\x0b\\x32\\x19.waymo.open_dataset.Label\\""\\xa1\\x01\\n\\x05Laser\\x12\\x30\\n\\x04name\\x18\\x01 \\x01(\\x0e\\x32\\"".waymo.open_dataset.LaserName.Name\\x12\\x32\\n\\nri_return1\\x18\\x02 \\x01(\\x0b\\x32\\x1e.waymo.open_dataset.RangeImage\\x12\\x32\\n\\nri_return2\\x18\\x03 \\x01(\\x0b\\x32\\x1e.waymo.open_dataset.RangeImage\\""\\xc0\\x03\\n\\x05\\x46rame\\x12,\\n\\x07\\x63ontext\\x18\\x01 \\x01(\\x0b\\x32\\x1b.waymo.open_dataset.Context\\x12\\x18\\n\\x10timestamp_micros\\x18\\x02 \\x01(\\x03\\x12+\\n\\x04pose\\x18\\x03 \\x01(\\x0b\\x32\\x1d.waymo.open_dataset.Transform\\x12/\\n\\x06images\\x18\\x04 \\x03(\\x0b\\x32\\x1f.waymo.open_dataset.CameraImage\\x12)\\n\\x06lasers\\x18\\x05 \\x03(\\x0b\\x32\\x19.waymo.open_dataset.Laser\\x12/\\n\\x0claser_labels\\x18\\x06 \\x03(\\x0b\\x32\\x19.waymo.open_dataset.Label\\x12@\\n\\x16projected_lidar_labels\\x18\\t \\x03(\\x0b\\x32 .waymo.open_dataset.CameraLabels\\x12\\x37\\n\\rcamera_labels\\x18\\x08 \\x03(\\x0b\\x32 .waymo.open_dataset.CameraLabels\\x12:\\n\\x0eno_label_zones\\x18\\x07 \\x03(\\x0b\\x32\\"".waymo.open_dataset.Polygon2dProto\'\n)\n\n\n\n_LABEL_BOX_TYPE = _descriptor.EnumDescriptor(\n  name=\'Type\',\n  full_name=\'waymo.open_dataset.Label.Box.Type\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_3D\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_2D\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_AA_2D\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=557,\n  serialized_end=623,\n)\n_sym_db.RegisterEnumDescriptor(_LABEL_BOX_TYPE)\n\n_LABEL_TYPE = _descriptor.EnumDescriptor(\n  name=\'Type\',\n  full_name=\'waymo.open_dataset.Label.Type\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_VEHICLE\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_PEDESTRIAN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_SIGN\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TYPE_CYCLIST\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=705,\n  serialized_end=801,\n)\n_sym_db.RegisterEnumDescriptor(_LABEL_TYPE)\n\n_LABEL_DIFFICULTYLEVEL = _descriptor.EnumDescriptor(\n  name=\'DifficultyLevel\',\n  full_name=\'waymo.open_dataset.Label.DifficultyLevel\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVEL_1\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVEL_2\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=803,\n  serialized_end=859,\n)\n_sym_db.RegisterEnumDescriptor(_LABEL_DIFFICULTYLEVEL)\n\n_CAMERANAME_NAME = _descriptor.EnumDescriptor(\n  name=\'Name\',\n  full_name=\'waymo.open_dataset.CameraName.Name\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FRONT\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FRONT_LEFT\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FRONT_RIGHT\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIDE_LEFT\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIDE_RIGHT\', index=5, number=5,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=1118,\n  serialized_end=1212,\n)\n_sym_db.RegisterEnumDescriptor(_CAMERANAME_NAME)\n\n_LASERNAME_NAME = _descriptor.EnumDescriptor(\n  name=\'Name\',\n  full_name=\'waymo.open_dataset.LaserName.Name\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TOP\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FRONT\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIDE_LEFT\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIDE_RIGHT\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'REAR\', index=5, number=5,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=1227,\n  serialized_end=1307,\n)\n_sym_db.RegisterEnumDescriptor(_LASERNAME_NAME)\n\n_CAMERACALIBRATION_ROLLINGSHUTTERREADOUTDIRECTION = _descriptor.EnumDescriptor(\n  name=\'RollingShutterReadOutDirection\',\n  full_name=\'waymo.open_dataset.CameraCalibration.RollingShutterReadOutDirection\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TOP_TO_BOTTOM\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LEFT_TO_RIGHT\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BOTTOM_TO_TOP\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RIGHT_TO_LEFT\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GLOBAL_SHUTTER\', index=5, number=5,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=1710,\n  serialized_end=1851,\n)\n_sym_db.RegisterEnumDescriptor(_CAMERACALIBRATION_ROLLINGSHUTTERREADOUTDIRECTION)\n\n\n_LABEL_BOX = _descriptor.Descriptor(\n  name=\'Box\',\n  full_name=\'waymo.open_dataset.Label.Box\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'center_x\', full_name=\'waymo.open_dataset.Label.Box.center_x\', index=0,\n      number=1, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'center_y\', full_name=\'waymo.open_dataset.Label.Box.center_y\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'center_z\', full_name=\'waymo.open_dataset.Label.Box.center_z\', index=2,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'length\', full_name=\'waymo.open_dataset.Label.Box.length\', index=3,\n      number=5, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'waymo.open_dataset.Label.Box.width\', index=4,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'waymo.open_dataset.Label.Box.height\', index=5,\n      number=6, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'heading\', full_name=\'waymo.open_dataset.Label.Box.heading\', index=6,\n      number=7, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LABEL_BOX_TYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=432,\n  serialized_end=623,\n)\n\n_LABEL_METADATA = _descriptor.Descriptor(\n  name=\'Metadata\',\n  full_name=\'waymo.open_dataset.Label.Metadata\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'speed_x\', full_name=\'waymo.open_dataset.Label.Metadata.speed_x\', index=0,\n      number=1, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'speed_y\', full_name=\'waymo.open_dataset.Label.Metadata.speed_y\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'accel_x\', full_name=\'waymo.open_dataset.Label.Metadata.accel_x\', index=2,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'accel_y\', full_name=\'waymo.open_dataset.Label.Metadata.accel_y\', index=3,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=625,\n  serialized_end=703,\n)\n\n_LABEL = _descriptor.Descriptor(\n  name=\'Label\',\n  full_name=\'waymo.open_dataset.Label\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'box\', full_name=\'waymo.open_dataset.Label.box\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metadata\', full_name=\'waymo.open_dataset.Label.metadata\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'waymo.open_dataset.Label.type\', index=2,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'waymo.open_dataset.Label.id\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'detection_difficulty_level\', full_name=\'waymo.open_dataset.Label.detection_difficulty_level\', index=4,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tracking_difficulty_level\', full_name=\'waymo.open_dataset.Label.tracking_difficulty_level\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_lidar_points_in_box\', full_name=\'waymo.open_dataset.Label.num_lidar_points_in_box\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_LABEL_BOX, _LABEL_METADATA, ],\n  enum_types=[\n    _LABEL_TYPE,\n    _LABEL_DIFFICULTYLEVEL,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=76,\n  serialized_end=859,\n)\n\n\n_POLYGON2DPROTO = _descriptor.Descriptor(\n  name=\'Polygon2dProto\',\n  full_name=\'waymo.open_dataset.Polygon2dProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'x\', full_name=\'waymo.open_dataset.Polygon2dProto.x\', index=0,\n      number=1, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'y\', full_name=\'waymo.open_dataset.Polygon2dProto.y\', index=1,\n      number=2, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'waymo.open_dataset.Polygon2dProto.id\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=861,\n  serialized_end=911,\n)\n\n\n_MATRIXSHAPE = _descriptor.Descriptor(\n  name=\'MatrixShape\',\n  full_name=\'waymo.open_dataset.MatrixShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dims\', full_name=\'waymo.open_dataset.MatrixShape.dims\', index=0,\n      number=1, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=913,\n  serialized_end=940,\n)\n\n\n_MATRIXFLOAT = _descriptor.Descriptor(\n  name=\'MatrixFloat\',\n  full_name=\'waymo.open_dataset.MatrixFloat\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'waymo.open_dataset.MatrixFloat.data\', index=0,\n      number=1, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=b\'\\020\\001\', file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'waymo.open_dataset.MatrixFloat.shape\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=942,\n  serialized_end=1021,\n)\n\n\n_MATRIXINT32 = _descriptor.Descriptor(\n  name=\'MatrixInt32\',\n  full_name=\'waymo.open_dataset.MatrixInt32\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'waymo.open_dataset.MatrixInt32.data\', index=0,\n      number=1, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=b\'\\020\\001\', file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'waymo.open_dataset.MatrixInt32.shape\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1023,\n  serialized_end=1102,\n)\n\n\n_CAMERANAME = _descriptor.Descriptor(\n  name=\'CameraName\',\n  full_name=\'waymo.open_dataset.CameraName\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CAMERANAME_NAME,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1104,\n  serialized_end=1212,\n)\n\n\n_LASERNAME = _descriptor.Descriptor(\n  name=\'LaserName\',\n  full_name=\'waymo.open_dataset.LaserName\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LASERNAME_NAME,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1214,\n  serialized_end=1307,\n)\n\n\n_TRANSFORM = _descriptor.Descriptor(\n  name=\'Transform\',\n  full_name=\'waymo.open_dataset.Transform\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'transform\', full_name=\'waymo.open_dataset.Transform.transform\', index=0,\n      number=1, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1309,\n  serialized_end=1339,\n)\n\n\n_VELOCITY = _descriptor.Descriptor(\n  name=\'Velocity\',\n  full_name=\'waymo.open_dataset.Velocity\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'v_x\', full_name=\'waymo.open_dataset.Velocity.v_x\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'v_y\', full_name=\'waymo.open_dataset.Velocity.v_y\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'v_z\', full_name=\'waymo.open_dataset.Velocity.v_z\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'w_x\', full_name=\'waymo.open_dataset.Velocity.w_x\', index=3,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'w_y\', full_name=\'waymo.open_dataset.Velocity.w_y\', index=4,\n      number=5, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'w_z\', full_name=\'waymo.open_dataset.Velocity.w_z\', index=5,\n      number=6, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1341,\n  serialized_end=1429,\n)\n\n\n_CAMERACALIBRATION = _descriptor.Descriptor(\n  name=\'CameraCalibration\',\n  full_name=\'waymo.open_dataset.CameraCalibration\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.CameraCalibration.name\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'intrinsic\', full_name=\'waymo.open_dataset.CameraCalibration.intrinsic\', index=1,\n      number=2, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'extrinsic\', full_name=\'waymo.open_dataset.CameraCalibration.extrinsic\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'waymo.open_dataset.CameraCalibration.width\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'waymo.open_dataset.CameraCalibration.height\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'rolling_shutter_direction\', full_name=\'waymo.open_dataset.CameraCalibration.rolling_shutter_direction\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CAMERACALIBRATION_ROLLINGSHUTTERREADOUTDIRECTION,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1432,\n  serialized_end=1851,\n)\n\n\n_LASERCALIBRATION = _descriptor.Descriptor(\n  name=\'LaserCalibration\',\n  full_name=\'waymo.open_dataset.LaserCalibration\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.LaserCalibration.name\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beam_inclinations\', full_name=\'waymo.open_dataset.LaserCalibration.beam_inclinations\', index=1,\n      number=2, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beam_inclination_min\', full_name=\'waymo.open_dataset.LaserCalibration.beam_inclination_min\', index=2,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'beam_inclination_max\', full_name=\'waymo.open_dataset.LaserCalibration.beam_inclination_max\', index=3,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'extrinsic\', full_name=\'waymo.open_dataset.LaserCalibration.extrinsic\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1854,\n  serialized_end=2059,\n)\n\n\n_CONTEXT_STATS_OBJECTCOUNT = _descriptor.Descriptor(\n  name=\'ObjectCount\',\n  full_name=\'waymo.open_dataset.Context.Stats.ObjectCount\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'waymo.open_dataset.Context.Stats.ObjectCount.type\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'count\', full_name=\'waymo.open_dataset.Context.Stats.ObjectCount.count\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2490,\n  serialized_end=2564,\n)\n\n_CONTEXT_STATS = _descriptor.Descriptor(\n  name=\'Stats\',\n  full_name=\'waymo.open_dataset.Context.Stats\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'laser_object_counts\', full_name=\'waymo.open_dataset.Context.Stats.laser_object_counts\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_object_counts\', full_name=\'waymo.open_dataset.Context.Stats.camera_object_counts\', index=1,\n      number=5, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'time_of_day\', full_name=\'waymo.open_dataset.Context.Stats.time_of_day\', index=2,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'location\', full_name=\'waymo.open_dataset.Context.Stats.location\', index=3,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'weather\', full_name=\'waymo.open_dataset.Context.Stats.weather\', index=4,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_CONTEXT_STATS_OBJECTCOUNT, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2272,\n  serialized_end=2564,\n)\n\n_CONTEXT = _descriptor.Descriptor(\n  name=\'Context\',\n  full_name=\'waymo.open_dataset.Context\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.Context.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_calibrations\', full_name=\'waymo.open_dataset.Context.camera_calibrations\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'laser_calibrations\', full_name=\'waymo.open_dataset.Context.laser_calibrations\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'stats\', full_name=\'waymo.open_dataset.Context.stats\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_CONTEXT_STATS, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2062,\n  serialized_end=2564,\n)\n\n\n_RANGEIMAGE = _descriptor.Descriptor(\n  name=\'RangeImage\',\n  full_name=\'waymo.open_dataset.RangeImage\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'range_image_compressed\', full_name=\'waymo.open_dataset.RangeImage.range_image_compressed\', index=0,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_projection_compressed\', full_name=\'waymo.open_dataset.RangeImage.camera_projection_compressed\', index=1,\n      number=3, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'range_image_pose_compressed\', full_name=\'waymo.open_dataset.RangeImage.range_image_pose_compressed\', index=2,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'range_image\', full_name=\'waymo.open_dataset.RangeImage.range_image\', index=3,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=b\'\\030\\001\', file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2567,\n  serialized_end=2744,\n)\n\n\n_CAMERAIMAGE = _descriptor.Descriptor(\n  name=\'CameraImage\',\n  full_name=\'waymo.open_dataset.CameraImage\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.CameraImage.name\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'image\', full_name=\'waymo.open_dataset.CameraImage.image\', index=1,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pose\', full_name=\'waymo.open_dataset.CameraImage.pose\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'velocity\', full_name=\'waymo.open_dataset.CameraImage.velocity\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pose_timestamp\', full_name=\'waymo.open_dataset.CameraImage.pose_timestamp\', index=4,\n      number=5, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shutter\', full_name=\'waymo.open_dataset.CameraImage.shutter\', index=5,\n      number=6, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_trigger_time\', full_name=\'waymo.open_dataset.CameraImage.camera_trigger_time\', index=6,\n      number=7, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_readout_done_time\', full_name=\'waymo.open_dataset.CameraImage.camera_readout_done_time\', index=7,\n      number=8, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2747,\n  serialized_end=3023,\n)\n\n\n_CAMERALABELS = _descriptor.Descriptor(\n  name=\'CameraLabels\',\n  full_name=\'waymo.open_dataset.CameraLabels\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.CameraLabels.name\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'labels\', full_name=\'waymo.open_dataset.CameraLabels.labels\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3025,\n  serialized_end=3133,\n)\n\n\n_LASER = _descriptor.Descriptor(\n  name=\'Laser\',\n  full_name=\'waymo.open_dataset.Laser\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'waymo.open_dataset.Laser.name\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ri_return1\', full_name=\'waymo.open_dataset.Laser.ri_return1\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'ri_return2\', full_name=\'waymo.open_dataset.Laser.ri_return2\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3136,\n  serialized_end=3297,\n)\n\n\n_FRAME = _descriptor.Descriptor(\n  name=\'Frame\',\n  full_name=\'waymo.open_dataset.Frame\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'context\', full_name=\'waymo.open_dataset.Frame.context\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'timestamp_micros\', full_name=\'waymo.open_dataset.Frame.timestamp_micros\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'pose\', full_name=\'waymo.open_dataset.Frame.pose\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'images\', full_name=\'waymo.open_dataset.Frame.images\', index=3,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lasers\', full_name=\'waymo.open_dataset.Frame.lasers\', index=4,\n      number=5, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'laser_labels\', full_name=\'waymo.open_dataset.Frame.laser_labels\', index=5,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'projected_lidar_labels\', full_name=\'waymo.open_dataset.Frame.projected_lidar_labels\', index=6,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'camera_labels\', full_name=\'waymo.open_dataset.Frame.camera_labels\', index=7,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'no_label_zones\', full_name=\'waymo.open_dataset.Frame.no_label_zones\', index=8,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=3300,\n  serialized_end=3748,\n)\n\n_LABEL_BOX.containing_type = _LABEL\n_LABEL_BOX_TYPE.containing_type = _LABEL_BOX\n_LABEL_METADATA.containing_type = _LABEL\n_LABEL.fields_by_name[\'box\'].message_type = _LABEL_BOX\n_LABEL.fields_by_name[\'metadata\'].message_type = _LABEL_METADATA\n_LABEL.fields_by_name[\'type\'].enum_type = _LABEL_TYPE\n_LABEL.fields_by_name[\'detection_difficulty_level\'].enum_type = _LABEL_DIFFICULTYLEVEL\n_LABEL.fields_by_name[\'tracking_difficulty_level\'].enum_type = _LABEL_DIFFICULTYLEVEL\n_LABEL_TYPE.containing_type = _LABEL\n_LABEL_DIFFICULTYLEVEL.containing_type = _LABEL\n_MATRIXFLOAT.fields_by_name[\'shape\'].message_type = _MATRIXSHAPE\n_MATRIXINT32.fields_by_name[\'shape\'].message_type = _MATRIXSHAPE\n_CAMERANAME_NAME.containing_type = _CAMERANAME\n_LASERNAME_NAME.containing_type = _LASERNAME\n_CAMERACALIBRATION.fields_by_name[\'name\'].enum_type = _CAMERANAME_NAME\n_CAMERACALIBRATION.fields_by_name[\'extrinsic\'].message_type = _TRANSFORM\n_CAMERACALIBRATION.fields_by_name[\'rolling_shutter_direction\'].enum_type = _CAMERACALIBRATION_ROLLINGSHUTTERREADOUTDIRECTION\n_CAMERACALIBRATION_ROLLINGSHUTTERREADOUTDIRECTION.containing_type = _CAMERACALIBRATION\n_LASERCALIBRATION.fields_by_name[\'name\'].enum_type = _LASERNAME_NAME\n_LASERCALIBRATION.fields_by_name[\'extrinsic\'].message_type = _TRANSFORM\n_CONTEXT_STATS_OBJECTCOUNT.fields_by_name[\'type\'].enum_type = _LABEL_TYPE\n_CONTEXT_STATS_OBJECTCOUNT.containing_type = _CONTEXT_STATS\n_CONTEXT_STATS.fields_by_name[\'laser_object_counts\'].message_type = _CONTEXT_STATS_OBJECTCOUNT\n_CONTEXT_STATS.fields_by_name[\'camera_object_counts\'].message_type = _CONTEXT_STATS_OBJECTCOUNT\n_CONTEXT_STATS.containing_type = _CONTEXT\n_CONTEXT.fields_by_name[\'camera_calibrations\'].message_type = _CAMERACALIBRATION\n_CONTEXT.fields_by_name[\'laser_calibrations\'].message_type = _LASERCALIBRATION\n_CONTEXT.fields_by_name[\'stats\'].message_type = _CONTEXT_STATS\n_RANGEIMAGE.fields_by_name[\'range_image\'].message_type = _MATRIXFLOAT\n_CAMERAIMAGE.fields_by_name[\'name\'].enum_type = _CAMERANAME_NAME\n_CAMERAIMAGE.fields_by_name[\'pose\'].message_type = _TRANSFORM\n_CAMERAIMAGE.fields_by_name[\'velocity\'].message_type = _VELOCITY\n_CAMERALABELS.fields_by_name[\'name\'].enum_type = _CAMERANAME_NAME\n_CAMERALABELS.fields_by_name[\'labels\'].message_type = _LABEL\n_LASER.fields_by_name[\'name\'].enum_type = _LASERNAME_NAME\n_LASER.fields_by_name[\'ri_return1\'].message_type = _RANGEIMAGE\n_LASER.fields_by_name[\'ri_return2\'].message_type = _RANGEIMAGE\n_FRAME.fields_by_name[\'context\'].message_type = _CONTEXT\n_FRAME.fields_by_name[\'pose\'].message_type = _TRANSFORM\n_FRAME.fields_by_name[\'images\'].message_type = _CAMERAIMAGE\n_FRAME.fields_by_name[\'lasers\'].message_type = _LASER\n_FRAME.fields_by_name[\'laser_labels\'].message_type = _LABEL\n_FRAME.fields_by_name[\'projected_lidar_labels\'].message_type = _CAMERALABELS\n_FRAME.fields_by_name[\'camera_labels\'].message_type = _CAMERALABELS\n_FRAME.fields_by_name[\'no_label_zones\'].message_type = _POLYGON2DPROTO\nDESCRIPTOR.message_types_by_name[\'Label\'] = _LABEL\nDESCRIPTOR.message_types_by_name[\'Polygon2dProto\'] = _POLYGON2DPROTO\nDESCRIPTOR.message_types_by_name[\'MatrixShape\'] = _MATRIXSHAPE\nDESCRIPTOR.message_types_by_name[\'MatrixFloat\'] = _MATRIXFLOAT\nDESCRIPTOR.message_types_by_name[\'MatrixInt32\'] = _MATRIXINT32\nDESCRIPTOR.message_types_by_name[\'CameraName\'] = _CAMERANAME\nDESCRIPTOR.message_types_by_name[\'LaserName\'] = _LASERNAME\nDESCRIPTOR.message_types_by_name[\'Transform\'] = _TRANSFORM\nDESCRIPTOR.message_types_by_name[\'Velocity\'] = _VELOCITY\nDESCRIPTOR.message_types_by_name[\'CameraCalibration\'] = _CAMERACALIBRATION\nDESCRIPTOR.message_types_by_name[\'LaserCalibration\'] = _LASERCALIBRATION\nDESCRIPTOR.message_types_by_name[\'Context\'] = _CONTEXT\nDESCRIPTOR.message_types_by_name[\'RangeImage\'] = _RANGEIMAGE\nDESCRIPTOR.message_types_by_name[\'CameraImage\'] = _CAMERAIMAGE\nDESCRIPTOR.message_types_by_name[\'CameraLabels\'] = _CAMERALABELS\nDESCRIPTOR.message_types_by_name[\'Laser\'] = _LASER\nDESCRIPTOR.message_types_by_name[\'Frame\'] = _FRAME\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nLabel = _reflection.GeneratedProtocolMessageType(\'Label\', (_message.Message,), {\n\n  \'Box\' : _reflection.GeneratedProtocolMessageType(\'Box\', (_message.Message,), {\n    \'DESCRIPTOR\' : _LABEL_BOX,\n    \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n    # @@protoc_insertion_point(class_scope:waymo.open_dataset.Label.Box)\n    })\n  ,\n\n  \'Metadata\' : _reflection.GeneratedProtocolMessageType(\'Metadata\', (_message.Message,), {\n    \'DESCRIPTOR\' : _LABEL_METADATA,\n    \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n    # @@protoc_insertion_point(class_scope:waymo.open_dataset.Label.Metadata)\n    })\n  ,\n  \'DESCRIPTOR\' : _LABEL,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Label)\n  })\n_sym_db.RegisterMessage(Label)\n_sym_db.RegisterMessage(Label.Box)\n_sym_db.RegisterMessage(Label.Metadata)\n\nPolygon2dProto = _reflection.GeneratedProtocolMessageType(\'Polygon2dProto\', (_message.Message,), {\n  \'DESCRIPTOR\' : _POLYGON2DPROTO,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Polygon2dProto)\n  })\n_sym_db.RegisterMessage(Polygon2dProto)\n\nMatrixShape = _reflection.GeneratedProtocolMessageType(\'MatrixShape\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MATRIXSHAPE,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.MatrixShape)\n  })\n_sym_db.RegisterMessage(MatrixShape)\n\nMatrixFloat = _reflection.GeneratedProtocolMessageType(\'MatrixFloat\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MATRIXFLOAT,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.MatrixFloat)\n  })\n_sym_db.RegisterMessage(MatrixFloat)\n\nMatrixInt32 = _reflection.GeneratedProtocolMessageType(\'MatrixInt32\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MATRIXINT32,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.MatrixInt32)\n  })\n_sym_db.RegisterMessage(MatrixInt32)\n\nCameraName = _reflection.GeneratedProtocolMessageType(\'CameraName\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CAMERANAME,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.CameraName)\n  })\n_sym_db.RegisterMessage(CameraName)\n\nLaserName = _reflection.GeneratedProtocolMessageType(\'LaserName\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LASERNAME,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.LaserName)\n  })\n_sym_db.RegisterMessage(LaserName)\n\nTransform = _reflection.GeneratedProtocolMessageType(\'Transform\', (_message.Message,), {\n  \'DESCRIPTOR\' : _TRANSFORM,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Transform)\n  })\n_sym_db.RegisterMessage(Transform)\n\nVelocity = _reflection.GeneratedProtocolMessageType(\'Velocity\', (_message.Message,), {\n  \'DESCRIPTOR\' : _VELOCITY,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Velocity)\n  })\n_sym_db.RegisterMessage(Velocity)\n\nCameraCalibration = _reflection.GeneratedProtocolMessageType(\'CameraCalibration\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CAMERACALIBRATION,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.CameraCalibration)\n  })\n_sym_db.RegisterMessage(CameraCalibration)\n\nLaserCalibration = _reflection.GeneratedProtocolMessageType(\'LaserCalibration\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LASERCALIBRATION,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.LaserCalibration)\n  })\n_sym_db.RegisterMessage(LaserCalibration)\n\nContext = _reflection.GeneratedProtocolMessageType(\'Context\', (_message.Message,), {\n\n  \'Stats\' : _reflection.GeneratedProtocolMessageType(\'Stats\', (_message.Message,), {\n\n    \'ObjectCount\' : _reflection.GeneratedProtocolMessageType(\'ObjectCount\', (_message.Message,), {\n      \'DESCRIPTOR\' : _CONTEXT_STATS_OBJECTCOUNT,\n      \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n      # @@protoc_insertion_point(class_scope:waymo.open_dataset.Context.Stats.ObjectCount)\n      })\n    ,\n    \'DESCRIPTOR\' : _CONTEXT_STATS,\n    \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n    # @@protoc_insertion_point(class_scope:waymo.open_dataset.Context.Stats)\n    })\n  ,\n  \'DESCRIPTOR\' : _CONTEXT,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Context)\n  })\n_sym_db.RegisterMessage(Context)\n_sym_db.RegisterMessage(Context.Stats)\n_sym_db.RegisterMessage(Context.Stats.ObjectCount)\n\nRangeImage = _reflection.GeneratedProtocolMessageType(\'RangeImage\', (_message.Message,), {\n  \'DESCRIPTOR\' : _RANGEIMAGE,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.RangeImage)\n  })\n_sym_db.RegisterMessage(RangeImage)\n\nCameraImage = _reflection.GeneratedProtocolMessageType(\'CameraImage\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CAMERAIMAGE,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.CameraImage)\n  })\n_sym_db.RegisterMessage(CameraImage)\n\nCameraLabels = _reflection.GeneratedProtocolMessageType(\'CameraLabels\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CAMERALABELS,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.CameraLabels)\n  })\n_sym_db.RegisterMessage(CameraLabels)\n\nLaser = _reflection.GeneratedProtocolMessageType(\'Laser\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LASER,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Laser)\n  })\n_sym_db.RegisterMessage(Laser)\n\nFrame = _reflection.GeneratedProtocolMessageType(\'Frame\', (_message.Message,), {\n  \'DESCRIPTOR\' : _FRAME,\n  \'__module__\' : \'waymo_open_dataset.waymo_open_dataset.dataset_pb2\'\n  # @@protoc_insertion_point(class_scope:waymo.open_dataset.Frame)\n  })\n_sym_db.RegisterMessage(Frame)\n\n\n_MATRIXFLOAT.fields_by_name[\'data\']._options = None\n_MATRIXINT32.fields_by_name[\'data\']._options = None\n_RANGEIMAGE.fields_by_name[\'range_image\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorflow_datasets/question_answering/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Question answering datasets.""""""\n\nfrom tensorflow_datasets.question_answering.cosmos_qa import CosmosQA\nfrom tensorflow_datasets.question_answering.mctaco import Mctaco\nfrom tensorflow_datasets.question_answering.natural_questions import NaturalQuestions\nfrom tensorflow_datasets.question_answering.squad import Squad\nfrom tensorflow_datasets.question_answering.trivia_qa import TriviaQA\nfrom tensorflow_datasets.question_answering.web_questions import WebQuestions\n'"
tensorflow_datasets/question_answering/cosmos_qa.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""The Cosmos QA dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport json\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{huang-etal-2019-cosmos,\n    title = ""Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning"",\n    author = ""Huang, Lifu  and\n      Le Bras, Ronan  and\n      Bhagavatula, Chandra  and\n      Choi, Yejin"",\n    booktitle = ""Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"",\n    year = ""2019"",\n    url = ""https://www.aclweb.org/anthology/D19-1243""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nCosmos QA is a large-scale dataset of 35.6K problems that require\n commonsense-based reading comprehension, formulated as multiple-choice\n questions. It focuses on reading between the lines over a diverse collection\n of people\'s everyday narratives, asking questions concerning on the likely\n causes or effects of events that require reasoning beyond the exact text\n spans in the context.\n""""""\n\n_SPLIT_DOWNLOAD_URL = {\n    \'train\':\n        \'https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/train.csv\',\n    \'validation\':\n        \'https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/valid.csv\',\n    \'test\':\n        \'https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/test.jsonl\'\n}\n\n\nclass CosmosQA(tfds.core.GeneratorBasedBuilder):\n  """"""The Cosmos QA dataset.""""""\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'context\': tfds.features.Text(),\n            \'question\': tfds.features.Text(),\n            \'answer0\': tfds.features.Text(),\n            \'answer1\': tfds.features.Text(),\n            \'answer2\': tfds.features.Text(),\n            \'answer3\': tfds.features.Text(),\n            # Label indicates which of the answers is correct.\n            \'label\': tfds.features.ClassLabel(names=[\'0\', \'1\', \'2\', \'3\']),\n            \'id\': tfds.features.Text(),\n        }),\n        # No default supervised_keys\n        supervised_keys=None,\n        homepage=\'https://wilburone.github.io/cosmos/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    file_paths = dl_manager.download(_SPLIT_DOWNLOAD_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=split, gen_kwargs={\'file_path\': file_path})\n        for split, file_path in file_paths.items()\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(file_path) as f:\n      # Test is in jsonl format whereas train and dev in tsv.\n      if file_path.endswith(\'.jsonl\'):\n        for line in f:\n          row = json.loads(line)\n          row[\'label\'] = -1\n          yield row[\'id\'], row\n      else:\n        reader = csv.DictReader(f, delimiter=\',\')\n        for row in reader:\n          yield row[\'id\'], row\n'"
tensorflow_datasets/question_answering/cosmos_qa_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for cosmos qa dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import cosmos_qa\n\n\nclass CosmosQATest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cosmos_qa.CosmosQA\n\n  DL_EXTRACT_RESULT = {\n      ""train"": ""train.csv"",\n      ""validation"": ""valid.csv"",\n      ""test"": ""test.jsonl"",\n  }\n  SPLITS = {\n      ""train"": 2,\n      ""validation"": 3,\n      ""test"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/question_answering/mctaco.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""The MC Taco dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\n\nimport tensorflow as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{ZKNR19,\n    author = {Ben Zhou, Daniel Khashabi, Qiang Ning and Dan Roth},\n    title = {""Going on a vacation"" takes longer than ""Going for a walk"": A Study of Temporal Commonsense Understanding },\n    booktitle = {EMNLP},\n    year = {2019},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nMC-TACO is a dataset of 13k question-answer pairs that require temporal\ncommonsense comprehension. The dataset contains five temporal properties:\n\n1. duration (how long an event takes)\n2. temporal ordering (typical order of events)\n3. typical time (when an event occurs)\n4. frequency (how often an event occurs)\n5. stationarity (whether a state is maintained for a very long time or indefinitely)\n\nWe hope that this dataset can promote the future exploration of this\n particular class of reasoning problems.\n""""""\n\n_SPLIT_DOWNLOAD_URL = {\n    \'validation\':\n        \'https://raw.githubusercontent.com/CogComp/MCTACO/master/dataset/dev_3783.tsv\',\n    \'test\':\n        \'https://raw.githubusercontent.com/CogComp/MCTACO/master/dataset/test_9442.tsv\',\n}\n\n\nclass Mctaco(tfds.core.GeneratorBasedBuilder):\n  """"""The Mctaco dataset.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'sentence\':\n                tfds.features.Text(),\n            \'question\':\n                tfds.features.Text(),\n            \'answer\':\n                tfds.features.Text(),\n            \'label\':\n                tfds.features.ClassLabel(names=[\'no\', \'yes\']),\n            \'category\':\n                tfds.features.ClassLabel(names=[\n                    \'Event Ordering\', \'Event Duration\', \'Frequency\',\n                    \'Stationarity\', \'Typical Time\'\n                ])\n        }),\n        # No default supervised_keys (as we have to pass both the sentence,\n        # question and possible answer as input.\n        supervised_keys=None,\n        homepage=\'https://github.com/CogComp/MCTACO\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    file_paths = dl_manager.download(_SPLIT_DOWNLOAD_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=split, gen_kwargs={\'file_path\': file_path})\n        for split, file_path in file_paths.items()\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(file_path) as f:\n      reader = csv.DictReader(\n          f,\n          delimiter=\'\\t\',\n          fieldnames=[\'sentence\', \'question\', \'answer\', \'label\', \'category\'])\n      for i, row in enumerate(reader):\n        yield i, {\n            \'sentence\': row[\'sentence\'],\n            \'question\': row[\'question\'],\n            \'answer\': row[\'answer\'],\n            \'label\': row[\'label\'],\n            \'category\': row[\'category\'],\n        }\n'"
tensorflow_datasets/question_answering/mctaco_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for mctaco dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import mctaco\n\n\nclass MctacoTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = mctaco.Mctaco\n  DL_EXTRACT_RESULT = {\n      ""validation"": ""dev_3783.tsv"",\n      ""test"": ""test_9942.tsv"",\n  }\n\n  SPLITS = {\n      ""validation"": 5,\n      ""test"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/question_answering/natural_questions.py,14,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Natural Questions: A Benchmark for Question Answering Research.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport re\n\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nif six.PY2:\n  import HTMLParser as html_parser  # pylint:disable=g-import-not-at-top\n  html_unescape = html_parser.HTMLParser().unescape\nelse:\n  import html  # pylint:disable=g-import-not-at-top\n  html_unescape = html.unescape\n\n_CITATION = """"""\n@article{47761,\ntitle\t= {Natural Questions: a Benchmark for Question Answering Research},\nauthor\t= {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},\nyear\t= {2019},\njournal\t= {Transactions of the Association of Computational Linguistics}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe NQ corpus contains questions from real users, and it requires QA systems to\nread and comprehend an entire Wikipedia article that may or may not contain the\nanswer to the question. The inclusion of real user questions, and the\nrequirement that solutions should read an entire page to find the answer, cause\nNQ to be a more realistic and challenging task than prior QA datasets.\n""""""\n\n_URL = \'https://ai.google.com/research/NaturalQuestions/dataset\'\n\n_BASE_DOWNLOAD_URL = \'https://storage.googleapis.com/natural_questions/v1.0\'\n_DOWNLOAD_URLS = {\n    \'train\': [\n        \'%s/train/nq-train-%02d.jsonl.gz\' % (_BASE_DOWNLOAD_URL, i)\n        for i in range(50)\n    ],\n    \'validation\': [\n        \'%s/dev/nq-dev-%02d.jsonl.gz\' % (_BASE_DOWNLOAD_URL, i)\n        for i in range(5)\n    ]\n}\n\n\nclass NaturalQuestions(tfds.core.BeamBasedBuilder):\n  """"""Natural Questions: A Benchmark for Question Answering Research.""""""\n\n  VERSION = tfds.core.Version(\'0.0.2\')\n  SUPPORTED_VERSIONS = [tfds.core.Version(\'0.0.1\')]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'id\': tf.string,\n            \'document\': {\n                \'title\': tfds.features.Text(),\n                \'url\': tfds.features.Text(),\n                \'html\': tfds.features.Text(),\n                \'tokens\': tfds.features.Sequence({\n                    \'token\': tfds.features.Text(),\n                    \'is_html\': tf.bool,\n                })\n            },\n            \'question\': {\n                \'text\': tfds.features.Text(),\n                \'tokens\': tfds.features.Sequence(tf.string),\n            },\n            \'annotations\': tfds.features.Sequence({\n                \'id\': tf.string,\n                \'long_answer\': {\n                    \'start_token\': tf.int64,\n                    \'end_token\': tf.int64,\n                    \'start_byte\': tf.int64,\n                    \'end_byte\': tf.int64,\n                },\n                \'short_answers\': tfds.features.Sequence({\n                    \'start_token\': tf.int64,\n                    \'end_token\': tf.int64,\n                    \'start_byte\': tf.int64,\n                    \'end_byte\': tf.int64,\n                    \'text\': tfds.features.Text(),\n                }),\n                \'yes_no_answer\': tfds.features.ClassLabel(\n                    names=[\'NO\', \'YES\'])  # Can also be -1 for NONE.\n            }),\n        }),\n        supervised_keys=None,\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    files = dl_manager.download(_DOWNLOAD_URLS)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'filepaths\': files[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'filepaths\': files[\'validation\']},\n        ),\n    ]\n\n  def _build_pcollection(self, pipeline, filepaths):\n    """"""Build PCollection of examples.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _parse_example(line):\n      """"""Parse a single json line and emit an example dict.""""""\n      ex_json = json.loads(line)\n      html_bytes = ex_json[\'document_html\'].encode(\'utf-8\')\n\n      def _parse_short_answer(short_ans):\n        """"""""Extract text of short answer.""""""\n        ans_bytes = html_bytes[\n            short_ans[\'start_byte\']:short_ans[\'end_byte\']]\n        # Remove non-breaking spaces.\n        ans_bytes = ans_bytes.replace(b\'\\xc2\\xa0\', b\' \')\n        text = ans_bytes.decode(\'utf-8\')\n        # Remove HTML markup.\n        text = re.sub(\'<([^>]*)>\', \'\', html_unescape(text))\n        # Replace \\xa0 characters with spaces.\n        return {\n            \'start_token\': short_ans[\'start_token\'],\n            \'end_token\': short_ans[\'end_token\'],\n            \'start_byte\': short_ans[\'start_byte\'],\n            \'end_byte\': short_ans[\'end_byte\'],\n            \'text\': text\n        }\n\n      def _parse_annotation(an_json):\n        return {\n            # Convert to str since some IDs cannot be represented by tf.int64.\n            \'id\': str(an_json[\'annotation_id\']),\n            \'long_answer\': {\n                \'start_token\': an_json[\'long_answer\'][\'start_token\'],\n                \'end_token\': an_json[\'long_answer\'][\'end_token\'],\n                \'start_byte\': an_json[\'long_answer\'][\'start_byte\'],\n                \'end_byte\': an_json[\'long_answer\'][\'end_byte\'],\n            },\n            \'short_answers\': [\n                _parse_short_answer(ans) for ans in an_json[\'short_answers\']],\n            \'yes_no_answer\': (\n                -1 if an_json[\'yes_no_answer\'] == \'NONE\'\n                else an_json[\'yes_no_answer\'])\n        }\n\n      beam.metrics.Metrics.counter(\'nq\', \'examples\').inc()\n      # Convert to str since some IDs cannot be represented by tf.int64.\n      id_ = str(ex_json[\'example_id\'])\n      return id_, {\n          \'id\': id_,\n          \'document\': {\n              \'title\': ex_json[\'document_title\'],\n              \'url\': ex_json[\'document_url\'],\n              \'html\': html_bytes,\n              \'tokens\': [\n                  {\'token\': t[\'token\'], \'is_html\': t[\'html_token\']}\n                  for t in ex_json[\'document_tokens\']\n              ]\n          },\n          \'question\': {\n              \'text\': ex_json[\'question_text\'],\n              \'tokens\': ex_json[\'question_tokens\'],\n          },\n          \'annotations\': [\n              _parse_annotation(an_json) for an_json in ex_json[\'annotations\']\n          ]\n      }\n\n    return (\n        pipeline\n        | beam.Create(filepaths)\n        | beam.io.ReadAllFromText()\n        | beam.Map(_parse_example))\n'"
tensorflow_datasets/question_answering/natural_questions_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for natural_questions dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import natural_questions\n\n\nclass NaturalQuestionsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = natural_questions.NaturalQuestions\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""train"": [""nq-train-00.jsonl.gz"", ""nq-train-01.jsonl.gz""],\n      ""validation"": [""nq-dev-00.jsonl.gz""],\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/question_answering/squad.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SQUAD: The Stanford Question Answering Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = ""{SQuAD: 100,000+ Questions for Machine Comprehension of Text}"",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}\n""""""\n\n_DESCRIPTION = """"""\\\nStanford Question Answering Dataset (SQuAD) is a reading comprehension \\\ndataset, consisting of questions posed by crowdworkers on a set of Wikipedia \\\narticles, where the answer to every question is a segment of text, or span, \\\nfrom the corresponding reading passage, or the question might be unanswerable.\n""""""\n\n\nclass SquadConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for SQUAD.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, **kwargs):\n    """"""BuilderConfig for SQUAD.\n\n    Args:\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(SquadConfig, self).__init__(**kwargs)\n\n\nclass Squad(tfds.core.GeneratorBasedBuilder):\n  """"""SQUAD: The Stanford Question Answering Dataset. Version 1.1.""""""\n  _URL = ""https://rajpurkar.github.io/SQuAD-explorer/dataset/""\n  _DEV_FILE = ""dev-v1.1.json""\n  _TRAINING_FILE = ""train-v1.1.json""\n\n  BUILDER_CONFIGS = [\n      SquadConfig(\n          name=""plain_text"",\n          version=tfds.core.Version(\n              ""1.0.0"",\n              ""New split API (https://tensorflow.org/datasets/splits)""),\n          description=""Plain text"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""id"":\n                tf.string,\n            ""title"":\n                tfds.features.Text(),\n            ""context"":\n                tfds.features.Text(),\n            ""question"":\n                tfds.features.Text(),\n            ""answers"":\n                tfds.features.Sequence({\n                    ""text"": tfds.features.Text(),\n                    ""answer_start"": tf.int32,\n                }),\n        }),\n        # No default supervised_keys (as we have to pass both question\n        # and context as input).\n        supervised_keys=None,\n        homepage=""https://rajpurkar.github.io/SQuAD-explorer/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    urls_to_download = {\n        ""train"": os.path.join(self._URL, self._TRAINING_FILE),\n        ""dev"": os.path.join(self._URL, self._DEV_FILE)\n    }\n    downloaded_files = dl_manager.download_and_extract(urls_to_download)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepath"": downloaded_files[""train""]}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""filepath"": downloaded_files[""dev""]}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""This function returns the examples in the raw (text) form.""""""\n    logging.info(""generating examples from = %s"", filepath)\n    with tf.io.gfile.GFile(filepath) as f:\n      squad = json.load(f)\n      for article in squad[""data""]:\n        title = article.get(""title"", """").strip()\n        for paragraph in article[""paragraphs""]:\n          context = paragraph[""context""].strip()\n          for qa in paragraph[""qas""]:\n            question = qa[""question""].strip()\n            id_ = qa[""id""]\n\n            answer_starts = [answer[""answer_start""] for answer in qa[""answers""]]\n            answers = [answer[""text""].strip() for answer in qa[""answers""]]\n\n            # Features currently used are ""context"", ""question"", and ""answers"".\n            # Others are extracted here for the ease of future expansions.\n            yield id_, {\n                ""title"": title,\n                ""context"": context,\n                ""question"": question,\n                ""id"": id_,\n                ""answers"": {\n                    ""answer_start"": answer_starts,\n                    ""text"": answers,\n                },\n            }\n'"
tensorflow_datasets/question_answering/squad_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for squad dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import squad\n\n\nclass SquadTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = squad.Squad\n\n  DL_EXTRACT_RESULT = {\n      ""train"": ""train-v1.1.json"",\n      ""dev"": ""dev-v1.1.json"",\n  }\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/question_answering/trivia_qa.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TriviaQA: A Reading Comprehension Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\n@article{2017arXivtriviaqa,\n       author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},\n                 Daniel and {Zettlemoyer}, Luke},\n        title = ""{triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}"",\n      journal = {arXiv e-prints},\n         year = 2017,\n          eid = {arXiv:1705.03551},\n        pages = {arXiv:1705.03551},\narchivePrefix = {arXiv},\n       eprint = {1705.03551},\n}\n""""""\n_DOWNLOAD_URL_TMPL = (\n    ""http://nlp.cs.washington.edu/triviaqa/data/triviaqa-{}.tar.gz"")\n_TRAIN_FILE_FORMAT = ""*-train.json""\n_VALIDATION_FILE_FORMAT = ""*-dev.json""\n_TEST_FILE_FORMAT = ""*test-without-answers.json""\n_WEB_EVIDENCE_DIR = ""evidence/web""\n_WIKI_EVIDENCE_DIR = ""evidence/wikipedia""\n\n_DESCRIPTION = """"""\\\nTriviaqQA is a reading comprehension dataset containing over 650K\nquestion-answer-evidence triples. TriviaqQA includes 95K question-answer\npairs authored by trivia enthusiasts and independently gathered evidence\ndocuments, six per question on average, that provide high quality distant\nsupervision for answering the questions.\n""""""\n\n_RC_DESCRIPTION = """"""\\\nQuestion-answer pairs where all documents for a given question contain the\nanswer string(s).\n""""""\n\n_UNFILTERED_DESCRIPTION = """"""\\\n110k question-answer pairs for open domain QA where not all documents for a\ngiven question contain the answer string(s). This makes the unfiltered dataset\nmore appropriate for IR-style QA.\n""""""\n\n_CONTEXT_ADDENDUM = ""Includes context from Wikipedia and search results.""\n\n\ndef _web_evidence_dir(tmp_dir):\n  return tf.io.gfile.glob(os.path.join(tmp_dir, _WEB_EVIDENCE_DIR))\n\n\ndef _wiki_evidence_dir(tmp_dir):\n  return tf.io.gfile.glob(os.path.join(tmp_dir, _WIKI_EVIDENCE_DIR))\n\n\nclass TriviaQAConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for TriviaQA.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, unfiltered=False, exclude_context=False, **kwargs):\n    """"""BuilderConfig for TriviaQA.\n\n    Args:\n      unfiltered: bool, whether to use the unfiltered version of the dataset,\n        intended for open-domain QA.\n      exclude_context: bool, whether to exclude Wikipedia and search context for\n        reduced size.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name = ""unfiltered"" if unfiltered else ""rc""\n    if exclude_context:\n      name += "".nocontext""\n    description = _UNFILTERED_DESCRIPTION if unfiltered else _RC_DESCRIPTION\n    if not exclude_context:\n      description += _CONTEXT_ADDENDUM\n    super(TriviaQAConfig, self).__init__(\n        name=name,\n        description=description,\n        version=tfds.core.Version(""1.1.0""),\n        **kwargs)\n    self.unfiltered = unfiltered\n    self.exclude_context = exclude_context\n\n\nclass TriviaQA(tfds.core.GeneratorBasedBuilder):\n  """"""TriviaQA is a reading comprehension dataset.\n\n  It containss over 650K question-answer-evidence triples.\n  """"""\n\n  BUILDER_CONFIGS = [\n      TriviaQAConfig(unfiltered=False, exclude_context=False),  # rc\n      TriviaQAConfig(unfiltered=False, exclude_context=True),  # rc.nocontext\n      TriviaQAConfig(unfiltered=True, exclude_context=False),  # unfiltered\n      TriviaQAConfig(unfiltered=True, exclude_context=True),\n      # unfilered.nocontext\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""question"":\n                tfds.features.Text(),\n            ""question_id"":\n                tfds.features.Text(),\n            ""question_source"":\n                tfds.features.Text(),\n            ""entity_pages"":\n                tfds.features.Sequence({\n                    ""doc_source"":\n                        tfds.features.Text(),\n                    ""filename"":\n                        tfds.features.Text(),\n                    ""title"":\n                        tfds.features.Text(),\n                    ""wiki_context"":\n                        tfds.features.Text(),\n                }),\n            ""search_results"":\n                tfds.features.Sequence({\n                    ""description"":\n                        tfds.features.Text(),\n                    ""filename"":\n                        tfds.features.Text(),\n                    ""rank"":\n                        tf.int32,\n                    ""title"":\n                        tfds.features.Text(),\n                    ""url"":\n                        tfds.features.Text(),\n                    ""search_context"":\n                        tfds.features.Text(),\n                }),\n            ""answer"":\n                tfds.features.FeaturesDict({\n                    ""aliases"":\n                        tfds.features.Sequence(tfds.features.Text()),\n                    ""normalized_aliases"":\n                        tfds.features.Sequence(tfds.features.Text()),\n                    ""matched_wiki_entity_name"":\n                        tfds.features.Text(),\n                    ""normalized_matched_wiki_entity_name"":\n                        tfds.features.Text(),\n                    ""normalized_value"":\n                        tfds.features.Text(),\n                    ""type"":\n                        tfds.features.Text(),\n                    ""value"":\n                        tfds.features.Text(),\n                }),\n        }),\n\n        supervised_keys=None,\n        homepage=""http://nlp.cs.washington.edu/triviaqa/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    cfg = self.builder_config\n    download_urls = dict()\n    if not (cfg.unfiltered and cfg.exclude_context):\n      download_urls[""rc""] = _DOWNLOAD_URL_TMPL.format(""rc"")\n    if cfg.unfiltered:\n      download_urls[""unfiltered""] = _DOWNLOAD_URL_TMPL.format(""unfiltered"")\n    file_paths = dl_manager.download_and_extract(download_urls)\n\n    qa_dir = (\n        os.path.join(file_paths[""unfiltered""], ""triviaqa-unfiltered"")\n        if cfg.unfiltered else\n        os.path.join(file_paths[""rc""], ""qa""))\n    train_files = tf.io.gfile.glob(os.path.join(qa_dir, _TRAIN_FILE_FORMAT))\n    valid_files = tf.io.gfile.glob(\n        os.path.join(qa_dir, _VALIDATION_FILE_FORMAT))\n    test_files = tf.io.gfile.glob(os.path.join(qa_dir, _TEST_FILE_FORMAT))\n\n    if cfg.exclude_context:\n      web_evidence_dir = None\n      wiki_evidence_dir = None\n    else:\n      web_evidence_dir = os.path.join(file_paths[""rc""], _WEB_EVIDENCE_DIR)\n      wiki_evidence_dir = os.path.join(file_paths[""rc""], _WIKI_EVIDENCE_DIR)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""files"": train_files,\n                        ""web_dir"": web_evidence_dir,\n                        ""wiki_dir"": wiki_evidence_dir}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""files"": valid_files,\n                        ""web_dir"": web_evidence_dir,\n                        ""wiki_dir"": wiki_evidence_dir}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""files"": test_files,\n                        ""web_dir"": web_evidence_dir,\n                        ""wiki_dir"": wiki_evidence_dir}),\n    ]\n\n  def _generate_examples(self, files, web_dir, wiki_dir):\n    """"""This function returns the examples.""""""\n\n    def parse_example(article):\n      """"""Return a single example from an article JSON record.""""""\n      def _strip(collection):\n        return [item.strip() for item in collection]\n\n      if ""Answer"" in article:\n        answer = article[""Answer""]\n        answer_dict = {\n            ""aliases"":\n                _strip(answer[""Aliases""]),\n            ""normalized_aliases"":\n                _strip(answer[""NormalizedAliases""]),\n            ""matched_wiki_entity_name"":\n                answer.get(""MatchedWikiEntryName"", """").strip(),\n            ""normalized_matched_wiki_entity_name"":\n                answer.get(""NormalizedMatchedWikiEntryName"", """").strip(),\n            ""normalized_value"":\n                answer[""NormalizedValue""].strip(),\n            ""type"":\n                answer[""Type""].strip(),\n            ""value"":\n                answer[""Value""].strip(),\n        }\n      else:\n        answer_dict = {\n            ""aliases"":\n                [],\n            ""normalized_aliases"":\n                [],\n            ""matched_wiki_entity_name"":\n                ""<unk>"",\n            ""normalized_matched_wiki_entity_name"":\n                ""<unk>"",\n            ""normalized_value"":\n                ""<unk>"",\n            ""type"":\n                """",\n            ""value"":\n                ""<unk>"",\n        }\n\n      if self.builder_config.exclude_context:\n        article[""SearchResults""] = []\n        article[""EntityPages""] = []\n\n      def _add_context(collection, context_field, file_dir):\n        """"""Adds context from file, or skips if file does not exist.""""""\n        new_items = []\n        for item in collection:\n          if ""Filename"" not in item:\n            logging.info(""Missing context \'Filename\', skipping."")\n            continue\n\n          new_item = item.copy()\n          fname = item[""Filename""]\n          try:\n            with tf.io.gfile.GFile(os.path.join(file_dir, fname)) as f:\n              new_item[context_field] = f.read()\n          except (IOError, tf.errors.NotFoundError):\n            logging.info(""File does not exist, skipping: %s"", fname)\n            continue\n          new_items.append(new_item)\n        return new_items\n\n      def _strip_if_str(v):\n        return v.strip() if isinstance(v, six.string_types) else v\n      def _transpose_and_strip_dicts(dicts, field_names):\n        return {\n            tfds.core.naming.camelcase_to_snakecase(k):\n                [_strip_if_str(d[k]) for d in dicts]\n            for k in field_names\n        }\n\n      search_results = _transpose_and_strip_dicts(\n          _add_context(\n              article.get(""SearchResults"", []), ""SearchContext"", web_dir),\n          [""Description"", ""Filename"", ""Rank"", ""Title"", ""Url"",\n           ""SearchContext""])\n\n      entity_pages = _transpose_and_strip_dicts(\n          _add_context(\n              article.get(""EntityPages"", []), ""WikiContext"", wiki_dir),\n          [""DocSource"", ""Filename"", ""Title"", ""WikiContext""])\n\n      question = article[""Question""].strip()\n      question_id = article[""QuestionId""]\n      question_source = article[""QuestionSource""].strip()\n\n      return {\n          ""entity_pages"": entity_pages,\n          ""search_results"": search_results,\n          ""question"": question,\n          ""question_id"": question_id,\n          ""question_source"": question_source,\n          ""answer"": answer_dict,\n      }\n\n    for filepath in files:\n      logging.info(""generating examples from = %s"", filepath)\n      fname = os.path.basename(filepath)\n\n      with tf.io.gfile.GFile(filepath) as f:\n        current_record = """"\n        for line in f:\n          if line == ""        {\\n"":\n            current_record = line\n          elif line.startswith(""        }""):  # Handles final record as well.\n            article = json.loads(current_record + ""}"")\n            current_record = """"\n            example = parse_example(article)\n            yield ""%s_%s"" % (fname, example[""question_id""]), example\n          else:\n            current_record += line\n'"
tensorflow_datasets/question_answering/trivia_qa_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for triviaqa dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import trivia_qa\n\n\nclass TriviaqaTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = trivia_qa.TriviaQA\n  DL_EXTRACT_RESULT = {\n      ""rc"": """",\n      ""unfiltered"": """",\n  }\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 1,\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/question_answering/web_questions.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WebQuestions Benchmark for Question Answering.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport re\n\nimport tensorflow as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\n@inproceedings{berant-etal-2013-semantic,\n    title = ""Semantic Parsing on {F}reebase from Question-Answer Pairs"",\n    author = ""Berant, Jonathan  and\n      Chou, Andrew  and\n      Frostig, Roy  and\n      Liang, Percy"",\n    booktitle = ""Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing"",\n    month = oct,\n    year = ""2013"",\n    address = ""Seattle, Washington, USA"",\n    publisher = ""Association for Computational Linguistics"",\n    url = ""https://www.aclweb.org/anthology/D13-1160"",\n    pages = ""1533--1544"",\n}\n""""""\n_SPLIT_DOWNLOAD_URL = {\n    \'train\':\n        \'https://worksheets.codalab.org/rest/bundles/0x4a763f8cde224c2da592b75f29e2f5c2/contents/blob/\',\n    \'test\':\n        \'https://worksheets.codalab.org/rest/bundles/0xe7bac352fce7448c9ef238fb0a297ec2/contents/blob/\',\n}\n\n_DESCRIPTION = """"""\\\nThis dataset consists of 6,642 question/answer pairs.\nThe questions are supposed to be answerable by Freebase, a large knowledge graph.\nThe questions are mostly centered around a single named entity.\nThe questions are popular ones asked on the web (at least in 2013).\n""""""\n\n\nclass WebQuestions(tfds.core.GeneratorBasedBuilder):\n  """"""WebQuestions Benchmark for Question Answering.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'url\':\n                tfds.features.Text(),\n            \'question\':\n                tfds.features.Text(),\n            \'answers\':\n                tfds.features.Sequence(tfds.features.Text()),\n        }),\n        supervised_keys=None,\n        homepage=\'https://worksheets.codalab.org/worksheets/0xba659fe363cb46e7a505c5b6a774dc8a\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    file_paths = dl_manager.download(_SPLIT_DOWNLOAD_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=split, gen_kwargs={\'file_path\': file_path})\n        for split, file_path in file_paths.items()\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Parses split file and yields examples.""""""\n\n    def _target_to_answers(target):\n      target = re.sub(r\'^\\(list |\\)$\', \'\', target)\n      return [\n          \'\'.join(ans) for ans in\n          re.findall(r\'\\(description (?:""([^""]+?)""|([^)]+?))\\)\\w*\', target)\n      ]\n\n    with tf.io.gfile.GFile(file_path) as f:\n      examples = json.load(f)\n      for i, ex in enumerate(examples):\n        yield i, {\n            \'url\': ex[\'url\'],\n            \'question\': ex[\'utterance\'],\n            \'answers\': _target_to_answers(ex[\'targetValue\']),\n        }\n'"
tensorflow_datasets/question_answering/web_questions_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for web_questions dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.question_answering import web_questions\n\n\nclass TriviaqaTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = web_questions.WebQuestions\n  DL_EXTRACT_RESULT = {\n      ""train"": ""train.json"",\n      ""test"": ""test.json"",\n  }\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/scripts/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n'"
tensorflow_datasets/scripts/create_new_dataset.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate the minimal source code for a new dataset.\n\npython -m tensorflow_datasets.scripts.create_new_dataset \\\n  --dataset dataset_name \\\n  --type dataset_type\n\n""""""\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\n# gfile cannot be imported directly\n# `from tensorflow.io import gfile`\nimport tensorflow.compat.v2 as tf\ngfile = tf.io.gfile\ndel tf\n\nfrom tensorflow_datasets.core import naming  # pylint: disable=g-import-not-at-top\nfrom tensorflow_datasets.core.utils import py_utils\n\nFLAGS = flags.FLAGS\n\n_DATASET_TYPE = [\n    \'audio\',\n    \'image\',\n    \'image_classification\',\n    \'object_detection\',\n    \'question_answering\',\n    \'structured\',\n    \'summarization\',\n    \'text\',\n    \'translate\',\n    \'video\',\n]\n\nflags.DEFINE_string(\'tfds_dir\', None, \'Root directory of tfds (auto-computed)\')\nflags.DEFINE_string(\'dataset\', None, \'Dataset name\')\nflags.DEFINE_enum(\'type\', None, _DATASET_TYPE, \'Dataset type\')\n\n\n_HEADER = """"""\\\n\\""""""{dataset_name} dataset.\\""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n""""""\n\n_DATASET_DEFAULT_IMPORTS = """"""\\\nimport tensorflow_datasets.public_api as tfds\n\n""""""\n\n_DATASET_TEST_DEFAULTS_IMPORTS = """"""\\\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.{dataset_type} import {dataset_name}\n\n""""""\n\n_CITATION = """"""\\\n# {TODO}: BibTeX citation\n_CITATION = \\""""""\n\\""""""\\n\n""""""\n\n_DESCRIPTION = """"""\\\n# {TODO}:\n_DESCRIPTION = \\""""""\n\\""""""\\n\n""""""\n\n_DATASET_DEFAULTS = """"""\\\n\nclass {dataset_cls}(tfds.core.GeneratorBasedBuilder):\n  \\""""""{TODO}: Short description of my dataset.\\""""""\n\n  # {TODO}: Set up version.\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n    # {TODO}: Specifies the tfds.core.DatasetInfo object\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({{\n            # These are the features of your dataset like images, labels ...\n        }}),\n        # If there\'s a common (input, target) tuple from the features,\n        # specify them here. They\'ll be used if as_supervised=True in\n        # builder.as_dataset.\n        supervised_keys=(),\n        # Homepage of the dataset for documentation\n        homepage=\'https://dataset-homepage/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    \\""""""Returns SplitGenerators.\\""""""\n    # {TODO}: Downloads the data and defines the splits\n    # dl_manager is a tfds.download.DownloadManager that can be used to\n    # download and extract URLs\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={{}},\n        ),\n    ]\n\n  def _generate_examples(self):\n    \\""""""Yields examples.\\""""""\n    # {TODO}: Yields (key, example) tuples from the dataset\n    yield \'key\', {{}}\\n\n""""""\n\n_DATASET_TEST_DEFAULTS = """"""\\\n\nclass {dataset_cls}Test(tfds.testing.DatasetBuilderTestCase):\n  # {TODO}:\n  DATASET_CLASS = {dataset_name}.{dataset_cls}\n  SPLITS = {{\n      ""train"": 3,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n  }}\n\n  # If you are calling `download/download_and_extract` with a dict, like:\n  #   dl_manager.download({{\'some_key\': \'http://a.org/out.txt\', ...}})\n  # then the tests needs to provide the fake output paths relative to the\n  # fake data directory\n  # DL_EXTRACT_RESULT = {{\'some_key\': \'output_file1.txt\', ...}}\n\n\nif __name__ == ""__main__"":\n  tfds.testing.test_main()\n\n""""""\n\n_CHECKSUM_FILE = """"""\\\n# {TODO}: If your dataset downloads files, then the checksums will be\n# automatically added here when running the download_and_prepare script\n# with --register_checksums.\n""""""\n\n\ndef create_dataset_file(root_dir, data):\n  """"""Create a new dataset from a template.""""""\n  file_path = os.path.join(root_dir, \'{dataset_type}\', \'{dataset_name}.py\')\n  context = (\n      _HEADER + _DATASET_DEFAULT_IMPORTS + _CITATION + _DESCRIPTION +\n      _DATASET_DEFAULTS)\n\n  with gfile.GFile(file_path.format(**data), \'w\') as f:\n    f.write(context.format(**data))\n\n\ndef add_the_init(root_dir, data):\n  """"""Append the new dataset file to the __init__.py.""""""\n  init_file = os.path.join(root_dir, \'{dataset_type}\', \'__init__.py\')\n  context = (\'from tensorflow_datasets.{dataset_type}.{dataset_name} import \'\n             \'{dataset_cls}  # {TODO} Sort alphabetically\\n\')\n  with gfile.GFile(init_file.format(**data), \'a\') as f:\n    f.write(context.format(**data))\n\n\ndef create_dataset_test_file(root_dir, data):\n  """"""Create the test file associated with the dataset.""""""\n  file_path = os.path.join(root_dir, \'{dataset_type}\', \'{dataset_name}_test.py\')\n  context = (_HEADER + _DATASET_TEST_DEFAULTS_IMPORTS + _DATASET_TEST_DEFAULTS)\n\n  with gfile.GFile(file_path.format(**data), \'w\') as f:\n    f.write(context.format(**data))\n\n\ndef create_fake_data(root_dir, data):\n  fake_examples_dir = os.path.join(root_dir, \'testing\', \'test_data\',\n                                   \'fake_examples\', \'{dataset_name}\')\n  fake_examples_dir = fake_examples_dir.format(**data)\n  gfile.makedirs(fake_examples_dir)\n\n  fake_path = os.path.join(fake_examples_dir,\n                           \'TODO-add_fake_data_in_this_directory.txt\')\n  with gfile.GFile(fake_path, \'w\') as f:\n    f.write(\'{TODO}: Add fake data in this directory\'.format(**data))\n\n\ndef create_checksum_file(root_dir, data):\n  checksum_path = os.path.join(root_dir, \'url_checksums\', \'{dataset_name}.txt\')\n  with gfile.GFile(checksum_path.format(**data), \'w\') as f:\n    f.write(_CHECKSUM_FILE.format(**data))\n\n\ndef main(_):\n  dataset_name = FLAGS.dataset\n  dataset_type = FLAGS.type\n  root_dir = FLAGS.tfds_dir\n  if not root_dir:\n    root_dir = py_utils.tfds_dir()\n\n  data = dict(\n      dataset_name=dataset_name,\n      dataset_type=dataset_type,\n      dataset_cls=naming.snake_to_camelcase(dataset_name),\n      TODO=\'TODO({})\'.format(dataset_name),\n  )\n\n  create_dataset_file(root_dir, data)\n  add_the_init(root_dir, data)\n  create_dataset_test_file(root_dir, data)\n  create_fake_data(root_dir, data)\n  create_checksum_file(root_dir, data)\n\n  print(\n      \'Dataset generated in {}\\n\'\n      \'You can start with searching TODO({}).\\n\'\n      \'Please check this \'\n      \'`https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md`\'\n      \'for details.\'.format(root_dir, dataset_name))\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/scripts/download_and_prepare.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Script to call download_and_prepare on DatasetBuilder.\n\nStandalone script to generate specific dataset(s). This can be\nused if you want to separate download/generation of dataset from actual usage.\n\nBy default, the dataset is generated in the default location\n(~/tensorflow_datasets), which the same as when calling `tfds.load()`.\n\nInstructions:\n\n```\npython -m tensorflow_datasets.scripts.download_and_prepare \\\n  --datasets=cifar10\n```\n\nIf you have your dataset defined outside of `tensorflow_datasets`, use\n`--module_import=""path.to.my.dataset_module""` to have your Python module\ncontaining your `DatasetBuilder` definition imported.\n\n\n""""""\n\nimport importlib\nimport os\nimport pdb\nimport time\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets as tfds\nimport termcolor\n\n\nFLAGS = flags.FLAGS\n\nDEFAULT_DATA_DIR = os.path.expanduser(os.path.join(""~"", ""tensorflow_datasets""))\n\nflags.DEFINE_string(""datasets"", """",\n                    ""Comma separated list of datasets to build, defaults to all""\n                    ""registered builders."")\nflags.DEFINE_string(""exclude_datasets"", """",\n                    ""Comma separated list of datasets to exclude,""\n                    ""(no download, no prepare)."")\nflags.DEFINE_multi_string(\n    ""module_import"", None,\n    ""Modules to import. Use this when your DatasetBuilder is defined outside ""\n    ""of tensorflow_datasets so that it is registered. Multiple imports can ""\n    ""be passed by calling the flag multiple times, or using coma separated ""\n    ""values."")\nflags.DEFINE_integer(\n    ""builder_config_id"", None,\n    ""If given 1 dataset with BUILDER_CONFIGS, id of config to build."")\nflags.DEFINE_boolean(\n    ""experimental_latest_version"", False,\n    ""Set to true to builder the latest version available, even if not default."")\n\nflags.DEFINE_string(""data_dir"", DEFAULT_DATA_DIR, ""Where to place the data."")\nflags.DEFINE_string(""download_dir"", None, ""Where to place downloads."")\nflags.DEFINE_string(""extract_dir"", None, ""Where to extract files."")\nflags.DEFINE_string(\n    ""manual_dir"", None,\n    ""Directory where dataset have manually been downloaded / extracted."")\nflags.DEFINE_string(""checksums_dir"", None,\n                    ""For external datasets, specify the location of the ""\n                    ""dataset checksums."")\n\nflags.DEFINE_boolean(\n    ""add_name_to_manual_dir"", False, ""If true, append the dataset name to the ""\n    ""`manual_dir`"")\n\ndefault_compute_stats = tfds.download.ComputeStatsMode.AUTO\nflags.DEFINE_enum(\n    ""compute_stats"",\n    default_compute_stats.value,\n    [e.value for e in tfds.download.ComputeStatsMode],\n    ""Whether to compute or not the dynamic statistics."")\nflags.DEFINE_integer(\n    ""max_examples_per_split"", None,\n    ""optional max number of examples to write into each split (for testing)."")\n\n# Beam flags\nflags.DEFINE_list(\n    ""beam_pipeline_options"", [],\n    ""A (comma-separated) list of flags to pass to `PipelineOptions` when ""\n    ""preparing with Apache Beam. Example: ""\n    ""`--beam_pipeline_options=job_name=my-job,project=my-project`"")\n\n\n# Development flags\nflags.DEFINE_boolean(""register_checksums"", False,\n                     ""If True, store size and checksum of downloaded files."")\nflags.DEFINE_boolean(\n    ""force_checksums_validation"",\n    False, ""If True, raise an error if the checksums are not found."")\n\n# Debug flags\nflags.DEFINE_boolean(""debug"", False,\n                     ""If True, will drop into debugger after data generation"")\nflags.DEFINE_boolean(""debug_start"", False,\n                     ""If True, will drop into debugger on startup"")\nflags.DEFINE_boolean(""sleep_start"", False,\n                     ""If True, will sleep on startup; useful for ssh"")\nflags.DEFINE_boolean(""disable_tqdm"", False, ""If True, disable tqdm."")\n\n\ndef download_config():\n  return tfds.download.DownloadConfig(\n      extract_dir=FLAGS.extract_dir,\n      manual_dir=FLAGS.manual_dir,\n      compute_stats=FLAGS.compute_stats,\n      # TODO(b/116270825): Add flag to force extraction / preparation.\n      download_mode=tfds.download.GenerateMode.REUSE_DATASET_IF_EXISTS,\n      max_examples_per_split=FLAGS.max_examples_per_split,\n      register_checksums=FLAGS.register_checksums,\n      force_checksums_validation=FLAGS.force_checksums_validation,\n  )\n\n\ndef download_and_prepare(builder):\n  """"""Generate data for a given dataset.""""""\n  logging.info(""download_and_prepare for dataset %s..."", builder.info.full_name)\n\n  dl_config = download_config()\n\n  if isinstance(builder, tfds.core.BeamBasedBuilder):\n    beam = tfds.core.lazy_imports.apache_beam\n    # TODO(b/129149715): Restore compute stats. Currently skipped because not\n    # beam supported.\n    dl_config.compute_stats = tfds.download.ComputeStatsMode.SKIP\n    dl_config.beam_options = beam.options.pipeline_options.PipelineOptions(\n        flags=[""--%s"" % opt for opt in FLAGS.beam_pipeline_options])\n\n  if FLAGS.add_name_to_manual_dir:\n    dl_config.manual_dir = os.path.join(dl_config.manual_dir, builder.name)\n\n  builder.download_and_prepare(\n      download_dir=FLAGS.download_dir,\n      download_config=dl_config,\n  )\n  termcolor.cprint(str(builder.info.as_proto), attrs=[""bold""])\n\n  if FLAGS.debug:\n    dataset = builder.as_dataset(split=tfds.Split.TRAIN)\n    pdb.set_trace()\n    del dataset\n\n\ndef import_modules(modules):\n  for module in modules:\n    for m in module.split("",""):  # Allow to pass imports as coma separated vals.\n      importlib.import_module(m)\n\n\ndef main(_):\n  if FLAGS.module_import:\n    import_modules(FLAGS.module_import)\n\n  if FLAGS.debug_start:\n    pdb.set_trace()\n  if FLAGS.sleep_start:\n    time.sleep(60*60*3)\n\n  if FLAGS.disable_tqdm:\n    logging.info(""Disabling tqdm."")\n    tfds.disable_progress_bar()\n\n  if FLAGS.checksums_dir:\n    tfds.download.add_checksums_dir(FLAGS.checksums_dir)\n\n  datasets_to_build = set(FLAGS.datasets and FLAGS.datasets.split("","")\n                          or tfds.list_builders())\n  datasets_to_build -= set(FLAGS.exclude_datasets.split("",""))\n\n  # Only pass the version kwargs when required. Otherwise, `version=None`\n  # overwrite the version parsed from the name.\n  # `tfds.builder(\'my_dataset:1.2.0\', version=None)`\n  if FLAGS.experimental_latest_version:\n    version_kwarg = {""version"": ""experimental_latest""}\n  else:\n    version_kwarg = {}\n\n  logging.info(""Running download_and_prepare for dataset(s):\\n%s"",\n               ""\\n"".join(datasets_to_build))\n  builders = {\n      name: tfds.builder(name, data_dir=FLAGS.data_dir, **version_kwarg)\n      for name in datasets_to_build\n  }\n\n  if FLAGS.builder_config_id is not None:\n    # Requesting a single config of a single dataset\n    if len(builders) > 1:\n      raise ValueError(\n          ""--builder_config_id can only be used when building a single dataset"")\n    builder = builders[list(builders.keys())[0]]\n    if not builder.BUILDER_CONFIGS:\n      raise ValueError(\n          ""--builder_config_id can only be used with datasets with configs"")\n    config = builder.BUILDER_CONFIGS[FLAGS.builder_config_id]\n    logging.info(""Running download_and_prepare for config: %s"", config.name)\n    builder_for_config = tfds.builder(\n        builder.name, data_dir=FLAGS.data_dir, config=config, **version_kwarg)\n    download_and_prepare(builder_for_config)\n  else:\n    for name, builder in builders.items():\n      if builder.BUILDER_CONFIGS and ""/"" not in name:\n        # If builder has multiple configs, and no particular config was\n        # requested, then compute all.\n        for config in builder.BUILDER_CONFIGS:\n          builder_for_config = tfds.builder(\n              builder.name,\n              data_dir=FLAGS.data_dir,\n              config=config,\n              **version_kwarg)\n          download_and_prepare(builder_for_config)\n      else:\n        # If there is a slash in the name, then user requested a specific\n        # dataset configuration.\n        download_and_prepare(builder)\n\n\nif __name__ == ""__main__"":\n  tf.enable_v2_behavior()\n  app.run(main)\n'"
tensorflow_datasets/scripts/freeze_dataset_versions.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Dump the list of all registered datasets/config/version in a `.txt` file.\n\nInstructions:\n\n```\npython tensorflow_datasets/scripts/freeze_dataset_version.py\n```\n\n\n""""""\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets as tfds\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(\'tfds_dir\', tfds.core.utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\n\ndef main(_):\n  version_path = os.path.join(FLAGS.tfds_dir, \'stable_versions.txt\')\n  registered_names = tfds.core.registered.list_full_names()\n  with tf.io.gfile.GFile(version_path, \'w\') as f:\n    f.write(\'\\n\'.join(registered_names))\n  print(f\'{len(registered_names)} datasets versions written.\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/scripts/metadata_cleanup.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Removes metadatas which are not present in the registered versions of TFDS.\n\nInstructions:\n\n```\npython tensorflow_datasets/scripts/metadata_cleanup.py\n```\n\n\n""""""\n\nimport os\nfrom typing import List\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow as tf\n\nimport tensorflow_datasets as tfds\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_boolean(\'dry_run\', True, \'Dry run\')\nflags.DEFINE_string(\'tfds_dir\', tfds.core.utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\n\ndef _extract_metadata_versions(metadata_dir: str) -> List[str]:\n  """"""Get all metadata direcotry versions paths.\n\n  It only extract the paths like \'dataset_name/version\'\n  or \'dataset_name/config/versions\' in metadata dir.\n\n  Args:\n    metadata_dir: Path to metadat directory (testing/metadata).\n\n  Returns:\n    Existing metadata full names.\n  """"""\n  existing_names = []\n  for root, _, _ in tf.io.gfile.walk(metadata_dir):\n    full_name = root[len(metadata_dir) + 1:]\n    if tfds.core.registered.is_full_name(full_name):\n      existing_names.append(full_name)\n  return existing_names\n\n\ndef _delete_metadata_dirs(metadata_dir: str) -> None:\n  """"""Removes metadatas which are not present in the registered versions of TFDS.\n\n  Args:\n    metadata_dir: Path to metadata directory (testing/metadata).\n  """"""\n  registered_names = set(tfds.core.registered.list_full_names())\n  existing_names = set(_extract_metadata_versions(metadata_dir))\n  for extra_full_name in sorted(existing_names - registered_names):\n    path_to_delete = os.path.join(metadata_dir, extra_full_name)\n    print(f\'Delete: {path_to_delete}\')\n    if FLAGS.dry_run:\n      continue\n    tf.io.gfile.rmtree(path_to_delete)\n\n\ndef main(_):\n  """"""Main script.""""""\n  # Delete metadata versions not present in register version.\n  metadata_dir = os.path.join(FLAGS.tfds_dir, \'testing\', \'metadata\')\n  _delete_metadata_dirs(metadata_dir)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/scripts/print_num_configs.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Script that prints number of configs for a dataset.""""""\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow_datasets as tfds\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(""dataset"", None, ""DatasetBuilder to print num configs for"")\n\n\ndef main(_):\n  print(len(tfds.builder(FLAGS.dataset).BUILDER_CONFIGS))\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/scripts/replace_fake_images.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Replace all images in the fake directory by more compressed version.\n\nThis allow to reduce size of the images in the `fake_data/` directory.\n\nInstructions:\n\npython replace_fake_images.py \\\n  --fake_dir=/path/to/tensorflow_datasets/testing/test_data/fake_examples\n\n\n""""""\n\nimport hashlib\nimport os\nimport tarfile\nimport tempfile\nimport zipfile\n\nimport absl.app\nimport absl.flags\nimport numpy as np\nimport PIL.Image\n\n\nFLAGS = absl.flags.FLAGS\n\nabsl.flags.DEFINE_string(\n    \'fake_dir\', None, \'path to the directory which contains files\')\n\n# Some dataset generation rely on the image content, so we cannot compress\n# those.\nSKIP_DATASETS = [\'curated_breast_imaging_ddsm\']\n\n\ndef rewrite_image(filepath):\n  """"""Replace the image by an new one with smaller size (uniform color).\n\n  Args:\n    filepath: path of the images to get processed\n  """"""\n  image_content = PIL.Image.open(filepath)\n  image = np.array(image_content)\n  # Filter unsuported images\n  if image_content.mode == \'RGBA\' or image.dtype == np.bool:\n    return\n\n  # The color is a deterministic function of the relative filepath.\n  assert filepath.startswith(FLAGS.fake_dir)\n  relative_filepath = filepath[len(FLAGS.fake_dir):]\n  color = int(hashlib.md5(relative_filepath.encode(\'utf-8\')).hexdigest(), 16)\n  color %= 255\n\n  image = np.ones_like(image) * color\n  image = PIL.Image.fromarray(image)\n  image.save(filepath, optimize=True)\n\n\ndef rewrite_zip(root_dir, zip_filepath):\n  """"""Rewrite the given .zip file into a new one containing compressed images.\n\n  Args:\n    root_dir: directory path which contain zip compressed file\n    zip_filepath: path from directory to file\n  """"""\n  # Creating a temporary file to store images\n  with tempfile.TemporaryDirectory(dir=root_dir) as temp_dir:\n    # Extraction of compressed .zip file\n    with zipfile.ZipFile(zip_filepath, \'r\') as zip_file:\n      zip_file.extractall(path=temp_dir)\n\n    rewrite_dir(temp_dir)  # Recursivelly compress the archive content\n\n    # Compress the .zip file again\n    with zipfile.ZipFile(\n        zip_filepath,\n        \'w\',\n        compression=zipfile.ZIP_DEFLATED,\n        # TODO(tfds): Python 3.7 Add `compresslevel=zlib.Z_BEST_COMPRESSION,`\n    ) as zip_file:\n      for file_dir, _, files in os.walk(temp_dir):\n        for file in files:\n          file_path = os.path.join(file_dir, file)\n          zip_file.write(file_path,\n                         arcname=os.path.relpath(file_path, temp_dir))\n\n\ndef rewrite_tar(root_dir, tar_filepath):\n  """"""Rewrite the older .tar file into new better compressed one.\n\n  Compression formats supports by this method (.tar.gz, .tgz, .tar.bz2)\n\n  Args:\n    root_dir: directory path which contain tar compressed file\n    tar_filepath: path from directory to file\n\n  """"""\n  # Create a tempfile to store the images contain noise\n  with tempfile.TemporaryDirectory(dir=root_dir, suffix=\'fake\') as temp_dir:\n    # Checking the extension of file to be extract\n    tar_filepath_lowercase = tar_filepath.lower()\n    if tar_filepath_lowercase.endswith(\'gz\'):\n      extension = \':gz\'\n    elif tar_filepath_lowercase.endswith(\'bz2\'):\n      extension = \':bz2\'\n    elif tar_filepath_lowercase.endswith(\'xz\'):\n      extension = \':xz\'\n    else:\n      extension = \'\'\n\n    # Extraction of .tar file\n    with tarfile.open(tar_filepath, \'r\' + extension) as tar:\n      tar.extractall(path=temp_dir)\n\n    rewrite_dir(temp_dir)  # Recursivelly compress the archive content\n\n    # Convert back into tar file\n    with tarfile.open(tar_filepath, \'w\' + extension) as tar:\n      tar.add(temp_dir, arcname=\'\', recursive=True)\n\n\ndef rewrite_dir(fake_dir):\n  """"""Process the whole directory which contains the compressed files.\n\n  Args:\n    fake_dir: path of the directory which contains all compression files\n  """"""\n  img_ext_list = [\'.jpg\', \'.jpeg\', \'.png\']\n\n  for root_dir, _, files in os.walk(fake_dir):\n    if any(skip_ds in root_dir for skip_ds in SKIP_DATASETS):\n      print(f\'Skipping {root_dir}\')\n      continue\n    print(f\'Processing {root_dir}\')\n    for file in files:\n      path = os.path.join(root_dir, file)\n      file_ext = os.path.splitext(file)[-1].lower()\n      if file_ext in img_ext_list:\n        rewrite_image(path)\n      elif file_ext == \'.npz\':  # Filter `.npz` files\n        continue\n      elif zipfile.is_zipfile(path):\n        rewrite_zip(root_dir, path)\n      elif tarfile.is_tarfile(path):\n        rewrite_tar(root_dir, path)\n\n\ndef main(_):\n  """"""Main script.""""""\n  if FLAGS.fake_dir is None:\n    raise ValueError(\'You should specify the path of the `fake_dir`\')\n  rewrite_dir(FLAGS.fake_dir)\n\n\nif __name__ == \'__main__\':\n  absl.app.run(main)\n'"
tensorflow_datasets/structured/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Structured datasets.""""""\n\nfrom tensorflow_datasets.structured.amazon_us_reviews import AmazonUSReviews\nfrom tensorflow_datasets.structured.forest_fires import ForestFires\nfrom tensorflow_datasets.structured.german_credit_numeric import GermanCreditNumeric\nfrom tensorflow_datasets.structured.higgs import Higgs\nfrom tensorflow_datasets.structured.iris import Iris\nfrom tensorflow_datasets.structured.rock_you import RockYou\nfrom tensorflow_datasets.structured.titanic import Titanic\n'"
tensorflow_datasets/structured/amazon_us_reviews.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Amazon Customer Reviews Dataset --- US REVIEWS DATASET.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n""""""\n\n_DESCRIPTION = """"""\\\nAmazon Customer Reviews (a.k.a. Product Reviews) is one of Amazons iconic products. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed over a hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Accordingly, we are releasing this data to further research in multiple disciplines related to understanding customer product experiences. Specifically, this dataset was constructed to represent a sample of customer evaluations and opinions, variation in the perception of a product across geographical regions, and promotional intent or bias in reviews.\n\nOver 130+ million customer reviews are available to researchers as part of this release. The data is available in TSV files in the amazon-reviews-pds S3 bucket in AWS US East Region. Each line in the data files corresponds to an individual review (tab delimited, with no quote and escape characters).\n\nEach Dataset contains the following columns : \n  marketplace       - 2 letter country code of the marketplace where the review was written.\n  customer_id       - Random identifier that can be used to aggregate reviews written by a single author.\n  review_id         - The unique ID of the review.\n  product_id        - The unique Product ID the review pertains to. In the multilingual dataset the reviews\n                      for the same product in different countries can be grouped by the same product_id.\n  product_parent    - Random identifier that can be used to aggregate reviews for the same product.\n  product_title     - Title of the product.\n  product_category  - Broad product category that can be used to group reviews \n                      (also used to group the dataset into coherent parts).\n  star_rating       - The 1-5 star rating of the review.\n  helpful_votes     - Number of helpful votes.\n  total_votes       - Number of total votes the review received.\n  vine              - Review was written as part of the Vine program.\n  verified_purchase - The review is on a verified purchase.\n  review_headline   - The title of the review.\n  review_body       - The review text.\n  review_date       - The date the review was written.\n""""""\n\n_DATA_OPTIONS_V1_00 = [\n    ""Wireless"", ""Watches"", ""Video_Games"", ""Video_DVD"", ""Video"", ""Toys"", ""Tools"",\n    ""Sports"", ""Software"", ""Shoes"", ""Pet_Products"", ""Personal_Care_Appliances"",\n    ""PC"", ""Outdoors"", ""Office_Products"", ""Musical_Instruments"", ""Music"",\n    ""Mobile_Electronics"", ""Mobile_Apps"", ""Major_Appliances"", ""Luggage"",\n    ""Lawn_and_Garden"", ""Kitchen"", ""Jewelry"", ""Home_Improvement"",\n    ""Home_Entertainment"", ""Home"", ""Health_Personal_Care"", ""Grocery"",\n    ""Gift_Card"", ""Furniture"", ""Electronics"", ""Digital_Video_Games"",\n    ""Digital_Video_Download"", ""Digital_Software"", ""Digital_Music_Purchase"",\n    ""Digital_Ebook_Purchase"", ""Camera"", ""Books"", ""Beauty"", ""Baby"", ""Automotive"",\n    ""Apparel""\n]\n\n_DATA_OPTIONS_V1_01 = [""Digital_Ebook_Purchase"", ""Books""]\n\n_DATA_OPTIONS_V1_02 = [""Books""]\n\n_DATA_OPTIONS = []\n\nfor entry in _DATA_OPTIONS_V1_00:\n  _DATA_OPTIONS.append(entry + ""_v1_00"")\n\nfor entry in _DATA_OPTIONS_V1_01:\n  _DATA_OPTIONS.append(entry + ""_v1_01"")\n\nfor entry in _DATA_OPTIONS_V1_02:\n  _DATA_OPTIONS.append(entry + ""_v1_02"")\n\n_DL_URLS = {\n    name: ""https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_"" +\n          name + "".tsv.gz"" for name in _DATA_OPTIONS\n}\n\n\nclass AmazonUSReviewsConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for AmazonUSReviews.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, data=None, **kwargs):\n    """"""Constructs a AmazonUSReviewsConfig.\n\n    Args:\n      data: `str`, one of `_DATA_OPTIONS`.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if data not in _DATA_OPTIONS:\n      raise ValueError(""data must be one of %s"" % _DATA_OPTIONS)\n\n    super(AmazonUSReviewsConfig, self).__init__(**kwargs)\n    self.data = data\n\n\nclass AmazonUSReviews(tfds.core.GeneratorBasedBuilder):\n  """"""AmazonUSReviews dataset.""""""\n\n  BUILDER_CONFIGS = [\n      AmazonUSReviewsConfig(  # pylint: disable=g-complex-comprehension\n          name=config_name,\n          description=""A dataset consisting of reviews of Amazon "" +\n          config_name +\n          "" products in US marketplace. Each product has its own version as specified with it."",\n          version=""0.1.0"",\n          data=config_name,\n      ) for config_name in _DATA_OPTIONS\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""data"":\n                collections.OrderedDict([\n                    (""marketplace"", tf.string), (""customer_id"", tf.string),\n                    (""review_id"", tf.string), (""product_id"", tf.string),\n                    (""product_parent"", tf.string), (""product_title"", tf.string),\n                    (""product_category"", tf.string), (""star_rating"", tf.int32),\n                    (""helpful_votes"", tf.int32), (""total_votes"", tf.int32),\n                    (""vine"", tfds.features.ClassLabel(names=[""Y"", ""N""])),\n                    (""verified_purchase"",\n                     tfds.features.ClassLabel(names=[""Y"", ""N""])),\n                    (""review_headline"", tf.string), (""review_body"", tf.string),\n                    (""review_date"", tf.string)\n                ])\n        }),\n        supervised_keys=None,\n        homepage=""https://s3.amazonaws.com/amazon-reviews-pds/readme.html"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    url = _DL_URLS[self.builder_config.name]\n    path = dl_manager.download_and_extract(url)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=""train"", gen_kwargs={\n                ""file_path"": path,\n            }),\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Generate features given the directory path.\n\n    Args:\n      file_path: path where the tsv file is stored\n\n    Yields:\n      The features.\n    """"""\n\n    with tf.io.gfile.GFile(file_path) as tsvfile:\n      # Need to disable quoting - as dataset contains invalid double quotes.\n      reader = csv.DictReader(\n          tsvfile, dialect=""excel-tab"", quoting=csv.QUOTE_NONE)\n      for i, row in enumerate(reader):\n        yield i, {\n            ""data"": row,\n        }\n'"
tensorflow_datasets/structured/amazon_us_reviews_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for amazon_us_reviews dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import amazon_us_reviews\n\n\nclass AmazonUSReviewsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = amazon_us_reviews.AmazonUSReviews\n  BUILDER_CONFIG_NAMES_TO_TEST = [""Apparel_v1_00""]\n  SPLITS = {\n      ""train"": 5,\n  }\n\n  DL_EXTRACT_RESULT = ""test.tsv""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/forest_fires.py,12,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Forest fires dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = r""""""\n@misc{Dua:2019 ,\nauthor = ""Dua, Dheeru and Graff, Casey"",\nyear = ""2017"",\ntitle = ""{UCI} Machine Learning Repository"",\nurl = ""http://archive.ics.uci.edu/ml"",\ninstitution = ""University of California, Irvine, School of Information and Computer Sciences"" }\n\n@article{cortez2007data,\n  title={A data mining approach to predict forest fires using meteorological data},\n  author={Cortez, Paulo and Morais, Anibal de Jesus Raimundo},\n  year={2007},\n  publisher={Associa{\\c{c}}{\\~a}o Portuguesa para a Intelig{\\^e}ncia Artificial (APPIA)}\n}\n""""""\n\n_DESCRIPTION = """"""\n\nThis is a regression task, where the aim is to predict the burned area of\nforest fires, in the northeast region of Portugal,\nby using meteorological and other data.\n\n\nData Set Information:\n\nIn [Cortez and Morais, 2007], the output \'area\' was first transformed\nwith a ln(x+1) function.\nThen, several Data Mining methods were applied. After fitting the models,\nthe outputs were\npost-processed with the inverse of the ln(x+1) transform. Four different\ninput setups were\nused. The experiments were conducted using a 10-fold (cross-validation)\nx 30 runs. Two\nregression metrics were measured: MAD and RMSE. A Gaussian support vector\nmachine (SVM) fed\nwith only 4 direct weather conditions (temp, RH, wind and rain) obtained\nthe best MAD value:\n12.71 +- 0.01 (mean and confidence interval within 95% using a t-student\ndistribution). The\nbest RMSE was attained by the naive mean predictor. An analysis to the\nregression error curve\n(REC) shows that the SVM model predicts more examples within a lower\nadmitted error. In effect,\nthe SVM model predicts better small fires, which are the majority.\n\nAttribute Information:\n\nFor more information, read [Cortez and Morais, 2007].\n\n1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n3. month - month of the year: \'jan\' to \'dec\'\n4. day - day of the week: \'mon\' to \'sun\'\n5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n6. DMC - DMC index from the FWI system: 1.1 to 291.3\n7. DC - DC index from the FWI system: 7.9 to 860.6\n8. ISI - ISI index from the FWI system: 0.0 to 56.10\n9. temp - temperature in Celsius degrees: 2.2 to 33.30\n10. RH - relative humidity in %: 15.0 to 100\n11. wind - wind speed in km/h: 0.40 to 9.40\n12. rain - outside rain in mm/m2 : 0.0 to 6.4\n13. area - the burned area of the forest (in ha): 0.00 to 1090.84\n(this output variable is very skewed towards 0.0, thus it may make\nsense to model with the logarithm transform).\n\n""""""\n\n_MONTHS = [\n    \'jan\', \'feb\', \'mar\', \'apr\', \'may\', \'jun\', \'jul\', \'aug\', \'sep\', \'oct\', \'nov\',\n    \'dec\'\n]\n\n_DAYS = [\'mon\', \'tue\', \'wed\', \'thu\', \'fri\', \'sat\', \'sun\']\n\n_URL = \'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv\'\n\nFEATURES = collections.OrderedDict([\n    (\'X\', tf.uint8),\n    (\'Y\', tf.uint8),\n    (\'month\', tfds.features.ClassLabel(names=_MONTHS)),\n    (\'day\', tfds.features.ClassLabel(names=_DAYS)),\n    (\'FFMC\', tf.float32),\n    (\'DMC\', tf.float32),\n    (\'DC\', tf.float32),\n    (\'ISI\', tf.float32),\n    (\'temp\', tf.float32),\n    (\'RH\', tf.float32),\n    (\'wind\', tf.float32),\n    (\'rain\', tf.float32),\n])\n\n\nclass ForestFires(tfds.core.GeneratorBasedBuilder):\n  """"""Regression task aimed to predict the burned area of forest fires.""""""\n\n  VERSION = tfds.core.Version(\'0.0.1\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'area\': tf.float32,\n            \'features\': {name: dtype for name, dtype in FEATURES.items()}\n        }),\n        supervised_keys=(\'area\', \'features\'),\n        homepage=\'https://archive.ics.uci.edu/ml/datasets/Forest+Fires\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    data = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'file_path\': data},\n        ),\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(file_path) as f:\n      raw_data = csv.DictReader(f)\n      for i, row in enumerate(raw_data):\n        yield i, {\n            \'area\': row.pop(\'area\'),\n            \'features\': {name: value for name, value in row.items()},\n        }\n'"
tensorflow_datasets/structured/forest_fires_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Forest Fires dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import forest_fires\n\n\nclass ForestFiresTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = forest_fires.ForestFires\n  SPLITS = {\n      ""train"": 1,\n  }\n\n  DL_EXTRACT_RESULT = ""forestfires.csv""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/german_credit_numeric.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""German Credit (numeric) dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nURL = ""https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric""\n\n_CITATION = """"""\\\n@misc{Dua:2019 ,\nauthor = ""Dua, Dheeru and Graff, Casey"",\nyear = ""2017"",\ntitle = ""{UCI} Machine Learning Repository"",\nurl = ""http://archive.ics.uci.edu/ml"",\ninstitution = ""University of California, Irvine, School of Information and Computer Sciences""\n}\n""""""\n\n_DESCRIPTION = """"""\nThis dataset classifies people described by a set of attributes as good or bad\ncredit risks. The version here is the ""numeric"" variant where categorical and\nordered categorical attributes have been encoded as indicator and integer\nquantities respectively.\n""""""\n\n\nclass GermanCreditNumeric(tfds.core.GeneratorBasedBuilder):\n  """"""German Credit (numeric) dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""features"":\n                tfds.features.Tensor(shape=(24,), dtype=tf.int32),\n            ""label"":\n                tfds.features.ClassLabel(names=[""Bad"", ""Good""]),\n        }),\n        supervised_keys=(""features"", ""label""),\n        homepage=""https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    data_file = dl_manager.download(URL)\n    with tf.io.gfile.GFile(data_file) as f:\n      all_lines = f.read().split(""\\n"")\n    records = [l for l in all_lines if l]  # get rid of empty lines\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""records"": records}),\n    ]\n\n  def _generate_examples(self, records):\n    """"""Yields examples.""""""\n    for i, row in enumerate(records):\n      elems = row.split()\n      yield i, {\n          ""features"": [int(e) for e in elems[:-1]],\n          ""label"": 2 - int(elems[-1]),\n      }\n'"
tensorflow_datasets/structured/german_credit_numeric_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""German Credit (numeric) tests.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import german_credit_numeric\n\n\nclass GermanCreditNumericTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = german_credit_numeric.GermanCreditNumeric\n\n  SPLITS = {\n      ""train"": 3,\n  }\n  DL_EXTRACT_RESULT = ""german.data-numeric""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/higgs.py,30,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""HIGGS Data Set.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n# From https://arxiv.org/abs/1402.4735\n_CITATION = """"""\\\n@article{Baldi:2014kfa,\n      author         = ""Baldi, Pierre and Sadowski, Peter and Whiteson, Daniel"",\n      title          = ""{Searching for Exotic Particles in High-Energy Physics\n                        with Deep Learning}"",\n      journal        = ""Nature Commun."",\n      volume         = ""5"",\n      year           = ""2014"",\n      pages          = ""4308"",\n      doi            = ""10.1038/ncomms5308"",\n      eprint         = ""1402.4735"",\n      archivePrefix  = ""arXiv"",\n      primaryClass   = ""hep-ph"",\n      SLACcitation   = ""%%CITATION = ARXIV:1402.4735;%%""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe data has been produced using Monte Carlo simulations. \nThe first 21 features (columns 2-22) are kinematic properties \nmeasured by the particle detectors in the accelerator. \nThe last seven features are functions of the first 21 features; \nthese are high-level features derived by physicists to help \ndiscriminate between the two classes. There is an interest \nin using deep learning methods to obviate the need for physicists \nto manually develop such features. Benchmark results using \nBayesian Decision Trees from a standard physics package and \n5-layer neural networks are presented in the original paper. \n""""""\n\n_URL = \'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\'\n\n\nclass Higgs(tfds.core.GeneratorBasedBuilder):\n  """"""HIGGS Data Set.""""""\n  VERSION = tfds.core.Version(\n      \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'class_label\': tf.float32,  # 1 for signal, 0 for background\n            # 21 low-level features\n            \'lepton_pT\': tf.float64,\n            \'lepton_eta\': tf.float64,\n            \'lepton_phi\': tf.float64,\n            \'missing_energy_magnitude\': tf.float64,\n            \'missing_energy_phi\': tf.float64,\n            \'jet_1_pt\': tf.float64,\n            \'jet_1_eta\': tf.float64,\n            \'jet_1_phi\': tf.float64,\n            \'jet_1_b-tag\': tf.float64,\n            \'jet_2_pt\': tf.float64,\n            \'jet_2_eta\': tf.float64,\n            \'jet_2_phi\': tf.float64,\n            \'jet_2_b-tag\': tf.float64,\n            \'jet_3_pt\': tf.float64,\n            \'jet_3_eta\': tf.float64,\n            \'jet_3_phi\': tf.float64,\n            \'jet_3_b-tag\': tf.float64,\n            \'jet_4_pt\': tf.float64,\n            \'jet_4_eta\': tf.float64,\n            \'jet_4_phi\': tf.float64,\n            \'jet_4_b-tag\': tf.float64,\n            # 7 high-level features\n            \'m_jj\': tf.float64,\n            \'m_jjj\': tf.float64,\n            \'m_lv\': tf.float64,\n            \'m_jlv\': tf.float64,\n            \'m_bb\': tf.float64,\n            \'m_wbb\': tf.float64,\n            \'m_wwbb\': tf.float64\n        }),\n        supervised_keys=None,\n        homepage=\'https://archive.ics.uci.edu/ml/datasets/HIGGS\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n\n    path = dl_manager.download_and_extract(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'file_path\': path,\n            }),\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Generate features given the directory path.\n\n    Args:\n      file_path: path where the csv file is stored\n\n    Yields:\n      The features, per row.\n    """"""\n\n    fieldnames = [\n        \'class_label\', \'lepton_pT\', \'lepton_eta\', \'lepton_phi\',\n        \'missing_energy_magnitude\', \'missing_energy_phi\', \'jet_1_pt\',\n        \'jet_1_eta\', \'jet_1_phi\', \'jet_1_b-tag\', \'jet_2_pt\', \'jet_2_eta\',\n        \'jet_2_phi\', \'jet_2_b-tag\', \'jet_3_pt\', \'jet_3_eta\', \'jet_3_phi\',\n        \'jet_3_b-tag\', \'jet_4_pt\', \'jet_4_eta\', \'jet_4_phi\', \'jet_4_b-tag\',\n        \'m_jj\', \'m_jjj\', \'m_lv\', \'m_jlv\', \'m_bb\', \'m_wbb\', \'m_wwbb\'\n    ]\n\n    with tf.io.gfile.GFile(file_path) as csvfile:\n      reader = csv.DictReader(csvfile, fieldnames=fieldnames)\n      for i, row in enumerate(reader):\n        yield i, row\n'"
tensorflow_datasets/structured/higgs_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for HIGGS dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import higgs\n\n\nclass HiggsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = higgs.Higgs\n  SPLITS = {\n      ""train"": 11,\n  }\n\n  DL_EXTRACT_RESULT = ""test.csv""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/iris.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Iris dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nIRIS_URL = ""https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data""\n\n_CITATION = """"""\\\n@misc{Dua:2019 ,\nauthor = ""Dua, Dheeru and Graff, Casey"",\nyear = ""2017"",\ntitle = ""{UCI} Machine Learning Repository"",\nurl = ""http://archive.ics.uci.edu/ml"",\ninstitution = ""University of California, Irvine, School of Information and Computer Sciences""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThis is perhaps the best known database to be found in the pattern recognition\nliterature. Fisher\'s paper is a classic in the field and is referenced\nfrequently to this day. (See Duda & Hart, for example.) The data set contains\n3 classes of 50 instances each, where each class refers to a type of iris\nplant. One class is linearly separable from the other 2; the latter are NOT\nlinearly separable from each other.\n""""""\n\n\nclass Iris(tfds.core.GeneratorBasedBuilder):\n  """"""Iris flower dataset.""""""\n  NUM_CLASSES = 3\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            ""features"":\n                tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n            # Here, labels can be one of 3 classes\n            ""label"":\n                tfds.features.ClassLabel(\n                    names=[""Iris-setosa"", ""Iris-versicolor"", ""Iris-virginica""]),\n        }),\n        supervised_keys=(""features"", ""label""),\n        homepage=""https://archive.ics.uci.edu/ml/datasets/iris"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    iris_file = dl_manager.download(IRIS_URL)\n    all_lines = tf.io.gfile.GFile(iris_file).read().splitlines()\n    records = [l for l in all_lines if l]  # get rid of empty lines\n\n    # Specify the splits\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""records"": records}),\n    ]\n\n  def _generate_examples(self, records):\n    for i, row in enumerate(records):\n      elems = row.split("","")\n      yield i, {\n          ""features"": [float(e) for e in elems[:-1]],\n          ""label"": elems[-1],\n      }\n'"
tensorflow_datasets/structured/iris_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.structured.iris.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import iris\n\n\nclass IrisTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = iris.Iris\n\n  SPLITS = {\n      ""train"": 15,\n  }\n  DL_EXTRACT_RESULT = ""iris.data""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/rock_you.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The rockyou dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n""""""\n\n_DESCRIPTION = """"""\\\nThis dataset contains 14,344,391 passwords that were leaked or stolen from from various sites. The author of this dataset states that ""I\'m hosting them because it seems like nobody else does (hopefully it isn\'t because hosting them is illegal :)). Naturally, I\'m not the one who stole these; I simply found them online, removed any names/email addresses/etc."". This dataset is used to train Machine Learning models for password guessing and cracking.\n""""""\n\n_DOWNLOAD_URL = ""https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt""\n\n\nclass RockYou(tfds.core.GeneratorBasedBuilder):\n  """"""This dataset contains passwords that were leaked or stolen from from various sites.""""""\n\n  VERSION = tfds.core.Version(""0.1.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""password"":\n                tfds.features.Text(encoder=tfds.features.text.ByteTextEncoder()\n                                  ),\n        }),\n        supervised_keys=None,\n        homepage=""https://wiki.skullsecurity.org/Passwords"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_path = dl_manager.download(_DOWNLOAD_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=""train"",\n            gen_kwargs={\n                ""path"": dl_path,\n            },\n        )\n    ]\n\n  def _generate_examples(self, path):\n\n    with tf.io.gfile.GFile(path, ""rb"") as f:\n      blines = f.readlines()\n\n    for i, bline in enumerate(blines):\n      yield i, {\n          ""password"": bline.strip(),\n      }\n'"
tensorflow_datasets/structured/rock_you_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for rockyou dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.structured import rock_you\n\n\nclass RockYouTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = rock_you.RockYou\n\n  SPLITS = {\n      ""train"": 11,\n  }\n\n  DL_EXTRACT_RESULT = ""rockyou.txt""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/structured/titanic.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Titanic dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@ONLINE {titanic,\nauthor = ""Frank E. Harrell Jr., Thomas Cason"",\ntitle  = ""Titanic dataset"",\nmonth  = ""oct"",\nyear   = ""2017"",\nurl    = ""https://www.openml.org/d/40945""\n}\n""""""\n\n_DESCRIPTION = (""Dataset describing the survival status of ""\n                ""individual passengers on the Titanic. Missing values in ""\n                ""the original dataset are represented using ?. ""\n                ""Float and int missing values are replaced with -1, string ""\n                ""missing values are replaced with \'Unknown\'."")\n\n_EMBARKED_DICT = collections.OrderedDict([\n    (""C"", ""Cherbourg""), (""Q"", ""Queenstown""), (""S"", ""Southampton""),\n    (""?"", ""Unknown"")\n])\n\n_PCLASS_DICT = collections.OrderedDict([\n    (""1"", ""1st_class""), (""2"", ""2nd_class""), (""3"", ""3rd_class"")\n])\n\n_SURVIVED_DICT = {""1"": ""survived"", ""0"": ""died""}\n\n\ndef convert_to_float(d):\n  return -1.0 if d == ""?"" else np.float32(d)\n\n\ndef convert_to_int(d):\n  return -1 if d == ""?"" else np.int32(d)\n\n\ndef convert_to_string(d):\n  return ""Unknown"" if d == ""?"" else d\n\n\ndef convert_to_label(d, dictionary):\n  return dictionary[d]\n\n\ndef return_same(d):\n  return d\n\n\nFEATURE_DICT = collections.OrderedDict([\n    (""pclass"", (tfds.features.ClassLabel(names=_PCLASS_DICT.values()),\n                lambda d: convert_to_label(d, _PCLASS_DICT))),\n    (""name"", (tf.string, convert_to_string)),\n    (""sex"", (tfds.features.ClassLabel(names=[""male"", ""female""]), return_same)),\n    (""age"", (tf.float32, convert_to_float)),\n    (""sibsp"", (tf.int32, convert_to_int)),\n    (""parch"", (tf.int32, convert_to_int)),\n    (""ticket"", (tf.string, convert_to_string)),\n    (""fare"", (tf.float32, convert_to_float)),\n    (""cabin"", (tf.string, convert_to_string)),\n    (""embarked"", (tfds.features.ClassLabel(names=_EMBARKED_DICT.values()),\n                  lambda d: convert_to_label(d, _EMBARKED_DICT))),\n    (""boat"", (tf.string, convert_to_string)),\n    (""body"", (tf.int32, convert_to_int)),\n    (""home.dest"", (tf.string, convert_to_string))\n])\n\n_URL = ""https://www.openml.org/data/get_csv/16826755/phpMYEkMl""\n\n\nclass Titanic(tfds.core.GeneratorBasedBuilder):\n  """"""Titanic dataset.""""""\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""survived"": tfds.features.ClassLabel(names=[""died"", ""survived""]),\n            ""features"": {name: dtype\n                         for name, (dtype, func) in FEATURE_DICT.items()}\n        }),\n        supervised_keys=(""features"", ""survived""),\n        homepage=""https://www.openml.org/d/40945"",\n        citation=_CITATION\n        )\n\n  def _split_generators(self, dl_manager):\n    path = dl_manager.download(_URL)\n\n    # There is no predefined train/val/test split for this dataset.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""file_path"": path\n            }),\n    ]\n\n  def _generate_examples(self, file_path):\n    """"""Generate features and target given the directory path.\n\n    Args:\n      file_path: path where the csv file is stored\n\n    Yields:\n      The features and the target\n    """"""\n\n    with tf.io.gfile.GFile(file_path) as f:\n      raw_data = csv.DictReader(f)\n      for i, row in enumerate(raw_data):\n        survive_val = row.pop(""survived"")\n        yield i, {\n            ""survived"": convert_to_label(survive_val, _SURVIVED_DICT),\n            ""features"": {\n                name: FEATURE_DICT[name][1](value)\n                for name, value in row.items()\n            }\n        }\n'"
tensorflow_datasets/structured/titanic_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for titanic data loading.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets.structured import titanic\nimport tensorflow_datasets.testing as tfds_test\n\n\nclass TitanicTest(tfds_test.DatasetBuilderTestCase):\n  DATASET_CLASS = titanic.Titanic\n\n  SPLITS = {\n      \'train\': 5\n  }\n\n  DL_EXTRACT_RESULT = \'test.csv\'\n\n\nif __name__ == \'__main__\':\n  tfds_test.test_main()\n'"
tensorflow_datasets/summarization/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Text datasets.""""""\n\nfrom tensorflow_datasets.summarization.aeslc import Aeslc\nfrom tensorflow_datasets.summarization.big_patent import BigPatent\nfrom tensorflow_datasets.summarization.billsum import Billsum\nfrom tensorflow_datasets.summarization.cnn_dailymail import CnnDailymail\nfrom tensorflow_datasets.summarization.cnn_dailymail import CnnDailymailConfig\nfrom tensorflow_datasets.summarization.covid19sum import Covid19sum\nfrom tensorflow_datasets.summarization.gigaword import Gigaword\nfrom tensorflow_datasets.summarization.multi_news import MultiNews\nfrom tensorflow_datasets.summarization.newsroom import Newsroom\nfrom tensorflow_datasets.summarization.opinion_abstracts import OpinionAbstracts\nfrom tensorflow_datasets.summarization.opinosis import Opinosis\nfrom tensorflow_datasets.summarization.reddit import Reddit\nfrom tensorflow_datasets.summarization.reddit_tifu import RedditTifu\nfrom tensorflow_datasets.summarization.samsum import Samsum\nfrom tensorflow_datasets.summarization.scientific_papers import ScientificPapers\nfrom tensorflow_datasets.summarization.wikihow import Wikihow\nfrom tensorflow_datasets.summarization.xsum import Xsum\n'"
tensorflow_datasets/summarization/aeslc.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Annotated Enron Subject Line Corpus Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{zhang2019email,\n    title={This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation},\n    author={Rui Zhang and Joel Tetreault},\n    year={2019},\n    eprint={1906.03497},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nA collection of email messages of employees in the Enron Corporation.\n\nThere are two features:\n  - email_body: email body text.\n  - subject_line: email subject text.\n""""""\n\n_URL = ""https://github.com/ryanzhumich/AESLC/archive/master.zip""\n\n_DOCUMENT = ""email_body""\n_SUMMARY = ""subject_line""\n\n\nclass Aeslc(tfds.core.GeneratorBasedBuilder):\n  """"""Annotated Enron Subject Line Corpus Dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text()\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/ryanzhumich/AESLC"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(tfds.download.Resource(\n        url=_URL,\n        extract_method=tfds.download.ExtractMethod.ZIP))\n    input_path = os.path.join(dl_path, ""AESLC-master"", ""enron_subject_line"")\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""pattern"": os.path.join(input_path, ""train"", ""*.subject"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""pattern"": os.path.join(input_path, ""dev"", ""*.subject"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""pattern"": os.path.join(input_path, ""test"", ""*.subject"")\n            },\n        ),\n    ]\n\n  def _generate_examples(self, pattern=None):\n    """"""Yields examples.""""""\n    for filename in tf.io.gfile.glob(pattern):\n      email_body, subject_line = _parse_email_file(filename)\n      key = os.path.basename(filename).rstrip("".subject"")\n      yield key, {_DOCUMENT: email_body, _SUMMARY: subject_line}\n\n\ndef _parse_email_file(filename):\n  """"""Parse email file text for email body and subject.""""""\n  with tf.io.gfile.GFile(filename) as f:\n    email_body = """"\n    for line in f:\n      if line == ""\\n"":\n        break\n      email_body += line\n    line = next(f)\n    subject = """"\n    for line in f:\n      if line == ""\\n"":\n        break\n      subject += line\n  return email_body, subject\n'"
tensorflow_datasets/summarization/aeslc_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Annotated Enron Subject Line Corpus Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import aeslc\n\n\nclass AeslcTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = aeslc.Aeslc\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/big_patent.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BIGPATENT Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport re\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{sharma2019bigpatent,\n    title={BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization},\n    author={Eva Sharma and Chen Li and Lu Wang},\n    year={2019},\n    eprint={1906.03741},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents\nalong with human written abstractive summaries.\nEach US patent application is filed under a Cooperative Patent Classification\n(CPC) code. There are nine such classification categories:\nA (Human Necessities), B (Performing Operations; Transporting),\nC (Chemistry; Metallurgy), D (Textiles; Paper), E (Fixed Constructions),\nF (Mechanical Engineering; Lightning; Heating; Weapons; Blasting),\nG (Physics), H (Electricity), and\nY (General tagging of new or cross-sectional technology)\n\nThere are two features:\n  - description: detailed description of patent.\n  - summary: Patent abastract.\n\n""""""\n\n# Raw data provided by Eva Sharma (evasharma@ccs.neu.edu).\n_URL = ""https://drive.google.com/uc?export=download&id=1mwH7eSh1kNci31xduR4Da_XcmTE8B8C3""\n\n_DOCUMENT = ""description""\n_SUMMARY = ""abstract""\n\n_CPC_DESCRIPTION = {\n    ""a"": ""Human Necessities"",\n    ""b"": ""Performing Operations; Transporting"",\n    ""c"": ""Chemistry; Metallurgy"",\n    ""d"": ""Textiles; Paper"",\n    ""e"": ""Fixed Constructions"",\n    ""f"": ""Mechanical Engineering; Lightning; Heating; Weapons; Blasting"",\n    ""g"": ""Physics"",\n    ""h"": ""Electricity"",\n    ""y"": ""General tagging of new or cross-sectional technology""\n}\n\n\nclass BigPatentConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for BigPatent.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, cpc_codes=None, **kwargs):\n    """"""BuilderConfig for Wikihow.\n\n    Args:\n      cpc_codes: str, cpc_codes\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(BigPatentConfig, self).__init__(\n        # 1.0.0 lower cased tokenized words.\n        # 2.0.0 cased raw strings.\n        version=tfds.core.Version(""2.0.0"", ""Updated to cased raw strings.""),\n        supported_versions=[tfds.core.Version(""1.0.0"")],\n        **kwargs)\n    self.cpc_codes = cpc_codes\n\n\nclass BigPatent(tfds.core.BeamBasedBuilder):\n  """"""BigPatent datasets.""""""\n\n  BUILDER_CONFIGS = [\n      BigPatentConfig(\n          cpc_codes=""*"",\n          name=""all"",\n          description=""Patents under all categories.""),\n  ] + [\n      BigPatentConfig(  # pylint:disable=g-complex-comprehension\n          cpc_codes=k,\n          name=k,\n          description=(""Patents under Cooperative Patent Classification (CPC)""\n                       ""{0}: {1}"".format(k, v)),\n      ) for k, v in sorted(_CPC_DESCRIPTION.items())\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text()\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://evasharma.github.io/bigpatent/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    split_types = [""train"", ""val"", ""test""]\n    extract_paths = dl_manager.extract({\n        k: os.path.join(dl_path, ""bigPatentDataNonTokenized"", k + "".tar.gz"")\n        for k in split_types\n    })\n    extract_paths = {k: os.path.join(extract_paths[k], k) for k in split_types}\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": extract_paths[""train""]},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""path"": extract_paths[""val""]},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""path"": extract_paths[""test""]},\n        ),\n    ]\n\n  def _build_pcollection(self, pipeline, path=None):\n    """"""Build PCollection of examples.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _process_example(row):\n      json_obj = json.loads(row)\n      yield json_obj[""publication_number""], {\n          _DOCUMENT: _bigpatent_clean_description(json_obj[_DOCUMENT]),\n          _SUMMARY: _bigpatent_clean_abstract(json_obj[_SUMMARY])\n      }\n\n    file_pattern = os.path.join(path, self.builder_config.cpc_codes, ""*"")\n    return (pipeline\n            | ""ReadTextIO"" >> beam.io.textio.ReadFromText(file_pattern)\n            | beam.FlatMap(_process_example))\n\n\n# The preprocessing functions below are kindly provided by\n#   Eva Sharma (evasharma@ccs.neu.edu).\n#   They are modified in a few ways:\n#    1) minor code formating changes, add prefix _bigpatent to those functions.\n#    2) enchant is replaced with nltk to detect english words.\n#    3) remove excessive white space.\n\n# Regex for cleaning the abstract and description fields of unwanted text\n# spans.\n\n_FIG_EXP1 = re.compile(r""(FIG.)\\s+(\\d)(,*)\\s*(\\d*)"")\n_FIG_EXP2 = re.compile(r""(FIGS.)\\s+(\\d)(,*)\\s*(\\d*)"")\n_FIG_EXP3 = re.compile(r""(FIGURE)\\s+(\\d)(,*)\\s*(\\d*)"")\n\n_LINE_NUM_EXP = re.compile(r""\\[(\\d+)\\]"")\n_NON_EMPTY_LINES = re.compile(r""^\\s*\\[(\\d+)\\]"")\n_TABLE_HEADER = re.compile(r""^(\\s*)TABLE\\s+\\d+(\\s+(.*))?$"")\n\n_ENGLISH_WORDS = None\n\n\ndef _get_english_words():\n  global _ENGLISH_WORDS\n  if not _ENGLISH_WORDS:\n    _ENGLISH_WORDS = frozenset(tfds.core.lazy_imports.nltk.corpus.words.words())\n  return _ENGLISH_WORDS\n\n\ndef _remove_excessive_whitespace(text):\n  return "" "".join([w for w in text.split("" "") if w])\n\n\ndef _bigpatent_clean_abstract(text):\n  """"""Cleans the abstract text.""""""\n  text = re.sub(r""[\\(\\{\\[].*?[\\}\\)\\]]"", """", text).strip()\n  text = _remove_excessive_whitespace(text)\n  return text\n\n\ndef _bigpatent_remove_referenecs(text):\n  """"""Remove references from description text.""""""\n  text = _FIG_EXP1.sub(r""FIG\\2 "", text)\n  text = _FIG_EXP2.sub(r""FIG\\2 "", text)\n  text = _FIG_EXP3.sub(r""FIG\\2 "", text)\n  return text\n\n\ndef _bigpatent_get_list_of_non_empty_lines(text):\n  """"""Remove non-empty lines.""""""\n  # Split into lines\n  # Remove empty lines\n  # Remove line numbers\n  return [\n      _NON_EMPTY_LINES.sub("""", s).strip()\n      for s in text.strip().splitlines(True)\n      if s.strip()\n  ]\n\n\ndef _bigpatent_remove_tables(sentences):\n  """"""Remove Tables from description text.""""""\n  # Remove tables from text\n  new_sentences = []\n  i = 0\n  table_start = 0\n  # A table header will be a line starting with ""TABLE"" after zero or more\n  # whitespaces, followed by an integer.\n  # After the integer, the line ends, or is followed by whitespace and\n  # description.\n  while i < len(sentences):\n    sentence = sentences[i]\n    if table_start == 0:\n      # Not inside a table\n      # Check if it\'s start of a table\n      if _TABLE_HEADER.match(sentence):\n        table_start = 1\n      else:\n        new_sentences.append(sentence)\n\n    elif table_start == 1:\n      words = sentence.strip(""\\t"").split("" "")\n      num_eng = 0\n      for w in words:\n        if not w.isalpha():\n          continue\n        if w in _get_english_words():\n          num_eng += 1\n          if num_eng > 20:\n            # Table end condition\n            table_start = 0\n            new_sentences.append(sentence)\n            break\n    i += 1\n  return new_sentences\n\n\ndef _bigpatent_remove_lines_with_less_words(sentences):\n  """"""Remove sentences with less than 10 words.""""""\n  new_sentences = []\n  for sentence in sentences:\n    words = set(sentence.split("" ""))\n    if len(words) > 10:\n      new_sentences.append(sentence)\n  return new_sentences\n\n\ndef _bigpatent_clean_description(text):\n  """"""Clean the description text.""""""\n  # split the text by newlines, keep only non-empty lines\n  sentences = _bigpatent_get_list_of_non_empty_lines(text)\n  # remove tables from the description text\n  sentences = _bigpatent_remove_tables(sentences)\n  # remove sentences with less than 10 words\n  sentences = _bigpatent_remove_lines_with_less_words(sentences)\n  text = ""\\n"".join(sentences)\n  # remove references like FIG. 8, FIGS. 8, 8, FIG. 8-d\n  text = _bigpatent_remove_referenecs(text)\n  # remove excessive whitespace\n  text = _remove_excessive_whitespace(text)\n  return text\n'"
tensorflow_datasets/summarization/big_patent_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for BigPatent dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import big_patent\n\n\nclass BigPatentTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = big_patent.BigPatent\n  BUILDER_CONFIG_NAMES_TO_TEST = [""all""]\n  SPLITS = {\n      ""train"": 9,  # Number of fake train example\n      ""validation"": 9,  # Number of fake val example\n      ""test"": 9,  # Number of fake test example\n  }\n\n\nclass BigPatentATest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = big_patent.BigPatent\n  BUILDER_CONFIG_NAMES_TO_TEST = [""a"", ""y""]\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake val example\n      ""test"": 1,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/billsum.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BillSum Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{kornilova2019billsum,\n    title={BillSum: A Corpus for Automatic Summarization of US Legislation},\n    author={Anastassia Kornilova and Vlad Eidelman},\n    year={2019},\n    eprint={1910.00523},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nBillSum, summarization of US Congressional and California state bills.\n\nThere are several features:\n  - text: bill text.\n  - summary: summary of the bills.\n  - title: title of the bills.\nfeatures for us bills. ca bills does not have.\n  - text_len: number of chars in text.\n  - sum_len: number of chars in summary.\n""""""\n\n_URL = ""https://drive.google.com/uc?export=download&id=1g89WgFHMRbr4QrvA0ngh26PY081Nv3lx""\n\n_DOCUMENT = ""text""\n_SUMMARY = ""summary""\n\n\nclass Billsum(tfds.core.GeneratorBasedBuilder):\n  """"""BillSum Dataset.""""""\n\n  # 2.0.0 data source updated to filter near duplicates.\n  # 3.0.0  none of the test examples are \'near duplicates\' of an example in the\n  #   train set AND they dont have the same title, regardless of similarity.\n  VERSION = tfds.core.Version(""3.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text(),\n            ""title"": tfds.features.Text(),\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/FiscalNote/BillSum"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_path, ""us_train_data_final_OFFICIAL.jsonl""),\n                ""key"":\n                    ""bill_id""\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_path, ""us_test_data_final_OFFICIAL.jsonl""),\n                ""key"":\n                    ""bill_id""\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=""ca_test"",\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_path, ""ca_test_data_final_OFFICIAL.jsonl""),\n                ""key"":\n                    ""external_id""\n            },\n        ),\n    ]\n\n  def _generate_examples(self, path=None, key=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path) as f:\n      for line in f:\n        # in us bills, json has fields:\n        #   text, summary, title, bill_id, text_len, sum_len\n        # in ca bills, json has fields:\n        #   text, summary, title, external_id\n        d = json.loads(line)\n        yield d[key], {k: d[k] for k in [_DOCUMENT, _SUMMARY, ""title""]}\n'"
tensorflow_datasets/summarization/billsum_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BillSum Dataset Test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import billsum\n\n\nclass BillsumTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = billsum.Billsum\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n      ""ca_test"": 1  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = """"\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/cnn_dailymail.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CNN/DailyMail Summarization dataset, non-anonymized version.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport hashlib\nimport os\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nCNN/DailyMail non-anonymized summarization dataset.\n\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary\n""""""\n\n# The second citation introduces the source data, while the first\n# introduces the specific form (non-anonymized) we use here.\n_CITATION = """"""\\\n@article{DBLP:journals/corr/SeeLM17,\n  author    = {Abigail See and\n               Peter J. Liu and\n               Christopher D. Manning},\n  title     = {Get To The Point: Summarization with Pointer-Generator Networks},\n  journal   = {CoRR},\n  volume    = {abs/1704.04368},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.04368},\n  archivePrefix = {arXiv},\n  eprint    = {1704.04368},\n  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{hermann2015teaching,\n  title={Teaching machines to read and comprehend},\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n  booktitle={Advances in neural information processing systems},\n  pages={1693--1701},\n  year={2015}\n}\n""""""\n\n_DL_URLS = {\n    # pylint: disable=line-too-long\n    \'cnn_stories\':\n        \'https://drive.google.com/uc?export=download&id=0BwmD_VLjROrfTHk4NFg2SndKcjQ\',\n    \'dm_stories\':\n        \'https://drive.google.com/uc?export=download&id=0BwmD_VLjROrfM1BxdkxVaTY2bWs\',\n    \'test_urls\':\n        \'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_test.txt\',\n    \'train_urls\':\n        \'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_train.txt\',\n    \'val_urls\':\n        \'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_val.txt\',\n    # pylint: enable=line-too-long\n}\n\n_HIGHLIGHTS = \'highlights\'\n_ARTICLE = \'article\'\n_SUPPORTED_VERSIONS = [\n    # Same data as 0.0.2\n    tfds.core.Version(\'1.0.0\',\n                      \'New split API (https://tensorflow.org/datasets/splits)\'),\n    # Having the model predict newline separators makes it easier to evaluate\n    # using summary-level ROUGE.\n    tfds.core.Version(\'2.0.0\', \'Separate target sentences with newline.\')\n]\n\n# Using cased version.\n_DEFAULT_VERSION = tfds.core.Version(\'3.0.0\', \'Using cased version.\')\n\n\nclass CnnDailymailConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CnnDailymail.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for CnnDailymail.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the CnnDailymail\n        (text) features\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(CnnDailymailConfig, self).__init__(\n        version=_DEFAULT_VERSION,\n        supported_versions=_SUPPORTED_VERSIONS,\n        **kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\ndef _get_url_hashes(path):\n  """"""Get hashes of urls in file.""""""\n  urls = _read_text_file(path)\n\n  def url_hash(u):\n    h = hashlib.sha1()\n    try:\n      u = u.encode(\'utf-8\')\n    except UnicodeDecodeError:\n      logging.error(\'Cannot hash url: %s\', u)\n    h.update(u)\n    return h.hexdigest()\n\n  return {url_hash(u): True for u in urls}\n\n\ndef _find_files(dl_paths, publisher, url_dict):\n  """"""Find files corresponding to urls.""""""\n  if publisher == \'cnn\':\n    top_dir = os.path.join(dl_paths[\'cnn_stories\'], \'cnn\', \'stories\')\n  elif publisher == \'dm\':\n    top_dir = os.path.join(dl_paths[\'dm_stories\'], \'dailymail\', \'stories\')\n  else:\n    logging.fatal(\'Unsupported publisher: %s\', publisher)\n  files = tf.io.gfile.listdir(top_dir)\n\n  ret_files = []\n  for p in files:\n    basename = os.path.basename(p)\n    if basename[0:basename.find(\'.story\')] in url_dict:\n      ret_files.append(os.path.join(top_dir, p))\n  return ret_files\n\n\ndef _subset_filenames(dl_paths, split):\n  """"""Get filenames for a particular split.""""""\n  assert isinstance(dl_paths, dict), dl_paths\n  # Get filenames for a split.\n  if split == tfds.Split.TRAIN:\n    urls = _get_url_hashes(dl_paths[\'train_urls\'])\n  elif split == tfds.Split.VALIDATION:\n    urls = _get_url_hashes(dl_paths[\'val_urls\'])\n  elif split == tfds.Split.TEST:\n    urls = _get_url_hashes(dl_paths[\'test_urls\'])\n  else:\n    logging.fatal(\'Unsupported split: %s\', split)\n  cnn = _find_files(dl_paths, \'cnn\', urls)\n  dm = _find_files(dl_paths, \'dm\', urls)\n  return cnn + dm\n\n\nDM_SINGLE_CLOSE_QUOTE = u\'\\u2019\'  # unicode\nDM_DOUBLE_CLOSE_QUOTE = u\'\\u201d\'\n# acceptable ways to end a sentence\nEND_TOKENS = [\n    \'.\', \'!\', \'?\', \'...\', ""\'"", \'`\', \'""\', DM_SINGLE_CLOSE_QUOTE,\n    DM_DOUBLE_CLOSE_QUOTE, \')\'\n]\n\n\ndef _read_text_file(text_file):\n  lines = []\n  with tf.io.gfile.GFile(text_file, \'r\') as f:\n    for line in f:\n      lines.append(line.strip())\n  return lines\n\n\ndef _get_art_abs(story_file, tfds_version):\n  """"""Get abstract (highlights) and article from a story file path.""""""\n  # Based on https://github.com/abisee/cnn-dailymail/blob/master/\n  #     make_datafiles.py\n\n  lines = _read_text_file(story_file)\n\n  # The github code lowercase the text and we removed it in 3.0.0.\n\n  # Put periods on the ends of lines that are missing them\n  # (this is a problem in the dataset because many image captions don\'t end in\n  # periods; consequently they end up in the body of the article as run-on\n  # sentences)\n  def fix_missing_period(line):\n    """"""Adds a period to a line that is missing a period.""""""\n    if \'@highlight\' in line:\n      return line\n    if not line:\n      return line\n    if line[-1] in END_TOKENS:\n      return line\n    return line + \' .\'\n\n  lines = [fix_missing_period(line) for line in lines]\n\n  # Separate out article and abstract sentences\n  article_lines = []\n  highlights = []\n  next_is_highlight = False\n  for line in lines:\n    if not line:\n      continue  # empty line\n    elif line.startswith(\'@highlight\'):\n      next_is_highlight = True\n    elif next_is_highlight:\n      highlights.append(line)\n    else:\n      article_lines.append(line)\n\n  # Make article into a single string\n  article = \' \'.join(article_lines)\n\n  if tfds_version >= \'2.0.0\':\n    abstract = \'\\n\'.join(highlights)\n  else:\n    abstract = \' \'.join(highlights)\n\n  return article, abstract\n\n\nclass CnnDailymail(tfds.core.GeneratorBasedBuilder):\n  """"""CNN/DailyMail non-anonymized summarization dataset.""""""\n  BUILDER_CONFIGS = [\n      CnnDailymailConfig(\n          name=\'plain_text\',\n          description=\'Plain text\',\n      ),\n      CnnDailymailConfig(\n          name=\'bytes\',\n          description=(\'Uses byte-level text encoding with \'\n                       \'`tfds.features.text.ByteTextEncoder`\'),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder=tfds.features.text.ByteTextEncoder()),\n      ),\n      CnnDailymailConfig(\n          name=\'subwords32k\',\n          description=(\'Uses `tfds.features.text.SubwordTextEncoder` with \'\n                       \'32k vocab size\'),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**15),\n      ),\n  ]\n\n  def _info(self):\n    # Should return a tfds.core.DatasetInfo object\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _ARTICLE:\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            _HIGHLIGHTS:\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n        }),\n        supervised_keys=(_ARTICLE, _HIGHLIGHTS),\n        homepage=\'https://github.com/abisee/cnn-dailymail\',\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, paths):\n    for _, ex in self._generate_examples(paths):\n      yield \' \'.join([ex[_ARTICLE], ex[_HIGHLIGHTS]])\n\n  def _split_generators(self, dl_manager):\n    dl_paths = dl_manager.download_and_extract(_DL_URLS)\n    train_files = _subset_filenames(dl_paths, tfds.Split.TRAIN)\n    # Generate shared vocabulary\n    # maybe_build_from_corpus uses SubwordTextEncoder if that\'s configured\n    self.info.features[_ARTICLE].maybe_build_from_corpus(\n        self._vocab_text_gen(train_files))\n    encoder = self.info.features[_ARTICLE].encoder\n    # Use maybe_set_encoder because the encoder may have been restored from\n    # package data.\n    self.info.features[_HIGHLIGHTS].maybe_set_encoder(encoder)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'files\': train_files}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'files\': _subset_filenames(dl_paths, tfds.Split.VALIDATION)\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'files\': _subset_filenames(dl_paths, tfds.Split.TEST)})\n    ]\n\n  def _generate_examples(self, files):\n    for p in files:\n      article, highlights = _get_art_abs(p, self.version)\n      if not article or not highlights:\n        continue\n      fname = os.path.basename(p)\n      yield fname, {_ARTICLE: article, _HIGHLIGHTS: highlights}\n'"
tensorflow_datasets/summarization/cnn_dailymail_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.text.cnn_dailymail.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\n\nfrom tensorflow_datasets import testing\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.summarization import cnn_dailymail\n\n_STORY_FILE = b""""""Some article.\nThis is some article text.\n\n@highlight\n\nhighlight text\n\n@highlight\n\nHighlight two\n\n@highlight\n\nhighlight Three\n""""""\n\n\nclass CnnDailymailTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cnn_dailymail.CnnDailymail\n  SPLITS = {\'train\': 3, \'validation\': 2, \'test\': 2}\n  DL_EXTRACT_RESULT = {\n      \'cnn_stories\': \'\',\n      \'dm_stories\': \'\',\n      \'test_urls\': \'all_test.txt\',\n      \'train_urls\': \'all_train.txt\',\n      \'val_urls\': \'all_val.txt\'\n  }\n\n  def test_get_art_abs(self):\n    with tempfile.NamedTemporaryFile(delete=True) as f:\n      f.write(_STORY_FILE)\n      f.flush()\n      article, abstract = cnn_dailymail._get_art_abs(f.name,\n                                                     tfds.core.Version(\'1.0.0\'))\n      self.assertEqual(\'Some article. This is some article text.\', article)\n      # This is a bit weird, but the original code at\n      # https://github.com/abisee/cnn-dailymail/ adds space before period\n      # for abstracts and we retain this behavior.\n      self.assertEqual(\'highlight text . Highlight two . highlight Three .\',\n                       abstract)\n\n      article, abstract = cnn_dailymail._get_art_abs(f.name,\n                                                     tfds.core.Version(\'2.0.0\'))\n      self.assertEqual(\'highlight text .\\nHighlight two .\\nhighlight Three .\',\n                       abstract)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/summarization/covid19sum.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""Summarizing abstract from covid19 publications.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, Iterator, List, Text, Tuple\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@ONLINE {CORD-19-research-challenge,\n    author = ""An AI challenge with AI2, CZI, MSR, Georgetown, NIH & The White House"",\n    title  = ""COVID-19 Open Research Dataset Challenge (CORD-19)"",\n    month  = ""april"",\n    year   = ""2020"",\n    url    = ""https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge""\n}\n""""""\n\n_HOMEPAGE = ""https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge""\n\n_DESCRIPTION = """"""\nCORD-19 is a resource of over 45,000 scholarly articles, including over 33,000\nwith full text, about COVID-19, SARS-CoV-2, and related coronaviruses.\n\nTo help organizing information in scientific literatures of COVID-19 through\nabstractive summarization. This dataset parse those articles to pairs of\ndocument and summaries of full_text-abstract or introduction-abstract.\n\nFeatures includes strings of: abstract, full_text, sha (hash of pdf),\nsource_x (source of publication), title, doi (digital object identifier),\nlicense, authors, publish_time, journal, url.\n""""""\n\n_ABSTRACT = ""abstract""\n_BODY_TEXT = ""body_text""\n_SECTION = ""section""\n_TEXT = ""text""\n_SHA = ""sha""\n_ADDITIONAL_FEATURES = [\n    _SHA, ""source_x"", ""title"", ""doi"", ""license"", ""authors"", ""publish_time"",\n    ""journal"", ""url""\n]\n\n\nclass Covid19sum(tfds.core.GeneratorBasedBuilder):\n  """"""Covid19sum Dataset.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\n    This dataset need to be manually downloaded through kaggle api:\n    `kaggle datasets download allen-institute-for-ai/CORD-19-research-challenge`\n    Place the downloaded zip file in the manual folder\n    (defaults to ~/tensorflow_datasets/manual/).\n    """"""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self) -> tfds.core.DatasetInfo:\n    features = {k: tf.string for k in _ADDITIONAL_FEATURES + [_ABSTRACT]}\n    features[_BODY_TEXT] = tfds.features.Sequence(\n        tfds.features.FeaturesDict({\n            _SECTION: tf.string,\n            _TEXT: tf.string\n        }))\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        supervised_keys=(_BODY_TEXT, _ABSTRACT),\n        homepage=_HOMEPAGE,\n        citation=_CITATION,\n    )\n\n  def _split_generators(\n      self, dl_manager: tfds.download.DownloadManager\n  ) -> List[tfds.core.SplitGenerator]:\n    """"""Returns SplitGenerators.""""""\n    extracted_path = dl_manager.extract(\n        os.path.join(dl_manager.manual_dir, ""CORD-19-research-challenge.zip""))\n    pd = tfds.core.lazy_imports.pandas\n    df = pd.read_csv(os.path.join(extracted_path, ""metadata.csv"")).fillna("""")\n    data_paths = []\n    for _, row in df.iterrows():\n      file_dir = row[""full_text_file""]\n      if row[""has_full_text""] and _has_abstract(row) and file_dir:\n        d = {k: row[k] for k in _ADDITIONAL_FEATURES + [_ABSTRACT]}\n        d[""path""] = os.path.join(extracted_path, file_dir, file_dir,\n                                 row[_SHA] + "".json"")\n        data_paths.append(d)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""data_paths"": data_paths},\n        )\n    ]\n\n  def _generate_examples(\n      self,\n      data_paths: List[Dict[Text, Any]] = None\n  ) -> Iterator[Tuple[Any, Dict[Text, Any]]]:\n    """"""Yields examples.""""""\n    for d in data_paths:\n      path = d.pop(""path"")\n      if tf.io.gfile.exists(path):\n        with tf.io.gfile.GFile(path, ""rb"") as f:\n          data_dict = json.load(f)\n          body_text = data_dict.get(_BODY_TEXT, [])\n          if body_text:\n            d[_BODY_TEXT] = [\n                {k: s[k] for k in [_SECTION, _TEXT]} for s in body_text\n            ]\n            yield d[_SHA], d\n\n\ndef _has_abstract(example: Dict[Text, Any]) -> bool:\n  abstract = example[_ABSTRACT]\n  return abstract and abstract.lower() != ""unknown""\n'"
tensorflow_datasets/summarization/covid19sum_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""Tests for Covid19Sum dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import covid19sum\n\n\nclass Covid19sumTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = covid19sum.Covid19sum\n  SPLITS = {\n      ""train"": 2,  # Number of fake train example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/gigaword.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Gigaword summarization dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{graff2003english,\n  title={English gigaword},\n  author={Graff, David and Kong, Junbo and Chen, Ke and Maeda, Kazuaki},\n  journal={Linguistic Data Consortium, Philadelphia},\n  volume={4},\n  number={1},\n  pages={34},\n  year={2003}\n}\n\n@article{Rush_2015,\n   title={A Neural Attention Model for Abstractive Sentence Summarization},\n   url={http://dx.doi.org/10.18653/v1/D15-1044},\n   DOI={10.18653/v1/d15-1044},\n   journal={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},\n   publisher={Association for Computational Linguistics},\n   author={Rush, Alexander M. and Chopra, Sumit and Weston, Jason},\n   year={2015}\n}\n""""""\n\n_DESCRIPTION = """"""\nHeadline-generation on a corpus of article pairs from Gigaword consisting of\naround 4 million articles. Use the \'org_data\' provided by\nhttps://github.com/microsoft/unilm/ which is identical to\nhttps://github.com/harvardnlp/sent-summary but with better format.\n\nThere are two features:\n  - document: article.\n  - summary: headline.\n\n""""""\n\n_URL = ""https://drive.google.com/uc?export=download&id=1USoQ8lJgN8kAWnUnRrupMGrPMLlDVqlV""\n\n_DOCUMENT = ""document""\n_SUMMARY = ""summary""\n\n\nclass Gigaword(tfds.core.GeneratorBasedBuilder):\n  """"""Gigaword summarization dataset.""""""\n\n  # 1.0.0 contains a bug that uses validation data as training data.\n  # 1.1.0 Update to the correct train, validation and test data.\n  # 1.2.0 Replace <unk> with <UNK> in train/val to be consistent with test.\n  VERSION = tfds.core.Version(""1.2.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text()\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/harvardnlp/sent-summary"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    pattern = os.path.join(dl_path, ""org_data"", ""%s.%s.txt"")\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""src_path"": pattern % (""train"", ""src""),\n                ""tgt_path"": pattern % (""train"", ""tgt""),\n                ""replace_unk"": True,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""src_path"": pattern % (""dev"", ""src""),\n                ""tgt_path"": pattern % (""dev"", ""tgt""),\n                ""replace_unk"": True,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""src_path"": pattern % (""test"", ""src""),\n                ""tgt_path"": pattern % (""test"", ""tgt""),\n                ""replace_unk"": False,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, src_path=None, tgt_path=None, replace_unk=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(src_path) as f_d, tf.io.gfile.GFile(tgt_path) as f_s:\n      for i, (doc_text, sum_text) in enumerate(zip(f_d, f_s)):\n        if replace_unk:\n          yield i, {\n              _DOCUMENT: doc_text.strip().replace(""<unk>"", ""UNK""),\n              _SUMMARY: sum_text.strip().replace(""<unk>"", ""UNK"")\n          }\n        else:\n          yield i, {_DOCUMENT: doc_text.strip(), _SUMMARY: sum_text.strip()}\n'"
tensorflow_datasets/summarization/gigaword_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Gigaword dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import gigaword\n\n\nclass GigawordOriginalTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = gigaword.Gigaword\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/multi_news.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Multi-News dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{alex2019multinews,\n    title={Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},\n    author={Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},\n    year={2019},\n    eprint={1906.01749},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nMulti-News, consists of news articles and human-written summaries\nof these articles from the site newser.com.\nEach summary is professionally written by editors and\nincludes links to the original articles cited.\n\nThere are two features:\n  - document: text of news articles seperated by special token ""|||||"".\n  - summary: news summary.\n""""""\n\n_URL = ""https://drive.google.com/uc?export=download&id=1vRY2wM6rlOZrf9exGTm5pXj5ExlVwJ0C""\n\n_DOCUMENT = ""document""\n_SUMMARY = ""summary""\n\n\nclass MultiNews(tfds.core.GeneratorBasedBuilder):\n  """"""Multi-News dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text()\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/Alex-Fabbri/Multi-News"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    extract_path = os.path.join(\n        dl_manager.download_and_extract(_URL), ""multi-news-original"")\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": os.path.join(extract_path, ""train"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""path"": os.path.join(extract_path, ""val"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""path"": os.path.join(extract_path, ""test"")},\n        ),\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(\n        os.path.join(path + "".src"")) as src_f, tf.io.gfile.GFile(\n            os.path.join(path + "".tgt"")) as tgt_f:\n      for i, (src_line, tgt_line) in enumerate(zip(src_f, tgt_f)):\n        yield i, {\n            # In original file, each line has one example and natural newline\n            # tokens ""\\n"" are being replaced with ""NEWLINE_CHAR"". Here restore\n            # the natural newline token to avoid special vocab ""NEWLINE_CHAR"".\n            _DOCUMENT: src_line.strip().replace(""NEWLINE_CHAR"", ""\\n""),\n            # Remove the starting token ""- "" for every target sequence.\n            _SUMMARY: tgt_line.strip().lstrip(""- "")\n        }\n'"
tensorflow_datasets/summarization/multi_news_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Multi-News dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import multi_news\n\n\nclass MultiNewsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = multi_news.MultiNews\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/newsroom.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""NEWSROOM Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{Grusky_2018,\n   title={Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies},\n   url={http://dx.doi.org/10.18653/v1/n18-1065},\n   DOI={10.18653/v1/n18-1065},\n   journal={Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 1 (Long Papers)},\n   publisher={Association for Computational Linguistics},\n   author={Grusky, Max and Naaman, Mor and Artzi, Yoav},\n   year={2018}\n}\n\n""""""\n\n_DESCRIPTION = """"""\nNEWSROOM is a large dataset for training and evaluating summarization systems.\nIt contains 1.3 million articles and summaries written by authors and\neditors in the newsrooms of 38 major publications.\n\nDataset features includes:\n  - text: Input news text.\n  - summary: Summary for the news.\nAnd additional features:\n  - title: news title.\n  - url: url of the news.\n  - date: date of the article.\n  - density: extractive density.\n  - coverage: extractive coverage.\n  - compression: compression ratio.\n  - density_bin: low, medium, high.\n  - coverage_bin: extractive, abstractive.\n  - compression_bin: low, medium, high.\n\nThis dataset can be downloaded upon requests. Unzip all the contents\n""train.jsonl, dev.josnl, test.jsonl"" to the tfds folder.\n\n""""""\n\n_DOCUMENT = ""text""\n_SUMMARY = ""summary""\n_ADDITIONAL_TEXT_FEATURES = [\n    ""title"", ""url"", ""date"", ""density_bin"", ""coverage_bin"", ""compression_bin""\n]\n_ADDITIONAL_FLOAT_FEATURES = [\n    ""density"",\n    ""coverage"",\n    ""compression"",\n]\n\n\nclass Newsroom(tfds.core.GeneratorBasedBuilder):\n  """"""NEWSROOM Dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  You should download the dataset from https://summari.es/download/\n  The webpage requires registration.\n  After downloading, please put dev.jsonl, test.jsonl and train.jsonl\n  files in the manual_dir.\n  """"""\n\n  def _info(self):\n    features = {\n        k: tfds.features.Text()\n        for k in [_DOCUMENT, _SUMMARY] + _ADDITIONAL_TEXT_FEATURES\n    }\n    features.update({\n        k: tfds.features.Tensor(shape=[], dtype=tf.float32)\n        for k in _ADDITIONAL_FLOAT_FEATURES\n    })\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://summari.es"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""input_file"": os.path.join(dl_manager.manual_dir, ""train.jsonl"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""input_file"": os.path.join(dl_manager.manual_dir, ""dev.jsonl"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""input_file"": os.path.join(dl_manager.manual_dir, ""test.jsonl"")\n            },\n        ),\n    ]\n\n  def _generate_examples(self, input_file=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(input_file) as f:\n      for i, line in enumerate(f):\n        d = json.loads(line)\n        # fields are ""url"", ""archive"", ""title"", ""date"", ""text"",\n        #  ""compression_bin"", ""density_bin"", ""summary"", ""density"",\n        #  ""compression\', ""coverage"", ""coverage_bin"",\n        yield i, {\n            k: d[k] for k in [_DOCUMENT, _SUMMARY] + _ADDITIONAL_TEXT_FEATURES +\n            _ADDITIONAL_FLOAT_FEATURES\n        }\n'"
tensorflow_datasets/summarization/newsroom_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for NEWSROOM dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import newsroom\n\n\nclass NewsroomTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = newsroom.Newsroom\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n      ""validation"": 2,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/opinion_abstracts.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""Opinion Abstracts Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, Iterator, List, Text, Tuple\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{wang-ling-2016-neural,\n    title = ""Neural Network-Based Abstract Generation for Opinions and Arguments"",\n    author = ""Wang, Lu  and\n      Ling, Wang"",\n    booktitle = ""Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies"",\n    month = jun,\n    year = ""2016"",\n    address = ""San Diego, California"",\n    publisher = ""Association for Computational Linguistics"",\n    url = ""https://www.aclweb.org/anthology/N16-1007"",\n    doi = ""10.18653/v1/N16-1007"",\n    pages = ""47--57"",\n}\n""""""\n\n_DESCRIPTION = """"""\nThere are two sub datasets:\n\n(1) RottenTomatoes: The movie critics and consensus crawled from\nhttp://rottentomatoes.com/. It has fields of ""_movie_name"", ""_movie_id"",\n""_critics"", and ""_critic_consensus"".\n\n(2) IDebate: The arguments crawled from http://idebate.org/. It has fields of\n""_debate_name"", ""_debate_id"", ""_claim"", ""_claim_id"", ""_argument_sentences"".\n\n""""""\n\n_URL = ""http://www.ccs.neu.edu/home/luwang/datasets/opinion_abstracts.zip""\n\n\nclass OpinionAbstractsConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for OpinionAbstracts.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               filename: Text = None,\n               name_key: Text = None,\n               id_key: Text = None,\n               opinions_key: Text = None,\n               summary_key: Text = None,\n               **kwargs):\n    """"""BuilderConfig for OpinionAbstracts.""""""\n    super(OpinionAbstractsConfig, self).__init__(\n        version=tfds.core.Version(""1.0.0""), **kwargs)\n    self.filename = filename\n    self.name_key = name_key\n    self.id_key = id_key\n    self.opinions_key = opinions_key\n    self.summary_key = summary_key\n\n\nclass OpinionAbstracts(tfds.core.GeneratorBasedBuilder):\n  """"""OpinionAbstracts Dataset Builder.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n  BUILDER_CONFIGS = [\n      OpinionAbstractsConfig(\n          name=""rotten_tomatoes"",\n          filename=""rottentomatoes.json"",\n          name_key=""_movie_name"",\n          id_key=""_movie_id"",\n          opinions_key=""_critics"",\n          summary_key=""_critic_consensus"",\n          description=""Professional critics and consensus of 3,731 movies."",\n      ),\n      OpinionAbstractsConfig(\n          name=""idebate"",\n          filename=""idebate.json"",\n          name_key=""_debate_name"",\n          id_key=""_claim_id"",\n          opinions_key=""_argument_sentences"",\n          summary_key=""_claim"",\n          description=""2,259 claims for 676 debates."",\n      )\n  ]\n\n  def _info(self) -> tfds.core.DatasetInfo:\n    config = self.builder_config\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            config.name_key:\n                tf.string,\n            config.id_key:\n                tf.string,\n            config.summary_key:\n                tf.string,\n            config.opinions_key:\n                tfds.features.Sequence(\n                    tfds.features.FeaturesDict({\n                        ""key"": tf.string,\n                        ""value"": tf.string\n                    })),\n        }),\n        supervised_keys=(config.opinions_key, config.summary_key),\n        homepage=""http://www.ccs.neu.edu/home/luwang/data.html"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(\n      self, dl_manager: tfds.download.DownloadManager\n  ) -> List[tfds.core.SplitGenerator]:\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    path = os.path.join(dl_path, ""opinion_abstracts"",\n                        self.builder_config.filename)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": path},\n        ),\n    ]\n\n  def _generate_examples(self,\n                         path: Text = None\n                        ) -> Iterator[Tuple[Text, Dict[Text, Any]]]:\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path, ""rb"") as f:\n      for example in json.load(f):\n        config = self.builder_config\n        opinions = example[config.opinions_key].items()\n        opinions = [{""key"": k, ""value"": v} for k, v in opinions]\n        features = {config.opinions_key: opinions}\n        for k in [config.name_key, config.id_key, config.summary_key]:\n          features[k] = example[k]\n        yield example[config.id_key], features\n'"
tensorflow_datasets/summarization/opinion_abstracts_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""OpinionAbstracts Dataset Test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import opinion_abstracts\n\n\nclass OpinionAbstractsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = opinion_abstracts.OpinionAbstracts\n  SPLITS = {\n      ""train"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/opinosis.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Opinosis Opinion Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{ganesan2010opinosis,\n  title={Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions},\n  author={Ganesan, Kavita and Zhai, ChengXiang and Han, Jiawei},\n  booktitle={Proceedings of the 23rd International Conference on Computational Linguistics},\n  pages={340--348},\n  year={2010},\n  organization={Association for Computational Linguistics}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe Opinosis Opinion Dataset consists of sentences extracted from reviews for 51 topics.\nTopics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.\n""""""\n\n_URL = ""https://github.com/kavgan/opinosis-summarization/raw/master/OpinosisDataset1.0_0.zip""\n\n_REVIEW_SENTS = ""review_sents""\n_SUMMARIES = ""summaries""\n\n\nclass Opinosis(tfds.core.GeneratorBasedBuilder):\n  """"""Opinosis Opinion Dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _REVIEW_SENTS: tfds.features.Text(),\n            _SUMMARIES: tfds.features.Sequence(tfds.features.Text())\n        }),\n        supervised_keys=(_REVIEW_SENTS, _SUMMARIES),\n        homepage=""http://kavita-ganesan.com/opinosis/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    extract_path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": extract_path},\n        ),\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    topics_path = os.path.join(path, ""topics"")\n    filenames = tf.io.gfile.listdir(topics_path)\n    for filename in filenames:\n      file_path = os.path.join(topics_path, filename)\n      topic_name = filename.split("".txt"")[0]\n      with tf.io.gfile.GFile(file_path, ""rb"") as src_f:\n        input_data = src_f.read()\n      summaries_path = os.path.join(path, ""summaries-gold"", topic_name)\n      summary_lst = []\n      for summ_filename in sorted(tf.io.gfile.listdir(summaries_path)):\n        file_path = os.path.join(summaries_path, summ_filename)\n        with tf.io.gfile.GFile(file_path, ""rb"") as tgt_f:\n          data = tgt_f.read().strip()\n          summary_lst.append(data)\n      summary_data = summary_lst\n      yield filename, {_REVIEW_SENTS: input_data, _SUMMARIES: summary_data}\n'"
tensorflow_datasets/summarization/opinosis_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Opinosis Opinion Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import opinosis\n\n\nclass OpinosisTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = opinosis.Opinosis\n  SPLITS = {\n      ""train"": 2,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/reddit.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Reddit dataset using tldr as summaries.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{volske-etal-2017-tl,\n    title = ""{TL};{DR}: Mining {R}eddit to Learn Automatic Summarization"",\n    author = {V{\\""o}lske, Michael  and\n      Potthast, Martin  and\n      Syed, Shahbaz  and\n      Stein, Benno},\n    booktitle = ""Proceedings of the Workshop on New Frontiers in Summarization"",\n    month = sep,\n    year = ""2017"",\n    address = ""Copenhagen, Denmark"",\n    publisher = ""Association for Computational Linguistics"",\n    url = ""https://www.aclweb.org/anthology/W17-4508"",\n    doi = ""10.18653/v1/W17-4508"",\n    pages = ""59--63"",\n    abstract = ""Recent advances in automatic text summarization have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining social media for author-provided summaries, taking advantage of the common practice of appending a {``}TL;DR{\'\'} to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is likely applicable to other social media sites and general web crawls."",\n}\n""""""\n\n_DESCRIPTION = """"""\nThis corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.\n""""""\n\n_URL = ""https://zenodo.org/record/1043504/files/corpus-webis-tldr-17.zip?download=1""\n\n_DOCUMENT = ""content""\n_SUMMARY = ""summary""\n_ADDITIONAL_FEATURES = [\n    ""author"", ""body"", ""normalizedBody"", ""subreddit"", ""subreddit_id"", ""id""\n]\n\n\nclass Reddit(tfds.core.GeneratorBasedBuilder):\n  """"""Reddit Dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            k: tf.string for k in _ADDITIONAL_FEATURES + [_DOCUMENT, _SUMMARY]\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/webis-de/webis-tldr-17-corpus"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""path"": os.path.join(dl_path, ""corpus-webis-tldr-17.json"")\n            },\n        )\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path, ""rb"") as f:\n      for i, line in enumerate(f):\n        # possible keys are:\n        #   author: string (nullable = true)\n        #   body: string (nullable = true)\n        #   normalizedBody: string (nullable = true)\n        #   content: string (nullable = true)\n        #   content_len: long (nullable = true)\n        #   summary: string (nullable = true)\n        #   summary_len: long (nullable = true)\n        #   id: string (nullable = true)\n        #   subreddit: string (nullable = true)\n        #   subreddit_id: string (nullable = true)\n        #   title: string (nullable = true)\n        d = json.loads(line)\n        if _SUMMARY in d and _DOCUMENT in d:\n          yield i, {\n              k: d.get(k, """")\n              for k in _ADDITIONAL_FEATURES + [_DOCUMENT, _SUMMARY]\n          }\n'"
tensorflow_datasets/summarization/reddit_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Reddit dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import reddit\n\n\nclass RedditTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = reddit.Reddit\n  SPLITS = {\n      ""train"": 2,  # Number of fake train example\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/reddit_tifu.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Reddit TIFU dataset using tifu or tldr from subreddit tifu.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{kim2018abstractive,\n    title={Abstractive Summarization of Reddit Posts with Multi-level Memory Networks},\n    author={Byeongchang Kim and Hyunwoo Kim and Gunhee Kim},\n    year={2018},\n    eprint={1811.00783},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nReddit dataset, where TIFU denotes the name of subbreddit /r/tifu.\nAs defined in the publication, styel ""short"" uses title as summary and\n""long"" uses tldr as summary.\n\nFeatures includes:\n  - document: post text without tldr.\n  - tldr: tldr line.\n  - title: trimmed title without tldr.\n  - ups: upvotes.\n  - score: score.\n  - num_comments: number of comments.\n  - upvote_ratio: upvote ratio.\n""""""\n\n_URL = ""https://drive.google.com/uc?export=download&id=1ffWfITKFMJeqjT8loC8aiCLRNJpc_XnF""\n\n_DOCUMENT = ""documents""\n_TITLE = ""title""\n_TLDR = ""tldr""\n_ADDITIONAL_FEATURES = [""ups"", ""num_comments"", ""score"", ""upvote_ratio""]\n\n\nclass RedditTifuConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for RedditTifu.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, summary_key=None, **kwargs):\n    """"""BuilderConfig for RedditTifu.\n\n    Args:\n      summary_key: key string of summary in downloaded json file.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    # Version 1.1.0 remove empty document and summary strings.\n    super(RedditTifuConfig, self).__init__(\n        version=tfds.core.Version(""1.1.0""), **kwargs)\n    self.summary_key = summary_key\n\n\nclass RedditTifu(tfds.core.GeneratorBasedBuilder):\n  """"""Reddit TIFU Dataset.""""""\n\n  BUILDER_CONFIGS = [\n      RedditTifuConfig(\n          name=""short"",\n          summary_key=_TITLE,\n          description=""Using title as summary."",\n      ),\n      RedditTifuConfig(\n          name=""long"",\n          summary_key=_TLDR,\n          description=""Using TLDR as summary."",\n      )\n  ]\n\n  def _info(self):\n    features = {\n        k: tfds.features.Tensor(shape=[], dtype=tf.float32)\n        for k in _ADDITIONAL_FEATURES\n    }\n    features.update(\n        {k: tfds.features.Text() for k in [_DOCUMENT, _TLDR, _TITLE]})\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        supervised_keys=(_DOCUMENT, self.builder_config.summary_key),\n        homepage=""https://github.com/ctr4si/MMN"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": dl_path},\n        )\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path, ""rb"") as f:\n      for i, line in enumerate(f):\n        # keys are \'title_tokenized\',\'permalink\',\'title\',\'url\',\'num_comments\',\n        #   \'tldr\'(optional),\'created_utc\',\'trimmed_title_tokenized\',\'ups\',\n        #   \'selftext_html\',\'score\',\'upvote_ratio\',\'tldr_tokenized\'(optional),\n        #   \'selftext\',\'trimmed_title\',\'selftext_without_tldr_tokenized\',\n        #   \'id\',\'selftext_without_tldr\'\n        d = json.loads(line)\n        r = {\n            _DOCUMENT: d[""selftext_without_tldr""].strip(),\n            _TITLE: d[""trimmed_title""].strip(),\n            _TLDR: (d[""tldr""] or """").strip(),\n        }\n        r.update({k: d[k] for k in _ADDITIONAL_FEATURES})\n        # skip if document or summary is empty\n        if r[_DOCUMENT] and r[self.builder_config.summary_key]:\n          yield i, r\n'"
tensorflow_datasets/summarization/reddit_tifu_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for Reddit TIFU Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import reddit_tifu\n\n\nclass RedditTifuTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = reddit_tifu.RedditTifu\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n  }\n  DL_EXTRACT_RESULT = ""data.json""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/samsum.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""SAMSum dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Dict, Iterator, List, Text, Tuple\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{gliwa2019samsum,\n  title={SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},\n  author={Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},\n  journal={arXiv preprint arXiv:1911.12237},\n  year={2019}\n}\n""""""\n\n_DESCRIPTION = """"""\nSAMSum Corpus contains over 16k chat dialogues with manually annotated\nsummaries.\n\nThere are two features:\n\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - id: id of a example.\n\n""""""\n\n_DOCUMENT = ""dialogue""\n_SUMMARY = ""summary""\n_ID = ""id""\n\n\nclass Samsum(tfds.core.GeneratorBasedBuilder):\n  """"""SAMSum dataset builder.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Download https://arxiv.org/src/1911.12237v2/anc/corpus.7z, decompress and\n  place train.json, val.json and test.json in the manual follder.\n  """"""\n\n  def _info(self) -> tfds.core.DatasetInfo:\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text(),\n            _ID: tfds.features.Text(),\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://arxiv.org/src/1911.12237v2/anc"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(\n      self, dl_manager: tfds.download.DownloadManager\n  ) -> List[tfds.core.SplitGenerator]:\n    """"""Returns SplitGenerators.""""""\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""path"": os.path.join(dl_manager.manual_dir, ""train.json"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""path"": os.path.join(dl_manager.manual_dir, ""val.json"")\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""path"": os.path.join(dl_manager.manual_dir, ""test.json"")\n            },\n        ),\n    ]\n\n  def _generate_examples(self,\n                         path: Text = None\n                        ) -> Iterator[Tuple[Text, Dict[Text, Text]]]:\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path, ""rb"") as f:\n      for example in json.load(f):\n        yield example[_ID], example\n'"
tensorflow_datasets/summarization/samsum_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""SAMSum dataset test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import samsum\n\n\nclass SamsumTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = samsum.Samsum\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake train example\n      ""test"": 1,  # Number of fake train example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/scientific_papers.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Scientific Papers Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{Cohan_2018,\n   title={A Discourse-Aware Attention Model for Abstractive Summarization of\n            Long Documents},\n   url={http://dx.doi.org/10.18653/v1/n18-2097},\n   DOI={10.18653/v1/n18-2097},\n   journal={Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 2 (Short Papers)},\n   publisher={Association for Computational Linguistics},\n   author={Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},\n   year={2018}\n}\n""""""\n\n_DESCRIPTION = """"""\nScientific papers datasets contains two sets of long and structured documents.\nThe datasets are obtained from ArXiv and PubMed OpenAccess repositories.\n\nBoth ""arxiv"" and ""pubmed"" have two features:\n\n  - article: the body of the document, pagragraphs seperated by ""/n"".\n  - abstract: the abstract of the document, pagragraphs seperated by ""/n"".\n  - section_names: titles of sections, seperated by ""/n"".\n\n""""""\n\n_DOCUMENT = ""article""\n_SUMMARY = ""abstract""\n\n_URLS = {\n    ""arxiv"":\n        ""https://drive.google.com/uc?id=1b3rmCSIoh6VhD4HKWjI4HOW-cSwcwbeC&export=download"",\n    ""pubmed"":\n        ""https://drive.google.com/uc?id=1lvsqvsFi3W-pE1SqNZI0s8NR9rC1tsja&export=download"",\n}\n\n\nclass ScientificPapersConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Scientific Papers.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, filename=None, **kwargs):\n    """"""BuilderConfig for Wikihow.\n\n    Args:\n      filename: filename of different configs for the dataset.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    # 1.1.0 remove sentence breaker <S> and </S> in summary.\n    super(ScientificPapersConfig, self).__init__(\n        version=tfds.core.Version(""1.1.1""),\n        supported_versions=[tfds.core.Version(""1.1.0"")],\n        **kwargs)\n    self.filename = filename\n\n\nclass ScientificPapers(tfds.core.GeneratorBasedBuilder):\n  """"""Scientific Papers.""""""\n\n  BUILDER_CONFIGS = [\n      ScientificPapersConfig(\n          name=""arxiv"", description=""Documents from ArXiv repository.""),\n      ScientificPapersConfig(\n          name=""pubmed"", description=""Documents from PubMed repository."")\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text(),\n            ""section_names"": tfds.features.Text(),\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/armancohan/long-summarization"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_paths = dl_manager.download_and_extract(_URLS)\n    path = os.path.join(dl_paths[self.builder_config.name],\n                        self.builder_config.name + ""-dataset"")\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": os.path.join(path, ""train.txt"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""path"": os.path.join(path, ""val.txt"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""path"": os.path.join(path, ""test.txt"")},\n        ),\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path) as f:\n      for line in f:\n        # Possible keys are:\n        # ""article_id"": str\n        # ""article_text"": list[str] article (list of paragraphs).\n        # ""abstract_text"": list[str], abstract (list of paragraphs).\n        # ""section_names"": list[str], list of section names.\n        # ""sections"": list[list[str]], list of sections (list of paragraphs)\n        d = json.loads(line)\n        summary = ""\\n"".join(d[""abstract_text""])\n        # In original paper, <S> and </S> are not used in vocab during training\n        # or during decoding.\n        # https://github.com/armancohan/long-summarization/blob/master/data.py#L27\n        summary = summary.replace(""<S>"", """").replace(""</S>"", """")\n        yield d[""article_id""], {\n            _DOCUMENT: ""\\n"".join(d[""article_text""]),\n            _SUMMARY: summary,\n            ""section_names"": ""\\n"".join(d[""section_names""])\n        }\n'"
tensorflow_datasets/summarization/scientific_papers_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Scientific Papers Dataset Test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import scientific_papers\n\n\nclass ScientificPapersTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = scientific_papers.ScientificPapers\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = {""arxiv"": """", ""pubmed"": """"}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/wikihow.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WikiHow Datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport re\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@misc{koupaee2018wikihow,\n    title={WikiHow: A Large Scale Text Summarization Dataset},\n    author={Mahnaz Koupaee and William Yang Wang},\n    year={2018},\n    eprint={1810.09305},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DESCRIPTION = """"""\nWikiHow is a new large-scale dataset using the online WikiHow\n(http://www.wikihow.com/) knowledge base.\n\nThere are two features:\n  - text: wikihow answers texts.\n  - headline: bold lines as summary.\n\nThere are two separate versions:\n  - all: consisting of the concatenation of all paragraphs as the articles and\n         the bold lines as the reference summaries.\n  - sep: consisting of each paragraph and its summary.\n\nDownload ""wikihowAll.csv"" and ""wikihowSep.csv"" from\nhttps://github.com/mahnazkoupaee/WikiHow-Dataset and place them in manual folder\nhttps://www.tensorflow.org/datasets/api_docs/python/tfds/download/DownloadConfig.\nTrain/validation/test splits are provided by the authors.\nPreprocessing is applied to remove short articles\n(abstract length < 0.75 article length) and clean up extra commas.\n""""""\n\n_DOCUMENT = ""text""\n_SUMMARY = ""headline""\n\n_URLS = {\n    ""train"":\n        ""https://raw.githubusercontent.com/mahnazkoupaee/WikiHow-Dataset/master/all_train.txt"",\n    ""validation"":\n        ""https://raw.githubusercontent.com/mahnazkoupaee/WikiHow-Dataset/master/all_val.txt"",\n    ""test"":\n        ""https://raw.githubusercontent.com/mahnazkoupaee/WikiHow-Dataset/master/all_test.txt""\n}\n\n\nclass WikihowConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Wikihow.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, filename=None, **kwargs):\n    """"""BuilderConfig for Wikihow.\n\n    Args:\n      filename: filename of different configs for the dataset.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    # Version 1.1.0 remove empty document and summary strings.\n    # Version 1.2.0 add train validation test split, add cleaning & filtering.\n    super(WikihowConfig, self).__init__(\n        version=tfds.core.Version(""1.2.0""), **kwargs)\n    self.filename = filename\n\n\nclass Wikihow(tfds.core.GeneratorBasedBuilder):\n  """"""WikiHow: A Large Scale Text Summarization Dataset.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Links to files can be found on https://github.com/mahnazkoupaee/WikiHow-Dataset\n  Please download both wikihowAll.csv and wikihowSep.csv.\n  """"""\n\n  BUILDER_CONFIGS = [\n      WikihowConfig(\n          name=""all"",\n          filename=""wikihowAll.csv"",\n          description=""Use the concatenation of all paragraphs as the articles""\n          "" and the bold lines as the reference summaries""),\n      WikihowConfig(\n          name=""sep"",\n          filename=""wikihowSep.csv"",\n          description=""use each paragraph and its summary."")\n  ]\n\n  def _info(self):\n    feature_names = [_DOCUMENT, _SUMMARY, ""title""]\n    if self.builder_config.name == ""sep"":\n      feature_names.extend([""overview"", ""sectionLabel""])\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(\n            {k: tfds.features.Text() for k in feature_names}),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=""https://github.com/mahnazkoupaee/WikiHow-Dataset"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download(_URLS)\n    titles = {k: set() for k in dl_path}\n    for k, path in dl_path.items():\n      with tf.io.gfile.GFile(path) as f:\n        for line in f:\n          titles[k].add(line.strip())\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_manager.manual_dir,\n                                 self.builder_config.filename),\n                ""title_set"":\n                    titles[""train""],\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_manager.manual_dir,\n                                 self.builder_config.filename),\n                ""title_set"":\n                    titles[""validation""],\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""path"":\n                    os.path.join(dl_manager.manual_dir,\n                                 self.builder_config.filename),\n                ""title_set"":\n                    titles[""test""],\n            },\n        )\n    ]\n\n  def _generate_examples(self, path=None, title_set=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path) as f:\n      reader = csv.reader(f)\n      headers = next(reader)\n      if self.builder_config.name == ""all"" and headers != [\n          ""headline"", ""title"", ""text""\n      ]:\n        raise ValueError(""Mismatched header in WikiAll.txt"")\n      if self.builder_config.name == ""sep"" and headers != [\n          ""overview"", ""headline"", ""text"", ""sectionLabel"", ""title""\n      ]:\n        raise ValueError(""Mismatched header in WikiSep.txt"")\n      key2id = {key: i for i, key in enumerate(headers)}\n      for i, line in enumerate(reader):\n        # skip empty line or insufficient line.\n        if len(line) == len(key2id):\n          summary = line[key2id[_SUMMARY]].strip()\n          document = line[key2id[_DOCUMENT]].strip()\n          summary, document = _filter_and_clean(summary, document)\n          if summary and document:\n            if line[key2id[""title""]].strip().replace("" "", """") in title_set:\n              d = {\n                  k: line[v].strip()\n                  for k, v in key2id.items()\n                  if k not in [_SUMMARY, _DOCUMENT]\n              }\n              d[_DOCUMENT] = document\n              d[_SUMMARY] = summary\n              yield i, d\n\n\n# This functions follow data processing acoording to original paper at\n# https://github.com/mahnazkoupaee/WikiHow-Dataset/blob/master/process.py\ndef _filter_and_clean(abstract, article):\n  """"""Remove short article and clean up commas in abstract and article.""""""\n  # a threshold is used to remove short articles with long summaries\n  # as well as articles with no summary\n  if len(abstract) < (0.75 * len(article)):\n    # remove extra commas in abstracts\n    abstract = abstract.replace("".,"", ""."")\n    # remove extra commas in articles\n    article = re.sub(r""[.]+[\\n]+[,]"", "".\\n"", article)\n    return abstract, article\n  else:\n    return """", """"\n'"
tensorflow_datasets/summarization/wikihow_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for WikiHow datasets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import wikihow\n\n\nclass WikihowTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = wikihow.Wikihow\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake train example\n      ""test"": 1,  # Number of fake train example\n  }\n  DL_EXTRACT_RESULT = {\n      ""train"": ""all_train.txt"",\n      ""test"": ""all_test.txt"",\n      ""validation"": ""all_validation.txt""\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/summarization/xsum.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""XSum dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{Narayan2018DontGM,\n  title={Don\'t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},\n  author={Shashi Narayan and Shay B. Cohen and Mirella Lapata},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1808.08745}\n}\n""""""\n\n_DESCRIPTION = """"""\nExtreme Summarization (XSum) Dataset.\n\nThere are two features:\n  - document: Input news article.\n  - summary: One sentence summary of the article.\n\nThis data need to manaully downloaded and extracted as described in\nhttps://github.com/EdinburghNLP/XSum/blob/master/XSum-Dataset/README.md.\nThe folder \'xsum-extracts-from-downloads\' need to be compressed as\n\'xsum-extracts-from-downloads.tar.gz\' and put in manually downloaded folder.\n""""""\n\n_URL = ""https://raw.githubusercontent.com/EdinburghNLP/XSum/master/XSum-Dataset/XSum-TRAINING-DEV-TEST-SPLIT-90-5-5.json""\n\n_DOCUMENT = ""document""\n_SUMMARY = ""summary""\n\n_REMOVE_LINES = set([\n    ""Share this with\\n"", ""Email\\n"", ""Facebook\\n"", ""Messenger\\n"", ""Twitter\\n"",\n    ""Pinterest\\n"", ""WhatsApp\\n"", ""Linkedin\\n"", ""LinkedIn\\n"", ""Copy this link\\n"",\n    ""These are external links and will open in a new window\\n""\n])\n\n\nclass Xsum(tfds.core.GeneratorBasedBuilder):\n  """"""Extreme Summarization (XSum) Dataset.""""""\n\n  # Version 1.1.0 removes web contents.\n  VERSION = tfds.core.Version(""1.1.0"")\n  SUPPORTED_VERSIONS = [tfds.core.Version(""1.0.0"", ""Dataset without cleaning."")]\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Detailed download instructions (which require running a custom script) are\n  here:\n  https://github.com/EdinburghNLP/XSum/blob/master/XSum-Dataset/README.md#running-the-download-and-extraction-scripts\n  Afterwards, please put xsum-extracts-from-downloads.tar.gz file in the manual_dir.\n  """"""\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _DOCUMENT: tfds.features.Text(),\n            _SUMMARY: tfds.features.Text(),\n        }),\n        supervised_keys=(_DOCUMENT, _SUMMARY),\n        homepage=\n        ""https://github.com/EdinburghNLP/XSum/tree/master/XSum-Dataset"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download(_URL)\n    with tf.io.gfile.GFile(dl_path, ""r"") as json_file:\n      split_ids = json.load(json_file)\n    folder_name = ""xsum-extracts-from-downloads""\n    extract_path = os.path.join(\n        dl_manager.extract(\n            os.path.join(dl_manager.manual_dir, folder_name + "".tar.gz"")),\n        folder_name)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""split_ids"": split_ids[""train""],\n                ""path"": extract_path,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""split_ids"": split_ids[""validation""],\n                ""path"": extract_path,\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""split_ids"": split_ids[""test""],\n                ""path"": extract_path,\n            },\n        ),\n    ]\n\n  def _generate_examples(self, split_ids=None, path=None):\n    """"""Yields examples.""""""\n    missing = 0\n    total_num = len(split_ids)\n    for i in split_ids:\n      filename = os.path.join(path, i + "".data"")\n      if tf.io.gfile.exists(filename):\n        with tf.io.gfile.GFile(filename) as f:\n          text = """".join([\n              line for line in f.readlines()\n              if line not in _REMOVE_LINES and line.strip()\n          ])\n          # Each file follows below format:\n          # [XSUM]URL[XSUM]\n          # http://somelink\n          #\n          # [XSUM]INTRODUCTION[XSUM]\n          # some intro\n          #\n          # [XSUM]RESTBODY[XSUM]\n          # text line.\n          # another text line.\n          # ""another text line.""\n          segs = text.split(""[XSUM]"")\n          yield i, {_DOCUMENT: segs[6].strip(), _SUMMARY: segs[4].strip()}\n      else:\n        missing += 1\n        logging.info(""id %s missing."", i)\n    if missing:\n      logging.warning(""%d out of %d examples are missing."", missing, total_num)\n'"
tensorflow_datasets/summarization/xsum_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for XSum dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.summarization import xsum\n\n\nclass XsumTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = xsum.Xsum\n  SPLITS = {\n      ""train"": 1,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = ""XSum-TRAINING-DEV-TEST-SPLIT-90-5-5.json""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/testing/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Testing utilities.""""""\n\nfrom tensorflow_datasets.testing.dataset_builder_testing import DatasetBuilderTestCase\nfrom tensorflow_datasets.testing.mocking import mock_data\nfrom tensorflow_datasets.testing.test_case import TestCase\nfrom tensorflow_datasets.testing.test_utils import DummyDatasetSharedGenerator\nfrom tensorflow_datasets.testing.test_utils import DummyMnist\nfrom tensorflow_datasets.testing.test_utils import DummyParser\nfrom tensorflow_datasets.testing.test_utils import DummySerializer\nfrom tensorflow_datasets.testing.test_utils import fake_examples_dir\nfrom tensorflow_datasets.testing.test_utils import FeatureExpectationItem\nfrom tensorflow_datasets.testing.test_utils import FeatureExpectationsTestCase\nfrom tensorflow_datasets.testing.test_utils import make_tmp_dir\nfrom tensorflow_datasets.testing.test_utils import mock_kaggle_api\nfrom tensorflow_datasets.testing.test_utils import MockFs\nfrom tensorflow_datasets.testing.test_utils import RaggedConstant\nfrom tensorflow_datasets.testing.test_utils import rm_tmp_dir\nfrom tensorflow_datasets.testing.test_utils import run_in_graph_and_eager_modes\nfrom tensorflow_datasets.testing.test_utils import SubTestCase\nfrom tensorflow_datasets.testing.test_utils import test_main\nfrom tensorflow_datasets.testing.test_utils import tmp_dir\n\n__all__ = [\n    ""DatasetBuilderTestCase"",\n    ""DummyDatasetSharedGenerator"",\n    ""DummyMnist"",\n    ""fake_examples_dir"",\n    ""FeatureExpectationItem"",\n    ""FeatureExpectationsTestCase"",\n    ""SubTestCase"",\n    ""TestCase"",\n    ""RaggedConstant"",\n    ""run_in_graph_and_eager_modes"",\n    ""test_main"",\n    ""tmp_dir"",  # TODO(afrozm): rm from here and add as methods to TestCase\n    ""make_tmp_dir"",  # TODO(afrozm): rm from here and add as methods to TestCase\n    ""mock_kaggle_api"",\n    ""mock_data"",\n    ""MockFs"",\n    ""rm_tmp_dir"",  # TODO(afrozm): rm from here and add as methods to TestCase\n]\n'"
tensorflow_datasets/testing/dataset_builder_testing.py,12,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base DatasetBuilderTestCase to test a DatasetBuilder base class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nimport itertools\nimport numbers\nimport os\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import download\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.download import checksums\nfrom tensorflow_datasets.core.utils import tf_utils\nfrom tensorflow_datasets.testing import test_utils\n\n\n# `os` module Functions for which tf.io.gfile equivalent should be preferred.\nFORBIDDEN_OS_FUNCTIONS = (\n    ""chmod"",\n    ""chown"",\n    ""link"",\n    ""listdir"",\n    ""lstat"",\n    ""makedirs"",\n    ""mkdir"",\n    ""mknod"",\n    ""open"",\n    ""pathconf"",\n    ""readlink"",\n    ""remove"",\n    ""removedirs"",\n    ""rename"",\n    ""renames"",\n    ""rmdir"",\n    ""stat"",\n    ""statvfs"",\n    ""symlink"",\n    ""unlink"",\n    ""walk"",\n)\nFORBIDDEN_OS_PATH_FUNCTIONS = (\n    ""exists"",\n    ""isdir"",\n    ""isfile"",\n)\n\n\n_ORGINAL_NP_LOAD = np.load\n\n\ndef _np_load(file_, mmap_mode=None, allow_pickle=False, **kwargs):\n  if not hasattr(file_, ""read""):\n    raise AssertionError(\n        ""You MUST pass a `tf.io.gfile.GFile` or file-like object to `np.load`."")\n  if allow_pickle:\n    raise AssertionError(""Unpicling files is forbidden for security reasons."")\n  return _ORGINAL_NP_LOAD(file_, mmap_mode, allow_pickle, **kwargs)\n\n\nclass DatasetBuilderTestCase(parameterized.TestCase, test_utils.SubTestCase):\n  """"""Inherit this class to test your DatasetBuilder class.\n\n  You must set the following class attributes:\n\n    * DATASET_CLASS: class object of DatasetBuilder you want to test.\n\n  You may set the following class attributes:\n\n    * VERSION: `str`. The version used to run the test. eg: \'1.2.*\'.\n      Defaults to None (canonical version).\n    * BUILDER_CONFIG_NAMES_TO_TEST: `list[str]`, the list of builder configs\n      that should be tested. If None, all the BUILDER_CONFIGS from the class\n      will be tested.\n    * DL_EXTRACT_RESULT: `dict[str]`, the returned result of mocked\n      `download_and_extract` method. The values should be the path of files\n      present in the `fake_examples` directory, relative to that directory.\n      If not specified, path to `fake_examples` will always be returned.\n    * DL_DOWNLOAD_RESULT: `dict[str]`, the returned result of mocked\n      `download_and_extract` method. The values should be the path of files\n      present in the `fake_examples` directory, relative to that directory.\n      If not specified: will use DL_EXTRACT_RESULT (this is due to backwards\n      compatibility and will be removed in the future).\n    * EXAMPLE_DIR: `str`, the base directory in in which fake examples are\n      contained. Optional; defaults to\n      tensorflow_datasets/testing/test_data/fake_examples/<dataset name>.\n    * OVERLAPPING_SPLITS: `list[str]`, splits containing examples from other\n      splits (e.g. a ""example"" split containing pictures from other splits).\n    * MOCK_OUT_FORBIDDEN_OS_FUNCTIONS: `bool`, defaults to True. Set to False to\n      disable checks preventing usage of `os` or builtin functions instead of\n      recommended `tf.io.gfile` API.\n    * SKIP_CHECKSUMS: Checks that the urls called by `dl_manager.download`\n      are registered.\n\n  This test case will check for the following:\n\n   - the dataset builder is correctly registered, i.e. `tfds.load(name)` works;\n   - the dataset builder can read the fake examples stored in\n       testing/test_data/fake_examples/{dataset_name};\n   - the dataset builder can produce serialized data;\n   - the dataset builder produces a valid Dataset object from serialized data\n     - in eager mode;\n     - in graph mode.\n   - the produced Dataset examples have the expected dimensions and types;\n   - the produced Dataset has and the expected number of examples;\n   - a example is not part of two splits, or one of these splits is whitelisted\n       in OVERLAPPING_SPLITS.\n  """"""\n\n  DATASET_CLASS = None\n  VERSION = None\n  BUILDER_CONFIG_NAMES_TO_TEST = None\n  DL_EXTRACT_RESULT = None\n  DL_DOWNLOAD_RESULT = None\n  EXAMPLE_DIR = None\n  OVERLAPPING_SPLITS = []\n  MOCK_OUT_FORBIDDEN_OS_FUNCTIONS = True\n  SKIP_CHECKSUMS = False\n\n  @classmethod\n  def setUpClass(cls):\n    tf.enable_v2_behavior()\n    super(DatasetBuilderTestCase, cls).setUpClass()\n    name = cls.__name__\n    # Check class has the right attributes\n    if cls.DATASET_CLASS is None or not callable(cls.DATASET_CLASS):\n      raise AssertionError(\n          ""Assign your DatasetBuilder class to %s.DATASET_CLASS."" % name)\n\n  def setUp(self):\n    super(DatasetBuilderTestCase, self).setUp()\n    self.patchers = []\n    self.builder = self._make_builder()\n\n    # Determine the fake_examples directory.\n    self.example_dir = os.path.join(\n        test_utils.fake_examples_dir(), self.builder.name)\n    if self.EXAMPLE_DIR is not None:\n      self.example_dir = self.EXAMPLE_DIR\n\n    if not tf.io.gfile.exists(self.example_dir):\n      err_msg = ""fake_examples dir %s not found."" % self.example_dir\n      raise ValueError(err_msg)\n    if self.MOCK_OUT_FORBIDDEN_OS_FUNCTIONS:\n      self._mock_out_forbidden_os_functions()\n\n    # Track the urls which are downloaded to validate the checksums\n    # The `dl_manager.download` and `dl_manager.download_and_extract` are\n    # patched to record the urls in `_download_urls`.\n    # Calling `dl_manager.download_checksums` stop the url\n    # registration (as checksums are stored remotelly)\n    # `_test_checksums` validates the recorded urls.\n    self._download_urls = set()\n    self._stop_record_download = False\n\n  def tearDown(self):\n    super(DatasetBuilderTestCase, self).tearDown()\n    for patcher in self.patchers:\n      patcher.stop()\n\n  def _mock_out_forbidden_os_functions(self):\n    """"""Raises error if forbidden os functions are called instead of gfile.""""""\n    err = AssertionError(""Do not use `os`, but `tf.io.gfile` module instead. ""\n                         ""This makes code compatible with more filesystems."")\n    sep = os.path.sep\n    mock_os_path = absltest.mock.Mock(os.path, wraps=os.path)\n    mock_os_path.sep = sep\n    for fop in FORBIDDEN_OS_PATH_FUNCTIONS:\n      getattr(mock_os_path, fop).side_effect = err\n    mock_os = absltest.mock.Mock(os, path=mock_os_path)\n    for fop in FORBIDDEN_OS_FUNCTIONS:\n      if os.name == ""nt"" and not hasattr(os, fop):\n        continue  # Not all `os` functions are available on Windows (ex: chmod).\n      getattr(mock_os, fop).side_effect = err\n    os_patcher = absltest.mock.patch(\n        self.DATASET_CLASS.__module__ + "".os"", mock_os, create=True)\n    os_patcher.start()\n    self.patchers.append(os_patcher)\n\n    mock_builtins = __builtins__.copy()  # pytype: disable=module-attr\n    mock_builtins[""open""] = absltest.mock.Mock(side_effect=err)\n    open_patcher = absltest.mock.patch(\n        self.DATASET_CLASS.__module__ + "".__builtins__"", mock_builtins)\n    open_patcher.start()\n    self.patchers.append(open_patcher)\n\n    # It\'s hard to mock open within numpy, so mock np.load.\n    np_load_patcher = absltest.mock.patch(""numpy.load"", _np_load)\n    np_load_patcher.start()\n    self.patchers.append(np_load_patcher)\n\n  def test_baseclass(self):\n    self.assertIsInstance(\n        self.builder, dataset_builder.DatasetBuilder,\n        ""Dataset class must inherit from `dataset_builder.DatasetBuilder`."")\n    # Since class was instantiated and base class is ABCMeta, then we know\n    # all needed methods were implemented.\n\n  def test_registered(self):\n    is_registered = self.builder.name in registered.list_builders()\n    exceptions = self.builder.IN_DEVELOPMENT\n    self.assertTrue(is_registered or exceptions,\n                    ""Dataset {} was not registered and is ""\n                    ""not `IN_DEVELOPMENT`."".format(self.builder.name))\n\n  def test_info(self):\n    info = self.builder.info\n    self.assertIsInstance(info, dataset_info.DatasetInfo)\n    self.assertEqual(self.builder.name, info.name)\n\n  def _add_url(self, url_or_urls):\n    if self._stop_record_download:\n      # Stop record the checksums if dl_manager.download_checksums has been\n      # called (as checksums may be stored remotelly)\n      return\n    if isinstance(url_or_urls, download.resource.Resource):\n      self._download_urls.add(url_or_urls.url)\n    else:\n      self._download_urls.add(url_or_urls)\n\n  def _get_dl_extract_result(self, url):\n    tf.nest.map_structure(self._add_url, url)\n    del url\n    if self.DL_EXTRACT_RESULT is None:\n      return self.example_dir\n    return utils.map_nested(lambda fname: os.path.join(self.example_dir, fname),\n                            self.DL_EXTRACT_RESULT)\n\n  def _get_dl_download_result(self, url):\n    tf.nest.map_structure(self._add_url, url)\n    if self.DL_DOWNLOAD_RESULT is None:\n      # This is only to be backwards compatible with old approach.\n      # In the future it will be replaced with using self.example_dir.\n      return self._get_dl_extract_result(url)\n    return utils.map_nested(lambda fname: os.path.join(self.example_dir, fname),\n                            self.DL_DOWNLOAD_RESULT)\n\n  def _download_checksums(self, url):\n    self._stop_record_download = True\n\n  def _make_builder(self, config=None):\n    return self.DATASET_CLASS(  # pylint: disable=not-callable\n        data_dir=self.tmp_dir,\n        config=config,\n        version=self.VERSION)\n\n  @test_utils.run_in_graph_and_eager_modes()\n  def test_download_and_prepare_as_dataset(self):\n    # If configs specified, ensure they are all valid\n    if self.BUILDER_CONFIG_NAMES_TO_TEST:\n      for config in self.BUILDER_CONFIG_NAMES_TO_TEST:  # pylint: disable=not-an-iterable\n        assert config in self.builder.builder_configs, (\n            ""Config %s specified in test does not exist. Available:\\n%s"" % (\n                config, list(self.builder.builder_configs)))\n\n    configs = self.builder.BUILDER_CONFIGS\n    print(""Total configs: %d"" % len(configs))\n    if configs:\n      for config in configs:\n        # Skip the configs that are not in the list.\n        if (self.BUILDER_CONFIG_NAMES_TO_TEST is not None and\n            (config.name not in self.BUILDER_CONFIG_NAMES_TO_TEST)):  # pylint: disable=unsupported-membership-test\n          print(""Skipping config %s"" % config.name)\n          continue\n        with self._subTest(config.name):\n          print(""Testing config %s"" % config.name)\n          builder = self._make_builder(config=config)\n          self._download_and_prepare_as_dataset(builder)\n    else:\n      self._download_and_prepare_as_dataset(self.builder)\n\n    if not self.SKIP_CHECKSUMS:\n      with self._subTest(""url_checksums""):\n        self._test_checksums()\n\n  def _test_checksums(self):\n    # If no call to `dl_manager.download`, then no need to check url presence.\n    if not self._download_urls:\n      return\n\n    err_msg = (""If you are developping outside TFDS and want to opt-out, ""\n               ""please add `SKIP_CHECKSUMS = True` to the ""\n               ""`DatasetBuilderTestCase`"")\n\n    with utils.try_reraise(suffix=err_msg):\n      filepath = os.path.join(checksums._get_path(self.builder.name))  # pylint: disable=protected-access\n      url_infos = checksums._get_url_infos(filepath)  # pylint: disable=protected-access\n\n    missing_urls = self._download_urls - set(url_infos.keys())\n    self.assertEmpty(\n        missing_urls,\n        ""Some urls checksums are missing at: {} ""\n        ""Did you forget to record checksums with `--register_checksums` ? ""\n        ""See instructions at: ""\n        ""https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally""\n        ""\\n{}"".format(filepath, err_msg)\n    )\n\n  def _download_and_prepare_as_dataset(self, builder):\n    # Provide the manual dir only if builder has MANUAL_DOWNLOAD_INSTRUCTIONS\n    # set.\n\n    missing_dir_mock = absltest.mock.PropertyMock(\n        side_effect=Exception(""Missing MANUAL_DOWNLOAD_INSTRUCTIONS""))\n\n    manual_dir = (\n        self.example_dir\n        if builder.MANUAL_DOWNLOAD_INSTRUCTIONS else missing_dir_mock)\n    with absltest.mock.patch.multiple(\n        ""tensorflow_datasets.core.download.DownloadManager"",\n        download_and_extract=self._get_dl_extract_result,\n        download=self._get_dl_download_result,\n        download_checksums=self._download_checksums,\n        manual_dir=manual_dir,\n    ):\n      if isinstance(builder, dataset_builder.BeamBasedBuilder):\n        # For Beam datasets, set-up the runner config\n        import apache_beam as beam   # pylint: disable=import-outside-toplevel,g-import-not-at-top\n        beam_runner = None\n        beam_options = beam.options.pipeline_options.PipelineOptions()\n      else:\n        beam_runner = None\n        beam_options = None\n\n      download_config = download.DownloadConfig(\n          compute_stats=download.ComputeStatsMode.SKIP,\n          beam_runner=beam_runner,\n          beam_options=beam_options,\n      )\n      builder.download_and_prepare(download_config=download_config)\n\n    with self._subTest(""as_dataset""):\n      self._assertAsDataset(builder)\n\n    with self._subTest(""num_examples""):\n      self._assertNumSamples(builder)\n\n    with self._subTest(""reload""):\n      # When reloading the dataset, metadata should been reloaded too.\n\n      builder_reloaded = self._make_builder(config=builder.builder_config)\n      self._assertNumSamples(builder_reloaded)\n\n      # After reloading, as_dataset should still be working\n      with self._subTest(""as_dataset""):\n        self._assertAsDataset(builder_reloaded)\n\n  def _assertAsDataset(self, builder):\n    split_to_checksums = {}  # {""split"": set(examples_checksums)}\n    for split_name, expected_examples_number in self.SPLITS.items():\n      ds = builder.as_dataset(split=split_name)\n      compare_shapes_and_types(\n          builder.info.features.get_tensor_info(),\n          tf.compat.v1.data.get_output_types(ds),\n          tf.compat.v1.data.get_output_shapes(ds),\n      )\n      examples = list(dataset_utils.as_numpy(\n          builder.as_dataset(split=split_name)))\n      split_to_checksums[split_name] = set(checksum(rec) for rec in examples)\n      self.assertLen(examples, expected_examples_number)\n    for (split1, hashes1), (split2, hashes2) in itertools.combinations(\n        split_to_checksums.items(), 2):\n      if (split1 in self.OVERLAPPING_SPLITS or\n          split2 in self.OVERLAPPING_SPLITS):\n        continue\n      self.assertFalse(\n          hashes1.intersection(hashes2),\n          (""Splits \'%s\' and \'%s\' are overlapping. Are you sure you want to ""\n           ""have the same objects in those splits? If yes, add one one of ""\n           ""them to OVERLAPPING_SPLITS class attribute."") % (split1, split2))\n\n  def _assertNumSamples(self, builder):\n    for split_name, expected_num_examples in self.SPLITS.items():\n      self.assertEqual(\n          builder.info.splits[split_name].num_examples,\n          expected_num_examples,\n      )\n    self.assertEqual(\n        builder.info.splits.total_num_examples,\n        sum(self.SPLITS.values()),\n    )\n\n\ndef checksum(example):\n  """"""Computes the md5 for a given example.""""""\n\n  def _bytes_flatten(flat_str, element):\n    """"""Recursively flatten an element to its byte representation.""""""\n    if isinstance(element, numbers.Number):\n      # In python3, bytes(-3) is not allowed (or large numbers),\n      # so convert to str to avoid problems.\n      element = str(element)\n    if isinstance(element, dict):\n      for k, v in sorted(element.items()):\n        flat_str.append(k)\n        _bytes_flatten(flat_str, v)\n    elif isinstance(element, str):\n      if hasattr(element, ""decode""):\n        # Python2 considers bytes to be str, but are almost always latin-1\n        # encoded bytes here. Extra step needed to avoid DecodeError.\n        element = element.decode(""latin-1"")\n      flat_str.append(element)\n    elif isinstance(element,\n                    (tf.RaggedTensor, tf.compat.v1.ragged.RaggedTensorValue)):\n      flat_str.append(str(element.to_list()))\n    elif isinstance(element, np.ndarray):\n      # tf.Tensor() returns np.array of dtype object, which don\'t work\n      # with x.to_bytes(). So instead convert numpy into list.\n      if element.dtype.type is np.object_:\n        flat_str.append(str(tuple(element.shape)))\n        flat_str.append(str(list(element.ravel())))\n      else:\n        flat_str.append(element.tobytes())\n    else:\n      flat_str.append(bytes(element))\n    return flat_str\n\n  flat_str = _bytes_flatten([], example)\n  flat_bytes = [\n      s.encode(""utf-8"") if not isinstance(s, bytes) else s\n      for s in flat_str\n  ]\n  flat_bytes = b"""".join(flat_bytes)\n\n  hash_ = hashlib.md5()\n  hash_.update(flat_bytes)\n  return hash_.hexdigest()\n\n\ndef compare_shapes_and_types(tensor_info, output_types, output_shapes):\n  """"""Compare shapes and types between TensorInfo and Dataset types/shapes.""""""\n  for feature_name, feature_info in tensor_info.items():\n    if isinstance(feature_info, dict):\n      compare_shapes_and_types(feature_info, output_types[feature_name],\n                               output_shapes[feature_name])\n    else:\n      expected_type = feature_info.dtype\n      output_type = output_types[feature_name]\n      if expected_type != output_type:\n        raise TypeError(""Feature %s has type %s but expected %s"" %\n                        (feature_name, output_type, expected_type))\n\n      expected_shape = feature_info.shape\n      output_shape = output_shapes[feature_name]\n      tf_utils.assert_shape_match(expected_shape, output_shape)\n'"
tensorflow_datasets/testing/dataset_builder_testing_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.testing.dataset_builder_testing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.testing import dataset_builder_testing\n\n\nclass DatasetBuilderTesting(tf.test.TestCase):\n\n  def test_checksum_string(self):\n    def _make_hash():\n      return dataset_builder_testing.checksum(\n          tf.constant([b\'foo\', b\'bar-obj\']).numpy())\n\n    # Ensure determinism by checking the hash is the same across examples\n    # Could harcode value instead but hash is different between Py2 and 3.\n    self.assertLen(set(_make_hash() for _ in range(5)), 1)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/testing/fake_data_utils.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utility library to generate dataset-like files.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport random\nimport tempfile\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\n\nMIN_HEIGHT_WIDTH = 10\nMAX_HEIGHT_WIDTH = 15\nCHANNELS_NB = 3\n\n_SAMPLE_RATE = 44100\n_AUDIO_DURATION = 5\n\n\ndef get_random_picture(height=None, width=None, channels=CHANNELS_NB):\n  """"""Returns random picture as np.ndarray (int).""""""\n  height = height or random.randrange(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n  width = width or random.randrange(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n  return np.random.randint(\n      256, size=(height, width, channels), dtype=np.uint8)\n\n\ndef get_random_jpeg(height=None, width=None, channels=CHANNELS_NB):\n  """"""Returns path to JPEG picture.""""""\n  image = get_random_picture(height, width, channels)\n  jpeg = tf.image.encode_jpeg(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(jpeg)\n  fobj = tempfile.NamedTemporaryFile(delete=False, mode=\'wb\', suffix=\'.JPEG\')\n  fobj.write(res)\n  fobj.close()\n  return fobj.name\n\n\ndef get_random_png(height=None, width=None, channels=CHANNELS_NB):\n  """"""Returns path to PNG picture.""""""\n  # Big randomly generated pngs take large amounts of diskspace.\n  # Instead, we resize a 4x4 random image to the png size.\n  image = get_random_picture(4, 4, channels)\n  image = tf.image.resize_nearest_neighbor(\n      tf.expand_dims(image, 0), (height, width))[0]\n  png = tf.image.encode_png(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(png)\n  fobj = tempfile.NamedTemporaryFile(delete=False, mode=\'wb\', suffix=\'.PNG\')\n  fobj.write(res)\n  fobj.close()\n  return fobj.name\n\n\ndef get_random_audio(duration=_AUDIO_DURATION, sample=_SAMPLE_RATE):\n  """"""Returns random audio as np.ndarray (float32).""""""\n  sample_number = np.arange(duration * sample)\n  waveform = np.sin(\n      2 * np.pi * sample_number * 440.0 / sample).astype(np.float32)\n  waveform = waveform * 0.3\n  return waveform\n\n\ndef get_random_wav_c1(\n    channels=1, duration=_AUDIO_DURATION, sample=_SAMPLE_RATE):\n  """"""Returns path to WAV audio having channels = 1.""""""\n  audio = get_random_audio(duration, sample).reshape(-1, channels)\n  wav = tf.audio.encode_wav(audio, sample)\n  with utils.nogpu_session() as sess:\n    res = sess.run(wav)\n  with tempfile.NamedTemporaryFile(delete=False, mode=\'wb\', suffix=\'.wav\') as f:\n    f.write(res)\n  return f.name\n\n\ndef get_random_wav_c2(\n    channels=2, duration=_AUDIO_DURATION, sample=_SAMPLE_RATE):\n  """"""Returns path to WAV audio having channels = 2.""""""\n  audio = get_random_audio(duration, sample).reshape(-1, channels)\n  wav = tf.audio.encode_wav(audio, sample)\n  with utils.nogpu_session() as sess:\n    res = sess.run(wav)\n  with tempfile.NamedTemporaryFile(delete=False, mode=\'wb\', suffix=\'.wav\') as f:\n    f.write(res)\n  return f.name\n'"
tensorflow_datasets/testing/mocking.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Mock util for tfds.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport functools\nimport os\nimport random\n\nfrom absl.testing import absltest\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import features as features_lib\n\n\n@contextlib.contextmanager\ndef mock_data(num_examples=1, as_dataset_fn=None, data_dir=None):\n  """"""Mock tfds to generate random data.\n\n  This function requires the true metadata files (dataset_info.json, label.txt,\n  vocabulary files) to be stored in `data_dir/dataset_name/version`, as they\n  would be for the true dataset.\n  The actual examples will be randomly generated using\n  `builder.info.features.get_tensor_info()`.\n  Download and prepare step will be skipped.\n\n  Warning: As the mocked builder will use the true metadata (label names,...),\n  the `info.split[\'train\'].num_examples` won\'t match `len(list(ds_train))`.\n\n  Usage (automated):\n\n  ```\n  with tfds.testing.mock_data(num_examples=5):\n    ds = tfds.load(\'some_dataset\', split=\'train\')\n\n    for ex in ds:  # ds will yield randomly generated examples.\n      ex\n  ```\n\n  The examples will be deterministically generated. Train and test split will\n  yield the same examples.\n\n  If you want more fine grain control over the generated examples, you can\n  manually overwrite the `DatasetBuilder._as_dataset` method.\n  Usage (manual):\n\n  ```\n  def as_dataset(self, *args, **kwargs):\n    return tf.data.Dataset.from_generator(\n        lambda: ({\n            \'image\': np.ones(shape=(28, 28, 1), dtype=np.uint8),\n            \'label\': i % 10,\n        } for i in range(num_examples)),\n        output_types=self.info.features.dtype,\n        output_shapes=self.info.features.shape,\n    )\n\n  with mock_data(as_dataset_fn=as_dataset):\n    ds = tfds.load(\'some_dataset\', split=\'train\')\n\n    for ex in ds:  # ds will yield the fake data example of \'as_dataset\'.\n      ex\n  ```\n\n  Args:\n    num_examples: `int`, the number of fake example to generate.\n    as_dataset_fn: if provided, will replace the default random example\n      generator. This function mock the `FileAdapterBuilder._as_dataset`\n    data_dir: `str`, `data_dir` folder from where to load the metadata.\n      Will overwrite `data_dir` kwargs from `tfds.load`.\n\n  Yields:\n    None\n  """"""\n\n  def mock_download_and_prepare(self, *args, **kwargs):\n    del args\n    del kwargs\n    if not tf.io.gfile.exists(self._data_dir):  # pylint: disable=protected-access\n      raise ValueError(\n          \'TFDS has been mocked, but metadata files were not found in {}. \'\n          \'You should copy the real metadata files, so that the dataset \'\n          \'can be loaded properly, or set the data_dir kwarg of \'\n          \'tfds.testing.mock_tfds(data_dir=...).\'\n          \'\'.format(self._data_dir, n=self.name)  # pylint: disable=protected-access\n      )\n\n  def mock_as_dataset(self, split, decoders=None, **kwargs):\n    """"""Function which overwrite builder._as_dataset.""""""\n    del split\n    del kwargs\n\n    if decoders is None:\n      generator_cls = RandomFakeGenerator\n      specs = self.info.features.get_tensor_info()\n      decode_fn = lambda ex: ex  # identity\n    else:\n      # If a decoder is passed, encode/decode the examples.\n      generator_cls = EncodedRandomFakeGenerator\n      specs = self.info.features.get_serialized_info()\n      decode_fn = functools.partial(\n          self.info.features.decode_example, decoders=decoders)\n\n    ds = tf.data.Dataset.from_generator(\n        # `from_generator` takes a callable with signature () -> iterable\n        # Recreating a new generator each time ensure that all pipelines are\n        # using the same examples\n        lambda: generator_cls(builder=self, num_examples=num_examples),\n        output_types=tf.nest.map_structure(lambda t: t.dtype, specs),\n        output_shapes=tf.nest.map_structure(lambda t: t.shape, specs),\n    )\n    ds.map(decode_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return ds\n\n  if not as_dataset_fn:\n    as_dataset_fn = mock_as_dataset\n\n  if not data_dir:\n    data_dir = os.path.join(os.path.dirname(__file__), \'metadata\')\n\n  download_and_prepare_path = \'tensorflow_datasets.core.dataset_builder.DatasetBuilder.download_and_prepare\'\n  as_dataset_path = \'tensorflow_datasets.core.dataset_builder.FileAdapterBuilder._as_dataset\'\n  data_dir_path = \'tensorflow_datasets.core.constants.DATA_DIR\'\n\n  with absltest.mock.patch(as_dataset_path, as_dataset_fn), \\\n       absltest.mock.patch(\n           download_and_prepare_path, mock_download_and_prepare), \\\n       absltest.mock.patch(data_dir_path, data_dir):\n    yield\n\n\nclass RandomFakeGenerator(object):\n  """"""Generator of fake examples randomly and deterministically generated.""""""\n\n  def __init__(self, builder, num_examples, seed=0):\n    self._rgn = np.random.RandomState(seed)  # Could use the split name as seed\n    self._py_rng = random.Random(seed)\n    self._builder = builder\n    self._num_examples = num_examples\n\n  def _generate_random_array(self, feature, tensor_info):\n    """"""Generates a random tensor for a single feature.""""""\n    # TODO(tfds): Could improve the fake generatiion:\n    # * Use the feature statistics (min, max)\n    # * For Sequence features\n    # * For Text\n    shape = [  # Fill dynamic shape with random values\n        self._rgn.randint(5, 50) if s is None else s\n        for s in tensor_info.shape\n    ]\n    if isinstance(feature, features_lib.ClassLabel):\n      max_value = feature.num_classes\n    elif isinstance(feature, features_lib.Text) and feature.vocab_size:\n      max_value = feature.vocab_size\n    else:\n      max_value = 255\n\n    # We cast the data to make sure `encode_example` don\'t raise errors\n    dtype = tensor_info.dtype\n    # Generate some random values, depending on the dtype\n    if dtype.is_integer:\n      return self._rgn.randint(0, max_value, shape).astype(dtype.as_numpy_dtype)\n    elif dtype.is_floating:\n      return self._rgn.random_sample(shape).astype(dtype.as_numpy_dtype)\n    elif dtype == tf.string:\n      return \'\'.join(\n          self._py_rng.choice(\' abcdefghij\')\n          for _ in range(self._py_rng.randint(10, 20))\n      )\n    raise ValueError(\'Fake generation not supported for {}\'.format(dtype))\n\n  def _generate_example(self):\n    """"""Generate the next example.""""""\n    root_feature = self._builder.info.features\n    flat_features = root_feature._flatten(root_feature)  # pylint: disable=protected-access\n    flat_tensor_info = root_feature._flatten(root_feature.get_tensor_info())  # pylint: disable=protected-access\n    flat_np = [\n        self._generate_random_array(feature, tensor_info)\n        for feature, tensor_info in zip(flat_features, flat_tensor_info)\n    ]\n    return root_feature._nest(flat_np)  # pylint: disable=protected-access\n\n  def __iter__(self):\n    """"""Yields all fake examples.""""""\n    for _ in range(self._num_examples):\n      yield self._generate_example()\n\n\nclass EncodedRandomFakeGenerator(RandomFakeGenerator):\n  """"""Generator of fake encoded examples.""""""\n\n  def __iter__(self):\n    """"""Yields all fake examples.""""""\n    for ex in super(EncodedRandomFakeGenerator, self).__iter__():\n      yield self._builder.info.features.encode_example(ex)\n'"
tensorflow_datasets/testing/mocking_test.py,14,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.testing.mocking.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import decode\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.testing import mocking\nfrom tensorflow_datasets.testing import test_case\nfrom tensorflow_datasets.testing import test_utils\n\n# Import for registration\n# pylint: disable=g-bad-import-order,unused-import\nfrom tensorflow_datasets.image_classification import imagenet\nfrom tensorflow_datasets.image_classification import mnist\nfrom tensorflow_datasets.text import lm1b\n# pylint: enable=g-bad-import-order,unused-import\n\ntf.enable_v2_behavior()\n\n\nclass MockingTest(test_case.TestCase):\n\n  def test_mocking_imagenet(self):\n    with mocking.mock_data():\n      ds = registered.load(\'imagenet2012\', split=\'train\')\n      self.assertEqual(ds.element_spec, {\n          \'file_name\': tf.TensorSpec(shape=(), dtype=tf.string),\n          \'image\': tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),\n          \'label\': tf.TensorSpec(shape=(), dtype=tf.int64),\n      })\n      list(ds.take(3))  # Iteration should work\n\n  def test_mocking_imagenet_decoders(self):\n    with mocking.mock_data():\n      ds, ds_info = registered.load(\n          \'imagenet2012\',\n          split=\'train\',\n          decoders={\'image\': decode.SkipDecoding()},\n          with_info=True,\n      )\n      self.assertEqual(ds.element_spec, {\n          \'file_name\': tf.TensorSpec(shape=(), dtype=tf.string),\n          \'image\': tf.TensorSpec(shape=(), dtype=tf.string),  # Encoded images\n          \'label\': tf.TensorSpec(shape=(), dtype=tf.int64),\n      })\n      for ex in ds.take(10):\n        # Image decoding should works\n        image = ds_info.features[\'image\'].decode_example(ex[\'image\'])\n        image.shape.assert_is_compatible_with((None, None, 3))\n        self.assertEqual(image.dtype, tf.uint8)\n\n  def test_mocking_lm1b(self):\n    with mocking.mock_data():\n      ds = registered.load(\'lm1b/bytes\', split=\'train\')\n      self.assertEqual(ds.element_spec, {\n          \'text\': tf.TensorSpec(shape=(None,), dtype=tf.int64),\n      })\n      for ex in ds.take(10):\n        self.assertEqual(ex[\'text\'].dtype, tf.int64)\n        ex[\'text\'].shape.assert_is_compatible_with((None,))\n\n  def test_custom_as_dataset(self):\n    def _as_dataset(self, *args, **kwargs):  # pylint: disable=unused-argument\n      return tf.data.Dataset.from_generator(\n          lambda: ({  # pylint: disable=g-long-lambda\n              \'text\': t,\n          } for t in [\'some sentence\', \'some other sentence\']),\n          output_types=self.info.features.dtype,\n          output_shapes=self.info.features.shape,\n      )\n\n    with mocking.mock_data(as_dataset_fn=_as_dataset):\n      ds = registered.load(\'lm1b\', split=\'train\')\n      out = [ex[\'text\'] for ex in dataset_utils.as_numpy(ds)]\n      self.assertEqual(out, [b\'some sentence\', b\'some other sentence\'])\n\n  def test_max_values(self):\n    with mocking.mock_data(num_examples=50):\n      ds = registered.load(\'mnist\', split=\'train\')\n      self.assertEqual(ds.element_spec, {\n          \'image\': tf.TensorSpec(shape=(28, 28, 1), dtype=tf.uint8),\n          \'label\': tf.TensorSpec(shape=(), dtype=tf.int64),\n      })\n      for ex in ds.take(50):\n        self.assertLessEqual(tf.math.reduce_max(ex[\'label\']).numpy(), 10)\n      self.assertEqual(  # Test determinism\n          [ex[\'label\'].numpy() for ex in ds.take(5)],\n          [1, 9, 2, 5, 3],\n      )\n      self.assertEqual(  # Iterating twice should yield the same samples\n          [ex[\'label\'].numpy() for ex in ds.take(5)],\n          [1, 9, 2, 5, 3],\n      )\n\n\nif __name__ == \'__main__\':\n  test_utils.test_main()\n'"
tensorflow_datasets/testing/test_case.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base TestCase to use test_data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport os\nimport tempfile\n\nfrom absl import logging\nfrom absl.testing import absltest\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import gcs_utils\n\n\nGCS_ACCESS_FNS = {\n    ""original_info"": gcs_utils.gcs_dataset_info_files,\n    ""dummy_info"": lambda _: [],\n    ""original_datasets"": gcs_utils.is_dataset_on_gcs,\n    ""dummy_datasets"": lambda _: False,\n}\n\n\nclass TestCase(tf.test.TestCase):\n  """"""Base TestCase to be used for all tests.\n\n  `test_data` class attribute: path to the directory with test data.\n  `tmp_dir` attribute: path to temp directory reset before every test.\n  """"""\n\n  @classmethod\n  def setUpClass(cls):\n    super(TestCase, cls).setUpClass()\n    cls.test_data = os.path.join(os.path.dirname(__file__), ""test_data"")\n    # Test must not communicate with GCS.\n    gcs_utils.gcs_dataset_info_files = GCS_ACCESS_FNS[""dummy_info""]\n    gcs_utils.is_dataset_on_gcs = GCS_ACCESS_FNS[""dummy_datasets""]\n\n  @contextlib.contextmanager\n  def gcs_access(self):\n    # Restore GCS access\n    gcs_utils.gcs_dataset_info_files = GCS_ACCESS_FNS[""original_info""]\n    gcs_utils.is_dataset_on_gcs = GCS_ACCESS_FNS[""original_datasets""]\n    yield\n    # Revert access\n    gcs_utils.gcs_dataset_info_files = GCS_ACCESS_FNS[""dummy_info""]\n    gcs_utils.is_dataset_on_gcs = GCS_ACCESS_FNS[""dummy_datasets""]\n\n  def setUp(self):\n    super(TestCase, self).setUp()\n    # get_temp_dir is actually the same for all tests, so create a temp sub-dir.\n    self.tmp_dir = tempfile.mkdtemp(dir=tf.compat.v1.test.get_temp_dir())\n\n  def assertRaisesWithPredicateMatch(self, err_type, predicate):\n    if isinstance(predicate, six.string_types):\n      predicate_fct = lambda err: predicate in str(err)\n    else:\n      predicate_fct = predicate\n    return super(TestCase, self).assertRaisesWithPredicateMatch(\n        err_type, predicate_fct)\n\n  @contextlib.contextmanager\n  def assertLogs(self, text, level=""info""):\n    with absltest.mock.patch.object(logging, level) as mock_log:\n      yield\n      concat_logs = """"\n      for log_call in mock_log.call_args_list:\n        args = log_call[0]\n        base, args = args[0], args[1:]\n        log_text = base % tuple(args)\n        concat_logs += "" "" + log_text\n      self.assertIn(text, concat_logs)\n'"
tensorflow_datasets/testing/test_utils.py,32,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport functools\nimport io\nimport os\nimport subprocess\nimport tempfile\nfrom typing import Iterator\n\nfrom absl.testing import absltest\n\nimport dill\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import dataset_builder\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import example_parser\nfrom tensorflow_datasets.core import example_serializer\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core import splits\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.testing import test_case\n\n\n@contextlib.contextmanager\ndef tmp_dir(dirname=None):\n  """"""Context manager for a temporary directory.""""""\n  tmp = make_tmp_dir(dirname)\n  yield tmp\n  rm_tmp_dir(tmp)\n\n\ndef make_tmp_dir(dirname=None):\n  """"""Make a temporary directory.""""""\n  if dirname and not tf.io.gfile.exists(dirname):\n    tf.io.gfile.makedirs(dirname)\n  return tempfile.mkdtemp(dir=dirname)\n\n\ndef rm_tmp_dir(dirname):\n  """"""Rm temporary directory.""""""\n  tf.io.gfile.rmtree(dirname)\n\n\ndef remake_dir(d):\n  """"""Possibly deletes and recreates directory.""""""\n  if tf.io.gfile.exists(d):\n    tf.io.gfile.rmtree(d)\n  tf.io.gfile.makedirs(d)\n\n\ndef fake_examples_dir():\n  return os.path.join(os.path.dirname(__file__), \'test_data\', \'fake_examples\')\n\n\nclass MockFs(object):\n  """"""This util wraps mock for the `tf.io.gfile` API.\n\n  Usage:\n\n  ```\n  fs = MockFs()\n  with fs.mock():\n\n    fs.add_file(\'/path/to/file1\', \'Content of file 1\')\n\n    assert tf.io.gfile.exists(\'/path/to/file1\')\n    with tf.io.gfile.GFile(\'/path/to/file2\', \'w\') as f:\n      f.write(\'Content of file 2\')\n    tf.io.gfile.rename(\'/path/to/file1\', \'/path/to/file1_moved\')\n\n    assert fs.files == {\n        \'/path/to/file2\': \'Content of file 2\',\n        \'/path/to/file1_moved\': \'Content of file 1\',\n    }\n  ```\n\n  Attributes:\n    files: Dict[str, str], mapping existing files -> file content\n  """"""\n\n  def __init__(self):\n    self.files = {}\n    self._cm = None\n\n  def __enter__(self):\n    self._cm = self.contextmanager()\n    return self._cm.__enter__()\n\n  def __exit__(self, exc_type, exc_value, traceback):\n    return self._cm.__exit__(exc_type, exc_value, traceback)\n\n  @contextlib.contextmanager\n  def contextmanager(self) -> Iterator[\'MockFs\']:\n    """"""Open the file.""""""\n    with self.mock():\n      yield self\n\n  def add_file(self, path, content=None) -> None:\n    content = \'Content of {}\'.format(path) if content is None else content\n    self.files[path] = content\n\n  def _list_directory(self, path):\n    path = path.rstrip(os.path.sep) + os.path.sep  # Make sure path is a `dir/`\n    return list({\n        # Extract `path/<dirname>/...` -> `<dirname>`\n        os.path.relpath(p, path).split(os.path.sep)[0]\n        for p in self.files if p.startswith(path)\n    })\n\n  @contextlib.contextmanager\n  def _open(self, path, mode=\'r\'):\n    """"""Patch `tf.io.gfile.GFile`.""""""\n    if mode.startswith(\'w\'):\n      self.add_file(path, \'\')\n    is_binary = \'b\' in mode\n\n    content = self.files[path]\n    if is_binary:\n      fobj = io.BytesIO(content.encode(\'utf-8\'))\n    else:\n      fobj = io.StringIO(content)\n\n    with fobj as f:\n      yield f\n      new_content = f.getvalue()  # Update the content\n\n    self.files[path] = new_content.decode(\'utf-8\') if is_binary else new_content  # pytype: disable=attribute-error\n\n  def _rename(self, from_, to, overwrite=False):\n    if not overwrite and to in self.files:\n      raise FileExistsError(\'Cannot overwrite: {} -> {}\'.format(from_, to))  # pytype: disable=name-error\n    if from_ not in self.files:\n      raise FileNotFoundError(\'Cannot rename unknown file: {}\'.format(from_))  # pytype: disable=name-error\n    self.files[to] = self.files.pop(from_)\n\n  def mock(self):\n    return absltest.mock.patch.object(\n        tf.io,\n        \'gfile\',\n        exists=lambda path: path in self.files,\n        makedirs=lambda _: None,\n        # Used to get name of file as downloaded:\n        listdir=self._list_directory,\n        GFile=self._open,\n        rename=self._rename,\n    )\n\n\nclass FeatureExpectationItem(object):\n  """"""Test item of a FeatureExpectation.""""""\n\n  def __init__(\n      self,\n      value,\n      expected=None,\n      expected_serialized=None,\n      decoders=None,\n      dtype=None,\n      shape=None,\n      raise_cls=None,\n      raise_msg=None):\n    self.value = value\n    self.expected = expected\n    self.expected_serialized = expected_serialized\n    self.decoders = decoders\n    self.dtype = dtype\n    self.shape = shape\n    if not decoders and (dtype is not None or shape is not None):\n      raise ValueError(\'dtype and shape should only be set with transform\')\n    self.raise_cls = raise_cls\n    self.raise_msg = raise_msg\n\n\nclass SubTestCase(test_case.TestCase):\n  """"""Adds subTest() context manager to the TestCase if supported.\n\n  Note: To use this feature, make sure you call super() in setUpClass to\n  initialize the sub stack.\n  """"""\n\n  @classmethod\n  def setUpClass(cls):\n    super(SubTestCase, cls).setUpClass()\n    cls._sub_test_stack = []\n\n  @contextlib.contextmanager\n  def _subTest(self, test_str):\n    self._sub_test_stack.append(test_str)\n    sub_test_str = \'/\'.join(self._sub_test_stack)\n    with self.subTest(sub_test_str):\n      yield\n    self._sub_test_stack.pop()\n\n  def assertAllEqualNested(self, d1, d2):\n    """"""Same as assertAllEqual but compatible with nested dict.""""""\n    if isinstance(d1, dict):\n      # assertAllEqual do not works well with dictionaries so assert\n      # on each individual elements instead\n      zipped_examples = utils.zip_nested(d1, d2, dict_only=True)\n      utils.map_nested(\n          lambda x: self.assertAllEqual(x[0], x[1]),\n          zipped_examples,\n          dict_only=True,\n      )\n    else:\n      self.assertAllEqual(d1, d2)\n\n\ndef run_in_graph_and_eager_modes(func=None,\n                                 config=None,\n                                 use_gpu=True):\n  """"""Execute the decorated test in both graph mode and eager mode.\n\n  This function returns a decorator intended to be applied to test methods in\n  a `test_case.TestCase` class. Doing so will cause the contents of the test\n  method to be executed twice - once in graph mode, and once with eager\n  execution enabled. This allows unittests to confirm the equivalence between\n  eager and graph execution.\n\n  NOTE: This decorator can only be used when executing eagerly in the\n  outer scope.\n\n  For example, consider the following unittest:\n\n  ```python\n  class SomeTest(tfds.testing.TestCase):\n\n    @tfds.testing.run_in_graph_and_eager_modes\n    def test_foo(self):\n      x = tf.constant([1, 2])\n      y = tf.constant([3, 4])\n      z = tf.add(x, y)\n      self.assertAllEqual([4, 6], self.evaluate(z))\n\n  if __name__ == \'__main__\':\n    tfds.testing.test_main()\n  ```\n\n  This test validates that `tf.add()` has the same behavior when computed with\n  eager execution enabled as it does when constructing a TensorFlow graph and\n  executing the `z` tensor with a session.\n\n  Args:\n    func: function to be annotated. If `func` is None, this method returns a\n      decorator the can be applied to a function. If `func` is not None this\n      returns the decorator applied to `func`.\n    config: An optional config_pb2.ConfigProto to use to configure the session\n      when executing graphs.\n    use_gpu: If True, attempt to run as many operations as possible on GPU.\n\n  Returns:\n    Returns a decorator that will run the decorated test method twice:\n    once by constructing and executing a graph in a session and once with\n    eager execution enabled.\n  """"""\n\n  def decorator(f):\n    """"""Decorator for a method.""""""\n    def decorated(self, *args, **kwargs):\n      """"""Run the decorated test method.""""""\n      if not tf.executing_eagerly():\n        raise ValueError(\'Must be executing eagerly when using the \'\n                         \'run_in_graph_and_eager_modes decorator.\')\n\n      # Run eager block\n      f(self, *args, **kwargs)\n      self.tearDown()\n\n      # Run in graph mode block\n      with tf.Graph().as_default():\n        self.setUp()\n        with self.test_session(use_gpu=use_gpu, config=config):\n          f(self, *args, **kwargs)\n\n    return decorated\n\n  if func is not None:\n    return decorator(func)\n\n  return decorator\n\n\nclass RaggedConstant(object):\n  """"""Container of tf.ragged.constant values.\n\n  This simple wrapper forward the arguments to delay the RaggedTensor\n  construction after `@run_in_graph_and_eager_modes` has been called.\n  This is required to avoid incompabilities between Graph/eager.\n  """"""\n\n  def __init__(self, *args, **kwargs):\n    self._args = args\n    self._kwargs = dict(kwargs)\n\n  def build(self):\n    return tf.ragged.constant(*self._args, **self._kwargs)\n\n\nclass FeatureExpectationsTestCase(SubTestCase):\n  """"""Tests FeatureExpectations with full encode-decode.""""""\n\n  @run_in_graph_and_eager_modes()\n  def assertFeature(self, feature, shape, dtype, tests, serialized_info=None):\n    """"""Test the given feature against the predicates.""""""\n\n    # Check the shape/dtype\n    with self._subTest(\'shape\'):\n      self.assertEqual(feature.shape, shape)\n    with self._subTest(\'dtype\'):\n      self.assertEqual(feature.dtype, dtype)\n\n    # Check the serialized features\n    if serialized_info is not None:\n      with self._subTest(\'serialized_info\'):\n        self.assertEqual(\n            serialized_info,\n            feature.get_serialized_info(),\n        )\n\n    # Create the feature dict\n    fdict = features.FeaturesDict({\'inner\': feature})\n    fdict._set_top_level()  # pylint: disable=protected-access\n\n    for i, test in enumerate(tests):\n      with self._subTest(str(i)):\n        self.assertFeatureTest(\n            fdict=fdict,\n            test=test,\n            feature=feature,\n            shape=shape,\n            dtype=dtype,\n        )\n\n  def assertFeatureTest(self, fdict, test, feature, shape, dtype):\n    """"""Test that encode=>decoding of a value works correctly.""""""\n    # test feature.encode_example can be pickled and unpickled for beam.\n    dill.loads(dill.dumps(feature.encode_example))\n\n    input_value = {\'inner\': test.value}\n\n    if test.raise_cls is not None:\n      with self._subTest(\'raise\'):\n        if not test.raise_msg:\n          raise ValueError(\n              \'test.raise_msg should be set with {} for test {}\'.format(\n                  test.raise_cls, type(feature)))\n        with self.assertRaisesWithPredicateMatch(\n            test.raise_cls, test.raise_msg):\n          features_encode_decode(fdict, input_value, decoders=test.decoders)\n    else:\n      # Test the serialization only\n      if test.expected_serialized is not None:\n        with self._subTest(\'out_serialize\'):\n          self.assertEqual(\n              test.expected_serialized,\n              feature.encode_example(test.value),\n          )\n\n      # Test serialization + decoding from disk\n      with self._subTest(\'out\'):\n        out_tensor, out_numpy = features_encode_decode(\n            fdict,\n            input_value,\n            decoders={\'inner\': test.decoders},\n        )\n        out_tensor = out_tensor[\'inner\']\n        out_numpy = out_numpy[\'inner\']\n\n        # Assert the returned type match the expected one\n        with self._subTest(\'dtype\'):\n          out_dtypes = utils.map_nested(lambda s: s.dtype, out_tensor)\n          self.assertEqual(out_dtypes, test.dtype or feature.dtype)\n        with self._subTest(\'shape\'):\n          # For shape, because (None, 3) match with (5, 3), we use\n          # tf.TensorShape.assert_is_compatible_with on each of the elements\n          expected_shape = feature.shape if test.shape is None else test.shape\n          out_shapes = utils.zip_nested(out_tensor, expected_shape)\n          utils.map_nested(\n              lambda x: x[0].shape.assert_is_compatible_with(x[1]),\n              out_shapes\n          )\n\n        # Assert value\n        with self._subTest(\'out_value\'):\n          # Eventually construct the tf.RaggedTensor\n          expected = utils.map_nested(\n              lambda t: t.build() if isinstance(t, RaggedConstant) else t,\n              test.expected)\n          self.assertAllEqualNested(out_numpy, expected)\n\n\ndef features_encode_decode(features_dict, example, decoders):\n  """"""Runs the full pipeline: encode > write > tmp files > read > decode.""""""\n  # Encode example\n  encoded_example = features_dict.encode_example(example)\n\n  # Serialize/deserialize the example\n  specs = features_dict.get_serialized_info()\n  serializer = example_serializer.ExampleSerializer(specs)\n  parser = example_parser.ExampleParser(specs)\n\n  serialized_example = serializer.serialize_example(encoded_example)\n  ds = tf.data.Dataset.from_tensors(serialized_example)\n  ds = ds.map(parser.parse_example)\n\n  # Decode the example\n  decode_fn = functools.partial(\n      features_dict.decode_example,\n      decoders=decoders,\n  )\n  ds = ds.map(decode_fn)\n\n  if tf.executing_eagerly():\n    out_tensor = next(iter(ds))\n  else:\n    out_tensor = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\n  out_numpy = dataset_utils.as_numpy(out_tensor)\n  return out_tensor, out_numpy\n\n\nclass DummyDatasetSharedGenerator(dataset_builder.GeneratorBasedBuilder):\n  """"""Test DatasetBuilder.""""""\n\n  VERSION = utils.Version(\'1.0.0\')\n  SUPPORTED_VERSIONS = [\n      \'2.0.0\',\n      \'0.0.9\',\n      \'0.0.8\',\n      utils.Version(\'0.0.7\', tfds_version_to_prepare=\'v1.0.0\'),\n  ]\n\n  def _info(self):\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({\'x\': tf.int64}),\n        supervised_keys=(\'x\', \'x\'),\n    )\n\n  def _split_generators(self, dl_manager):\n    # Split the 30 examples from the generator into 2 train shards and 1 test\n    # shard.\n    del dl_manager\n    return [\n        splits.SplitGenerator(\n            name=splits.Split.TRAIN,\n            gen_kwargs={\'range_\': range(20)}),\n        splits.SplitGenerator(\n            name=splits.Split.TEST,\n            gen_kwargs={\'range_\': range(20, 30)}),\n    ]\n\n  def _generate_examples(self, range_):\n    for i in range_:\n      yield i, {\'x\': i}\n\n\nclass DummyMnist(dataset_builder.GeneratorBasedBuilder):\n  """"""Test DatasetBuilder.""""""\n\n  VERSION = utils.Version(\'1.0.0\')\n\n  def _info(self):\n    return dataset_info.DatasetInfo(\n        builder=self,\n        features=features.FeaturesDict({\n            \'image\': features.Image(shape=(28, 28, 1)),\n            \'label\': features.ClassLabel(num_classes=10),\n        }),\n        description=\'Mnist description.\',\n    )\n\n  def _split_generators(self, dl_manager):\n    return [\n        splits.SplitGenerator(\n            name=splits.Split.TRAIN,\n            gen_kwargs=dict()),\n        splits.SplitGenerator(\n            name=splits.Split.TEST,\n            gen_kwargs=dict()),\n    ]\n\n  def _generate_examples(self):\n    for i in range(20):\n      yield i, {\n          \'image\': np.ones((28, 28, 1), dtype=np.uint8),\n          \'label\': i % 10,\n      }\n\n\ndef test_main():\n  """"""Entrypoint for tests.""""""\n  tf.enable_v2_behavior()\n  tf.test.main()\n\n\n@contextlib.contextmanager\ndef mock_kaggle_api(filenames=None, err_msg=None):\n  """"""Mock out the kaggle CLI.\n\n  Args:\n    filenames: `list<str>`, names of the competition files.\n    err_msg: `str`, if provided, the kaggle CLI will raise a CalledProcessError\n      and this will be the command output.\n\n  Yields:\n    None, context will have kaggle CLI mocked out.\n  """"""\n\n  def make_mock_files_call(filenames, err_msg):\n    """"""Mock subprocess.check_output for files call.""""""\n\n    def check_output(command_args):\n      assert command_args[2] == \'files\'\n      if err_msg:\n        raise subprocess.CalledProcessError(1, command_args,\n                                            tf.compat.as_bytes(err_msg))\n      return tf.compat.as_bytes(\n          \'\\n\'.join([\'name,size,creationDate\'] +\n                    [\'%s,34MB,None\\n\' % fname for fname in filenames]))\n\n    return check_output\n\n  def make_mock_download_call():\n    """"""Mock subprocess.check_output for download call.""""""\n\n    def check_output(command_args):\n      assert command_args[2] == \'download\'\n      fname = command_args[command_args.index(\'--file\') + 1]\n      out_dir = command_args[command_args.index(\'--path\') + 1]\n      fpath = os.path.join(out_dir, fname)\n      with tf.io.gfile.GFile(fpath, \'w\') as f:\n        f.write(fname)\n      return tf.compat.as_bytes(\'Downloading %s to %s\' % (fname, fpath))\n\n    return check_output\n\n  def make_mock_check_output(filenames, err_msg):\n    """"""Mock subprocess.check_output for both calls.""""""\n\n    files_call = make_mock_files_call(filenames, err_msg)\n    dl_call = make_mock_download_call()\n\n    def check_output(command_args):\n      if command_args[2] == \'files\':\n        return files_call(command_args)\n      else:\n        assert command_args[2] == \'download\'\n        return dl_call(command_args)\n\n    return check_output\n\n  with absltest.mock.patch(\'subprocess.check_output\',\n                           make_mock_check_output(filenames, err_msg)):\n    yield\n\n\nclass DummySerializer(object):\n  """"""To mock example_serializer.ExampleSerializer.""""""\n\n  def __init__(self, specs):\n    del specs\n\n  def serialize_example(self, example):\n    return bytes(example)\n\n\nclass DummyParser(object):\n  """"""To mock example_parser.ExampleParser.""""""\n\n  def __init__(self, specs):\n    del specs\n\n  def parse_example(self, ex):\n    return ex\n\n'"
tensorflow_datasets/testing/test_utils_test.py,16,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.test_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.testing import test_case\nfrom tensorflow_datasets.testing import test_utils\n\ntf.enable_v2_behavior()\n\n\nclass RunInGraphAndEagerTest(test_case.TestCase):\n\n  def test_run_in_graph_and_eager_modes(self):\n    l = []\n    def inc(self, with_brackets):\n      del self  # self argument is required by run_in_graph_and_eager_modes.\n      mode = \'eager\' if tf.executing_eagerly() else \'graph\'\n      with_brackets = \'with_brackets\' if with_brackets else \'without_brackets\'\n      l.append((with_brackets, mode))\n\n    f = test_utils.run_in_graph_and_eager_modes(inc)\n    f(self, with_brackets=False)\n    f = test_utils.run_in_graph_and_eager_modes()(inc)\n    f(self, with_brackets=True)\n\n    self.assertEqual(len(l), 4)\n    self.assertEqual(set(l), {\n        (\'with_brackets\', \'graph\'),\n        (\'with_brackets\', \'eager\'),\n        (\'without_brackets\', \'graph\'),\n        (\'without_brackets\', \'eager\'),\n    })\n\n  def test_run_in_graph_and_eager_modes_setup_in_same_mode(self):\n    modes = []\n    mode_name = lambda: \'eager\' if tf.executing_eagerly() else \'graph\'\n\n    class ExampleTest(test_case.TestCase):\n\n      def runTest(self):\n        pass\n\n      def setUp(self):\n        super(ExampleTest, self).setUp()\n        modes.append(\'setup_\' + mode_name())\n\n      @test_utils.run_in_graph_and_eager_modes\n      def testBody(self):\n        modes.append(\'run_\' + mode_name())\n\n    e = ExampleTest()\n    e.setUp()\n    e.testBody()\n\n    self.assertEqual(modes[0:2], [\'setup_eager\', \'run_eager\'])\n    self.assertEqual(modes[2:], [\'setup_graph\', \'run_graph\'])\n\n  def test_mock_fs(self):\n    if sys.version_info.major < 3:  # Disable test on Python2\n      return\n\n    fs = test_utils.MockFs()\n    with fs.mock():\n      fs.add_file(\'/path/to/file1\', \'Content of file 1\')\n      fs.add_file(\'/path/file.txt\', \'Content of file.txt\')\n\n      # Test `tf.io.gfile.exists`\n      self.assertTrue(tf.io.gfile.exists(\'/path/to/file1\'))\n      self.assertFalse(tf.io.gfile.exists(\'/path/to/file1_nonexisting\'))\n\n      # Test `tf.io.gfile.GFile` (write and read mode)\n      with tf.io.gfile.GFile(\'/path/to/file2\', \'w\') as f:\n        f.write(\'Content of file 2 (old)\')\n      self.assertEqual(fs.files[\'/path/to/file2\'], \'Content of file 2 (old)\')\n      with tf.io.gfile.GFile(\'/path/to/file2\', \'w\') as f:\n        f.write(\'Content of file 2 (new)\')\n      self.assertEqual(fs.files[\'/path/to/file2\'], \'Content of file 2 (new)\')\n      with tf.io.gfile.GFile(\'/path/to/file2\', \'r\') as f:\n        self.assertEqual(f.read(), \'Content of file 2 (new)\')\n\n      # Test `tf.io.gfile.rename`\n      self.assertEqual(fs.files[\'/path/to/file1\'], \'Content of file 1\')\n      tf.io.gfile.rename(\'/path/to/file1\', \'/path/to/file1_moved\')\n      self.assertNotIn(\'/path/to/file1\', fs.files)\n      self.assertEqual(fs.files[\'/path/to/file1_moved\'], \'Content of file 1\')\n\n      # Test `tf.io.gfile.listdir`\n      self.assertCountEqual(\n          tf.io.gfile.listdir(\'/path/to\'), tf.io.gfile.listdir(\'/path/to/\'))\n      self.assertCountEqual(\n          tf.io.gfile.listdir(\'/path/to\'), [\'file1_moved\', \'file2\'])\n      self.assertCountEqual(tf.io.gfile.listdir(\'/path\'), [\'file.txt\', \'to\'])\n\n      # Test `MockFs.files`\n      self.assertEqual(fs.files, {\n          \'/path/to/file2\': \'Content of file 2 (new)\',\n          \'/path/to/file1_moved\': \'Content of file 1\',\n          \'/path/file.txt\': \'Content of file.txt\',\n      })\n\nif __name__ == \'__main__\':\n  test_utils.test_main()\n'"
tensorflow_datasets/text/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Text datasets.""""""\n\nfrom tensorflow_datasets.text.anli import Anli\nfrom tensorflow_datasets.text.blimp import Blimp\nfrom tensorflow_datasets.text.c4 import C4\nfrom tensorflow_datasets.text.cfq import CFQ\nfrom tensorflow_datasets.text.cfq import CFQConfig\nfrom tensorflow_datasets.text.civil_comments import CivilComments\nfrom tensorflow_datasets.text.cos_e import CosE\nfrom tensorflow_datasets.text.definite_pronoun_resolution import DefinitePronounResolution\nfrom tensorflow_datasets.text.eraser_multi_rc import EraserMultiRc\nfrom tensorflow_datasets.text.esnli import Esnli\nfrom tensorflow_datasets.text.gap import Gap\nfrom tensorflow_datasets.text.glue import Glue\nfrom tensorflow_datasets.text.imdb import IMDBReviews\nfrom tensorflow_datasets.text.imdb import IMDBReviewsConfig\nfrom tensorflow_datasets.text.irc_disentanglement import IrcDisentanglement\nfrom tensorflow_datasets.text.librispeech_lm import LibrispeechLm\nfrom tensorflow_datasets.text.lm1b import Lm1b\nfrom tensorflow_datasets.text.lm1b import Lm1bConfig\nfrom tensorflow_datasets.text.math_dataset import MathDataset\nfrom tensorflow_datasets.text.movie_rationales import MovieRationales\nfrom tensorflow_datasets.text.multi_nli import MultiNLI\nfrom tensorflow_datasets.text.multi_nli_mismatch import MultiNLIMismatch\nfrom tensorflow_datasets.text.pg19 import Pg19\nfrom tensorflow_datasets.text.qa4mre import Qa4mre\nfrom tensorflow_datasets.text.scan import Scan\nfrom tensorflow_datasets.text.scan import ScanConfig\nfrom tensorflow_datasets.text.scicite import Scicite\nfrom tensorflow_datasets.text.snli import Snli\nfrom tensorflow_datasets.text.super_glue import SuperGlue\nfrom tensorflow_datasets.text.tiny_shakespeare import TinyShakespeare\nfrom tensorflow_datasets.text.wiki40b import Wiki40b\nfrom tensorflow_datasets.text.wikipedia import Wikipedia\nfrom tensorflow_datasets.text.winogrande import Winogrande\nfrom tensorflow_datasets.text.xnli import Xnli\nfrom tensorflow_datasets.text.yelp_polarity import YelpPolarityReviews\n'"
tensorflow_datasets/text/anli.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Commonsense Explanations (CoS-E) Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{Nie2019AdversarialNA,\n    title = ""Adversarial NLI: A New Benchmark for Natural Language Understanding"",\n    author = ""Nie, Yixin and\n      Williams, Adina and\n      Dinan, Emily  and\n      Bansal, Mohit and\n      Weston, Jason and\n      Kiela, Douwe"",\n      year=""2019"",\n    url =""https://arxiv.org/abs/1910.14599""\n}\n""""""\n\n_DESCRIPTION = """"""\nAdversarial NLI (ANLI) is a large-scale NLI benchmark dataset, collected via an\niterative, adversarial human-and-model-in-the-loop procedure.\n""""""\n\n_ANLI_URL = ""https://dl.fbaipublicfiles.com/anli/anli_v0.1.zip""\n\nEXTRACT_PATH_TOKEN = ""anli_v0.1""\n\nVERSION = tfds.core.Version(""0.1.0"")\n\n\nclass AnliConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Anli.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, round_dir=None, **kwargs):\n    """"""BuilderConfig for Anli.\n\n    Args:\n      round_dir: str. The directory for the Anli round to read.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(AnliConfig, self).__init__(\n        version=VERSION,\n        **kwargs)\n    self.round_dir = round_dir\n\n\nclass Anli(tfds.core.GeneratorBasedBuilder):\n  """"""ANLI: Adversarial NLI corpus.""""""\n\n  BUILDER_CONFIGS = [\n      AnliConfig(\n          name=""r1"",\n          description=""Round One"",\n          round_dir=""R1"",\n      ),\n      AnliConfig(\n          name=""r2"",\n          description=""Round Two"",\n          round_dir=""R2"",\n      ),\n      AnliConfig(\n          name=""r3"",\n          description=""Round Three"",\n          round_dir=""R3"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""uid"": tfds.features.Text(),\n            ""context"": tfds.features.Text(),\n            ""hypothesis"": tfds.features.Text(),\n            ""label"": tfds.features.ClassLabel(names=[""e"", ""n"", ""c""]),\n        }),\n        supervised_keys=None,\n        homepage=""https://github.com/facebookresearch/anli"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    dl_dir = dl_manager.download_and_extract(_ANLI_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""filepath"": os.path.join(\n                    dl_dir, EXTRACT_PATH_TOKEN, self._builder_config.round_dir,\n                    ""test.jsonl"")\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""filepath"": os.path.join(\n                dl_dir, EXTRACT_PATH_TOKEN, self._builder_config.round_dir,\n                ""dev.jsonl"")}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""filepath"": os.path.join(\n                    dl_dir, EXTRACT_PATH_TOKEN, self._builder_config.round_dir,\n                    ""train.jsonl"")\n            })\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(filepath) as f:\n      for line in f:\n        element = json.loads(line)\n        yield element[""uid""], {\n            ""uid"": element[""uid""],\n            ""context"": element[""context""],\n            ""hypothesis"": element[""hypothesis""],\n            ""label"": element[""label""],\n        }\n'"
tensorflow_datasets/text/anli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for ANLI dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import anli\n\n\nclass AnliTest(testing.DatasetBuilderTestCase):\n\n  BUILDER_CONFIG_NAMES_TO_TEST = [""r3""]\n\n  DATASET_CLASS = anli.Anli\n  SPLITS = {\n      ""validation"": 2,  # Number of fake validation examples\n      ""test"": 2,  # Number of fake test examples\n      ""train"": 2,  # Number of fake train examples\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/blimp.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BLiMP dataset with minimal pairs of grammatical phenomena in English.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{warstadt2019blimp,\n  title={BLiMP: A Benchmark of Linguistic Minimal Pairs for English},\n  author={Warstadt, Alex and Parrish, Alicia and Liu, Haokun and Mohananey, Anhad and Peng, Wei, and Wang, Sheng-Fu and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1912.00582},\n  year={2019}\n}\n""""""\n\n_DESCRIPTION = """"""\nBLiMP is a challenge set for evaluating what language models (LMs) know about\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\nmorphology, or semantics. The data is automatically generated according to\nexpert-crafted grammars.\n""""""\n\n_PROJECT_URL = \'https://github.com/alexwarstadt/blimp/tree/master/\'\n_DOWNLOAD_URL = \'https://raw.githubusercontent.com/alexwarstadt/blimp/master\'\n\n\nclass BlimpConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Blimp.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, paradigm_uid, **kwargs):\n    """"""BuilderConfig for Blimp.\n\n    Args:\n      paradigm_uid: string, UID of the linguistic paradigm\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name = paradigm_uid\n\n    description = _DESCRIPTION\n    description += (\'This configuration includes the paradigm {}.\').format(name)\n\n    super(BlimpConfig, self).__init__(\n        name=name,\n        description=description,\n        version=tfds.core.Version(\'0.1.0\'),\n        **kwargs)\n\n\nclass Blimp(tfds.core.GeneratorBasedBuilder):\n  """"""Minimal grammatical and ungrammatical pairs of 67 linguistic paradigms.""""""\n\n  all_paradigms = [\n      \'adjunct_island\',\n      \'anaphor_gender_agreement\',\n      \'anaphor_number_agreement\',\n      \'animate_subject_passive\',\n      \'animate_subject_trans\',\n      \'causative\',\n      \'complex_NP_island\',\n      \'coordinate_structure_constraint_complex_left_branch\',\n      \'coordinate_structure_constraint_object_extraction\',\n      \'determiner_noun_agreement_1\',\n      \'determiner_noun_agreement_2\',\n      \'determiner_noun_agreement_irregular_1\',\n      \'determiner_noun_agreement_irregular_2\',\n      \'determiner_noun_agreement_with_adj_2\',\n      \'determiner_noun_agreement_with_adj_irregular_1\',\n      \'determiner_noun_agreement_with_adj_irregular_2\',\n      \'determiner_noun_agreement_with_adjective_1\',\n      \'distractor_agreement_relational_noun\',\n      \'distractor_agreement_relative_clause\',\n      \'drop_argument\',\n      \'ellipsis_n_bar_1\',\n      \'ellipsis_n_bar_2\',\n      \'existential_there_object_raising\',\n      \'existential_there_quantifiers_1\',\n      \'existential_there_quantifiers_2\',\n      \'existential_there_subject_raising\',\n      \'expletive_it_object_raising\',\n      \'inchoative\',\n      \'intransitive\',\n      \'irregular_past_participle_adjectives\',\n      \'irregular_past_participle_verbs\',\n      \'irregular_plural_subject_verb_agreement_1\',\n      \'irregular_plural_subject_verb_agreement_2\',\n      \'left_branch_island_echo_question\',\n      \'left_branch_island_simple_question\',\n      \'matrix_question_npi_licensor_present\',\n      \'npi_present_1\',\n      \'npi_present_2\',\n      \'only_npi_licensor_present\',\n      \'only_npi_scope\',\n      \'passive_1\',\n      \'passive_2\',\n      \'principle_A_c_command\',\n      \'principle_A_case_1\',\n      \'principle_A_case_2\',\n      \'principle_A_domain_1\',\n      \'principle_A_domain_2\',\n      \'principle_A_domain_3\',\n      \'principle_A_reconstruction\',\n      \'regular_plural_subject_verb_agreement_1\',\n      \'regular_plural_subject_verb_agreement_2\',\n      \'sentential_negation_npi_licensor_present\',\n      \'sentential_negation_npi_scope\',\n      \'sentential_subject_island\',\n      \'superlative_quantifiers_1\',\n      \'superlative_quantifiers_2\',\n      \'tough_vs_raising_1\',\n      \'tough_vs_raising_2\',\n      \'transitive\',\n      \'wh_island\',\n      \'wh_questions_object_gap\',\n      \'wh_questions_subject_gap\',\n      \'wh_questions_subject_gap_long_distance\',\n      \'wh_vs_that_no_gap\',\n      \'wh_vs_that_no_gap_long_distance\',\n      \'wh_vs_that_with_gap\',\n      \'wh_vs_that_with_gap_long_distance\',\n  ]\n\n  BUILDER_CONFIGS = [\n      BlimpConfig(paradigm_uid=paradigm) for paradigm in all_paradigms\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'sentence_good\': tfds.features.Text(),\n            \'sentence_bad\': tfds.features.Text(),\n            \'field\': tfds.features.Text(),\n            \'linguistics_term\': tfds.features.Text(),\n            \'UID\': tfds.features.Text(),\n            \'simple_LM_method\': tf.bool,\n            \'one_prefix_method\': tf.bool,\n            \'two_prefix_method\': tf.bool,\n            \'lexically_identical\': tf.bool,\n            \'pair_id\': tf.int32,\n        }),\n        supervised_keys=None,\n        # Homepage of the dataset for documentation\n        homepage=_PROJECT_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    cfg = self.builder_config\n    download_urls = {\n        cfg.name: \'/\'.join([_DOWNLOAD_URL, \'data\', cfg.name + \'.jsonl\'])\n    }\n\n    downloaded_files = dl_manager.download_and_extract(download_urls)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'filepath\': downloaded_files[cfg.name]})\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(filepath, \'rb\') as f:\n      for line in f:\n        line_dict = json.loads(line)\n        id_ = line_dict[\'UID\'] + \'_\' + line_dict[\'pairID\']\n        feats = {\n            \'sentence_good\': line_dict[\'sentence_good\'],\n            \'sentence_bad\': line_dict[\'sentence_bad\'],\n            \'field\': line_dict[\'field\'],\n            \'linguistics_term\': line_dict[\'linguistics_term\'],\n            \'UID\': line_dict[\'UID\'],\n            \'simple_LM_method\': line_dict[\'simple_LM_method\'],\n            \'one_prefix_method\': line_dict[\'one_prefix_method\'],\n            \'two_prefix_method\': line_dict[\'two_prefix_method\'],\n            \'lexically_identical\': line_dict[\'lexically_identical\'],\n            \'pair_id\': line_dict[\'pairID\'],\n        }\n        yield id_, feats\n'"
tensorflow_datasets/text/blimp_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for blimp dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import blimp\n\n\nclass BlimpTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = blimp.Blimp\n  SPLITS = {\n      ""train"": 5,  # Number of fake train example\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""tough_vs_raising_1"": ""tough_vs_raising_1.jsonl"",\n  }\n\n  BUILDER_CONFIG_NAMES_TO_TEST = [""tough_vs_raising_1""]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/c4.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""C4 dataset based on Common Crawl.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.text import c4_utils\n\n_DESCRIPTION = """"""\\\nA colossal, cleaned version of Common Crawl\'s web crawl corpus.\n\nBased on Common Crawl dataset: https://commoncrawl.org\n\nTo generate this dataset, please follow\n[the instructions from t5](https://github.com/google-research/text-to-text-transfer-transformer#c4).\n\nDue to the overhead of cleaning the dataset, it is recommend you prepare it with\na distributed service like Cloud Dataflow. More info at\nhttps://www.tensorflow.org/datasets/beam_datasets.\n""""""\n_CITATION = """"""\n@article{2019t5,\n  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n  journal = {arXiv e-prints},\n  year = {2019},\n  archivePrefix = {arXiv},\n  eprint = {1910.10683},\n}\n""""""\n_VERSION = tfds.core.Version(""2.3.0"", ""Deduplicate lines within a page."")\n\n_SUPPORTED_VERSIONS = [\n    tfds.core.Version(""2.2.1"", ""Update dataset_info.json""),\n    tfds.core.Version(""2.2.0""),\n]\n\n_DOWNLOAD_HOST = ""https://commoncrawl.s3.amazonaws.com""\n_WET_PATH_URL = ""https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-{cc_version}/wet.paths.gz""\n_REALNEWS_DOMAINS_URL = ""https://raw.githubusercontent.com/rowanz/grover/38f7184bd87237ae2d3bc330b99f1e2e246f6d51/realnews/domain_to_allowed_subdomains.json""\n_BADWORDS_URL = ""https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/25e679f03d96baa721cde20db9944649e8d0a844/{lang}""\n_CHECKSUMS_URL = ""https://storage.googleapis.com/tfds-data/manual_checksums/c4.txt""\n_OPENWEBTEXT_URLS_ZIP = ""OpenWebText.zip""\n_OPENWEBTEXT_URLS_URL = ""https://mega.nz/#F!EZZD0YwJ!9_PlEQzdMVLaNdKv_ICNVQ""\n_OPENWEBTEXT_URLS_FILE_PATTERN = ""OpenWebText/Version 1/URLs/*.txt""\n\n_DEFAULT_CC_VERSIONS = (""2019-18"",)  # April 2019\n_DEFAULT_WEBTEXTLIKE_CC_VERSIONS = (  # August 2018 - July 2019\n    ""2018-34"", ""2018-39"", ""2018-43"", ""2018-47"", ""2018-51"",\n    ""2019-04"", ""2019-09"", ""2019-13"", ""2019-18"", ""2019-22"", ""2019-26"", ""2019-30"")\n\n\nclass C4Config(tfds.core.BuilderConfig):\n  """"""BuilderConfig for C4 dataset.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               language,\n               cc_versions=None,\n               clean=True,\n               realnewslike=False,\n               webtextlike=False,\n               **kwargs):\n    """"""BuilderConfig for C4.\n\n    Args:\n      language: string, the language code, or ""all"" to disable language\n        filtering.\n      cc_versions: tuple(string), a collection of versions of Common Crawl to\n        use as the raw source text. Set to None to use defaults.\n      clean: bool, whether to clean the dataset for badwords, duplications, etc.\n      realnewslike: bool, whether to limit to news domains as compiled by\n        RealNews.\n      webtextlike: bool, whether to limit to WebText-like URLs.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name_parts = [language]\n    if cc_versions:\n      name_parts.append(""_"".join(cc_versions))\n    if not clean:\n      name_parts.append(""noclean"")\n    if realnewslike:\n      name_parts.append(""realnewslike"")\n    if webtextlike:\n      name_parts.append(""webtextlike"")\n    name = ""."".join(name_parts)\n    super(C4Config, self).__init__(\n        name=name,\n        version=_VERSION,\n        supported_versions=_SUPPORTED_VERSIONS,\n        **kwargs)\n    self.lang = language\n    self.cc_versions = cc_versions or (\n        _DEFAULT_WEBTEXTLIKE_CC_VERSIONS if webtextlike else\n        _DEFAULT_CC_VERSIONS)\n    self.clean = clean\n    self.realnewslike = realnewslike\n    self.webtextlike = webtextlike\n\n\nclass C4(tfds.core.BeamBasedBuilder):\n  """"""C4 dataset based on Common Crawl.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  For the WebText-like config, you must manually download \'OpenWebText.zip\'\n  (from https://mega.nz/#F!EZZD0YwJ!9_PlEQzdMVLaNdKv_ICNVQ) and the Common Crawl\n  WET files from August 2018 to July 2019\n  (https://commoncrawl.org/the-data/get-started/) and place them in the\n  `manual_dir`.\n  """"""\n\n  BUILDER_CONFIGS = [\n      C4Config(language=""en"", description=""English C4 dataset.""),\n      C4Config(\n          language=""en"",\n          clean=False,\n          description=""Disables all cleaning (deduplication, removal based on bad words, ""\n          ""etc.)""),\n      C4Config(\n          language=""en"",\n          realnewslike=True,\n          description=""Filters from the default config to only include content from the ""\n          ""domains used in the \'RealNews\' dataset (Zellers et al., 2019).""),\n      C4Config(\n          language=""en"",\n          webtextlike=True,\n          description=""Filters from the default config to only include content from the ""\n          ""URLs in OpenWebText (https://github.com/jcpeterson/openwebtext).""),\n  ]\n\n  def _info(self):\n    features = {\n        ""text"": tfds.features.Text(),\n        ""url"": tfds.features.Text(),\n    }\n    if self.version > ""1.0.0"":\n      features.update({\n          ""content-type"": tfds.features.Text(),\n          ""content-length"": tfds.features.Text(),\n          ""timestamp"": tfds.features.Text(),\n      })\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        citation=_CITATION,\n        homepage=\n        ""https://github.com/google-research/text-to-text-transfer-transformer#datasets"",\n    )\n\n  def _split_generators(self, dl_manager, pipeline):\n    dl_manager.download_checksums(_CHECKSUMS_URL)\n\n    # We will automatically down the default CC version(s), but others need to\n    # be manually downloaded.\n    cc_versions = set(self.builder_config.cc_versions)\n    auto_cc_versions = cc_versions & set(_DEFAULT_CC_VERSIONS)\n    manual_cc_versions = cc_versions - set(_DEFAULT_CC_VERSIONS)\n\n    files_to_download = {}\n    files_to_download[""wet_path_urls""] = [\n        _WET_PATH_URL.format(cc_version=cc_version)\n        for cc_version in auto_cc_versions]\n    if self.builder_config.clean:\n      files_to_download[""badwords""] = _BADWORDS_URL.format(\n          lang=self.builder_config.lang)\n    if self.builder_config.realnewslike:\n      files_to_download[""realnews_domains""] = _REALNEWS_DOMAINS_URL\n    file_paths = dl_manager.download_and_extract(files_to_download)\n\n    if self.builder_config.webtextlike:\n      owt_path = os.path.join(dl_manager.manual_dir, _OPENWEBTEXT_URLS_ZIP)\n      if not tf.io.gfile.exists(owt_path):\n        raise AssertionError(\n            ""For the WebText-like config, you must manually download the ""\n            ""following file from {0} and place it in {1}: {2}"".format(\n                _OPENWEBTEXT_URLS_URL, dl_manager.manual_dir,\n                _OPENWEBTEXT_URLS_ZIP))\n      file_paths[""openwebtext_urls_zip""] = dl_manager.extract(owt_path)\n\n    wet_urls = []\n    for wet_path_url in file_paths[""wet_path_urls""]:\n      with tf.io.gfile.GFile(wet_path_url) as f:\n        wet_urls.extend([""%s/%s"" % (_DOWNLOAD_HOST, l.strip()) for l in f])\n    if dl_manager.register_checksums:\n      # Download locally to register checksums.\n      file_paths.update(dl_manager.download({""wet_files"": wet_urls}))\n    else:\n      # Download on the beam workers.\n      file_paths[""wet_urls""] = wet_urls\n      file_paths[""wet_files""] = []\n\n    for cc_version in manual_cc_versions:\n      cc_dir = os.path.join(dl_manager.manual_dir, cc_version)\n      wet_files = tf.io.gfile.glob(os.path.join(cc_dir, ""*.warc.wet.gz""))\n      if not tf.io.gfile.exists(cc_dir):\n        raise AssertionError(\n            ""For the non-default Common Crawl version {0}, you must manually ""\n            ""download the WET files to the directory {1}."".format(\n                cc_version, cc_dir))\n      logging.info(\n          ""Adding %d WET files for manually downloaded version %s."",\n          len(wet_files), cc_version)\n      file_paths[""wet_files""].extend(wet_files)\n\n    page_content_pcollection = self._get_page_content(\n        pipeline, file_paths, dl_manager)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs=dict(\n                split=""train"",\n                page_content=page_content_pcollection,\n                hashed_url_predicate=lambda x: x % 1000 != 0  # 99.9%\n            ),\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=dict(\n                split=""validation"",\n                page_content=page_content_pcollection,\n                hashed_url_predicate=lambda x: x % 1000 == 0  # 0.01%\n            ),\n        ),\n    ]\n\n  def _get_page_content(self, pipeline, file_paths, dl_manager):\n    """"""Build PCollection of un-split page content.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    wet_file_paths = (\n        pipeline |\n        ""create_wet_files"" >> beam.Create(file_paths[""wet_files""]))\n    if ""wet_urls"" in file_paths:\n      def download_url(url, downloader):\n        return downloader.download({url: url})[url]\n      dl_wet_file_paths = (\n          pipeline\n          | ""create_wet_urls"" >> beam.Create(file_paths[""wet_urls""])\n          | beam.Map(download_url, downloader=dl_manager))\n      wet_file_paths = (wet_file_paths, dl_wet_file_paths) | beam.Flatten()\n\n    # Parse WET files and filter by length.\n    # Output: url, text\n    page_content = (\n        wet_file_paths\n        | beam.FlatMap(c4_utils.split_wet_file)\n        | beam.Filter(c4_utils.is_valid_length))\n\n    # Optionally filter for RealNews domains.\n    # Output: url, text\n    if self.builder_config.realnewslike:\n      with tf.io.gfile.GFile(file_paths[""realnews_domains""]) as f:\n        realnews_domains = json.load(f)\n      page_content = (\n          page_content\n          | beam.Filter(c4_utils.is_realnews_domain, realnews_domains))\n\n    # Normalize and deduplicate by URL.\n    # Output: url, text\n    page_content = (\n        page_content\n        | ""normalize_url"" >> beam.Map(c4_utils.normalize_url)\n        | ""group_url"" >> beam.GroupByKey()\n        | beam.Map(c4_utils.dedupe_urls))\n\n    # Optionally filter for WebText-like URLs.\n    # Output: url, text\n    if self.builder_config.webtextlike:\n      webtextlike_urls = (\n          pipeline\n          | ""read_webtextlike_urls"" >>\n          beam.io.ReadFromText(\n              os.path.join(file_paths[""openwebtext_urls_zip""],\n                           _OPENWEBTEXT_URLS_FILE_PATTERN))\n          | ""add_dummy_page"" >> beam.Map(lambda x: (x, """"))\n          | ""normal_webtext_url"" >> beam.Map(c4_utils.normalize_url))\n      page_content = (\n          {\n              ""text"": page_content,\n              ""webtextlike_urls"": webtextlike_urls\n          }\n          | ""group_webtextlike_urls"" >> beam.CoGroupByKey()\n          | beam.FlatMap(c4_utils.filter_by_webtextlike))\n\n    # Optionally clean pages of badwords, boilerpolate text, and duplicate\n    # spans of sentences.\n    # Output: url, text\n    if self.builder_config.clean:\n      with tf.io.gfile.GFile(file_paths[""badwords""]) as f:\n        badwords = [l.strip() for l in f]\n      page_content = (\n          page_content\n          | ""clean_pages"" >> beam.FlatMap(c4_utils.get_clean_page_fn(badwords)))\n      page_content = c4_utils.remove_duplicate_text(page_content)\n\n    # Optionally filter out non-`language` pages. We do this after cleaning\n    # since it may change the predominate language.\n    if self.builder_config.lang != ""all"":\n      page_content |= beam.Filter(\n          c4_utils.is_language, language=self.builder_config.lang)\n\n    return page_content\n\n  def _build_pcollection(\n      self, unused_pipeline, split, page_content, hashed_url_predicate):\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _emit_examples(el):\n      c4_utils.get_counter_inc_fn(split)(""examples"")\n      _, features = el\n      return features[""url""], {\n          ""url"": features[""url""],\n          ""text"": features[""text""],\n          ""content-type"": features[""content-type""],\n          ""content-length"": features[""content-length""],\n          ""timestamp"": features[""timestamp""]\n      }\n    return (page_content\n            | beam.Filter(\n                c4_utils.get_hashed_url_filter_fn(hashed_url_predicate))\n            | beam.Map(_emit_examples))\n'"
tensorflow_datasets/text/c4_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for c4 dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import c4\n\n\nclass C4Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = c4.C4\n  # 10k shards take make the test too slow.\n  c4._DEFAULT_NUM_SHARDS = 1\n  # GzipFile + GFile and TextIOWrapper are broken for py2.\n  BUILDER_CONFIG_NAMES_TO_TEST = [""en""] if six.PY3 else []\n\n  DL_EXTRACT_RESULT = {\n      ""wet_path_urls"": [""wet_urls.txt""],\n      ""wet_files"": [""cc_0.warc.wet.gz"", ""cc_1.warc.wet.gz""],\n      ""https://commoncrawl.s3.amazonaws.com/cc_0.warc.wet.gz"":\n          ""cc_0.warc.wet.gz"",\n      ""https://commoncrawl.s3.amazonaws.com/cc_1.warc.wet.gz"":\n          ""cc_1.warc.wet.gz"",\n      ""badwords"": ""badwords.txt"",\n  }\n  SPLITS = {\n      ""train"": 1,\n      ""validation"": 1,\n  }\n\n\nclass C4NoCleanTest(C4Test):\n  # GzipFile + GFile and TextIOWrapper are broken for py2.\n  BUILDER_CONFIG_NAMES_TO_TEST = [""en.noclean""] if six.PY3 else []\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/c4_utils.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for generating the C4 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport gzip\nimport hashlib\nimport io\nimport re\nimport threading\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# WET file constants\n_PAGE_DELIMITER = ""WARC/1.0""\n_URL_KEY = ""WARC-Target-URI:""\n_URL_DATE = ""WARC-Date:""\n_CONTENT_TYPE = ""Content-Type:""\n_CONTENT_LEN = ""Content-Length:""\n_METADATA_PREFIXES = (""WARC"", ""CONTENT-"", ""Content-"")\n\n# Filters\n_MIN_WORDS_PER_LINE = 5\n_MIN_NUM_SENTENCES = 3\n_MAX_WORD_LENGTH = 1000\n_END_MARKS = (""."", ""?"", ""!"", ""\\"""")\n_ELLIPSIS = ""...""\n_POLICY_SUBSTRINGS = [\n    ""terms of use"", ""privacy policy"", ""cookie policy"", ""uses cookies"",\n    ""use of cookies"", ""use cookies""]\n\n# Memoized sentence tokenizer.\n_SENTENCE_TOKENIZER = None\n\n\ndef get_counter_inc_fn(namespace):\n  def counter_inc_fn(counter, amt=1):\n    tfds.core.lazy_imports.apache_beam.metrics.Metrics.counter(\n        namespace, counter).inc(amt)\n  return counter_inc_fn\n\n\ndef get_hashed_url_filter_fn(predicate_fn):\n  def filter_fn(el):\n    url, _ = el\n    val = int(\n        hashlib.md5(tf.compat.as_text(url).encode(""utf-8"")).hexdigest(), 16)\n    return predicate_fn(val)\n  return filter_fn\n\n\ndef _load_sentence_tokenizer():\n  """"""Returns a sentence tokenization function.""""""\n  nltk = tfds.core.lazy_imports.nltk\n  # Lock to avoid a race-condition in the creation of the download directory.\n  with threading.Lock():\n    nltk.download(""punkt"")\n    return nltk.data.load(""nltk:tokenizers/punkt/english.pickle"")\n\n\n\n\ndef _get_sentences(text):\n  global _SENTENCE_TOKENIZER\n  if not _SENTENCE_TOKENIZER:\n    _SENTENCE_TOKENIZER = _load_sentence_tokenizer()\n  return list(_SENTENCE_TOKENIZER.tokenize(tf.compat.as_text(text)))\n\n\ndef _get_sentences_by_line(text, lower=False):\n  sentences = []\n  for line in text.splitlines():\n    sentences.append([\n        s.lower() if lower else s for s in _get_sentences(line)\n    ])\n  return sentences\n\n\ndef is_language(page, language, min_probability=0.99):\n  """"""Returns True iff text is in `language` with at least `min_probability`.""""""\n  unused_url, features = page\n  text = features[""text""]\n\n  counter_inc_fn = get_counter_inc_fn(""detected-lang"")\n\n  langdetect = tfds.core.lazy_imports.langdetect\n  # Make langdetect predictions deterministic.\n  langdetect.DetectorFactory.seed = 0\n  try:\n    predictions = langdetect.detect_langs(text)\n  except langdetect.lang_detect_exception.LangDetectException:\n    counter_inc_fn(""langdetect-exception"")\n    return False\n  if not predictions:\n    counter_inc_fn(""page-filtered-nolangpredictions"")\n    return False\n  best_prediction = predictions[0]\n  if best_prediction.prob < min_probability:\n    counter_inc_fn(""page-filtered-lowlangdetectconf"")\n    return False\n  if best_prediction.lang != language:\n    counter_inc_fn(""page-filtered-ignoredlang"")\n    counter_inc_fn(""page-filtered-ignoredlang-%s"" % (best_prediction.lang))\n    return False\n  counter_inc_fn(""page-emited-%s"" % best_prediction.lang)\n  return True\n\n\ndef get_clean_page_fn(badwords=None):\n  """"""Returns `clean_page` with pre-compiled badword and citation regexes.""""""\n  # Used to filter citation from Wikipedia pages (among others).\n  citation_regex = re.compile(r""\\[\\d*\\]|\\[edit\\]|\\[citation needed\\]"")\n  if badwords:\n    badwords_regex = re.compile(\n        ""[^a-z]({})[^a-z]"".format(""|"".join(badwords or [])))\n  else:\n    badwords_regex = None\n  return functools.partial(\n      clean_page, citation_regex=citation_regex, badwords_regex=badwords_regex)\n\n\ndef clean_page(url_and_features,\n               citation_regex,\n               badwords_regex=None,\n               counter_inc_fn=None,\n               min_words_per_line=_MIN_WORDS_PER_LINE,\n               min_num_sentences=_MIN_NUM_SENTENCES,\n               max_word_length=_MAX_WORD_LENGTH):\n  """"""Cleans a CommonCrawl page, yielding nothing if it should be skipped.\n\n  Cleaning removes lines with no end marks or with too few words. After line\n  filtering, pages are filtered out if they have too few sentences based on a\n  simple count of end marks.\n\n  Args:\n    url_and_features: tuple(string, dict), the url and features of the page.\n    citation_regex: Regex to use for finding Wikipedia-like citations to filter.\n    badwords_regex: Regex to use for finding badwords. Default None, which means\n      don\'t apply badwords filtering.\n    counter_inc_fn: function, a function taking the name of a counter to be\n      incremented and the (optional) amount. Defaults to a beam Metric counter.\n    min_words_per_line: int, the minimum number of words a line needs to not be\n      removed.\n    min_num_sentences: int, the minimum number of sentences a page needs to not\n      be skipped.\n    max_word_length: int, the maximum number of characters allowed in a word.\n      Lines containing a word with too many characters are removed.\n  Yields:\n    The url and cleaned text for the page.\n  """"""\n  url, features = url_and_features\n  text = features[""text""]\n\n  if not counter_inc_fn:\n    counter_inc_fn = get_counter_inc_fn(""clean-page"")\n\n  lines = text.splitlines()\n  valid_lines = []\n  num_sentences = 0\n\n  def line_has_too_long_word(line):\n    for word in line.split():\n      if len(word) > max_word_length:\n        return True\n    return False\n\n  for line in lines:\n    line = line.strip()\n    if line_has_too_long_word(line):\n      counter_inc_fn(""lines-with-too-long-word"")\n      continue\n    line = citation_regex.sub("""", line)\n    if not line.endswith(_END_MARKS) or line.endswith(_ELLIPSIS):\n      counter_inc_fn(""lines-no-endmark"")\n      continue\n    if len(line.split()) < min_words_per_line:\n      counter_inc_fn(""lines-too-short"")\n      continue\n    line_lower = line.lower()\n    # Remove documents which contain lorem ipsum\n    if ""lorem ipsum"" in line_lower:\n      counter_inc_fn(""filtered-page-loremipsum"")\n      return\n    # Remove ""javascript must be enabled"" notices\n    if ""javascript"" in line_lower:\n      counter_inc_fn(""lines-javascript"")\n      continue\n    # Remove docs which probably contain javascript code\n    if ""{"" in line:\n      counter_inc_fn(""filtered-page-squigglybracket"")\n      return\n    # Remove policy lines\n    if any(p in line_lower for p in _POLICY_SUBSTRINGS):\n      counter_inc_fn(""lines-policy"")\n      continue\n    # If any badword appears on its own in the line, skip this doc\n    if badwords_regex:\n      badwords_found = badwords_regex.search(line_lower)\n      if badwords_found is not None:\n        counter_inc_fn(""filtered-page-badword"")\n        return\n    num_sentences += len(_get_sentences(line))\n    valid_lines.append(line)\n    counter_inc_fn(""lines-valid"")\n\n  if num_sentences < min_num_sentences:\n    counter_inc_fn(""filtered-page-toofewsentences"")\n    return\n  counter_inc_fn(""emitted-clean-pages"")\n  features[""text""] = ""\\n"".join(valid_lines).strip()\n  yield url, features\n\n\ndef _hash_line(line):\n  m = hashlib.md5()\n  m.update(tf.compat.as_text(line).encode(""utf-8"").strip().lower())\n  return m.hexdigest()\n\n\ndef _emit_url_to_lines(page):\n  """"""Emits url to all (lower-cased, hashed) lines.""""""\n  url, features = page\n  text = features[""text""]\n  for line in text.split(""\\n""):\n    yield _hash_line(line), url\n\n\ndef _emit_line_to_urls(el, counter_inc_fn):\n  """"""Emits (hashed) line to all but one url.""""""\n  line, urls = el\n  # Materialize urls as a list.\n  urls = list(urls)\n  # Hash urls and sort to have a consistent, but unbiased, selection when the\n  # same urls exist for multiple lines.\n  skip_url = min(\n      urls,\n      key=lambda x: hashlib.md5(tf.compat.as_text(x).encode(""utf-8"")).\n      hexdigest())\n  for url in urls:\n    if url != skip_url:\n      yield url, line\n  counter_inc_fn(""emitted-line-duplicate"", amt=len(urls)-1)\n\n\ndef _remove_lines_from_text(\n    el, counter_inc_fn, min_num_sentences=_MIN_NUM_SENTENCES):\n  """"""Removes matching lines from the page.\n\n  Process the result of a join containing a single value for \'features\' and zero\n  or more values for \'lines\'. Each value in \'lines\' is a lower-cased, hashed\n  line.\n\n  If a line has fewer sentences than `max_window_size`, the full line is\n  compared for a match.\n\n  Args:\n    el: `(string, {\'features\': features_dict, \'lines\': [string]})`,\n      element containing the result of a join on key with both the page text\n      and lower-cased, hashed lines to remove.\n    counter_inc_fn: function, a function taking the name of a counter to be\n      incremented and the (optional) amount.\n    min_num_sentences: int, the minimum number of sentences a page needs to not\n      be skipped.\n\n  Yields:\n    url: The URL of the page.\n    features: The page features with lines removed from text.\n  """"""\n  url, join_values = el\n  features = join_values[""features""]\n\n  assert len(features) == 1, ""Invalid page count (%d) for %s"" % (\n      len(features), url)\n  features = features[0]\n  text = features[""text""]\n  lines_to_remove = set(join_values[""lines""])\n  new_lines = []\n  hashed_lines = set()\n  for line in text.split(""\\n""):\n    hashed_line = _hash_line(line)\n    if hashed_line in lines_to_remove:\n      counter_inc_fn(""filtered-lines-duplicate"")\n    elif hashed_line not in hashed_lines:\n      new_lines.append(line)\n      hashed_lines.add(hashed_line)\n  new_text = ""\\n"".join(new_lines)\n  if len(_get_sentences(new_text)) < min_num_sentences:\n    counter_inc_fn(""filtered-doc-toofewsentences"")\n    return\n  new_features = features.copy()\n  new_features[""text""] = new_text\n  yield (url, new_features)\n\n\ndef remove_duplicate_text(pages):\n  """"""Utility to remove duplicate lines across text documents.""""""\n  # Output: url, lines\n  beam = tfds.core.lazy_imports.apache_beam\n  counter_inc_fn = get_counter_inc_fn(""dedupe-lines"")\n  lines_to_remove = (\n      pages\n      | beam.FlatMap(_emit_url_to_lines)\n      | ""group_sentences"" >> beam.GroupByKey()\n      | beam.FlatMap(_emit_line_to_urls, counter_inc_fn=counter_inc_fn))\n\n  # Output: url, text\n  final_docs = ({\n      ""features"": pages,\n      ""lines"": lines_to_remove\n  }\n                | ""group_features_and_lines_by_url"" >> beam.CoGroupByKey()\n                | beam.FlatMap(\n                    _remove_lines_from_text,\n                    counter_inc_fn=counter_inc_fn))\n\n  return final_docs\n\n\ndef split_wet_file(wet_file_path, counter_inc_fn=None):\n  """"""Split a WET file into separate pages.""""""\n  logging.info(""Splitting file: %s"", wet_file_path)\n  if not counter_inc_fn:\n    counter_inc_fn = get_counter_inc_fn(""split-wet-file"")\n  counter_inc_fn(""wet-file"")\n\n  with tf.io.gfile.GFile(wet_file_path, ""rb"") as f, gzip.GzipFile(\n      fileobj=f) as g:\n    url = None\n    content = None\n    content_len = None\n    content_type = None\n    timestamp = None\n\n    def _maybe_get_page():\n      """"""Generate a (url, {features}) page.""""""\n      if not url and url is not None:\n        counter_inc_fn(""page-filtered-nourl"")\n      if not content and content is not None:\n        counter_inc_fn(""page-filtered-nocontent"")\n      if not content_type and content_type is not None:\n        counter_inc_fn(""page-nocontenttype"")\n      if not content_len and content_len is not None:\n        counter_inc_fn(""page-nocontentlen"")\n      if not timestamp and timestamp is not None:\n        counter_inc_fn(""page-notimestamp"")\n      if content and url:\n        counter_inc_fn(""page-emitted"")\n        return (url, {\n            ""text"": ""\\n"".join(content),\n            ""content-type"": content_type,\n            ""content-length"": content_len,\n            ""timestamp"": timestamp,\n            ""url"": url\n        })\n      return None\n\n    for line in io.TextIOWrapper(g, encoding=""utf-8""):  # pytype: disable=wrong-arg-types\n      line = line.strip()\n      if not line:\n        continue\n      if line == _PAGE_DELIMITER:\n        page = _maybe_get_page()\n        if page:\n          yield page\n        url = """"\n        content = []\n        content_len = """"\n        content_type = """"\n        timestamp = """"\n\n      if line.startswith(_URL_KEY):\n        url = line[len(_URL_KEY):].strip()\n\n      if line.startswith(_URL_DATE):\n        timestamp = line[len(_URL_DATE):].strip()\n\n      if line.startswith(_CONTENT_TYPE):\n        content_type = line[len(_CONTENT_TYPE):].strip()\n\n      if line.startswith(_CONTENT_LEN):\n        content_len = line[len(_CONTENT_LEN):].strip()\n\n      if line.startswith(_METADATA_PREFIXES):\n        continue\n\n      content.append(line)  # pytype: disable=attribute-error\n\n    page = _maybe_get_page()\n    if page:\n      yield page\n\n\ndef dedupe_urls(el):\n  """"""Returns the first value for a given URL.""""""\n  counter_inc_fn = get_counter_inc_fn(""dedupe-urls"")\n  url, vals = el\n  cnt = 0\n  v = None\n  for v in vals:\n    cnt += 1\n  counter_inc_fn(""filtered-url-duplicate"", cnt - 1)\n  counter_inc_fn(""unique-url"")\n  return url, v\n\n\ndef is_valid_length(el, max_length=1.9e5):\n  """"""Returns False iff page\'s text is too long.""""""\n  counter_inc_fn = get_counter_inc_fn(""is-valid-length"")\n  _, page = el\n  if len(page[""text""]) > max_length:\n    counter_inc_fn(""filtered-page-contenttoolong"")\n    return False\n  counter_inc_fn(""valid-length"")\n  return True\n\n\ndef is_realnews_domain(el, realnews_domains):\n  """"""Returns False iff page\'s (sub)domain is not allowed.""""""\n  counter_inc_fn = get_counter_inc_fn(""is-realnews-domain"")\n  url, _ = el\n  ext = tfds.core.lazy_imports.tldextract.extract(url)\n  main_domain = ext.domain + ""."" + ext.suffix\n  if main_domain not in realnews_domains:\n    counter_inc_fn(""filtered-url-invaliddomain"")\n    return False\n  allowed_subdomains = realnews_domains[main_domain]\n  if (isinstance(allowed_subdomains, list) and\n      ext.subdomain not in allowed_subdomains):\n    counter_inc_fn(""filtered-url-invalidsubdomain"")\n    return False\n  counter_inc_fn(""realnews-domain"")\n  return True\n\n\ndef filter_by_webtextlike(el):\n  """"""Yields only pages with a matching WebText-like URL.""""""\n  counter_inc_fn = get_counter_inc_fn(""filter-by-webtextlike"")\n  url, join_values = el\n  text = join_values[""text""]\n  webtextlike = join_values[""webtextlike_urls""]\n  if not webtextlike:\n    counter_inc_fn(""filtered-url-notwebtextlike"")\n    return\n  if not text:\n    counter_inc_fn(""missing-webtextlike"")\n    return\n  assert len(text) == 1\n  counter_inc_fn(""found-webtextlike"")\n  yield url, text[0]\n\n\ndef normalize_url(el):\n  url, val = el\n  url = tf.compat.as_text(url)\n  url = re.sub(r""https?:\\/\\/(www\\.)?"", """", url)\n  url = re.sub(r""\\?(utm_|ref|feed).*"", """", url)\n  url = url.rstrip(""/"")\n  return url, val\n'"
tensorflow_datasets/text/c4_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for c4_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\n\nimport six\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.lazy_imports_lib import lazy_imports\nfrom tensorflow_datasets.text import c4_utils\n\nEN_TEXT = """"""This line has enough words and ends in punctuation, Dr. Roberts!\nEconomic History | All Institutions | Open Access Articles | Digital Commons Network\n\\""Open Access. Powered by Scholars. Published by Universities.\\""\nDigital Commons Network\xe2\x84\xa2/ Social and Behavioral Sciences...\nToo few words.\nYou need to enable javascript in your browser in order to see this page.\nYou have JavaScript disabled and that means you can\'t see this page.\nAdam Roberts has a cookie policy: always eat them.\nColin has a privacy policy: don\'t share people\'s secrets.\nYou\'d better follow our terms of use!\n""""""\n\nEXPECTED_CLEAN_EN = """"""This line has enough words and ends in punctuation, Dr. Roberts!\n\\""Open Access. Powered by Scholars. Published by Universities.\\""""""""\n\nFAKE_CONTENT_LENGTH = ""5793""\nFAKE_CONTENT_TYPE = ""text/plain""\nFAKE_TIMESTAMP = ""2019-04-24T09:23:58Z""\n\n\ndef _get_counters():\n  counters = collections.defaultdict(int)\n\n  def counter_inc_fn(c, amt=1):\n    counters[c] += amt\n\n  return counters, counter_inc_fn\n\n\nclass C4UtilsTest(testing.TestCase):\n\n  def run_clean_page(self, features, badwords=None):\n    counters, counter_inc_fn = _get_counters()\n    results = list(\n        c4_utils.get_clean_page_fn(badwords)(\n            url_and_features=(""url"", features), counter_inc_fn=counter_inc_fn))\n    self.assertLessEqual(len(results), 1)\n    result = None if not results else results[0][1]\n    return result, counters\n\n  def test_clean_page(self):\n    clean_en, counters = self.run_clean_page({\n        ""text"": EN_TEXT,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP\n    })\n    self.assertEqual(EXPECTED_CLEAN_EN, clean_en[""text""])\n    self.assertEqual(\n        {\n            ""lines-valid"": 2,\n            ""lines-too-short"": 1,\n            ""lines-no-endmark"": 2,\n            ""lines-javascript"": 2,\n            ""lines-policy"": 3,\n            ""emitted-clean-pages"": 1\n        }, dict(counters))\n\n  def test_clean_page_toofewsentences(self):\n    text_with_toofewsentences = """"""This first line has one sentence.\nThis line looks like it has three sentences...but it\'s actually just 1.""""""\n    clean_en, counters = self.run_clean_page({\n        ""text"": text_with_toofewsentences,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP\n    })\n    self.assertEqual(None, clean_en)\n    self.assertEqual({\n        ""lines-valid"": 2,\n        ""filtered-page-toofewsentences"": 1\n    }, dict(counters))\n\n  def test_clean_page_squigglybracket(self):\n    text_that_is_actually_code = """"""This page starts out with some text.\nEverything looks good at first, since these are sentences.\nBut then, all of a sudden, there\'s a bunch of code like the next block.\nfn foo(a) { bar = a + 10; }.""""""\n    clean_en, counters = self.run_clean_page({\n        ""text"": text_that_is_actually_code,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP,\n    })\n    self.assertEqual(None, clean_en)\n    self.assertEqual({\n        ""filtered-page-squigglybracket"": 1,\n        ""lines-valid"": 3\n    }, dict(counters))\n\n  def test_clean_page_loremipsum(self):\n    lorem_ipsum_text = """"""Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nUt enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\nExcepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.""""""\n    clean_en, counters = self.run_clean_page({\n        ""text"": lorem_ipsum_text,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP\n    })\n    self.assertEqual(None, clean_en)\n    self.assertEqual({""filtered-page-loremipsum"": 1}, dict(counters))\n\n  def test_clean_page_badwords(self):\n    padding_text = """"""This page starts out with some text.\nEverything looks good at first, since these are sentences.\nBut then, all of a sudden, there\'s a badword... or not?\n""""""\n    final_sentences = [\n        # Make sure ass in a longer word doesn\'t cause false-positive\n        ""I asked my friend for assistance polishing my cutlass."",\n        # Check that a standard appearance of a badword triggers\n        ""He took the saddle and put it on his ass in preparation for travel."",\n        # Make sure lowercasing works\n        ""Ass is one of several species of small, horse-like animals.""\n        # Make sure it will still trigger when surrounded by punctuation.\n        ""Donkey is one synonym for the word \\""ass\\"".""\n    ]\n    outputs_should_be_none = [False, True, True, True]\n    expected_counters = [\n        {\n            ""lines-valid"": 4,\n            ""emitted-clean-pages"": 1\n        },\n        {\n            ""lines-valid"": 3,\n            ""filtered-page-badword"": 1\n        },\n        {\n            ""lines-valid"": 3,\n            ""filtered-page-badword"": 1\n        },\n        {\n            ""lines-valid"": 3,\n            ""filtered-page-badword"": 1\n        },\n    ]\n    for final_sentence, output_should_be_none, expected_counter in zip(\n        final_sentences, outputs_should_be_none, expected_counters):\n      text = padding_text + final_sentence\n      out, counters = self.run_clean_page(\n          {\n              ""text"": text,\n              ""content-type"": FAKE_CONTENT_TYPE,\n              ""content-length"": FAKE_CONTENT_LENGTH,\n              ""timestamp"": FAKE_TIMESTAMP\n          },\n          badwords=[""ass""])\n      if output_should_be_none:\n        self.assertEqual(None, out)\n      else:\n        self.assertEqual(text, out[""text""])\n      self.assertEqual(expected_counter, dict(counters))\n\n  def test_clean_page_citations(self):\n    text = """"""This page has some text.\nSome lines don\'t end with punctuation\nAnd some of these lines end with citations.[3]\nOr have requested citations[citation needed]. Or the option to edit.[edit]\n""""""\n    expected_clean_text = """"""This page has some text.\nAnd some of these lines end with citations.\nOr have requested citations. Or the option to edit.""""""\n    expected_counters = {\n        ""lines-valid"": 3,\n        ""lines-no-endmark"": 1,\n        ""emitted-clean-pages"": 1\n    }\n    out, counters = self.run_clean_page({\n        ""text"": text,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP\n    })\n    self.assertEqual(expected_clean_text, out[""text""])\n    self.assertEqual(expected_counters, dict(counters))\n\n  def test_clean_page_policy(self):\n    text = """"""This page has with some text. So, that\'s good!\nBut at the end it has some polciy lines.\nThis line mentions the Terms of Use.\nThis line should be okay.\nThe privacy policy is mentioned in this line.\nLet\'s talk about the Cookie Policy now.\n""""""\n    expected_clean_text = """"""This page has with some text. So, that\'s good!\nBut at the end it has some polciy lines.\nThis line should be okay.""""""\n    expected_counters = {\n        ""lines-valid"": 3,\n        ""lines-policy"": 3,\n        ""emitted-clean-pages"": 1\n    }\n    out, counters = self.run_clean_page({\n        ""text"": text,\n        ""content-type"": FAKE_CONTENT_TYPE,\n        ""content-length"": FAKE_CONTENT_LENGTH,\n        ""timestamp"": FAKE_TIMESTAMP\n    })\n    self.assertEqual(expected_clean_text, out[""text""])\n    self.assertEqual(expected_counters, dict(counters))\n\n  def test_remove_duplicate_text(self):\n    import apache_beam.testing.util as beam_testing_util  # pylint:disable=g-import-not-at-top\n    beam = lazy_imports.apache_beam\n    input_urls_and_text = [\n        (""url/1-0"",\n         ""This is a duplicated line.\\nThis is a unique line.\\n""\n         ""This one comes first and so it stays.\\n""\n         ""This one is duplicate within the page so the others are removed.\\n""\n         ""Here is a sentence between the duplicates.\\n""\n         ""This one is duplicate within the page so the others are removed.\\n""\n         ""this One is Duplicate WITHIN the page so the others are removed. ""),\n        (""url/2-1"",\n         ""This is 2nd unique line.\\nThis one comes second so it is removed ""\n         ""even though the capitalizaiton is different.\\n""\n         ""this is a Duplicated line. ""),\n        (""url/3-4"",\n         ""This is a 3rd unique line.\\nThis is a duplicated line.\\n""\n         ""This one comes third and so it is removed. But the page stays ""\n         ""because there are still 3 sentences remaining.""),\n        (""url/4-4"",\n         ""This is a 4th unique line.\\nThis is a duplicated line.\\n""\n         ""This one comes third and so it is removed, and the page is too ""\n         ""since there aren\'t enough sentences left.""),\n    ]\n    expected_urls_and_text = [\n        (""url/1-0"",\n         ""This is a duplicated line.\\nThis is a unique line.\\n""\n         ""This one comes first and so it stays.\\n""\n         ""This one is duplicate within the page so the others are removed.\\n""\n         ""Here is a sentence between the duplicates.""),\n        (""url/3-4"",\n         ""This is a 3rd unique line.\\n""\n         ""This one comes third and so it is removed. But the page stays ""\n         ""because there are still 3 sentences remaining.""),\n    ]\n    with beam.Pipeline() as pipeline:\n      pages = pipeline | beam.Create([\n          (url, {""text"": text}) for url, text in input_urls_and_text\n      ])\n      deduped_pages = c4_utils.remove_duplicate_text(pages)\n      beam_testing_util.assert_that(\n          deduped_pages,\n          beam_testing_util.equal_to([\n              (url, {""text"": text}) for url, text in expected_urls_and_text\n          ]))\n\n  def test_split_wet_file(self):\n    if six.PY2:\n      # GzipFile + GFile and TextIOWrapper are broken for py2.\n      return\n    counters, counter_inc_fn = _get_counters()\n    list(\n        c4_utils.split_wet_file(\n            os.path.join(testing.fake_examples_dir(), ""c4"", ""cc_0.warc.wet.gz""),\n            counter_inc_fn=counter_inc_fn))\n    self.assertEqual(\n        {\n            ""wet-file"": 1,\n            ""page-emitted"": 2,\n            ""page-filtered-nourl"": 1,\n        }, dict(counters))\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/cfq.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CFQ (Compositional Freebase Question) dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport re\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{Keysers2020,\n  title={Measuring Compositional Generalization: A Comprehensive Method on\n         Realistic Data},\n  author={Daniel Keysers and Nathanael Sch\\""{a}rli and Nathan Scales and\n          Hylke Buisman and Daniel Furrer and Sergii Kashubin and\n          Nikola Momchev and Danila Sinopalnikov and Lukasz Stafiniak and\n          Tibor Tihon and Dmitry Tsarkov and Xiao Wang and Marc van Zee and\n          Olivier Bousquet},\n  booktitle={ICLR},\n  year={2020},\n  url={https://arxiv.org/abs/1912.09713.pdf},\n}\n""""""\n\n_DESCRIPTION = """"""\nThe CFQ dataset (and it\'s splits) for measuring compositional generalization.\n\nSee https://arxiv.org/abs/1912.09713.pdf for background.\n\nA note about the validation set: Since it has the same distribution as the test\nset and we are interested in measuring the compositional generalization of a\n*model* with respect to an *unknown* test distribution we suggest that any\ntuning should be done on a subset of the train set only (see section 5.1 of the\npaper).\n\nExample usage:\n\n```\ndata = tfds.load(\'cfq/mcd1\')\n```\n""""""\n\n_DATA_URL = \'https://storage.googleapis.com/cfq_dataset/cfq.tar.gz\'\n\n_RANDOM_SEEDS = [\n    \'4_0\', \'4_42\', \'4.5_0\', \'4.5_45\', \'5_50\', \'5_50\', \'5.5_0\', \'5.5_55\', \'6_0\'\n]\n\n\nclass CFQConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for CFQ splits.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               name=None,\n               directory=None,\n               compound_divergence=None,\n               random_seed=None,\n               **kwargs):\n    """"""BuilderConfig for CFQ.\n\n    Can be constucted in two ways:\n    1. With directory and name in which case these determine the split file.\n    2. With compound_divergence (and optionally random_seed).\n\n    Args:\n      name: Unique name of the split.\n      directory: Which subdirectory to read the split from.\n      compound_divergence: The desired compound divergence.\n      random_seed: The random seed. Can be either the specific random-seeds used\n        to generate the split as string or an index in the range [1, 9].\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if compound_divergence is not None:\n      if random_seed is None:\n        random_seed_index = 1\n        random_seed = _RANDOM_SEEDS[0]\n      elif random_seed in range(0, 10):\n        random_seed_index = random_seed\n        random_seed = _RANDOM_SEEDS[random_seed - 1]\n      elif random_seed in _RANDOM_SEEDS:\n        random_seed_index = _RANDOM_SEEDS.index(random_seed)\n      else:\n        raise ValueError(\'Invalid random seed: %s\' % random_seed)\n      directory = \'splits/all_divergence_splits\'\n      split_name = \'divergence_split_s0.4_d%s_r%s\' % (compound_divergence,\n                                                      random_seed)\n      name = \'cd%s_r%s\' % (compound_divergence, random_seed_index)\n    else:\n      directory = \'splits\'\n      split_name = name\n    super(CFQConfig, self).__init__(\n        name=name,\n        version=tfds.core.Version(\'1.2.0\'),\n        description=_DESCRIPTION,\n        **kwargs)\n    self.split_file = os.path.join(directory, split_name + \'.json\')\n\n\n_QUESTION = \'question\'\n_QUERY = \'query\'\n_QUESTION_FIELD = \'questionPatternModEntities\'\n_QUERY_FIELD = \'sparqlPatternModEntities\'\n\n\ndef _generate_compound_divergence_builder_configs():\n  """"""Generate configs for different compound divergences and random seeds.""""""\n  configs = []\n  for compound_divergence in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 1]:\n    for random_seed in range(1, 10):\n      configs.append(\n          CFQConfig(\n              compound_divergence=compound_divergence, random_seed=random_seed))\n  return configs\n\n\nclass CFQ(tfds.core.GeneratorBasedBuilder):\n  """"""CFQ task / splits.""""""\n\n  BUILDER_CONFIGS = [\n      CFQConfig(name=\'mcd1\'),\n      CFQConfig(name=\'mcd2\'),\n      CFQConfig(name=\'mcd3\'),\n      CFQConfig(name=\'question_complexity_split\'),\n      CFQConfig(name=\'question_pattern_split\'),\n      CFQConfig(name=\'query_complexity_split\'),\n      CFQConfig(name=\'query_pattern_split\'),\n      CFQConfig(name=\'random_split\'),\n  ] + _generate_compound_divergence_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _QUESTION: tfds.features.Text(),\n            _QUERY: tfds.features.Text(),\n        }),\n        supervised_keys=(_QUESTION, _QUERY),\n        homepage=\'https://github.com/google-research/google-research/tree/master/cfq\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    data_dir = dl_manager.download_and_extract(_DATA_URL)\n    data_dir = os.path.join(data_dir, \'cfq\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'base_directory\': data_dir,\n                \'splits_file\': self.builder_config.split_file,\n                \'split_id\': \'trainIdxs\'\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'base_directory\': data_dir,\n                \'splits_file\': self.builder_config.split_file,\n                \'split_id\': \'devIdxs\'\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'base_directory\': data_dir,\n                \'splits_file\': self.builder_config.split_file,\n                \'split_id\': \'testIdxs\'\n            })\n    ]\n\n  def _scrub_json(self, content):\n    """"""Reduce JSON by filtering out only the fields of interest.""""""\n    # Loading of json data with the standard Python library is very inefficient:\n    # For the 4GB dataset file it requires more than 40GB of RAM and takes 3min.\n    # There are more efficient libraries but in order to avoid additional\n    # dependencies we use a simple (perhaps somewhat brittle) regexp to reduce\n    # the content to only what is needed. This takes 1min to execute but\n    # afterwards loading requires only 500MB or RAM and is done in 2s.\n    regex = re.compile(\n        r\'(""%s"":\\s*""[^""]*"").*?(""%s"":\\s*""[^""]*"")\' %\n        (_QUESTION_FIELD, _QUERY_FIELD), re.DOTALL)\n    return \'[\' + \',\'.join([\n        \'{\' + m.group(1) + \',\' + m.group(2) + \'}\'\n        for m in regex.finditer(content)\n    ]) + \']\'\n\n  def _generate_examples(self, base_directory, splits_file, split_id):\n    """"""Yields examples.""""""\n    samples_path = os.path.join(base_directory, \'dataset.json\')\n    splits_path = os.path.join(base_directory, splits_file)\n    with tf.io.gfile.GFile(samples_path) as samples_file:\n      with tf.io.gfile.GFile(splits_path) as splits_file:\n        logging.info(\'Reading json from %s into memory...\', samples_path)\n        samples = json.loads(self._scrub_json(samples_file.read()))\n        logging.info(\'%d samples loaded\', len(samples))\n        logging.info(\'Loaded json data from %s.\', samples_path)\n        splits = json.load(splits_file)\n        for idx in splits[split_id]:\n          sample = samples[idx]\n          yield idx, {\n              _QUESTION: sample[_QUESTION_FIELD],\n              _QUERY: sample[_QUERY_FIELD]\n          }\n'"
tensorflow_datasets/text/cfq_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for CFQ dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import cfq\n\n\nclass CFQTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cfq.CFQ\n  BUILDER_CONFIG_NAMES_TO_TEST = [""mcd1""]\n  SPLITS = {\n      ""train"": 2,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n      ""validation"": 1,  # Number of fake validation example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/civil_comments.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""CivilComments from Jigsaw Unintended Bias Kaggle Competition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{DBLP:journals/corr/abs-1903-04561,\n  author    = {Daniel Borkan and\n               Lucas Dixon and\n               Jeffrey Sorensen and\n               Nithum Thain and\n               Lucy Vasserman},\n  title     = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n               Classification},\n  journal   = {CoRR},\n  volume    = {abs/1903.04561},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1903.04561},\n  archivePrefix = {arXiv},\n  eprint    = {1903.04561},\n  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-04561},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe comments in this dataset come from an archive of the Civil Comments\nplatform, a commenting plugin for independent news sites. These public comments\nwere created from 2015 - 2017 and appeared on approximately 50 English-language\nnews sites across the world. When Civil Comments shut down in 2017, they chose\nto make the public comments available in a lasting open archive to enable future\nresearch. The original data, published on figshare, includes the public comment\ntext, some associated metadata such as article IDs, timestamps and\ncommenter-generated ""civility"" labels, but does not include user ids. Jigsaw\nextended this dataset by adding additional labels for toxicity and identity\nmentions. This data set is an exact replica of the data released for the\nJigsaw Unintended Bias in Toxicity Classification Kaggle challenge.  This\ndataset is released under CC0, as is the underlying comment text.\n""""""\n\n_DOWNLOAD_URL = \'https://storage.googleapis.com/jigsaw-unintended-bias-in-toxicity-classification/civil_comments.zip\'\n\n\nclass CivilComments(tfds.core.GeneratorBasedBuilder):\n  """"""Classification and tagging of 2M comments on news sites.\n\n  This version of the CivilComments Dataset provides access to the primary\n  seven labels that were annotated by crowd workers, the toxicity and other\n  tags are a value between 0 and 1 indicating the fraction of annotators that\n  assigned these attributes to the comment text.\n\n  The other tags, which are only available for a fraction of the input examples\n  are currently ignored, as are all of the attributes that were part of the\n  original civil comments release. See the Kaggle documentation for more\n  details about the available features.\n  """"""\n\n  VERSION = tfds.core.Version(\'0.9.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            \'text\': tfds.features.Text(),\n            \'toxicity\': tf.float32,\n            \'severe_toxicity\': tf.float32,\n            \'obscene\': tf.float32,\n            \'threat\': tf.float32,\n            \'insult\': tf.float32,\n            \'identity_attack\': tf.float32,\n            \'sexual_explicit\': tf.float32\n        }),\n        # The supervised_keys version is very impoverished.\n        supervised_keys=(\'text\', \'toxicity\'),\n        homepage=\'https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'filename\': os.path.join(dl_path, \'train.csv\'),\n                \'toxicity_label\': \'target\'\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'filename\': os.path.join(dl_path, \'test_public_expanded.csv\'),\n                \'toxicity_label\': \'toxicity\'\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'filename\': os.path.join(dl_path, \'test_private_expanded.csv\'),\n                \'toxicity_label\': \'toxicity\'\n            },\n        ),\n    ]\n\n  def _generate_examples(self, filename, toxicity_label):\n    """"""Yields examples.\n\n    Each example contains a text input and then seven annotation labels.\n\n    Args:\n      filename: the path of the file to be read for this split.\n      toxicity_label: indicates \'target\' or \'toxicity\' to capture the variation\n        in the released labels for this dataset.\n\n    Yields:\n      A dictionary of features, all floating point except the input text.\n    """"""\n    with tf.io.gfile.GFile(filename) as f:\n      reader = csv.DictReader(f)\n      for row in reader:\n        example = {}\n        example[\'text\'] = row[\'comment_text\']\n        example[\'toxicity\'] = float(row[toxicity_label])\n        for label in [\n            \'severe_toxicity\', \'obscene\', \'threat\', \'insult\', \'identity_attack\',\n            \'sexual_explicit\'\n        ]:\n          example[label] = float(row[label])\n        yield row[\'id\'], example\n'"
tensorflow_datasets/text/civil_comments_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for CivilComments from Jigsaw Unintended Bias Kaggle Competition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import civil_comments\n\n\nclass CivilCommentsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = civil_comments.CivilComments\n  SPLITS = {\n      ""train"": 2,  # Number of fake train examples\n      ""test"": 1,  # Number of fake test examples\n      ""validation"": 1,  # Number of fake validation examples\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/cos_e.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Commonsense Explanations (CoS-E) Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{rajani2019explain,\n     title = ""Explain Yourself! Leveraging Language models for Commonsense Reasoning"",\n    author = ""Rajani, Nazneen Fatema  and\n      McCann, Bryan  and\n      Xiong, Caiming  and\n      Socher, Richard"",\n      year=""2019"",\n    booktitle = ""Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019)"",\n    url =""https://arxiv.org/abs/1906.02361""\n}\n""""""\n\n_DESCRIPTION = """"""\nCommon Sense Explanations (CoS-E) allows for training language models to\nautomatically generate explanations that can be used during training and\ninference in a novel Commonsense Auto-Generated Explanation (CAGE) framework.\n""""""\n\n_COS_E_URL = ""https://raw.githubusercontent.com/salesforce/cos-e/master/data/""\n\n# COS E has explanations for the CQA dataset, which is joined by ID.\n_CQA_URL_TRAIN = ""https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl""\n_CQA_URL_DEV = ""https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl""\n_CQA_URL_TEST = ""https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl""\n\n\ndef _download_and_index_cqa(dl_manager):\n  """"""Downloads CQA and returns it, indexed by id, for joining with Cos-E.""""""\n\n  downloaded_files = dl_manager.download_and_extract({\n      ""cqa_train"": _CQA_URL_TRAIN,\n      ""cqa_dev"": _CQA_URL_DEV,\n      ""cqa_test"": _CQA_URL_TEST\n  })\n\n  # NB: ""cqa_test"" is included in the files, but not in any of the CoS-E splits.\n  cqa_splits = [""cqa_train"", ""cqa_dev""]\n  cqa_complete = []\n  for split in cqa_splits:\n    with tf.io.gfile.GFile(downloaded_files[split]) as f:\n      for _, line in enumerate(f):\n        d = json.loads(line)\n        cqa_complete.append(d)\n\n    # Index the CQA dataset by id for joining with Cos-E.\n    cqa_indexed = {}\n  for d in cqa_complete:\n    cqa_indexed[d[""id""]] = d\n  return cqa_indexed\n\n\ndef _get_choices_and_answer(cqa):\n  """"""Returns choices and the answer from a cqa example.""""""\n  choices = []\n  answer_key = cqa[""answerKey""]\n  answer = None\n  for choice in cqa[""question""][""choices""]:\n    choices.append(choice[""text""])\n    if answer_key == choice[""label""]:\n      answer = choice[""text""]\n  return choices, answer\n\n\nclass CosE(tfds.core.GeneratorBasedBuilder):\n  """"""CoS-E: Common Sense Explanations corpus.""""""\n\n  VERSION = tfds.core.Version(""0.0.1"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""id"": tfds.features.Text(),\n            ""question"": tfds.features.Text(),\n            ""choices"": tfds.features.Sequence(tfds.features.Text()),\n            ""answer"": tfds.features.Text(),\n            ""abstractive_explanation"": tfds.features.Text(),\n            ""extractive_explanation"": tfds.features.Text(),\n        }),\n        supervised_keys=None,\n        homepage=""https://github.com/salesforce/cos-e"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    # NB: The CQA Dataset should be read only once, and only by callers who\n    # want to _create_ the Cos-E dataset from scratch.\n    cqa_indexed = _download_and_index_cqa(dl_manager)\n\n    files = dl_manager.download_and_extract({\n        ""dev"": [\n            os.path.join(_COS_E_URL, ""v1.11/dev/cose_dev_v1.11_processed.jsonl"")\n        ],\n        ""train"": [\n            os.path.join(_COS_E_URL,\n                         ""v1.11/train/cose_train_v1.11_processed.jsonl"")\n        ]\n    })\n\n    # We use the CoS-E/CQA dev set as our validation set.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""files"": files[""dev""],\n                        ""cqa_indexed"": cqa_indexed},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""files"": files[""train""],\n                        ""cqa_indexed"": cqa_indexed},\n        ),\n    ]\n\n  def _generate_examples(self, files, **kwargs):\n    """"""Yields examples.""""""\n    cqa_indexed = kwargs[""cqa_indexed""]\n    for filepath in files:\n      with tf.io.gfile.GFile(filepath) as f:\n        for line in f:\n          cos = json.loads(line)\n          cqa = cqa_indexed[cos[""id""]]\n          choices, answer = _get_choices_and_answer(cqa)\n          yield cos[""id""], {\n              ""id"": cos[""id""],\n              ""question"": cqa[""question""][""stem""],\n              ""choices"": choices,\n              ""answer"": answer,\n              ""abstractive_explanation"": cos[""explanation""][""open-ended""],\n              ""extractive_explanation"": cos[""explanation""][""selected""],\n          }\n'"
tensorflow_datasets/text/cos_e_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for CoS-E dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import cos_e\n\n\nclass CosETest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = cos_e.CosE\n  SPLITS = {\n      ""validation"": 2,  # Number of fake validation examples\n      ""train"": 2,  # Number of fake train examples\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""dev"": [""cos_e_dev.jsonl""],\n      ""train"": [""cos_e_train.jsonl""],\n      ""cqa_dev"": ""cqa_dev.jsonl"",\n      ""cqa_train"": ""cqa_train.jsonl"",\n      ""cqa_test"": ""cqa_test.jsonl"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/definite_pronoun_resolution.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Definite Pronoun Resolution Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{rahman2012resolving,\n  title={Resolving complex cases of definite pronouns: the winograd schema challenge},\n  author={Rahman, Altaf and Ng, Vincent},\n  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},\n  pages={777--789},\n  year={2012},\n  organization={Association for Computational Linguistics}\n}""""""\n\n_DESCRIPTION = """"""\\\nComposed by 30 students from one of the author\'s undergraduate classes. These\nsentence pairs cover topics ranging from real events (e.g., Iran\'s plan to\nattack the Saudi ambassador to the U.S.) to events/characters in movies (e.g.,\nBatman) and purely imaginary situations, largely reflecting the pop culture as\nperceived by the American kids born in the early 90s. Each annotated example\nspans four lines: the first line contains the sentence, the second line contains\nthe target pronoun, the third line contains the two candidate antecedents, and\nthe fourth line contains the correct antecedent. If the target pronoun appears\nmore than once in the sentence, its first occurrence is the one to be resolved.\n""""""\n\n_DATA_URL_PATTERN = \'http://www.hlt.utdallas.edu/~vince/data/emnlp12/{}.c.txt\'\n\n\nclass DefinitePronounResolution(tfds.core.GeneratorBasedBuilder):\n  """"""The Definite Pronoun Resolution Dataset.""""""\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'plain_text\',\n          version=tfds.core.Version(\n              \'1.0.0\',\n              \'New split API (https://tensorflow.org/datasets/splits)\'),\n          description=\'Plain text import of the Definite Pronoun Resolution Dataset.\',  # pylint: disable=line-too-long\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'sentence\':\n                tfds.features.Text(),\n            \'pronoun\':\n                tfds.features.Text(),\n            \'candidates\':\n                tfds.features.Sequence(tfds.features.Text(), length=2),\n            \'label\':\n                tfds.features.ClassLabel(num_classes=2),\n        }),\n        supervised_keys=(\'sentence\', \'label\'),\n        homepage=\'http://www.hlt.utdallas.edu/~vince/data/emnlp12/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    files = dl_manager.download({\n        \'train\': _DATA_URL_PATTERN.format(\'train\'),\n        \'test\': _DATA_URL_PATTERN.format(\'test\'),\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'filepath\': files[\'test\']}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'filepath\': files[\'train\']}),\n    ]\n\n  def _generate_examples(self, filepath):\n    with tf.io.gfile.GFile(filepath) as f:\n      line_num = -1\n      while True:\n        line_num += 1\n        sentence = f.readline().strip()\n        pronoun = f.readline().strip()\n        candidates = [c.strip() for c in f.readline().strip().split(\',\')]\n        correct = f.readline().strip()\n        f.readline()\n        if not sentence:\n          break\n        yield line_num, {\n            \'sentence\': sentence,\n            \'pronoun\': pronoun,\n            \'candidates\': candidates,\n            \'label\': candidates.index(correct),\n        }\n'"
tensorflow_datasets/text/definite_pronoun_resolution_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for definite_pronoun_resolution dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import definite_pronoun_resolution\n\n\nclass DefinitePronounResolutionTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = definite_pronoun_resolution.DefinitePronounResolution\n  DL_EXTRACT_RESULT = {\n      ""train"": ""train.c.txt"",\n      ""test"": ""test.c.txt"",\n  }\n  SPLITS = {\n      ""test"": 3,\n      ""train"": 4,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/eraser_multi_rc.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Passage, query, answers and answer classification with explanations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@unpublished{eraser2019,\n    title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n    author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n}\n@inproceedings{MultiRC2018,\n    author = {Daniel Khashabi and Snigdha Chaturvedi and Michael Roth and Shyam Upadhyay and Dan Roth},\n    title = {Looking Beyond the Surface:A Challenge Set for Reading Comprehension over Multiple Sentences},\n    booktitle = {NAACL},\n    year = {2018}\n}\n""""""\n\n_DESCRIPTION = """"""\nEraser Multi RC is a dataset for queries over multi-line passages, along with\nanswers and a rationalte. Each example in this dataset has the following 5 parts\n1. A Mutli-line Passage\n2. A Query about the passage\n3. An Answer to the query\n4. A Classification as to whether the answer is right or wrong\n5. An Explanation justifying the classification\n""""""\n\n_DOWNLOAD_URL = \'http://www.eraserbenchmark.com/zipped/multirc.tar.gz\'\n\n\nclass EraserMultiRc(tfds.core.GeneratorBasedBuilder):\n  """"""Multi Sentence Reasoning with Explanations (Eraser Benchmark).""""""\n\n  VERSION = tfds.core.Version(\'0.1.1\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'passage\': tfds.features.Text(),\n            \'query_and_answer\': tfds.features.Text(),\n            \'label\': tfds.features.ClassLabel(names=[\'False\', \'True\']),\n            \'evidences\': tfds.features.Sequence(tfds.features.Text())\n        }),\n        supervised_keys=None,\n        homepage=\'https://cogcomp.seas.upenn.edu/multirc/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    dl_dir = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    data_dir = os.path.join(dl_dir, \'multirc\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\'data_dir\': data_dir,\n                        \'filepath\': os.path.join(data_dir, \'train.jsonl\')},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\'data_dir\': data_dir,\n                        \'filepath\': os.path.join(data_dir, \'val.jsonl\')},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\'data_dir\': data_dir,\n                        \'filepath\': os.path.join(data_dir, \'test.jsonl\')},\n        ),\n    ]\n\n  def _generate_examples(self, data_dir, filepath):\n    """"""Yields examples.""""""\n\n    multirc_dir = os.path.join(data_dir, \'docs\')\n    with tf.io.gfile.GFile(filepath) as f:\n      for line in f:\n        row = json.loads(line)\n        evidences = []\n\n        for evidence in row[\'evidences\'][0]:\n          docid = evidence[\'docid\']\n          evidences.append(evidence[\'text\'])\n\n        passage_file = os.path.join(multirc_dir, docid)\n        with tf.io.gfile.GFile(passage_file) as f1:\n          passage_text = f1.read()\n\n        yield row[\'annotation_id\'], {\n            \'passage\': passage_text,\n            \'query_and_answer\': row[\'query\'],\n            \'label\': row[\'classification\'],\n            \'evidences\': evidences\n        }\n'"
tensorflow_datasets/text/eraser_multi_rc_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for eraser_multi_rc dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import eraser_multi_rc\n\n\nclass EraserMultiRcTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = eraser_multi_rc.EraserMultiRc\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n\n'"
tensorflow_datasets/text/esnli.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""e-SNLI: Natural Language Inference with Natural Language Explanations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@incollection{NIPS2018_8163,\ntitle = {e-SNLI: Natural Language Inference with Natural Language Explanations},\nauthor = {Camburu, Oana-Maria and Rockt\\""{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},\nbooktitle = {Advances in Neural Information Processing Systems 31},\neditor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\npages = {9539--9549},\nyear = {2018},\npublisher = {Curran Associates, Inc.},\nurl = {http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\ninclude human-annotated natural language explanations of the entailment\nrelations.\n""""""\n_URL = \'https://raw.githubusercontent.com/OanaMariaCamburu/e-SNLI/master/dataset/\'\n\n\nclass Esnli(tfds.core.GeneratorBasedBuilder):\n  """"""e-SNLI: Natural Language Inference with Natural Language Explanations corpus.""""""\n\n  # Version History\n  # 0.0.2 Added explanation_2, explanation_3 fields which exist in the dev/test\n  # splits only.\n  # 0.0.1 Initial version\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'plain_text\',\n          version=tfds.core.Version(\'0.0.2\'),\n          description=\'Plain text import of e-SNLI\',\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'premise\':\n                tfds.features.Text(),\n            \'hypothesis\':\n                tfds.features.Text(),\n            \'label\':\n                tfds.features.ClassLabel(\n                    names=[\'entailment\', \'neutral\', \'contradiction\']),\n            \'explanation_1\':\n                tfds.features.Text(),\n            \'explanation_2\':\n                tfds.features.Text(),\n            \'explanation_3\':\n                tfds.features.Text(),\n        }),\n        supervised_keys=None,\n        homepage=\'https://github.com/OanaMariaCamburu/e-SNLI\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    files = dl_manager.download_and_extract({\n        \'train\': [os.path.join(_URL, \'esnli_train_1.csv\'),\n                  os.path.join(_URL, \'esnli_train_2.csv\')],\n        \'validation\': [os.path.join(_URL, \'esnli_dev.csv\')],\n        \'test\': [os.path.join(_URL, \'esnli_test.csv\')]\n    })\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'files\': files[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'files\': files[\'validation\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'files\': files[\'test\']},\n        ),\n    ]\n\n  def _generate_examples(self, files):\n    """"""Yields examples.""""""\n    for filepath in files:\n      with tf.io.gfile.GFile(filepath) as f:\n        reader = csv.DictReader(f)\n        for _, row in enumerate(reader):\n          yield row[\'pairID\'], {\n              \'premise\': row[\'Sentence1\'],\n              \'hypothesis\': row[\'Sentence2\'],\n              \'label\': row[\'gold_label\'],\n              \'explanation_1\': row[\'Explanation_1\'],\n              \'explanation_2\': row.get(\'Explanation_2\', \'\'),\n              \'explanation_3\': row.get(\'Explanation_3\', \'\'),\n          }\n'"
tensorflow_datasets/text/esnli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for e-SNLI dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import esnli\n\n\nclass EsnliTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = esnli.Esnli\n  SPLITS = {\n      ""train"": 2,  # Number of fake train examples\n      ""test"": 1,  # Number of fake test examples\n      ""validation"": 1,  # Number of fake validation examples\n  }\n\n  DL_EXTRACT_RESULT = {\n      ""train"": [""esnli_train_1.csv"", ""esnli_train_2.csv""],\n      ""test"": [""esnli_test.csv""],\n      ""validation"": [""esnli_dev.csv""],\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/gap.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""GAP is a gender-balanced text data set.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{DBLP:journals/corr/abs-1810-05201,\n  author    = {Kellie Webster and\n               Marta Recasens and\n               Vera Axelrod and\n               Jason Baldridge},\n  title     = {Mind the {GAP:} {A} Balanced Corpus of Gendered Ambiguous Pronouns},\n  journal   = {CoRR},\n  volume    = {abs/1810.05201},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1810.05201},\n  archivePrefix = {arXiv},\n  eprint    = {1810.05201},\n  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-05201},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\nGAP is a gender-balanced dataset containing 8,908 coreference-labeled pairs of \n(ambiguous pronoun, antecedent name), sampled from Wikipedia and released by \nGoogle AI Language for the evaluation of coreference resolution in practical \napplications.\n""""""\n\n_TRAINURL = \'https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\'\n_VALIDATIONURL = \'https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\'\n_TESTURL = \'https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\'\n\n\nclass Gap(tfds.core.GeneratorBasedBuilder):\n  """"""GAP is a gender-balanced dataset.\n\n  It contains 8,908 coreference-labeled pairs\n  of (ambiguous pronoun, antecedent name), sampled from Wikipedia.\n  """"""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'ID\': tfds.features.Text(),\n            \'Text\': tfds.features.Text(),\n            \'Pronoun\': tfds.features.Text(),\n            \'Pronoun-offset\': tf.int32,\n            \'A\': tfds.features.Text(),\n            \'A-offset\': tf.int32,\n            \'A-coref\': tf.bool,\n            \'B\': tfds.features.Text(),\n            \'B-offset\': tf.int32,\n            \'B-coref\': tf.bool,\n            \'URL\': tfds.features.Text()\n        }),\n        supervised_keys=None,\n        homepage=\'https://github.com/google-research-datasets/gap-coreference\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    directory = dl_manager.download_and_extract({\n        \'train\': _TRAINURL,\n        \'validation\': _VALIDATIONURL,\n        \'test\': _TESTURL\n    })\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'filepath\': directory[\'train\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'filepath\': directory[\'validation\']},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'filepath\': directory[\'test\']},\n        )\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(filepath) as tsvfile:\n      reader = csv.DictReader(tsvfile, dialect=\'excel-tab\')\n      for i, row in enumerate(reader):\n        yield i, row\n'"
tensorflow_datasets/text/gap_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for GAP data set.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import gap\n\n\nclass GapTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = gap.Gap\n  SPLITS = {\n      ""train"": 5,  # Number of fake train examples\n      ""validation"": 3,  # Number of fake validation examples\n      ""test"": 3,  # Number of fake test examples\n  }\n  DL_EXTRACT_RESULT = {\n      ""train"": ""gap-development.tsv"",\n      ""validation"": ""gap-validation.tsv"",\n      ""test"": ""gap-test.tsv"",\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/glue.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The General Language Understanding Evaluation (GLUE) benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport textwrap\n\nimport numpy as np\nimport six\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_GLUE_CITATION = """"""\\\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.""""""\n\n_GLUE_DESCRIPTION = """"""\\\nGLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n""""""\n\n_MRPC_DEV_IDS = ""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc""\n_MRPC_TRAIN = ""https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt""\n_MRPC_TEST = ""https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt""\n\n_MNLI_BASE_KWARGS = dict(\n    text_features={\n        ""premise"": ""sentence1"",\n        ""hypothesis"": ""sentence2"",\n    },\n    label_classes=[""entailment"", ""neutral"", ""contradiction""],\n    label_column=""gold_label"",\n    data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce"",\n    data_dir=""MNLI"",\n    citation=textwrap.dedent(""""""\\\n      @InProceedings{N18-1101,\n        author = ""Williams, Adina\n                  and Nangia, Nikita\n                  and Bowman, Samuel"",\n        title = ""A Broad-Coverage Challenge Corpus for\n                 Sentence Understanding through Inference"",\n        booktitle = ""Proceedings of the 2018 Conference of\n                     the North American Chapter of the\n                     Association for Computational Linguistics:\n                     Human Language Technologies, Volume 1 (Long\n                     Papers)"",\n        year = ""2018"",\n        publisher = ""Association for Computational Linguistics"",\n        pages = ""1112--1122"",\n        location = ""New Orleans, Louisiana"",\n        url = ""http://aclweb.org/anthology/N18-1101""\n      }\n      @article{bowman2015large,\n        title={A large annotated corpus for learning natural language inference},\n        author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},\n        journal={arXiv preprint arXiv:1508.05326},\n        year={2015}\n      }""""""),\n    url=""http://www.nyu.edu/projects/bowman/multinli/"")\n\n\nclass GlueConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for GLUE.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               text_features,\n               label_column,\n               data_url,\n               data_dir,\n               citation,\n               url,\n               label_classes=None,\n               process_label=lambda x: x,\n               **kwargs):\n    """"""BuilderConfig for GLUE.\n\n    Args:\n      text_features: `dict[string, string]`, map from the name of the feature\n        dict for each text field to the name of the column in the tsv file\n      label_column: `string`, name of the column in the tsv file corresponding\n        to the label\n      data_url: `string`, url to download the zip file from\n      data_dir: `string`, the path to the folder containing the tsv files in the\n        downloaded zip\n      citation: `string`, citation for the data set\n      url: `string`, url for information about the data set\n      label_classes: `list[string]`, the list of classes if the label is\n        categorical. If not provided, then the label will be of type\n        `tf.float32`.\n      process_label: `Function[string, any]`, function taking in the raw value\n        of the label and processing it to the form required by the label feature\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(GlueConfig, self).__init__(\n        version=tfds.core.Version(\n            ""1.0.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.text_features = text_features\n    self.label_column = label_column\n    self.label_classes = label_classes\n    self.data_url = data_url\n    self.data_dir = data_dir\n    self.citation = citation\n    self.url = url\n    self.process_label = process_label\n\n\nclass Glue(tfds.core.GeneratorBasedBuilder):\n  """"""The General Language Understanding Evaluation (GLUE) benchmark.""""""\n  BUILDER_CONFIGS = [\n      GlueConfig(\n          name=""cola"",\n          description=textwrap.dedent(""""""\\\n            The Corpus of Linguistic Acceptability consists of English\n            acceptability judgments drawn from books and journal articles on\n            linguistic theory. Each example is a sequence of words annotated\n            with whether it is a grammatical English sentence.""""""),\n          text_features={""sentence"": ""sentence""},\n          label_classes=[""unacceptable"", ""acceptable""],\n          label_column=""is_acceptable"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4"",\n          data_dir=""CoLA"",\n          citation=textwrap.dedent(""""""\\\n            @article{warstadt2018neural,\n              title={Neural Network Acceptability Judgments},\n              author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\n              journal={arXiv preprint arXiv:1805.12471},\n              year={2018}\n            }""""""),\n          url=""https://nyu-mll.github.io/CoLA/""),\n      GlueConfig(\n          name=""sst2"",\n          description=textwrap.dedent(""""""\\\n            The Stanford Sentiment Treebank consists of sentences from movie reviews and\n            human annotations of their sentiment. The task is to predict the sentiment of a\n            given sentence. We use the two-way (positive/negative) class split, and use only\n            sentence-level labels.""""""),\n          text_features={""sentence"": ""sentence""},\n          label_classes=[""negative"", ""positive""],\n          label_column=""label"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8"",\n          data_dir=""SST-2"",\n          citation=textwrap.dedent(""""""\\\n            @inproceedings{socher2013recursive,\n              title={Recursive deep models for semantic compositionality over a sentiment treebank},\n              author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew and Potts, Christopher},\n              booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},\n              pages={1631--1642},\n              year={2013}\n            }""""""),\n          url=""https://nlp.stanford.edu/sentiment/index.html""),\n      GlueConfig(\n          name=""mrpc"",\n          description=textwrap.dedent(""""""\\\n            The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of\n            sentence pairs automatically extracted from online news sources, with human annotations\n            for whether the sentences in the pair are semantically equivalent.""""""),  # pylint: disable=line-too-long\n          text_features={\n              ""sentence1"": """",\n              ""sentence2"": """"\n          },\n          label_classes=[""not_equivalent"", ""equivalent""],\n          label_column=""Quality"",\n          data_url="""",  # MRPC isn\'t hosted by GLUE.\n          data_dir=""MRPC"",\n          citation=textwrap.dedent(""""""\\\n            @inproceedings{dolan2005automatically,\n              title={Automatically constructing a corpus of sentential paraphrases},\n              author={Dolan, William B and Brockett, Chris},\n              booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\n              year={2005}\n            }""""""),\n          url=""https://www.microsoft.com/en-us/download/details.aspx?id=52398""\n      ),\n      GlueConfig(\n          name=""qqp"",\n          description=textwrap.dedent(""""""\\\n            The Quora Question Pairs2 dataset is a collection of question pairs from the\n            community question-answering website Quora. The task is to determine whether a\n            pair of questions are semantically equivalent.""""""),\n          text_features={\n              ""question1"": ""question1"",\n              ""question2"": ""question2"",\n          },\n          label_classes=[""not_duplicate"", ""duplicate""],\n          label_column=""is_duplicate"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5"",\n          data_dir=""QQP"",\n          citation=textwrap.dedent(""""""\\\n          @online{WinNT,\n            author = {Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornel},\n            title = {First Quora Dataset Release: Question Pairs},\n            year = 2017,\n            url = {https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs},\n            urldate = {2019-04-03}\n          }""""""),\n          url=""https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs""\n      ),\n      GlueConfig(\n          name=""stsb"",\n          description=textwrap.dedent(""""""\\\n            The Semantic Textual Similarity Benchmark (Cer et al., 2017) is a collection of\n            sentence pairs drawn from news headlines, video and image captions, and natural\n            language inference data. Each pair is human-annotated with a similarity score\n            from 1 to 5.""""""),\n          text_features={\n              ""sentence1"": ""sentence1"",\n              ""sentence2"": ""sentence2"",\n          },\n          label_column=""score"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5"",\n          data_dir=""STS-B"",\n          citation=textwrap.dedent(""""""\\\n            @article{cer2017semeval,\n              title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},\n              author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},\n              journal={arXiv preprint arXiv:1708.00055},\n              year={2017}\n            }""""""),\n          url=""http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark"",\n          process_label=np.float32),\n      GlueConfig(\n          name=""mnli"",\n          description=textwrap.dedent(""""""\\\n            The Multi-Genre Natural Language Inference Corpus is a crowdsourced\n            collection of sentence pairs with textual entailment annotations. Given a premise sentence\n            and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis\n            (entailment), contradicts the hypothesis (contradiction), or neither (neutral). The premise sentences are\n            gathered from ten different sources, including transcribed speech, fiction, and government reports.\n            We use the standard test set, for which we obtained private labels from the authors, and evaluate\n            on both the matched (in-domain) and mismatched (cross-domain) section. We also use and recommend\n            the SNLI corpus as 550k examples of auxiliary training data.""""""),\n          **_MNLI_BASE_KWARGS),\n      GlueConfig(\n          name=""mnli_mismatched"",\n          description=textwrap.dedent(""""""\\\n          The mismatched validation and test splits from MNLI.\n          See the ""mnli"" BuilderConfig for additional information.""""""),\n          **_MNLI_BASE_KWARGS),\n      GlueConfig(\n          name=""mnli_matched"",\n          description=textwrap.dedent(""""""\\\n          The matched validation and test splits from MNLI.\n          See the ""mnli"" BuilderConfig for additional information.""""""),\n          **_MNLI_BASE_KWARGS),\n      GlueConfig(\n          name=""qnli"",\n          description=textwrap.dedent(""""""\\\n            The Stanford Question Answering Dataset is a question-answering\n            dataset consisting of question-paragraph pairs, where one of the sentences in the paragraph (drawn\n            from Wikipedia) contains the answer to the corresponding question (written by an annotator). We\n            convert the task into sentence pair classification by forming a pair between each question and each\n            sentence in the corresponding context, and filtering out pairs with low lexical overlap between the\n            question and the context sentence. The task is to determine whether the context sentence contains\n            the answer to the question. This modified version of the original task removes the requirement that\n            the model select the exact answer, but also removes the simplifying assumptions that the answer\n            is always present in the input and that lexical overlap is a reliable cue.""""""),  # pylint: disable=line-too-long\n          text_features={\n              ""question"": ""question"",\n              ""sentence"": ""sentence"",\n          },\n          label_classes=[""entailment"", ""not_entailment""],\n          label_column=""label"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601"",\n          data_dir=""QNLI"",\n          citation=textwrap.dedent(""""""\\\n            @article{rajpurkar2016squad,\n              title={Squad: 100,000+ questions for machine comprehension of text},\n              author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},\n              journal={arXiv preprint arXiv:1606.05250},\n              year={2016}\n            }""""""),\n          url=""https://rajpurkar.github.io/SQuAD-explorer/""),\n      GlueConfig(\n          name=""rte"",\n          description=textwrap.dedent(""""""\\\n            The Recognizing Textual Entailment (RTE) datasets come from a series of annual textual\n            entailment challenges. We combine the data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim\n            et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).4 Examples are\n            constructed based on news and Wikipedia text. We convert all datasets to a two-class split, where\n            for three-class datasets we collapse neutral and contradiction into not entailment, for consistency.""""""),  # pylint: disable=line-too-long\n          text_features={\n              ""sentence1"": ""sentence1"",\n              ""sentence2"": ""sentence2"",\n          },\n          label_classes=[""entailment"", ""not_entailment""],\n          label_column=""label"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb"",\n          data_dir=""RTE"",\n          citation=textwrap.dedent(""""""\\\n            @inproceedings{dagan2005pascal,\n              title={The PASCAL recognising textual entailment challenge},\n              author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},\n              booktitle={Machine Learning Challenges Workshop},\n              pages={177--190},\n              year={2005},\n              organization={Springer}\n            }\n            @inproceedings{bar2006second,\n              title={The second pascal recognising textual entailment challenge},\n              author={Bar-Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},\n              booktitle={Proceedings of the second PASCAL challenges workshop on recognising textual entailment},\n              volume={6},\n              number={1},\n              pages={6--4},\n              year={2006},\n              organization={Venice}\n            }\n            @inproceedings{giampiccolo2007third,\n              title={The third pascal recognizing textual entailment challenge},\n              author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},\n              booktitle={Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing},\n              pages={1--9},\n              year={2007},\n              organization={Association for Computational Linguistics}\n            }\n            @inproceedings{bentivogli2009fifth,\n              title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},\n              author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},\n              booktitle={TAC},\n              year={2009}\n            }""""""),\n          url=""https://aclweb.org/aclwiki/Recognizing_Textual_Entailment""\n      ),\n      GlueConfig(\n          name=""wnli"",\n          description=textwrap.dedent(""""""\\\n            The Winograd Schema Challenge (Levesque et al., 2011) is a reading comprehension task\n            in which a system must read a sentence with a pronoun and select the referent of that pronoun from\n            a list of choices. The examples are manually constructed to foil simple statistical methods: Each\n            one is contingent on contextual information provided by a single word or phrase in the sentence.\n            To convert the problem into sentence pair classification, we construct sentence pairs by replacing\n            the ambiguous pronoun with each possible referent. The task is to predict if the sentence with the\n            pronoun substituted is entailed by the original sentence. We use a small evaluation set consisting of\n            new examples derived from fiction books that was shared privately by the authors of the original\n            corpus. While the included training set is balanced between two classes, the test set is imbalanced\n            between them (65% not entailment). Also, due to a data quirk, the development set is adversarial:\n            hypotheses are sometimes shared between training and development examples, so if a model memorizes the\n            training examples, they will predict the wrong label on corresponding development set\n            example. As with QNLI, each example is evaluated separately, so there is not a systematic correspondence\n            between a model\'s score on this task and its score on the unconverted original task. We\n            call converted dataset WNLI (Winograd NLI).""""""),\n          text_features={\n              ""sentence1"": ""sentence1"",\n              ""sentence2"": ""sentence2"",\n          },\n          label_classes=[""not_entailment"", ""entailment""],\n          label_column=""label"",\n          data_url=""https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf"",\n          data_dir=""WNLI"",\n          citation=textwrap.dedent(""""""\\\n            @inproceedings{levesque2012winograd,\n              title={The winograd schema challenge},\n              author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},\n              booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},\n              year={2012}\n            }""""""),\n          url=""https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html""\n      ),\n      GlueConfig(\n          name=""ax"",\n          description=textwrap.dedent(""""""\\\n            A manually-curated evaluation dataset for fine-grained analysis of\n            system performance on a broad range of linguistic phenomena. This\n            dataset evaluates sentence understanding through Natural Language\n            Inference (NLI) problems. Use a model trained on MulitNLI to produce\n            predictions for this dataset.""""""),\n          text_features={\n              ""premise"": ""sentence1"",\n              ""hypothesis"": ""sentence2"",\n          },\n          label_classes=[""entailment"", ""neutral"", ""contradiction""],\n          label_column="""",  # No label since we only have test set.\n          # We must use a URL shortener since the URL from GLUE is very long and\n          # causes issues in TFDS.\n          data_url=""https://bit.ly/2BOtOJ7"",\n          data_dir="""",  # We are downloading a tsv.\n          citation="""",  # The GLUE citation is sufficient.\n          url=""https://gluebenchmark.com/diagnostics""),\n  ]\n\n  def _info(self):\n    features = {\n        text_feature: tfds.features.Text()\n        for text_feature in six.iterkeys(self.builder_config.text_features)\n    }\n    if self.builder_config.label_classes:\n      features[""label""] = tfds.features.ClassLabel(\n          names=self.builder_config.label_classes)\n    else:\n      features[""label""] = tf.float32\n    features[""idx""] = tf.int32\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_GLUE_DESCRIPTION,\n        features=tfds.features.FeaturesDict(features),\n        homepage=self.builder_config.url,\n        citation=self.builder_config.citation + ""\\n"" + _GLUE_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    if self.builder_config.name == ""ax"":\n      data_file = dl_manager.download(self.builder_config.data_url)\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs={\n                  ""data_file"": data_file,\n                  ""split"": ""test"",\n              })\n      ]\n\n    if self.builder_config.name == ""mrpc"":\n      data_dir = None\n      mrpc_files = dl_manager.download({\n          ""dev_ids"": _MRPC_DEV_IDS,\n          ""train"": _MRPC_TRAIN,\n          ""test"": _MRPC_TEST,\n      })\n    else:\n      dl_dir = dl_manager.download_and_extract(self.builder_config.data_url)\n      data_dir = os.path.join(dl_dir, self.builder_config.data_dir)\n      mrpc_files = None\n    train_split = tfds.core.SplitGenerator(\n        name=tfds.Split.TRAIN,\n        gen_kwargs={\n            ""data_file"": os.path.join(data_dir or """", ""train.tsv""),\n            ""split"": ""train"",\n            ""mrpc_files"": mrpc_files,\n        })\n    if self.builder_config.name == ""mnli"":\n      return [\n          train_split,\n          _mnli_split_generator(\n              ""validation_matched"", data_dir, ""dev"", matched=True),\n          _mnli_split_generator(\n              ""validation_mismatched"", data_dir, ""dev"", matched=False),\n          _mnli_split_generator(""test_matched"", data_dir, ""test"", matched=True),\n          _mnli_split_generator(\n              ""test_mismatched"", data_dir, ""test"", matched=False)\n      ]\n    elif self.builder_config.name == ""mnli_matched"":\n      return [\n          _mnli_split_generator(""validation"", data_dir, ""dev"", matched=True),\n          _mnli_split_generator(""test"", data_dir, ""test"", matched=True)\n      ]\n    elif self.builder_config.name == ""mnli_mismatched"":\n      return [\n          _mnli_split_generator(""validation"", data_dir, ""dev"", matched=False),\n          _mnli_split_generator(""test"", data_dir, ""test"", matched=False)\n      ]\n    else:\n      return [\n          train_split,\n          tfds.core.SplitGenerator(\n              name=tfds.Split.VALIDATION,\n              gen_kwargs={\n                  ""data_file"": os.path.join(data_dir or """", ""dev.tsv""),\n                  ""split"": ""dev"",\n                  ""mrpc_files"": mrpc_files,\n              }),\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs={\n                  ""data_file"": os.path.join(data_dir or """", ""test.tsv""),\n                  ""split"": ""test"",\n                  ""mrpc_files"": mrpc_files,\n              }),\n      ]\n\n  def _generate_examples(self, data_file, split, mrpc_files=None):\n    if self.builder_config.name == ""mrpc"":\n      # We have to prepare the MRPC dataset from the original sources ourselves.\n      examples = self._generate_example_mrpc_files(\n          mrpc_files=mrpc_files, split=split)\n      for example in examples:\n        yield example[""idx""], example\n    else:\n      process_label = self.builder_config.process_label\n      label_classes = self.builder_config.label_classes\n\n      # The train and dev files for CoLA are the only tsv files without a\n      # header.\n      is_cola_non_test = self.builder_config.name == ""cola"" and split != ""test""\n\n      with tf.io.gfile.GFile(data_file) as f:\n        reader = csv.DictReader(f, delimiter=""\\t"", quoting=csv.QUOTE_NONE)\n        if is_cola_non_test:\n          reader = csv.reader(f, delimiter=""\\t"", quoting=csv.QUOTE_NONE)\n\n        for n, row in enumerate(reader):\n          if is_cola_non_test:\n            row = {\n                ""sentence"": row[3],\n                ""is_acceptable"": row[1],\n            }\n\n          example = {\n              feat: row[col]\n              for feat, col in six.iteritems(self.builder_config.text_features)\n          }\n          example[""idx""] = n\n\n          if self.builder_config.label_column in row:\n            label = row[self.builder_config.label_column]\n            # For some tasks, the label is represented as 0 and 1 in the tsv\n            # files and needs to be cast to integer to work with the feature.\n            if label_classes and label not in label_classes:\n              label = int(label) if label else None\n            example[""label""] = process_label(label)\n          else:\n            example[""label""] = process_label(-1)\n\n          # Filter out corrupted rows.\n          for value in six.itervalues(example):\n            if value is None:\n              break\n          else:\n            yield example[""idx""], example\n\n  def _generate_example_mrpc_files(self, mrpc_files, split):\n    if split == ""test"":\n      with tf.io.gfile.GFile(mrpc_files[""test""]) as f:\n        reader = csv.DictReader(f, delimiter=""\\t"", quoting=csv.QUOTE_NONE)\n        for n, row in enumerate(reader):\n          yield {\n              ""sentence1"": row[""#1 String""],\n              ""sentence2"": row[""#2 String""],\n              ""label"": -1,\n              ""idx"": n,\n          }\n    else:\n      with tf.io.gfile.GFile(mrpc_files[""dev_ids""]) as f:\n        reader = csv.reader(f, delimiter=""\\t"", quoting=csv.QUOTE_NONE)\n        dev_ids = [[row[0], row[1]] for row in reader]\n      with tf.io.gfile.GFile(mrpc_files[""train""]) as f:\n        # The first 3 bytes are the utf-8 BOM \\xef\\xbb\\xbf, which messes with\n        # the Quality key.\n        f.seek(3)\n        reader = csv.DictReader(f, delimiter=""\\t"", quoting=csv.QUOTE_NONE)\n        for n, row in enumerate(reader):\n          is_row_in_dev = [row[""#1 ID""], row[""#2 ID""]] in dev_ids\n          if is_row_in_dev == (split == ""dev""):\n            yield {\n                ""sentence1"": row[""#1 String""],\n                ""sentence2"": row[""#2 String""],\n                ""label"": int(row[""Quality""]),\n                ""idx"": n,\n            }\n\n\ndef _mnli_split_generator(name, data_dir, split, matched):\n  return tfds.core.SplitGenerator(\n      name=name,\n      gen_kwargs={\n          ""data_file"": os.path.join(\n              data_dir,\n              ""%s_%s.tsv"" % (split, ""matched"" if matched else ""mismatched"")),\n          ""split"": split,\n          ""mrpc_files"": None,\n      })\n'"
tensorflow_datasets/text/glue_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the GLUE data set.\n\nWe have an individual test for each config so that we can use sharding to\nprevent the test from timing out.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import glue\n\n\nclass GlueColaTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""cola""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueSst2Test(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""sst2""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueQqpTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""qqp""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueStsbTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""stsb""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueMnliTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""mnli""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation_matched"": 2,\n      ""validation_mismatched"": 2,\n      ""test_matched"": 1,\n      ""test_mismatched"": 1,\n  }\n\n\nclass GlueQnliTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""qnli""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueRteTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""rte""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueWnliTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""wnli""]\n  DATASET_CLASS = glue.Glue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass GlueMrpcTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""mrpc""]\n  DATASET_CLASS = glue.Glue\n  DL_EXTRACT_RESULT = {\n      ""train"": ""MRPC/msr_paraphrase_train.txt"",\n      ""test"": ""MRPC/msr_paraphrase_test.txt"",\n      ""dev_ids"": ""MRPC/mrpc_dev_ids.tsv"",\n  }\n  SPLITS = {\n      ""train"": 10,\n      ""validation"": 8,\n      ""test"": 15,\n  }\n\n\nclass GlueAxTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""ax""]\n  DATASET_CLASS = glue.Glue\n  DL_EXTRACT_RESULT = ""AX/ax.tsv""\n  SPLITS = {\n      ""test"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/imdb.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""IMDB movie reviews dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\n\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially \\\nmore data than previous benchmark datasets. We provide a set of 25,000 highly \\\npolar movie reviews for training, and 25,000 for testing. There is additional \\\nunlabeled data for use as well.\\\n""""""\n\n_CITATION = """"""\\\n@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n  title     = {Learning Word Vectors for Sentiment Analysis},\n  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n  month     = {June},\n  year      = {2011},\n  address   = {Portland, Oregon, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {142--150},\n  url       = {http://www.aclweb.org/anthology/P11-1015}\n}\n""""""\n\n_DOWNLOAD_URL = ""http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz""\n\n\nclass IMDBReviewsConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for IMDBReviews.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for IMDBReviews.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the IMDB `""text""`\n        feature.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(IMDBReviewsConfig, self).__init__(\n        version=tfds.core.Version(\n            ""1.0.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\nclass IMDBReviews(tfds.core.GeneratorBasedBuilder):\n  """"""IMDB movie reviews dataset.""""""\n  BUILDER_CONFIGS = [\n      IMDBReviewsConfig(\n          name=""plain_text"",\n          description=""Plain text"",\n      ),\n      IMDBReviewsConfig(\n          name=""bytes"",\n          description=(""Uses byte-level text encoding with ""\n                       ""`tfds.features.text.ByteTextEncoder`""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder=tfds.features.text.ByteTextEncoder()),\n      ),\n      IMDBReviewsConfig(\n          name=""subwords8k"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with 8k ""\n                       ""vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**13),\n      ),\n      IMDBReviewsConfig(\n          name=""subwords32k"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with ""\n                       ""32k vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**15),\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""text"": tfds.features.Text(\n                encoder_config=self.builder_config.text_encoder_config),\n            ""label"": tfds.features.ClassLabel(names=[""neg"", ""pos""]),\n        }),\n        supervised_keys=(""text"", ""label""),\n        homepage=""http://ai.stanford.edu/~amaas/data/sentiment/"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, archive):\n    for _, ex in self._generate_examples(\n        archive, os.path.join(""aclImdb"", ""train"")):\n      yield ex[""text""]\n\n  def _split_generators(self, dl_manager):\n    arch_path = dl_manager.download(_DOWNLOAD_URL)\n    archive = lambda: dl_manager.iter_archive(arch_path)\n\n    # Generate vocabulary from training data if SubwordTextEncoder configured\n    self.info.features[""text""].maybe_build_from_corpus(\n        self._vocab_text_gen(archive()))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""archive"": archive(),\n                        ""directory"": os.path.join(""aclImdb"", ""train"")}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""archive"": archive(),\n                        ""directory"": os.path.join(""aclImdb"", ""test"")}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split(""unsupervised""),\n            gen_kwargs={""archive"": archive(),\n                        ""directory"": os.path.join(""aclImdb"", ""train""),\n                        ""labeled"": False}),\n    ]\n\n  def _generate_examples(self, archive, directory, labeled=True):\n    """"""Generate IMDB examples.""""""\n    # For labeled examples, extract the label from the path.\n    reg_path = ""(?P<label>neg|pos)"" if labeled else ""unsup""\n    reg = re.compile(\n        os.path.join(""^%s"" % directory, reg_path, """").replace(""\\\\"", ""\\\\\\\\""))\n    for path, imdb_f in archive:\n      res = reg.match(path)\n      if not res:\n        continue\n      text = imdb_f.read().strip()\n      label = res.groupdict()[""label""] if labeled else -1\n      yield path, {\n          ""text"": text,\n          ""label"": label,\n      }\n'"
tensorflow_datasets/text/imdb_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for imdb dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import imdb\n\n\nclass IMDBReviewsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = imdb.IMDBReviews\n  SPLITS = {\n      ""train"": 5,\n      ""test"": 4,\n      ""unsupervised"": 3,\n  }\n  DL_EXTRACT_RESULT = ""aclImdb_v1.tar.gz""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/irc_disentanglement.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""irc_disentanglement dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nfrom typing import List\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@InProceedings{acl19disentangle,\n  author    = {Jonathan K. Kummerfeld and Sai R. Gouravajhala and Joseph Peper and Vignesh Athreya and Chulaka Gunasekara and Jatin Ganhotra and Siva Sankalp Patel and Lazaros Polymenakos and Walter S. Lasecki},\n  title     = {A Large-Scale Corpus for Conversation Disentanglement},\n  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n  location  = {Florence, Italy},\n  month     = {July},\n  year      = {2019},\n  doi       = {10.18653/v1/P19-1374},\n  pages     = {3846--3856},\n  url       = {https://aclweb.org/anthology/papers/P/P19/P19-1374/},\n  arxiv     = {https://arxiv.org/abs/1810.11118},\n  software  = {https://jkk.name/irc-disentanglement},\n  data      = {https://jkk.name/irc-disentanglement},\n}\n""""""\n_DESCRIPTION = """"""\nIRC Disentanglement dataset contains over 77,563 messages from Ubuntu IRC\nchannel.\n\nFeatures include message id, message text and timestamp.\nTarget is list of messages that current message replies to.\n""""""\n_DOWNLOAD_URL = \\\n    ""https://github.com/jkkummerfeld/irc-disentanglement/zipball/fd379e9""\n_DOWNLOAD_ARCHIVE_SUBDIR = os.path.join(\n    ""jkkummerfeld-irc-disentanglement-fd379e9"", ""data"")\n\n_MESSAGE_ID = ""id""\n_MESSAGE_TEXT = ""text""\n_MESSAGE_TIMESTAMP = ""timestamp""\n_MESSAGE_PARENTS_IDS = ""parents""\n\n\ndef _get_day_to_paths(data_dir):\n  """"""Prepares paths to files with raw chat messages and replies annotations.\n\n  Args:\n    data_dir: directory containing files with data. directory can be\n\n  Returns:\n    day_to_paths: dict formatted date -> dict with paths\n      day_to_paths[day_str][""text""] - path to file with raw chat messages\n      day_to_paths[day_str][""annot""] - path to file with replies annotations.\n  """"""\n  day_to_paths = collections.defaultdict(dict)\n  for filename in tf.io.gfile.listdir(data_dir):\n    filepath = os.path.join(data_dir, filename)\n    day_str = filename[:len(""YYYY-MM-DD"")]  # e.g. 2004-12-25.train-c.raw.txt\n\n    if ""raw"" in filename:\n      day_to_paths[day_str][""text""] = filepath\n    if ""annotation"" in filename:\n      day_to_paths[day_str][""annot""] = filepath\n\n  return day_to_paths\n\n\ndef _read_texts_file(path):\n  with tf.io.gfile.GFile(path, ""r"") as f:\n    return [line.strip() for line in f]\n\n\ndef _read_annot_file(path):\n  """"""Reads file with replies annotation.""""""\n  with tf.io.gfile.GFile(path, ""r"") as f:\n    return [(int(first), int(second))\n            for first, second, _ in map(str.split, f)]\n\n\ndef _parse_out_timestamps(raw_texts, day_str):\n  """"""Parsing timestamps from IRC chat messages.\n\n  Similar logic is implemented here.\n  https://github.com/jkkummerfeld/irc-disentanglement/blob/master/src/disentangle.py#L174\n\n  Args:\n    raw_texts: list of raw chat messages.\n    day_str: formatted date string.\n\n  Returns:\n    texts: list of texts without timestamps.\n    timestamps: list of formatted timestamps\n  """"""\n  prev_hours = 0\n  timestamps, texts = [], []\n  for raw_text in raw_texts:\n    if raw_text.startswith(""[""):  # Regular messsages e.g. ""[04:13]<xxx>: Hi!""\n      hours = int(raw_text[1:3])\n      mins = int(raw_text[4:6])\n\n      # 12h format -> 24h format\n      if hours < prev_hours:  # All messages belong to the same day and are\n        hours += 12  # chronologically ordered, but AM/PM info is absent\n      prev_hours = hours\n\n      timestamps.append(""{}_{:02}_{:02}"".format(day_str, hours, mins))\n      raw_text = raw_text[7:]\n    else:  # System messages e.g. ""=== xxx has joned #ubuntu""\n      timestamps.append("""")\n\n    texts.append(raw_text)\n\n  return texts, timestamps\n\n\ndef _get_msg_id(day, line_num):\n  return ""{}_{:05}"".format(day, line_num)\n\n\ndef _prepare_examples(texts_file_path, annot_file_path, day_str):\n  """"""Prepares examples for 1 day.""""""\n  # Read raw data\n  raw_texts = _read_texts_file(texts_file_path)\n  annotations = _read_annot_file(annot_file_path)\n\n  # Construct replies graph\n  idx_to_parents = {idx: [] for idx in range(len(raw_texts))}\n  for parent_msg_idx, msg_idx in annotations:\n    idx_to_parents[msg_idx].append(parent_msg_idx)\n\n  texts, timestamps = _parse_out_timestamps(raw_texts, day_str)\n\n  for line_idx, parents in idx_to_parents.items():\n    parents_ids = [_get_msg_id(day_str, parent) for parent in parents]\n    yield {\n        _MESSAGE_ID: _get_msg_id(day_str, line_idx),\n        _MESSAGE_TEXT: texts[line_idx],\n        _MESSAGE_TIMESTAMP: timestamps[line_idx],\n        _MESSAGE_PARENTS_IDS: parents_ids\n        }\n\n\nclass IrcDisentanglement(tfds.core.GeneratorBasedBuilder):\n  """"""IRC Disentanglement dataset.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self) -> tfds.core.DatasetInfo:\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _MESSAGE_ID: tfds.features.Text(),\n            _MESSAGE_TEXT: tfds.features.Text(),\n            _MESSAGE_TIMESTAMP: tfds.features.Text(),\n            _MESSAGE_PARENTS_IDS: tfds.features.Sequence(tfds.features.Text()),\n        }),\n        homepage=""https://jkk.name/irc-disentanglement"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager: tfds.download.DownloadManager\n                       ) -> List[tfds.core.SplitGenerator]:\n    """"""Returns SplitGenerators.""""""\n    base_dir = dl_manager.download_and_extract(\n        tfds.download.Resource(\n            url=_DOWNLOAD_URL,\n            # Specify extract method manually as filename reported by github.com\n            # misses the .zip extension so auto-detection doesn\'t work.\n            extract_method=tfds.download.ExtractMethod.ZIP))\n    data_dir = os.path.join(base_dir, _DOWNLOAD_ARCHIVE_SUBDIR)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""day_to_paths"":\n                            _get_day_to_paths(os.path.join(data_dir, ""train""))},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""day_to_paths"":\n                            _get_day_to_paths(os.path.join(data_dir, ""dev""))},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""day_to_paths"":\n                            _get_day_to_paths(os.path.join(data_dir, ""test""))},\n        ),\n    ]\n\n  def _generate_examples(self, day_to_paths):\n    """"""Yields examples.""""""\n    for day, paths in day_to_paths.items():\n      for example in _prepare_examples(paths[""text""], paths[""annot""], day):\n        yield example[_MESSAGE_ID], example\n'"
tensorflow_datasets/text/irc_disentanglement_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python2, python3\n""""""irc_disentanglement dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.text import irc_disentanglement\n\n\nclass IrcDisentanglementTest(tfds.testing.DatasetBuilderTestCase):\n  DATASET_CLASS = irc_disentanglement.IrcDisentanglement\n  SPLITS = {\n      ""train"": 5,  # Number of fake train example\n      ""validation"": 6,  # Number of fake validation example\n      ""test"": 5,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  tfds.testing.test_main()\n\n'"
tensorflow_datasets/text/librispeech_lm.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Librispeech language modeling dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nLanguage modeling resources to be used in conjunction with the LibriSpeech ASR corpus.\n""""""\n\n_URL = \'http://www.openslr.org/11\'\n\n_DL_URL = \'http://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz\'\n\n\nclass LibrispeechLm(tfds.core.GeneratorBasedBuilder):\n  """"""Librispeech language modeling dataset.""""""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'text\': tfds.features.Text(),\n        }),\n        supervised_keys=(\'text\', \'text\'),\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    archive_path = dl_manager.download(_DL_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\'files_iter\': dl_manager.iter_archive(archive_path)},\n        ),\n    ]\n\n  def _generate_examples(self, files_iter):\n    """"""Yields examples.""""""\n    # The archive contains a single file.\n    _, f = next(files_iter)\n    for key, line in enumerate(f):\n      text = line.strip()\n      if text:  # Skip empty lines.\n        yield key, {\'text\': text}\n'"
tensorflow_datasets/text/librispeech_lm_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for LibrispeechLm dataset builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import librispeech_lm\n\n\nclass LibrispeechLmTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = librispeech_lm.LibrispeechLm\n  SPLITS = {\n      ""train"": 4,  # Number of fake train examples.\n  }\n  DL_DOWNLOAD_RESULT = ""librispeech-lm-norm.txt.gz""\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/lm1b.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Language Model 1 Billion dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/ChelbaMSGBK13,\n  author    = {Ciprian Chelba and\n               Tomas Mikolov and\n               Mike Schuster and\n               Qi Ge and\n               Thorsten Brants and\n               Phillipp Koehn},\n  title     = {One Billion Word Benchmark for Measuring Progress in Statistical Language\n               Modeling},\n  journal   = {CoRR},\n  volume    = {abs/1312.3005},\n  year      = {2013},\n  url       = {http://arxiv.org/abs/1312.3005},\n  archivePrefix = {arXiv},\n  eprint    = {1312.3005},\n  timestamp = {Mon, 13 Aug 2018 16:46:16 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/ChelbaMSGBK13},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nA benchmark corpus to be used for measuring progress in statistical language \\\nmodeling. This has almost one billion words in the training data.\n""""""\n\n_DOWNLOAD_URL = (""http://www.statmt.org/lm-benchmark/""\n                 ""1-billion-word-language-modeling-benchmark-r13output.tar.gz"")\n_TOP_LEVEL_DIR = ""1-billion-word-language-modeling-benchmark-r13output""\n_TRAIN_FILE_FORMAT = os.path.join(_TOP_LEVEL_DIR,\n                                  ""training-monolingual.tokenized.shuffled"",\n                                  ""news.en-*"")\n_HELDOUT_FILE_FORMAT = os.path.join(_TOP_LEVEL_DIR,\n                                    ""heldout-monolingual.tokenized.shuffled"",\n                                    ""news.en.heldout-*"")\n\n\nclass Lm1bConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Lm1b.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for Lm1b.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the Lm1b `""text""`\n        feature.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(Lm1bConfig, self).__init__(\n        version=tfds.core.Version(\n            ""1.0.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\ndef _train_data_filenames(tmp_dir):\n  return tf.io.gfile.glob(os.path.join(tmp_dir, _TRAIN_FILE_FORMAT))\n\n\ndef _test_data_filenames(tmp_dir):\n  return tf.io.gfile.glob(os.path.join(tmp_dir, _HELDOUT_FILE_FORMAT))\n\n\nclass Lm1b(tfds.core.GeneratorBasedBuilder):\n  """"""1 Billion Word Language Model Benchmark dataset.""""""\n  BUILDER_CONFIGS = [\n      Lm1bConfig(\n          name=""plain_text"",\n          description=""Plain text"",\n      ),\n      Lm1bConfig(\n          name=""bytes"",\n          description=(""Uses byte-level text encoding with ""\n                       ""`tfds.features.text.ByteTextEncoder`""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder=tfds.features.text.ByteTextEncoder()),\n      ),\n      Lm1bConfig(\n          name=""subwords8k"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with 8k ""\n                       ""vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**13),\n      ),\n      Lm1bConfig(\n          name=""subwords32k"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with ""\n                       ""32k vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**15),\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""text"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n        }),\n        supervised_keys=(""text"", ""text""),\n        homepage=""http://www.statmt.org/lm-benchmark/"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, training_files):\n    for _, ex in self._generate_examples(training_files):\n      yield ex[""text""]\n\n  def _split_generators(self, dl_manager):\n    lm1b_path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n\n    train_files = _train_data_filenames(lm1b_path)\n    test_files = _test_data_filenames(lm1b_path)\n\n    # Generate vocabulary from training data if SubwordTextEncoder configured\n    self.info.features[""text""].maybe_build_from_corpus(\n        self._vocab_text_gen(train_files))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""files"": train_files}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""files"": test_files}),\n    ]\n\n  def _generate_examples(self, files):\n    for filepath in files:\n      logging.info(""generating examples from = %s"", filepath)\n      with tf.io.gfile.GFile(filepath) as f:\n\n        for idx, line in enumerate(f):\n          yield ""%s_%d"" % (os.path.basename(filepath), idx), {\n              ""text"": line.strip(),\n          }\n'"
tensorflow_datasets/text/lm1b_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for lm1b dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import lm1b\n\n\nclass Lm1bTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = lm1b.Lm1b\n  SPLITS = {\n      ""train"": 3,\n      ""test"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/math_dataset.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Mathematics database.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{2019arXiv,\n  author = {Saxton, Grefenstette, Hill, Kohli},\n  title = {Analysing Mathematical Reasoning Abilities of Neural Models},\n  year = {2019},\n  journal = {arXiv:1904.01557}\n}\n""""""\n\n_DESCRIPTION = """"""\nMathematics database.\n\nThis dataset code generates mathematical question and answer pairs,\nfrom a range of question types at roughly school-level difficulty.\nThis is designed to test the mathematical learning and algebraic\nreasoning skills of learning models.\n\nOriginal paper: Analysing Mathematical Reasoning Abilities of Neural Models\n(Saxton, Grefenstette, Hill, Kohli).\n\nExample usage:\n\n```\ntrain_examples, val_examples = tfds.load(\n    \'math_dataset/arithmetic__mul\',\n    split=[\'train\', \'test\'],\n    as_supervised=True)\n```\n""""""\n\n_DATA_URL = ""https://storage.googleapis.com/mathematics-dataset/mathematics_dataset-v1.0.tar.gz""\n\n_TRAIN_CATEGORY = [\n    ""train-easy"",\n    ""train-medium"",\n    ""train-hard"",\n]\n\n_INTERPOLATE_CATEGORY = [\n    ""interpolate"",\n]\n\n_MODULES = [\n    # extrapolate\n    ""measurement__conversion"",\n\n    # interpolate\n    ""algebra__linear_1d"",\n    ""algebra__linear_1d_composed"",\n    ""algebra__linear_2d"",\n    ""algebra__linear_2d_composed"",\n    ""algebra__polynomial_roots"",\n    ""algebra__polynomial_roots_composed"",\n    ""algebra__sequence_next_term"",\n    ""algebra__sequence_nth_term"",\n    ""arithmetic__add_or_sub"",\n    ""arithmetic__add_or_sub_in_base"",\n    ""arithmetic__add_sub_multiple"",\n    ""arithmetic__div"",\n    ""arithmetic__mixed"",\n    ""arithmetic__mul"",\n    ""arithmetic__mul_div_multiple"",\n    ""arithmetic__nearest_integer_root"",\n    ""arithmetic__simplify_surd"",\n    ""calculus__differentiate"",\n    ""calculus__differentiate_composed"",\n    ""comparison__closest"",\n    ""comparison__closest_composed"",\n    ""comparison__kth_biggest"",\n    ""comparison__kth_biggest_composed"",\n    ""comparison__pair"",\n    ""comparison__pair_composed"",\n    ""comparison__sort"",\n    ""comparison__sort_composed"",\n    ""measurement__conversion"",\n    ""measurement__time"",\n    ""numbers__base_conversion"",\n    ""numbers__div_remainder"",\n    ""numbers__div_remainder_composed"",\n    ""numbers__gcd"",\n    ""numbers__gcd_composed"",\n    ""numbers__is_factor"",\n    ""numbers__is_factor_composed"",\n    ""numbers__is_prime"",\n    ""numbers__is_prime_composed"",\n    ""numbers__lcm"",\n    ""numbers__lcm_composed"",\n    ""numbers__list_prime_factors"",\n    ""numbers__list_prime_factors_composed"",\n    ""numbers__place_value"",\n    ""numbers__place_value_composed"",\n    ""numbers__round_number"",\n    ""numbers__round_number_composed"",\n    ""polynomials__add"",\n    ""polynomials__coefficient_named"",\n    ""polynomials__collect"",\n    ""polynomials__compose"",\n    ""polynomials__evaluate"",\n    ""polynomials__evaluate_composed"",\n    ""polynomials__expand"",\n    ""polynomials__simplify_power"",\n    ""probability__swr_p_level_set"",\n    ""probability__swr_p_sequence"",\n\n    # train-easy train-medium train-hard\n    ""algebra__linear_1d"",\n    ""algebra__linear_1d_composed"",\n    ""algebra__linear_2d"",\n    ""algebra__linear_2d_composed"",\n    ""algebra__polynomial_roots"",\n    ""algebra__polynomial_roots_composed"",\n    ""algebra__sequence_next_term"",\n    ""algebra__sequence_nth_term"",\n    ""arithmetic__add_or_sub"",\n    ""arithmetic__add_or_sub_in_base"",\n    ""arithmetic__add_sub_multiple"",\n    ""arithmetic__div"",\n    ""arithmetic__mixed"",\n    ""arithmetic__mul"",\n    ""arithmetic__mul_div_multiple"",\n    ""arithmetic__nearest_integer_root"",\n    ""arithmetic__simplify_surd"",\n    ""calculus__differentiate"",\n    ""calculus__differentiate_composed"",\n    ""comparison__closest"",\n    ""comparison__closest_composed"",\n    ""comparison__kth_biggest"",\n    ""comparison__kth_biggest_composed"",\n    ""comparison__pair"",\n    ""comparison__pair_composed"",\n    ""comparison__sort"",\n    ""comparison__sort_composed"",\n    ""measurement__conversion"",\n    ""measurement__time"",\n    ""numbers__base_conversion"",\n    ""numbers__div_remainder"",\n    ""numbers__div_remainder_composed"",\n    ""numbers__gcd"",\n    ""numbers__gcd_composed"",\n    ""numbers__is_factor"",\n    ""numbers__is_factor_composed"",\n    ""numbers__is_prime"",\n    ""numbers__is_prime_composed"",\n    ""numbers__lcm"",\n    ""numbers__lcm_composed"",\n    ""numbers__list_prime_factors"",\n    ""numbers__list_prime_factors_composed"",\n    ""numbers__place_value"",\n    ""numbers__place_value_composed"",\n    ""numbers__round_number"",\n    ""numbers__round_number_composed"",\n    ""polynomials__add"",\n    ""polynomials__coefficient_named"",\n    ""polynomials__collect"",\n    ""polynomials__compose"",\n    ""polynomials__evaluate"",\n    ""polynomials__evaluate_composed"",\n    ""polynomials__expand"",\n    ""polynomials__simplify_power"",\n    ""probability__swr_p_level_set"",\n    ""probability__swr_p_sequence"",\n]\n\n_QUESTION = ""question""\n_ANSWER = ""answer""\n\n_DATASET_VERSION = ""mathematics_dataset-v1.0""\n\n\ndef _generate_builder_configs():\n  """"""Generate configs with different subsets of mathematics dataset.""""""\n  configs = []\n  for module in sorted(set(_MODULES)):\n    configs.append(\n        tfds.core.BuilderConfig(\n            name=module,\n            version=tfds.core.Version(""1.0.0""),\n            description=_DESCRIPTION,\n        ))\n\n  return configs\n\n\nclass MathDataset(tfds.core.GeneratorBasedBuilder):\n  """"""Math Dataset.""""""\n\n  BUILDER_CONFIGS = _generate_builder_configs()\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _QUESTION: tfds.features.Text(),\n            _ANSWER: tfds.features.Text(),\n        }),\n        supervised_keys=(_QUESTION, _ANSWER),\n        homepage=""https://github.com/deepmind/mathematics_dataset"",\n        citation=_CITATION,\n    )\n\n  def _read_data_from_all_categories(self, directory, config, categories):\n    lines = []\n    for category in categories:\n      data_file = os.path.join(directory, _DATASET_VERSION, category, config)\n      if tf.io.gfile.exists(data_file):\n        with tf.io.gfile.GFile(data_file) as f:\n          ls = f.read().split(""\\n"")\n\n          for l in ls[::-1]:\n            if not l:\n              ls.remove(l)\n\n          lines.extend(ls)\n\n    return lines\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    directory = dl_manager.download_and_extract(_DATA_URL)\n    config = self.builder_config.name + "".txt""\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""directory"": directory,\n                ""config"": config,\n                ""categories"": _TRAIN_CATEGORY,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""directory"": directory,\n                ""config"": config,\n                ""categories"": _INTERPOLATE_CATEGORY,\n            }),\n    ]\n\n  def _generate_examples(self, directory, config, categories):\n    """"""Yields examples based on directory, module file..""""""\n\n    lines = self._read_data_from_all_categories(directory, config, categories)\n    logging.info(""%s: %s contains total: %d"", categories, config, len(lines))\n    questions = lines[::2]\n    answers = lines[1::2]\n\n    assert len(answers) == len(\n        questions), ""answers: %d do not match questions: %d"" % (len(answers),\n                                                                len(questions))\n\n    for idx, (q, a) in enumerate(zip(questions, answers)):\n      result = {_QUESTION: q, _ANSWER: a}\n      if all(result.values()):\n        yield idx, result\n'"
tensorflow_datasets/text/math_dataset_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Mathematical dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import math_dataset\n\n\nclass MathDatasetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = math_dataset.MathDataset\n  BUILDER_CONFIG_NAMES_TO_TEST = [""algebra__linear_1d""]\n  SPLITS = {\n      ""train"": 6,  # Number of fake train example pairs\n      ""test"": 6,  # Number of fake test example pairs\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/movie_rationales.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Movie reviews with human annotated rationales.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@unpublished{eraser2019,\n    title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n    author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n}\n@InProceedings{zaidan-eisner-piatko-2008:nips,\n  author    =  {Omar F. Zaidan  and  Jason Eisner  and  Christine Piatko},\n  title     =  {Machine Learning with Annotator Rationales to Reduce Annotation Cost},\n  booktitle =  {Proceedings of the NIPS*2008 Workshop on Cost Sensitive Learning},\n  month     =  {December},\n  year      =  {2008}\n}\n""""""\n\n_DESCRIPTION = """"""\nThe movie rationale dataset contains human annotated rationales for movie\nreviews.\n""""""\n\n_DOWNLOAD_URL = \'http://www.eraserbenchmark.com/zipped/movies.tar.gz\'\n\n\nclass MovieRationales(tfds.core.GeneratorBasedBuilder):\n  """"""Movie reviews with human annotated rationales.""""""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'review\': tfds.features.Text(),\n            \'label\': tfds.features.ClassLabel(names=[\'NEG\', \'POS\']),\n            \'evidences\': tfds.features.Sequence(tfds.features.Text()),\n        }),\n        supervised_keys=None,\n        homepage=\'http://www.cs.jhu.edu/~ozaidan/rationales/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_dir = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    data_dir = os.path.join(dl_dir, \'movies\')\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'data_dir\': data_dir,\n                \'filepath\': os.path.join(data_dir, \'train.jsonl\')\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'data_dir\': data_dir,\n                \'filepath\': os.path.join(data_dir, \'val.jsonl\')\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'data_dir\': data_dir,\n                \'filepath\': os.path.join(data_dir, \'test.jsonl\')\n            },\n        ),\n    ]\n\n  def _generate_examples(self, data_dir, filepath):\n    """"""Yields examples.""""""\n    reviews_dir = os.path.join(data_dir, \'docs\')\n\n    with tf.io.gfile.GFile(filepath) as f:\n      for line in f:\n        row = json.loads(line)\n        doc_id = row[\'annotation_id\']\n        review_file = os.path.join(reviews_dir, doc_id)\n        with tf.io.gfile.GFile(review_file) as f1:\n          review_text = f1.read()\n\n        evidences = []\n        for evidence in row[\'evidences\']:\n          for e in evidence:\n            evidences.append(e[\'text\'])\n\n        yield doc_id, {\n            \'review\': review_text,\n            \'label\': row[\'classification\'],\n            \'evidences\': evidences,\n        }\n'"
tensorflow_datasets/text/movie_rationales_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for movie rationales dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import movie_rationales\n\n\nclass MovieRationalesTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = movie_rationales.MovieRationales\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/multi_nli.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Multi-Genre NLI Corpus.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{N18-1101,\n  author = ""Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel"",\n  title = ""A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference"",\n  booktitle = ""Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)"",\n  year = ""2018"",\n  publisher = ""Association for Computational Linguistics"",\n  pages = ""1112--1122"",\n  location = ""New Orleans, Louisiana"",\n  url = ""http://aclweb.org/anthology/N18-1101""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe Multi-Genre Natural Language Inference (MultiNLI) corpus is a\ncrowd-sourced collection of 433k sentence pairs annotated with textual\nentailment information. The corpus is modeled on the SNLI corpus, but differs in\nthat covers a range of genres of spoken and written text, and supports a\ndistinctive cross-genre generalization evaluation. The corpus served as the\nbasis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.\n""""""\n\n\nclass MultiNLIConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for MultiNLI.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for MultiNLI.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the features feature.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(MultiNLIConfig, self).__init__(\n        version=tfds.core.Version(\n            ""1.0.0"", ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\nclass MultiNLI(tfds.core.GeneratorBasedBuilder):\n  """"""MultiNLI: The Stanford Question Answering Dataset. Version 1.1.""""""\n\n  BUILDER_CONFIGS = [\n      MultiNLIConfig(\n          name=""plain_text"",\n          description=""Plain text"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""premise"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""hypothesis"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""label"":\n                tfds.features.ClassLabel(\n                    names=[""entailment"", ""neutral"", ""contradiction""]),\n        }),\n        # No default supervised_keys (as we have to pass both premise\n        # and hypothesis as input).\n        supervised_keys=None,\n        homepage=""https://www.nyu.edu/projects/bowman/multinli/"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, filepath):\n    for _, ex in self._generate_examples(filepath):\n      yield "" "".join([ex[""premise""], ex[""hypothesis""]])\n\n  def _split_generators(self, dl_manager):\n\n    downloaded_dir = dl_manager.download_and_extract(\n        ""https://cims.nyu.edu/~sbowman/multinli/multinli_1.0.zip"")\n    mnli_path = os.path.join(downloaded_dir, ""multinli_1.0"")\n    train_path = os.path.join(mnli_path, ""multinli_1.0_train.txt"")\n    matched_validation_path = os.path.join(mnli_path,\n                                           ""multinli_1.0_dev_matched.txt"")\n    mismatched_validation_path = os.path.join(\n        mnli_path, ""multinli_1.0_dev_mismatched.txt"")\n    # Generate shared vocabulary\n    # maybe_build_from_corpus uses SubwordTextEncoder if that\'s configured\n    self.info.features[""premise""].maybe_build_from_corpus(\n        self._vocab_text_gen(train_path))\n    encoder = self.info.features[""premise""].encoder\n    # Use maybe_set_encoder because the encoder may have been restored from\n    # package data.\n    self.info.features[""premise""].maybe_set_encoder(encoder)\n    self.info.features[""hypothesis""].maybe_set_encoder(encoder)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepath"": train_path}),\n        tfds.core.SplitGenerator(\n            name=""validation_matched"",\n            gen_kwargs={""filepath"": matched_validation_path}),\n        tfds.core.SplitGenerator(\n            name=""validation_mismatched"",\n            gen_kwargs={""filepath"": mismatched_validation_path}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Generate mnli examples.\n\n    Args:\n      filepath: a string\n\n    Yields:\n      dictionaries containing ""premise"", ""hypothesis"" and ""label"" strings\n    """"""\n    for idx, line in enumerate(tf.io.gfile.GFile(filepath, ""rb"")):\n      if idx == 0:\n        continue  # skip header\n      line = tf.compat.as_text(line.strip())\n      split_line = line.split(""\\t"")\n      # Examples not marked with a three out of five consensus are marked with\n      # ""-"" and should not be used in standard evaluations.\n      if split_line[0] == ""-"":\n        continue\n      # Works for both splits even though dev has some extra human labels.\n      yield idx, {\n          ""premise"": split_line[5],\n          ""hypothesis"": split_line[6],\n          ""label"": split_line[0]\n      }\n'"
tensorflow_datasets/text/multi_nli_mismatch.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Multi-Genre NLI Corpus.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{N18-1101,\n  author = ""Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel"",\n  title = ""A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference"",\n  booktitle = ""Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)"",\n  year = ""2018"",\n  publisher = ""Association for Computational Linguistics"",\n  pages = ""1112--1122"",\n  location = ""New Orleans, Louisiana"",\n  url = ""http://aclweb.org/anthology/N18-1101""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe Multi-Genre Natural Language Inference (MultiNLI) corpus is a\ncrowd-sourced collection of 433k sentence pairs annotated with textual\nentailment information. The corpus is modeled on the SNLI corpus, but differs in\nthat covers a range of genres of spoken and written text, and supports a\ndistinctive cross-genre generalization evaluation. The corpus served as the\nbasis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.\n""""""\n\nROOT_URL = ""https://cims.nyu.edu/~sbowman/multinli/multinli_1.0.zip""\n\n\nclass MultiNLIMismatchConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for MultiNLI Mismatch.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for MultiNLI Mismatch.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the features feature.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(MultiNLIMismatchConfig, self).__init__(**kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\nclass MultiNLIMismatch(tfds.core.GeneratorBasedBuilder):\n  """"""MultiNLI: The Stanford Question Answering Dataset. Version 1.1.""""""\n\n  BUILDER_CONFIGS = [\n      MultiNLIMismatchConfig(\n          name=""plain_text"",\n          version=""0.0.1"",\n          description=""Plain text"",\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""premise"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""hypothesis"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""label"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n        }),\n        # No default supervised_keys (as we have to pass both premise\n        # and hypothesis as input).\n        supervised_keys=None,\n        homepage=""https://www.nyu.edu/projects/bowman/multinli/"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, filepath):\n    for _, ex in self._generate_examples(filepath):\n      yield "" "".join([ex[""premise""], ex[""hypothesis""], ex[""label""]])\n\n  def _split_generators(self, dl_manager):\n\n    downloaded_dir = dl_manager.download_and_extract(ROOT_URL)\n    mnli_path = os.path.join(downloaded_dir, ""multinli_1.0"")\n    train_path = os.path.join(mnli_path, ""multinli_1.0_train.txt"")\n\n    validation_path = os.path.join(mnli_path, ""multinli_1.0_dev_mismatched.txt"")\n\n    # Generate shared vocabulary\n    # maybe_build_from_corpus uses SubwordTextEncoder if that\'s configured\n    self.info.features[""premise""].maybe_build_from_corpus(\n        self._vocab_text_gen(train_path))\n    encoder = self.info.features[""premise""].encoder\n\n    self.info.features[""premise""].maybe_set_encoder(encoder)\n    self.info.features[""hypothesis""].maybe_set_encoder(encoder)\n    self.info.features[""label""].maybe_set_encoder(encoder)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepath"": train_path}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""filepath"": validation_path}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Generate mnli mismatch examples.\n\n    Args:\n      filepath: a string\n\n    Yields:\n      dictionaries containing ""premise"", ""hypothesis"" and ""label"" strings\n    """"""\n    for idx, line in enumerate(tf.io.gfile.GFile(filepath, ""rb"")):\n      if idx == 0:\n        continue\n      line = tf.compat.as_text(line.strip())\n      split_line = line.split(""\\t"")\n      yield idx, {\n          ""premise"": split_line[5],\n          ""hypothesis"": split_line[6],\n          ""label"": split_line[0]\n      }\n'"
tensorflow_datasets/text/multi_nli_mismatch_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for multinli dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import multi_nli_mismatch\n\n\nclass MultiNLIMismatchTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = multi_nli_mismatch.MultiNLIMismatch\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/multi_nli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for multinli dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import multi_nli\n\n\nclass MultiNLITest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = multi_nli.MultiNLI\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation_matched"": 2,\n      ""validation_mismatched"": 1,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/pg19.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""PG-19 language modeling dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@article{raecompressive2019,\nauthor = {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and\n          Hillier, Chloe and Lillicrap, Timothy P},\ntitle = {Compressive Transformers for Long-Range Sequence Modelling},\njournal = {arXiv preprint},\nurl = {https://arxiv.org/abs/1911.05507},\nyear = {2019},\n}\n""""""\n\n_DESCRIPTION = """"""\nThis dataset contains the PG-19 language modeling benchmark. It includes a set\nof books extracted from the Project Gutenberg books project\n(https://www.gutenberg.org), that were published before 1919. It also contains\nmetadata of book titles and publication dates.\nPG-19 is over double the size of the Billion Word benchmark and contains\ndocuments that are 20X longer, on average, than the WikiText long-range\nlanguage modelling benchmark.\n\nBooks are partitioned into a train, validation, and test set. Books metadata is\nstored in metadata.csv which contains\n(book_id, short_book_title, publication_date, book_link).\n""""""\n\n_DATA_DIR = \'gs://deepmind-gutenberg\'\n\n\nclass Pg19(tfds.core.GeneratorBasedBuilder):\n  """"""This dataset contains the PG-19 language modeling benchmark.""""""\n\n  VERSION = tfds.core.Version(\'0.1.0\')\n\n  def _info(self):\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'book_text\': tfds.features.Text(),\n            \'book_id\': tf.int32,\n            \'book_title\': tf.string,\n            \'publication_date\': tf.string,\n            \'book_link\': tf.string\n        }),\n        supervised_keys=None,\n        homepage=\'https://github.com/deepmind/pg19\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    del dl_manager  # Unused\n\n    metadata_dict = dict()\n    metadata_path = os.path.join(_DATA_DIR, \'metadata.csv\')\n    metadata = tf.io.gfile.GFile(metadata_path).read().splitlines()\n\n    for row in metadata:\n      row_split = row.split(\',\')\n      # book_id: [book_title, publication_date, book_link]\n      metadata_dict[int(row_split[0])] = row_split[1:]\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'metadata\': metadata_dict,\n                \'filepath\': os.path.join(_DATA_DIR, \'train\')},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'metadata\': metadata_dict,\n                \'filepath\': os.path.join(_DATA_DIR, \'validation\')},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'metadata\': metadata_dict,\n                \'filepath\': os.path.join(_DATA_DIR, \'test\')},\n        ),\n    ]\n\n  def _generate_examples(self, filepath, metadata):\n    """"""Yields examples.""""""\n    for file in tf.io.gfile.listdir(filepath):\n      book_id = int(file.rstrip(\'.txt\'))\n      book_data = metadata[book_id]\n      path = os.path.join(filepath, file)\n      with tf.io.gfile.GFile(path, \'r\') as f:\n        text = f.read().strip()\n        yield book_id, {\n            \'book_text\': text,\n            \'book_id\': book_id,\n            \'book_title\': book_data[0],\n            \'publication_date\': book_data[1],\n            \'book_link\': book_data[2],\n        }\n'"
tensorflow_datasets/text/pg19_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for PG-19 dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.text import pg19\n\n\nclass Pg19Test(tfds.testing.DatasetBuilderTestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(Pg19Test, cls).setUpClass()\n    pg19._DATA_DIR = os.path.join(\n        os.path.normpath(os.path.dirname(__file__) + ""/../""),\n        ""testing"",\n        ""test_data"",\n        ""fake_examples"",\n        ""pg19"",\n    )\n\n  DATASET_CLASS = pg19.Pg19\n  SPLITS = {\n      ""train"": 3,   # Number of fake train example\n      ""test"": 1,      # Number of fake test example\n      ""validation"": 1  # Number of fake validation example\n  }\n\nif __name__ == ""__main__"":\n  tfds.testing.test_main()\n'"
tensorflow_datasets/text/qa4mre.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""QA4MRE (CLEF 2011/2012/2013): a reading comprehension dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport xml.etree.ElementTree as ET\nfrom absl import logging\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n# pylint: disable=anomalous-backslash-in-string\n_CITATION = r""""""\n@InProceedings{10.1007/978-3-642-40802-1_29,\nauthor=""Pe{\\~{n}}as, Anselmo\nand Hovy, Eduard\nand Forner, Pamela\nand Rodrigo, {\\\'A}lvaro\nand Sutcliffe, Richard\nand Morante, Roser"",\neditor=""Forner, Pamela\nand M{\\""u}ller, Henning\nand Paredes, Roberto\nand Rosso, Paolo\nand Stein, Benno"",\ntitle=""QA4MRE 2011-2013: Overview of Question Answering for Machine Reading Evaluation"",\nbooktitle=""Information Access Evaluation. Multilinguality, Multimodality, and Visualization"",\nyear=""2013"",\npublisher=""Springer Berlin Heidelberg"",\naddress=""Berlin, Heidelberg"",\npages=""303--320"",\nabstract=""This paper describes the methodology for testing the performance of Machine Reading systems through Question Answering and Reading Comprehension Tests. This was the attempt of the QA4MRE challenge which was run as a Lab at CLEF 2011--2013. The traditional QA task was replaced by a new Machine Reading task, whose intention was to ask questions that required a deep knowledge of individual short texts and in which systems were required to choose one answer, by analysing the corresponding test document in conjunction with background text collections provided by the organization. Four different tasks have been organized during these years: Main Task, Processing Modality and Negation for Machine Reading, Machine Reading of Biomedical Texts about Alzheimer\'s disease, and Entrance Exams. This paper describes their motivation, their goals, their methodology for preparing the data sets, their background collections, their metrics used for the evaluation, and the lessons learned along these three years."",\nisbn=""978-3-642-40802-1""\n}\n""""""\n\n_DESCRIPTION = """"""\nQA4MRE dataset was created for the CLEF 2011/2012/2013 shared tasks to promote research in \nquestion answering and reading comprehension. The dataset contains a supporting \npassage and a set of questions corresponding to the passage. Multiple options \nfor answers are provided for each question, of which only one is correct. The \ntraining and test datasets are available for the main track.\nAdditional gold standard documents are available for two pilot studies: one on \nalzheimers data, and the other on entrance exams data.\n""""""\n\n_BASE_URL = \'http://nlp.uned.es/clef-qa/repository/js/scripts/downloadFile.php?file=/var/www/html/nlp/clef-qa/repository/resources/QA4MRE/\'\n\nPATHS = {\n    \'2011\': {\n        \'_TRACKS\': (\'main\'),\n        \'_PATH_TMPL_MAIN_GS\':\n            \'2011/Training_Data/Goldstandard/QA4MRE-2011-{}_GS.xml\',\n        \'_LANGUAGES_MAIN\': (\'DE\', \'EN\', \'ES\', \'IT\', \'RO\'),\n    },\n    \'2012\': {\n        \'_TRACKS\': (\'main\', \'alzheimers\'),\n        \'_PATH_TMPL_MAIN_GS\':\n            \'2012/Main_Task/Training_Data/Goldstandard/Used_in_Evaluation/QA4MRE-2012-{}_GS.xml\',\n        \'_LANGUAGES_MAIN\': (\'AR\', \'BG\', \'DE\', \'EN\', \'ES\', \'IT\', \'RO\'),\n        \'_PATH_ALZHEIMER\':\n            \'2012/Pilot_Tasks/Biomedical_About_Alzheimer/Training_Data/Goldstandard/QA4MRE-2012_BIOMEDICAL_GS.xml\',\n    },\n    \'2013\': {\n        \'_TRACKS\': (\'main\', \'alzheimers\', \'entrance_exam\'),\n        \'_PATH_TMPL_MAIN_GS\':\n            \'2013/Main_Task/Training_Data/Goldstandard/QA4MRE-2013-{}_GS.xml\',\n        \'_LANGUAGES_MAIN\': (\'AR\', \'BG\', \'EN\', \'ES\', \'RO\'),\n        \'_PATH_ALZHEIMER\':\n            \'2013/Biomedical_About_Alzheimer/Training_Data/Goldstandard/QA4MRE-2013_BIO_GS-RUN.xml\',\n        \'_PATH_ENTRANCE_EXAM\':\n            \'2013/Entrance_Exams/Training_Data/Goldstandard/qa4mre-exam-test-withanswer.xml\',\n    }\n}\n\n\ndef _get_question(topic_id, topic_name, test_id, document_id, document_str,\n                  question):\n  """"""Gets instance ID and features for every question.\n\n  Args:\n    topic_id: string\n    topic_name: string\n    test_id: string\n    document_id: string\n    document_str: string\n    question: XML element for question\n\n  Returns:\n    id_: string. Unique ID for instance.\n    feats: dict of instance features\n  """"""\n\n  question_id = question.attrib[\'q_id\']\n  for q_text in question.iter(\'q_str\'):\n    question_str = q_text.text\n  possible_answers = list()\n  for answer in question.iter(\'answer\'):\n    answer_id = answer.attrib[\'a_id\']\n    answer_str = answer.text\n    possible_answers.append({\'answer_id\': answer_id, \'answer_str\': answer_str})\n    if \'correct\' in answer.attrib:\n      correct_answer_id = answer_id\n      correct_answer_str = answer_str\n\n  id_ = \'_\'.join([topic_id, topic_name, test_id, question_id])\n  logging.info(\'ID: %s\', id_)\n\n  feats = {\n      \'topic_id\': topic_id,\n      \'topic_name\': topic_name,\n      \'test_id\': test_id,\n      \'document_id\': document_id,\n      \'document_str\': document_str,\n      \'question_id\': question_id,\n      \'question_str\': question_str,\n      \'answer_options\': possible_answers,\n      \'correct_answer_id\': correct_answer_id,\n      \'correct_answer_str\': correct_answer_str,\n  }\n\n  return id_, feats\n\n\nclass Qa4mreConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Qa4mre.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, year, track=\'main\', language=\'EN\', **kwargs):\n    """"""BuilderConfig for Qa4Mre.\n\n    Args:\n      year: string, year of dataset\n      track: string, the task track from PATHS[year][\'_TRACKS\'].\n      language: string, Acronym for language in the main task.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    if track.lower() not in PATHS[year][\'_TRACKS\']:\n      raise ValueError(\n          \'Incorrect track. Track should be one of the following: \',\n          PATHS[year][\'_TRACKS\'])\n\n    if track.lower() != \'main\' and language.upper() != \'EN\':\n      logging.warn(\'Only English documents available for pilot \'\n                   \'tracks. Setting English by default.\')\n      language = \'EN\'\n\n    if track.lower() == \'main\' and language.upper(\n    ) not in PATHS[year][\'_LANGUAGES_MAIN\']:\n      raise ValueError(\n          \'Incorrect language for the main track. Correct options: \',\n          PATHS[year][\'_LANGUAGES_MAIN\'])\n\n    self.year = year\n    self.track = track.lower()\n    self.lang = language.upper()\n\n    name = self.year + \'.\' + self.track + \'.\' + self.lang\n\n    description = _DESCRIPTION\n    description += (\'This configuration includes the {} track for {} language \'\n                    \'in {} year.\').format(self.track, self.lang, self.year)\n\n    super(Qa4mreConfig, self).__init__(\n        name=name,\n        description=description,\n        version=tfds.core.Version(\'0.1.0\'),\n        **kwargs)\n\n\nclass Qa4mre(tfds.core.GeneratorBasedBuilder):\n  """"""QA4MRE dataset from CLEF shared tasks 2011, 2012, 2013.""""""\n\n  BUILDER_CONFIGS = [\n      Qa4mreConfig(year=\'2011\', track=\'main\',\n                   language=\'DE\'),  # 2011 Main track German (2011.main.DE)\n      Qa4mreConfig(year=\'2011\', track=\'main\',\n                   language=\'EN\'),  # 2011 Main track English (2011.main.EN)\n      Qa4mreConfig(year=\'2011\', track=\'main\',\n                   language=\'ES\'),  # 2011 Main track Spanish (2011.main.ES)\n      Qa4mreConfig(year=\'2011\', track=\'main\',\n                   language=\'IT\'),  # 2011 Main track Italian (2011.main.IT)\n      Qa4mreConfig(year=\'2011\', track=\'main\',\n                   language=\'RO\'),  # 2011 Main track Romanian (2011.main.RO)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'AR\'),  # 2012 Main track Arabic (2012.main.AR)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'BG\'),  # 2012 Main track Bulgarian (2012.main.BG)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'DE\'),  # 2012 Main track German (2012.main.DE)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'EN\'),  # 2012 Main track English (2012.main.EN)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'ES\'),  # 2012 Main track Spanish (2012.main.ES)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'IT\'),  # 2012 Main track Italian (2012.main.IT)\n      Qa4mreConfig(year=\'2012\', track=\'main\',\n                   language=\'RO\'),  # 2012 Main track Romanian (2012.main.RO)\n      Qa4mreConfig(year=\'2012\', track=\'alzheimers\',\n                   language=\'EN\'),  # (2012.alzheimers.EN)\n      Qa4mreConfig(year=\'2013\', track=\'main\',\n                   language=\'AR\'),  # 2013 Main track Arabic (2013.main.AR)\n      Qa4mreConfig(year=\'2013\', track=\'main\',\n                   language=\'BG\'),  # 2013 Main track Bulgarian (2013.main.BG)\n      Qa4mreConfig(year=\'2013\', track=\'main\',\n                   language=\'EN\'),  # 2013 Main track English (2013.main.EN)\n      Qa4mreConfig(year=\'2013\', track=\'main\',\n                   language=\'ES\'),  # 2013 Main track Spanish (2013.main.ES)\n      Qa4mreConfig(year=\'2013\', track=\'main\',\n                   language=\'RO\'),  # 2013 Main track Romanian (2013.main.RO)\n      Qa4mreConfig(year=\'2013\', track=\'alzheimers\',\n                   language=\'EN\'),  # (2013.alzheimers.EN)\n      Qa4mreConfig(year=\'2013\', track=\'entrance_exam\',\n                   language=\'EN\'),  # (2013.entrance_exam.EN)\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            \'topic_id\':\n                tfds.features.Text(),\n            \'topic_name\':\n                tfds.features.Text(),\n            \'test_id\':\n                tfds.features.Text(),\n            \'document_id\':\n                tfds.features.Text(),\n            \'document_str\':\n                tfds.features.Text(),\n            \'question_id\':\n                tfds.features.Text(),\n            \'question_str\':\n                tfds.features.Text(),\n            \'answer_options\':\n                tfds.features.Sequence({\n                    \'answer_id\': tfds.features.Text(),\n                    \'answer_str\': tfds.features.Text()\n                }),\n            \'correct_answer_id\':\n                tfds.features.Text(),\n            \'correct_answer_str\':\n                tfds.features.Text(),\n        }),\n\n        # No default supervised keys because both passage and question are used\n        # to determine the correct answer.\n        supervised_keys=None,\n        homepage=\'http://nlp.uned.es/clef-qa/repository/pastCampaigns.php\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    cfg = self.builder_config\n    download_urls = dict()\n\n    if cfg.track == \'main\':\n      download_urls[\'{}.main.{}\'.format(cfg.year, cfg.lang)] = os.path.join(\n          _BASE_URL, PATHS[cfg.year][\'_PATH_TMPL_MAIN_GS\'].format(cfg.lang))\n\n    if cfg.year in [\'2012\', \'2013\'] and cfg.track == \'alzheimers\':\n      download_urls[\'{}.alzheimers.EN\'.format(cfg.year)] = os.path.join(\n          _BASE_URL, PATHS[cfg.year][\'_PATH_ALZHEIMER\'])\n\n    if cfg.year == \'2013\' and cfg.track == \'entrance_exam\':\n      download_urls[\'2013.entrance_exam.EN\'] = os.path.join(\n          _BASE_URL, PATHS[cfg.year][\'_PATH_ENTRANCE_EXAM\'])\n\n    downloaded_files = dl_manager.download_and_extract(download_urls)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'filepath\':\n                    downloaded_files[\'{}.{}.{}\'.format(cfg.year, cfg.track,\n                                                       cfg.lang)]\n            })\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(filepath, \'rb\') as f:\n      tree = ET.parse(f)\n      root = tree.getroot()  # test-set\n      for topic in root:\n        topic_id = topic.attrib[\'t_id\']\n        topic_name = topic.attrib[\'t_name\']\n        for test in topic:\n          test_id = test.attrib[\'r_id\']\n          for document in test.iter(\'doc\'):\n            document_id = document.attrib[\'d_id\']\n            document_str = document.text\n          for question in test.iter(\'q\'):\n            yield _get_question(topic_id, topic_name, test_id, document_id,\n                                document_str, question)\n'"
tensorflow_datasets/text/qa4mre_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Qa4mre dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import qa4mre\n\n\nclass Qa4mreMainTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = qa4mre.Qa4mre\n\n  DL_EXTRACT_RESULT = {\n      ""2011.main.DE"": ""2011.main.DE.xml"",\n      ""2011.main.EN"": ""2011.main.EN.xml"",\n      ""2011.main.ES"": ""2011.main.ES.xml"",\n      ""2011.main.IT"": ""2011.main.IT.xml"",\n      ""2011.main.RO"": ""2011.main.RO.xml"",\n      ""2012.main.AR"": ""2012.main.AR.xml"",\n      ""2012.main.BG"": ""2012.main.BG.xml"",\n      ""2012.main.DE"": ""2012.main.DE.xml"",\n      ""2012.main.EN"": ""2012.main.EN.xml"",\n      ""2012.main.ES"": ""2012.main.ES.xml"",\n      ""2012.main.IT"": ""2012.main.IT.xml"",\n      ""2012.main.RO"": ""2012.main.RO.xml"",\n      ""2012.alzheimers.EN"": ""2012.alzheimers.EN.xml"",\n      ""2013.main.AR"": ""2013.main.AR.xml"",\n      ""2013.main.BG"": ""2013.main.BG.xml"",\n      ""2013.main.EN"": ""2013.main.EN.xml"",\n      ""2013.main.ES"": ""2013.main.ES.xml"",\n      ""2013.main.RO"": ""2013.main.RO.xml"",\n      ""2013.alzheimers.EN"": ""2013.alzheimers.EN.xml"",\n      ""2013.entrance_exam.EN"": ""2013.entrance_exam.EN.xml""\n  }\n\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/scan.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SCAN tasks with various different splits.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{Lake2018GeneralizationWS,\n  title={Generalization without Systematicity: On the Compositional Skills of\n         Sequence-to-Sequence Recurrent Networks},\n  author={Brenden M. Lake and Marco Baroni},\n  booktitle={ICML},\n  year={2018},\n  url={https://arxiv.org/pdf/1711.00350.pdf},\n}\n@inproceedings{Keysers2020,\n  title={Measuring Compositional Generalization: A Comprehensive Method on\n         Realistic Data},\n  author={Daniel Keysers and Nathanael Sch\\""{a}rli and Nathan Scales and\n          Hylke Buisman and Daniel Furrer and Sergii Kashubin and\n          Nikola Momchev and Danila Sinopalnikov and Lukasz Stafiniak and\n          Tibor Tihon and Dmitry Tsarkov and Xiao Wang and Marc van Zee and\n          Olivier Bousquet},\n  note={Additional citation for MCD splits},\n  booktitle={ICLR},\n  year={2020},\n  url={https://arxiv.org/abs/1912.09713.pdf},\n}\n""""""\n\n_DESCRIPTION = """"""SCAN tasks with various splits.\n\nSCAN is a set of simple language-driven navigation tasks for studying\ncompositional learning and zero-shot generalization.\n\nMost splits are described at https://github.com/brendenlake/SCAN. For the MCD\nsplits please see https://arxiv.org/abs/1912.09713.pdf.\n\nBasic usage:\n\n```\ndata = tfds.load(\'scan/length\')\n```\n\nMore advanced example:\n\n```\ndata = tfds.load(\n    \'scan\',\n    builder_kwargs=dict(\n        config=tfds.text.ScanConfig(\n            name=\'simple_p8\', directory=\'simple_split/size_variations\')))\n```\n""""""\n\n_DATA_URL = \'https://github.com/brendenlake/SCAN/archive/master.zip\'\n_MCD_SPLITS_URL = (\n    \'https://storage.googleapis.com/cfq_dataset/scan-splits.tar.gz\')\n\n\nclass ScanConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for SCAN.\n\n  Splits can be read in two formats:\n\n  1) As a pair of train and test files where each file contains one example\n     input and output per line.\n  2) With a \'splitfile\' which contains for each split the indices into the full\n     (unsplit) dataset.\n  """"""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, name, directory=None, splitfile=None, **kwargs):\n    """"""BuilderConfig for SCAN.\n\n    Args:\n      name: Unique name of the split.\n      directory: Which subdirectory to read the data files from.\n      splitfile: If set the samples are read from the original archive\n        (tasks.txt) but the splits are created using this index file.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    # Version history:\n    super(ScanConfig, self).__init__(\n        name=name,\n        version=tfds.core.Version(\'1.1.1\'),\n        description=_DESCRIPTION,\n        **kwargs)\n    self.splitfile = splitfile\n    if \'mcd\' in name:\n      self.splitfile = name + \'.json\'\n    if self.splitfile and directory is None:\n      self.directory = \'\'\n    elif directory is None:\n      self.directory = name + \'_split\'\n    else:\n      self.directory = directory\n\n\n_COMMANDS = \'commands\'\n_ACTIONS = \'actions\'\n\n\nclass Scan(tfds.core.GeneratorBasedBuilder):\n  """"""SCAN task / splits as proposed by Brenden M. Lake and Marco Baroni.""""""\n\n  BUILDER_CONFIGS = [\n      ScanConfig(name=\'simple\'),\n      ScanConfig(name=\'addprim_jump\', directory=\'add_prim_split\'),\n      ScanConfig(name=\'addprim_turn_left\', directory=\'add_prim_split\'),\n      ScanConfig(name=\'filler_num0\', directory=\'filler_split\'),\n      ScanConfig(name=\'filler_num1\', directory=\'filler_split\'),\n      ScanConfig(name=\'filler_num2\', directory=\'filler_split\'),\n      ScanConfig(name=\'filler_num3\', directory=\'filler_split\'),\n      ScanConfig(name=\'length\'),\n      ScanConfig(name=\'template_around_right\', directory=\'template_split\'),\n      ScanConfig(name=\'template_jump_around_right\', directory=\'template_split\'),\n      ScanConfig(name=\'template_opposite_right\', directory=\'template_split\'),\n      ScanConfig(name=\'template_right\', directory=\'template_split\'),\n      ScanConfig(name=\'mcd1\'),\n      ScanConfig(name=\'mcd2\'),\n      ScanConfig(name=\'mcd3\'),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            _COMMANDS: tfds.features.Text(),\n            _ACTIONS: tfds.features.Text(),\n        }),\n        supervised_keys=(_COMMANDS, _ACTIONS),\n        homepage=\'https://github.com/brendenlake/SCAN\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    data_dir = dl_manager.download_and_extract(\n        tfds.download.Resource(\n            url=_DATA_URL,\n            # Specify extract method manually as filename reported by github.com\n            # misses the .zip extension so auto-detection doesn\'t work.\n            extract_method=tfds.download.ExtractMethod.ZIP))\n    data_dir = os.path.join(data_dir, \'SCAN-master\',\n                            self.builder_config.directory)\n    split = self.builder_config.name\n    splitfile = self.builder_config.splitfile\n    if \'mcd\' in split:\n      split_dir = dl_manager.download_and_extract(_MCD_SPLITS_URL)\n      split_dir = os.path.join(split_dir, \'scan-splits\')\n      splitfile = os.path.join(split_dir, splitfile)\n    if splitfile:\n      kwargs = {\n          \'datapath\': os.path.join(data_dir, \'tasks.txt\'),\n          \'splitpath\': splitfile\n      }\n      train_kwargs = kwargs.copy()\n      train_kwargs[\'splitname\'] = \'train\'\n      test_kwargs = kwargs.copy()\n      test_kwargs[\'splitname\'] = \'test\'\n    else:\n      train_kwargs = {\n          \'datapath\': os.path.join(data_dir, \'tasks_train_\' + split + \'.txt\')\n      }\n      test_kwargs = {\n          \'datapath\': os.path.join(data_dir, \'tasks_test_\' + split + \'.txt\')\n      }\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN, gen_kwargs=train_kwargs),\n        tfds.core.SplitGenerator(name=tfds.Split.TEST, gen_kwargs=test_kwargs)\n    ]\n\n  def _read_examples(self, datapath):\n    with tf.io.gfile.GFile(datapath) as infile:\n      for i, line in enumerate(infile):\n        if not line.startswith(\'IN: \'):\n          continue\n        # Chop the prefix and split string between input and output\n        commands, actions = line[len(\'IN: \'):].strip().split(\' OUT: \', 1)\n        yield i, {_COMMANDS: commands, _ACTIONS: actions}\n\n  def _generate_examples(self, datapath, splitpath=None, splitname=None):\n    """"""Yields examples.""""""\n    if splitpath:\n      all_samples = list(self._read_examples(datapath))\n      with tf.io.gfile.GFile(splitpath) as infile:\n        split = json.load(infile)\n      for idx in split[splitname + \'Idxs\']:\n        yield all_samples[idx]\n    else:\n      for example in self._read_examples(datapath):\n        yield example\n'"
tensorflow_datasets/text/scan_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for SCAN dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import scan\n\n\nclass ScanTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = scan.Scan\n  BUILDER_CONFIG_NAMES_TO_TEST = [""simple""]\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n      ""test"": 1,  # Number of fake test example\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/scicite.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The scicite dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n\n_CITATION = """"""\n@InProceedings{Cohan2019Structural,\n  author={Arman Cohan and Waleed Ammar and Madeleine Van Zuylen and Field Cady},\n  title={Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n  booktitle=""NAACL"",\n  year=""2019""\n}\n""""""\n\n_DESCRIPTION = """"""\nThis is a dataset for classifying citation intents in academic papers.\nThe main citation intent label for each Json object is specified with the label\nkey while the citation context is specified in with a context key. Example:\n{\n \'string\': \'In chacma baboons, male-infant relationships can be linked to both\n    formation of friendships and paternity success [30,31].\'\n \'sectionName\': \'Introduction\',\n \'label\': \'background\',\n \'citingPaperId\': \'7a6b2d4b405439\',\n \'citedPaperId\': \'9d1abadc55b5e0\',\n ...\n }\nYou may obtain the full information about the paper using the provided paper ids\nwith the Semantic Scholar API (https://api.semanticscholar.org/).\nThe labels are:\nMethod, Background, Result\n""""""\n\n_SOURCE_NAMES = [\n    ""properNoun"", ""andPhrase"", ""acronym"", ""etAlPhrase"", ""explicit"",\n    ""acronymParen"", ""nan""\n]\n\n\nclass Scicite(tfds.core.GeneratorBasedBuilder):\n  """"""This is a dataset for classifying citation intents in academic papers.""""""\n\n  VERSION = tfds.core.Version(""1.0.0"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        # This is the description that will appear on the datasets page.\n        description=_DESCRIPTION,\n        # tfds.features.FeatureConnectors\n        features=tfds.features.FeaturesDict({\n            ""string"":\n                tfds.features.Text(),\n            ""sectionName"":\n                tfds.features.Text(),\n            ""label"":\n                tfds.features.ClassLabel(\n                    names=[""method"", ""background"", ""result""]),\n            ""citingPaperId"":\n                tfds.features.Text(),\n            ""citedPaperId"":\n                tfds.features.Text(),\n            ""excerpt_index"":\n                tf.int32,\n            ""isKeyCitation"":\n                tf.bool,\n            ""label2"":\n                tfds.features.ClassLabel(names=[\n                    ""supportive"", ""not_supportive"", ""cant_determine"", ""none""\n                ]),\n            ""citeEnd"":\n                tf.int64,\n            ""citeStart"":\n                tf.int64,\n            ""source"":\n                tfds.features.ClassLabel(names=_SOURCE_NAMES),\n            ""label_confidence"":\n                tf.float32,\n            ""label2_confidence"":\n                tf.float32,\n            ""id"":\n                tfds.features.Text(),\n        }),\n        # If there\'s a common (input, target) tuple from the features,\n        # specify them here. They\'ll be used if as_supervised=True in\n        # builder.as_dataset.\n        supervised_keys=(""string"", ""label""),\n        # Homepage of the dataset for documentation\n        homepage=""https://github.com/allenai/scicite"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    dl_paths = dl_manager.download_and_extract({\n        ""scicite"":\n            ""https://s3-us-west-2.amazonaws.com/ai2-s2-research/scicite/scicite.tar.gz"",\n    })\n    path = os.path.join(dl_paths[""scicite""], ""scicite"")\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""path"": os.path.join(path, ""train.jsonl"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""path"": os.path.join(path, ""dev.jsonl"")},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""path"": os.path.join(path, ""test.jsonl"")},\n        ),\n    ]\n\n  def _generate_examples(self, path=None):\n    """"""Yields examples.""""""\n    with tf.io.gfile.GFile(path) as f:\n      unique_ids = {}\n      for line in f:\n        d = json.loads(line)\n        unique_id = str(d[""unique_id""])\n        if unique_id in unique_ids:\n          continue\n        unique_ids[unique_id] = True\n        yield unique_id, {\n            ""string"": d[""string""],\n            ""label"": str(d[""label""]),\n            ""sectionName"": str(d[""sectionName""]),\n            ""citingPaperId"": str(d[""citingPaperId""]),\n            ""citedPaperId"": str(d[""citedPaperId""]),\n            ""excerpt_index"": int(d[""excerpt_index""]),\n            ""isKeyCitation"": bool(d[""isKeyCitation""]),\n            ""label2"": str(d.get(""label2"", ""none"")),\n            ""citeEnd"": _safe_int(d[""citeEnd""]),\n            ""citeStart"": _safe_int(d[""citeStart""]),\n            ""source"": str(d[""source""]),\n            ""label_confidence"": float(d.get(""label_confidence"", 0.)),\n            ""label2_confidence"": float(d.get(""label2_confidence"", 0.)),\n            ""id"": str(d[""id""]),\n        }\n\n\ndef _safe_int(a):\n  try:\n    # skip NaNs\n    return int(a)\n  except ValueError:\n    return -1\n'"
tensorflow_datasets/text/scicite_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for scicite dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import scicite\n\n\nclass SciciteTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = scicite.Scicite\n  SPLITS = {\n      ""train"": 3,  # Number of fake train example\n      ""validation"": 1,  # Number of fake validation example\n      ""test"": 1,  # Number of fake test example\n  }\n  DL_EXTRACT_RESULT = {""scicite"": """"}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/snli.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The Stanford Natural Language Inference (SNLI) Corpus.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@inproceedings{snli:emnlp2015,\n\tAuthor = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\n\tBooktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n\tPublisher = {Association for Computational Linguistics},\n\tTitle = {A large annotated corpus for learning natural language inference},\n\tYear = {2015}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe SNLI corpus (version 1.0) is a collection of 570k human-written English\nsentence pairs manually labeled for balanced classification with the labels\nentailment, contradiction, and neutral, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).\n""""""\n\n_DATA_URL = \'https://nlp.stanford.edu/projects/snli/snli_1.0.zip\'\n\n\nclass Snli(tfds.core.GeneratorBasedBuilder):\n  """"""The Stanford Natural Language Inference (SNLI) Corpus.""""""\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'plain_text\',\n          version=tfds.core.Version(\n              \'1.0.0\',\n              \'New split API (https://tensorflow.org/datasets/splits)\'),\n          description=\'Plain text import of SNLI\',\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'premise\':\n                tfds.features.Text(),\n            \'hypothesis\':\n                tfds.features.Text(),\n            \'label\':\n                tfds.features.ClassLabel(\n                    names=[\'entailment\', \'neutral\', \'contradiction\']),\n        }),\n        # No default supervised_keys (as we have to pass both premise\n        # and hypothesis as input).\n        supervised_keys=None,\n        homepage=\'https://nlp.stanford.edu/projects/snli/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n    data_dir = os.path.join(dl_dir, \'snli_1.0\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'filepath\': os.path.join(data_dir, \'snli_1.0_test.txt\')\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'filepath\': os.path.join(data_dir,\n                                                 \'snli_1.0_dev.txt\')}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'filepath\': os.path.join(data_dir, \'snli_1.0_train.txt\')\n            }),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(filepath) as f:\n      reader = csv.DictReader(f, delimiter=\'\\t\', quoting=csv.QUOTE_NONE)\n      for idx, row in enumerate(reader):\n        label = -1 if row[\'gold_label\'] == \'-\' else row[\'gold_label\']\n        yield idx, {\n            \'premise\': row[\'sentence1\'],\n            \'hypothesis\': row[\'sentence2\'],\n            \'label\': label,\n        }\n'"
tensorflow_datasets/text/snli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for snli dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import snli\n\n\nclass SnliTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = snli.Snli\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/super_glue.py,16,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The SuperGLUE benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_SUPER_GLUE_CITATION = """"""\\\n@article{wang2019superglue,\n  title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},\n  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1905.00537},\n  year={2019}\n}\n\nNote that each SuperGLUE dataset has its own citation. Please see the source to\nget the correct citation for each contained dataset.\n""""""\n\n_GLUE_DESCRIPTION = """"""\\\nSuperGLUE (https://super.gluebenchmark.com/) is a new benchmark styled after\nGLUE with a new set of more difficult language understanding tasks, improved\nresources, and a new public leaderboard.\n\n""""""\n\n_BOOLQ_DESCRIPTION = """"""\\\nBoolQ (Boolean Questions, Clark et al., 2019a) is a QA task where each example consists of a short\npassage and a yes/no question about the passage. The questions are provided anonymously and\nunsolicited by users of the Google search engine, and afterwards paired with a paragraph from a\nWikipedia article containing the answer. Following the original work, we evaluate with accuracy.""""""\n\n_CB_DESCRIPTION = """"""\\\nThe CommitmentBank (De Marneffe et al., 2019) is a corpus of short texts in which at least\none sentence contains an embedded clause. Each of these embedded clauses is annotated with the\ndegree to which we expect that the person who wrote the text is committed to the truth of the clause.\nThe resulting task framed as three-class textual entailment on examples that are drawn from the Wall\nStreet Journal, fiction from the British National Corpus, and Switchboard. Each example consists\nof a premise containing an embedded clause and the corresponding hypothesis is the extraction of\nthat clause. We use a subset of the data that had inter-annotator agreement above 0.85. The data is\nimbalanced (relatively fewer neutral examples), so we evaluate using accuracy and F1, where for\nmulti-class F1 we compute the unweighted average of the F1 per class.""""""\n\n_COPA_DESCRIPTION = """"""\\\nThe Choice Of Plausible Alternatives (COPA, Roemmele et al., 2011) dataset is a causal\nreasoning task in which a system is given a premise sentence and two possible alternatives. The\nsystem must choose the alternative which has the more plausible causal relationship with the premise.\nThe method used for the construction of the alternatives ensures that the task requires causal reasoning\nto solve. Examples either deal with alternative possible causes or alternative possible effects of the\npremise sentence, accompanied by a simple question disambiguating between the two instance\ntypes for the model. All examples are handcrafted and focus on topics from online blogs and a\nphotography-related encyclopedia. Following the recommendation of the authors, we evaluate using\naccuracy.""""""\n\n_RECORD_DESCRIPTION = """"""\\\n(Reading Comprehension with Commonsense Reasoning Dataset, Zhang et al., 2018) is a\nmultiple-choice QA task. Each example consists of a news article and a Cloze-style question about\nthe article in which one entity is masked out. The system must predict the masked out entity from a\ngiven list of possible entities in the provided passage, where the same entity may be expressed using\nmultiple different surface forms, all of which are considered correct. Articles are drawn from CNN\nand Daily Mail. Following the original work, we evaluate with max (over all mentions) token-level\nF1 and exact match (EM).""""""\n\n_RTE_DESCRIPTION = """"""\\\nThe Recognizing Textual Entailment (RTE) datasets come from a series of annual competitions\non textual entailment, the problem of predicting whether a given premise sentence entails a given\nhypothesis sentence (also known as natural language inference, NLI). RTE was previously included\nin GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan\net al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli\net al., 2009). All datasets are combined and converted to two-class classification: entailment and\nnot_entailment. Of all the GLUE tasks, RTE was among those that benefited from transfer learning\nthe most, jumping from near random-chance performance (~56%) at the time of GLUE\'s launch to\n85% accuracy (Liu et al., 2019c) at the time of writing. Given the eight point gap with respect to\nhuman performance, however, the task is not yet solved by machines, and we expect the remaining\ngap to be difficult to close.""""""\n\n_MULTIRC_DESCRIPTION = """"""\\\nThe Multi-Sentence Reading Comprehension dataset (MultiRC, Khashabi et al., 2018)\nis a true/false question-answering task. Each example consists of a context paragraph, a question\nabout that paragraph, and a list of possible answers to that question which must be labeled as true or\nfalse. Question-answering (QA) is a popular problem with many datasets. We use MultiRC because\nof a number of desirable properties: (i) each question can have multiple possible correct answers,\nso each question-answer pair must be evaluated independent of other pairs, (ii) the questions are\ndesigned such that answering each question requires drawing facts from multiple context sentences,\nand (iii) the question-answer pair format more closely matches the API of other SuperGLUE tasks\nthan span-based extractive QA does. The paragraphs are drawn from seven domains including news,\nfiction, and historical text.""""""\n\n_WIC_DESCRIPTION = """"""\\\nThe Word-in-Context (WiC, Pilehvar and Camacho-Collados, 2019) dataset supports a word\nsense disambiguation task cast as binary classification over sentence pairs. Given two sentences and a\npolysemous (sense-ambiguous) word that appears in both sentences, the task is to determine whether\nthe word is used with the same sense in both sentences. Sentences are drawn from WordNet (Miller,\n1995), VerbNet (Schuler, 2005), and Wiktionary. We follow the original work and evaluate using\naccuracy.""""""\n\n_WSC_DESCRIPTION = """"""\\\nThe Winograd Schema Challenge (WSC, Levesque et al., 2012) is a reading comprehension\ntask in which a system must read a sentence with a pronoun and select the referent of that pronoun\nfrom a list of choices. Given the difficulty of this task and the headroom still left, we have included\nWSC in SuperGLUE and recast the dataset into its coreference form. The task is cast as a binary\nclassification problem, as opposed to N-multiple choice, in order to isolate the model\'s ability to\nunderstand the coreference links within a sentence as opposed to various other strategies that may\ncome into play in multiple choice conditions. With that in mind, we create a split with 65% negative\nmajority class in the validation set, reflecting the distribution of the hidden test set, and 52% negative\nclass in the training set. The training and validation examples are drawn from the original Winograd\nSchema dataset (Levesque et al., 2012), as well as those distributed by the affiliated organization\nCommonsense Reasoning. The test examples are derived from fiction books and have been shared\nwith us by the authors of the original dataset. Previously, a version of WSC recast as NLI as included\nin GLUE, known as WNLI. No substantial progress was made on WNLI, with many submissions\nopting to submit only majority class predictions. WNLI was made especially difficult due to an\nadversarial train/dev split: Premise sentences that appeared in the training set sometimes appeared\nin the development set with a different hypothesis and a flipped label. If a system memorized the\ntraining set without meaningfully generalizing, which was easy due to the small size of the training\nset, it could perform far below chance on the development set. We remove this adversarial design\nin the SuperGLUE version of WSC by ensuring that no sentences are shared between the training,\nvalidation, and test sets.\n\nHowever, the validation and test sets come from different domains, with the validation set consisting\nof ambiguous examples such that changing one non-noun phrase word will change the coreference\ndependencies in the sentence. The test set consists only of more straightforward examples, with a\nhigh number of noun phrases (and thus more choices for the model), but low to no ambiguity.""""""\n\n_AXB_DESCRIPTION = """"""\\\nAn expert-constructed,\ndiagnostic dataset that automatically tests models for a broad range of linguistic, commonsense, and\nworld knowledge. Each example in this broad-coverage diagnostic is a sentence pair labeled with\na three-way entailment relation (entailment, neutral, or contradiction) and tagged with labels that\nindicate the phenomena that characterize the relationship between the two sentences. Submissions\nto the GLUE leaderboard are required to include predictions from the submission\'s MultiNLI\nclassifier on the diagnostic dataset, and analyses of the results were shown alongside the main\nleaderboard. Since this broad-coverage diagnostic task has proved difficult for top models, we retain\nit in SuperGLUE. However, since MultiNLI is not part of SuperGLUE, we collapse contradiction\nand neutral into a single not_entailment label, and request that submissions include predictions\non the resulting set from the model used for the RTE task.\n""""""\n\n_AXG_DESCRIPTION = """"""\\\nWinogender is designed to measure gender\nbias in coreference resolution systems. We use the Diverse Natural Language Inference Collection\n(DNC; Poliak et al., 2018) version that casts Winogender as a textual entailment task. Each example\nconsists of a premise sentence with a male or female pronoun and a hypothesis giving a possible\nantecedent of the pronoun. Examples occur in minimal pairs, where the only difference between\nan example and its pair is the gender of the pronoun in the premise. Performance on Winogender\nis measured with both accuracy and the gender parity score: the percentage of minimal pairs for\nwhich the predictions are the same. We note that a system can trivially obtain a perfect gender parity\nscore by guessing the same class for all examples, so a high gender parity score is meaningless unless\naccompanied by high accuracy. As a diagnostic test of gender bias, we view the schemas as having high\npositive predictive value and low negative predictive value; that is, they may demonstrate the presence\nof gender bias in a system, but not prove its absence.\n""""""\n\n_BOOLQ_CITATION = """"""\\\n@inproceedings{clark2019boolq,\n  title={BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},\n  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei, and Kwiatkowski, Tom and Collins, Michael, and Toutanova, Kristina},\n  booktitle={NAACL},\n  year={2019}\n}""""""\n\n_CB_CITATION = """"""\\\n@article{de marneff_simons_tonhauser_2019,\n  title={The CommitmentBank: Investigating projection in naturally occurring discourse},\n  journal={proceedings of Sinn und Bedeutung 23},\n  author={De Marneff, Marie-Catherine and Simons, Mandy and Tonhauser, Judith},\n  year={2019}\n}""""""\n\n_COPA_CITATION = """"""\\\n@inproceedings{roemmele2011choice,\n  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},\n  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},\n  booktitle={2011 AAAI Spring Symposium Series},\n  year={2011}\n}""""""\n\n_RECORD_CITATION = """"""\\\n@article{zhang2018record,\n  title={Record: Bridging the gap between human and machine commonsense reading comprehension},\n  author={Zhang, Sheng and Liu, Xiaodong and Liu, Jingjing and Gao, Jianfeng and Duh, Kevin and Van Durme, Benjamin},\n  journal={arXiv preprint arXiv:1810.12885},\n  year={2018}\n}""""""\n\n_RTE_CITATION = """"""\\\n@inproceedings{dagan2005pascal,\n  title={The PASCAL recognising textual entailment challenge},\n  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},\n  booktitle={Machine Learning Challenges Workshop},\n  pages={177--190},\n  year={2005},\n  organization={Springer}\n}\n@inproceedings{bar2006second,\n  title={The second pascal recognising textual entailment challenge},\n  author={Bar-Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},\n  booktitle={Proceedings of the second PASCAL challenges workshop on recognising textual entailment},\n  volume={6},\n  number={1},\n  pages={6--4},\n  year={2006},\n  organization={Venice}\n}\n@inproceedings{giampiccolo2007third,\n  title={The third pascal recognizing textual entailment challenge},\n  author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},\n  booktitle={Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing},\n  pages={1--9},\n  year={2007},\n  organization={Association for Computational Linguistics}\n}\n@inproceedings{bentivogli2009fifth,\n  title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},\n  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},\n  booktitle={TAC},\n  year={2009}\n}""""""\n\n_MULTIRC_CITATION = """"""\\\n@inproceedings{MultiRC2018,\n    author = {Daniel Khashabi and Snigdha Chaturvedi and Michael Roth and Shyam Upadhyay and Dan Roth},\n    title = {Looking Beyond the Surface:A Challenge Set for Reading Comprehension over Multiple Sentences},\n    booktitle = {Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL)},\n    year = {2018}\n}""""""\n\n_WIC_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1808-09121,\n  author={Mohammad Taher Pilehvar and os{\\\'{e}} Camacho{-}Collados},\n  title={WiC: 10, 000 Example Pairs for Evaluating Context-Sensitive Representations},\n  journal={CoRR},\n  volume={abs/1808.09121},\n  year={2018},\n  url={http://arxiv.org/abs/1808.09121},\n  archivePrefix={arXiv},\n  eprint={1808.09121},\n  timestamp={Mon, 03 Sep 2018 13:36:40 +0200},\n  biburl={https://dblp.org/rec/bib/journals/corr/abs-1808-09121},\n  bibsource={dblp computer science bibliography, https://dblp.org}\n}""""""\n\n_WSC_CITATION = """"""\\\n@inproceedings{levesque2012winograd,\n  title={The winograd schema challenge},\n  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},\n  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},\n  year={2012}\n}""""""\n\n_AXG_CITATION = """"""\\\n@inproceedings{rudinger-EtAl:2018:N18,\n  author    = {Rudinger, Rachel  and  Naradowsky, Jason  and  Leonard, Brian  and  {Van Durme}, Benjamin},\n  title     = {Gender Bias in Coreference Resolution},\n  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},\n  month     = {June},\n  year      = {2018},\n  address   = {New Orleans, Louisiana},\n  publisher = {Association for Computational Linguistics}\n}\n""""""\n\n\nclass SuperGlueConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for SuperGLUE.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               features,\n               data_url,\n               citation,\n               url,\n               label_classes=(""False"", ""True""),\n               **kwargs):\n    """"""BuilderConfig for SuperGLUE.\n\n    Args:\n      features: `list[string]`, list of the features that will appear in the\n        feature dict. Should not include ""label"".\n      data_url: `string`, url to download the zip file from.\n      citation: `string`, citation for the data set.\n      url: `string`, url for information about the data set.\n      label_classes: `list[string]`, the list of classes for the label if the\n        label is present as a string. Non-string labels will be cast to either\n        \'False\' or \'True\'.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    # Version history:\n    # 1.0.2: Fixed non-nondeterminism in ReCoRD.\n    # 1.0.1: Change from the pre-release trial version of SuperGLUE (v1.9) to\n    #        the full release (v2.0).\n    # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).\n    # 0.0.2: Initial version.\n    super(SuperGlueConfig, self).__init__(\n        version=tfds.core.Version(""1.0.2""),\n        **kwargs)\n    self.features = features\n    self.label_classes = label_classes\n    self.data_url = data_url\n    self.citation = citation\n    self.url = url\n\n\nclass SuperGlue(tfds.core.GeneratorBasedBuilder):\n  """"""The SuperGLUE benchmark.""""""\n  BUILDER_CONFIGS = [\n      SuperGlueConfig(\n          name=""boolq"",\n          description=_BOOLQ_DESCRIPTION,\n          features=[""question"", ""passage""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/BoolQ.zip"",\n          citation=_BOOLQ_CITATION,\n          url=""https://github.com/google-research-datasets/boolean-questions""),\n      SuperGlueConfig(\n          name=""cb"",\n          description=_CB_DESCRIPTION,\n          features=[""premise"", ""hypothesis""],\n          label_classes=[""entailment"", ""contradiction"", ""neutral""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/CB.zip"",\n          citation=_CB_CITATION,\n          url=""https://github.com/mcdm/CommitmentBank""),\n      SuperGlueConfig(\n          name=""copa"",\n          description=_COPA_DESCRIPTION,\n          label_classes=[""choice1"", ""choice2""],\n          # Note that question will only be the X in the statement ""What\'s\n          # the X for this?"".\n          features=[""premise"", ""choice1"", ""choice2"", ""question""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/COPA.zip"",\n          citation=_COPA_CITATION,\n          url=""http://people.ict.usc.edu/~gordon/copa.html""),\n      SuperGlueConfig(\n          name=""multirc"",\n          description=_MULTIRC_DESCRIPTION,\n          features=[""paragraph"", ""question"", ""answer""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/MultiRC.zip"",\n          citation=_MULTIRC_CITATION,\n          url=""https://cogcomp.org/multirc/""),\n      SuperGlueConfig(\n          name=""record"",\n          description=_RECORD_DESCRIPTION,\n          # Note that entities and answers will be a sequences of strings. Query\n          # will contain @placeholder as a substring, which represents the word\n          # to be substituted in.\n          features=[""passage"", ""query"", ""entities"", ""answers""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/ReCoRD.zip"",\n          citation=_RECORD_CITATION,\n          url=""https://sheng-z.github.io/ReCoRD-explorer/""),\n      SuperGlueConfig(\n          name=""rte"",\n          description=_RTE_DESCRIPTION,\n          features=[""premise"", ""hypothesis""],\n          label_classes=[""entailment"", ""not_entailment""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip"",\n          citation=_RTE_CITATION,\n          url=""https://aclweb.org/aclwiki/Recognizing_Textual_Entailment""),\n      SuperGlueConfig(\n          name=""wic"",\n          description=_WIC_DESCRIPTION,\n          # Note that start1, start2, end1, and end2 will be integers stored as\n          # tf.int32.\n          features=[\n              ""word"", ""sentence1"", ""sentence2"", ""start1"", ""start2"", ""end1"",\n              ""end2""\n          ],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/WiC.zip"",\n          citation=_WIC_CITATION,\n          url=""https://pilehvar.github.io/wic/""),\n      SuperGlueConfig(\n          name=""wsc"",\n          description=_WSC_DESCRIPTION,\n          # Note that span1_index and span2_index will be integers stored as\n          # tf.int32.\n          features=[\n              ""text"", ""span1_index"", ""span2_index"", ""span1_text"", ""span2_text""\n          ],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/WSC.zip"",\n          citation=_WSC_CITATION,\n          url=""https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html""\n      ),\n      SuperGlueConfig(\n          name=""wsc.fixed"",\n          description=(\n              _WSC_DESCRIPTION +\n              ""\\n\\nThis version fixes issues where the spans are not actually ""\n              ""substrings of the text.""),\n          # Note that span1_index and span2_index will be integers stored as\n          # tf.int32.\n          features=[\n              ""text"", ""span1_index"", ""span2_index"", ""span1_text"", ""span2_text""\n          ],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/WSC.zip"",\n          citation=_WSC_CITATION,\n          url=""https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html""\n      ),\n      SuperGlueConfig(\n          name=""axb"",\n          description=_AXB_DESCRIPTION,\n          features=[""sentence1"", ""sentence2""],\n          label_classes=[""entailment"", ""not_entailment""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/AX-b.zip"",\n          citation="""",  # The GLUE citation is sufficient.\n          url=""https://gluebenchmark.com/diagnostics""),\n      SuperGlueConfig(\n          name=""axg"",\n          description=_AXG_DESCRIPTION,\n          features=[""premise"", ""hypothesis""],\n          label_classes=[""entailment"", ""not_entailment""],\n          data_url=""https://dl.fbaipublicfiles.com/glue/superglue/data/v2/AX-g.zip"",\n          citation=_AXG_CITATION,\n          url=""https://github.com/rudinger/winogender-schemas""),\n  ]\n\n  def _info(self):\n    features = {\n        feature: tfds.features.Text()\n        for feature in self.builder_config.features\n    }\n    if self.builder_config.name.startswith(""wsc""):\n      features[""span1_index""] = tf.int32\n      features[""span2_index""] = tf.int32\n    if self.builder_config.name == ""wic"":\n      features[""start1""] = tf.int32\n      features[""start2""] = tf.int32\n      features[""end1""] = tf.int32\n      features[""end2""] = tf.int32\n    if self.builder_config.name == ""multirc"":\n      features[""idx""] = tfds.features.FeaturesDict({\n          ""paragraph"": tf.int32,\n          ""question"": tf.int32,\n          ""answer"": tf.int32,\n      })\n    elif self.builder_config.name == ""record"":\n      features[""idx""] = tfds.features.FeaturesDict({\n          ""passage"": tf.int32,\n          ""query"": tf.int32,\n      })\n    else:\n      features[""idx""] = tf.int32\n\n    if self.builder_config.name == ""record"":\n      # Entities are the set of possible choices for the placeholder.\n      features[""entities""] = tfds.features.Sequence(tfds.features.Text())\n      # Answers are the subset of entities that are correct.\n      features[""answers""] = tfds.features.Sequence(tfds.features.Text())\n    else:\n      features[""label""] = tfds.features.ClassLabel(\n          names=self.builder_config.label_classes)\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_GLUE_DESCRIPTION + self.builder_config.description,\n        features=tfds.features.FeaturesDict(features),\n        homepage=self.builder_config.url,\n        citation=self.builder_config.citation + ""\\n"" + _SUPER_GLUE_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(self.builder_config.data_url) or """"\n    task_name = _get_task_name_from_data_url(self.builder_config.data_url)\n    dl_dir = os.path.join(dl_dir, task_name)\n    if self.builder_config.name in [""axb"", ""axg""]:\n      return [\n          tfds.core.SplitGenerator(\n              name=tfds.Split.TEST,\n              gen_kwargs={\n                  ""data_file"":\n                      os.path.join(dl_dir, ""{}.jsonl"".format(task_name)),\n                  ""split"":\n                      tfds.Split.TEST,\n              }),\n      ]\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""data_file"": os.path.join(dl_dir, ""train.jsonl""),\n                ""split"": tfds.Split.TRAIN,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""data_file"": os.path.join(dl_dir, ""val.jsonl""),\n                ""split"": tfds.Split.VALIDATION,\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""data_file"": os.path.join(dl_dir, ""test.jsonl""),\n                ""split"": tfds.Split.TEST,\n            }),\n    ]\n\n  def _generate_examples(self, data_file, split):\n    with tf.io.gfile.GFile(data_file) as f:\n      for line in f:\n        row = json.loads(line)\n\n        if self.builder_config.name == ""multirc"":\n          paragraph = row[""passage""]\n          for question in paragraph[""questions""]:\n            for answer in question[""answers""]:\n              label = answer.get(""label"")\n              key = ""%s_%s_%s"" % (row[""idx""], question[""idx""], answer[""idx""])\n              yield key, {\n                  ""paragraph"": paragraph[""text""],\n                  ""question"": question[""question""],\n                  ""answer"": answer[""text""],\n                  ""label"": -1 if label is None else _cast_label(bool(label)),\n                  ""idx"": {\n                      ""paragraph"": row[""idx""],\n                      ""question"": question[""idx""],\n                      ""answer"": answer[""idx""]\n                  }\n              }\n        elif self.builder_config.name == ""record"":\n          passage = row[""passage""]\n          for qa in row[""qas""]:\n            yield qa[""idx""], {\n                ""passage"": passage[""text""],\n                ""query"": qa[""query""],\n                ""entities"": _get_record_entities(passage),\n                ""answers"": _get_record_answers(qa),\n                ""idx"": {\n                    ""passage"": row[""idx""],\n                    ""query"": qa[""idx""]\n                }\n            }\n        else:\n          if self.builder_config.name.startswith(""wsc""):\n            row.update(row[""target""])\n          example = {\n              feature: row[feature] for feature in self.builder_config.features\n          }\n          if self.builder_config.name == ""wsc.fixed"":\n            example = _fix_wst(example)\n          example[""idx""] = row[""idx""]\n\n          if ""label"" in row:\n            if self.builder_config.name == ""copa"":\n              example[""label""] = ""choice2"" if row[""label""] else ""choice1""\n            else:\n              example[""label""] = _cast_label(row[""label""])\n          else:\n            assert split == tfds.Split.TEST, row\n            example[""label""] = -1\n          yield example[""idx""], example\n\n\ndef _fix_wst(ex):\n  """"""Fixes most cases where spans are not actually substrings of text.""""""\n  def _fix_span_text(k):\n    """"""Fixes a single span.""""""\n    text = ex[k + ""_text""]\n    index = ex[k + ""_index""]\n\n    if text in ex[""text""]:\n      return\n\n    if text in (""Kamenev and Zinoviev"", ""Kamenev, Zinoviev, and Stalin""):\n      # There is no way to correct these examples since the subjects have\n      # intervening text.\n      return\n\n    if ""theyscold"" in text:\n      ex[""text""].replace(""theyscold"", ""they scold"")  # pytype: disable=attribute-error\n      ex[""span2_index""] = 10\n    # Make sure case of the first words match.\n    first_word = ex[""text""].split()[index]  # pytype: disable=attribute-error\n    if first_word[0].islower():\n      text = text[0].lower() + text[1:]\n    else:\n      text = text[0].upper() + text[1:]\n    # Remove punctuation in span.\n    text = text.rstrip(""."")\n    # Replace incorrect whitespace character in span.\n    text = text.replace(""\\n"", "" "")\n    ex[k + ""_text""] = text\n    assert ex[k + ""_text""] in ex[""text""], ex\n  _fix_span_text(""span1"")\n  _fix_span_text(""span2"")\n  return ex\n\n\ndef _cast_label(label):\n  """"""Converts the label into the appropriate string version.""""""\n  if isinstance(label, six.string_types):\n    return label\n  elif isinstance(label, bool):\n    return ""True"" if label else ""False""\n  elif isinstance(label, six.integer_types):\n    assert label in (0, 1)\n    return str(label)\n  else:\n    raise ValueError(""Invalid label format."")\n\n\ndef _get_record_entities(passage):\n  """"""Returns the unique set of entities.""""""\n  text = passage[""text""]\n  entities = set()\n  for entity in passage[""entities""]:\n    entities.add(text[entity[""start""]:entity[""end""] + 1])\n  return sorted(entities)\n\n\ndef _get_record_answers(qa):\n  """"""Returns the unique set of answers.""""""\n  if ""answers"" not in qa:\n    return []\n  answers = set()\n  for answer in qa[""answers""]:\n    answers.add(answer[""text""])\n  return sorted(answers)\n\n\ndef _get_task_name_from_data_url(data_url):\n  return data_url.split(""/"")[-1].split(""."")[0]\n'"
tensorflow_datasets/text/super_glue_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for super_glue dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import super_glue\n\n_BASE_DIR = os.path.join(\n    os.path.dirname(__file__), ""../"",\n    ""testing/test_data/fake_examples/super_glue"")\n\n\nclass SuperGlueBoolQTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""boolq""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueCbTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""cb""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueCopaTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""copa""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueMultiRcTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""multirc""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 58,\n      ""validation"": 62,\n      ""test"": 58,\n  }\n\n\nclass SuperGlueReCoRDTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""record""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 9,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueRteTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""rte""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueWscTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""wsc"", ""wsc.fixed""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueWicTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""wic""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nclass SuperGlueAxBTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""axb""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""test"": 3,\n  }\n\n\nclass SuperGlueAxGTest(testing.DatasetBuilderTestCase):\n  BUILDER_CONFIG_NAMES_TO_TEST = [""axg""]\n  DATASET_CLASS = super_glue.SuperGlue\n  SPLITS = {\n      ""test"": 3,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/tiny_shakespeare.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tiny Shakespeare dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@misc{\n  author={Karpathy, Andrej},\n  title={char-rnn},\n  year={2015},\n  howpublished={\\\\url{https://github.com/karpathy/char-rnn}}\n}""""""\n\n_DESCRIPTION = """"""\\\n40,000 lines of Shakespeare from a variety of Shakespeare\'s plays. \\\nFeatured in Andrej Karpathy\'s blog post \'The Unreasonable Effectiveness of \\\nRecurrent Neural Networks\': \\\nhttp://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\nTo use for e.g. character modelling:\n\n```\nd = tfds.load(name=\'tiny_shakespeare\')[\'train\']\nd = d.map(lambda x: tf.strings.unicode_split(x[\'text\'], \'UTF-8\'))\n# train split includes vocabulary for other splits\nvocabulary = sorted(set(next(iter(d)).numpy()))\nd = d.map(lambda x: {\'cur_char\': x[:-1], \'next_char\': x[1:]})\nd = d.unbatch()\nseq_len = 100\nbatch_size = 2\nd = d.batch(seq_len)\nd = d.batch(batch_size)\n```\n""""""\n\n\nclass TinyShakespeare(tfds.core.GeneratorBasedBuilder):\n  """"""Tiny Shakespeare dataset builder.""""""\n\n  VERSION = tfds.core.Version(\'1.0.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\'text\': tfds.features.Text()}),\n        supervised_keys=None,\n        homepage=\'https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n    download_path = dl_manager.download(\n        \'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\'\n    )\n    if tf.io.gfile.isdir(download_path):\n      # During testing the download manager mock gives us a directory\n      txt_path = os.path.join(download_path, \'input.txt\')\n    else:\n      txt_path = download_path\n    with tf.io.gfile.GFile(txt_path, \'r\') as f:\n      text = f.read()\n\n    # 90/5/5 split\n    i = int(len(text) * 0.9)\n    train_text, text = text[:i], text[i:]\n    i = int(len(text) * 0.5)\n    validation_text, text = text[:i], text[i:]\n    test_text = text\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            # These kwargs will be passed to _generate_examples\n            gen_kwargs={\n                \'split_key\': \'train\',\n                \'split_text\': train_text\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                \'split_key\': \'validation\',\n                \'split_text\': validation_text\n            },\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'split_key\': \'test\',\n                \'split_text\': test_text\n            },\n        ),\n    ]\n\n  def _generate_examples(self, split_key, split_text):\n    """"""Yields examples.""""""\n    data_key = split_key  # Should uniquely identify the thing yielded\n    feature_dict = {\'text\': split_text}\n    yield data_key, feature_dict\n'"
tensorflow_datasets/text/tiny_shakespeare_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tiny Shakespeare dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import tiny_shakespeare\n\n\nclass TinyShakespeareTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = tiny_shakespeare.TinyShakespeare\n  SPLITS = {\n      ""train"": 1,\n      ""validation"": 1,\n      ""test"": 1,\n  }\n\n  # If you are calling `download/download_and_extract` with a dict, like:\n  #   dl_manager.download({\'some_key\': \'http://a.org/out.txt\', ...})\n  # then the tests needs to provide the fake output paths relative to the\n  # fake data directory\n  # DL_EXTRACT_RESULT = {\'some_key\': \'output_file1.txt\', ...}\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n\n'"
tensorflow_datasets/text/wiki40b.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Wiki40B: A clean Wikipedia dataset for 40+ languages.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import logging\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\n@inproceedings{49029,\ntitle = {Wiki-40B: Multilingual Language Model Dataset},\nauthor = {Mandy Guo and Zihang Dai and Denny Vrandecic and Rami Al-Rfou},\nyear = {2020},\nbooktitle\t= {LREC 2020}\n}\n""""""\n\n_DESCRIPTION = """"""\nClean-up text for 40+ Wikipedia languages editions of pages\ncorrespond to entities. The datasets have train/dev/test splits per language.\nThe dataset is cleaned up by page filtering to remove disambiguation pages,\nredirect pages, deleted pages, and non-entity pages. Each example contains the\nwikidata id of the entity, and the full Wikipedia article after page processing\nthat removes non-content sections and structured objects. The language models\ntrained on this corpus - including 41 monolingual models, and 2 multilingual\nmodels - can be found at https://tfhub.dev/google/collections/wiki40b-lm/1.\n""""""\n\n_LICENSE = """"""\nThis work is licensed under the Creative Commons Attribution-ShareAlike\n3.0 Unported License. To view a copy of this license, visit\nhttp://creativecommons.org/licenses/by-sa/3.0/ or send a letter to\nCreative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n""""""\n\n_URL = ""https://research.google/pubs/pub49029/""\n\n_DATA_DIRECTORY = tfds.core.gcs_path(""downloads/wiki40b/tfrecord_prod"")\n\nWIKIPEDIA_LANGUAGES = [\n    ""en"", ""ar"", ""zh-cn"", ""zh-tw"", ""nl"", ""fr"", ""de"", ""it"", ""ja"", ""ko"", ""pl"",\n    ""pt"", ""ru"", ""es"", ""th"", ""tr"", ""bg"", ""ca"", ""cs"", ""da"", ""el"", ""et"", ""fa"",\n    ""fi"", ""he"", ""hi"", ""hr"", ""hu"", ""id"", ""lt"", ""lv"", ""ms"", ""no"", ""ro"", ""sk"",\n    ""sl"", ""sr"", ""sv"", ""tl"", ""uk"", ""vi""]\n\n\nclass Wiki40bConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Wiki40B.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, language=None, **kwargs):\n    """"""BuilderConfig for Wiki40B.\n\n    Args:\n      language: string, the language code for the Wiki40B dataset to use.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(Wiki40bConfig, self).__init__(\n        name=language,\n        description=""Wiki40B dataset for {}."".format(language),\n        **kwargs)\n    self.language = language\n\n\n_VERSION = tfds.core.Version(""1.3.0"")\n\n\nclass Wiki40b(tfds.core.BeamBasedBuilder):\n  """"""Wiki40B: A Clean Wikipedia Dataset for Mutlilingual Language Modeling.""""""\n\n  BUILDER_CONFIGS = [\n      Wiki40bConfig(  # pylint:disable=g-complex-comprehension\n          version=_VERSION,\n          language=lang,\n      ) for lang in WIKIPEDIA_LANGUAGES\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""wikidata_id"":\n                tfds.features.Text(),\n            ""text"":\n                tfds.features.Text(),\n            ""version_id"":\n                tfds.features.Text(),\n        }),\n        supervised_keys=None,\n        homepage=_URL,\n        citation=_CITATION,\n        redistribution_info={""license"": _LICENSE},\n    )\n\n  def _split_generators(self, dl_manager):\n    """"""Returns SplitGenerators.""""""\n\n    del dl_manager  # Unused\n\n    lang = self._builder_config.language\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""filepaths"": os.path.join(\n                    _DATA_DIRECTORY, ""train"", ""{}_examples-*"".format(lang))},\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""filepaths"": os.path.join(\n                    _DATA_DIRECTORY, ""dev"", ""{}_examples-*"".format(lang))}\n        ),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""filepaths"": os.path.join(\n                    _DATA_DIRECTORY, ""test"", ""{}_examples-*"".format(lang))}\n        ),\n    ]\n\n  def _build_pcollection(self, pipeline, filepaths):\n    """"""Build PCollection of examples.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n    logging.info(""generating examples from = %s"", filepaths)\n\n    def _extract_content(example):\n      """"""Extracts content from a TFExample.""""""\n      wikidata_id = example.features.feature[\n          ""wikidata_id""].bytes_list.value[0].decode(""utf-8"")\n      text = example.features.feature[\n          ""text""].bytes_list.value[0].decode(""utf-8"")\n      version_id = example.features.feature[\n          ""version_id""].bytes_list.value[0].decode(""utf-8"")\n\n      # wikidata_id could be duplicated with different texts.\n      yield wikidata_id + text, {""wikidata_id"": wikidata_id,\n                                 ""text"": text,\n                                 ""version_id"": version_id,}\n\n    return (\n        pipeline\n        | beam.io.ReadFromTFRecord(\n            filepaths, coder=beam.coders.ProtoCoder(tf.train.Example))\n        | beam.FlatMap(_extract_content))\n'"
tensorflow_datasets/text/wiki40b_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for wiki40b dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import wiki40b\n\n_EXAMPLE_DIR = os.path.join(\n    os.path.normpath(os.path.dirname(__file__) + ""/../""),\n    ""testing"",\n    ""test_data"",\n    ""fake_examples"",\n    ""wiki40b"",\n)\n\n\nclass Wiki40bTest(testing.DatasetBuilderTestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(Wiki40bTest, cls).setUpClass()\n    wiki40b._DATA_DIRECTORY = _EXAMPLE_DIR\n\n  DATASET_CLASS = wiki40b.Wiki40b\n  BUILDER_CONFIG_NAMES_TO_TEST = [""en""]\n\n  SPLITS = {\n      ""train"": 3,\n      ""validation"": 2,\n      ""test"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/wikipedia.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Wikipedia dataset containing cleaned articles of all languages.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport json\nimport re\nimport xml.etree.cElementTree as etree\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nif six.PY3:\n  import bz2  # pylint:disable=g-import-not-at-top\nelse:\n  # py2\'s built-in bz2 package does not support reading from file objects.\n  import bz2file as bz2  # pylint:disable=g-import-not-at-top\n\n_CITATION = """"""\\\n@ONLINE {wikidump,\n    author = ""Wikimedia Foundation"",\n    title  = ""Wikimedia Downloads"",\n    url    = ""https://dumps.wikimedia.org""\n}\n""""""\n\n_DESCRIPTION = """"""\\\nWikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).\n""""""\n\n_LICENSE = (\n    ""This work is licensed under the Creative Commons Attribution-ShareAlike ""\n    ""3.0 Unported License. To view a copy of this license, visit ""\n    ""http://creativecommons.org/licenses/by-sa/3.0/ or send a letter to ""\n    ""Creative Commons, PO Box 1866, Mountain View, CA 94042, USA."")\n\n# Source: https://en.wikipedia.org/wiki/List_of_Wikipedias (accessed 3/1/2019)\n# Removed because no articles: hz.\nWIKIPEDIA_LANGUAGES = [\n    ""aa"", ""ab"", ""ace"", ""ady"", ""af"", ""ak"", ""als"", ""am"", ""an"", ""ang"", ""ar"", ""arc"",\n    ""arz"", ""as"", ""ast"", ""atj"", ""av"", ""ay"", ""az"", ""azb"", ""ba"", ""bar"", ""bat-smg"",\n    ""bcl"", ""be"", ""be-x-old"", ""bg"", ""bh"", ""bi"", ""bjn"", ""bm"", ""bn"", ""bo"", ""bpy"",\n    ""br"", ""bs"", ""bug"", ""bxr"", ""ca"", ""cbk-zam"", ""cdo"", ""ce"", ""ceb"", ""ch"", ""cho"",\n    ""chr"", ""chy"", ""ckb"", ""co"", ""cr"", ""crh"", ""cs"", ""csb"", ""cu"", ""cv"", ""cy"", ""da"",\n    ""de"", ""din"", ""diq"", ""dsb"", ""dty"", ""dv"", ""dz"", ""ee"", ""el"", ""eml"", ""en"", ""eo"",\n    ""es"", ""et"", ""eu"", ""ext"", ""fa"", ""ff"", ""fi"", ""fiu-vro"", ""fj"", ""fo"", ""fr"",\n    ""frp"", ""frr"", ""fur"", ""fy"", ""ga"", ""gag"", ""gan"", ""gd"", ""gl"", ""glk"", ""gn"",\n    ""gom"", ""gor"", ""got"", ""gu"", ""gv"", ""ha"", ""hak"", ""haw"", ""he"", ""hi"", ""hif"",\n    ""ho"", ""hr"", ""hsb"", ""ht"", ""hu"", ""hy"", ""ia"", ""id"", ""ie"", ""ig"", ""ii"",\n    ""ik"", ""ilo"", ""inh"", ""io"", ""is"", ""it"", ""iu"", ""ja"", ""jam"", ""jbo"", ""jv"", ""ka"",\n    ""kaa"", ""kab"", ""kbd"", ""kbp"", ""kg"", ""ki"", ""kj"", ""kk"", ""kl"", ""km"", ""kn"", ""ko"",\n    ""koi"", ""krc"", ""ks"", ""ksh"", ""ku"", ""kv"", ""kw"", ""ky"", ""la"", ""lad"", ""lb"",\n    ""lbe"", ""lez"", ""lfn"", ""lg"", ""li"", ""lij"", ""lmo"", ""ln"", ""lo"", ""lrc"", ""lt"",\n    ""ltg"", ""lv"", ""mai"", ""map-bms"", ""mdf"", ""mg"", ""mh"", ""mhr"", ""mi"", ""min"", ""mk"",\n    ""ml"", ""mn"", ""mr"", ""mrj"", ""ms"", ""mt"", ""mus"", ""mwl"", ""my"", ""myv"", ""mzn"", ""na"",\n    ""nah"", ""nap"", ""nds"", ""nds-nl"", ""ne"", ""new"", ""ng"", ""nl"", ""nn"", ""no"", ""nov"",\n    ""nrm"", ""nso"", ""nv"", ""ny"", ""oc"", ""olo"", ""om"", ""or"", ""os"", ""pa"", ""pag"", ""pam"",\n    ""pap"", ""pcd"", ""pdc"", ""pfl"", ""pi"", ""pih"", ""pl"", ""pms"", ""pnb"", ""pnt"", ""ps"",\n    ""pt"", ""qu"", ""rm"", ""rmy"", ""rn"", ""ro"", ""roa-rup"", ""roa-tara"", ""ru"", ""rue"",\n    ""rw"", ""sa"", ""sah"", ""sat"", ""sc"", ""scn"", ""sco"", ""sd"", ""se"", ""sg"", ""sh"", ""si"",\n    ""simple"", ""sk"", ""sl"", ""sm"", ""sn"", ""so"", ""sq"", ""sr"", ""srn"", ""ss"", ""st"",\n    ""stq"", ""su"", ""sv"", ""sw"", ""szl"", ""ta"", ""tcy"", ""te"", ""tet"", ""tg"", ""th"", ""ti"",\n    ""tk"", ""tl"", ""tn"", ""to"", ""tpi"", ""tr"", ""ts"", ""tt"", ""tum"", ""tw"", ""ty"", ""tyv"",\n    ""udm"", ""ug"", ""uk"", ""ur"", ""uz"", ""ve"", ""vec"", ""vep"", ""vi"", ""vls"", ""vo"", ""wa"",\n    ""war"", ""wo"", ""wuu"", ""xal"", ""xh"", ""xmf"", ""yi"", ""yo"", ""za"", ""zea"", ""zh"",\n    ""zh-classical"", ""zh-min-nan"", ""zh-yue"", ""zu""]\n\n_BASE_URL_TMPL = ""https://dumps.wikimedia.your.org/{lang}wiki/{date}/""\n_INFO_FILE = ""dumpstatus.json""\n\n\nclass WikipediaConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for Wikipedia.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, language=None, date=None, **kwargs):\n    """"""BuilderConfig for Wikipedia.\n\n    Args:\n      language: string, the language code for the Wikipedia dump to use.\n      date: string, date of the Wikipedia dump in YYYYMMDD format. A list of\n        available dates can be found at https://dumps.wikimedia.org/enwiki/.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(WikipediaConfig, self).__init__(\n        name=""{0}.{1}"".format(date, language),\n        description=""Wikipedia dataset for {0}, parsed from {1} dump."".format(\n            language, date),\n        **kwargs)\n    self.date = date\n    self.language = language\n\n\n_VERSION = tfds.core.Version(\n    ""1.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n\nclass Wikipedia(tfds.core.BeamBasedBuilder):\n  """"""Wikipedia dataset.""""""\n  # Use mirror (your.org) to avoid download caps.\n\n  BUILDER_CONFIGS = [\n      WikipediaConfig(  # pylint:disable=g-complex-comprehension\n          version=_VERSION,\n          language=lang,\n          date=""20200301"",\n      ) for lang in WIKIPEDIA_LANGUAGES\n  ] + [\n      # Old versions files do not exists anymore but config are kept as\n      # previously generated datasets can still be read.\n      WikipediaConfig(  # pylint:disable=g-complex-comprehension\n          version=_VERSION,\n          language=lang,\n          date=""20190301"",\n      ) for lang in WIKIPEDIA_LANGUAGES\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""title"":\n                tfds.features.Text(),\n            ""text"":\n                tfds.features.Text(),\n        }),\n        # No default supervised_keys.\n        supervised_keys=None,\n        homepage=""https://dumps.wikimedia.org"",\n        citation=_CITATION,\n        redistribution_info={""license"": _LICENSE},\n    )\n\n  def _split_generators(self, dl_manager):\n    def _base_url(lang):\n      return _BASE_URL_TMPL.format(\n          lang=lang.replace(""-"", ""_""), date=self._builder_config.date)\n\n    lang = self._builder_config.language\n\n    info_url = _base_url(lang) + _INFO_FILE\n    # Use dictionary since testing mock always returns the same result.\n    downloaded_files = dl_manager.download_and_extract({""info"": info_url})\n\n    xml_urls = []\n    total_bytes = 0\n    with tf.io.gfile.GFile(downloaded_files[""info""]) as f:\n      dump_info = json.load(f)\n    multistream_dump_info = dump_info[""jobs""][""articlesmultistreamdump""]\n    assert multistream_dump_info[""status""] == ""done"", (\n        ""Specified dump (%s) multistream status is not \'done\': %s"" % (\n            _base_url(lang), multistream_dump_info[""status""]))\n\n    for fname, info in multistream_dump_info[""files""].items():\n      if "".xml"" not in fname:\n        continue\n      total_bytes += info[""size""]\n      xml_urls.append(_base_url(lang) + fname)\n\n      # Use dictionary since testing mock always returns the same result.\n    downloaded_files = dl_manager.download({""xml"": xml_urls})\n\n    return [\n        tfds.core.SplitGenerator(  # pylint:disable=g-complex-comprehension\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepaths"": downloaded_files[""xml""], ""language"": lang})\n    ]\n\n  def _build_pcollection(self, pipeline, filepaths, language):\n    """"""Build PCollection of examples in the raw (text) form.""""""\n\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _extract_content(filepath):\n      """"""Extracts article content from a single WikiMedia XML file.""""""\n      logging.info(""generating examples from = %s"", filepath)\n      with tf.io.gfile.GFile(filepath, ""rb"") as f:\n        f = bz2.BZ2File(filename=f)\n        if six.PY3:\n          # Workaround due to:\n          # https://github.com/tensorflow/tensorflow/issues/33563\n          utf_f = codecs.getreader(""utf-8"")(f)  # pytype: disable=wrong-arg-types\n        else:\n          utf_f = f\n\n        # To clear root, to free-up more memory than just `elem.clear()`.\n        context = etree.iterparse(utf_f, events=(""end"",))\n        context = iter(context)\n        unused_event, root = next(context)\n        for unused_event, elem in context:\n          if not elem.tag.endswith(""page""):\n            continue\n          namespace = elem.tag[:-4]\n          title = elem.find(""./{0}title"".format(namespace)).text\n          ns = elem.find(""./{0}ns"".format(namespace)).text\n          id_ = elem.find(""./{0}id"".format(namespace)).text\n\n          # Filter pages that are not in the ""main"" namespace.\n          if ns != ""0"":\n            root.clear()\n            continue\n\n          raw_content = elem.find(\n              ""./{0}revision/{0}text"".format(namespace)).text\n          root.clear()\n\n          # Filter redirects.\n          if raw_content is None or raw_content.lower().startswith(""#redirect""):\n            beam.metrics.Metrics.counter(language, ""filtered-redirects"").inc()\n            continue\n\n          beam.metrics.Metrics.counter(language, ""extracted-examples"").inc()\n          yield (id_, title, raw_content)\n\n    def _clean_content(inputs):\n      """"""Cleans raw wikicode to extract text.""""""\n      id_, title, raw_content = inputs\n      try:\n        text = _parse_and_clean_wikicode(raw_content)\n      except (\n          tfds.core.lazy_imports.mwparserfromhell.parser.ParserError) as e:\n        beam.metrics.Metrics.counter(language, ""parser-error"").inc()\n        logging.error(""mwparserfromhell ParseError: %s"", e)\n        return\n\n      if not text:\n        beam.metrics.Metrics.counter(language, ""empty-clean-examples"").inc()\n        return\n\n      beam.metrics.Metrics.counter(language, ""cleaned-examples"").inc()\n\n      yield id_, {\n          ""title"": title,\n          ""text"": text\n      }\n\n    return (\n        pipeline\n        | beam.Create(filepaths)\n        | beam.FlatMap(_extract_content)\n        | beam.transforms.Reshuffle()\n        | beam.FlatMap(_clean_content)\n    )\n\n\ndef _parse_and_clean_wikicode(raw_content):\n  """"""Strips formatting and unwanted sections from raw page content.""""""\n  wikicode = tfds.core.lazy_imports.mwparserfromhell.parse(raw_content)\n\n  # Filters for references, tables, and file/image links.\n  re_rm_wikilink = re.compile(\n      ""^(?:File|Image|Media):"", flags=re.IGNORECASE | re.UNICODE)\n  def rm_wikilink(obj):\n    return bool(re_rm_wikilink.match(six.text_type(obj.title)))  # pytype: disable=wrong-arg-types\n  def rm_tag(obj):\n    return six.text_type(obj.tag) in {""ref"", ""table""}\n  def rm_template(obj):\n    return obj.name.lower() in {\n        ""reflist"", ""notelist"", ""notelist-ua"", ""notelist-lr"", ""notelist-ur"",\n        ""notelist-lg""}\n\n  def try_remove_obj(obj, section):\n    try:\n      section.remove(obj)\n    except ValueError:\n      # For unknown reasons, objects are sometimes not found.\n      pass\n\n  section_text = []\n  # Filter individual sections to clean.\n  for section in wikicode.get_sections(\n      flat=True, include_lead=True, include_headings=True):\n    for obj in section.ifilter_wikilinks(matches=rm_wikilink, recursive=True):\n      try_remove_obj(obj, section)\n    for obj in section.ifilter_templates(matches=rm_template, recursive=True):\n      try_remove_obj(obj, section)\n    for obj in section.ifilter_tags(matches=rm_tag, recursive=True):\n      try_remove_obj(obj, section)\n\n    section_text.append(section.strip_code().strip())\n  return ""\\n\\n"".join(section_text)\n'"
tensorflow_datasets/text/wikipedia_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for wikipedia dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import wikipedia\n\n\nclass WikipediaTest(testing.DatasetBuilderTestCase):\n  """"""Test Wikipedia Dataset generation on fake dataset.""""""\n  DATASET_CLASS = wikipedia.Wikipedia\n  BUILDER_CONFIG_NAMES_TO_TEST = [""20200301.en""]\n\n  # url_checksums are read from `dumpstatus.json`\n  # Modify dumpstatus.json if `date` is not `20200301`\n  DL_EXTRACT_RESULT = {\n      ""info"": ""dumpstatus.json"",\n      ""xml"": [""enwiki_fake.xml.bz2"", ""enwiki_fake2.xml.bz2""]\n  }\n\n  SPLITS = {\n      ""train"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/winogrande.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""The Winogrande Challenge.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport tensorflow as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@article{sakaguchi2019winogrande,\n    title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale},\n    author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},\n    journal={arXiv preprint arXiv:1907.10641},\n    year={2019}\n}\n""""""\n\n_DESCRIPTION = """"""\\\nThe  WinoGrande, a large-scale dataset of 44k problems, inspired by the original\n Winograd Schema Challenge design, but adjusted to improve both the scale and\n the hardness of the dataset.\n""""""\n\n_DATA_URL = \'https://storage.googleapis.com/ai2-mosaic/public/winogrande/winogrande_1.1.zip\'\n\n\nclass Winogrande(tfds.core.GeneratorBasedBuilder):\n  """"""The Winogrande challenge.""""""\n\n  VERSION = tfds.core.Version(\'1.1.0\')\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'sentence\': tfds.features.Text(),\n            \'option1\': tfds.features.Text(),\n            \'option2\': tfds.features.Text(),\n            \'label\': tfds.features.ClassLabel(names=[\'1\', \'2\']),\n        }),\n        # No default supervised_keys (as we have to pass both the sentence\n        # and options as input).\n        supervised_keys=None,\n        homepage=\'http://winogrande.allenai.org/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n    data_dir = os.path.join(dl_dir, \'winogrande_1.1\')\n\n    # Winogrande has different standardized training data sizes and reports\n    # numbers for each of these data sizes, so make those available.\n    data_sizes = [\'xs\', \'s\', \'m\', \'l\', \'xl\']\n    train_splits = []\n    for size in data_sizes:\n      train_splits.append(\n          tfds.core.SplitGenerator(\n              name=tfds.Split(\'train_{}\'.format(size)),\n              gen_kwargs={\n                  \'filepath\':\n                      os.path.join(data_dir, \'train_{}.jsonl\'.format(size))\n              }))\n    return train_splits + [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'filepath\': os.path.join(data_dir, \'test.jsonl\')}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'filepath\': os.path.join(data_dir, \'dev.jsonl\')}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(filepath) as f:\n      for row in f:\n        row_fields = json.loads(row)\n        yield row_fields[\'qID\'], {\n            \'sentence\': row_fields[\'sentence\'],\n            \'option1\': row_fields[\'option1\'],\n            \'option2\': row_fields[\'option2\'],\n            \'label\': row_fields.get(\'answer\', -1),\n        }\n'"
tensorflow_datasets/text/winogrande_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for Winogrande dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import winogrande\n\n\nclass WinograndeTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = winogrande.Winogrande\n\n  SPLITS = {\n      ""train_xl"": 2,\n      ""train_l"": 2,\n      ""train_m"": 2,\n      ""train_s"": 2,\n      ""train_xs"": 2,\n      ""validation"": 2,\n      ""test"": 2,\n  }\n\n  OVERLAPPING_SPLITS = [\n      ""train_{}"".format(size) for size in (""xs"", ""s"", ""m"", ""l"", ""xl"")\n  ]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/xnli.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""XNLI: The Cross-Lingual NLI Corpus.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport csv\nimport os\nimport six\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_CITATION = """"""\\\n@InProceedings{conneau2018xnli,\n  author = ""Conneau, Alexis\n                 and Rinott, Ruty\n                 and Lample, Guillaume\n                 and Williams, Adina\n                 and Bowman, Samuel R.\n                 and Schwenk, Holger\n                 and Stoyanov, Veselin"",\n  title = ""XNLI: Evaluating Cross-lingual Sentence Representations"",\n  booktitle = ""Proceedings of the 2018 Conference on Empirical Methods\n               in Natural Language Processing"",\n  year = ""2018"",\n  publisher = ""Association for Computational Linguistics"",\n  location = ""Brussels, Belgium"",\n}""""""\n\n_DESCRIPTION = """"""\\\nXNLI is a subset of a few thousand examples from MNLI which has been translated\ninto a 14 different languages (some low-ish resource). As with MNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).\n""""""\n\n_DATA_URL = \'https://cims.nyu.edu/~sbowman/xnli/XNLI-1.0.zip\'\n\n_LANGUAGES = (\'ar\', \'bg\', \'de\', \'el\', \'en\', \'es\', \'fr\', \'hi\', \'ru\', \'sw\', \'th\',\n              \'tr\', \'ur\', \'vi\', \'zh\')\n\n\nclass Xnli(tfds.core.GeneratorBasedBuilder):\n  """"""XNLI: The Cross-Lingual NLI Corpus. Version 1.0.""""""\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'plain_text\',\n          version=tfds.core.Version(\n              \'1.0.0\',\n              \'New split API (https://tensorflow.org/datasets/splits)\'),\n          description=\'Plain text import of XNLI\',\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'premise\':\n                tfds.features.Translation(\n                    languages=_LANGUAGES,),\n            \'hypothesis\':\n                tfds.features.TranslationVariableLanguages(\n                    languages=_LANGUAGES,),\n            \'label\':\n                tfds.features.ClassLabel(\n                    names=[\'entailment\', \'neutral\', \'contradiction\']),\n        }),\n        # No default supervised_keys (as we have to pass both premise\n        # and hypothesis as input).\n        supervised_keys=None,\n        homepage=\'https://www.nyu.edu/projects/bowman/xnli/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n    data_dir = os.path.join(dl_dir, \'XNLI-1.0\')\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\'filepath\': os.path.join(data_dir, \'xnli.test.tsv\')}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'filepath\': os.path.join(data_dir, \'xnli.dev.tsv\')}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""This function returns the examples in the raw (text) form.""""""\n    rows_per_pair_id = collections.defaultdict(list)\n\n    with tf.io.gfile.GFile(filepath) as f:\n      reader = csv.DictReader(f, delimiter=\'\\t\', quoting=csv.QUOTE_NONE)\n      for row in reader:\n        rows_per_pair_id[row[\'pairID\']].append(row)\n\n    for rows in six.itervalues(rows_per_pair_id):\n      premise = {row[\'language\']: row[\'sentence1\'] for row in rows}\n      hypothesis = {row[\'language\']: row[\'sentence2\'] for row in rows}\n      yield rows[0][\'pairID\'], {\n          \'premise\': premise,\n          \'hypothesis\': hypothesis,\n          \'label\': rows[0][\'gold_label\'],\n      }\n'"
tensorflow_datasets/text/xnli_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for multinli dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import xnli\n\n\nclass XnliTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = xnli.Xnli\n\n  SPLITS = {\n      ""test"": 3,\n      ""validation"": 2,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/text/yelp_polarity.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Yelp Polarity Reviews dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nLarge Yelp Review Dataset.\nThis is a dataset for binary sentiment classification. \\\nWe provide a set of 560,000 highly polar yelp reviews for training, and 38,000 for testing. \\\n\nORIGIN\nThe Yelp reviews dataset consists of reviews from Yelp. It is extracted\nfrom the Yelp Dataset Challenge 2015 data. For more information, please\nrefer to http://www.yelp.com/dataset_challenge\n\nThe Yelp reviews polarity dataset is constructed by\nXiang Zhang (xiang.zhang@nyu.edu) from the above dataset.\nIt is first used as a text classification benchmark in the following paper:\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks\nfor Text Classification. Advances in Neural Information Processing Systems 28\n(NIPS 2015).\n\n\nDESCRIPTION\n\nThe Yelp reviews polarity dataset is constructed by considering stars 1 and 2\nnegative, and 3 and 4 positive. For each polarity 280,000 training samples and\n19,000 testing samples are take randomly. In total there are 560,000 trainig\nsamples and 38,000 testing samples. Negative polarity is class 1,\nand positive class 2.\n\nThe files train.csv and test.csv contain all the training samples as\ncomma-sparated values. There are 2 columns in them, corresponding to class\nindex (1 and 2) and review text. The review texts are escaped using double\nquotes (""), and any internal double quote is escaped by 2 double quotes ("""").\nNew lines are escaped by a backslash followed with an ""n"" character,\nthat is ""\\n"".\n""""""\n\n_CITATION = """"""\\\n@article{zhangCharacterlevelConvolutionalNetworks2015,\n  archivePrefix = {arXiv},\n  eprinttype = {arxiv},\n  eprint = {1509.01626},\n  primaryClass = {cs},\n  title = {Character-Level {{Convolutional Networks}} for {{Text Classification}}},\n  abstract = {This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.},\n  journal = {arXiv:1509.01626 [cs]},\n  author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},\n  month = sep,\n  year = {2015},\n}\n\n""""""\n\n_DOWNLOAD_URL = ""https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz""\n\n\nclass YelpPolarityReviewsConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for YelpPolarityReviews.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, **kwargs):\n    """"""BuilderConfig for YelpPolarityReviews.\n\n    Args:\n        text_encoder_config: `tfds.features.text.TextEncoderConfig`,\n          configuration for the `tfds.features.text.TextEncoder` used for the\n          Yelp `""text""` feature.\n        **kwargs: keyword arguments forwarded to super.\n    """"""\n    super(YelpPolarityReviewsConfig, self).__init__(**kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n\nclass YelpPolarityReviews(tfds.core.GeneratorBasedBuilder):\n  """"""Yelp Polarity reviews dataset.""""""\n  BUILDER_CONFIGS = [\n      YelpPolarityReviewsConfig(\n          name=""plain_text"",\n          version=""0.1.0"",\n          description=""Plain text"",\n      ),\n      YelpPolarityReviewsConfig(\n          name=""bytes"",\n          version=""0.1.0"",\n          description=(""Uses byte-level text encoding with ""\n                       ""`tfds.features.text.ByteTextEncoder`""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder=tfds.features.text.ByteTextEncoder()),\n      ),\n      YelpPolarityReviewsConfig(\n          name=""subwords8k"",\n          version=""0.1.0"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with 8k ""\n                       ""vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**13),\n      ),\n      YelpPolarityReviewsConfig(\n          name=""subwords32k"",\n          version=""0.1.0"",\n          description=(""Uses `tfds.features.text.SubwordTextEncoder` with ""\n                       ""32k vocab size""),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              vocab_size=2**15),\n      ),\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""text"":\n                tfds.features.Text(\n                    encoder_config=self.builder_config.text_encoder_config),\n            ""label"":\n                tfds.features.ClassLabel(names=[""1"", ""2""]),\n        }),\n        supervised_keys=(""text"", ""label""),\n        homepage=""https://course.fast.ai/datasets"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, train_file):\n    for _, ex in self._generate_examples(train_file):\n      yield ex[""text""]\n\n  def _split_generators(self, dl_manager):\n    arch_path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n    train_file = os.path.join(arch_path, ""yelp_review_polarity_csv"",\n                              ""train.csv"")\n    test_file = os.path.join(arch_path, ""yelp_review_polarity_csv"", ""test.csv"")\n    self.info.features[""text""].maybe_build_from_corpus(\n        self._vocab_text_gen(train_file))\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={""filepath"": train_file}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""filepath"": test_file}),\n    ]\n\n  def _generate_examples(self, filepath):\n    """"""Generate Yelp examples.""""""\n    with tf.io.gfile.GFile(filepath) as f:\n      for line_id, line in enumerate(f):\n        # The format of the line is:\n        # ""1"", ""The text of the review.""\n        yield line_id, {""text"": line[5:-2].strip(), ""label"": line[1]}\n'"
tensorflow_datasets/text/yelp_polarity_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for yelp dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.text import yelp_polarity\n\n\nclass YelpPolarityReviewsTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = yelp_polarity.YelpPolarityReviews\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 2,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/translate/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Translation datasets.""""""\n\nfrom tensorflow_datasets.translate.flores import Flores\nfrom tensorflow_datasets.translate.flores import FloresConfig\nfrom tensorflow_datasets.translate.para_crawl import ParaCrawl\nfrom tensorflow_datasets.translate.para_crawl import ParaCrawlConfig\nfrom tensorflow_datasets.translate.ted_hrlr import TedHrlrTranslate\nfrom tensorflow_datasets.translate.ted_multi import TedMultiTranslate\nfrom tensorflow_datasets.translate.wmt import WmtConfig\nfrom tensorflow_datasets.translate.wmt14 import Wmt14Translate\nfrom tensorflow_datasets.translate.wmt15 import Wmt15Translate\nfrom tensorflow_datasets.translate.wmt16 import Wmt16Translate\nfrom tensorflow_datasets.translate.wmt17 import Wmt17Translate\nfrom tensorflow_datasets.translate.wmt18 import Wmt18Translate\nfrom tensorflow_datasets.translate.wmt19 import Wmt19Translate\nfrom tensorflow_datasets.translate.wmt_t2t import WmtT2tTranslate\n'"
tensorflow_datasets/translate/flores.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Facebook Low Resource (FLoRes) machine translation benchmark dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nEvaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English.\n""""""\n\n_CITATION = """"""\\\n@misc{guzmn2019new,\n    title={Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English},\n    author={Francisco Guzman and Peng-Jen Chen and Myle Ott and Juan Pino and Guillaume Lample and Philipp Koehn and Vishrav Chaudhary and Marc\'Aurelio Ranzato},\n    year={2019},\n    eprint={1902.01382},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n""""""\n\n_DATA_URL = ""https://github.com/facebookresearch/flores/raw/master/data/wikipedia_en_ne_si_test_sets.tgz""\n\n# Tuple that describes a single pair of files with matching translations.\n# language_to_file is the map from language (2 letter string: example \'en\')\n# to the file path in the extracted directory.\nTranslateData = collections.namedtuple(""TranslateData"",\n                                       [""url"", ""language_to_file""])\n\n\nclass FloresConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for FLoRes.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               text_encoder_config=None,\n               language_pair=(None, None),\n               **kwargs):\n    """"""BuilderConfig for FLoRes.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the features feature.\n      language_pair: pair of languages that will be used for translation. Should\n        contain 2-letter coded strings. First will be used at source and second\n        as target in supervised mode. For example: (""se"", ""en"").\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    encoder_name = (\n        text_encoder_config.name if text_encoder_config else ""plain_text"")\n    name = ""%s%s_%s"" % (language_pair[0], language_pair[1], encoder_name)\n\n    description = (\n        ""Translation dataset from %s to %s, uses encoder %s."") % (\n            language_pair[0], language_pair[1], encoder_name)\n    super(FloresConfig, self).__init__(\n        name=name,\n        description=description,\n        version=tfds.core.Version(\n            ""1.1.0"",\n            ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n\n    # Validate language pair.\n    assert ""en"" in language_pair, (\n        ""Config language pair must contain `en`, got: %s"",\n        language_pair)\n    source, target = language_pair\n    non_en = source if target == ""en"" else target\n    assert non_en in [""ne"", ""si""], (\n        ""Invalid non-en language in pair: %s"", non_en)\n\n    self.language_pair = language_pair\n\n\nclass Flores(tfds.core.GeneratorBasedBuilder):\n  """"""FLoRes machine translation dataset.""""""\n\n  BUILDER_CONFIGS = [\n      FloresConfig(\n          language_pair=(""ne"", ""en""),\n      ),\n      FloresConfig(\n          language_pair=(""si"", ""en""),\n      ),\n  ]\n\n  def _info(self):\n    source, target = self.builder_config.language_pair\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.Translation(\n            languages=self.builder_config.language_pair,\n            encoder_config=self.builder_config.text_encoder_config),\n        supervised_keys=(source, target),\n        homepage=""https://github.com/facebookresearch/flores/"",\n        citation=_CITATION,\n    )\n\n  def _vocab_text_gen(self, files, language):\n    for _, ex in self._generate_examples(**files):\n      yield ex[language]\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n\n    source, target = self.builder_config.language_pair\n    non_en = source if target == ""en"" else target\n    path_tmpl = (\n        ""{dl_dir}/wikipedia_en_ne_si_test_sets/wikipedia.{split}.{non_en}-en.""\n        ""{lang}"")\n\n    files = {}\n    for split in (""dev"", ""devtest""):\n      files[split] = {\n          ""source_file"": path_tmpl.format(\n              dl_dir=dl_dir, split=split, non_en=non_en, lang=source),\n          ""target_file"": path_tmpl.format(\n              dl_dir=dl_dir, split=split, non_en=non_en, lang=target),\n      }\n\n    # Generate vocabulary from dev data if text encoder configured.\n    for language in self.builder_config.language_pair:\n      self.info.features[source].maybe_build_from_corpus(\n          self._vocab_text_gen(files[""dev""], language))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs=files[""dev""]),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=files[""devtest""]),\n    ]\n\n  def _generate_examples(self, source_file, target_file):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(source_file) as f:\n      source_sentences = f.read().split(""\\n"")\n    with tf.io.gfile.GFile(target_file) as f:\n      target_sentences = f.read().split(""\\n"")\n\n    assert len(target_sentences) == len(\n        source_sentences), ""Sizes do not match: %d vs %d for %s vs %s."" % (\n            len(source_sentences), len(target_sentences), source_file,\n            target_file)\n\n    source, target = self.builder_config.language_pair\n    for idx, (l1, l2) in enumerate(\n        zip(source_sentences, target_sentences)):\n      result = {source: l1, target: l2}\n      # Make sure that both translations are non-empty.\n      if all(result.values()):\n        yield idx, result\n'"
tensorflow_datasets/translate/para_crawl.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""ParaCrawl (Bitextor) parallel open-source machine translation benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import utils\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = ""Web-Scale Parallel Corpora for Official European Languages.""\n\n_BENCHMARK_URL = ""https://paracrawl.eu/releases.html""\n\n_CITATION = """"""\\\n@misc {paracrawl,\n    title  = ""ParaCrawl"",\n    year   = ""2018"",\n    url    = ""http://paracrawl.eu/download.html.""\n}\n""""""\n\n_BASE_DATA_URL_FORMAT_STR = (""https://s3.amazonaws.com/web-language-models/""\n                             ""paracrawl/release4/en-{target_lang}.bicleaner07.""\n                             ""txt.gz"")\n\n\n@utils.memoize()\ndef _target_languages():\n  """"""Create the sorted dictionary of language codes, and language names.\n\n  Returns:\n    The sorted dictionary as an instance of `collections.OrderedDict`.\n  """"""\n  langs = {\n      ""bg"": ""Bulgarian"",\n      ""cs"": ""Czech"",\n      ""da"": ""Danish"",\n      ""de"": ""German"",\n      ""el"": ""Greek"",\n      ""es"": ""Spanish"",\n      ""et"": ""Estonian"",\n      ""fi"": ""Finnish"",\n      ""fr"": ""French"",\n      ""ga"": ""Irish"",\n      ""hr"": ""Croatian"",\n      ""hu"": ""Hungarian"",\n      ""it"": ""Italian"",\n      ""lt"": ""Lithuanian"",\n      ""lv"": ""Latvian"",\n      ""mt"": ""Maltese"",\n      ""nl"": ""Dutch"",\n      ""pl"": ""Polish"",\n      ""pt"": ""Portuguese"",\n      ""ro"": ""Romanian"",\n      ""sk"": ""Slovak"",\n      ""sl"": ""Slovenian"",\n      ""sv"": ""Swedish"",\n  }\n  return collections.OrderedDict(sorted(langs.items()))\n\n\nclass ParaCrawlConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for ParaCrawl.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, text_encoder_config=None, target_language=None, **kwargs):\n    """"""BuilderConfig for ParaCrawl.\n\n    Args:\n      text_encoder_config: `tfds.features.text.TextEncoderConfig`, configuration\n        for the `tfds.features.text.TextEncoder` used for the features feature.\n      target_language: Target language that will be used to translate to from\n        English which is always the source language. It has to contain 2-letter\n        coded strings. For example: ""se"", ""hu"".\n      **kwargs: Keyword arguments forwarded to super.\n    """"""\n    # Validate the target language.\n    if target_language not in _target_languages():\n      raise ValueError(""Invalid target language: %s "" % target_language)\n\n    # Initialize the base class.\n    encoder_name = (\n        text_encoder_config.name if text_encoder_config else ""plain_text"")\n    name = ""en%s_%s"" % (target_language, encoder_name)\n\n    description = (""Translation dataset from English to %s, uses encoder %s.""\n                  ) % (target_language, encoder_name)\n    super(ParaCrawlConfig, self).__init__(\n        name=name, description=description, **kwargs)\n\n    # Store the attributes.\n    self.text_encoder_config = (\n        text_encoder_config or tfds.features.text.TextEncoderConfig())\n    self.target_language = target_language\n    self.data_url = _BASE_DATA_URL_FORMAT_STR.format(\n        target_lang=target_language)\n\n\nclass ParaCrawl(tfds.core.GeneratorBasedBuilder):\n  """"""ParaCrawl machine translation dataset.""""""\n\n  # Version history:\n  # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).\n  # 0.1.0: Initial version.\n  BUILDER_CONFIGS = [\n      # The version below does not refer to the version of the released\n      # database. It only indicates the version of the TFDS integration.\n      ParaCrawlConfig(  # pylint: disable=g-complex-comprehension\n          target_language=target_language,\n          version=tfds.core.Version(""1.0.0""),\n      )\n      for target_language in _target_languages()\n  ]\n\n  def _info(self):\n    target_language = self.builder_config.target_language\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.Translation(\n            languages=(""en"", target_language),\n            encoder_config=self.builder_config.text_encoder_config),\n        supervised_keys=(""en"", target_language),\n        homepage=_BENCHMARK_URL,\n        citation=_CITATION)\n\n  def _vocab_text_gen(self, files, language):\n    for _, ex in self._generate_examples(**files):\n      yield ex[language]\n\n  def _split_generators(self, dl_manager):\n    # Download the data file.\n    data_file = dl_manager.download_and_extract(\n        {""data_file"": self.builder_config.data_url})\n\n    # Return the single split of the data.\n    return [\n        tfds.core.SplitGenerator(name=tfds.Split.TRAIN, gen_kwargs=data_file)\n    ]\n\n  def _generate_examples(self, data_file):\n    """"""This function returns the examples in the raw (text) form.""""""\n    target_language = self.builder_config.target_language\n\n    with tf.io.gfile.GFile(data_file) as f:\n      for idx, line in enumerate(f):\n        line_parts = line.strip().split(""\\t"")\n        if len(line_parts) != 2:\n          msg = (""Wrong data format in line {}. The line \'{}\' does ""\n                 ""not have exactly one delimiter."").format(idx, line)\n          raise ValueError(msg)\n        source, target = line_parts[0].strip(), line_parts[1].strip()\n        yield idx, {""en"": source, target_language: target}\n'"
tensorflow_datasets/translate/para_crawl_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for para_crawl dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.testing as tfds_test\nfrom tensorflow_datasets.translate import para_crawl\n\n\nclass ParacrawlTest(tfds_test.DatasetBuilderTestCase):\n\n  DATASET_CLASS = para_crawl.ParaCrawl\n  BUILDER_CONFIG_NAMES_TO_TEST = [""enhu_plain_text""]\n  SPLITS = {\n      ""train"": 5,\n  }\n  DL_EXTRACT_RESULT = {""data_file"": ""en-hu.bicleaner07.txt""}\n\n\nif __name__ == ""__main__"":\n  tfds_test.test_main()\n'"
tensorflow_datasets/translate/ted_hrlr.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TED talk high/low-resource paired language data set from Qi, et al. 2018.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nData sets derived from TED talk transcripts for comparing similar language pairs\nwhere one is high resource and the other is low resource.\n""""""\n\n_CITATION = """"""\\\n@inproceedings{Ye2018WordEmbeddings,\n  author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n  title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n  booktitle = {HLT-NAACL},\n  year    = {2018},\n  }\n""""""\n\n_DATA_URL = ""http://www.phontron.com/data/qi18naacl-dataset.tar.gz""\n\n_VALID_LANGUAGE_PAIRS = (\n    (""az"", ""en""),\n    (""az_tr"", ""en""),\n    (""be"", ""en""),\n    (""be_ru"", ""en""),\n    (""es"", ""pt""),\n    (""fr"", ""pt""),\n    (""gl"", ""en""),\n    (""gl_pt"", ""en""),\n    (""he"", ""pt""),\n    (""it"", ""pt""),\n    (""pt"", ""en""),\n    (""ru"", ""en""),\n    (""ru"", ""pt""),\n    (""tr"", ""en""),\n)\n\n\nclass TedHrlrConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for TED talk data comparing high/low resource languages.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, language_pair=(None, None), **kwargs):\n    """"""BuilderConfig for TED talk data comparing high/low resource languages.\n\n    The first language in `language_pair` should either be a 2-letter coded\n    string or two such strings joined by an underscore (e.g., ""az"" or ""az_tr"").\n    In cases where it contains two languages, the train data set will contain an\n    (unlabelled) mix of the two languages and the validation and test sets\n    will contain only the first language. This dataset will refer to the\n    source language by the 5-letter string with the underscore. The second\n    language in `language_pair` must be a 2-letter coded string.\n\n    For example, to get pairings between Russian and English, specify\n    `(""ru"", ""en"")` as `language_pair`. To get a mix of Belarusian and Russian in\n    the training set and purely Belarusian in the validation and test sets,\n    specify `(""be_ru"", ""en"")`.\n\n    Args:\n      language_pair: pair of languages that will be used for translation. The\n        first will be used as source and second as target in supervised mode.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name = ""%s_to_%s"" % (language_pair[0].replace(""_"", """"), language_pair[1])\n\n    description = (""Translation dataset from %s to %s in plain text."") % (\n        language_pair[0], language_pair[1])\n    super(TedHrlrConfig, self).__init__(\n        name=name, description=description, **kwargs)\n\n    # Validate language pair.\n    assert language_pair in _VALID_LANGUAGE_PAIRS, (\n        ""Config language pair (%s, ""\n        ""%s) not supported"") % language_pair\n\n    self.language_pair = language_pair\n\n\nclass TedHrlrTranslate(tfds.core.GeneratorBasedBuilder):\n  """"""TED talk data set for comparing high and low resource languages.""""""\n\n  BUILDER_CONFIGS = [\n      TedHrlrConfig(  # pylint: disable=g-complex-comprehension\n          language_pair=pair,\n          version=tfds.core.Version(\n              ""1.0.0"",\n              ""New split API (https://tensorflow.org/datasets/splits)""),\n      ) for pair in _VALID_LANGUAGE_PAIRS\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.Translation(\n            languages=self.builder_config.language_pair),\n        homepage=""https://github.com/neulab/word-embeddings-for-nmt"",\n        supervised_keys=self.builder_config.language_pair,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n    source, target = self.builder_config.language_pair\n\n    data_dir = os.path.join(dl_dir, ""datasets"", ""%s_to_%s"" % (source, target))\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""source_file"":\n                    os.path.join(data_dir, ""{}.train"".format(\n                        source.replace(""_"", ""-""))),\n                ""target_file"":\n                    os.path.join(data_dir, ""{}.train"".format(target))\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\n                ""source_file"":\n                    os.path.join(data_dir, ""{}.dev"".format(\n                        source.split(""_"")[0])),\n                ""target_file"":\n                    os.path.join(data_dir, ""{}.dev"".format(target))\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""source_file"":\n                    os.path.join(data_dir, ""{}.test"".format(\n                        source.split(""_"")[0])),\n                ""target_file"":\n                    os.path.join(data_dir, ""{}.test"".format(target))\n            }),\n    ]\n\n  def _generate_examples(self, source_file, target_file):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(source_file) as f:\n      source_sentences = f.read().split(""\\n"")\n    with tf.io.gfile.GFile(target_file) as f:\n      target_sentences = f.read().split(""\\n"")\n\n    assert len(target_sentences) == len(\n        source_sentences), ""Sizes do not match: %d vs %d for %s vs %s."" % (len(\n            source_sentences), len(target_sentences), source_file, target_file)\n\n    source, target = self.builder_config.language_pair\n    for idx, (l1, l2) in enumerate(\n        zip(source_sentences, target_sentences)):\n      result = {source: l1, target: l2}\n      # Make sure that both translations are non-empty.\n      if all(result.values()):\n        yield idx, result\n'"
tensorflow_datasets/translate/ted_hrlr_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the bilingual translate TED Talk module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.translate import ted_hrlr\n\n\nclass TedHrlrTranslateTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = ted_hrlr.TedHrlrTranslate\n  BUILDER_CONFIG_NAMES_TO_TEST = [""az_to_en"", ""aztr_to_en""]\n  SPLITS = {\n      ""train"": 4,\n      ""validation"": 4,\n      ""test"": 4,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/translate/ted_multi.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TED talk multilingual data set.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\nimport six\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nMassively multilingual (60 language) data set derived from TED Talk transcripts.\nEach record consists of parallel arrays of language and text. Missing and\nincomplete translations will be filtered out.\n""""""\n\n_CITATION = """"""\\\n@InProceedings{qi-EtAl:2018:N18-2,\n  author    = {Qi, Ye  and  Sachan, Devendra  and  Felix, Matthieu  and  Padmanabhan, Sarguna  and  Neubig, Graham},\n  title     = {When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\n  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\n  month     = {June},\n  year      = {2018},\n  address   = {New Orleans, Louisiana},\n  publisher = {Association for Computational Linguistics},\n  pages     = {529--535},\n  abstract  = {The performance of Neural Machine Translation (NMT) systems often suffers in low-resource scenarios where sufficiently large-scale parallel corpora cannot be obtained. Pre-trained word embeddings have proven to be invaluable for improving performance in natural language analysis tasks, which often suffer from paucity of data. However, their utility for NMT has not been extensively explored. In this work, we perform five sets of experiments that analyze when we can expect pre-trained word embeddings to help in NMT tasks. We show that such embeddings can be surprisingly effective in some cases -- providing gains of up to 20 BLEU points in the most favorable setting.},\n  url       = {http://www.aclweb.org/anthology/N18-2084}\n}\n""""""\n\n_DATA_URL = \'http://phontron.com/data/ted_talks.tar.gz\'\n\n_LANGUAGES = (\'en\', \'es\', \'pt-br\', \'fr\', \'ru\', \'he\', \'ar\', \'ko\', \'zh-cn\', \'it\',\n              \'ja\', \'zh-tw\', \'nl\', \'ro\', \'tr\', \'de\', \'vi\', \'pl\', \'pt\', \'bg\',\n              \'el\', \'fa\', \'sr\', \'hu\', \'hr\', \'uk\', \'cs\', \'id\', \'th\', \'sv\', \'sk\',\n              \'sq\', \'lt\', \'da\', \'calv\', \'my\', \'sl\', \'mk\', \'fr-ca\', \'fi\', \'hy\',\n              \'hi\', \'nb\', \'ka\', \'mn\', \'et\', \'ku\', \'gl\', \'mr\', \'zh\', \'ur\', \'eo\',\n              \'ms\', \'az\', \'ta\', \'bn\', \'kk\', \'be\', \'eu\', \'bs\')\n\n\nclass TedMultiTranslate(tfds.core.GeneratorBasedBuilder):\n  """"""TED talk multilingual data set.""""""\n\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'plain_text\',\n          version=tfds.core.Version(\n              \'1.0.0\',\n              \'New split API (https://tensorflow.org/datasets/splits)\'),\n          description=\'Plain text import of multilingual TED talk translations\',\n      )\n  ]\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            \'translations\':\n                tfds.features.TranslationVariableLanguages(languages=_LANGUAGES\n                                                          ),\n            \'talk_name\':\n                tfds.features.Text(),\n        }),\n        homepage=\'https://github.com/neulab/word-embeddings-for-nmt\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    dl_dir = dl_manager.download_and_extract(_DATA_URL)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'data_file\': os.path.join(dl_dir, \'all_talks_train.tsv\')\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={\'data_file\': os.path.join(dl_dir,\n                                                  \'all_talks_dev.tsv\')}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'data_file\': os.path.join(dl_dir, \'all_talks_test.tsv\')\n            }),\n    ]\n\n  def _generate_examples(self, data_file):\n    """"""This function returns the examples in the raw (text) form.""""""\n    with tf.io.gfile.GFile(data_file) as f:\n      reader = csv.DictReader(f, delimiter=\'\\t\', quoting=csv.QUOTE_NONE)\n      for idx, row in enumerate(reader):\n        # Everything in the row except for \'talk_name\' will be a translation.\n        # Missing/incomplete translations will contain the string ""__NULL__"" or\n        # ""_ _ NULL _ _"".\n        yield idx, {\n            \'translations\': {\n                lang: text\n                for lang, text in six.iteritems(row)\n                if lang != \'talk_name\' and _is_translation_complete(text)\n            },\n            \'talk_name\': row[\'talk_name\']\n        }\n\n\ndef _is_translation_complete(text):\n  return text and \'__NULL__\' not in text and \'_ _ NULL _ _\' not in text\n'"
tensorflow_datasets/translate/ted_multi_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for the translate TED Talk module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.translate import ted_multi\n\n\nclass TedMultiTranslateTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = ted_multi.TedMultiTranslate\n  SPLITS = {  # Expected number of examples on each split from fake example.\n      ""train"": 4,\n      ""validation"": 4,\n      ""test"": 4,\n  }\n  DL_EXTRACT_RESULT = """"\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/translate/wmt.py,15,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport functools\nimport gzip\nimport itertools\nimport os\nimport re\nimport xml.etree.cElementTree as ElementTree\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\n_DESCRIPTION = """"""\\\nTranslate dataset based on the data from statmt.org.\n\nVersions exists for the different years using a combination of multiple data\nsources. The base `wmt_translate` allows you to create your own config to choose\nyour own data/language pair by creating a custom `tfds.translate.wmt.WmtConfig`.\n\n```\nconfig = tfds.translate.wmt.WmtConfig(\n    version=""0.0.1"",\n    language_pair=(""fr"", ""de""),\n    subsets={\n        tfds.Split.TRAIN: [""commoncrawl_frde""],\n        tfds.Split.VALIDATION: [""euelections_dev2019""],\n    },\n)\nbuilder = tfds.builder(""wmt_translate"", config=config)\n```\n\n""""""\n\n\nCWMT_SUBSET_NAMES = [\n    ""casia2015"", ""casict2011"", ""casict2015"", ""datum2015"", ""datum2017"", ""neu2017""\n]\n\n\nclass SubDataset(object):\n  """"""Class to keep track of information on a sub-dataset of WMT.""""""\n\n  def __init__(self, name, target, sources, url, path, manual_dl_files=None):\n    """"""Sub-dataset of WMT.\n\n    Args:\n      name: `string`, a unique dataset identifier.\n      target: `string`, the target language code.\n      sources: `set<string>`, the set of source language codes.\n      url: `string` or `(string, string)`, URL(s) or URL template(s) specifying\n        where to download the raw data from. If two strings are provided, the\n        first is used for the source language and the second for the target.\n        Template strings can either contain \'{src}\' placeholders that will be\n        filled in with the source language code, \'{0}\' and \'{1}\' placeholders\n        that will be filled in with the source and target language codes in\n        alphabetical order, or all 3.\n      path: `string` or `(string, string)`, path(s) or path template(s)\n        specifing the path to the raw data relative to the root of the\n        downloaded archive. If two strings are provided, the dataset is assumed\n        to be made up of parallel text files, the first being the source and the\n        second the target. If one string is provided, both languages are assumed\n        to be stored within the same file and the extension is used to determine\n        how to parse it. Template strings should be formatted the same as in\n        `url`.\n      manual_dl_files: `<list>(string)` (optional), the list of files that must\n        be manually downloaded to the data directory.\n    """"""\n    self._paths = (path,) if isinstance(path, six.string_types) else path\n    self._urls = (url,) if isinstance(url, six.string_types) else url\n    self._manual_dl_files = manual_dl_files if manual_dl_files else []\n    self.name = name\n    self.target = target\n    self.sources = set(sources)\n\n  def _inject_language(self, src, strings):\n    """"""Injects languages into (potentially) template strings.""""""\n    if src not in self.sources:\n      raise ValueError(""Invalid source for \'{0}\': {1}"".format(self.name, src))\n    def _format_string(s):\n      if ""{0}"" in s and ""{1}"" and ""{src}"" in s:\n        return s.format(*sorted([src, self.target]), src=src)\n      elif ""{0}"" in s and ""{1}"" in s:\n        return s.format(*sorted([src, self.target]))\n      elif ""{src}"" in s:\n        return s.format(src=src)\n      else:\n        return s\n    return [_format_string(s) for s in strings]\n\n  def get_url(self, src):\n    return self._inject_language(src, self._urls)\n\n  def get_manual_dl_files(self, src):\n    return self._inject_language(src, self._manual_dl_files)\n\n  def get_path(self, src):\n    return self._inject_language(src, self._paths)\n\n\n# Subsets used in the training sets for various years of WMT.\n_TRAIN_SUBSETS = [\n    # pylint:disable=line-too-long\n    SubDataset(\n        name=""commoncrawl"",\n        target=""en"",   # fr-de pair in commoncrawl_frde\n        sources={""cs"", ""de"", ""es"", ""fr"", ""ru""},\n        url=""http://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz"",\n        path=(""commoncrawl.{src}-en.{src}"", ""commoncrawl.{src}-en.en"")),\n    SubDataset(\n        name=""commoncrawl_frde"",\n        target=""de"",\n        sources={""fr""},\n        url=(""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/commoncrawl.fr.gz"",\n             ""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/commoncrawl.de.gz""),\n        path=("""", """")),\n    SubDataset(\n        name=""czeng_10"",\n        target=""en"",\n        sources={""cs""},\n        url=""http://ufal.mff.cuni.cz/czeng/czeng10"",\n        manual_dl_files=[""data-plaintext-format.%d.tar"" % i for i in range(10)],\n        # Each tar contains multiple files, which we process specially in\n        # _parse_czeng.\n        path=(""data.plaintext-format/??train.gz"",) * 10),\n    SubDataset(\n        name=""czeng_16pre"",\n        target=""en"",\n        sources={""cs""},\n        url=""http://ufal.mff.cuni.cz/czeng/czeng16pre"",\n        manual_dl_files=[""czeng16pre.deduped-ignoring-sections.txt.gz""],\n        path=""""),\n    SubDataset(\n        name=""czeng_16"",\n        target=""en"",\n        sources={""cs""},\n        url=""http://ufal.mff.cuni.cz/czeng"",\n        manual_dl_files=[""data-plaintext-format.%d.tar"" % i for i in range(10)],\n        # Each tar contains multiple files, which we process specially in\n        # _parse_czeng.\n        path=(""data.plaintext-format/??train.gz"",) * 10),\n    SubDataset(\n        # This dataset differs from the above in the filtering that is applied\n        # during parsing.\n        name=""czeng_17"",\n        target=""en"",\n        sources={""cs""},\n        url=""http://ufal.mff.cuni.cz/czeng"",\n        manual_dl_files=[""data-plaintext-format.%d.tar"" % i for i in range(10)],\n        # Each tar contains multiple files, which we process specially in\n        # _parse_czeng.\n        path=(""data.plaintext-format/??train.gz"",) * 10),\n    SubDataset(\n        name=""dcep_v1"",\n        target=""en"",\n        sources={""lv""},\n        url=""http://data.statmt.org/wmt17/translation-task/dcep.lv-en.v1.tgz"",\n        path=(""dcep.en-lv/dcep.lv"", ""dcep.en-lv/dcep.en"")),\n    SubDataset(\n        name=""europarl_v7"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr""},\n        url=""http://www.statmt.org/wmt13/training-parallel-europarl-v7.tgz"",\n        path=(""training/europarl-v7.{src}-en.{src}"",\n              ""training/europarl-v7.{src}-en.en"")),\n    SubDataset(\n        name=""europarl_v7_frde"",\n        target=""de"",\n        sources={""fr""},\n        url=(""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/europarl-v7.fr.gz"",\n             ""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/europarl-v7.de.gz""),\n        path=("""", """")),\n    SubDataset(\n        name=""europarl_v8_18"",\n        target=""en"",\n        sources={""et"", ""fi""},\n        url=""http://data.statmt.org/wmt18/translation-task/training-parallel-ep-v8.tgz"",\n        path=(""training/europarl-v8.{src}-en.{src}"",\n              ""training/europarl-v8.{src}-en.en"")),\n    SubDataset(\n        name=""europarl_v8_16"",\n        target=""en"",\n        sources={""fi"", ""ro""},\n        url=""http://data.statmt.org/wmt16/translation-task/training-parallel-ep-v8.tgz"",\n        path=(""training-parallel-ep-v8/europarl-v8.{src}-en.{src}"",\n              ""training-parallel-ep-v8/europarl-v8.{src}-en.en"")),\n    SubDataset(\n        name=""europarl_v9"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fi"", ""lt""},\n        url=""http://www.statmt.org/europarl/v9/training/europarl-v9.{src}-en.tsv.gz"",\n        path=""""),\n    SubDataset(\n        name=""gigafren"",\n        target=""en"",\n        sources={""fr""},\n        url=""http://www.statmt.org/wmt10/training-giga-fren.tar"",\n        path=(""giga-fren.release2.fixed.fr.gz"",\n              ""giga-fren.release2.fixed.en.gz"")),\n    SubDataset(\n        name=""hindencorp_01"",\n        target=""en"",\n        sources={""hi""},\n        url=""http://ufallab.ms.mff.cuni.cz/~bojar/hindencorp"",\n        manual_dl_files=[""hindencorp0.1.gz""],\n        path=""""),\n    SubDataset(\n        name=""leta_v1"",\n        target=""en"",\n        sources={""lv""},\n        url=""http://data.statmt.org/wmt17/translation-task/leta.v1.tgz"",\n        path=(""LETA-lv-en/leta.lv"", ""LETA-lv-en/leta.en"")),\n    SubDataset(\n        name=""multiun"",\n        target=""en"",\n        sources={""es"", ""fr""},\n        url=""http://www.statmt.org/wmt13/training-parallel-un.tgz"",\n        path=(""un/undoc.2000.{src}-en.{src}"", ""un/undoc.2000.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v9"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fr"", ""ru""},\n        url=""http://www.statmt.org/wmt14/training-parallel-nc-v9.tgz"",\n        path=(""training/news-commentary-v9.{src}-en.{src}"",\n              ""training/news-commentary-v9.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v10"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fr"", ""ru""},\n        url=""http://www.statmt.org/wmt15/training-parallel-nc-v10.tgz"",\n        path=(""news-commentary-v10.{src}-en.{src}"",\n              ""news-commentary-v10.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v11"",\n        target=""en"",\n        sources={""cs"", ""de"", ""ru""},\n        url=""http://data.statmt.org/wmt16/translation-task/training-parallel-nc-v11.tgz"",\n        path=(""training-parallel-nc-v11/news-commentary-v11.{src}-en.{src}"",\n              ""training-parallel-nc-v11/news-commentary-v11.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v12"",\n        target=""en"",\n        sources={""cs"", ""de"", ""ru"", ""zh""},\n        url=""http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz"",\n        path=(""training/news-commentary-v12.{src}-en.{src}"",\n              ""training/news-commentary-v12.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v13"",\n        target=""en"",\n        sources={""cs"", ""de"", ""ru"", ""zh""},\n        url=""http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz"",\n        path=(""training-parallel-nc-v13/news-commentary-v13.{src}-en.{src}"",\n              ""training-parallel-nc-v13/news-commentary-v13.{src}-en.en"")),\n    SubDataset(\n        name=""newscommentary_v14"",\n        target=""en"",  # fr-de pair in newscommentary_v14_frde\n        sources={""cs"", ""de"", ""kk"", ""ru"", ""zh""},\n        url=""http://data.statmt.org/news-commentary/v14/training/news-commentary-v14.{0}-{1}.tsv.gz"",\n        path=""""),\n    SubDataset(\n        name=""newscommentary_v14_frde"",\n        target=""de"",\n        sources={""fr""},\n        url=""http://data.statmt.org/news-commentary/v14/training/news-commentary-v14.de-fr.tsv.gz"",\n        path=""""),\n    SubDataset(\n        name=""onlinebooks_v1"",\n        target=""en"",\n        sources={""lv""},\n        url=""http://data.statmt.org/wmt17/translation-task/books.lv-en.v1.tgz"",\n        path=(""farewell/farewell.lv"", ""farewell/farewell.en"")),\n    SubDataset(\n        name=""paracrawl_v1"",\n        target=""en"",\n        sources={""cs"", ""de"", ""et"", ""fi"", ""ru""},\n        url=""https://s3.amazonaws.com/web-language-models/paracrawl/release1/paracrawl-release1.en-{src}.zipporah0-dedup-clean.tgz"",\n        path=(""paracrawl-release1.en-{src}.zipporah0-dedup-clean.{src}"",\n              ""paracrawl-release1.en-{src}.zipporah0-dedup-clean.en"")),\n    SubDataset(\n        name=""paracrawl_v1_ru"",\n        target=""en"",\n        sources={""ru""},\n        url=""https://s3.amazonaws.com/web-language-models/paracrawl/release1/paracrawl-release1.en-ru.zipporah0-dedup-clean.tgz"",\n        path=(""paracrawl-release1.en-ru.zipporah0-dedup-clean.ru"",\n              ""paracrawl-release1.en-ru.zipporah0-dedup-clean.en"")),\n    SubDataset(\n        name=""paracrawl_v3"",\n        target=""en"",  # fr-de pair in paracrawl_v3_frde\n        sources={""cs"", ""de"", ""fi"", ""lt""},\n        url=""https://s3.amazonaws.com/web-language-models/paracrawl/release3/en-{src}.bicleaner07.tmx.gz"",\n        path=""""),\n    SubDataset(\n        name=""paracrawl_v3_frde"",\n        target=""de"",\n        sources={""fr""},\n        url=(""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/de-fr.bicleaner07.de.gz"",\n             ""http://data.statmt.org/wmt19/translation-task/fr-de/bitexts/de-fr.bicleaner07.fr.gz""),\n        path=("""", """")),\n    SubDataset(\n        name=""rapid_2016"",\n        target=""en"",\n        sources={""de"", ""et"", ""fi""},\n        url=""http://data.statmt.org/wmt18/translation-task/rapid2016.tgz"",\n        path=(""rapid2016.{0}-{1}.{src}"", ""rapid2016.{0}-{1}.en"")),\n    SubDataset(\n        name=""rapid_2016_ltfi"",\n        target=""en"",\n        sources={""fi"", ""lt""},\n        url=""https://tilde-model.s3-eu-west-1.amazonaws.com/rapid2016.en-{src}.tmx.zip"",\n        path=""rapid2016.en-{src}.tmx""),\n    SubDataset(\n        name=""rapid_2019"",\n        target=""en"",\n        sources={""de""},\n        url=""https://s3-eu-west-1.amazonaws.com/tilde-model/rapid2019.de-en.zip"",\n        path=(""rapid2019.de-en.de"", ""rapid2019.de-en.en"")),\n    SubDataset(\n        name=""setimes_2"",\n        target=""en"",\n        sources={""ro"", ""tr""},\n        url=""http://opus.nlpl.eu/download.php?f=SETIMES/v2/tmx/en-{src}.tmx.gz"",\n        path=""""),\n    SubDataset(\n        name=""uncorpus_v1"",\n        target=""en"",\n        sources={""ru"", ""zh""},\n        url=""https://storage.googleapis.com/tfds-data/downloads/uncorpus/UNv1.0.en-{src}.tar.gz"",\n        path=(""en-{src}/UNv1.0.en-{src}.{src}"", ""en-{src}/UNv1.0.en-{src}.en"")),\n    SubDataset(\n        name=""wikiheadlines_fi"",\n        target=""en"",\n        sources={""fi""},\n        url=""http://www.statmt.org/wmt15/wiki-titles.tgz"",\n        path=""wiki/fi-en/titles.fi-en""),\n    SubDataset(\n        name=""wikiheadlines_hi"",\n        target=""en"",\n        sources={""hi""},\n        url=""http://www.statmt.org/wmt14/wiki-titles.tgz"",\n        path=""wiki/hi-en/wiki-titles.hi-en""),\n    SubDataset(\n        # Verified that wmt14 and wmt15 files are identical.\n        name=""wikiheadlines_ru"",\n        target=""en"",\n        sources={""ru""},\n        url=""http://www.statmt.org/wmt15/wiki-titles.tgz"",\n        path=""wiki/ru-en/wiki.ru-en""),\n    SubDataset(\n        name=""wikititles_v1"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fi"", ""gu"", ""kk"", ""lt"", ""ru"", ""zh""},\n        url=""http://data.statmt.org/wikititles/v1/wikititles-v1.{src}-en.tsv.gz"",\n        path=""""),\n    SubDataset(\n        name=""yandexcorpus"",\n        target=""en"",\n        sources={""ru""},\n        url=""https://translate.yandex.ru/corpus?lang=en"",\n        manual_dl_files=[""1mcorpus.zip""],\n        path=(""corpus.en_ru.1m.ru"", ""corpus.en_ru.1m.en"")),\n    # pylint:enable=line-too-long\n] + [\n    SubDataset(  # pylint:disable=g-complex-comprehension\n        name=ss,\n        target=""en"",\n        sources={""zh""},\n        url=""ftp://cwmt-wmt:cwmt-wmt@nlp.nju.edu.cn/parallel/%s.zip"" % ss,\n        path=(""%s/*_c[hn].txt"" % ss, ""%s/*_en.txt"" % ss))\n    for ss in CWMT_SUBSET_NAMES\n]\n\n_DEV_SUBSETS = [\n    SubDataset(\n        name=""euelections_dev2019"",\n        target=""de"",\n        sources={""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/euelections_dev2019.fr-de.src.fr"",\n              ""dev/euelections_dev2019.fr-de.tgt.de"")),\n    SubDataset(\n        name=""newsdev2014"",\n        target=""en"",\n        sources={""hi""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2014.hi"", ""dev/newsdev2014.en"")),\n    SubDataset(\n        name=""newsdev2015"",\n        target=""en"",\n        sources={""fi""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2015-fien-src.{src}.sgm"",\n              ""dev/newsdev2015-fien-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdiscussdev2015"",\n        target=""en"",\n        sources={""ro"", ""tr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdiscussdev2015-{src}en-src.{src}.sgm"",\n              ""dev/newsdiscussdev2015-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdev2016"",\n        target=""en"",\n        sources={""ro"", ""tr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2016-{src}en-src.{src}.sgm"",\n              ""dev/newsdev2016-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdev2017"",\n        target=""en"",\n        sources={""lv"", ""zh""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2017-{src}en-src.{src}.sgm"",\n              ""dev/newsdev2017-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdev2018"",\n        target=""en"",\n        sources={""et""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2018-{src}en-src.{src}.sgm"",\n              ""dev/newsdev2018-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdev2019"",\n        target=""en"",\n        sources={""gu"", ""kk"", ""lt""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdev2019-{src}en-src.{src}.sgm"",\n              ""dev/newsdev2019-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdiscussdev2015"",\n        target=""en"",\n        sources={""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdiscussdev2015-{src}en-src.{src}.sgm"",\n              ""dev/newsdiscussdev2015-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdiscusstest2015"",\n        target=""en"",\n        sources={""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdiscusstest2015-{src}en-src.{src}.sgm"",\n              ""dev/newsdiscusstest2015-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newssyscomb2009"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newssyscomb2009.{src}"",\n              ""dev/newssyscomb2009.en"")),\n    SubDataset(\n        name=""newstest2008"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr"", ""hu""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/news-test2008.{src}"", ""dev/news-test2008.en"")),\n    SubDataset(\n        name=""newstest2009"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2009.{src}"", ""dev/newstest2009.en"")),\n    SubDataset(\n        name=""newstest2010"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2010.{src}"", ""dev/newstest2010.en"")),\n    SubDataset(\n        name=""newstest2011"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2011.{src}"", ""dev/newstest2011.en"")),\n    SubDataset(\n        name=""newstest2012"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr"", ""ru""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2012.{src}"", ""dev/newstest2012.en"")),\n    SubDataset(\n        name=""newstest2013"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr"", ""ru""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2013.{src}"", ""dev/newstest2013.en"")),\n    SubDataset(\n        name=""newstest2014"",\n        target=""en"",\n        sources={""cs"", ""de"", ""es"", ""fr"", ""hi"", ""ru""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2014-{src}en-src.{src}.sgm"",\n              ""dev/newstest2014-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newstest2015"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fi"", ""ru""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2015-{src}en-src.{src}.sgm"",\n              ""dev/newstest2015-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newsdiscusstest2015"",\n        target=""en"",\n        sources={""fr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newsdiscusstest2015-{src}en-src.{src}.sgm"",\n              ""dev/newsdiscusstest2015-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newstest2016"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fi"", ""ro"", ""ru"", ""tr""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2016-{src}en-src.{src}.sgm"",\n              ""dev/newstest2016-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newstestB2016"",\n        target=""en"",\n        sources={""fi""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstestB2016-enfi-ref.{src}.sgm"",\n              ""dev/newstestB2016-enfi-src.en.sgm"")),\n    SubDataset(\n        name=""newstest2017"",\n        target=""en"",\n        sources={""cs"", ""de"", ""fi"", ""lv"", ""ru"", ""tr"", ""zh""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2017-{src}en-src.{src}.sgm"",\n              ""dev/newstest2017-{src}en-ref.en.sgm"")),\n    SubDataset(\n        name=""newstestB2017"",\n        target=""en"",\n        sources={""fi""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstestB2017-fien-src.fi.sgm"",\n              ""dev/newstestB2017-fien-ref.en.sgm"")),\n    SubDataset(\n        name=""newstest2018"",\n        target=""en"",\n        sources={""cs"", ""de"", ""et"", ""fi"", ""ru"", ""tr"", ""zh""},\n        url=""http://data.statmt.org/wmt19/translation-task/dev.tgz"",\n        path=(""dev/newstest2018-{src}en-src.{src}.sgm"",\n              ""dev/newstest2018-{src}en-ref.en.sgm"")),\n]\n\nDATASET_MAP = {ds.name: ds for ds in _TRAIN_SUBSETS + _DEV_SUBSETS}\n\n_CZENG17_FILTER = SubDataset(\n    name=""czeng17_filter"",\n    target=""en"",\n    sources={""cs""},\n    url=""http://ufal.mff.cuni.cz/czeng/download.php?f=convert_czeng16_to_17.pl.zip"",\n    path=""convert_czeng16_to_17.pl""\n)\n\n\nclass WmtConfig(tfds.core.BuilderConfig):\n  """"""BuilderConfig for WMT.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self,\n               url=None,\n               citation=None,\n               description=None,\n               language_pair=(None, None),\n               text_encoder_config=None,\n               subsets=None,\n               **kwargs):\n    """"""BuilderConfig for WMT.\n\n    Args:\n      url: The reference URL for the dataset.\n      citation: The paper citation for the dataset.\n      description: The description of the dataset.\n      language_pair: pair of languages that will be used for translation. Should\n                 contain 2 letter coded strings. For example: (""en"", ""de"").\n      text_encoder_config: `tfds.features.text.TextEncoderConfig` (optional),\n        configuration for the `tfds.features.text.TextEncoder` used for the\n        `tfds.features.text.Translation` features.\n      subsets: Dict[split, list[str]]. List of the subset to use for each of the\n        split. Note that WMT subclasses overwrite this parameter.\n      **kwargs: keyword arguments forwarded to super.\n    """"""\n    name = ""%s-%s"" % (language_pair[0], language_pair[1])\n    if text_encoder_config:\n      name += ""."" + text_encoder_config.name\n    if ""name"" in kwargs:  # Add name suffix for custom configs\n      name += ""."" + kwargs.pop(""name"")\n\n    super(WmtConfig, self).__init__(\n        name=name, description=description, **kwargs)\n\n    self.url = url or ""http://www.statmt.org""\n    self.citation = citation\n    self.language_pair = language_pair\n    self.text_encoder_config = text_encoder_config\n    self.subsets = subsets\n\n\nclass WmtTranslate(tfds.core.GeneratorBasedBuilder):\n  """"""WMT translation dataset.""""""\n\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""\\\n  Some of the wmt configs here, require a manual download.\n  Please look into wmt.py to see the exact path (and file name) that has to\n  be downloaded.\n  """"""\n\n  def __init__(self, *args, **kwargs):\n    if type(self) == WmtTranslate and ""config"" not in kwargs:   # pylint: disable=unidiomatic-typecheck\n      raise ValueError(\n          ""The raw `wmt_translate` can only be instantiated with the config ""\n          ""kwargs. You may want to use one of the `wmtYY_translate` ""\n          ""implementation instead to get the WMT dataset for a specific year.""\n      )\n    super(WmtTranslate, self).__init__(*args, **kwargs)\n\n  @property\n  def _subsets(self):\n    """"""Subsets that make up each split of the dataset.""""""\n    return self.builder_config.subsets\n\n  @property\n  def subsets(self):\n    """"""Subsets that make up each split of the dataset for the language pair.""""""\n    source, target = self.builder_config.language_pair\n    filtered_subsets = {}\n    for split, ss_names in self._subsets.items():\n      filtered_subsets[split] = []\n      for ss_name in ss_names:\n        ds = DATASET_MAP[ss_name]\n        if ds.target != target or source not in ds.sources:\n          logging.info(\n              ""Skipping sub-dataset that does not include language pair: %s"",\n              ss_name)\n        else:\n          filtered_subsets[split].append(ss_name)\n    logging.info(""Using sub-datasets: %s"", filtered_subsets)\n    return filtered_subsets\n\n  def _info(self):\n    src, target = self.builder_config.language_pair\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.Translation(\n            languages=self.builder_config.language_pair,\n            encoder_config=self.builder_config.text_encoder_config),\n        supervised_keys=(src, target),\n        homepage=self.builder_config.url,\n        citation=self.builder_config.citation,\n    )\n\n  def _vocab_text_gen(self, split_subsets, extraction_map, language):\n    for _, ex in self._generate_examples(split_subsets, extraction_map):\n      yield ex[language]\n\n  def _split_generators(self, dl_manager):\n    source, _ = self.builder_config.language_pair\n\n    def _check_manual_files(ds):\n      """"""Verifies the manual files are downloaded for the given sub-dataset.""""""\n      manual_dl_files = ds.get_manual_dl_files(source)\n      manual_paths = []\n      for fname in manual_dl_files:\n        manual_path = os.path.join(dl_manager.manual_dir, fname)\n        if not tf.io.gfile.exists(manual_path):\n          raise AssertionError(\n              ""For {0}, you must manually download the following file(s) ""\n              ""from {1} and place them in {2}: {3}"".format(\n                  ds.name, ds.get_url(source), dl_manager.manual_dir,\n                  "", "".join(manual_dl_files)))\n        manual_paths.append(manual_path)\n      return manual_paths\n\n    manual_paths = {}\n    urls_to_download = {}\n    for ss_name in itertools.chain.from_iterable(self.subsets.values()):\n      if ss_name == ""czeng_17"":\n        # CzEng1.7 is CzEng1.6 with some blocks filtered out. We must download\n        # the filtering script so we can parse out which blocks need to be\n        # removed.\n        urls_to_download[_CZENG17_FILTER.name] = _CZENG17_FILTER.get_url(source)\n      ds = DATASET_MAP[ss_name]\n      if ds.get_manual_dl_files(source):\n        manual_paths[ss_name] = _check_manual_files(ds)\n      else:\n        urls_to_download[ss_name] = ds.get_url(source)\n\n    # Download and extract files from URLs.\n    downloaded_files = dl_manager.download_and_extract(urls_to_download)\n    # Extract manually downloaded files.\n    manual_files = dl_manager.extract(manual_paths)\n\n    extraction_map = dict(downloaded_files, **manual_files)\n\n    # Generate vocabulary from training data if SubwordTextEncoder configured.\n    for language in self.builder_config.language_pair:\n      self.info.features[language].maybe_build_from_corpus(\n          self._vocab_text_gen(\n              self.subsets[tfds.Split.TRAIN], extraction_map, language))\n\n    return [\n        tfds.core.SplitGenerator(  # pylint:disable=g-complex-comprehension\n            name=split,\n            gen_kwargs={""split_subsets"": split_subsets,\n                        ""extraction_map"": extraction_map})\n        for split, split_subsets in self.subsets.items()\n    ]\n\n  def _generate_examples(self, split_subsets, extraction_map):\n    """"""Returns the examples in the raw (text) form.""""""\n    source, _ = self.builder_config.language_pair\n\n    def _get_local_paths(ds, extract_dirs):\n      rel_paths = ds.get_path(source)\n      if len(extract_dirs) == 1:\n        extract_dirs = extract_dirs * len(rel_paths)\n      return [os.path.join(ex_dir, rel_path) if rel_path else ex_dir\n              for ex_dir, rel_path in zip(extract_dirs, rel_paths)]\n\n    for ss_name in split_subsets:\n      logging.info(""Generating examples from: %s"", ss_name)\n      ds = DATASET_MAP[ss_name]\n      extract_dirs = extraction_map[ss_name]\n      files = _get_local_paths(ds, extract_dirs)\n      if ss_name.startswith(""czeng""):\n        if ss_name.endswith(""16pre""):\n          sub_generator = functools.partial(\n              _parse_tsv, language_pair=(""en"", ""cs""))\n        elif ss_name.endswith(""17""):\n          filter_path = _get_local_paths(\n              _CZENG17_FILTER, extraction_map[_CZENG17_FILTER.name])[0]\n          sub_generator = functools.partial(\n              _parse_czeng, filter_path=filter_path)\n        else:\n          sub_generator = _parse_czeng\n      elif ss_name == ""hindencorp_01"":\n        sub_generator = _parse_hindencorp\n      elif len(files) == 2:\n        if ss_name.endswith(""_frde""):\n          sub_generator = _parse_frde_bitext\n        else:\n          sub_generator = _parse_parallel_sentences\n      elif len(files) == 1:\n        fname = files[0]\n        # Note: Due to formatting used by `download_manager`, the file\n        # extension may not be at the end of the file path.\n        if "".tsv"" in fname:\n          sub_generator = _parse_tsv\n        elif ss_name.startswith(""newscommentary_v14""):\n          sub_generator = functools.partial(\n              _parse_tsv, language_pair=self.builder_config.language_pair)\n        elif ""tmx"" in fname:\n          sub_generator = _parse_tmx\n        elif ss_name.startswith(""wikiheadlines""):\n          sub_generator = _parse_wikiheadlines\n        else:\n          raise ValueError(""Unsupported file format: %s"" % fname)\n      else:\n        raise ValueError(""Invalid number of files: %d"" % len(files))\n\n      for sub_key, ex in sub_generator(*files):\n        if not all(ex.values()):\n          continue\n        # TODO(adarob): Add subset feature.\n        # ex[""subset""] = subset\n        key = ""{}/{}"".format(ss_name, sub_key)\n        yield key, ex\n\n\ndef _parse_parallel_sentences(f1, f2):\n  """"""Returns examples from parallel SGML or text files, which may be gzipped.""""""\n  def _parse_text(path):\n    """"""Returns the sentences from a single text file, which may be gzipped.""""""\n    split_path = path.split(""."")\n\n    if split_path[-1] == ""gz"":\n      lang = split_path[-2]\n      with tf.io.gfile.GFile(path, ""rb"") as f, gzip.GzipFile(fileobj=f) as g:\n        return g.read().decode(""utf-8"").splitlines(), lang\n\n    if split_path[-1] == ""txt"":\n      # CWMT\n      lang = split_path[-2].split(""_"")[-1]\n      lang = ""zh"" if lang in (""ch"", ""cn"") else lang\n    else:\n      lang = split_path[-1]\n    with tf.io.gfile.GFile(path) as f:\n      return f.read().splitlines(), lang\n\n  def _parse_sgm(path):\n    """"""Returns sentences from a single SGML file.""""""\n    lang = path.split(""."")[-2]\n    sentences = []\n    # Note: We can\'t use the XML parser since some of the files are badly\n    # formatted.\n    seg_re = re.compile(r""<seg id=\\""\\d+\\"">(.*)</seg>"")\n    with tf.io.gfile.GFile(path) as f:\n      for line in f:\n        seg_match = re.match(seg_re, line)\n        if seg_match:\n          assert len(seg_match.groups()) == 1\n          sentences.append(seg_match.groups()[0])\n    return sentences, lang\n\n  parse_file = _parse_sgm if f1.endswith("".sgm"") else _parse_text\n\n  # Some datasets (e.g., CWMT) contain multiple parallel files specified with\n  # a wildcard. We sort both sets to align them and parse them one by one.\n  f1_files = tf.io.gfile.glob(f1)\n  f2_files = tf.io.gfile.glob(f2)\n\n  assert f1_files and f2_files, ""No matching files found: %s, %s."" % (f1, f2)\n  assert len(f1_files) == len(f2_files), (\n      ""Number of files do not match: %d vs %d for %s vs %s."" % (\n          len(f1_files), len(f2_files), f1, f2))\n\n  for f_id, (f1_i, f2_i) in enumerate(zip(sorted(f1_files), sorted(f2_files))):\n    l1_sentences, l1 = parse_file(f1_i)\n    l2_sentences, l2 = parse_file(f2_i)\n\n    assert len(l1_sentences) == len(l2_sentences), (\n        ""Sizes do not match: %d vs %d for %s vs %s."" % (\n            len(l1_sentences), len(l2_sentences), f1_i, f2_i))\n\n    for line_id, (s1, s2) in enumerate(zip(l1_sentences, l2_sentences)):\n      key = ""{}/{}"".format(f_id, line_id)\n      yield key, {\n          l1: s1,\n          l2: s2\n      }\n\n\ndef _parse_frde_bitext(fr_path, de_path):\n  with tf.io.gfile.GFile(fr_path) as f:\n    fr_sentences = f.read().splitlines()\n  with tf.io.gfile.GFile(de_path) as f:\n    de_sentences = f.read().splitlines()\n  assert len(fr_sentences) == len(de_sentences), (\n      ""Sizes do not match: %d vs %d for %s vs %s."" % (\n          len(fr_sentences), len(de_sentences), fr_path, de_path))\n  for line_id, (s1, s2) in enumerate(zip(fr_sentences, de_sentences)):\n    yield line_id, {\n        ""fr"": s1,\n        ""de"": s2\n    }\n\n\ndef _parse_tmx(path):\n  """"""Generates examples from TMX file.""""""\n  def _get_tuv_lang(tuv):\n    for k, v in tuv.items():\n      if k.endswith(""}lang""):\n        return v\n    raise AssertionError(""Language not found in `tuv` attributes."")\n\n  def _get_tuv_seg(tuv):\n    segs = tuv.findall(""seg"")\n    assert len(segs) == 1, ""Invalid number of segments: %d"" % len(segs)\n    return segs[0].text\n\n  with tf.io.gfile.GFile(path, ""rb"") as f:\n    if six.PY3:\n      # Workaround due to: https://github.com/tensorflow/tensorflow/issues/33563\n      utf_f = codecs.getreader(""utf-8"")(f)\n    else:\n      utf_f = f\n    for line_id, (_, elem) in enumerate(ElementTree.iterparse(utf_f)):  # pytype: disable=wrong-arg-types\n      if elem.tag == ""tu"":\n        yield line_id, {\n            _get_tuv_lang(tuv):\n                _get_tuv_seg(tuv) for tuv in elem.iterfind(""tuv"")\n        }\n        elem.clear()\n\n\ndef _parse_tsv(path, language_pair=None):\n  """"""Generates examples from TSV file.""""""\n  if language_pair is None:\n    lang_match = re.match(r"".*\\.([a-z][a-z])-([a-z][a-z])\\.tsv"", path)\n    assert lang_match is not None, ""Invalid TSV filename: %s"" % path\n    l1, l2 = lang_match.groups()\n  else:\n    l1, l2 = language_pair\n  with tf.io.gfile.GFile(path) as f:\n    for j, line in enumerate(f):\n      cols = line.split(""\\t"")\n      if len(cols) != 2:\n        logging.warning(\n            ""Skipping line %d in TSV (%s) with %d != 2 columns."",\n            j, path, len(cols))\n        continue\n      s1, s2 = cols\n      yield j, {\n          l1: s1.strip(),\n          l2: s2.strip()\n      }\n\n\ndef _parse_wikiheadlines(path):\n  """"""Generates examples from Wikiheadlines dataset file.""""""\n  lang_match = re.match(r"".*\\.([a-z][a-z])-([a-z][a-z])$"", path)\n  assert lang_match is not None, ""Invalid Wikiheadlines filename: %s"" % path\n  l1, l2 = lang_match.groups()\n  with tf.io.gfile.GFile(path) as f:\n    for line_id, line in enumerate(f):\n      s1, s2 = line.split(""|||"")\n      yield line_id, {\n          l1: s1.strip(),\n          l2: s2.strip()\n      }\n\n\ndef _parse_czeng(*paths, **kwargs):\n  """"""Generates examples from CzEng v1.6, with optional filtering for v1.7.""""""\n  filter_path = kwargs.get(""filter_path"", None)\n  if filter_path:\n    re_block = re.compile(r""^[^-]+-b(\\d+)-\\d\\d[tde]"")\n    with tf.io.gfile.GFile(filter_path) as f:\n      bad_blocks = set(\n          re.search(r""qw{([\\s\\d]*)}"", f.read()).groups()[0].split())  # pytype: disable=attribute-error\n    logging.info(\n        ""Loaded %d bad blocks to filter from CzEng v1.6 to make v1.7."",\n        len(bad_blocks))\n\n  for path in paths:\n    for gz_path in tf.io.gfile.glob(path):\n      with tf.io.gfile.GFile(gz_path, ""rb"") as g, gzip.GzipFile(fileobj=g) as f:\n        filename = os.path.basename(gz_path)\n        for line_id, line in enumerate(f):\n          line = line.decode(""utf-8"")  # required for py3\n          if not line.strip():\n            continue\n          id_, unused_score, cs, en = line.split(""\\t"")\n          if filter_path:\n            block_match = re.match(re_block, id_)\n            if block_match and block_match.groups()[0] in bad_blocks:\n              continue\n          sub_key = ""{}/{}"".format(filename, line_id)\n          yield sub_key, {\n              ""cs"": cs.strip(),\n              ""en"": en.strip(),\n          }\n\n\ndef _parse_hindencorp(path):\n  with tf.io.gfile.GFile(path) as f:\n    for line_id, line in enumerate(f):\n      split_line = line.split(""\\t"")\n      if len(split_line) != 5:\n        logging.warning(""Skipping invalid HindEnCorp line: %s"", line)\n        continue\n      yield line_id, {\n          ""en"": split_line[3].strip(),\n          ""hi"": split_line[4].strip()\n      }\n'"
tensorflow_datasets/translate/wmt14.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT14: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt14/translation-task.html""\n_CITATION = """"""\n@InProceedings{bojar-EtAl:2014:W14-33,\n  author    = {Bojar, Ondrej  and  Buck, Christian  and  Federmann, Christian  and  Haddow, Barry  and  Koehn, Philipp  and  Leveling, Johannes  and  Monz, Christof  and  Pecina, Pavel  and  Post, Matt  and  Saint-Amand, Herve  and  Soricut, Radu  and  Specia, Lucia  and  Tamchyna, Ale\\v{s}},\n  title     = {Findings of the 2014 Workshop on Statistical Machine Translation},\n  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},\n  month     = {June},\n  year      = {2014},\n  address   = {Baltimore, Maryland, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {12--58},\n  url       = {http://www.aclweb.org/anthology/W/W14/W14-3302}\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""fr"", ""hi"", ""ru""]\n]\n\n\nclass Wmt14Translate(wmt.WmtTranslate):\n  """"""WMT 14 translation datasets for all {xx, ""en""} language pairs.""""""\n\n  # Version history:\n  # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2014 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""commoncrawl"", ""multiun"",\n            ""newscommentary_v9"", ""gigafren"", ""czeng_10"", ""yandexcorpus"",\n            ""wikiheadlines_hi"", ""wikiheadlines_ru"", ""hindencorp_01""\n        ],\n        tfds.Split.VALIDATION: [\n            ""newsdev2014"", ""newstest2013""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2014""\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt15.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT15: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt15/translation-task.html""\n_CITATION = """"""\n@InProceedings{bojar-EtAl:2015:WMT,\n  author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Haddow, Barry  and  Huck, Matthias  and  Hokamp, Chris  and  Koehn, Philipp  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Post, Matt  and  Scarton, Carolina  and  Specia, Lucia  and  Turchi, Marco},\n  title     = {Findings of the 2015 Workshop on Statistical Machine Translation},\n  booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},\n  month     = {September},\n  year      = {2015},\n  address   = {Lisbon, Portugal},\n  publisher = {Association for Computational Linguistics},\n  pages     = {1--46},\n  url       = {http://aclweb.org/anthology/W15-3001}\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""fi"", ""fr"", ""ru""]\n]\n\n\nclass Wmt15Translate(wmt.WmtTranslate):\n  """"""WMT 15 translation datasets for all {xx, ""en""} language pairs.""""""\n\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2015 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ] + [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=(\n              ""WMT 2015 %s-%s translation task dataset with subword encoding.""\n              % (l1, l2)),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          text_encoder_config=tfds.features.text.TextEncoderConfig(\n              encoder_cls=tfds.features.text.SubwordTextEncoder,\n              name=""subwords8k"",\n              vocab_size=2**13),\n          version=tfds.core.Version(""1.0.0""),\n          )\n      for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""europarl_v8_16"", ""commoncrawl"", ""multiun"",\n            ""newscommentary_v10"", ""gigafren"", ""czeng_10"", ""yandexcorpus"",\n            ""wikiheadlines_fi"", ""wikiheadlines_ru""],\n        tfds.Split.VALIDATION: [\n            ""newsdev2015"", ""newsdiscussdev2015"", ""newstest2014""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2015"", ""newsdiscusstest2015"",\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt16.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT16: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt16/translation-task.html""\n_CITATION = """"""\n@InProceedings{bojar-EtAl:2016:WMT1,\n  author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Graham, Yvette  and  Haddow, Barry  and  Huck, Matthias  and  Jimeno Yepes, Antonio  and  Koehn, Philipp  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Neveol, Aurelie  and  Neves, Mariana  and  Popel, Martin  and  Post, Matt  and  Rubino, Raphael  and  Scarton, Carolina  and  Specia, Lucia  and  Turchi, Marco  and  Verspoor, Karin  and  Zampieri, Marcos},\n  title     = {Findings of the 2016 Conference on Machine Translation},\n  booktitle = {Proceedings of the First Conference on Machine Translation},\n  month     = {August},\n  year      = {2016},\n  address   = {Berlin, Germany},\n  publisher = {Association for Computational Linguistics},\n  pages     = {131--198},\n  url       = {http://www.aclweb.org/anthology/W/W16/W16-2301}\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""fi"", ""ro"", ""ru"", ""tr""]\n]\n\n\nclass Wmt16Translate(wmt.WmtTranslate):\n  """"""WMT 16 translation datasets for all {xx, ""en""} language pairs.""""""\n\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2016 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""europarl_v8_16"", ""commoncrawl"",\n            ""newscommentary_v11"", ""czeng_16pre"", ""yandexcorpus"",\n            ""wikiheadlines_fi"", ""wikiheadlines_ru"", ""setimes_2""\n        ],\n        tfds.Split.VALIDATION: [\n            ""newsdev2016"", ""newstest2015""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2016"", ""newstestB2016""\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt17.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT17: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt17/translation-task.html""\n_CITATION = """"""\n@InProceedings{bojar-EtAl:2017:WMT1,\n  author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Graham, Yvette  and  Haddow, Barry  and  Huang, Shujian  and  Huck, Matthias  and  Koehn, Philipp  and  Liu, Qun  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Post, Matt  and  Rubino, Raphael  and  Specia, Lucia  and  Turchi, Marco},\n  title     = {Findings of the 2017 Conference on Machine Translation (WMT17)},\n  booktitle = {Proceedings of the Second Conference on Machine Translation, Volume 2: Shared Task Papers},\n  month     = {September},\n  year      = {2017},\n  address   = {Copenhagen, Denmark},\n  publisher = {Association for Computational Linguistics},\n  pages     = {169--214},\n  url       = {http://www.aclweb.org/anthology/W17-4717}\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""fi"", ""lv"", ""ru"", ""tr"", ""zh""]\n]\n\n\nclass Wmt17Translate(wmt.WmtTranslate):\n  """"""WMT 17 translation datasets for all {xx, ""en""} language pairs.""""""\n\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2017 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""europarl_v8_16"", ""commoncrawl"",\n            ""newscommentary_v12"", ""czeng_16"", ""yandexcorpus"",\n            ""wikiheadlines_fi"", ""wikiheadlines_ru"", ""setimes_2"", ""uncorpus_v1"",\n            ""rapid_2016"", ""leta_v1"", ""dcep_v1"", ""onlinebooks_v1""\n        ] + wmt.CWMT_SUBSET_NAMES,\n        tfds.Split.VALIDATION: [\n            ""newsdev2017"", ""newstest2016"", ""newstestB2016""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2017"", ""newstestB2017""\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt18.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT18: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt18/translation-task.html""\n_CITATION = """"""\\\n@InProceedings{bojar-EtAl:2018:WMT1,\n  author    = {Bojar, Ond\\v{r}ej  and  Federmann, Christian  and  Fishel, Mark\n    and Graham, Yvette  and  Haddow, Barry  and  Huck, Matthias  and\n    Koehn, Philipp  and  Monz, Christof},\n  title     = {Findings of the 2018 Conference on Machine Translation (WMT18)},\n  booktitle = {Proceedings of the Third Conference on Machine Translation,\n    Volume 2: Shared Task Papers},\n  month     = {October},\n  year      = {2018},\n  address   = {Belgium, Brussels},\n  publisher = {Association for Computational Linguistics},\n  pages     = {272--307},\n  url       = {http://www.aclweb.org/anthology/W18-6401}\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""et"", ""fi"", ""kk"", ""ru"", ""tr"", ""zh""]\n]\n\n\nclass Wmt18Translate(wmt.WmtTranslate):\n  """"""WMT 18 translation datasets for all {xx, ""en""} language pairs.""""""\n\n  # Version history:\n  # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2018 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""europarl_v8_18"", ""paracrawl_v1"", ""commoncrawl"",\n            ""newscommentary_v13"", ""czeng_17"", ""yandexcorpus"",\n            ""wikiheadlines_fi"", ""wikiheadlines_ru"", ""setimes_2"",\n            ""uncorpus_v1"", ""rapid_2016""] + wmt.CWMT_SUBSET_NAMES,\n        tfds.Split.VALIDATION: [\n            ""newsdev2018"", ""newstest2017"", ""newstestB2017""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2018""\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt19.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""WMT19: Translate dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""http://www.statmt.org/wmt19/translation-task.html""\n# TODO(adarob): Update with citation of overview paper once it is published.\n_CITATION = """"""\n@ONLINE {wmt19translate,\n    author = ""Wikimedia Foundation"",\n    title  = ""ACL 2019 Fourth Conference on Machine Translation (WMT19), Shared Task: Machine Translation of News"",\n    url    = ""http://www.statmt.org/wmt19/translation-task.html""\n}\n""""""\n\n_LANGUAGE_PAIRS = [\n    (lang, ""en"") for lang in [""cs"", ""de"", ""fi"", ""gu"", ""kk"", ""lt"", ""ru"", ""zh""]\n] + [(""fr"", ""de"")]\n\n\nclass Wmt19Translate(wmt.WmtTranslate):\n  """"""WMT 19 translation datasets for {(xx, ""en"")} + (""fr"", ""de"") pairs.""""""\n\n  # Version history:\n  # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT 2019 %s-%s translation task dataset."" % (l1, l2),\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(l1, l2),\n          version=tfds.core.Version(""1.0.0""),\n      ) for l1, l2 in _LANGUAGE_PAIRS\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v9"", ""europarl_v7_frde"", ""paracrawl_v3"",\n            ""paracrawl_v1_ru"", ""paracrawl_v3_frde"", ""commoncrawl"",\n            ""commoncrawl_frde"", ""newscommentary_v14"", ""newscommentary_v14_frde"",\n            ""czeng_17"", ""yandexcorpus"", ""wikititles_v1"", ""uncorpus_v1"",\n            ""rapid_2016_ltfi"", ""rapid_2019""] + wmt.CWMT_SUBSET_NAMES,\n        tfds.Split.VALIDATION: [\n            ""euelections_dev2019"", ""newsdev2019"", ""newstest2018""]\n    }\n'"
tensorflow_datasets/translate/wmt19_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for WMT translate dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.translate import wmt19\n\n\nclass TranslateDeEnWmt19Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = wmt19.Wmt19Translate\n  BUILDER_CONFIG_NAMES_TO_TEST = [""de-en""]\n  OVERLAPPING_SPLITS = [""validation""]\n\n  DL_EXTRACT_RESULT = {\n      ""europarl_v9"": [""sentences.de-en.tsv""],\n      ""paracrawl_v3"": [""sentences.de-en.tmx""],\n      ""commoncrawl"": [""commoncrawl""],\n      ""newscommentary_v14"": [""sentences.de-en.tsv""],\n      ""wikititles_v1"": [""sentences.de-en.tsv""],\n      ""rapid_2019"": [""rapid_2019""],\n      ""newstest2018"": [""validation""],\n  }\n\n  SPLITS = {\n      ""train"": 12,\n      ""validation"": 2,\n  }\n\n\nclass TranslateCsEnWmt19Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = wmt19.Wmt19Translate\n  BUILDER_CONFIG_NAMES_TO_TEST = [""cs-en""]\n  OVERLAPPING_SPLITS = [""validation""]\n\n  DL_EXTRACT_RESULT = {\n      ""czeng17_filter"": [""czeng""],\n      ""europarl_v9"": [""sentences.cs-en.tsv""],\n      ""paracrawl_v3"": [""sentences.cs-en.tmx""],\n      ""commoncrawl"": [""commoncrawl""],\n      ""newscommentary_v14"": [""sentences.cs-en.tsv""],\n      ""wikititles_v1"": [""sentences.cs-en.tsv""],\n      ""newstest2018"": [""validation""],\n  }\n\n  SPLITS = {\n      ""train"": 13,\n      ""validation"": 2,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/translate/wmt_t2t.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""The WMT EnDe Translate dataset used by the Tensor2Tensor library.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n_URL = ""https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/translate_ende.py""\n_CITATION = """"""\n@InProceedings{bojar-EtAl:2014:W14-33,\n  author    = {Bojar, Ondrej  and  Buck, Christian  and  Federmann, Christian  and  Haddow, Barry  and  Koehn, Philipp  and  Leveling, Johannes  and  Monz, Christof  and  Pecina, Pavel  and  Post, Matt  and  Saint-Amand, Herve  and  Soricut, Radu  and  Specia, Lucia  and  Tamchyna, Ale\\v{s}},\n  title     = {Findings of the 2014 Workshop on Statistical Machine Translation},\n  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},\n  month     = {June},\n  year      = {2014},\n  address   = {Baltimore, Maryland, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {12--58},\n  url       = {http://www.aclweb.org/anthology/W/W14/W14-3302}\n}\n""""""\n\n\nclass WmtT2tTranslate(wmt.WmtTranslate):\n  """"""The WMT EnDe Translate dataset used by the Tensor2Tensor library.""""""\n\n  BUILDER_CONFIGS = [\n      wmt.WmtConfig(  # pylint:disable=g-complex-comprehension\n          description=""WMT T2T EnDe translation task dataset."",\n          url=_URL,\n          citation=_CITATION,\n          language_pair=(""de"", ""en""),\n          version=tfds.core.Version(""1.0.0""),\n      )\n  ]\n\n  @property\n  def _subsets(self):\n    return {\n        tfds.Split.TRAIN: [\n            ""europarl_v7"", ""commoncrawl"", ""newscommentary_v13""],\n        tfds.Split.VALIDATION: [\n            ""newstest2013""\n        ],\n        tfds.Split.TEST: [\n            ""newstest2014""\n        ]\n    }\n'"
tensorflow_datasets/translate/wmt_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# -*- coding: utf-8 -*-\n""""""Tests for WMT translate dataset module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport six\nfrom tensorflow_datasets import testing\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.translate import wmt\n\n\nclass TranslateWmtCustomConfigTest(testing.DatasetBuilderTestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(TranslateWmtCustomConfigTest, cls).setUpClass()\n\n    config = wmt.WmtConfig(\n        name=""small"",\n        language_pair=(""cs"", ""en""),\n        description=""Example of custom config"",\n        subsets={\n            ""train"": [""paracrawl_v3""],\n            ""validation"": [""newstest2009"", ""newstest2010""],\n        },\n        version=tfds.core.Version(""1.0.0""),\n    )\n    wmt.WmtTranslate.BUILDER_CONFIGS = [config]\n\n  @classmethod\n  def tearDownClass(cls):\n    super(TranslateWmtCustomConfigTest, cls).tearDownClass()\n    wmt.WmtTranslate.BUILDER_CONFIGS.pop()\n\n  DATASET_CLASS = wmt.WmtTranslate\n  # OVERLAPPING_SPLITS = [""validation""]\n\n  DL_EXTRACT_RESULT = {\n      ""czeng17_filter"": [""czeng""],\n      ""europarl_v9"": [""sentences.cs-en.tsv""],\n      ""paracrawl_v3"": [""sentences.cs-en.tmx""],\n      ""commoncrawl"": [""commoncrawl""],\n      ""newscommentary_v14"": [""sentences.cs-en.tsv""],\n      ""wikititles_v1"": [""sentences.cs-en.tsv""],\n      ""newssyscomb2009"": [""validation""],\n      ""newstest2008"": [""validation""],\n      ""newstest2009"": [""validation""],\n      ""newstest2010"": [""validation""],\n      ""newstest2011"": [""validation""],\n      ""newstest2012"": [""validation""],\n      ""newstest2013"": [""validation""],\n      ""newstest2014"": [""validation""],\n      ""newstest2015"": [""validation""],\n      ""newstest2016"": [""validation""],\n      ""newstest2017"": [""validation""],\n      ""newstest2018"": [""validation""],\n  }\n\n  SPLITS = {\n      ""train"": 2,\n      ""validation"": 4,\n  }\n\n  # Wmt itself do not define checksums. Checksums are contained in individual\n  # `wmt16.txt`, `wmt17.txt`,... files.\n  SKIP_CHECKSUMS = True\n\n  def test_gzip_reading(self):\n    results = [\n        x for _, x in wmt._parse_parallel_sentences(\n            os.path.join(self.example_dir, ""first.cs.gz""),\n            os.path.join(self.example_dir, ""second.en.txt""))\n    ]\n    self.assertEqual(results[1][""cs""], ""zmizel"")\n    if six.PY3:\n      self.assertEqual(results[0][""cs""], ""b\xc4\x9b\xc5\xbe\xc3\xadm"")\n    else:\n      self.assertTrue(results[0][""cs""] == u""b\xc4\x9b\xc5\xbe\xc3\xadm"")  # pylint: disable=g-generic-assert\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/video/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Video datasets.""""""\n\nfrom tensorflow_datasets.video.bair_robot_pushing import BairRobotPushingSmall\nfrom tensorflow_datasets.video.moving_mnist import MovingMnist\nfrom tensorflow_datasets.video.robonet import Robonet\nfrom tensorflow_datasets.video.starcraft import StarcraftVideo\nfrom tensorflow_datasets.video.starcraft import StarcraftVideoConfig\nfrom tensorflow_datasets.video.ucf101 import Ucf101\nfrom tensorflow_datasets.video.ucf101 import Ucf101Config\n'"
tensorflow_datasets/video/bair_robot_pushing.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Berkeley (BAIR) robot pushing dataset.\n\nSelf-Supervised Visual Planning with Temporal Skip Connections\nFrederik Ebert, Chelsea Finn, Alex X. Lee, and Sergey Levine.\nhttps://arxiv.org/abs/1710.05268\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\nDATA_URL = ""http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar""\n\n# There are exactly 30 frames in each video.\nFRAMES_PER_VIDEO = 30\nIMG_SHAPE = (64, 64, 3)\n\n\n_CITATION = """"""\\\n@misc{1710.05268,\n  Author = {Frederik Ebert and Chelsea Finn and Alex X. Lee and Sergey Levine},\n  Title = {Self-Supervised Visual Planning with Temporal Skip Connections},\n  Year = {2017},\n  Eprint = {arXiv:1710.05268},\n}\n""""""\n\n\nclass BairRobotPushingSmall(tfds.core.GeneratorBasedBuilder):\n  """"""Robot pushing dataset from BAIR (Small 64x64 version).""""""\n\n  VERSION = tfds.core.Version(\n      ""2.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    # The Bair dataset consist of a sequence of frames (video) with associated\n    # metadata (action and position)\n    features = tfds.features.Sequence({\n        ""image_main"": tfds.features.Image(shape=IMG_SHAPE),\n        ""image_aux1"": tfds.features.Image(shape=IMG_SHAPE),\n        ""action"": tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n        ""endeffector_pos"": tfds.features.Tensor(shape=(3,), dtype=tf.float32),\n    }, length=FRAMES_PER_VIDEO)\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""This data set contains roughly 44,000 examples of robot ""\n        ""pushing motions, including one training set (train) and ""\n        ""two test sets of previously seen (testseen) and unseen ""\n        ""(testnovel) objects. This is the small 64x64 version."",\n        features=features,\n        homepage=""https://sites.google.com/view/sna-visual-mpc/"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    files = dl_manager.download_and_extract(DATA_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""filedir"": os.path.join(files, ""softmotion30_44k"", ""train""),\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                ""filedir"": os.path.join(files, ""softmotion30_44k"", ""test""),\n            }),\n    ]\n\n  def _generate_examples(self, filedir):\n    logging.info(""Reading data from %s."", filedir)\n    files = tf.io.gfile.listdir(filedir)\n    logging.info(""%d files found."", len(files))\n\n    # For each file\n    for filename in sorted(tf.io.gfile.listdir(filedir)):\n      filepath = os.path.join(filedir, filename)\n\n      # For each video inside the file\n      for video_id, example_str in enumerate(\n          tf.compat.v1.io.tf_record_iterator(filepath)):\n        example = tf.train.SequenceExample.FromString(example_str)\n\n        # Merge all frames together\n        all_frames = []\n        for frame_id in range(FRAMES_PER_VIDEO):\n          # Extract all features from the original proto context field\n          frame_feature = {   # pylint: disable=g-complex-comprehension\n              out_key: example.context.feature[in_key.format(frame_id)]   # pylint: disable=g-complex-comprehension\n              for out_key, in_key in [\n                  (""image_main"", ""{}/image_main/encoded""),\n                  (""image_aux1"", ""{}/image_aux1/encoded""),\n                  (""endeffector_pos"", ""{}/endeffector_pos""),\n                  (""action"", ""{}/action""),\n              ]\n          }\n\n          # Decode float\n          for key in (""endeffector_pos"", ""action""):\n            values = frame_feature[key].float_list.value\n            frame_feature[key] = [values[i] for i in range(len(values))]\n\n          # Decode images (from encoded string)\n          for key in (""image_main"", ""image_aux1""):\n            img = frame_feature[key].bytes_list.value[0]  # pytype: disable=attribute-error\n            img = np.frombuffer(img, dtype=np.uint8)\n            img = np.reshape(img, IMG_SHAPE)\n            frame_feature[key] = img\n\n          all_frames.append(frame_feature)\n\n        # Encode the sequence (list) of frames (feature dicts)\n        # yield [\n        #     {\'action\': [...], \'image_main\': img_frame0, ...},  # Frame 0\n        #     {\'action\': [...], \'image_main\': img_frame1, ...},  # Frame 1\n        #     ...,\n        # ]\n        yield ""%s_%s"" % (filepath, video_id), all_frames\n'"
tensorflow_datasets/video/bair_robot_pushing_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.video.bair_robot_pushing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.video import bair_robot_pushing\n\n\nclass BairRobotPushingTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = bair_robot_pushing.BairRobotPushingSmall\n\n  SPLITS = {\n      ""train"": 1,\n      ""test"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/video/moving_mnist.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""MovingMNIST.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.video.moving_sequence import image_as_moving_sequence  # pylint: disable=unused-import\n\n_OUT_RESOLUTION = (64, 64)\n_SEQUENCE_LENGTH = 20\n_URL = ""http://www.cs.toronto.edu/~nitish/unsupervised_video/""\n_CITATION = """"""\\\n@article{DBLP:journals/corr/SrivastavaMS15,\n  author    = {Nitish Srivastava and\n               Elman Mansimov and\n               Ruslan Salakhutdinov},\n  title     = {Unsupervised Learning of Video Representations using LSTMs},\n  journal   = {CoRR},\n  volume    = {abs/1502.04681},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1502.04681},\n  archivePrefix = {arXiv},\n  eprint    = {1502.04681},\n  timestamp = {Mon, 13 Aug 2018 16:47:05 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SrivastavaMS15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n_DESCRIPTION = """"""\\\nMoving variant of MNIST database of handwritten digits. This is the\ndata used by the authors for reporting model performance. See\n`tfds.video.moving_mnist.image_as_moving_sequence`\nfor generating training/validation data from the MNIST dataset.\n""""""\n\n\nclass MovingMnist(tfds.core.GeneratorBasedBuilder):\n  """"""MovingMnist.""""""\n\n  VERSION = tfds.core.Version(\n      ""1.0.0"", ""New split API (https://tensorflow.org/datasets/splits)"")\n\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=_DESCRIPTION,\n        features=tfds.features.FeaturesDict({\n            ""image_sequence"": tfds.features.Video(\n                shape=(_SEQUENCE_LENGTH,) + _OUT_RESOLUTION + (1,))\n        }),\n        homepage=_URL,\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    data_path = dl_manager.download(_URL + ""mnist_test_seq.npy"")\n\n    # authors only provide test data.\n    # See `tfds.video.moving_mnist.image_as_moving_sequence` for mapping\n    # function to create training/validation dataset from MNIST.\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs=dict(data_path=data_path)),\n    ]\n\n  def _generate_examples(self, data_path):\n    """"""Generate MovingMnist sequences.\n\n    Args:\n      data_path (str): Path to the data file\n\n    Yields:\n      20 x 64 x 64 x 1 uint8 numpy arrays\n    """"""\n    with tf.io.gfile.GFile(data_path, ""rb"") as fp:\n      images = np.load(fp)\n    images = np.transpose(images, (1, 0, 2, 3))\n    images = np.expand_dims(images, axis=-1)\n    for i, sequence in enumerate(images):\n      yield i, dict(image_sequence=sequence)\n'"
tensorflow_datasets/video/moving_sequence.py,33,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Provides `image_as_moving_sequence`.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport tensorflow.compat.v2 as tf\n\n\ndef _create_moving_sequence(image, pad_lefts, total_padding):\n  """"""Create a moving image sequence from the given image a left padding values.\n\n  Args:\n    image: [in_h, in_w, n_channels] uint8 array\n    pad_lefts: [sequence_length, 2] int32 array of left padding values\n    total_padding: tensor of padding values, (pad_h, pad_w)\n\n  Returns:\n    [sequence_length, out_h, out_w, n_channels] uint8 image sequence, where\n      out_h = in_h + pad_h, out_w = in_w + out_w\n  """"""\n\n  with tf.name_scope(""moving_sequence""):\n    def get_padded_image(args):\n      pad_left, = args\n      pad_right = total_padding - pad_left\n      padding = tf.stack([pad_left, pad_right], axis=-1)\n      z = tf.zeros((1, 2), dtype=pad_left.dtype)\n      padding = tf.concat([padding, z], axis=0)\n      return tf.pad(image, padding)\n\n    padded_images = tf.map_fn(\n        get_padded_image, [pad_lefts], dtype=tf.uint8, infer_shape=False,\n        back_prop=False)\n\n  return padded_images\n\n\ndef _get_linear_trajectory(x0, velocity, t):\n  """"""Construct a linear trajectory from x0.\n\n  Args:\n    x0: N-D float tensor.\n    velocity: N-D float tensor\n    t: [sequence_length]-length float tensor\n\n  Returns:\n    x: [sequence_length, ndims] float tensor.\n  """"""\n  x0 = tf.convert_to_tensor(x0)\n  velocity = tf.convert_to_tensor(velocity)\n  t = tf.convert_to_tensor(t)\n  if x0.shape.ndims != 1:\n    raise ValueError(""x0 must be a rank 1 tensor"")\n  if velocity.shape.ndims != 1:\n    raise ValueError(""velocity must be a rank 1 tensor"")\n  if t.shape.ndims != 1:\n    raise ValueError(""t must be a rank 1 tensor"")\n  x0 = tf.expand_dims(x0, axis=0)\n  velocity = tf.expand_dims(velocity, axis=0)\n  dx = velocity * tf.expand_dims(t, axis=-1)\n  linear_trajectories = x0 + dx\n  assert linear_trajectories.shape.ndims == 2, \\\n    ""linear_trajectories should be a rank 2 tensor""\n  return linear_trajectories\n\n\ndef _bounce_to_bbox(points):\n  """"""Bounce potentially unbounded points to [0, 1].\n\n  Bouncing occurs by exact reflection, i.e. a pre-bound point at 1.1 is moved\n  to 0.9, -0.2 -> 0.2. This theoretically can occur multiple times, e.g.\n  2.3 -> -0.7 -> 0.3\n\n  Implementation\n  points <- points % 2\n  return min(2 - points, points)\n\n  Args:\n    points: float array\n\n  Returns:\n    tensor with same shape/dtype but values in [0, 1].\n  """"""\n  points = points % 2\n  return tf.math.minimum(2 - points, points)\n\n\ndef _get_random_unit_vector(ndims=2, dtype=tf.float32):\n  x = tf.random.normal((ndims,), dtype=dtype)\n  return x / tf.linalg.norm(x, axis=-1, keepdims=True)\n\nMovingSequence = collections.namedtuple(\n    ""_MovingSequence"",\n    [""image_sequence"", ""trajectory"", ""start_position"", ""velocity""])\n\n\ndef image_as_moving_sequence(\n    image, sequence_length=20, output_size=(64, 64), velocity=0.1,\n    start_position=None):\n  """"""Turn simple static images into sequences of the originals bouncing around.\n\n  Adapted from Srivastava et al.\n  http://www.cs.toronto.edu/~nitish/unsupervised_video/\n\n  Example usage:\n  ```python\n  import tensorflow.compat.v2 as tf\n  import tensorflow_datasets as tfds\n  from tensorflow_datasets.video import moving_sequence\n  tf.enable_v2_behavior()\n\n  def animate(sequence):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import matplotlib.animation as animation\n    sequence = np.squeeze(sequence, axis=-1)\n\n    fig = plt.figure()\n    plt.axis(""off"")\n    ims = [[plt.imshow(im, cmap=""gray"", animated=True)] for im in sequence]\n    # don\'t remove `anim =` as linter may suggets\n    # weird behaviour, plot will freeze on last frame\n    anim = animation.ArtistAnimation(\n        fig, ims, interval=50, blit=True, repeat_delay=100)\n\n    plt.show()\n    plt.close()\n\n\n  tf.enable_v2_behavior()\n  mnist_ds = tfds.load(""mnist"", split=tfds.Split.TRAIN, as_supervised=True,\n                       shuffle_files=True)\n  mnist_ds = mnist_ds.repeat().shuffle(1024)\n\n  def map_fn(image, label):\n    sequence = moving_sequence.image_as_moving_sequence(\n        image, sequence_length=20)\n    return sequence.image_sequence\n\n  moving_mnist_ds = mnist_ds.map(map_fn).batch(2).map(\n      lambda x: dict(image_sequence=tf.reduce_max(x, axis=0)))\n\n  # # for comparison with test data provided by original authors\n  # moving_mnist_ds = tfds.load(""moving_mnist"", split=tfds.Split.TEST)\n\n  for seq in moving_mnist_ds:\n    animate(seq[""image_sequence""].numpy())\n  ```\n\n  Args:\n    image: [in_h, in_w, n_channels] tensor defining the sub-image to be bouncing\n        around.\n    sequence_length: int, length of sequence.\n    output_size: (out_h, out_w) size returned images.\n    velocity: scalar speed or 2D velocity of image. If scalar, the 2D\n        velocity is randomly generated with this magnitude. This is the\n        normalized distance moved each time step by the sub-image, where\n        normalization occurs over the feasible distance the sub-image can move\n        e.g if the input image is [10 x 10] and the output image is [60 x 60],\n        a speed of 0.1 means the sub-image moves (60 - 10) * 0.1 = 5 pixels per\n        time step.\n    start_position: 2D float32 normalized initial position of each\n        image in [0, 1]. Randomized uniformly if not given.\n\n  Returns:\n    `MovingSequence` namedtuple containing:\n        `image_sequence`:\n          [sequence_length, out_h, out_w, n_channels] image at each time step.\n          padded values are all zero. Same dtype as input image.\n        `trajectory`: [sequence_length, 2] float32 in [0, 1]\n          2D normalized coordinates of the image at every time step.\n        `start_position`: 2D float32 initial position in [0, 1].\n          2D normalized initial position of image. Same as input if provided,\n          otherwise the randomly value generated.\n        `velocity`: 2D float32 normalized velocity. Same as input velocity\n          if provided as a 2D tensor, otherwise the random velocity generated.\n  """"""\n  ndims = 2\n  image = tf.convert_to_tensor(image)\n  if image.shape.ndims != 3:\n    raise ValueError(""image must be rank 3, got %s"" % str(image))\n  output_size = tf.TensorShape(output_size)\n  if len(output_size) != ndims:\n    raise ValueError(""output_size must have exactly %d elements, got %s""\n                     % (ndims, output_size))\n  image_shape = tf.shape(image)\n  if start_position is None:\n    start_position = tf.random.uniform((ndims,), dtype=tf.float32)\n  elif start_position.shape != (ndims,):\n    raise ValueError(""start_positions must (%d,)"" % ndims)\n  velocity = tf.convert_to_tensor(velocity, dtype=tf.float32)\n  if velocity.shape.ndims == 0:\n    velocity = _get_random_unit_vector(ndims, tf.float32) * velocity\n  elif velocity.shape.ndims != 1:\n    raise ValueError(""velocity must be rank 0 or rank 1, got %s"" % velocity)\n  t = tf.range(sequence_length, dtype=tf.float32)\n  trajectory = _get_linear_trajectory(start_position, velocity, t)\n  trajectory = _bounce_to_bbox(trajectory)\n\n  total_padding = output_size - image_shape[:2]\n\n  if not tf.executing_eagerly():\n    cond = tf.compat.v1.assert_greater(total_padding, -1)\n    with tf.control_dependencies([cond]):\n      total_padding = tf.identity(total_padding)\n\n  sequence_pad_lefts = tf.cast(\n      tf.math.round(trajectory * tf.cast(total_padding, tf.float32)), tf.int32)\n\n  sequence = _create_moving_sequence(image, sequence_pad_lefts, total_padding)\n  sequence.set_shape(\n      [sequence_length] + output_size.as_list() + [image.shape[-1]])\n  return MovingSequence(\n      image_sequence=sequence,\n      trajectory=trajectory,\n      start_position=start_position,\n      velocity=velocity)\n'"
tensorflow_datasets/video/moving_sequence_test.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for moving_sequence.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets import testing\nimport tensorflow_datasets.video.moving_sequence as ms\n\ntf.enable_v2_behavior()\n\n\nclass MovingSequenceTest(tf.test.TestCase):\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_images_as_moving_sequence(self):\n    h, w = (28, 28)\n    sequence_length = 8\n\n    vh = 1 / (sequence_length)\n    vw = 1 / (2*(sequence_length))\n    image = tf.ones((28, 28, 1), dtype=tf.uint8)\n\n    velocity = tf.constant([vh, vw], dtype=tf.float32)\n    out_size = (h + sequence_length, w + sequence_length)\n    start_position = tf.constant([0, 0], dtype=tf.float32)\n\n    sequence = ms.image_as_moving_sequence(\n        image, start_position=start_position, velocity=velocity,\n        output_size=out_size, sequence_length=sequence_length)\n    sequence = tf.cast(sequence.image_sequence, tf.float32)\n\n    self.assertAllEqual(*self.evaluate([\n        tf.reduce_sum(sequence, axis=(1, 2, 3)),\n        tf.fill((sequence_length,),\n                tf.reduce_sum(tf.cast(image, tf.float32)))\n    ]))\n\n    for i, full_image in enumerate(tf.unstack(sequence, axis=0)):\n      j = i // 2\n      subimage = full_image[i:i+h, j:j+w]\n      n_true = tf.reduce_sum(subimage)\n      # allow for pixel rounding errors in each dimension\n      self.assertGreaterEqual(self.evaluate(n_true), (h-1)*(w-1))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/video/robonet.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""RoboNet dataset.\n\nRoboNet: Large-Scale Multi-Robot Learning\n\nSudeep Dasari, Frederik Ebert, Stephen Tian, Suraj Nair, Bernadette Bucher,\nKarl Schmeckpeper, Siddharth Singh, Sergey Levine, Chelsea Finn\n\nhttps://www.robonet.wiki/\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport textwrap\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\n\nDATA_URL_SAMPLE = (\'https://drive.google.com/uc?export=download&\'\n                   \'id=1YX2TgT8IKSn9V4wGCwdzbRnS53yicV2P\')\nDATA_URL = (\'https://drive.google.com/uc?export=download&\'\n            \'id=1BkqHzfRkfzgzCfc73NbNnPMK_rg3i1n9\')\n\nSTATES_DIM = 5\nACTIONS_DIM = 5\n\n_CITATION = """"""\\\n@article{dasari2019robonet,\n  title={RoboNet: Large-Scale Multi-Robot Learning},\n  author={Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and\n  Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl\n  and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},\n  journal={arXiv preprint arXiv:1910.11215},\n  year={2019}\n}\n""""""\n\n\nclass RobonetConfig(tfds.core.BuilderConfig):\n  """"""""Configuration for RoboNet video rescaling.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, sample_dataset=False, width=None, height=None, **kwargs):\n    """"""The parameters specifying how the dataset will be processed.\n\n    The dataset comes with three separate splits. You can specify which split\n    you want in `split_number`. If `width` and `height` are set, the videos\n    will be rescaled to have those heights and widths (using ffmpeg).\n\n    Args:\n      sample_dataset: Whether or not to use the sample dataset.\n      width: An integer with the width or None.\n      height: An integer with the height or None.\n      **kwargs: Passed on to the constructor of `BuilderConfig`.\n    """"""\n    super(RobonetConfig, self).__init__(\n        version=tfds.core.Version(\'4.0.0\'), **kwargs)\n    if (width is None) ^ (height is None):\n      raise ValueError(\'Either both dimensions should be set, or none of them\')\n    self.sample_dataset = sample_dataset\n    self.width = width\n    self.height = height\n\n\nclass Robonet(tfds.core.BeamBasedBuilder):\n  """"""RoboNet: Large-Scale Multi-Robot Learning.""""""\n\n  BUILDER_CONFIGS = [\n      RobonetConfig(\n          name=\'robonet_sample_64\',\n          description=\'64x64 RoboNet Sample.\',\n          sample_dataset=True,\n          width=64,\n          height=64,\n      ),\n      RobonetConfig(\n          name=\'robonet_sample_128\',\n          description=\'128x128 RoboNet Sample.\',\n          sample_dataset=True,\n          width=128,\n          height=128,\n      ),\n      RobonetConfig(\n          name=\'robonet_64\',\n          description=\'64x64 RoboNet.\',\n          sample_dataset=False,\n          width=64,\n          height=64,\n      ),\n      RobonetConfig(\n          name=\'robonet_128\',\n          description=\'128x128 RoboNet.\',\n          sample_dataset=False,\n          width=128,\n          height=128,\n      ),\n  ]\n\n  def _info(self):\n    if self.builder_config.width is not None:\n      if self.builder_config.height is None:\n        raise ValueError(\'Provide either both height and width or none.\')\n      ffmpeg_extra_args = (\n          \'-vf\', \'scale={}x{}\'.format(self.builder_config.height,\n                                      self.builder_config.width))\n    else:\n      ffmpeg_extra_args = []\n\n    video_shape = (\n        None, self.builder_config.height, self.builder_config.width, 3)\n\n    features = tfds.features.FeaturesDict({\n        # Video frames: uint8 [None, Time, Width, Height, Channels]\n        \'video\': tfds.features.Video(\n            video_shape,\n            ffmpeg_extra_args=ffmpeg_extra_args,\n            encoding_format=\'png\'),\n        # Robot actions: float32, [None, ACTIONS_DIM]\n        \'actions\': tfds.features.Tensor(\n            shape=(None, ACTIONS_DIM), dtype=tf.float32),\n        # Robot states: float32, [None, STATE_DIM]\n        \'states\': tfds.features.Tensor(\n            shape=(None, STATES_DIM), dtype=tf.float32)\n    })\n\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=textwrap.dedent(""""""\\\n        RoboNet contains over 15 million video frames of robot-object\n        interaction, taken from 113 unique camera viewpoints.\n\n        * The actions are deltas in position and rotation to the robot\n        end-effector with one additional dimension of the action vector\n        reserved for the gripper joint.\n\n        * The states are cartesian end-effector control action space\n        with restricted rotation, and a gripper joint""""""),\n        features=features,\n        homepage=\'https://www.robonet.wiki/\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    files = dl_manager.download_and_extract(\n        DATA_URL_SAMPLE if self.builder_config.sample_dataset else DATA_URL)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'filedir\': os.path.join(files, \'hdf5\'),\n            }),\n    ]\n\n  def _build_pcollection(self, pipeline, filedir):\n    """"""Generate examples as dicts.""""""\n    beam = tfds.core.lazy_imports.apache_beam\n\n    def _process_example(filename):\n      """"""Converts one video from hdf5 format.""""""\n      h5py = tfds.core.lazy_imports.h5py\n      with h5py.File(filename) as hf:\n        video_bytes = hf[\'env\'][\'cam0_video\'][\'frames\'][:].tostring()\n        states = hf[\'env\'][\'state\'][:].astype(np.float32)\n        states = np.pad(\n            states, ((0, 0), (0, STATES_DIM-states.shape[1])), \'constant\')\n        actions = hf[\'policy\'][\'actions\'][:].astype(np.float32)\n        actions = np.pad(\n            actions, ((0, 0), (0, ACTIONS_DIM-actions.shape[1])), \'constant\')\n\n      features = {\n          \'video\': video_bytes,\n          \'actions\': actions,\n          \'states\': states,\n      }\n      return os.path.basename(filename), features\n\n    filenames = tf.io.gfile.glob(os.path.join(filedir, \'*.hdf5\'))\n    return (\n        pipeline\n        | beam.Create(filenames)\n        | beam.Map(_process_example)\n    )\n'"
tensorflow_datasets/video/robonet_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.video.robonet.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.video import robonet\n\n\nclass Robonet64Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = robonet.Robonet\n\n  SPLITS = {\n      ""train"": 9,\n  }\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/video/starcraft.py,15,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SCV dataset from http://arxiv.org/abs/1812.01717 .""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.public_api as tfds\n\nDATA_URL_DIR = ""https://storage.googleapis.com/scv_dataset/data/""\n_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1812-01717,\n  author    = {Thomas Unterthiner and\n               Sjoerd van Steenkiste and\n               Karol Kurach and\n               Rapha{\\""{e}}l Marinier and\n               Marcin Michalski and\n               Sylvain Gelly},\n  title     = {Towards Accurate Generative Models of Video: {A} New Metric and\n               Challenges},\n  journal   = {CoRR},\n  volume    = {abs/1812.01717},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.01717},\n  archivePrefix = {arXiv},\n  eprint    = {1812.01717},\n  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1812-01717},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n\nclass StarcraftVideoConfig(tfds.core.BuilderConfig):\n  """"""Config for StarcraftVideo dataset.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, map_name, resolution, size_in_gb, **kwargs):\n    super(StarcraftVideoConfig, self).__init__(\n        version=tfds.core.Version(\n            ""1.0.0"", ""New split API (https://tensorflow.org/datasets/splits)""),\n        **kwargs)\n    self.map_name = map_name\n    self.resolution = resolution\n    self.size_in_gb = size_in_gb\n\n\nclass StarcraftVideo(tfds.core.GeneratorBasedBuilder):\n  """"""Starcraft video datasets.""""""\n\n  BUILDER_CONFIGS = [\n      StarcraftVideoConfig(\n          name=""brawl_64"",\n          description=""Brawl map with 64x64 resolution."",\n          map_name=""Brawl"",\n          resolution=64,\n          size_in_gb=6.3,\n      ),\n      StarcraftVideoConfig(\n          name=""brawl_128"",\n          description=""Brawl map with 128x128 resolution."",\n          map_name=""Brawl"",\n          resolution=128,\n          size_in_gb=20.7,\n      ),\n      StarcraftVideoConfig(\n          name=""collect_mineral_shards_64"",\n          description=""CollectMineralShards map with 64x64 resolution."",\n          map_name=""CollectMineralShards"",\n          resolution=64,\n          size_in_gb=6.3,\n      ),\n      StarcraftVideoConfig(\n          name=""collect_mineral_shards_128"",\n          description=""CollectMineralShards map with 128x128 resolution."",\n          map_name=""CollectMineralShards"",\n          resolution=128,\n          size_in_gb=20.7,\n      ),\n      StarcraftVideoConfig(\n          name=""move_unit_to_border_64"",\n          description=""MoveUnitToBorder map with 64x64 resolution."",\n          map_name=""MoveUnitToBorder"",\n          resolution=64,\n          size_in_gb=5.8,\n      ),\n      StarcraftVideoConfig(\n          name=""move_unit_to_border_128"",\n          description=""MoveUnitToBorder map with 128x128 resolution."",\n          map_name=""MoveUnitToBorder"",\n          resolution=128,\n          size_in_gb=20.7,\n      ),\n      StarcraftVideoConfig(\n          name=""road_trip_with_medivac_64"",\n          description=""RoadTripWithMedivac map with 64x64 resolution."",\n          map_name=""RoadTripWithMedivac"",\n          resolution=64,\n          size_in_gb=2.4,\n      ),\n      StarcraftVideoConfig(\n          name=""road_trip_with_medivac_128"",\n          description=""RoadTripWithMedivac map with 128x128 resolution."",\n          map_name=""RoadTripWithMedivac"",\n          resolution=128,\n          size_in_gb=7.9,\n      ),\n  ]\n\n  def _info(self):\n    features = tfds.features.FeaturesDict({\n        ""rgb_screen"":\n            tfds.features.Video(\n                shape=(None, self.builder_config.resolution,\n                       self.builder_config.resolution, 3)),\n    })\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=""This data set contains videos generated from Starcraft."",\n        features=features,\n        homepage=""https://storage.googleapis.com/scv_dataset/README.html"",\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    url = DATA_URL_DIR + ""%s_%dx%d_png/"" % (self.builder_config.map_name,\n                                            self.builder_config.resolution,\n                                            self.builder_config.resolution)\n\n    urls_to_download = {\n        ""train_%d"" % i: url + ""train-0000%d-of-00010.tfrecords"" % i\n        for i in range(10)\n    }\n    urls_to_download[""valid""] = url + ""valid-00000-of-00001.tfrecords""\n    urls_to_download[""test""] = url + ""test-00000-of-00001.tfrecords""\n\n    downloaded_urls = dl_manager.download_and_extract(urls_to_download)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                ""files"": [\n                    download for name, download in downloaded_urls.items()\n                    if ""train"" in name\n                ]\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={""files"": [downloaded_urls[""test""]]}),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.VALIDATION,\n            gen_kwargs={""files"": [downloaded_urls[""valid""]]}),\n    ]\n\n  def _parse_single_video(self, example_proto):\n    """"""Parses single video from the input tfrecords.\n\n    Args:\n      example_proto: tfExample proto with a single video.\n\n    Returns:\n      dict with all frames, positions and actions.\n    """"""\n    context_features = {\n        ""game_duration_loops"": tf.io.FixedLenFeature([1], tf.int64),\n        ""game_duration_seconds"": tf.io.FixedLenFeature([1], tf.float32),\n        ""n_steps"": tf.io.FixedLenFeature([1], tf.int64),\n        ""screen_size"": tf.io.FixedLenFeature([2], tf.int64),\n    }\n\n    sequence_features = {\n        ""rgb_screen"": tf.io.FixedLenSequenceFeature([], tf.string),\n    }\n\n    _, seq_feat = tf.io.parse_single_sequence_example(\n        example_proto,\n        context_features=context_features,\n        sequence_features=sequence_features)\n\n    video_frames = tf.map_fn(\n        tf.image.decode_png, seq_feat[""rgb_screen""], dtype=tf.uint8)\n    return video_frames\n\n  def _generate_examples(self, files):\n    logging.info(""Reading data from %s."", "","".join(files))\n    with tf.Graph().as_default():\n      ds = tf.data.TFRecordDataset(sorted(files))\n      ds = ds.map(\n          self._parse_single_video,\n          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n      iterator = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\n      with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.global_variables_initializer())\n        try:\n          i = 0\n          while True:\n            video = sess.run(iterator)\n            yield i, {""rgb_screen"": video}\n            i += 1\n\n        except tf.errors.OutOfRangeError:\n          # End of file.\n          return\n'"
tensorflow_datasets/video/starcraft_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for starcraft video dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.video import starcraft\n\n\nclass StarcraftVideoDatasetTest(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = starcraft.StarcraftVideo\n  BUILDER_CONFIG_NAMES_TO_TEST = [""brawl_64""]\n\n  DL_EXTRACT_RESULT = {\n      ""valid"": ""valid.tfrecords"",\n      ""test"": ""test.tfrecords"",\n      ""train_0"": ""train_0.tfrecords"",\n      ""train_1"": ""train_1.tfrecords""\n  }\n\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 1,\n      ""validation"": 1,\n  }\n\n\nclass StarcraftVideoDataset128Test(testing.DatasetBuilderTestCase):\n  """"""Separate test to cover the 128x128 resolution videos.""""""\n  DATASET_CLASS = starcraft.StarcraftVideo\n  BUILDER_CONFIG_NAMES_TO_TEST = [""brawl_128""]\n\n  DL_EXTRACT_RESULT = {\n      ""valid"": ""128_valid.tfrecords"",\n      ""test"": ""128_test.tfrecords"",\n      ""train_0"": ""128_train_0.tfrecords"",\n      ""train_1"": ""128_train_1.tfrecords""\n  }\n\n  SPLITS = {\n      ""train"": 2,\n      ""test"": 1,\n      ""validation"": 1,\n  }\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/video/ucf101.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""UCF-101 dataset from https://www.crcv.ucf.edu/data/UCF101.php.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets.public_api as tfds\n\nUCF_101_URL = \'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip\'\nSPLITS_URL = (\'https://www.crcv.ucf.edu/data/UCF101/\'\n              \'UCF101TrainTestSplits-RecognitionTask.zip\')\n\n_CITATION = """"""\\\n@article{DBLP:journals/corr/abs-1212-0402,\n  author    = {Khurram Soomro and\n               Amir Roshan Zamir and\n               Mubarak Shah},\n  title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in\n               The Wild},\n  journal   = {CoRR},\n  volume    = {abs/1212.0402},\n  year      = {2012},\n  url       = {http://arxiv.org/abs/1212.0402},\n  archivePrefix = {arXiv},\n  eprint    = {1212.0402},\n  timestamp = {Mon, 13 Aug 2018 16:47:45 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1212-0402},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n""""""\n\n_LABELS_FNAME = \'video/ucf101_labels.txt\'\n\n\nclass Ucf101Config(tfds.core.BuilderConfig):\n  """"""""Configuration for UCF101 split and possible video rescaling.""""""\n\n  @tfds.core.disallow_positional_args\n  def __init__(self, split_number, width=None, height=None, **kwargs):\n    """"""The parameters specifying how the dataset will be processed.\n\n    The dataset comes with three separate splits. You can specify which split\n    you want in `split_number`. If `width` and `height` are set, the videos\n    will be rescaled to have those heights and widths (using ffmpeg).\n\n    Args:\n      split_number: The split number, one of (1, 2, 3)\n      width: An integer with the width or None.\n      height: An integer with the height or None.\n      **kwargs: Passed on to the constructor of `BuilderConfig`.\n    """"""\n    super(Ucf101Config, self).__init__(**kwargs)\n    if (width is None) ^ (height is None):\n      raise ValueError(\'Either both dimensions should be set, or none of them\')\n    self.width = width\n    self.height = height\n    if split_number not in (1, 2, 3):\n      raise ValueError(\'Unknown split number {}, should be 1, 2 or 3\'.format(\n          split_number))\n    self.split_number = split_number\n\n\n_VERSION = tfds.core.Version(\n    \'2.0.0\', \'New split API (https://tensorflow.org/datasets/splits)\')\n\n\nclass Ucf101(tfds.core.GeneratorBasedBuilder):\n  """"""Ucf101 action recognition dataset.\n\n  Note that in contrast to the labels provided in the original dataset, here the\n  labels start at zero, not at one.\n  """"""\n\n  BUILDER_CONFIGS = [\n      Ucf101Config(\n          name=\'ucf101_1_256\',\n          description=\'256x256 UCF with the first action recognition split.\',\n          width=256,\n          height=256,\n          split_number=1,\n          version=_VERSION,\n      ),\n      Ucf101Config(\n          name=\'ucf101_1\',\n          description=\'UCF with the action recognition split #1.\',\n          width=None,\n          height=None,\n          split_number=1,\n          version=_VERSION,\n      ),\n      Ucf101Config(\n          name=\'ucf101_2\',\n          description=\'UCF with the action recognition split #2.\',\n          width=None,\n          height=None,\n          split_number=2,\n          version=_VERSION,\n      ),\n      Ucf101Config(\n          name=\'ucf101_3\',\n          description=\'UCF with the action recognition split #3.\',\n          width=None,\n          height=None,\n          split_number=3,\n          version=_VERSION,\n      ),\n  ]\n\n  def _info(self):\n    if self.builder_config.width is not None:\n      if self.builder_config.height is None:\n        raise ValueError(\'Provide either both height and width or none.\')\n      ffmpeg_extra_args = (\n          \'-vf\', \'scale={}x{}\'.format(self.builder_config.height,\n                                      self.builder_config.width))\n    else:\n      ffmpeg_extra_args = []\n\n    video_shape = (\n        None, self.builder_config.height, self.builder_config.width, 3)\n    labels_names_file = tfds.core.get_tfds_path(_LABELS_FNAME)\n    features = tfds.features.FeaturesDict({\n        \'video\': tfds.features.Video(video_shape,\n                                     ffmpeg_extra_args=ffmpeg_extra_args,\n                                     encoding_format=\'jpeg\'),\n        \'label\': tfds.features.ClassLabel(names_file=labels_names_file),\n    })\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=\'A 101-label video classification dataset.\',\n        features=features,\n        homepage=\'https://www.crcv.ucf.edu/data/UCF101.php\',\n        citation=_CITATION,\n    )\n\n  def _split_generators(self, dl_manager):\n    splits_folder = \'ucfTrainTestlist\'\n\n    urls_to_download = {\n        \'videos\': UCF_101_URL,\n        \'splits\': SPLITS_URL,\n    }\n    downloaded_urls = dl_manager.download_and_extract(urls_to_download)\n\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            gen_kwargs={\n                \'videos_dir\': downloaded_urls[\'videos\'],\n                \'splits_dir\': downloaded_urls[\'splits\'],\n                \'data_list\': \'{}/trainlist{:02d}.txt\'.format(\n                    splits_folder, self.builder_config.split_number),\n            }),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            gen_kwargs={\n                \'videos_dir\': downloaded_urls[\'videos\'],\n                \'splits_dir\': downloaded_urls[\'splits\'],\n                \'data_list\': \'{}/testlist{:02d}.txt\'.format(\n                    splits_folder, self.builder_config.split_number),\n            }),\n    ]\n\n  def _generate_examples(self, videos_dir, splits_dir, data_list):\n    data_list_path_path = os.path.join(splits_dir, data_list)\n    with tf.io.gfile.GFile(data_list_path_path, \'r\') as data_list_file:\n      labels_and_paths = data_list_file.readlines()\n    for label_and_path in sorted(labels_and_paths):\n      # The train splits contain not only the filename, but also a digit\n      # encoding the label separated by a space, which we ignore.\n      label_and_path = label_and_path.strip().split(\' \')[0]\n      label, path = os.path.split(label_and_path)\n      # Fix an inconsistency between the names in the list and in the zip file.\n      path = path.replace(\'HandStandPushups\', \'HandstandPushups\')\n      video_path = os.path.join(videos_dir, \'UCF101\', path)\n      if not tf.io.gfile.exists(video_path):\n        logging.error(\'Example %s not found\', video_path)\n        continue\n      # We extract the label from the filename.\n      yield path, {\'video\': video_path, \'label\': label}\n'"
tensorflow_datasets/video/ucf101_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.video import ucf101\n\n\nclass Ucf101Test(testing.DatasetBuilderTestCase):\n  DATASET_CLASS = ucf101.Ucf101\n\n  SPLITS = {\n      \'train\': 3,\n      \'test\': 2,\n  }\n\n  DL_EXTRACT_RESULT = {\n      \'videos\': \'videos\',\n      \'splits\': \'splits\',\n  }\n\n  BUILDER_CONFIG_NAMES_TO_TEST = [\'ucf101_1_256\', \'ucf101_2\']\n\n  def _assertAsDataset(self, builder):\n    """"""Check the label distribution for each split.""""""\n    super(Ucf101Test, self)._assertAsDataset(builder)\n    label_frequncies = {}\n    label_feature = builder.info.features[\'label\']\n    dataset = builder.as_dataset()\n    for split_name in Ucf101Test.SPLITS:\n      label_frequncies[split_name] = collections.defaultdict(int)\n      for features in dataset_utils.as_numpy(dataset[split_name]):\n        label_name = label_feature.int2str(features[\'label\'])\n        label_frequncies[split_name][label_name] += 1\n    self.assertEqual(dict(label_frequncies),\n                     {\'test\': {\'Archery\': 1, \'Nunchucks\': 1},\n                      \'train\': {\'Archery\': 1, \'Nunchucks\': 2}})\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/decode/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Decoder public API.\n\n""""""\n\nfrom tensorflow_datasets.core.decode.base import Decoder\nfrom tensorflow_datasets.core.decode.base import make_decoder\nfrom tensorflow_datasets.core.decode.base import SkipDecoding\n\n__all__ = [\n    \'Decoder\',\n    \'make_decoder\',\n    \'SkipDecoding\',\n]\n'"
tensorflow_datasets/core/decode/base.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport functools\n\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core.utils import py_utils\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Decoder(object):\n  """"""Base decoder object.\n\n  `tfds.decode.Decoder` allows for overriding the default decoding by\n  implementing a subclass, or skipping it entirely with\n  `tfds.decode.SkipDecoding`.\n\n  Instead of subclassing, you can also create a `Decoder` from a function\n  with the `tfds.decode.make_decoder` decorator.\n\n  All decoders must derive from this base class. The implementation can\n  access the `self.feature` property which will correspond to the\n  `FeatureConnector` to which this decoder is applied.\n\n  To implement a decoder, the main method to override is `decode_example`,\n  which takes the serialized feature as input and returns the decoded feature.\n\n  If `decode_example` changes the output dtype, you must also override\n  the `dtype` property. This enables compatibility with\n  `tfds.features.Sequence`.\n  """"""\n\n  def __init__(self):\n    self.feature = None\n\n  @api_utils.disallow_positional_args\n  def setup(self, feature):\n    """"""Transformation contructor.\n\n    The initialization of decode object is deferred because the objects only\n    know the builder/features on which it is used after it has been\n    constructed, the initialization is done in this function.\n\n    Args:\n      feature: `tfds.features.FeatureConnector`, the feature to which is applied\n        this transformation.\n\n    """"""\n    self.feature = feature\n\n  @property\n  def dtype(self):\n    """"""Returns the `dtype` after decoding.""""""\n    tensor_info = self.feature.get_tensor_info()\n    return py_utils.map_nested(lambda t: t.dtype, tensor_info)\n\n  @abc.abstractmethod\n  def decode_example(self, serialized_example):\n    """"""Decode the example feature field (eg: image).\n\n    Args:\n      serialized_example: `tf.Tensor` as decoded, the dtype/shape should be\n        identical to `feature.get_serialized_info()`\n\n    Returns:\n      example: Decoded example.\n    """"""\n    raise NotImplementedError(\'Abstract class\')\n\n  def decode_batch_example(self, serialized_example):\n    """"""See `FeatureConnector.decode_batch_example` for details.""""""\n    return tf.map_fn(\n        self.decode_example,\n        serialized_example,\n        dtype=self.dtype,\n        parallel_iterations=10,\n        back_prop=False,\n        name=\'sequence_decode\',\n    )\n\n\nclass SkipDecoding(Decoder):\n  """"""Transformation which skip the decoding entirelly.\n\n  Example of usage:\n\n  ```python\n  ds = ds.load(\n      \'imagenet2012\',\n      split=\'train\',\n      decoders={\n          \'image\': tfds.decode.SkipDecoding(),\n      }\n  )\n\n  for ex in ds.take(1):\n    assert ex[\'image\'].dtype == tf.string\n  ```\n  """"""\n\n  @property\n  def dtype(self):\n    tensor_info = self.feature.get_serialized_info()\n    return py_utils.map_nested(lambda t: t.dtype, tensor_info)\n\n  def decode_example(self, serialized_example):\n    """"""Forward the serialized feature field.""""""\n    return serialized_example\n\n\nclass DecoderFn(Decoder):\n  """"""Decoder created by `tfds.decoder.make_decoder` decorator.""""""\n\n  def __init__(self, fn, output_dtype, *args, **kwargs):\n    super(DecoderFn, self).__init__()\n    self._fn = fn\n    self._output_dtype = output_dtype\n    self._args = args\n    self._kwargs = kwargs\n\n  @property\n  def dtype(self):\n    if self._output_dtype is None:\n      return super(DecoderFn, self).dtype\n    else:\n      return self._output_dtype\n\n  def decode_example(self, serialized_example):\n    """"""Decode the example using the function.""""""\n    return self._fn(\n        serialized_example, self.feature, *self._args, **self._kwargs)\n\n\ndef make_decoder(output_dtype=None):\n  """"""Decorator to create a decoder.\n\n  The decorated function should have the signature `(example, feature, *args,\n  **kwargs) -> decoded_example`.\n\n   * `example`: Serialized example before decoding\n   * `feature`: `FeatureConnector` associated with the example\n   * `*args, **kwargs`: Optional additional kwargs forwarded to the function\n\n  Example:\n\n  ```\n  @tfds.decode.make_decoder(output_dtype=tf.string)\n  def no_op_decoder(example, feature):\n    \\""\\""\\""Decoder simply decoding feature normally.\\""\\""\\""\n    return feature.decode_example(example)\n\n  tfds.load(\'mnist\', split=\'train\', decoders: {\n      \'image\': no_op_decoder(),\n  })\n  ```\n\n  Args:\n    output_dtype: The output dtype after decoding. Required only if the decoded\n      example has a different type than the `FeatureConnector.dtype` and is\n      used to decode features inside sequences (ex: videos)\n\n  Returns:\n    The decoder object\n  """"""  # pylint: disable=g-docstring-has-escape\n\n  def decorator(fn):\n\n    @functools.wraps(fn)\n    def decorated(*args, **kwargs):\n      return DecoderFn(fn, output_dtype, *args, **kwargs)\n    return decorated\n\n  return decorator\n'"
tensorflow_datasets/core/decode/base_test.py,14,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.transform.image.image_transform.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import decode as decode_lib\nfrom tensorflow_datasets.core import features as features_lib\nfrom tensorflow_datasets.core import utils\n\ntf.enable_v2_behavior()\n\nrandint = np.random.randint\n\n\nclass BaseDecodeTest(testing.FeatureExpectationsTestCase):\n\n  def test_image_custom_decode(self):\n\n    # Do not uses random here because Jpeg compression has loss, so decoded\n    # value isn\'t the same\n    img_shaped = np.ones(shape=(30, 60, 3), dtype=np.uint8)\n    x, y, w, h = 4, 7, 10, 13\n    img_cropped = img_shaped[y:y + h, x:x + w, :]\n\n    class DecodeCrop(decode_lib.Decoder):\n      """"""Simple class on how to customize the decoding.""""""\n\n      def decode_example(self, serialized_image):\n        return tf.image.decode_and_crop_jpeg(\n            serialized_image,\n            [y, x, h, w],\n            channels=self.feature.shape[-1],\n        )\n\n    @decode_lib.make_decoder()\n    def decode_crop(serialized_image, feature):\n      return tf.image.decode_and_crop_jpeg(\n          serialized_image,\n          [y, x, h, w],\n          channels=feature.shape[-1],\n      )\n\n    image_path = utils.get_tfds_path(\'testing/test_data/test_image.jpg\')\n    with tf.io.gfile.GFile(image_path, \'rb\') as f:\n      serialized_img = f.read()\n\n    self.assertFeature(\n        # Image with statically defined shape\n        feature=features_lib.Image(shape=(30, 60, 3), encoding_format=\'jpeg\'),\n        shape=(30, 60, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=img_shaped,\n                expected=img_cropped,\n                shape=(13, 10, 3),  # Shape is cropped\n                decoders=DecodeCrop(),\n            ),\n            testing.FeatureExpectationItem(\n                value=img_shaped,\n                expected=img_cropped,\n                shape=(13, 10, 3),  # Shape is cropped\n                decoders=decode_crop(),  # pylint: disable=no-value-for-parameter\n            ),\n            testing.FeatureExpectationItem(\n                value=image_path,\n                expected=serialized_img,\n                shape=(),\n                dtype=tf.string,\n                decoders=decode_lib.SkipDecoding(),\n            ),\n        ],\n    )\n\n  def test_video_custom_decode(self):\n\n    image_path = utils.get_tfds_path(\'testing/test_data/test_image.jpg\')\n    with tf.io.gfile.GFile(image_path, \'rb\') as f:\n      serialized_img = f.read()\n\n    self.assertFeature(\n        # Image with statically defined shape\n        feature=features_lib.Video(shape=(None, 30, 60, 3)),\n        shape=(None, 30, 60, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[image_path] * 15,  # 15 frames of video\n                expected=[serialized_img] * 15,  # Non-decoded image\n                shape=(15,),\n                dtype=tf.string,  # Only string are decoded\n                decoders=decode_lib.SkipDecoding(),\n            ),\n        ],\n    )\n\n    # Test with FeatureDict\n    self.assertFeature(\n        feature=features_lib.FeaturesDict({\n            \'image\': features_lib.Image(\n                shape=(30, 60, 3), encoding_format=\'jpeg\'),\n            \'label\': tf.int64,\n        }),\n        shape={\n            \'image\': (30, 60, 3),\n            \'label\': (),\n        },\n        dtype={\n            \'image\': tf.uint8,\n            \'label\': tf.int64,\n        },\n        tests=[\n            testing.FeatureExpectationItem(\n                decoders={\n                    \'image\': decode_lib.SkipDecoding(),\n                },\n                value={\n                    \'image\': image_path,\n                    \'label\': 123,\n                },\n                expected={\n                    \'image\': serialized_img,\n                    \'label\': 123,\n                },\n                shape={\n                    \'image\': (),\n                    \'label\': (),\n                },\n                dtype={\n                    \'image\': tf.string,\n                    \'label\': tf.int64,\n                },\n            ),\n        ],\n    )\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/download/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""`tfds.download.DownloadManager` API.""""""\n\nfrom tensorflow_datasets.core.download.checksums import add_checksums_dir\nfrom tensorflow_datasets.core.download.download_manager import DownloadConfig\nfrom tensorflow_datasets.core.download.download_manager import DownloadManager\nfrom tensorflow_datasets.core.download.downloader import DownloadError\nfrom tensorflow_datasets.core.download.extractor import iter_archive\nfrom tensorflow_datasets.core.download.resource import ExtractMethod\nfrom tensorflow_datasets.core.download.resource import Resource\nfrom tensorflow_datasets.core.download.util import ComputeStatsMode\nfrom tensorflow_datasets.core.download.util import GenerateMode\n\n__all__ = [\n    ""add_checksums_dir"",\n    ""DownloadConfig"",\n    ""DownloadManager"",\n    ""DownloadError"",\n    ""ComputeStatsMode"",\n    ""GenerateMode"",\n    ""Resource"",\n    ""ExtractMethod"",\n    ""iter_archive"",\n]\n'"
tensorflow_datasets/core/download/checksums.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Methods to retrieve and store size/checksums associated to URLs.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, Iterable, List\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\n\n\n_ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(__file__), \'../..\'))\n\n_CHECKSUM_DIRS = [\n    os.path.join(_ROOT_DIR, \'url_checksums\'),\n]\n_CHECKSUM_SUFFIX = \'.txt\'\n\n\nclass UrlInfo(object):  # TODO(tfds): Use dataclasses\n  """"""Small wrapper around the url metadata (checksum, size).\n\n  Attributes:\n    size: Download size of the file\n    checksum: Checksum of the file\n  """"""\n\n  def __init__(self, size: int, checksum: str):\n    self.size = size\n    self.checksum = checksum\n\n  def asdict(self) -> Dict[str, Any]:\n    """"""Returns the dict representation of the dataclass.""""""\n    # TODO(tfds): Replace by `dataclasses.asdict(self)`\n    return {\n        \'size\': self.size,\n        \'checksum\': self.checksum,\n    }\n\n  def __eq__(self, other) -> bool:\n    return (\n        type(self) == type(other) and  # pylint: disable=unidiomatic-typecheck\n        self.size == other.size and\n        self.checksum == other.checksum\n    )\n\n  def __ne__(self, other) -> bool:  # Required in Py2\n    return not self == other\n\n  def __repr__(self) -> str:\n    return \'{}(size={}, checksum={})\'.format(\n        type(self).__name__, self.size, self.checksum)\n\n\ndef add_checksums_dir(checksums_dir: str) -> None:\n  """"""Registers a new checksums dir.\n\n  This function allow external datasets not present in the tfds repository to\n  define their own checksums_dir containing the dataset downloads checksums.\n\n  Note: When redistributing your dataset, you should distribute the checksums\n  files with it and set `add_checksums_dir` when the user is importing your\n  `my_dataset.py`.\n\n  ```\n  # Set-up the folder containing the \'my_dataset.txt\' checksums.\n  checksum_dir = os.path.join(os.path.dirname(__file__), \'checksums/\')\n  checksum_dir = os.path.normpath(checksum_dir)\n\n  # Add the checksum dir (will be executed when the user import your dataset)\n  tfds.download.add_checksums_dir(checksum_dir)\n\n  class MyDataset(tfds.core.DatasetBuilder):\n    ...\n  ```\n\n  Args:\n    checksums_dir: `str`, checksums dir to add to the registry\n  """"""\n  if checksums_dir in _CHECKSUM_DIRS:  # Avoid duplicate\n    return\n  _CHECKSUM_DIRS.append(checksums_dir)\n\n\ndef _list_dir(path: str) -> List[str]:\n  return tf.io.gfile.listdir(path)\n\n\n\n\n@utils.memoize()\ndef _checksum_paths() -> Dict[str, str]:\n  """"""Returns dict {\'dataset_name\': \'path/to/checksums/file\'}.""""""\n  dataset2path = {}\n  for dir_path in _CHECKSUM_DIRS:\n    for fname in _list_dir(dir_path):\n      if not fname.endswith(_CHECKSUM_SUFFIX):\n        continue\n      fpath = os.path.join(dir_path, fname)\n      dataset_name = fname[:-len(_CHECKSUM_SUFFIX)]\n      dataset2path[dataset_name] = fpath\n  return dataset2path\n\n\ndef _get_path(dataset_name: str) -> str:\n  """"""Returns path to where checksums are stored for a given dataset.""""""\n  path = _checksum_paths().get(dataset_name, None)\n  if path:\n    return path\n  msg = (\n      \'No checksums file could be find for dataset {}. Please \'\n      \'create one in one of:\\n{}\'\n      \'If you are developing your own dataset outsite tfds, you can register \'\n      \'your own checksums_dir with `tfds.download.add_checksums_dir(\'\n      \'checksums_dir)` or pass it to the download_and_prepare script with \'\n      \'`--checksums_dir=`\'\n  ).format(\n      dataset_name,\n      \'\'.join([\'* {}\\n\'.format(c) for c in _CHECKSUM_DIRS]))\n  raise AssertionError(msg)\n\n\ndef _get_url_infos(checksums_path: str) -> Dict[str, UrlInfo]:\n  """"""Returns {URL: (size, checksum)}s stored within file at given path.""""""\n  with tf.io.gfile.GFile(checksums_path) as f:\n    content = f.read()\n  return parse_url_infos(content.splitlines())\n\n\ndef parse_url_infos(checksums_file: Iterable[str]) -> Dict[str, UrlInfo]:\n  """"""Returns {URL: (size, checksum)}s stored within given file.""""""\n  url_infos = {}\n  for line in checksums_file:\n    line = line.strip()  # Remove the trailing \'\\r\' on Windows OS.\n    if not line or line.startswith(\'#\'):\n      continue\n    # URL might have spaces inside, but size and checksum will not.\n    url, size, checksum = line.rsplit(\' \', 2)\n    url_infos[url] = UrlInfo(size=int(size), checksum=checksum)\n  return url_infos\n\n\n@utils.memoize()\ndef get_all_url_infos() -> Dict[str, UrlInfo]:\n  """"""Returns dict associating URL to (size, sha256).""""""\n  url_infos = {}\n  for path in _checksum_paths().values():\n    dataset_url_infos = _get_url_infos(path)\n    for url, url_info in dataset_url_infos.items():\n      if url_infos.get(url, url_info) != url_info:\n        raise AssertionError(\n            \'URL {} is registered with 2+ distinct size/checksum tuples. \'\n            \'{} vs {}\'.format(url, url_info, url_infos[url]))\n    url_infos.update(dataset_url_infos)\n  return url_infos\n\n\ndef store_checksums(dataset_name: str, url_infos: Dict[str, UrlInfo]) -> None:\n  """"""Store given checksums and sizes for specific dataset.\n\n  Content of file is never disgarded, only updated. This is to ensure that if\n  process is killed right after first download finishes, checksums registered\n  during previous runs aren\'t lost.\n\n  It is the responsibility of the caller not to call function multiple times in\n  parallel for a given dataset.\n\n  Only original file content is updated. This means the entire set of new sizes\n  and checksums must be given at every call.\n\n  Args:\n    dataset_name: string.\n    url_infos: dict, {url: (size_in_bytes, checksum)}.\n  """"""\n  path = _get_path(dataset_name)\n  original_data = _get_url_infos(path)\n  new_data = original_data.copy()\n  new_data.update(url_infos)\n  if original_data == new_data:\n    return\n  with tf.io.gfile.GFile(path, \'w\') as f:\n    for url, url_info in sorted(new_data.items()):\n      f.write(\'{} {} {}\\n\'.format(url, url_info.size, url_info.checksum))\n'"
tensorflow_datasets/core/download/download_manager.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Download manager interface.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport concurrent.futures\nimport hashlib\nimport os\nimport sys\nfrom typing import Optional, Union\nimport uuid\n\nfrom absl import logging\nimport promise\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.download import checksums\nfrom tensorflow_datasets.core.download import downloader\nfrom tensorflow_datasets.core.download import extractor\nfrom tensorflow_datasets.core.download import resource as resource_lib\nfrom tensorflow_datasets.core.download import util\n\n\nclass NonMatchingChecksumError(Exception):\n  """"""The downloaded file doesn\'t have expected checksum.""""""\n\n  def __init__(self, url, tmp_path):\n    msg = (\n        \'Artifact {}, downloaded to {}, has wrong checksum. This might \'\n        \'indicate:\\n\'\n        \' * The website may be down (e.g. returned a 503 status code). Please \'\n        \'check the url.\\n\'\n        \' * For Google Drive URLs, try again later as Drive sometimes rejects \'\n        \'downloads when too many people access the same URL. See \'\n        \'https://github.com/tensorflow/datasets/issues/1482\\n\'\n        \' * The original datasets files may have been updated. In this case \'\n        \'the TFDS dataset builder should be updated to use the new files \'\n        \'and checksums. Sorry about that. Please open an issue or send us a PR \'\n        \'with a fix.\\n\'\n        \' * If you\\\'re adding a new dataset, don\\\'t forget to register the \'\n        \'checksums as explained in: \'\n        \'https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\\n\'\n    ).format(url, tmp_path)\n    Exception.__init__(self, msg)\n\n\nclass DownloadConfig(object):\n  """"""Configuration for `tfds.core.DatasetBuilder.download_and_prepare`.""""""\n\n  def __init__(\n      self,\n      extract_dir=None,\n      manual_dir=None,\n      download_mode=None,\n      compute_stats=None,\n      max_examples_per_split=None,\n      register_checksums=False,\n      force_checksums_validation=False,\n      beam_runner=None,\n      beam_options=None,\n      try_download_gcs=True,\n  ):\n    """"""Constructs a `DownloadConfig`.\n\n    Args:\n      extract_dir: `str`, directory where extracted files are stored.\n        Defaults to ""<download_dir>/extracted"".\n      manual_dir: `str`, read-only directory where manually downloaded/extracted\n        data is stored. Defaults to `<download_dir>/manual`.\n      download_mode: `tfds.GenerateMode`, how to deal with downloads or data\n        that already exists. Defaults to `REUSE_DATASET_IF_EXISTS`, which will\n        reuse both downloads and data if it already exists.\n      compute_stats: `tfds.download.ComputeStats`, whether to compute\n        statistics over the generated data. Defaults to `AUTO`.\n      max_examples_per_split: `int`, optional max number of examples to write\n        into each split (used for testing).\n      register_checksums: `bool`, defaults to False. If True, checksum of\n        downloaded files are recorded.\n      force_checksums_validation: `bool`, defaults to False. If True, raises\n        an error if an URL do not have checksums.\n      beam_runner: Runner to pass to `beam.Pipeline`, only used for datasets\n        based on Beam for the generation.\n      beam_options: `PipelineOptions` to pass to `beam.Pipeline`, only used for\n        datasets based on Beam for the generation.\n      try_download_gcs: `bool`, defaults to True. If True, prepared dataset\n        will be downloaded from GCS, when available. If False, dataset will be\n        downloaded and prepared from scratch.\n    """"""\n    self.extract_dir = extract_dir\n    self.manual_dir = manual_dir\n    self.download_mode = util.GenerateMode(\n        download_mode or util.GenerateMode.REUSE_DATASET_IF_EXISTS)\n    self.compute_stats = util.ComputeStatsMode(\n        compute_stats or util.ComputeStatsMode.AUTO)\n    self.max_examples_per_split = max_examples_per_split\n    self.register_checksums = register_checksums\n    self.force_checksums_validation = force_checksums_validation\n    self.beam_runner = beam_runner\n    self.beam_options = beam_options\n    self.try_download_gcs = try_download_gcs\n\n\nclass DownloadManager(object):\n  """"""Manages the download and extraction of files, as well as caching.\n\n  Downloaded files are cached under `download_dir`. The file name of downloaded\n   files follows pattern ""{sanitized_url}{content_checksum}.{ext}"". Eg:\n   \'cs.toronto.edu_kriz_cifar-100-pythonJDF[...]I.tar.gz\'.\n\n  While a file is being downloaded, it is placed into a directory following a\n  similar but different pattern:\n  ""{sanitized_url}{url_checksum}.tmp.{uuid}"".\n\n  When a file is downloaded, a ""{fname}.INFO.json"" file is created next to it.\n  This INFO file contains the following information:\n  {""dataset_names"": [""name1"", ""name2""],\n   ""urls"": [""http://url.of/downloaded_file""]}\n\n  Extracted files/dirs are stored under `extract_dir`. The file name or\n  directory name is the same as the original name, prefixed with the extraction\n  method. E.g.\n   ""{extract_dir}/TAR_GZ.cs.toronto.edu_kriz_cifar-100-pythonJDF[...]I.tar.gz"".\n\n  The function members accept either plain value, or values wrapped into list\n  or dict. Giving a data structure will parallelize the downloads.\n\n  Example of usage:\n\n  ```\n  # Sequential download: str -> str\n  train_dir = dl_manager.download_and_extract(\'https://abc.org/train.tar.gz\')\n  test_dir = dl_manager.download_and_extract(\'https://abc.org/test.tar.gz\')\n\n  # Parallel download: list -> list\n  image_files = dl_manager.download(\n      [\'https://a.org/1.jpg\', \'https://a.org/2.jpg\', ...])\n\n  # Parallel download: dict -> dict\n  data_dirs = dl_manager.download_and_extract({\n     \'train\': \'https://abc.org/train.zip\',\n     \'test\': \'https://abc.org/test.zip\',\n  })\n  data_dirs[\'train\']\n  data_dirs[\'test\']\n  ```\n\n  For more customization on the download/extraction (ex: passwords, output_name,\n  ...), you can pass a `tfds.download.Resource` as argument.\n  """"""\n\n  @api_utils.disallow_positional_args\n  def __init__(\n      self,\n      download_dir: str,\n      extract_dir: Optional[str] = None,\n      manual_dir: Optional[str] = None,\n      manual_dir_instructions: Optional[str] = None,\n      dataset_name: Optional[str] = None,\n      force_download: bool = False,\n      force_extraction: bool = False,\n      force_checksums_validation: bool = False,\n      register_checksums: bool = False,\n  ):\n    """"""Download manager constructor.\n\n    Args:\n      download_dir: Path to directory where downloads are stored.\n      extract_dir: Path to directory where artifacts are extracted.\n      manual_dir: Path to manually downloaded/extracted data directory.\n      manual_dir_instructions: Human readable instructions on how to\n        prepare contents of the manual_dir for this dataset.\n      dataset_name: Name of dataset this instance will be used for. If\n        provided, downloads will contain which datasets they were used for.\n      force_download: If True, always [re]download.\n      force_extraction: If True, always [re]extract.\n      force_checksums_validation: If True, raises an error if an URL do not\n        have checksums.\n      register_checksums: If True, dl checksums aren\'t\n        checked, but stored into file.\n    """"""\n    self._dataset_name = dataset_name\n    self._download_dir = os.path.expanduser(download_dir)\n    self._extract_dir = os.path.expanduser(\n        extract_dir or os.path.join(download_dir, \'extracted\'))\n    self._manual_dir = manual_dir and os.path.expanduser(manual_dir)\n    self._manual_dir_instructions = manual_dir_instructions\n    tf.io.gfile.makedirs(self._download_dir)\n    tf.io.gfile.makedirs(self._extract_dir)\n    self._force_download = force_download\n    self._force_extraction = force_extraction\n    self._force_checksums_validation = force_checksums_validation\n    self._register_checksums = register_checksums\n    # All known URLs: {url: (size, checksum)}\n    self._url_infos = checksums.get_all_url_infos()\n    # To record what is being used: {url: (size, checksum)}\n    self._recorded_url_infos = {}\n    # These attributes are lazy-initialized since they must be cleared when this\n    # object is pickled for Beam. They are then recreated on each worker.\n    self.__downloader = None\n    self.__extractor = None\n    # Executor to avoid blocking other download/extractions when running I/O\n    # operations (reading/renaming download file).\n    # Only use a single thread as the read/ops are locked by the\n    # `build_synchronize_decorator`.\n    # Note: This thread is in additions of the download and extraction\n    # executors threads.\n    self._executor = concurrent.futures.ThreadPoolExecutor(1)\n\n  def __getstate__(self):\n    """"""Remove un-pickleable attributes and return the state.""""""\n    if self._register_checksums:\n      # Currently, checksums registration from Beam not supported.\n      raise NotImplementedError(\n          \'`register_checksums` must be disabled in a parallelized \'\n          \'DownloadManager. Please open a PR if you would like this feature.\')\n    state = self.__dict__.copy()\n    state[\'_DownloadManager__downloader\'] = None\n    state[\'_DownloadManager__extractor\'] = None\n    state[\'_executor\'] = None\n    return state\n\n  @property\n  def _downloader(self):\n    if not self.__downloader:\n      self.__downloader = downloader.get_downloader()\n    return self.__downloader\n\n  @property\n  def _extractor(self):\n    if not self.__extractor:\n      self.__extractor = extractor.get_extractor()\n    return self.__extractor\n\n  @property\n  def downloaded_size(self):\n    """"""Returns the total size of downloaded files.""""""\n    return sum(url_info.size for url_info in self._recorded_url_infos.values())\n\n  def _get_final_dl_path(self, url, sha256):\n    return os.path.join(self._download_dir,\n                        resource_lib.get_dl_fname(url, sha256))\n\n  @property\n  def register_checksums(self):\n    """"""Returns whether checksums are being computed and recorded to file.""""""\n    return self._register_checksums\n\n  @utils.build_synchronize_decorator()\n  def _record_url_infos(self):\n    """"""Store in file when recorded size/checksum of downloaded files.""""""\n    checksums.store_checksums(self._dataset_name,\n                              self._recorded_url_infos)\n\n  def _handle_download_result(\n      self,\n      resource: resource_lib.Resource,\n      tmp_dir_path: str,\n      url_path: str,\n      url_info: checksums.UrlInfo,\n  ) -> str:\n    """"""Post-processing of the downloaded file.\n\n    * Write `.INFO` file\n    * Rename `tmp_dir/file.xyz` -> `url_path`\n    * Validate/record checksums\n    * Eventually rename `url_path` -> `file_path` when `record_checksums=True`\n\n    Args:\n      resource: The url to download.\n      tmp_dir_path: Temporary dir where the file was downloaded.\n      url_path: Destination path.\n      url_info: File checksums, size, computed during download.\n\n    Returns:\n      dst_path: `url_path` (or `file_path` when `register_checksums=True`)\n\n    Raises:\n      NonMatchingChecksumError:\n    """"""\n    # Extract the file name, path from the tmp_dir\n    fnames = tf.io.gfile.listdir(tmp_dir_path)\n    if len(fnames) != 1:\n      raise ValueError(\n          \'Download not found for url {} in: {}. Found {} files, but expected \'\n          \'1.\'.format(resource.url, tmp_dir_path, len(fnames)))\n    original_fname, = fnames  # Unpack list\n    tmp_path = os.path.join(tmp_dir_path, original_fname)\n\n    # Write `.INFO` file and rename `tmp_dir/file.xyz` -> `url_path`\n    resource_lib.write_info_file(\n        resource=resource,\n        path=url_path,\n        dataset_name=self._dataset_name,\n        original_fname=original_fname,\n        url_info=url_info,\n    )\n    # Unconditionally overwrite because either file doesn\'t exist or\n    # FORCE_DOWNLOAD=true\n    tf.io.gfile.rename(tmp_path, url_path, overwrite=True)\n    tf.io.gfile.rmtree(tmp_dir_path)\n\n    # After this checkpoint, the url file is cached, so should never be\n    # downloaded again, even if there are error in registering checksums.\n\n    # Even if `_handle_download_result` is executed asyncronously, Python\n    # built-in ops are atomic in CPython (and Pypy), so it should be safe\n    # to update `_recorded_url_infos`.\n    self._recorded_url_infos[resource.url] = url_info\n\n    # Validate the download checksum, or register checksums\n    dst_path = url_path\n    if self._register_checksums:\n      # Change `dst_path` from `url_path` -> `file_path`\n      dst_path = self._save_url_info_and_rename(\n          url=resource.url, url_path=url_path, url_info=url_info)\n    elif resource.url not in self._url_infos:\n      if self._force_checksums_validation:\n        raise ValueError(\n            \'Missing checksums url: {}, yet `force_checksums_validation=True`. \'\n            \'Did you forgot to register checksums ?\')\n      # Otherwise, missing checksums, do nothing\n    elif url_info != self._url_infos.get(resource.url, None):\n      raise NonMatchingChecksumError(resource.url, tmp_path)\n\n    return dst_path\n\n  def _save_url_info_and_rename(\n      self,\n      url: str,\n      url_path: str,\n      url_info: checksums.UrlInfo,\n  ) -> str:\n    """"""Saves the checksums on disk and renames `url_path` -> `file_path`.\n\n    This function assume the file has already be downloaded in `url_path`.\n\n    Args:\n      url: Url downloaded\n      url_path: Path of the downloaded file.\n      url_info: Downloaded file information.\n\n    Returns:\n      file_path: The downloaded file after renaming.\n    """"""\n    # Record checksums/download size\n    # As downloads are cached even without checksum, we could\n    # avoid recording the checksums for each urls, and record them once\n    # globally at the end.\n    assert url in self._recorded_url_infos\n    self._record_url_infos()\n\n    # Rename (after checksum got saved succesfully)\n    file_path = self._get_final_dl_path(url, url_info.checksum)\n    tf.io.gfile.rename(url_path, file_path, overwrite=True)\n    resource_lib.rename_info_file(url_path, file_path, overwrite=True)\n    return file_path\n\n  def _find_existing_path(self, url: str, url_path: str) -> Optional[str]:\n    """"""Returns the downloaded file path if it exists.\n\n    The file can be located in two different locations:\n\n    * `file_path = f(url, hash(file))`\n    * `url_path = f(url, hash(url))`\n\n    `file_path` can only be computed if the file checksum is known in\n    advance. Otherwise, `url_path` is used as fallback.\n\n    Args:\n      url: Downloaded url\n      url_path: File path when the file checksums is unknown\n\n    Returns:\n      existing_path: `file_path` or `url_path` if the file was already\n        downloaded. `None` otherwise.\n    """"""\n    existing_path = None\n    # If download is forced, then have to re-download in all cases\n    if not self._force_download:\n      # File checksum is registered (`file_path` known)\n      if url in self._url_infos:\n        expected_file_checksum = self._url_infos[url].checksum\n        file_path = self._get_final_dl_path(url, expected_file_checksum)\n        if resource_lib.Resource.exists_locally(file_path):\n          existing_path = file_path\n          # Info restored from `checksums/dataset.txt` files.\n          self._recorded_url_infos[url] = self._url_infos[url]\n\n      # If `file_path` isn\'t found (or unknown), fall back to `url_path`\n      if not existing_path and resource_lib.Resource.exists_locally(url_path):\n        existing_path = url_path\n        # Info restored from `.INFO` file\n        self._recorded_url_infos[url] = _read_url_info(url_path)\n    return existing_path\n\n  def download_checksums(self, checksums_url):\n    """"""Downloads checksum file from the given URL and adds it to registry.""""""\n    checksums_path = self.download(checksums_url)\n    with tf.io.gfile.GFile(checksums_path) as f:\n      self._url_infos.update(checksums.parse_url_infos(f))\n\n  # Synchronize and memoize decorators ensure same resource will only be\n  # processed once, even if passed twice to download_manager.\n  @utils.build_synchronize_decorator()\n  @utils.memoize()\n  def _download(self, resource: Union[str, resource_lib.Resource]):\n    """"""Download resource, returns Promise->path to downloaded file.\n\n    Args:\n      resource: The URL to download.\n\n    Returns:\n      path: The path to the downloaded resource.\n    """"""\n    # Normalize the input\n    if isinstance(resource, six.string_types):\n      resource = resource_lib.Resource(url=resource)\n    url = resource.url\n\n    # Compute the existing path if the file was previously downloaded\n    url_path = self._get_final_dl_path(\n        url, hashlib.sha256(url.encode(\'utf-8\')).hexdigest())\n    existing_path = self._find_existing_path(url=url, url_path=url_path)\n\n    # If register checksums and file already downloaded, then:\n    # * Record the url_infos of the downloaded file\n    # * Rename the filename `url_path` -> `file_path`, and return it.\n    if self._register_checksums and existing_path == url_path:\n      logging.info(\n          \'URL %s already downloaded: Recording checksums from %s.\',\n          url,\n          existing_path,\n      )\n      future = self._executor.submit(\n          self._save_url_info_and_rename,\n          url=url,\n          url_path=url_path,\n          url_info=self._recorded_url_infos[url],\n      )\n      return promise.Promise.resolve(future)\n    # Otherwise, url_infos are either already registered, or will be registered\n    # in the `_handle_download_result` callback.\n\n    # If the file file already exists (`file_path` or `url_path`), return it.\n    if existing_path:\n      logging.info(\'URL %s already downloaded: reusing %s.\', url, existing_path)\n      return promise.Promise.resolve(existing_path)\n\n    # Otherwise, download the file, and eventually computing the checksums.\n    # There is a slight difference between downloader and extractor here:\n    # the extractor manages its own temp directory, while the DownloadManager\n    # manages the temp directory of downloader.\n    download_dir_path = os.path.join(\n        self._download_dir,\n        \'%s.tmp.%s\' % (resource_lib.get_dl_dirname(url), uuid.uuid4().hex))\n    tf.io.gfile.makedirs(download_dir_path)\n    logging.info(\'Downloading %s into %s...\', url, download_dir_path)\n    def callback(url_info):\n      return self._handle_download_result(\n          resource=resource,\n          tmp_dir_path=download_dir_path,\n          url_path=url_path,\n          url_info=url_info,\n      )\n    return self._downloader.download(url, download_dir_path).then(callback)\n\n  @utils.build_synchronize_decorator()\n  @utils.memoize()\n  def _extract(self, resource):\n    """"""Extract a single archive, returns Promise->path to extraction result.""""""\n    if isinstance(resource, six.string_types):\n      resource = resource_lib.Resource(path=resource)\n    path = resource.path\n    extract_method = resource.extract_method\n    if extract_method == resource_lib.ExtractMethod.NO_EXTRACT:\n      logging.info(\'Skipping extraction for %s (method=NO_EXTRACT).\', path)\n      return promise.Promise.resolve(path)\n    method_name = resource_lib.ExtractMethod(extract_method).name\n    extract_path = os.path.join(self._extract_dir,\n                                \'%s.%s\' % (method_name, os.path.basename(path)))\n    if not self._force_extraction and tf.io.gfile.exists(extract_path):\n      logging.info(\'Reusing extraction of %s at %s.\', path, extract_path)\n      return promise.Promise.resolve(extract_path)\n    return self._extractor.extract(path, extract_method, extract_path)\n\n  @utils.build_synchronize_decorator()\n  @utils.memoize()\n  def _download_extract(self, resource):\n    """"""Download-extract `Resource` or url, returns Promise->path.""""""\n    if isinstance(resource, six.string_types):\n      resource = resource_lib.Resource(url=resource)\n    def callback(path):\n      resource.path = path\n      return self._extract(resource)\n    return self._download(resource).then(callback)\n\n  def download_kaggle_data(self, competition_name):\n    """"""Download data for a given Kaggle competition.""""""\n    with self._downloader.tqdm():\n      kaggle_downloader = self._downloader.kaggle_downloader(competition_name)\n      urls = kaggle_downloader.competition_urls\n      files = kaggle_downloader.competition_files\n      return _map_promise(self._download,\n                          dict((f, u) for (f, u) in zip(files, urls)))\n\n  def download(self, url_or_urls):\n    """"""Download given url(s).\n\n    Args:\n      url_or_urls: url or `list`/`dict` of urls to download and extract. Each\n        url can be a `str` or `tfds.download.Resource`.\n\n    Returns:\n      downloaded_path(s): `str`, The downloaded paths matching the given input\n        url_or_urls.\n    """"""\n    # Add progress bar to follow the download state\n    with self._downloader.tqdm():\n      return _map_promise(self._download, url_or_urls)\n\n  def iter_archive(self, resource):\n    """"""Returns iterator over files within archive.\n\n    **Important Note**: caller should read files as they are yielded.\n    Reading out of order is slow.\n\n    Args:\n      resource: path to archive or `tfds.download.Resource`.\n\n    Returns:\n      Generator yielding tuple (path_within_archive, file_obj).\n    """"""\n    if isinstance(resource, six.string_types):\n      resource = resource_lib.Resource(path=resource)\n    return extractor.iter_archive(resource.path, resource.extract_method)\n\n  def extract(self, path_or_paths):\n    """"""Extract given path(s).\n\n    Args:\n      path_or_paths: path or `list`/`dict` of path of file to extract. Each\n        path can be a `str` or `tfds.download.Resource`.\n\n    If not explicitly specified in `Resource`, the extraction method is deduced\n    from downloaded file name.\n\n    Returns:\n      extracted_path(s): `str`, The extracted paths matching the given input\n        path_or_paths.\n    """"""\n    # Add progress bar to follow the download state\n    with self._extractor.tqdm():\n      return _map_promise(self._extract, path_or_paths)\n\n  def download_and_extract(self, url_or_urls):\n    """"""Download and extract given url_or_urls.\n\n    Is roughly equivalent to:\n\n    ```\n    extracted_paths = dl_manager.extract(dl_manager.download(url_or_urls))\n    ```\n\n    Args:\n      url_or_urls: url or `list`/`dict` of urls to download and extract. Each\n        url can be a `str` or `tfds.download.Resource`.\n\n    If not explicitly specified in `Resource`, the extraction method will\n    automatically be deduced from downloaded file name.\n\n    Returns:\n      extracted_path(s): `str`, extracted paths of given URL(s).\n    """"""\n    # Add progress bar to follow the download state\n    with self._downloader.tqdm():\n      with self._extractor.tqdm():\n        return _map_promise(self._download_extract, url_or_urls)\n\n  @property\n  def manual_dir(self):\n    """"""Returns the directory containing the manually extracted data.""""""\n    if not self._manual_dir:\n      raise AssertionError(\n          \'Manual directory was enabled. \'\n          \'Did you set MANUAL_DOWNLOAD_INSTRUCTIONS in your dataset?\')\n    if (not tf.io.gfile.exists(self._manual_dir) or\n        not list(tf.io.gfile.listdir(self._manual_dir))):\n      raise AssertionError(\n          \'Manual directory {} does not exist or is empty. Create it and \'\n          \'download/extract dataset artifacts in there. Additional \'\n          \'instructions: {}\'.format(\n              self._manual_dir, self._manual_dir_instructions))\n    return self._manual_dir\n\n\ndef _read_url_info(url_path: str) -> checksums.UrlInfo:\n  """"""Loads the `UrlInfo` from the `.INFO` file.""""""\n  file_info = resource_lib.read_info_file(url_path)\n  if \'url_info\' not in file_info:\n    raise ValueError(\n        \'Could not found `url_info` in {}. This likelly indicates that \'\n        \'the files where downloaded with a previous version of TFDS (<=3.1.0). \'\n    )\n  return checksums.UrlInfo(**file_info[\'url_info\'])\n\n\n# ============================================================================\n# In Python 2.X, threading.Condition.wait() cannot be interrupted by SIGINT,\n# unless it\'s given a timeout. Here we artificially give a long timeout to\n# allow ctrl+C.\n# This code should be deleted once python2 is no longer supported.\nif sys.version_info[0] > 2:\n\n  def _wait_on_promise(p):\n    return p.get()\n\nelse:\n\n  def _wait_on_promise(p):\n    while True:\n      result = p.get(sys.maxint)  # pylint: disable=g-deprecated-member-used\n      if p.is_fulfilled:\n        return result\n\n# ============================================================================\n\n\ndef _map_promise(map_fn, all_inputs):\n  """"""Map the function into each element and resolve the promise.""""""\n  all_promises = utils.map_nested(map_fn, all_inputs)  # Apply the function\n  res = utils.map_nested(_wait_on_promise, all_promises)\n  return res\n'"
tensorflow_datasets/core/download/download_manager_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.download.download_manager.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nimport json\nimport os\nimport pickle\n\nfrom absl.testing import absltest\nimport promise\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.download import checksums as checksums_lib\nfrom tensorflow_datasets.core.download import download_manager as dm\nfrom tensorflow_datasets.core.download import downloader\nfrom tensorflow_datasets.core.download import extractor\nfrom tensorflow_datasets.core.download import resource as resource_lib\n\n\nZIP = resource_lib.ExtractMethod.ZIP\nTAR = resource_lib.ExtractMethod.TAR\nNO_EXTRACT = resource_lib.ExtractMethod.NO_EXTRACT\n\n\ndef _sha256(str_):\n  return hashlib.sha256(str_.encode(\'utf8\')).hexdigest()\n\n\nclass Artifact(object):\n  # For testing only.\n\n  def __init__(self, name, url=None):\n    url = url or f\'http://foo-bar.ch/{name}\'\n    content = f\'content of {name}\'\n    self.url = url\n    self.url_info = checksums_lib.UrlInfo(\n        size=len(content),\n        checksum=_sha256(content),\n    )\n    self.file_name = resource_lib.get_dl_fname(url, self.url_info.checksum)\n    self.file_path = f\'/dl_dir/{self.file_name}\'\n    self.url_name = resource_lib.get_dl_fname(url, _sha256(url))\n    self.url_path = f\'/dl_dir/{self.url_name}\'\n\n\nclass DownloadManagerTest(testing.TestCase):\n  """"""Download manager test.\n\n  During tests, the `tf.io.gfile` API is mocked. Instead, files I/O are tracked\n  through `fs` (`tfds.testing.MockFs`).\n\n  The downloader/extrator results are mocked with:\n\n    dl_results: Dict[str, UrlInfo], mapping `url` -> `downloader.download(url)`\n    dl_fnames: Dict[str, str], mapping `url` -> `filename`, if the name\n      cannot be extracted from the url (e.g. `https://a.org/download?id=123`)\n    extract_results: Dict[str, str], mapping `path` -> `extractor.extract()`\n\n  To check whether url/path are actually downloaded vs cached reused:\n\n    downloaded_urls: Track calls of `downloader.download`\n    extracted_paths: Track calls of `extractor.extract`\n  """"""\n\n  # ----- Downloader/Extractor patch -----\n\n  def _make_downloader_mock(self):\n    """"""`downloader.download` patch which creates the returns the path.""""""\n\n    def _download(url, tmpdir_path):\n      self.downloaded_urls.append(url)  # Record downloader.download() calls\n      # If the name isn\'t explicitly provided, then it is extracted from the\n      # url.\n      filename = self.dl_fnames.get(url, os.path.basename(url))\n      # Save the file in the tmp_dir\n      self.fs.add_file(os.path.join(tmpdir_path, filename))\n      return promise.Promise.resolve(self.dl_results[url])\n\n    return absltest.mock.patch.object(\n        downloader._Downloader, \'download\', side_effect=_download)\n\n  def _make_extractor_mock(self):\n    """"""`extractor.extract` patch which creates the returns the path.""""""\n\n    def _extract(path, method, dest):\n      self.extracted_paths.append(path)  # Record downloader.download() calls\n      self.fs.add_file(dest, f\'Extracted dir from {path}\')\n      if not os.path.basename(dest).startswith(method.name):\n        raise ValueError(\n            f\'Destination {dest} do not match extraction method {method}\')\n      return promise.Promise.resolve(self.extract_results[path])\n\n    return absltest.mock.patch.object(\n        extractor._Extractor, \'extract\', side_effect=_extract).start()\n\n  def setUp(self):\n    super(DownloadManagerTest, self).setUp()\n\n    # Input of the DownloadManager\n    self.dl_results = {}\n    self.dl_fnames = {}\n    self.extract_results = {}\n\n    # Track calls to downloader/extractor\n    self.downloaded_urls = []\n    self.extracted_paths = []\n\n    # Virtual file system\n    self.fs = testing.MockFs()  # Dict file_path -> file_content\n\n    # Start all mocks\n    self.fs.mock().start()\n    absltest.mock.patch.object(checksums_lib, \'store_checksums\').start()\n    self._make_downloader_mock().start()\n    self._make_extractor_mock().start()\n\n    self.addCleanup(absltest.mock.patch.stopall)\n\n  def _write_info(self, path, info):\n    content = json.dumps(info)\n    self.fs.add_file(path, content)\n\n  def _get_manager(\n      self,\n      register_checksums=True,\n      url_infos=None,\n      dl_dir=\'/dl_dir\',\n      extract_dir=\'/extract_dir\',\n      **kwargs\n  ):\n    manager = dm.DownloadManager(\n        dataset_name=\'mnist\',\n        download_dir=dl_dir,\n        extract_dir=extract_dir,\n        manual_dir=\'/manual_dir\',\n        register_checksums=register_checksums,\n        **kwargs\n    )\n    if url_infos:\n      manager._url_infos = url_infos\n    return manager\n\n  def test_download(self):\n    """"""One file in cache, one not.""""""\n    a, b, c = [Artifact(i) for i in \'abc\']\n    # File `a` is cached\n    self.fs.add_file(a.file_path)\n    self.fs.add_file(a.file_path + \'.INFO\')\n    # INFO file of c has been deleted:\n    self.fs.add_file(c.file_path)\n\n    self.dl_results[b.url] = b.url_info\n    self.dl_results[c.url] = c.url_info\n    manager = self._get_manager(url_infos={\n        art.url: art.url_info for art in (a, b, c)\n    })\n    downloads = manager.download({\n        \'cached\': a.url,\n        \'new\': b.url,\n        \'info_deleted\': c.url,\n    })\n    expected = {\n        \'cached\': a.file_path,\n        \'new\': b.file_path,\n        \'info_deleted\': c.file_path,\n    }\n    self.assertEqual(downloads, expected)\n    # A isn\'t downloaded as already cached\n    # C is re-downloaded as incomplete\n    self.assertCountEqual(self.downloaded_urls, {b.url, c.url})\n    self.assertEqual(  # Downloaded size include cached downloads\n        manager.downloaded_size, sum([art.url_info.size for art in (a, b, c)]))\n\n  def test_extract(self):\n    """"""One file already extracted, one file with NO_EXTRACT, one to extract.""""""\n    cached = resource_lib.Resource(path=\'/dl_dir/cached\', extract_method=ZIP)\n    new_ = resource_lib.Resource(path=\'/dl_dir/new\', extract_method=TAR)\n    no_extract = resource_lib.Resource(path=\'/dl_dir/noextract\',\n                                       extract_method=NO_EXTRACT)\n    self.fs.add_file(\'/extract_dir/ZIP.cached\')\n    self.extract_results[\'/dl_dir/new\'] = \'/extract_dir/TAR.new\'\n    manager = self._get_manager()\n    res = manager.extract({\n        \'cached\': cached,\n        \'new\': new_,\n        \'noextract\': no_extract,\n    })\n    expected = {\n        \'cached\': \'/extract_dir/ZIP.cached\',\n        \'new\': \'/extract_dir/TAR.new\',\n        \'noextract\': \'/dl_dir/noextract\',\n    }\n    self.assertEqual(res, expected)\n    self.assertCountEqual(self.extracted_paths, [\'/dl_dir/new\'])\n\n  def test_extract_twice_parallel(self):\n    # Make sure calling extract twice on same resource actually does the\n    # extraction once.\n    self.extract_results[\'/dl_dir/foo.tar\'] = \'/extract_dir/TAR.foo\'\n    manager = self._get_manager()\n    out1 = manager.extract([\'/dl_dir/foo.tar\', \'/dl_dir/foo.tar\'])\n    out2 = manager.extract(\'/dl_dir/foo.tar\')\n    self.assertEqual(out1, [\'/extract_dir/TAR.foo\', \'/extract_dir/TAR.foo\'])\n    self.assertEqual(out2, \'/extract_dir/TAR.foo\')\n    # Result is memoize so extract has only been called once\n    self.assertCountEqual(self.extracted_paths, [\'/dl_dir/foo.tar\'])\n\n  def test_download_and_extract(self):\n    a, b = Artifact(\'a.zip\'), Artifact(\'b\')\n    self.dl_results[a.url] = a.url_info\n    self.dl_results[b.url] = b.url_info\n    self.extract_results[a.file_path] = f\'/extract_dir/ZIP.{a.file_name}\'\n    # url_b doesn\'t need any extraction.\n\n    # Result is the same after caching:\n    manager = self._get_manager(url_infos={\n        a.url: a.url_info,\n        b.url: b.url_info,\n    })\n    res = manager.download_and_extract({\'a\': a.url, \'b\': b.url})\n    self.assertEqual(res, {\n        \'a\': \'/extract_dir/ZIP.%s\' % a.file_name,\n        \'b\': b.file_path,\n    })\n\n  def test_download_and_extract_archive_ext_in_fname(self):\n    # Make sure extraction method is properly deduced from original fname, and\n    # not from URL.\n    a = Artifact(\'a\', url=\'http://a?key=1234\')\n    self.dl_results[a.url] = a.url_info\n    self.dl_fnames[a.url] = \'abc.zip\'\n    self.extract_results[a.file_path] = f\'/extract_dir/ZIP.{a.file_name}\'\n\n    manager = self._get_manager(url_infos={\n        a.url: a.url_info,\n    })\n    res = manager.download_and_extract({\'a\': a.url})\n    self.assertEqual(res, {\n        \'a\': \'/extract_dir/ZIP.%s\' % a.file_name,\n    })\n\n\n  def test_download_and_extract_already_downloaded(self):\n    a = Artifact(\'a\')  # Extract can\'t be deduced from the url, but from .INFO\n    # File was already downloaded:\n    self.fs.add_file(a.file_path)\n    self._write_info(a.file_path + \'.INFO\', {\'original_fname\': \'a.zip\'})\n    self.extract_results[a.file_path] = f\'/extract_dir/ZIP.{a.file_name}\'\n    manager = self._get_manager(url_infos={\n        a.url: a.url_info,\n    })\n    res = manager.download_and_extract(a.url)\n    self.assertEqual(res, f\'/extract_dir/ZIP.{a.file_name}\')\n    # No url downloaded, but file extracted.\n    self.assertCountEqual(self.downloaded_urls, [])\n    self.assertCountEqual(self.extracted_paths, [a.file_path])\n\n  def test_force_download_and_extract(self):\n    a = Artifact(\'a.tar.gz\')\n    self.dl_results[a.url] = a.url_info\n    self.extract_results[a.file_path] = (\n        f\'/extract_dir/TAR_GZ.{a.file_name}\')\n\n    # Old content already exists\n    self.fs.files = {\n        a.file_path: \'old content\',\n        a.file_path + \'.INFO\': \'{}\',\n        f\'/extract_dir/TAR_GZ.{a.file_name}\': \'old content\',\n    }\n\n    # Redownloading the data overwrite the content\n    manager = self._get_manager(\n        force_download=True,\n        force_extraction=True,\n        url_infos={\n            a.url: a.url_info,\n        })\n    res = manager.download_and_extract(a.url)\n    self.assertEqual(res, f\'/extract_dir/TAR_GZ.{a.file_name}\')\n\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.extracted_paths, [a.file_path])\n    self.assertNotEqual(a.file_path, \'old content\')\n    self.assertNotEqual(a.file_path + \'.INFO\', \'{}\')\n    self.assertNotEqual(f\'/extract_dir/TAR_GZ.{a.file_name}\', \'old content\')\n\n  def test_wrong_checksum(self):\n    a = Artifact(\'a.tar.gz\')\n    sha_b = _sha256(\'content of another file\')\n    self.dl_results[a.url] = a.url_info\n    manager = self._get_manager(\n        register_checksums=False,\n        url_infos={\n            a.url: checksums_lib.UrlInfo(size=a.url_info.size, checksum=sha_b),\n        },\n    )\n    with self.assertRaises(dm.NonMatchingChecksumError):\n      manager.download(a.url)\n\n  def test_pickle(self):\n    dl_manager = self._get_manager(register_checksums=False)\n    pickle.loads(pickle.dumps(dl_manager))\n\n    dl_manager = self._get_manager(register_checksums=True)\n    with self.assertRaisesRegex(\n        NotImplementedError, \'`register_checksums` must be disabled\'):\n      pickle.dumps(dl_manager)\n\n  def test_force_checksums_validation(self):\n    """"""Tests for download manager with checksums.""""""\n    dl_manager = self._get_manager(\n        force_checksums_validation=True,\n        register_checksums=False,\n    )\n\n    a = Artifact(\'x\')\n    self.dl_results[a.url] = a.url_info\n    with self.assertRaisesRegex(ValueError, \'Missing checksums url\'):\n      dl_manager.download(a.url)\n\n  def test_download_cached(self):\n    """"""Tests that the URL is downloaded only once.""""""\n    a = Artifact(\'x\')\n    self.dl_results[a.url] = a.url_info\n\n    # Download the URL\n    dl_manager = self._get_manager(\n        register_checksums=False,\n    )\n    self.assertEqual(dl_manager.download(a.url), a.url_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.fs.files, [a.url_path, a.url_path + \'.INFO\'])\n\n    # Reuse downloaded cache\n    dl_manager = self._get_manager(\n        register_checksums=False,\n    )\n    self.assertEqual(dl_manager.download(a.url), a.url_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.fs.files, [a.url_path, a.url_path + \'.INFO\'])\n\n    # Reuse downloaded cache, even if url_info is present\n    dl_manager = self._get_manager(\n        register_checksums=False,\n        url_infos={a.url: a.url_info},\n    )\n    self.assertEqual(dl_manager.download(a.url), a.url_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.fs.files, [a.url_path, a.url_path + \'.INFO\'])\n\n    # Reuse downloaded cache and register the checksums\n    dl_manager = self._get_manager(\n        register_checksums=True,  # <<< Register checksums !!!\n    )\n    self.assertEqual(dl_manager.download(a.url), a.file_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    # The files have been renamed `url_path` -> `file_path`\n    self.assertCountEqual(self.fs.files, [a.file_path, a.file_path + \'.INFO\'])\n\n    # After checksums have been registered, `file_path` is used\n    dl_manager = self._get_manager(\n        register_checksums=False,\n        url_infos={a.url: a.url_info},\n    )\n    self.assertEqual(dl_manager.download(a.url), a.file_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.fs.files, [a.file_path, a.file_path + \'.INFO\'])\n\n    # Registering checksums twice still reuse the cached `file_path`\n    dl_manager = self._get_manager(\n        register_checksums=True,  # <<< Re-register checksums...\n        url_infos={a.url: a.url_info},  # ...but checksums already known\n    )\n    self.assertEqual(dl_manager.download(a.url), a.file_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])  # Still one download\n    self.assertCountEqual(self.fs.files, [a.file_path, a.file_path + \'.INFO\'])\n\n    # Checksums unknown, so `file_path` unknown, re-downloading\n    dl_manager = self._get_manager(\n        register_checksums=False,\n    )\n    self.assertEqual(dl_manager.download(a.url), a.url_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url, a.url])  # Re-download!!\n    self.assertCountEqual(self.fs.files, [\n        a.url_path,\n        a.url_path + \'.INFO\',\n        a.file_path,  # `file_path` still exists from previous download\n        a.file_path + \'.INFO\',\n    ])\n\n  def test_download_cached_checksums_error(self):\n    """"""Tests that the download is cached, even if record_checksums fails.""""""\n    a = Artifact(\'x\')\n    self.dl_results[a.url] = a.url_info\n\n    class StoreChecksumsError(Exception):\n      pass\n\n    dl_manager = self._get_manager(\n        register_checksums=True,\n    )\n    with absltest.mock.patch.object(\n        checksums_lib, \'store_checksums\', side_effect=StoreChecksumsError()):\n      with self.assertRaises(StoreChecksumsError):\n        dl_manager.download(a.url)\n    # Even after failure, the file was properly downloaded\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    self.assertCountEqual(self.fs.files, [a.url_path, a.url_path + \'.INFO\'])\n\n    # When the user retry, it should suceed without redownloading the file\n    dl_manager = self._get_manager(\n        register_checksums=True,\n    )\n    self.assertEqual(dl_manager.download(a.url), a.file_path)\n    self.assertCountEqual(self.downloaded_urls, [a.url])\n    # The files have been renamed `url_path` -> `file_path`\n    self.assertCountEqual(self.fs.files, [a.file_path, a.file_path + \'.INFO\'])\n\n  def test_download_url_info_in_info_file_missmatch(self):\n    """"""Tests failure when downloaded checksums and `.INFO` mismatch.""""""\n\n    a = Artifact(\'x\')\n    self.dl_results[a.url] = a.url_info\n\n    # Download the url once\n    dl_manager = self._get_manager(register_checksums=False)\n    dl_manager.download(a.url)\n\n    # The second time, download the url with a different checksum\n    self.dl_results[a.url] = checksums_lib.UrlInfo(\n        size=a.url_info.size,\n        checksum=_sha256(\'Other content\'),\n    )\n    dl_manager = self._get_manager(\n        register_checksums=False,\n        force_download=True,\n    )\n    with self.assertRaisesRegexp(ValueError, \'contains a different checksum\'):\n      dl_manager.download(a.url)\n\n    # If the url is re-downloaded with the same hash, no error is raised\n    self.dl_results[a.url] = a.url_info\n    dl_manager = self._get_manager(\n        register_checksums=False,\n        force_download=True,\n    )\n    dl_manager.download(a.url)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/download/downloader.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Async download API with checksum verification. No business logic.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport concurrent.futures\nimport contextlib\nimport functools\nimport hashlib\nimport io\nimport os\nimport re\nfrom typing import Any, ContextManager, Iterable, Iterator, Tuple, Union\nimport promise\nimport requests\n\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import units\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.download import checksums as checksums_lib\nfrom tensorflow_datasets.core.download import kaggle\n\n_DRIVE_URL = re.compile(r\'^https://drive\\.google\\.com/\')\n\n\n# Response interface. Has `.url` and `.headers` attribute\nResponse = Union[requests.Response, urllib.response.addinfourl]\n\n\n@utils.memoize()\ndef get_downloader(*args: Any, **kwargs: Any) -> \'_Downloader\':\n  return _Downloader(*args, **kwargs)\n\n\ndef _get_filename(response: Response) -> str:\n  content_disposition = response.headers.get(\'content-disposition\', None)\n  if content_disposition:\n    match = re.findall(\'filename=""(.+?)""\', content_disposition)\n    if match:\n      return match[0]\n  return utils.basename_from_url(response.url)\n\n\nclass DownloadError(Exception):\n  pass\n\n\nclass _Downloader(object):\n  """"""Class providing async download API with checksum validation.\n\n  Do not instantiate this class directly. Instead, call `get_downloader()`.\n  """"""\n\n  def __init__(self, max_simultaneous_downloads: int = 50, checksumer=None):\n    """"""Init _Downloader instance.\n\n    Args:\n      max_simultaneous_downloads: `int`, max number of simultaneous downloads.\n      checksumer: `hashlib.HASH`. Defaults to `hashlib.sha256`.\n    """"""\n    self._executor = concurrent.futures.ThreadPoolExecutor(\n        max_workers=max_simultaneous_downloads)\n    self._checksumer_cls = checksumer or hashlib.sha256\n    self._pbar_url = None\n    self._pbar_dl_size = None\n\n  @utils.memoize()\n  def kaggle_downloader(\n      self, competition_name: str) -> kaggle.KaggleCompetitionDownloader:\n    return kaggle.KaggleCompetitionDownloader(competition_name)\n\n  @contextlib.contextmanager\n  def tqdm(self) -> Iterator[None]:\n    """"""Add a progression bar for the current download.""""""\n    async_tqdm = utils.async_tqdm\n    with async_tqdm(total=0, desc=\'Dl Completed...\', unit=\' url\') as pbar_url:\n      with async_tqdm(total=0, desc=\'Dl Size...\', unit=\' MiB\') as pbar_dl_size:\n        self._pbar_url = pbar_url\n        self._pbar_dl_size = pbar_dl_size\n        yield\n\n  def download(self, url: str, destination_path: str):\n    """"""Download url to given path.\n\n    Returns Promise -> sha256 of downloaded file.\n\n    Args:\n      url: address of resource to download.\n      destination_path: `str`, path to directory where to download the resource.\n\n    Returns:\n      Promise obj -> (`str`, int): (downloaded object checksum, size in bytes).\n    """"""\n    self._pbar_url.update_total(1)\n    future = self._executor.submit(self._sync_download, url, destination_path)\n    return promise.Promise.resolve(future)\n\n  def _sync_kaggle_download(self, kaggle_url, destination_path):\n    """"""Download with Kaggle API.""""""\n    kaggle_file = kaggle.KaggleFile.from_url(kaggle_url)\n    downloader = self.kaggle_downloader(kaggle_file.competition)\n    filepath = downloader.download_file(kaggle_file.filename, destination_path)\n\n    dl_size = tf.io.gfile.stat(filepath).length\n    checksum = self._checksumer_cls()\n    with tf.io.gfile.GFile(filepath, \'rb\') as f:\n      while True:\n        block = f.read(io.DEFAULT_BUFFER_SIZE)\n        if not block:\n          break\n        checksum.update(block)\n    return checksums_lib.UrlInfo(\n        checksum=checksum.hexdigest(),\n        size=dl_size,\n    )\n\n  def _sync_file_copy(\n      self, filepath: str, destination_path: str) -> checksums_lib.UrlInfo:\n    out_path = os.path.join(destination_path, os.path.basename(filepath))\n    tf.io.gfile.copy(filepath, out_path)\n    hexdigest, size = utils.read_checksum_digest(\n        out_path, checksum_cls=self._checksumer_cls)\n    return checksums_lib.UrlInfo(checksum=hexdigest, size=size)\n\n  def _sync_download(\n      self, url: str, destination_path: str) -> checksums_lib.UrlInfo:\n    """"""Synchronous version of `download` method.\n\n    To download through a proxy, the `HTTP_PROXY`, `HTTPS_PROXY`,\n    `REQUESTS_CA_BUNDLE`,... environement variables can be exported, as\n    described in:\n    https://requests.readthedocs.io/en/master/user/advanced/#proxies\n\n    Args:\n      url: url to download\n      destination_path: path where to write it\n\n    Returns:\n      None\n\n    Raises:\n      DownloadError: when download fails.\n    """"""\n    if kaggle.KaggleFile.is_kaggle_url(url):\n      # Forward the request proxy to Kaggle tool\n      # See: https://github.com/Kaggle/kaggle-api\n      if \'HTTP_PROXY\' in os.environ:\n        os.environ[\'KAGGLE_PROXY\'] = os.environ[\'HTTP_PROXY\']\n      return self._sync_kaggle_download(url, destination_path)\n\n    try:\n      # If url is on a filesystem that gfile understands, use copy. Otherwise,\n      # use requests (http) or urllib (ftp).\n      if not url.startswith(\'http\'):\n        return self._sync_file_copy(url, destination_path)\n    except tf.errors.UnimplementedError:\n      pass\n\n    with _open_url(url) as (response, iter_content):\n      fname = _get_filename(response)\n      path = os.path.join(destination_path, fname)\n      size = 0\n\n      # Initialize the download size progress bar\n      size_mb = 0\n      unit_mb = units.MiB\n      total_size = int(response.headers.get(\'Content-length\', 0)) // unit_mb\n      self._pbar_dl_size.update_total(total_size)\n      with tf.io.gfile.GFile(path, \'wb\') as file_:\n        checksum = self._checksumer_cls()\n        for block in iter_content:\n          size += len(block)\n          checksum.update(block)\n          file_.write(block)\n\n          # Update the download size progress bar\n          size_mb += len(block)\n          if size_mb > unit_mb:\n            self._pbar_dl_size.update(size_mb // unit_mb)\n            size_mb %= unit_mb\n    self._pbar_url.update(1)\n    return checksums_lib.UrlInfo(checksum=checksum.hexdigest(), size=size)\n\n\ndef _open_url(url: str) -> ContextManager[Tuple[Response, Iterable[bytes]]]:\n  """"""Context manager to open an url.\n\n  Args:\n    url: The url to open\n\n  Returns:\n    response: The url response with `.url` and `.header` attributes.\n    iter_content: A `bytes` iterator which yield the content.\n  """"""\n  # Download FTP urls with `urllib`, otherwise use `requests`\n  open_fn = _open_with_urllib if url.startswith(\'ftp\') else _open_with_requests\n  return open_fn(url)\n\n\n@contextlib.contextmanager\ndef _open_with_requests(url: str) -> Iterator[Tuple[Response, Iterable[bytes]]]:\n  with requests.Session() as session:\n    if _DRIVE_URL.match(url):\n      url = _get_drive_url(url, session)\n    with session.get(url, stream=True) as response:\n      _assert_status(response)\n      yield (response, response.iter_content(chunk_size=io.DEFAULT_BUFFER_SIZE))\n\n\n@contextlib.contextmanager\ndef _open_with_urllib(url: str) -> Iterator[Tuple[Response, Iterable[bytes]]]:\n  with urllib.request.urlopen(url) as response:  # pytype: disable=attribute-error\n    yield (\n        response,\n        iter(functools.partial(response.read, io.DEFAULT_BUFFER_SIZE), b\'\'),\n    )\n\n\ndef _get_drive_url(url: str, session: requests.Session) -> str:\n  """"""Returns url, possibly with confirmation token.""""""\n  with session.get(url, stream=True) as response:\n    _assert_status(response)\n    for k, v in response.cookies.items():\n      if k.startswith(\'download_warning\'):\n        return url + \'&confirm=\' + v  # v is the confirm token\n  # No token found, let\'s try with original URL:\n  return url\n\n\ndef _assert_status(response: requests.Response) -> None:\n  """"""Ensure the URL response is 200.""""""\n  if response.status_code != 200:\n    raise DownloadError(\'Failed to get url {}. HTTP code: {}.\'.format(\n        response.url, response.status_code))\n'"
tensorflow_datasets/core/download/downloader_test.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for downloader.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nimport io\nimport os\nimport tempfile\n\nfrom absl.testing import absltest\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.download import downloader\nfrom tensorflow_datasets.core.download import resource as resource_lib\n\n\nclass _FakeResponse(object):\n\n  def __init__(self, url, content, cookies=None, headers=None, status_code=200):\n    self.url = url\n    self.raw = io.BytesIO(content)\n    self.cookies = cookies or {}\n    self.headers = headers or {\'Content-length\': 12345}\n    self.status_code = status_code\n    # For urllib codepath\n    self.read = self.raw.read\n\n  def __enter__(self):\n    return self\n\n  def __exit__(self, *args):\n    return\n\n  def iter_content(self, chunk_size):\n    del chunk_size\n    for line in self.raw:\n      yield line\n\n\nclass DownloaderTest(testing.TestCase):\n\n  def setUp(self):\n    super(DownloaderTest, self).setUp()\n    self.addCleanup(absltest.mock.patch.stopall)\n    self.downloader = downloader.get_downloader(10, hashlib.sha256)\n    self.tmp_dir = tempfile.mkdtemp(dir=tf.compat.v1.test.get_temp_dir())\n    self.url = \'http://example.com/foo.tar.gz\'\n    self.resource = resource_lib.Resource(url=self.url)\n    self.path = os.path.join(self.tmp_dir, \'foo.tar.gz\')\n    self.incomplete_path = \'%s.incomplete\' % self.path\n    self.response = b\'This \\nis an \\nawesome\\n response!\'\n    self.resp_checksum = hashlib.sha256(self.response).hexdigest()\n    self.cookies = {}\n    absltest.mock.patch.object(\n        downloader.requests.Session,\n        \'get\',\n        lambda *a, **kw: _FakeResponse(self.url, self.response, self.cookies),\n    ).start()\n    self.downloader._pbar_url = absltest.mock.MagicMock()\n    self.downloader._pbar_dl_size = absltest.mock.MagicMock()\n    absltest.mock.patch.object(\n        downloader.urllib.request,\n        \'urlopen\',\n        lambda *a, **kw: _FakeResponse(self.url, self.response, self.cookies),\n    ).start()\n\n  def test_ok(self):\n    promise = self.downloader.download(self.url, self.tmp_dir)\n    url_info = promise.get()\n    self.assertEqual(url_info.checksum, self.resp_checksum)\n    with tf.io.gfile.GFile(self.path, \'rb\') as result:\n      self.assertEqual(result.read(), self.response)\n    self.assertFalse(tf.io.gfile.exists(self.incomplete_path))\n\n  def test_drive_no_cookies(self):\n    url = \'https://drive.google.com/uc?export=download&id=a1b2bc3\'\n    promise = self.downloader.download(url, self.tmp_dir)\n    url_info = promise.get()\n    self.assertEqual(url_info.checksum, self.resp_checksum)\n    with tf.io.gfile.GFile(self.path, \'rb\') as result:\n      self.assertEqual(result.read(), self.response)\n    self.assertFalse(tf.io.gfile.exists(self.incomplete_path))\n\n  def test_drive(self):\n    self.cookies = {\'foo\': \'bar\', \'download_warning_a\': \'token\', \'a\': \'b\'}\n    self.test_drive_no_cookies()\n\n  def test_http_error(self):\n    error = downloader.requests.exceptions.HTTPError(\'Problem serving file.\')\n    absltest.mock.patch.object(\n        downloader.requests.Session, \'get\', side_effect=error).start()\n    promise = self.downloader.download(self.url, self.tmp_dir)\n    with self.assertRaises(downloader.requests.exceptions.HTTPError):\n      promise.get()\n\n  def test_bad_http_status(self):\n    absltest.mock.patch.object(\n        downloader.requests.Session,\n        \'get\',\n        lambda *a, **kw: _FakeResponse(self.url, b\'error\', status_code=404),\n    ).start()\n    promise = self.downloader.download(self.url, self.tmp_dir)\n    with self.assertRaises(downloader.DownloadError):\n      promise.get()\n\n  def test_kaggle_api(self):\n    fname = \'a.csv\'\n    with testing.mock_kaggle_api(filenames=[fname, \'b.txt\']):\n      # Testing Competition Downloader\n      promise = self.downloader.download(\n          \'kaggle://competition/some-competition/a.csv\',\n          self.tmp_dir)\n      url_info = promise.get()\n      self.assertEqual(url_info.size, len(fname))\n      with tf.io.gfile.GFile(os.path.join(self.tmp_dir, fname)) as f:\n        self.assertEqual(fname, f.read())\n\n      # Testing Dataset Downloader\n      promise = self.downloader.download(\n          \'kaggle://dataset/some-author/some-dataset/a.csv\',\n          self.tmp_dir)\n      url_info = promise.get()\n      self.assertEqual(url_info.size, len(fname))\n      with tf.io.gfile.GFile(os.path.join(self.tmp_dir, fname)) as f:\n        self.assertEqual(fname, f.read())\n\n  def test_ftp(self):\n    url = \'ftp://username:password@example.com/foo.tar.gz\'\n    promise = self.downloader.download(url, self.tmp_dir)\n    url_info = promise.get()\n    self.assertEqual(url_info.checksum, self.resp_checksum)\n    with tf.io.gfile.GFile(self.path, \'rb\') as result:\n      self.assertEqual(result.read(), self.response)\n    self.assertFalse(tf.io.gfile.exists(self.incomplete_path))\n\n  def test_ftp_error(self):\n    error = downloader.urllib.error.URLError(\'Problem serving file.\')\n    absltest.mock.patch.object(\n        downloader.urllib.request,\n        \'urlopen\',\n        side_effect=error,\n    ).start()\n    url = \'ftp://example.com/foo.tar.gz\'\n    promise = self.downloader.download(url, self.tmp_dir)\n    with self.assertRaises(downloader.urllib.error.URLError):\n      promise.get()\n\n\nclass GetFilenameTest(testing.TestCase):\n\n  def test_no_headers(self):\n    resp = _FakeResponse(\'http://foo.bar/baz.zip\', b\'content\')\n    res = downloader._get_filename(resp)\n    self.assertEqual(res, \'baz.zip\')\n\n  def test_headers(self):\n    cdisp = (\'attachment;filename=""hello.zip"";\'\n             \'filename*=UTF-8\\\'\\\'hello.zip\')\n    resp = _FakeResponse(\'http://foo.bar/baz.zip\', b\'content\', headers={\n        \'content-disposition\': cdisp,\n    })\n    res = downloader._get_filename(resp)\n    self.assertEqual(res, \'hello.zip\')\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/download/extractor.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Module to use to extract archives. No business logic.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport concurrent.futures\nimport contextlib\nimport gzip\nimport io\nimport os\nimport tarfile\nimport uuid\nimport zipfile\n\nfrom absl import logging\nimport promise\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import constants\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.download import resource as resource_lib\n\nif six.PY3:\n  import bz2  # pylint:disable=g-import-not-at-top\nelse:\n  # py2\'s built-in bz2 package does not support reading from file objects.\n  import bz2file as bz2  # pylint:disable=g-import-not-at-top\n\n\n@utils.memoize()\ndef get_extractor(*args, **kwargs):\n  return _Extractor(*args, **kwargs)\n\n\nclass ExtractError(Exception):\n  """"""There was an error while extracting the archive.""""""\n\n\nclass UnsafeArchiveError(Exception):\n  """"""The archive is unsafe to unpack, e.g. absolute path.""""""\n\n\nclass _Extractor(object):\n  """"""Singleton (use `get_extractor()` module fct) to extract archives.""""""\n\n  def __init__(self, max_workers=12):\n    self._executor = concurrent.futures.ThreadPoolExecutor(\n        max_workers=max_workers)\n    self._pbar_path = None\n\n  @contextlib.contextmanager\n  def tqdm(self):\n    """"""Add a progression bar for the current extraction.""""""\n    with utils.async_tqdm(\n        total=0, desc=\'Extraction completed...\', unit=\' file\') as pbar_path:\n      self._pbar_path = pbar_path\n      yield\n\n  def extract(self, path, extract_method, to_path):\n    """"""Returns `promise.Promise` => to_path.""""""\n    self._pbar_path.update_total(1)\n    if extract_method not in _EXTRACT_METHODS:\n      raise ValueError(\'Unknown extraction method ""%s"".\' % extract_method)\n    future = self._executor.submit(self._sync_extract,\n                                   path, extract_method, to_path)\n    return promise.Promise.resolve(future)\n\n  def _sync_extract(self, from_path, method, to_path):\n    """"""Returns `to_path` once resource has been extracted there.""""""\n    to_path_tmp = \'%s%s_%s\' % (to_path, constants.INCOMPLETE_SUFFIX,\n                               uuid.uuid4().hex)\n    path = None\n    dst_path = None  # To avoid undefined variable if exception is raised\n    try:\n      for path, handle in iter_archive(from_path, method):\n        path = tf.compat.as_text(path)\n        dst_path = path and os.path.join(to_path_tmp, path) or to_path_tmp\n        _copy(handle, dst_path)\n    except BaseException as err:\n      msg = \'Error while extracting {} to {} (file: {}) : {}\'.format(\n          from_path, to_path, path, err)\n      # Check if running on windows\n      if os.name == \'nt\' and dst_path and len(dst_path) > 250:\n        msg += (\n            \'\\n\'\n            \'On windows, path lengths greater than 260 characters may \'\n            \'result in an error. See the doc to remove the limiration: \'\n            \'https://docs.python.org/3/using/windows.html#removing-the-max-path-limitation\'\n        )\n      raise ExtractError(msg)\n    # `tf.io.gfile.Rename(overwrite=True)` doesn\'t work for non empty\n    # directories, so delete destination first, if it already exists.\n    if tf.io.gfile.exists(to_path):\n      tf.io.gfile.rmtree(to_path)\n    tf.io.gfile.rename(to_path_tmp, to_path)\n    self._pbar_path.update(1)\n    return to_path\n\n\ndef _copy(src_file, dest_path):\n  """"""Copy data read from src file obj to new file in dest_path.""""""\n  tf.io.gfile.makedirs(os.path.dirname(dest_path))\n  with tf.io.gfile.GFile(dest_path, \'wb\') as dest_file:\n    while True:\n      data = src_file.read(io.DEFAULT_BUFFER_SIZE)\n      if not data:\n        break\n      dest_file.write(data)\n\n\ndef _normpath(path):\n  path = os.path.normpath(path)\n  if (path.startswith(\'.\')\n      or os.path.isabs(path)\n      or path.endswith(\'~\')\n      or os.path.basename(path).startswith(\'.\')):\n    return None\n  return path\n\n\n@contextlib.contextmanager\ndef _open_or_pass(path_or_fobj):\n  if isinstance(path_or_fobj, six.string_types):\n    with tf.io.gfile.GFile(path_or_fobj, \'rb\') as f_obj:\n      yield f_obj\n  else:\n    yield path_or_fobj\n\n\ndef iter_tar(arch_f, stream=False):\n  """"""Iter over tar archive, yielding (path, object-like) tuples.\n\n  Args:\n    arch_f: File object of the archive to iterate.\n    stream: If True, open the archive in stream mode which allows for faster\n      processing and less temporary disk consumption, but random access to the\n      file is not allowed.\n\n  Yields:\n    (filepath, extracted_fobj) for each file in the archive.\n  """"""\n  read_type = \'r\' + (\'|\' if stream else \':\') + \'*\'\n\n  with _open_or_pass(arch_f) as fobj:\n    tar = tarfile.open(mode=read_type, fileobj=fobj)\n    for member in tar:\n      if stream and (member.islnk() or member.issym()):\n        # Links cannot be dereferenced in stream mode.\n        logging.warning(\'Skipping link during extraction: %s\', member.name)\n        continue\n      extract_file = tar.extractfile(member)\n      if extract_file:  # File with data (not directory):\n        path = _normpath(member.path)  # pytype: disable=attribute-error\n        if not path:\n          continue\n        yield [path, extract_file]\n\n\ndef iter_tar_stream(arch_f):\n  return iter_tar(arch_f, stream=True)\n\n\ndef iter_gzip(arch_f):\n  with _open_or_pass(arch_f) as fobj:\n    gzip_ = gzip.GzipFile(fileobj=fobj)\n    yield (\'\', gzip_)  # No inner file.\n\n\ndef iter_bzip2(arch_f):\n  with _open_or_pass(arch_f) as fobj:\n    bz2_ = bz2.BZ2File(filename=fobj)\n    yield (\'\', bz2_)  # No inner file.\n\n\ndef iter_zip(arch_f):\n  """"""Iterate over zip archive.""""""\n  with _open_or_pass(arch_f) as fobj:\n    z = zipfile.ZipFile(fobj)\n    for member in z.infolist():\n      extract_file = z.open(member)\n      if member.is_dir():  # Filter directories  # pytype: disable=attribute-error\n        continue\n      path = _normpath(member.filename)\n      if not path:\n        continue\n      yield [path, extract_file]\n\n\n_EXTRACT_METHODS = {\n    resource_lib.ExtractMethod.BZIP2: iter_bzip2,\n    resource_lib.ExtractMethod.GZIP: iter_gzip,\n    resource_lib.ExtractMethod.TAR: iter_tar,\n    resource_lib.ExtractMethod.TAR_GZ: iter_tar,\n    resource_lib.ExtractMethod.TAR_GZ_STREAM: iter_tar_stream,\n    resource_lib.ExtractMethod.TAR_STREAM: iter_tar_stream,\n    resource_lib.ExtractMethod.ZIP: iter_zip,\n}\n\n\ndef iter_archive(path, method):\n  """"""Iterate over an archive.\n\n  Args:\n    path: `str`, archive path\n    method: `tfds.download.ExtractMethod`, extraction method\n\n  Returns:\n    An iterator of `(path_in_archive, f_obj)`\n  """"""\n  return _EXTRACT_METHODS[method](path)\n'"
tensorflow_datasets/core/download/extractor_test.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for extractor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl.testing import absltest\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.download import extractor\nfrom tensorflow_datasets.core.download import resource as resource_lib\n\nBZIP2 = resource_lib.ExtractMethod.BZIP2\nGZIP = resource_lib.ExtractMethod.GZIP\nNO_EXTRACT = resource_lib.ExtractMethod.NO_EXTRACT\nTAR = resource_lib.ExtractMethod.TAR\nTAR_GZ = resource_lib.ExtractMethod.TAR_GZ\nZIP = resource_lib.ExtractMethod.ZIP\nTAR_STREAM = resource_lib.ExtractMethod.TAR_STREAM\nTAR_GZ_STREAM = resource_lib.ExtractMethod.TAR_GZ_STREAM\n\n\ndef _read(path):\n  with tf.io.gfile.GFile(path, \'rb\') as f:\n    return f.read()\n\n\nclass ExtractorTest(testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(ExtractorTest, cls).setUpClass()\n    f1_path = os.path.join(cls.test_data, \'6pixels.png\')\n    f2_path = os.path.join(cls.test_data, \'foo.csv\')\n    with tf.io.gfile.GFile(f1_path, \'rb\') as f1_f:\n      cls.f1_content = f1_f.read()\n    with tf.io.gfile.GFile(f2_path, \'rb\') as f2_f:\n      cls.f2_content = f2_f.read()\n\n  def setUp(self):\n    super(ExtractorTest, self).setUp()\n    self.extractor = extractor.get_extractor()\n    self.extractor._pbar_path = absltest.mock.MagicMock()\n    # Where archive will be extracted:\n    self.to_path = os.path.join(self.tmp_dir, \'extracted_arch\')\n    # Obviously it must not exist before test runs:\n    self.assertFalse(tf.io.gfile.exists(self.to_path))\n\n    self.result_path = os.path.join(self.to_path, \'6pixels.png\')\n\n  def test_unknown_method(self):\n    with self.assertRaises(ValueError):\n      self.extractor.extract(\'from/path\', NO_EXTRACT, \'to/path\')\n\n  def _test_extract(self, method, archive_name, expected_files):\n    from_path = os.path.join(self.test_data, \'archives\', archive_name)\n    self.extractor.extract(from_path, method, self.to_path).get()\n    for name, content in expected_files.items():\n      path = os.path.join(self.to_path, name)\n      self.assertEqual(_read(path), content, \'File %s has bad content.\' % path)\n\n  def test_zip(self):\n    self._test_extract(\n        ZIP, \'arch1.zip\',\n        {\'6pixels.png\': self.f1_content, \'foo.csv\': self.f2_content})\n\n  def test_tar(self):\n    self._test_extract(\n        TAR, \'arch1.tar\',\n        {\'6pixels.png\': self.f1_content, \'foo.csv\': self.f2_content})\n\n  def test_targz(self):\n    self._test_extract(\n        TAR_GZ, \'arch1.tar.gz\',\n        {\'6pixels.png\': self.f1_content, \'foo.csv\': self.f2_content})\n\n  def test_tar_stream(self):\n    self._test_extract(\n        TAR_STREAM, \'arch1.tar\',\n        {\'6pixels.png\': self.f1_content, \'foo.csv\': self.f2_content})\n\n  def test_targz_stream(self):\n    self._test_extract(\n        TAR_GZ_STREAM, \'arch1.tar.gz\',\n        {\'6pixels.png\': self.f1_content, \'foo.csv\': self.f2_content})\n\n  def test_gzip(self):\n    from_path = os.path.join(self.test_data, \'archives\', \'arch1.tar.gz\')\n    self.extractor.extract(from_path, GZIP, self.to_path).get()\n    arch1_path = os.path.join(self.test_data, \'archives\', \'arch1.tar\')\n    self.assertEqual(_read(self.to_path), _read(arch1_path))\n\n  def test_gzip2(self):\n    # Same as previous test, except it is not a .tar.gz, but a .gz.\n    from_path = os.path.join(self.test_data, \'archives\', \'foo.csv.gz\')\n    self.extractor.extract(from_path, GZIP, self.to_path).get()\n    foo_csv_path = os.path.join(self.test_data, \'foo.csv\')\n    self.assertEqual(_read(self.to_path), _read(foo_csv_path))\n\n  def test_bzip2(self):\n    from_path = os.path.join(self.test_data, \'archives\', \'foo.csv.bz2\')\n    self.extractor.extract(from_path, BZIP2, self.to_path).get()\n    foo_csv_path = os.path.join(self.test_data, \'foo.csv\')\n    self.assertEqual(_read(self.to_path), _read(foo_csv_path))\n\n  def test_absolute_path(self):\n    # There is a file with absolute path (ignored) + a file named ""foo"".\n    self._test_extract(TAR, \'absolute_path.tar\', {\'foo\': b\'bar\\n\'})\n\n  def test_wrong_method(self):\n    from_path = os.path.join(self.test_data, \'archives\', \'foo.csv.gz\')\n    promise = self.extractor.extract(from_path, ZIP, self.to_path)\n    expected_msg = \'File is not a zip file\'\n    with self.assertRaisesWithPredicateMatch(\n        extractor.ExtractError, expected_msg):\n      promise.get()\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/download/kaggle.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Data downloads using the Kaggle CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport subprocess as sp\nimport zipfile\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.download import extractor\nfrom tensorflow_datasets.core.download import resource\n\n_ERR_MSG = """"""\\\nTo download Kaggle data through TFDS, follow the instructions to install the \\\nkaggle API and get API credentials:\nhttps://github.com/Kaggle/kaggle-api#installation\n\nAdditionally, you must join the competition through the Kaggle competition\'s \\\nwebsite:\nhttps://www.kaggle.com/c/%s\n""""""\n\n_NOT_FOUND_ERR_MSG = """"""\\\nCompetition %s not found. Please ensure you have spelled the competition name \\\ncorrectly.\n""""""\n\nKaggleType = collections.namedtuple(\n    ""KaggleType"",\n    [""prefix"", ""download_cmd"", ""dl_flag"", ""extra_flag""])\n\n_KAGGLE_TYPES = {\n    ""dataset"": KaggleType(\n        prefix=""dataset"",\n        download_cmd=""datasets"",\n        dl_flag=""-d"",\n        extra_flag=""--unzip""),\n    ""competition"": KaggleType(\n        prefix=""competition"",\n        download_cmd=""competitions"",\n        dl_flag=""-c"",\n        extra_flag="""")\n}\n\n\ndef _get_kaggle_type(competition_name):\n  if ""/"" in competition_name:\n    return _KAGGLE_TYPES[""dataset""]\n  return _KAGGLE_TYPES[""competition""]\n\n\nclass KaggleFile(object):\n  """"""Represents a Kaggle competition file.""""""\n  _URL_PREFIX = ""kaggle://""\n\n  def __init__(self, competition_name, filename):\n    self._competition_name = competition_name\n    self._filename = filename\n    self.type = _get_kaggle_type(competition_name)\n\n  @property\n  def competition(self):\n    return self._competition_name\n\n  @property\n  def filename(self):\n    return self._filename\n\n  @classmethod\n  def from_url(cls, url):\n    if not KaggleFile.is_kaggle_url(url):\n      raise TypeError(""Not a valid kaggle URL"")\n    download_type, competition_name, filename = (\n        url[len(cls._URL_PREFIX):].split(""/"", 2))\n    if download_type == ""dataset"":\n      dataset_name, filename = filename.split(""/"", 1)\n      competition_name = ""%s/%s"" % (competition_name, dataset_name)\n    return cls(competition_name, filename)\n\n  @staticmethod\n  def is_kaggle_url(url):\n    return url.startswith(KaggleFile._URL_PREFIX)\n\n  def to_url(self):\n    return ""%s%s/%s/%s"" % (self._URL_PREFIX,\n                           self.type.prefix,\n                           self._competition_name,\n                           self._filename)\n\n\nclass KaggleCompetitionDownloader(object):\n  """"""Downloader for a Kaggle competition.\n\n  Usage:\n  You can download with dataset or competition name like `zillow/zecon`\n  or `titanic`.\n\n  ```\n  downloader = KaggleCompetitionDownloader(competition_name)\n  for fname in downloader.competition_files:\n    downloader.download_file(fname, make_file_output_path(fname))\n  ```\n  """"""\n\n  def __init__(self, competition_name):\n    self._competition_name = competition_name\n    self._kaggle_type = _get_kaggle_type(self._competition_name)\n\n  @utils.memoized_property\n  def competition_files(self):\n    """"""List of competition files.""""""\n    command = [\n        ""kaggle"",\n        self._kaggle_type.download_cmd,\n        ""files"",\n        ""-v"",\n        self._competition_name,\n    ]\n    output = _run_kaggle_command(command, self._competition_name)\n    return sorted([\n        line.split("","")[0] for line in output.split(""\\n"")[1:] if line\n    ])\n\n  @utils.memoized_property\n  def competition_urls(self):\n    """"""Returns \'kaggle://\' urls.""""""\n    return [\n        KaggleFile(self._competition_name, fname).to_url()\n        for fname in self.competition_files  # pylint: disable=not-an-iterable\n    ]\n\n  def download_file(self, fname, output_dir):\n    """"""Downloads competition file to output_dir.""""""\n    if fname not in self.competition_files:  # pylint: disable=unsupported-membership-test\n      raise ValueError(""%s is not one of the competition\'s ""\n                       ""files: %s"" % (fname, self.competition_files))\n    command = [\n        ""kaggle"",\n        self._kaggle_type.download_cmd,\n        ""download"",\n        ""--file"",\n        fname,\n        ""--path"",\n        output_dir,\n        self._kaggle_type.dl_flag,\n        self._competition_name\n    ]\n    if self._kaggle_type.extra_flag:\n      command.append(self._kaggle_type.extra_flag)\n    _run_kaggle_command(command, self._competition_name)\n    # kaggle silently compresses some files to \'.zip` files.\n    # TODO(tfds): use --unzip once supported by kaggle\n    # (https://github.com/Kaggle/kaggle-api/issues/9)\n    fpath = os.path.join(output_dir, fname + "".zip"")\n    if zipfile.is_zipfile(fpath):\n      e = extractor.get_extractor()\n      with e.tqdm():\n        e.extract(fpath, resource.ExtractMethod.ZIP, output_dir).get()\n    return os.path.join(output_dir, fname)\n\n\ndef _run_kaggle_command(command_args, competition_name):\n  """"""Run kaggle command with subprocess.""""""\n  try:\n    output = sp.check_output(command_args)\n    return tf.compat.as_text(output)\n  except sp.CalledProcessError as err:\n    output = err.output\n    _log_command_output(output, error=True)\n    if output.startswith(b""404""):\n      logging.error(_NOT_FOUND_ERR_MSG, competition_name)\n      raise\n    logging.error(_ERR_MSG, competition_name)\n    raise\n\n\ndef _log_command_output(output, error=False):\n  log = logging.error if error else logging.info\n  log(""kaggle command output:\\n%s"", tf.compat.as_text(output))\n'"
tensorflow_datasets/core/download/kaggle_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Kaggle API.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.download import kaggle\n\n\nclass KaggleTest(testing.TestCase):\n\n  def test_competition_download(self):\n    filenames = [""a"", ""b""]\n    with testing.mock_kaggle_api(filenames):\n      downloader = kaggle.KaggleCompetitionDownloader(""digit-recognizer"")\n      self.assertEqual(downloader.competition_files, [""a"", ""b""])\n      with testing.tmp_dir() as tmp_dir:\n        for fname in downloader.competition_files:\n          out_path = downloader.download_file(fname, tmp_dir)\n          self.assertEqual(out_path, os.path.join(tmp_dir, fname))\n          with tf.io.gfile.GFile(out_path) as f:\n            self.assertEqual(fname, f.read())\n\n  def test_competition_download_404(self):\n    with testing.mock_kaggle_api(err_msg=""404 - Not found""):\n      with self.assertLogs(\n          ""spelled the competition name correctly"", level=""error""):\n        downloader = kaggle.KaggleCompetitionDownloader(""digit-recognizer"")\n        with self.assertRaises(subprocess.CalledProcessError):\n          _ = downloader.competition_files\n\n  def test_competition_download_error(self):\n    with testing.mock_kaggle_api(err_msg=""Some error""):\n      with self.assertLogs(""install the kaggle API"", level=""error""):\n        downloader = kaggle.KaggleCompetitionDownloader(""digit-recognizer"")\n        with self.assertRaises(subprocess.CalledProcessError):\n          _ = downloader.competition_files\n\n  def test_kaggle_type(self):\n    downloader = kaggle.KaggleCompetitionDownloader(""digit-recognizer"")\n    self.assertEqual(downloader._kaggle_type.download_cmd, ""competitions"")\n\n    downloader = kaggle.KaggleCompetitionDownloader(""author/dataset"")\n    self.assertEqual(downloader._kaggle_type.download_cmd, ""datasets"")\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/download/resource.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes to specify download or extraction information.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport base64\nimport codecs\nimport enum\nimport hashlib\nimport itertools\nimport json\nimport os\nimport re\nfrom typing import Any\n\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core.download import checksums as checksums_lib\nfrom tensorflow_datasets.core.utils import py_utils\n\n# Should be `Union[int, float, bool, str, Dict[str, Json], List[Json]]`\nJson = Any\n\n\n_hex_codec = codecs.getdecoder(\'hex_codec\')\n\n\ndef _decode_hex(hexstr):\n  """"""Returns binary digest, given str hex digest.""""""\n  return _hex_codec(hexstr)[0]\n\n\nclass ExtractMethod(enum.Enum):\n  """"""The extraction method to use to pre-process a downloaded file.""""""\n  NO_EXTRACT = 1\n  TAR = 2\n  TAR_GZ = 3  # Deprecated: use TAR.\n  GZIP = 4\n  ZIP = 5\n  BZIP2 = 6\n  TAR_STREAM = 7\n  TAR_GZ_STREAM = 8  # Deprecated: use TAR_STREAM\n\n\n_EXTRACTION_METHOD_TO_EXTS = [\n    (ExtractMethod.TAR_GZ, [\'.tar.gz\', \'.tgz\']),\n    (ExtractMethod.TAR, [\'.tar\', \'.tar.bz2\', \'.tbz2\', \'.tbz\', \'.tb2\']),\n    (ExtractMethod.ZIP, [\'.zip\']),\n    (ExtractMethod.GZIP, [\'.gz\']),\n    (ExtractMethod.BZIP2, [\'.bz2\']),\n]\n\n_KNOWN_EXTENSIONS = [\n    ext_ for ext_ in itertools.chain(  # pylint: disable=g-complex-comprehension\n        *[extensions_ for _, extensions_ in _EXTRACTION_METHOD_TO_EXTS])]\n\n_NETLOC_COMMON_PREFIXES = [\n    \'www.\',\n    \'storage.googleapis.com\',\n    \'drive.google.com\',\n    \'github.com\',\n]\n\n_NETLOC_COMMON_SUFFIXES = [\n    \'.github.io\',\n    \'.s3-website.eu-central-1.amazonaws.com\',\n    \'.amazonaws.com\',  # Must be kept after the other amazonaws.com subdomains.\n]\n\n_URL_COMMON_PARTS = [\n    \'_data_\',\n    \'_dataset_\',\n    \'_static_\',\n    \'_of_\',\n    \'-of-\',\n]\n\n\ndef _guess_extract_method(fname):\n  """"""Guess extraction method, given file name (or path).""""""\n  for method, extensions in _EXTRACTION_METHOD_TO_EXTS:\n    for ext in extensions:\n      if fname.endswith(ext):\n        return method\n  return ExtractMethod.NO_EXTRACT\n\n\ndef _sanitize_url(url, max_length):\n  """"""Sanitize and shorten url to fit in max_length.\n\n  Function is stable: same input MUST ALWAYS give same result, accros changes\n  in code as well. Different URLs might give same result.\n  As much as possible, the extension should be kept.\n\n  Heuristics are applied to only keep useful info from url.\n\n  1- Drop generic [sub]domains.\n    \'www.cs.toronto.edu/...\' -> \'cs.toronto.edu/...\'\n    \'storage.googleapis.com/foo/...\' -> \'foo/...\'\n    \'drive.google.com/bar/...\' -> \'bar/...\'\n    \'github.com/baz/...\' -> \'baz/...\'\n\n  2- Remove leading \'0\'s from url components:\n    \'foo/train-00004-of-00010.tfrecords\' -> \'foo/train-4-of-10.tfrecords\'\n\n  3- Truncate each component of url until total size fits or each component is\n     left with 4 chars (or total size is <= limit):\n     \'MoveUnitToBorder_64x64_png/train-4-of-10.tfrecords\'\n     (here truncate components to 4 chars per component max)\n      -> \'Move_64x6_png/trai-4-of-10.tfrecords\'\n\n  4- Truncate result, keeping prefix: \'abc_def_ghi_jkl\' -> \'abc_def\'\n\n  Args:\n    url: string, url to sanitize and shorten.\n    max_length: int, max length of result.\n\n  Returns:\n    (string, string): sanitized and shorted url, file extension.\n  """"""\n  url = urllib.parse.urlparse(url)\n  netloc = url.netloc\n  for prefix in _NETLOC_COMMON_PREFIXES:\n    if netloc.startswith(prefix):\n      netloc = netloc[len(prefix):]\n  for suffix in _NETLOC_COMMON_SUFFIXES:\n    if netloc.endswith(suffix):\n      netloc = netloc[:-len(suffix)]\n  url = \'%s%s%s%s\' % (netloc, url.path, url.params, url.query)\n  # Get the extension:\n  for ext in _KNOWN_EXTENSIONS:\n    if url.endswith(ext):\n      extension = ext\n      url = url[:-len(extension)]\n      break\n  else:\n    url, extension = os.path.splitext(url)\n  max_length -= len(extension)\n  # Replace non authorized chars (including \'/\') by \'_\':\n  url = re.sub(r\'[^a-zA-Z0-9\\.\\-_]+\', \'_\', url)\n  # Remove parts with no info:\n  for common_part in _URL_COMMON_PARTS:\n    url = url.replace(common_part, \'_\')\n  url = url.strip(\'_\')\n  # Remove leading zeros in groups of numbers:\n  url = re.sub(\'(?<![0-9])0+(?=[0-9])\', \'\', url)\n  # Decrease max size of URL components:\n  c_size = max(len(c) for c in re.split(r\'[\\.\\-_]\', url))\n  while c_size > 4 and len(url) > max_length:\n    c_size -= 1\n    url = re.sub(r\'[^\\.\\-_]{4,}\', lambda match: match.group(0)[:c_size], url)\n  return url[:max_length], extension\n\n\ndef get_dl_fname(url, checksum):\n  """"""Returns name of file for (url, checksum).\n\n  The max length of linux and windows filenames is 255 chars.\n  Windows however expects short paths (260 chars), so we limit the file name\n  to an arbitrary 90 chars.\n\n  Naming pattern: \'{url}{checksum}\'.\n   - url: url sanitized and shortened to 46 chars.\n   - checksum: base64url encoded sha256: 44 chars (removing trailing \'=\').\n\n  Args:\n    url: `str`, url of the file.\n    checksum: `str` (hex), the sha256 hexdigest of file or url.\n\n  Returns:\n    string of 90 chars max.\n  """"""\n  checksum = base64.urlsafe_b64encode(_decode_hex(checksum))  # pytype: disable=wrong-arg-types\n  checksum = tf.compat.as_text(checksum)[:-1]\n  name, extension = _sanitize_url(url, max_length=46)\n  return \'%s%s%s\' % (name, checksum, extension)\n\n\ndef get_dl_dirname(url):\n  """"""Returns name of temp dir for given url.""""""\n  checksum = hashlib.sha256(tf.compat.as_bytes(url)).hexdigest()\n  return get_dl_fname(url, checksum)\n\n\ndef _get_info_path(path):\n  """"""Returns path (`str`) of INFO file associated with resource at path.""""""\n  return \'%s.INFO\' % path\n\n\ndef _read_info(info_path) -> Json:\n  """"""Returns info dict or None.""""""\n  if not tf.io.gfile.exists(info_path):\n    return None\n  with tf.io.gfile.GFile(info_path) as info_f:\n    return json.load(info_f)\n\n\n# TODO(pierrot): one lock per info path instead of locking everything.\nsynchronize_decorator = py_utils.build_synchronize_decorator()\n\n\ndef rename_info_file(\n    src_path: str,\n    dst_path: str,\n    overwrite: bool = False,\n) -> None:\n  tf.io.gfile.rename(\n      _get_info_path(src_path), _get_info_path(dst_path), overwrite=overwrite)\n\n\n@synchronize_decorator\ndef read_info_file(info_path: str) -> Json:\n  return _read_info(_get_info_path(info_path))\n\n\n@synchronize_decorator\ndef write_info_file(\n    resource: \'Resource\',\n    path: str,\n    dataset_name: str,\n    original_fname: str,\n    url_info: checksums_lib.UrlInfo,\n) -> None:\n  """"""Write the INFO file next to local file.\n\n  Although the method is synchronized, there is still a risk two processes\n  running at the same time overlap here. Risk accepted, since potentially lost\n  data (`dataset_name`) is only for human consumption.\n\n  Args:\n    resource: resource for which to write the INFO file.\n    path: path of downloaded file.\n    dataset_name: data used to dl the file.\n    original_fname: name of file as downloaded.\n    url_info: checksums/size info of the url\n  """"""\n  url_info_dict = url_info.asdict()\n  info_path = _get_info_path(path)\n  info = _read_info(info_path) or {}\n  urls = set(info.get(\'urls\', []) + [resource.url])\n  dataset_names = info.get(\'dataset_names\', [])\n  if dataset_name:\n    dataset_names.append(dataset_name)\n  if info.get(\'original_fname\', original_fname) != original_fname:\n    raise ValueError(\n        \'`original_fname` ""{}"" stored in {} does NOT match ""{}"".\'.format(\n            info[\'original_fname\'], info_path, original_fname))\n  if info.get(\'url_info\', url_info_dict) != url_info_dict:\n    raise ValueError(\n        \'File info {} contains a different checksum that the downloaded one: \'\n        \'Stored: {}; Expected: {}\'.format(\n            info_path, info[\'url_info\'], url_info_dict))\n  info = dict(\n      urls=list(urls),\n      dataset_names=list(set(dataset_names)),\n      original_fname=original_fname,\n      url_info=url_info_dict,\n  )\n  with py_utils.atomic_write(info_path, \'w\') as info_f:\n    json.dump(info, info_f, sort_keys=True)\n\n\ndef get_extract_method(path):\n  """"""Returns `ExtractMethod` to use on resource at path. Cannot be None.""""""\n  info_path = _get_info_path(path)\n  info = _read_info(info_path)\n  fname = info.get(\'original_fname\', path) if info else path\n  return _guess_extract_method(fname)\n\n\nclass Resource(object):\n  """"""Represents a resource to download, extract, or both.""""""\n\n  @api_utils.disallow_positional_args()\n  def __init__(self,\n               url=None,\n               extract_method=None,\n               path=None):\n    """"""Resource constructor.\n\n    Args:\n      url: `str`, the URL at which to download the resource.\n      extract_method: `ExtractMethod` to be used to extract resource. If\n        not set, will be guessed from downloaded file name `original_fname`.\n      path: `str`, path of resource on local disk. Can be None if resource has\n        not be downloaded yet. In such case, `url` must be set.\n    """"""\n    self.url = url\n    self.path = path\n    self._extract_method = extract_method\n\n  @classmethod\n  def exists_locally(cls, path):\n    """"""Returns whether the resource exists locally, at `resource.path`.""""""\n    # If INFO file doesn\'t exist, consider resource does NOT exist, as it would\n    # prevent guessing the `extract_method`.\n    return (tf.io.gfile.exists(path) and\n            tf.io.gfile.exists(_get_info_path(path)))\n\n  @property\n  def extract_method(self):\n    """"""Returns `ExtractMethod` to use on resource. Cannot be None.""""""\n    if self._extract_method:\n      return self._extract_method\n    return get_extract_method(self.path)\n'"
tensorflow_datasets/core/download/resource_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for resource module.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.download import resource\n\nNO_EXTRACT = resource.ExtractMethod.NO_EXTRACT\nTAR = resource.ExtractMethod.TAR\nTAR_GZ = resource.ExtractMethod.TAR_GZ\nGZIP = resource.ExtractMethod.GZIP\nZIP = resource.ExtractMethod.ZIP\nBZIP2 = resource.ExtractMethod.BZIP2\n\n\nclass GuessExtractMethodTest(testing.TestCase):\n\n  def test_(self):\n    for fname, expected_result in [\n        (\'bar.tar.gz\', TAR_GZ),\n        (\'bar.gz\', GZIP),\n        (\'bar.tar.zip\', ZIP),\n        (\'bar.gz.strange\', NO_EXTRACT),\n        (\'bar.tar\', TAR),\n        (\'bar.tar.bz2\', TAR),\n        (\'bar.bz2\', BZIP2),\n    ]:\n      res = resource._guess_extract_method(fname)\n      self.assertEqual(res, expected_result, \'(%s)->%s instead of %s\' % (\n          fname, res, expected_result))\n\n\nclass DlDirNameTest(testing.TestCase):\n  urls = \'\'\'\\\nhttp://data.statmt.org/wmt17/translation-task/dev.tgz\nhttp://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz\nhttp://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nhttp://ufldl.stanford.edu/housenumbers/test_32x32.mat\nhttp://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz\nhttp://www.statmt.org/wmt13/training-parallel-europarl-v7.tgz\nhttp://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nhttp://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nhttps://drive.google.com/uc?export=download&id=0B7EVK8r0v71pd0FJY3Blby1HUTQ\nhttps://github.com/brendenlake/omniglot/raw/master/python/images_background_small2.zip\nhttps://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\nhttps://storage.googleapis.com/scv_dataset/data/Brawl_64x64_png/valid-00000-of-00001.tfrecords\nhttps://storage.googleapis.com/scv_dataset/data/CollectMineralShards_128x128_png/train-00005-of-00010.tfrecords\nhttps://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\\\n\'\'\'.split(\'\\n\')\n  expected = \'\'\'\\\ndata.statmt.org_wmt17_translation-task_devDjZ11PU9sKPPvF2sZTAzTsV7Pi3IYHaPDMOoeEuby2E.tgz\ndata.stat.org_wmt1_tran-task_trai-para-nc-6LWgxBgzCHdv_LtotNmnXjpCH6OhzkF8D3v10aRrznA.tgz\nfashion-mnist_train-images-idx3-ubytepR2BibiiUp2twRbpoktblvl2KbaPDel0VUV9KrXm91Y.gz\nufldl.stanford.edu_housenumbers_test_32x32kIzM03CdHZsHqtImuAxFCXPGHhEH4JT7Owsqi_QawO4.mat\nstat.org_lm-benc_1-bill-word-lang-mode-fPxXes4bTZ_y2eAI2mGRqBKUvUJm1CS1Idm0DH98KN8.tar.gz\nstatmt.org_wmt13_traini-parall-europa-v71cKcs9sx8w9ctm8xHloEI83SJqzD7piDNK3xUXpQIB4.tgz\nyann.lecu.com_exdb_mnis_trai-imag-idx3-ubyt5m0Lc_VeEzGZ1PUycLKoWNyYkH_vWEKNi0mu7m4Hmbk.gz\nyann.lecu.com_exdb_mnis_trai-labe-idx1-ubyt7cc_IeM51G_ngIY2ORleKjMjLVCXd-TCUHlYvEiRiKI.gz\nucexport_download_id_0B7EVK8r0v71pd0FJY3Blby1HbdQ1eXJPJLYv0yq8hL1lCD5T2aOraaQwvj25ndmE7pg\nbren_omni_raw_mast_pyth_imag_back_smalUSA8LkdUW89lgXr31txDoVFbI9BtQhxvtZWYTIdAJAg.zip\nrajpurkar_SQuAD-explorer_train-v1.1uLsZc14btZFRCgHMAy9Mn5abwO6wga4bMozTBvOyQAg.json\nscv_Brawl_64x64_png_valid-0_1Ez3yPwN0QDCxBd0xHeLb2DfUERJjkqFd2dyL5Z7-ULg.tfrecords\nscv_CollectMi_128x128_png_train-5_10kiunW_2RTDhXuPrxCVkUZKCoWpADYBUWE8DpraC8zAA.tfrecords\ncs.toronto.edu_kriz_cifar-100-pythonJDFhDchdt5UW8GUAkvf_-H_r_LnFs6sHlOrqTidrpSI.tar.gz\\\n\'\'\'.split(\'\\n\')\n\n  def test_(self):\n    for url, expected in zip(self.urls, self.expected):\n      res = resource.get_dl_dirname(url)\n      self.assertEqual(res, expected)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/download/util.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utils functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\n\n\nclass GenerateMode(enum.Enum):\n  """"""`Enum` for how to treat pre-existing downloads and data.\n\n  The default mode is `REUSE_DATASET_IF_EXISTS`, which will reuse both\n  raw downloads and the prepared dataset if they exist.\n\n  The generations modes:\n\n  |                                    | Downloads | Dataset |\n  | -----------------------------------|-----------|---------|\n  | `REUSE_DATASET_IF_EXISTS` (default)| Reuse     | Reuse   |\n  | `REUSE_CACHE_IF_EXISTS`            | Reuse     | Fresh   |\n  | `FORCE_REDOWNLOAD`                 | Fresh     | Fresh   |\n  """"""\n\n  REUSE_DATASET_IF_EXISTS = \'reuse_dataset_if_exists\'\n  REUSE_CACHE_IF_EXISTS = \'reuse_cache_if_exists\'\n  FORCE_REDOWNLOAD = \'force_redownload\'\n\n\nclass ComputeStatsMode(enum.Enum):\n  """"""Mode to decide if dynamic dataset info fields should be computed or not.\n\n  Mode can be:\n\n  * AUTO: Compute the DatasetInfo dynamic fields only if they haven\'t been\n    restored from GCS.\n  * FORCE: Always recompute DatasetInfo dynamic  fields, even if they are\n    already present\n  * SKIP: Ignore the dataset dynamic field computation (whether they already\n    exist or not)\n\n  """"""\n\n  AUTO = \'auto\'\n  FORCE = \'force\'\n  SKIP = \'skip\'\n'"
tensorflow_datasets/core/features/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""`tfds.features.FeatureConnector` API defining feature types.""""""\n\nfrom tensorflow_datasets.core.features import text\n\nfrom tensorflow_datasets.core.features.audio_feature import Audio\nfrom tensorflow_datasets.core.features.bounding_boxes import BBox\nfrom tensorflow_datasets.core.features.bounding_boxes import BBoxFeature\nfrom tensorflow_datasets.core.features.class_label_feature import ClassLabel\nfrom tensorflow_datasets.core.features.feature import FeatureConnector\nfrom tensorflow_datasets.core.features.feature import Tensor\nfrom tensorflow_datasets.core.features.feature import TensorInfo\nfrom tensorflow_datasets.core.features.features_dict import FeaturesDict\nfrom tensorflow_datasets.core.features.image_feature import Image\nfrom tensorflow_datasets.core.features.sequence_feature import Sequence\nfrom tensorflow_datasets.core.features.text_feature import Text\nfrom tensorflow_datasets.core.features.translation_feature import Translation\nfrom tensorflow_datasets.core.features.translation_feature import TranslationVariableLanguages\nfrom tensorflow_datasets.core.features.video_feature import Video\n\n__all__ = [\n    ""text"",\n    ""Audio"",\n    ""BBox"",\n    ""BBoxFeature"",\n    ""ClassLabel"",\n    ""FeatureConnector"",\n    ""FeaturesDict"",\n    ""Tensor"",\n    ""TensorInfo"",\n    ""Sequence"",\n    ""Image"",\n    ""Text"",\n    ""Video"",\n]\n'"
tensorflow_datasets/core/features/audio_feature.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Audio feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core.features import feature\n\n\nclass Audio(feature.Tensor):\n  """"""`FeatureConnector` for audio, encoded as raw integer wave form.""""""\n\n  @api_utils.disallow_positional_args\n  def __init__(\n      self,\n      file_format=None,\n      shape=(None,),\n      dtype=tf.int64,\n      sample_rate=None,\n  ):\n    """"""Constructs the connector.\n\n    Args:\n      file_format: `str`, the audio file format. Can be any format ffmpeg\n        understands. If `None`, will attempt to infer from the file extension.\n      shape: `tuple`, shape of the data.\n      dtype: The dtype of the data.\n      sample_rate: `int`, additional metadata exposed to the user through\n        `info.features[\'audio\'].sample_rate`. This value isn\'t used neither in\n        encoding nor decoding.\n    """"""\n    self._file_format = file_format\n    if len(shape) != 1:\n      raise TypeError(\n          ""Audio feature currently only supports 1-D values, got %s."" % shape)\n    self._shape = shape\n    self._sample_rate = sample_rate\n    super(Audio, self).__init__(shape=shape, dtype=dtype)\n\n  def _encode_file(self, fobj, file_format):\n    audio_segment = lazy_imports_lib.lazy_imports.pydub.AudioSegment.from_file(\n        fobj, format=file_format)\n    np_dtype = np.dtype(self.dtype.as_numpy_dtype)\n    return super(Audio, self).encode_example(\n        np.array(audio_segment.get_array_of_samples()).astype(np_dtype))\n\n  def encode_example(self, audio_or_path_or_fobj):\n    if isinstance(audio_or_path_or_fobj, (np.ndarray, list)):\n      return audio_or_path_or_fobj\n    elif isinstance(audio_or_path_or_fobj, six.string_types):\n      filename = audio_or_path_or_fobj\n      file_format = self._file_format or filename.split(""."")[-1]\n      with tf.io.gfile.GFile(filename, ""rb"") as audio_f:\n        return self._encode_file(audio_f, file_format)\n    else:\n      return self._encode_file(audio_or_path_or_fobj, self._file_format)\n\n  @property\n  def sample_rate(self):\n    """"""Returns the `sample_rate` metadata associated with the dataset.""""""\n    return self._sample_rate\n'"
tensorflow_datasets/core/features/audio_feature_test.py,7,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.audio_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport array\nimport tempfile\n\nimport numpy as np\nimport pydub\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\n\ntf.enable_v2_behavior()\n\n\nclass AudioFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def create_np_audio(self):\n    return np.random.randint(-2**10, 2**10, size=(10,), dtype=np.int64)\n\n  def test_numpy_array(self):\n    np_audio = self.create_np_audio()\n\n    self.assertFeature(\n        feature=features.Audio(),\n        shape=(None,),\n        dtype=tf.int64,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np_audio,\n                expected=np_audio,\n            ),\n        ],\n    )\n\n  def test_numpy_array_float(self):\n    np_audio = self.create_np_audio().astype(np.float32)\n    self.assertFeature(\n        feature=features.Audio(dtype=tf.float32),\n        shape=(None,),\n        dtype=tf.float32,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np_audio,\n                expected=np_audio,\n            ),\n        ],\n    )\n\n  def write_wave_file(self, np_audio, path):\n    audio = pydub.AudioSegment.empty().set_sample_width(2)\n    # See documentation for _spawn usage:\n    # https://github.com/jiaaro/pydub/blob/master/API.markdown#audiosegmentget_array_of_samples\n    audio = audio._spawn(array.array(audio.array_type, np_audio))\n    audio.export(path, format=""wav"")\n\n  def test_wav_file(self):\n\n    np_audio = self.create_np_audio()\n    _, tmp_file = tempfile.mkstemp()\n    self.write_wave_file(np_audio, tmp_file)\n\n    self.assertFeature(\n        feature=features.Audio(file_format=""wav""),\n        shape=(None,),\n        dtype=tf.int64,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=tmp_file,\n                expected=np_audio,\n            ),\n        ],\n    )\n\n  def test_file_object(self):\n    np_audio = self.create_np_audio()\n    _, tmp_file = tempfile.mkstemp()\n    self.write_wave_file(np_audio, tmp_file)\n\n    class GFileWithSeekOnRead(tf.io.gfile.GFile):\n      """"""Wrapper around GFile which is reusable across multiple read() calls.\n\n      This is needed because assertFeature reuses the same\n      FeatureExpectationItem several times.\n      """"""\n\n      def read(self, *args, **kwargs):\n        data_read = super(GFileWithSeekOnRead, self).read(*args, **kwargs)\n        self.seek(0)\n        return data_read\n\n    with GFileWithSeekOnRead(tmp_file, ""rb"") as file_obj:\n      self.assertFeature(\n          feature=features.Audio(file_format=""wav""),\n          shape=(None,),\n          dtype=tf.int64,\n          tests=[\n              testing.FeatureExpectationItem(\n                  value=file_obj,\n                  expected=np_audio,\n              ),\n          ],\n      )\n\n  def test_sample_rate_property(self):\n    self.assertEqual(features.Audio(sample_rate=1600).sample_rate, 1600)\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/features/bounding_boxes.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Bounding boxes feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.features import feature\n\n\nBBox = collections.namedtuple(\'BBox\', \'ymin, xmin, ymax, xmax\')\n\n\nclass BBoxFeature(feature.Tensor):\n  """"""`FeatureConnector` for a normalized bounding box.\n\n  Note: If you have multiple bounding boxes, you may want to wrap the feature\n  inside a `tfds.feature.Sequence`.\n\n  Input:\n    * `tfds.features.BBox` tuple.\n\n  Output:\n    bbox: tf.Tensor of type `tf.float32` and shape `[4,]` which contains the\n      normalized coordinates of the bounding box `[ymin, xmin, ymax, xmax]`\n\n  Example:\n    * In the DatasetInfo object:\n\n    ```\n    features=features.FeatureDict({\n        \'bbox\': features.BBox(shape=(None, 64, 64, 3)),\n    })\n    ```\n\n    * During generation:\n\n    ```\n    yield {\n        \'input\': tfds.feature.BBox(ymin=0.3, xmin=0.8, ymax=0.5, xmax=1.0),\n    }\n    ```\n  """"""\n\n  def __init__(self):\n    super(BBoxFeature, self).__init__(shape=(4,), dtype=tf.float32)\n\n  def encode_example(self, bbox):\n    """"""See base class for details.""""""\n    # Validate the coordinates\n    for coordinate in bbox:\n      if not isinstance(coordinate, float):\n        raise ValueError(\n            \'BBox coordinates should be float. Got {}.\'.format(bbox))\n      if not 0.0 <= coordinate <= 1.0:\n        raise ValueError(\n            \'BBox coordinates should be between 0 and 1. Got {}.\'.format(bbox))\n      if bbox.xmax < bbox.xmin or bbox.ymax < bbox.ymin:\n        raise ValueError(\n            \'BBox coordinates should have min <= max. Got {}.\'.format(bbox))\n\n    return super(BBoxFeature, self).encode_example(\n        [bbox.ymin, bbox.xmin, bbox.ymax, bbox.xmax]\n    )\n'"
tensorflow_datasets/core/features/bounding_boxes_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for bounding_boxes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\n\ntf.enable_v2_behavior()\n\n\nclass BBoxFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_feature(self):\n\n    self.assertFeature(\n        feature=features.BBoxFeature(),\n        shape=(4,),\n        dtype=tf.float32,\n        tests=[\n            # Numpy array\n            testing.FeatureExpectationItem(\n                value=features.BBox(\n                    ymin=0.0,\n                    xmin=0.25,\n                    ymax=1.0,\n                    xmax=0.75,\n                ),\n                expected=[0.0, 0.25, 1.0, 0.75],\n            ),\n        ],\n    )\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/class_label_feature.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""ClassLabel feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core.features import feature\n\n\nclass ClassLabel(feature.Tensor):\n  """"""`FeatureConnector` for integer class labels.""""""\n\n  @api_utils.disallow_positional_args\n  def __init__(self, num_classes=None, names=None, names_file=None):\n    """"""Constructs a ClassLabel FeatureConnector.\n\n    There are 3 ways to define a ClassLabel, which correspond to the 3\n    arguments:\n\n     * `num_classes`: create 0 to (num_classes-1) labels\n     * `names`: a list of label strings\n     * `names_file`: a file containing the list of labels.\n\n    Note: On python2, the strings are encoded as utf-8.\n\n    Args:\n      num_classes: `int`, number of classes. All labels must be < num_classes.\n      names: `list<str>`, string names for the integer classes. The\n        order in which the names are provided is kept.\n      names_file: `str`, path to a file with names for the integer\n        classes, one per line.\n    """"""\n    super(ClassLabel, self).__init__(shape=(), dtype=tf.int64)\n\n    self._num_classes = None\n    self._str2int = None\n    self._int2str = None\n\n    # The label is explicitly set as undefined (no label defined)\n    if all(a is None for a in (num_classes, names, names_file)):\n      return\n\n    if sum(a is not None for a in (num_classes, names, names_file)) != 1:\n      raise ValueError(\n          ""Only a single argument of ClassLabel() should be provided."")\n\n    if num_classes is not None:\n      self._num_classes = num_classes\n    elif names is not None:\n      self.names = names\n    else:\n      self.names = _load_names_from_file(names_file)\n\n  @property\n  def num_classes(self):\n    return self._num_classes\n\n  @property\n  def names(self):\n    if not self._int2str:\n      return [tf.compat.as_text(str(i)) for i in range(self._num_classes)]\n    return list(self._int2str)\n\n  @names.setter\n  def names(self, new_names):\n    int2str = [tf.compat.as_text(name) for name in new_names]\n    # Names can only be defined once\n    if self._int2str is not None and self._int2str != int2str:\n      raise ValueError(\n          ""Trying to overwrite already defined ClassLabel names. Previous: {} ""\n          "", new: {}"".format(self._int2str, int2str))\n\n    # Set-up [new] names\n    self._int2str = int2str\n    self._str2int = {name: i for i, name in enumerate(self._int2str)}\n    if len(self._int2str) != len(self._str2int):\n      raise ValueError(\n          ""Some label names are duplicated. Each label name should be unique."")\n\n    # If num_classes has been defined, ensure that num_classes and names match\n    num_classes = len(self._str2int)\n    if self._num_classes is None:\n      self._num_classes = num_classes\n    elif self._num_classes != num_classes:\n      raise ValueError(\n          ""ClassLabel number of names do not match the defined num_classes. ""\n          ""Got {} names VS {} num_classes"".format(\n              num_classes, self._num_classes)\n      )\n\n  def str2int(self, str_value):\n    """"""Conversion class name string => integer.""""""\n    str_value = tf.compat.as_text(str_value)\n    if self._str2int:\n      return self._str2int[str_value]\n\n    # No names provided, try to integerize\n    failed_parse = False\n    try:\n      int_value = int(str_value)\n    except ValueError:\n      failed_parse = True\n    if failed_parse or not 0 <= int_value < self._num_classes:\n      raise ValueError(""Invalid string class label %s"" % str_value)\n    return int_value\n\n  def int2str(self, int_value):\n    """"""Conversion integer => class name string.""""""\n    if self._int2str:\n      # Maybe should support batched np array/eager tensors, to allow things\n      # like\n      # out_ids = model(inputs)\n      # labels = cifar10.info.features[\'label\'].int2str(out_ids)\n      return self._int2str[int_value]\n\n    # No names provided, return str(int)\n    if not 0 <= int_value < self._num_classes:\n      raise ValueError(""Invalid integer class label %d"" % int_value)\n    return tf.compat.as_text(str(int_value))\n\n  def encode_example(self, example_data):\n    if self._num_classes is None:\n      raise ValueError(\n          ""Trying to use ClassLabel feature with undefined number of class. ""\n          ""Please set ClassLabel.names or num_classes.""\n      )\n\n    # If a string is given, convert to associated integer\n    if isinstance(example_data, six.string_types):\n      example_data = self.str2int(example_data)\n\n    # Allowing -1 to mean no label.\n    if not -1 <= example_data < self._num_classes:\n      raise ValueError(""Class label %d greater than configured num_classes %d"" %\n                       (example_data, self._num_classes))\n    return example_data\n\n  def save_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    # Save names if defined\n    if self._str2int is not None:\n      names_filepath = _get_names_filepath(data_dir, feature_name)\n      _write_names_to_file(names_filepath, self.names)\n\n  def load_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    # Restore names if defined\n    names_filepath = _get_names_filepath(data_dir, feature_name)\n    if tf.io.gfile.exists(names_filepath):\n      self.names = _load_names_from_file(names_filepath)\n\n  def _additional_repr_info(self):\n    return {""num_classes"": self.num_classes}\n\n\ndef _get_names_filepath(data_dir, feature_name):\n  return os.path.join(data_dir, ""{}.labels.txt"".format(feature_name))\n\n\ndef _load_names_from_file(names_filepath):\n  with tf.io.gfile.GFile(names_filepath, ""r"") as f:\n    return [\n        name.strip()\n        for name in tf.compat.as_text(f.read()).split(""\\n"")\n        if name.strip()  # Filter empty names\n    ]\n\n\ndef _write_names_to_file(names_filepath, names):\n  with tf.io.gfile.GFile(names_filepath, ""w"") as f:\n    f.write(""\\n"".join(names) + ""\\n"")\n'"
tensorflow_datasets/core/features/class_label_feature_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.class_label_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\n\ntf.enable_v2_behavior()\n\n\nclass ClassLabelFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_feature(self):\n    self.assertFeature(\n        feature=features.ClassLabel(num_classes=10),\n        dtype=tf.int64,\n        shape=(),\n        tests=[\n            testing.FeatureExpectationItem(\n                value=3,\n                expected=3,\n            ),\n            testing.FeatureExpectationItem(\n                value=\'3\',\n                expected=3,\n            ),\n            testing.FeatureExpectationItem(\n                value=10,\n                raise_cls=ValueError,\n                raise_msg=\'greater than configured num_classes\',\n            ),\n            testing.FeatureExpectationItem(\n                value=\'10\',\n                raise_cls=ValueError,\n                raise_msg=\'Invalid\',\n            ),\n        ]\n    )\n\n  def test_labels(self):\n\n    self.assertFeature(\n        feature=features.ClassLabel(names=[\'left\', \'right\']),\n        dtype=tf.int64,\n        shape=(),\n        tests=[\n            testing.FeatureExpectationItem(\n                value=1,\n                expected=1,\n            ),\n            testing.FeatureExpectationItem(\n                value=\'left\',\n                expected=0,\n            ),\n            testing.FeatureExpectationItem(\n                value=\'right\',\n                expected=1,\n            ),\n        ]\n    )\n\n  def test_num_classes(self):\n    labels = features.ClassLabel(num_classes=10)\n    self.assertEqual(10, labels.num_classes)\n    self.assertEqual(10, len(labels.names))\n\n    self.assertEqual(1, labels.str2int(\'1\'))\n    self.assertEqual(u\'1\', labels.int2str(1))\n\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Invalid\'):\n      labels.str2int(\'10\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Invalid\'):\n      labels.int2str(10)\n\n  def test_empty(self):\n    # Encoding should works if num_classes=0\n    labels = features.ClassLabel(num_classes=0)\n    self.assertEqual(0, labels.num_classes)\n    self.assertEqual(0, len(labels.names))\n    self.assertEqual(-1, labels.encode_example(-1))\n\n    labels = features.ClassLabel(names=[])\n    self.assertEqual(0, labels.num_classes)\n    self.assertEqual(0, len(labels.names))\n    self.assertEqual(-1, labels.encode_example(-1))\n\n  def test_str_classes(self):\n    labels = features.ClassLabel(names=[\n        \'label3\',\n        \'label1\',\n        \'label2\',\n    ])\n    self.assertEqual(3, labels.num_classes)\n    self.assertEqual(labels.names, [\n        \'label3\',\n        \'label1\',\n        \'label2\',\n    ])\n\n    self.assertEqual(labels.str2int(\'label3\'), 0)\n    self.assertEqual(labels.str2int(\'label1\'), 1)\n    self.assertEqual(labels.str2int(\'label2\'), 2)\n    self.assertEqual(labels.int2str(0), \'label3\')\n    self.assertEqual(labels.int2str(1), \'label1\')\n    self.assertEqual(labels.int2str(2), \'label2\')\n\n  def test_save_load(self):\n    labels1 = features.ClassLabel(names=[\'label3\', \'label1\', \'label2\'])\n    labels2 = features.ClassLabel(num_classes=None)\n    labels3 = features.ClassLabel(num_classes=1)\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      labels1.save_metadata(tmp_dir, \'test-labels\')\n      labels2.load_metadata(tmp_dir, \'test-labels\')\n      with self.assertRaisesWithPredicateMatch(\n          ValueError, \'number of names do not match the defined num_classes\'):\n        labels3.load_metadata(tmp_dir, \'test-labels\')\n\n    # labels2 should have been copied from label1\n    self.assertEqual(3, labels2.num_classes)\n    self.assertEqual(labels2.names, [\n        \'label3\',\n        \'label1\',\n        \'label2\',\n    ])\n\n  def test_names(self):\n\n    labels = features.ClassLabel(names=[\'label3\', \'label1\', \'label2\'])\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'overwrite already defined ClassLabel\'):\n      labels.names = [\'other\', \'labels\']\n\n    labels = features.ClassLabel()\n    labels.names = [\'label3\', \'label1\', \'label2\']\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'overwrite already defined ClassLabel\'):\n      labels.names = [\'other\', \'labels\']\n\n    labels = features.ClassLabel(num_classes=3)\n    labels.names = [\'label3\', \'label1\', \'label2\']\n\n    labels = features.ClassLabel(num_classes=3)\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'number of names do not match the defined num_classes\'):\n      labels.names = [\'label3\', \'label1\']\n\n  def test_duplicate_names(self):\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'label names are duplicated\'):\n      features.ClassLabel(names=[\'label1\', \'label1\', \'label2\'])\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/feature.py,42,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Feature connector.\n\nFeatureConnector is a way of abstracting what data is returned by the\ntensorflow/datasets builders from how they are encoded/decoded from file.\n\n# Use FeatureConnector in `GeneratorBasedBuilder`\n\n1) In the _build_info() function, define the features as you would like them\nto be returned by the tf.data.Dataset() object.\n\nEx:\n\n  ```\n  features=features.FeaturesDict({\n      \'input\': features.Image(),\n      \'target\': features.Text(encoder=SubWordEncoder()),\n      \'extra_data\': {\n          \'label_id\': tf.int64,\n          \'language\': tf.string,\n      }\n  })\n  ```\n\nThe tf.data.Dataset will return each examples as a dict:\n\n  ```\n  {\n      \'input\': tf.Tensor(shape=(batch, height, width, channel), tf.uint8),\n      \'target\': tf.Tensor(shape=(batch, sequence_length), tf.int64),\n      \'extra_data\': {\n          \'label_id\': tf.Tensor(shape=(batch,), tf.int64),\n          \'language\': tf.Tensor(shape=(batch,), tf.string),\n      }\n  }\n  ```\n\n2) In the generator function, yield the examples to match what you have defined\nin the spec. The values will automatically be encoded.\n\n  ```\n  yield {\n      \'input\': np_image,\n      \'target\': \'This is some text\',\n      \'extra_data\': {\n          \'label_id\': 43,\n          \'language\': \'en\',\n      }\n  }\n  ```\n\n# Create your own FeatureConnector\n\nTo create your own feature connector, you need to inherit from FeatureConnector\nand implement the abstract methods.\n\n1. If your connector only contains one value, then the get_serialized_info,\n   get_tensor_info, encode_example, and decode_example can directly process\n   single value, without wrapping it in a dict.\n\n2. If your connector is a container of multiple sub-connectors, the easiest\n   way is to inherit from features.FeaturesDict and use the super() methods to\n   automatically encode/decode the sub-connectors.\n\nThis file contains the following FeatureConnector:\n * FeatureConnector: The abstract base class defining the interface\n * FeaturesDict: Container of FeatureConnector\n * Tensor: Simple tensor value with static or dynamic shape\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport collections\n\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import utils\n\n\nclass TensorInfo(object):\n  """"""Structure containing info on the `tf.Tensor` shape/dtype.""""""\n\n  def __init__(self, shape, dtype, default_value=None, sequence_rank=None):\n    """"""Constructor.\n\n    Args:\n      shape: `tuple[int]`, shape of the tensor\n      dtype: Tensor dtype\n      default_value: Used for retrocompatibility with previous files if a new\n        field is added to provide a default value when reading the file.\n      sequence_rank: `int`, Number of `tfds.features.Sequence` dimension.\n    """"""\n    self.shape = shape\n    self.dtype = dtype\n    self.default_value = default_value\n    self.sequence_rank = sequence_rank or 0\n\n  @classmethod\n  def copy_from(cls, tensor_info):\n    """"""Copy constructor.""""""\n    return cls(\n        shape=tensor_info.shape,\n        dtype=tensor_info.dtype,\n        default_value=tensor_info.default_value,\n        sequence_rank=tensor_info.sequence_rank,\n    )\n\n  def __eq__(self, other):\n    """"""Equality.""""""\n    return (\n        self.shape == other.shape and\n        self.dtype == other.dtype and\n        self.default_value == other.default_value\n    )\n\n  def __repr__(self):\n    return \'{}(shape={}, dtype={})\'.format(\n        type(self).__name__,\n        self.shape,\n        repr(self.dtype),\n    )\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass FeatureConnector(object):\n  """"""Abstract base class for feature types.\n\n  This class provides an interface between the way the information is stored\n  on disk, and the way it is presented to the user.\n\n  Here is a diagram on how FeatureConnector methods fit into the data\n  generation/reading:\n\n  ```\n  generator => encode_example() => tf_example => decode_example() => data dict\n  ```\n\n  The connector can either get raw or dictionary values as input, depending on\n  the connector type.\n\n  """"""\n\n  @abc.abstractmethod\n  def get_tensor_info(self):\n    """"""Return the tf.Tensor dtype/shape of the feature.\n\n    This returns the tensor dtype/shape, as returned by .as_dataset by the\n    `tf.data.Dataset` object.\n\n    Ex:\n\n    ```\n    return {\n        \'image\': tfds.features.TensorInfo(shape=(None,), dtype=tf.uint8),\n        \'height\': tfds.features.TensorInfo(shape=(), dtype=tf.int32),\n        \'width\': tfds.features.TensorInfo(shape=(), dtype=tf.int32),\n    }\n    ```\n\n    FeatureConnector which are not containers should return the feature proto\n    directly:\n\n    ```\n    return tfds.features.TensorInfo(shape=(256, 256), dtype=tf.uint8)\n    ```\n\n    Returns:\n      tensor_info: Either a dict of `tfds.features.TensorInfo` object, or a\n        `tfds.features.TensorInfo`\n\n    """"""\n    raise NotImplementedError\n\n  @property\n  def shape(self):\n    """"""Return the shape (or dict of shape) of this FeatureConnector.""""""\n    return utils.map_nested(lambda t: t.shape, self.get_tensor_info())\n\n  @property\n  def dtype(self):\n    """"""Return the dtype (or dict of dtype) of this FeatureConnector.""""""\n    return utils.map_nested(lambda t: t.dtype, self.get_tensor_info())\n\n  def get_serialized_info(self):\n    """"""Return the shape/dtype of features after encoding (for the adapter).\n\n    The `FileAdapter` then use those information to write data on disk.\n\n    This function indicates how this feature is encoded on file internally.\n    The DatasetBuilder are written on disk as tf.train.Example proto.\n\n    Ex:\n\n    ```\n    return {\n        \'image\': tfds.features.TensorInfo(shape=(None,), dtype=tf.uint8),\n        \'height\': tfds.features.TensorInfo(shape=(), dtype=tf.int32),\n        \'width\': tfds.features.TensorInfo(shape=(), dtype=tf.int32),\n    }\n    ```\n\n    FeatureConnector which are not containers should return the feature proto\n    directly:\n\n    ```\n    return tfds.features.TensorInfo(shape=(64, 64), tf.uint8)\n    ```\n\n    If not defined, the retuned values are automatically deduced from the\n    `get_tensor_info` function.\n\n    Returns:\n      features: Either a dict of feature proto object, or a feature proto object\n\n    """"""\n    return self.get_tensor_info()\n\n  @abc.abstractmethod\n  def encode_example(self, example_data):\n    """"""Encode the feature dict into tf-example compatible input.\n\n    The input example_data can be anything that the user passed at data\n    generation. For example:\n\n    For features:\n\n    ```\n    features={\n        \'image\': tfds.features.Image(),\n        \'custom_feature\': tfds.features.CustomFeature(),\n    }\n    ```\n\n    At data generation (in `_generate_examples`), if the user yields:\n\n    ```\n    yield {\n        \'image\': \'path/to/img.png\',\n        \'custom_feature\': [123, \'str\', lambda x: x+1]\n    }\n    ```\n\n    Then:\n\n     * `tfds.features.Image.encode_example` will get `\'path/to/img.png\'` as\n       input\n     * `tfds.features.CustomFeature.encode_example` will get `[123, \'str\',\n       lambda x: x+1] as input\n\n    Args:\n      example_data: Value or dictionary of values to convert into tf-example\n        compatible data.\n\n    Returns:\n      tfexample_data: Data or dictionary of data to write as tf-example. Data\n        can be a list or numpy array.\n        Note that numpy arrays are flattened so it\'s the feature connector\n        responsibility to reshape them in `decode_example()`.\n        Note that tf.train.Example only supports int64, float32 and string so\n        the data returned here should be integer, float or string. User type\n        can be restored in `decode_example()`.\n    """"""\n    raise NotImplementedError\n\n  def decode_example(self, tfexample_data):\n    """"""Decode the feature dict to TF compatible input.\n\n    Note: If eager is not enabled, this function will be executed as a\n    tensorflow graph (in `tf.data.Dataset.map(features.decode_example)`).\n\n    Args:\n      tfexample_data: Data or dictionary of data, as read by the tf-example\n        reader. It correspond to the `tf.Tensor()` (or dict of `tf.Tensor()`)\n        extracted from the `tf.train.Example`, matching the info defined in\n        `get_serialized_info()`.\n\n    Returns:\n      tensor_data: Tensor or dictionary of tensor, output of the tf.data.Dataset\n        object\n    """"""\n    return tfexample_data\n\n  def decode_batch_example(self, tfexample_data):\n    """"""Decode multiple features batched in a single tf.Tensor.\n\n    This function is used to decode features wrapped in\n    `tfds.features.Sequence()`.\n    By default, this function apply `decode_example` on each individual\n    elements using `tf.map_fn`. However, for optimization, features can\n    overwrite this method to apply a custom batch decoding.\n\n    Args:\n      tfexample_data: Same `tf.Tensor` inputs as `decode_example`, but with\n        and additional first dimension for the sequence length.\n\n    Returns:\n      tensor_data: Tensor or dictionary of tensor, output of the tf.data.Dataset\n        object\n    """"""\n    # Note: This all works fine in Eager mode (without tf.function) because\n    # tf.data pipelines are always executed in Graph mode.\n\n    # Apply the decoding to each of the individual distributed features.\n    return tf.map_fn(\n        self.decode_example,\n        tfexample_data,\n        dtype=self.dtype,\n        parallel_iterations=10,\n        back_prop=False,\n        name=\'sequence_decode\',\n    )\n\n  def decode_ragged_example(self, tfexample_data):\n    """"""Decode nested features from a tf.RaggedTensor.\n\n    This function is used to decode features wrapped in nested\n    `tfds.features.Sequence()`.\n    By default, this function apply `decode_batch_example` on the flat values\n    of the ragged tensor. For optimization, features can\n    overwrite this method to apply a custom batch decoding.\n\n    Args:\n      tfexample_data: `tf.RaggedTensor` inputs containing the nested encoded\n        examples.\n\n    Returns:\n      tensor_data: The decoded `tf.RaggedTensor` or dictionary of tensor,\n        output of the tf.data.Dataset object\n    """"""\n    return tf.ragged.map_flat_values(self.decode_batch_example, tfexample_data)\n\n  def _flatten(self, x):\n    """"""Flatten the input dict into a list of values.\n\n    For instance, the following feature:\n    ```\n    feature = FeatureDict({\n        \'a\': w,\n        \'b\': x,\n        \'c\': {\n            \'d\': y,\n            \'e\': z,\n        },\n    })\n    ```\n\n    Applied to the following `dict`:\n    ```\n    feature._flatten({\n        \'b\': X,\n        \'c\': {\n            \'d\': Y,\n        },\n    })\n    ```\n\n    Will produce the following flattened output:\n    ```\n    [\n        None,\n        X,\n        Y,\n        None,\n    ]\n    ```\n\n    Args:\n      x: A nested `dict` like structure matching the structure of the\n      `FeatureConnector`. Note that some elements may be missing.\n\n    Returns:\n      `list`: The flattened list of element of `x`. Order is guaranteed to be\n      deterministic. Missing elements will be filled with `None`.\n    """"""\n    return [x]\n\n  def _nest(self, list_x):\n    """"""Pack the list into a nested dict.\n\n    This is the reverse function of flatten.\n\n    For instance, the following feature:\n    ```\n    feature = FeatureDict({\n        \'a\': w,\n        \'b\': x,\n        \'c\': {\n            \'d\': y,\n            \'e\': z,\n        },\n    })\n    ```\n\n    Applied to the following `dict`:\n    ```\n    feature._nest([\n        None,\n        X,\n        Y,\n        None,\n    ])\n    ```\n\n    Will produce the following flattened output:\n    ```\n    {\n        \'a\': None,\n        \'b\': X,\n        \'c\': {\n            \'d\': Y,\n            \'e\': None,\n        },\n    }\n    ```\n\n    Args:\n      list_x: List of values matching the flattened `FeatureConnector`\n        structure. Missing values should be filled with None.\n\n    Returns:\n      nested_x: nested `dict` matching the flattened `FeatureConnector`\n        structure.\n    """"""\n    assert len(list_x) == 1\n    return list_x[0]\n\n  def _additional_repr_info(self):\n    """"""Override to return additional info to go into __repr__.""""""\n    return {}\n\n  def __repr__(self):\n    """"""Display the feature dictionary.""""""\n    tensor_info = self.get_tensor_info()\n    if not isinstance(tensor_info, TensorInfo):\n      return \'{}({})\'.format(type(self).__name__, tensor_info)\n\n    # Ensure ordering of keys by adding them one-by-one\n    repr_info = collections.OrderedDict()\n    repr_info[\'shape\'] = tensor_info.shape\n    repr_info[\'dtype\'] = repr(tensor_info.dtype)\n    additional_info = self._additional_repr_info()\n    for k, v in additional_info.items():\n      repr_info[k] = v\n\n    info_str = \', \'.join([\'%s=%s\' % (k, v) for k, v in repr_info.items()])\n    return \'{}({})\'.format(\n        type(self).__name__,\n        info_str,\n    )\n\n  def save_metadata(self, data_dir, feature_name):\n    """"""Save the feature metadata on disk.\n\n    This function is called after the data has been generated (by\n    `_download_and_prepare`) to save the feature connector info with the\n    generated dataset.\n\n    Some dataset/features dynamically compute info during\n    `_download_and_prepare`. For instance:\n\n     * Labels are loaded from the downloaded data\n     * Vocabulary is created from the downloaded data\n     * ImageLabelFolder compute the image dtypes/shape from the manual_dir\n\n    After the info have been added to the feature, this function allow to\n    save those additional info to be restored the next time the data is loaded.\n\n    By default, this function do not save anything, but sub-classes can\n    overwrite the function.\n\n    Args:\n      data_dir: `str`, path to the dataset folder to which save the info (ex:\n        `~/datasets/cifar10/1.2.0/`)\n      feature_name: `str`, the name of the feature (from the FeaturesDict key)\n    """"""\n    pass\n\n  def load_metadata(self, data_dir, feature_name):\n    """"""Restore the feature metadata from disk.\n\n    If a dataset is re-loaded and generated files exists on disk, this function\n    will restore the feature metadata from the saved file.\n\n    Args:\n      data_dir: `str`, path to the dataset folder to which save the info (ex:\n        `~/datasets/cifar10/1.2.0/`)\n      feature_name: `str`, the name of the feature (from the FeaturesDict key)\n    """"""\n    pass\n\n\nclass Tensor(FeatureConnector):\n  """"""`FeatureConnector` for generic data of arbitrary shape and type.""""""\n\n  @api_utils.disallow_positional_args\n  def __init__(self, shape, dtype):\n    """"""Construct a Tensor feature.""""""\n    self._shape = tuple(shape)\n    self._dtype = dtype\n\n  def get_tensor_info(self):\n    """"""See base class for details.""""""\n    return TensorInfo(shape=self._shape, dtype=self._dtype)\n\n  def decode_batch_example(self, example_data):\n    """"""See base class for details.""""""\n    # Overwrite the `tf.map_fn`, decoding is a no-op\n    return self.decode_example(example_data)\n\n  def decode_ragged_example(self, example_data):\n    """"""See base class for details.""""""\n    # Overwrite the `tf.map_fn`, decoding is a no-op\n    return self.decode_example(example_data)\n\n  def encode_example(self, example_data):\n    """"""See base class for details.""""""\n    np_dtype = np.dtype(self.dtype.as_numpy_dtype)\n    if not isinstance(example_data, np.ndarray):\n      example_data = np.array(example_data, dtype=np_dtype)\n    # Ensure the shape and dtype match\n    if example_data.dtype != np_dtype:\n      raise ValueError(\'Dtype {} do not match {}\'.format(\n          example_data.dtype, np_dtype))\n    utils.assert_shape_match(example_data.shape, self._shape)\n    return example_data\n\n\ndef get_inner_feature_repr(feature):\n  """"""Utils which returns the object which should get printed in __repr__.\n\n  This is used in container features (Sequence, FeatureDict) to print scalar\n  Tensor in a less verbose way `Sequence(tf.int32)` rather than\n  `Sequence(Tensor(shape=(), dtype=tf.in32))`.\n\n  Args:\n    feature: The feature to dispaly\n\n  Returns:\n    Either the feature or it\'s inner value.\n  """"""\n  # We only print `tf.int32` rather than `Tensor(shape=(), dtype=tf.int32)`\n  # * For the base `Tensor` class (and not subclass).\n  # * When shape is scalar (explicit check to avoid trigger when `shape=None`).\n  if type(feature) == Tensor and feature.shape == ():  # pylint: disable=unidiomatic-typecheck,g-explicit-bool-comparison\n    return repr(feature.dtype)\n  else:\n    return repr(feature)\n'"
tensorflow_datasets/core/features/features_dict.py,13,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""FeatureDict: Main feature connector container.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.features import feature as feature_lib\nfrom tensorflow_datasets.core.features import top_level_feature\n\n\nclass FeaturesDict(top_level_feature.TopLevelFeature):\n  """"""Composite `FeatureConnector`; each feature in `dict` has its own connector.\n\n  The encode/decode method of the spec feature will recursively encode/decode\n  every sub-connector given on the constructor.\n  Other features can inherit from this class and call super() in order to get\n  nested container.\n\n  Example:\n\n  For DatasetInfo:\n\n  ```\n  features = tfds.features.FeaturesDict({\n      \'input\': tfds.features.Image(),\n      \'output\': tf.int32,\n  })\n  ```\n\n  At generation time:\n\n  ```\n  for image, label in generate_examples:\n    yield {\n        \'input\': image,\n        \'output\': label\n    }\n  ```\n\n  At tf.data.Dataset() time:\n\n  ```\n  for example in tfds.load(...):\n    tf_input = example[\'input\']\n    tf_output = example[\'output\']\n  ```\n\n  For nested features, the FeaturesDict will internally flatten the keys for the\n  features and the conversion to tf.train.Example. Indeed, the tf.train.Example\n  proto do not support nested feature, while tf.data.Dataset does.\n  But internal transformation should be invisible to the user.\n\n  Example:\n\n  ```\n  tfds.features.FeaturesDict({\n      \'input\': tf.int32,\n      \'target\': {\n          \'height\': tf.int32,\n          \'width\': tf.int32,\n      },\n  })\n  ```\n\n  Will internally store the data as:\n\n  ```\n  {\n      \'input\': tf.io.FixedLenFeature(shape=(), dtype=tf.int32),\n      \'target/height\': tf.io.FixedLenFeature(shape=(), dtype=tf.int32),\n      \'target/width\': tf.io.FixedLenFeature(shape=(), dtype=tf.int32),\n  }\n  ```\n\n  """"""\n\n  def __init__(self, feature_dict):\n    """"""Initialize the features.\n\n    Args:\n      feature_dict (dict): Dictionary containing the feature connectors of a\n        example. The keys should correspond to the data dict as returned by\n        tf.data.Dataset(). Types (tf.int32,...) and dicts will automatically\n        be converted into FeatureConnector.\n\n    Raises:\n      ValueError: If one of the given features is not recognized\n    """"""\n    super(FeaturesDict, self).__init__()\n    self._feature_dict = {k: to_feature(v) for k, v in feature_dict.items()}\n\n  # Dict functions.\n  # In Python 3, should inherit from collections.abc.Mapping().\n\n  def keys(self):\n    return self._feature_dict.keys()\n\n  def items(self):\n    return self._feature_dict.items()\n\n  def values(self):\n    return self._feature_dict.values()\n\n  def __contains__(self, k):\n    return k in self._feature_dict\n\n  def __getitem__(self, key):\n    """"""Return the feature associated with the key.""""""\n    return self._feature_dict[key]\n\n  def __len__(self):\n    return len(self._feature_dict)\n\n  def __iter__(self):\n    return iter(self._feature_dict)\n\n  # Feature functions\n\n  def __repr__(self):\n    """"""Display the feature dictionary.""""""\n    lines = [\'{}({{\'.format(type(self).__name__)]\n    # Add indentation\n    for key, feature in sorted(list(self._feature_dict.items())):\n      feature_repr = feature_lib.get_inner_feature_repr(feature)\n      all_sub_lines = \'\\\'{}\\\': {},\'.format(key, feature_repr)\n      lines.extend(\'    \' + l for l in all_sub_lines.split(\'\\n\'))\n    lines.append(\'})\')\n    return \'\\n\'.join(lines)\n\n  def get_tensor_info(self):\n    """"""See base class for details.""""""\n    return {\n        feature_key: feature.get_tensor_info()\n        for feature_key, feature in self._feature_dict.items()\n    }\n\n  def get_serialized_info(self):\n    """"""See base class for details.""""""\n    return {\n        feature_key: feature.get_serialized_info()\n        for feature_key, feature in self._feature_dict.items()\n    }\n\n  def encode_example(self, example_dict):\n    """"""See base class for details.""""""\n    return {\n        k: feature.encode_example(example_value)\n        for k, (feature, example_value)\n        in utils.zip_dict(self._feature_dict, example_dict)\n    }\n\n  def _flatten(self, x):\n    """"""See base class for details.""""""\n    if x and not isinstance(x, (dict, FeaturesDict)):\n      raise ValueError(\n          \'Error while flattening dict: FeaturesDict received a non dict item: \'\n          \'{}\'.format(x))\n\n    cache = {\'counter\': 0}  # Could use nonlocal in Python\n    def _get(k):\n      if x and k in x:\n        cache[\'counter\'] += 1\n        return x[k]\n      return None\n\n    out = []\n    for k, f in sorted(self.items()):\n      out.extend(f._flatten(_get(k)))  # pylint: disable=protected-access\n\n    if x and cache[\'counter\'] != len(x):\n      raise ValueError(\n          \'Error while flattening dict: Not all dict items have been consumed, \'\n          \'this means that the provided dict structure does not match the \'\n          \'`FeatureDict`. Please check for typos in the key names. \'\n          \'Available keys: {}. Unrecognized keys: {}\'.format(\n              list(self.keys()), list(set(x.keys()) - set(self.keys())))\n      )\n    return out\n\n  def _nest(self, list_x):\n    """"""See base class for details.""""""\n    curr_pos = 0\n    out = {}\n    for k, f in sorted(self.items()):\n      offset = len(f._flatten(None))  # pylint: disable=protected-access\n      out[k] = f._nest(list_x[curr_pos:curr_pos+offset])  # pylint: disable=protected-access\n      curr_pos += offset\n    if curr_pos != len(list_x):\n      raise ValueError(\n          \'Error while nesting: Expected length {} does not match input \'\n          \'length {} of {}\'.format(curr_pos, len(list_x), list_x))\n    return out\n\n  def save_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    # Recursively save all child features\n    for feature_key, feature in six.iteritems(self._feature_dict):\n      feature_key = feature_key.replace(\'/\', \'.\')\n      if feature_name:\n        feature_key = \'-\'.join((feature_name, feature_key))\n      feature.save_metadata(data_dir, feature_name=feature_key)\n\n  def load_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    # Recursively load all child features\n    for feature_key, feature in six.iteritems(self._feature_dict):\n      feature_key = feature_key.replace(\'/\', \'.\')\n      if feature_name:\n        feature_key = \'-\'.join((feature_name, feature_key))\n      feature.load_metadata(data_dir, feature_name=feature_key)\n\n\ndef to_feature(value):\n  """"""Convert the given value to Feature if necessary.""""""\n  if isinstance(value, feature_lib.FeatureConnector):\n    return value\n  elif utils.is_dtype(value):  # tf.int32, tf.string,...\n    return feature_lib.Tensor(shape=(), dtype=tf.as_dtype(value))\n  elif isinstance(value, dict):\n    return FeaturesDict(value)\n  else:\n    raise ValueError(\'Feature not supported: {}\'.format(value))\n'"
tensorflow_datasets/core/features/features_test.py,59,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""Tests for tensorflow_datasets.core.features.feature.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport textwrap\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features as features_lib\n\ntf.enable_v2_behavior()\n\n\nclass AnInputConnector(features_lib.FeatureConnector):\n  """"""Simple FeatureConnector implementing the based methods used for test.""""""\n\n  def get_tensor_info(self):\n    # With this connector, the way the data is on disk ({\'a\', \'b\'}) do not match\n    # the way it is exposed to the user (int64), so we overwrite\n    # FeaturesDict.get_tensor_info\n    return features_lib.TensorInfo(shape=(), dtype=tf.int64)\n\n  def get_serialized_info(self):\n    return {\n        \'a\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n        \'b\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n    }\n\n  def encode_example(self, example_data):\n    # Encode take the input data and wrap in in a dict\n    return {\n        \'a\': example_data + 1,\n        \'b\': example_data * 10\n    }\n\n  def decode_example(self, tfexample_dict):\n    # Merge the two values\n    return tfexample_dict[\'a\'] + tfexample_dict[\'b\']\n\n\nclass AnOutputConnector(features_lib.FeatureConnector):\n  """"""Simple FeatureConnector implementing the based methods used for test.""""""\n\n  def get_tensor_info(self):\n    return features_lib.TensorInfo(shape=(), dtype=tf.float32)\n\n  def encode_example(self, example_data):\n    return example_data * 10.0\n\n  def decode_example(self, tfexample_data):\n    return tfexample_data / 10.0\n\n\nclass FeatureDictTest(testing.FeatureExpectationsTestCase):\n\n  def test_tensor_info(self):\n\n    self.assertEqual(\n        features_lib.TensorInfo(shape=(None, 3), dtype=tf.string),\n        features_lib.TensorInfo(shape=(None, 3), dtype=tf.string),\n    )\n\n    self.assertNotEqual(\n        features_lib.TensorInfo(shape=(None, 3), dtype=tf.string),\n        features_lib.TensorInfo(shape=(None, 3), dtype=tf.int32),\n    )\n\n    self.assertNotEqual(\n        features_lib.TensorInfo(shape=(2, 3), dtype=tf.string),\n        features_lib.TensorInfo(shape=(5, 3), dtype=tf.string),\n    )\n\n    t = features_lib.TensorInfo(shape=(None, 3), dtype=tf.string)\n    self.assertEqual(t, features_lib.TensorInfo.copy_from(t))\n\n  def test_fdict(self):\n\n    self.assertFeature(\n        feature=features_lib.FeaturesDict({\n            \'input\': AnInputConnector(),\n            \'output\': AnOutputConnector(),\n            \'img\': {\n                \'size\': {\n                    \'height\': tf.int64,\n                    \'width\': tf.int64,\n                },\n                \'metadata/path\': tf.string,\n            }\n        }),\n        serialized_info={\n            \'input\': {\n                \'a\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n                \'b\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n            },\n            \'output\': features_lib.TensorInfo(shape=(), dtype=tf.float32),\n            \'img\': {\n                \'size\': {\n                    \'height\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n                    \'width\': features_lib.TensorInfo(shape=(), dtype=tf.int64),\n                },\n                \'metadata/path\':\n                    features_lib.TensorInfo(shape=(), dtype=tf.string),\n            }\n        },\n        dtype={\n            \'input\': tf.int64,\n            \'output\': tf.float32,\n            \'img\': {\n                \'size\': {\n                    \'height\': tf.int64,\n                    \'width\': tf.int64,\n                },\n                \'metadata/path\': tf.string,\n            }\n        },\n        shape={\n            \'input\': (),\n            \'output\': (),\n            \'img\': {\n                \'size\': {\n                    \'height\': (),\n                    \'width\': (),\n                },\n                \'metadata/path\': (),\n            },\n        },\n        tests=[\n            # Np array\n            testing.FeatureExpectationItem(\n                value={\n                    \'input\': 1,\n                    \'output\': -1,\n                    \'img\': {\n                        \'size\': {\n                            \'height\': 256,\n                            \'width\': 128,\n                        },\n                        \'metadata/path\': \'path/to/xyz.jpg\',\n                    }\n                },\n                expected_serialized={\n                    \'input\': {\n                        \'a\': 2,  # 1 + 1\n                        \'b\': 10,  # 1 * 10\n                    },\n                    \'output\': -10.0,  # -1 * 10.0\n                    \'img\': {\n                        \'size\': {\n                            \'height\': 256,\n                            \'width\': 128,\n                        },\n                        \'metadata/path\': \'path/to/xyz.jpg\',\n                    }\n                },\n                expected={\n                    # a = 1 + 1, b = 1 * 10 => output = a + b = 2 + 10 = 12\n                    \'input\': 12,  # 2 + 10\n                    \'output\': -1.0,\n                    \'img\': {\n                        \'size\': {\n                            \'height\': 256,\n                            \'width\': 128,\n                        },\n                        \'metadata/path\':\n                            tf.compat.as_bytes(\'path/to/xyz.jpg\'),\n                    },\n                },\n            ),\n        ],\n    )\n\n  def test_feature_getitem(self):\n    fdict = features_lib.FeaturesDict({\n        \'integer\': tf.int32,\n        \'string\': tf.string,\n    })\n    self.assertEqual(fdict[\'integer\'].dtype, tf.int32)\n    self.assertEqual(fdict[\'string\'].dtype, tf.string)\n\n  def test_feature__repr__(self):\n\n    label = features_lib.ClassLabel(names=[\'m\', \'f\'])\n    feature_dict = features_lib.FeaturesDict({\n        \'metadata\': features_lib.Sequence({\n            \'frame\': features_lib.Image(shape=(32, 32, 3)),\n        }),\n        \'label\': features_lib.Sequence(label),\n    })\n\n    self.assertEqual(\n        repr(feature_dict),\n        textwrap.dedent(""""""\\\n        FeaturesDict({\n            \'label\': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=2)),\n            \'metadata\': Sequence({\n                \'frame\': Image(shape=(32, 32, 3), dtype=tf.uint8),\n            }),\n        })""""""),\n    )\n\n  def test_feature_save_load_metadata_slashes(self):\n    with testing.tmp_dir() as data_dir:\n      fd = features_lib.FeaturesDict({\n          \'image/frame\': features_lib.Image(shape=(32, 32, 3)),\n          \'image/label\': features_lib.ClassLabel(num_classes=2),\n      })\n      fd.save_metadata(data_dir)\n      fd.load_metadata(data_dir)\n\n\nclass FeatureTensorTest(testing.FeatureExpectationsTestCase):\n\n  def test_shape_static(self):\n\n    np_input = np.random.rand(2, 3).astype(np.float32)\n    array_input = [\n        [1, 2, 3],\n        [4, 5, 6],\n    ]\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(2, 3), dtype=tf.float32),\n        dtype=tf.float32,\n        shape=(2, 3),\n        tests=[\n            # Np array\n            testing.FeatureExpectationItem(\n                value=np_input,\n                expected=np_input,\n            ),\n            # Python array\n            testing.FeatureExpectationItem(\n                value=array_input,\n                expected=array_input,\n            ),\n            # Invalid dtype\n            testing.FeatureExpectationItem(\n                # On Windows, np default dtype is `int32`\n                value=np.random.randint(256, size=(2, 3), dtype=np.int64),\n                raise_cls=ValueError,\n                raise_msg=\'int64 do not match\',\n            ),\n            # Invalid shape\n            testing.FeatureExpectationItem(\n                value=np.random.rand(2, 4).astype(np.float32),\n                raise_cls=ValueError,\n                raise_msg=\'are incompatible\',\n            ),\n        ],\n    )\n\n  def test_shape_dynamic(self):\n\n    np_input_dynamic_1 = np.random.randint(256, size=(2, 3, 2), dtype=np.int32)\n    np_input_dynamic_2 = np.random.randint(256, size=(5, 3, 2), dtype=np.int32)\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(None, 3, 2), dtype=tf.int32),\n        dtype=tf.int32,\n        shape=(None, 3, 2),\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np_input_dynamic_1,\n                expected=np_input_dynamic_1,\n            ),\n            testing.FeatureExpectationItem(\n                value=np_input_dynamic_2,\n                expected=np_input_dynamic_2,\n            ),\n            # Invalid shape\n            testing.FeatureExpectationItem(\n                value=\n                np.random.randint(256, size=(2, 3, 1), dtype=np.int32),\n                raise_cls=ValueError,\n                raise_msg=\'are incompatible\',\n            ),\n        ]\n    )\n\n  def test_bool_flat(self):\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(), dtype=tf.bool),\n        dtype=tf.bool,\n        shape=(),\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np.array(True),\n                expected=True,\n            ),\n            testing.FeatureExpectationItem(\n                value=np.array(False),\n                expected=False,\n            ),\n            testing.FeatureExpectationItem(\n                value=True,\n                expected=True,\n            ),\n            testing.FeatureExpectationItem(\n                value=False,\n                expected=False,\n            ),\n        ]\n    )\n\n  def test_bool_array(self):\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(3,), dtype=tf.bool),\n        dtype=tf.bool,\n        shape=(3,),\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np.array([True, True, False]),\n                expected=[True, True, False],\n            ),\n            testing.FeatureExpectationItem(\n                value=[True, False, True],\n                expected=[True, False, True],\n            ),\n        ]\n    )\n\n  def test_string(self):\n    nonunicode_text = \'hello world\'\n    unicode_text = u\'\xe4\xbd\xa0\xe5\xa5\xbd\'\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(), dtype=tf.string),\n        shape=(),\n        dtype=tf.string,\n        tests=[\n            # Non-unicode\n            testing.FeatureExpectationItem(\n                value=nonunicode_text,\n                expected=tf.compat.as_bytes(nonunicode_text),\n            ),\n            # Unicode\n            testing.FeatureExpectationItem(\n                value=unicode_text,\n                expected=tf.compat.as_bytes(unicode_text),\n            ),\n            # Empty string\n            testing.FeatureExpectationItem(\n                value=\'\',\n                expected=b\'\',\n            ),\n            # Trailing zeros\n            testing.FeatureExpectationItem(\n                value=b\'abc\\x00\\x00\',\n                expected=b\'abc\\x00\\x00\',\n            ),\n        ],\n    )\n\n    self.assertFeature(\n        feature=features_lib.Tensor(shape=(2, 1), dtype=tf.string),\n        shape=(2, 1),\n        dtype=tf.string,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[[nonunicode_text], [unicode_text]],\n                expected=[\n                    [tf.compat.as_bytes(nonunicode_text)],\n                    [tf.compat.as_bytes(unicode_text)],\n                ],\n            ),\n            testing.FeatureExpectationItem(\n                value=[nonunicode_text, unicode_text],  # Wrong shape\n                raise_cls=ValueError,\n                raise_msg=\'(2,) and (2, 1) must have the same rank\',\n            ),\n            testing.FeatureExpectationItem(\n                value=[[\'some text\'], [123]],  # Wrong dtype\n                raise_cls=TypeError,\n                raise_msg=\'Expected binary or unicode string, got 123\',\n            ),\n        ],\n    )\n\n  def test_repr_tensor(self):\n\n    # Top level Tensor is printed expanded\n    self.assertEqual(\n        repr(features_lib.Tensor(shape=(), dtype=tf.int32)),\n        \'Tensor(shape=(), dtype=tf.int32)\',\n    )\n\n    # Sequences colapse tensor repr\n    self.assertEqual(\n        repr(features_lib.Sequence(tf.int32)),\n        \'Sequence(tf.int32)\',\n    )\n\n    class ChildTensor(features_lib.Tensor):\n      pass\n\n    self.assertEqual(\n        repr(features_lib.FeaturesDict({\n            \'colapsed\': features_lib.Tensor(shape=(), dtype=tf.int32),\n            # Tensor with defined shape are printed expanded\n            \'noncolapsed\': features_lib.Tensor(shape=(1,), dtype=tf.int32),\n            # Tensor inherited are expanded\n            \'child\': ChildTensor(shape=(), dtype=tf.int32),\n        })),\n        textwrap.dedent(""""""\\\n        FeaturesDict({\n            \'child\': ChildTensor(shape=(), dtype=tf.int32),\n            \'colapsed\': tf.int32,\n            \'noncolapsed\': Tensor(shape=(1,), dtype=tf.int32),\n        })""""""),\n    )\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/image_feature.py,17,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Image feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import api_utils\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.features import feature\n\nENCODE_FN = {\n    \'png\': tf.image.encode_png,\n    \'jpeg\': tf.image.encode_jpeg,\n}\n\nACCEPTABLE_CHANNELS = {\n    \'png\': (0, 1, 2, 3),\n    \'jpeg\': (0, 1, 3),\n}\n\nACCEPTABLE_DTYPES = {\n    \'png\': [tf.uint8, tf.uint16],\n    \'jpeg\': [tf.uint8],\n}\n\n\nclass Image(feature.FeatureConnector):\n  """"""`FeatureConnector` for images.\n\n  During `_generate_examples`, the feature connector accept as input any of:\n\n    * `str`: path to a {bmp,gif,jpeg,png} image (ex: `/path/to/img.png`).\n    * `np.array`: 3d `np.uint8` array representing an image.\n    * A file object containing the png or jpeg encoded image string (ex:\n      `io.BytesIO(encoded_img_bytes)`)\n\n  Output:\n\n    `tf.Tensor` of type `tf.uint8` and shape `[height, width, num_channels]`\n    for BMP, JPEG, and PNG images and shape `[num_frames, height, width, 3]` for\n    GIF images.\n\n  Example:\n\n    * In the `tfds.core.DatasetInfo` object:\n\n    ```python\n    features=features.FeaturesDict({\n        \'input\': features.Image(),\n        \'target\': features.Image(shape=(None, None, 1),\n                                   encoding_format=\'png\'),\n    })\n    ```\n\n    * During generation:\n\n    ```python\n    yield {\n        \'input\': \'path/to/img.jpg\',\n        \'target\': np.ones(shape=(64, 64, 1), dtype=np.uint8),\n    }\n    ```\n  """"""\n\n  @api_utils.disallow_positional_args\n  def __init__(self, shape=None, dtype=None, encoding_format=None):\n    """"""Construct the connector.\n\n    Args:\n      shape: tuple of ints or None, the shape of decoded image.\n        For GIF images: (num_frames, height, width, channels=3). num_frames,\n          height and width can be None.\n        For other images: (height, width, channels). height and width can be\n          None. See `tf.image.encode_*` for doc on channels parameter.\n        Defaults to (None, None, 3).\n      dtype: tf.uint16 or tf.uint8 (default).\n        tf.uint16 can be used only with png encoding_format\n      encoding_format: \'jpeg\' or \'png\' (default). Format to serialize np.ndarray\n        images on disk.\n        If image is loaded from {bmg,gif,jpeg,png} file, this parameter is\n        ignored, and file original encoding is used.\n\n    Raises:\n      ValueError: If the shape is invalid\n    """"""\n    self._encoding_format = None\n    self._shape = None\n    self._runner = None\n    self._dtype = None\n\n    # Set and validate values\n    self.set_encoding_format(encoding_format or \'png\')\n    self.set_shape(shape or (None, None, 3))\n    self.set_dtype(dtype or tf.uint8)\n\n  def set_dtype(self, dtype):\n    """"""Update the dtype.""""""\n    dtype = tf.as_dtype(dtype)\n    acceptable_dtypes = ACCEPTABLE_DTYPES[self._encoding_format]\n    if dtype not in acceptable_dtypes:\n      raise ValueError(\'Acceptable `dtype` for %s: %s (was %s)\' % (\n          self._encoding_format, acceptable_dtypes, dtype))\n    self._dtype = dtype\n\n  def set_encoding_format(self, encoding_format):\n    """"""Update the encoding format.""""""\n    supported = ENCODE_FN.keys()\n    if encoding_format not in supported:\n      raise ValueError(\'`encoding_format` must be one of %s.\' % supported)\n    self._encoding_format = encoding_format\n\n  def set_shape(self, shape):\n    """"""Update the shape.""""""\n    channels = shape[-1]\n    acceptable_channels = ACCEPTABLE_CHANNELS[self._encoding_format]\n    if channels not in acceptable_channels:\n      raise ValueError(\'Acceptable `channels` for %s: %s (was %s)\' % (\n          self._encoding_format, acceptable_channels, channels))\n    self._shape = tuple(shape)\n\n  def get_tensor_info(self):\n    # Image is returned as a 3-d uint8 tf.Tensor.\n    return feature.TensorInfo(shape=self._shape, dtype=self._dtype)\n\n  def get_serialized_info(self):\n    # Only store raw image (includes size).\n    return feature.TensorInfo(shape=(), dtype=tf.string)\n\n  def _encode_image(self, np_image):\n    """"""Returns np_image encoded as jpeg or png.""""""\n    if not self._runner:\n      self._runner = utils.TFGraphRunner()\n    if np_image.dtype != self._dtype.as_numpy_dtype:\n      raise ValueError(\'Image dtype should be %s. Detected: %s.\' % (\n          self._dtype.as_numpy_dtype, np_image.dtype))\n    utils.assert_shape_match(np_image.shape, self._shape)\n    return self._runner.run(ENCODE_FN[self._encoding_format], np_image)\n\n  def __getstate__(self):\n    state = self.__dict__.copy()\n    state[\'_runner\'] = None\n    return state\n\n  def encode_example(self, image_or_path_or_fobj):\n    """"""Convert the given image into a dict convertible to tf example.""""""\n    if isinstance(image_or_path_or_fobj, np.ndarray):\n      encoded_image = self._encode_image(image_or_path_or_fobj)\n    elif isinstance(image_or_path_or_fobj, six.string_types):\n      with tf.io.gfile.GFile(image_or_path_or_fobj, \'rb\') as image_f:\n        encoded_image = image_f.read()\n    else:\n      encoded_image = image_or_path_or_fobj.read()\n    return encoded_image\n\n  def decode_example(self, example):\n    """"""Reconstruct the image from the tf example.""""""\n    img = tf.image.decode_image(\n        example, channels=self._shape[-1], dtype=self._dtype)\n    img.set_shape(self._shape)\n    return img\n\n  def save_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    filepath = _get_metadata_filepath(data_dir, feature_name)\n    with tf.io.gfile.GFile(filepath, \'w\') as f:\n      json.dump({\n          \'shape\': [-1 if d is None else d for d in self._shape],\n          \'encoding_format\': self._encoding_format,\n      }, f, sort_keys=True)\n\n  def load_metadata(self, data_dir, feature_name=None):\n    """"""See base class for details.""""""\n    # Restore names if defined\n    filepath = _get_metadata_filepath(data_dir, feature_name)\n    if tf.io.gfile.exists(filepath):\n      with tf.io.gfile.GFile(filepath, \'r\') as f:\n        info_data = json.load(f)\n      self.set_encoding_format(info_data[\'encoding_format\'])\n      self.set_shape([None if d == -1 else d for d in info_data[\'shape\']])\n\n\ndef _get_metadata_filepath(data_dir, feature_name):\n  return os.path.join(data_dir, \'{}.image.json\'.format(feature_name))\n'"
tensorflow_datasets/core/features/image_feature_test.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.image_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features as features_lib\n\ntf.enable_v2_behavior()\n\n\nrandint = np.random.randint\n\n\nclass ImageFeatureTest(\n    testing.FeatureExpectationsTestCase, parameterized.TestCase):\n\n  @parameterized.parameters(tf.uint8, tf.uint16)\n  def test_images(self, dtype):\n    np_dtype = dtype.as_numpy_dtype\n    img = randint(256, size=(128, 100, 3), dtype=np_dtype)\n    img_other_shape = randint(256, size=(64, 200, 3), dtype=np_dtype)\n    img_file_path = os.path.join(os.path.dirname(__file__),\n                                 \'../../testing/test_data/6pixels.png\')\n    img_file_expected_content = np.array([  # see tests_data/README.md\n        [[0, 255, 0], [255, 0, 0], [255, 0, 255]],\n        [[0, 0, 255], [255, 255, 0], [126, 127, 128]],\n    ], dtype=np_dtype)\n    if dtype == tf.uint16:\n      img_file_expected_content *= 257  # Scale int16 images\n\n    self.assertFeature(\n        feature=features_lib.Image(dtype=dtype),\n        shape=(None, None, 3),\n        dtype=dtype,\n        tests=[\n            # Numpy array\n            testing.FeatureExpectationItem(\n                value=img,\n                expected=img,\n            ),\n            # File path\n            testing.FeatureExpectationItem(\n                value=img_file_path,\n                expected=img_file_expected_content,\n            ),\n            # \'img\' shape can be dynamic\n            testing.FeatureExpectationItem(\n                value=img_other_shape,\n                expected=img_other_shape,\n            ),\n            # Invalid type\n            testing.FeatureExpectationItem(\n                value=randint(256, size=(128, 128, 3), dtype=np.uint32),\n                raise_cls=ValueError,\n                raise_msg=\'dtype should be\',\n            ),\n            # Invalid number of dimensions\n            testing.FeatureExpectationItem(\n                value=randint(256, size=(128, 128), dtype=np_dtype),\n                raise_cls=ValueError,\n                raise_msg=\'must have the same rank\',\n            ),\n            # Invalid number of channels\n            testing.FeatureExpectationItem(\n                value=randint(256, size=(128, 128, 1), dtype=np_dtype),\n                raise_cls=ValueError,\n                raise_msg=\'are incompatible\',\n            ),\n        ],\n    )\n\n  def test_image_shaped(self):\n\n    img_shaped = randint(256, size=(32, 64, 3), dtype=np.uint8)\n\n    self.assertFeature(\n        # Image with statically defined shape\n        feature=features_lib.Image(shape=(32, 64, 3)),\n        shape=(32, 64, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=img_shaped,\n                expected=img_shaped,\n            ),\n            # \'img_shaped\' shape should be static\n            testing.FeatureExpectationItem(\n                value=randint(256, size=(31, 64, 3), dtype=np.uint8),\n                raise_cls=ValueError,\n                raise_msg=\'are incompatible\',\n            ),\n        ],\n    )\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/sequence_feature.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Sequence feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.features import feature as feature_lib\nfrom tensorflow_datasets.core.features import features_dict\nfrom tensorflow_datasets.core.features import top_level_feature\n\n\nclass Sequence(top_level_feature.TopLevelFeature):\n  """"""Composite `FeatureConnector` for a `dict` where each value is a list.\n\n  `Sequence` correspond to sequence of `tfds.features.FeatureConnector`. At\n  generation time, a list for each of the sequence element is given. The output\n  of `tf.data.Dataset` will batch all the elements of the sequence together.\n\n  If the length of the sequence is static and known in advance, it should be\n  specified in the constructor using the `length` param.\n\n  Note that `Sequence` does not support features which are of type\n  `tf.io.FixedLenSequenceFeature`.\n\n  Example:\n  At construction time:\n\n  ```\n  tfds.features.Sequence(tfds.features.Image(), length=NB_FRAME)\n  ```\n\n  or:\n\n  ```\n  tfds.features.Sequence({\n      \'frame\': tfds.features.Image(shape=(64, 64, 3))\n      \'action\': tfds.features.ClassLabel([\'up\', \'down\', \'left\', \'right\'])\n  }, length=NB_FRAME)\n  ```\n\n  During data generation:\n\n  ```\n  yield {\n      \'frame\': np.ones(shape=(NB_FRAME, 64, 64, 3)),\n      \'action\': [\'left\', \'left\', \'up\', ...],\n  }\n  ```\n\n  Tensor returned by `.as_dataset()`:\n\n  ```\n  {\n      \'frame\': tf.Tensor(shape=(NB_FRAME, 64, 64, 3), dtype=tf.uint8),\n      \'action\': tf.Tensor(shape=(NB_FRAME,), dtype=tf.int64),\n  }\n  ```\n\n  At generation time, you can specify a list of features dict, a dict of list\n  values or a stacked numpy array. The lists will automatically be distributed\n  into their corresponding `FeatureConnector`.\n\n  """"""\n\n  def __init__(self, feature, length=None, **kwargs):\n    """"""Construct a sequence dict.\n\n    Args:\n      feature: `dict`, the features to wrap\n      length: `int`, length of the sequence if static and known in advance\n      **kwargs: `dict`, constructor kwargs of `tfds.features.FeaturesDict`\n    """"""\n    # Convert {} => FeaturesDict, tf.int32 => Tensor(shape=(), dtype=tf.int32)\n    self._feature = features_dict.to_feature(feature)\n    self._length = length\n    super(Sequence, self).__init__(**kwargs)\n\n  @property\n  def feature(self):\n    """"""The inner feature.""""""\n    return self._feature\n\n  def _add_length_dim(self, tensor_info):\n    """"""Add the length dimension to the given tensor_info.""""""\n    tensor_info = feature_lib.TensorInfo.copy_from(tensor_info)\n    tensor_info.shape = (self._length,) + tensor_info.shape\n    tensor_info.sequence_rank += 1\n    return tensor_info\n\n  def get_tensor_info(self):\n    """"""See base class for details.""""""\n    # Add the additional length dimension to every shape\n    tensor_info = self._feature.get_tensor_info()\n    return utils.map_nested(self._add_length_dim, tensor_info)\n\n  def get_serialized_info(self):\n    """"""See base class for details.""""""\n    # Add the additional length dimension to every serialized features\n    tensor_info = self._feature.get_serialized_info()\n    return utils.map_nested(self._add_length_dim, tensor_info)\n\n  def encode_example(self, example_dict):\n    # Convert nested dict[list] into list[nested dict]\n    sequence_elements = _transpose_dict_list(example_dict)\n\n    # If length is static, ensure that the given length match\n    if self._length is not None and len(sequence_elements) != self._length:\n      raise ValueError(\n          \'Input sequence length do not match the defined one. Got {} != \'\n          \'{}\'.format(len(sequence_elements), self._length)\n      )\n\n    # Empty sequences return empty arrays\n    if not sequence_elements:\n      def _build_empty_np(serialized_info):\n        return np.empty(\n            shape=tuple(s if s else 0 for s in serialized_info.shape),\n            dtype=serialized_info.dtype.as_numpy_dtype,\n        )\n\n      return utils.map_nested(_build_empty_np, self.get_serialized_info())\n\n    # Encode each individual elements\n    sequence_elements = [\n        self.feature.encode_example(sequence_elem)\n        for sequence_elem in sequence_elements\n    ]\n\n    # Then convert back list[nested dict] => nested dict[list]\n    def _stack_nested(sequence_elements):\n      """"""Recursivelly stack the tensors from the same dict field.""""""\n      if isinstance(sequence_elements[0], dict):\n        return {\n            # Stack along the first dimension\n            k: _stack_nested(sub_sequence)\n            for k, sub_sequence in utils.zip_dict(*sequence_elements)\n        }\n      # Note: As each field can be a nested ragged list, we don\'t check here\n      # that all elements from the list have matching dtype/shape.\n      # Checking is done in `example_serializer` when elements\n      # are converted to numpy array and stacked togethers.\n      return list(sequence_elements)\n\n    return _stack_nested(sequence_elements)\n\n  def _flatten(self, x):\n    """"""See base class for details.""""""\n    if isinstance(x, Sequence):\n      return self.feature._flatten(x.feature)  # pylint: disable=protected-access\n    return self.feature._flatten(x)  # pylint: disable=protected-access\n\n  def _nest(self, list_x):\n    """"""See base class for details.""""""\n    return self.feature._nest(list_x)  # pylint: disable=protected-access\n\n  def save_metadata(self, *args, **kwargs):\n    """"""See base class for details.""""""\n    self._feature.save_metadata(*args, **kwargs)\n\n  def load_metadata(self, *args, **kwargs):\n    """"""See base class for details.""""""\n    self._feature.load_metadata(*args, **kwargs)\n\n  def __getitem__(self, key):\n    """"""Convenience method to access the underlying features.""""""\n    return self._feature[key]\n\n  def __getattr__(self, key):\n    """"""Allow to access the underlying attributes directly.""""""\n    return getattr(self._feature, key)\n\n  # The __getattr__ method triggers an infinite recursion loop when loading a\n  # pickled instance. So we override that name in the instance dict, and remove\n  # it when unplickling.\n  def __getstate__(self):\n    state = self.__dict__.copy()\n    state[\'__getattr__\'] = 0\n    return state\n\n  def __setstate__(self, state):\n    del state[\'__getattr__\']\n    self.__dict__.update(state)\n\n  def __repr__(self):\n    """"""Display the feature.""""""\n    inner_feature_repr = feature_lib.get_inner_feature_repr(self._feature)\n    if inner_feature_repr.startswith(\'FeaturesDict(\'):\n      # Minor formatting cleaning: \'Sequence(FeaturesDict({\' => \'Sequence({\'\n      inner_feature_repr = inner_feature_repr[len(\'FeaturesDict(\'):-len(\')\')]\n    return \'{}({})\'.format(type(self).__name__, inner_feature_repr)\n\n\ndef _np_to_list(elem):\n  """"""Returns list from list, tuple or ndarray.""""""\n  if isinstance(elem, list):\n    return elem\n  elif isinstance(elem, tuple):\n    return list(elem)\n  elif isinstance(elem, np.ndarray):\n    return list(elem)\n  else:\n    raise ValueError(\n        \'Input elements of a sequence should be either a numpy array, a \'\n        \'python list or tuple. Got {}\'.format(type(elem)))\n\n\ndef _transpose_dict_list(dict_list):\n  """"""Transpose a nested dict[list] into a list[nested dict].""""""\n  # 1. Unstack numpy arrays into list\n  dict_list = utils.map_nested(_np_to_list, dict_list, dict_only=True)\n\n  # 2. Extract the sequence length (and ensure the length is constant for all\n  # elements)\n  length = {\'value\': None}  # dict because `nonlocal` is Python3 only\n  def update_length(elem):\n    if length[\'value\'] is None:\n      length[\'value\'] = len(elem)\n    elif length[\'value\'] != len(elem):\n      raise ValueError(\n          \'The length of all elements of one sequence should be the same. \'\n          \'Got {} != {}\'.format(length[\'value\'], len(elem)))\n    return elem\n  utils.map_nested(update_length, dict_list, dict_only=True)\n\n  # 3. Extract each individual elements\n  return [\n      utils.map_nested(lambda elem: elem[i], dict_list, dict_only=True)   # pylint: disable=cell-var-from-loop\n      for i in range(length[\'value\'])  # pytype: disable=wrong-arg-types\n  ]\n'"
tensorflow_datasets/core/features/sequence_feature_test.py,32,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.sequence_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features as feature_lib\n\ntf.enable_v2_behavior()\n\n\nclass SequenceDictFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_int(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence({\'int\': tf.int32}, length=3),\n        shape={\'int\': (3,)},\n        dtype={\'int\': tf.int32},\n        serialized_info={\n            \'int\': feature_lib.TensorInfo(shape=(3,), dtype=tf.int32),\n        },\n        tests=[\n            # Python array\n            testing.FeatureExpectationItem(\n                value={\'int\': [1, 2, 3]},\n                expected={\'int\': [1, 2, 3]},\n            ),\n            # Numpy array\n            testing.FeatureExpectationItem(\n                value={\'int\': np.ones(shape=(3,), dtype=np.int32)},\n                expected={\'int\': [1, 1, 1]},\n            ),\n            # Array of dict\n            testing.FeatureExpectationItem(\n                value=[\n                    {\'int\': 1},\n                    {\'int\': 10},\n                    {\'int\': 100},\n                ],\n                expected={\'int\': [1, 10, 100]},\n            ),\n            # Wrong sequence length\n            testing.FeatureExpectationItem(\n                value={\'int\': np.ones(shape=(4,), dtype=np.int32)},\n                raise_cls=ValueError,\n                raise_msg=\'Input sequence length do not match\',\n            ),\n        ],\n    )\n\n  def test_label(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence({\n            \'label\': feature_lib.ClassLabel(names=[\'left\', \'right\']),\n        }, length=None),\n        shape={\'label\': (None,)},\n        dtype={\'label\': tf.int64},\n        serialized_info={\n            \'label\': feature_lib.TensorInfo(shape=(None,), dtype=tf.int64),\n        },\n        tests=[\n            testing.FeatureExpectationItem(\n                value={\'label\': [\'right\', \'left\', \'left\']},\n                expected={\'label\': [1, 0, 0]},\n            ),\n            # Variable sequence length\n            testing.FeatureExpectationItem(\n                value={\'label\': [\'right\', \'left\', \'right\', \'left\']},\n                expected={\'label\': [1, 0, 1, 0]},\n            ),\n            # Empty sequence length\n            testing.FeatureExpectationItem(\n                value={\'label\': []},\n                expected={\'label\': []},\n            ),\n        ],\n    )\n\n  def test_nested(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence({\n            \'a\': tf.string,\n            \'b\': {\n                \'c\': feature_lib.Tensor(shape=(4, 2), dtype=tf.int32),\n                \'d\': tf.uint8,\n            }\n        }, length=None),\n        shape={\n            \'a\': (None,),\n            \'b\': {\n                \'c\': (None, 4, 2),\n                \'d\': (None,),\n            }\n        },\n        dtype={\n            \'a\': tf.string,\n            \'b\': {\n                \'c\': tf.int32,\n                \'d\': tf.uint8,\n            }\n        },\n        tests=[\n            testing.FeatureExpectationItem(\n                value={\n                    \'a\': [\'aa\', \'b\', \'ccc\'],\n                    \'b\': {\n                        \'c\': np.ones(shape=(3, 4, 2), dtype=np.int32),\n                        \'d\': [1, 2, 3],\n                    }\n                },\n                expected={\n                    \'a\': [\n                        tf.compat.as_bytes(t) for t in (\'aa\', \'b\', \'ccc\')\n                    ],\n                    \'b\': {\n                        \'c\': np.ones(shape=(3, 4, 2), dtype=np.int32),\n                        \'d\': [1, 2, 3],\n                    }\n                },\n            ),\n            testing.FeatureExpectationItem(\n                value={\n                    \'a\': [str(i) for i in range(100)],\n                    \'b\': [{   # pylint: disable=g-complex-comprehension\n                        \'c\': np.ones(shape=(4, 2), dtype=np.int32),\n                        \'d\': 5,\n                    } for _ in range(100)]\n                },\n                expected={\n                    \'a\': [tf.compat.as_bytes(str(i)) for i in range(100)],\n                    \'b\': {\n                        \'c\': np.ones(shape=(100, 4, 2), dtype=np.int32),\n                        \'d\': [5] * 100,\n                    }\n                },\n            ),\n            # Test inputs not same sequence length\n            testing.FeatureExpectationItem(\n                value={\n                    \'a\': [\'aa\', \'b\', \'ccc\'],\n                    \'b\': {\n                        \'c\': np.ones(shape=(4, 4, 2), dtype=np.int32),\n                        \'d\': [1, 2, 3],\n                    }\n                },\n                raise_cls=ValueError,\n                raise_msg=\'length of all elements of one sequence should\',\n            ),\n        ],\n    )\n\n  def test_encoding(self):\n\n    f = feature_lib.Sequence({\n        \'a\': feature_lib.Sequence({\'c\': tf.int64}),\n        \'b\': tf.int64,\n    })\n\n    # Different combinaison of list of dict/dict of list to encode the same\n    # nested sequence\n    ex1 = f.encode_example([\n        {\'a\': {\'c\': [1, 1, 1]}, \'b\': 1},\n        {\'a\': {\'c\': []}, \'b\': 2},\n        {\'a\': {\'c\': [3, 3]}, \'b\': 3},\n    ])\n\n    ex2 = f.encode_example([\n        {\'a\': [{\'c\': 1}, {\'c\': 1}, {\'c\': 1}], \'b\': 1},\n        {\'a\': [], \'b\': 2},\n        {\'a\': [{\'c\': 3}, {\'c\': 3}], \'b\': 3},\n    ])\n\n    ex3 = f.encode_example({\n        \'a\': [\n            [{\'c\': 1}, {\'c\': 1}, {\'c\': 1}],\n            [],\n            [{\'c\': 3}, {\'c\': 3}],\n        ],\n        \'b\': [1, 2, 3],\n    })\n\n    ex4 = f.encode_example({\n        \'a\': {\'c\': [[1, 1, 1], [], [3, 3]]},\n        \'b\': [1, 2, 3],\n    })\n\n    out = {\n        \'a\': {\'c\': tf.ragged.constant([\n            [1, 1, 1],\n            [],\n            [3, 3],\n        ])},\n        \'b\': [1, 2, 3],\n    }\n\n    def to_ragged(ex):\n      ex[\'a\'][\'c\'] = tf.ragged.constant(ex[\'a\'][\'c\'])\n      return ex\n    self.assertAllEqualNested(to_ragged(ex1), out)\n    self.assertAllEqualNested(to_ragged(ex2), out)\n    self.assertAllEqualNested(to_ragged(ex3), out)\n    self.assertAllEqualNested(to_ragged(ex4), out)\n\n    # Should raise error if two sequences do not have the same length.\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'length of all elements\'):\n      f.encode_example({\n          \'a\': {\'c\': [[1, 1, 1], []]},\n          \'b\': [1, 2, 3],\n      })\n\n    # Empty sequence should create the correct number of dimension\n    ex2 = f.encode_example([])\n    self.assertAllEqualNested(ex2, {\n        \'a\': {\'c\': np.zeros((0, 0), np.int64)},\n        \'b\': np.zeros((0,), np.int64),\n    })\n\n  def test_2lvl_sequences_mixed(self):\n    # Mix of sequence and non-sequence\n    self.assertFeature(\n        feature=feature_lib.Sequence({\n            \'a\': feature_lib.Sequence(tf.int32),\n            \'b\': tf.int32,\n        }),\n        shape={\n            \'a\': (None, None),\n            \'b\': (None,),\n        },\n        dtype={\n            \'a\': tf.int32,\n            \'b\': tf.int32,\n        },\n        tests=[\n            testing.FeatureExpectationItem(\n                value={\n                    \'a\': [[1, 1, 1], [], [3, 3]],\n                    \'b\': [1, 2, 3],\n                },\n                expected={\n                    \'a\': [[1, 1, 1], [], [3, 3]],\n                    \'b\': [1, 2, 3],\n                },\n            ),\n        ],\n    )\n\n  def test_2lvl_sequences(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence(\n            feature_lib.Sequence(\n                feature_lib.Tensor(shape=(2,), dtype=tf.int32),\n            ),\n        ),\n        shape=(None, None, 2),\n        dtype=tf.int32,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[\n                    [[0, 1], [2, 3]],\n                    [],\n                    [[4, 5]],\n                ],\n                expected=testing.RaggedConstant([\n                    [[0, 1], [2, 3]],\n                    [],\n                    [[4, 5]],\n                ], inner_shape=(2,)),\n            ),\n            # Empty\n            testing.FeatureExpectationItem(\n                value=[],\n                expected=[],\n            ),\n            # List of empty lists\n            testing.FeatureExpectationItem(\n                value=[[], [], []],\n                expected=[[], [], []],\n            ),\n            # List of empty np.array\n            testing.FeatureExpectationItem(\n                value=[\n                    np.empty(shape=(0, 2), dtype=np.int32),\n                    np.empty(shape=(0, 2), dtype=np.int32),\n                ],\n                expected=[\n                    [],\n                    [],\n                ],\n            ),\n            testing.FeatureExpectationItem(\n                value=[\n                    np.empty(shape=(0, 2), dtype=np.int32),\n                    np.empty(shape=(0, 2), dtype=np.int32),\n                    np.ones(shape=(3, 2), dtype=np.int32),\n                ],\n                expected=[\n                    [],\n                    [],\n                    [[1, 1], [1, 1], [1, 1]],\n                ],\n            ),\n            # Wrong types should fails\n            testing.FeatureExpectationItem(\n                value=[\n                    np.ones(shape=(3, 2), dtype=np.float32),\n                ],\n                raise_cls=ValueError,\n                raise_msg=\'float32 do not match int32\',\n            ),\n        ],\n    )\n\n  def test_2lvl_sequences_string(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence(\n            feature_lib.Sequence(tf.string),\n        ),\n        shape=(None, None,),\n        dtype=tf.string,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[\n                    [\'abcd\', \'\', \'efg\'],\n                    [],\n                    [\'\', \'\'],\n                    [\'hij\'],\n                ],\n                expected=[\n                    [b\'abcd\', b\'\', b\'efg\'],\n                    [],\n                    [b\'\', b\'\'],\n                    [b\'hij\'],\n                ],\n            ),\n            testing.FeatureExpectationItem(\n                value=[\n                    [],\n                    [],\n                ],\n                expected=[\n                    [],\n                    [],\n                ],\n            ),\n            testing.FeatureExpectationItem(\n                value=[\n                    [\'abcd\', \'efg\', 123],\n                ],\n                raise_cls=TypeError,\n                raise_msg=\'Expected binary or unicode string\',\n            ),\n        ],\n    )\n\n  def test_3lvl_sequence(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence(\n            feature_lib.Sequence(\n                feature_lib.Sequence(tf.int32),\n                length=3,\n            ),\n        ),\n        shape=(None, 3, None),\n        dtype=tf.int32,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[\n                    [[1, 2, 3], [], [4, 5]],\n                    [[10, 11], [12, 13], [14]],\n                ],\n                expected=[\n                    [[1, 2, 3], [], [4, 5]],\n                    [[10, 11], [12, 13], [14]],\n                ],\n            ),\n            testing.FeatureExpectationItem(\n                value=[\n                    [[1, 2, 3], [4, 5]],  # < Only 2 instead of 3\n                    [[10, 11], [12, 13], [14]],\n                ],\n                raise_cls=ValueError,\n                raise_msg=\'Input sequence length do not match\',\n            ),\n        ],\n    )\n\n  def test_image(self):\n\n    imgs = [\n        np.random.randint(256, size=(128, 100, 3), dtype=np.uint8),\n        np.random.randint(256, size=(128, 100, 3), dtype=np.uint8),\n        np.random.randint(256, size=(128, 100, 3), dtype=np.uint8),\n        np.random.randint(256, size=(128, 100, 3), dtype=np.uint8),\n    ]\n    imgs_stacked = np.stack(imgs)\n\n    self.assertFeature(\n        feature=feature_lib.Sequence({\n            \'image\': feature_lib.Image(shape=(128, 100, 3)),\n        }, length=None),\n        shape={\'image\': (None, 128, 100, 3)},\n        dtype={\'image\': tf.uint8},\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[{\'image\': img} for img in imgs],\n                expected={\'image\': imgs_stacked},\n            ),\n            testing.FeatureExpectationItem(\n                value={\'image\': imgs_stacked},\n                expected={\'image\': imgs_stacked},\n            ),\n            testing.FeatureExpectationItem(\n                value={\'image\': imgs},\n                expected={\'image\': imgs_stacked},\n            ),\n            # Empty value\n            testing.FeatureExpectationItem(\n                value={\'image\': []},\n                # The empty value still has the right shape\n                expected={\'image\': np.empty(\n                    shape=(0, 128, 100, 3),\n                    dtype=np.uint8\n                )},\n            ),\n        ],\n    )\n\n  # Should add unittest for _transpose_dict_list\n\n\nclass SequenceFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_int(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence(tf.int32, length=3),\n        shape=(3,),\n        dtype=tf.int32,\n        tests=[\n            # Python array\n            testing.FeatureExpectationItem(\n                value=[1, 2, 3],\n                expected=[1, 2, 3],\n            ),\n            # Numpy array\n            testing.FeatureExpectationItem(\n                value=np.ones(shape=(3,), dtype=np.int32),\n                expected=[1, 1, 1],\n            ),\n            # Wrong sequence length\n            testing.FeatureExpectationItem(\n                value=np.ones(shape=(4,), dtype=np.int32),\n                raise_cls=ValueError,\n                raise_msg=\'Input sequence length do not match\',\n            ),\n        ],\n    )\n\n  def test_label(self):\n\n    self.assertFeature(\n        feature=feature_lib.Sequence(\n            feature_lib.ClassLabel(names=[\'left\', \'right\']),\n        ),\n        shape=(None,),\n        dtype=tf.int64,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=[\'right\', \'left\', \'left\'],\n                expected=[1, 0, 0],\n            ),\n            # Variable sequence length\n            testing.FeatureExpectationItem(\n                value=[\'right\', \'left\', \'right\', \'left\'],\n                expected=[1, 0, 1, 0],\n            ),\n            # Empty sequence length\n            testing.FeatureExpectationItem(\n                value=[],\n                expected=[],\n            ),\n        ],\n    )\n\n  def test_getattr(self):\n    feature = feature_lib.Sequence(\n        feature_lib.ClassLabel(names=[\'left\', \'right\']),\n    )\n    self.assertEqual(feature.names, [\'left\', \'right\'])\n\n    feature = feature_lib.Sequence({\n        \'label\': feature_lib.ClassLabel(names=[\'left\', \'right\']),\n    })\n    self.assertEqual(feature[\'label\'].names, [\'left\', \'right\'])\n\n  def test_metadata(self):\n    feature = feature_lib.Sequence(feature_lib.ClassLabel(num_classes=2))\n    feature.feature.names = [\'left\', \'right\']\n    with testing.tmp_dir() as tmp_dir:\n      feature.save_metadata(data_dir=tmp_dir, feature_name=\'test\')\n\n      feature2 = feature_lib.Sequence(feature_lib.ClassLabel(num_classes=2))\n      feature2.load_metadata(data_dir=tmp_dir, feature_name=\'test\')\n    self.assertEqual(feature2.feature.names, [\'left\', \'right\'])\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/text_feature.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Text feature.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.features import feature\nfrom tensorflow_datasets.core.features import text as text_lib\n\n\nclass Text(feature.Tensor):\n  """"""`FeatureConnector` for text, encoding to integers with a `TextEncoder`.""""""\n\n  def __init__(self, encoder=None, encoder_config=None):\n    """"""Constructs a Text FeatureConnector.\n\n    Args:\n      encoder: `tfds.features.text.TextEncoder`, an encoder that can convert\n        text to integers. If None, the text will be utf-8 byte-encoded.\n      encoder_config: `tfds.features.text.TextEncoderConfig`, needed if\n        restoring from a file with `load_metadata`.\n    """"""\n    if encoder and encoder_config:\n      raise ValueError(""If encoder is provided, encoder_config must be None."")\n    if encoder:\n      encoder_config = text_lib.TextEncoderConfig(\n          encoder_cls=type(encoder),\n          vocab_size=encoder.vocab_size)\n    elif encoder_config:\n      encoder = encoder_config.encoder\n\n    self._encoder = encoder\n    self._encoder_config = encoder_config\n\n    has_encoder = bool(encoder or self._encoder_cls)\n    if has_encoder:\n      logging.warning(\n          ""TFDS datasets with text encoding are deprecated and will be removed ""\n          ""in a future version. Instead, you should use the plain text version ""\n          ""and tokenize the text using `tensorflow_text` (See: ""\n          ""https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)""\n      )\n    super(Text, self).__init__(\n        shape=(None,) if has_encoder else (),\n        dtype=tf.int64 if has_encoder else tf.string,\n    )\n\n  @property\n  def encoder(self):\n    return self._encoder\n\n  @encoder.setter\n  def encoder(self, new_encoder):\n    if self.encoder:\n      raise ValueError(""Cannot override encoder"")\n    self._encoder = new_encoder\n    encoder_cls = self._encoder_cls or type(None)\n    if not isinstance(new_encoder, encoder_cls):\n      raise ValueError(\n          ""Changing type of encoder. Got %s but must be %s"" %\n          (type(new_encoder).__name__,\n           self._encoder_cls.__name__))\n\n  def maybe_set_encoder(self, new_encoder):\n    """"""Set encoder, but no-op if encoder is already set.""""""\n    if self.encoder:\n      return\n    self.encoder = new_encoder\n\n  @property\n  def vocab_size(self):\n    return self.encoder and self.encoder.vocab_size\n\n  def str2ints(self, str_value):\n    """"""Conversion string => encoded list[int].""""""\n    if not self._encoder:\n      raise ValueError(\n          ""Text.str2ints is not available because encoder hasn\'t been defined."")\n    return self._encoder.encode(str_value)\n\n  def ints2str(self, int_values):\n    """"""Conversion list[int] => decoded string.""""""\n    if not self._encoder:\n      raise ValueError(\n          ""Text.ints2str is not available because encoder hasn\'t been defined."")\n    return self._encoder.decode(int_values)\n\n  def encode_example(self, example_data):\n    if self.encoder:\n      example_data = self.encoder.encode(example_data)\n    return super(Text, self).encode_example(example_data)\n\n  def save_metadata(self, data_dir, feature_name):\n    fname_prefix = os.path.join(data_dir, ""%s.text"" % feature_name)\n    if not self.encoder:\n      return\n    self.encoder.save_to_file(fname_prefix)\n\n  def load_metadata(self, data_dir, feature_name):\n    fname_prefix = os.path.join(data_dir, ""%s.text"" % feature_name)\n    encoder_cls = self._encoder_cls\n    if encoder_cls:\n      self._encoder = encoder_cls.load_from_file(fname_prefix)  # pytype: disable=attribute-error\n      return\n\n    # Error checking: ensure there are no metadata files\n    feature_files = [\n        f for f in tf.io.gfile.listdir(data_dir) if f.startswith(fname_prefix)\n    ]\n    if feature_files:\n      raise ValueError(\n          ""Text feature files found for feature %s but encoder_cls=None. ""\n          ""Make sure to set encoder_cls in the TextEncoderConfig. ""\n          ""Files: %s"" % (feature_name, feature_files))\n\n  def maybe_build_from_corpus(self, corpus_generator, **kwargs):\n    """"""Call SubwordTextEncoder.build_from_corpus is encoder_cls is such.\n\n    If `self.encoder` is `None` and `self._encoder_cls` is of type\n    `SubwordTextEncoder`, the method instantiates `self.encoder` as returned\n    by `SubwordTextEncoder.build_from_corpus()`.\n\n    Args:\n      corpus_generator: generator yielding `str`, from which\n        subwords will be constructed.\n      **kwargs: kwargs forwarded to `SubwordTextEncoder.build_from_corpus()`\n    """"""\n    if self._encoder_cls is not text_lib.SubwordTextEncoder:\n      return\n    if self.encoder:\n      return\n\n    vocab_size = self._encoder_config.vocab_size\n    self.encoder = text_lib.SubwordTextEncoder.build_from_corpus(\n        corpus_generator=corpus_generator,\n        target_vocab_size=vocab_size,\n        **kwargs)\n\n  @property\n  def _encoder_cls(self):\n    return self._encoder_config and self._encoder_config.encoder_cls\n\n  def _additional_repr_info(self):\n    if self.encoder is None:\n      return {}\n    return {""encoder"": repr(self.encoder)}\n'"
tensorflow_datasets/core/features/text_feature_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""Tests for tensorflow_datasets.core.features.text_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core.features.text import text_encoder\n\ntf.enable_v2_behavior()\n\n\nclass TextFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_text(self):\n    nonunicode_text = \'hello world\'\n    unicode_text = u\'\xe4\xbd\xa0\xe5\xa5\xbd\'\n\n    self.assertFeature(\n        feature=features.Text(),\n        shape=(),\n        dtype=tf.string,\n        tests=[\n            # Non-unicode\n            testing.FeatureExpectationItem(\n                value=nonunicode_text,\n                expected=tf.compat.as_bytes(nonunicode_text),\n            ),\n            # Unicode\n            testing.FeatureExpectationItem(\n                value=unicode_text,\n                expected=tf.compat.as_bytes(unicode_text),\n            ),\n            # Empty string\n            testing.FeatureExpectationItem(\n                value=\'\',\n                expected=tf.compat.as_bytes(\'\'),\n            ),\n        ],\n    )\n\n  def test_text_encoded(self):\n    unicode_text = u\'\xe4\xbd\xa0\xe5\xa5\xbd\'\n\n    # Unicode integer-encoded by byte\n    self.assertFeature(\n        feature=features.Text(encoder=text_encoder.ByteTextEncoder()),\n        shape=(None,),\n        dtype=tf.int64,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=unicode_text,\n                expected=[i + 1 for i in [228, 189, 160, 229, 165, 189]],\n            ),\n            # Empty string\n            testing.FeatureExpectationItem(\n                value=\'\',\n                expected=[],\n            ),\n        ],\n    )\n\n  def test_text_conversion(self):\n    text_f = features.Text(encoder=text_encoder.ByteTextEncoder())\n    text = u\'\xe4\xbd\xa0\xe5\xa5\xbd\'\n    self.assertEqual(text, text_f.ints2str(text_f.str2ints(text)))\n\n  def test_save_load_metadata(self):\n    text_f = features.Text(\n        encoder=text_encoder.ByteTextEncoder(additional_tokens=[\'HI\']))\n    text = u\'HI \xe4\xbd\xa0\xe5\xa5\xbd\'\n    ids = text_f.str2ints(text)\n    self.assertEqual(1, ids[0])\n\n    with testing.tmp_dir(self.get_temp_dir()) as data_dir:\n      feature_name = \'dummy\'\n      text_f.save_metadata(data_dir, feature_name)\n\n      new_f = features.Text()\n      new_f.load_metadata(data_dir, feature_name)\n      self.assertEqual(ids, text_f.str2ints(text))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/top_level_feature.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Wrapper around FeatureDict to allow better control over decoding.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.features import feature as feature_lib\n\n\nclass TopLevelFeature(feature_lib.FeatureConnector):\n  """"""Top-level `FeatureConnector` to manage decoding.\n\n  Note that `FeatureConnector` which are declared as `TopLevelFeature` can be\n  nested. However, only the top-level feature can be decoded.\n\n  `TopLevelFeature` allows better control over the decoding, and\n  eventually better support for augmentations.\n  """"""\n\n  def __init__(self, *args, **kwargs):\n    """"""Constructor.""""""\n    self.__is_top_level = False\n    super(TopLevelFeature, self).__init__(*args, **kwargs)\n\n  # AutoGraph doesn\'t support mangled names (__is_top_level), so we explicitly\n  # disable it in methods that use them, to avoid the warning.\n  # TODO(mdan): Remove decorator once AutoGraph supports mangled names.\n  @tf.autograph.experimental.do_not_convert()\n  def _set_top_level(self):\n    """"""Indicates that the feature is top level.\n\n    Internal function called by `DatasetInfo`.\n    """"""\n    self.__is_top_level = True\n\n  # AutoGraph doesn\'t support mangled names (__is_top_level), so we explicitly\n  # disable it in methods that use them, to avoid the warning.\n  # TODO(mdan): Remove decorator once AutoGraph supports mangled names.\n  @tf.autograph.experimental.do_not_convert()\n  def decode_example(self, serialized_example, decoders=None):\n    # pylint: disable=line-too-long\n    """"""Decode the serialize examples.\n\n    Args:\n      serialized_example: Nested `dict` of `tf.Tensor`\n      decoders: Nested dict of `Decoder` objects which allow to customize the\n        decoding. The structure should match the feature structure, but only\n        customized feature keys need to be present. See\n        [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n        for more info.\n\n    Returns:\n      example: Nested `dict` containing the decoded nested examples.\n    """"""\n    # pylint: enable=line-too-long\n    if not self.__is_top_level:\n      raise AssertionError(\n          \'Feature {} can only be decoded when defined as top-level \'\n          \'feature, through info.features.decode_example()\'.format(\n              type(self).__name__))\n\n    # Step 1: Flatten the nested dict => []\n    flat_example = self._flatten(serialized_example)\n    flat_features = self._flatten(self)\n    flat_serialized_info = self._flatten(self.get_serialized_info())\n    flat_decoders = self._flatten(decoders)\n\n    # Step 2: Apply the decoding\n    flatten_decoded = []\n    for (\n        feature,\n        example,\n        serialized_info,\n        decoder,\n    ) in zip(\n        flat_features,\n        flat_example,\n        flat_serialized_info,\n        flat_decoders):\n      flatten_decoded.append(_decode_feature(\n          feature=feature,\n          example=example,\n          serialized_info=serialized_info,\n          decoder=decoder,\n      ))\n\n    # Step 3: Restore nesting [] => {}\n    nested_decoded = self._nest(flatten_decoded)\n    return nested_decoded\n\n\ndef _decode_feature(feature, example, serialized_info, decoder):\n  """"""Decode a single feature.""""""\n  # Eventually overwrite the default decoding\n  if decoder is not None:\n    decoder.setup(feature=feature)\n  else:\n    decoder = feature\n\n  sequence_rank = _get_sequence_rank(serialized_info)\n  if sequence_rank == 0:\n    return decoder.decode_example(example)\n  elif sequence_rank == 1:\n    # Return a batch of examples from a sequence\n    return decoder.decode_batch_example(example)\n  elif sequence_rank > 1:\n    # Use ragged tensor if the sequance rank is greater than one\n    return decoder.decode_ragged_example(example)\n\n\ndef _get_sequence_rank(serialized_info):\n  """"""Return the number of sequence dimensions of the feature.""""""\n  if isinstance(serialized_info, dict):\n    all_sequence_rank = [s.sequence_rank for s in serialized_info.values()]\n  else:\n    all_sequence_rank = [serialized_info.sequence_rank]\n\n  sequence_ranks = set(all_sequence_rank)\n  if len(sequence_ranks) != 1:\n    raise NotImplementedError(\n        \'Decoding do not support mixing sequence and context features within a \'\n        \'single FeatureConnector. Received inputs of different sequence_rank: \'\n        \'{}\'.format(sequence_ranks)\n    )\n  return next(iter(sequence_ranks))\n'"
tensorflow_datasets/core/features/top_level_feature_test.py,13,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.top_level_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features as features_lib\nfrom tensorflow_datasets.core.features import top_level_feature\n\n\nclass FeaturesManagerTest(testing.TestCase):\n\n  def test_sequence_rank(self):\n\n    self.assertEqual(1, top_level_feature._get_sequence_rank({\n        \'a\': features_lib.TensorInfo(\n            shape=(None, 3), dtype=tf.int32, sequence_rank=1),\n        \'b\': features_lib.TensorInfo(\n            shape=(None,), dtype=tf.int32, sequence_rank=1),\n    }))\n\n    with self.assertRaisesWithPredicateMatch(\n        NotImplementedError, \'mixing sequence and context\'):\n      top_level_feature._get_sequence_rank({\n          \'a\': features_lib.TensorInfo(\n              shape=(), dtype=tf.int32),\n          \'b\': features_lib.TensorInfo(\n              shape=(None,), dtype=tf.int32, sequence_rank=1),\n      })\n\n  def test_flatten_nested(self):\n\n    f = features_lib.FeaturesDict({\n        \'a\': tf.int32,\n        \'b\': {\n            \'c\': {\n                \'d\': tf.int32,\n                \'e\': tf.int32,\n            },\n        },\n        \'f\': features_lib.Sequence({\n            \'g\': features_lib.Sequence(tf.int32),\n            \'h\': tf.int32,\n        }),\n    })\n\n    flat1 = f._flatten({\n        \'a\': \'a\',\n        \'b\': {\n            \'c\': {\n                \'d\': {\'d\': 123},\n            },\n        },\n        \'f\': {\n            \'g\': \'g\',\n        },\n    })\n    self.assertEqual(flat1, [\n        \'a\',\n        {\'d\': 123},\n        None,  # \'e\'\n        \'g\',\n        None,  # h\n    ])\n    self.assertEqual(f._nest(flat1), {\n        \'a\': \'a\',\n        \'b\': {\n            \'c\': {\n                \'d\': {\'d\': 123},\n                \'e\': None,\n            },\n        },\n        \'f\': {\n            \'g\': \'g\',\n            \'h\': None,\n        },\n    })\n\n    f = features_lib.FeaturesDict({\n        \'a\': tf.int32,\n        \'b\': {\n            \'c\': tf.int32,\n        },\n    })\n    with self.assertRaisesWithPredicateMatch(ValueError, \'received a non dict\'):\n      f._flatten({\'b\': 123})\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'Unrecognized keys: [\\\'d\\\']\'):\n      f._flatten({\'b\': {\'c\': 123, \'d\': 123}})\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'Expected length 2 does not match input length 3\'):\n      f._nest([None, None, None])\n\n  def test_top_level(self):\n\n    f = features_lib.FeaturesDict({\n        \'a\': tf.int32,\n        \'b\': {\n            \'c\': tf.int32,\n        },\n    })\n    f._set_top_level()\n\n    # Only top level can be decoded\n    f.decode_example({\n        \'a\': 1,\n        \'b\': {\n            \'c\': 2,\n        },\n    })\n\n    with self.assertRaisesWithPredicateMatch(\n        AssertionError, \'decoded when defined as top-level\'):\n      f[\'b\'].decode_example({\'c\': 1})\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/translation_feature.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Translation feature that supports multiple languages.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nfrom tensorflow_datasets.core.features import features_dict\nfrom tensorflow_datasets.core.features import sequence_feature\nfrom tensorflow_datasets.core.features import text_feature\ntry:\n  # This fallback applies for all versions of Python before 3.3\n  import collections.abc as collections_abc  # pylint:disable=g-import-not-at-top  # pytype: disable=module-attr\nexcept ImportError:\n  import collections as collections_abc  # pylint:disable=g-import-not-at-top\n\n\nclass Translation(features_dict.FeaturesDict):\n  """"""`FeatureConnector` for translations with fixed languages per example.\n\n  Input: The Translate feature accepts a dictionary for each example mapping\n    string language codes to string translations.\n\n  Output: A dictionary mapping string language codes to translations as `Text`\n    features.\n\n  Example:\n  At construction time:\n\n  ```\n  tfds.features.Translation(languages=[\'en\', \'fr\', \'de\'])\n  ```\n\n  During data generation:\n\n  ```\n  yield {\n      \'en\': \'the cat\',\n      \'fr\': \'le chat\',\n      \'de\': \'die katze\'\n  }\n  ```\n\n  Tensor returned by `.as_dataset()`:\n\n  ```\n  {\n      \'en\': tf.Tensor(shape=(), dtype=tf.string, numpy=\'the cat\'),\n      \'fr\': tf.Tensor(shape=(), dtype=tf.string, numpy=\'le chat\'),\n      \'de\': tf.Tensor(shape=(), dtype=tf.string, numpy=\'die katze\'),\n  }\n  ```\n  """"""\n\n  def __init__(self, languages, encoder=None, encoder_config=None):\n    """"""Constructs a Translation FeatureConnector.\n\n    Args:\n      languages: `list<string>` Full list of languages codes.\n      encoder: `tfds.features.text.TextEncoder` or\n        list<tfds.features.text.TextEncoder> (optional), an encoder that can\n        convert text to integer. One can be shared one per language provided. If\n        None, the text will be utf-8 byte-encoded.\n      encoder_config: `tfds.features.text.TextEncoderConfig` or\n        `list<tfds.features.text.TextEncoderConfig>` (optional), needed\n        if restoring from a file with `load_metadata`. One config can be shared\n        or one per language can be provided.\n    """"""\n    # If encoder and encoder_config aren\'t lists, use the same values for all\n    # languages.\n    if not isinstance(encoder, collections_abc.Iterable):\n      encoder = [encoder] * len(languages)\n    if not isinstance(encoder_config, collections_abc.Iterable):\n      encoder_config = [encoder_config] * len(languages)\n\n    super(Translation, self).__init__(\n        {lang: text_feature.Text(enc, enc_conf) for lang, enc, enc_conf in zip(\n            languages, encoder, encoder_config)})\n\n  @property\n  def languages(self):\n    """"""List of languages.""""""\n    return sorted(self.keys())\n\n\nclass TranslationVariableLanguages(sequence_feature.Sequence):\n  """"""`FeatureConnector` for translations with variable languages per example.\n\n  Input: The TranslationVariableLanguages feature accepts a dictionary for each\n    example mapping string language codes to one or more string translations.\n    The languages present may vary from example to example.\n\n  Output:\n    language: variable-length 1D tf.Tensor of tf.string language codes, sorted\n      in ascending order.\n    translation: variable-length 1D tf.Tensor of tf.string plain text\n      translations, sorted to align with language codes.\n\n  Example (fixed language list):\n  At construction time:\n\n  ```\n  tfds.features.Translation(languages=[\'en\', \'fr\', \'de\'])\n  ```\n\n  During data generation:\n\n  ```\n  yield {\n      \'en\': \'the cat\',\n      \'fr\': [\'le chat\', \'la chatte,\']\n      \'de\': \'die katze\'\n  }\n  ```\n\n  Tensor returned by `.as_dataset()`:\n\n  ```\n  {\n      \'language\': tf.Tensor(\n          shape=(4,), dtype=tf.string, numpy=array([\'en\', \'de\', \'fr\', \'fr\']),\n      \'translation\': tf.Tensor(\n          shape=(4,), dtype=tf.string,\n          numpy=array([\'the cat\', \'die katze\', \'la chatte\', \'le chat\'])),\n  }\n  ```\n  """"""\n\n  def __init__(self, languages=None):\n    """"""Constructs a Translation FeatureConnector.\n\n    Args:\n      languages: `list<string>` (optional), full list of language codes if known\n        in advance.\n    """"""\n    # TODO(adarob): Add optional text encoders once `Sequence` adds support\n    # for FixedVarLenFeatures.\n\n    self._languages = set(languages) if languages else None\n    super(TranslationVariableLanguages, self).__init__({\n        ""language"": text_feature.Text(),\n        ""translation"": text_feature.Text(),\n    })\n\n  @property\n  def num_languages(self):\n    """"""Number of languages or None, if not specified in advance.""""""\n    return len(self._languages) if self._languages else None\n\n  @property\n  def languages(self):\n    """"""List of languages or None, if not specified in advance.""""""\n    return sorted(list(self._languages)) if self._languages else None\n\n  def encode_example(self, translation_dict):\n    if self.languages and set(translation_dict) - self._languages:\n      raise ValueError(\n          ""Some languages in example ({0}) are not in valid set ({1})."".format(\n              "", "".join(sorted(set(translation_dict) - self._languages)),\n              "", "".join(self.languages)))\n\n    # Convert dictionary into tuples, splitting out cases where there are\n    # multiple translations for a single language.\n    translation_tuples = []\n    for lang, text in translation_dict.items():\n      if isinstance(text, six.string_types):\n        translation_tuples.append((lang, text))\n      else:\n        translation_tuples.extend([(lang, el) for el in text])\n\n    # Ensure translations are in ascending order by language code.\n    languages, translations = zip(*sorted(translation_tuples))\n\n    return super(TranslationVariableLanguages, self).encode_example(\n        {""language"": languages,\n         ""translation"": translations})\n\n'"
tensorflow_datasets/core/features/translation_feature_test.py,22,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""Tests for tensorflow_datasets.core.features.text_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\nfrom tensorflow_datasets.core.features.text import text_encoder\n\ntf.enable_v2_behavior()\n\nDE_HELLO = ""hallo ""\nEN_HELLO = ""hello ""\nFR_HELLO = ""bonjour ""\nZH_HELLO = ""\xe4\xbd\xa0\xe5\xa5\xbd ""\n\nDE_B = tf.compat.as_bytes(""de"")\nEN_B = tf.compat.as_bytes(""en"")\nFR_B = tf.compat.as_bytes(""fr"")\nZH_B = tf.compat.as_bytes(""zh"")\n\n\nclass TranslationFeatureTest(testing.FeatureExpectationsTestCase):\n\n  def test_translation(self):\n    self.assertFeature(\n        feature=features.Translation([""en"", ""zh""]),\n        shape={""en"": (), ""zh"": ()},\n        dtype={""en"": tf.string, ""zh"": tf.string},\n        tests=[\n            testing.FeatureExpectationItem(\n                value={""en"": EN_HELLO, ""zh"": ZH_HELLO},\n                expected={""en"": tf.compat.as_bytes(EN_HELLO),\n                          ""zh"": tf.compat.as_bytes(ZH_HELLO)}\n            ),\n        ],\n    )\n\n  def test_translation_encoded(self):\n    # Unicode integer-encoded by byte\n    self.assertFeature(\n        feature=features.Translation(\n            languages=[""en"", ""zh""],\n            encoder=text_encoder.ByteTextEncoder()),\n        shape={""en"": (None,), ""zh"": (None,)},\n        dtype={""en"": tf.int64, ""zh"": tf.int64},\n        tests=[\n            testing.FeatureExpectationItem(\n                value={""en"": EN_HELLO, ""zh"": ZH_HELLO},\n                expected={\n                    # Incremented for pad\n                    ""en"": [i + 1 for i in [104, 101, 108, 108, 111, 32]],\n                    ""zh"": [i + 1 for i in [228, 189, 160, 229, 165, 189, 32]]\n                },\n            ),\n        ],\n    )\n\n  def test_translation_multiple_encoders(self):\n    # Unicode integer-encoded by byte\n    self.assertFeature(\n        feature=features.Translation(\n            languages=[""en"", ""zh""],\n            encoder=[text_encoder.TokenTextEncoder([""hello"", "" ""]),\n                     text_encoder.ByteTextEncoder()]),\n        shape={""en"": (None,), ""zh"": (None,)},\n        dtype={""en"": tf.int64, ""zh"": tf.int64},\n        tests=[\n            testing.FeatureExpectationItem(\n                value={""en"": EN_HELLO, ""zh"": ZH_HELLO},\n                expected={\n                    ""en"": [1],\n                    ""zh"": [i + 1 for i in [228, 189, 160, 229, 165, 189, 32]]\n                },\n            ),\n        ],\n    )\n\n\nclass TranslationVariableLanguagesFeatureTest(\n    testing.FeatureExpectationsTestCase):\n\n  def test_translation_variable_languages_nolist(self):\n    self.assertFeature(\n        feature=features.TranslationVariableLanguages(),\n        shape={""language"": (None,), ""translation"": (None,)},\n        dtype={""language"": tf.string, ""translation"": tf.string},\n        tests=[\n            testing.FeatureExpectationItem(\n                value={""en"": EN_HELLO, ""zh"": ZH_HELLO},\n                expected={""language"": [EN_B, ZH_B],\n                          ""translation"": [tf.compat.as_bytes(EN_HELLO),\n                                          tf.compat.as_bytes(ZH_HELLO)]}\n            ),\n            testing.FeatureExpectationItem(\n                value={""fr"": FR_HELLO, ""de"": DE_HELLO, ""zh"": ZH_HELLO},\n                expected={""language"": [DE_B, FR_B, ZH_B],\n                          ""translation"": [tf.compat.as_bytes(DE_HELLO),\n                                          tf.compat.as_bytes(FR_HELLO),\n                                          tf.compat.as_bytes(ZH_HELLO)]}\n            ),\n            testing.FeatureExpectationItem(\n                value={""fr"": [FR_HELLO, FR_HELLO[0:-1]],\n                       ""en"": EN_HELLO},\n                expected={""language"": [EN_B, FR_B, FR_B],\n                          ""translation"": [tf.compat.as_bytes(EN_HELLO),\n                                          tf.compat.as_bytes(FR_HELLO[0:-1]),\n                                          tf.compat.as_bytes(FR_HELLO)]}\n            ),\n        ],\n    )\n\n  def test_translation_variable_languages_list(self):\n    self.assertFeature(\n        feature=features.TranslationVariableLanguages(\n            languages=[""en"", ""de"", ""zh""]),\n        shape={""language"": (None,), ""translation"": (None,)},\n        dtype={""language"": tf.string, ""translation"": tf.string},\n        tests=[\n            testing.FeatureExpectationItem(\n                value={""en"": EN_HELLO, ""zh"": ZH_HELLO},\n                expected={""language"": [EN_B, ZH_B],\n                          ""translation"": [tf.compat.as_bytes(EN_HELLO),\n                                          tf.compat.as_bytes(ZH_HELLO)]}\n            ),\n            testing.FeatureExpectationItem(\n                value={""fr"": FR_HELLO, ""de"": DE_HELLO, ""zh"": ZH_HELLO},\n                raise_cls=ValueError,\n                raise_msg=""Some languages in example (fr) are not in valid set ""\n                          ""(de, en, zh)"",\n            ),\n        ],\n    )\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/features/video_feature.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Video feature.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\nimport tempfile\n\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.features import image_feature\nfrom tensorflow_datasets.core.features import sequence_feature\n\n\nclass Video(sequence_feature.Sequence):\n  """"""`FeatureConnector` for videos, encoding frames individually on disk.\n\n  Video: The image connector accepts as input a 4 dimensional `tf.uint8` array\n  representing a video, a sequence of paths to encoded frames, or a path or a\n  file object that can be decoded with ffmpeg. Note that not all formats in\n  ffmpeg support reading from pipes, so providing a file object might fail.\n  Furthermore, if a path is given that is not on the local file system, we first\n  copy it to a temporary local file before passing it to ffmpeg.\n\n  Output:\n    video: tf.Tensor of type `tf.uint8` and shape\n      [num_frames, height, width, channels], where channels must be 1 or 3\n\n  Example:\n    * In the DatasetInfo object:\n\n    ```\n    features=features.FeatureDict({\n        \'video\': features.Video(shape=(None, 64, 64, 3)),\n    })\n    ```\n\n    * During generation, you can use any of:\n\n    ```\n    yield {\n        \'video\': np.ones(shape=(128, 64, 64, 3), dtype=np.uint8),\n    }\n    ```\n\n    or list of frames:\n\n    ```\n    yield {\n        \'video\': [\'path/to/frame001.png\', \'path/to/frame002.png\'],\n    }\n    ```\n\n    or path to video:\n\n    ```\n    yield {\n        \'video\': \'/path/to/video.avi\',\n    }\n    ```\n\n    or file object:\n\n    ```\n    yield {\n        \'video\': tf.io.gfile.GFile(\'/complex/path/video.avi\'),\n    }\n    ```\n\n  """"""\n\n  def __init__(self, shape, encoding_format=\'png\', ffmpeg_extra_args=()):\n    """"""Initializes the connector.\n\n    Args:\n      shape: tuple of ints, the shape of the video (num_frames, height, width,\n        channels), where channels is 1 or 3.\n      encoding_format: The video is stored as a sequence of encoded images.\n        You can use any encoding format supported by image_feature.Feature.\n      ffmpeg_extra_args: A sequence of additional args to be passed to the\n        ffmpeg binary. Specifically, ffmpeg will be called as:\n          ``\n          ffmpeg -i <input_file> <ffmpeg_extra_args> %010d.<encoding_format>\n          ``\n    Raises:\n      ValueError: If the shape is invalid\n    """"""\n    shape = tuple(shape)\n    if len(shape) != 4:\n      raise ValueError(\'Video shape should be of rank 4\')\n    self._encoding_format = encoding_format\n    self._extra_ffmpeg_args = list(ffmpeg_extra_args or [])\n    super(Video, self).__init__(\n        image_feature.Image(shape=shape[1:], encoding_format=encoding_format),\n        length=shape[0],\n    )\n\n  @property\n  def _ffmpeg_path(self):\n    return \'ffmpeg\'\n\n\n  def _ffmpeg_decode(self, path_or_fobj):\n    if isinstance(path_or_fobj, six.string_types):\n      ffmpeg_args = [self._ffmpeg_path, \'-i\', path_or_fobj]\n      ffmpeg_stdin = None\n    else:\n      ffmpeg_args = [self._ffmpeg_path, \'-i\', \'pipe:0\']\n      ffmpeg_stdin = path_or_fobj.read()\n\n    ffmpeg_dir = tempfile.mkdtemp()\n    output_pattern = os.path.join(ffmpeg_dir, \'%010d.\' + self._encoding_format)\n    ffmpeg_args += self._extra_ffmpeg_args\n    ffmpeg_args.append(output_pattern)\n    try:\n      process = subprocess.Popen(ffmpeg_args,\n                                 stdin=subprocess.PIPE,\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE)\n      stdout_data, stderr_data = process.communicate(ffmpeg_stdin)\n      ffmpeg_ret_code = process.returncode\n      if ffmpeg_ret_code:\n        raise ValueError(\n            \'ffmpeg returned error code {}, command={}\\n\'\n            \'stdout={}\\nstderr={}\\n\'.format(ffmpeg_ret_code,\n                                            \' \'.join(ffmpeg_args),\n                                            stdout_data,\n                                            stderr_data))\n      frames = []\n      for image_name in sorted(tf.io.gfile.listdir(ffmpeg_dir)):\n        image_path = os.path.join(ffmpeg_dir, image_name)\n        with tf.io.gfile.GFile(image_path, \'rb\') as frame_file:\n          frames.append(six.BytesIO(frame_file.read()))\n      return frames\n    except OSError as exception:\n      raise IOError(\n          \'It seems that ffmpeg is not installed on the system. Please follow \'\n          \'the instrutions at https://ffmpeg.org/. \'\n          \'Original exception: {}\'.format(exception))\n    finally:\n      tf.io.gfile.rmtree(ffmpeg_dir)\n\n  def encode_example(self, video_or_path_or_fobj):\n    """"""Converts the given image into a dict convertible to tf example.""""""\n    if isinstance(video_or_path_or_fobj, six.string_types):\n      if not os.path.isfile(video_or_path_or_fobj):\n        _, video_temp_path = tempfile.mkstemp()\n        try:\n          tf.io.gfile.copy(\n              video_or_path_or_fobj, video_temp_path, overwrite=True)\n          encoded_video = self._ffmpeg_decode(video_temp_path)\n        finally:\n          os.unlink(video_temp_path)\n      else:\n        encoded_video = self._ffmpeg_decode(video_or_path_or_fobj)\n    elif isinstance(video_or_path_or_fobj, bytes):\n      with tempfile.TemporaryDirectory() as tmpdirname:\n        video_temp_path = os.path.join(tmpdirname, \'video\')\n        with tf.io.gfile.GFile(video_temp_path, \'wb\') as f:\n          f.write(video_or_path_or_fobj)\n        encoded_video = self._ffmpeg_decode(video_temp_path)\n    elif hasattr(video_or_path_or_fobj, \'read\'):\n      encoded_video = self._ffmpeg_decode(video_or_path_or_fobj)\n    else:\n      encoded_video = video_or_path_or_fobj\n    return super(Video, self).encode_example(encoded_video)\n'"
tensorflow_datasets/core/features/video_feature_test.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.features.video_feature.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os.path\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import features\n\ntf.enable_v2_behavior()\n\n\nclass VideoFeatureTest(testing.FeatureExpectationsTestCase):\n\n  @property\n  def _test_data_path(self):\n    return os.path.join(os.path.dirname(__file__), \'../../testing/test_data\')\n\n  def test_video_numpy(self):\n    np_video = np.random.randint(256, size=(128, 64, 64, 3), dtype=np.uint8)\n\n    self.assertFeature(\n        feature=features.Video(shape=(None, 64, 64, 3)),\n        shape=(None, 64, 64, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=np_video,\n                expected=np_video,\n            ),\n        ],\n    )\n\n  def test_video_concatenated_frames(self):\n    video_shape = (None, 400, 640, 3)\n    lsun_examples_path = os.path.join(self._test_data_path, \'lsun_examples\')\n    frames_paths = [os.path.join(lsun_examples_path, \'{}.jpg\'.format(i))\n                    for i in (1, 2, 3, 4)]\n    frames = []\n    for frame_path in frames_paths:\n      with tf.io.gfile.GFile(frame_path, \'rb\') as frame_fp:\n        frames.append(tf.image.decode_jpeg(frame_fp.read(), channels=3))\n    video = tf.stack(frames)\n\n    self.assertFeature(\n        feature=features.Video(shape=video_shape),\n        shape=video_shape,\n        dtype=tf.uint8,\n        tests=[\n            # Numpy array\n            testing.FeatureExpectationItem(\n                value=frames_paths,\n                expected=video,\n            ),\n        ],\n    )\n\n  def test_video_ffmpeg(self):\n    video_path = os.path.join(self._test_data_path, \'video.mkv\')\n    video_json_path = os.path.join(self._test_data_path, \'video.json\')\n    with tf.io.gfile.GFile(video_json_path) as fp:\n      video_array = np.asarray(json.load(fp))\n\n    self.assertFeature(\n        feature=features.Video(shape=(5, 4, 2, 3)),\n        shape=(5, 4, 2, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=video_path,\n                expected=video_array,\n            ),\n        ],\n    )\n\n    self.assertFeature(\n        feature=features.Video(shape=(5, 4, 2, 3)),\n        shape=(5, 4, 2, 3),\n        dtype=tf.uint8,\n        tests=[\n            testing.FeatureExpectationItem(\n                value=video_path,\n                expected=video_array,\n            ),\n        ],\n    )\n\n    class GFileWithSeekOnRead(tf.io.gfile.GFile):\n\n      def read(self, *args, **kwargs):\n        data_read = super(GFileWithSeekOnRead, self).read(*args, **kwargs)\n        self.seek(0)\n        return data_read\n\n    with GFileWithSeekOnRead(video_path, \'rb\') as video_fp:\n      self.assertFeature(\n          feature=features.Video(shape=(5, 4, 2, 3)),\n          shape=(5, 4, 2, 3),\n          dtype=tf.uint8,\n          tests=[\n              testing.FeatureExpectationItem(\n                  value=video_fp,\n                  expected=video_array,\n              ),\n          ],\n      )\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/proto/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Public API of the proto package.""""""\n\nfrom tensorflow_datasets.core.proto import dataset_info_generated_pb2 as dataset_info_pb2  # pylint: disable=line-too-long\n\nSplitInfo = dataset_info_pb2.SplitInfo\n'"
tensorflow_datasets/core/proto/dataset_info_generated_pb2.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n\n# pylint: skip-file\n# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: dataset_info.proto\n\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_metadata.proto.v0 import statistics_pb2 as tensorflow__metadata_dot_proto_dot_v0_dot_statistics__pb2\nfrom tensorflow_metadata.proto.v0 import schema_pb2 as tensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'dataset_info.proto\',\n  package=\'tensorflow_datasets\',\n  syntax=\'proto3\',\n  serialized_options=b\'\\370\\001\\001\',\n  serialized_pb=b\'\\n\\x12\\x64\\x61taset_info.proto\\x12\\x13tensorflow_datasets\\x1a-tensorflow_metadata/proto/v0/statistics.proto\\x1a)tensorflow_metadata/proto/v0/schema.proto\\""\\x1f\\n\\x0f\\x44\\x61tasetLocation\\x12\\x0c\\n\\x04urls\\x18\\x01 \\x03(\\t\\""\\x9d\\x01\\n\\tSplitInfo\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nnum_shards\\x18\\x02 \\x01(\\x03\\x12\\x15\\n\\rshard_lengths\\x18\\x04 \\x03(\\x03\\x12\\x11\\n\\tnum_bytes\\x18\\x05 \\x01(\\x03\\x12\\x44\\n\\nstatistics\\x18\\x03 \\x01(\\x0b\\x32\\x30.tensorflow.metadata.v0.DatasetFeatureStatistics\\""/\\n\\x0eSupervisedKeys\\x12\\r\\n\\x05input\\x18\\x01 \\x01(\\t\\x12\\x0e\\n\\x06output\\x18\\x02 \\x01(\\t\\""%\\n\\x12RedistributionInfo\\x12\\x0f\\n\\x07license\\x18\\x01 \\x01(\\t\\""\\xb4\\x04\\n\\x0b\\x44\\x61tasetInfo\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x13\\n\\x0b\\x64\\x65scription\\x18\\x02 \\x01(\\t\\x12\\x0f\\n\\x07version\\x18\\t \\x01(\\t\\x12\\x10\\n\\x08\\x63itation\\x18\\x03 \\x01(\\t\\x12\\x19\\n\\rsize_in_bytes\\x18\\x04 \\x01(\\x03\\x42\\x02\\x18\\x01\\x12\\x15\\n\\rdownload_size\\x18\\x0c \\x01(\\x03\\x12\\x36\\n\\x08location\\x18\\x05 \\x01(\\x0b\\x32$.tensorflow_datasets.DatasetLocation\\x12W\\n\\x12\\x64ownload_checksums\\x18\\n \\x03(\\x0b\\x32\\x37.tensorflow_datasets.DatasetInfo.DownloadChecksumsEntryB\\x02\\x18\\x01\\x12.\\n\\x06schema\\x18\\x06 \\x01(\\x0b\\x32\\x1e.tensorflow.metadata.v0.Schema\\x12.\\n\\x06splits\\x18\\x07 \\x03(\\x0b\\x32\\x1e.tensorflow_datasets.SplitInfo\\x12<\\n\\x0fsupervised_keys\\x18\\x08 \\x01(\\x0b\\x32#.tensorflow_datasets.SupervisedKeys\\x12\\x44\\n\\x13redistribution_info\\x18\\x0b \\x01(\\x0b\\x32\\\'.tensorflow_datasets.RedistributionInfo\\x1a\\x38\\n\\x16\\x44ownloadChecksumsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\x42\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n  ,\n  dependencies=[tensorflow__metadata_dot_proto_dot_v0_dot_statistics__pb2.DESCRIPTOR,tensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2.DESCRIPTOR,])\n\n\n\n\n_DATASETLOCATION = _descriptor.Descriptor(\n  name=\'DatasetLocation\',\n  full_name=\'tensorflow_datasets.DatasetLocation\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'urls\', full_name=\'tensorflow_datasets.DatasetLocation.urls\', index=0,\n      number=1, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=133,\n  serialized_end=164,\n)\n\n\n_SPLITINFO = _descriptor.Descriptor(\n  name=\'SplitInfo\',\n  full_name=\'tensorflow_datasets.SplitInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorflow_datasets.SplitInfo.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_shards\', full_name=\'tensorflow_datasets.SplitInfo.num_shards\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shard_lengths\', full_name=\'tensorflow_datasets.SplitInfo.shard_lengths\', index=2,\n      number=4, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_bytes\', full_name=\'tensorflow_datasets.SplitInfo.num_bytes\', index=3,\n      number=5, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'statistics\', full_name=\'tensorflow_datasets.SplitInfo.statistics\', index=4,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=167,\n  serialized_end=324,\n)\n\n\n_SUPERVISEDKEYS = _descriptor.Descriptor(\n  name=\'SupervisedKeys\',\n  full_name=\'tensorflow_datasets.SupervisedKeys\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'tensorflow_datasets.SupervisedKeys.input\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output\', full_name=\'tensorflow_datasets.SupervisedKeys.output\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=326,\n  serialized_end=373,\n)\n\n\n_REDISTRIBUTIONINFO = _descriptor.Descriptor(\n  name=\'RedistributionInfo\',\n  full_name=\'tensorflow_datasets.RedistributionInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'license\', full_name=\'tensorflow_datasets.RedistributionInfo.license\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=375,\n  serialized_end=412,\n)\n\n\n_DATASETINFO_DOWNLOADCHECKSUMSENTRY = _descriptor.Descriptor(\n  name=\'DownloadChecksumsEntry\',\n  full_name=\'tensorflow_datasets.DatasetInfo.DownloadChecksumsEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'tensorflow_datasets.DatasetInfo.DownloadChecksumsEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorflow_datasets.DatasetInfo.DownloadChecksumsEntry.value\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=b\'8\\001\',\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=923,\n  serialized_end=979,\n)\n\n_DATASETINFO = _descriptor.Descriptor(\n  name=\'DatasetInfo\',\n  full_name=\'tensorflow_datasets.DatasetInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorflow_datasets.DatasetInfo.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'description\', full_name=\'tensorflow_datasets.DatasetInfo.description\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorflow_datasets.DatasetInfo.version\', index=2,\n      number=9, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'citation\', full_name=\'tensorflow_datasets.DatasetInfo.citation\', index=3,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=b"""".decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'size_in_bytes\', full_name=\'tensorflow_datasets.DatasetInfo.size_in_bytes\', index=4,\n      number=4, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=b\'\\030\\001\', file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'download_size\', full_name=\'tensorflow_datasets.DatasetInfo.download_size\', index=5,\n      number=12, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'location\', full_name=\'tensorflow_datasets.DatasetInfo.location\', index=6,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'download_checksums\', full_name=\'tensorflow_datasets.DatasetInfo.download_checksums\', index=7,\n      number=10, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=b\'\\030\\001\', file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'schema\', full_name=\'tensorflow_datasets.DatasetInfo.schema\', index=8,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'splits\', full_name=\'tensorflow_datasets.DatasetInfo.splits\', index=9,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'supervised_keys\', full_name=\'tensorflow_datasets.DatasetInfo.supervised_keys\', index=10,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'redistribution_info\', full_name=\'tensorflow_datasets.DatasetInfo.redistribution_info\', index=11,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_DATASETINFO_DOWNLOADCHECKSUMSENTRY, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=415,\n  serialized_end=979,\n)\n\n_SPLITINFO.fields_by_name[\'statistics\'].message_type = tensorflow__metadata_dot_proto_dot_v0_dot_statistics__pb2._DATASETFEATURESTATISTICS\n_DATASETINFO_DOWNLOADCHECKSUMSENTRY.containing_type = _DATASETINFO\n_DATASETINFO.fields_by_name[\'location\'].message_type = _DATASETLOCATION\n_DATASETINFO.fields_by_name[\'download_checksums\'].message_type = _DATASETINFO_DOWNLOADCHECKSUMSENTRY\n_DATASETINFO.fields_by_name[\'schema\'].message_type = tensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2._SCHEMA\n_DATASETINFO.fields_by_name[\'splits\'].message_type = _SPLITINFO\n_DATASETINFO.fields_by_name[\'supervised_keys\'].message_type = _SUPERVISEDKEYS\n_DATASETINFO.fields_by_name[\'redistribution_info\'].message_type = _REDISTRIBUTIONINFO\nDESCRIPTOR.message_types_by_name[\'DatasetLocation\'] = _DATASETLOCATION\nDESCRIPTOR.message_types_by_name[\'SplitInfo\'] = _SPLITINFO\nDESCRIPTOR.message_types_by_name[\'SupervisedKeys\'] = _SUPERVISEDKEYS\nDESCRIPTOR.message_types_by_name[\'RedistributionInfo\'] = _REDISTRIBUTIONINFO\nDESCRIPTOR.message_types_by_name[\'DatasetInfo\'] = _DATASETINFO\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nDatasetLocation = _reflection.GeneratedProtocolMessageType(\'DatasetLocation\', (_message.Message,), {\n  \'DESCRIPTOR\' : _DATASETLOCATION,\n  \'__module__\' : \'dataset_info_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorflow_datasets.DatasetLocation)\n  })\n_sym_db.RegisterMessage(DatasetLocation)\n\nSplitInfo = _reflection.GeneratedProtocolMessageType(\'SplitInfo\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SPLITINFO,\n  \'__module__\' : \'dataset_info_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorflow_datasets.SplitInfo)\n  })\n_sym_db.RegisterMessage(SplitInfo)\n\nSupervisedKeys = _reflection.GeneratedProtocolMessageType(\'SupervisedKeys\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SUPERVISEDKEYS,\n  \'__module__\' : \'dataset_info_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorflow_datasets.SupervisedKeys)\n  })\n_sym_db.RegisterMessage(SupervisedKeys)\n\nRedistributionInfo = _reflection.GeneratedProtocolMessageType(\'RedistributionInfo\', (_message.Message,), {\n  \'DESCRIPTOR\' : _REDISTRIBUTIONINFO,\n  \'__module__\' : \'dataset_info_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorflow_datasets.RedistributionInfo)\n  })\n_sym_db.RegisterMessage(RedistributionInfo)\n\nDatasetInfo = _reflection.GeneratedProtocolMessageType(\'DatasetInfo\', (_message.Message,), {\n\n  \'DownloadChecksumsEntry\' : _reflection.GeneratedProtocolMessageType(\'DownloadChecksumsEntry\', (_message.Message,), {\n    \'DESCRIPTOR\' : _DATASETINFO_DOWNLOADCHECKSUMSENTRY,\n    \'__module__\' : \'dataset_info_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorflow_datasets.DatasetInfo.DownloadChecksumsEntry)\n    })\n  ,\n  \'DESCRIPTOR\' : _DATASETINFO,\n  \'__module__\' : \'dataset_info_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorflow_datasets.DatasetInfo)\n  })\n_sym_db.RegisterMessage(DatasetInfo)\n_sym_db.RegisterMessage(DatasetInfo.DownloadChecksumsEntry)\n\n\nDESCRIPTOR._options = None\n_DATASETINFO_DOWNLOADCHECKSUMSENTRY._options = None\n_DATASETINFO.fields_by_name[\'size_in_bytes\']._options = None\n_DATASETINFO.fields_by_name[\'download_checksums\']._options = None\n# @@protoc_insertion_point(module_scope)'"
tensorflow_datasets/core/utils/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Util import.""""""\n\n# pylint: disable=wildcard-import\nfrom tensorflow_datasets.core.utils.gcs_utils import gcs_path\nfrom tensorflow_datasets.core.utils.image_utils import *\nfrom tensorflow_datasets.core.utils.py_utils import *\nfrom tensorflow_datasets.core.utils.tf_utils import *\nfrom tensorflow_datasets.core.utils.tqdm_utils import *\nfrom tensorflow_datasets.core.utils.version import Experiment\nfrom tensorflow_datasets.core.utils.version import Version\n# pylint: enable=wildcard-import\n'"
tensorflow_datasets/core/utils/gcs_utils.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for accessing TFDS GCS buckets.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport concurrent.futures\nimport posixpath\nfrom typing import Optional\nfrom xml.etree import ElementTree\n\nimport requests\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.core.utils import tqdm_utils\n\nGCS_ROOT_DIR = \'gs://tfds-data\'\nGCS_URL = \'https://storage.googleapis.com\'\n\n# for dataset_info/\nGCS_BUCKET = posixpath.join(GCS_URL, \'tfds-data\')\nGCS_DATASET_INFO_DIR = \'dataset_info\'\nGCS_DATASETS_DIR = \'datasets\'\n\n\ndef gcs_path(suffix: Optional[str] = None) -> str:\n  """"""Returns the GCS URI path.\n\n  Args:\n    suffix: Eventual relative path in the bucket. If `None`, returns the root\n      GCS bucket uri.\n\n  Returns:\n    path: The GCS uri.\n  """"""\n  path = GCS_ROOT_DIR\n  if suffix:\n    path = posixpath.join(path, suffix)\n  return path\n\n\ndef download_gcs_file(path, out_fname=None, prefix_filter=None):\n  """"""Download a file from GCS, optionally to a file.""""""\n  url = posixpath.join(GCS_BUCKET, path)\n  if prefix_filter:\n    url += \'?prefix=%s\' % prefix_filter\n  stream = bool(out_fname)\n  resp = requests.get(url, stream=stream)\n  if not resp.ok:\n    raise ValueError(\'GCS bucket inaccessible\')\n  if out_fname:\n    with tf.io.gfile.GFile(out_fname, \'wb\') as f:\n      for chunk in resp.iter_content(1024):\n        f.write(chunk)\n  else:\n    return resp.content\n\n\n@py_utils.memoize()\ndef gcs_files(prefix_filter=None):\n  """"""List all files in GCS bucket.""""""\n  top_level_xml_str = download_gcs_file(\'\', prefix_filter=prefix_filter)\n  xml_root = ElementTree.fromstring(top_level_xml_str)\n  filenames = [el[0].text for el in xml_root if el.tag.endswith(\'Contents\')]\n  return filenames\n\n\ndef gcs_dataset_info_files(dataset_dir):\n  """"""Return paths to GCS files in the given dataset directory.""""""\n  prefix = posixpath.join(GCS_DATASET_INFO_DIR, dataset_dir, \'\')\n  # Filter for this dataset\n  filenames = [el for el in gcs_files(prefix_filter=prefix)\n               if el.startswith(prefix) and len(el) > len(prefix)]\n  return filenames\n\n\ndef is_dataset_on_gcs(dataset_name):\n  """"""If the dataset is available on the GCS bucket gs://tfds-data/datasets.""""""\n  dir_name = posixpath.join(GCS_DATASETS_DIR, dataset_name)\n  return len(gcs_files(prefix_filter=dir_name)) > 2\n\n\ndef download_gcs_dataset(\n    dataset_name, local_dataset_dir, max_simultaneous_downloads=50):\n  """"""Downloads prepared GCS dataset to local dataset directory.""""""\n  prefix = posixpath.join(GCS_DATASETS_DIR, dataset_name)\n  gcs_paths_to_dl = gcs_files(prefix)\n\n  # Filter out the diffs folder if present\n  filter_prefix = posixpath.join(prefix, \'diffs\')\n  gcs_paths_to_dl = [p for p in gcs_paths_to_dl\n                     if not p.startswith(filter_prefix)]\n\n  with tqdm_utils.async_tqdm(\n      total=len(gcs_paths_to_dl), desc=\'Dl Completed...\', unit=\' file\') as pbar:\n    def _copy_from_gcs(gcs_path_):\n      local_path = posixpath.join(\n          local_dataset_dir, posixpath.basename(gcs_path_))\n      download_gcs_file(gcs_path_, local_path)\n      pbar.update(1)\n    with concurrent.futures.ThreadPoolExecutor(\n        max_workers=max_simultaneous_downloads) as executor:\n      futures = [\n          executor.submit(_copy_from_gcs, path) for path in gcs_paths_to_dl]\n      for future in concurrent.futures.as_completed(futures):\n        future.result()\n'"
tensorflow_datasets/core/utils/gcs_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""GCS utils test.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.utils import gcs_utils\n\n\nclass GcsUtilsTest(testing.TestCase):\n\n  def is_dataset_accessible(self):\n    # Re-enable GCS access. TestCase disables it.\n    with self.gcs_access():\n      self.assertTrue(gcs_utils.is_dataset_on_gcs(""mnist/1.0.0""))\n\n  def test_mnist(self):\n    with self.gcs_access():\n      mnist = tfds.image_classification.MNIST(\n          data_dir=""gs://tfds-data/datasets"")\n      example = next(tfds.as_numpy(mnist.as_dataset(split=""train"").take(1)))\n    _ = example[""image""], example[""label""]\n\n\nif __name__ == ""__main__"":\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/image_utils.py,5,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities to manipulate images.\n\nNote: these functions are not meant to be used inside of a TF graph.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.core.utils import tf_utils\n\n\n@py_utils.memoize()\ndef _get_runner():\n  return tf_utils.TFGraphRunner()\n\n\ndef decode_image(image_bytes):\n  """"""Returns np.array corresponding to encoded image.""""""\n  runner = _get_runner()\n  return runner.run(tf.image.decode_image, image_bytes)\n\n\ndef png_to_jpeg(image_bytes, quality=100):\n  """"""Converts PNG image (bytes or str) to JPEG (bytes).""""""\n  runner = _get_runner()\n  decode_fn = lambda img: tf.image.decode_png(img, channels=3)\n  image = runner.run(decode_fn, image_bytes)\n  fn = lambda img: tf.image.encode_jpeg(img, format=\'rgb\', quality=quality)\n  return runner.run(fn, image)\n\n\ndef jpeg_cmyk_to_rgb(image_bytes, quality=100):\n  """"""Converts JPEG CMYK image (bytes) to RGB JPEG (bytes).""""""\n  runner = _get_runner()\n  image = runner.run(tf.image.decode_jpeg, image_bytes)\n  fn = lambda img: tf.image.encode_jpeg(img, format=\'rgb\', quality=quality)\n  return runner.run(fn, image)\n'"
tensorflow_datasets/core/utils/image_utils_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.utils.image_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.utils import image_utils\n\n# pylint: disable=bad-whitespace\nSIX_PIXELS = [\n    [[  0, 255,   0],\n     [255,   0,   0],\n     [255,   0, 255]],\n    [[  0,   0, 255],\n     [255, 255,   0],\n     [126, 127, 128]]]\n\nSIX_PIXELS_JPEG = [\n    [[158, 161,  92],\n     [ 76,  79,  10],\n     [180,  57, 181]],\n    [[ 33,  36,   0],\n     [229, 232, 163],\n     [201,  78, 202]]]\n# pylint: enable=bad-whitespace\n\n\nclass ImageUtilsTest(testing.TestCase):\n\n  def _get_image(self, name):\n    path = os.path.join(self.test_data, name)\n    with tf.io.gfile.GFile(path, \'rb\') as img_f:\n      return img_f.read()\n\n  def test_decode_image(self):\n    image = self._get_image(\'6pixels.png\')\n    np_image = image_utils.decode_image(image)\n    np.testing.assert_array_equal(np_image, SIX_PIXELS)\n\n  def test_png_to_jpeg(self):\n    image = self._get_image(\'6pixels.png\')\n    jpeg = image_utils.png_to_jpeg(image)\n    image_np_jpeg = image_utils.decode_image(jpeg)\n    np.testing.assert_array_equal(image_np_jpeg, SIX_PIXELS_JPEG)\n\n  def test_png_4chan_to_jpeg(self):\n    image = self._get_image(\'6pixels_4chan.png\')\n    jpeg = image_utils.png_to_jpeg(image)\n    image_np_jpeg = image_utils.decode_image(jpeg)\n    np.testing.assert_array_equal(image_np_jpeg, SIX_PIXELS_JPEG)\n\n  def test_jpeg_cmyk_to_rgb(self):\n    image = self._get_image(\'6pixels_cmyk.jpeg\')\n    new_image = image_utils.jpeg_cmyk_to_rgb(image, quality=100)\n    self.assertNotEqual(image, new_image)\n    # Converting between color systems is not bijective, so high rtol.\n    original_np_image = image_utils.decode_image(image)\n    new_np_image = image_utils.decode_image(new_image)\n    np.testing.assert_allclose(original_np_image, new_np_image, rtol=10)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/py_utils.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Some python utils function and classes.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport hashlib\nimport io\nimport itertools\nimport logging\nimport os\nimport random\nimport string\nimport sys\nimport textwrap\nimport threading\nfrom typing import Any, Callable, Iterator, List, TypeVar\nimport uuid\n\nimport six\nfrom six.moves import urllib\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import constants\n\n\n# pylint: disable=g-import-not-at-top\ntry:  # Use shutil on Python 3.3+\n  from shutil import disk_usage  # pytype: disable=import-error  # pylint: disable=g-importing-member\nexcept ImportError:\n  from psutil import disk_usage  # pytype: disable=import-error  # pylint: disable=g-importing-member\nif sys.version_info[0] > 2:\n  import functools\nelse:\n  import functools32 as functools\n# pylint: enable=g-import-not-at-top\n\n\n# NOTE: When used on an instance method, the cache is shared across all\n# instances and IS NOT per-instance.\n# See\n# https://stackoverflow.com/questions/14946264/python-lru-cache-decorator-per-instance\n# For @property methods, use @memoized_property below.\nmemoize = functools.lru_cache\n\n\nT = TypeVar(\'T\')\n\nFn = TypeVar(\'Fn\', bound=Callable[..., Any])\n\n\ndef is_notebook():\n  """"""Returns True if running in a notebook (Colab, Jupyter) environement.""""""\n  # Inspired from the tfdm autonotebook code\n  try:\n    import IPython  # pytype: disable=import-error  # pylint: disable=import-outside-toplevel,g-import-not-at-top\n    if \'IPKernelApp\' not in IPython.get_ipython().config:\n      return False  # Run in a IPython terminal\n  except:  # pylint: disable=bare-except\n    return False\n  else:\n    return True\n\n\n@contextlib.contextmanager\ndef temporary_assignment(obj, attr, value):\n  """"""Temporarily assign obj.attr to value.""""""\n  original = getattr(obj, attr)\n  setattr(obj, attr, value)\n  try:\n    yield\n  finally:\n    setattr(obj, attr, original)\n\n\ndef zip_dict(*dicts):\n  """"""Iterate over items of dictionaries grouped by their keys.""""""\n  for key in set(itertools.chain(*dicts)):  # set merge all keys\n    # Will raise KeyError if the dict don\'t have the same keys\n    yield key, tuple(d[key] for d in dicts)\n\n\n@contextlib.contextmanager\ndef disable_logging():\n  """"""Temporarily disable the logging.""""""\n  logger = logging.getLogger()\n  logger_disabled = logger.disabled\n  logger.disabled = True\n  try:\n    yield\n  finally:\n    logger.disabled = logger_disabled\n\n\nclass NonMutableDict(dict):\n  """"""Dict where keys can only be added but not modified.\n\n  Will raise an error if the user try to overwrite one key. The error message\n  can be customized during construction. It will be formatted using {key} for\n  the overwritten key.\n  """"""\n\n  def __init__(self, *args, **kwargs):\n    self._error_msg = kwargs.pop(\n        \'error_msg\',\n        \'Try to overwrite existing key: {key}\',\n    )\n    if kwargs:\n      raise ValueError(\'NonMutableDict cannot be initialized with kwargs.\')\n    super(NonMutableDict, self).__init__(*args, **kwargs)\n\n  def __setitem__(self, key, value):\n    if key in self:\n      raise ValueError(self._error_msg.format(key=key))\n    return super(NonMutableDict, self). __setitem__(key, value)\n\n  def update(self, other):\n    if any(k in self for k in other):\n      raise ValueError(self._error_msg.format(key=set(self) & set(other)))\n    return super(NonMutableDict, self).update(other)\n\n\nclass classproperty(property):  # pylint: disable=invalid-name\n  """"""Descriptor to be used as decorator for @classmethods.""""""\n\n  def __get__(self, obj, objtype=None):\n    return self.fget.__get__(None, objtype)()  # pytype: disable=attribute-error\n\n\nclass memoized_property(property):  # pylint: disable=invalid-name\n  """"""Descriptor that mimics @property but caches output in member variable.""""""\n\n  def __get__(self, obj, objtype=None):\n    # See https://docs.python.org/3/howto/descriptor.html#properties\n    if obj is None:\n      return self\n    if self.fget is None:  # pytype: disable=attribute-error\n      raise AttributeError(\'unreadable attribute\')\n    attr = \'__cached_\' + self.fget.__name__  # pytype: disable=attribute-error\n    cached = getattr(obj, attr, None)\n    if cached is None:\n      cached = self.fget(obj)  # pytype: disable=attribute-error\n      setattr(obj, attr, cached)\n    return cached\n\n\ndef map_nested(function, data_struct, dict_only=False, map_tuple=False):\n  """"""Apply a function recursively to each element of a nested data struct.""""""\n\n  # Could add support for more exotic data_struct, like OrderedDict\n  if isinstance(data_struct, dict):\n    return {\n        k: map_nested(function, v, dict_only, map_tuple)\n        for k, v in data_struct.items()\n    }\n  elif not dict_only:\n    types = [list]\n    if map_tuple:\n      types.append(tuple)\n    if isinstance(data_struct, tuple(types)):\n      mapped = [map_nested(function, v, dict_only, map_tuple)\n                for v in data_struct]\n      if isinstance(data_struct, list):\n        return mapped\n      else:\n        return tuple(mapped)\n  # Singleton\n  return function(data_struct)\n\n\ndef zip_nested(arg0, *args, **kwargs):\n  """"""Zip data struct together and return a data struct with the same shape.""""""\n  # Python 2 do not support kwargs only arguments\n  dict_only = kwargs.pop(\'dict_only\', False)\n  assert not kwargs\n\n  # Could add support for more exotic data_struct, like OrderedDict\n  if isinstance(arg0, dict):\n    return {\n        k: zip_nested(*a, dict_only=dict_only) for k, a in zip_dict(arg0, *args)\n    }\n  elif not dict_only:\n    if isinstance(arg0, list):\n      return [zip_nested(*a, dict_only=dict_only) for a in zip(arg0, *args)]\n  # Singleton\n  return (arg0,) + args\n\n\ndef flatten_nest_dict(d):\n  """"""Return the dict with all nested keys flattened joined with \'/\'.""""""\n  # Use NonMutableDict to ensure there is no collision between features keys\n  flat_dict = NonMutableDict()\n  for k, v in d.items():\n    if isinstance(v, dict):\n      flat_dict.update({\n          \'{}/{}\'.format(k, k2): v2 for k2, v2 in flatten_nest_dict(v).items()\n      })\n    else:\n      flat_dict[k] = v\n  return flat_dict\n\n\ndef dedent(text):\n  """"""Wrapper around `textwrap.dedent` which also `strip()` and handle `None`.""""""\n  return textwrap.dedent(text).strip() if text else text\n\n\ndef pack_as_nest_dict(flat_d, nest_d):\n  """"""Pack a 1-lvl dict into a nested dict with same structure as `nest_d`.""""""\n  nest_out_d = {}\n  for k, v in nest_d.items():\n    if isinstance(v, dict):\n      v_flat = flatten_nest_dict(v)\n      sub_d = {\n          k2: flat_d.pop(\'{}/{}\'.format(k, k2)) for k2, _ in v_flat.items()\n      }\n      # Recursivelly pack the dictionary\n      nest_out_d[k] = pack_as_nest_dict(sub_d, v)\n    else:\n      nest_out_d[k] = flat_d.pop(k)\n  if flat_d:  # At the end, flat_d should be empty\n    raise ValueError(\n        \'Flat dict strucure do not match the nested dict. Extra keys: \'\n        \'{}\'.format(list(flat_d.keys())))\n  return nest_out_d\n\n\n@contextlib.contextmanager\ndef nullcontext(enter_result: T = None) -> Iterator[T]:\n  """"""Backport of `contextlib.nullcontext`.""""""\n  yield enter_result\n\n\ndef as_proto_cls(proto_cls):\n  """"""Simulate proto inheritance.\n\n  By default, protobuf do not support direct inheritance, so this decorator\n  simulates inheritance to the class to which it is applied.\n\n  Example:\n\n  ```\n  @as_proto_class(proto.MyProto)\n  class A(object):\n    def custom_method(self):\n      return self.proto_field * 10\n\n  p = proto.MyProto(proto_field=123)\n\n  a = A()\n  a.CopyFrom(p)  # a is like a proto object\n  assert a.proto_field == 123\n  a.custom_method()  # But has additional methods\n\n  ```\n\n  Args:\n    proto_cls: The protobuf class to inherit from\n\n  Returns:\n    decorated_cls: The decorated class\n  """"""\n\n  def decorator(cls):\n    """"""Decorator applied to the class.""""""\n\n    class ProtoCls(object):\n      """"""Base class simulating the protobuf.""""""\n\n      def __init__(self, *args, **kwargs):\n        super(ProtoCls, self).__setattr__(\n            \'_ProtoCls__proto\',\n            proto_cls(*args, **kwargs),\n        )\n\n      def __getattr__(self, attr_name):\n        return getattr(self.__proto, attr_name)\n\n      def __setattr__(self, attr_name, new_value):\n        try:\n          if isinstance(new_value, list):\n            self.ClearField(attr_name)\n            getattr(self.__proto, attr_name).extend(new_value)\n          else:\n            return setattr(self.__proto, attr_name, new_value)\n        except AttributeError:\n          return super(ProtoCls, self).__setattr__(attr_name, new_value)\n\n      def __eq__(self, other):\n        return self.__proto, other.get_proto()\n\n      def get_proto(self):\n        return self.__proto\n\n      def __repr__(self):\n        return \'<{cls_name}\\n{proto_repr}\\n>\'.format(\n            cls_name=cls.__name__, proto_repr=repr(self.__proto))\n\n    decorator_cls = type(cls.__name__, (cls, ProtoCls), {\n        \'__doc__\': cls.__doc__,\n    })\n    return decorator_cls\n  return decorator\n\n\ndef _get_incomplete_path(filename):\n  """"""Returns a temporary filename based on filename.""""""\n  random_suffix = \'\'.join(\n      random.choice(string.ascii_uppercase + string.digits) for _ in range(6))\n  return filename + \'.incomplete\' + random_suffix\n\n\n@contextlib.contextmanager\ndef incomplete_dir(dirname):\n  """"""Create temporary dir for dirname and rename on exit.""""""\n  tmp_dir = _get_incomplete_path(dirname)\n  tf.io.gfile.makedirs(tmp_dir)\n  try:\n    yield tmp_dir\n    tf.io.gfile.rename(tmp_dir, dirname)\n  finally:\n    if tf.io.gfile.exists(tmp_dir):\n      tf.io.gfile.rmtree(tmp_dir)\n\n\ndef tfds_dir() -> str:\n  """"""Path to tensorflow_datasets directory.\n\n  The difference with `tfds.core.get_tfds_path` is that this function can be\n  used for write access while `tfds.core.get_tfds_path` should be used for\n  read-only.\n\n  Returns:\n    tfds_dir: The root TFDS path.\n  """"""\n  return os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n\n\n@contextlib.contextmanager\ndef atomic_write(path, mode):\n  """"""Writes to path atomically, by writing to temp file and renaming it.""""""\n  tmp_path = \'%s%s_%s\' % (path, constants.INCOMPLETE_SUFFIX, uuid.uuid4().hex)\n  with tf.io.gfile.GFile(tmp_path, mode) as file_:\n    yield file_\n  tf.io.gfile.rename(tmp_path, path, overwrite=True)\n\n\nclass abstractclassmethod(classmethod):  # pylint: disable=invalid-name\n  """"""Decorate a method to mark it as an abstract @classmethod.""""""\n\n  __isabstractmethod__ = True\n\n  def __init__(self, fn):\n    fn.__isabstractmethod__ = True\n    super(abstractclassmethod, self).__init__(fn)\n\n\ndef get_tfds_path(relative_path):\n  """"""Returns absolute path to file given path relative to tfds root.""""""\n  path = os.path.join(tfds_dir(), relative_path)\n  return path\n\n\ndef read_checksum_digest(path, checksum_cls=hashlib.sha256):\n  """"""Given a hash constructor, returns checksum digest and size of file.""""""\n  checksum = checksum_cls()\n  size = 0\n  with tf.io.gfile.GFile(path, \'rb\') as f:\n    while True:\n      block = f.read(io.DEFAULT_BUFFER_SIZE)\n      size += len(block)\n      if not block:\n        break\n      checksum.update(block)\n  return checksum.hexdigest(), size\n\n\ndef reraise(prefix=None, suffix=None):\n  """"""Reraise an exception with an additional message.""""""\n  exc_type, exc_value, exc_traceback = sys.exc_info()\n  prefix = prefix or \'\'\n  suffix = \'\\n\' + suffix if suffix else \'\'\n  msg = prefix + str(exc_value) + suffix\n  six.reraise(exc_type, exc_type(msg), exc_traceback)\n\n\n@contextlib.contextmanager\ndef try_reraise(*args, **kwargs):\n  """"""Reraise an exception with an additional message.""""""\n  try:\n    yield\n  except Exception:   # pylint: disable=broad-except\n    reraise(*args, **kwargs)\n\n\ndef rgetattr(obj, attr, *args):\n  """"""Get attr that handles dots in attr name.""""""\n  def _getattr(obj, attr):\n    return getattr(obj, attr, *args)\n  return functools.reduce(_getattr, [obj] + attr.split(\'.\'))\n\n\ndef has_sufficient_disk_space(needed_bytes, directory=\'.\'):\n  try:\n    free_bytes = disk_usage(os.path.abspath(directory)).free\n  except OSError:\n    return True\n  return needed_bytes < free_bytes\n\n\ndef get_class_path(cls, use_tfds_prefix=True):\n  """"""Returns path of given class or object. Eg: `tfds.image.cifar.Cifar10`.""""""\n  if not isinstance(cls, type):\n    cls = cls.__class__\n  module_path = cls.__module__\n  if use_tfds_prefix and module_path.startswith(\'tensorflow_datasets\'):\n    module_path = \'tfds\' + module_path[len(\'tensorflow_datasets\'):]\n  return \'.\'.join([module_path, cls.__name__])\n\n\ndef get_class_url(cls):\n  """"""Returns URL of given class or object.""""""\n  cls_path = get_class_path(cls, use_tfds_prefix=False)\n  module_path, unused_class_name = cls_path.rsplit(\'.\', 1)\n  module_path = module_path.replace(\'.\', \'/\')\n  return constants.SRC_BASE_URL + module_path + \'.py\'\n\n\ndef build_synchronize_decorator() -> Callable[[Fn], Fn]:\n  """"""Returns a decorator which prevents concurrent calls to functions.\n\n  Usage:\n    synchronized = build_synchronize_decorator()\n\n    @synchronized\n    def read_value():\n      ...\n\n    @synchronized\n    def write_value(x):\n      ...\n\n  Returns:\n    make_threadsafe (fct): The decorator which lock all functions to which it\n      is applied under a same lock\n  """"""\n  lock = threading.Lock()\n\n  def lock_decorator(fn: Fn) -> Fn:\n\n    @functools.wraps(fn)\n    def lock_decorated(*args, **kwargs):\n      with lock:\n        return fn(*args, **kwargs)\n\n    return lock_decorated\n\n  return lock_decorator\n\n\ndef basename_from_url(url: str) -> str:\n  """"""Returns file name of file at given url.""""""\n  return os.path.basename(urllib.parse.urlparse(url).path) or \'unknown_name\'\n\n\ndef list_info_files(dir_path: str) -> List[str]:\n  """"""Returns name of info files within dir_path.""""""\n  # TODO(tfds): Is there a better filtering scheme which would be more\n  # resistant to future modifications (ex: tfrecord => other format)\n  return [\n      fname for fname in tf.io.gfile.listdir(dir_path)\n      if \'.tfrecord\' not in fname and\n      not tf.io.gfile.isdir(os.path.join(dir_path, fname))\n  ]\n'"
tensorflow_datasets/core/utils/py_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for py_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport hashlib\nimport os\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import constants\nfrom tensorflow_datasets.core.utils import py_utils\n\n\nclass PyUtilsTest(testing.TestCase):\n\n  def test_is_notebook(self):\n    self.assertFalse(py_utils.is_notebook())\n\n  def test_map_nested(self):\n    """"""Test the mapping function.""""""\n    def map_fn(x):\n      return x * 10\n\n    result = py_utils.map_nested(map_fn, {\n        \'a\': 1,\n        \'b\': {\n            \'c\': 2,\n            \'e\': [3, 4, 5],\n        },\n    })\n    self.assertEqual(result, {\n        \'a\': 10,\n        \'b\': {\n            \'c\': 20,\n            \'e\': [30, 40, 50],\n        },\n    })\n\n    result = py_utils.map_nested(map_fn, [1, 2, 3])\n    self.assertEqual(result, [10, 20, 30])\n\n    result = py_utils.map_nested(map_fn, 1)\n    self.assertEqual(result, 10)\n\n  def test_zip_nested(self):\n    """"""Test the zip nested function.""""""\n\n    arg0 = {\n        \'a\': 1,\n        \'b\': {\n            \'c\': 2,\n            \'e\': [3, 4, 5],\n        },\n    }\n    arg1 = {\n        \'a\': 10,\n        \'b\': {\n            \'c\': 20,\n            \'e\': [30, 40, 50],\n        },\n    }\n\n    result = py_utils.zip_nested(arg0, arg1)\n    self.assertEqual(result, {\n        \'a\': (1, 10),\n        \'b\': {\n            \'c\': (2, 20),\n            \'e\': [(3, 30), (4, 40), (5, 50)],\n        },\n    })\n\n    result = py_utils.zip_nested(1, 2)\n    self.assertEqual(result, (1, 2))\n\n  def test_dict_only(self):\n    def map_fn(x):\n      return x[0] + x[1]\n\n    arg0 = {\n        \'a\': (1, 2),\n        \'b\': {\n            \'c\': 2,\n            \'e\': [3, 4, 5],\n        },\n    }\n    arg1 = {\n        \'a\': (10, 20),\n        \'b\': {\n            \'c\': 20,\n            \'e\': [30, 40, 50],\n        },\n    }\n\n    result = py_utils.zip_nested(arg0, arg1, dict_only=True)\n    self.assertEqual(result, {\n        \'a\': ((1, 2), (10, 20)),\n        \'b\': {\n            \'c\': (2, 20),\n            \'e\': ([3, 4, 5], [30, 40, 50]),\n        },\n    })\n\n    result = py_utils.map_nested(map_fn, result, dict_only=True)\n    self.assertEqual(result, {\n        \'a\': (1, 2, 10, 20),\n        \'b\': {\n            \'c\': 22,\n            \'e\': [3, 4, 5, 30, 40, 50],\n        },\n    })\n\n  def test_flatten_nest_dict(self):\n\n    nest_d = {\n        \'a\': 1,\n        \'b/c\': 2,\n        \'b\': {\n            \'e\': 3,\n            \'f\': {\n                \'g\': 4\n            },\n        },\n    }\n    flat_d = {\n        \'a\': 1,\n        \'b/c\': 2,\n        \'b/e\': 3,\n        \'b/f/g\': 4,\n    }\n\n    self.assertEqual(py_utils.flatten_nest_dict(nest_d), flat_d)\n    self.assertEqual(py_utils.pack_as_nest_dict(flat_d, nest_d), nest_d)\n\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Extra keys\'):\n      py_utils.pack_as_nest_dict({\n          \'a\': 1,\n          \'b/c\': 2,\n          \'b/e\': 3,\n          \'b/f/g\': 4,\n          \'b/h\': 5,  # Extra key\n      }, nest_d)\n\n    with self.assertRaisesWithPredicateMatch(KeyError, \'b/e\'):\n      py_utils.pack_as_nest_dict(\n          {\n              \'a\': 1,\n              \'b/c\': 2,\n              \'b/d\': 3,\n          },\n          {\n              \'a\': 1,\n              \'b\': {\n                  \'c\': 2,\n                  \'d\': 3,\n                  \'e\': 4,  # Extra key\n              }\n          },\n      )\n\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'overwrite existing key:\'):\n      py_utils.flatten_nest_dict({\n          \'a\': {\n              \'b\': 1,\n          },\n          \'a/b\': 2,  # Collision\n      })\n\n  def test_tfds_dir(self):\n    """"""Test the proper suffix only, since the prefix can vary.""""""\n    self.assertEqual(\n        os.path.basename(py_utils.tfds_dir()), \'tensorflow_datasets\')\n\n\nclass ReadChecksumDigestTest(testing.TestCase):\n\n  def test_digest(self):\n    digest, size = py_utils.read_checksum_digest(\n        os.path.join(self.test_data, \'6pixels.png\'), hashlib.sha256)\n    self.assertEqual(\n        digest,\n        \'04f38ebed34d3b027d2683193766155912fba647158c583c3bdb4597ad8af34c\')\n    self.assertEqual(102, size)\n\n\nclass GetClassPathUrlTest(testing.TestCase):\n\n  def test_get_class_path(self):\n    cls_path = py_utils.get_class_path(py_utils.NonMutableDict)\n    self.assertEqual(cls_path, \'tfds.core.utils.py_utils.NonMutableDict\')\n    cls_path = py_utils.get_class_path(\n        py_utils.NonMutableDict(), use_tfds_prefix=False)\n    self.assertEqual(cls_path,\n                     \'tensorflow_datasets.core.utils.py_utils.NonMutableDict\')\n\n  def test_get_class_url(self):\n    cls_url = py_utils.get_class_url(py_utils.NonMutableDict)\n    self.assertEqual(\n        cls_url,\n        (constants.SRC_BASE_URL + \'tensorflow_datasets/core/utils/py_utils.py\'))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/read_config.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""This module contains the reader config.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\nimport attr\n\nimport tensorflow.compat.v2 as tf\n\n\n_OLD = \'interleave_parallel_reads\'\n_NEW = \'interleave_cycle_length\'\n_WARNING_MSG = (\n    \'`{}` argument of `tfds.ReadConfig` is \'\n    \'deprecated and will be removed in a future version. Please use \'\n    \'`{}` instead.\').format(_OLD, _NEW)\n\n\n# TODO(tfds): Use dataclasses once Py2 support is dropped\n@attr.s\nclass _ReadConfig(object):\n  """"""Configures input reading pipeline.""""""\n  # General tf.data.Dataset parametters\n  options = attr.ib(factory=tf.data.Options)\n  try_autocache = attr.ib(default=True)\n  # tf.data.Dataset.shuffle parameters\n  shuffle_seed = attr.ib(default=None)\n  shuffle_reshuffle_each_iteration = attr.ib(default=None)\n  # Interleave parameters\n  # Both parallel_reads and block_length have empirically been tested to give\n  # good results on imagenet.\n  # This values might be changes in the future, with more performance test runs.\n  interleave_cycle_length = attr.ib(default=16)\n  interleave_block_length = attr.ib(default=16)\n  input_context = attr.ib(default=None)\n  experimental_interleave_sort_fn = attr.ib(default=None)\n\n  @property\n  def interleave_parallel_reads(self):\n    logging.warning(_WARNING_MSG)\n    return self.interleave_cycle_length\n\n  @interleave_parallel_reads.setter\n  def interleave_parallel_reads(self, value):\n    logging.warning(_WARNING_MSG)\n    self.interleave_cycle_length = value\n\n\nclass ReadConfig(_ReadConfig):\n  """"""Configures input reading pipeline.\n\n  Attributes:\n    options: `tf.data.Options()`, dataset options. Those options are added to\n      the default values defined in `tfrecord_reader.py`.\n      Note that when `shuffle_files` is True and no seed is defined,\n      experimental_deterministic will be set to False internally,\n      unless it is defined here.\n    try_autocache: If True (default) and the dataset satisfy the right\n      conditions (dataset small enough, files not shuffled,...) the dataset\n      will be cached during the first iteration (through `ds = ds.cache()`).\n    shuffle_seed: `tf.int64`, seeds forwarded to `tf.data.Dataset.shuffle` when\n      `shuffle_files=True`.\n    shuffle_reshuffle_each_iteration: `bool`, forwarded to\n      `tf.data.Dataset.shuffle` when `shuffle_files=True`.\n    interleave_cycle_length: `int`, forwarded to `tf.data.Dataset.interleave`.\n      Default to 16.\n    interleave_block_length: `int`, forwarded to `tf.data.Dataset.interleave`.\n      Default to 16.\n    input_context: `tf.distribute.InputContext`, if set, each worker\n      will read a different set of file. For more info, see the\n      [distribute_datasets_from_function\n      documentation](https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#experimental_distribute_datasets_from_function).\n      Note:\n\n      * Each workers will always read the same subset of files. `shuffle_files`\n        only shuffle files within each worker.\n      * If `info.splits[split].num_shards < input_context.num_input_pipelines`,\n        an error will be raised, as some workers would be empty.\n\n    experimental_interleave_sort_fn: Function with signature\n      `List[FileDict] -> List[FileDict]`, which takes the list of\n      `dict(file: str, take: int, skip: int)` and returns the modified version\n      to read. This can be used to sort/shuffle the shards to read in\n      a custom order, instead of relying on `shuffle_files=True`.\n  """"""\n\n  def __init__(self, **kwargs):\n    if _OLD in kwargs:\n      if _NEW in kwargs:\n        raise ValueError(\'Cannot set both {} and {}\'.format(_OLD, _NEW))\n      logging.warning(_WARNING_MSG)\n      kwargs[_NEW] = kwargs.pop(_OLD)\n    super(ReadConfig, self).__init__(**kwargs)\n'"
tensorflow_datasets/core/utils/shard_utils.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Logic to read sharded files (tfrecord, buckets, ...).\n\nThis logic is shared between:\n - tfrecord_reader, to read sharded tfrecord files, based on user instructions.\n - tfrecord_writer, to read sharded bucket files (temp files), based on final\n sharding needs.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Sequence\n\nimport attr\n\n\n@attr.s(frozen=True)\nclass FileInstruction(object):  # TODO(epot): Uses dataclasses instead\n  """"""Instruction to read a single shard/file.\n\n  Attributes:\n    filename: The filenames contains the relative path, not absolute.\n    skip: Indicates which example read in the shard (`ds.skip().take()`). `None`\n      if no skipping\n    take: Indicates how many examples to read (`None` to read all)\n    num_examples: `int`, The total number of examples\n  """"""\n  filename = attr.ib()\n  skip = attr.ib()\n  take = attr.ib()\n  num_examples = attr.ib()\n\n  def asdict(self):\n    return {\n        \'filename\': self.filename,\n        \'skip\': self.skip,\n        \'take\': self.take,\n        \'num_examples\': self.num_examples,\n    }\n\n  def replace(self, **kwargs):\n    new_attrs = self.asdict()\n    new_attrs.update(kwargs)\n    return type(self)(**new_attrs)\n\n\ndef get_file_instructions(\n    from_: int,\n    to: int,\n    filenames: Sequence[str],\n    shard_lengths: Sequence[int],\n) -> List[FileInstruction]:\n  """"""Returns a list of files (+skip/take) to read [from_:to] items from shards.\n\n  Args:\n    from_: int, Index (included) of element from which to read.\n    to: int, Index (excluded) of element to which to read.\n    filenames: list of strings or ints, the filenames of the shards. Not really\n      used, but to place in result.\n    shard_lengths: the number of elements in every shard.\n\n  Returns:\n    list of dict(filename, skip, take).\n  """"""\n  index_start = 0  # Beginning (included) of moving window.\n  index_end = 0  # End (excluded) of moving window.\n  file_instructions = []\n  for filename, length in zip(filenames, shard_lengths):\n    if not length:\n      continue  # Empty shard - can happen with temporary buckets.\n    index_end += length\n    if from_ < index_end and to > index_start:  # There is something to take.\n      skip = from_ - index_start if from_ > index_start else 0\n      take = to - index_start - skip if to < index_end else -1\n      if take == 0:\n        continue\n      file_instructions.append(FileInstruction(\n          filename=filename,\n          skip=skip,\n          take=take,\n          num_examples=length - skip if take == -1 else take,\n      ))\n    index_start += length\n  return file_instructions\n'"
tensorflow_datasets/core/utils/shard_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.utils.shard_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.utils import shard_utils\n\n\nclass GetReadInstructionsTest(testing.TestCase):\n\n  def test_read_all_even_sharding(self):\n    # Even sharding\n    res = shard_utils.get_file_instructions(\n        0, 12, [\'f1\', \'f2\', \'f3\'], [4, 4, 4])\n    self.assertEqual(res, [\n        shard_utils.FileInstruction(\n            filename=\'f1\', skip=0, take=-1, num_examples=4),\n        shard_utils.FileInstruction(\n            filename=\'f2\', skip=0, take=-1, num_examples=4),\n        shard_utils.FileInstruction(\n            filename=\'f3\', skip=0, take=-1, num_examples=4),\n    ])\n\n  def test_read_all_empty_shard(self):\n    res = shard_utils.get_file_instructions(\n        0, 12, [\'f1\', \'f2\', \'f3\', \'f4\'], [4, 4, 0, 4])\n    self.assertEqual(res, [\n        shard_utils.FileInstruction(\n            filename=\'f1\', skip=0, take=-1, num_examples=4),\n        shard_utils.FileInstruction(\n            filename=\'f2\', skip=0, take=-1, num_examples=4),\n        shard_utils.FileInstruction(\n            filename=\'f4\', skip=0, take=-1, num_examples=4),\n    ])\n\n  def test_from1_to10(self):\n    res = shard_utils.get_file_instructions(\n        1, 10, [\'f1\', \'f2\', \'f3\', \'f4\'], [4, 4, 0, 4])\n    self.assertEqual(res, [\n        shard_utils.FileInstruction(\n            filename=\'f1\', skip=1, take=-1, num_examples=3),\n        shard_utils.FileInstruction(\n            filename=\'f2\', skip=0, take=-1, num_examples=4),\n        shard_utils.FileInstruction(\n            filename=\'f4\', skip=0, take=2, num_examples=2),\n    ])\n\n  def test_nothing_to_read(self):\n    res = shard_utils.get_file_instructions(\n        0, 0, [\'f1\', \'f2\', \'f3\', \'f4\'], [0, 3, 0, 2])\n    self.assertEqual(res, [])\n    res = shard_utils.get_file_instructions(\n        4, 4, [\'f1\', \'f2\', \'f3\', \'f4\'], [0, 3, 0, 2])\n    self.assertEqual(res, [])\n    res = shard_utils.get_file_instructions(\n        5, 5, [\'f1\', \'f2\', \'f3\', \'f4\'], [0, 3, 0, 2])\n    self.assertEqual(res, [])\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/tf_utils.py,13,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""TensorFlow utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport contextlib\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\n\n# Struct containing a graph for the TFGraphRunner\nGraphRun = collections.namedtuple(\n    \'GraphRun\', \'graph, session, placeholder, output\')\n\n# Struct containing the run args, kwargs\nRunArgs = collections.namedtuple(\'RunArgs\', \'fct, input\')\n\n\nclass TFGraphRunner(object):\n  """"""Run in session mode or Eager mode.\n\n  This is a compatibility util between graph and eager TensorFlow.\n\n  The graph runner allow to run function defining small TensorFlow graphs:\n   * In eager mode: The function is simply run eagerly and the result is\n     returned\n   * In graph mode: The first time, the function is compiled in a new graph,\n     then, every time the same function will be called, the cached graph and\n     session will be run.\n\n  Ideally, one graph runner should only be used with a single function to avoid\n  having too many opened session in session mode.\n  Limitations:\n   * Currently the graph runner only support function with single input\n     and output. Support for more complex function could be added and should be\n     relatively straightforward.\n   * A different graph is created for each input shape, so it isn\'t really\n     adapted for dynamic batch size.\n\n  Usage:\n    graph_runner = TFGraphRunner()\n    output = graph_runner.run(tf.sigmoid, np.ones(shape=(5,)))\n\n  """"""\n\n  def __init__(self):\n    """"""Constructor.""""""\n    # Cache containing all compiled graph and opened session. Only used in\n    # non-eager mode.\n    self._graph_run_cache = {}\n\n  def run(self, fct, input_):\n    """"""Execute the given TensorFlow function.""""""\n    # TF 2.0\n    if tf.executing_eagerly():\n      return fct(input_).numpy()\n    # TF 1.0\n    else:\n      # Should compile the function if this is the first time encountered\n      if not isinstance(input_, np.ndarray):\n        input_ = np.array(input_)\n      run_args = RunArgs(fct=fct, input=input_)\n      signature = self._build_signature(run_args)\n      if signature not in self._graph_run_cache:\n        graph_run = self._build_graph_run(run_args)\n        self._graph_run_cache[signature] = graph_run\n      else:\n        graph_run = self._graph_run_cache[signature]\n\n      # Then execute the cached graph\n      return graph_run.session.run(\n          graph_run.output,\n          feed_dict={graph_run.placeholder: input_},\n      )\n\n  def _build_graph_run(self, run_args):\n    """"""Create a new graph for the given args.""""""\n    # Could try to use tfe.py_func(fct) but this would require knowing\n    # information about the signature of the function.\n\n    # Create a new graph:\n    with tf.Graph().as_default() as g:\n      # Create placeholder\n      input_ = run_args.input\n      placeholder = tf.compat.v1.placeholder(\n          dtype=input_.dtype, shape=input_.shape)\n      output = run_args.fct(placeholder)\n    return GraphRun(\n        session=raw_nogpu_session(g),\n        graph=g,\n        placeholder=placeholder,\n        output=output,\n    )\n\n  def _build_signature(self, run_args):\n    """"""Create a unique signature for each fct/inputs.""""""\n    return (id(run_args.fct), run_args.input.dtype, run_args.input.shape)\n\n  def __del__(self):\n    # Close all sessions\n    for graph_run in self._graph_run_cache.values():\n      graph_run.session.close()\n\n\ndef is_dtype(value):\n  """"""Return True is the given value is a TensorFlow dtype.""""""\n  try:\n    tf.as_dtype(value)\n  except TypeError:\n    return False\n  return True\n\n\ndef assert_shape_match(shape1, shape2):\n  """"""Ensure the shape1 match the pattern given by shape2.\n\n  Ex:\n    assert_shape_match((64, 64, 3), (None, None, 3))\n\n  Args:\n    shape1 (tuple): Static shape\n    shape2 (tuple): Dynamic shape (can contain None)\n  """"""\n  shape1 = tf.TensorShape(shape1)\n  shape2 = tf.TensorShape(shape2)\n  if shape1.ndims is None or shape2.ndims is None:\n    raise ValueError(\'Shapes must have known rank. Got %s and %s.\' %\n                     (shape1.ndims, shape2.ndims))\n  shape1.assert_same_rank(shape2)\n  shape1.assert_is_compatible_with(shape2)\n\n\n@contextlib.contextmanager\ndef nogpu_session(graph=None):\n  """"""tf.Session context manager, hiding GPUs.""""""\n  # We don\'t use the with construction because we don\'t want the Session to be\n  # installed as the ""default"" session.\n  sess = raw_nogpu_session(graph)\n  yield sess\n  sess.close()\n\n\ndef raw_nogpu_session(graph=None):\n  """"""tf.Session, hiding GPUs.""""""\n  config = tf.compat.v1.ConfigProto(device_count={\'GPU\': 0})\n  return tf.compat.v1.Session(config=config, graph=graph)\n\n\n@contextlib.contextmanager\ndef maybe_with_graph(graph=None, create_if_none=True):\n  """"""Eager-compatible Graph().as_default() yielding the graph.""""""\n  if tf.executing_eagerly():\n    yield None\n  else:\n    if graph is None and create_if_none:\n      graph = tf.Graph()\n\n    if graph is None:\n      yield None\n    else:\n      with graph.as_default():\n        yield graph\n'"
tensorflow_datasets/core/utils/tf_utils_test.py,8,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.utils.tf_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.utils import tf_utils\n\ntf.enable_v2_behavior()\n\n\nclass TfUtilsTest(testing.TestCase):\n\n  @testing.run_in_graph_and_eager_modes()\n  def test_graph_runner(self):\n    graph_runner = tf_utils.TFGraphRunner()\n\n    output = graph_runner.run(tf.nn.relu, [1, 1, -1, -1, 1])\n    self.assertAllEqual(output, [1, 1, 0, 0, 1])\n\n    output = graph_runner.run(tf.nn.relu, [-1, -1, -1, 1, 1])\n    self.assertAllEqual(output, [0, 0, 0, 1, 1])\n\n    # Cache should have been re-used, so should only contains one GraphRun\n    # Ideally there should be two separate @tf.eager.run_test_in_graph() and\n    # @tf.eager.run_test_in_eager() to avoid logic on the test. But haven\'t\n    # found it.\n    if not tf.executing_eagerly():\n      self.assertEqual(len(graph_runner._graph_run_cache), 1)\n    else:\n      self.assertEqual(len(graph_runner._graph_run_cache), 0)\n\n    # Different signature (different shape), so new GraphRun created\n    output = graph_runner.run(tf.nn.relu, [-1, 1, 1])\n    self.assertAllEqual(output, [0, 1, 1])\n    if not tf.executing_eagerly():\n      self.assertEqual(len(graph_runner._graph_run_cache), 2)\n    else:\n      self.assertEqual(len(graph_runner._graph_run_cache), 0)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/tqdm_utils.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Wrapper around tqdm.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport os\n\nfrom tqdm import auto as tqdm_lib\n\n\nclass EmptyTqdm(object):\n  """"""Dummy tqdm which doesn\'t do anything.""""""\n\n  def __init__(self, *args, **kwargs):   # pylint: disable=unused-argument\n    self._iterator = args[0] if args else None\n\n  def __iter__(self):\n    return iter(self._iterator)\n\n  def __getattr__(self, _):\n    """"""Return empty function.""""""\n    def empty_fn(*args, **kwargs):   # pylint: disable=unused-argument\n      return\n    return empty_fn\n\n  def __enter__(self):\n    return self\n\n  def __exit__(self, type_, value, traceback):\n    return\n\n_active = True\n# Disable progression bar when TFDS is executed inside TF kokoro documentation\n# infrastructure. Otherwise it creates visual artifacts in the notebook output\n# of the documentation pages.\nif \'TF_DOCS_INFRA_KOKORO\' in os.environ:\n  _active = False\n\n\ndef tqdm(*args, **kwargs):\n  if _active:\n    return tqdm_lib.tqdm(*args, **kwargs)\n  else:\n    return EmptyTqdm(*args, **kwargs)\n\n\ndef async_tqdm(*args, **kwargs):\n  if _active:\n    return _async_tqdm(*args, **kwargs)\n  else:\n    return EmptyTqdm(*args, **kwargs)\n\n\ndef disable_progress_bar():\n  """"""Disabled Tqdm progress bar.\n\n  Usage:\n\n  tfds.disable_progress_bar()\n  """"""\n  # Replace tqdm\n  global _active\n  _active = False\n\n\n@contextlib.contextmanager\ndef _async_tqdm(*args, **kwargs):\n  """"""Wrapper around Tqdm which can be updated in threads.\n\n  Usage:\n\n  ```\n  with utils.async_tqdm(...) as pbar:\n    # pbar can then be modified inside a thread\n    # pbar.update_total(3)\n    # pbar.update()\n  ```\n\n  Args:\n    *args: args of tqdm\n    **kwargs: kwargs of tqdm\n\n  Yields:\n    pbar: Async pbar which can be shared between threads.\n  """"""\n  with tqdm_lib.tqdm(*args, **kwargs) as pbar:\n    pbar = _TqdmPbarAsync(pbar)\n    yield pbar\n    pbar.clear()  # pop pbar from the active list of pbar\n    print()  # Avoid the next log to overlapp with the bar\n\n\nclass _TqdmPbarAsync(object):\n  """"""Wrapper around Tqdm pbar which be shared between thread.""""""\n  _tqdm_bars = []\n\n  def __init__(self, pbar):\n    self._lock = tqdm_lib.tqdm.get_lock()\n    self._pbar = pbar\n    self._tqdm_bars.append(pbar)\n\n  def update_total(self, n=1):\n    """"""Increment total pbar value.""""""\n    with self._lock:\n      self._pbar.total += n\n      self.refresh()\n\n  def update(self, n=1):\n    """"""Increment current value.""""""\n    with self._lock:\n      self._pbar.update(n)\n      self.refresh()\n\n  def refresh(self):\n    """"""Refresh all.""""""\n    for pbar in self._tqdm_bars:\n      pbar.refresh()\n\n  def clear(self):\n    """"""Remove the tqdm pbar from the update.""""""\n    self._tqdm_bars.pop()\n'"
tensorflow_datasets/core/utils/tqdm_utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.utils.tqdm_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core.utils import tqdm_utils\n\n\nclass TqdmUtilsTest(testing.TestCase):\n\n  def test_disable_tqdm(self):\n    tqdm_utils.disable_progress_bar()\n\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      builder = testing.DummyMnist(data_dir=tmp_dir)\n      builder.download_and_prepare()\n\n      # Check the data has been generated\n      train_ds, test_ds = builder.as_dataset(split=[\'train\', \'test\'])\n      train_ds, test_ds = dataset_utils.as_numpy((train_ds, test_ds))\n      self.assertEqual(20, len(list(train_ds)))\n      self.assertEqual(20, len(list(test_ds)))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/utils/version.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Version utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\nimport re\n\nimport six\n\n_VERSION_TMPL = (\n    r""^(?P<major>{v})""\n    r""\\.(?P<minor>{v})""\n    r""\\.(?P<patch>{v})$"")\n_VERSION_WILDCARD_REG = re.compile(_VERSION_TMPL.format(v=r""\\d+|\\*""))\n_VERSION_RESOLVED_REG = re.compile(_VERSION_TMPL.format(v=r""\\d+""))\n\n\nclass Experiment(enum.Enum):\n  """"""Experiments which can be enabled/disabled on a per version basis.\n\n  Experiments are designed to gradually apply changes to datasets while\n  maintaining backward compatibility with previous versions. All experiments\n  should eventually be deleted, once used by all versions of all datasets.\n\n  Eg:\n  class Experiment(enum.Enum):\n    EXP_A = enum.auto()  # Short description of experiment.\n\n  class MyBuilder(...):\n    VERSION = tfds.core.Version(\'1.2.3\', experiments={\n        tfds.core.Experiment.EXP_A: True,\n        })\n  """"""\n  # A Dummy experiment, which should NOT be used, except for testing.\n  DUMMY = 1\n\n\nclass Version(object):\n  """"""Dataset version MAJOR.MINOR.PATCH.""""""\n\n  _DEFAULT_EXPERIMENTS = {\n      Experiment.DUMMY: False,\n  }\n\n  def __init__(self, version_str, description=None, experiments=None,\n               tfds_version_to_prepare=None):\n    """"""Version init.\n\n    Args:\n      version_str: string. Eg: ""1.2.3"".\n      description: string, a description of what is new in this version.\n      experiments: dict of experiments. See Experiment.\n      tfds_version_to_prepare: string, defaults to None. If set, indicates that\n        current version of TFDS cannot be used to `download_and_prepare` the\n        dataset, but that TFDS at version {tfds_version_to_prepare} should be\n        used instead.\n    """"""\n    if description is not None and not isinstance(description, str):\n      raise TypeError(\n          ""Description should be a string. Got {}"".format(description))\n    self.description = description\n    self._experiments = self._DEFAULT_EXPERIMENTS.copy()\n    self.tfds_version_to_prepare = tfds_version_to_prepare\n    if experiments:\n      self._experiments.update(experiments)\n    self.major, self.minor, self.patch = _str_to_version(version_str)\n\n  def implements(self, experiment):\n    """"""Returns True if version implements given experiment.""""""\n    return self._experiments[experiment]\n\n  def __str__(self):\n    return ""{}.{}.{}"".format(*self.tuple)\n\n  @property\n  def tuple(self):\n    return self.major, self.minor, self.patch\n\n  def _validate_operand(self, other):\n    if isinstance(other, six.string_types):\n      return Version(other)\n    elif isinstance(other, Version):\n      return other\n    raise AssertionError(""{} (type {}) cannot be compared to version."".format(\n        other, type(other)))\n\n  def __eq__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple == other.tuple\n\n  def __ne__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple != other.tuple\n\n  def __lt__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple < other.tuple\n\n  def __le__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple <= other.tuple\n\n  def __gt__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple > other.tuple\n\n  def __ge__(self, other):\n    other = self._validate_operand(other)\n    return self.tuple >= other.tuple\n\n  def match(self, other_version):\n    """"""Returns True if other_version matches.\n\n    Args:\n      other_version: string, of the form ""x[.y[.x]]"" where {x,y,z} can be a\n        number or a wildcard.\n    """"""\n    major, minor, patch = _str_to_version(other_version, allow_wildcard=True)\n    return (major in [self.major, ""*""] and minor in [self.minor, ""*""]\n            and patch in [self.patch, ""*""])\n\n\ndef _str_to_version(version_str, allow_wildcard=False):\n  """"""Return the tuple (major, minor, patch) version extracted from the str.""""""\n  reg = _VERSION_WILDCARD_REG if allow_wildcard else _VERSION_RESOLVED_REG\n  res = reg.match(version_str)\n  if not res:\n    msg = ""Invalid version \'{}\'. Format should be x.y.z"".format(version_str)\n    if allow_wildcard:\n      msg += "" with {x,y,z} being digits or wildcard.""\n    else:\n      msg += "" with {x,y,z} being digits.""\n    raise ValueError(msg)\n  return tuple(\n      v if v == ""*"" else int(v)\n      for v in [res.group(""major""), res.group(""minor""), res.group(""patch"")])\n'"
tensorflow_datasets/core/utils/version_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for tensorflow_datasets.core.utils.version.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.utils import version\n\n\nclass VersionTest(testing.TestCase):\n\n  def test_str_to_version(self):\n    self.assertEqual(version._str_to_version(\'1.2.3\'), (1, 2, 3))\n    self.assertEqual(version._str_to_version(\'1.2.*\', True), (1, 2, \'*\'))\n    self.assertEqual(version._str_to_version(\'1.*.3\', True), (1, \'*\', 3))\n    self.assertEqual(version._str_to_version(\'*.2.3\', True), (\'*\', 2, 3))\n    self.assertEqual(version._str_to_version(\'1.*.*\', True), (1, \'*\', \'*\'))\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Invalid version \'):\n      version.Version(\'1.3\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Invalid version \'):\n      version.Version(\'1.3.*\')\n\n  def test_version(self):\n    v = version.Version(\'1.3.534\')\n    self.assertEqual((v.major, v.minor, v.patch), (1, 3, 534))\n    self.assertEqual(str(v), \'1.3.534\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Format should be \'):\n      version.Version(\'1.3.-534\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Format should be \'):\n      version.Version(\'1.3\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Format should be \'):\n      version.Version(\'1.3.\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Format should be \'):\n      version.Version(\'1..5\')\n    with self.assertRaisesWithPredicateMatch(ValueError, \'Format should be \'):\n      version.Version(\'a.b.c\')\n\n  def test_comparison(self):\n    v = version.Version(\'1.3.534\')\n    self.assertLess(v, version.Version(\'1.3.999\'))\n    self.assertLess(v, \'1.3.999\')\n    self.assertGreater(\'1.4.5\', v)\n    self.assertEqual(v, \'1.3.534\')\n    self.assertNotEqual(v, version.Version(\'1.3.535\'))\n\n  def test_invalid_comparison(self):\n    v = version.Version(\'1.3.534\')\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, \'Format should be \'):\n      unused_ = v < \'abc\'\n    with self.assertRaisesWithPredicateMatch(\n        AssertionError, \'cannot be compared to version\'):\n      unused_ = v > 123\n\n  def test_match(self):\n    v = version.Version(\'1.2.3\')\n    self.assertTrue(v.match(\'1.2.3\'))\n    self.assertTrue(v.match(\'1.2.*\'))\n    self.assertTrue(v.match(\'1.*.*\'))\n    self.assertTrue(v.match(\'*.*.*\'))\n    self.assertTrue(v.match(\'*.2.3\'))\n    self.assertFalse(v.match(\'1.2.4\'))\n    self.assertFalse(v.match(\'1.3.*\'))\n    self.assertFalse(v.match(\'1.3.*\'))\n    self.assertFalse(v.match(\'2.*.*\'))\n\n  def test_eq(self):\n    v1 = version.Version(\'1.2.3\')\n    v2 = version.Version(\'1.2.3\')\n    v3 = \'1.2.3\'\n    # pylint: disable=g-generic-assert\n    self.assertTrue(v1 == v2)\n    self.assertTrue(v1 <= v2)\n    self.assertTrue(v1 >= v2)\n    self.assertTrue(v1 == v3)\n    self.assertTrue(v1 <= v3)\n    self.assertTrue(v1 >= v3)\n    # pylint: enable=g-generic-assert\n\n  def test_neq(self):\n    v1 = version.Version(\'1.2.3\')\n    v2 = version.Version(\'1.2.4\')\n    v3 = \'1.2.4\'\n    # pylint: disable=g-generic-assert\n    self.assertTrue(v1 != v2)\n    self.assertTrue(v1 != v3)\n    # pylint: enable=g-generic-assert\n\n  def test_less(self):\n    v1 = version.Version(\'1.2.3\')\n    v2 = version.Version(\'1.2.4\')\n    v3 = \'1.2.4\'\n    # pylint: disable=g-generic-assert\n    self.assertTrue(v1 < v2)\n    self.assertTrue(v1 <= v2)\n    self.assertTrue(v1 < v3)\n    self.assertTrue(v1 <= v3)\n    # pylint: enable=g-generic-assert\n\n  def test_sup(self):\n    v1 = version.Version(\'1.2.3\')\n    v2 = version.Version(\'1.2.4\')\n    v3 = \'1.2.4\'\n    # pylint: disable=g-generic-assert\n    self.assertTrue(v2 > v1)\n    self.assertTrue(v2 >= v1)\n    self.assertTrue(v3 > v1)\n    self.assertTrue(v3 >= v1)\n    # pylint: enable=g-generic-assert\n\n  def test_experiment_default(self):\n    v = version.Version(\'1.2.3\')\n    self.assertFalse(v.implements(version.Experiment.DUMMY))\n\n  def test_experiment_override(self):\n    v = version.Version(\'1.2.3\', experiments={version.Experiment.DUMMY: True})\n    self.assertTrue(v.implements(version.Experiment.DUMMY))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/visualization/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Visualizer utils.""""""\n\nfrom tensorflow_datasets.core.visualization.image_visualizer import ImageGridVisualizer\nfrom tensorflow_datasets.core.visualization.show_examples import show_examples\nfrom tensorflow_datasets.core.visualization.show_examples import show_statistics\nfrom tensorflow_datasets.core.visualization.visualizer import Visualizer\n\n\n__all__ = [\n    ""ImageGridVisualizer"",\n    ""show_examples"",\n    ""Visualizer"",\n]\n'"
tensorflow_datasets/core/visualization/image_visualizer.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Image visualizer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional\n\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import dataset_utils\nfrom tensorflow_datasets.core import features as features_lib\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core.visualization import visualizer\n\n\ndef _make_grid(plot_single_ex_fn, ds, rows, cols, plot_scale):\n  """"""Plot each individual example in a grid.\n\n  Args:\n    plot_single_ex_fn: Function with fill a single cell of the grid, with\n      signature `fn(ax: matplotlib.axes.Axes, ex: Nested[np.array]) -> None`\n    ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n      should not be batched. Examples will be consumed in order until\n      (rows * cols) are read or the dataset is consumed.\n    rows: `int`, number of rows of the display grid.\n    cols: `int`, number of columns of the display grid.\n    plot_scale: `float`, controls the plot size of the images. Keep this\n      value around 3 to get a good plot. High and low values may cause\n      the labels to get overlapped.\n\n  Returns:\n    fig: The `matplotlib.Figure` object.\n  """"""\n  plt = lazy_imports_lib.lazy_imports.matplotlib.pyplot\n\n  num_examples = rows * cols\n  examples = list(dataset_utils.as_numpy(ds.take(num_examples)))\n\n  fig = plt.figure(figsize=(plot_scale * cols, plot_scale * rows))\n  fig.subplots_adjust(hspace=1 / plot_scale, wspace=1 / plot_scale)\n\n  for i, ex in enumerate(examples):\n    ax = fig.add_subplot(rows, cols, i+1)\n    plot_single_ex_fn(ax, ex)\n\n  plt.show()\n  return fig\n\n\ndef _add_image(ax, image):\n  """"""Add the image to the given `matplotlib.axes.Axes`.""""""\n  plt = lazy_imports_lib.lazy_imports.matplotlib.pyplot\n\n  if len(image.shape) != 3:\n    raise ValueError(\n        \'Image dimension should be 3. tfds.show_examples does not support \'\n        \'batched examples or video.\')\n  _, _, c = image.shape\n  if c == 1:\n    image = image.reshape(image.shape[:2])\n  ax.imshow(image, cmap=\'gray\')\n  ax.grid(False)\n  plt.xticks([], [])\n  plt.yticks([], [])\n\n\nclass ImageGridVisualizer(visualizer.Visualizer):\n  """"""Visualizer for supervised image datasets.""""""\n\n  def match(self, ds_info: dataset_info.DatasetInfo) -> bool:\n    """"""See base class.""""""\n    # Supervised required a single image key\n    image_keys = visualizer.extract_keys(ds_info.features, features_lib.Image)\n    return len(image_keys) >= 1\n\n  def show(\n      self,\n      ds: tf.data.Dataset,\n      ds_info: dataset_info.DatasetInfo,\n      rows: int = 3,\n      cols: int = 3,\n      plot_scale: float = 3.,\n      image_key: Optional[str] = None,\n  ):\n    """"""Display the dataset.\n\n    Args:\n      ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n        should not be batched. Examples will be consumed in order until\n        (rows * cols) are read or the dataset is consumed.\n      ds_info: `tfds.core.DatasetInfo` object of the dataset to visualize.\n      rows: `int`, number of rows of the display grid.\n      cols: `int`, number of columns of the display grid.\n      plot_scale: `float`, controls the plot size of the images. Keep this\n        value around 3 to get a good plot. High and low values may cause\n        the labels to get overlapped.\n      image_key: `string`, name of the feature that contains the image. If not\n         set, the system will try to auto-detect it.\n\n    Returns:\n      fig: The pyplot figure.\n    """"""\n    # Extract the image key\n    if not image_key:\n      image_keys = visualizer.extract_keys(ds_info.features, features_lib.Image)\n      if len(image_keys) > 1:\n        raise ValueError(\n            \'Multiple image features detected in the dataset. \'\n            \'Use `image_key` argument to override. Images detected: {}\'.format(\n                image_keys))\n      image_key = image_keys[0]\n\n    # Optionally extract the label key\n    label_keys = visualizer.extract_keys(\n        ds_info.features, features_lib.ClassLabel)\n    label_key = label_keys[0] if len(label_keys) == 1 else None\n    if not label_key:\n      logging.info(\'Was not able to auto-infer label.\')\n\n    # Single image display\n    def make_cell_fn(ax, ex):\n      plt = lazy_imports_lib.lazy_imports.matplotlib.pyplot\n\n      if not isinstance(ex, dict):\n        raise ValueError(\n            \'{} requires examples as `dict`, with the same \'\n            \'structure as `ds_info.features`. It is currently not compatible \'\n            \'with `as_supervised=True`. Received: {}\'.format(\n                type(self).__name__, type(ex)))\n\n      _add_image(ax, ex[image_key])\n      if label_key:\n        label = ex[label_key]\n        label_str = ds_info.features[label_key].int2str(label)\n        plt.xlabel(\'{} ({})\'.format(label_str, label))\n\n    # Returns the grid.\n    fig = _make_grid(make_cell_fn, ds, rows, cols, plot_scale)\n    return fig\n'"
tensorflow_datasets/core/visualization/show_examples.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Show example util.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import dataset_info\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core import splits\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.visualization import image_visualizer\nfrom tensorflow_metadata.proto.v0 import statistics_pb2\n\n\n_ALL_VISUALIZERS = [\n    image_visualizer.ImageGridVisualizer(),\n]\n\n\ndef show_examples(\n    ds: tf.data.Dataset,\n    ds_info: dataset_info.DatasetInfo,\n    **options_kwargs: Any\n):\n  """"""Visualize images (and labels) from an image classification dataset.\n\n  This function is for interactive use (Colab, Jupyter). It displays and return\n  a plot of (rows*columns) images from a tf.data.Dataset.\n\n  Usage:\n  ```python\n  ds, ds_info = tfds.load(\'cifar10\', split=\'train\', with_info=True)\n  fig = tfds.show_examples(ds, ds_info)\n  ```\n\n  Args:\n    ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n      should not be batched. Examples will be consumed in order until\n      (rows * cols) are read or the dataset is consumed.\n    ds_info: The dataset info object to which extract the label and features\n      info. Available either through `tfds.load(\'mnist\', with_info=True)` or\n      `tfds.builder(\'mnist\').info`\n    **options_kwargs: Additional display options, specific to the dataset type\n      to visualize. Are forwarded to `tfds.visualization.Visualizer.show`.\n      See the `tfds.visualization` for a list of available visualizers.\n\n  Returns:\n    fig: The `matplotlib.Figure` object\n  """"""\n  if not isinstance(ds_info, dataset_info.DatasetInfo):  # Arguments inverted\n    # `absl.logging` does not appear on Colab by default, so uses print instead.\n    print(\'WARNING: For consistency with `tfds.load`, the `tfds.show_examples` \'\n          \'signature has been modified from (info, ds) to (ds, info).\\n\'\n          \'The old signature is deprecated and will be removed. \'\n          \'Please change your call to `tfds.show_examples(ds, info)`\')\n    ds, ds_info = ds_info, ds\n  for visualizer in _ALL_VISUALIZERS:\n    if visualizer.match(ds_info):\n      return visualizer.show(ds, ds_info, **options_kwargs)\n    raise ValueError(\n        \'Visualisation not supported for dataset `{}`\'.format(ds_info.name)\n    )\n\n\ndef show_statistics(\n    ds_info: dataset_info.DatasetInfo,\n    split: splits.Split = splits.Split.TRAIN,\n    disable_logging: bool = True,\n) -> None:\n  """"""Display the datasets statistics on a Colab/Jupyter notebook.\n\n  `tfds.show_statistics` is a wrapper around\n  [tensorflow_data_validation](https://www.tensorflow.org/tfx/data_validation/get_started)\n  which calls `tfdv.visualize_statistics`. Statistics are displayed using\n  [FACETS OVERVIEW](https://pair-code.github.io/facets/).\n\n  Usage:\n\n  ```\n  builder = tfds.builder(\'mnist\')\n  tfds.show_statistics(builder.info)\n  ```\n\n  Or:\n\n  ```\n  ds, ds_info = tfds.load(\'mnist\', with_info)\n  tfds.show_statistics(ds_info)\n  ```\n\n  Note: In order to work, `tensorflow_data_validation` must be installed and\n  the dataset info object must contain the statistics. For ""official"" datasets,\n  only datasets which have been added/updated recently will contains statistics.\n  For ""custom"" datasets, you need to generate the dataset with\n  `tensorflow_data_validation` installed to have the statistics.\n\n  Args:\n    ds_info: The `tfds.core.DatasetInfo` object containing the statistics.\n    split: Split for which generate the statistics.\n    disable_logging: `bool`, if True, disable the tfdv logs which can be\n      too verbose.\n\n  Returns:\n    `None`\n  """"""\n  tfdv = lazy_imports_lib.lazy_imports.tensorflow_data_validation\n\n  if split not in ds_info.splits:\n    raise ValueError(\n        \'Invalid requested split: \\\'{}\\\'. Only {} are availables.\'.format(\n            split, list(ds_info.splits)))\n\n  # Creates the statistics.\n  statistics = statistics_pb2.DatasetFeatureStatisticsList()\n  statistics.datasets.add().CopyFrom(ds_info.splits[split].statistics)\n  with utils.disable_logging() if disable_logging else utils.nullcontext():\n    return tfdv.visualize_statistics(statistics)\n'"
tensorflow_datasets/core/visualization/show_examples_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for `tensorflow_datasets.core.visualization.show_examples`.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\n\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core import registered\nfrom tensorflow_datasets.core import visualization\n\n# Import for registration\nfrom tensorflow_datasets.image_classification import imagenet  # pylint: disable=unused-import,g-bad-import-order\n\n\nclass ShowExamplesTest(testing.TestCase):\n\n  @mock.patch(\'matplotlib.pyplot.figure\')\n  def test_show_examples(self, mock_fig):\n    with testing.mock_data(num_examples=20):\n      ds, ds_info = registered.load(\n          \'imagenet2012\', split=\'train\', with_info=True)\n    visualization.show_examples(ds, ds_info)\n\n  # TODO(tfds): Should add test when there isn\'t enough examples (ds.take(3))\n\n\nclass ShowStatisticsTest(testing.TestCase):\n\n  def test_show_examples(self):\n    with testing.mock_data():\n      builder = registered.builder(\'imagenet2012\')\n      visualization.show_statistics(builder.info)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/visualization/visualizer.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base visualizer class.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Any\n\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import dataset_info\n\n\ndef extract_keys(feature_dict, feature_cls):\n  """"""Extracts keys from features dict based on feature type.\n\n  Args:\n    feature_dict: `tfds.features.FeaturesDict` from which extract keys\n    feature_cls: `tfds.features.FeatureConnector` class to search.\n\n  Returns:\n    List of extracted keys matching the class.\n  """"""\n  return [k for k, f in feature_dict.items() if isinstance(f, feature_cls)]\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Visualizer(object):\n  """"""Visualizer.""""""\n\n  @abc.abstractmethod\n  def match(self, ds_info: dataset_info.DatasetInfo) -> bool:\n    """"""Returns whether the visualizer is compatible with the dataset.\n\n    Args:\n      ds_info: `tfds.core.DatasetInfo` object of the dataset to visualize.\n\n    Returns:\n      bool: True if the visualizer can be applied to the dataset.\n    """"""\n\n  @abc.abstractmethod\n  def show(\n      self,\n      ds: tf.data.Dataset,\n      ds_info: dataset_info.DatasetInfo,\n      **options_kwargs: Any\n  ):\n    """"""Display the dataset.\n\n    Args:\n      ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n        should not be batched. Examples will be consumed in order until\n        (rows * cols) are read or the dataset is consumed.\n      ds_info: `tfds.core.DatasetInfo` object of the dataset to visualize.\n      **options_kwargs: Additional display options, specific to the dataset type\n        to visualize. See the `tfds.visualization` for a list of available\n        visualizers.\n    """"""\n'"
tensorflow_datasets/scripts/deployment/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n'"
tensorflow_datasets/scripts/deployment/copy_dataset_info_files.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Copy the info files from placer to GCS bucket.\n""""""\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets as tfds\n\n\nflags.DEFINE_boolean(\'dry_run\', True, \'If True, just print, do nothing.\')\nflags.DEFINE_boolean(\'overwrite\', False, \'If True, overwrites the data.\')\nflags.DEFINE_string(\n    \'from_directory\', tfds.core.constants.DATA_DIR,\n    \'Where to get the info files from (datasets/ dir on placer).\')\nflags.DEFINE_string(\n    \'to_directory\', tfds.core.gcs_path(\'dataset_info\'),\n    \'Path where dataset info files will be copied.\')\n\nFLAGS = flags.FLAGS\n\n\ndef _copy_metadata(from_dir, to_dir):\n  """"""Copy the info files from within `from_dir` to `to_dir`.""""""\n  if not FLAGS.dry_run:\n    tf.io.gfile.makedirs(to_dir)\n  for fname in tfds.core.utils.list_info_files(from_dir):\n    from_path = os.path.join(from_dir, fname)\n    to_path = os.path.join(to_dir, fname)\n    logging.info(\'cp %s %s\', from_path, to_path)\n    if not FLAGS.dry_run:\n      tf.io.gfile.copy(from_path, to_path, overwrite=True)\n\n\ndef copy(from_dir: str, to_dir: str) -> None:\n  """"""Copy the info files from within `from_dir` to `to_dir`.""""""\n  predicate_fn = lambda _: True  # All datasets\n\n  for full_name in tfds.core.registered.list_full_names(predicate_fn):\n    from_full_name_dir = os.path.join(from_dir, full_name)\n    to_full_name_dir = os.path.join(to_dir, full_name)\n\n    # Skip if the dataset isn\'t generated or that metadata are already copied\n    if not tf.io.gfile.exists(from_full_name_dir):\n      logging.info(\'Skipping %s (not found)\', from_full_name_dir)\n      continue\n    if tf.io.gfile.exists(to_full_name_dir) and not FLAGS.overwrite:\n      logging.info(\'Skipping %s (already exists)\', to_full_name_dir)\n      continue\n\n    _copy_metadata(from_dir=from_full_name_dir, to_dir=to_full_name_dir)\n\n\ndef main(_):\n  copy(FLAGS.from_directory, FLAGS.to_directory)\n\nif __name__ == \'__main__\':\n  app.run(main)\n\n'"
tensorflow_datasets/scripts/documentation/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n'"
tensorflow_datasets/scripts/documentation/build_api_docs.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""generates api_docs for tensorflow_datasets.""""""\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets import testing\n\nfrom tensorflow_docs.api_generator import generate_lib\nimport yaml\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(""output_dir"", ""/tmp/datasets_api"",\n                    ""Where to output the docs"")\nflags.DEFINE_string(\n    ""code_url_prefix"",\n    ""https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/"",\n    ""The url prefix for links to code."")\n\nflags.DEFINE_bool(""search_hints"", True,\n                  ""Include metadata search hints in the generated files"")\n\nflags.DEFINE_string(""site_path"", ""datasets/api_docs/python"",\n                    ""Path prefix in the _toc.yaml"")\n\nMOVES = [(""tfds/features/text.md"", ""tfds/features/text_lib.md"")]\n\n\ndef execute(output_dir, code_url_prefix, search_hints, site_path):\n  """"""Builds API docs for tensorflow_datasets.""""""\n  # Internally, tfds.testing defaults to None. Fill it in here so that we get\n  # documentation.\n  tfds.testing = testing\n  doc_generator = generate_lib.DocGenerator(\n      root_title=""TensorFlow Datasets"",\n      py_modules=[(""tfds"", tfds)],\n      base_dir=os.path.dirname(tfds.__file__),\n      search_hints=search_hints,\n      code_url_prefix=code_url_prefix,\n      site_path=site_path)\n\n  doc_generator.build(output_dir)\n\n  new_redirects = []\n  for before, after in MOVES:\n    old_path = os.path.join(output_dir, before)\n    new_path = os.path.join(output_dir, after)\n    os.rename(old_path, new_path)\n\n    new_redirects.append({\n        ""from"":\n            os.path.join(""/datasets/api_docs/python/"",\n                         os.path.splitext(before)[0]),\n        ""to"":\n            os.path.join(""/datasets/api_docs/python/"",\n                         os.path.splitext(after)[0])\n    })\n\n  redirect_path = os.path.join(output_dir, ""_redirects.yaml"")\n  with open(redirect_path) as f:\n    redirect_content = yaml.load(f)\n  redirect_content[""redirects""].extend(new_redirects)\n  with open(redirect_path, ""w"") as f:\n    yaml.dump(redirect_content, f, default_flow_style=False)\n\n\ndef main(unused_argv):\n  execute(FLAGS.output_dir, FLAGS.code_url_prefix, FLAGS.search_hints,\n          FLAGS.site_path)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/scripts/documentation/build_api_docs_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Smoke Test for docs generation.""""""\n\nimport os\nimport shutil\nimport tempfile\n\nfrom absl.testing import absltest\n\nfrom tensorflow_datasets.scripts.documentation import build_api_docs\n\n\nclass BuildDocsTest(absltest.TestCase):\n\n  def setUp(self):\n    super(BuildDocsTest, self).setUp()\n    self.workdir = tempfile.mkdtemp()\n    if os.path.exists(self.workdir):\n      shutil.rmtree(self.workdir)\n    os.makedirs(self.workdir)\n\n  def test_api_gen(self):\n    build_api_docs.execute(\n        output_dir=self.workdir,\n        code_url_prefix="""",\n        search_hints=True,\n        site_path=""datasets/api_docs/python"")\n\n    # Check that the ""defined in"" section is working\n    with open(os.path.join(self.workdir, ""tfds.md"")) as f:\n      content = f.read()\n    self.assertIn(""__init__.py"", content)\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
tensorflow_datasets/scripts/documentation/build_catalog.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Tool to generate the dataset catalog documentation.\n""""""\n\nimport argparse\nimport os\nfrom typing import List, Optional\n\nfrom absl import app\nfrom absl.flags import argparse_flags\nimport dataclasses\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets.scripts.documentation import document_datasets\nimport yaml\n\n\ndef _parse_flags(_) -> argparse.Namespace:\n  """"""Command line flags.""""""\n  parser = argparse_flags.ArgumentParser(\n      prog=\'build_catalog\',\n      description=\'Tool to generate the dataset catalog documentation\',\n  )\n  parser.add_argument(\n      \'--datasets\',\n      help=\'Comma separated list of datasets to document. None for all \'\n      \'datasets.\',\n  )\n  parser.add_argument(\n      \'--catalog_dir\',\n      help=\'Directory path where to generate the catalog. Default to TFDS dir.\',\n  )\n  return parser.parse_args()\n\n\ndef main(args: argparse.Namespace):\n  catalog_dir = args.catalog_dir or os.path.join(\n      tfds.core.utils.tfds_dir(),\n      \'docs\',\n      \'catalog\',\n  )\n\n  build_catalog(\n      datasets=args.datasets.split(\',\') if args.datasets else None,\n      catalog_dir=catalog_dir,\n  )\n\n\n@dataclasses.dataclass\nclass DatasetItem(object):\n  name: str\n  path: str\n  is_nightly: bool = False\n\n\ndef create_section_toc(section, section_datasets):\n  heading = \'\\n### `%s`\\n\' % section\n  nightly_suffix = \' \' + document_datasets.NightlyDocUtil.icon\n  entries = [\n      f\' * [`{item.name}`]({item.path})\' +\n      (item.is_nightly and nightly_suffix or \'\') for item in section_datasets\n  ]\n  return \'\\n\'.join([heading] + entries)\n\n\ndef build_catalog(\n    datasets: Optional[List[str]] = None,\n    catalog_dir: Optional[str] = None,\n    toc_relative_path: str = \'/datasets/catalog/\',\n) -> None:\n  """"""Document all datasets, including the table of content.\n\n  Args:\n    datasets: Lists of dataset to document (all if not set)\n    catalog_dir: Destination path for the catalog\n    toc_relative_path: Relative path of the catalog directory, used to\n      generate the table of content relative links.\n  """"""\n  # Build datasets doc\n  print(\'Build datasets overview...\')\n  overview_doc, datasets_dict = document_datasets.dataset_docs_str(datasets)\n\n  # For _toc.yaml\n  toc_dictionary = {\'toc\': [{\n      \'title\': \'Overview\',\n      \'path\': os.path.join(toc_relative_path, \'overview\'),\n  }]}\n\n  section_tocs = []\n\n  nightly_util = document_datasets.NightlyDocUtil()\n\n  print(\'Build Sections\')\n  for section, datasets_in_section in sorted(list(datasets_dict.items())):\n    print(\'Section %s...\' % section)\n    section_str = section.replace(\'_\', \' \').capitalize()\n    sec_dict = {\'title\': section_str}\n    sec_paths = list()\n    section_toc = []\n    for dataset_name, is_manual, doc in datasets_in_section:\n      print(\'Dataset %s...\' % dataset_name)\n\n      sidebar_item = {\n          \'path\': os.path.join(toc_relative_path, dataset_name),\n          \'title\': dataset_name + (\' (manual)\' if is_manual else \'\')\n      }\n      ds_item = DatasetItem(\n          name=dataset_name,\n          path=dataset_name + \'.md\',\n      )\n      if nightly_util.is_builder_nightly(dataset_name):\n        sidebar_item[\'status\'] = \'nightly\'\n        ds_item.is_nightly = True\n\n      sec_paths.append(sidebar_item)\n      section_toc.append(ds_item)\n\n      dataset_file = os.path.join(catalog_dir, dataset_name + \'.md\')\n      with tf.io.gfile.GFile(dataset_file, \'w\') as f:\n        f.write(doc)\n\n    section_tocs.append(create_section_toc(section_str, section_toc))\n    sec_dict[\'section\'] = sec_paths\n    toc_dictionary[\'toc\'].append(sec_dict)\n\n  with tf.io.gfile.GFile(os.path.join(catalog_dir, \'overview.md\'), \'w\') as f:\n    f.write(overview_doc.format(toc=\'\\n\'.join(section_tocs)))\n\n  with tf.io.gfile.GFile(os.path.join(catalog_dir, \'_toc.yaml\'), \'w\') as f:\n    yaml.dump(toc_dictionary, f, default_flow_style=False)\n\n\nif __name__ == \'__main__\':\n  app.run(main, flags_parser=_parse_flags)\n'"
tensorflow_datasets/scripts/documentation/document_datasets.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Util to generate the dataset documentation content.\n\nUsed by tensorflow_datasets/scripts/documentation/build_catalog.py\n\n""""""\n\nimport collections\nfrom concurrent import futures\nimport os\nfrom typing import Dict, List, Tuple, Union, Set\n\nimport mako.lookup\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets as tfds\n\nWORKER_COUNT_DATASETS = 200\nWORKER_COUNT_CONFIGS = 50\n\nBASE_URL = \'https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets\'\n\n# WmtTranslate: The raw wmt can only be instantiated with the config kwargs\n# TODO(tfds): Document image_label_folder datasets in a separate section\nBUILDER_BLACKLIST = [\'wmt_translate\']\n\n\n# Dict of `full_names_dict[\'dataset\'][\'config\'][\'version\']`\nFullNamesDict = Dict[str, Dict[str, Set[str]]]\n# Same as `FullNamesDict`, but contains `True` for nightly datasets:\n# * New dataset: nightly_dict[\'dataset\'] is True\n# * New config: nightly_dict[\'dataset\'][\'config\'] is True\n# * New version: nightly_dict[\'dataset\'][\'config\'][\'version\'] is True\nNightlyDict = Dict[str, Union[bool, Dict[str, Union[bool, Dict[str, bool]]]]]\n\n\nclass VisualizationDocUtil(object):\n  """"""Small util which generate the path/urls for the visualizations.""""""\n  # Url used to display images\n  BASE_PATH = tfds.core.gcs_path(\'visualization/\')\n  BASE_URL = \'https://storage.googleapis.com/tfds-data/visualization/\'\n\n  def _get_name(self, builder):\n    return builder.info.full_name.replace(\'/\', \'-\') + \'.png\'\n\n  def get_url(self, builder):\n    return self.BASE_URL + self._get_name(builder)\n\n  def get_html_tag(self, builder: tfds.core.DatasetBuilder) -> str:\n    """"""Returns the <img> html tag.""""""\n    url = self.get_url(builder)\n    return f\'<img src=""{url}"" alt=""Visualization"" width=""500px"">\'\n\n  def has_visualization(self, builder):\n    filepath = os.path.join(self.BASE_PATH, self._get_name(builder))\n    return tf.io.gfile.exists(filepath)\n\n\ndef _split_full_name(full_name: str) -> Tuple[str, str, str]:\n  """"""Extracts the `(ds name, config, version)` from the full_name.""""""\n  if not tfds.core.registered.is_full_name(full_name):\n    raise ValueError(\n        f\'Parsing builder name string {full_name} failed.\'\n        \'The builder name string must be of the following format:\'\n        \'`dataset_name[/config_name]/version`\')\n  ds_name, *optional_config, version = full_name.split(\'/\')\n  assert len(optional_config) <= 1\n  config = next(iter(optional_config)) if optional_config else \'\'\n  return ds_name, config, version\n\n\ndef _full_names_to_dict(full_names: List[str]) -> FullNamesDict:\n  """"""Creates the dict `d[\'dataset\'][\'config\'][\'version\']`.""""""\n  full_names_dict = collections.defaultdict(\n      lambda: collections.defaultdict(set))\n  for full_name in full_names:\n    ds_name, config, version = _split_full_name(full_name)\n    full_names_dict[ds_name][config].add(version)\n  return full_names_dict\n\n\ndef _build_nightly_dict(\n    registered_ds: FullNamesDict,\n    stable_version_ds: FullNamesDict,\n) -> NightlyDict:\n  """"""Computes the nightly dict from the registered and stable dict.""""""\n  nightly_ds = collections.defaultdict(\n      lambda: collections.defaultdict(  # pylint: disable=g-long-lambda\n          lambda: collections.defaultdict(bool)))\n  for dataset in registered_ds:\n    if dataset in stable_version_ds:\n      for config in registered_ds[dataset]:\n        if config in stable_version_ds[dataset]:\n          for version in registered_ds[dataset][config]:\n            if version in stable_version_ds[dataset][config]:\n              # (dataset, config, version) already exists\n              # We add it to the nightly dict to make sure the\n              # key exists\n              nightly_ds[dataset][config][version] = False\n            else:\n              # New version only present in tfds-nightly\n              nightly_ds[dataset][config][version] = True\n        else:\n          # New config only present in tfds-nightly\n          nightly_ds[dataset][config] = True\n    else:\n      # New dataset only present in tfds-nightly\n      nightly_ds[dataset] = True\n  return nightly_ds\n\n\n@tfds.core.utils.memoize()\ndef _load_nightly_dict() -> NightlyDict:\n  """"""Loads (and caches) the nightly dict.""""""\n  version_path = tfds.core.utils.get_tfds_path(\'stable_versions.txt\')\n  with tf.io.gfile.GFile(version_path, \'r\') as f:\n    stable_versions = f.read().splitlines()\n\n  # Build the `full_names_dict[\'dataset\'][\'config\'][\'version\']` for both\n  # nightly and stable version\n  registered_ds = _full_names_to_dict(\n      tfds.core.registered.list_full_names())\n  stable_version_ds = _full_names_to_dict(stable_versions)\n\n  # Nightly versions are `registered - stable`\n  return _build_nightly_dict(registered_ds, stable_version_ds)\n\n\nclass NightlyDocUtil(object):\n  """"""Small util to format the doc.""""""\n\n  def __init__(self):\n    self._nightly_dict: NightlyDict = _load_nightly_dict()\n\n  def is_builder_nightly(\n      self,\n      builder: Union[tfds.core.DatasetBuilder, str],\n  ) -> bool:\n    """"""Returns `True` if the builder is new.""""""\n    if isinstance(builder, tfds.core.DatasetBuilder):\n      builder_name = builder.name\n    else:\n      builder_name = builder\n    return self._nightly_dict[builder_name] is True  # pylint: disable=g-bool-id-comparison\n\n  def is_config_nightly(self, builder: tfds.core.DatasetBuilder) -> bool:\n    """"""Returns `True` if the config is new.""""""\n    ds_name, config, _ = _split_full_name(builder.info.full_name)\n    if self.is_builder_nightly(builder):\n      return False\n    return self._nightly_dict[ds_name][config] is True  # pylint: disable=g-bool-id-comparison\n\n  def is_version_nightly(\n      self,\n      builder: tfds.core.DatasetBuilder,\n      version: str,\n  ) -> bool:\n    """"""Returns `True` if the version is new.""""""\n    ds_name, config, _ = _split_full_name(builder.info.full_name)\n    if self.is_builder_nightly(builder) or self.is_config_nightly(builder):\n      return False\n    return self._nightly_dict[ds_name][config][version] is True  # pylint: disable=g-bool-id-comparison\n\n  def has_nightly(self, builder: tfds.core.DatasetBuilder) -> bool:\n    """"""Returns True if any of the builder/config/version is new.""""""\n    def reduce(value):\n      if isinstance(value, bool):\n        return value\n      elif isinstance(value, dict):\n        return any(reduce(x) for x in value.values())\n      else:\n        raise AssertionError(f\'Invalid nightly_dict value: {value}\')\n\n    return reduce(self._nightly_dict[builder.name])\n\n  icon = (\n      \'<span class=""material-icons"" \'\n      \'title=""Available only in the tfds-nightly package"">nights_stay</span>\')\n\n\n@tfds.core.utils.memoize()\ndef get_mako_template(tmpl_name):\n  """"""Returns mako.lookup.Template object to use to render documentation.\n\n  Args:\n    tmpl_name: string, name of template to load.\n\n  Returns:\n    mako \'Template\' instance that can be rendered.\n  """"""\n  tmpl_path = tfds.core.utils.get_tfds_path(\n      \'scripts/documentation/templates/%s.mako.md\' % tmpl_name)\n  with tf.io.gfile.GFile(tmpl_path, \'r\') as tmpl_f:\n    tmpl_content = tmpl_f.read()\n  return mako.lookup.Template(tmpl_content, default_filters=[\'str\', \'trim\'])\n\n\ndef document_single_builder(builder):\n  """"""Doc string for a single builder, with or without configs.""""""\n  print(\'Document builder %s...\' % builder.name)\n  get_config_builder = lambda config: tfds.builder(builder.name, config=config)\n  config_builders = []\n  if builder.builder_configs:\n    with futures.ThreadPoolExecutor(max_workers=WORKER_COUNT_CONFIGS) as tpool:\n      config_builders = list(\n          tpool.map(get_config_builder, builder.BUILDER_CONFIGS))\n  tmpl = get_mako_template(\'dataset\')\n  visu_doc_util = VisualizationDocUtil()\n  out_str = tmpl.render_unicode(\n      builder=builder,\n      config_builders=config_builders,\n      visu_doc_util=visu_doc_util,\n      nightly_doc_util=NightlyDocUtil(),\n  ).strip()\n  schema_org_tmpl = get_mako_template(\'schema_org\')\n  schema_org_out_str = schema_org_tmpl.render_unicode(\n      builder=builder,\n      config_builders=config_builders,\n      visu_doc_util=visu_doc_util,\n  ).strip()\n  out_str = schema_org_out_str + \'\\n\' + out_str\n  return out_str\n\n\ndef make_module_to_builder_dict(datasets=None):\n  """"""Get all builders organized by module in nested dicts.""""""\n  # pylint: disable=g-long-lambda\n  # dict to hold tfds->image->mnist->[builders]\n  module_to_builder = collections.defaultdict(\n      lambda: collections.defaultdict(\n          lambda: collections.defaultdict(list)))\n  # pylint: enable=g-long-lambda\n\n  if not datasets:\n    datasets = [\n        name for name in tfds.list_builders() if name not in BUILDER_BLACKLIST\n    ]\n  print(\'Creating the vanilla builders for %s datasets...\' % len(datasets))\n  with futures.ThreadPoolExecutor(max_workers=WORKER_COUNT_DATASETS) as tpool:\n    builders = tpool.map(tfds.builder, datasets)\n  print(\'Vanilla builders built, constructing module_to_builder dict...\')\n\n  for builder in builders:\n    module_name = builder.__class__.__module__\n    modules = module_name.split(\'.\')\n    if \'testing\' in modules:\n      continue\n\n    current_mod_ctr = module_to_builder\n    for mod in modules:\n      current_mod_ctr = current_mod_ctr[mod]\n    current_mod_ctr.append(builder)  # pytype: disable=attribute-error\n\n  module_to_builder = module_to_builder[\'tensorflow_datasets\']\n  return module_to_builder\n\n\ndef dataset_docs_str(datasets=None):\n  """"""Create dataset documentation string for given datasets.\n\n  Args:\n    datasets: list of datasets for which to create documentation.\n              If None, then all available datasets will be used.\n\n  Returns:\n    - overview document\n    - a dictionary of sections. Each dataset in a section is represented by a\n    tuple (dataset_name, is_manual_dataset, string describing the datasets\n    (in the MarkDown format))\n  """"""\n\n  print(\'Retrieving the list of builders...\')\n  module_to_builder = make_module_to_builder_dict(datasets)\n  sections = sorted(list(module_to_builder.keys()))\n  section_docs = collections.defaultdict(list)\n\n  for section in sections:\n    builders = tf.nest.flatten(module_to_builder[section])\n    builders = sorted(builders, key=lambda b: b.name)\n    unused_ = get_mako_template(\'dataset\')  # To warm cache.\n    with futures.ThreadPoolExecutor(max_workers=WORKER_COUNT_DATASETS) as tpool:\n      builder_docs = tpool.map(document_single_builder, builders)\n    builder_docs = [(builder.name, builder.MANUAL_DOWNLOAD_INSTRUCTIONS,\n                     builder_doc)\n                    for (builder, builder_doc) in zip(builders, builder_docs)]\n    section_docs[section] = builder_docs\n  tmpl = get_mako_template(\'catalog_overview\')\n  catalog_overview = tmpl.render_unicode().lstrip()\n  return [catalog_overview, section_docs]\n'"
tensorflow_datasets/scripts/documentation/document_datasets_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test of `document_datasets.py`.""""""\n\n# import collections\nimport mock\n\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets.scripts.documentation import document_datasets\n\nDummyMnist = tfds.testing.DummyMnist\n\n\nclass DummyNewDs(DummyMnist):\n  pass\n\n\nclass DummyNewConfig(DummyMnist):\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'new_config\',\n          version=tfds.core.Version(\'1.0.0\'),\n          description=\'Config description.\',\n      ),\n      tfds.core.BuilderConfig(\n          name=\'old_config\',\n          version=tfds.core.Version(\'2.0.0\'),\n          supported_versions=[\n              tfds.core.Version(\'1.0.0\'),\n          ],\n          description=\'Config description.\',\n      ),\n  ]\n\n\nclass DummyMnistConfigs(DummyMnist):\n  """"""Builder with config and manual instructions.""""""\n  MANUAL_DOWNLOAD_INSTRUCTIONS = """"""Some manual instructions.""""""\n  BUILDER_CONFIGS = [\n      tfds.core.BuilderConfig(\n          name=\'config_name\',\n          version=tfds.core.Version(\'0.0.1\'),\n          description=\'Config description.\',\n      ),\n  ]\n\n\nclass DocumentDatasetsTest(tfds.testing.TestCase):\n\n  @classmethod\n  def setUpClass(cls):\n    super(DocumentDatasetsTest, cls).setUpClass()\n    cls._tfds_tmp_dir = tfds.testing.make_tmp_dir()\n    builder = DummyMnist(data_dir=cls._tfds_tmp_dir)\n    builder.download_and_prepare()\n\n    # Patch the visualization util (to avoid GCS access during test)\n    cls._old_path = document_datasets.VisualizationDocUtil.BASE_PATH\n    document_datasets.VisualizationDocUtil.BASE_PATH = cls._tfds_tmp_dir\n\n    # Patch the register\n    # `pytest` do not execute the tests in isolation.\n    # All tests seems to be imported before execution, which leak the\n    # registration. Datasets from `register_test.py` are registered when\n    # `document_dataset_test.py` is executed.\n    # As `_load_nightly_dict` load the full register, we patch it\n    # to avoid invalid dataset errors.\n    # Context: https://github.com/tensorflow/datasets/issues/1960\n    cls._patch_register = mock.patch.object(\n        tfds.core.registered, \'list_full_names\', return_value=[])\n    cls._patch_register.start()\n\n  @classmethod\n  def tearDownClass(cls):\n    super(DocumentDatasetsTest, cls).tearDownClass()\n    tfds.testing.rm_tmp_dir(cls._tfds_tmp_dir)\n    document_datasets.VisualizationDocUtil.BASE_PATH = cls._old_path\n\n    cls._patch_register.stop()\n\n  def setUp(self):\n    super(DocumentDatasetsTest, self).setUp()\n    self.builder = DummyMnist(data_dir=self._tfds_tmp_dir)\n\n  def test_document_datasets(self):\n    document_datasets.dataset_docs_str(datasets=[\'mnist\', \'cifar10\'])\n\n  def test_schema_org(self):\n    schema_str = document_datasets.document_single_builder(self.builder)\n    self.assertIn(\'http://schema.org/Dataset\', schema_str)\n    self.assertIn(\n        \'<meta itemprop=""url"" \'\n        \'content=""https://www.tensorflow.org\'\n        \'/datasets/catalog/%s"" />\' % self.builder.name, schema_str)\n\n  def test_with_config(self):\n    """"""Test that builder with configs are correctly generated.""""""\n    with tfds.testing.tmp_dir() as tmp_dir:\n      builder = DummyMnistConfigs(data_dir=tmp_dir)\n      builder.download_and_prepare()\n    doc_str = document_datasets.document_single_builder(builder)\n\n    self.assertIn(\'Some manual instructions.\', doc_str)\n    self.assertIn(\'Mnist description.\', doc_str)  # Shared description.\n    self.assertIn(\'Config description.\', doc_str)  # Config-specific description\n\n\nclass DocumentNightlyDatasetsTest(tfds.testing.TestCase):\n\n  def test_full_names_to_dict(self):\n    full_names_dict = document_datasets._full_names_to_dict([\n        \'ds1/c1/1.0.0\',\n        \'ds1/c1/2.0.0\',\n        \'ds1/c2/2.0.0\',\n        \'ds2/1.0.0\',\n        \'ds2/2.0.0\',\n    ])\n    self.assertEqual(full_names_dict, {\n        \'ds1\': {\n            \'c1\': {\'1.0.0\', \'2.0.0\'},\n            \'c2\': {\'2.0.0\'},\n        },\n        \'ds2\': {\n            \'\': {\'1.0.0\', \'2.0.0\'}\n        }\n    })\n\n  def test_build_nightly_dict(self):\n    nightly_dict = document_datasets._build_nightly_dict(\n        # Registered datasets\n        document_datasets._full_names_to_dict([\n            \'ds_same/config/1.0.0\',\n            \'ds_with_config/config_new/2.0.0\',  # Added config\n            \'ds_with_config/config_same/2.0.0\',  # Added version\n            \'ds_with_config/config_same/1.0.0\',\n            \'ds_new/1.0.0\',  # Added dataset\n            \'ds_changed/2.0.0\',  # Added version\n            \'ds_changed/1.0.0\',\n            \'ds_type/config/1.0.0\',  # `ds/version` -> `ds/config/version`\n        ]),\n        # Stable datasets\n        document_datasets._full_names_to_dict([\n            \'ds_same/config/1.0.0\',\n            \'ds_with_config/config_same/1.0.0\',\n            \'ds_with_config/config_same/0.0.0\',  # Removed version\n            \'ds_with_config/config_removed/1.0.0\',  # Removed config\n            \'ds_changed/1.0.0\',\n            \'ds_changed/0.0.0\',  # Removed version\n            \'ds_removed/1.0.0\',  # Removed dataset\',\n            \'ds_type/1.0.0\',  # `ds/version` -> `ds/config/version`\n        ]),\n    )\n    # Check that the added datasets, config, versions are marked as nightly\n    self.assertEqual(nightly_dict, {\n        \'ds_with_config\': {\n            \'config_new\': True,\n            \'config_same\': {\n                \'2.0.0\': True,\n                \'1.0.0\': False,\n            },\n        },\n        \'ds_new\': True,\n        \'ds_changed\': {\n            \'\': {\n                \'2.0.0\': True,\n                \'1.0.0\': False,\n            },\n        },\n        \'ds_same\': {\'config\': {\'1.0.0\': False}},\n        \'ds_type\': {\'config\': True},\n    })\n\n  def test_nightly_doc_util(self):\n    data_dir = \'/tmp/dummy_dir\'\n\n    nightly_dict = {\n        \'dummy_mnist\': {\'\': {\'1.0.0\': False}},\n        \'dummy_new_ds\': True,\n        \'dummy_new_config\': {\n            \'new_config\': True,\n            \'old_config\': {\n                \'2.0.0\': True,  # New versions\n                \'1.0.0\': False,\n            },\n        },\n    }\n    with mock.patch.object(\n        document_datasets, \'_load_nightly_dict\', return_value=nightly_dict):\n      ndu = document_datasets.NightlyDocUtil()\n\n    dummy_mnist = DummyMnist(data_dir=data_dir)\n    dummy_new_ds = DummyNewDs(data_dir=data_dir)\n    dummy_new_config = DummyNewConfig(data_dir=data_dir, config=\'new_config\')\n    dummy_new_version = DummyNewConfig(data_dir=data_dir, config=\'old_config\')\n\n    # Only `dummy_new_ds` is a new builder\n    self.assertFalse(ndu.is_builder_nightly(dummy_mnist))\n    self.assertTrue(ndu.is_builder_nightly(dummy_new_ds))\n    self.assertFalse(ndu.is_builder_nightly(dummy_new_config))\n    self.assertFalse(ndu.is_builder_nightly(dummy_new_version))\n\n    # Only `dummy_new_ds/new_config` is a new config\n    self.assertFalse(ndu.is_config_nightly(dummy_mnist))\n    self.assertFalse(ndu.is_config_nightly(dummy_new_ds))\n    self.assertTrue(ndu.is_config_nightly(dummy_new_config))\n    self.assertFalse(ndu.is_config_nightly(dummy_new_version))\n\n    # Only `dummy_new_ds/new_version/2.0.0` is a new version\n    self.assertFalse(ndu.is_version_nightly(dummy_mnist, \'1.0.0\'))\n    self.assertFalse(ndu.is_version_nightly(dummy_new_ds, \'x.x.x\'))\n    self.assertFalse(ndu.is_version_nightly(dummy_new_config, \'x.x.x\'))\n    self.assertFalse(ndu.is_version_nightly(dummy_new_version, \'1.0.0\'))\n    self.assertTrue(ndu.is_version_nightly(dummy_new_version, \'2.0.0\'))\n\n    # Only `dummy_mnist` don\'t have a nightly version\n    self.assertFalse(ndu.has_nightly(dummy_mnist))\n    self.assertTrue(ndu.has_nightly(dummy_new_ds))\n    self.assertTrue(ndu.has_nightly(dummy_new_config))\n    self.assertTrue(ndu.has_nightly(dummy_new_version))\n\n\nif __name__ == \'__main__\':\n  tfds.testing.test_main()\n'"
tensorflow_datasets/scripts/documentation/generate_visualization.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Script which generates datasets figures.\n""""""\n\nimport functools\nimport itertools\nimport multiprocessing\nimport os\nimport tempfile\nimport traceback\nfrom typing import List, Optional\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\n\nWORKER_COUNT_DATASETS = 10\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(\n    \'datasets\', None,\n    \'Comma separated list of datasets to generates. None for all datasets.\')\nflags.DEFINE_string(\n    \'dst_dir\', tfds.core.gcs_path(\'visualization\'),\n    \'Destination dir to save the images.\')\n\n\n# pylint: disable=logging-format-interpolation,logging-not-lazy\n\n\ndef _log_exception(fn):\n  """"""Logs the exceptions from a `ThreadPoolExecutor`.""""""\n\n  @functools.wraps(fn)\n  def decorated(*args, **kwargs):\n    try:\n      return fn(*args, **kwargs)\n    except Exception:  # pylint: disable=broad-except\n      err_str = traceback.format_exc()\n      logging.error(f\'Exception occured for {args}, {kwargs}:\\n\' + err_str)\n      raise\n\n  return decorated\n\n\n@_log_exception\ndef _generate_single_visualization(full_name: str, dst_dir: str) -> None:\n  """"""Save the generated figures for the dataset in dst_dir.\n\n  Args:\n    full_name: Name of the dataset to build `dataset`, `dataset/config`.\n    dst_dir: Destination where the dataset will be saved (as\n      `dataset-config-version`)\n  """"""\n  dst_filename = full_name.replace(\'/\', \'-\') + \'.png\'\n  dst_path = os.path.join(dst_dir, dst_filename)\n  # If the image already exists, skip the image generation\n  if tf.io.gfile.exists(dst_path):\n    logging.info(f\'Skiping visualization for {full_name} (already exists)\')\n    return\n\n  logging.info(f\'Generating visualization for {full_name}...\')\n  # Load the dataset.\n  builder_name, _, version = full_name.rpartition(\'/\')\n  builder = tfds.builder(f\'{builder_name}:{version}\')\n  split_names = list(builder.info.splits.keys())\n  if not split_names:\n    logging.info(f\'Dataset `{full_name}` not generated.\')\n    return\n  elif \'train\' in split_names:\n    split = \'train\'\n  else:\n    split = split_names[0]\n  ds = builder.as_dataset(split=split, shuffle_files=False)\n\n  if not tf.io.gfile.exists(dst_dir):\n    tf.io.gfile.makedirs(dst_dir)\n  try:\n    figure = tfds.show_examples(ds, builder.info)\n  except Exception:  # pylint: disable=broad-except\n    logging.info(f\'Visualisation not supported for dataset `{full_name}`\')\n    return\n\n  # `savefig` do not support GCS, so first save the image locally.\n  with tempfile.TemporaryDirectory() as tmp_dir:\n    tmp_path = os.path.join(tmp_dir, dst_filename)\n    figure.savefig(tmp_path)\n    tf.io.gfile.copy(tmp_path, dst_path)\n  plt.close(figure)\n\n\ndef _get_full_names(datasets: Optional[List[str]] = None) -> List[str]:\n  """"""List all builder names `ds/version` and `ds/config/version` to generate.\n\n  Args:\n    datasets: List of datasets from which get the builder names.\n\n  Returns:\n    builder_names: The builder names.\n  """"""\n  if datasets is None:\n    return tfds.core.registered.list_full_names(\n        current_version_only=True,\n    )\n  else:\n    builder_names = list(itertools.chain.from_iterable([\n        tfds.core.registered.single_full_names(builder_name)\n        for builder_name in datasets\n    ]))\n    return builder_names\n\n\ndef generate_visualization(\n    datasets: Optional[List[str]] = None,\n    *,\n    dst_dir: str,\n) -> None:\n  """"""Generate Visualization for datasets.\n\n  Args:\n    datasets: List of all `dataset` names to generate. If None, visualization\n      for all available datasets will be generated.\n    dst_dir: Directory where saving the images.\n  """"""\n  full_names = _get_full_names(datasets)\n  generate_fn = functools.partial(\n      _generate_single_visualization, dst_dir=dst_dir)\n  logging.info(f\'Generate figures for {len(full_names)} builders\')\n  with multiprocessing.Pool(WORKER_COUNT_DATASETS) as tpool:\n    tpool.map(generate_fn, full_names)\n\n\ndef main(_):\n  """"""Main script.""""""\n  datasets = FLAGS.datasets.split(\',\') if FLAGS.datasets else None\n  generate_visualization(datasets, dst_dir=FLAGS.dst_dir)\n\n\nif __name__ == \'__main__\':\n  flags.mark_flags_as_required([\'dst_dir\'])\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/abstract_reasoning.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate AbstractReasoning-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tarfile\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nENCODING_MAP = {\n    ""shape"": 0,\n    ""line"": 1,\n    ""color"": 2,\n    ""number"": 3,\n    ""position"": 4,\n    ""size"": 5,\n    ""type"": 6,\n    ""progression"": 7,\n    ""XOR"": 8,\n    ""OR"": 9,\n    ""AND"": 10,\n    ""consistent_union"": 11,\n}\n\nRELATIONS = [""progression"", ""XOR"", ""OR"", ""AND"", ""consistent_union""]\nATTRIBUTES = [""color"", ""number"", ""position"", ""size"", ""type""]\nOBJECTS = [""shape"", ""line""]\n\nSPLIT_TYPES = [\n    ""neutral"",\n    ""interpolation"",\n    ""extrapolation"",\n    ""attr.rel.pairs"",\n    ""attr.rels"",\n    ""attrs.pairs"",\n    ""attrs.shape.color"",\n    ""attrs.line.type"",\n]\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef _random_content(random_state):\n  """"""Returns a dictionary with a data sample with random content.""""""\n  # Randomly sample the number of relations.\n  num_relations = random_state.randint(1, 5)\n  # Randomly sample the relations.\n  relation_structure = []\n  for _ in range(num_relations):\n    relation_structure.append(\n        (random_state.choice(OBJECTS), random_state.choice(ATTRIBUTES),\n         random_state.choice(RELATIONS)))\n  # Encode the relations.\n  relation_structure_encoded = np.zeros((4, 12), dtype=np.int64)\n  for i, relation in enumerate(relation_structure):\n    for name in relation:\n      relation_structure_encoded[i, ENCODING_MAP[name]] = 1\n\n  # Create the meta target which is the max across the relations.\n  meta_target = np.max(relation_structure_encoded, axis=0)\n\n  # Create the final object.\n  return {\n      ""relation_structure_encoded"": relation_structure_encoded,\n      ""relation_structure"": np.array(relation_structure),\n      ""target"": random_state.randint(8, dtype=np.int64),\n      ""image"": random_state.randint(8, size=(160, 160, 16), dtype=np.int64),\n      ""meta_target"": meta_target,\n  }\n\n\ndef _create_fake_file(folder, split_type, random_state):\n  """"""Creates a fake data file.""""""\n  path = os.path.join(folder, ""{}.tar.gz"".format(split_type))\n  with tf.io.gfile.GFile(path, ""w"") as fout:\n    with tarfile.open(fileobj=fout, mode=""w:gz"") as tar:\n      for i in range(5):\n        for split in [""train"", ""test"", ""val""]:\n          # Write serialized numpy to buffer.\n          content = _random_content(random_state)\n          buf = six.BytesIO()\n          np.savez(buf, **content)\n          buf.seek(0)\n          # Create tarinfo for the file.\n          filename = ""{split_type}/PGM_{split_type}_{split}_{id}.npz"".format(\n              split_type=split_type, split=split, id=i)\n          tarinfo = tarfile.TarInfo(filename)\n          tarinfo.size = len(buf.getvalue())\n          # Add the file to the archive.\n          tar.addfile(tarinfo=tarinfo, fileobj=buf)\n\n\ndef _generate():\n  """"""Generates a fake data set and writes it to the fake_examples directory.""""""\n  output_dir = os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"",\n                            ""fake_examples"", ""abstract_reasoning"")\n  test_utils.remake_dir(output_dir)\n  random_state = np.random.RandomState(0)\n  for split_type in SPLIT_TYPES:\n    _create_fake_file(output_dir, split_type, random_state)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/arc.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate ARC-like files, smaller and with random data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nflags.DEFINE_string(\n    name=""tfds_dir"",\n    default=py_utils.tfds_dir(),\n    help=""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n_COMMIT = ""0123456789abcdef0123456789abcdef01234567""  # fake commit\n_EXTRACT_SUBDIR = ""fchollet-ARC-{}"".format(_COMMIT[:7])\nNUM_TASKS = {""training"": 10, ""evaluation"": 5}\n\n\ndef examples_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""arc"", _EXTRACT_SUBDIR, ""data"")\n\n\ndef arc_dir(name):\n  return os.path.join(examples_dir(), name)\n\n\ndef make_grid_data():\n  size = np.random.randint(30, size=2) + 1\n  grid = np.random.randint(10, size=size[0] * size[1]).reshape(size)\n  return grid.tolist()\n\n\ndef make_pair():\n  return {\n      ""input"": make_grid_data(),\n      ""output"": make_grid_data(),\n  }\n\n\ndef make_task():\n  num_train_pairs = np.random.randint(3) + 2  # 2 to 4\n  num_test_pairs = np.random.randint(2) + 1  # 1 or 2\n  return {\n      ""train"": [make_pair() for _ in range(num_train_pairs)],\n      ""test"": [make_pair() for _ in range(num_test_pairs)],\n  }\n\n\ndef write_task(output_dir, task_id, task):\n  path = os.path.join(output_dir, ""{}.json"".format(task_id))\n  with tf.io.gfile.GFile(path, ""w"") as f:\n    json.dump(task, f)\n\n\ndef main(_):\n  task_index = np.random.randint(2**31)\n  for subset in [""training"", ""evaluation""]:\n    output_dir = arc_dir(subset)\n    test_utils.remake_dir(output_dir)\n    num_tasks = NUM_TASKS[subset]\n    for _ in range(num_tasks):\n      task_index += 1\n      task_id = ""{:08x}"".format(task_index)\n      task = make_task()\n      write_task(output_dir, task_id, task)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/bair_robot_pushing.py,11,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tool for preparing test example of BAIR dataset.\n\nmkdir test/\nmkdir train/\n\n./bair_robot_pushing  --output_file=train/traj_1792_to_2047.tfrecords\n./bair_robot_pushing  --output_file=test/traj_0_to_255.tfrecords\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(""output_file"", None, ""Path to the output file."")\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise tf.app.UsageError(""Too many command-line arguments."")\n\n  writer = tf.io.TFRecordWriter(FLAGS.output_file)\n\n  feature = {}\n\n  for frame in range(30):\n    feature[""%d/action"" % frame] = tf.train.Feature(\n        float_list=tf.train.FloatList(value=np.random.uniform(size=(4))))\n    feature[""%d/endeffector_pos"" % frame] = tf.train.Feature(\n        float_list=tf.train.FloatList(value=np.random.uniform(size=(3))))\n    feature[""%d/image_aux1/encoded"" % frame] = tf.train.Feature(\n        bytes_list=tf.train.BytesList(value=[""\\x00\\xff\\x00"" * 64 * 64]))\n    feature[""%d/image_main/encoded"" % frame] = tf.train.Feature(\n        bytes_list=tf.train.BytesList(value=[""\\x00\\x00\\xff"" * 64 * 64]))\n  example = tf.train.Example(features=tf.train.Features(feature=feature))\n  writer.write(example.SerializeToString())\n  writer.close()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/beans.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate fake data for beans dataset.\n\n""""""\n\n# from __future__ import absolute_import\n# from __future__ import division\n# from __future__ import print_function\n\nimport os\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'beans\')\n\n\ndef _get_jpeg(height, width):\n  """"""Returns jpeg picture.""""""\n  image = fake_data_utils.get_random_picture(height, width)\n  jpeg = tf.image.encode_jpeg(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(jpeg)\n  return res\n\n\ndef create_zip(fname):\n  out_path = os.path.join(_output_dir(), fname)\n  jpeg = _get_jpeg(height=5, width=5)\n  with zipfile.ZipFile(out_path, \'w\') as myzip:\n    myzip.writestr(\'angular_leaf_spot/0.jpg\', jpeg)\n    myzip.writestr(\'bean_rust/0.jpg\', jpeg)\n    myzip.writestr(\'healthy/0.jpg\', jpeg)\n\n\ndef main(argv):\n  del argv\n  create_zip(\'beans_train.zip\')\n  create_zip(\'beans_validation.zip\')\n  create_zip(\'beans_test.zip\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/binarized_mnist.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate Binarized MNIST-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef examples_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"")\n\n\ndef mnist_dir(name):\n  return os.path.join(examples_dir(), name)\n\n\n_TRAIN_DATA_FILENAME = ""binarized_mnist_train.amat""\n_VALID_DATA_FILENAME = ""binarized_mnist_valid.amat""\n_TEST_DATA_FILENAME = ""binarized_mnist_test.amat""\n\n\ndef make_images(num_images):\n  return (np.random.randint(256, size=(28 * 28 * num_images), dtype=np.uint8)\n          .reshape((num_images, -1)))\n\n\ndef write_image_file(filename, num_images):\n  with tf.io.gfile.GFile(filename, ""wb"") as f:\n    np.savetxt(f, make_images(num_images), delimiter="" "")\n\n\ndef main(_):\n  output_dir = mnist_dir(""binarized_mnist"")\n  test_utils.remake_dir(output_dir)\n  write_image_file(os.path.join(output_dir, _TRAIN_DATA_FILENAME), 10)\n  write_image_file(os.path.join(output_dir, _VALID_DATA_FILENAME), 2)\n  write_image_file(os.path.join(output_dir, _TEST_DATA_FILENAME), 2)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/caltech.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Script to generate Caltech101 like files with random data for testing.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.image_classification import caltech\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n\nFLAGS = flags.FLAGS\n\nNUM_CLASSES = 3\nIMAGES_PER_CLASS = 2\nMIN_EDGE_LENGTH = 150\nMAX_EDGE_LENGTH = 350\n\n\ndef _output_dir():\n  """"""Returns output directory.""""""\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""caltech101"", ""{}_ObjectCategories"".format(NUM_CLASSES))\n\n\ndef _save_image(jpeg, label, image_idx):\n  """"""Saves jpeg.""""""\n  dirname = os.path.join(_output_dir(), label)\n  if not os.path.exists(dirname):\n    os.makedirs(dirname)\n  path = os.path.join(dirname, ""image_{:04d}.jpg"".format(image_idx))\n  with open(path, ""wb"") as out_file:\n    out_file.write(jpeg)\n\n\ndef _get_jpeg(height, width):\n  """"""Returns jpeg picture.""""""\n  image = fake_data_utils.get_random_picture(height, width)\n  jpeg = tf.image.encode_jpeg(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(jpeg)\n  return res\n\n\ndef _generate_images():\n  """"""Generates training images.""""""\n  names_file = tfds.core.get_tfds_path(caltech._LABELS_FNAME)  # pylint: disable=protected-access\n  label_names = tfds.features.ClassLabel(\n      names_file=names_file).names[:NUM_CLASSES]\n  for label in label_names:\n    for i in range(IMAGES_PER_CLASS):\n      height = np.random.randint(low=MIN_EDGE_LENGTH, high=MAX_EDGE_LENGTH)\n      width = np.random.randint(low=MIN_EDGE_LENGTH, high=MAX_EDGE_LENGTH)\n      jpeg = _get_jpeg(height=height, width=width)\n      _save_image(jpeg, label, i + 1)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_images()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/cassava.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate fake data for cassava dataset.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'cassava\')\n\n\ndef _save_images(jpg, imgpaths):\n  """"""Save images with a proper hierarchy.""""""\n  for imgpath in imgpaths:\n    dirpath = os.path.dirname(imgpath)\n    if not os.path.exists(dirpath):\n      os.makedirs(dirpath)\n    with tf.io.gfile.GFile(imgpath, \'wb\') as fimg:\n      fimg.write(jpg)\n\n\ndef _get_jpeg(height, width):\n  """"""Returns jpeg picture.""""""\n  image = fake_data_utils.get_random_picture(height, width)\n  jpeg = tf.image.encode_jpeg(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(jpeg)\n  return res\n\n\ndef main(argv):\n  del argv\n  out_path = os.path.join(_output_dir(), \'cassavaleafdata\')\n  jpg = _get_jpeg(height=6, width=6)\n\n  for idx, label in enumerate([\'cbb\', \'cgm\', \'cbsd\', \'cmd\', \'healthy\']):\n    example_imgs = []\n    for category in [\'train\', \'test\', \'validation\']:\n      example = \'{cat}/{label}/{cat}-{label}-{id}.jpg\'.format(\n          label=label, id=idx, cat=category)\n      example_imgs.append(os.path.join(out_path, example))\n    _save_images(jpg, example_imgs)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/cats_vs_dogs.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate fake data for cats_vs_dogs dataset.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'cats_vs_dogs\')\n\n\ndef main(argv):\n  del argv\n  out_path = os.path.join(_output_dir(), \'cats_vs_dogs.zip\')\n  jpg = fake_data_utils.get_random_jpeg(height=1, width=1)\n  with zipfile.ZipFile(out_path, \'w\') as myzip:\n    myzip.write(jpg, \'PetImages/Dog/0.jpg\')\n    myzip.write(jpg, \'PetImages/Dog/1.jpg\')\n    myzip.write(jpg, \'PetImages/Cat/0.jpg\')\n    myzip.write(jpg, \'PetImages/Cat/1.jpg\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/cifar.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate cifar10/cifar100 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\n\nimport tensorflow_datasets as tfds\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nNUMBER_IMAGES_PER_BATCH = 2\nHEIGHT, WIDTH = (32, 32)\nNUMBER_BATCHES = 5\nNUMBER_LABELS = 10\nNUMBER_FINE_LABELS = 100\nNUMBER_COARSE_LABELS = 20\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef cifar10_output_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""cifar10"", ""cifar-10-batches-bin"")\n\n\ndef cifar100_output_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""cifar100"", ""cifar-100-binary"")\n\n\ndef dump(output_dir, fname, images, labels):\n  path = os.path.join(output_dir, fname)\n  print(""Writing %s..."" % path)\n  with open(path, ""wb"") as out_file:\n    for image, labels in zip(images, labels):\n      out_file.write(labels.tobytes())\n      out_file.write(image.tobytes())\n\n\ndef generate_cifar100_batch(fname, num_examples):\n  images = np.random.randint(\n      256, size=(num_examples, HEIGHT * WIDTH * 3), dtype=np.uint8)\n  fine_labels = np.random.randint(\n      NUMBER_FINE_LABELS, size=(num_examples), dtype=np.uint8)\n  coarse_labels = np.random.randint(\n      NUMBER_COARSE_LABELS, size=(num_examples), dtype=np.uint8)\n  labels = np.vstack((coarse_labels, fine_labels)).T\n  dump(cifar100_output_dir(), fname, images, labels)\n\n\ndef generate_cifar10_batch(batch_name):\n  images = np.random.randint(\n      256, size=(NUMBER_IMAGES_PER_BATCH, HEIGHT * WIDTH * 3), dtype=np.uint8)\n  labels = np.random.randint(\n      NUMBER_LABELS, size=(NUMBER_IMAGES_PER_BATCH), dtype=np.uint8)\n  dump(cifar10_output_dir(), batch_name, images, labels)\n\n\ndef _generate_cifar100_data():\n  """"""Generates .bin and label .txt files for cifar100.""""""\n  output_dir = cifar100_output_dir()\n  test_utils.remake_dir(output_dir)\n  generate_cifar100_batch(""train.bin"", 10)\n  generate_cifar100_batch(""test.bin"", 2)\n  fine_names = tfds.builder(""cifar100"").info.features[""label""].names\n  coarse_names = tfds.builder(""cifar100"").info.features[""coarse_label""].names\n  with open(os.path.join(output_dir, ""fine_label_names.txt""), ""w"") as f:\n    f.write(""\\n"".join(fine_names))\n  with open(os.path.join(output_dir, ""coarse_label_names.txt""), ""w"") as f:\n    f.write(""\\n"".join(coarse_names))\n\n\ndef _generate_cifar10_data():\n  output_dir = cifar10_output_dir()\n  test_utils.remake_dir(output_dir)\n  for batch_number in range(1, NUMBER_BATCHES + 1):\n    generate_cifar10_batch(""data_batch_%s.bin"" % batch_number)\n  generate_cifar10_batch(""test_batch.bin"")\n  label_names = tfds.builder(""cifar10"").info.features[""label""].names\n  print(label_names)\n  with open(os.path.join(output_dir, ""batches.meta.txt""), ""w"") as f:\n    f.write(""\\n"".join(label_names))\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_cifar10_data()\n  _generate_cifar100_data()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/cityscapes.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Helper functions to generate fake Cityscapes-like data for testing.""""""\n\nimport os\nimport random\nimport re\nimport zipfile\nfrom tensorflow_datasets.testing.fake_data_utils import get_random_png\n\nCITY_IN_ID_RE = re.compile(r\'(.+)_[0-9]+_[0-9]+\')\n\n\ndef generate_ids(city, num=2):\n  """"""Generates image ids following the format of the cityscapes dataset.\n\n  Args:\n    city (str): The city/scene the ids belong to, used as a prefix to the id.\n    num (int): Number of random ids to generate.\n\n  Yields:\n    Generator for id strings.\n  """"""\n  for _ in range(num):\n    yield \'{}_{:06d}_{:06d}\'.format(city, random.randint(0, 999999),\n                                    random.randint(0, 999999))\n\n\ndef create_zipfile(zip_filepath, splits_with_ids, suffixes, maindir=None):\n  """"""Generates a zipfile with a cityscapes-like file structure and random pngs.\n\n  Args:\n    zip_filepath (str): filepath to the zip archive that will be created\n    splits_with_ids (Dict[str, List[str]]): data-splits like \'train\' or \'val\'\n      that map to a list of image ids\n    suffixes (List[str]): suffix per modality that should be created e.g.\n      \'leftImg8bit\'\n    maindir (str): name of the root directory of the zipfile, defaults to the\n      name of the zipfile\n  """"""\n  with zipfile.ZipFile(zip_filepath, \'w\') as z:\n    for split, ids in splits_with_ids.items():\n      if maindir is None:\n        maindir = os.path.basename(zip_filepath).strip(\'.zip\')\n      split = os.path.join(maindir, split)\n      for img_id in ids:\n        city = CITY_IN_ID_RE.match(img_id).group(1)\n        for suffix in suffixes:\n          if \'Img\' in suffix:\n            img = get_random_png(height=1024, width=2048, channels=3)\n          else:\n            img = get_random_png(height=1024, width=2048, channels=1)\n          z.write(img, os.path.join(split, city,\n                                    \'{}_{}.png\'.format(img_id, suffix)))\n'"
tensorflow_datasets/testing/fake_data_generation/clevr.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate ilsvrc2012 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\n_IMAGE_NUMBERS = {\'train\': 5, \'val\': 5, \'test\': 5}\n_NUM_OBJECTS = 7\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\',\n                      \'fake_examples\', \'clevr\', \'CLEVR_v1.0\')\n\n\ndef _generate_data(split):\n  """"""Generate images archive.""""""\n\n  # Generate images\n  images_dir = os.path.join(_output_dir(), \'images\', split)\n  if not tf.io.gfile.exists(images_dir):\n    tf.io.gfile.makedirs(images_dir)\n  for i in range(_IMAGE_NUMBERS[split]):\n    image_name = \'CLEVR_{}_{:06d}.png\'.format(split, i)\n    tf.io.gfile.copy(fake_data_utils.get_random_png(),\n                     os.path.join(images_dir, image_name),\n                     overwrite=True)\n\n  if split in [\'train\', \'val\']:\n    # Generate annotations\n    scenes_dir = os.path.join(_output_dir(), \'scenes\')\n    if not tf.io.gfile.exists(scenes_dir):\n      tf.io.gfile.makedirs(scenes_dir)\n\n    annotations = {\'scenes\': [{\'objects\':\n                                   [{\'color\': \'red\',\n                                     \'shape\': \'sphere\',\n                                     \'size\': \'small\',\n                                     \'material\': \'rubber\',\n                                     \'3d_coords\': [0.0, 0.0, 0.0],\n                                     \'pixel_coords\': [0.0, 0.0, 0.0],\n                                     \'rotation\': 0.0}] * _NUM_OBJECTS\n                              }] * _IMAGE_NUMBERS[split]\n                  }\n\n    annotations_file = os.path.join(scenes_dir,\n                                    \'CLEVR_{}_scenes.json\'.format(split))\n    with tf.io.gfile.GFile(annotations_file, \'w\') as f:\n      json.dump(annotations, f)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(\'Too many command-line arguments.\')\n  for split in [\'train\', \'val\', \'test\']:\n    _generate_data(split)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/coil100.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Fake Data Generator for Coil-100 Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'coil100\')\n\n\ndef create_images(label):\n  images_dir = _output_dir()\n  if not tf.io.gfile.exists(images_dir):\n    tf.io.gfile.makedirs(images_dir)\n  for l in label:\n    image_name = \'obj1_{}.png\'.format(l)\n    tf.io.gfile.copy(\n        fake_data_utils.get_random_png(128, 128),\n        os.path.join(images_dir, image_name),\n        overwrite=True)\n\n\ndef main(argv):\n  del argv\n  label = [x for x in range(0, 25, 5)]\n  create_images(label)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/colorectal_histology.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate ColorectalHistology-like files with random data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import lazy_imports_lib\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.image_classification import colorectal_histology\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n# --compression=raw may be more portable, but results in massive files (>100mb)\nflags.DEFINE_string(\n    ""compression"", ""tiff_lzw"", ""Used by PIL to compress fake images"")\nFLAGS = flags.FLAGS\n\n# pylint: disable=protected-access\n\nnum_classes = len(colorectal_histology._CLASS_NAMES)\nclass_index = {c: i for i, c in enumerate(colorectal_histology._CLASS_NAMES)}\n\n\ndef examples_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"")\n\n\ndef histology_dir(large=False):\n  folder = os.path.join(examples_dir(), ""colorectal_histology"")\n  if large:\n    folder = ""%s_large"" % folder\n  return folder\n\n\ndef make_images(num_images, size):\n  # random values compress badly\n  return np.zeros((num_images, size, size, 3), dtype=np.uint8)\n\n\ndef write_image(filename, data):\n  lazy_imports_lib.lazy_imports.PIL_Image.fromarray(data).save(\n      filename, compression=FLAGS.compression)\n\n\ndef main(_):\n  base_dir = os.path.join(\n      histology_dir(False), colorectal_histology._TILES_SUBDIR)\n  for ci, class_name in enumerate(colorectal_histology._CLASS_NAMES):\n    subdir = os.path.join(\n        base_dir, colorectal_histology._class_subdir(ci, class_name))\n    tf.io.gfile.makedirs(subdir)\n\n    for i, image_data in enumerate(\n        make_images(2, colorectal_histology._TILES_SIZE)):\n      fn = ""image%d.tif"" % i\n      write_image(os.path.join(subdir, fn), image_data)\n\n  base_dir = os.path.join(\n      histology_dir(True), colorectal_histology._LARGE_SUBDIR)\n  tf.io.gfile.makedirs(base_dir)\n  write_image(\n      os.path.join(base_dir, ""large_image.tif""),\n      make_images(1, colorectal_histology._LARGE_SIZE)[0])\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/curated_breast_imaging_ddsm.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate CBIS-DDSM like files, smaller and with fake data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nimport tensorflow_datasets.public_api as tfds\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\nMAMMOGRAPHY_HEIGHT = 100    # Note: Much smaller than original images.\nMAMMOGRAPHY_WIDTH = 80\nABNORMALITY_SIZE_MIN = 10\nABNORMALITY_SIZE_MAX = 20\nNUM_ABNORMALITIES_MAX = 5\nBREAST_INTENSITY_MIN = 20\nBREAST_INTENSITY_MAX = 200\n\n\ndef remake_dirs(path):\n  if not tf.io.gfile.exists(path):\n    tf.io.gfile.makedirs(path)\n\n\ndef write_png(filepath, img):\n  cv2 = tfds.core.lazy_imports.cv2\n  with tf.io.gfile.GFile(filepath, \'wb\') as f:\n    _, buf = cv2.imencode(\'.png\', img, (cv2.IMWRITE_PNG_COMPRESSION, 9))\n    f.write(buf.tobytes())\n\n\ndef _yield_mammography_with_abnormalities():\n  """"""Generate a fake mammography image containing a set of abnormalities.""""""\n  mammography = np.zeros((MAMMOGRAPHY_HEIGHT, MAMMOGRAPHY_WIDTH),\n                         dtype=np.uint8)\n  # Draw a rectangle representing the breast region.\n  breast_h = np.random.randint(\n      int(MAMMOGRAPHY_HEIGHT * 0.7), int(MAMMOGRAPHY_HEIGHT * 0.9) + 1)\n  breast_w = np.random.randint(\n      int(MAMMOGRAPHY_WIDTH * 0.7), int(MAMMOGRAPHY_WIDTH * 0.9) + 1)\n  breast_y = np.random.randint(0, MAMMOGRAPHY_HEIGHT - breast_h)\n  breast_x = np.random.randint(0, MAMMOGRAPHY_WIDTH - breast_w)\n  breast_intensity = np.random.randint(BREAST_INTENSITY_MIN,\n                                       BREAST_INTENSITY_MAX + 1)\n  mammography[\n      breast_y:(breast_y + breast_h),\n      breast_x:(breast_x + breast_w)] = breast_intensity\n\n  abnormalities = []  # Note: pairs of (mask, crop).\n  for _ in range(np.random.randint(1, NUM_ABNORMALITIES_MAX + 1)):\n    abnorm_h = np.random.randint(ABNORMALITY_SIZE_MIN, ABNORMALITY_SIZE_MAX + 1)\n    abnorm_w = np.random.randint(ABNORMALITY_SIZE_MIN, ABNORMALITY_SIZE_MAX + 1)\n    abnorm_y = np.random.randint(0, breast_h - abnorm_h) + breast_y\n    abnorm_x = np.random.randint(0, breast_w - abnorm_w) + breast_x\n    abnorm_intensity = np.random.randint(int(BREAST_INTENSITY_MIN * 1.2), 256)\n    while np.absolute(abnorm_intensity - breast_intensity) < 10:\n      abnorm_intensity = np.random.randint(int(BREAST_INTENSITY_MIN * 1.2), 256)\n    # Draw abnormality in the mammography.\n    mammography[\n        abnorm_y:(abnorm_y + abnorm_h),\n        abnorm_x:(abnorm_x + abnorm_w)] = abnorm_intensity\n    # Abnormality mask w.r.t the full mammography.\n    abnorm_mask = np.zeros_like(mammography)\n    abnorm_mask[\n        abnorm_y:(abnorm_y + abnorm_h), abnorm_x:(abnorm_x + abnorm_w)] = 255\n    # Abnormality crop.\n    abnorm_crop = np.ones((abnorm_h, abnorm_w)) * abnorm_intensity\n    abnormalities.append((abnorm_mask, abnorm_crop))\n\n  return mammography, abnormalities\n\n\ndef _yield_csv_rows_base(output_dir, row_extra_info_gen_fn):\n  """"""Yield rows for the CSV ground-truth files, also creates fake images.""""""\n  mammography, abnormalities = _yield_mammography_with_abnormalities()\n  patient_id = \'P_%05d\' % np.random.randint(0, 1000)\n  breast_density = np.random.randint(1, 5)\n  left_or_right_breast = np.random.choice([\'LEFT\', \'RIGHT\'])\n  image_view = np.random.choice([\'CC\', \'MLO\'])\n  study_id = tuple(np.random.randint(0, 999999999+1, size=2))\n  study_id = \'1.3.6.1.4.1.9590.100.1.2.%010d.%010d\' % study_id\n  series_id = tuple(np.random.randint(0, 999999999+1, size=2))\n  series_id = \'1.3.6.1.4.1.9590.100.1.2.%010d.%010d\' % series_id\n  remake_dirs(os.path.join(output_dir, \'%s/%s\' % (study_id, series_id)))\n  # Write mammography image.\n  mammography_basename = \'%s/%s/000000\' % (study_id, series_id)\n  write_png(\n      os.path.join(output_dir, mammography_basename + \'.png\'), mammography)\n\n  for abnormality_id, abnormality in enumerate(abnormalities, 1):\n    # Write abnormality crop image.\n    crop_basename = \'%s/%s/%06d\' % (study_id, series_id, abnormality_id * 2 - 1)\n    write_png(\n        os.path.join(output_dir, crop_basename + \'.png\'), abnormality[1])\n    # Write abnormality mask image.\n    mask_basename = \'%s/%s/%06d\' % (study_id, series_id, abnormality_id * 2)\n    write_png(\n        os.path.join(output_dir, mask_basename + \'.png\'), abnormality[0])\n    row = {\n        \'patient_id\': patient_id,\n        \'breast density\': breast_density,\n        \'left or right breast\': left_or_right_breast,\n        \'image view\': image_view,\n        \'abnormality id\': abnormality_id,\n        \'abnormality type\': \'calcification\',\n        \'assessment\': np.random.randint(1, 5),\n        \'pathology\': np.random.choice(\n            [\'BENIGN\', \'BENIGN_WITHOUT_CALLBACK\', \'MALIGNANT\']),\n        \'subtlety\': np.random.randint(1, 5),\n        \'image file path\': mammography_basename + \'.dcm\',\n        \'cropped image file path\': crop_basename + \'.dcm\',\n        \'ROI mask file path\': mask_basename + \'.dcm\',\n    }\n    row.update(row_extra_info_gen_fn())\n    yield row\n\n\ndef _yield_csv_rows_calc(output_dir, calc_types, calc_distributions):\n  """"""Generate a row for the calcification abnormalities.""""""\n  def _row_extra_info_gen_fn():\n    return {\n        \'calc type\': np.random.choice(calc_types),\n        \'calc distribution\': np.random.choice(calc_distributions),\n    }\n\n  return _yield_csv_rows_base(output_dir, _row_extra_info_gen_fn)\n\n\ndef _yield_csv_rows_mass(output_dir, mass_shapes, mass_margins):\n  """"""Generate a row for the mass abnormalities.""""""\n  def _row_extra_info_gen_fn():\n    return {\n        \'mass shape\': np.random.choice(mass_shapes),\n        \'mass margins\': np.random.choice(mass_margins),\n    }\n\n  return _yield_csv_rows_base(output_dir, _row_extra_info_gen_fn)\n\n\ndef _generate_csv(csv_filepath, row_yielder, number_of_mammograms):\n  """"""Generate a csv file with `number_of_examples` mammograms.""""""\n  with tf.io.gfile.GFile(os.path.join(csv_filepath), \'w\') as f:\n    writer = None\n    for _ in range(number_of_mammograms):\n      for row in row_yielder():\n        if writer is None:\n          writer = csv.DictWriter(f, row.keys())\n          writer.writeheader()\n        writer.writerow(row)\n\n\ndef _generate_data_calc(output_dir, number_of_mammograms):\n  """"""Generate train/test CSV and images of calcification abnormalities.""""""\n  calc_types = tfds.features.ClassLabel(\n      names_file=tfds.core.get_tfds_path(\n          os.path.join(\'image\', \'cbis_ddsm_calc_types.txt\'))).names\n  calc_distributions = tfds.features.ClassLabel(\n      names_file=tfds.core.get_tfds_path(\n          os.path.join(\'image\', \'cbis_ddsm_calc_distributions.txt\'))).names\n  _generate_csv(\n      os.path.join(output_dir, \'calc_case_description_train_set.csv\'),\n      lambda: _yield_csv_rows_calc(output_dir, calc_types, calc_distributions),\n      number_of_mammograms[0])\n  _generate_csv(\n      os.path.join(output_dir, \'calc_case_description_test_set.csv\'),\n      lambda: _yield_csv_rows_calc(output_dir, calc_types, calc_distributions),\n      number_of_mammograms[1])\n\n\ndef _generate_data_mass(output_dir, number_of_mammograms):\n  """"""Generate train/test CSV and images of mass abnormalities.""""""\n  mass_shapes = tfds.features.ClassLabel(\n      names_file=tfds.core.get_tfds_path(\n          os.path.join(\'image\', \'cbis_ddsm_mass_shapes.txt\'))).names\n  mass_margins = tfds.features.ClassLabel(\n      names_file=tfds.core.get_tfds_path(\n          os.path.join(\'image\', \'cbis_ddsm_mass_margins.txt\'))).names\n\n  _generate_csv(\n      os.path.join(output_dir, \'mass_case_description_train_set.csv\'),\n      lambda: _yield_csv_rows_mass(output_dir, mass_shapes, mass_margins),\n      number_of_mammograms[0])\n  _generate_csv(\n      os.path.join(output_dir, \'mass_case_description_test_set.csv\'),\n      lambda: _yield_csv_rows_mass(output_dir, mass_shapes, mass_margins),\n      number_of_mammograms[1])\n\n\ndef main(_):\n  output_dir = os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\',\n                            \'fake_examples\', \'curated_breast_imaging_ddsm\')\n  np.random.seed(0x12345)\n  _generate_data_calc(output_dir, (3, 2))\n  _generate_data_mass(output_dir, (3, 2))\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/div2k.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Generates DIV2K like files with random data for testing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n\nFLAGS = flags.FLAGS\n\nDATA = {\n    ""DIV2K_train_HR"": ""0001.png"",\n    ""DIV2K_train_LR_bicubic_X2"": ""0001x2.png"",\n    ""DIV2K_train_LR_bicubic_X3"": ""0001x3.png"",\n    ""DIV2K_train_LR_bicubic_X4"": ""0001x4.png"",\n    ""DIV2K_train_LR_difficult"": ""0001x4d.png"",\n    ""DIV2K_train_LR_mild"": ""0001x4m.png"",\n    ""DIV2K_train_LR_unknown_X2"": ""0001x2.png"",\n    ""DIV2K_train_LR_unknown_X3"": ""0001x3.png"",\n    ""DIV2K_train_LR_unknown_X4"": ""0001x4.png"",\n    ""DIV2K_train_LR_wild"": ""0001x4w.png"",\n    ""DIV2K_train_LR_x8"": ""0001x8.png"",\n    ""DIV2K_valid_HR"": ""0002.png"",\n    ""DIV2K_valid_LR_bicubic_X2"": ""0002x2.png"",\n    ""DIV2K_valid_LR_bicubic_X3"": ""0002x3.png"",\n    ""DIV2K_valid_LR_bicubic_X4"": ""0002x4.png"",\n    ""DIV2K_valid_LR_difficult"": ""0002x4d.png"",\n    ""DIV2K_valid_LR_mild"": ""0002x4m.png"",\n    ""DIV2K_valid_LR_unknown_X2"": ""0002x2.png"",\n    ""DIV2K_valid_LR_unknown_X3"": ""0002x3.png"",\n    ""DIV2K_valid_LR_unknown_X4"": ""0002x4.png"",\n    ""DIV2K_valid_LR_wild"": ""0002x4w.png"",\n    ""DIV2K_valid_LR_x8"": ""0002x8.png"",\n}\n\n\ndef _output_dir():\n  """"""Returns output directory.""""""\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""div2k"")\n\n\ndef _generate_image(fdir, fname):\n  dirname = os.path.join(_output_dir(), fdir)\n  if not os.path.exists(dirname):\n    os.makedirs(dirname)\n  tf.io.gfile.copy(\n      fake_data_utils.get_random_png(1, 1),\n      os.path.join(dirname, fname),\n      overwrite=True)\n\n\ndef main(argv):\n  del argv\n  for fdir, fname in DATA.items():\n    _generate_image(fdir, fname)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/dsprites.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate dsprites like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport h5py\nimport numpy as np\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nNUM_IMAGES = 5\nFACTOR_COUNTS = [1, 3, 6, 40, 32, 32]\nFACTOR_VALUES = [\n    [1.], [1., 2., 3.], [0.5, 0.6, 0.7, 0.8, 0.9, 1.],\n    [\n        0., 0.16110732, 0.32221463, 0.48332195, 0.64442926, 0.80553658,\n        0.96664389, 1.12775121, 1.28885852, 1.44996584, 1.61107316, 1.77218047,\n        1.93328779, 2.0943951, 2.25550242, 2.41660973, 2.57771705, 2.73882436,\n        2.89993168, 3.061039, 3.22214631, 3.38325363, 3.54436094, 3.70546826,\n        3.86657557, 4.02768289, 4.1887902, 4.34989752, 4.51100484, 4.67211215,\n        4.83321947, 4.99432678, 5.1554341, 5.31654141, 5.47764873, 5.63875604,\n        5.79986336, 5.96097068, 6.12207799, 6.28318531\n    ],\n    [\n        0., 0.03225806, 0.06451613, 0.09677419, 0.12903226, 0.16129032,\n        0.19354839, 0.22580645, 0.25806452, 0.29032258, 0.32258065, 0.35483871,\n        0.38709677, 0.41935484, 0.4516129, 0.48387097, 0.51612903, 0.5483871,\n        0.58064516, 0.61290323, 0.64516129, 0.67741935, 0.70967742, 0.74193548,\n        0.77419355, 0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n        0.96774194, 1.\n    ],\n    [\n        0., 0.03225806, 0.06451613, 0.09677419, 0.12903226, 0.16129032,\n        0.19354839, 0.22580645, 0.25806452, 0.29032258, 0.32258065, 0.35483871,\n        0.38709677, 0.41935484, 0.4516129, 0.48387097, 0.51612903, 0.5483871,\n        0.58064516, 0.61290323, 0.64516129, 0.67741935, 0.70967742, 0.74193548,\n        0.77419355, 0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n        0.96774194, 1.\n    ]\n]\nOUTPUT_NAME = ""dsprites_ndarray_co1sh3sc6or40x32y32_64x64.hdf5""\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef _create_fake_samples():\n  """"""Creates a fake set of samples.\n\n  Returns:\n    Tuple with fake images, class labels and latent values.\n  """"""\n  rs = np.random.RandomState(0)\n  images = rs.randint(256, size=(NUM_IMAGES, 64, 64)).astype(""uint8"")\n\n  classes = []\n  values = []\n  for num_factors, factor_values in zip(FACTOR_COUNTS, FACTOR_VALUES):\n    classes.append(rs.randint(num_factors, size=(NUM_IMAGES), dtype=np.int64))\n    values.append(rs.choice(factor_values, size=(NUM_IMAGES)))\n\n  return images, classes.T, values.T  # pytype: disable=attribute-error\n\n\ndef _generate():\n  """"""Generates a fake data set and writes it to the fake_examples directory.""""""\n  output_dir = os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"",\n                            ""fake_examples"", ""dsprites"")\n  test_utils.remake_dir(output_dir)\n\n  images, classes, values = _create_fake_samples()\n\n  with h5py.File(os.path.join(output_dir, OUTPUT_NAME), ""w"") as f:\n    img_dataset = f.create_dataset(""imgs"", images.shape, ""|u1"")\n    img_dataset.write_direct(images)\n\n    classes_dataset = f.create_dataset(""latents/classes"", classes.shape, ""<i8"")\n    classes_dataset.write_direct(np.ascontiguousarray(classes))\n\n    values_dataset = f.create_dataset(""latents/values"", values.shape, ""<f8"")\n    values_dataset.write_direct(np.ascontiguousarray(values))\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/dtd.py,4,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate DTD like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""dtd"")\n\n\ndef _makedir_if_not_exists(dirname):\n  if not tf.io.gfile.exists(dirname):\n    tf.io.gfile.makedirs(dirname)\n\n\ndef _generate_data(split_name, num_examples):\n  """"""Generate test data.""""""\n  names_file = tfds.core.get_tfds_path(\n      os.path.join(""image"", ""dtd_key_attributes.txt""))\n  label_names = tfds.features.ClassLabel(names_file=names_file).names\n\n  # Generate images.\n  generated_filenames = []\n  for n in range(num_examples):\n    label = random.choice(label_names)\n    fname = ""%s/%s_%04d.jpg"" % (label, label, n)\n    tmp_file_path = fake_data_utils.get_random_jpeg()\n    dst_file_path = os.path.join(_output_dir(), ""dtd"", ""images"", fname)\n    generated_filenames.append(fname)\n\n    _makedir_if_not_exists(os.path.dirname(dst_file_path))\n    tf.io.gfile.copy(tmp_file_path, dst_file_path, overwrite=True)\n\n  split_path = os.path.join(_output_dir(), ""dtd"", ""labels"", split_name + "".txt"")\n  _makedir_if_not_exists(os.path.dirname(split_path))\n  with tf.io.gfile.GFile(split_path, ""w"") as split_file:\n    for fname in generated_filenames:\n      split_file.write(""%s\\n"" % fname)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_data(""test1"", 3)\n  _generate_data(""train1"", 2)\n  _generate_data(""val1"", 1)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/e2e_binary.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Binary exercising critical workflow of tensorflow datasets.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets as tfds\n\ntf.enable_v2_behavior()\n\n\ndef main(argv):\n  del argv\n  mnist, info = tfds.load(\'mnist\', with_info=True)\n  print(mnist, info)\n  mnist_train = tfds.load(\'mnist\', split=\'train\')\n  print(mnist_train)\n  mnist_subsplit = tfds.Split.TRAIN.subsplit(tfds.percent[:10])  # pytype: disable=module-attr\n  mnist_train2 = tfds.load(\'mnist\', split=mnist_subsplit)\n  print(mnist_train2)\n  for i, unused_row in enumerate(mnist_train2):\n    if i > 10:\n      break\n    print(i)\n  builder = tfds.builder(\'cifar10\')\n  dataset = builder.as_dataset(split=\'train\')\n  print(dataset)\n  cifar10_np = tfds.as_numpy(dataset)\n  print(cifar10_np)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/flic.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Generates FLIC like files with random data for testing.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport numpy as np\nimport scipy.io\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir(data):\n  """"""Returns output directory.""""""\n  dname = ""FLIC"" if data == ""small"" else ""FLIC-full""\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""flic"", dname)\n\n\ndef _generate_image(data, fdir, fname):\n  dirname = os.path.join(_output_dir(data), fdir)\n  if not os.path.exists(dirname):\n    os.makedirs(dirname)\n  tf.io.gfile.copy(\n      fake_data_utils.get_random_jpeg(480, 720),\n      os.path.join(dirname, fname),\n      overwrite=True)\n\n\ndef _generate_mat(data, train_fname, test_fname):\n  """"""Generate MAT file for given data type (small or full).""""""\n  dirname = os.path.join(_output_dir(data), ""examples.mat"")\n  data = {\n      ""examples"":\n          np.array([\n              np.array([\n                  np.array([1, 2, 3], dtype=np.uint16),\n                  ""example_movie"",\n                  np.array(\n                      [np.array([1.0, 2.0, 3.0]),\n                       np.array([1.0, 2.0, 3.0])]),\n                  train_fname,\n                  np.array([1.0, 2.0, 3.0]),\n                  1.0,\n                  np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32),\n                  True,\n                  False,\n              ]),\n              np.array([\n                  np.array([1, 2, 3], dtype=np.uint16),\n                  ""example_movie"",\n                  np.array(\n                      [np.array([1.0, 2.0, 3.0]),\n                       np.array([1.0, 2.0, 3.0])]),\n                  test_fname,\n                  np.array([1.0, 2.0, 3.0]),\n                  1.0,\n                  np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32),\n                  False,\n                  True,\n              ]),\n          ]),\n  }\n\n  scipy.io.savemat(dirname, data)\n\n\ndef main(unused_argv):\n  _generate_image(""small"", ""images"", ""example_movie00000001.jpg"")\n  _generate_image(""small"", ""images"", ""example_movie00000002.jpg"")\n  _generate_mat(""small"", ""example_movie00000001.jpg"",\n                ""example_movie00000002.jpg"")\n\n  _generate_image(""full"", ""images"", ""example_movie00000003.jpg"")\n  _generate_image(""full"", ""images"", ""example_movie00000004.jpg"")\n  _generate_mat(""full"", ""example_movie00000003.jpg"",\n                ""example_movie00000004.jpg"")\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/horses_or_humans.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate fake data for horses_or_humans dataset.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'horses_or_humans\')\n\n\ndef create_zip(fname):\n  out_path = os.path.join(_output_dir(), fname)\n  png = fake_data_utils.get_random_png(height=1, width=1)\n  with zipfile.ZipFile(out_path, \'w\') as myzip:\n    myzip.write(png, \'horses/0.png\')\n    myzip.write(png, \'humans/0.png\')\n\n\ndef main(argv):\n  del argv\n  create_zip(\'hoh_train.zip\')\n  create_zip(\'hoh_test.zip\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/imagenet.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate ilsvrc2012 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tarfile\nimport tempfile\n\nfrom absl import app\nfrom absl import flags\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.image import imagenet  # pytype: disable=import-error\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\nTRAIN_SYNSET_NUMBER = 10\nTRAIN_IMAGES_PER_SYNSET = 10\nVAL_IMAGES_NUMBER = 10\n\n\ndef _get_synset(synset_name):\n  """"""Returns path to synset archive.""""""\n  fobj = tempfile.NamedTemporaryFile(delete=False, mode=\'wb\', suffix=\'.tar\')\n  tar = tarfile.open(mode=\'w\', fileobj=fobj)\n  for i in range(1, TRAIN_IMAGES_PER_SYNSET+1):\n    fname = \'%s_%s.JPEG\' % (synset_name, i)\n    # There are a few PNG and CMYK images:\n    if synset_name == \'n01440764\' and i == 1:\n      path = fake_data_utils.get_random_png()\n    elif synset_name == \'n01440764\' and i in [2, 3]:\n      path = os.path.join(\n          FLAGS.tfds_dir, \'testing\', \'test_data\', \'6pixels_cmyk.jpeg\')\n    else:\n      path = fake_data_utils.get_random_jpeg()\n    tar.add(path, arcname=fname)\n  fobj.close()\n  return fobj.name\n\n\ndef _ilsvrc2012_output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'imagenet2012\')\n\n\ndef _generate_train_archive():\n  """"""Generate train archive.""""""\n  output_path = os.path.join(_ilsvrc2012_output_dir(),\n                             \'ILSVRC2012_img_train.tar\')\n  tar = tarfile.open(output_path, mode=\'w\')\n  names_file = tfds.core.get_tfds_path(imagenet._LABELS_FNAME)  # pylint: disable=protected-access\n  label_names = tfds.features.ClassLabel(names_file=names_file).names\n  for i in range(TRAIN_SYNSET_NUMBER):\n    synset_name = label_names[i]\n    synset = _get_synset(synset_name)\n    tar.add(synset, arcname=\'%s.tar\' % synset_name)\n  tar.close()\n\n\ndef _generate_val_archive():\n  """"""Generate val archive.""""""\n  output_path = os.path.join(_ilsvrc2012_output_dir(),\n                             \'ILSVRC2012_img_val.tar\')\n  tar = tarfile.open(output_path, mode=\'w\')\n  for i in range(1, VAL_IMAGES_NUMBER+1):\n    fname = \'ILSVRC2012_val_0000%03i.JPEG\' % i\n    jpeg = fake_data_utils.get_random_jpeg()\n    tar.add(jpeg, arcname=fname)\n  tar.close()\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(\'Too many command-line arguments.\')\n  _generate_train_archive()\n  _generate_val_archive()\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/imagenet_resized.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Script to generate imagenet resized like files for testing.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nimport numpy as np\nfrom tensorflow_datasets.core.utils import py_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n\nFLAGS = flags.FLAGS\n\n\ndef _write_zipped(output_dir, data, tmp_name, zip_name):\n  train_path = os.path.join(output_dir, tmp_name)\n  with open(train_path, ""w"") as f:\n    np.savez(f, **data)\n\n  zip_path = os.path.join(output_dir, zip_name)\n  with zipfile.ZipFile(zip_path, ""w"") as f:\n    f.write(train_path)\n  os.remove(train_path)\n\n\ndef _generate_data():\n  """"""Generates training archives for both train and valiation.""""""\n  output_dir = os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"",\n                            ""fake_examples"", ""imagenet_resized"")\n\n  train = {}\n  train[""data""] = np.zeros(shape=[3, 8, 8, 3], dtype=np.uint8)\n  train[""labels""] = np.zeros(shape=[3], dtype=np.int64)\n\n  _write_zipped(output_dir, train, ""Imagenet8_train.npz"",\n                ""Imagenet8_train_npz.zip"")\n\n  valid = {}\n  valid[""data""] = np.ones(shape=[1, 8, 8, 3], dtype=np.uint8)\n  valid[""labels""] = np.ones(shape=[1], dtype=np.int64)\n\n  _write_zipped(output_dir, valid, ""Imagenet8_val.npz"", ""Imagenet8_val_npz.zip"")\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_data()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/kitti.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Script to generate fake Kitti files with random data for testing.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core import utils\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.object_detection import kitti\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\n\nFLAGS = flags.FLAGS\nNUM_IMAGES = 10\nNUM_VIDEOS = 5\nHEIGHT = 375\nWIDTH = 1242\nOBJECTS = [\n    ""Car"",\n    ""Van"",\n    ""Truck"",\n    ""Pedestrian"",\n    ""Person_sitting"",\n    ""Cyclist"",\n    ""Tram"",\n    ""Misc"",\n]\n\n\ndef _get_png():\n  """"""Returns a random png image.""""""\n  image = fake_data_utils.get_random_picture(HEIGHT, WIDTH)\n  png = tf.image.encode_png(image)\n  with utils.nogpu_session() as sess:\n    res = sess.run(png)\n  return res\n\n\ndef _list_f2s(float_list):\n  """"""Converts a list of floats to strings.""""""\n  return [""{:0.2f}"".format(x) for x in float_list]\n\n\ndef _list_d2s(int_list):\n  """"""Converts a list of ints to strings.""""""\n  return [""{:d}"".format(x) for x in int_list]\n\n\ndef _get_object_annotation():\n  """"""Returns a annotation for a random object.""""""\n  objects = kitti._OBJECT_LABELS  # pylint: disable=protected-access\n  obj_type = list(np.random.choice(objects, size=1))\n  truncated = _list_f2s(np.random.rand(1))\n  occluded = _list_d2s(np.random.choice(range(4), size=1))\n  alpha = _list_f2s(np.random.uniform(low=-np.pi, high=np.pi, size=1))\n  lr = np.random.uniform(low=0, high=WIDTH, size=2)\n  tb = np.random.uniform(low=0, high=HEIGHT, size=2)\n  # Left, top, right, bottom. Origin is the top-left pixel.\n  bbox = _list_f2s([min(lr), HEIGHT - max(tb), max(lr), HEIGHT - min(tb)])\n  # Height, width, length.\n  dimensions = _list_f2s(np.random.uniform(low=0, high=5, size=3))\n  location = _list_f2s(np.random.uniform(low=0, high=30, size=3))\n  rotation = _list_f2s(np.random.uniform(low=-np.pi, high=np.pi, size=1))\n  return "" "".join(obj_type + truncated + occluded + alpha + bbox + dimensions +\n                  location + rotation)\n\n\ndef _get_dontcare_object_annotation():\n  """"""Returns a annotation for a random object in class `DontCare`.""""""\n  obj_type = [""DontCare""]\n  truncated = _list_f2s([-1])\n  occluded = _list_d2s([-1])\n  alpha = _list_f2s([-10])\n  lr = np.random.uniform(low=0, high=WIDTH, size=2)\n  tb = np.random.uniform(low=0, high=HEIGHT, size=2)\n  # Left, top, right, bottom. Origin is the top-left pixel.\n  bbox = _list_f2s([min(lr), HEIGHT - max(tb), max(lr), HEIGHT - min(tb)])\n  # Height, width, length.\n  dimensions = _list_f2s([-1] * 3)\n  location = _list_f2s([-1000] * 3)\n  rotation = _list_f2s([-10])\n  return "" "".join(obj_type + truncated + occluded + alpha + bbox + dimensions +\n                  location + rotation)\n\n\ndef _get_annotations():\n  """"""Generates annotations for a random number of objects in the image.""""""\n  annotation = []\n  for _ in range(np.random.choice(range(1, 10))):\n    annotation.append(_get_object_annotation())\n\n  # Add some DontCare objects.\n  for _ in range(np.random.choice(range(1, 3))):\n    annotation.append(_get_dontcare_object_annotation())\n\n  return annotation\n\n\ndef _output_dir():\n  """"""Returns output directory.""""""\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""kitti"")\n\n\ndef _get_label_file(annotation):\n  """"""Returns path to label files.""""""\n  fobj = tempfile.NamedTemporaryFile(delete=False, mode=""wb"", suffix="".txt"")\n  for row in annotation:\n    fobj.write(row + ""\\n"")\n  fobj.close()\n  return fobj.name\n\n\ndef _get_mapping_files():\n  """"""Returns dummy image to video mapping files.""""""\n  # Random indices file.\n  train_rand = np.random.permutation(range(1, NUM_IMAGES + 1))  # 1-based index\n  fobj_rand = tempfile.NamedTemporaryFile(\n      delete=False, mode=""wb"", suffix="".txt"")\n  fobj_rand.write("","".join([str(x) for x in train_rand]))  # pytype: disable=wrong-arg-types\n  fobj_rand.close()\n\n  # Mapping file.\n  fobj_map = tempfile.NamedTemporaryFile(delete=False, mode=""wb"", suffix="".txt"")\n  assert NUM_IMAGES > NUM_VIDEOS\n  assert NUM_IMAGES % NUM_VIDEOS == 0\n  vid_ids = list(range(NUM_VIDEOS)) * (NUM_IMAGES // NUM_VIDEOS)\n  for vid in vid_ids:\n    row = ""2011_09_26 2011_09_26_drive_00{:02d}_sync 0000000123"".format(vid)\n    fobj_map.write(row + ""\\n"")  # pytype: disable=wrong-arg-types\n  fobj_map.close()\n\n  return fobj_rand.name, fobj_map.name\n\n\ndef _create_zip_files():\n  """"""Saves png and label using name index.""""""\n  if not os.path.exists(_output_dir()):\n    os.makedirs(_output_dir())\n\n  images_out_path = os.path.join(_output_dir(), ""data_object_image_2.zip"")\n  with zipfile.ZipFile(images_out_path, ""w"") as image_zip:\n    for i in range(NUM_IMAGES):\n      png = fake_data_utils.get_random_png(HEIGHT, WIDTH)\n      image_zip.write(\n          png, os.path.join(""training"", ""image_2"",\n                            ""image_{:06d}.png"".format(i)))\n\n  label_out_path = os.path.join(_output_dir(), ""data_object_label_2.zip"")\n  with zipfile.ZipFile(label_out_path, ""w"") as label_zip:\n    for i in range(NUM_IMAGES):\n      annotation = _get_annotations()\n      label = _get_label_file(annotation)\n      label_zip.write(\n          label,\n          os.path.join(""training"", ""label_2"", ""label_{:06d}.txt"".format(i)))\n\n  devkit_out_path = os.path.join(_output_dir(), ""devkit_object.zip"")\n  with zipfile.ZipFile(devkit_out_path, ""w"") as devkit_zip:\n    train_rand, train_mapping = _get_mapping_files()\n    devkit_zip.write(train_rand, os.path.join(""mapping"", ""train_rand.txt""))\n    devkit_zip.write(train_mapping, os.path.join(""mapping"",\n                                                 ""train_mapping.txt""))\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _create_zip_files()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/lost_and_found.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Script to generate fake \'Lost and Found\' data.""""""\nimport tensorflow.compat.v2 as tf\n\nimport tensorflow_datasets.testing.cityscapes as cityscapes\n\nif __name__ == \'__main__\':\n  example_dir = (\'tensorflow_datasets/testing/test_data/fake_examples/\'\n                 \'lost_and_found\')\n  base_path = example_dir + \'/{}.zip\'\n  # generate image ids matching between zipfiles\n  train_ids = list(cityscapes.generate_ids(\'01_Turmstr_17\')) + list(\n      cityscapes.generate_ids(\'02_Goethe_Str_6\'))\n  test_ids = list(cityscapes.generate_ids(\'03_Schlossallee_1\'))\n  splits = {\'train\': train_ids, \'test\': test_ids}\n  with tf.Graph().as_default():\n    cityscapes.create_zipfile(\n        base_path.format(\'leftImg8bit\'),\n        splits_with_ids=splits,\n        suffixes=[\'leftImg8bit\'])\n    cityscapes.create_zipfile(\n        base_path.format(\'gtCoarse\'),\n        splits_with_ids=splits,\n        suffixes=[\n            \'gtCoarse_instanceIds\', \'gtCoarse_labelIds\', \'gtCoarse_color\'\n        ])\n    cityscapes.create_zipfile(\n        base_path.format(\'rightImg8bit\'),\n        splits_with_ids=splits,\n        suffixes=[\'rightImg8bit\'])\n    cityscapes.create_zipfile(\n        base_path.format(\'disparity\'),\n        splits_with_ids=splits,\n        suffixes=[\'disparity\'])\n'"
tensorflow_datasets/testing/fake_data_generation/lsun.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tool for putting given images into a single lmdb database.\n\nThis is the format that\'s used by LSUN dataset (it also\nuses webP encoded images inside).\n\nTo generate the example dataset:\n\npython lsun.py --input_files=test_data/lsun_examples/1.webp,\n                             test_data/lsun_examples/2.webp,\n                             test_data/lsun_examples/3.webp\n               --output_file=/tmp/lsun/train\n\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nfrom absl import flags\nimport lmdb  # pytype: disable=import-error\nimport tensorflow.compat.v2 as tf\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(""input_files"", None,\n                    ""Comma separated list of files to put into the database."")\nflags.DEFINE_string(""output_file"", None, ""Path to the output file."")\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise tf.app.UsageError(""Too many command-line arguments."")\n\n  db = lmdb.open(FLAGS.output_file)\n  with db.begin(write=True) as txn:\n    for index, path in enumerate(FLAGS.input_files.split("","")):\n      data = tf.io.gfile.GFile(path, ""rb"").read()\n      txn.put(str(index), data)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/malaria.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Fake Data Generator for Malaria Dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'malaria\', \'cell_images\')\n\n\ndef create_folder(fname):\n  images_dir = os.path.join(_output_dir(), fname)\n  if not tf.io.gfile.exists(images_dir):\n    tf.io.gfile.makedirs(images_dir)\n  for i in range(2):\n    image_name = \'C189P150ThinF_IMG_20151203_141809_cell_{:03d}.png\'.format(i)\n    tf.io.gfile.copy(\n        fake_data_utils.get_random_png(300, 300),\n        os.path.join(images_dir, image_name),\n        overwrite=True)\n\n\ndef main(argv):\n  del argv\n  create_folder(\'Parasitized\')\n  create_folder(\'Uninfected\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/mnist.py,2,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate MNIST-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef examples_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"")\n\n\ndef mnist_dir(name):\n  return os.path.join(examples_dir(), name)\n\n\n_TRAIN_DATA_FILENAME = ""train-image""\n_TRAIN_LABELS_FILENAME = ""train-label""\n_TEST_DATA_FILENAME = ""test-image""\n_TEST_LABELS_FILENAME = ""test-label""\n\n\ndef make_images(num_images):\n  return np.random.randint(256, size=(28 * 28 * num_images), dtype=np.uint8)\n\n\ndef make_labels(num_labels):\n  return np.random.randint(10, size=(num_labels), dtype=np.uint8)\n\n\ndef write_image_file(filename, num_images):\n  with tf.io.gfile.GFile(filename, ""wb"") as f:\n    f.write(b""1"" * 16)  # header\n    f.write(make_images(num_images).tobytes())\n\n\ndef write_label_file(filename, num_labels):\n  with tf.io.gfile.GFile(filename, ""wb"") as f:\n    f.write(b""1"" * 8)  # header\n    f.write(make_labels(num_labels).tobytes())\n\n\ndef main(_):\n  for mnist in [""mnist"", ""fashion_mnist"", ""kmnist"", ""emnist""]:\n    output_dir = mnist_dir(mnist)\n    test_utils.remake_dir(output_dir)\n    write_image_file(os.path.join(output_dir, _TRAIN_DATA_FILENAME), 10)\n    write_label_file(os.path.join(output_dir, _TRAIN_LABELS_FILENAME), 10)\n    write_image_file(os.path.join(output_dir, _TEST_DATA_FILENAME), 2)\n    write_label_file(os.path.join(output_dir, _TEST_LABELS_FILENAME), 2)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/nyu_depth_v2.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Generation script.""""""\n\nimport os\n\nimport h5py\nimport numpy as np\n\nref = h5py.File(\n    os.path.expanduser(\n        ""~/tensorflow_datasets/downloads/extracted/TAR_GZ.datasets.lids.mit.edu_fastdept_nyudepthBjtXYu6zBBYUv0ByLqXPgFy4ygUuVvPRxjz9Ip5_97M.tar.gz/nyudepthv2/val/official/00001.h5""\n    ),\n    ""r"",\n)\n\nrgb = ref[""rgb""][:]\ndepth = ref[""depth""][:]\nrgb_fake = np.ones(rgb.shape, dtype=np.uint8)  # np.zeros for val\ndepth_fake = np.ones(depth.shape).astype(depth.dtype)  # np.zeros for val\n\n# 00001 and 00002 for train; 00001 for val\nwith h5py.File(""00001.h5"", ""w"") as f:\n  f.create_dataset(""rgb"", data=rgb_fake, compression=""gzip"")\n  f.create_dataset(""depth"", data=depth_fake, compression=""gzip"")\n'"
tensorflow_datasets/testing/fake_data_generation/open_images.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate open_images like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\nimport tarfile\n\nfrom absl import app\nfrom absl import flags\n\nfrom tensorflow_datasets.core.features import ClassLabel\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.object_detection import open_images\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'open_images_v4\')\n\n\ndef _get_image_ids(images_number, prefix=None):\n  """"""Returns the names (as string) of images.""""""\n  if prefix:\n    get_id = lambda: \'%s%0.15X\' % (prefix, random.getrandbits(56))\n  else:\n    get_id = lambda: \'%0.16X\' % random.getrandbits(64)\n  return sorted([get_id().lower() for unused_i in range(images_number)])\n\n\ndef _write_tar(path, split_name, image_ids, prefix=None):\n  """"""Writes tar file with images to given path.\n\n  Args:\n    path: sting, path to tar to be written.\n    split_name: string. eg: \'train\', \'validation\', \'test\'.\n    image_ids: list of str, ids of the images to add to tar file.\n    prefix: one of [0-9a-f], or None.\n  """"""\n  if prefix is not None:\n    split_name = \'%s_%s\' % (split_name, prefix)\n  with tarfile.open(path, mode=\'w\') as tar:\n    for i, image_id in enumerate(image_ids):\n      fname = \'%s/%s.jpg\' % (split_name, image_id)\n      # Note: Generate two large images with more than 300k pixels.\n      kwargs = dict(height=600, width=600) if i < 2 else dict()\n      tar.add(fake_data_utils.get_random_jpeg(**kwargs), arcname=fname)\n\n\ndef _write_image_level_labels(fname, image_ids, machine=False):\n  """"""Writes CSV with 0-10 labels per image.""""""\n  lines = [\'ImageID,Source,LabelName,Condidence\']\n  all_class_label = ClassLabel(names_file=py_utils.get_tfds_path(\n      os.path.join(\'object_detection\', \'open_images_classes_all.txt\')))\n  trainable_class_label = ClassLabel(names_file=py_utils.get_tfds_path(\n      os.path.join(\'object_detection\', \'open_images_classes_trainable.txt\')))\n  for i, image_id in enumerate(image_ids):\n    if i < 1:\n      # Ensure that at least some image contains trainable classes.\n      labels = random.sample(trainable_class_label.names, random.randint(0, 10))\n    else:\n      labels = random.sample(all_class_label.names, random.randint(0, 10))\n    for label in labels:\n      source = random.choice(open_images.IMAGE_LEVEL_SOURCES)\n      confidence = random.choice((0, 1))\n      if machine:\n        confidence = \'%.1f\' % (random.randint(0, 10) / 10.)\n      else:\n        confidence = random.choice((0, 1))\n      lines.append(\'%s,%s,%s,%s\' % (image_id, source, label, confidence))\n  path = os.path.join(_output_dir(), fname)\n  with open(path, \'w\') as csv_f:\n    csv_f.write(\'\\n\'.join(lines))\n\n\ndef _write_bbox_labels(fname, image_ids):\n  """"""Writes CSV with 0-10 labels per image.""""""\n  lines = [\'ImageID,Source,LabelName,Confidence,XMin,XMax,YMin,YMax,IsOccluded,\'\n           \'IsTruncated,IsGroupOf,IsDepiction,IsInside\']\n  boxable_class_label = ClassLabel(names_file=py_utils.get_tfds_path(\n      os.path.join(\'object_detection\', \'open_images_classes_boxable.txt\')))\n  for image_id in image_ids:\n    labels = random.sample(boxable_class_label.names, random.randint(0, 10))\n    for label in labels:\n      source = random.choice(open_images.BBOX_SOURCES)\n      xmin = random.uniform(0, 1)\n      xmax = random.uniform(xmin, 1)\n      ymin = random.uniform(0, 1)\n      ymax = random.uniform(ymin, 1)\n      p1, p2, p3, p4, p5 = [random.randint(-1, 1) for unused_i in range(5)]\n      lines.append(\'%s,%s,%s,1,%.6f,%.6f,%.6f,%.6f,%s,%s,%s,%s,%s\' % (\n          image_id, source, label, xmin, xmax, ymin, ymax, p1, p2, p3, p4, p5))\n  path = os.path.join(_output_dir(), fname)\n  with open(path, \'w\') as csv_f:\n    csv_f.write(\'\\n\'.join(lines))\n\n\ndef _generate_train_files():\n  """"""Generate train files (archives and CSV files).""""""\n  all_image_ids = []\n  for prefix in \'0123456789abcdef\':\n    path = os.path.join(_output_dir(), \'s3-tar_train_sha1_%s.tar\' % prefix)\n    image_ids = _get_image_ids(images_number=32, prefix=prefix)\n    all_image_ids.extend(image_ids)\n    _write_tar(path, \'train\', image_ids, prefix)\n  _write_image_level_labels(\'train-human-labels.csv\', all_image_ids)\n  _write_image_level_labels(\'train-machine-labels.csv\', all_image_ids,\n                            machine=True)\n  _write_bbox_labels(\'train-annotations-bbox.csv\', all_image_ids)\n\n\ndef _generate_test_files():\n  """"""Generate test files (archive and CSV files).""""""\n  path = os.path.join(_output_dir(), \'s3-tar_test_sha2.tar\')\n  image_ids = _get_image_ids(images_number=36)\n  _write_tar(path, \'test\', image_ids)\n  _write_image_level_labels(\'test-human-labels.csv\', image_ids)\n  _write_image_level_labels(\'test-machine-labels.csv\', image_ids, machine=True)\n  _write_bbox_labels(\'test-annotations-bbox.csv\', image_ids)\n\n\ndef _generate_validation_files():\n  """"""Generate validation files (archive and CSV files).""""""\n  path = os.path.join(_output_dir(), \'s3-tar_validation_sha3.tar\')\n  image_ids = _get_image_ids(images_number=12)\n  _write_tar(path, \'test\', image_ids)\n  _write_image_level_labels(\'validation-human-labels.csv\', image_ids)\n  _write_image_level_labels(\'validation-machine-labels.csv\', image_ids,\n                            machine=True)\n  _write_bbox_labels(\'validation-annotations-bbox.csv\', image_ids)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(\'Too many command-line arguments.\')\n  _generate_train_files()\n  _generate_test_files()\n  _generate_validation_files()\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/oxford_iiit_pet.py,9,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate ilsvrc2012 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\n_TRAIN_IMAGES_NUMBER = 5\n_TEST_IMAGES_NUMBER = 5\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'oxford_iiit_pet\')\n\n\ndef _generate_data():\n  """"""Generate images archive.""""""\n\n  # Generate images\n  images_dir = os.path.join(_output_dir(), \'images\')\n  if not tf.io.gfile.exists(images_dir):\n    tf.io.gfile.makedirs(images_dir)\n  for i in range(_TRAIN_IMAGES_NUMBER + _TEST_IMAGES_NUMBER):\n    image_name = \'image{:03d}.jpg\'.format(i)\n    tf.io.gfile.copy(fake_data_utils.get_random_jpeg(),\n                     os.path.join(images_dir, image_name),\n                     overwrite=True)\n\n  # Generate annotations\n  annotations_dir = os.path.join(_output_dir(), \'annotations\')\n\n  if not tf.io.gfile.exists(annotations_dir):\n    tf.io.gfile.makedirs(annotations_dir)\n\n  # Generate trimaps\n  trimaps_dir = os.path.join(annotations_dir, \'trimaps\')\n\n  if not tf.io.gfile.exists(trimaps_dir):\n    tf.io.gfile.makedirs(trimaps_dir)\n\n  global_count = 0\n  for filename, num_examples in [(\'trainval.txt\', _TRAIN_IMAGES_NUMBER),\n                                 (\'test.txt\', _TEST_IMAGES_NUMBER)]:\n    fobj = tempfile.NamedTemporaryFile(delete=False, mode=\'w\')\n    with fobj:\n      for i in range(num_examples):\n        fobj.write(\'image{:03d} {} 0 0\\n\'.format(global_count, i % 37))\n        global_count += 1\n    tf.io.gfile.copy(fobj.name, os.path.join(annotations_dir, filename),\n                     overwrite=True)\n\n  # Create trimaps\n  for i in range(_TRAIN_IMAGES_NUMBER + _TEST_IMAGES_NUMBER):\n    trimap_name = \'image{:03d}.png\'.format(i)\n    tf.io.gfile.copy(fake_data_utils.get_random_png(channels=1),\n                     os.path.join(trimaps_dir, trimap_name),\n                     overwrite=True)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(\'Too many command-line arguments.\')\n  _generate_data()\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/patch_camelyon.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Create fake data for Camelyon Patch dataset.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\n\nimport h5py\nimport numpy as np\nfrom tensorflow_datasets.core.utils import py_utils\n\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\nFLAGS = flags.FLAGS\n\n\ndef get_output_file_prefix(split):\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'patch_camelyon\',\n                      \'camelyonpatch_level_2_split_%s\' % split)\n\n\ndef write_to_h5_file(filepath, dataset_name, content):\n  with h5py.File(filepath, \'w\') as h5_f:\n    h5_f.create_dataset(dataset_name, data=content)\n\n\ndef main(_):\n  np.random.seed(0x12345)\n  for split, num_examples in [(\'train\', 5), (\'test\', 4), (\'valid\', 3)]:\n    x = np.random.randint(\n        low=0, high=256, size=(num_examples, 96, 96, 3), dtype=np.uint8)\n    y = np.random.randint(\n        low=0, high=2, size=(num_examples, 1, 1, 1), dtype=np.uint32)\n    images_filepath = get_output_file_prefix(split) + \'_x.h5\'\n    labels_filepath = get_output_file_prefix(split) + \'_y.h5\'\n    write_to_h5_file(images_filepath, dataset_name=\'x\', content=x)\n    write_to_h5_file(labels_filepath, dataset_name=\'y\', content=y)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/rock_paper_scissors.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate fake data for rock_paper_scissors dataset.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport zipfile\n\nfrom absl import app\nfrom absl import flags\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(\'tfds_dir\', py_utils.tfds_dir(),\n                    \'Path to tensorflow_datasets directory\')\n\nFLAGS = flags.FLAGS\n\n\ndef _output_dir():\n  return os.path.join(FLAGS.tfds_dir, \'testing\', \'test_data\', \'fake_examples\',\n                      \'rock_paper_scissors\')\n\n\ndef create_zip(fname, prefix):\n  out_path = os.path.join(_output_dir(), fname)\n  png = fake_data_utils.get_random_png(height=1, width=1)\n  with zipfile.ZipFile(out_path, \'w\') as myzip:\n    myzip.write(png, prefix + \'rock/0.png\')\n    myzip.write(png, prefix + \'paper/0.png\')\n    myzip.write(png, prefix + \'scissors/0.png\')\n\n\ndef main(argv):\n  del argv\n  create_zip(\'rps_train.zip\', \'rps/\')\n  create_zip(\'rps_test.zip\', \'rps-test-set/\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/shapes3d.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate Shapes3d-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport h5py\nimport numpy as np\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nNUM_IMAGES = 5\nFACTOR_VALUES = [[0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n                 [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n                 [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n                 [\n                     0.75, 0.82142857, 0.89285714, 0.96428571, 1.03571429,\n                     1.10714286, 1.17857143, 1.25\n                 ], [0., 1., 2., 3.],\n                 [\n                     -30., -25.71428571, -21.42857143, -17.14285714,\n                     -12.85714286, -8.57142857, -4.28571429, 0., 4.28571429,\n                     8.57142857, 12.85714286, 17.14285714, 21.42857143,\n                     25.71428571, 30.\n                 ]]\nOUTPUT_NAME = ""3dshapes.h5""\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef _create_fake_samples():\n  """"""Creates a fake set of samples.\n\n  Returns:\n    Tuple with fake images and fake latent values.\n  """"""\n  rs = np.random.RandomState(0)\n  images = rs.randint(256, size=(NUM_IMAGES, 64, 64, 3)).astype(""uint8"")\n  values = []\n  for factor_values in FACTOR_VALUES:\n    values.append(rs.choice(factor_values, size=(NUM_IMAGES)))\n\n  return images, np.transpose(values)\n\n\ndef _generate():\n  """"""Generates a fake data set and writes it to the fake_examples directory.""""""\n  output_dir = os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"",\n                            ""fake_examples"", ""shapes3d"")\n  test_utils.remake_dir(output_dir)\n\n  images, values = _create_fake_samples()\n\n  with h5py.File(os.path.join(output_dir, OUTPUT_NAME), ""w"") as f:\n    img_dataset = f.create_dataset(""images"", images.shape, ""|u1"")\n    img_dataset.write_direct(images)\n    values_dataset = f.create_dataset(""labels"", values.shape, ""<f8"")\n    values_dataset.write_direct(np.ascontiguousarray(values))\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/smallnorb.py,1,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate Smallnorb-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nNUM_IMAGES = 5\nFACTOR_VALUES = [\n    list(range(10)),\n    list(range(9)),\n    list(range(0, 36, 2)),\n    list(range(6)),\n]\nTRAINING_OUTPUT_NAME = ""smallnorb-5x46789x9x18x6x2x96x96-training""\nTESTING_OUTPUT_NAME = ""smallnorb-5x01235x9x18x6x2x96x96-testing""\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory."")\nFLAGS = flags.FLAGS\n\n\ndef write_binary_matrix(filename, array):\n  """"""Writes array as a binary formatted matrix to the file.\n\n  The file format is described on the data set page:\n  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/\n\n  Args:\n    filename: String with path to the file.\n    array: Numpy array that should be written to the file.\n  """"""\n  with tf.io.gfile.GFile(filename, ""wb"") as f:\n\n    # All data is stored in little-endian byte order.\n    int32_dtype = np.dtype(""int32"").newbyteorder(""<"")\n\n    # The first 4 bytes specify the data type.\n    if array.dtype.str == ""<i4"":\n      # Magic code for little-endian int32.\n      f.write(np.asarray(507333716, dtype=int32_dtype).tobytes())\n    elif array.dtype.str == ""|u1"":\n      # Magic code for uint8.\n      f.write(np.asarray(507333717, dtype=int32_dtype).tobytes())\n    else:\n      raise ValueError(""Array data type %r not supported."" % array.dtype.str)\n\n    # Next, we specify the number of dimensions of the array to be stored as a\n    # 32 bit integer.\n    f.write(np.asarray(array.ndim, int32_dtype).tobytes())\n\n    # The shape of the array is saved as 32-bit integers. If there are less than\n    # 3 dimensions, the shape is padded with ones.\n    shape = list(array.shape) + [1] * max(0, 3 - array.ndim)\n    f.write(np.asarray(shape, int32_dtype).tobytes())\n\n    # Finally, the data is written as a C-contiguous matrix. There is no need to\n    # check for the byte order as we checked for this when writing the magic\n    # code.\n    f.write(np.ascontiguousarray(array).tobytes())\n\n\ndef _create_chunk(prefix, random_state):\n  """"""Creates fake dat, cat, and info files with the given prefix.""""""\n  # Create the images.\n  image_shape = (NUM_IMAGES, 2, 96, 96)  # Data file contains pairs of images.\n  images = random_state.randint(256, size=image_shape).astype(""uint8"")\n  write_binary_matrix(""%s-dat.mat"" % prefix, images)\n\n  # Create the class label file.\n  class_labels = random_state.choice(range(5), size=(NUM_IMAGES))\n  write_binary_matrix(""%s-cat.mat"" % prefix, class_labels.astype(""int32""))\n\n  # Create the auxiliary info file that contains additional labels.\n  info = []\n  for values in FACTOR_VALUES:\n    info.append(random_state.choice(values, size=(NUM_IMAGES)))\n  write_binary_matrix(""%s-info.mat"" % prefix, np.array(info).T.astype(""int32""))\n\n\ndef _generate():\n  """"""Generates a fake data set and writes it to the fake_examples directory.""""""\n  output_dir = os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"",\n                            ""fake_examples"", ""smallnorb"")\n  test_utils.remake_dir(output_dir)\n  random_state = np.random.RandomState(0)\n  _create_chunk(os.path.join(output_dir, TRAINING_OUTPUT_NAME), random_state)\n  _create_chunk(os.path.join(output_dir, TESTING_OUTPUT_NAME), random_state)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/smallnorb_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for smallnorb.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\nfrom tensorflow_datasets.image_classification import smallnorb as smallnorb_tfds\nfrom tensorflow_datasets.testing import test_utils\nfrom tensorflow_datasets.testing.fake_data_generation import smallnorb as smallnorb_builder\n\n\nclass SmallnorbTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      (""uint8"", np.array([[1, 2, 3], [1, 2, 3]], dtype=np.dtype(""|u1""))),\n      (""int32"", np.array([-1, 0, 1], dtype=np.dtype(""<i4""))),)\n  def test_write_and_read(self, matrix):\n    with test_utils.tmp_dir() as directory:\n      path = os.path.join(directory, ""matrix.mat"")\n      smallnorb_builder.write_binary_matrix(path, matrix)\n      restored_matrix = smallnorb_tfds.read_binary_matrix(path)\n      np.testing.assert_allclose(restored_matrix, matrix)\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
tensorflow_datasets/testing/fake_data_generation/starcraft.py,16,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tool for preparing test example of Starcraft dataset.\n\n\n./starcraft  --resolution=64 --output_file=test.tfrecords\n./starcraft  --resolution=64 --output_file=train_0.tfrecords\n./starcraft  --resolution=64 --output_file=train_1.tfrecords\n./starcraft  --resolution=64 --output_file=valid.tfrecords\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\nimport png\nimport six\nimport tensorflow.compat.v2 as tf\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_integer(""resolution"", 64, ""Resolution of the video."")\nflags.DEFINE_string(""output_file"", None, ""Path to the output file."")\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise tf.app.UsageError(""Too many command-line arguments."")\n\n  writer = tf.io.TFRecordWriter(FLAGS.output_file)\n\n  feature_list = {}\n  frame_list = []\n  for _ in range(20):\n    # generate 20 frames.\n    png_image = six.StringIO()\n    png.from_array(\n        np.random.randint(\n            low=0,\n            high=255,\n            size=(FLAGS.resolution, FLAGS.resolution, 3),\n            dtype=np.uint8), ""RGB"").save(png_image)\n    frame_list.append(\n        tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[png_image.getvalue()])))\n    png_image.close()\n\n  feature_list[""rgb_screen""] = tf.train.FeatureList(feature=frame_list)\n\n  context_feature = {}\n  context_feature[""game_duration_loops""] = tf.train.Feature(\n      int64_list=tf.train.Int64List(value=[20]))\n  context_feature[""game_duration_seconds""] = tf.train.Feature(\n      float_list=tf.train.FloatList(value=[20.0]))\n  context_feature[""n_steps""] = tf.train.Feature(\n      int64_list=tf.train.Int64List(value=[20]))\n  context_feature[""screen_size""] = tf.train.Feature(\n      int64_list=tf.train.Int64List(value=[FLAGS.resolution, FLAGS.resolution]))\n\n  example = tf.train.SequenceExample(\n      feature_lists=tf.train.FeatureLists(feature_list=feature_list),\n      context=tf.train.Features(feature=context_feature))\n  writer.write(example.SerializeToString())\n  writer.close()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/stl10.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate stl10 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nimport numpy as np\n\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.testing import test_utils\n\nHEIGHT, WIDTH = (96, 96)\nNUMBER_LABELS = 10\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\n\ndef stl_output_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""stl10"", ""stl10_binary"")\n\n\ndef dump(output_dir, fname, data):\n  path = os.path.join(output_dir, fname)\n  print(""Writing %s..."" % path)\n  with open(path, ""wb"") as out_file:\n    out_file.write(data.tobytes())\n\n\ndef _generate_stl10_data():\n  """"""Generates .bin files for stl10.""""""\n  output_dir = stl_output_dir()\n  test_utils.remake_dir(output_dir)\n  for fname in [""train_y.bin"", ""test_y.bin""]:\n    labels = np.random.randint(\n        NUMBER_LABELS, size=(1), dtype=np.uint8)\n    dump(stl_output_dir(), fname, labels)\n\n  for fname in [""train_X.bin"", ""test_X.bin"", ""unlabeled_X.bin""]:\n    images = np.random.randint(\n        256, size=(1, HEIGHT * WIDTH * 3), dtype=np.uint8)\n    dump(stl_output_dir(), fname, images)\n  label_names = [\n      ""airplane"", ""bird"", ""car"", ""cat"", ""deer"", ""dog"", ""horse"", ""monkey"",\n      ""ship"", ""truck""\n  ]\n  with open(os.path.join(output_dir, ""class_names.txt""), ""w"") as f:\n    f.write(""\\n"".join(label_names))\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_stl10_data()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/sun397.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate sun397-like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport os\nimport random\nimport tarfile\nimport tempfile\n\nfrom absl import app\nfrom absl import flags\nimport md5  # pytype: disable=import-error\n\nimport numpy as np\nfrom tensorflow_datasets.core.utils import py_utils\nimport tensorflow_datasets.public_api as tfds\n\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\nMIN_HEIGHT_WIDTH = 10\nMAX_HEIGHT_WIDTH = 15\n\n\ndef _output_dir():\n  return os.path.join(\n      FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"", ""sun397"")\n\n\ndef _get_random_picture(height=None, width=None, channels=None):\n  """"""Returns random picture as np.ndarray (int).""""""\n  height = height or random.randrange(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n  width = width or random.randrange(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n  channels = channels or random.randrange(1, 4)\n  return np.random.randint(256, size=(height, width, channels), dtype=np.uint8)\n\n\ndef _encode_image(image, image_format=None, fobj=None):\n  """"""Encodes and writes an image in a Numpy array to a file object.\n\n  Args:\n    image: A numpy array with shape (height, width, channels).\n    image_format: Encode and write the image in this format.\n      If None, JPEG is used.\n    fobj: File object to write the encoded image. Random access (seek) is\n      required. If None, it creates a BytesIO file.\n\n  Returns:\n    Resulting file object. If fobj was given, the functions returns it.\n  """"""\n  if len(image.shape) != 3:\n    raise ValueError(""The image should have shape (height, width, channels)"")\n\n  # By default, for images with alpha channel use PNG, otherwise use JPEG.\n  if image_format is None:\n    image_format = ""JPEG""\n\n  # Remove extra channel for grayscale images, or PIL complains.\n  if image.shape[-1] == 1:\n    image = image.reshape(image.shape[:-1])\n\n  fobj = fobj or io.BytesIO()\n  image = tfds.core.lazy_imports.PIL_Image.fromarray(image)\n  image.save(fobj, format=image_format)\n  fobj.seek(0)\n  return fobj\n\n\ndef _generate_data():\n  """"""Generate random data for testing the Sun397 dataset builder.""""""\n\n  names_file = tfds.core.get_tfds_path(\n      os.path.join(""image"", ""sun397_labels.txt""))\n  label_names = tfds.features.ClassLabel(names_file=names_file).names\n\n  def _generate_image_to_tar(image_format, channels, tar):\n    """"""Generate a random image and add it to the given tar file.""""""\n    label = random.choice(label_names)\n    image = _get_random_picture(channels=channels)\n    # Regardless of the actual format, always write with .jpg extension.\n    fobj = tempfile.NamedTemporaryFile(delete=False, suffix="".jpg"")\n    _encode_image(image, image_format, fobj=fobj)\n    filename = ""SUN397/%s/sun_%s.jpg"" % (label,\n                                         md5.new(fobj.read()).hexdigest())\n    fobj.seek(0)\n    fobj.close()\n    tar.add(fobj.name, arcname=filename)\n\n  tar = tarfile.open(os.path.join(_output_dir(), ""SUN397.tar.gz""), mode=""w:gz"")\n  _generate_image_to_tar(image_format=""JPEG"", channels=1, tar=tar)\n  _generate_image_to_tar(image_format=""JPEG"", channels=3, tar=tar)\n  _generate_image_to_tar(image_format=""GIF"", channels=3, tar=tar)\n  _generate_image_to_tar(image_format=""BMP"", channels=1, tar=tar)\n  _generate_image_to_tar(image_format=""BMP"", channels=3, tar=tar)\n  _generate_image_to_tar(image_format=""PNG"", channels=1, tar=tar)\n  _generate_image_to_tar(image_format=""PNG"", channels=3, tar=tar)\n  _generate_image_to_tar(image_format=""PNG"", channels=4, tar=tar)\n  tar.close()\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_data()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/testing/fake_data_generation/voc2007.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\nr""""""Generate voc2007 like files, smaller and with random data.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\n\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\nfrom tensorflow_datasets.object_detection import voc\nimport tensorflow_datasets.public_api as tfds\nfrom tensorflow_datasets.testing import fake_data_utils\n\nflags.DEFINE_string(""tfds_dir"", py_utils.tfds_dir(),\n                    ""Path to tensorflow_datasets directory"")\nFLAGS = flags.FLAGS\n\nMIN_HEIGHT_WIDTH = 10\nMAX_HEIGHT_WIDTH = 15\nMIN_OBJECT_HEIGHT_WIDTH = 3\nMAX_OBJECT_HEIGHT_WIDTH = 8\nMIN_NUM_OBJECTS = 1\nMAX_NUM_OBJECTS = 3\n\n\ndef _voc2007_output_dir():\n  return os.path.join(FLAGS.tfds_dir, ""testing"", ""test_data"", ""fake_examples"",\n                      ""voc2007"")\n\n\ndef _write_text_file(filepath, content):\n  """"""Write a text file given its content.""""""\n  dirname = os.path.dirname(filepath)\n  if not tf.io.gfile.exists(dirname):\n    tf.io.gfile.makedirs(dirname)\n  with tf.io.gfile.GFile(filepath, ""w"") as f:\n    f.write(content)\n\n\ndef _generate_jpeg(example_id, height, width):\n  """"""Generate a fake jpeg image for the given example id.""""""\n  jpeg = fake_data_utils.get_random_jpeg(height=height, width=width)\n  filepath = os.path.join(_voc2007_output_dir(),\n                          ""VOCdevkit/VOC2007/JPEGImages/%06d.jpg"" % example_id)\n  dirname = os.path.dirname(filepath)\n  if not tf.io.gfile.exists(dirname):\n    tf.io.gfile.makedirs(dirname)\n  tf.io.gfile.copy(jpeg, filepath, overwrite=True)\n\n\ndef _generate_annotation(example_id, height, width):\n  """"""Generate a fake annotation XML for the given example id.""""""\n  # pylint: disable=protected-access\n  label_names = tfds.features.ClassLabel(names=voc._VOC2007_LABELS).names  # pytype: disable=module-attr\n  pose_names = tfds.features.ClassLabel(names=voc._VOC2007_POSES).names  # pytype: disable=module-attr\n  # pylint: enable=protected-access\n  annotation = ""<annotation>\\n""\n  annotation += ""<size>\\n""\n  annotation += ""<width>%d</width>\\n"" % width\n  annotation += ""<height>%d</height>\\n"" % height\n  annotation += ""</size>\\n""\n  for i in range(random.randint(MIN_NUM_OBJECTS, MAX_NUM_OBJECTS)):\n    annotation += ""<object>\\n""\n    annotation += ""  <name>%s</name>\\n"" % random.choice(label_names)\n    annotation += ""  <pose>%s</pose>\\n"" % random.choice(pose_names)\n    annotation += ""  <truncated>%s</truncated>\\n"" % random.randint(0, 1)\n    if i > 0:\n      annotation += ""  <difficult>%s</difficult>\\n"" % random.randint(0, 1)\n    else:\n      annotation += ""  <difficult>0</difficult>\\n""\n    obj_w = random.randint(MIN_OBJECT_HEIGHT_WIDTH, MAX_OBJECT_HEIGHT_WIDTH)\n    obj_h = random.randint(MIN_OBJECT_HEIGHT_WIDTH, MAX_OBJECT_HEIGHT_WIDTH)\n    obj_x = random.randint(0, width - obj_w)\n    obj_y = random.randint(0, height - obj_h)\n    annotation += ""  <bndbox>\\n""\n    annotation += ""  <xmin>%d</xmin>\\n"" % obj_x\n    annotation += ""  <ymin>%d</ymin>\\n"" % obj_y\n    annotation += ""  <xmax>%d</xmax>\\n"" % (obj_x + obj_w - 1)\n    annotation += ""  <ymax>%d</ymax>\\n"" % (obj_y + obj_h - 1)\n    annotation += ""  </bndbox>\\n""\n    annotation += ""</object>\\n""\n  annotation += ""</annotation>\\n""\n  # Add annotation XML to the tar file.\n  filepath = os.path.join(_voc2007_output_dir(),\n                          ""VOCdevkit/VOC2007/Annotations/%06d.xml"" % example_id)\n  _write_text_file(filepath, annotation)\n\n\ndef _generate_data_for_set(set_name, example_start, num_examples):\n  """"""Generate different data examples for the train, validation or test sets.""""""\n  # Generate JPEG and XML files of each example.\n  for example_id in range(example_start, example_start + num_examples):\n    height = random.randint(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n    width = random.randint(MIN_HEIGHT_WIDTH, MAX_HEIGHT_WIDTH)\n    _generate_jpeg(example_id, height, width)\n    _generate_annotation(example_id, height, width)\n  # Add all example ids to the TXT file with all examples in the set.\n  filepath = os.path.join(_voc2007_output_dir(),\n                          ""VOCdevkit/VOC2007/ImageSets/Main/%s.txt"" % set_name)\n  _write_text_file(\n      filepath, """".join([\n          ""%06d\\n"" % example_id\n          for example_id in range(example_start, example_start + num_examples)\n      ]))\n\n\ndef _generate_trainval_archive():\n  """"""Generate train/val archive.""""""\n  _generate_data_for_set(""train"", example_start=0, num_examples=1)\n  _generate_data_for_set(""val"", example_start=1, num_examples=2)\n\n\ndef _generate_test_archive():\n  """"""Generate test archive.""""""\n  _generate_data_for_set(""test"", example_start=3, num_examples=3)\n\n\ndef main(argv):\n  if len(argv) > 1:\n    raise app.UsageError(""Too many command-line arguments."")\n  _generate_trainval_archive()\n  _generate_test_archive()\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tensorflow_datasets/core/features/text/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Text utilities.\n\n`tfds` includes a set of `TextEncoder`s as well as a `Tokenizer` to enable\nexpressive, performant, and reproducible natural language research.\n""""""\n\nfrom tensorflow_datasets.core.features.text.subword_text_encoder import SubwordTextEncoder\nfrom tensorflow_datasets.core.features.text.text_encoder import ByteTextEncoder\nfrom tensorflow_datasets.core.features.text.text_encoder import TextEncoder\nfrom tensorflow_datasets.core.features.text.text_encoder import TextEncoderConfig\nfrom tensorflow_datasets.core.features.text.text_encoder import Tokenizer\nfrom tensorflow_datasets.core.features.text.text_encoder import TokenTextEncoder\n\n__all__ = [\n    ""ByteTextEncoder"",\n    ""SubwordTextEncoder"",\n    ""TextEncoder"",\n    ""TextEncoderConfig"",\n    ""Tokenizer"",\n    ""TokenTextEncoder"",\n]\n'"
tensorflow_datasets/core/features/text/subword_text_encoder.py,6,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""SubwordTextEncoder.""""""\n# This implementation is based on SubwordTextEncoder in Tensor2Tensor,\n# originally written by Noam Shazeer (GitHub: nshazeer).\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport collections\n\nfrom absl import logging\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom tensorflow_datasets.core.features.text import text_encoder\n\n# Internally, an underscore indicates a single space, so, to ensure\n# user-supplied underscores are encoded properly, they are replaced with this\n# string during encoding.\n_UNDERSCORE_REPLACEMENT = ""\\\\&undsc""\n\n\nclass SubwordTextEncoder(text_encoder.TextEncoder):\n  """"""Invertible `TextEncoder` using word pieces with a byte-level fallback.\n\n  Encoding is fully invertible because all out-of-vocab wordpieces are\n  byte-encoded.\n\n  The vocabulary is ""trained"" on a corpus and all wordpieces are stored in a\n  vocabulary file. To generate a vocabulary from a corpus, use\n  `tfds.features.text.SubwordTextEncoder.build_from_corpus`.\n\n  Typical usage:\n\n  ```\n  # Build\n  encoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n      corpus_generator, target_vocab_size=2**15)\n  encoder.save_to_file(vocab_filename)\n\n  # Load\n  encoder = tfds.features.text.SubwordTextEncoder.load_from_file(vocab_filename)\n  ids = encoder.encode(""hello world"")\n  text = encoder.decode([1, 2, 3, 4])\n  ```\n  """"""\n\n  def __init__(self, vocab_list=None):\n    r""""""Constructs a SubwordTextEncoder from a vocabulary list.\n\n    Note: To generate a vocabulary from a corpus, use\n    `tfds.features.text.SubwordTextEncoder.build_from_corpus`.\n\n    Args:\n      vocab_list: `list<str>`, list of subwords for the vocabulary. Note that an\n        underscore at the end of a subword indicates the end of the word (i.e. a\n        space will be inserted afterwards when decoding). Underscores in the\n        interior of subwords are disallowed and should use the underscore\n        escape sequence.\n    """"""\n    self._init_from_list(vocab_list)\n\n  def encode(self, s):\n    """"""Encodes text into a list of integers.""""""\n    s = tf.compat.as_text(s)\n    tokens = self._tokenizer.tokenize(s)\n    tokens = _prepare_tokens_for_encode(tokens)\n    ids = []\n    for token in tokens:\n      ids.extend(self._token_to_ids(token))\n    return text_encoder.pad_incr(ids)\n\n  def decode(self, ids):\n    """"""Decodes a list of integers into text.""""""\n    ids = text_encoder.pad_decr(ids)\n    subword_ids = ids\n    del ids\n\n    subwords = []\n\n    # Some ids correspond to bytes. Because unicode characters are composed of\n    # possibly multiple bytes, we attempt to decode contiguous lists of bytes\n    # all together. Invalid byte sequences are replaced with the unicode\n    # replacement (i.e. unknown) character U+FFFD.\n    prev_bytes = []\n\n    def consume_prev_bytes():\n      if prev_bytes:\n        bytestr = b"""".join(prev_bytes)\n        bytes_text = bytestr.decode(""utf-8"", ""replace"")\n        subwords.append(bytes_text)\n      return []\n\n    for subword_id in subword_ids:\n      subword = self._id_to_subword(subword_id)\n      if isinstance(subword, six.binary_type):\n        # Byte-encoded\n        prev_bytes.append(subword)\n      else:\n        # If there were bytes previously, convert to unicode.\n        prev_bytes = consume_prev_bytes()\n        trimmed, add_space = _trim_underscore_and_tell(subword)\n        subwords.append(trimmed)\n        if add_space:\n          subwords.append("" "")\n    # If there were trailing bytes, convert to unicode.\n    prev_bytes = consume_prev_bytes()\n\n    return tf.compat.as_text("""".join(subwords))\n\n  @property\n  def vocab_size(self):\n    # Vocab is:\n    # * pad=0\n    # * subwords\n    # * bytes\n    return 1 + len(self._subwords) + text_encoder.NUM_BYTES\n\n  @property\n  def subwords(self):\n    return list(self._subwords)\n\n  def _token_to_ids(self, token):\n    """"""Convert a single token to a list of integer ids.""""""\n    # Check cache\n    cache_location = hash(token) % self._cache_size\n    cache_key, cache_value = self._token_to_ids_cache[cache_location]\n    if cache_key == token:\n      return cache_value\n\n    subwords = self._token_to_subwords(token)\n    ids = []\n    for subword in subwords:\n      if subword == _UNDERSCORE_REPLACEMENT:\n        ids.append(len(self._subwords) + ord(""_""))\n        continue\n      subword_id = self._subword_to_id.get(subword)\n      if subword_id is None:\n        # Byte-encode\n        ids.extend(self._byte_encode(subword))\n      else:\n        ids.append(subword_id)\n\n    # Update cache\n    self._token_to_ids_cache[cache_location] = (token, ids)\n\n    return ids\n\n  def _byte_encode(self, token):\n    """"""Encode a single token byte-wise into integer ids.""""""\n    # Vocab ids for all bytes follow ids for the subwords\n    offset = len(self._subwords)\n    if token == ""_"":\n      return [len(self._subwords) + ord("" "")]\n    return [i + offset for i in list(bytearray(tf.compat.as_bytes(token)))]\n\n  def _id_to_subword(self, subword_id):\n    """"""Converts a subword integer ID to a subword string.""""""\n    if subword_id < 0 or subword_id >= (self.vocab_size - 1):\n      raise ValueError(""Received id %d which is invalid. Ids must be within ""\n                       ""[0, %d)."" % (subword_id + 1, self.vocab_size))\n\n    if 0 <= subword_id < len(self._subwords):\n      # Subword\n      return self._subwords[subword_id]\n    else:\n      # Byte\n      offset = len(self._subwords)\n      subword_id -= offset\n      bytestr = bytes(bytearray([subword_id]))\n      return bytestr\n\n  def _token_to_subwords(self, token):\n    """"""Greedily split token into subwords.""""""\n    subwords = []\n\n    start = 0\n    while start < len(token):\n      subword = None\n      for end in range(\n          min(len(token), start + self._max_subword_len), start, -1):\n        candidate = token[start:end]\n        if (candidate in self._subword_to_id or\n            candidate == _UNDERSCORE_REPLACEMENT):\n          subword = candidate\n          subwords.append(subword)\n          start = end\n          break\n      # No subword match found. Consume a single (unicode) character.\n      if subword is None:\n        subwords.append(token[start])\n        start += 1\n\n    return subwords\n\n  def _init_from_list(self, subwords):\n    """"""Initializes the encoder from a list of subwords.""""""\n    subwords = [tf.compat.as_text(s) for s in subwords if s]\n    self._subwords = subwords\n    # Note that internally everything is 0-indexed. Padding is dealt with at the\n    # end of encode and the beginning of decode.\n    self._subword_to_id = {s: i for i, s in enumerate(subwords)}\n\n    # We remember the maximum length of any subword to avoid having to\n    # check arbitrarily long strings.\n    self._max_subword_len = max(\n        len(_UNDERSCORE_REPLACEMENT), max([len(s) for s in subwords] or [1]))\n\n    # Initialize the cache\n    self._cache_size = 2**20\n    self._token_to_ids_cache = [(None, None)] * self._cache_size\n\n    # Setup tokenizer\n    # Reserved tokens are all tokens that are mixed alphanum and non-alphanum.\n    reserved_tokens = set([_UNDERSCORE_REPLACEMENT])\n    for t in self._subwords:\n      if text_encoder.is_mixed_alphanum(t):\n        reserved_tokens.add(t)\n    self._tokenizer = text_encoder.Tokenizer(\n        alphanum_only=False, reserved_tokens=reserved_tokens)\n\n  @classmethod\n  def _filename(cls, filename_prefix):\n    return filename_prefix + "".subwords""\n\n  def save_to_file(self, filename_prefix):\n    """"""Save the vocabulary to a file.""""""\n    # Wrap in single quotes to make it easier to see the full subword when\n    # it has spaces and make it easier to search with ctrl+f.\n    filename = self._filename(filename_prefix)\n    lines = [""\'%s\'"" % s for s in self._subwords]\n    self._write_lines_to_file(filename, lines)\n\n  @classmethod\n  def load_from_file(cls, filename_prefix):\n    """"""Extracts list of subwords from file.""""""\n    filename = cls._filename(filename_prefix)\n    lines, _ = cls._read_lines_from_file(filename)\n    # Strip wrapping single quotes\n    vocab_list = [line[1:-1] for line in lines]\n    return cls(vocab_list=vocab_list)\n\n  @classmethod\n  def build_from_corpus(cls,\n                        corpus_generator,\n                        target_vocab_size,\n                        max_subword_length=20,\n                        max_corpus_chars=None,\n                        reserved_tokens=None):\n    """"""Builds a `SubwordTextEncoder` based on the `corpus_generator`.\n\n    Args:\n      corpus_generator: generator yielding `str`, from which subwords will be\n        constructed.\n      target_vocab_size: `int`, approximate size of the vocabulary to create.\n      max_subword_length: `int`, maximum length of a subword. Note that memory\n        and compute scale quadratically in the length of the longest token.\n      max_corpus_chars: `int`, the maximum number of characters to consume from\n        `corpus_generator` for the purposes of building the subword vocabulary.\n      reserved_tokens: `list<str>`, list of tokens that will always be treated\n        as whole tokens and not split up. Note that these must contain a mix of\n        alphanumeric and non-alphanumeric characters (e.g. ""<EOS>"") and not end\n        in an underscore.\n\n    Returns:\n      `SubwordTextEncoder`.\n    """"""\n    reserved_tokens = reserved_tokens or []\n    _validate_build_arguments(\n        max_subword_length=max_subword_length,\n        reserved_tokens=reserved_tokens,\n        target_vocab_size=target_vocab_size)\n    token_counts = _token_counts_from_generator(\n        generator=corpus_generator,\n        max_chars=max_corpus_chars,\n        reserved_tokens=reserved_tokens)\n\n    # Binary search on the minimum token count to build a vocabulary with\n    # approximately the right size\n    def _binary_search(min_token_count, max_token_count):\n      """"""Binary search min_token_count to build SubwordTextEncoder vocab.""""""\n      candidate_min = (min_token_count + max_token_count) // 2\n      logging.info(""SubwordTextEncoder build: trying min_token_count %d"",\n                   candidate_min)\n      encoder = cls._build_from_token_counts(\n          token_counts=token_counts,\n          min_token_count=candidate_min,\n          reserved_tokens=reserved_tokens,\n          num_iterations=4,\n          max_subword_length=max_subword_length)\n      vocab_size = encoder.vocab_size\n\n      # Being within 1% of the target vocab size is ok\n      target_achieved = (\n          abs(vocab_size - target_vocab_size) * 100 < target_vocab_size)\n      if (target_achieved or min_token_count >= max_token_count or\n          candidate_min <= 1):\n        # Search complete\n        return encoder\n\n      # Recurse\n      if vocab_size > target_vocab_size:\n        next_encoder = _binary_search(candidate_min + 1, max_token_count)\n      else:\n        next_encoder = _binary_search(min_token_count, candidate_min - 1)\n\n      # Return the one that\'s closest to the target_vocab_size\n      if (abs(vocab_size - target_vocab_size) <\n          abs(next_encoder.vocab_size - target_vocab_size)):\n        return encoder\n      else:\n        return next_encoder\n\n    # Get min and max token counts.\n    min_token_count = max(min(token_counts.values()), 1)\n    max_token_count = max(token_counts.values())\n\n    # Another option could be to do a binary search over *ranks* of the tokens.\n    return _binary_search(min_token_count, max_token_count)\n\n  @classmethod\n  def _build_from_token_counts(cls, token_counts, min_token_count,\n                               reserved_tokens, num_iterations,\n                               max_subword_length):\n    # Start with subwords initialized to only reserved_tokens\n    subwords = list(reserved_tokens)\n\n    for _ in range(num_iterations):\n      encoder = cls(vocab_list=subwords)\n      subword_counts = collections.defaultdict(int)\n      for token, count in six.iteritems(token_counts):\n        start_idx = 0\n        for subword in encoder._token_to_subwords(token):  # pylint: disable=protected-access\n          last_idx = min(len(token), start_idx + max_subword_length)\n          for end_idx in range(start_idx + 1, last_idx + 1):\n            candidate_subword = token[start_idx:end_idx]\n            subword_counts[candidate_subword] += count\n          start_idx += len(subword)\n\n      # Group subword candidates by length and filter bad candidates\n      len_to_subwords = [set() for _ in range(max_subword_length + 1)]\n      for subword, count in six.iteritems(subword_counts):\n        if count < min_token_count:\n          continue\n        # Skip single bytes because they\'re always in the vocab\n        if len(tf.compat.as_bytes(subword)) <= 1:\n          continue\n        len_to_subwords[len(subword)].add(subword)\n\n      # Consider subword candidates by descending length so that if a longer\n      # subword is accepted, its prefixes can have their counts decremented.\n      candidate_subwords = []\n      for subword_len in reversed(range(max_subword_length + 1)):\n        for subword in len_to_subwords[subword_len]:\n          count = subword_counts[subword]\n          if count < min_token_count:\n            continue\n          candidate_subwords.append((count, subword))\n          # Decrement prefix counts\n          for end_idx in range(1, subword_len):\n            subword_counts[subword[:end_idx]] -= count\n\n      # Sort subwords by count in descending order, keeping reserved_tokens as\n      # the beginning.\n      candidate_subwords.sort(reverse=True)\n      subwords = reserved_tokens + [s for _, s in candidate_subwords]\n\n    return cls(vocab_list=subwords)\n\n\ndef _token_counts_from_generator(generator, max_chars, reserved_tokens):\n  """"""Builds token counts from generator.""""""\n  reserved_tokens = list(reserved_tokens) + [_UNDERSCORE_REPLACEMENT]\n  tokenizer = text_encoder.Tokenizer(\n      alphanum_only=False, reserved_tokens=reserved_tokens)\n  num_chars = 0\n  token_counts = collections.defaultdict(int)\n  for s in generator:\n    s = tf.compat.as_text(s)\n    if max_chars and (num_chars + len(s)) >= max_chars:\n      s = s[:(max_chars - num_chars)]\n    tokens = tokenizer.tokenize(s)\n    tokens = _prepare_tokens_for_encode(tokens)\n    for t in tokens:\n      token_counts[t] += 1\n    if max_chars:\n      num_chars += len(s)\n      if num_chars > max_chars:\n        break\n  return token_counts\n\n\ndef _validate_build_arguments(max_subword_length, reserved_tokens,\n                              target_vocab_size):\n  """"""Validate arguments for SubwordTextEncoder.build_from_corpus.""""""\n  if max_subword_length <= 0:\n    raise ValueError(\n        ""max_subword_length must be > 0. Note that memory and compute for ""\n        ""building the vocabulary scale quadratically in the length of the ""\n        ""longest token."")\n  for t in reserved_tokens:\n    if t.endswith(""_"") or not text_encoder.is_mixed_alphanum(t):\n      raise ValueError(\n          ""Reserved tokens must not end with _ and they must contain a mix ""\n          ""of alphanumeric and non-alphanumeric characters. For example, ""\n          ""\'<EOS>\'."")\n  # Minimum vocab size = bytes + pad + 1\n  minimum_vocab_size = text_encoder.NUM_BYTES + 1 + 1\n  if target_vocab_size < minimum_vocab_size:\n    raise ValueError(""target_vocab_size must be >= %d. Got %d"" %\n                     (minimum_vocab_size, target_vocab_size))\n\n\ndef _trim_underscore(token):\n  if token.endswith(""_""):\n    return token[:-1]\n  return token\n\n\ndef _trim_underscore_and_tell(token):\n  if token.endswith(""_""):\n    return token[:-1], True\n  return token, False\n\n\ndef _escape(s):\n  return s.replace(""_"", _UNDERSCORE_REPLACEMENT)\n\n\ndef _unescape(s):\n  return s.replace(_UNDERSCORE_REPLACEMENT, ""_"")\n\n\ndef _prepare_tokens_for_encode(tokens):\n  """"""Prepare tokens for encoding.\n\n  Tokens followed by a single space have ""_"" appended and the single space token\n  is dropped.\n\n  If a token is _UNDERSCORE_REPLACEMENT, it is broken up into 2 tokens.\n\n  Args:\n    tokens: `list<str>`, tokens to prepare.\n\n  Returns:\n    `list<str>` prepared tokens.\n  """"""\n  prepared_tokens = []\n\n  def _prepare_token(t, next_t):\n    skip_next = False\n    t = _escape(t)\n    # If next token is a single space, add _ suffix to token and skip the\n    # empty space.\n    if next_t == "" "":\n      t += ""_""\n      skip_next = True\n    return t, skip_next\n\n  next_tokens = tokens[1:] + [None]\n  skip_single_token = False\n  for token, next_token in zip(tokens, next_tokens):\n    if skip_single_token:\n      skip_single_token = False\n      continue\n\n    # If the user-supplied string contains the underscore replacement string,\n    # break it into 2 tokens and encode those separately.\n    if token == _UNDERSCORE_REPLACEMENT:\n      t1, t2 = _UNDERSCORE_REPLACEMENT[:2], _UNDERSCORE_REPLACEMENT[2:]\n      t1, _ = _prepare_token(t1, None)\n      t2, _ = _prepare_token(t2, next_token)\n      prepared_tokens.append(t1)\n      prepared_tokens.append(t2)\n      continue\n\n    token, skip_single_token = _prepare_token(token, next_token)\n    prepared_tokens.append(token)\n  return prepared_tokens\n'"
tensorflow_datasets/core/features/text/subword_text_encoder_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""Tests for tensorflow_datasets.core.features.text.subword_text_encoder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\n\nfrom absl.testing import parameterized\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.features.text import subword_text_encoder\nfrom tensorflow_datasets.core.features.text import text_encoder\nfrom tensorflow_datasets.core.utils import py_utils\n\nTEST_DATA_DIR = os.path.join(py_utils.tfds_dir(), \'testing\', \'test_data\')\n\n\nclass SubwordTextEncoderTest(parameterized.TestCase, testing.TestCase):\n\n  def setUp(self):\n    super(SubwordTextEncoderTest, self).setUp()\n    # Vocab ids will be (offset for pad=0):\n    #                  1       2       3      4      5\n    self.vocab_list = [\'foo_\', \'bar_\', \'foo\', \'bar\', \'<EOS>\']\n    self.encoder = subword_text_encoder.SubwordTextEncoder(\n        vocab_list=self.vocab_list)\n\n  def test_vocab_size(self):\n    # Bytes + pad + subwords\n    self.assertEqual((256 + 1 + len(self.vocab_list)), self.encoder.vocab_size)\n\n  @parameterized.parameters(\n      (\'foo bar\', [1, 4]),\n      (\'foobar foo bar<EOS>bar\', [3, 2, 1, 4, 5, 4]),\n      # Respects whitespace\n      (\'bar <EOS>bar\', [2, 5, 4]),\n      (\'bar <EOS> bar\', [2, 5, 38, 4]),\n      (\'bar<EOS> bar\', [4, 5, 38, 4]),\n      # Invertible even with oov, respecting underscores and backslashes\n      (\'a_b!\', [103, 101, 104, 39]),\n      (\'foo \\\\bar_!\', [3, 38, 98, 4, 101, 39]),\n      (\'foo \\\\\\\\bar_!\', [3, 38, 98, 98, 4, 101, 39]),\n      (\'hello world!\', None),\n      (\'foo_ bar\', None),\n      (\'foo _ bar\', None),\n      (\'foo _bar\', None),\n      (\'hello_world\', None),\n      (\'hello_ world\', None),\n      (\'hello _ world\', None),\n      (\'hello _world\', None),\n      (\'_\', None),\n      # Test that the underscore replacement string is unharmed\n      (\'\\\\&undsc\', None),\n      # Unicode encoded as bytes but decoded back to unicode character\n      (\'\xe4\xbd\xa0\', [234, 195, 166]),\n  )\n  def test_encode_decode(self, text, expected_ids):\n    ids = self.encoder.encode(text)\n    # Test ids match if ids provided\n    if expected_ids:\n      self.assertEqual(expected_ids, ids)\n    # Test invertibility\n    self.assertEqual(tf.compat.as_text(text), self.encoder.decode(ids))\n\n  def test_bad_bytes(self):\n    valid_unicode = \'\xe4\xbd\xa0\'\n    bad_bytes = [220 + len(self.vocab_list) + 1]\n    bad_ids = self.encoder.encode(\'\xe4\xbd\xa0\') + bad_bytes\n    text = self.encoder.decode(bad_ids)\n    # Valid unicode character preserved\n    self.assertEqual(valid_unicode, text[0])\n    # Invalid byte converted to unknown character\n    self.assertEqual(\'\\uFFFD\', text[1])\n\n  def test_vocab_file(self):\n    vocab_file = os.path.join(self.get_temp_dir(), \'vocab\')\n    self.encoder.save_to_file(vocab_file)\n    encoder = subword_text_encoder.SubwordTextEncoder.load_from_file(vocab_file)\n    self.assertEqual(encoder.subwords, self.vocab_list)\n\n\nclass SubwordTextEncoderBuildTest(testing.TestCase):\n\n  def test_build(self):\n    text_gen = lorem_ipsum_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300)\n    # Created some subwords\n    self.assertGreater(encoder.vocab_size, text_encoder.NUM_BYTES + 1)\n\n    base_encoder = subword_text_encoder.SubwordTextEncoder(vocab_list=[])\n    for line in text_gen():\n      # Invertible\n      encoded = encoder.encode(line)\n      self.assertEqual(line, encoder.decode(encoded))\n      # Shorter than base\n      if len(line) > 2:\n        self.assertLess(len(encoded), len(base_encoder.encode(line)))\n\n  def test_build_with_unicode(self):\n    text_gen = lorem_ipsum_zh_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300)\n    # Created some subwords\n    self.assertGreater(encoder.vocab_size, text_encoder.NUM_BYTES + 1)\n\n    base_encoder = subword_text_encoder.SubwordTextEncoder(vocab_list=[])\n    for line in text_gen():\n      # Invertible\n      encoded = encoder.encode(line)\n      self.assertEqual(line, encoder.decode(encoded))\n      # Shorter than base\n      if len(line) > 2:\n        self.assertLess(len(encoded), len(base_encoder.encode(line)))\n\n  def test_max_subword_length(self):\n    text_gen = lorem_ipsum_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300, max_subword_length=1)\n    # Created no subwords because there are no unicode characters in lorem ipsum\n    # and single byte subwords are skipped because all bytes are in the vocab by\n    # default.\n    self.assertEqual(encoder.vocab_size, text_encoder.NUM_BYTES + 1)\n    self.assertEqual(len(encoder.subwords), 0)\n\n    # Not the case when there are unicode characters\n    text_gen = lorem_ipsum_zh_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300, max_subword_length=1)\n    self.assertGreater(encoder.vocab_size, text_encoder.NUM_BYTES + 1)\n    self.assertGreater(len(encoder.subwords), 0)\n\n  def test_max_chars(self):\n    text_gen = lorem_ipsum_zh_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300, max_corpus_chars=1)\n    self.assertGreater(encoder.vocab_size, text_encoder.NUM_BYTES + 1)\n    self.assertEqual(1, len(encoder.subwords))\n    first_letter = next(lorem_ipsum_zh_generator())[0]\n    self.assertEqual(first_letter, encoder.subwords[0])\n\n  def test_reserved_tokens(self):\n    text_gen = lorem_ipsum_generator\n    build_fn = subword_text_encoder.SubwordTextEncoder.build_from_corpus\n    encoder = build_fn(text_gen(), 300, reserved_tokens=[\'<EOS>\', \'<EOD>\'])\n    self.assertEqual(2, encoder.encode(\'Lorem<EOD>\')[-1])\n    self.assertEqual(2, encoder.encode(\'Lorem<EOD>a\')[-2])\n    self.assertEqual(2, encoder.encode(\'Lorem<EOD>{\')[-2])\n    self.assertEqual(2, encoder.encode(\'Lorem<EOD> \')[-2])\n    self.assertEqual(\'<EOS> <EOD>\', encoder.decode([1, 78, 2]))\n    self.assertEqual([\'<EOS>\', \'<EOD>\'], encoder.subwords[:2])\n\n\ndef _yield_lines_from_file(txt_file):\n  with tf.io.gfile.GFile(txt_file, \'rb\') as f:\n    for line in f:\n      yield tf.compat.as_text(line)\n\n\ndef lorem_ipsum_generator():\n  txt_file = os.path.join(TEST_DATA_DIR, \'lorem_ipsum.txt\')\n  return _yield_lines_from_file(txt_file)\n\n\ndef lorem_ipsum_zh_generator():\n  txt_file = os.path.join(TEST_DATA_DIR, \'lorem_ipsum_zh.txt\')\n  return _yield_lines_from_file(txt_file)\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/core/features/text/text_encoder.py,17,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""TextEncoders convert between text and integers.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport hashlib\nimport json\nimport re\n\nimport six\nimport tensorflow.compat.v2 as tf\nfrom tensorflow_datasets.core.utils import py_utils\n\n\ndef _re_compile(pattern):\n  return re.compile(pattern, flags=re.UNICODE)  # pytype: disable=wrong-keyword-args\n\n\nNUM_BYTES = 2**8\nALPHANUM_REGEX = _re_compile(r""\\W+"")\nALL_REGEX = _re_compile(r""(\\W+)"")\n\n\n\n\nclass TextEncoderConfig(object):\n  """"""Configuration for `tfds.features.Text`.""""""\n\n  def __init__(self, encoder=None, encoder_cls=None, vocab_size=None,\n               name=None):\n    if encoder:\n      if (encoder_cls or vocab_size):\n        raise ValueError(""If encoder is provided, encoder_cls and ""\n                         ""vocab_size must be None"")\n      encoder_cls = type(encoder)\n      vocab_size = encoder.vocab_size\n    else:\n      if encoder_cls is ByteTextEncoder:\n        encoder = encoder_cls()\n\n    self.encoder = encoder\n    self.encoder_cls = encoder_cls\n    self.vocab_size = vocab_size\n    self.name = name\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass TextEncoder(object):\n  """"""Abstract base class for converting between text and integers.\n\n  **A note on padding**:\n\n    Because text data is typically variable length and nearly always requires\n    padding during training, ID 0 is always reserved for padding. To accommodate\n    this, all `TextEncoder`s behave in certain ways:\n\n    * `encode`: never returns id 0 (all ids are 1+)\n    * `decode`: drops 0 in the input ids\n    * `vocab_size`: includes ID 0\n\n    New subclasses should be careful to match this behavior.\n  """"""\n\n  @abc.abstractmethod\n  def encode(self, s):\n    """"""Encodes text into a list of integers.""""""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def decode(self, ids):\n    """"""Decodes a list of integers into text.""""""\n    raise NotImplementedError\n\n  @abc.abstractproperty\n  def vocab_size(self):\n    """"""Size of the vocabulary. Decode produces ints [1, vocab_size).""""""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def save_to_file(self, filename_prefix):\n    """"""Store to file. Inverse of load_from_file.""""""\n    raise NotImplementedError\n\n  @py_utils.abstractclassmethod\n  def load_from_file(cls, filename_prefix):  # pylint: disable=no-self-argument\n    """"""Load from file. Inverse of save_to_file.""""""\n    raise NotImplementedError\n\n  @classmethod\n  def _write_lines_to_file(cls, filename, lines, metadata_dict=None):\n    """"""Writes lines to file prepended by header and metadata.""""""\n    write_lines_to_file(cls.__name__, filename, lines, metadata_dict)\n\n  @classmethod\n  def _read_lines_from_file(cls, filename):\n    return read_lines_from_file(cls.__name__, filename)\n\n  def __repr__(self):\n    return ""<%s vocab_size=%d>"" % (type(self).__name__, self.vocab_size)\n\n\nclass ByteTextEncoder(TextEncoder):\n  """"""Byte-encodes text.""""""\n\n  def __init__(self, additional_tokens=None):\n    """"""Constructs ByteTextEncoder.\n\n    Args:\n      additional_tokens: `list<str>`, list of additional tokens. These will be\n        assigned vocab ids `[1, 1+len(additional_tokens)]`. Useful for things\n        like ""end-of-string"" tokens (e.g. ""<EOS>"").\n    """"""\n    self._additional_tokens, self._additional_tokens_re = (\n        _prepare_reserved_tokens(additional_tokens))\n    # Note that internally everything is 0-indexed. Padding is dealt with at the\n    # end of encode and the beginning of decode.\n    self._additional_token_to_id = dict(\n        zip(self._additional_tokens, range(len(self._additional_tokens))))\n\n  def encode(self, s):\n    if not self.additional_tokens:\n      return pad_incr(list(bytearray(tf.compat.as_bytes(s))))\n\n    # Handle additional tokens\n    s = tf.compat.as_text(s)\n    ids = []\n    for substr in self._additional_tokens_re.split(s):\n      if not substr:\n        continue\n      tok_id = self._additional_token_to_id.get(substr)\n      if tok_id is None:\n        offset = len(self.additional_tokens)\n        tok_ids = [i + offset for i in\n                   list(bytearray(tf.compat.as_bytes(substr)))]\n      else:\n        tok_ids = [tok_id]\n      ids.extend(tok_ids)\n\n    return pad_incr(ids)\n\n  def decode(self, ids):\n    ids = pad_decr(ids)\n    if not self.additional_tokens:\n      return tf.compat.as_text(bytes(bytearray(ids)))\n\n    # Handle additional tokens\n    # First pass picks out the additional tokens\n    tmp_decoded = []\n    for byte_id in ids:\n      is_additional_token = byte_id < len(self.additional_tokens)\n      if is_additional_token:\n        tmp_decoded.append(self.additional_tokens[byte_id])\n      else:\n        # Leave these as ints so that we can contiguously decode bytes\n        # afterwards\n        tmp_decoded.append(byte_id - len(self.additional_tokens))\n\n    # Second pass to decode contiguous bytes\n    strs = []\n    i = 0\n    while i < len(tmp_decoded):\n      el = tmp_decoded[i]\n      if isinstance(el, six.string_types):\n        strs.append(el)\n        i += 1\n      else:\n        # Decode contiguous bytes\n        byte_ids = []\n        while i < len(tmp_decoded):\n          b = tmp_decoded[i]\n          if isinstance(b, int):\n            byte_ids.append(b)\n            i += 1\n          else:\n            break\n        strs.append(bytes(bytearray(byte_ids)).decode(""utf-8"", ""replace""))\n    return """".join(strs)\n\n  @property\n  def vocab_size(self):\n    # Plus 1 for pad\n    return len(self.additional_tokens) + NUM_BYTES + 1\n\n  @property\n  def additional_tokens(self):\n    return self._additional_tokens\n\n  @classmethod\n  def _filename(cls, filename_prefix):\n    return filename_prefix + "".bytes""\n\n  def save_to_file(self, filename_prefix):\n    self._write_lines_to_file(\n        self._filename(filename_prefix), self.additional_tokens)\n\n  @classmethod\n  def load_from_file(cls, filename_prefix):\n    lines, _ = cls._read_lines_from_file(cls._filename(filename_prefix))\n    return cls(additional_tokens=lines)\n\n\nclass TokenTextEncoder(TextEncoder):\n  r""""""TextEncoder backed by a list of tokens.\n\n  Tokenization splits on (and drops) non-alphanumeric characters with\n  regex ""\\W+"".\n  """"""\n\n  def __init__(self,\n               vocab_list,\n               oov_buckets=1,\n               oov_token=""UNK"",\n               lowercase=False,\n               tokenizer=None,\n               strip_vocab=True,\n               decode_token_separator="" ""):\n    """"""Constructs a TokenTextEncoder.\n\n    To load from a file saved with `TokenTextEncoder.save_to_file`, use\n    `TokenTextEncoder.load_from_file`.\n\n    Args:\n      vocab_list: `list<str>`, list of tokens.\n      oov_buckets: `int`, the number of `int`s to reserve for OOV hash buckets.\n        Tokens that are OOV will be hash-modded into a OOV bucket in `encode`.\n      oov_token: `str`, the string to use for OOV ids in `decode`.\n      lowercase: `bool`, whether to make all text and tokens lowercase.\n      tokenizer: `Tokenizer`, responsible for converting incoming text into a\n        list of tokens.\n      strip_vocab: `bool`, whether to strip whitespace from the beginning and\n        end of elements of `vocab_list`.\n      decode_token_separator: `str`, the string used to separate tokens when\n        decoding.\n    """"""\n    self._vocab_list = [tf.compat.as_text(el) for el in vocab_list]\n    if strip_vocab:\n      self._vocab_list = [el.strip() for el in self._vocab_list]\n    self._lowercase = lowercase\n    if self._lowercase:\n      self._vocab_list = [t.lower() for t in self._vocab_list]\n    # Note that internally everything is 0-indexed. Padding is dealt with at the\n    # end of encode and the beginning of decode.\n    self._token_to_id = dict(\n        zip(self._vocab_list, range(len(self._vocab_list))))\n    self._oov_buckets = oov_buckets\n    self._oov_token = tf.compat.as_text(oov_token)\n\n    # Reserved tokens are all tokens that are mixed alphanum and non-alphanum.\n    reserved_tokens = [t for t in self._vocab_list if is_mixed_alphanum(t)]\n    self._tokenizer = (tokenizer or Tokenizer(reserved_tokens=reserved_tokens))\n    self._user_defined_tokenizer = tokenizer\n\n    self._decode_token_separator = decode_token_separator\n\n  def encode(self, s):\n    s = tf.compat.as_text(s)\n    if self.lowercase:\n      s = s.lower()\n    ids = []\n    for token in self._tokenizer.tokenize(s):\n      int_id = self._token_to_id.get(token, -1)\n      if int_id < 0:\n        int_id = self._oov_bucket(token)\n        if int_id is None:\n          raise ValueError(""Out of vocabulary token %s"" % token)\n      ids.append(int_id)\n\n    # Increment for pad id 0\n    return pad_incr(ids)\n\n  def decode(self, ids):\n    ids = pad_decr(ids)\n\n    tokens = []\n    for int_id in ids:\n      if int_id < len(self._vocab_list):\n        tokens.append(self._vocab_list[int_id])\n      else:\n        tokens.append(self._oov_token)\n    return self._decode_token_separator.join(tokens)\n\n  @property\n  def vocab_size(self):\n    # Plus 1 for pad\n    return len(self._vocab_list) + self._oov_buckets + 1\n\n  @property\n  def tokens(self):\n    return list(self._vocab_list)\n\n  @property\n  def oov_token(self):\n    return self._oov_token\n\n  @property\n  def lowercase(self):\n    return self._lowercase\n\n  @property\n  def tokenizer(self):\n    return self._tokenizer\n\n  def _oov_bucket(self, token):\n    if self._oov_buckets <= 0:\n      return None\n    if self._oov_buckets == 1:\n      return len(self._vocab_list)\n    hash_val = int(hashlib.md5(tf.compat.as_bytes(token)).hexdigest(), 16)\n    return len(self._vocab_list) + hash_val % self._oov_buckets\n\n  @classmethod\n  def _filename(cls, filename_prefix):\n    return filename_prefix + "".tokens""\n\n  def save_to_file(self, filename_prefix):\n    filename = self._filename(filename_prefix)\n    kwargs = {\n        ""oov_buckets"": self._oov_buckets,\n        ""lowercase"": self._lowercase,\n        ""oov_token"": self._oov_token,\n    }\n    if self._user_defined_tokenizer is not None:\n      self._tokenizer.save_to_file(filename)\n      kwargs[""has_tokenizer""] = True\n    self._write_lines_to_file(filename, self._vocab_list, kwargs)\n\n  @classmethod\n  def load_from_file(cls, filename_prefix):\n    filename = cls._filename(filename_prefix)\n    vocab_lines, kwargs = cls._read_lines_from_file(filename)\n    has_tokenizer = kwargs.pop(""has_tokenizer"", False)\n    if has_tokenizer:\n      kwargs[""tokenizer""] = Tokenizer.load_from_file(filename)\n    return cls(vocab_list=vocab_lines, **kwargs)\n\n\nclass Tokenizer(object):\n  """"""Splits a string into tokens, and joins them back.""""""\n\n  def __init__(self, alphanum_only=True, reserved_tokens=None):\n    """"""Constructs a Tokenizer.\n\n    Note that the Tokenizer is invertible if `alphanum_only=False`.\n    i.e. `s == t.join(t.tokenize(s))`.\n\n    Args:\n      alphanum_only: `bool`, if `True`, only parse out alphanumeric tokens\n        (non-alphanumeric characters are dropped);\n        otherwise, keep all characters (individual tokens will still be either\n        all alphanumeric or all non-alphanumeric).\n      reserved_tokens: `list<str>`, a list of strings that, if any are in `s`,\n        will be preserved as whole tokens, even if they contain mixed\n        alphanumeric/non-alphanumeric characters.\n    """"""\n    self._alphanum_only = alphanum_only\n    reserved_tokens, self._reserved_tokens_re = _prepare_reserved_tokens(\n        reserved_tokens)\n    self._reserved_tokens = set(reserved_tokens)\n\n  @property\n  def alphanum_only(self):\n    return self._alphanum_only\n\n  @property\n  def reserved_tokens(self):\n    return self._reserved_tokens\n\n  def tokenize(self, s):\n    """"""Splits a string into tokens.""""""\n    s = tf.compat.as_text(s)\n\n    if self.reserved_tokens:\n      # First split out the reserved tokens\n      substrs = self._reserved_tokens_re.split(s)\n    else:\n      substrs = [s]\n\n    toks = []\n    for substr in substrs:\n      if substr in self.reserved_tokens:\n        toks.append(substr)\n      elif self._alphanum_only:\n        toks.extend(ALPHANUM_REGEX.split(substr))\n      else:\n        toks.extend(ALL_REGEX.split(substr))\n\n    # Filter out empty strings\n    toks = [t for t in toks if t]\n    return toks\n\n  def join(self, tokens):\n    """"""Joins tokens into a string.""""""\n    if self._alphanum_only:\n      return "" "".join(tokens)\n    else:\n      # Fully invertible\n      return """".join(tokens)\n\n  @classmethod\n  def _filename(cls, filename_prefix):\n    return filename_prefix + "".tokenizer""\n\n  def save_to_file(self, filename_prefix):\n    filename = self._filename(filename_prefix)\n    kwargs = {\n        ""reserved_tokens"": list(self._reserved_tokens),\n        ""alphanum_only"": self._alphanum_only\n    }\n    write_lines_to_file(type(self).__name__, filename, [], kwargs)\n\n  @classmethod\n  def load_from_file(cls, filename_prefix):\n    filename = cls._filename(filename_prefix)\n    _, kwargs = read_lines_from_file(cls.__name__, filename)\n    return cls(**kwargs)\n\n\ndef pad_decr(ids):\n  """"""Strip ID 0 and decrement ids by 1.""""""\n  if len(ids) < 1:\n    return list(ids)\n  if not any(ids):\n    return []  # all padding.\n  idx = -1\n  while not ids[idx]:\n    idx -= 1\n  if idx == -1:\n    ids = ids  # pylint: disable=self-assigning-variable\n  else:\n    ids = ids[:idx + 1]\n  return [i - 1 for i in ids]\n\n\ndef pad_incr(ids):\n  """"""Add 1 to ids to account for pad.""""""\n  return [i + 1 for i in ids]\n\n\ndef _prepare_reserved_tokens(reserved_tokens):\n  """"""Prepare reserved tokens and a regex for splitting them out of strings.""""""\n  reserved_tokens = [tf.compat.as_text(tok) for tok in reserved_tokens or []]\n  dups = _find_duplicates(reserved_tokens)\n  if dups:\n    raise ValueError(""Duplicates found in tokens: %s"" % dups)\n  reserved_tokens_re = _make_reserved_tokens_re(reserved_tokens)\n  return reserved_tokens, reserved_tokens_re\n\n\ndef _re_escape(s):\n  """"""Escape regex control characters.""""""\n  escaped = re.sub(r""[(){}\\[\\].*?|^$\\\\+-]"", r""\\\\\\g<0>"", s)\n  return escaped\n\n\ndef _make_reserved_tokens_re(reserved_tokens):\n  """"""Constructs compiled regex to parse out reserved tokens.""""""\n  if not reserved_tokens:\n    return None\n  escaped_tokens = [_re_escape(rt) for rt in reserved_tokens]\n  pattern = ""(%s)"" % ""|"".join(escaped_tokens)\n  reserved_tokens_re = _re_compile(pattern)\n  return reserved_tokens_re\n\n\ndef _find_duplicates(els):\n  seen = set()\n  dups = []\n  for x in els:\n    if x in seen:\n      dups.append(x)\n    else:\n      seen.add(x)\n  return dups\n\n\ndef is_mixed_alphanum(token):\n  return len([s for s in ALL_REGEX.split(token) if s]) > 1\n\n\n_HEADER_PREFIX = ""### ""\n_METADATA_PREFIX = ""### Metadata: ""\n\n\ndef write_lines_to_file(cls_name, filename, lines, metadata_dict):\n  """"""Writes lines to file prepended by header and metadata.""""""\n  metadata_dict = metadata_dict or {}\n  header_line = ""%s%s"" % (_HEADER_PREFIX, cls_name)\n  metadata_line = ""%s%s"" % (_METADATA_PREFIX,\n                            json.dumps(metadata_dict, sort_keys=True))\n  with tf.io.gfile.GFile(filename, ""wb"") as f:\n    for line in [header_line, metadata_line]:\n      f.write(tf.compat.as_bytes(line))\n      f.write(tf.compat.as_bytes(""\\n""))\n    if lines:\n      f.write(tf.compat.as_bytes(""\\n"".join(lines)))\n      f.write(tf.compat.as_bytes(""\\n""))\n\n\ndef read_lines_from_file(cls_name, filename):\n  """"""Read lines from file, parsing out header and metadata.""""""\n  with tf.io.gfile.GFile(filename, ""rb"") as f:\n    lines = [tf.compat.as_text(line)[:-1] for line in f]\n  header_line = ""%s%s"" % (_HEADER_PREFIX, cls_name)\n  if lines[0] != header_line:\n    raise ValueError(""File {fname} does not seem to have been created from ""\n                     ""{name}.save_to_file."".format(\n                         fname=filename, name=cls_name))\n  metadata_dict = json.loads(lines[1][len(_METADATA_PREFIX):])\n  return lines[2:], metadata_dict\n'"
tensorflow_datasets/core/features/text/text_encoder_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n# coding=utf-8\n""""""Tests for tensorflow_datasets.core.features.text.text_encoder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\n\nfrom absl.testing import parameterized\nimport numpy as np\nfrom tensorflow_datasets import testing\nfrom tensorflow_datasets.core.features.text import text_encoder\n\nZH_HELLO = \'\xe4\xbd\xa0\xe5\xa5\xbd \'\nEN_HELLO = \'hello \'\n\n\nclass TextEncoderTest(testing.TestCase):\n\n  def test_pad_decr(self):\n    self.assertEqual([2, 1, 0], text_encoder.pad_decr([3, 2, 1]))\n    self.assertEqual([2, 1, 0], text_encoder.pad_decr([3, 2, 1, 0, 0, 0]))\n    self.assertEqual([-1, 2, 1, 0], text_encoder.pad_decr([0, 3, 2, 1, 0, 0]))\n    self.assertEqual([], text_encoder.pad_decr([]))\n    self.assertEqual([], text_encoder.pad_decr(np.array([])))\n\n  def test_pad_incr(self):\n    self.assertEqual([4, 3, 2], text_encoder.pad_incr([3, 2, 1]))\n    self.assertEqual([4, 3, 2, 1], text_encoder.pad_incr([3, 2, 1, 0]))\n\n  def test_is_mixed_alphanum(self):\n    self.assertFalse(text_encoder.is_mixed_alphanum(\'hi\'))\n    self.assertFalse(text_encoder.is_mixed_alphanum(ZH_HELLO[:-1]))\n    self.assertTrue(text_encoder.is_mixed_alphanum(\'hi.\'))\n    self.assertTrue(text_encoder.is_mixed_alphanum(\'hi.bye\'))\n    self.assertTrue(text_encoder.is_mixed_alphanum(\'hi \'))\n    self.assertTrue(text_encoder.is_mixed_alphanum(ZH_HELLO))\n\n\nclass ByteTextEncoderTest(parameterized.TestCase, testing.TestCase):\n  # Incremented for pad\n  ZH_HELLO_IDS = [i + 1 for i in [228, 189, 160, 229, 165, 189, 32]]\n  EN_HELLO_IDS = [i + 1 for i in [104, 101, 108, 108, 111, 32]]\n\n  def test_encode_decode(self):\n    encoder = text_encoder.ByteTextEncoder()\n    self.assertEqual(self.ZH_HELLO_IDS, encoder.encode(ZH_HELLO))\n    self.assertEqual(self.EN_HELLO_IDS, encoder.encode(EN_HELLO))\n    self.assertEqual(self.EN_HELLO_IDS, encoder.encode(\'hello \'))\n    self.assertEqual(EN_HELLO, encoder.decode(self.EN_HELLO_IDS))\n    self.assertEqual(ZH_HELLO, encoder.decode(self.ZH_HELLO_IDS))\n    self.assertEqual(text_encoder.NUM_BYTES + 1, encoder.vocab_size)\n\n  def test_additional_tokens(self):\n    # One with non-alphanumeric chars, one uppercase, one lowercase\n    additional_tokens = [\'<EOS>\', \'FOO\', \'bar\']\n    encoder = text_encoder.ByteTextEncoder(additional_tokens=additional_tokens)\n    # Without additional tokens\n    hello_ids = [i + len(additional_tokens) for i in self.ZH_HELLO_IDS]\n    self.assertEqual(hello_ids, encoder.encode(ZH_HELLO))\n    # With additional tokens\n    text_additional = \'%s %s%s%s\' % (additional_tokens[0], ZH_HELLO,\n                                     additional_tokens[1], additional_tokens[2])\n    expected_ids = [1, 32 + 1 + len(additional_tokens)] + hello_ids + [2, 3]\n    self.assertEqual(expected_ids,\n                     encoder.encode(text_additional))\n    self.assertEqual(text_additional, encoder.decode(expected_ids))\n    self.assertEqual(text_encoder.NUM_BYTES + 1 + len(additional_tokens),\n                     encoder.vocab_size)\n\n  @parameterized.parameters(\n      ([\'<EOS>\', \'FOO\', \'bar\'],),\n      ([],),\n  )\n  def test_file_backed(self, additional_tokens):\n    encoder = text_encoder.ByteTextEncoder(additional_tokens=additional_tokens)\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      vocab_fname = os.path.join(tmp_dir, \'vocab\')\n      encoder.save_to_file(vocab_fname)\n\n      file_backed_encoder = text_encoder.ByteTextEncoder.load_from_file(\n          vocab_fname)\n      self.assertEqual(encoder.vocab_size, file_backed_encoder.vocab_size)\n      self.assertEqual(encoder.additional_tokens,\n                       file_backed_encoder.additional_tokens)\n\n\nclass TokenTextEncoderTest(testing.TestCase):\n\n  def test_encode_decode(self):\n    encoder = text_encoder.TokenTextEncoder(\n        vocab_list=[\'hi\', \'bye\', ZH_HELLO])\n    ids = [i + 1 for i in [0, 1, 2, 0]]\n    self.assertEqual(ids, encoder.encode(\'hi  bye %s hi\' % ZH_HELLO))\n    self.assertEqual(\'hi bye %shi\' % ZH_HELLO, encoder.decode(ids))\n\n  def test_oov(self):\n    encoder = text_encoder.TokenTextEncoder(\n        vocab_list=[\'hi\', \'bye\', ZH_HELLO],\n        oov_buckets=1,\n        oov_token=\'UNK\')\n    ids = [i + 1 for i in [0, 3, 3, 1]]\n    self.assertEqual(ids, encoder.encode(\'hi boo foo bye\'))\n    self.assertEqual(\'hi UNK UNK bye\', encoder.decode(ids))\n    self.assertEqual(5, encoder.vocab_size)\n\n  def test_multiple_oov(self):\n    encoder = text_encoder.TokenTextEncoder(\n        vocab_list=[\'hi\', \'bye\', ZH_HELLO],\n        oov_buckets=2,\n        oov_token=\'UNK\')\n    encoded = encoder.encode(\'hi boo zoo too foo bye\')\n    self.assertEqual(1, encoded[0])\n    self.assertEqual(2, encoded[-1])\n    self.assertIn(4, encoded)\n    self.assertIn(5, encoded)\n    self.assertEqual(6, encoder.vocab_size)\n    self.assertEqual(\'hi UNK UNK bye\', encoder.decode([1, 4, 5, 2]))\n\n  def test_tokenization(self):\n    encoder = text_encoder.TokenTextEncoder(vocab_list=[\'hi\', \'bye\', ZH_HELLO])\n    text = \'hi<<>><<>foo!^* bar && bye (%s hi)\' % ZH_HELLO\n    self.assertEqual([\'hi\', \'foo\', \'bar\', \'bye\',\n                      ZH_HELLO.strip(), \'hi\'],\n                     text_encoder.Tokenizer().tokenize(text))\n    self.assertEqual([i + 1 for i in [0, 3, 3, 1, 2, 0]], encoder.encode(text))\n\n  def test_file_backed(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      vocab_fname = os.path.join(tmp_dir, \'vocab\')\n      encoder = text_encoder.TokenTextEncoder(\n          vocab_list=[\'hi\', \'bye\', ZH_HELLO])\n      encoder.save_to_file(vocab_fname)\n      file_backed_encoder = text_encoder.TokenTextEncoder.load_from_file(\n          vocab_fname)\n      self.assertEqual(encoder.tokens, file_backed_encoder.tokens)\n\n  def test_file_backed_with_args(self):\n    with testing.tmp_dir(self.get_temp_dir()) as tmp_dir:\n      # Set all the args to non-default values, including Tokenizer\n      tokenizer = text_encoder.Tokenizer(\n          reserved_tokens=[\'<FOOBAR>\'], alphanum_only=False)\n      encoder = text_encoder.TokenTextEncoder(\n          vocab_list=[\'hi\', \'bye\', ZH_HELLO],\n          lowercase=True,\n          oov_buckets=2,\n          oov_token=\'ZOO\',\n          tokenizer=tokenizer)\n\n      vocab_fname = os.path.join(tmp_dir, \'vocab\')\n      encoder.save_to_file(vocab_fname)\n\n      file_backed_encoder = text_encoder.TokenTextEncoder.load_from_file(\n          vocab_fname)\n      self.assertEqual(encoder.tokens, file_backed_encoder.tokens)\n      self.assertEqual(encoder.vocab_size, file_backed_encoder.vocab_size)\n      self.assertEqual(encoder.lowercase, file_backed_encoder.lowercase)\n      self.assertEqual(encoder.oov_token, file_backed_encoder.oov_token)\n      self.assertEqual(encoder.tokenizer.alphanum_only,\n                       file_backed_encoder.tokenizer.alphanum_only)\n      self.assertEqual(encoder.tokenizer.reserved_tokens,\n                       file_backed_encoder.tokenizer.reserved_tokens)\n\n  def test_mixedalphanum_tokens(self):\n    mixed_tokens = [\'<EOS>\', \'zoo!\', \'!foo\']\n    vocab_list = mixed_tokens + [\'hi\', \'bye\', ZH_HELLO]\n\n    encoder = text_encoder.TokenTextEncoder(vocab_list=vocab_list)\n\n    # No mixed tokens\n    text = \'hi<<>><<>foo!^* bar && bye (%s hi)\' % ZH_HELLO\n    # hi=3, foo=OOV, bar=OOV, bye=4, ZH_HELLO=5, hi=3\n    text_ids = [i + 1 for i in [3, 6, 6, 4, 5, 3]]\n    self.assertEqual(text_ids, encoder.encode(text))\n\n    # With mixed tokens\n    text = \'hi<<>><<>foo!<EOS>^* barzoo! FOO && bye (%s hi)\' % ZH_HELLO\n    # hi=3, foo=OOV, <EOS>=0, bar=OOV, zoo!=1, FOO=OOV, bye=4, ZH_HELLO=5, hi=3\n    text_ids = [i + 1 for i in [3, 6, 0, 6, 1, 6, 4, 5, 3]]\n    self.assertEqual(text_ids, encoder.encode(text))\n\n  def test_lowercase(self):\n    mixed_tokens = [\'<EOS>\', \'zoo!\']\n    vocab_list = mixed_tokens + [\'hi\', \'bye\', ZH_HELLO]\n    encoder = text_encoder.TokenTextEncoder(\n        vocab_list=vocab_list, lowercase=True)\n    # No mixed tokens\n    self.assertEqual([3, 4, 3], encoder.encode(\'hi byE HI!\'))\n    # With mixed tokens\n    self.assertEqual([3, 1, 4, 2, 3], encoder.encode(\'hi<EOS>byE Zoo! HI!\'))\n\n  def test_with_tokenizer(self):\n\n    class DummyTokenizer(object):\n\n      def tokenize(self, s):\n        del s\n        return [\'hi\', \'bye\']\n\n    tokenizer = DummyTokenizer()\n    vocab_list = [\'hi\', \'bye\', ZH_HELLO]\n    encoder = text_encoder.TokenTextEncoder(\n        vocab_list=vocab_list, tokenizer=tokenizer)\n    # Ensure it uses the passed tokenizer and not the default\n    self.assertEqual([1, 2], encoder.encode(\'zoo foo\'))\n\n\nclass TokenizeTest(parameterized.TestCase, testing.TestCase):\n\n  def test_default(self):\n    text = \'hi<<>><<>foo!^* bar &&  bye (%s hi)\' % ZH_HELLO\n    self.assertEqual([\'hi\', \'foo\', \'bar\', \'bye\', ZH_HELLO.strip(), \'hi\'],\n                     text_encoder.Tokenizer().tokenize(text))\n\n  def test_with_nonalphanum(self):\n    text = \'hi world<<>><<>foo!^* bar &&  bye (%s hi)\' % ZH_HELLO\n    tokens = [\n        \'hi\', \' \', \'world\', \'<<>><<>\', \'foo\', \'!^* \', \'bar\', \' &&  \', \'bye\',\n        \' (\', ZH_HELLO.strip(), \'  \', \'hi\', \')\'\n    ]\n    tokenizer = text_encoder.Tokenizer(alphanum_only=False)\n    self.assertEqual(\n        tokens, tokenizer.tokenize(text))\n    self.assertEqual(\n        text, tokenizer.join(tokenizer.tokenize(text)))\n\n  @parameterized.parameters(\n      # Single Space at at beginning\n      (\' hello world\', [\' \', \'hello\', \' \', \'world\']),\n      (\' !hello world\', [\' !\', \'hello\', \' \', \'world\']),\n      # Single space at end\n      (\'hello world \', [\'hello\', \' \', \'world\', \' \']),\n      (\'hello world! \', [\'hello\', \' \', \'world\', \'! \']),\n      # Double space at beginning\n      (\'  hello world\', [\'  \', \'hello\', \' \', \'world\']),\n      (\'  !hello world\', [\'  !\', \'hello\', \' \', \'world\']),\n      # Double space in middle\n      (\'hello  world\', [\'hello\', \'  \', \'world\']),\n      (\'hello!  world\', [\'hello\', \'!  \', \'world\']),\n      (\'hello  !world\', [\'hello\', \'  !\', \'world\']),\n  )\n  def test_whitespace(self, s, exp):\n    tokenizer = text_encoder.Tokenizer(alphanum_only=False)\n    self.assertEqual(exp, tokenizer.tokenize(s))\n    self.assertEqual(s, tokenizer.join(tokenizer.tokenize(s)))\n\n  def test_reserved_tokens(self):\n    text = \'hello worldbar bar foozoo zoo FOO<EOS>\'\n    tokens = [\'hello\', \' \', \'world\', \'bar\', \' \', \'bar\', \' \', \'foozoo\',\n              \' \', \'zoo\', \' \', \'FOO\', \'<EOS>\']\n    tokenizer = text_encoder.Tokenizer(alphanum_only=False,\n                                       reserved_tokens=[\'<EOS>\', \'FOO\', \'bar\'])\n    self.assertEqual(tokens, tokenizer.tokenize(text))\n    self.assertEqual(text, tokenizer.join(tokenizer.tokenize(text)))\n\n  def test_reserved_tokens_with_regex_chars(self):\n    text = r\'hello worldba\\)r bar foozoo zoo FOO|<EOS>\'\n    tokens = [\'hello\', \' \', \'world\', r\'ba\\)r\', \' \', \'bar\', \' \', \'foozoo\',\n              \' \', \'zoo\', \' \', \'FOO|\', \'<EOS>\']\n    tokenizer = text_encoder.Tokenizer(\n        alphanum_only=False,\n        reserved_tokens=[\'<EOS>\', \'FOO|\', r\'ba\\)r\'])\n    self.assertEqual(tokens, tokenizer.tokenize(text))\n    self.assertEqual(text, tokenizer.join(tokenizer.tokenize(text)))\n\n\nif __name__ == \'__main__\':\n  testing.test_main()\n'"
tensorflow_datasets/testing/test_data/fake_examples/svhn_cropped/generate_data.py,0,"b'# coding=utf-8\n# Copyright 2020 The TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Generate fake data for SVHN.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport scipy.io\n\nfor split_name, num_examples in [\n    (\'train\', 3),\n    (\'test\', 2),\n    (\'extra\', 1),\n]:\n  img_shape = (32, 32, 3, num_examples)\n  scipy.io.savemat(\'{}_32x32.mat\'.format(split_name), {\n      \'X\': np.random.randint(255, size=img_shape, dtype=np.uint8),\n      \'y\': np.random.randint(1, 10, size=(num_examples, 1)),\n  })\n'"
