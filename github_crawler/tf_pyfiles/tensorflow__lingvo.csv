file_path,api_count,code
lingvo/compat.py,4,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""The compatible tensorflow library.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v1 as tf1\nfrom tensorflow.compat.v2 import *  # pylint:disable=wildcard-import, g-bad-import-order\n\n# Import absl.flags and absl.logging to overwrite the Tensorflow ones.\n# This is the intended behavior in TF 2.0.\n# pylint:disable=g-bad-import-order, unused-import, g-import-not-at-top\nfrom absl import flags\nfrom absl import logging\n# pylint: disable=g-direct-tensorflow-import\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.framework import function as _function_lib\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import check_ops\nfrom tensorflow.python.ops import embedding_ops\nfrom tensorflow.python.ops import functional_ops\nfrom tensorflow.python.ops import inplace_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.util import module_wrapper as _module_wrapper\n\nfrom tensorflow.python.platform import app\n# pylint: enable=g-direct-tensorflow-import\n# pylint: enable=unused-import, g-bad-import-order, g-import-not-at-top\n\nif tf1.executing_eagerly():\n  logging.warning(""Lingvo does not support eager execution yet. Please disable ""\n                  ""eager execution with tf.compat.v1.disable_eager_execution() ""\n                  ""or proceed at your own risk."")\n\n\ndef _clone_module(m):\n  """"""Shallow clone of module `m`.""""""\n  if isinstance(m, _module_wrapper.TFModuleWrapper):\n    # pylint: disable=protected-access\n    return _module_wrapper.TFModuleWrapper(\n        wrapped=_clone_module(m._tfmw_wrapped_module),\n        module_name=m._tfmw_module_name,\n        public_apis=m._tfmw_public_apis,\n        deprecation=m._tfmw_print_deprecation_warnings,\n        has_lite=m._tfmw_has_lite)\n    # pylint: enable=protected-access\n  out = type(m)(m.__name__, m.__doc__)\n  out.__dict__.update(m.__dict__)\n  return out\n\n# Aliases to a few routines lingvo libraries uses often.\nDefun = _function_lib.Defun\nWhile = functional_ops.While\nIf = functional_ops.If\nInplaceUpdate = inplace_ops.alias_inplace_update\nEmpty = inplace_ops.empty\nEmptyLike = inplace_ops.empty_like\n\n# pylint: disable=undefined-variable, used-before-assignment\n# Move this V2 symbol here to avoid being overwritten by its following V1\n# version.\nwhere_v2 = where\nwhile_loop_v2 = while_loop\n\n# Import the local V2 module to maker sure the following V1 overwritting never\n# applies to the global module and symbol.\ndata = _clone_module(data)\ngraph_util = _clone_module(graph_util)\nimage = _clone_module(image)\nio = _clone_module(io)\nlosses = _clone_module(keras.losses)\nmetrics = _clone_module(keras.metrics)\nnn = _clone_module(nn)\nsaved_model = _clone_module(saved_model)\nstrings = _clone_module(strings)\nsummary = _clone_module(summary)\ntest = _clone_module(test)\ntrain = _clone_module(train)\n# pylint: enable=undefined-variable, used-before-assignment\n\n# TF 1.x symbols used in the codebase.\n# To keep this list short, please use TF 2.x API whenever applicable.\n# Only use TF 1.x API if it has no 2.x equivalent.\n# pylint: disable=undefined-variable\nadd_to_collection = tf1.add_to_collection\nall_variables = tf1.global_variables\n# The following asserts can be directly replaced with TF2 `tf.debugging.*`\n# after TF2/eager is enabled.\nassert_integer = tf1.assert_integer\nassert_positive = tf1.assert_positive\nassert_type = tf1.assert_type\nassert_scalar = tf1.assert_scalar\nassign = tf1.assign\nassign_add = tf1.assign_add\nassign_sub = tf1.assign_sub\nAUTO_REUSE = tf1.AUTO_REUSE\ncontainer = tf1.container\ndata.Dataset = tf1.data.Dataset\ndata.TFRecordDataset = tf1.data.TFRecordDataset\ndevice = tf1.device\nDimension = tf1.Dimension\ndisable_eager_execution = tf1.disable_eager_execution\ndiv = tf1.div\nenable_eager_execution = tf1.enable_eager_execution\nfloor_div = tf1.floor_div\nget_collection = tf1.get_collection\nget_collection_ref = tf1.get_collection_ref\nget_default_graph = tf1.get_default_graph\nget_local_variable = tf1.get_local_variable\nget_seed = tf1.get_seed\nget_variable = tf1.get_variable\nget_variable_scope = tf1.get_variable_scope\nglobal_variables = tf1.global_variables\nglobal_variables_initializer = tf1.global_variables_initializer\ngradients = tf1.gradients\ngraph_util.convert_variables_to_constants = (\n    tf1.graph_util.convert_variables_to_constants)\ngraph_util.extract_sub_graph = tf1.graph_util.extract_sub_graph\nGraphDef = tf1.GraphDef\nGraphKeys = tf1.GraphKeys\nGraphOptions = tf1.GraphOptions\ngroup = tf1.group\nimage.resize_bilinear = tf1.image.resize_bilinear\nimage.resize_images = tf1.image.resize_images\nimage.resize_nearest_neighbor = tf1.image.resize_nearest_neighbor\ninitialize_all_tables = tf1.initialize_all_tables\nInteractiveSession = tf1.InteractiveSession\nio.tf_record_iterator = tf1.io.tf_record_iterator\nlayers = tf1.layers\nlocal_variables_initializer = tf1.local_variables_initializer\nlosses.absolute_difference = tf1.losses.absolute_difference\nlosses.add_loss = tf1.losses.add_loss\nlosses.compute_weighted_loss = tf1.losses.compute_weighted_loss\nlosses.get_regularization_loss = tf1.losses.get_regularization_loss\nlosses.huber_loss = tf1.losses.huber_loss\nlosses.mean_squared_error = tf1.losses.mean_squared_error\nlosses.Reduction.MEAN = tf1.losses.Reduction.MEAN\nlosses.Reduction.SUM = tf1.losses.Reduction.SUM\nlosses.sigmoid_cross_entropy = tf1.losses.sigmoid_cross_entropy\nlosses.softmax_cross_entropy = tf1.losses.softmax_cross_entropy\nlosses.sparse_softmax_cross_entropy = (tf1.losses.sparse_softmax_cross_entropy)\nmake_template = tf1.make_template\nmetrics.accuracy = tf1.metrics.accuracy\nmetrics.auc = tf1.metrics.auc\nmetrics.precision = tf1.metrics.precision\nmetrics.recall = tf1.metrics.recall\nmoving_average_variables = tf1.moving_average_variables\nmultinomial = tf1.multinomial\nname_scope = tf1.name_scope\nOptimizerOptions = tf1.OptimizerOptions\nplaceholder = tf1.placeholder\nplaceholder_with_default = tf1.placeholder_with_default\nPrint = tf1.Print\npy_func = tf1.py_func\npython_io = tf1.python_io\nreport_uninitialized_variables = tf1.report_uninitialized_variables\nreset_default_graph = tf1.reset_default_graph\nresource_loader = tf1.resource_loader\nRunMetadata = tf1.RunMetadata\nRunOptions = tf1.RunOptions\nsaved_model.build_signature_def = tf1.saved_model.build_signature_def\nsaved_model.Builder = tf1.saved_model.Builder\nsaved_model.load = tf1.saved_model.load\nsaved_model.loader = tf1.saved_model.loader\nsaved_model.signature_constants = tf1.saved_model.signature_constants\nsaved_model.simple_save = tf1.saved_model.simple_save\nsaved_model.tag_constants = tf1.saved_model.tag_constants\nsaved_model.utils = tf1.saved_model.utils\nSession = tf1.Session\nsparse_to_dense = tf1.sparse_to_dense\nstring_split = tf1.string_split\nstrings.reduce_join = tf1.reduce_join\nstrings.split = tf1.strings.split\nSummary = tf1.Summary\nif tf1.summary is not None:\n  # tf.summary are not supported on TPU so we sometimes set tf.summary to None\n  # to prohibit the direct use of it.\n  # It is safe to skip copying tf.summary members in such cases.\n  summary.audio = tf1.summary.audio\n  summary.FileWriter = tf1.summary.FileWriter\n  summary.histogram = tf1.summary.histogram\n  summary.image = tf1.summary.image\n  summary.merge = tf1.summary.merge\n  summary.merge_all = tf1.summary.merge_all\n  summary.scalar = tf1.summary.scalar\n  summary.Summary = tf1.summary.Summary\n  summary.Summary.FromString = tf1.summary.Summary.FromString\ntables_initializer = tf1.tables_initializer\ntest.compute_gradient_error = tf1.test.compute_gradient_error\ntest.get_temp_dir = tf1.test.get_temp_dir\ntest.mock = tf1.test.mock\ntpu = tf1.tpu\ntrain.AdadeltaOptimizer = tf1.train.AdadeltaOptimizer\ntrain.AdagradOptimizer = tf1.train.AdagradOptimizer\ntrain.AdamOptimizer = tf1.train.AdamOptimizer\ntrain.export_meta_graph = tf1.train.export_meta_graph\ntrain.get_or_create_global_step = tf1.train.get_or_create_global_step\ntrain.get_global_step = tf1.train.get_global_step\ntrain.GradientDescentOptimizer = tf1.train.GradientDescentOptimizer\ntrain.MomentumOptimizer = tf1.train.MomentumOptimizer\ntrain.MonitoredTrainingSession = tf1.train.MonitoredTrainingSession\ntrain.NewCheckpointReader = tf1.train.NewCheckpointReader\ntrain.Optimizer = tf1.train.Optimizer\ntrain.RMSPropOptimizer = tf1.train.RMSPropOptimizer\ntrain.Saver = tf1.train.Saver\ntrain.SaverDef = tf1.train.SaverDef\ntrain.summary_iterator = tf1.train.summary_iterator\ntrainable_variables = tf1.trainable_variables\nVariable = tf1.Variable\nvariables_initializer = tf1.variables_initializer\nVariableScope = tf1.VariableScope\nvariable_scope = tf1.variable_scope\nwhere = tf1.where\nwhile_loop = tf1.while_loop\nwrap_function = tf1.wrap_function\n\n# Explicit 1.x symbol import.\ndata.make_initializable_iterator = dataset_ops.make_initializable_iterator\ndata.make_one_shot_iterator = dataset_ops.make_one_shot_iterator\n# For `nn.embedding_lookup`, v2 doesn\'t have the arg \'partition_strategy\' in\n# the API, and uses \'partition_strategy=""div""\' by default;\n# while v1 uses \'partition_strategy=""mod""\' by default. Keep this for now.\nnn.embedding_lookup = embedding_ops.embedding_lookup\n# pylint: enable=undefined-variable\n'"
