file_path,api_count,code
build_docs.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tool to generate open source api_docs for tensorflow_model_optimization.\n\nTo use:\n\n  1. Install the tensorflow docs package, which is only compatible with Python\n\n    python3 -m pip install git+https://github.com/tensorflow/docs\n\n  2. Install TensorFlow Model Optimization. The API docs are generated from\n  `tfmot` from the import of the tfmot package below, based on what is exposed\n  under\n   https://github.com/tensorflow/model-optimization/tree/master/tensorflow_model_optimization/python/core/api.\n\n    See https://www.tensorflow.org/model_optimization/guide/install.\n\n  3. Run build_docs.py.\n\n    python3 build_docs.py --output_dir=/tmp/model_optimization_api\n\n  4. View the generated markdown files on a viewer. One option is to fork\n     https://github.com/tensorflow/model-optimization/, push a change that\n     copies the files to tensorflow_model_optimization/g3doc, and then\n     view the files on Github.\n\nNote:\n  If duplicate or spurious docs are generated (e.g. internal names), consider\n  blacklisting them via the `private_map` argument below.\n""""""\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom absl import app\nfrom absl import flags\nfrom tensorflow_docs.api_generator import generate_lib\n\nimport tensorflow_model_optimization as tfmot\n\nflags.DEFINE_string(""output_dir"", ""/tmp/model_optimization_api"",\n                    ""Where to output the docs"")\n\nflags.DEFINE_string(\n    ""code_url_prefix"",\n    (""https://github.com/tensorflow/model-optimization/blob/master/""\n     ""tensorflow_model_optimization""),\n    ""The url prefix for links to code."")\n\nflags.DEFINE_bool(""search_hints"", True,\n                  ""Include metadata search hints in the generated files"")\n\nflags.DEFINE_string(""site_path"", ""model_optimization/api_docs/python"",\n                    ""Path prefix in the _toc.yaml"")\n\nFLAGS = flags.FLAGS\n\n\ndef main(unused_argv):\n  doc_generator = generate_lib.DocGenerator(\n      root_title=""TensorFlow Model Optimization"",\n      py_modules=[(""tfmot"", tfmot)],\n      base_dir=os.path.dirname(tfmot.__file__),\n      code_url_prefix=FLAGS.code_url_prefix,\n      search_hints=FLAGS.search_hints,\n      site_path=FLAGS.site_path,\n      private_map={\n          ""tfmot.sparsity.keras"": [\n              # List of internal classes which get exposed when imported.\n              ""InputLayer"", ""custom_object_scope"", ""pruning_sched"",\n              ""pruning_wrapper"", ""absolute_import"", ""division"", ""print_function""\n          ]\n      },\n  )\n\n  doc_generator.build(output_dir=FLAGS.output_dir)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
setup.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Install tensorflow_model_optimization.""""""\nimport datetime\nimport os\nimport sys\n\nfrom setuptools import find_packages\nfrom setuptools import setup\nfrom setuptools.command.install import install as InstallCommandBase\nfrom setuptools.dist import Distribution\n\n# To enable importing version.py directly, we add its path to sys.path.\nversion_path = os.path.join(\n    os.path.dirname(__file__), \'tensorflow_model_optimization\', \'python/core\')\nsys.path.append(version_path)\nfrom version import __version__  # pylint: disable=g-import-not-at-top\n\n# TODO(alanchiao): add explicit Tensorflow requirement once Tensorflow\n# moves from a tf and tf-gpu packaging approach (where a user installs\n# one of the two) to one where a user installs the tf package and then\n# also installs the gpu package if they need gpu support. The latter allows\n# us (and our dependents) to maintain a single package instead of two.\nREQUIRED_PACKAGES = [\n    \'numpy~=1.14\',\n    \'six~=1.10\',\n    \'enum34~=1.1;python_version<""3.4""\',\n    \'dm-tree~=0.1.1\',\n]\n\nif \'--release\' in sys.argv:\n  release = True\n  sys.argv.remove(\'--release\')\nelse:\n  # Build a nightly package by default.\n  release = False\n\nif release:\n  project_name = \'tensorflow-model-optimization\'\nelse:\n  # Nightly releases use date-based versioning of the form\n  # \'0.0.1.dev20180305\'\n  project_name = \'tf-model-optimization-nightly\'\n  datestring = datetime.datetime.now().strftime(\'%Y%m%d\')\n  __version__ += datestring\n\n\nclass BinaryDistribution(Distribution):\n  """"""This class is needed in order to create OS specific wheels.""""""\n\n  def has_ext_modules(self):\n    return False\n\nsetup(\n    name=project_name,\n    version=__version__,\n    description=\'A suite of tools that users, both novice and advanced\'\n    \' can use to optimize machine learning models for deployment\'\n    \' and execution.\',\n    author=\'Google LLC\',\n    author_email=\'no-reply@google.com\',\n    url=\'https://github.com/tensorflow/model-optimization\',\n    license=\'Apache 2.0\',\n    packages=find_packages(),\n    install_requires=REQUIRED_PACKAGES,\n    # Add in any packaged data.\n    include_package_data=True,\n    package_data={\'\': [\'*.so\']},\n    exclude_package_data={\'\': [\'BUILD\', \'*.h\', \'*.cc\']},\n    zip_safe=False,\n    distclass=BinaryDistribution,\n    cmdclass={\n        \'pip_pkg\': InstallCommandBase,\n    },\n    classifiers=[\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n    ],\n    keywords=\'tensorflow model optimization machine learning\',\n)\n'"
tensorflow_model_optimization/__init__.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Init module for TensorFlow Model Optimization Python API.\n\n```\nimport tensorflow_model_optimization as tfmot\n```\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\n# We need to put some imports inside a function call below, and the function\n# call needs to come before the *actual* imports that populate the\n# tensorflow_model_optimization namespace. Hence, we disable this lint check\n# throughout the file.\n#\n# pylint: disable=g-import-not-at-top\n\n\n# Ensure TensorFlow is importable and its version is sufficiently recent. This\n# needs to happen before anything else, since the imports below will try to\n# import tensorflow, too.\ndef _ensure_tf_install():  # pylint: disable=g-statement-before-imports\n  """"""Attempt to import tensorflow, and ensure its version is sufficient.\n\n  Raises:\n    ImportError: if either tensorflow is not importable or its version is\n    inadequate.\n  """"""\n  try:\n    import tensorflow as tf\n  except ImportError:\n    # Print more informative error message, then reraise.\n    print(\n        \'\\n\\nFailed to import TensorFlow. Please note that TensorFlow is not \'\n        \'installed by default when you install TensorFlow Model Optimization. This \'\n        \'is so that users can decide whether to install the GPU-enabled \'\n        \'TensorFlow package. To use TensorFlow Model Optimization, please install \'\n        \'the most recent version of TensorFlow, by following instructions at \'\n        \'https://tensorflow.org/install.\\n\\n\')\n    raise\n\n  import distutils.version\n\n  #\n  # Update this whenever we need to depend on a newer TensorFlow release.\n  #\n  required_tensorflow_version = \'1.14.0\'\n\n  if (distutils.version.LooseVersion(tf.version.VERSION) <\n      distutils.version.LooseVersion(required_tensorflow_version)):\n    raise ImportError(\n        \'This version of TensorFlow Model Optimization requires TensorFlow \'\n        \'version >= {required}; Detected an installation of version {present}. \'\n        \'Please upgrade TensorFlow to proceed.\'.format(\n            required=required_tensorflow_version, present=tf.__version__))\n\n\n_ensure_tf_install()\n\n\nimport inspect as _inspect\nimport os as _os\nimport sys as _sys\n\n\n# To ensure users only access the expected public API, the API structure is\n# created in the `api` directory. Import all api modules.\n# pylint: disable=wildcard-import\nfrom tensorflow_model_optimization.python.core.api import *\n# pylint: enable=wildcard-import\n\n\n# Use sparsity module to fetch the path for the `api` directory.\n# This handles all techniques, not just sparsity.\n_API_MODULE = sparsity  # pylint: disable=undefined-variable\n# Returns $(install_dir)/tensorflow_model_optimization/api\n_sparsity_api_dir = _os.path.dirname(\n    _os.path.dirname(_inspect.getfile(_API_MODULE)))\n\n# Add the `api` directory to `__path__` so that `from * import module` works.\n_current_module = _sys.modules[__name__]\nif not hasattr(_current_module, \'__path__\'):\n  __path__ = [_sparsity_api_dir]\nelif _os.path.dirname(_inspect.getfile(_API_MODULE)) not in __path__:\n  __path__.append(_sparsity_api_dir)\n\n\n# Delete python module so that users only access the code using the API path\n# rather than using the code directory structure.\n# This will disallow usage such as `tfmot.python.core.sparsity.keras`.\n# pylint: disable=undefined-variable\ntry:\n  del python\nexcept NameError:\n  pass\n# pylint: enable=undefined-variable\n'"
tensorflow_model_optimization/python/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/version.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Define TensorFlow Model Optimization version information.""""""\n\n# We follow Semantic Versioning (https://semver.org/)\n_MAJOR_VERSION = \'0\'\n_MINOR_VERSION = \'3\'\n_PATCH_VERSION = \'0\'\n\n# When building releases, we can update this value on the release branch to\n# reflect the current release candidate (\'rc0\', \'rc1\') or, finally, the official\n# stable release (indicated by `_VERSION_SUFFIX = \'\'`). Outside the context of a\n# release branch, the current version is by default assumed to be a\n# \'development\' version, labeled \'dev\'.\n_VERSION_SUFFIX = \'dev\'\n\n# Example, \'0.4.0-dev\'\n__version__ = \'.\'.join([\n    _MAJOR_VERSION,\n    _MINOR_VERSION,\n    _PATCH_VERSION,\n])\nif _VERSION_SUFFIX:\n  __version__ = \'{}-{}\'.format(__version__, _VERSION_SUFFIX)\n'"
tensorflow_model_optimization/python/examples/__init__.py,0,b''
tensorflow_model_optimization/python/core/api/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Import API modules for Tensorflow Model Optimization.""""""\nfrom tensorflow_model_optimization.python.core.api import quantization\nfrom tensorflow_model_optimization.python.core.api import sparsity\n'"
tensorflow_model_optimization/python/core/clustering/__init__.py,0,b''
tensorflow_model_optimization/python/core/internal/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/keras/__init__.py,0,b''
tensorflow_model_optimization/python/core/keras/compat.py,4,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Functions for TF 1.X and 2.X compatibility.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef assign(ref, value, name=None):\n  if hasattr(tf, \'assign\'):\n    return tf.assign(ref, value, name=name)\n  else:\n    return ref.assign(value, name=name)\n\n\ndef initialize_variables(testcase):\n  """"""Handle global variable initialization in TF 1.X.\n\n  Arguments:\n    testcase: instance of tf.test.TestCase\n  """"""\n  if hasattr(tf, \'global_variables_initializer\') and not tf.executing_eagerly():\n    testcase.evaluate(tf.global_variables_initializer())\n\n\ndef is_v1_apis():\n  return hasattr(tf, \'assign\')\n'"
tensorflow_model_optimization/python/core/keras/test_utils.py,12,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Test utilities for generating, saving, and evaluating models.""""""\n# TODO(tf-mot): dedup and migrate to testing/ directory.\n\nimport numpy as np\nimport tensorflow as tf\n\nl = tf.keras.layers\n\n\nclass ModelCompare(object):\n  """"""Mixin with helper functions for model comparison.\n\n  Needs to be used with tf.test.TestCase.\n\n  Note the following test only trainable_weights.\n  """"""\n\n  def _assert_weights_same_objects(self, model1, model2):\n    self.assertEqual(\n        len(model1.trainable_weights), len(model2.trainable_weights))\n    for w1, w2 in zip(model1.trainable_weights, model2.trainable_weights):\n      self.assertEqual(id(w1), id(w2))\n\n  def _assert_weights_different_objects(self, model1, model2):\n    self.assertEqual(\n        len(model1.trainable_weights), len(model2.trainable_weights))\n    for w1, w2 in zip(model1.trainable_weights, model2.trainable_weights):\n      self.assertNotEqual(id(w1), id(w2))\n\n  def _assert_weights_same_values(self, model1, model2):\n    self.assertEqual(\n        len(model1.trainable_weights), len(model2.trainable_weights))\n\n    model1_weights = tf.keras.backend.batch_get_value(model1.trainable_weights)\n    model2_weights = tf.keras.backend.batch_get_value(model2.trainable_weights)\n    for w1, w2 in zip(model1_weights, model2_weights):\n      self.assertAllClose(w1, w2)\n\n  def _assert_weights_different_values(self, model1, model2):\n    self.assertEqual(\n        len(model1.trainable_weights), len(model2.trainable_weights))\n\n    model1_weights = tf.keras.backend.batch_get_value(model1.trainable_weights)\n    model2_weights = tf.keras.backend.batch_get_value(model2.trainable_weights)\n    for w1, w2 in zip(model1_weights, model2_weights):\n      self.assertNotAllClose(w1, w2)\n\n\ndef build_simple_dense_model():\n  return tf.keras.Sequential([\n      l.Dense(8, activation=\'relu\', input_shape=(10,)),\n      l.Dense(5, activation=\'softmax\')\n  ])\n\n\ndef get_preprocessed_mnist_data(img_rows=28,\n                                img_cols=28,\n                                num_classes=10,\n                                is_quantized_model=False):\n  """"""Get data for mnist training and evaluation.""""""\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n  if tf.keras.backend.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\n  else:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\n  if not is_quantized_model:\n    x_train = x_train.astype(\'float32\')\n    x_test = x_test.astype(\'float32\')\n    x_train /= 255\n    x_test /= 255\n\n  # convert class vectors to binary class matrices\n  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n  return (x_train, y_train), (x_test, y_test), input_shape\n\n\ndef eval_mnist_tflite(model_path=None, model_content=None, is_quantized=False):\n  """"""Evaluate mnist in TFLite for accuracy.""""""\n  interpreter = tf.lite.Interpreter(\n      model_path=model_path, model_content=model_content)\n  interpreter.allocate_tensors()\n  input_index = interpreter.get_input_details()[0][\'index\']\n  output_index = interpreter.get_output_details()[0][\'index\']\n\n  _, test_data, _ = get_preprocessed_mnist_data(is_quantized_model=is_quantized)\n  x_test, y_test = test_data\n\n  total_seen = 0\n  num_correct = 0\n\n  for img, label in zip(x_test, y_test):\n    inp = img.reshape((1, 28, 28, 1))\n    total_seen += 1\n    interpreter.set_tensor(input_index, inp)\n    interpreter.invoke()\n    predictions = interpreter.get_tensor(output_index)\n    if np.argmax(predictions) == np.argmax(label):\n      num_correct += 1\n\n    if total_seen % 1000 == 0:\n      print(\'Accuracy after %i images: %f\' %\n            (total_seen, float(num_correct) / float(total_seen)))\n\n  return float(num_correct) / float(total_seen)\n'"
tensorflow_model_optimization/python/core/quantization/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/sparsity/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/examples/quantization/__init__.py,0,b''
tensorflow_model_optimization/python/core/api/quantization/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Module containing code for quantization.""""""\nfrom tensorflow_model_optimization.python.core.api.quantization import keras\n'"
tensorflow_model_optimization/python/core/api/sparsity/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Module containing code for sparsity.""""""\nfrom tensorflow_model_optimization.python.core.api.sparsity import keras\n'"
tensorflow_model_optimization/python/core/clustering/keras/__init__.py,0,b''
tensorflow_model_optimization/python/core/clustering/keras/cluster.py,5,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Clustering API functions for Keras models.""""""\n\nfrom tensorflow import keras\nfrom tensorflow.keras import initializers\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_centroids\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster_wrapper\n\nk = keras.backend\nCustomObjectScope = keras.utils.CustomObjectScope\nLayer = keras.layers.Layer\nInputLayer = keras.layers.InputLayer\n\n\ndef cluster_scope():\n  """"""Provides a scope in which Clustered layers and models can be deserialized.\n\n  If a keras model or layer has been clustered, it needs to be within this scope\n  to be successfully deserialized.\n\n  Returns:\n      Object of type `CustomObjectScope` with clustering objects included.\n\n  Example:\n\n  ```python\n  clustered_model = cluster_weights(model, **self.params)\n  keras.models.save_model(clustered_model, keras_file)\n\n  with cluster_scope():\n    loaded_model = keras.models.load_model(keras_file)\n  ```\n  """"""\n  return CustomObjectScope(\n      {\n          \'ClusterWeights\': cluster_wrapper.ClusterWeights\n      }\n  )\n\n\ndef cluster_weights(to_cluster,\n                    number_of_clusters,\n                    cluster_centroids_init,\n                    **kwargs):\n  """"""Modify a keras layer or model to be clustered during training.\n\n  This function wraps a keras model or layer with clustering functionality\n  which clusters the layer\'s weights during training. For examples, using\n  this with number_of_clusters equals 8 will ensure that each weight tensor has\n  no more than 8 unique values.\n\n  Before passing to the clustering API, a model should already be trained and\n  show some acceptable performance on the testing/validation sets.\n\n  The function accepts either a single keras layer\n  (subclass of `keras.layers.Layer`), list of keras layers or a keras model\n  (instance of `keras.models.Model`) and handles them appropriately.\n\n  If it encounters a layer it does not know how to handle, it will throw an\n  error. While clustering an entire model, even a single unknown layer would\n  lead to an error.\n\n  Cluster a model:\n\n  ```python\n  clustering_params = {\n    \'number_of_clusters\': 8,\n    \'cluster_centroids_init\': \'density-based\'\n  }\n\n  clustered_model = cluster_weights(original_model, **clustering_params)\n  ```\n\n  Cluster a layer:\n\n  ```python\n  clustering_params = {\n    \'number_of_clusters\': 8,\n    \'cluster_centroids_init\': \'density-based\'\n  }\n\n  model = keras.Sequential([\n      layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n      cluster_weights(layers.Dense(2, activation=\'tanh\'), **clustering_params)\n  ])\n  ```\n\n  Arguments:\n      to_cluster: A single keras layer, list of keras layers, or a\n        `tf.keras.Model` instance.\n      number_of_clusters: the number of cluster centroids to form when\n        clustering a layer/model. For example, if number_of_clusters=8 then only\n        8 unique values will be used in each weight array.\n      cluster_centroids_init: how to initialize the cluster centroids.\n        Can have following values:\n          1. \'random\' : centroids are sampled using the uniform distribution\n          between the minimum and maximum weight values in a given layer\n          2. \'density-based\' : density-based sampling. First, cumulative\n          distribution function is built for weights, then y-axis is evenly\n          spaced into number_of_clusters regions. After this the corresponding x\n          values are obtained and used to initialize clusters centroids.\n          3. \'linear\' : cluster centroids are evenly spaced between the minimum\n          and maximum values of a given weight\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n        Ignored when to_cluster is not a keras layer.\n\n  Returns:\n    Layer or model modified to include clustering related metadata.\n\n  Raises:\n    ValueError: if the keras layer is unsupported, or the keras model contains\n    an unsupported layer.\n  """"""\n  if not clustering_centroids.CentroidsInitializerFactory.\\\n      init_is_supported(cluster_centroids_init):\n    raise ValueError(""cluster centroids can only be one of three values: ""\n                     ""random, density-based, linear"")\n\n  def _add_clustering_wrapper(layer):\n    if isinstance(layer, cluster_wrapper.ClusterWeights):\n      return layer\n    if isinstance(layer, InputLayer):\n      return layer.__class__.from_config(layer.get_config())\n\n    return cluster_wrapper.ClusterWeights(layer,\n                                          number_of_clusters,\n                                          cluster_centroids_init,\n                                          **kwargs)\n\n  def _wrap_list(layers):\n    output = []\n    for layer in layers:\n      output.append(_add_clustering_wrapper(layer))\n\n    return output\n\n  if isinstance(to_cluster, keras.Model):\n    return keras.models.clone_model(to_cluster,\n                                    input_tensors=None,\n                                    clone_function=_add_clustering_wrapper)\n  if isinstance(to_cluster, Layer):\n    return _add_clustering_wrapper(layer=to_cluster)\n  if isinstance(to_cluster, list):\n    return _wrap_list(to_cluster)\n\n\ndef strip_clustering(model):\n  """"""Strip clustering wrappers from the model.\n\n  Once a model has been clustered, this method can be used\n  to restore the original model with the clustered weights.\n\n  Only sequential and functional models are supported for now.\n\n  Arguments:\n      model: A `tf.keras.Model` instance with clustered layers.\n\n  Returns:\n    A keras model with clustering wrappers removed.\n\n  Raises:\n    ValueError: if the model is not a `tf.keras.Model` instance.\n    NotImplementedError: if the model is a subclass model.\n\n  Usage:\n\n  ```python\n  orig_model = tf.keras.Model(inputs, outputs)\n  clustered_model = cluster_weights(orig_model)\n  exported_model = strip_clustering(clustered_model)\n  ```\n  The exported_model and the orig_model have the same structure.\n  """"""\n  if not isinstance(model, keras.Model):\n    raise ValueError(\n        \'Expected model to be a `tf.keras.Model` instance but got: \', model)\n\n  def _strip_clustering_wrapper(layer):\n    if isinstance(layer, cluster_wrapper.ClusterWeights):\n      if not hasattr(layer.layer, \'_batch_input_shape\') and\\\n          hasattr(layer, \'_batch_input_shape\'):\n        layer.layer._batch_input_shape = layer._batch_input_shape\n\n      # We reset both arrays of weights, so that we can guarantee the correct\n      # order of newly created weights\n      layer.layer._trainable_weights = []\n      layer.layer._non_trainable_weights = []\n      for i in range(len(layer.restore)):\n        # This is why we used integers as keys\n        name, weight = layer.restore[i]\n        # In both cases we use k.batch_get_value since we need physical copies\n        # of the arrays to initialize a new tensor\n        if i in layer.gone_variables:\n          # If the variable was removed because it was clustered, we restore it\n          # by using updater we created earlier\n          new_weight_value = k.batch_get_value([weight()])[0]\n        else:\n          # If the value was not clustered(e.g. bias), we still store a valid\n          # reference to the tensor. We use this reference to get the value\n          new_weight_value = k.batch_get_value([weight])[0]\n        layer.layer.add_weight(\n            name=name,\n            shape=new_weight_value.shape,\n            initializer=initializers.Constant(new_weight_value),\n            trainable=True\n        )\n      # When all weights are filled with the values, just return the underlying\n      # layer since it is now fully autonomous from its wrapper\n      return layer.layer\n    return layer\n\n  # Just copy the model with the right callback\n  return keras.models.clone_model(model,\n                                  input_tensors=None,\n                                  clone_function=_strip_clustering_wrapper)\n'"
tensorflow_model_optimization/python/core/clustering/keras/cluster_integration_test.py,2,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""End-to-end tests for keras clustering API.""""""\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom absl.testing import parameterized\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster\n\nkeras = tf.keras\nlayers = keras.layers\ntest = tf.test\n\n\nclass ClusterIntegrationTest(test.TestCase, parameterized.TestCase):\n  """"""Integration tests for clustering.""""""\n\n  @keras_parameterized.run_all_keras_modes\n  def testValuesRemainClusteredAfterTraining(self):\n    """"""\n    Verifies that training a clustered model does not destroy the clusters.\n    """"""\n    number_of_clusters = 10\n    original_model = keras.Sequential([\n        layers.Dense(2, input_shape=(2,)),\n        layers.Dense(2),\n    ])\n\n    clustered_model = cluster.cluster_weights(\n        original_model,\n        number_of_clusters=number_of_clusters,\n        cluster_centroids_init=\'linear\'\n    )\n\n    clustered_model.compile(\n        loss=keras.losses.categorical_crossentropy,\n        optimizer=\'adam\',\n        metrics=[\'accuracy\']\n    )\n\n    def dataset_generator():\n      x_train = np.array([\n          [0, 1],\n          [2, 0],\n          [0, 3],\n          [4, 1],\n          [5, 1],\n      ])\n      y_train = np.array([\n          [0, 1],\n          [1, 0],\n          [1, 0],\n          [0, 1],\n          [0, 1],\n      ])\n      for x, y in zip(x_train, y_train):\n        yield np.array([x]), np.array([y])\n\n    clustered_model.fit_generator(dataset_generator(), steps_per_epoch=1)\n    stripped_model = cluster.strip_clustering(clustered_model)\n    weights_as_list = stripped_model.get_weights()[0].reshape(-1,).tolist()\n    unique_weights = set(weights_as_list)\n    self.assertLessEqual(len(unique_weights), number_of_clusters)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/clustering/keras/cluster_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for keras clustering API.""""""\n\nimport json\nimport tensorflow as tf\n\nfrom absl.testing import parameterized\nfrom tensorflow.python.keras import keras_parameterized\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster_wrapper\nfrom tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_registry\n\nkeras = tf.keras\nerrors_impl = tf.errors\nlayers = keras.layers\ntest = tf.test\n\n\nclass TestModel(keras.Model):\n  """"""A model subclass.""""""\n\n  def __init__(self):\n    """"""A test subclass model with one dense layer.""""""\n    super(TestModel, self).__init__(name=\'test_model\')\n    self.layer1 = keras.layers.Dense(10, activation=\'relu\')\n\n  def call(self, inputs):\n    return self.layer1(inputs)\n\n\nclass CustomClusterableLayer(layers.Dense, clusterable_layer.ClusterableLayer):\n\n  def get_clusterable_weights(self):\n    return [(\'kernel\', self.kernel)]\n\n\nclass CustomNonClusterableLayer(layers.Dense):\n  pass\n\n\nclass ClusterTest(test.TestCase, parameterized.TestCase):\n  """"""Unit tests for the cluster module.""""""\n\n  def setUp(self):\n    super(ClusterTest, self).setUp()\n\n    self.keras_clusterable_layer = layers.Dense(10)\n    self.keras_non_clusterable_layer = layers.Dropout(0.4)\n    self.keras_unsupported_layer = layers.ConvLSTM2D(2, (5, 5))  # Unsupported\n    self.custom_clusterable_layer = CustomClusterableLayer(10)\n    self.custom_non_clusterable_layer = CustomNonClusterableLayer(10)\n\n    clustering_registry.ClusteringLookupRegistry.register_new_implementation(\n        {\n            CustomClusterableLayer: {\n                \'kernel\': clustering_registry.DenseWeightsCA\n            }\n        }\n    )\n\n    self.model = keras.Sequential()\n    self.params = {\n        \'number_of_clusters\': 8,\n        \'cluster_centroids_init\': \'density-based\'\n    }\n\n  def _build_clustered_layer_model(self, layer):\n    wrapped_layer = cluster.cluster_weights(layer, **self.params)\n    self.model.add(wrapped_layer)\n    self.model.build(input_shape=(10, 1))\n\n    return wrapped_layer\n\n  def _validate_clustered_layer(self, original_layer, wrapped_layer):\n    self.assertIsInstance(wrapped_layer, cluster_wrapper.ClusterWeights)\n    self.assertEqual(original_layer, wrapped_layer.layer)\n\n  @staticmethod\n  def _count_clustered_layers(model):\n    count = 0\n    for layer in model.layers:\n      if isinstance(layer, cluster_wrapper.ClusterWeights):\n        count += 1\n    return count\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterKerasClusterableLayer(self):\n    """"""\n    Verifies that a built-in keras layer marked as clusterable is being\n    clustered correctly.\n    """"""\n    wrapped_layer = self._build_clustered_layer_model(\n        self.keras_clusterable_layer)\n\n    self._validate_clustered_layer(self.keras_clusterable_layer, wrapped_layer)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterKerasNonClusterableLayer(self):\n    """"""\n    Verifies that a built-in keras layer not marked as clusterable is\n    not being clustered.\n    """"""\n    wrapped_layer = self._build_clustered_layer_model(\n        self.keras_non_clusterable_layer)\n\n    self._validate_clustered_layer(self.keras_non_clusterable_layer,\n                                   wrapped_layer)\n    self.assertEqual([], wrapped_layer.layer.get_clusterable_weights())\n\n  def testClusterKerasUnsupportedLayer(self):\n    """"""\n    Verifies that attempting to cluster an unsupported layer raises an\n    exception.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster.cluster_weights(self.keras_unsupported_layer, **self.params)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterCustomClusterableLayer(self):\n    """"""\n    Verifies that a custom clusterable layer is being clustered correctly.\n    """"""\n    wrapped_layer = self._build_clustered_layer_model(\n        self.custom_clusterable_layer)\n\n    self._validate_clustered_layer(self.custom_clusterable_layer, wrapped_layer)\n    self.assertEqual([(\'kernel\', wrapped_layer.layer.kernel)],\n                     wrapped_layer.layer.get_clusterable_weights())\n\n  def testClusterCustomNonClusterableLayer(self):\n    """"""\n    Verifies that attempting to cluster a custom non-clusterable layer raises\n    an exception.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights(self.custom_non_clusterable_layer,\n                                     **self.params)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterSequentialModelSelectively(self):\n    """"""\n    Verifies that layers within a sequential model can be clustered\n    selectively.\n    """"""\n    clustered_model = keras.Sequential()\n    clustered_model.add(cluster.cluster_weights(self.keras_clusterable_layer, **self.params))\n    clustered_model.add(self.keras_clusterable_layer)\n    clustered_model.build(input_shape=(1, 10))\n\n    self.assertIsInstance(clustered_model.layers[0], cluster_wrapper.ClusterWeights)\n    self.assertNotIsInstance(clustered_model.layers[1], cluster_wrapper.ClusterWeights)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterFunctionalModelSelectively(self):\n    """"""\n    Verifies that layers within a functional model can be clustered\n    selectively.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = cluster.cluster_weights(layers.Dense(10), **self.params)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    clustered_model = keras.Model(inputs=[i1, i2], outputs=outputs)\n\n    self.assertIsInstance(clustered_model.layers[2], cluster_wrapper.ClusterWeights)\n    self.assertNotIsInstance(clustered_model.layers[3], cluster_wrapper.ClusterWeights)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterModelValidLayersSuccessful(self):\n    """"""\n    Verifies that clustering a sequential model results in all clusterable\n    layers within the model being clustered.\n    """"""\n    model = keras.Sequential([\n        self.keras_clusterable_layer,\n        self.keras_non_clusterable_layer,\n        self.custom_clusterable_layer\n    ])\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    clustered_model.build(input_shape=(1, 28, 28, 1))\n\n    self.assertEqual(len(model.layers), len(clustered_model.layers))\n    for layer, clustered_layer in zip(model.layers, clustered_model.layers):\n      self._validate_clustered_layer(layer, clustered_layer)\n\n  def testClusterModelUnsupportedKerasLayerRaisesError(self):\n    """"""\n    Verifies that attempting to cluster a model that contains an unsupported\n    layer raises an exception.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster.cluster_weights(\n          keras.Sequential([\n              self.keras_clusterable_layer, self.keras_non_clusterable_layer,\n              self.custom_clusterable_layer, self.keras_unsupported_layer\n          ]), **self.params)\n\n  def testClusterModelCustomNonClusterableLayerRaisesError(self):\n    """"""\n    Verifies that attempting to cluster a model that contains a custom\n    non-clusterable layer raises an exception.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster.cluster_weights(\n          keras.Sequential([\n              self.keras_clusterable_layer, self.keras_non_clusterable_layer,\n              self.custom_clusterable_layer, self.custom_non_clusterable_layer\n          ]), **self.params)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterModelDoesNotWrapAlreadyWrappedLayer(self):\n    """"""\n    Verifies that clustering a model that contains an already clustered layer\n    does not result in wrapping the clustered layer into another\n    cluster_wrapper.\n    """"""\n    model = keras.Sequential(\n        [\n            layers.Flatten(),\n            cluster.cluster_weights(layers.Dense(10), **self.params),\n        ])\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    clustered_model.build(input_shape=(10, 10, 1))\n\n    self.assertEqual(len(model.layers), len(clustered_model.layers))\n    self._validate_clustered_layer(model.layers[0], clustered_model.layers[0])\n    # Second layer is used as-is since it\'s already a clustered layer.\n    self.assertEqual(model.layers[1], clustered_model.layers[1])\n    self._validate_clustered_layer(model.layers[1].layer,\n                                   clustered_model.layers[1])\n\n  def testClusterValidLayersListSuccessful(self):\n    """"""\n    Verifies that clustering a list of layers results in all clusterable\n    layers within the list being clustered.\n    """"""\n    model_layers = [\n        self.keras_clusterable_layer,\n        self.keras_non_clusterable_layer,\n        self.custom_clusterable_layer\n    ]\n    clustered_list = cluster.cluster_weights(model_layers, **self.params)\n\n    self.assertEqual(len(model_layers), len(clustered_list))\n    for layer, clustered_layer in zip(model_layers, clustered_list):\n      self._validate_clustered_layer(layer, clustered_layer)\n\n  def testClusterSequentialModelNoInput(self):\n    """"""\n    Verifies that a sequential model without an input layer is being clustered\n    correctly.\n    """"""\n    # No InputLayer\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(self._count_clustered_layers(clustered_model), 2)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterSequentialModelWithInput(self):\n    """"""\n    Verifies that a sequential model with an input layer is being clustered\n    correctly.\n    """"""\n    # With InputLayer\n    model = keras.Sequential([\n        layers.Dense(10, input_shape=(10,)),\n        layers.Dense(10),\n    ])\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(self._count_clustered_layers(clustered_model), 2)\n\n  def testClusterSequentialModelPreservesBuiltStateNoInput(self):\n    """"""\n    Verifies that clustering a sequential model without an input layer\n    preserves the built state of the model.\n    """"""\n    # No InputLayer\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n    self.assertEqual(model.built, False)\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(model.built, False)\n\n    # Test built state is preserved across serialization\n    with cluster.cluster_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(clustered_model.to_json()))\n      self.assertEqual(loaded_model.built, False)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterSequentialModelPreservesBuiltStateWithInput(self):\n    """"""\n    Verifies that clustering a sequential model with an input layer preserves\n    the built state of the model.\n    """"""\n    # With InputLayer\n    model = keras.Sequential([\n        layers.Dense(10, input_shape=(10,)),\n        layers.Dense(10),\n    ])\n    self.assertEqual(model.built, True)\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(model.built, True)\n\n    # Test built state is preserved across serialization\n    with cluster.cluster_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(clustered_model.to_json()))\n    self.assertEqual(loaded_model.built, True)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterFunctionalModelPreservesBuiltState(self):\n    """"""\n    Verifies that clustering a functional model preserves the built state of\n    the model.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n    self.assertEqual(model.built, True)\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(model.built, True)\n\n    # Test built state preserves across serialization\n    with cluster.cluster_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(clustered_model.to_json()))\n    self.assertEqual(loaded_model.built, True)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterFunctionalModel(self):\n    """"""\n    Verifies that a functional model is being clustered correctly.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(self._count_clustered_layers(clustered_model), 3)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterFunctionalModelWithLayerReused(self):\n    """"""\n    Verifies that a layer reused within a functional model multiple times is\n    only being clustered once.\n    """"""\n    # The model reuses the Dense() layer. Make sure it\'s only clustered once.\n    inp = keras.Input(shape=(10,))\n    dense_layer = layers.Dense(10)\n    x = dense_layer(inp)\n    x = dense_layer(x)\n    model = keras.Model(inputs=[inp], outputs=[x])\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    self.assertEqual(self._count_clustered_layers(clustered_model), 1)\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterSubclassModel(self):\n    """"""\n    Verifies that attempting to cluster an instance of a subclass of\n    keras.Model raises an exception.\n    """"""\n    model = TestModel()\n    with self.assertRaises(ValueError):\n      _ = cluster.cluster_weights(model, **self.params)\n\n  @keras_parameterized.run_all_keras_modes\n  def testStripClusteringSequentialModel(self):\n    """"""\n    Verifies that stripping the clustering wrappers from a sequential model\n    produces the expected config.\n    """"""\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    self.assertEqual(self._count_clustered_layers(stripped_model), 0)\n    self.assertEqual(model.get_config(), stripped_model.get_config())\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterStrippingFunctionalModel(self):\n    """"""\n    Verifies that stripping the clustering wrappers from a functional model\n    produces the expected config.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    self.assertEqual(self._count_clustered_layers(stripped_model), 0)\n    self.assertEqual(model.get_config(), stripped_model.get_config())\n\n  @keras_parameterized.run_all_keras_modes\n  def testClusterWeightsStrippedWeights(self):\n    """"""\n    Verifies that stripping the clustering wrappers from a functional model\n    preserves the clustered weights.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    x1 = layers.BatchNormalization()(i1)\n    outputs = x1\n    model = keras.Model(inputs=[i1], outputs=outputs)\n\n    clustered_model = cluster.cluster_weights(model, **self.params)\n    cluster_weight_length = (len(clustered_model.get_weights()))\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    self.assertEqual(self._count_clustered_layers(stripped_model), 0)\n    self.assertEqual(len(stripped_model.get_weights()), cluster_weight_length)\n\n  @keras_parameterized.run_all_keras_modes\n  def testStripSelectivelyClusteredFunctionalModel(self):\n    """"""\n    Verifies that invoking strip_clustering() on a selectively clustered\n    functional model strips the clustering wrappers from the clustered layers.\n    """"""\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = cluster.cluster_weights(layers.Dense(10), **self.params)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    clustered_model = keras.Model(inputs=[i1, i2], outputs=outputs)\n\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    self.assertEqual(self._count_clustered_layers(stripped_model), 0)\n    self.assertIsInstance(stripped_model.layers[2], layers.Dense)\n\n  @keras_parameterized.run_all_keras_modes\n  def testStripSelectivelyClusteredSequentialModel(self):\n    """"""\n    Verifies that invoking strip_clustering() on a selectively clustered\n    sequential model strips the clustering wrappers from the clustered layers.\n    """"""\n    clustered_model = keras.Sequential([\n      cluster.cluster_weights(layers.Dense(10), **self.params),\n      layers.Dense(10),\n    ])\n    clustered_model.build(input_shape=(1, 10))\n\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    self.assertEqual(self._count_clustered_layers(stripped_model), 0)\n    self.assertIsInstance(stripped_model.layers[0], layers.Dense)\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Keras ClusterWeights wrapper API.""""""\n\nimport tensorflow as tf\n\nfrom tensorflow.keras import initializers\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_centroids\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_registry\n\nkeras = tf.keras\nk = keras.backend\nLayer = keras.layers.Layer\nWrapper = keras.layers.Wrapper\n\n\nclass ClusterWeights(Wrapper):\n  """"""This wrapper augments a keras layer so that the weight tensor(s) can be\n  clustered.\n\n  This wrapper implements nearest neighbor clustering algorithm. This algorithm\n  ensures that only a specified number of unique values are used in a weight\n  tensor. This allows for certain types of hardware to benefit from advanced\n  weight compression techniques and the associated reduction in model memory\n  footprint and bandwidth.\n\n  From practical standpoint this is implemented using a lookup table to hold the\n  cluster centroid values during model training. The weight array is populated\n  with \'gather\' operation so that during back propagation the gradients can be\n  calculated in a normal way. The lookup table is then adjusted using the\n  cumulative gradient values for the weights that correspond to the same\n  centroid.\n\n  The number of unique values required as well as the way cluster centroids\n  are initialized are passed in the wrapper\'s constructor.\n\n  The initial values of cluster centroids are fine-tuned during the training.\n  """"""\n\n  def __init__(self,\n               layer,\n               number_of_clusters,\n               cluster_centroids_init,\n               **kwargs):\n    if not isinstance(layer, Layer):\n      raise ValueError(\n          \'Please initialize `Cluster` layer with a \'\n          \'`Layer` instance. You passed: {input}\'.format(input=layer))\n\n    if isinstance(layer, clusterable_layer.ClusterableLayer):\n      # A user-defined custom layer\n      super(ClusterWeights, self).__init__(layer, **kwargs)\n    elif clustering_registry.ClusteringRegistry.supports(layer):\n      super(ClusterWeights, self).__init__(\n          clustering_registry.ClusteringRegistry.make_clusterable(layer),\n          **kwargs\n      )\n    else:\n      raise ValueError(\n          \'Please initialize `Cluster` with a supported layer. Layers should \'\n          \'either be a `ClusterableLayer` instance, or should be supported by \'\n          \'the ClusteringRegistry. You passed: {input}\'.format(\n              input=layer.__class__\n          )\n      )\n\n    if not isinstance(number_of_clusters, int):\n      raise ValueError(\n          ""number_of_clusters must be an integer. Given: {}"".format(\n              number_of_clusters.__class__\n          )\n      )\n\n    if number_of_clusters <= 1:\n      raise ValueError(\n          ""number_of_clusters must be greater than 1. Given: {}"".format(\n              number_of_clusters\n          )\n      )\n\n    self._track_trackable(layer, name=\'layer\')\n\n    # The way how cluster centroids will be initialized\n    self.cluster_centroids_init = cluster_centroids_init\n\n    # The number of cluster centroids\n    self.number_of_clusters = number_of_clusters\n\n    # Stores the pairs of weight names and references to their tensors\n    self.clustered_vars = []\n\n    # Stores references to class instances that implement different clustering\n    # behaviour for different shapes of objects\n    self.clustering_impl = {}\n\n    # A dictionary that stores pairs of weight names and their respective\n    # indices lookup tables\n    self.pulling_indices_tf = {}\n\n    # A dictionary that stores pairs of weight names and their respective\n    # cluster centroids lookup tables\n    self.cluster_centroids_tf = {}\n\n    # A list for restoring the original order of weights later on, see the\n    # comments in the code for usage explanations\n    self.restore = []\n\n    # setattr will remove the original weights from layer.weights array. We need\n    # to memorise the original state of the array since saving the model relies\n    # on the variables order in layer.weights rather than on values stored in\n    # e.g. kernel/bias attributes of the layer object.\n    self.gone_variables = []\n\n    # If the input shape was specified, then we need to preserve this\n    # information in the layer. If this info is not preserved, then the `built`\n    # state will not be preserved between serializations.\n    if not hasattr(self, \'_batch_input_shape\')\\\n        and hasattr(layer, \'_batch_input_shape\'):\n      self._batch_input_shape = self.layer._batch_input_shape\n\n  @staticmethod\n  def _weight_name(name):\n    """"""Extracts the weight name from the full TensorFlow variable name.\n\n    For example, returns \'kernel\' for \'dense_2/kernel:0\'.\n\n    Args:\n      name: TensorFlow variable name.\n\n    Returns:\n      Extracted weight name.\n    """"""\n    return name.split(\':\')[0].split(\'/\')[-1]\n\n  def build(self, input_shape):\n    super(ClusterWeights, self).build(input_shape)\n\n    clusterable_weights = self.layer.get_clusterable_weights()\n\n    # Map automatically assigned TF variable name (e.g. \'dense/kernel:0\') to\n    # provided human readable name (e.g. as in Dense(10).kernel)\n    clusterable_weights_to_variables = {}\n\n    for weight_name, weight in clusterable_weights:\n      # If a variable appears in this loop, then it is going to be removed from\n      # self._trainable_weights. We need to memorise what variables are going\n      # away so that later we are able to restore them. We have to do this to\n      # maintain the original order of the weights in the underlying layer.\n      # Incorrect order results in the incorrect OPs weights configurations.\n\n      # We can be sure that weight will be found in this array since the\n      # variable is either in the self._trainable_weights or in\n      # self._non_trainable_weights and self.weights is the result of\n      # concatenation of those arrays\n      original_index = self.layer.weights.index(weight)\n      self.gone_variables.append(original_index)\n\n      # Again, not sure if this is needed. Leaving for now.\n      clusterable_weights_to_variables[self._weight_name(weight.name)] =\\\n          weight_name\n\n      # Build initial cluster centroids for a given tensor. Factory returns a\n      # class and we init an object immediately\n      centroid_initializer = clustering_centroids.CentroidsInitializerFactory.\\\n          get_centroid_initializer(\n              self.cluster_centroids_init\n          )(weight, self.number_of_clusters)\n\n      cluster_centroids = centroid_initializer.get_cluster_centroids()\n\n      # Use k.batch_get_value since we need to initialize the variables with an\n      # initial value taken from a Tensor object. For each weight there is a\n      # different set of cluster centroids\n      self.cluster_centroids_tf[weight_name] = self.add_weight(\n          \'cluster_centroids_tf\',\n          shape=(self.number_of_clusters,),\n          dtype=weight.dtype,\n          trainable=True,\n          initializer=initializers.Constant(\n              value=k.batch_get_value([cluster_centroids])[0]\n          )\n      )\n\n      # There are vectorised implementations of look-ups, we use a new one for\n      # different number of dimensions.\n      clustering_impl_cls = clustering_registry.ClusteringLookupRegistry().\\\n          get_clustering_impl(self.layer, weight_name)\n      self.clustering_impl[weight_name] = clustering_impl_cls(\n          self.cluster_centroids_tf[weight_name]\n      )\n\n      # We find the nearest cluster centroids and store them so that ops can\n      # build their weights upon it. These indices are calculated once and\n      # stored forever. We use to make look-ups from self.cluster_centroids_tf\n      pulling_indices = self.clustering_impl[weight_name].\\\n          get_pulling_indices(weight)\n      self.pulling_indices_tf[weight_name] = self.add_weight(\n          \'pulling_indices_tf\',\n          shape=pulling_indices.shape,\n          dtype=tf.int32,\n          trainable=False,\n          initializer=initializers.Constant(\n              value=k.batch_get_value([pulling_indices])[0]\n          )\n      )\n\n      # We store these pairs to easily update this variables later on\n      self.clustered_vars.append((weight_name, weight))\n\n    # We use currying here to get an updater which can be triggered at any time\n    # in future and it would return the latest version of clustered weights\n    def get_updater(for_weight_name):\n      def fn():\n        return self.clustering_impl[for_weight_name].get_clustered_weight(\n            self.pulling_indices_tf[for_weight_name]\n        )\n\n      return fn\n\n    # This will allow us to restore the order of weights later\n    # This loop stores pairs of weight names and how to restore them\n\n    for ct, weight in enumerate(self.layer.weights):\n      name = self._weight_name(weight.name)\n      if ct in self.gone_variables:\n        # Again, not sure if this is needed\n        weight_name = clusterable_weights_to_variables[name]\n        self.restore.append((name, get_updater(weight_name)))\n      else:\n        self.restore.append((name, weight))\n\n  def call(self, inputs):\n    # Go through all tensors and replace them with their clustered copies.\n    for weight_name, _ in self.clustered_vars:\n      setattr(\n          self.layer, weight_name,\n          self.clustering_impl[weight_name].get_clustered_weight(\n              self.pulling_indices_tf[weight_name]\n          )\n      )\n\n    return self.layer.call(inputs)\n\n  def compute_output_shape(self, input_shape):\n    return self.layer.compute_output_shape(input_shape)\n\n  def get_config(self):\n    base_config = super(ClusterWeights, self).get_config()\n    config = {\n        \'number_of_clusters\': self.number_of_clusters,\n        \'cluster_centroids_init\': self.cluster_centroids_init,\n    }\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config, custom_objects=None):\n    config = config.copy()\n\n    number_of_clusters = config.pop(\'number_of_clusters\')\n    cluster_centroids_init = config.pop(\'cluster_centroids_init\')\n    config[\'number_of_clusters\'] = number_of_clusters\n    config[\'cluster_centroids_init\'] = cluster_centroids_init\n\n    from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top\n    layer = deserialize_layer(config.pop(\'layer\'),\n                              custom_objects=custom_objects)\n    config[\'layer\'] = layer\n\n    return cls(**config)\n\n  @property\n  def trainable(self):\n    return self.layer.trainable\n\n  @trainable.setter\n  def trainable(self, value):\n    self.layer.trainable = value\n\n  @property\n  def trainable_weights(self):\n    return self.layer.trainable_weights + self._trainable_weights\n\n  @property\n  def non_trainable_weights(self):\n    return self.layer.non_trainable_weights + self._non_trainable_weights\n\n  @property\n  def updates(self):\n    return self.layer.updates + self._updates\n\n  @property\n  def losses(self):\n    return self.layer.losses + self._losses\n\n  def get_weights(self):\n    return self.layer.get_weights()\n\n  def set_weights(self, weights):\n    self.layer.set_weights(weights)\n'"
tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper_test.py,4,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for keras ClusterWeights wrapper API.""""""\n\nimport itertools\nimport numpy as np\nimport tensorflow as tf\n\nfrom absl.testing import parameterized\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster_wrapper\nfrom tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_registry\n\nkeras = tf.keras\nerrors_impl = tf.errors\nlayers = keras.layers\ntest = tf.test\n\nlayers = keras.layers\nClusterRegistry = clustering_registry.ClusteringRegistry\nClusteringLookupRegistry = clustering_registry.ClusteringLookupRegistry\n\n\nclass NonClusterableLayer(layers.Dense):\n  """"""A custom layer that is not clusterable.""""""\n\n\nclass AlreadyClusterableLayer(layers.Dense, clusterable_layer.ClusterableLayer):\n  """"""A custom layer that is clusterable.""""""\n\n  def get_clusterable_weights(self):\n    pass\n\n\nclass ClusterWeightsTest(test.TestCase, parameterized.TestCase):\n  """"""Unit tests for the cluster_wrapper module.""""""\n\n  def testCannotBeInitializedWithNonLayerObject(self):\n    """"""\n    Verifies that ClusterWeights cannot be initialized with an object that is\n    not an instance of keras.layers.Layer.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights({\n          \'this\': \'is not a Layer instance\'\n      }, number_of_clusters=13, cluster_centroids_init=\'linear\')\n\n  def testCannotBeInitializedWithNonClusterableLayer(self):\n    """"""\n    Verifies that ClusterWeights cannot be initialized with a non-clusterable\n    custom layer.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights(NonClusterableLayer(10),\n                                     number_of_clusters=13,\n                                     cluster_centroids_init=\'linear\')\n\n  def testCanBeInitializedWithClusterableLayer(self):\n    """"""\n    Verifies that ClusterWeights can be initialized with a built-in clusterable\n    layer.\n    """"""\n    l = cluster_wrapper.ClusterWeights(layers.Dense(10),\n                                       number_of_clusters=13,\n                                       cluster_centroids_init=\'linear\')\n    self.assertIsInstance(l, cluster_wrapper.ClusterWeights)\n\n  def testCannotBeInitializedWithNonIntegerNumberOfClusters(self):\n    """"""\n    Verifies that ClusterWeights cannot be initialized with a string value\n    provided for the number of clusters.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights(layers.Dense(10),\n                                     number_of_clusters=""13"",\n                                     cluster_centroids_init=\'linear\')\n\n  def testCannotBeInitializedWithFloatNumberOfClusters(self):\n    """"""\n    Verifies that ClusterWeights cannot be initialized with a decimal value\n    provided for the number of clusters.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights(layers.Dense(10),\n                                     number_of_clusters=13.4,\n                                     cluster_centroids_init=\'linear\')\n\n  @parameterized.parameters(\n      (0),\n      (1),\n      (-32)\n  )\n  def testCannotBeInitializedWithNumberOfClustersLessThanTwo(\n      self, number_of_clusters):\n    """"""\n    Verifies that ClusterWeights cannot be initialized with less than two\n    clusters.\n    """"""\n    with self.assertRaises(ValueError):\n      cluster_wrapper.ClusterWeights(layers.Dense(10),\n                                     number_of_clusters=number_of_clusters,\n                                     cluster_centroids_init=\'linear\')\n\n  def testCanBeInitializedWithAlreadyClusterableLayer(self):\n    """"""\n    Verifies that ClusterWeights can be initialized with a custom clusterable\n    layer.\n    """"""\n    layer = AlreadyClusterableLayer(10)\n    l = cluster_wrapper.ClusterWeights(layer,\n                                       number_of_clusters=13,\n                                       cluster_centroids_init=\'linear\')\n    self.assertIsInstance(l, cluster_wrapper.ClusterWeights)\n\n  def testIfLayerHasBatchShapeClusterWeightsMustHaveIt(self):\n    """"""\n    Verifies that the ClusterWeights instance created from a layer that has\n    a batch shape attribute, will also have this attribute.\n    """"""\n    l = cluster_wrapper.ClusterWeights(layers.Dense(10, input_shape=(10,)),\n                                       number_of_clusters=13,\n                                       cluster_centroids_init=\'linear\')\n    self.assertTrue(hasattr(l, \'_batch_input_shape\'))\n\n  # Makes it easier to test all possible parameters combinations.\n  @parameterized.parameters(\n      *itertools.product(range(2, 16, 4), (\'linear\', \'random\', \'density-based\'))\n  )\n  def testValuesAreClusteredAfterStripping(self,\n                                           number_of_clusters,\n                                           cluster_centroids_init):\n    """"""\n    Verifies that, for any number of clusters and any centroid initialization\n    method, the number of unique weight values after stripping is always less\n    or equal to number_of_clusters.\n    """"""\n    original_model = tf.keras.Sequential([\n        layers.Dense(32, input_shape=(10,)),\n    ])\n    clustered_model = cluster.cluster_weights(\n        original_model,\n        number_of_clusters=number_of_clusters,\n        cluster_centroids_init=cluster_centroids_init\n    )\n    stripped_model = cluster.strip_clustering(clustered_model)\n    weights_as_list = stripped_model.get_weights()[0].reshape(-1,).tolist()\n    unique_weights = set(weights_as_list)\n    # Make sure numbers match\n    self.assertLessEqual(len(unique_weights), number_of_clusters)\n\n    # Make sure that the stripped layer is the Dense one\n    self.assertIsInstance(stripped_model.layers[0], layers.Dense)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/clustering/keras/clusterable_layer.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Clusterable layer API class for Keras models.""""""\n\nimport abc\nimport six\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass ClusterableLayer:\n  """"""Abstract Base Class for making your own keras layer clusterable.\n\n  Custom keras layers that need to support clustering should implement this\n  class.\n\n  """"""\n\n  @abc.abstractmethod\n  def get_clusterable_weights(self):\n    """"""Returns list of clusterable weight tensors.\n\n    All the weight tensors which the layer wants to be clustered during\n    training must be returned by this method.\n\n    Returns: List of weight tensors/kernels in the keras layer which must be\n        clustered during training. Each element in the list is a (name, kernel)\n        2-tuple that consists of the name of the clusterable kernel and the\n        kernel object itself.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n'"
tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids.py,21,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Clusters centroids initialization API for Keras clustering API.""""""\n\nimport abc\nimport six\nimport tensorflow as tf\n\nk = tf.keras.backend\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass AbstractCentroidsInitialisation:\n  """"""\n  Abstract base class for implementing different cluster centroid\n  initialisation algorithms. Must be initialised with a reference to the\n  weights and implement the single method below.\n  """"""\n\n  def __init__(self, weights, number_of_clusters):\n    self.weights = weights\n    self.number_of_clusters = number_of_clusters\n\n  @abc.abstractmethod\n  def get_cluster_centroids(self):\n    pass\n\n\nclass LinearCentroidsInitialisation(AbstractCentroidsInitialisation):\n  """"""\n  Spaces cluster centroids evenly in the interval [min(weights), max(weights)]\n  """"""\n\n  def get_cluster_centroids(self):\n    weight_min = tf.reduce_min(self.weights)\n    weight_max = tf.reduce_max(self.weights)\n    cluster_centroids = tf.linspace(weight_min,\n                                    weight_max,\n                                    self.number_of_clusters)\n    return cluster_centroids\n\n\nclass RandomCentroidsInitialisation(AbstractCentroidsInitialisation):\n  """"""\n  Sample centroids randomly and uniformly from the interval\n  [min(weights), max(weights)]\n  """"""\n\n  def get_cluster_centroids(self):\n    weight_min = tf.reduce_min(self.weights)\n    weight_max = tf.reduce_max(self.weights)\n    cluster_centroids = tf.random.uniform(shape=(self.number_of_clusters,),\n                                          minval=weight_min,\n                                          maxval=weight_max,\n                                          dtype=self.weights.dtype)\n    return cluster_centroids\n\n\nclass TFLinearEquationSolver:\n  """"""\n  Solves a linear equantion y=ax+b for either y or x.\n\n  The line equation is defined with two points (x1, y1) and (x2,y2)\n  """"""\n\n  def __init__(self, x1, y1, x2, y2):\n    self.x1 = x1\n    self.y1 = y1\n    self.x2 = x2\n    self.y2 = y2\n\n    # Writing params for y=ax+b\n    self.a = (y2 - y1) / tf.maximum(x2 - x1, 0.001)\n    self.b = y1 - x1 * ((y2 - y1) / tf.maximum(x2 - x1, 0.001))\n\n  def solve_for_x(self, y):\n    """"""\n    For a given y value, find x at which linear function takes value y\n    :param y: the y value\n    :return: the corresponding x value\n    """"""\n    return (y - self.b) / self.a\n\n  def solve_for_y(self, x):\n    """"""\n    For a given x value, find y at which linear function takes value x\n    :param x: the x value\n    :return: the corresponding y value\n    """"""\n    return self.a * x + self.b\n\n\nclass TFCumulativeDistributionFunction:\n  """"""\n  Takes an array and builds cumulative distribution function(CDF)\n  """"""\n\n  def __init__(self, weights):\n    self.weights = weights\n\n  def get_cdf_value(self, given_weight):\n    mask = tf.less_equal(self.weights, given_weight)\n    less_than = tf.cast(tf.math.count_nonzero(mask), dtype=tf.float32)\n    return less_than / tf.size(self.weights, out_type=tf.float32)\n\n\nclass DensityBasedCentroidsInitialisation(AbstractCentroidsInitialisation):\n  """"""\n  This initialisation means that we build a cumulative distribution\n  function(CDF), then linearly space y-axis of this function then find the\n  corresponding x-axis points. In order to simplify the implementation, here is\n  a plan how it is achieved:\n  1. Calculate CDF values at points spaced linearly between weight_min and\n  weight_max(e.g. 20 points)\n  2. Build an array of values linearly spaced between 0 and 1(probability)\n  3. Go through the second array and find segment of CDF that contains this\n  y-axis value, \\\\hat{y}\n  4. interpolate linearly between those two points, get a line equation y=ax+b\n  5. solve equation \\\\hat{y}=ax+b for x. The found x value is a new cluster\n  centroid\n  """"""\n\n  def get_cluster_centroids(self):\n    weight_min = tf.reduce_min(self.weights)\n    weight_max = tf.reduce_max(self.weights)\n    # Calculating interpolation nodes, +/- 0.01 is introduced to guarantee that\n    # CDF will have 0 and 1 and the first and last value respectively.\n    # The value 30 is a guess. We just need a sufficiently large number here\n    # since we are going to interpolate values linearly anyway and the initial\n    # guess will drift away. For these reasons we do not really\n    # care about the granularity of the lookup.\n    cdf_x_grid = tf.linspace(weight_min - 0.01, weight_max + 0.01, 30)\n\n    f = TFCumulativeDistributionFunction(weights=self.weights)\n\n    cdf_values = k.map_fn(f.get_cdf_value, cdf_x_grid)\n\n    probability_space = tf.linspace(0 + 0.01, 1, self.number_of_clusters)\n\n    # Use upper-bound algorithm to find the appropriate bounds\n    matching_indices = tf.searchsorted(sorted_sequence=cdf_values,\n                                       values=probability_space,\n                                       side=\'right\')\n\n    # Interpolate linearly between every found indices I at position using I at\n    # pos n-1 as a second point. The value of x is a new cluster centroid\n    def get_single_centroid(i):\n      i_clipped = tf.minimum(i, tf.size(cdf_values) - 1)\n      i_previous = tf.maximum(0, i_clipped - 1)\n\n      s = TFLinearEquationSolver(x1=cdf_x_grid[i_clipped],\n                                 y1=cdf_values[i_clipped],\n                                 x2=cdf_x_grid[i_previous],\n                                 y2=cdf_values[i_previous])\n\n      y = cdf_values[i_clipped]\n\n      single_centroid = s.solve_for_x(y)\n      return single_centroid\n\n    centroids = k.map_fn(get_single_centroid,\n                         matching_indices,\n                         dtype=tf.float32)\n    cluster_centroids = tf.reshape(centroids, (self.number_of_clusters,))\n    return cluster_centroids\n\n\nclass CentroidsInitializerFactory:\n  """"""\n  Factory that creates concrete initializers for factory centroids.\n  To implement a custom one, inherit from AbstractCentroidsInitialisation\n  and implement all the required methods.\n\n  After this, update CentroidsInitialiserFactory.__initialisers hashtable to\n  reflect new methods available.\n  """"""\n  _initialisers = {\n      \'linear\': LinearCentroidsInitialisation,\n      \'random\': RandomCentroidsInitialisation,\n      \'density-based\': DensityBasedCentroidsInitialisation\n  }\n\n  @classmethod\n  def init_is_supported(cls, init_method):\n    return init_method in cls._initialisers\n\n  @classmethod\n  def get_centroid_initializer(cls, init_method):\n    """"""\n    :param init_method: a string representation of the init methods requested\n    :return: A concrete implementation of  AbstractCentroidsInitialisation\n    :raises: ValueError if the string representation is not recognised\n    """"""\n    if not cls.init_is_supported(init_method):\n      raise ValueError(\n          ""Unknown initialisation method: {init_method}. Allowed values are : ""\n          ""{allowed}"".format(\n              init_method=init_method,\n              allowed=\',\'.join(cls._initialisers.keys())\n          ))\n\n    return cls._initialisers[init_method]\n'"
tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for keras clustering centroids initialisation API.""""""\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom absl.testing import parameterized\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_centroids\n\nkeras = tf.keras\nerrors_impl = tf.errors\nlayers = keras.layers\ntest = tf.test\n\n\nclass ClusteringCentroidsTest(test.TestCase, parameterized.TestCase):\n  """"""Unit tests for the clustering_centroids module.""""""\n\n  def setUp(self):\n    self.factory = clustering_centroids.CentroidsInitializerFactory\n\n  @parameterized.parameters(\n      (\'linear\'),\n      (\'random\'),\n      (\'density-based\'),\n  )\n  def testExistingInitsAreSupported(self, init_type):\n    """"""\n    Verifies that the given centroid initialization methods are supported.\n    """"""\n    self.assertTrue(self.factory.init_is_supported(init_type))\n\n  def testNonExistingInitIsNotSupported(self):\n    self.assertFalse(self.factory.init_is_supported(""DEADBEEF""))\n\n  @parameterized.parameters(\n      (\'linear\', clustering_centroids.LinearCentroidsInitialisation),\n      (\'random\', clustering_centroids.RandomCentroidsInitialisation),\n      (\n          \'density-based\',\n          clustering_centroids.DensityBasedCentroidsInitialisation\n      ),\n  )\n  def testReturnsMethodForExistingInit(self, init_type, method):\n    """"""\n    Verifies that the centroid initializer factory method returns the expected\n    classes for the given initialization methods.\n    """"""\n    self.assertEqual(self.factory.get_centroid_initializer(init_type), method)\n\n  def testThrowsValueErrorForNonExistingInit(self):\n    """"""\n    Verifies that the centroid initializer factory method raises an exception\n    when invoked with an unsupported initialization method.\n    """"""\n    with self.assertRaises(ValueError):\n      self.factory.get_centroid_initializer(""DEADBEEF"")\n\n  @parameterized.parameters(\n      (0, 0, 1, 1, 1, 0),\n      (0, 0, 5, 5, 1, 0),\n      (1, 2, 3, 4, 1, 1),\n      (7, 12, 17, 22, 1, 5),\n      (-5, 4, 7, 10, 1.0 / 2.0, 13.0 / 2.0),\n  )\n  def testLinearSolverConstruction(self, x1, y1, x2, y2, a, b):\n    """"""\n    Verifies that a TFLinearEquationSolver is constructed correctly.\n    """"""\n    solver = clustering_centroids.TFLinearEquationSolver(float(x1),\n                                                         float(y1),\n                                                         float(x2),\n                                                         float(y2))\n    solver_a = solver.a\n    self.assertAlmostEqual(K.batch_get_value([solver_a])[0], a)\n    self.assertAlmostEqual(K.batch_get_value([solver.b])[0], b)\n\n  @parameterized.parameters(\n      (0, 0, 1, 1, 5, 5),\n      (0, 0, 5, 5, 20, 20),\n      (1, 2, 3, 4, 3, 4),\n      (7, 12, 17, 22, 3, 8),\n  )\n  def testLinearSolverSolveForX(self, x1, y1, x2, y2, x, y):\n    """"""\n    Verifies that TFLinearEquationSolver solves the given equations correctly\n    for X.\n    """"""\n    solver = clustering_centroids.TFLinearEquationSolver(float(x1),\n                                                         float(y1),\n                                                         float(x2),\n                                                         float(y2))\n    for_x = solver.solve_for_x(y)\n    self.assertAlmostEqual(K.batch_get_value([for_x])[0], x)\n\n  @parameterized.parameters(\n      (0, 0, 1, 1, 5, 5),\n      (0, 0, 5, 5, 20, 20),\n      (1, 2, 3, 4, 3, 4),\n      (7, 12, 17, 22, 3, 8),\n  )\n  def testLinearSolverSolveForY(self, x1, y1, x2, y2, x, y):\n    """"""\n    Verifies that TFLinearEquationSolver solves the given equations correctly\n    for Y.\n    """"""\n    solver = clustering_centroids.TFLinearEquationSolver(float(x1),\n                                                         float(y1),\n                                                         float(x2),\n                                                         float(y2))\n    for_y = solver.solve_for_y(x)\n    self.assertAlmostEqual(K.batch_get_value([for_y])[0], y)\n\n  @parameterized.parameters(\n      ([1, 2, 6, 7], 4, 0.5),\n      ([1, 2, 6, 7], 1, 1. / 4.),\n      ([1, 2, 3, 4, 5, 6, 7, 8, 9], 3, 1. / 3.),\n      ([1, 2, 3, 4, 5, 6, 7, 8, 9], 99, 1.),\n      ([1, 2, 3, 4, 5, 6, 7, 8, 9], -20, 0.)\n  )\n  def testCDFValues(self, weights, point, probability):\n    """"""\n    Verifies that TFCumulativeDistributionFunction yields the expected output\n    for the inputs provided.\n    """"""\n    cdf_calc = clustering_centroids.TFCumulativeDistributionFunction(weights)\n    self.assertAlmostEqual(\n        probability,\n        K.batch_get_value([cdf_calc.get_cdf_value(point)])[0]\n    )\n\n  @parameterized.parameters(\n      (\n          [0, 1, 2, 3, 3.1, 3.2, 3.3, 3.4, 3.5],\n          5,\n          [0.11137931, 2.0534482, 3.145862, 3.3886206, 3.51]\n      ),\n      (\n          [0, 1, 2, 3, 3.1, 3.2, 3.3, 3.4, 3.5],\n          3,\n          [0.11137931, 3.145862, 3.51]\n      ),\n      (\n          [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n          3,\n          [0.3010345, 5.2775865, 9.01]\n      )\n  )\n  def testClusterCentroids(self, weights, number_of_clusters, centroids):\n    dbci = clustering_centroids.DensityBasedCentroidsInitialisation(\n        weights,\n        number_of_clusters\n    )\n    calc_centroids = K.batch_get_value([dbci.get_cluster_centroids()])[0]\n    self.assertSequenceAlmostEqual(centroids, calc_centroids, places=4)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/clustering/keras/clustering_registry.py,27,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Registry responsible for built-in keras classes.""""""\n\nimport abc\nimport six\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass AbstractClusteringAlgorithm(object):\n  """"""\n  The reason to have an abstract class here is to be able to implement highly\n  efficient vectorised look-ups.\n\n  We do not utilise looping for that purpose, instead we `smartly` reshape and\n  tile arrays. The trade-off is that we are potentially using way more memory\n  than we would have if looping is used.\n\n  Each class that inherits from this class is supposed to implement a particular\n  lookup function for a certain shape.\n\n  For example, look-ups for 2D table will be different in the case of 3D.\n  """"""\n\n  def __init__(self, clusters_centroids):\n    """"""\n    For generating clustered tensors we will need two things: cluster centroids\n    and the final shape tensor must have.\n    :param clusters_centroids: An array of shape (N,) that contains initial\n      values of clusters centroids.\n    """"""\n    self.cluster_centroids = clusters_centroids\n\n  @abc.abstractmethod\n  def get_pulling_indices(self, weight):\n    """"""\n    Takes a weight(can be 1D, 2D or ND) and creates tf.int32 array of the same\n    shape that will hold indices of cluster centroids clustered arrays elements\n    will be pulled from.\n\n    In the current setup pulling indices are meant to be created once and used\n    everywhere\n    :param weight: ND array of weights. For each weight in this array the\n      closest cluster centroids is found.\n    :return: ND array of the same shape as `weight` parameter of the type\n      tf.int32. The returned array contain weight lookup indices\n    """"""\n    pass\n\n  def get_clustered_weight(self, pulling_indices):\n    """"""\n    Takes an array with integer number that represent lookup indices and forms a\n    new array according to the given indices.\n    :param pulling_indices: an array of indices used for lookup.\n    :return: array with the same shape as `pulling_indices`. Each array element\n      is a member of self.cluster_centroids\n    """"""\n    return tf.reshape(\n        tf.gather(self.cluster_centroids,\n                  tf.reshape(pulling_indices, shape=(-1,))),\n        pulling_indices.shape\n    )\n\n\nclass ConvolutionalWeightsCA(AbstractClusteringAlgorithm):\n  """"""\n  Look-ups for convolutional kernels, e.g. tensors with shape [B,W,H,C]\n  """"""\n\n  def get_pulling_indices(self, weight):\n    clst_num = self.cluster_centroids.shape[0]\n    tiled_weights = tf.tile(tf.expand_dims(weight, 4), [1, 1, 1, 1, clst_num])\n\n    # Do the ugly reshape to the clustering points\n    tiled_cluster_centroids = tf.stack(\n        [tf.tile(tf.stack(\n            [tf.reshape(self.cluster_centroids, [1, 1, clst_num])] *\n            weight.shape[-2], axis=2),\n                 [weight.shape[0], weight.shape[1], 1, 1])] * weight.shape[-1],\n        axis=3)\n\n    # We find the nearest cluster centroids and store them so that ops can build\n    # their kernels upon it\n    pulling_indices = tf.argmin(\n        tf.abs(tiled_weights - tiled_cluster_centroids), axis=4\n    )\n\n    return pulling_indices\n\n\nclass DenseWeightsCA(AbstractClusteringAlgorithm):\n  """"""\n  Dense layers store their weights in 2D tables, i.e. tensor of the shape [U, D]\n  """"""\n\n  def get_pulling_indices(self, weight):\n    clst_num = self.cluster_centroids.shape[0]\n    tiled_weights = tf.tile(tf.expand_dims(weight, axis=2), [1, 1, clst_num])\n    tiled_cluster_centroids = tf.tile(\n        tf.reshape(self.cluster_centroids, [1, 1, clst_num]),\n        [weight.shape[0], weight.shape[1], 1])\n\n    # We find the nearest cluster centroids and store them so that ops can build\n    # their kernels upon it\n    pulling_indices = tf.argmin(tf.abs(tiled_weights - tiled_cluster_centroids),\n                                axis=2)\n\n    return pulling_indices\n\n\nclass BiasWeightsCA(AbstractClusteringAlgorithm):\n  """"""\n  Biases are stored as tensors of rank 0\n  """"""\n\n  def get_pulling_indices(self, weight):\n    clst_num = self.cluster_centroids.shape[0]\n    tiled_weights = tf.tile(tf.expand_dims(weight, axis=1), [1, clst_num])\n    tiled_cluster_centroids = tf.tile(\n        tf.reshape(self.cluster_centroids, [1, clst_num]), [weight.shape[0], 1])\n\n    pulling_indices = tf.argmin(tf.abs(tiled_weights - tiled_cluster_centroids),\n                                axis=1)\n\n    return pulling_indices\n\n\nclass ClusteringLookupRegistry(object):\n  """"""\n  The keys represent built-in keras layers and the values represent the\n  strategy accoding to which clustering will be done.\n  If the key is not present in the map, that means that there is nothing to\n  work on, or the strategy is not currently supported\n  """"""\n  _LAYERS_RESHAPE_MAP = {\n      layers.Conv1D: {\'kernel\': ConvolutionalWeightsCA},\n      layers.Conv2D: {\'kernel\': ConvolutionalWeightsCA},\n      layers.Conv2DTranspose: {\'kernel\': ConvolutionalWeightsCA},\n      layers.Conv3D: {\'kernel\': ConvolutionalWeightsCA},\n      layers.Conv3DTranspose: {\'kernel\': ConvolutionalWeightsCA},\n      layers.DepthwiseConv2D: {\'depthwise_kernel\': ConvolutionalWeightsCA},\n      layers.SeparableConv1D: {\'pointwise_kernel\': ConvolutionalWeightsCA},\n      layers.SeparableConv2D: {\'pointwise_kernel\': ConvolutionalWeightsCA},\n      layers.Dense: {\'kernel\': DenseWeightsCA},\n      layers.Embedding: {\'embeddings\': DenseWeightsCA},\n      layers.LocallyConnected1D: {\'kernel\': ConvolutionalWeightsCA},\n      layers.LocallyConnected2D: {\'kernel\': ConvolutionalWeightsCA},\n  }\n\n  @classmethod\n  def register_new_implementation(cls, new_impl):\n    """"""\n    For custom user-defined objects define the way how clusterable weights\n    are going to be formed. If weights are any of these, 1D,2D or 4D, please\n    consider using existing implementations: BiasWeightsCA,\n    ConvolutionalWeightsCA and DenseWeightsCA.\n\n    :param new_impl: dictionary. Keys are classes and values are dictionaries.\n      The latter have strings as keys and values are classes inherited from\n      AbstractClusteringAlgorithm. Normally, the set keys of the latter\n      dictionaries should match the set of clusterable weights names for the\n      layer.\n    :return: None\n    """"""\n    if not isinstance(new_impl, dict):\n      raise TypeError(""new_impl must be a dictionary"")\n    for k, v in new_impl.items():\n      if not isinstance(v, dict):\n        raise TypeError(\n            ""Every value of new_impl must be a dictionary. Item for key {key} ""\n            ""has class {vclass}"".format(\n                key=k,\n                vclass=v\n            )\n        )\n\n    cls._LAYERS_RESHAPE_MAP.update(new_impl)\n\n  @classmethod\n  def get_clustering_impl(cls, layer, weight_name):\n    """"""\n    Returns a certain reshape/lookup implementation for a given array\n    :param layer: A layer that is being clustered\n    :param weight_name: concrete weight name to be clustered.\n    :return: a concrete implementation of a lookup algorithm\n    """"""\n    if not layer.__class__ in cls._LAYERS_RESHAPE_MAP:\n      raise ValueError(\n          ""Class {given_class} has not been registerd in the""\n          ""ClusteringLookupRegistry. Use ClusteringLookupRegistry.""\n          ""register_new_implemenetation to fix this."".format(\n              given_class=layer.__class__\n          )\n      )\n    if weight_name not in cls._LAYERS_RESHAPE_MAP[layer.__class__]:\n      raise ValueError(\n          ""Weight with the name \'{given_weight_name}\' for class {given_class} ""\n          ""has not been registerd in the ClusteringLookupRegistry. Use ""\n          ""ClusteringLookupRegistry.register_new_implemenetation ""\n          ""to fix this."".format(\n              given_class=layer.__class__,\n              given_weight_name=weight_name\n          )\n      )\n    # Different weights will have different shapes hence there is double hash\n    # map lookup.\n    return cls._LAYERS_RESHAPE_MAP[layer.__class__][weight_name]\n\n\nclass ClusteringRegistry(object):\n  """"""Registry responsible for built-in keras layers.""""""\n\n  # The keys represent built-in keras layers and the values represent the\n  # the variables within the layers which hold the kernel weights. This\n  # allows the wrapper to access and modify the weights.\n  _LAYERS_WEIGHTS_MAP = {\n      layers.ELU: [],\n      layers.LeakyReLU: [],\n      layers.ReLU: [],\n      layers.Softmax: [],\n      layers.ThresholdedReLU: [],\n      layers.Conv1D: [\'kernel\'],\n      layers.Conv2D: [\'kernel\'],\n      layers.Conv2DTranspose: [\'kernel\'],\n      layers.Conv3D: [\'kernel\'],\n      layers.Conv3DTranspose: [\'kernel\'],\n      layers.Cropping1D: [],\n      layers.Cropping2D: [],\n      layers.Cropping3D: [],\n      layers.DepthwiseConv2D: [\'depthwise_kernel\'],\n      layers.SeparableConv1D: [\'pointwise_kernel\'],\n      layers.SeparableConv2D: [\'pointwise_kernel\'],\n      layers.UpSampling1D: [],\n      layers.UpSampling2D: [],\n      layers.UpSampling3D: [],\n      layers.ZeroPadding1D: [],\n      layers.ZeroPadding2D: [],\n      layers.ZeroPadding3D: [],\n      layers.Activation: [],\n      layers.ActivityRegularization: [],\n      layers.Dense: [\'kernel\'],\n      layers.Dropout: [],\n      layers.Flatten: [],\n      layers.Lambda: [],\n      layers.Masking: [],\n      layers.Permute: [],\n      layers.RepeatVector: [],\n      layers.Reshape: [],\n      layers.SpatialDropout1D: [],\n      layers.SpatialDropout2D: [],\n      layers.SpatialDropout3D: [],\n      layers.Embedding: [\'embeddings\'],\n      layers.LocallyConnected1D: [\'kernel\'],\n      layers.LocallyConnected2D: [\'kernel\'],\n      layers.Add: [],\n      layers.Average: [],\n      layers.Concatenate: [],\n      layers.Dot: [],\n      layers.Maximum: [],\n      layers.Minimum: [],\n      layers.Multiply: [],\n      layers.Subtract: [],\n      layers.AlphaDropout: [],\n      layers.GaussianDropout: [],\n      layers.GaussianNoise: [],\n      layers.BatchNormalization: [],\n      layers.LayerNormalization: [],\n      layers.AveragePooling1D: [],\n      layers.AveragePooling2D: [],\n      layers.AveragePooling3D: [],\n      layers.GlobalAveragePooling1D: [],\n      layers.GlobalAveragePooling2D: [],\n      layers.GlobalAveragePooling3D: [],\n      layers.GlobalMaxPooling1D: [],\n      layers.GlobalMaxPooling2D: [],\n      layers.GlobalMaxPooling3D: [],\n      layers.MaxPooling1D: [],\n      layers.MaxPooling2D: [],\n      layers.MaxPooling3D: [],\n  }\n\n  _RNN_CELLS_WEIGHTS_MAP = {\n      # NOTE: RNN cells are added via compat.v1 and compat.v2 to support legacy\n      # TensorFlow 2.X behavior where the v2 RNN uses the v1 RNNCell instead of\n      # the v2 RNNCell.\n      tf.compat.v1.keras.layers.GRUCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.GRUCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v1.keras.layers.LSTMCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.LSTMCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v1.keras.experimental.PeepholeLSTMCell: [\n          \'kernel\', \'recurrent_kernel\'\n      ],\n      tf.compat.v2.keras.experimental.PeepholeLSTMCell: [\n          \'kernel\', \'recurrent_kernel\'\n      ],\n      tf.compat.v1.keras.layers.SimpleRNNCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.SimpleRNNCell: [\'kernel\', \'recurrent_kernel\'],\n  }\n\n  _RNN_LAYERS = {\n      layers.GRU,\n      layers.LSTM,\n      layers.RNN,\n      layers.SimpleRNN,\n  }\n\n  _RNN_CELLS_STR = \', \'.join(str(_RNN_CELLS_WEIGHTS_MAP.keys()))\n\n  _RNN_CELL_ERROR_MSG = (\n      \'RNN Layer {} contains cell type {} which is either not supported or does\'\n      \'not inherit ClusterableLayer. The cell must be one of {}, or implement \'\n      \'ClusterableLayer.\'\n  )\n\n  @classmethod\n  def supports(cls, layer):\n    """"""Returns whether the registry supports this layer type.\n\n    Args:\n      layer: The layer to check for support.\n\n    Returns:\n      True/False whether the layer type is supported.\n\n    """"""\n    if layer.__class__ in cls._LAYERS_WEIGHTS_MAP:\n      return True\n\n    if layer.__class__ in cls._RNN_LAYERS:\n      for cell in cls._get_rnn_cells(layer):\n        if cell.__class__ not in cls._RNN_CELLS_WEIGHTS_MAP \\\n                and not isinstance(cell, clusterable_layer.ClusterableLayer):\n          return False\n      return True\n\n    return False\n\n  @staticmethod\n  def _get_rnn_cells(rnn_layer):\n    if isinstance(rnn_layer.cell, layers.StackedRNNCells):\n      return rnn_layer.cell.cells\n    return [rnn_layer.cell]\n\n  @classmethod\n  def _is_rnn_layer(cls, layer):\n    return layer.__class__ in cls._RNN_LAYERS\n\n  @classmethod\n  def _weight_names(cls, layer):\n    return cls._LAYERS_WEIGHTS_MAP[layer.__class__]\n\n  @classmethod\n  def make_clusterable(cls, layer):\n    """"""Modifies a built-in layer object to support clustering.\n\n    Args:\n      layer: layer to modify for support.\n\n    Returns:\n      The modified layer object.\n\n    """"""\n\n    if not cls.supports(layer):\n      raise ValueError(\'Layer \' + str(layer.__class__) + \' is not supported.\')\n\n    def get_clusterable_weights():\n      return [(weight, getattr(layer, weight)) for weight in\n              cls._weight_names(layer)]\n\n    def get_clusterable_weights_rnn():  # pylint: disable=missing-docstring\n      def get_clusterable_weights_rnn_cell(cell):\n        if cell.__class__ in cls._RNN_CELLS_WEIGHTS_MAP:\n          return [(weight, getattr(cell, weight))\n                  for weight in cls._RNN_CELLS_WEIGHTS_MAP[cell.__class__]]\n\n        if isinstance(cell, clusterable_layer.ClusterableLayer):\n          return cell.get_clusterable_weights()\n\n        raise ValueError(cls._RNN_CELL_ERROR_MSG.format(\n            layer.__class__, cell.__class__, cls._RNN_CELLS_WEIGHTS_MAP.keys()))\n\n      clusterable_weights = []\n      for rnn_cell in cls._get_rnn_cells(layer):\n        clusterable_weights.extend(get_clusterable_weights_rnn_cell(rnn_cell))\n      return clusterable_weights\n\n    if cls._is_rnn_layer(layer):\n      layer.get_clusterable_weights = get_clusterable_weights_rnn\n    else:\n      layer.get_clusterable_weights = get_clusterable_weights\n\n    return layer\n'"
tensorflow_model_optimization/python/core/clustering/keras/clustering_registry_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for keras clustering registry API.""""""\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom absl.testing import parameterized\n\nfrom tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer\nfrom tensorflow_model_optimization.python.core.clustering.keras import clustering_registry\n\nkeras = tf.keras\nk = keras.backend\nlayers = keras.layers\n\nerrors_impl = tf.errors\ntest = tf.test\n\nClusterRegistry = clustering_registry.ClusteringRegistry\nClusteringLookupRegistry = clustering_registry.ClusteringLookupRegistry\n\n\nclass ClusteringAlgorithmTest(parameterized.TestCase):\n  """"""Unit tests for clustering lookup algorithms""""""\n\n  def _pull_values(self, ca, pulling_indices, expected_output):\n    pulling_indices_np = np.array(pulling_indices)\n    res_tf = ca.get_clustered_weight(pulling_indices_np)\n\n    res_np = k.batch_get_value([res_tf])[0]\n    res_np_list = res_np.tolist()\n\n    self.assertSequenceEqual(res_np_list, expected_output)\n\n  @parameterized.parameters(\n      ([-1, 1], [[0, 0, 1], [1, 1, 1]], [[-1, -1, 1], [1, 1, 1]]),\n      ([-1, 0, 1], [[1, 1, 1], [1, 1, 1]], [[0, 0, 0], [0, 0, 0]]),\n  )\n  def testDenseWeightsCA(self,\n                         clustering_centroids,\n                         pulling_indices,\n                         expected_output):\n    """"""\n    Verifies that DenseWeightsCA works as expected.\n    """"""\n    ca = clustering_registry.DenseWeightsCA(clustering_centroids)\n    self._pull_values(ca, pulling_indices, expected_output)\n\n  @parameterized.parameters(\n      ([-1, 1], [0, 0, 0, 0, 1], [-1, -1, -1, -1, 1]),\n      ([0, 1, 2, 3], [0, 1, 2, 3, 0, 1, 2, 3], [0, 1, 2, 3, 0, 1, 2, 3]),\n  )\n  def testBiasWeightsCA(self,\n                        clustering_centroids,\n                        pulling_indices,\n                        expected_output):\n    """"""\n    Verifies that BiasWeightsCA works as expected.\n    """"""\n    ca = clustering_registry.BiasWeightsCA(clustering_centroids)\n    self._pull_values(ca, pulling_indices, expected_output)\n\n  @parameterized.parameters(\n      ([0, 3], [[[[0, 0, 0], [1, 1, 1], [0, 0, 0]]]],\n       [[[[0, 0, 0], [3, 3, 3], [0, 0, 0]]]]),\n      ([0, 3, 5], [[[[0, 1, 2], [1, 1, 1], [2, 1, 0]]]],\n       [[[[0, 3, 5], [3, 3, 3], [5, 3, 0]]]]),\n  )\n  def testConvolutionalWeightsCA(self,\n                                 clustering_centroids,\n                                 pulling_indices,\n                                 expected_output):\n    """"""\n    Verifies that ConvolutionalWeightsCA works as expected.\n    """"""\n    ca = clustering_registry.ConvolutionalWeightsCA(clustering_centroids)\n    self._pull_values(ca, pulling_indices, expected_output)\n\n\nclass CustomLayer(layers.Layer):\n  """"""A custom non-clusterable layer class.""""""\n\n\nclass ClusteringLookupRegistryTest(test.TestCase, parameterized.TestCase):\n  """"""Unit tests for the ClusteringLookupRegistry class.""""""\n\n  def testLookupHasEverythingFromRegistry(self):\n    """"""\n    Verifies that every layer that has non-empty ClusteringRegistry records is\n    also presented in the ClusteringLookup.\n    """"""\n    for layer, clustering_record in ClusterRegistry._LAYERS_WEIGHTS_MAP.items():\n      if clustering_record == []:\n        continue\n\n      self.assertIn(layer, ClusteringLookupRegistry._LAYERS_RESHAPE_MAP)\n\n      for cr in clustering_record:\n        self.assertIn(cr, ClusteringLookupRegistry._LAYERS_RESHAPE_MAP[layer])\n\n  def testGetClusteringImplFailsWithUnknonwClassUnknownWeight(self):\n    """"""\n    Verifies that get_clustering_impl() raises an error when invoked with an\n    unsupported layer class and an unsupported weight name.\n    """"""\n    with self.assertRaises(ValueError):\n      ClusteringLookupRegistry.get_clustering_impl(CustomLayer(),\n                                                   \'no_such_weight\')\n\n  def testGetClusteringImplFailsWithKnonwClassUnknownWeight(self):\n    """"""\n    Verifies that get_clustering_impl() raises an error when invoked with a\n    supported layer class and an unsupported weight name.\n    """"""\n    with self.assertRaises(ValueError):\n      ClusteringLookupRegistry.get_clustering_impl(layers.Dense(10),\n                                                   \'no_such_weight\')\n\n  @parameterized.parameters(\n      (layers.Conv2D, \'kernel\', clustering_registry.ConvolutionalWeightsCA),\n      (layers.Conv1D, \'kernel\', clustering_registry.ConvolutionalWeightsCA),\n  )\n  def testReturnsResultsForKnownTypeKnownWeights(self,\n                                                 layer_type,\n                                                 weight,\n                                                 expected):\n    """"""\n    Verifies that get_clustering_impl() returns the expected clustering lookup\n    algorithm for the inputs provided.\n    """"""\n    # layer_type is a class, thus constructing an object here\n    self.assertTrue(ClusteringLookupRegistry.get_clustering_impl(\n        layer_type(32, 3), weight) is expected)\n\n  def testRegisterNewImplWorks(self):\n    """"""\n    Verifies that registering a custom clustering lookup algorithm works as\n    expected.\n    """"""\n    class NewKernelCA(clustering_registry.AbstractClusteringAlgorithm):\n\n      def get_pulling_indices(self, weight):\n        return 1, 2, 3\n\n    new_impl = {\n        CustomLayer: {\n            \'new_kernel\': NewKernelCA\n        }\n    }\n\n    ClusteringLookupRegistry.register_new_implementation(new_impl)\n    self.assertTrue(ClusteringLookupRegistry.get_clustering_impl(\n        CustomLayer(), \'new_kernel\') is NewKernelCA)\n\n  def testFailsIfNotADictIsGivenAsInput(self):\n    """"""\n    Verifies that registering a custom clustering lookup algorithm fails if the\n    input provided is not a dict.\n    """"""\n    with self.assertRaises(TypeError):\n      ClusteringLookupRegistry.register_new_implementation([1, 2, 3, 4])\n\n  def testFailsIfNotADictIsGivenAsConcreteImplementation(self):\n    """"""\n    Verifies that registering a custom clustering lookup algorithm fails if the\n    input provided for the concrete implementation is not a dict.\n    """"""\n    with self.assertRaises(TypeError):\n      ClusteringLookupRegistry.register_new_implementation({\n          ClusteringLookupRegistry: [(\'new_kernel\', lambda x: x)]\n      })\n\n\nclass ClusterRegistryTest(test.TestCase):\n  """"""Unit tests for the ClusteringRegistry class.""""""\n\n  class CustomLayerFromClusterableLayer(layers.Dense):\n    """"""A custom layer class derived from a built-in clusterable layer.""""""\n    pass\n\n  class MinimalRNNCell(keras.layers.Layer):\n    """"""A minimal RNN cell implementation.""""""\n\n    def __init__(self, units, **kwargs):\n      self.units = units\n      self.state_size = units\n      super(ClusterRegistryTest.MinimalRNNCell, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n      self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                    initializer=\'uniform\',\n                                    name=\'kernel\')\n      self.recurrent_kernel = self.add_weight(\n          shape=(self.units, self.units),\n          initializer=\'uniform\',\n          name=\'recurrent_kernel\')\n      self.built = True\n\n    def call(self, inputs, states):\n      prev_output = states[0]\n      h = k.dot(inputs, self.kernel)\n      output = h + k.dot(prev_output, self.recurrent_kernel)\n      return output, [output]\n\n  class MinimalRNNCellClusterable(MinimalRNNCell,\n                                  clusterable_layer.ClusterableLayer):\n    """"""A clusterable minimal RNN cell implementation.""""""\n\n    def get_clusterable_weights(self):\n      return [\n          (\'kernel\', self.kernel),\n          (\'recurrent_kernel\', self.recurrent_kernel)\n      ]\n\n  def testSupportsKerasClusterableLayer(self):\n    """"""\n    Verifies that ClusterRegistry supports a built-in clusterable layer.\n    """"""\n    self.assertTrue(ClusterRegistry.supports(layers.Dense(10)))\n\n  def testSupportsKerasClusterableLayerAlias(self):\n    """"""\n    Verifies that ClusterRegistry supports a built-in clusterable layer alias.\n    """"""\n    # layers.Conv2D maps to layers.convolutional.Conv2D\n    self.assertTrue(ClusterRegistry.supports(layers.Conv2D(10, 5)))\n\n  def testSupportsKerasNonClusterableLayer(self):\n    """"""\n    Verifies that ClusterRegistry supports a built-in non-clusterable layer.\n    """"""\n    # Dropout is a layer known to not be clusterable.\n    self.assertTrue(ClusterRegistry.supports(layers.Dropout(0.5)))\n\n  def testDoesNotSupportKerasUnsupportedLayer(self):\n    """"""\n    Verifies that ClusterRegistry does not support an unknown built-in layer.\n    """"""\n    # ConvLSTM2D is a built-in keras layer but not supported.\n    self.assertFalse(ClusterRegistry.supports(layers.ConvLSTM2D(2, (5, 5))))\n\n  def testSupportsKerasRNNLayers(self):\n    """"""\n    Verifies that ClusterRegistry supports the expected built-in RNN layers.\n    """"""\n    self.assertTrue(ClusterRegistry.supports(layers.LSTM(10)))\n    self.assertTrue(ClusterRegistry.supports(layers.GRU(10)))\n    self.assertTrue(ClusterRegistry.supports(layers.SimpleRNN(10)))\n\n  def testDoesNotSupportKerasRNNLayerUnknownCell(self):\n    """"""\n    Verifies that ClusterRegistry does not support a custom non-clusterable RNN\n    cell.\n    """"""\n    self.assertFalse(ClusterRegistry.supports(\n        keras.layers.RNN(ClusterRegistryTest.MinimalRNNCell(32))))\n\n  def testSupportsKerasRNNLayerClusterableCell(self):\n    """"""\n    Verifies that ClusterRegistry supports a custom clusterable RNN cell.\n    """"""\n    self.assertTrue(ClusterRegistry.supports(\n        keras.layers.RNN(ClusterRegistryTest.MinimalRNNCellClusterable(32))))\n\n  def testDoesNotSupportCustomLayer(self):\n    """"""\n    Verifies that ClusterRegistry does not support a custom non-clusterable\n    layer.\n    """"""\n    self.assertFalse(ClusterRegistry.supports(CustomLayer(10)))\n\n  def testDoesNotSupportCustomLayerInheritedFromClusterableLayer(self):\n    """"""\n    Verifies that ClusterRegistry does not support a custom layer derived from\n    a clusterable layer.\n    """"""\n    self.assertFalse(\n        ClusterRegistry.supports(\n            ClusterRegistryTest.CustomLayerFromClusterableLayer(10)))\n\n  def testMakeClusterableRaisesErrorForKerasUnsupportedLayer(self):\n    """"""\n    Verifies that an unsupported built-in layer cannot be made clusterable by\n    calling make_clusterable().\n    """"""\n    with self.assertRaises(ValueError):\n      ClusterRegistry.make_clusterable(layers.ConvLSTM2D(2, (5, 5)))\n\n  def testMakeClusterableRaisesErrorForCustomLayer(self):\n    """"""\n    Verifies that a custom non-clusterable layer cannot be made clusterable by\n    calling make_clusterable().\n    """"""\n    with self.assertRaises(ValueError):\n      ClusterRegistry.make_clusterable(CustomLayer(10))\n\n  def testMakeClusterableRaisesErrorForCustomLayerInheritedFromClusterableLayer(\n      self):\n    """"""\n    Verifies that a non-clusterable layer derived from a clusterable layer\n    cannot be made clusterable by calling make_clusterable().\n    """"""\n    with self.assertRaises(ValueError):\n      ClusterRegistry.make_clusterable(\n          ClusterRegistryTest.CustomLayerFromClusterableLayer(10))\n\n  def testMakeClusterableWorksOnKerasClusterableLayer(self):\n    """"""\n    Verifies that make_clusterable() works as expected on a built-in\n    clusterable layer.\n    """"""\n    layer = layers.Dense(10)\n    with self.assertRaises(AttributeError):\n      layer.get_clusterable_weights()\n\n    ClusterRegistry.make_clusterable(layer)\n    # Required since build method sets up the layer weights.\n    keras.Sequential([layer]).build(input_shape=(10, 1))\n\n    self.assertEqual([(\'kernel\', layer.kernel)],\n                     layer.get_clusterable_weights())\n\n  def testMakeClusterableWorksOnKerasNonClusterableLayer(self):\n    """"""\n    Verifies that make_clusterable() works as expected on a built-in\n    non-clusterable layer.\n    """"""\n    layer = layers.Dropout(0.5)\n    with self.assertRaises(AttributeError):\n      layer.get_clusterable_weights()\n\n    ClusterRegistry.make_clusterable(layer)\n\n    self.assertEqual([], layer.get_clusterable_weights())\n\n  def testMakeClusterableWorksOnKerasRNNLayer(self):\n    """"""\n    Verifies that make_clusterable() works as expected on a built-in\n    RNN layer.\n    """"""\n    layer = layers.LSTM(10)\n    with self.assertRaises(AttributeError):\n      layer.get_clusterable_weights()\n\n    ClusterRegistry.make_clusterable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    expected_weights = [\n        (\'kernel\', layer.cell.kernel),\n        (\'recurrent_kernel\', layer.cell.recurrent_kernel)\n    ]\n    self.assertEqual(expected_weights, layer.get_clusterable_weights())\n\n  def testMakeClusterableWorksOnKerasRNNLayerWithRNNCellsParams(self):\n    """"""\n    Verifies that make_clusterable() works as expected on a built-in\n    RNN layer with built-in RNN cells.\n    """"""\n    cell1 = layers.LSTMCell(10)\n    cell2 = layers.GRUCell(5)\n    layer = layers.RNN([cell1, cell2])\n    with self.assertRaises(AttributeError):\n      layer.get_clusterable_weights()\n\n    ClusterRegistry.make_clusterable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    expected_weights = [\n        (\'kernel\', cell1.kernel),\n        (\'recurrent_kernel\', cell1.recurrent_kernel),\n        (\'kernel\', cell2.kernel),\n        (\'recurrent_kernel\', cell2.recurrent_kernel)\n    ]\n    self.assertEqual(expected_weights, layer.get_clusterable_weights())\n\n  def testMakeClusterableWorksOnKerasRNNLayerWithClusterableCell(self):\n    """"""\n    Verifies that make_clusterable() works as expected on a built-in\n    RNN layer with a custom clusterable RNN cell.\n    """"""\n    cell1 = layers.LSTMCell(10)\n    cell2 = ClusterRegistryTest.MinimalRNNCellClusterable(5)\n    layer = layers.RNN([cell1, cell2])\n    with self.assertRaises(AttributeError):\n      layer.get_clusterable_weights()\n\n    ClusterRegistry.make_clusterable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    expected_weights = [\n        (\'kernel\', cell1.kernel),\n        (\'recurrent_kernel\', cell1.recurrent_kernel),\n        (\'kernel\', cell2.kernel),\n        (\'recurrent_kernel\', cell2.recurrent_kernel)\n    ]\n    self.assertEqual(expected_weights, layer.get_clusterable_weights())\n\n  def testMakeClusterableRaisesErrorOnRNNLayersUnsupportedCell(self):\n    """"""\n    Verifies that make_clusterable() raises an exception when invoked with a\n    built-in RNN layer that contains a non-clusterable custom RNN cell.\n    """"""\n    with self.assertRaises(ValueError):\n      ClusterRegistry.make_clusterable(layers.RNN(\n          [layers.LSTMCell(10), ClusterRegistryTest.MinimalRNNCell(5)]))\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""The Tensor Encoding package.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding import core\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding import encoders\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding import stages\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding import testing\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding import utils\n'"
tensorflow_model_optimization/python/core/keras/testing/__init__.py,0,b''
tensorflow_model_optimization/python/core/keras/testing/test_utils_mnist.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Utils for testing MOT code with MNIST model/dataset.""""""\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python import keras\nl = keras.layers\n\n\ndef layers_list():\n  return [\n      l.Conv2D(32, 5, padding=\'same\', activation=\'relu\',\n               input_shape=input_shape()),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      # TODO(pulkitb): Add BatchNorm when transformations are ready.\n      # l.BatchNormalization(),\n      l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      l.Dense(1024, activation=\'relu\'),\n      l.Dropout(0.4),\n      l.Dense(10, activation=\'softmax\')\n  ]\n\n\ndef sequential_model():\n  return keras.Sequential(layers_list())\n\n\ndef functional_model():\n  """"""Builds an MNIST functional model.""""""\n  inp = keras.Input(input_shape())\n  x = l.Conv2D(32, 5, padding=\'same\', activation=\'relu\')(inp)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  # TODO(pulkitb): Add BatchNorm when transformations are ready.\n  # x = l.BatchNormalization()(x)\n  x = l.Conv2D(64, 5, padding=\'same\', activation=\'relu\')(x)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.Flatten()(x)\n  x = l.Dense(1024, activation=\'relu\')(x)\n  x = l.Dropout(0.4)(x)\n  out = l.Dense(10, activation=\'softmax\')(x)\n\n  return keras.models.Model([inp], [out])\n\n\ndef input_shape(img_rows=28, img_cols=28):\n  if tf.keras.backend.image_data_format() == \'channels_first\':\n    return 1, img_rows, img_cols\n  else:\n    return img_rows, img_cols, 1\n\n\ndef preprocessed_data(img_rows=28,\n                      img_cols=28,\n                      num_classes=10):\n  """"""Get data for mnist training and evaluation.""""""\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n  if tf.keras.backend.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n  else:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n\n  x_train = x_train.astype(\'float32\')\n  x_test = x_test.astype(\'float32\')\n  x_train /= 255\n  x_test /= 255\n\n  # convert class vectors to binary class matrices\n  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n  return x_train, y_train, x_test, y_test\n\n\ndef eval_tflite(model_path):\n  """"""Evaluate mnist in TFLite for accuracy.""""""\n  interpreter = tf.lite.Interpreter(model_path=model_path)\n  interpreter.allocate_tensors()\n  input_index = interpreter.get_input_details()[0][\'index\']\n  output_index = interpreter.get_output_details()[0][\'index\']\n\n  _, _, x_test, y_test = preprocessed_data()\n  # Testing the entire dataset is too slow. Verifying only 300 of 10k samples.\n  x_test = x_test[0:300, :]\n  y_test = y_test[0:300, :]\n\n  total_seen = 0\n  num_correct = 0\n\n  for img, label in zip(x_test, y_test):\n    batch_input_shape = (1,) + input_shape()\n    inp = img.reshape(batch_input_shape)\n    total_seen += 1\n    interpreter.set_tensor(input_index, inp)\n    interpreter.invoke()\n    predictions = interpreter.get_tensor(output_index)\n    if np.argmax(predictions) == np.argmax(label):\n      num_correct += 1\n\n  return float(num_correct) / float(total_seen)\n'"
tensorflow_model_optimization/python/core/quantization/keras/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/quantization/keras/quant_ops.py,22,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Python support for quantization operations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.training import moving_averages\nfrom tensorflow_model_optimization.python.core.keras import compat as tf_compat\n\n\ndef FixedQuantize(inputs, init_min=-6.0, init_max=6.0, scope=None):\n  """"""Adds a fake quantize layer with fixed quantization interval.\n\n  Args:\n    inputs: a tensor containing values to be quantized.\n    init_min: the lower end of quantization interval.\n    init_max: the upper end of quantization interval.\n    scope: Optional scope for name_scope.\n  Returns:\n    a tensor containing quantized values.\n  """"""\n  if scope is None:\n    scope = \'FixedQuantize\'\n\n  with tf.name_scope(scope):\n    return tf.quantization.fake_quant_with_min_max_args(\n        inputs, min=init_min, max=init_max)\n\n\ndef LastValueQuantize(inputs,\n                      min_var,\n                      max_var,\n                      per_channel=False,\n                      name_prefix=\'LastValueQuant\',\n                      is_training=True,\n                      num_bits=8,\n                      narrow_range=False,\n                      symmetric=False):\n  """"""Adds a layer that collects quantization ranges as last input ranges.\n\n  LastValueQuantize creates variables called \'min\' and \'max\', representing the\n  interval used for quantization and clamping.\n\n  Args:\n    inputs: a tensor containing values to be quantized.\n    per_channel: (Optional) a boolean specifying whether to use different\n      quantization ranges per output channel.\n    init_min: a float scalar, the initial value for variable min.\n    init_max: a float scalar, the initial value for variable max.\n    name_prefix: name_prefix for created nodes.\n    is_training: Whether the op is applied to a training or eval graph.\n    num_bits: Number of bits to use for quantization, must be between 2 and 8.\n    narrow_range: Whether to use the narrow quantization range\n      [1; 2^num_bits - 1] or wide range [0; 2^num_bits - 1].\n    symmetric: If true, use symmetric quantization limits instead of training\n      the minimum and maximum of each quantization range separately.\n  Returns:\n    a tensor containing quantized values.\n  """"""\n  with tf.name_scope(name_prefix):\n    input_shape = inputs.get_shape()\n    input_dim = len(input_shape)\n\n    if not is_training:\n      return _FakeQuantWithMinMaxVars(\n          inputs,\n          min_var,\n          max_var,\n          per_channel=per_channel,\n          num_bits=num_bits,\n          narrow_range=narrow_range)\n\n    if per_channel:\n      if input_dim == 2:\n        reduce_dims = [0]\n      elif input_dim == 4:\n        reduce_dims = [0, 1, 2]\n\n    if per_channel:\n      if input_dim >= 2:\n        batch_min = tf.math.reduce_min(\n            inputs, axis=reduce_dims, name=\'BatchMin\')\n      else:\n        batch_min = inputs\n    else:\n      batch_min = tf.math.reduce_min(inputs, name=\'BatchMin\')\n\n    if per_channel:\n      if input_dim >= 2:\n        batch_max = tf.math.reduce_max(\n            inputs, axis=reduce_dims, name=\'BatchMax\')\n      else:\n        batch_max = inputs\n    else:\n      batch_max = tf.math.reduce_max(inputs, name=\'BatchMax\')\n\n    if symmetric:\n      if narrow_range:\n        min_max_ratio = -1\n      else:\n        # In two\'s complement notation, the negative range is slightly larger\n        # than the positive range.\n        min_max_ratio = -((1 << num_bits) - 2) / (1 << num_bits)\n\n      # TFLite requires that 0.0 if always in the [min; max] range. Because\n      # batch_min <= batch_max, it follows that range_min <= 0 <= range_max.\n      range_min = tf.math.minimum(batch_min, batch_max / min_max_ratio)\n      range_max = tf.math.maximum(batch_max, batch_min * min_max_ratio)\n    else:\n      # TFLite requires that 0.0 if always in the [min; max] range.\n      range_min = tf.math.minimum(batch_min, 0.0)\n      range_max = tf.math.maximum(batch_max, 0.0)\n\n    assign_min = tf_compat.assign(min_var, range_min, name=\'AssignMinLast\')\n    assign_max = tf_compat.assign(max_var, range_max, name=\'AssignMaxLast\')\n\n    return _FakeQuantWithMinMaxVars(\n        inputs,\n        assign_min,\n        assign_max,\n        per_channel=per_channel,\n        num_bits=num_bits,\n        narrow_range=narrow_range)\n\n\ndef MovingAvgQuantize(inputs,\n                      min_var,\n                      max_var,\n                      per_channel=False,\n                      ema_decay=0.999,\n                      name_prefix=\'MovingAvgQuantize\',\n                      is_training=True,\n                      num_bits=8,\n                      narrow_range=False,\n                      symmetric=False):\n  """"""Adds a layer that collects quantization ranges as EMAs of input ranges.\n\n  MovingAvgQuantize creates variables called \'min\' and \'max\', representing the\n  interval used for quantization and clamping.\n\n  Args:\n    inputs: a tensor containing values to be quantized.\n    per_channel: (default False) a boolean specifying whether to use different\n      quantization ranges per output channel.\n    init_min: a float scalar, the initial value for variable min.\n    init_max: a float scalar, the initial value for variable max.\n    ema_decay: EMA decay parameter.\n    name_prefix: name_prefix for created nodes.\n    is_training: Whether the op is applied to a training or eval graph.\n    num_bits: Number of bits to use for quantization, must be between 2 and 8.\n    narrow_range: Whether to use the narrow quantization range\n      [1; 2^num_bits - 1] or wide range [0; 2^num_bits - 1].\n    symmetric: If true, use symmetric quantization limits instead of training\n      the minimum and maximum of each quantization range separately.\n  Returns:\n    a tensor containing quantized values.\n  """"""\n  with tf.name_scope(name_prefix):\n    input_shape = inputs.get_shape()\n    input_dim = len(input_shape)\n\n    if not is_training:\n      return _FakeQuantWithMinMaxVars(\n          inputs,\n          min_var,\n          max_var,\n          per_channel=per_channel,\n          num_bits=num_bits,\n          narrow_range=narrow_range)\n    if per_channel:\n      if input_dim == 2:\n        reduce_dims = [0]\n      elif input_dim == 4:\n        reduce_dims = [0, 1, 2]\n\n    if per_channel:\n      if input_dim >= 2:\n        batch_min = tf.math.reduce_min(\n            inputs, axis=reduce_dims, name=\'BatchMin\')\n      else:\n        batch_min = inputs\n    else:\n      batch_min = tf.math.reduce_min(inputs, name=\'BatchMin\')\n\n    if per_channel:\n      if input_dim >= 2:\n        batch_max = tf.math.reduce_max(\n            inputs, axis=reduce_dims, name=\'BatchMax\')\n      else:\n        batch_max = inputs\n    else:\n      batch_max = tf.math.reduce_max(inputs, name=\'BatchMax\')\n\n    if symmetric:\n      if narrow_range:\n        min_max_ratio = -1\n      else:\n        # In two\'s complement notation, the negative range is slightly larger\n        # than the positive range.\n        min_max_ratio = -((1 << num_bits) - 2) / (1 << num_bits)\n\n      # TFLite requires that 0.0 if always in the [min; max] range. Because\n      # batch_min <= batch_max, it follows that range_min <= 0 <= range_max.\n      range_min = tf.minimum(batch_min, batch_max / min_max_ratio)\n      range_max = tf.maximum(batch_max, batch_min * min_max_ratio)\n    else:\n      # TFLite requires that 0.0 if always in the [min; max] range.\n      range_min = tf.minimum(batch_min, 0.0)\n      range_max = tf.maximum(batch_max, 0.0)\n\n    assign_min = moving_averages.assign_moving_average(\n        min_var, range_min, ema_decay, zero_debias=False, name=\'AssignMinEma\')\n    assign_max = moving_averages.assign_moving_average(\n        max_var, range_max, ema_decay, zero_debias=False, name=\'AssignMaxEma\')\n\n    return _FakeQuantWithMinMaxVars(\n        inputs,\n        assign_min,\n        assign_max,\n        per_channel=per_channel,\n        num_bits=num_bits,\n        narrow_range=narrow_range)\n\n\ndef _FakeQuantWithMinMaxVars(inputs, min_var, max_var, per_channel, num_bits,\n                             narrow_range):\n  """"""Adds a fake quantization operation.\n\n  Depending on value of per_channel, this operation may do global quantization\n  or per channel quantization.  min_var and max_var should have corresponding\n  shapes: [1] when per_channel == False and [d] when per_channel == True.\n\n  Args:\n    inputs: a tensor containing values to be quantized.\n    min_var: a variable containing quantization range lower end(s).\n    max_var: a variable containing quantization range upper end(s).\n    per_channel: a boolean specifying whether to use per-channel quantization.\n    num_bits: Number of bits to use for quantization, must be between 2 and 8.\n    narrow_range: Whether to use the narrow quantization range\n      [1; 2^num_bits - 1] or wide range [0; 2^num_bits - 1].\n  Returns:\n    a tensor containing quantized values.\n  """"""\n\n  if per_channel:\n    assert len(min_var.get_shape()) == 1\n    assert len(max_var.get_shape()) == 1\n    return tf.quantization.fake_quant_with_min_max_vars_per_channel(\n        inputs, min_var, max_var, num_bits=num_bits, narrow_range=narrow_range)\n  else:\n    assert min_var.get_shape() == []  # pylint: disable=g-explicit-bool-comparison\n    assert max_var.get_shape() == []  # pylint: disable=g-explicit-bool-comparison\n    return tf.quantization.fake_quant_with_min_max_vars(\n        inputs, min_var, max_var, num_bits=num_bits, narrow_range=narrow_range)\n'"
tensorflow_model_optimization/python/core/quantization/keras/quant_ops_test.py,17,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Quantize Ops.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.quantization.keras import quant_ops\n\n_SYMMETRIC_RANGE_RATIO = 0.9921875  # 127 / 128\n\n\n@keras_parameterized.run_all_keras_modes\nclass QuantOpsTest(tf.test.TestCase, parameterized.TestCase):\n\n  def testLastValueQuantizeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(quant_ops.LastValueQuantize,\n                                                 [tf.constant([-1.0, 1.0])])\n    self.assertEqual(min_value, -1.0)\n    self.assertEqual(max_value, 1.0)\n\n  def testLastValueSymmetricQuantizeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(\n        quant_ops.LastValueQuantize,\n        [tf.constant([-_SYMMETRIC_RANGE_RATIO, _SYMMETRIC_RANGE_RATIO])],\n        symmetric=True,\n        narrow_range=False)\n    self.assertEqual(min_value, -1.0)\n    self.assertEqual(max_value, _SYMMETRIC_RANGE_RATIO)\n\n  def testLastValueSymmetricQuantizeNarrowRangeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(\n        quant_ops.LastValueQuantize, [tf.constant([-1, 0.5])],\n        symmetric=True,\n        narrow_range=True)\n    self.assertEqual(min_value, -1.0)\n    self.assertEqual(max_value, 1)\n\n  def testMovingAvgQuantizeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(\n        quant_ops.MovingAvgQuantize,\n        [tf.constant([-1.0, 1.0]),\n         tf.constant([0., 0.])])\n    self.assertAlmostEqual(min_value, -0.000999, delta=1e-6)\n    self.assertAlmostEqual(max_value, 0.000999, delta=1e-6)\n\n  def testMovingAvgSymmetricQuantizeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(\n        quant_ops.MovingAvgQuantize,\n        [tf.constant([-1, 0.5]), tf.constant([0., 0.])],\n        symmetric=True)\n    self.assertAlmostEqual(min_value, -0.000999, delta=1e-6)\n    self.assertAlmostEqual(\n        max_value, 0.000999 * _SYMMETRIC_RANGE_RATIO, delta=1e-6)\n    self.assertAlmostEqual(max_value, min_value * -_SYMMETRIC_RANGE_RATIO)\n\n  def testMovingAvgSymmetricQuantizeNarrowRangeTrainingAssign(self):\n    min_value, max_value = self._GetMinMaxValues(\n        quant_ops.MovingAvgQuantize,\n        [tf.constant([-1, 0.5]), tf.constant([0., 0.])],\n        symmetric=True,\n        narrow_range=True)\n    self.assertAlmostEqual(min_value, -0.000999, delta=1e-6)\n    self.assertAlmostEqual(max_value, 0.000999, delta=1e-6)\n    self.assertAlmostEqual(max_value, -min_value)\n\n  def testVariablesNotPartitioned_LastValue(self):\n    x = tf.constant([1.0, 2.0])\n    min_var = tf.Variable(0.0)\n    max_var = tf.Variable(0.0)\n    _ = quant_ops.LastValueQuantize(x, min_var, max_var, is_training=True)\n\n  def testVariablesNotPartitioned_MovingAvg(self):\n    x = tf.constant([1.0, 2.0])\n    min_var = tf.Variable(0.0)\n    max_var = tf.Variable(0.0)\n    _ = quant_ops.MovingAvgQuantize(x, min_var, max_var, is_training=True)\n\n  def _GetMinMaxValues(self, quantize_fn, input_values, **kwds):\n    min_var = tf.Variable(0.0)\n    max_var = tf.Variable(0.0)\n    compat.initialize_variables(self)\n\n    for input_elem in input_values:\n      y = quantize_fn(input_elem, min_var, max_var, is_training=True, **kwds)\n      self.evaluate(y)\n\n    # Now check that the min_max_vars were, in fact, updated.\n    min_max_values = self.evaluate([min_var, max_var])\n    return min_max_values[0], min_max_values[1]\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize.py,34,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantization API functions for tf.keras models.""""""\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_annotate as quantize_annotate_mod\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config as quantize_config_mod\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_wrapper\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_layout_transform\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm\n\nkeras = tf.keras\n\n\ndef quantize_scope(*args):\n  """"""Scope which can be used to deserialize quantized Keras models and layers.\n\n  Under `quantize_scope`, Keras methods such as `tf.keras.load_model` and\n  `tf.keras.models.model_from_config` will be able to deserialize Keras models\n  and layers which contain quantization classes such as `QuantizeConfig`\n  and `Quantizer`.\n\n  Example:\n\n  ```python\n  tf.keras.models.save_model(quantized_model, keras_file)\n\n  with quantize_scope():\n    loaded_model = tf.keras.models.load_model(keras_file)\n\n  # If your quantized model uses custom objects such as a specific `Quantizer`,\n  # you can pass them to quantize_scope to deserialize your model.\n  with quantize_scope({\'FixedRangeQuantizer\', FixedRangeQuantizer}\n    loaded_model = tf.keras.models.load_model(keras_file)\n  ```\n\n  For further understanding, see `tf.keras.utils.custom_object_scope`.\n\n  Args:\n    *args: Variable length list of dictionaries of `{name, class}` pairs to add\n      to the scope created by this method.\n\n  Returns:\n    Object of type `CustomObjectScope` with quantization objects included.\n  """"""\n  quantization_objects = {\n      \'QuantizeAnnotate\': quantize_annotate_mod.QuantizeAnnotate,\n      \'QuantizeAwareActivation\':\n          quantize_aware_activation.QuantizeAwareActivation,\n      \'NoOpActivation\': quantize_aware_activation.NoOpActivation,\n      \'QuantizeWrapper\': quantize_wrapper.QuantizeWrapper,\n      \'QuantizeLayer\': quantize_layer.QuantizeLayer,\n      # TODO(tf-mot): add way for different quantization schemes to modify this.\n      \'_DepthwiseConvBatchNorm2D\': conv_batchnorm._DepthwiseConvBatchNorm2D,  # pylint: disable=protected-access\n      \'_ConvBatchNorm2D\': conv_batchnorm._ConvBatchNorm2D  # pylint: disable=protected-access\n  }\n  quantization_objects.update(default_8bit_quantize_registry._types_dict())  # pylint: disable=protected-access\n  quantization_objects.update(quantizers._types_dict())  # pylint: disable=protected-access\n\n  return tf.keras.utils.custom_object_scope(*(args + (quantization_objects,)))\n\n\ndef quantize_model(to_quantize):\n  """"""Quantize a `tf.keras` model with the default quantization implementation.\n\n  Quantization constructs a model which emulates quantization during training.\n  This allows the model to learn parameters robust to quantization loss, and\n  also model the accuracy of a quantized model.\n\n  For more information, see\n  https://www.tensorflow.org/model_optimization/guide/quantization/training\n\n  Quantize a model:\n\n  ```python\n  # Quantize sequential model\n  model = quantize_model(\n      keras.Sequential([\n          layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n          layers.Dense(2, activation=\'sigmoid\')\n      ]))\n\n  # Quantize functional model\n  in = tf.keras.Input((3,))\n  out = tf.keras.Dense(2)(in)\n  model = tf.keras.Model(in, out)\n\n  quantized_model = quantize_model(model)\n  ```\n\n  Note that this function removes the optimizer from the original model.\n\n  The returned model copies over weights from the original model. So while\n  it preserves the original weights, training it will not modify the weights\n  of the original model.\n\n  Args:\n    to_quantize: tf.keras model to be quantized. It can have pre-trained\n      weights.\n\n  Returns:\n    Returns a new `tf.keras` model prepared for quantization.\n  """"""\n  if to_quantize is None:\n    raise ValueError(\'`to_quantize` cannot be None\')\n\n  if not isinstance(to_quantize, keras.Model):\n    raise ValueError(\n        \'`to_quantize` can only be a `tf.keras.Model` instance. Use \'\n        \'the `quantize_annotate_layer` API to handle individual layers.\'\n        \'You passed an instance of type: {input}.\'.format(\n            input=to_quantize.__class__.__name__))\n\n  if not isinstance(to_quantize, keras.Sequential) \\\n      and not to_quantize._is_graph_network:  # pylint: disable=protected-access\n    raise ValueError(\n        \'`to_quantize` can only either be a tf.keras Sequential or \'\n        \'Functional model.\')\n\n  annotated_model = quantize_annotate_model(to_quantize)\n  return quantize_apply(annotated_model)\n\n\ndef quantize_annotate_model(to_annotate):\n  """"""Annotate a `tf.keras` model to be quantized.\n\n  This function does not actually quantize the model. It merely specifies\n  that the model needs to be quantized. `quantize_apply` can then be used\n  to quantize the model.\n\n  This function is intended to be used in conjunction with the\n  `quantize_annotate_layer` API. Otherwise, it is simpler to use\n  `quantize_model`.\n\n  Annotate a model while overriding the default behavior for a layer:\n\n  ```python\n  quantize_config = MyDenseQuantizeConfig()\n\n  model = quantize_annotate_model(\n    keras.Sequential([\n      layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n      quantize_annotate_layer(\n          layers.Dense(2, activation=\'sigmoid\'),\n          quantize_config=quantize_config)\n    ]))\n\n  # The first Dense layer gets quantized with the default behavior,\n  # but the second layer uses `MyDenseQuantizeConfig` for quantization.\n  quantized_model = quantize_apply(model)\n  ```\n\n  Note that this function removes the optimizer from the original model.\n\n  Args:\n    to_annotate: `tf.keras` model which needs to be quantized.\n\n  Returns:\n    New tf.keras model with each layer in the model wrapped with\n    `QuantizeAnnotate`. The new model preserves weights from the original\n    model.\n  """"""\n  if to_annotate is None:\n    raise ValueError(\'`to_annotate` cannot be None\')\n\n  if not isinstance(to_annotate, keras.Model):\n    raise ValueError(\n        \'`to_annotate` can only be a `tf.keras.Model` instance. Use \'\n        \'the `quantize_annotate_layer` API to handle individual layers. \'\n        \'You passed an instance of type: {input}.\'.format(\n            input=to_annotate.__class__.__name__))\n\n  if not isinstance(to_annotate, keras.Sequential) \\\n      and not to_annotate._is_graph_network:  # pylint: disable=protected-access\n    raise ValueError(\n        \'`to_annotate` can only either be a tf.keras Sequential or \'\n        \'Functional model.\')\n\n  def _add_quant_wrapper(layer):\n    """"""Add annotation wrapper.""""""\n    # Already annotated layer. No need to wrap.\n    if isinstance(layer, quantize_annotate_mod.QuantizeAnnotate):\n      return layer\n\n    if isinstance(layer, tf.keras.Model):\n      raise ValueError(\n          \'Quantizing a tf.keras Model inside another tf.keras Model is not supported.\'\n      )\n\n    return quantize_annotate_mod.QuantizeAnnotate(layer)\n\n  return keras.models.clone_model(\n      to_annotate, input_tensors=None, clone_function=_add_quant_wrapper)\n\n\ndef quantize_annotate_layer(to_annotate, quantize_config=None):\n  """"""Annotate a `tf.keras` layer to be quantized.\n\n  This function does not actually quantize the layer. It is merely used to\n  specify that the layer should be quantized. The layer then gets quantized\n  accordingly when `quantize_apply` is used.\n\n  This method should be used when the user wants to quantize only certain\n  layers of the model, or change the default behavior of how a layer is\n  quantized.\n\n  Annotate a layer:\n\n  ```python\n  model = keras.Sequential([\n      layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n      quantize_annotate_layer(layers.Dense(2, activation=\'sigmoid\'))\n  ])\n\n  # Only the second Dense layer is quantized.\n  quantized_model = quantize_apply(model)\n  ```\n\n  Args:\n    to_annotate: `tf.keras` layer which needs to be quantized.\n    quantize_config: optional `QuantizeConfig` which controls how the layer is\n      quantized. In its absence, the default behavior for the layer is used.\n\n  Returns:\n    `tf.keras` layer wrapped with `QuantizeAnnotate`.\n  """"""\n  if to_annotate is None:\n    raise ValueError(\'`to_annotate` cannot be None\')\n\n  # Check against keras.Model since it is an instance of keras.layers.Layer.\n  if not isinstance(to_annotate, keras.layers.Layer) or isinstance(\n      to_annotate, keras.Model):\n    raise ValueError(\n        \'`to_annotate` can only be a `tf.keras.layers.Layer` instance. \'\n        \'You passed an instance of type: {input}.\'.format(\n            input=to_annotate.__class__.__name__))\n\n  if quantize_config is not None and not isinstance(\n      quantize_config, quantize_config_mod.QuantizeConfig):\n    raise ValueError(\n        \'`quantize_config` can only be a `tfmot.quantization.keras.QuantizeConfig` instance.\'\n        \'You passed an instance of type: {input}.\'.format(\n            input=quantize_config.__class__.__name__))\n\n  return quantize_annotate_mod.QuantizeAnnotate(\n      layer=to_annotate, quantize_config=quantize_config)\n\n\ndef quantize_apply(model):\n  """"""Quantize a `tf.keras` model that has been annotated for quantization.\n\n  Quantization constructs a model which emulates quantization during training.\n  This allows the model to learn parameters robust to quantization loss, and\n  also model the accuracy of a quantized model.\n\n  For more information, see\n  https://www.tensorflow.org/model_optimization/guide/quantization/training\n  TODO(tfmot): Link blog once launched.\n\n  This function takes a `tf.keras` model in which the desired layers for\n  quantization have already been annotated. See `quantize_annotate_model`\n  and `quantize_annotate_layer`.\n\n  Quantize model.\n  ```python\n  model = keras.Sequential([\n      layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n      quantize_annotate_layer(layers.Dense(2, activation=\'sigmoid\'))\n  ])\n\n  # Only the second Dense layer is quantized.\n  quantized_model = quantize_apply(model)\n  ```\n\n  Note that this function removes the optimizer from the original model.\n\n  The returned model copies over weights from the original model. So while\n  it preserves the original weights, training it will not modify the weights\n  of the original model.\n\n  Args:\n    model: A `tf.keras` Sequential or Functional model which has been annotated\n      with `quantize_annotate`. It can have pre-trained weights.\n\n  Returns:\n    Returns a new `tf.keras` model in which the annotated layers have been\n    prepared for quantization.\n  """"""\n  if model is None:\n    raise ValueError(\'`model` cannot be None\')\n\n  if not isinstance(model, keras.Model):\n    raise ValueError(\'`model` can only be a `tf.keras.Model` instance.\'\n                     \'You passed an instance of type: {input}.\'.format(\n                         input=model.__class__.__name__))\n\n  if not isinstance(model, keras.Sequential) \\\n      and not model._is_graph_network:  # pylint: disable=protected-access\n    raise ValueError(\'`model` can only either be a tf.keras Sequential or \'\n                     \'Functional model.\')\n\n  # Have at least 1 layer annotated with QuantizeAnnotate\n  if not any(isinstance(layer, quantize_annotate_mod.QuantizeAnnotate)\n             for layer in model.layers):\n    raise ValueError(\'`model` must contain at least one layer which have been \'\n                     \'annotated with `quantize_annotate*`. There are no layers \'\n                     \'to quantize.\')\n\n  if not model.built:\n    raise ValueError(\'`model` must be a built model. \'\n                     \'been built yet. Please call `model.build(input_shape)` \'\n                     \'before quantizing your model.\')\n\n  def _clone_model_with_weights(model_to_clone):\n    cloned_model = keras.models.clone_model(model_to_clone)\n    cloned_model.set_weights(model_to_clone.get_weights())\n\n    return cloned_model\n\n  def _extract_original_model(model_to_unwrap):\n    """"""Extracts original model by removing wrappers.""""""\n    layer_quantize_map = {}\n\n    def _unwrap(layer):\n      if not isinstance(layer, quantize_annotate_mod.QuantizeAnnotate):\n        return layer\n\n      annotate_wrapper = layer\n      layer_quantize_map[annotate_wrapper.layer.name] = {\n          \'quantize_config\': annotate_wrapper.quantize_config\n      }\n      return annotate_wrapper.layer\n\n    unwrapped_model = keras.models.clone_model(\n        model_to_unwrap, input_tensors=None, clone_function=_unwrap)\n\n    return unwrapped_model, layer_quantize_map\n\n  def _quantize(layer):  # pylint: disable=missing-docstring\n    if layer.name not in layer_quantize_map:\n      return layer\n\n    quantize_config = layer_quantize_map[layer.name].get(\'quantize_config\')\n    if not quantize_config and quantize_registry.supports(layer):\n      quantize_config = quantize_registry.get_quantize_config(layer)\n\n    if not quantize_config:\n      error_msg = (\n          \'Layer {}:{} is not supported. You can quantize this \'\n          \'layer by passing a `tfmot.quantization.keras.QuantizeConfig` \'\n          \'instance to the `quantize_annotate_layer` \'\n          \'API.\')\n      raise RuntimeError(\n          error_msg.format(layer.name, layer.__class__,\n                           quantize_registry.__class__))\n\n    # `QuantizeWrapper` does not copy any additional layer params from\n    # `QuantizeAnnotate`. This should generally be fine, but occasionally\n    # `QuantizeAnnotate` wrapper may contain `batch_input_shape` like params.\n    # TODO(pulkitb): Ensure this does not affect model cloning.\n    return quantize_wrapper.QuantizeWrapper(layer, quantize_config)\n\n  # 1. Create a copy of the model with the same weights. This ensures\n  # modifications don\'t affect the original model, or its weights.\n  try:\n    model_copy = _clone_model_with_weights(model)\n  except ValueError:\n    raise ValueError(\n        \'Unable to clone model. This generally happens if you used custom Keras layers or objects \'\n        \'in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` \'\n        \'and `quantize_apply`.\'\n    )\n\n  # 2. Remove QuantizeAnnotate wrappers from the layers in the model. This\n  # extracts the original model structure (easier to transform), and\n  # stores relevant quantization information in a map.\n  unwrapped_model, layer_quantize_map = _extract_original_model(model_copy)\n  # Model cloning excludes input layers. Add input layers into the map\n  # since they need to be matched for patterns as well.\n  # pylint: disable=protected-access\n  for input_layer in unwrapped_model._input_layers:\n    for outbound_node in input_layer._outbound_nodes:\n      if outbound_node.outbound_layer.name in layer_quantize_map:\n        layer_quantize_map[input_layer.name] = {}\n  # pylint: enable=protected-access\n\n  # 3. Apply the graph transformations required to match model passes on\n  # target device/dialect.\n  quantize_transform = \\\n    default_8bit_quantize_layout_transform.QuantizeLayoutTransform()\n  # layer_quantize_map gets modified by the transformations.\n  transformed_model, layer_quantize_map = quantize_transform.apply(\n      unwrapped_model, layer_quantize_map)\n\n  # TODO(pulkitb): Think more about how to introduce Default specific code.\n  quantize_registry = default_8bit_quantize_registry.QuantizeRegistry(\n  )\n\n  # 4. Actually quantize all the relevant layers in the model. This is done by\n  # wrapping the layers with QuantizeWrapper, and passing the associated\n  # `QuantizeConfig`.\n\n  return keras.models.clone_model(\n      transformed_model, input_tensors=None, clone_function=_quantize)\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py,11,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantize Annotate Wrapper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\nserialize_keras_object = tf.keras.utils.serialize_keras_object\n\n\nclass QuantizeAnnotate(tf.keras.layers.Wrapper):\n  """"""Annotates layers which quantization should be applied to.\n\n  QuantizeAnnotate does not actually apply quantization to the underlying\n  layers but acts as a way to specify which layers quantization should be\n  applied to.\n\n  The wrapper functions as a NoOp or pass-through wrapper by simply delegating\n  calls to the underlying layer. The presence of this wrapper indicates to code\n  which actually applies quantization to determine which layers should be\n  modified.\n  """"""\n\n  _UNSUPPORTED_LAYER_ERROR_MSG = (\n      \'Layer {} not supported for quantization. Layer should either inherit \'\n      \'QuantizeEmulatableLayer or be a supported keras built-in layer.\')\n\n  def __init__(self, layer, quantize_config=None, **kwargs):\n    """"""Create a quantize annotate wrapper over a keras layer.\n\n    Args:\n      layer: The keras layer to be quantized.\n      quantize_config: Optional `QuantizeConfig` to quantize the layer.\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n    """"""\n    super(QuantizeAnnotate, self).__init__(layer, **kwargs)\n\n    if layer is None:\n      raise ValueError(\'`layer` cannot be None.\')\n\n    # Check against keras.Model since it is an instance of keras.layers.Layer.\n    if not isinstance(layer, tf.keras.layers.Layer) or isinstance(\n        layer, tf.keras.Model):\n      raise ValueError(\n          \'`layer` can only be a `tf.keras.layers.Layer` instance. \'\n          \'You passed an instance of type: {input}.\'.format(\n              input=layer.__class__.__name__))\n\n    self.quantize_config = quantize_config\n\n    self._track_trackable(layer, name=\'layer\')\n    # Enables end-user to annotate the first layer in Sequential models, while\n    # passing the input shape to the original layer.\n    #\n    # tf.keras.Sequential(\n    #   quantize_annotate_layer(tf.keras.layers.Dense(2, input_shape=(3,)))\n    # )\n    #\n    # as opposed to\n    #\n    # tf.keras.Sequential(\n    #   quantize_annotate_layer(tf.keras.layers.Dense(2), input_shape=(3,))\n    # )\n    #\n    # Without this code, the QuantizeAnnotate wrapper doesn\'t have an input\n    # shape and being the first layer, this causes the model to not be\n    # built. Being not built is confusing since the end-user has passed an\n    # input shape.\n    if (not hasattr(self, \'_batch_input_shape\') and\n        hasattr(layer, \'_batch_input_shape\')):\n      self._batch_input_shape = self.layer._batch_input_shape  # pylint: disable=protected-access\n\n  def call(self, inputs, training=None):\n    return self.layer.call(inputs)\n\n  def get_config(self):\n    base_config = super(QuantizeAnnotate, self).get_config()\n    config = {\'quantize_config\': serialize_keras_object(self.quantize_config)}\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    config = config.copy()\n\n    quantize_config = deserialize_keras_object(\n        config.pop(\'quantize_config\'),\n        module_objects=globals(),\n        custom_objects=None)\n\n    layer = tf.keras.layers.deserialize(config.pop(\'layer\'))\n\n    return cls(layer=layer, quantize_config=quantize_config, **config)\n\n  def compute_output_shape(self, input_shape):\n    return self.layer.compute_output_shape(input_shape)\n\n  @property\n  def trainable(self):\n    return self.layer.trainable\n\n  @trainable.setter\n  def trainable(self, value):\n    self.layer.trainable = value\n\n  @property\n  def trainable_weights(self):\n    return self.layer.trainable_weights\n\n  @property\n  def non_trainable_weights(self):\n    return self.layer.non_trainable_weights + self._non_trainable_weights\n\n  @property\n  def updates(self):\n    return self.layer.updates + self._updates\n\n  @property\n  def losses(self):\n    return self.layer.losses + self._losses\n\n  def get_weights(self):\n    return self.layer.get_weights()\n\n  def set_weights(self, weights):\n    self.layer.set_weights(weights)\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate_test.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantize Annotate Wrapper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_annotate\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config as quantize_config_mod\n\nkeras = tf.keras\ndeserialize_layer = tf.keras.layers.deserialize\nserialize_layer = tf.keras.layers.serialize\n\n\nclass QuantizeAnnotateTest(tf.test.TestCase):\n\n  class TestQuantizeConfig(quantize_config_mod.QuantizeConfig):\n\n    def get_weights_and_quantizers(self, layer):\n      pass\n\n    def get_activations_and_quantizers(self, layer):\n      pass\n\n    def set_quantize_weights(self, layer, quantize_weights):\n      pass\n\n    def set_quantize_activations(self, layer, quantize_activations):\n      pass\n\n    def get_output_quantizers(self, layer):\n      pass\n\n    def get_config(self):\n      return {}\n\n  def testAnnotatesKerasLayer(self):\n    layer = keras.layers.Dense(5, activation=\'relu\', input_shape=(10,))\n    model = keras.Sequential([layer])\n\n    quantize_config = self.TestQuantizeConfig()\n    annotated_model = keras.Sequential([\n        quantize_annotate.QuantizeAnnotate(\n            layer, quantize_config=quantize_config, input_shape=(10,))\n    ])\n\n    annotated_layer = annotated_model.layers[0]\n    self.assertEqual(layer, annotated_layer.layer)\n    self.assertEqual(quantize_config, annotated_layer.quantize_config)\n\n    # Annotated model should not affect computation. Returns same results.\n    x_test = np.random.rand(10, 10)\n    self.assertAllEqual(model.predict(x_test), annotated_model.predict(x_test))\n\n  def testSerializationQuantizeAnnotate(self):\n    input_shape = (2,)\n    layer = keras.layers.Dense(3)\n    wrapper = quantize_annotate.QuantizeAnnotate(\n        layer=layer,\n        quantize_config=self.TestQuantizeConfig(),\n        input_shape=input_shape)\n\n    custom_objects = {\n        \'QuantizeAnnotate\': quantize_annotate.QuantizeAnnotate,\n        \'TestQuantizeConfig\': self.TestQuantizeConfig\n    }\n\n    serialized_wrapper = serialize_layer(wrapper)\n    with tf.keras.utils.custom_object_scope(custom_objects):\n      wrapper_from_config = deserialize_layer(serialized_wrapper)\n\n    self.assertEqual(wrapper_from_config.get_config(), wrapper.get_config())\n\n  def testQuantizeAnnotate_FailsWithModel(self):\n    layer = keras.layers.Dense(5, activation=\'relu\', input_shape=(10,))\n    model = keras.Sequential([layer])\n\n    with self.assertRaises(ValueError):\n      quantize_annotate.QuantizeAnnotate(model)\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_aware_activation.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Activation layer which applies emulates quantization during training.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras.utils import tf_utils\n\nactivations = tf.keras.activations\n\n\nclass NoOpActivation(object):\n  """"""No-op activation which simply returns the incoming tensor.\n\n  This activation is required to distinguish between `keras.activations.linear`\n  which does the same thing. The main difference is that NoOpActivation should\n  not have any quantize operation applied to it.\n  """"""\n\n  def __call__(self, x):\n    return x\n\n  def get_config(self):\n    return {}\n\n  def __eq__(self, other):\n    if not other or not isinstance(other, NoOpActivation):\n      return False\n\n    return True\n\n  def __ne__(self, other):\n    """"""Ensure this works on Python2.""""""\n    return not self.__eq__(other)\n\n\nclass QuantizeAwareActivation(object):\n  """"""Activation wrapper for quantization aware training.\n\n  The goal of this class is to apply quantize operations during training such\n  that the training network mimics quantization loss experienced in activations\n  during inference.\n\n  It introduces quantization loss before and after activations as required to\n  mimic inference loss. The layer has built-in knowledge of how quantized\n  activations are laid out during inference to emulate exact behavior.\n\n  For example, ReLU activations are typically fused into their parent layer\n  such as Conv/Dense. Hence, loss is introduced only after the activation has\n  been applied. For Softmax on the other hand quantization loss is experienced\n  both before and after the activation.\n\n  Input shape:\n    Arbitrary.\n\n  Output shape:\n    Same shape as input.\n  """"""\n\n  # TODO(pulkitb): Other activations such as elu, tanh etc., should just work\n  # on inclusion. Verify in TFLite before enabling.\n\n  # These activations should be quantized prior to the activation being applied.\n  _PRE_QUANT_ACTIVATIONS = frozenset({\'softmax\'})\n\n  # These activations should be quantized after the activation has been applied.\n  _POST_QUANT_ACTIVATIONS = frozenset({\'linear\', \'relu\'})\n\n  # Don\'t take any quantize operations for these activations.\n  _NO_QUANTIZE_ACTIVATIONS = frozenset({\'NoOpActivation\'})\n\n  _CUSTOM_ACTIVATION_ERR_MSG = (\n      \'Only some Keras activations under `tf.keras.activations` are supported. \'\n      \'For other activations, use `Quantizer` directly, and update layer \'\n      \'config using `QuantizeConfig`.\')\n\n  def __init__(self, activation, quantizer, step, quantize_wrapper):\n    """"""Constructs object, and initializes weights for quantization.\n\n    Args:\n      activation: Activation function to use.\n      quantizer: `Quantizer` to be used to quantize the activation.\n      step: Variable which tracks optimizer step.\n      quantize_wrapper: `QuantizeWrapper` which owns this activation.\n    """"""\n    self.activation = activation\n    self.quantizer = quantizer\n    self.step = step\n    self.quantize_wrapper = quantize_wrapper\n\n    if not self._is_supported_activation(self.activation):\n      raise ValueError(self._CUSTOM_ACTIVATION_ERR_MSG)\n\n    if self._should_pre_quantize():\n      self._pre_activation_vars = quantizer.build(None, \'pre_activation\',\n                                                  quantize_wrapper)\n\n    if self._should_post_quantize():\n      self._post_activation_vars = quantizer.build(None, \'post_activation\',\n                                                   quantize_wrapper)\n\n  @staticmethod\n  def _name(activation):\n    if hasattr(activation, \'__name__\'):\n      return activation.__name__\n    return activation.__class__.__name__\n\n  def _is_supported_activation(self, activation):\n    activation_name = self._name(activation)\n\n    return activation_name in self._PRE_QUANT_ACTIVATIONS \\\n           or activation_name in self._POST_QUANT_ACTIVATIONS \\\n           or activation_name in self._NO_QUANTIZE_ACTIVATIONS\n\n  def _should_pre_quantize(self):\n    return self._name(self.activation) in self._PRE_QUANT_ACTIVATIONS\n\n  def _should_post_quantize(self):\n    return self._name(self.activation) in self._POST_QUANT_ACTIVATIONS\n\n  @property\n  def training(self):\n    return self._training\n\n  @training.setter\n  def training(self, value):\n    self._training = value\n\n  def _dict_vars(self, min_var, max_var):\n    return {\'min_var\': min_var, \'max_var\': max_var}\n\n  def __call__(self, inputs, *args, **kwargs):\n\n    def make_quantizer_fn(training, x, quantizer_vars):\n      """"""Use currying to return True/False specialized fns to the cond.""""""\n\n      def quantizer_fn(x=x,\n                       quantizer=self.quantizer,\n                       quantizer_vars=quantizer_vars):\n        return quantizer(x, training,\n                         weights=quantizer_vars)\n\n      return quantizer_fn\n\n    x = inputs\n    if self._should_pre_quantize():\n      x = tf_utils.smart_cond(\n          self._training,\n          make_quantizer_fn(True, x, self._pre_activation_vars),\n          make_quantizer_fn(False, x, self._pre_activation_vars))\n\n    x = self.activation(x, *args, **kwargs)\n\n    if self._should_post_quantize():\n      x = tf_utils.smart_cond(\n          self._training,\n          make_quantizer_fn(True, x, self._post_activation_vars),\n          make_quantizer_fn(False, x, self._post_activation_vars))\n\n    return x\n\n  # `QuantizeAwareActivation` wraps the activation within a layer to perform\n  # quantization. In the process, the layer\'s activation is replaced with\n  # `QuantizeAwareActivation`.\n  # However, when the layer is serialized and deserialized, we want the original\n  # activation to be reconstructed. This ensures that when `QuantizeWrapper`\n  # wraps the layer, it can again replace the original activation.\n\n  @classmethod\n  def from_config(cls, config):\n    return activations.deserialize(config[\'activation\'])\n\n  def get_config(self):\n    return {\n        \'activation\': activations.serialize(self.activation)\n    }\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_aware_activation_test.py,10,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for QuantizeAwareActivation.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\nkeras = tf.keras\nactivations = tf.keras.activations\nK = tf.keras.backend\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\nserialize_keras_object = tf.keras.utils.serialize_keras_object\n\nQuantizeAwareActivation = quantize_aware_activation.QuantizeAwareActivation\nMovingAverageQuantizer = quantizers.MovingAverageQuantizer\n\n\n@keras_parameterized.run_all_keras_modes\nclass QuantizeAwareQuantizationTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(QuantizeAwareQuantizationTest, self).setUp()\n    self.quantizer = MovingAverageQuantizer(\n        num_bits=8, per_axis=False, symmetric=True, narrow_range=False)\n\n  class TestLayer(keras.layers.Layer):\n\n    def call(self, inputs, training=None):\n      if training is None:\n        training = K.learning_phase()\n\n      self.activation.training = training\n      # Going through `identity` to create a new tensor. TF throws an error\n      # if input tensor is fetched during a run.\n      return self.activation(tf.identity(inputs))\n\n    def compute_output_shape(self, input_shape):\n      return input_shape\n\n  def testConstruction_SupportedAndUnsupportedActivations(self):\n    layer = self.TestLayer()\n\n    # Supported activations. No error thrown.\n    QuantizeAwareActivation(activations.relu, self.quantizer, 0, layer)\n    QuantizeAwareActivation(activations.softmax, self.quantizer, 0, layer)\n    QuantizeAwareActivation(\n        quantize_aware_activation.NoOpActivation(), self.quantizer, 0, layer)\n\n    def custom_quantize(x):\n      return x\n\n    with self.assertRaises(ValueError) as cm:\n      QuantizeAwareActivation(custom_quantize, self.quantizer, 0, layer)\n    self.assertEqual(\n        str(cm.exception), QuantizeAwareActivation._CUSTOM_ACTIVATION_ERR_MSG)\n\n  def testAppliesQuantizationPostActivation(self):\n    layer = self.TestLayer()\n    layer.activation = QuantizeAwareActivation(\n        activations.get(\'relu\'), self.quantizer, 0, layer)\n\n    model = keras.Sequential([layer])\n\n    x = np.array([-6.0, -3.0, 0.0, 0.05, 0.1, 3.0, 6.0])\n    # All negative values are removed due to ReLU. The other expected values\n    # are the border values of float buckets when [-6, 6] range is quantized to\n    # 256 buckets.\n    # Derived using `tf.fake_quant_with_min_max_vars`\n    expected_activation = np.array(\n        [0.0, 0.0, 0.0, 0.04705906, 0.09411764, 3.011765,\n         5.9764705]).reshape(7, 1)\n\n    for weight in layer.weights:\n      self.assertIn(\'post_activation\', weight.name)\n    self.assertAllClose(expected_activation, model.predict(x))\n\n  def testAppliesQuantizationPreActivation(self):\n    layer = self.TestLayer()\n    layer.activation = QuantizeAwareActivation(\n        activations.get(\'softmax\'), self.quantizer, 0, layer)\n\n    model = keras.Sequential([layer])\n\n    x = np.array([[1.0, 2.0]])\n    # expected_activation is determined using the float buckets when [-6, 6] is\n    # quantized. Derived using `tf.fake_quant_with_min_max_vars`. For sigmoid,\n    # quantization is applied twice.\n    #\n    # FakeQuant([1.0, 2.0]) = [0.9882355, 1.9764705]\n    # Softmax([0.9882355, 1.9764705]) = [0.27126083, 0.72873914]\n    expected_activation = np.array([[0.27126083, 0.72873914]])\n\n    for weight in layer.weights:\n      self.assertIn(\'pre_activation\', weight.name)\n    self.assertAllClose(expected_activation, model.predict(x))\n\n  def testDoesNotQuantizeNoOpActivation(self):\n    layer = self.TestLayer()\n    layer.activation = QuantizeAwareActivation(\n        quantize_aware_activation.NoOpActivation(), self.quantizer, 0, layer)\n\n    model = keras.Sequential([layer])\n\n    x = np.array([[-2.0, -1.0, 1.0, 2.0]])\n    self.assertAllClose(x, model.predict(x))\n    self.assertEmpty(layer.weights)\n\n  @parameterized.parameters(\n      (activations.get(\'relu\'), {\'activation\': \'relu\'}),\n      (quantize_aware_activation.NoOpActivation(),\n       {\'activation\': {\'class_name\': \'NoOpActivation\', \'config\': {}}})\n  )\n  def testSerializationReturnsWrappedActivation(\n      self, activation, activation_config):\n    quantize_activation = QuantizeAwareActivation(\n        activation, self.quantizer, 0, self.TestLayer())\n    serialized_quantize_activation = serialize_keras_object(quantize_activation)\n\n    expected_config = {\n        \'class_name\': \'QuantizeAwareActivation\',\n        \'config\': activation_config\n    }\n    self.assertEqual(expected_config, serialized_quantize_activation)\n\n    deserialized_activation = deserialize_keras_object(\n        serialized_quantize_activation,\n        custom_objects={\n            \'QuantizeAwareActivation\': QuantizeAwareActivation,\n            \'NoOpActivation\': quantize_aware_activation.NoOpActivation\n        })\n\n    self.assertEqual(activation, deserialized_activation)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_config.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Interface for a layer to express how to quantize it.""""""\n\nimport abc\nimport six\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass QuantizeConfig(object):\n  """"""ABC interface for Keras layers to express how they should be quantized.\n\n  This is an experimental API not subject to backward compatibility.\n\n  QuantizeConfig encapsulates all the information needed by the quantization\n  code to quantize a layer. It specifies what parts of a layer should be\n  quantized and how they should be quantized.\n\n  It can be used to precisely control the quantization behavior of a layer.\n  The framework provides default behavior for each layer, but this can be used\n  to override it.\n\n  Create QuantizeConfig for a Dense layer:\n\n  ```python\n  class MyDenseQuantizeConfig(QuantizeConfig):\n\n    def get_weights_and_quantizers(self, layer):\n      return [(layer.kernel, LastValueQuantizer())]\n\n    def get_activations_and_quantizers(self, layer):\n      return [(layer.activation, MovingAverageQuantizer())]\n\n    def set_quantize_weights(self, layer, quantize_weights):\n      layer.kernel = quantize_weights[0]\n\n    def set_quantize_activations(self, layer, quantize_activations):\n      layer.activation = quantize_activations[0]\n\n    def get_output_quantizers(self, layer):\n      # Does not quantize output, since we return an empty list.\n      return []\n\n    def get_config(self):\n      return {}\n  ```\n\n  For a full example, see\n  https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide.md\n\n  """"""\n\n  @abc.abstractmethod\n  def get_weights_and_quantizers(self, layer):\n    """"""Return weights to be quantized along with their quantizers.\n\n    This function tells the quantize code which weights within a layer\n    should be quantized, and how. The weights are the TF variables in a layer\n    and the quantizers are `Quantizer` instances.\n\n    This method is invoked by the quantization code when quantizing a layer.\n\n    Example for a `Dense` layer:\n    ```python\n    def get_weights_and_quantizers(self, layer):\n      return [(layer.kernel, LastValueQuantizer())]\n    ```\n\n    Args:\n      layer: layer being quantized.\n\n    Returns:\n      List of 2-tuples. Each tuple is a weight tensor and an associated\n      quantizer.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n  @abc.abstractmethod\n  def get_activations_and_quantizers(self, layer):\n    """"""Return activations to be quantized along with their quantizers.\n\n    This function tells the quantize code which activations within a layer\n    should be quantized, and how. The activations are the activation\n    attributes in a layer, and the quantizers are `Quantizer` instances.\n\n    This method is invoked by the quantization code when quantizing a layer.\n\n    Example for a `Dense` layer:\n    ```python\n    def get_activations_and_quantizers(self, layer):\n      return [(layer.activation, MovingAverageQuantizer())]\n    ```\n\n    Args:\n      layer: layer being quantized.\n\n    Returns:\n      List of 2-tuples. Each tuple is a keras activation and an associated\n      quantizer.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n  @abc.abstractmethod\n  def set_quantize_weights(self, layer, quantize_weights):\n    """"""Replace the weights in the layer with quantized weights.\n\n    This method is invoked by the quantization code to replace the weights\n    within a layer with quantized weights. It is responsible for ensuring that\n    the weights within a layer are properly replaced.\n\n    Example for a `Dense` layer:\n    ```python\n    def set_quantize_weights(self, layer, quantize_weights):\n      layer.kernel = quantize_weights[0]\n    ```\n\n    Args:\n      layer: layer being quantized.\n      quantize_weights: List of quantized weight tensors.\n\n    Returns:\n      None\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n  @abc.abstractmethod\n  def set_quantize_activations(self, layer, quantize_activations):\n    """"""Replace the activations in the layer with quantized activations.\n\n    This method is invoked by the quantization code to replace the activations\n    within a layer with quantized activations. It is responsible for ensuring\n    that the activations within a layer are properly replaced.\n\n    Example for a `Dense` layer:\n    ```python\n    def set_quantize_activations(self, layer, quantize_activations):\n      layer.activation = quantize_activations[0]\n    ```\n\n    Args:\n      layer: layer being quantized.\n      quantize_activations: List of quantized activations to replace the\n        original activations in the layer.\n\n    Returns:\n      None\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n  @abc.abstractmethod\n  def get_output_quantizers(self, layer):\n    """"""Returns the quantizer used to quantize the outputs from a layer.\n\n    For certain layers, we may want to quantize the outputs tensors returned\n    by the layer\'s `call` function. This allows us to quantize those output\n    tensors.\n\n    This function should return a list of quantizers. In most cases, a layer\n    outputs only a single tensor so it should only have one quantizer. Return\n    an empty list for if no quantization operation is desired on the results\n    of the layer.\n\n    Args:\n      layer: layer being quantized.\n\n    Returns:\n      List of `Quantizer`s to be used to quantize the resulting tensors from\n      a layer.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n\n  @abc.abstractmethod\n  def get_config(self):\n    """"""Returns the config used to serialize `QuantizeConfig`.""""""\n    raise NotImplementedError(\'QuantizeConfig should implement get_config().\')\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_functional_test.py,9,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Functional test which fully trains quantized models and verifies accuracy.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.keras.testing import test_utils_mnist\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import utils as test_utils\n\nlayers = tf.keras.layers\n\n\n@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\nclass QuantizeFunctionalTest(tf.test.TestCase, parameterized.TestCase):\n\n  # TODO(pulkitb): Parameterize test and include functional mnist, and\n  # other RNN models.\n  def testQuantizesMnist(self):\n    if not compat.is_v1_apis():\n      return\n\n    model = test_utils_mnist.sequential_model()\n    x_train, y_train, x_test, y_test = test_utils_mnist.preprocessed_data()\n\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    model.fit(x_train, y_train, batch_size=500)\n    _, model_accuracy = model.evaluate(x_test, y_test, verbose=0)\n\n    quantized_model = quantize.quantize_model(model)\n    quantized_model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n\n    quantized_model.fit(x_train, y_train, batch_size=500)\n    _, quantized_model_accuracy = quantized_model.evaluate(\n        x_test, y_test, verbose=0)\n\n    self.assertGreater(quantized_model_accuracy, 0.6)\n\n    _, quantized_tflite_file = tempfile.mkstemp(\'.tflite\')\n\n    with quantize.quantize_scope():\n      test_utils.convert_keras_to_tflite(\n          model=quantized_model,\n          output_path=quantized_tflite_file,\n          is_quantized=True)\n    quantized_model_tflite_accuracy = test_utils_mnist.eval_tflite(\n        quantized_tflite_file)\n\n    # Ensure accuracy for quantized TF and TFLite models are similar to original\n    # model. There is no clear way to measure quantization, but for MNIST\n    # results which differ a lot likely suggest an error in quantization.\n    self.assertAllClose(\n        model_accuracy, quantized_model_accuracy,\n        rtol=0.2, atol=0.2)\n    self.assertAllClose(\n        quantized_model_accuracy, quantized_model_tflite_accuracy,\n        rtol=0.2, atol=0.2)\n\n\n# Set of tests to determine what we can include in the whitelisted layers\n# for the default API.\n#\n# TFLite in TF 2.X currently does not support creation of full-integer models.\n# However, having every layer pass these tests ensures that the resulting\n# quantization-aware trained model will have a path to deployment once\n# TFLite adds support.\n#\n# Note these tests are not perfect yet.\n# 1. Some Keras layers use different\n# TensorFlow ops depending on the initialization parameters. This\n# tests the most noticable ones, but unlikely all.\n#\n# TODO(tfmot): merge with test class above when run_all_keras_modes works\n# with V1.\nclass QuantizeFullIntegerModelTest(tf.test.TestCase, parameterized.TestCase):\n\n  _LAYER_PARAMS = [\n      (layers.ReLU, {}),\n      (layers.Softmax, {}),\n      (layers.Conv1D, {\n          \'input_shape\': (3, 6),\n          \'filters\': 4,\n          \'kernel_size\': 2,\n      }),\n      (layers.Conv2D, {\n          \'input_shape\': (4, 6, 1),\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n      (layers.Conv3D, {\n          \'input_shape\': (3, 4, 6, 1),\n          \'filters\': 4,\n          \'kernel_size\': (2, 2, 2)\n      }),\n      (layers.Conv2DTranspose, {\n          \'input_shape\': (4, 6, 1),\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n      (layers.Conv3DTranspose, {\n          \'input_shape\': (3, 4, 6, 1),\n          \'filters\': 4,\n          \'kernel_size\': (2, 2, 2)\n      }),\n      (layers.Cropping1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.Cropping2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.Cropping3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      (layers.UpSampling1D, {\n          \'input_shape\': (3, 6)\n      }),\n      (layers.UpSampling2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.UpSampling3D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.ZeroPadding1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.ZeroPadding2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.ZeroPadding3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      (layers.ActivityRegularization, {}),\n      (layers.Dense, {\n          \'units\': 2\n      }),\n      (layers.Dropout, {\n          \'rate\': 0.2\n      }),\n      (layers.Flatten, {}),\n      (layers.Masking, {}),\n      (layers.Permute, {\n          \'input_shape\': (10, 64),\n          \'dims\': (2, 1)\n      }),\n      (layers.RepeatVector, {\n          \'n\': 3\n      }),\n      (layers.Reshape, {\n          \'target_shape\': [5, 1, 1]\n      }),\n      (layers.SpatialDropout1D, {\n          \'input_shape\': (3, 6),\n          \'rate\': 0.2,\n      }),\n      (layers.SpatialDropout2D, {\n          \'input_shape\': (4, 6, 1),\n          \'rate\': 0.2,\n      }),\n      (layers.SpatialDropout3D, {\n          \'input_shape\': (3, 4, 6, 1),\n          \'rate\': 0.2,\n      }),\n      (layers.AveragePooling1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.AveragePooling2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.AveragePooling3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      (layers.GlobalAveragePooling1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.GlobalAveragePooling2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.GlobalAveragePooling3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      (layers.GlobalMaxPooling1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.GlobalMaxPooling2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.GlobalMaxPooling3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      (layers.MaxPooling1D, {\n          \'input_shape\': (3, 6),\n      }),\n      (layers.MaxPooling2D, {\n          \'input_shape\': (4, 6, 1),\n      }),\n      (layers.MaxPooling3D, {\n          \'input_shape\': (3, 4, 6, 1),\n      }),\n      # LocallyConnected1D implementations use significantly different TF\n      # operations underneath, so they should be all tested.\n      (layers.LocallyConnected1D, {\n          \'input_shape\': (3, 6),\n          \'implementation\': 1,\n          \'filters\': 4,\n          \'kernel_size\': 2\n      }),\n      (layers.LocallyConnected1D, {\n          \'input_shape\': (3, 6),\n          \'implementation\': 2,\n          \'filters\': 4,\n          \'kernel_size\': 2\n      }),\n      (layers.LocallyConnected1D, {\n          \'input_shape\': (3, 6),\n          \'implementation\': 3,\n          \'filters\': 4,\n          \'kernel_size\': 2\n      }),\n      (layers.LocallyConnected2D, {\n          \'input_shape\': (4, 6, 1),\n          \'implementation\': 1,\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n      (layers.LocallyConnected2D, {\n          \'input_shape\': (4, 6, 1),\n          \'implementation\': 2,\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n      (layers.LocallyConnected2D, {\n          \'input_shape\': (4, 6, 1),\n          \'implementation\': 3,\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n  ]\n\n  # pylint: disable=g-complex-comprehension,undefined-variable\n\n  @parameterized.parameters([\n      l for l in _LAYER_PARAMS if l[0] not in [\n          # Not done since TFLite converter doesn\'t support in TF2 yet.\n          layers.UpSampling2D,\n          layers.Conv3D,\n          layers.Conv3DTranspose,\n          layers.AveragePooling3D,\n          layers.MaxPooling3D,\n          layers.LocallyConnected1D,\n          layers.LocallyConnected2D,\n          # Not done since TFLite inference doesn\'t support yet.\n          layers.ZeroPadding3D,  # Does not support 5D inputs yet.\n          # Not done because converter transforms graph until there are\n          # zero ops, and then an error is thrown because it cannot handle\n          # zero op graphs.\n          layers.ActivityRegularization,\n          layers.Dropout,\n          layers.Flatten,\n          layers.SpatialDropout1D,\n          layers.SpatialDropout2D,\n          layers.SpatialDropout3D,\n          # Not done since there are float tensors besides\n          # the inputs and outputs (e.g. FakeQuant not placed in\n          # all areas or converter support not there).\n          layers.Masking,\n          layers.RepeatVector,\n          layers.MaxPooling1D,\n          layers.UpSampling1D,\n          layers.UpSampling3D,\n          # Not done since not registered since not per-axis yet.\n          layers.Conv1D,\n          layers.Conv2DTranspose,\n      ]\n  ])\n  def testQuantizeSingleLayer_ProducesFullIntegerModel_TF2(\n      self, layer_type, kwargs):\n    # ""FullInteger"" in the sense that ignores inputs and outputs.\n    if compat.is_v1_apis():\n      return\n\n    if \'input_shape\' not in kwargs:\n      kwargs[\'input_shape\'] = (5,)\n\n    layer = layer_type(**kwargs)\n    model = tf.keras.Sequential([layer])\n    quantized_model = quantize.quantize_model(model)\n\n    _, quantized_tflite_file = tempfile.mkstemp(\'.tflite\')\n\n    with quantize.quantize_scope():\n      test_utils.convert_keras_to_tflite(\n          model=quantized_model,\n          output_path=quantized_tflite_file,\n          is_quantized=True,\n          input_quant_params=(0., 1.),\n          experimental_new_converter=True)\n\n    interpreter = tf.lite.Interpreter(model_path=quantized_tflite_file)\n    interpreter.allocate_tensors()\n\n    input_tensor_details = interpreter.get_input_details()\n    self.assertEqual(input_tensor_details[0][\'dtype\'], np.float32)\n\n    output_tensor_details = interpreter.get_output_details()\n    self.assertEqual(output_tensor_details[0][\'dtype\'], np.float32)\n\n    tensor_details = interpreter.get_tensor_details()\n    float_tensor_details = [\n        t for t in tensor_details if t[\'dtype\'] == np.float32\n    ]\n    # Only the input and outputs are float. The rest are integer.\n    #\n    # TODO(tfmot): update this test to use the full-integer path when available,\n    # so that float_tensor_details should be length 0.\n    self.assertLen(float_tensor_details, 2)\n\n  # This unit test runs in TF1. While we don\'t publicly support this path in\n  # the Keras tooling, this is useful for two reasons:\n  # 1. TOCO has better debugging functionality than MLIR, for incrementally\n  # adding new layers.\n  # 2. It\'s useful to track supported layers in TF1 converter in case we\n  # want to eventually support V1 conversion.\n  # 3. This also tracks more layers where FakeQuant placement is incorrect,\n  # given that the TF2 converter doesn\'t support all layers that TF1 did.\n  @parameterized.parameters([\n      l for l in _LAYER_PARAMS if l[0] not in [\n          # Not done since per-channel not supported in TF1 without MLIR.\n          # By temporarily switching layers to be per-tensor instead of\n          # per-channel, some minimum testing can be done.\n          #\n          # TODO(tfmot): add Conv1D/Conv3D/Conv with Transpose after they\n          # are made per-channel by quantization scheme.\n          layers.Conv2D,\n          # Not done since FakeQuants are not placed in right areas or\n          # converter doesn\'t handle it properly yet.\n          layers.Conv3D,\n          layers.Conv3DTranspose,\n          layers.Masking,\n          layers.LocallyConnected1D,\n          # TODO(tfmot): find reason.\n          layers.LocallyConnected2D,\n          # Not done because TF1 converter doesn\'t support quantized op.\n          layers.AveragePooling3D,\n          layers.MaxPooling3D,\n          # Not done because TF1 converter transforms graph until there are\n          # zero ops, and then an error is thrown because it cannot handle\n          # zero op graphs.\n          layers.ActivityRegularization,\n          layers.Dropout,\n          layers.Flatten,\n          layers.SpatialDropout1D,\n          layers.SpatialDropout2D,\n          layers.SpatialDropout3D,\n          # Note done because not support in TF2, so we had disabled it.\n          # Works fine in TF1 TOCO.\n          layers.MaxPooling1D,\n          layers.UpSampling3D,\n          layers.RepeatVector,\n          layers.ZeroPadding3D,\n          layers.Conv1D,\n          layers.Conv2DTranspose,\n          layers.UpSampling1D,\n          layers.UpSampling2D,\n      ]\n  ])\n  def testQuantizeSingleLayer_ProducesFullIntegerModel_TF1(\n      self, layer_type, kwargs):\n    if not compat.is_v1_apis():\n      return\n\n    if \'input_shape\' not in kwargs:\n      kwargs[\'input_shape\'] = (5,)\n\n    layer = layer_type(**kwargs)\n    model = tf.keras.Sequential([layer])\n    quantized_model = quantize.quantize_model(model)\n\n    with quantize.quantize_scope():\n      test_utils.convert_keras_to_tflite(\n          model=quantized_model,\n          output_path=None,\n          is_quantized=True,\n          inference_type=tf.uint8,\n          inference_input_type=tf.uint8,\n          input_quant_params=(0., 1.),\n          # Set to False to throw errors when FakeQuants are\n          # not placed everywhere to create full-integer model. Errors\n          # are not thrown when set to True.\n          experimental_new_converter=False)\n\n  # pylint: enable=g-complex-comprehension,undefined-variable\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_integration_test.py,12,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Integration test which ensures user facing code paths work.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\n\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.keras import test_utils\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras import utils\n\nQuantizeConfig = quantize_config.QuantizeConfig\nQuantizer = quantizers.Quantizer\nMovingAverageQuantizer = quantizers.MovingAverageQuantizer\n\nl = tf.keras.layers\n\n\n# TODO(tfmot): enable for v1. Currently fails because the decorator\n# on graph mode wraps everything in a graph, which is not compatible\n# with the TFLite converter\'s call to clear_session().\n@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\nclass QuantizeIntegrationTest(tf.test.TestCase, parameterized.TestCase):\n\n  @staticmethod\n  def _batch(dims, batch_size):\n    """"""Adds provided batch_size to existing dims.\n\n    If dims is (None, 5, 2), returns (batch_size, 5, 2)\n\n    Args:\n      dims: Dimensions\n      batch_size: batch_size\n\n    Returns:\n      dims with batch_size added as first parameter of list.\n    """"""\n    if dims[0] is None:\n      dims[0] = batch_size\n    return dims\n\n  def _assert_models_equal(self, model1, model2):\n    model1_config = model1.get_config()\n    model1_config.pop(\'build_input_shape\', None)\n    model2_config = model2.get_config()\n    model2_config.pop(\'build_input_shape\', None)\n    self.assertEqual(model1_config, model2_config)\n    self.assertAllClose(model1.get_weights(), model2.get_weights())\n\n    self._assert_outputs_equal(model1, model2)\n\n  # After saving a model to SavedModel and then loading it back,\n  # the class changes, which results in config differences. This\n  # may change after a sync (TF 2.2.0): TODO(alanchiao): try it.\n  def _assert_outputs_equal(self, model1, model2):\n    inputs = np.random.randn(\n        *self._batch(model1.input.get_shape().as_list(), 1))\n    self.assertAllClose(model1.predict(inputs), model2.predict(inputs))\n\n  # TODO(tfmot): use shared test util that is model-independent.\n  @staticmethod\n  def _train_model(model):\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    model.fit(\n        np.random.rand(20, 10),\n        tf.keras.utils.to_categorical(np.random.randint(5, size=(20, 1)), 5),\n        batch_size=20)\n\n  ####################################################################\n  # Tests for research with quantization.\n\n  # Test example in quantization comprehensive guide\n  class _FixedRangeQuantizer(Quantizer):\n    """"""Quantizer which keeps values between -1 and 1.""""""\n\n    # Test build function that returns no weights.\n    def build(self, tensor_shape, name, layer):\n      return {}\n\n    def __call__(self, inputs, training, weights, **kwargs):\n      return tf.keras.backend.clip(inputs, -1.0, 1.0)\n\n    def get_config(self):\n      return {}\n\n  @staticmethod\n  def _get_quant_params(quantizer_class):\n    if quantizer_class == quantizers.LastValueQuantizer:\n      return {\n          \'num_bits\': 8,\n          \'per_axis\': False,\n          \'symmetric\': False,\n          \'narrow_range\': False\n      }\n    else:\n      return {}\n\n  @parameterized.parameters(quantizers.LastValueQuantizer, _FixedRangeQuantizer)\n  def testCustomWeightQuantizers_Run(self, quantizer_type):\n    init_params = self._get_quant_params(quantizer_type)\n\n    # Additional test that same quantizer object can be shared\n    # between Configs, though we don\'t expicitly promote this\n    # anywhere in the documentation.\n    quantizer = quantizer_type(**init_params)\n\n    class DenseQuantizeConfig(QuantizeConfig):\n      """"""Custom QuantizeConfig for Dense layer.""""""\n\n      def get_weights_and_quantizers(self, layer):\n        return [(layer.kernel, quantizer)]\n\n      def get_activations_and_quantizers(self, layer):\n        # Defaults.\n        return [(layer.activation,\n                 MovingAverageQuantizer(\n                     num_bits=8,\n                     per_axis=False,\n                     symmetric=False,\n                     narrow_range=False))]\n\n      def set_quantize_weights(self, layer, quantize_weights):\n        layer.kernel = quantize_weights[0]\n\n      def set_quantize_activations(self, layer, quantize_activations):\n        return\n\n      def get_output_quantizers(self, layer):\n        return []\n\n      def get_config(self):\n        return {}\n\n    annotated_model = tf.keras.Sequential([\n        quantize.quantize_annotate_layer(\n            l.Dense(8, input_shape=(10,)), DenseQuantizeConfig()),\n        quantize.quantize_annotate_layer(\n            l.Dense(5), DenseQuantizeConfig())\n    ])\n\n    with quantize.quantize_scope(\n        {\'DenseQuantizeConfig\': DenseQuantizeConfig}):\n      quant_model = quantize.quantize_apply(annotated_model)\n\n    # Check no error happens.\n    self._train_model(quant_model)\n\n  ####################################################################\n  # Tests for training with quantization with checkpointing.\n\n  # TODO(pulkitb): Parameterize and add more model/runtime options.\n  def testSerialization_KerasModel(self):\n    model = test_utils.build_simple_dense_model()\n    quantized_model = quantize.quantize_model(model)\n    self._train_model(quantized_model)\n\n    _, model_file = tempfile.mkstemp(\'.h5\')\n    tf.keras.models.save_model(quantized_model, model_file)\n    with quantize.quantize_scope():\n      loaded_model = tf.keras.models.load_model(model_file)\n\n    self._assert_models_equal(quantized_model, loaded_model)\n\n  def testSerialization_KerasCheckpoint(self):\n    model = test_utils.build_simple_dense_model()\n    quantized_model = quantize.quantize_model(model)\n    self._train_model(quantized_model)\n\n    _, keras_weights = tempfile.mkstemp(\'.h5\')\n    quantized_model.save_weights(keras_weights)\n\n    same_architecture_model = test_utils.build_simple_dense_model()\n    same_architecture_model = quantize.quantize_model(same_architecture_model)\n    same_architecture_model.load_weights(keras_weights)\n\n    self._assert_outputs_equal(quantized_model, same_architecture_model)\n\n  def testSerialization_TF2SavedModel(self):\n    if compat.is_v1_apis():\n      return\n\n    model = test_utils.build_simple_dense_model()\n    quantized_model = quantize.quantize_model(model)\n    self._train_model(quantized_model)\n\n    model_dir = tempfile.mkdtemp()\n    tf.keras.models.save_model(quantized_model, model_dir)\n    loaded_model = tf.keras.models.load_model(model_dir)\n\n    self._assert_outputs_equal(quantized_model, loaded_model)\n\n  def testSerialization_TF1SavedModel(self):\n    if not compat.is_v1_apis():\n      return\n\n    model = test_utils.build_simple_dense_model()\n    quantized_model = quantize.quantize_model(model)\n    self._train_model(quantized_model)\n\n    saved_model_dir = tempfile.mkdtemp()\n    with quantize.quantize_scope():\n      tf.keras.experimental.export_saved_model(quantized_model, saved_model_dir)\n\n    with quantize.quantize_scope():\n      loaded_model = tf.keras.experimental.load_from_saved_model(\n          saved_model_dir)\n\n    self._assert_outputs_equal(quantized_model, loaded_model)\n\n  def testSerialization_TFCheckpoint(self):\n    model = test_utils.build_simple_dense_model()\n    quantized_model = quantize.quantize_model(model)\n    self._train_model(quantized_model)\n\n    _, tf_weights = tempfile.mkstemp(\'.tf\')\n    quantized_model.save_weights(tf_weights)\n\n    same_architecture_model = test_utils.build_simple_dense_model()\n    same_architecture_model = quantize.quantize_model(same_architecture_model)\n    same_architecture_model.load_weights(tf_weights)\n\n    self._assert_outputs_equal(quantized_model, same_architecture_model)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_layer.py,6,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Keras Layer which quantizes tensors.\n\nModule: tfmot.quantization.keras\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow.python.keras.utils import tf_utils\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\nserialize_keras_object = tf.keras.utils.serialize_keras_object\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\n\n\nclass QuantizeLayer(tf.keras.layers.Layer):\n  """"""Emulate quantization of tensors passed through the layer.""""""\n\n  def __init__(self, quantizer, **kwargs):\n    """"""Create a QuantizeLayer.\n\n    Args:\n      quantizer: `Quantizer` used to quantize tensors.\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n    """"""\n    super(QuantizeLayer, self).__init__(**kwargs)\n\n    if quantizer is None or not isinstance(quantizer, quantizers.Quantizer):\n      raise ValueError(\'quantizer should not be None, and should be an instance\'\n                       \'of `tfmot.quantization.keras.quantizers.Quantizer`.\')\n\n    self.quantizer = quantizer\n\n  def build(self, input_shape):\n    self.quantizer_vars = self.quantizer.build(\n        input_shape, self.name, self)\n\n    self.optimizer_step = self.add_weight(\n        \'optimizer_step\',\n        initializer=tf.keras.initializers.Constant(-1),\n        dtype=tf.dtypes.int32,\n        trainable=False)\n\n  def call(self, inputs, training=None):\n    if training is None:\n      training = tf.keras.backend.learning_phase()\n\n    def _make_quantizer_fn(train_var):\n      def quantizer_fn():\n        return self.quantizer(\n            inputs, train_var,\n            weights=self.quantizer_vars)\n\n      return quantizer_fn\n\n    return tf_utils.smart_cond(\n        training, _make_quantizer_fn(True), _make_quantizer_fn(False))\n\n  def get_config(self):\n    base_config = super(QuantizeLayer, self).get_config()\n    config = {\n        \'quantizer\': serialize_keras_object(self.quantizer)\n    }\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    config = config.copy()\n\n    # Deserialization code should ensure Quantizer is in keras scope.\n    quantizer = deserialize_keras_object(\n        config.pop(\'quantizer\'),\n        module_objects=globals(),\n        custom_objects=None)\n\n    return cls(quantizer=quantizer, **config)\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_layer_test.py,7,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for QuantizeWrapper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\nQuantizeLayer = quantize_layer.QuantizeLayer\ndeserialize_layer = tf.keras.layers.deserialize\nserialize_layer = tf.keras.layers.serialize\n\n\nclass QuantizeLayerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(QuantizeLayerTest, self).setUp()\n    self.quant_params = {\n        \'num_bits\': 8,\n        \'narrow_range\': False\n    }\n    self.quantizer = quantizers.LastValueQuantizer(\n        per_axis=False, symmetric=True, **self.quant_params)\n\n  def testQuantizesTensors(self):\n    model = tf.keras.Sequential([\n        QuantizeLayer(\n            quantizer=self.quantizer,\n            input_shape=(4,)\n        )])\n\n    x = np.random.rand(1, 4)\n    quant_x = tf.quantization.fake_quant_with_min_max_vars(\n        x, -6.0, 6.0, **self.quant_params)\n\n    self.assertAllClose(self.evaluate(quant_x), model.predict(x))\n\n  def testSerializationQuantizeLayer(self):\n    layer = QuantizeLayer(\n        quantizer=self.quantizer,\n        input_shape=(4,))\n\n    custom_objects = {\n        \'QuantizeLayer\': QuantizeLayer,\n        \'LastValueQuantizer\': quantizers.LastValueQuantizer\n    }\n\n    serialized_layer = serialize_layer(layer)\n    with tf.keras.utils.custom_object_scope(custom_objects):\n      layer_from_config = deserialize_layer(serialized_layer)\n\n    self.assertEqual(layer_from_config.get_config(), layer.get_config())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_layout_transform.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Abstract Base Class for quantization transformations to a keras model.\n\nKeras models need certain transformations for quantization to exactly match the\nbehavior of the backend they will be implemented on. This is important for\nimproving model performance.\n\nThis interface abstracts that behavior. Different backends can implement their\nown version.\n\nModule: tfmot.quantization.keras\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport six\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass QuantizeLayoutTransform(object):\n  """"""Apply transformations to the model.\n\n  Transforms the original model to perform better while quantized\n  and also match the layout of the target backend.\n  """"""\n\n  @abc.abstractmethod\n  def apply(self, model, layer_quantize_map):\n    """"""Transform model to a quantization friendly model.\n\n    Args:\n      model: Keras model to be quantized.\n      layer_quantize_map: Map containing list of layers to be quantized and\n        associated metadata. Keys are layer names which need to be quantized,\n        and values are dicts containing relevant metadata. For example,\n        any custom `QuantizeConfig` passed with a layer is present.\n\n    Returns:\n      New keras model based on `model` which has been\n      transformed to match the layout of the target backend.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_models_test.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Test quantization on keras application models.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport inspect\nimport tempfile\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import utils\n\n\n@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\nclass QuantizeModelsTest(tf.test.TestCase, parameterized.TestCase):\n\n  # Derived using\n  # `inspect.getmembers(tf.keras.applications, inspect.isfunction)`\n  _KERAS_APPLICATION_MODELS = [\n      # \'DenseNet121\',\n      # \'DenseNet169\',\n      # \'DenseNet201\',\n      # \'InceptionResNetV2\',\n      # \'InceptionV3\',\n      \'MobileNet\',\n      \'MobileNetV2\',\n      # \'NASNetLarge\',\n      # \'NASNetMobile\',\n      \'ResNet101\',\n      # \'ResNet101V2\',\n      \'ResNet152\',\n      # \'ResNet152V2\',\n      \'ResNet50\',\n      # \'ResNet50V2\',\n      # \'VGG16\',\n      # \'VGG19\',\n      # \'Xception\'\n  ]\n\n  _MODEL_INPUT_SHAPES = {\n      \'InceptionV3\': (75, 75, 3)\n  }\n\n  @staticmethod\n  def _batch(dims, batch_size):\n    if dims[0] is None:\n      dims[0] = batch_size\n    return dims\n\n  @staticmethod\n  def _get_model(model_type):\n    model_fn = [\n        y for x, y in inspect.getmembers(tf.keras.applications)\n        if x == model_type\n    ][0]\n\n    input_shape = QuantizeModelsTest._MODEL_INPUT_SHAPES.get(\n        model_type, (32, 32, 3))\n\n    return model_fn(weights=None, input_shape=input_shape)\n\n  def _create_test_data(self, model):\n    x_train = np.random.randn(\n        *self._batch(model.input.get_shape().as_list(), 2)).astype(\'float32\')\n    y_train = tf.keras.utils.to_categorical(\n        np.random.randint(1000, size=(2, 1)), 1000)\n\n    return x_train, y_train\n\n  @staticmethod\n  def _verify_tflite(tflite_file, x_test, y_test):\n    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n    interpreter.allocate_tensors()\n    input_index = interpreter.get_input_details()[0][\'index\']\n    output_index = interpreter.get_output_details()[0][\'index\']\n\n    for x, _ in zip(x_test, y_test):\n      x = x.reshape((1,) + x.shape)\n      interpreter.set_tensor(input_index, x)\n      interpreter.invoke()\n      interpreter.get_tensor(output_index)\n\n  @parameterized.parameters(_KERAS_APPLICATION_MODELS)\n  def testModelEndToEnd(self, model_type):\n    # 1. Check whether quantized model graph can be constructed.\n    model = self._get_model(model_type)\n    model = quantize.quantize_model(model)\n\n    # 2. Sanity check to ensure basic training on random data works.\n    x_train, y_train = self._create_test_data(model)\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    model.fit(x_train, y_train)\n\n    # 3. Ensure conversion to TFLite works.\n    _, tflite_file = tempfile.mkstemp(\'.tflite\')\n    print(\'TFLite File: \', tflite_file)\n    with quantize.quantize_scope():\n      utils.convert_keras_to_tflite(model, tflite_file)\n\n    # 4. Verify input runs on converted model.\n    self._verify_tflite(tflite_file, x_train, y_train)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_registry.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantization registry which specifies how layers should be quantized.\n\nModule: tfmot.quantization.keras\n""""""\n\nimport abc\nimport six\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass QuantizeRegistry(object):\n  """"""ABC interface which specifies how layers should be quantized.\n\n  The Registry is designed to function as a repository of `QuantizeConfig`s\n  linked to layers. The idea is that while applying quantization to the various\n  layers within a Keras model, the registry can be used to query which\n  `QuantizeConfig` can be used to quantize a specific `layer`. The\n  `QuantizeConfig` itself contains information to quantize that specific\n  layer.\n\n  We provide a default registry for built-in Keras layers, but implementing this\n  interface allows users the ability to write their own custom registries\n  specific to their needs. It can also be extended to be used for any Keras\n  layer, such as custom Keras layers.\n  """"""\n\n  @abc.abstractmethod\n  def get_quantize_config(self, layer):\n    """"""Returns the quantization config for the given layer.\n\n    Args:\n      layer: input layer to return quantize config for.\n\n    Returns:\n      Returns the QuantizeConfig for the given layer.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_test.py,7,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for quantize API functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_annotate as quantize_annotate_mod\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config as quantize_config_mod\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_wrapper as quantize_wrapper_mod\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\n\nquantize_annotate_layer = quantize.quantize_annotate_layer\nquantize_annotate_model = quantize.quantize_annotate_model\nquantize_apply = quantize.quantize_apply\nQuantizeAnnotate = quantize_annotate_mod.QuantizeAnnotate\nQuantizeWrapper = quantize_wrapper_mod.QuantizeWrapper\n\nkeras = tf.keras\nK = tf.keras.backend\ncustom_object_scope = tf.keras.utils.custom_object_scope\n\n\nclass _TestQuantizeConfig(quantize_config_mod.QuantizeConfig):\n\n  def get_weights_and_quantizers(self, layer):\n    return []\n\n  def get_activations_and_quantizers(self, layer):\n    return []\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    pass\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    pass\n\n  def get_output_quantizers(self, layer):\n    pass\n\n  def get_config(self):\n    return {}\n\n\nclass QuantizeTest(tf.test.TestCase):\n\n  def testQuantizeModel_Passes(self):\n    model = keras.Sequential(\n        [keras.layers.Dense(10, input_shape=(5,)),\n         keras.layers.Dropout(0.4)])\n\n    quantize.quantize_model(model)\n\n  def testQuantizeLayer_Fails(self):\n    layer = keras.layers.Dense(10, input_shape=(5,))\n\n    with self.assertRaises(ValueError):\n      quantize.quantize_model(layer)\n\n\nclass QuantizeAnnotateTest(tf.test.TestCase):\n\n  def _assertWrappedLayer(self, layer, quantize_config=None):\n    self.assertIsInstance(layer, quantize_annotate_mod.QuantizeAnnotate)\n    self.assertEqual(quantize_config, layer.quantize_config)\n\n  def _assertWrappedModel(self, model):\n    for layer in model.layers:\n      self._assertWrappedLayer(layer)\n\n  def testQuantizeAnnotateLayer(self):\n    layer = keras.layers.Dense(10, input_shape=(5,))\n    wrapped_layer = quantize_annotate_layer(layer)\n\n    self._assertWrappedLayer(wrapped_layer)\n\n    inputs = np.random.rand(1, 5)\n    model = keras.Sequential([layer])\n    wrapped_model = keras.Sequential([wrapped_layer])\n\n    # Both models should have the same results, since quantize_annotate does\n    # not modify behavior.\n    self.assertAllEqual(model.predict(inputs), wrapped_model.predict(inputs))\n\n  def testQuantizeAnnotateSequentialFirstLayer_IsBuilt(self):\n    model = keras.Sequential([\n        quantize_annotate_layer(keras.layers.Dense(10, input_shape=(5,))),\n        keras.layers.Dropout(0.4)\n    ])\n\n    self.assertTrue(model.built)\n\n  def testQuantizeAnnotateLayer_FailsWithModel(self):\n    model = keras_test_utils.build_simple_dense_model()\n\n    with self.assertRaises(ValueError):\n      quantize.quantize_annotate_layer(model)\n\n  def testQuantizeAnnotateModel(self):\n    model = keras.Sequential([\n        keras.layers.Dense(10, input_shape=(5,)),\n        keras.layers.Dropout(0.4)\n    ])\n    annotated_model = quantize_annotate_model(model)\n\n    self._assertWrappedModel(annotated_model)\n\n    inputs = np.random.rand(1, 5)\n    self.assertAllEqual(model.predict(inputs), annotated_model.predict(inputs))\n\n  def testQuantizeAnnotateModel_HasAnnotatedLayers(self):\n    quantize_config = _TestQuantizeConfig()\n\n    model = keras.Sequential([\n        keras.layers.Dense(10, input_shape=(5,)),\n        quantize_annotate_layer(\n            keras.layers.Dense(5), quantize_config=quantize_config)\n    ])\n    annotated_model = quantize_annotate_model(model)\n\n    self._assertWrappedLayer(annotated_model.layers[0])\n    self._assertWrappedLayer(annotated_model.layers[1], quantize_config)\n    # Ensure an already annotated layer is not wrapped again.\n    self.assertIsInstance(annotated_model.layers[1].layer, keras.layers.Dense)\n\n    inputs = np.random.rand(1, 5)\n    self.assertAllEqual(model.predict(inputs), annotated_model.predict(inputs))\n\n  def testQuantizeAnnotateModel_FailsWithLayer(self):\n    layer = keras.layers.Dense(10)\n\n    with self.assertRaises(ValueError):\n      quantize.quantize_annotate_model(layer)\n\n  class CustomLayer(keras.layers.Dense):\n    pass\n\n  def testQuantizeAnnotateModel_PassesWithCustomLayer(self):\n    model = keras.Sequential([self.CustomLayer(3, input_shape=(2,))])\n    quantize_annotate_model(model)\n\n  # TODO(tfmot): this behavior may change in the future. If a user\n  # start training a model without quantization and then wants to apply\n  # it, not removing the optimizer would allow them to skip recompiling\n  # the model.\n  def testQuantizeAnnotateModel_RemovesOptimizer(self):\n    model = keras_test_utils.build_simple_dense_model()\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n\n    self.assertIsNotNone(model.optimizer)\n\n    annotated_model = quantize_annotate_model(model)\n    self.assertIsNone(annotated_model.optimizer)\n\n  def testQuantizeAnnotateModel_FailsWithSubclassedModel(self):\n    class MyModel(keras.Model):\n      def call(self, inputs, training=None, mask=None):  # pylint: disable=g-wrong-blank-lines\n        return inputs\n\n    with self.assertRaises(ValueError):\n      quantize_annotate_model(MyModel())\n\n  def testQuantizeAnnotateModel_FailsWithNestedModels(self):\n    with self.assertRaises(ValueError):\n      quantize_annotate_model(\n          keras.Sequential(\n              [keras.Sequential([keras.layers.Dense(10, input_shape=(2,))])]))\n\n\nclass QuantizeApplyTest(tf.test.TestCase):\n\n  # Validation tests\n\n  def testRaisesErrorIfNotKerasModel(self):\n    with self.assertRaises(ValueError):\n      quantize_apply(keras.layers.Dense(32))\n\n  def testRaisesErrorIfKerasSubclassedModel(self):\n    class MyModel(keras.Model):\n      def call(self, inputs, training=None, mask=None):  # pylint: disable=g-wrong-blank-lines\n        return inputs\n\n    with self.assertRaises(ValueError):\n      quantize_apply(MyModel())\n\n  def testRaisesErrorNoAnnotatedLayers_Sequential(self):\n    model = keras.Sequential([\n        keras.layers.Dense(10), keras.layers.Dropout(0.4)])\n\n    with self.assertRaises(ValueError):\n      quantize_apply(model)\n\n  def testRaisesErrorNoAnnotatedLayers_Functional(self):\n    inputs = keras.Input(shape=(10,))\n    x = keras.layers.Dense(32, activation=\'relu\')(inputs)\n    results = keras.layers.Dense(5, activation=\'softmax\')(x)\n    model = keras.Model(inputs=inputs, outputs=results)\n\n    with self.assertRaises(ValueError):\n      quantize_apply(model)\n\n  def testRaisesErrorModelNotBuilt(self):\n    model = keras.Sequential([quantize_annotate_layer(keras.layers.Dense(10))])\n\n    self.assertFalse(model.built)\n    with self.assertRaises(ValueError):\n      quantize_apply(model)\n\n  def testRaisesErrorNotInstanceOfQuantizeConfig(self):\n    with self.assertRaises(ValueError):\n      keras.Sequential([\n          quantize_annotate_layer(\n              keras.layers.Dense(10),\n              quantize_config=object())\n      ])\n\n  # Helper functions to verify quantize wrapper applied correctly.\n\n  def _assert_weights_equal_value(self, annotated_weights, emulated_weights):\n    annotated_weight_values = K.batch_get_value(annotated_weights)\n    emulated_weight_values = K.batch_get_value(emulated_weights)\n\n    self.assertEqual(len(annotated_weight_values), len(emulated_weight_values))\n    for aw, ew in zip(annotated_weight_values, emulated_weight_values):\n      self.assertAllClose(aw, ew)\n\n  def _assert_weights_different_objects(\n      self, annotated_weights, emulated_weights):\n    self.assertEqual(len(annotated_weights), len(emulated_weights))\n    for aw, ew in zip(annotated_weights, emulated_weights):\n      self.assertNotEqual(id(aw), id(ew))\n\n  def _assert_layer_quantized(\n      self, annotate_wrapper, quantize_wrapper, exclude_keys=None):\n    self.assertIsInstance(quantize_wrapper, QuantizeWrapper)\n\n    # Extract configs of the inner layers they wrap.\n    annotated_config = annotate_wrapper.layer.get_config()\n    quantized_config = quantize_wrapper.layer.get_config()\n\n    # The underlying layers aren\'t always exactly the same. For example,\n    # activations in the underlying layers might be replaced. Exclude keys\n    # if required.\n    if exclude_keys:\n      for key in exclude_keys:\n        annotated_config.pop(key)\n        quantized_config.pop(key)\n\n    self.assertEqual(annotated_config, quantized_config)\n\n    def _sort_weights(weights):\n      # Variables are named `quantize_annotate0/kernel:0` and\n      # `quantize_emulate0/kernel:0`. Strip layer name to sort.\n      return sorted(weights, key=lambda w: w.name.split(\'/\')[1])\n\n    annotated_weights = _sort_weights(annotate_wrapper.trainable_weights)\n    quantized_weights = _sort_weights(quantize_wrapper.trainable_weights)\n\n    # Quantized model should pick the same weight values from the original\n    # model. However, they should not be the same weight objects. We don\'t\n    # want training the quantized model to change weights in the original model.\n    self._assert_weights_different_objects(annotated_weights, quantized_weights)\n    self._assert_weights_equal_value(annotated_weights, quantized_weights)\n\n  def _assert_model_quantized(\n      self, annotated_model, quantized_model, exclude_keys=None):\n    for layer_annotated, layer_quantized in \\\n        zip(annotated_model.layers, quantized_model.layers):\n\n      if not isinstance(layer_annotated, QuantizeAnnotate):\n        self.assertNotIsInstance(layer_quantized, QuantizeWrapper)\n        continue\n\n      self._assert_layer_quantized(\n          layer_annotated, layer_quantized, exclude_keys)\n\n  # quantize_apply Tests\n\n  class CustomLayer(keras.layers.Dense):\n    pass\n\n  def testQuantizeCustomLayerWithoutQuantizeScope_RaisesError(self):\n    annotated_model = keras.Sequential(\n        [quantize_annotate_layer(self.CustomLayer(3, input_shape=(2,)))])\n\n    with self.assertRaises(ValueError) as err:\n      quantize_apply(annotated_model)\n\n    expected_error = (\n        \'Unable to clone model. This generally happens if you used custom \'\n        \'Keras layers or objects in your model. Please specify them via \'\n        \'`quantize_scope` for your calls to `quantize_model` and \'\n        \'`quantize_apply`.\')\n\n    self.assertEqual(str(err.exception), expected_error)\n\n  def testQuantize_RaisesErrorIfNoQuantizeConfig(self):\n    annotated_model = keras.Sequential([\n        QuantizeAnnotate(self.CustomLayer(3), input_shape=(2,))])\n\n    with custom_object_scope({\'CustomLayer\': self.CustomLayer}):\n      with self.assertRaises(RuntimeError):\n        quantize_apply(annotated_model)\n\n  def testQuantize_UsesBuiltinQuantizeConfig(self):\n    annotated_model = keras.Sequential([\n        quantize_annotate_layer(keras.layers.Dense(3, input_shape=(2,)))])\n\n    quantized_model = quantize_apply(annotated_model)\n    quantized_layer = quantized_model.layers[1]\n\n    # \'activation\' gets replaced while quantizing the model. Hence excluded\n    # from equality checks.\n    self._assert_layer_quantized(\n        annotated_model.layers[0], quantized_layer, [\'activation\'])\n    self.assertIsInstance(\n        quantized_layer.quantize_config,\n        default_8bit_quantize_registry.Default8BitQuantizeConfig)\n\n  def testQuantize_UsesQuantizeConfigFromUser_NoBuiltIn(self):\n    annotated_model = keras.Sequential([\n        quantize_annotate_layer(\n            self.CustomLayer(3, input_shape=(2,)),\n            quantize_config=_TestQuantizeConfig())\n    ])\n\n    with custom_object_scope({\n        \'CustomLayer\': self.CustomLayer,\n        \'_TestQuantizeConfig\': _TestQuantizeConfig\n    }):\n      quantized_model = quantize_apply(annotated_model)\n    quantized_layer = quantized_model.layers[1]\n\n    self._assert_layer_quantized(annotated_model.layers[0], quantized_layer)\n    self.assertIsInstance(quantized_layer.quantize_config, _TestQuantizeConfig)\n\n  def testQuantize_PreferenceToUserSpecifiedQuantizeConfig(self):\n    annotated_model = keras.Sequential([\n        quantize_annotate_layer(\n            keras.layers.Dense(3, input_shape=(2,)),\n            quantize_config=_TestQuantizeConfig())\n    ])\n\n    with custom_object_scope({\'_TestQuantizeConfig\': _TestQuantizeConfig}):\n      quantized_model = quantize_apply(annotated_model)\n    quantized_layer = quantized_model.layers[1]\n\n    self._assert_layer_quantized(annotated_model.layers[0], quantized_layer)\n    self.assertIsInstance(quantized_layer.quantize_config, _TestQuantizeConfig)\n\n  def testAppliesQuantizationToAnnotatedModel_Sequential(self):\n    model = keras.Sequential([\n        keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1), activation=\'relu\'),\n        quantize_annotate_layer(keras.layers.Dense(10, activation=\'relu\')),\n        quantize_annotate_layer(keras.layers.Dense(5, activation=\'softmax\')),\n    ])\n\n    quantized_model = quantize_apply(model)\n\n    self._assert_model_quantized(model, quantized_model, [\'activation\'])\n\n  def testAppliesQuantizationToAnnotatedModel_PreservesBuiltState(self):\n    model = keras_test_utils.build_simple_dense_model()\n    annotated_model = quantize_annotate_model(model)\n\n    self.assertTrue(annotated_model.built)\n\n    quantized_model = quantize_apply(annotated_model)\n\n    self.assertTrue(quantized_model.built)\n\n  def _get_simple_functional_model(self):\n    inputs = keras.Input(shape=(28, 28, 1))\n    x = keras.layers.Conv2D(32, 5, activation=\'relu\')(inputs)\n    x = quantize_annotate_layer(keras.layers.Dense(10, activation=\'relu\'))(x)\n    results = quantize_annotate_layer(\n        keras.layers.Dense(5, activation=\'softmax\'))(\n            x)\n    return keras.Model(inputs=inputs, outputs=results)\n\n  def testAppliesQuantizationToAnnotatedModel_Functional(self):\n    model = self._get_simple_functional_model()\n    quantized_model = quantize_apply(model)\n\n    self._assert_model_quantized(model, quantized_model, [\'activation\'])\n\n  def testDoesNotQuantizeInputLayer_OutboundLayerNotQuantized(self):\n    model = self._get_simple_functional_model()\n\n    quantized_model = quantize_apply(model)\n\n    # Since first layer is not quantized, QuantizeLayer does not get inserted\n    # after InputLayer.\n\n    input_layer = quantized_model._input_layers[0]\n    next_layer = input_layer._outbound_nodes[0].outbound_layer\n    self.assertNotIsInstance(next_layer, quantize_layer.QuantizeLayer)\n\n  def testQuantizesInputLayer_OutboundLayerIsQuantized(self):\n    inputs = keras.Input(shape=(28, 28, 1))\n    x = quantize_annotate_layer(keras.layers.Conv2D(32, 5, activation=\'relu\'))(\n        inputs)\n    x = quantize_annotate_layer(keras.layers.Dense(10, activation=\'relu\'))(x)\n    model = keras.Model(inputs=inputs, outputs=x)\n\n    quantized_model = quantize_apply(model)\n\n    # First layer is quantized. Hence QuantizeLayer gets inserted after\n    # InputLayer.\n\n    input_layer = quantized_model._input_layers[0]\n    next_layer = input_layer._outbound_nodes[0].outbound_layer\n    self.assertIsInstance(next_layer, quantize_layer.QuantizeLayer)\n\n  # TODO(tfmot): this behavior may change in the future. If a user\n  # start training a model without quantization and then wants to apply\n  # it, not removing the optimizer would allow them to skip recompiling\n  # the model.\n  def testQuantizeApply_RemovesOptimizer(self):\n    model = keras_test_utils.build_simple_dense_model()\n    annotated_model = quantize_annotate_model(model)\n    annotated_model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n\n    self.assertIsNotNone(annotated_model.optimizer)\n\n    quantized_model = quantize_apply(annotated_model)\n    self.assertIsNone(quantized_model.optimizer)\n\n  def testQuantizeApply_RunsWhenNestedModelNotAnnotated(self):\n    annotated_model = keras.Sequential([\n        keras.Sequential([keras.layers.Dense(10, input_shape=(2,))]),\n        quantize_annotate_layer(keras.layers.Dense(10)),\n    ])\n\n    quantize_apply(annotated_model)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_wrapper.py,10,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Wrapper which applies quantization operations over underlying layer.\n\n   `QuantizeWrapper` is responsible for modifying the construction of the\n   underlying layer to ensure proper quantization operations are placed in the\n   graph.\n\n   These operations ensure proper introduction of inference time losses during\n   training.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras.utils import tf_utils\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\n\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\nserialize_keras_object = tf.keras.utils.serialize_keras_object\n\n\nclass QuantizeWrapper(tf.keras.layers.Wrapper):\n  """"""Quantizes the weights and activations of the keras layer it wraps.""""""\n\n  def __init__(self, layer, quantize_config, **kwargs):\n    """"""Create a quantize emulate wrapper for a keras layer.\n\n    Args:\n      layer: The keras layer to be quantized.\n      quantize_config: `QuantizeConfig` to quantize layer.\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n    """"""\n    if layer is None:\n      raise ValueError(\'`layer` cannot be None.\')\n\n    # Check against keras.Model since it is an instance of keras.layers.Layer.\n    if not isinstance(layer, tf.keras.layers.Layer) or isinstance(\n        layer, tf.keras.Model):\n      raise ValueError(\n          \'`layer` can only be a `tf.keras.layers.Layer` instance. \'\n          \'You passed an instance of type: {input}.\'.format(\n              input=layer.__class__.__name__))\n\n    if quantize_config is None:\n      raise ValueError(\'quantize_config cannot be None. It is needed to \'\n                       \'quantize a layer.\')\n\n    if \'name\' not in kwargs:\n      kwargs[\'name\'] = self._make_layer_name(layer)\n\n    super(QuantizeWrapper, self).__init__(layer, **kwargs)\n    self.quantize_config = quantize_config\n\n    self._track_trackable(layer, name=\'layer\')\n\n  @staticmethod\n  def _make_layer_name(layer):\n    return \'{}_{}\'.format(\'quant\', layer.name)\n\n  @staticmethod\n  def _weight_name(name):\n    """"""Extracts the weight name from the full TensorFlow variable name.\n\n    For example, returns \'kernel\' for \'dense_2/kernel:0\'.\n\n    Args:\n      name: TensorFlow variable name.\n\n    Returns:\n      Extracted weight name.\n    """"""\n    return name.split(\':\')[0].split(\'/\')[-1]\n\n  def build(self, input_shape):\n    super(QuantizeWrapper, self).build(input_shape)\n\n    self.optimizer_step = self.add_weight(\n        \'optimizer_step\',\n        initializer=tf.keras.initializers.Constant(-1),\n        dtype=tf.dtypes.int32,\n        trainable=False)\n\n    self._weight_vars = []\n    for weight, quantizer in \\\n        self.quantize_config.get_weights_and_quantizers(self.layer):\n      quantizer_vars = quantizer.build(weight.shape,\n                                       self._weight_name(weight.name), self)\n\n      self._weight_vars.append((weight, quantizer, quantizer_vars))\n      # Needed to ensure unquantized weights get trained as part of the wrapper.\n      self._trainable_weights.append(weight)\n\n    self._quantize_activations = []\n    for activation, quantizer in \\\n        self.quantize_config.get_activations_and_quantizers(self.layer):\n      quantize_activation = quantize_aware_activation.QuantizeAwareActivation(\n          activation, quantizer, self.optimizer_step, self)\n\n      self._quantize_activations.append(quantize_activation)\n\n    self._output_quantizers = self.quantize_config.get_output_quantizers(\n        self.layer)\n    if self._output_quantizers:\n      self._output_quantizer_vars = self._output_quantizers[0].build(\n          self.layer.compute_output_shape(input_shape), \'output\', self)\n\n  def compute_output_shape(self, input_shape):\n    return self.layer.compute_output_shape(self.layer.input_shape)\n\n  def _make_quantizer_fn(self, quantizer, x, training, quantizer_vars):\n    """"""Use currying to return True/False specialized fns to the cond.""""""\n\n    def quantizer_fn():\n      return quantizer(x, training, weights=quantizer_vars)\n\n    return quantizer_fn\n\n  def call(self, inputs, training=None):\n    if training is None:\n      training = tf.keras.backend.learning_phase()\n\n    # Quantize all weights, and replace them in the underlying layer.\n\n    quantized_weights = []\n    for unquantized_weight, quantizer, quantizer_vars in self._weight_vars:\n      quantized_weight = tf_utils.smart_cond(\n          training,\n          self._make_quantizer_fn(quantizer, unquantized_weight, True,\n                                  quantizer_vars),\n          self._make_quantizer_fn(quantizer, unquantized_weight, False,\n                                  quantizer_vars))\n      quantized_weights.append(quantized_weight)\n\n    self.quantize_config.set_quantize_weights(self.layer, quantized_weights)\n\n    # Replace all activations with `QuantizeAwareActivation`s which can\n    # quantize activation tensors during graph construction.\n\n    for quantize_activation in self._quantize_activations:\n      quantize_activation.training = training\n\n    self.quantize_config.set_quantize_activations(self.layer,\n                                                  self._quantize_activations)\n\n    outputs = self.layer.call(inputs)\n\n    if not self._output_quantizers:\n      return outputs\n\n    # Assuming outputs is a single tensor. There might be some rare layers\n    # where this is not true. Handle them when enabling such a layer.\n    if isinstance(outputs, list) or isinstance(outputs, tuple):\n      raise RuntimeError(\'Multiple output tensors not handled currently.\')\n\n    output_quantizer = self._output_quantizers[0]\n    return tf_utils.smart_cond(\n        training,\n        self._make_quantizer_fn(output_quantizer, outputs, True,\n                                self._output_quantizer_vars),\n        self._make_quantizer_fn(output_quantizer, outputs, False,\n                                self._output_quantizer_vars))\n\n  def get_config(self):\n    base_config = super(QuantizeWrapper, self).get_config()\n    config = {\'quantize_config\': serialize_keras_object(self.quantize_config)}\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    config = config.copy()\n\n    # QuantizeWrapper may be constructed with any QuantizeConfig and the\n    # wrapper itself cannot know all the possible config classes.\n    # The deserialization code should ensure the QuantizeConfig is in keras\n    # serialization scope.\n    quantize_config = deserialize_keras_object(\n        config.pop(\'quantize_config\'),\n        module_objects=globals(),\n        custom_objects=None)\n\n    layer = tf.keras.layers.deserialize(config.pop(\'layer\'))\n\n    return cls(layer=layer, quantize_config=quantize_config, **config)\n\n  @property\n  def trainable(self):\n    return self.layer.trainable\n\n  @trainable.setter\n  def trainable(self, value):\n    self.layer.trainable = value\n\n  @property\n  def trainable_weights(self):\n    return self.layer.trainable_weights + self._trainable_weights\n\n  @property\n  def non_trainable_weights(self):\n    return self.layer.non_trainable_weights + self._non_trainable_weights\n\n  @property\n  def updates(self):\n    return self.layer.updates + self._updates\n\n  @property\n  def losses(self):\n    return self.layer.losses + self._losses\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantize_wrapper_test.py,11,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for QuantizeWrapper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_wrapper\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\n\nQuantizeAwareActivation = quantize_aware_activation.QuantizeAwareActivation\nQuantizeWrapper = quantize_wrapper.QuantizeWrapper\nQuantizeRegistry = default_8bit_quantize_registry.QuantizeRegistry\n\nkeras = tf.keras\nlayers = tf.keras.layers\n\ncustom_object_scope = tf.keras.utils.custom_object_scope\ndeserialize_layer = tf.keras.layers.deserialize\nserialize_layer = tf.keras.layers.serialize\n\n\nclass QuantizeWrapperTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(QuantizeWrapperTest, self).setUp()\n    self.quantize_registry = QuantizeRegistry()\n\n  def testQuantizesWeightsInLayer(self):\n    weights = lambda shape, dtype: np.array([[-1.0, 0.0], [0.0, 1.0]])\n    layer = keras.layers.Dense(2, kernel_initializer=weights)\n\n    model = keras.Sequential([\n        QuantizeWrapper(\n            layer=layer,\n            quantize_config=self.quantize_registry.get_quantize_config(layer),\n            input_shape=(2,))\n    ])\n\n    # FakeQuant([-1.0, 1.0]) = [-0.9882355, 0.9882355]\n    # Obtained from tf.fake_quant_with_min_max_vars\n    self.assertAllClose(\n        np.array([[-0.9882355, 0.9882355]]),\n        # Inputs are all ones, so result comes directly from weights.\n        model.predict(np.ones((1, 2))))\n\n  # TODO(pulkitb): Extend test to support more layers.\n  # The test validates several keras layers, but has limitations currently.\n  #  1. Only layers with \'kernel\' attribute work. Need to extend to others.\n  #  2. Activations are not tested currently.\n  #  3. RNN layers need to be added\n  # TODO(tfmot): reenable some of these once added back to whitelist\n  # after testing in quantize_functional_test.py.\n  @parameterized.parameters(\n      # (layers.Conv1D, (3, 6), {\n      #     \'filters\': 4,\n      #     \'kernel_size\': 2\n      # }),\n      (layers.Conv2D, (4, 6, 1), {\n          \'filters\': 4,\n          \'kernel_size\': (2, 2)\n      }),\n      # (layers.Conv2DTranspose, (7, 6, 3), {\n      #     \'filters\': 2,\n      #     \'kernel_size\': (3, 3)\n      # }),\n      # (layers.Conv3D, (5, 7, 6, 3), {\n      #     \'filters\': 2,\n      #     \'kernel_size\': (3, 3, 3)\n      # }),\n      # (layers.Conv3DTranspose, (5, 7, 6, 3), {\n      #     \'filters\': 2,\n      #    \'kernel_size\': (3, 3, 3)\n      # }),\n      # TODO(pulkitb): Add missing SeparableConv layers. The initializers are\n      # different, so will need a change.\n      (layers.Dense, (3,), {\n          \'units\': 2\n      }),\n      # (layers.LocallyConnected1D, (3, 6), {\n      #     \'filters\': 4,\n      #     \'kernel_size\': 2\n      # }),\n      # (layers.LocallyConnected2D, (4, 6, 1), {\n      #     \'filters\': 4,\n      #     \'kernel_size\': (2, 2)\n      # })\n  )\n  def testQuantizesWeights_KerasLayers(self, layer_type, input_shape, kwargs):\n    self.weights = None\n\n    def _get_random_weights(shape, dtype):  # pylint: disable=unused-argument\n      self.weights = np.random.rand(*shape)\n      return self.weights\n\n    def _get_quantized_weights(shape, dtype):  # pylint: disable=unused-argument\n      assert tuple(shape) == self.weights.shape\n\n      # Default values used in DefaultRegistry.\n      return tf.quantization.fake_quant_with_min_max_vars(\n          self.weights, -6.0, 6.0, num_bits=8, narrow_range=True)\n\n    layer = layer_type(kernel_initializer=_get_random_weights, **kwargs)\n    quantized_model = keras.Sequential([\n        QuantizeWrapper(\n            layer=layer,\n            quantize_config=self.quantize_registry.get_quantize_config(layer),\n            input_shape=input_shape)\n    ])\n    # `model` gets constructed with same parameters as `quantized_model`. The\n    # weights used are a quantized version of weights used in `quantized_model`.\n    # This ensures the results of both the models should be the same since\n    # quantization has been applied externally to `model`.\n    model = keras.Sequential([\n        layer_type(\n            input_shape=input_shape,\n            kernel_initializer=_get_quantized_weights,\n            **kwargs)\n    ])\n\n    inputs = np.random.rand(1, *input_shape)\n    # `quantized_model` should apply FakeQuant. Explicitly applying to the\n    # results of `model` to verify QuantizeWrapper works as expected.\n    expected_output = tf.quantization.fake_quant_with_min_max_vars(\n        model.predict(inputs), -6.0, 6.0, num_bits=8, narrow_range=False)\n    self.assertAllClose(expected_output, quantized_model.predict(inputs))\n\n  def testQuantizesOutputsFromLayer(self):\n    # TODO(pulkitb): Increase coverage by adding other output quantize layers\n    # such as AveragePooling etc.\n\n    layer = layers.ReLU()\n    quantized_model = keras.Sequential([\n        QuantizeWrapper(\n            layers.ReLU(),\n            quantize_config=self.quantize_registry.get_quantize_config(layer))\n    ])\n\n    model = keras.Sequential([layers.ReLU()])\n\n    inputs = np.random.rand(1, 2, 1)\n    expected_output = tf.quantization.fake_quant_with_min_max_vars(\n        model.predict(inputs), -6.0, 6.0, num_bits=8, narrow_range=False)\n    self.assertAllClose(expected_output, quantized_model.predict(inputs))\n\n  def testSerializationQuantizeWrapper(self):\n    input_shape = (2,)\n    layer = keras.layers.Dense(3)\n    wrapper = QuantizeWrapper(\n        layer=layer,\n        quantize_config=self.quantize_registry.get_quantize_config(layer),\n        input_shape=input_shape)\n\n    custom_objects = {\n        \'QuantizeAwareActivation\': QuantizeAwareActivation,\n        \'QuantizeWrapper\': QuantizeWrapper\n    }\n    custom_objects.update(default_8bit_quantize_registry._types_dict())\n\n    serialized_wrapper = serialize_layer(wrapper)\n    with custom_object_scope(custom_objects):\n      wrapper_from_config = deserialize_layer(serialized_wrapper)\n\n    self.assertEqual(wrapper_from_config.get_config(), wrapper.get_config())\n\n  def testQuantizeWrapper_FailsWithModel(self):\n    layer = keras.layers.Dense(5, activation=\'relu\', input_shape=(10,))\n    model = keras.Sequential([layer])\n\n    with self.assertRaises(ValueError):\n      QuantizeWrapper(\n          model,\n          quantize_config=self.quantize_registry.get_quantize_config(layer))\n\n  # TODO(pulkitb): Add test to ensure weights are also preserved.\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantizers.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantizer classes which implement quantization using TF Ops on a tensor.\n\nModule: tfmot.quantization.keras\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport six\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quant_ops\n\nkeras = tf.keras\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Quantizer(object):\n  """"""ABC interface which encapsulates the logic of how to quantize tensors.\n\n  This is an experimental API not subject to backward compatibility.\n\n  A `Quantizer` is used by the library code to apply the mathematical\n  transformations which actually quantize a tensor, hence allowing the user\n  precise control over the algorithm with which tensors are quantized. When used\n  in conjunction with `QuantizeConfig` it controls how a layer is quantized.\n\n  Create a custom quantizer:\n\n  ```python\n  class FixedRangeQuantizer(Quantizer):\n    # Example quantizer which clips tensors in a fixed range.\n\n    def build(self, tensor_shape, name, layer):\n      range_var = layer.add_weight(\n        name + \'_range\',\n        initializer=keras.initializers.Constant(6.0),\n        trainable=False)\n\n      return {\n        \'range_var\': range_var,\n      }\n\n    def __call__(self, inputs, training, weights, **kwargs):\n      return tf.keras.backend.clip(\n          inputs, 0.0, weights[\'range_var\'])\n\n    def get_config(self):\n      # Not needed. No __init__ parameters to serialize.\n      return {}\n  ```\n\n  For a full example, see\n  https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide.md\n  """"""\n\n  @abc.abstractmethod\n  def build(self, tensor_shape, name, layer):\n    """"""Construct the weights required by the quantizer.\n\n    A quantizer may need to construct variables to hold the state for its\n    algorithm. This function is invoked during the `build` stage of the layer\n    that the quantizer is used for. Any variables constructed are under the\n    scope of the `layer` and serialized as part of the layer.\n\n    Args:\n      tensor_shape: Shape of tensor which needs to be quantized.\n      name: Name of tensor.\n      layer: Keras layer which is quantizing the tensors. The layer is needed\n        to construct the weights, and is also the owner of the weights.\n\n    Returns: Dictionary of constructed weights. This dictionary will be\n      passed to the quantizer\'s __call__ function as a `weights` dictionary.\n    """"""\n\n  @abc.abstractmethod\n  def __call__(self, inputs, training, weights, **kwargs):\n    """"""Apply quantization to the input tensor.\n\n    This is the main function of the `Quantizer` which implements the core logic\n    to quantize the tensor. It is invoked during the `call` stage of the layer,\n    and allows modifying the tensors used in graph construction.\n\n    Args:\n      inputs: Input tensor to be quantized.\n      training: Whether the graph is currently training.\n      weights: Dictionary of weights the quantizer can use to quantize the\n        tensor. This contains the weights created in the `build` function.\n      **kwargs: Additional variables which may be passed to the quantizer.\n\n    Returns: quantized tensor.\n    """"""\n\n  @abc.abstractmethod\n  def get_config(self):\n    """"""Returns the config used to serialize the `Quantizer`.""""""\n    raise NotImplementedError(\'Quantizer should implement get_config().\')\n\n  @classmethod\n  def from_config(cls, config):\n    """"""Instantiates a `Quantizer` from its config.\n\n    Args:\n        config: Output of `get_config()`.\n\n    Returns:\n        A `Quantizer` instance.\n    """"""\n    return cls(**config)\n\n\nclass _QuantizeHelper(object):\n  """"""Mixin with helper functions for quantizers.""""""\n\n  def _add_range_weights(self, layer, name):\n    """"""Add min and max vars to layer.""""""\n    min_weight = layer.add_weight(\n        name + \'_min\',\n        initializer=keras.initializers.Constant(-6.0),\n        trainable=False)\n    max_weight = layer.add_weight(\n        name + \'_max\',\n        initializer=keras.initializers.Constant(6.0),\n        trainable=False)\n\n    return {\'min_var\': min_weight, \'max_var\': max_weight}\n\n\nclass LastValueQuantizer(_QuantizeHelper, Quantizer):\n  """"""Quantize tensor based on range the last batch of values.""""""\n\n  # TODO(pulkitb): Decide and change num_bits to num_fixedpoint_values.\n\n  def __init__(self, num_bits, per_axis, symmetric, narrow_range):\n    """"""Construct a LastValueQuantizer.\n\n    This is an experimental API not subject to backward compatibility.\n\n    Args:\n      num_bits: Number of bits for quantization\n      per_axis: Whether to apply per_axis quantization. The last dimension is\n        used as the axis.\n      symmetric: If true, use symmetric quantization limits instead of training\n        the minimum and maximum of each quantization range separately.\n      narrow_range: In case of 8 bits, narrow_range nudges the quantized range\n        to be [-127, 127] instead of [-128, 127]. This ensures symmetric\n        range has 0 as the centre.\n    """"""\n    self.num_bits = num_bits\n    self.per_axis = per_axis\n    self.symmetric = symmetric\n    self.narrow_range = narrow_range\n\n  def build(self, tensor_shape, name, layer):\n    return self._add_range_weights(layer, name)\n\n  def __call__(self, inputs, training, weights, **kwargs):\n    """"""Quantize tensor.\n\n    Args:\n      inputs: Input tensor to be quantized.\n      training: Whether the graph is currently training.\n      weights: Dictionary of weights the quantizer can use to quantize the\n        tensor. This contains the weights created in the `build` function.\n      **kwargs: Additional variables which may be passed to the quantizer.\n\n    Returns:\n      Quantized tensor.\n    """"""\n    return quant_ops.LastValueQuantize(\n        inputs,\n        weights[\'min_var\'],\n        weights[\'max_var\'],\n        is_training=training,\n        num_bits=self.num_bits,\n        per_channel=self.per_axis,\n        symmetric=self.symmetric,\n        narrow_range=self.narrow_range\n    )\n\n  def get_config(self):\n    return {\n        \'num_bits\': self.num_bits,\n        \'per_axis\': self.per_axis,\n        \'symmetric\': self.symmetric,\n        \'narrow_range\': self.narrow_range\n    }\n\n  def __eq__(self, other):\n    if not isinstance(other, LastValueQuantizer):\n      return False\n\n    return (self.num_bits == other.num_bits and\n            self.per_axis == other.per_axis and\n            self.symmetric == other.symmetric and\n            self.narrow_range == other.narrow_range)\n\n  def __ne__(self, other):\n    return not self.__eq__(other)\n\n\nclass MovingAverageQuantizer(_QuantizeHelper, Quantizer):\n  """"""Quantize tensor based on a moving average of values across batches.""""""\n\n  def __init__(self, num_bits, per_axis, symmetric, narrow_range):\n    """"""Construct a MovingAverageQuantizer.\n\n    This is an experimental API not subject to backward compatibility.\n\n    Args:\n      num_bits: Number of bits for quantization\n      per_axis: Whether to apply per_axis quantization. The last dimension is\n        used as the axis.\n      symmetric: If true, use symmetric quantization limits instead of training\n        the minimum and maximum of each quantization range separately.\n      narrow_range: In case of 8 bits, narrow_range nudges the quantized range\n        to be [-127, 127] instead of [-128, 127]. This ensures symmetric\n        range has 0 as the centre.\n    """"""\n    self.num_bits = num_bits\n    self.per_axis = per_axis\n    self.symmetric = symmetric\n    self.narrow_range = narrow_range\n\n  def build(self, tensor_shape, name, layer):\n    return self._add_range_weights(layer, name)\n\n  def __call__(self, inputs, training, weights, **kwargs):\n    """"""Quantize tensor.\n\n    Args:\n      inputs: Input tensor to be quantized.\n      training: Whether the graph is currently training.\n      weights: Dictionary of weights the quantizer can use to quantize the\n        tensor. This contains the weights created in the `build` function.\n      **kwargs: Additional variables which may be passed to the quantizer.\n\n    Returns:\n      Quantized tensor.\n    """"""\n    return quant_ops.MovingAvgQuantize(\n        inputs,\n        weights[\'min_var\'],\n        weights[\'max_var\'],\n        ema_decay=0.999,\n        is_training=training,\n        num_bits=self.num_bits,\n        per_channel=self.per_axis,\n        symmetric=self.symmetric,\n        narrow_range=self.narrow_range,\n    )\n\n  def get_config(self):\n    return {\n        \'num_bits\': self.num_bits,\n        \'per_axis\': self.per_axis,\n        \'symmetric\': self.symmetric,\n        \'narrow_range\': self.narrow_range\n    }\n\n  def __eq__(self, other):\n    if not isinstance(other, MovingAverageQuantizer):\n      return False\n\n    return (self.num_bits == other.num_bits and\n            self.per_axis == other.per_axis and\n            self.symmetric == other.symmetric and\n            self.narrow_range == other.narrow_range)\n\n  def __ne__(self, other):\n    return not self.__eq__(other)\n\n\ndef _types_dict():\n  return {\n      \'LastValueQuantizer\': LastValueQuantizer,\n      \'MovingAverageQuantizer\': MovingAverageQuantizer\n  }\n'"
tensorflow_model_optimization/python/core/quantization/keras/quantizers_test.py,8,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Quantizers.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\nserialize_keras_object = tf.keras.utils.serialize_keras_object\n\n\n@keras_parameterized.run_all_keras_modes\n@parameterized.parameters(\n    quantizers.LastValueQuantizer, quantizers.MovingAverageQuantizer)\nclass QuantizersTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(QuantizersTest, self).setUp()\n    self.quant_params = {\n        \'num_bits\': 8,\n        \'per_axis\': False,\n        \'symmetric\': False,\n        \'narrow_range\': False\n    }\n\n  def _test_quantizer(self, quantizer):\n    inputs = tf.Variable(\n        np.array([[-1.0, 0.5], [0.0, 1.0]]),\n        name=\'inputs\',\n        dtype=tf.dtypes.float32)\n    min_var = tf.Variable(0.0)\n    max_var = tf.Variable(0.0)\n\n    weights = {\'min_var\': min_var, \'max_var\': max_var}\n    quant_tensor = quantizer(inputs, training=True, weights=weights)\n\n    compat.initialize_variables(self)\n    results = self.evaluate(quant_tensor)\n    min_max_values = self.evaluate([min_var, max_var])\n\n    # TODO(pulkitb): Assert on expected values for testing.\n    # Since the underlying code is already tested in quant_ops_test.py, this\n    # just ensures the Quantizers code is wired properly.\n    print(\'Result: \', results)\n    print(\'min_var: \', min_max_values[0])\n    print(\'max_var: \', min_max_values[1])\n\n  def testQuantizer(self, quantizer_type):\n    quantizer = quantizer_type(**self.quant_params)\n\n    self._test_quantizer(quantizer)\n\n  def testSerialization(self, quantizer_type):\n    quantizer = quantizer_type(**self.quant_params)\n\n    expected_config = {\n        \'class_name\': quantizer_type.__name__,\n        \'config\': {\n            \'num_bits\': 8,\n            \'per_axis\': False,\n            \'symmetric\': False,\n            \'narrow_range\': False\n        }\n    }\n    serialized_quantizer = serialize_keras_object(quantizer)\n\n    self.assertEqual(expected_config, serialized_quantizer)\n\n    quantizer_from_config = deserialize_keras_object(\n        serialized_quantizer,\n        module_objects=globals(),\n        custom_objects=quantizers._types_dict())\n\n    self.assertEqual(quantizer, quantizer_from_config)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/utils.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=protected-access\n""""""Quantization specific utilities for generating, saving, testing, and evaluating models.""""""\n\nimport tempfile\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import compat\n\n\ndef convert_keras_to_tflite(model,\n                            output_path,\n                            custom_objects=None,\n                            is_quantized=True,\n                            inference_type=None,\n                            inference_input_type=None,\n                            input_quant_params=(-128., 255.),\n                            experimental_new_converter=True):\n  """"""Convert Keras model to TFLite.""""""\n  if custom_objects is None:\n    custom_objects = {}\n\n  if not compat.is_v1_apis():\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n  else:\n    _, keras_file = tempfile.mkstemp(\'.h5\')\n    tf.keras.models.save_model(model, keras_file)\n    converter = tf.lite.TFLiteConverter.from_keras_model_file(\n        keras_file, custom_objects=custom_objects)\n\n  converter.experimental_new_converter = experimental_new_converter\n\n  if is_quantized:\n    if not compat.is_v1_apis():\n      converter.optimizations = [tf.lite.Optimize.DEFAULT]\n    else:\n      converter.inference_type = tf.lite.constants.INT8\n      converter.inference_input_type = tf.lite.constants.FLOAT\n      # TODO(tfmot): should be able to make everything use the\n      # same inference_type in TF 1.X tests.\n      if inference_type:\n        converter.inference_type = inference_type\n      if inference_input_type:\n        converter.inference_input_type = inference_input_type\n\n      input_arrays = converter.get_input_arrays()\n      converter.quantized_input_stats = {\n          input_arrays[0]: input_quant_params\n      }  # mean, std_dev values for float to quantized int8 values.\n\n  tflite_model = converter.convert()\n\n  if output_path is not None:\n    with open(output_path, \'wb\') as f:\n      f.write(tflite_model)\n\n  return tflite_model\n'"
tensorflow_model_optimization/python/core/sparsity/keras/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/sparsity/keras/estimator_utils.py,0,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Utility functions for making pruning wrapper work with estimators.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n# import g3\n\nfrom tensorflow.python.estimator.model_fn import EstimatorSpec\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.training import monitored_session\nfrom tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper import PruneLowMagnitude\n\n\nclass PruningEstimatorSpec(EstimatorSpec):\n  """"""Returns an EstimatorSpec modified to prune the model while training.""""""\n\n  def __new__(cls, model, step=None, train_op=None, **kwargs):\n    if ""mode"" not in kwargs:\n      raise ValueError(""Must provide a mode (TRAIN/EVAL/PREDICT) when ""\n                       ""creating an EstimatorSpec"")\n\n    if train_op is None:\n      raise ValueError(\n          ""Must provide train_op for creating a PruningEstimatorSpec"")\n\n    def _get_step_increment_ops(model, step=None):\n      """"""Returns ops to increment the pruning_step in the prunable layers.""""""\n      increment_ops = []\n\n      for layer in model.layers:\n        if isinstance(layer, PruneLowMagnitude):\n          if step is None:\n            # Add ops to increment the pruning_step by 1\n            increment_ops.append(state_ops.assign_add(layer.pruning_step, 1))\n          else:\n            increment_ops.append(\n                state_ops.assign(layer.pruning_step,\n                                 math_ops.cast(step, dtypes.int32)))\n\n      return control_flow_ops.group(increment_ops)\n\n    pruning_ops = []\n    # Grab the ops to update pruning step in every prunable layer\n    step_increment_ops = _get_step_increment_ops(model, step)\n    pruning_ops.append(step_increment_ops)\n    # Grab the model updates.\n    pruning_ops.append(model.updates)\n\n    kwargs[""train_op""] = control_flow_ops.group(pruning_ops, train_op)\n\n    def init_fn(scaffold, session):  # pylint: disable=unused-argument\n      return session.run(step_increment_ops)\n\n    def get_new_scaffold(old_scaffold):\n      if old_scaffold.init_fn is None:\n        return monitored_session.Scaffold(\n            init_fn=init_fn, copy_from_scaffold=old_scaffold)\n      # TODO(suyoggupta): Figure out a way to merge the init_fn of the\n      # original scaffold with the one defined above.\n      raise ValueError(""Scaffold provided to PruningEstimatorSpec must not ""\n                       ""set an init_fn."")\n\n    scaffold = monitored_session.Scaffold(init_fn=init_fn)\n    if ""scaffold"" in kwargs:\n      scaffold = get_new_scaffold(kwargs[""scaffold""])\n\n    kwargs[""scaffold""] = scaffold\n\n    return super(PruningEstimatorSpec, cls).__new__(cls, **kwargs)\n\n\ndef add_pruning_summaries(model):\n  """"""Add pruning summaries to the graph for the given model.""""""\n\n  with ops.name_scope(""pruning_summaries""):\n    for layer in model.layers:\n      if isinstance(layer, PruneLowMagnitude):\n        # Add the summary under the underlying layer\'s name_scope.\n        # TODO(suyoggupta): Look for a less ugly way of doing this.\n        with ops.name_scope(layer.layer.name):\n          layer.pruning_obj.add_pruning_summaries()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prunable_layer.py,0,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Abstract Base Class for making a custom keras layer prunable.""""""\n\nimport abc\nimport six\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass PrunableLayer(object):\n  """"""Abstract Base Class for making your own keras layer prunable.\n\n  Custom keras layers which want to add pruning should implement this class.\n\n  """"""\n\n  @abc.abstractmethod\n  def get_prunable_weights(self):\n    """"""Returns list of prunable weight tensors.\n\n    All the weight tensors which the layer wants to be pruned during\n    training must be returned by this method.\n\n    Returns: List of weight tensors/kernels in the keras layer which must be\n        pruned during training.\n    """"""\n    raise NotImplementedError(\'Must be implemented in subclasses.\')\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune.py,15,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=protected-access,missing-docstring,unused-argument\n""""""Entry point for pruning models during training.""""""\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule as pruning_sched\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\nkeras = tf.keras\ncustom_object_scope = tf.keras.utils.custom_object_scope\n\n\ndef prune_scope():\n  """"""Provides a scope in which Pruned layers and models can be deserialized.\n\n  For TF 2.X: this is not needed for SavedModel or TF checkpoints, which are\n  the recommended serialization formats.\n\n  For TF 1.X: if a tf.keras h5 model or layer has been pruned, it needs to be\n  within this\n  scope to be successfully deserialized. This is not needed for loading just\n  keras weights.\n\n  Returns:\n      Object of type `CustomObjectScope` with pruning objects included.\n\n  Example:\n\n  ```python\n  pruned_model = prune_low_magnitude(model, **self.params)\n  keras.models.save_model(pruned_model, keras_file)\n\n  with prune_scope():\n    loaded_model = keras.models.load_model(keras_file)\n  ```\n  """"""\n  return custom_object_scope(\n      {\'PruneLowMagnitude\': pruning_wrapper.PruneLowMagnitude})\n\n\ndef prune_low_magnitude(to_prune,\n                        pruning_schedule=pruning_sched.ConstantSparsity(0.5, 0),\n                        block_size=(1, 1),\n                        block_pooling_type=\'AVG\',\n                        **kwargs):\n  """"""Modify a tf.keras layer or model to be pruned during training.\n\n  This function wraps a tf.keras model or layer with pruning functionality which\n  sparsifies the layer\'s weights during training. For example, using this with\n  50% sparsity will ensure that 50% of the layer\'s weights are zero.\n\n  The function accepts either a single keras layer\n  (subclass of `tf.keras.layers.Layer`), list of keras layers or a Sequential\n  or Functional tf.keras model and handles them appropriately.\n\n  If it encounters a layer it does not know how to handle, it will throw an\n  error. While pruning an entire model, even a single unknown layer would lead\n  to an error.\n\n  Prune a model:\n\n  ```python\n  pruning_params = {\n      \'pruning_schedule\': ConstantSparsity(0.5, 0),\n      \'block_size\': (1, 1),\n      \'block_pooling_type\': \'AVG\'\n  }\n\n  model = prune_low_magnitude(\n      keras.Sequential([\n          layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n          layers.Dense(2, activation=\'sigmoid\')\n      ]), **pruning_params)\n  ```\n\n  Prune a layer:\n\n  ```python\n  pruning_params = {\n      \'pruning_schedule\': PolynomialDecay(initial_sparsity=0.2,\n          final_sparsity=0.8, begin_step=1000, end_step=2000),\n      \'block_size\': (2, 3),\n      \'block_pooling_type\': \'MAX\'\n  }\n\n  model = keras.Sequential([\n      layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n      prune_low_magnitude(layers.Dense(2, activation=\'tanh\'), **pruning_params)\n  ])\n  ```\n\n  Pretrained models: you must first load the weights and then apply the\n  prune API:\n\n  ```python\n  model.load_weights(...)\n  model = prune_low_magnitude(model)\n  ```\n\n  Optimizer: this function removes the optimizer. The user is expected to\n  compile the model\n  again. It\'s easiest to rely on the default (step starts at 0) and then\n  use that to determine the desired begin_step for the pruning_schedules.\n\n  Checkpointing: checkpointing should include the optimizer, not just the\n  weights. Pruning supports\n  checkpointing though\n  upon inspection, the weights of checkpoints are not sparse\n  (https://github.com/tensorflow/model-optimization/issues/206).\n\n  Arguments:\n      to_prune: A single keras layer, list of keras layers, or a\n        `tf.keras.Model` instance.\n      pruning_schedule: A `PruningSchedule` object that controls pruning rate\n        throughout training.\n      block_size: (optional) The dimensions (height, weight) for the block\n        sparse pattern in rank-2 weight tensors.\n      block_pooling_type: (optional) The function to use to pool weights in the\n        block. Must be \'AVG\' or \'MAX\'.\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n        Ignored when to_prune is not a keras layer.\n\n  Returns:\n    Layer or model modified with pruning wrappers. Optimizer is removed.\n\n  Raises:\n    ValueError: if the keras layer is unsupported, or the keras model contains\n    an unsupported layer.\n  """"""\n\n  def _prune_list(layers, **params):\n    wrapped_layers = []\n\n    for layer in layers:\n      # Allow layer that is already wrapped by the pruning wrapper\n      # to be used as is.\n      # No need to wrap the input layer either.\n      if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n        wrapped_layers.append(layer)\n      elif isinstance(layer, keras.layers.InputLayer):\n        # TODO(yunluli): Replace with a clone function in keras.\n        wrapped_layers.append(layer.__class__.from_config(layer.get_config()))\n      else:\n        wrapped_layers.append(\n            pruning_wrapper.PruneLowMagnitude(layer, **params))\n\n    return wrapped_layers\n\n  def _add_pruning_wrapper(layer):\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      return layer\n    return pruning_wrapper.PruneLowMagnitude(layer, **params)\n\n  params = {\n      \'pruning_schedule\': pruning_schedule,\n      \'block_size\': block_size,\n      \'block_pooling_type\': block_pooling_type\n  }\n  is_sequential_or_functional = isinstance(\n      to_prune, keras.Model) and (isinstance(to_prune, keras.Sequential) or\n                                  to_prune._is_graph_network)\n\n  # A subclassed model is also a subclass of keras.layers.Layer.\n  is_keras_layer = isinstance(\n      to_prune, keras.layers.Layer) and not isinstance(to_prune, keras.Model)\n\n  if isinstance(to_prune, list):\n    return _prune_list(to_prune, **params)\n  elif is_sequential_or_functional:\n    return keras.models.clone_model(\n        to_prune, input_tensors=None, clone_function=_add_pruning_wrapper)\n  elif is_keras_layer:\n    params.update(kwargs)\n    return pruning_wrapper.PruneLowMagnitude(to_prune, **params)\n  else:\n    raise ValueError(\n        \'`prune_low_magnitude` can only prune an object of the following \'\n        \'types: tf.keras.models.Sequential, tf.keras functional model, \'\n        \'tf.keras.layers.Layer, list of tf.keras.layers.Layer. You passed \'\n        \'an object of type: {input}.\'.format(input=to_prune.__class__.__name__))\n\n\ndef strip_pruning(model):\n  """"""Strip pruning wrappers from the model.\n\n  Once a model has been pruned to required sparsity, this method can be used\n  to restore the original model with the sparse weights.\n\n  Only sequential and functional models are supported for now.\n\n  Arguments:\n      model: A `tf.keras.Model` instance with pruned layers.\n\n  Returns:\n    A keras model with pruning wrappers removed.\n\n  Raises:\n    ValueError: if the model is not a `tf.keras.Model` instance.\n    NotImplementedError: if the model is a subclass model.\n\n  Usage:\n\n  ```python\n  orig_model = tf.keras.Model(inputs, outputs)\n  pruned_model = prune_low_magnitude(orig_model)\n  exported_model = strip_pruning(pruned_model)\n  ```\n  The exported_model and the orig_model share the same structure.\n  """"""\n\n  if not isinstance(model, keras.Model):\n    raise ValueError(\n        \'Expected model to be a `tf.keras.Model` instance but got: \', model)\n\n  def _strip_pruning_wrapper(layer):\n    if isinstance(layer, tf.keras.Model):\n      # A keras model with prunable layers\n      return keras.models.clone_model(\n          layer, input_tensors=None, clone_function=_strip_pruning_wrapper)\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      # The _batch_input_shape attribute in the first layer makes a Sequential\n      # model to be built. This makes sure that when we remove the wrapper from\n      # the first layer the model\'s built state preserves.\n      if not hasattr(layer.layer, \'_batch_input_shape\') and hasattr(\n          layer, \'_batch_input_shape\'):\n        layer.layer._batch_input_shape = layer._batch_input_shape\n      return layer.layer\n    return layer\n\n  return keras.models.clone_model(\n      model, input_tensors=None, clone_function=_strip_pruning_wrapper)\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune_distributed_test.py,7,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Distributed pruning test.""""""\n\nimport tempfile\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import test_utils\n\nkeras = tf.keras\n\n\ndef _distribution_strategies():\n  return [\n      tf.distribute.experimental.MultiWorkerMirroredStrategy(),\n      tf.distribute.MirroredStrategy(),\n      # TODO(pulkitb): Add parameter_server\n      # tf.distribute.experimental.ParameterServerStrategy,\n      tf.distribute.OneDeviceStrategy(\'/cpu:0\'),\n  ]\n\n\nclass PruneDistributedTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(PruneDistributedTest, self).setUp()\n    self.params = {\n        \'pruning_schedule\': pruning_schedule.ConstantSparsity(0.5, 0, -1, 1),\n        \'block_size\': (1, 1),\n        \'block_pooling_type\': \'AVG\'\n    }\n\n  @parameterized.parameters(_distribution_strategies())\n  def testPrunesSimpleDenseModel(self, distribution):\n    with distribution.scope():\n      model = prune.prune_low_magnitude(\n          keras_test_utils.build_simple_dense_model(), **self.params)\n      model.compile(\n          loss=\'categorical_crossentropy\',\n          optimizer=\'sgd\',\n          metrics=[\'accuracy\'])\n\n    # Model hasn\'t been trained yet. Sparsity 0.0\n    test_utils.assert_model_sparsity(self, 0.0, model)\n\n    # Simple unpruned model. No sparsity.\n    model.fit(\n        np.random.rand(20, 10),\n        keras.utils.to_categorical(np.random.randint(5, size=(20, 1)), 5),\n        epochs=2,\n        callbacks=[pruning_callbacks.UpdatePruningStep()],\n        batch_size=20)\n    model.predict(np.random.rand(20, 10))\n    test_utils.assert_model_sparsity(self, 0.5, model)\n\n    _, keras_file = tempfile.mkstemp(\'.h5\')\n    keras.models.save_model(model, keras_file)\n\n    with prune.prune_scope():\n      loaded_model = keras.models.load_model(keras_file)\n\n    test_utils.assert_model_sparsity(self, 0.5, loaded_model)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune_integration_test.py,11,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""End to End tests for the Pruning API.""""""\n\nimport tempfile\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune_registry\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\nfrom tensorflow_model_optimization.python.core.sparsity.keras import test_utils\n\n\nkeras = tf.keras\nlayers = keras.layers\n\nlist_to_named_parameters = test_utils.list_to_named_parameters\nModelCompare = keras_test_utils.ModelCompare\n\n\n@keras_parameterized.run_all_keras_modes\nclass PruneIntegrationTest(tf.test.TestCase, parameterized.TestCase,\n                           ModelCompare):\n\n  # Fetch all the prunable layers from the registry.\n  _PRUNABLE_LAYERS = [\n      layer for layer, weights in\n      prune_registry.PruneRegistry._LAYERS_WEIGHTS_MAP.items()\n        if (weights and layer != tf.keras.layers.Conv3DTranspose\n                    and layer != tf.keras.layers.Conv2DTranspose)\n  ]\n\n  # Fetch all the non-prunable layers from the registry.\n  _NON_PRUNABLE_LAYERS = [\n      layer for layer, weights in\n      prune_registry.PruneRegistry._LAYERS_WEIGHTS_MAP.items()\n      if not weights\n  ]\n\n  @staticmethod\n  def _batch(dims, batch_size):\n    """"""Adds provided batch_size to existing dims.\n\n    If dims is (None, 5, 2), returns (batch_size, 5, 2)\n\n    Args:\n      dims: Dimensions\n      batch_size: batch_size\n\n    Returns:\n      dims with batch_size added as first parameter of list.\n    """"""\n    if dims[0] is None:\n      dims[0] = batch_size\n    return dims\n\n  @staticmethod\n  def _get_params_for_layer(layer_type):\n    """"""Returns the arguments required to construct a layer.\n\n    For a given `layer_type`, return ( [params], (input_shape) )\n\n    Args:\n      layer_type: Type of layer, Dense, Conv2D etc.\n\n    Returns:\n      Arguments to construct layer as a 2-tuple. First value is the list of\n      params required to construct the layer. Second value is the input_shape\n      for the layer.\n    """"""\n    return {\n        layers.Conv1D: ([4, 2], (3, 6)),\n        layers.Conv2D: ([4, (2, 2)], (4, 6, 1)),\n        # TODO(tf-mot): fix for Conv2DTranspose on some form of eager,\n        # with or without functions. The weights become nan (though the\n        # mask seems fine still).\n        #layers.Conv2DTranspose: ([2, (3, 3)], (7, 6, 3)),\n        layers.Conv3D: ([2, (3, 3, 3)], (5, 7, 6, 3)),\n        # TODO(tf-mot): fix for Conv3DTranspose on some form of eager,\n        # with or without functions. The weights become nan (though the\n        # mask seems fine still).\n        #layers.Conv3DTranspose: ([2, (3, 3, 3)], (5, 7, 6, 3)),\n        layers.SeparableConv1D: ([4, 3], (3, 6)),\n        layers.SeparableConv2D: ([4, (2, 2)], (4, 6, 1)),\n        layers.Dense: ([4], (6,)),\n        layers.LocallyConnected1D: ([4, 2], (3, 6)),\n        layers.LocallyConnected2D: ([4, (2, 2)], (4, 6, 1)),\n\n        # Embedding has a separate test since training it is not\n        # feasible as a single layer.\n        layers.Embedding: (None, None),\n    }[layer_type]\n\n  def setUp(self):\n    super(PruneIntegrationTest, self).setUp()\n    self.params = {\n        \'pruning_schedule\': pruning_schedule.ConstantSparsity(0.5, 0, -1, 1),\n        # TODO(pulkitb): Add tests for block sparsity.\n        \'block_size\': (1, 1),\n        \'block_pooling_type\': \'AVG\'\n    }\n\n  # TODO(pulkitb): Also assert correct weights are pruned.\n  # TODO(tfmot): this should not be verified in all the unit tests.\n  # As long as there are a few unit tests for strip_pruning,\n  # these checks are redundant.\n  def _check_strip_pruning_matches_original(\n      self, model, sparsity, input_data=None):\n    stripped_model = prune.strip_pruning(model)\n    test_utils.assert_model_sparsity(self, sparsity, stripped_model)\n\n    if input_data is None:\n      input_data = np.random.randn(\n          *self._batch(model.input.get_shape().as_list(), 1))\n\n    model_result = model.predict(input_data)\n    stripped_model_result = stripped_model.predict(input_data)\n    np.testing.assert_almost_equal(model_result, stripped_model_result)\n\n  @staticmethod\n  def _is_pruned(model):\n    for layer in model.layers:\n      if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n        return True\n\n  @staticmethod\n  def _train_model(model, epochs=1, x_train=None, y_train=None, callbacks=None):\n    if x_train is None:\n      x_train = np.random.rand(20, 10),\n    if y_train is None:\n      y_train = keras.utils.to_categorical(\n          np.random.randint(5, size=(20, 1)), 5)\n\n    if model.optimizer is None:\n      model.compile(\n          loss=\'categorical_crossentropy\',\n          optimizer=\'sgd\',\n          metrics=[\'accuracy\'])\n\n    if callbacks is None:\n      callbacks = []\n      if PruneIntegrationTest._is_pruned(model):\n        callbacks = [pruning_callbacks.UpdatePruningStep()]\n\n    model.fit(\n        x_train, y_train, epochs=epochs, batch_size=20, callbacks=callbacks)\n\n  def _get_pretrained_model(self):\n    model = keras_test_utils.build_simple_dense_model()\n    self._train_model(model, epochs=1)\n    return model\n\n  ###################################################################\n  # Sanity checks and special cases for training with pruning.\n\n  def testPrunesZeroSparsity_IsNoOp(self):\n    model = keras_test_utils.build_simple_dense_model()\n\n    model2 = keras_test_utils.build_simple_dense_model()\n    model2.set_weights(model.get_weights())\n\n    params = self.params\n    params[\'pruning_schedule\'] = pruning_schedule.ConstantSparsity(\n        target_sparsity=0, begin_step=0, frequency=1)\n    pruned_model = prune.prune_low_magnitude(model2, **params)\n\n    x_train = np.random.rand(20, 10),\n    y_train = keras.utils.to_categorical(np.random.randint(5, size=(20, 1)), 5)\n\n    self._train_model(model, epochs=1, x_train=x_train, y_train=y_train)\n    self._train_model(pruned_model, epochs=1, x_train=x_train, y_train=y_train)\n\n    self._assert_weights_different_objects(model, pruned_model)\n    self._assert_weights_same_values(model, pruned_model)\n\n  # TODO(tfmot): https://github.com/tensorflow/model-optimization/issues/215\n  def testPruneWithHighSparsity_Fails(self):\n    params = self.params\n    params[\'pruning_schedule\'] = pruning_schedule.ConstantSparsity(\n        target_sparsity=0.99, begin_step=0, frequency=1)\n\n    model = prune.prune_low_magnitude(\n        keras_test_utils.build_simple_dense_model(), **params)\n\n    with self.assertRaises(tf.errors.InvalidArgumentError):\n      self._train_model(model, epochs=1)\n\n  ###################################################################\n  # Tests for training with pruning with pretrained models or weights.\n\n  def testPrunePretrainedModel_RemovesOptimizer(self):\n    model = self._get_pretrained_model()\n\n    self.assertIsNotNone(model.optimizer)\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertIsNone(pruned_model.optimizer)\n\n  def testPrunePretrainedModel_PreservesWeightObjects(self):\n    model = self._get_pretrained_model()\n\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self._assert_weights_same_objects(model, pruned_model)\n\n  def testPrunePretrainedModel_SameInferenceWithoutTraining(self):\n    model = self._get_pretrained_model()\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n\n    input_data = np.random.rand(10, 10)\n\n    out = model.predict(input_data)\n    pruned_out = pruned_model.predict(input_data)\n\n    self.assertTrue((out == pruned_out).all())\n\n  def testLoadTFWeightsThenPrune_SameInferenceWithoutTraining(self):\n    model = self._get_pretrained_model()\n\n    _, tf_weights = tempfile.mkstemp(\'.tf\')\n    model.save_weights(tf_weights)\n\n    # load weights into model then prune.\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    same_architecture_model.load_weights(tf_weights)\n    pruned_model = prune.prune_low_magnitude(same_architecture_model,\n                                             **self.params)\n\n    input_data = np.random.rand(10, 10)\n\n    out = model.predict(input_data)\n    pruned_out = pruned_model.predict(input_data)\n\n    self.assertTrue((out == pruned_out).all())\n\n  # Test this and _DifferentInferenceWithoutTraining\n  # because pruning and then loading pretrained weights\n  # is unusual behavior and extra coverage is safer.\n  def testPruneThenLoadTFWeights_DoesNotPreserveWeights(self):\n    model = self._get_pretrained_model()\n\n    _, tf_weights = tempfile.mkstemp(\'.tf\')\n    model.save_weights(tf_weights)\n\n    # load weights into pruned model.\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(same_architecture_model,\n                                             **self.params)\n    pruned_model.load_weights(tf_weights)\n\n    self._assert_weights_different_values(model, pruned_model)\n\n  def testPruneThenLoadTFWeights_DifferentInferenceWithoutTraining(self):\n    model = self._get_pretrained_model()\n\n    _, tf_weights = tempfile.mkstemp(\'.tf\')\n    model.save_weights(tf_weights)\n\n    # load weights into pruned model.\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(same_architecture_model,\n                                             **self.params)\n    pruned_model.load_weights(tf_weights)\n\n    input_data = np.random.rand(10, 10)\n\n    out = model.predict(input_data)\n    pruned_out = pruned_model.predict(input_data)\n\n    self.assertFalse((out == pruned_out).any())\n\n  def testPruneThenLoadsKerasWeights_Fails(self):\n    model = self._get_pretrained_model()\n\n    _, keras_weights = tempfile.mkstemp(\'.h5\')\n    model.save_weights(keras_weights)\n\n    # load weights into pruned model.\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(same_architecture_model,\n                                             **self.params)\n\n    # error since number of keras_weights is fewer than weights in pruned model\n    # because pruning introduces weights.\n    with self.assertRaises(ValueError):\n      pruned_model.load_weights(keras_weights)\n\n  ###################################################################\n  # Tests for training with pruning from scratch.\n\n  @parameterized.parameters(_PRUNABLE_LAYERS)\n  def testPrunesSingleLayer_ReachesTargetSparsity(self, layer_type):\n    model = keras.Sequential()\n    args, input_shape = self._get_params_for_layer(layer_type)\n    if args is None:\n      return  # Test for layer not supported yet.\n    model.add(prune.prune_low_magnitude(\n        layer_type(*args), input_shape=input_shape, **self.params))\n\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    test_utils.assert_model_sparsity(self, 0.0, model)\n    model.fit(\n        np.random.randn(*self._batch(model.input.get_shape().as_list(), 32)),\n        np.random.randn(*self._batch(model.output.get_shape().as_list(), 32)),\n        callbacks=[pruning_callbacks.UpdatePruningStep()])\n\n    test_utils.assert_model_sparsity(self, 0.5, model)\n\n    self._check_strip_pruning_matches_original(model, 0.5)\n\n  @parameterized.parameters(prune_registry.PruneRegistry._RNN_LAYERS -\n                            {keras.layers.RNN})\n  def testRNNLayersSingleCell_ReachesTargetSparsity(self, layer_type):\n    model = keras.Sequential()\n    model.add(\n        prune.prune_low_magnitude(\n            layer_type(10), input_shape=(3, 4), **self.params))\n\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    test_utils.assert_model_sparsity(self, 0.0, model)\n    model.fit(\n        np.random.randn(*self._batch(model.input.get_shape().as_list(), 32)),\n        np.random.randn(*self._batch(model.output.get_shape().as_list(), 32)),\n        callbacks=[pruning_callbacks.UpdatePruningStep()])\n\n    test_utils.assert_model_sparsity(self, 0.5, model)\n\n    self._check_strip_pruning_matches_original(model, 0.5)\n\n  def testRNNLayersWithRNNCellParams_ReachesTargetSparsity(self):\n    model = keras.Sequential()\n    model.add(\n        prune.prune_low_magnitude(\n            keras.layers.RNN([\n                layers.LSTMCell(10),\n                layers.GRUCell(10),\n                tf.keras.experimental.PeepholeLSTMCell(10),\n                layers.SimpleRNNCell(10)\n            ]),\n            input_shape=(3, 4),\n            **self.params))\n\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    test_utils.assert_model_sparsity(self, 0.0, model)\n    model.fit(\n        np.random.randn(*self._batch(model.input.get_shape().as_list(), 32)),\n        np.random.randn(*self._batch(model.output.get_shape().as_list(), 32)),\n        callbacks=[pruning_callbacks.UpdatePruningStep()])\n\n    test_utils.assert_model_sparsity(self, 0.5, model)\n\n    self._check_strip_pruning_matches_original(model, 0.5)\n\n  def testPrunesEmbedding_ReachesTargetSparsity(self):\n    model = keras.Sequential()\n    model.add(\n        prune.prune_low_magnitude(\n            layers.Embedding(input_dim=10, output_dim=3),\n            input_shape=(5,),\n            **self.params))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1, activation=\'sigmoid\'))\n\n    model.compile(\n        loss=\'binary_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    test_utils.assert_model_sparsity(self, 0.0, model)\n    model.fit(\n        np.random.randint(10, size=(32, 5)),\n        np.random.randint(2, size=(32, 1)),\n        callbacks=[pruning_callbacks.UpdatePruningStep()])\n\n    test_utils.assert_model_sparsity(self, 0.5, model)\n\n    input_data = np.random.randint(10, size=(32, 5))\n    self._check_strip_pruning_matches_original(model, 0.5, input_data)\n\n  @parameterized.parameters(test_utils.model_type_keys())\n  def testPrunesMnist_ReachesTargetSparsity(self, model_type):\n    model = test_utils.build_mnist_model(model_type, self.params)\n    if model_type == \'layer_list\':\n      model = keras.Sequential(prune.prune_low_magnitude(model, **self.params))\n    elif model_type in [\'sequential\', \'functional\']:\n      model = prune.prune_low_magnitude(model, **self.params)\n\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    test_utils.assert_model_sparsity(self, 0.0, model, rtol=1e-4, atol=1e-4)\n    model.fit(\n        np.random.rand(32, 28, 28, 1),\n        keras.utils.to_categorical(np.random.randint(10, size=(32, 1)), 10),\n        callbacks=[pruning_callbacks.UpdatePruningStep()])\n\n    test_utils.assert_model_sparsity(self, 0.5, model, rtol=1e-4, atol=1e-4)\n\n    self._check_strip_pruning_matches_original(model, 0.5)\n\n  ###################################################################\n  # Tests for pruning with checkpointing.\n\n  # TODO(tfmot): https://github.com/tensorflow/model-optimization/issues/206.\n  #\n  # Note the following:\n  # 1. This test doesn\'t exactly reproduce bug. Test should sometimes\n  # pass when ModelCheckpoint save_freq=\'epoch\'. The behavior was seen when\n  # training mobilenet.\n  # 2. testPruneStopAndRestart_PreservesSparsity passes, indicating\n  # checkpointing in general works. Just don\'t use the checkpoint for\n  # serving.\n  def testPruneCheckpoints_CheckpointsNotSparse(self):\n    is_model_sparsity_not_list = []\n\n    # Run multiple times since problem doesn\'t always happen.\n    for _ in range(3):\n      model = keras_test_utils.build_simple_dense_model()\n      pruned_model = prune.prune_low_magnitude(model, **self.params)\n\n      checkpoint_dir = tempfile.mkdtemp()\n      checkpoint_path = checkpoint_dir + \'/weights.{epoch:02d}.tf\'\n\n      callbacks = [\n          pruning_callbacks.UpdatePruningStep(),\n          tf.keras.callbacks.ModelCheckpoint(\n              filepath=checkpoint_path, save_weights_only=True, save_freq=1)\n      ]\n\n      # Train one step. Sparsity reaches final sparsity.\n      self._train_model(pruned_model, epochs=1, callbacks=callbacks)\n      test_utils.assert_model_sparsity(self, 0.5, pruned_model)\n\n      latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n\n      same_architecture_model = keras_test_utils.build_simple_dense_model()\n      pruned_model = prune.prune_low_magnitude(same_architecture_model,\n                                               **self.params)\n\n      # Sanity check.\n      test_utils.assert_model_sparsity(self, 0, pruned_model)\n\n      pruned_model.load_weights(latest_checkpoint)\n      is_model_sparsity_not_list.append(\n          test_utils.is_model_sparsity_not(0.5, pruned_model))\n\n    self.assertTrue(any(is_model_sparsity_not_list))\n\n  @parameterized.parameters(test_utils.save_restore_fns())\n  def testPruneStopAndRestart_PreservesSparsity(self, save_restore_fn):\n    # TODO(tfmot): renable once SavedModel preserves step again.\n    # This existed in TF 2.0 and 2.1 and should be reenabled in\n    # TF 2.3. b/151755698\n    if save_restore_fn.__name__ == \'_save_restore_tf_model\':\n      return\n\n    begin_step, end_step = 0, 4\n    params = self.params\n    params[\'pruning_schedule\'] = pruning_schedule.PolynomialDecay(\n        0.2, 0.6, begin_step, end_step, 3, 1)\n\n    model = prune.prune_low_magnitude(\n        keras_test_utils.build_simple_dense_model(), **params)\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n    # Model hasn\'t been trained yet. Sparsity 0.0\n    test_utils.assert_model_sparsity(self, 0.0, model)\n\n    # Train only 1 step. Sparsity 0.2 (initial_sparsity)\n    self._train_model(model, epochs=1)\n    test_utils.assert_model_sparsity(self, 0.2, model)\n\n    model = save_restore_fn(model)\n\n    # Training has run all 4 steps. Sparsity 0.6 (final_sparsity)\n    self._train_model(model, epochs=3)\n    test_utils.assert_model_sparsity(self, 0.6, model)\n\n    self._check_strip_pruning_matches_original(model, 0.6)\n\n  @parameterized.parameters(test_utils.save_restore_fns())\n  def testPruneWithPolynomialDecayPastEndStep_PreservesSparsity(\n      self, save_restore_fn):\n    # TODO(tfmot): renable once SavedModel preserves step again.\n    # This existed in TF 2.0 and 2.1 and should be reenabled in\n    # TF 2.3. b/151755698\n    if save_restore_fn.__name__ == \'_save_restore_tf_model\':\n      return\n\n    begin_step, end_step = 0, 2\n    params = self.params\n    params[\'pruning_schedule\'] = pruning_schedule.PolynomialDecay(\n        0.2, 0.6, begin_step, end_step, 3, 1)\n\n    model = prune.prune_low_magnitude(\n        keras_test_utils.build_simple_dense_model(), **params)\n    model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n\n    # Model hasn\'t been trained yet. Sparsity 0.0\n    test_utils.assert_model_sparsity(self, 0.0, model)\n\n    # Train 3 steps, past end_step. Sparsity 0.6 (final_sparsity)\n    self._train_model(model, epochs=3)\n    test_utils.assert_model_sparsity(self, 0.6, model)\n\n    model = save_restore_fn(model)\n\n    # Ensure sparsity is preserved.\n    test_utils.assert_model_sparsity(self, 0.6, model)\n\n    # Train one more step to ensure nothing happens that brings sparsity\n    # back below 0.6.\n    self._train_model(model, epochs=1)\n    test_utils.assert_model_sparsity(self, 0.6, model)\n\n    self._check_strip_pruning_matches_original(model, 0.6)\n\n\n@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\nclass PruneIntegrationCustomTrainingLoopTest(tf.test.TestCase,\n                                             parameterized.TestCase):\n\n  def testPrunesModel_CustomTrainingLoop_ReachesTargetSparsity(self):\n    pruned_model = prune.prune_low_magnitude(\n        keras_test_utils.build_simple_dense_model())\n\n    batch_size = 20\n    x_train = np.random.rand(20, 10)\n    y_train = keras.utils.to_categorical(\n        np.random.randint(5, size=(batch_size, 1)), 5)\n\n    loss = keras.losses.categorical_crossentropy\n    optimizer = keras.optimizers.SGD()\n\n    unused_arg = -1\n\n    step_callback = pruning_callbacks.UpdatePruningStep()\n    step_callback.set_model(pruned_model)\n    pruned_model.optimizer = optimizer\n\n    step_callback.on_train_begin()\n    # 2 epochs\n    for _ in range(2):\n      step_callback.on_train_batch_begin(batch=unused_arg)\n      inp = np.reshape(x_train, [batch_size, 10])  # original shape: from [10].\n      with tf.GradientTape() as tape:\n        logits = pruned_model(inp, training=True)\n        loss_value = loss(y_train, logits)\n        grads = tape.gradient(loss_value, pruned_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, pruned_model.trainable_variables))\n      step_callback.on_epoch_end(batch=unused_arg)\n\n    test_utils.assert_model_sparsity(self, 0.5, pruned_model)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune_registry.py,9,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Registry responsible for built-in keras classes.""""""\n\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras.engine.base_layer import TensorFlowOpLayer\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prunable_layer\n\nlayers = tf.keras.layers\n\n\nclass PruneRegistry(object):\n  """"""Registry responsible for built-in keras layers.""""""\n\n  # The keys represent built-in keras layers and the values represent the\n  # the variables within the layers which hold the kernel weights. This\n  # allows the wrapper to access and modify the weights.\n  _LAYERS_WEIGHTS_MAP = {\n      layers.ELU: [],\n      layers.LeakyReLU: [],\n      layers.ReLU: [],\n      layers.Softmax: [],\n      layers.ThresholdedReLU: [],\n      layers.Conv1D: [\'kernel\'],\n      layers.Conv2D: [\'kernel\'],\n      layers.Conv2DTranspose: [\'kernel\'],\n      layers.Conv3D: [\'kernel\'],\n      layers.Conv3DTranspose: [\'kernel\'],\n      layers.Cropping1D: [],\n      layers.Cropping2D: [],\n      layers.Cropping3D: [],\n      layers.DepthwiseConv2D: [],\n      layers.SeparableConv1D: [\'pointwise_kernel\'],\n      layers.SeparableConv2D: [\'pointwise_kernel\'],\n      layers.UpSampling1D: [],\n      layers.UpSampling2D: [],\n      layers.UpSampling3D: [],\n      layers.ZeroPadding1D: [],\n      layers.ZeroPadding2D: [],\n      layers.ZeroPadding3D: [],\n      layers.Activation: [],\n      layers.ActivityRegularization: [],\n      layers.Dense: [\'kernel\'],\n      layers.Dropout: [],\n      layers.Flatten: [],\n      layers.Lambda: [],\n      layers.Masking: [],\n      layers.Permute: [],\n      layers.RepeatVector: [],\n      layers.Reshape: [],\n      layers.SpatialDropout1D: [],\n      layers.SpatialDropout2D: [],\n      layers.SpatialDropout3D: [],\n      layers.Embedding: [\'embeddings\'],\n      layers.LocallyConnected1D: [\'kernel\'],\n      layers.LocallyConnected2D: [\'kernel\'],\n      layers.Add: [],\n      layers.Average: [],\n      layers.Concatenate: [],\n      layers.Dot: [],\n      layers.Maximum: [],\n      layers.Minimum: [],\n      layers.Multiply: [],\n      layers.Subtract: [],\n      layers.AlphaDropout: [],\n      layers.GaussianDropout: [],\n      layers.GaussianNoise: [],\n      layers.BatchNormalization: [],\n      layers.LayerNormalization: [],\n      layers.AveragePooling1D: [],\n      layers.AveragePooling2D: [],\n      layers.AveragePooling3D: [],\n      layers.GlobalAveragePooling1D: [],\n      layers.GlobalAveragePooling2D: [],\n      layers.GlobalAveragePooling3D: [],\n      layers.GlobalMaxPooling1D: [],\n      layers.GlobalMaxPooling2D: [],\n      layers.GlobalMaxPooling3D: [],\n      layers.MaxPooling1D: [],\n      layers.MaxPooling2D: [],\n      layers.MaxPooling3D: [],\n      TensorFlowOpLayer: [],\n  }\n\n  _RNN_CELLS_WEIGHTS_MAP = {\n      # Whitelist via compat.v1 and compat.v2 to support legacy TensorFlow 2.X\n      # behavior where the v2 RNN uses the v1 RNNCell instead of the v2 RNNCell.\n      # See b/145939875 for details.\n      tf.compat.v1.keras.layers.GRUCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.GRUCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v1.keras.layers.LSTMCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.LSTMCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v1.keras.experimental.PeepholeLSTMCell: [\n          \'kernel\', \'recurrent_kernel\'\n      ],\n      tf.compat.v2.keras.experimental.PeepholeLSTMCell: [\n          \'kernel\', \'recurrent_kernel\'\n      ],\n      tf.compat.v1.keras.layers.SimpleRNNCell: [\'kernel\', \'recurrent_kernel\'],\n      tf.compat.v2.keras.layers.SimpleRNNCell: [\'kernel\', \'recurrent_kernel\'],\n  }\n\n  _RNN_LAYERS = frozenset({\n      layers.GRU,\n      layers.LSTM,\n      layers.RNN,\n      layers.SimpleRNN,\n  })\n\n  _RNN_CELLS_STR = \', \'.join(str(_RNN_CELLS_WEIGHTS_MAP.keys()))\n\n  _RNN_CELL_ERROR_MSG = (\n      \'RNN Layer {} contains cell type {} which is either not supported or does\'\n      \'not inherit PrunableLayer. The cell must be one of {}, or implement \'\n      \'PrunableLayer.\')\n\n  @classmethod\n  def supports(cls, layer):\n    """"""Returns whether the registry supports this layer type.\n\n    Args:\n      layer: The layer to check for support.\n\n    Returns:\n      True/False whether the layer type is supported.\n\n    """"""\n    if layer.__class__ in cls._LAYERS_WEIGHTS_MAP:\n      return True\n\n    if layer.__class__ in cls._RNN_LAYERS:\n      for cell in cls._get_rnn_cells(layer):\n        if cell.__class__ not in cls._RNN_CELLS_WEIGHTS_MAP \\\n            and not isinstance(cell, prunable_layer.PrunableLayer):\n          return False\n      return True\n\n    return False\n\n  @staticmethod\n  def _get_rnn_cells(rnn_layer):\n    if isinstance(rnn_layer.cell, layers.StackedRNNCells):\n      return rnn_layer.cell.cells\n    else:\n      return [rnn_layer.cell]\n\n  @classmethod\n  def _is_rnn_layer(cls, layer):\n    return layer.__class__ in cls._RNN_LAYERS\n\n  @classmethod\n  def _weight_names(cls, layer):\n    return cls._LAYERS_WEIGHTS_MAP[layer.__class__]\n\n  @classmethod\n  def make_prunable(cls, layer):\n    """"""Modifies a built-in layer object to support pruning.\n\n    Args:\n      layer: layer to modify for support.\n\n    Returns:\n      The modified layer object.\n\n    """"""\n\n    if not cls.supports(layer):\n      raise ValueError(\'Layer \' + str(layer.__class__) + \' is not supported.\')\n\n    def get_prunable_weights():\n      return [getattr(layer, weight) for weight in cls._weight_names(layer)]\n\n    def get_prunable_weights_rnn():  # pylint: disable=missing-docstring\n      def get_prunable_weights_rnn_cell(cell):\n        if cell.__class__ in cls._RNN_CELLS_WEIGHTS_MAP:\n          return [getattr(cell, weight)\n                  for weight in cls._RNN_CELLS_WEIGHTS_MAP[cell.__class__]]\n\n        if isinstance(cell, prunable_layer.PrunableLayer):\n          return cell.get_prunable_weights()\n\n        raise ValueError(cls._RNN_CELL_ERROR_MSG.format(\n            layer.__class__, cell.__class__, cls._RNN_CELLS_WEIGHTS_MAP.keys()))\n\n      prunable_weights = []\n      for rnn_cell in cls._get_rnn_cells(layer):\n        prunable_weights.extend(get_prunable_weights_rnn_cell(rnn_cell))\n      return prunable_weights\n\n    if cls._is_rnn_layer(layer):\n      layer.get_prunable_weights = get_prunable_weights_rnn\n    else:\n      layer.get_prunable_weights = get_prunable_weights\n\n    return layer\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune_registry_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for prune registry.""""""\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prunable_layer\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune_registry\n\nkeras = tf.keras\nlayers = keras.layers\nPruneRegistry = prune_registry.PruneRegistry\n\n\nclass PruneRegistryTest(tf.test.TestCase):\n\n  class CustomLayer(layers.Layer):\n    pass\n\n  class CustomLayerFromPrunableLayer(layers.Dense):\n    pass\n\n  class MinimalRNNCell(keras.layers.Layer):\n\n    def __init__(self, units, **kwargs):\n      self.units = units\n      self.state_size = units\n      super(PruneRegistryTest.MinimalRNNCell, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n      self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                    initializer=\'uniform\',\n                                    name=\'kernel\')\n      self.recurrent_kernel = self.add_weight(\n          shape=(self.units, self.units),\n          initializer=\'uniform\',\n          name=\'recurrent_kernel\')\n      self.built = True\n\n    def call(self, inputs, states):\n      prev_output = states[0]\n      h = keras.backend.dot(inputs, self.kernel)\n      output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n      return output, [output]\n\n  class MinimalRNNCellPrunable(MinimalRNNCell, prunable_layer.PrunableLayer):\n\n    def get_prunable_weights(self):\n      return [self.kernel, self.recurrent_kernel]\n\n  def testSupportsKerasPrunableLayer(self):\n    self.assertTrue(PruneRegistry.supports(layers.Dense(10)))\n\n  def testSupportsKerasPrunableLayerAlias(self):\n    # layers.Conv2D maps to layers.convolutional.Conv2D\n    self.assertTrue(PruneRegistry.supports(layers.Conv2D(10, 5)))\n\n  def testSupportsKerasNonPrunableLayer(self):\n    # Dropout is a layer known to not be prunable.\n    self.assertTrue(PruneRegistry.supports(layers.Dropout(0.5)))\n\n  def testDoesNotSupportKerasUnsupportedLayer(self):\n    # ConvLSTM2D is a built-in keras layer but not supported.\n    self.assertFalse(PruneRegistry.supports(layers.ConvLSTM2D(2, (5, 5))))\n\n  def testSupportsKerasRNNLayers(self):\n    self.assertTrue(PruneRegistry.supports(layers.LSTM(10)))\n    self.assertTrue(PruneRegistry.supports(layers.GRU(10)))\n    self.assertTrue(PruneRegistry.supports(layers.SimpleRNN(10)))\n\n  def testSupportsKerasRNNLayerWithRNNCellsParams(self):\n    self.assertTrue(PruneRegistry.supports(layers.RNN(layers.LSTMCell(10))))\n\n    self.assertTrue(\n        PruneRegistry.supports(\n            layers.RNN([\n                layers.LSTMCell(10),\n                layers.GRUCell(10),\n                keras.experimental.PeepholeLSTMCell(10),\n                layers.SimpleRNNCell(10)\n            ])))\n\n  def testDoesNotSupportKerasRNNLayerUnknownCell(self):\n    self.assertFalse(PruneRegistry.supports(\n        keras.layers.RNN(PruneRegistryTest.MinimalRNNCell(32))))\n\n  def testSupportsKerasRNNLayerPrunableCell(self):\n    self.assertTrue(PruneRegistry.supports(\n        keras.layers.RNN(PruneRegistryTest.MinimalRNNCellPrunable(32))))\n\n  def testDoesNotSupportCustomLayer(self):\n    self.assertFalse(PruneRegistry.supports(PruneRegistryTest.CustomLayer(10)))\n\n  def testDoesNotSupportCustomLayerInheritedFromPrunableLayer(self):\n    self.assertFalse(\n        PruneRegistry.supports(\n            PruneRegistryTest.CustomLayerFromPrunableLayer(10)))\n\n  def testMakePrunableRaisesErrorForKerasUnsupportedLayer(self):\n    with self.assertRaises(ValueError):\n      PruneRegistry.make_prunable(layers.ConvLSTM2D(2, (5, 5)))\n\n  def testMakePrunableRaisesErrorForCustomLayer(self):\n    with self.assertRaises(ValueError):\n      PruneRegistry.make_prunable(PruneRegistryTest.CustomLayer(10))\n\n  def testMakePrunableRaisesErrorForCustomLayerInheritedFromPrunableLayer(self):\n    with self.assertRaises(ValueError):\n      PruneRegistry.make_prunable(\n          PruneRegistryTest.CustomLayerFromPrunableLayer(10))\n\n  def testMakePrunableWorksOnKerasPrunableLayer(self):\n    layer = layers.Dense(10)\n    with self.assertRaises(AttributeError):\n      layer.get_prunable_weights()\n\n    PruneRegistry.make_prunable(layer)\n    # Required since build method sets up the layer weights.\n    keras.Sequential([layer]).build(input_shape=(10, 1))\n\n    self.assertEqual([layer.kernel], layer.get_prunable_weights())\n\n  def testMakePrunableWorksOnKerasNonPrunableLayer(self):\n    layer = layers.Dropout(0.5)\n    with self.assertRaises(AttributeError):\n      layer.get_prunable_weights()\n\n    PruneRegistry.make_prunable(layer)\n\n    self.assertEqual([], layer.get_prunable_weights())\n\n  def testMakePrunableWorksOnKerasRNNLayer(self):\n    layer = layers.LSTM(10)\n    with self.assertRaises(AttributeError):\n      layer.get_prunable_weights()\n\n    PruneRegistry.make_prunable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    self.assertEqual(\n        [layer.cell.kernel, layer.cell.recurrent_kernel],\n        layer.get_prunable_weights())\n\n  def testMakePrunableWorksOnKerasRNNLayerWithRNNCellsParams(self):\n    cell1 = layers.LSTMCell(10)\n    cell2 = layers.GRUCell(5)\n    layer = layers.RNN([cell1, cell2])\n    with self.assertRaises(AttributeError):\n      layer.get_prunable_weights()\n\n    PruneRegistry.make_prunable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    expected_weights = [\n        cell1.kernel, cell1.recurrent_kernel, cell2.kernel,\n        cell2.recurrent_kernel\n    ]\n    self.assertEqual(expected_weights, layer.get_prunable_weights())\n\n  def testMakePrunableWorksOnKerasRNNLayerWithPrunableCell(self):\n    cell1 = layers.LSTMCell(10)\n    cell2 = PruneRegistryTest.MinimalRNNCellPrunable(5)\n    layer = layers.RNN([cell1, cell2])\n    with self.assertRaises(AttributeError):\n      layer.get_prunable_weights()\n\n    PruneRegistry.make_prunable(layer)\n    keras.Sequential([layer]).build(input_shape=(2, 3, 4))\n\n    expected_weights = [\n        cell1.kernel, cell1.recurrent_kernel, cell2.kernel,\n        cell2.recurrent_kernel\n    ]\n    self.assertEqual(expected_weights, layer.get_prunable_weights())\n\n  def testMakePrunableRaisesErrorOnRNNLayersUnsupportedCell(self):\n    with self.assertRaises(ValueError):\n      PruneRegistry.make_prunable(layers.RNN(\n          [layers.LSTMCell(10), PruneRegistryTest.MinimalRNNCell(5)]))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/prune_test.py,15,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for tf.keras pruning APIs under prune.py.""""""\n\nimport json\nimport tempfile\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prunable_layer\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\nkeras = tf.keras\nerrors_impl = tf.errors\nlayers = keras.layers\ntest = tf.test\n\n\nclass TestSubclassedModel(keras.Model):\n  """"""A model subclass.""""""\n\n  def __init__(self):\n    """"""A test subclass model with one dense layer.""""""\n    super(TestSubclassedModel, self).__init__(name=\'test_model\')\n    self.layer1 = keras.layers.Dense(10, activation=\'relu\')\n\n  def call(self, inputs):\n    return self.layer1(inputs)\n\n\nclass CustomPrunableLayer(layers.Dense, prunable_layer.PrunableLayer):\n\n  def get_prunable_weights(self):\n    return [self.kernel]\n\n\nclass CustomNonPrunableLayer(layers.Dense):\n  pass\n\n\nclass PruneTest(test.TestCase, parameterized.TestCase):\n\n  INVALID_TO_PRUNE_PARAM_ERROR = (\'`prune_low_magnitude` can only prune an \'\n                                  \'object of the following types: \'\n                                  \'tf.keras.models.Sequential, tf.keras \'\n                                  \'functional model, tf.keras.layers.Layer, \'\n                                  \'list of tf.keras.layers.Layer. You passed an\'\n                                  \' object of type: {input}.\')\n\n  def setUp(self):\n    super(PruneTest, self).setUp()\n\n    # Layers passed in for Pruning can either be standard Keras layers provided\n    # by the tf.keras API (these fall under the `keras.layers` namespace), or\n    # custom layers provided by the user which inherit the base\n    # `keras.layers.Layer`.\n    # Standard Keras layers can either be Prunable (we know how to prune them),\n    # Non-Prunable (we know these layers can\'t be pruned) and Unsupported (we\n    # don\'t know how to deal with these yet.). Unsupported layers will raise an\n    # error when tried to prune.\n    # Custom Layers can either be Prunable (ie., they implement the\n    # `PrunableLayer` interface, or Non-Prunable (they don\'t expose any pruning\n    # behavior.)\n\n    # TODO(pulkitb): Change naming of Prunable/Non-Prunable/Unsupported to be\n    # clearer.\n    self.keras_prunable_layer = layers.Dense(10)  # Supports pruning\n    self.keras_non_prunable_layer = layers.Dropout(\n        0.4)  # Pruning not applicable\n    self.keras_unsupported_layer = layers.ConvLSTM2D(2, (5, 5))  # Unsupported\n    self.custom_prunable_layer = CustomPrunableLayer(10)\n    self.custom_non_prunable_layer = CustomNonPrunableLayer(10)\n\n    self.model = keras.Sequential()\n    self.params = {\n        \'pruning_schedule\': pruning_schedule.ConstantSparsity(0.5, 0),\n        \'block_size\': (1, 1),\n        \'block_pooling_type\': \'AVG\'\n    }\n\n  def _build_pruned_layer_model(self, layer):\n    wrapped_layer = prune.prune_low_magnitude(layer, **self.params)\n    self.model.add(wrapped_layer)\n    self.model.build(input_shape=(10, 1))\n\n    return wrapped_layer\n\n  def _validate_pruned_layer(self, original_layer, wrapped_layer):\n    self.assertIsInstance(wrapped_layer, pruning_wrapper.PruneLowMagnitude)\n    self.assertEqual(original_layer, wrapped_layer.layer)\n    self.assertEqual(\n        self.params[\'pruning_schedule\'], wrapped_layer.pruning_schedule)\n    self.assertEqual(self.params[\'block_size\'], wrapped_layer.block_size)\n    self.assertEqual(\n        self.params[\'block_pooling_type\'], wrapped_layer.block_pooling_type)\n\n  @staticmethod\n  def _count_pruned_layers(model):\n    count = 0\n    for layer in model._layers:\n      if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n        count += 1\n    return count\n\n  def testPruneKerasPrunableLayer(self):\n    wrapped_layer = self._build_pruned_layer_model(self.keras_prunable_layer)\n\n    self._validate_pruned_layer(self.keras_prunable_layer, wrapped_layer)\n\n  def testPruneKerasNonPrunableLayer(self):\n    wrapped_layer = self._build_pruned_layer_model(\n        self.keras_non_prunable_layer)\n\n    self._validate_pruned_layer(self.keras_non_prunable_layer, wrapped_layer)\n    self.assertEqual([], wrapped_layer.layer.get_prunable_weights())\n\n  def testPruneKerasUnsupportedLayer(self):\n    with self.assertRaises(ValueError):\n      prune.prune_low_magnitude(self.keras_unsupported_layer, **self.params)\n\n  def testPruneCustomPrunableLayer(self):\n    wrapped_layer = self._build_pruned_layer_model(self.custom_prunable_layer)\n\n    self._validate_pruned_layer(self.custom_prunable_layer, wrapped_layer)\n    self.assertEqual([wrapped_layer.layer.kernel],\n                     wrapped_layer.layer.get_prunable_weights())\n\n  def testPruneCustomNonPrunableLayer(self):\n    with self.assertRaises(ValueError):\n      prune.prune_low_magnitude(self.custom_non_prunable_layer, **self.params)\n\n  def testPruneModelValidLayersSuccessful(self):\n    model = keras.Sequential([\n        self.keras_prunable_layer,\n        self.keras_non_prunable_layer,\n        self.custom_prunable_layer\n    ])\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    pruned_model.build(input_shape=(1, 28, 28, 1))\n\n    self.assertEqual(len(model.layers), len(pruned_model.layers))\n    for layer, pruned_layer in zip(model.layers, pruned_model.layers):\n      self._validate_pruned_layer(layer, pruned_layer)\n\n  def testPruneModelUnsupportedKerasLayerRaisesError(self):\n    with self.assertRaises(ValueError):\n      prune.prune_low_magnitude(\n          keras.Sequential([\n              self.keras_prunable_layer, self.keras_non_prunable_layer,\n              self.custom_prunable_layer, self.keras_unsupported_layer\n          ]), **self.params)\n\n  def testPruneModelCustomNonPrunableLayerRaisesError(self):\n    with self.assertRaises(ValueError):\n      prune.prune_low_magnitude(\n          keras.Sequential([\n              self.keras_prunable_layer, self.keras_non_prunable_layer,\n              self.custom_prunable_layer, self.custom_non_prunable_layer\n          ]), **self.params)\n\n  def testPruneModelDoesNotWrapAlreadyWrappedLayer(self):\n    model = keras.Sequential(\n        [layers.Dense(10),\n         prune.prune_low_magnitude(layers.Dense(10), **self.params)])\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    pruned_model.build(input_shape=(10, 1))\n\n    self.assertEqual(len(model.layers), len(pruned_model.layers))\n    self._validate_pruned_layer(model.layers[0], pruned_model.layers[0])\n    # Second layer is used as-is since it\'s already a pruned layer.\n    self.assertEqual(model.layers[1], pruned_model.layers[1])\n\n  def testPruneValidLayersListSuccessful(self):\n    model_layers = [\n        self.keras_prunable_layer,\n        self.keras_non_prunable_layer,\n        self.custom_prunable_layer\n    ]\n    pruned_layers = prune.prune_low_magnitude(model_layers, **self.params)\n\n    self.assertEqual(len(model_layers), len(pruned_layers))\n    for layer, pruned_layer in zip(model_layers, pruned_layers):\n      self._validate_pruned_layer(layer, pruned_layer)\n\n  @keras_parameterized.run_all_keras_modes\n  def testPruneInferenceWorks_PruningStepCallbackNotRequired(self):\n    model = prune.prune_low_magnitude(\n        keras.Sequential([\n            layers.Dense(10, activation=\'relu\', input_shape=(100,)),\n            layers.Dense(2, activation=\'sigmoid\')\n        ]), **self.params)\n\n    model.compile(\n        loss=keras.losses.categorical_crossentropy,\n        optimizer=keras.optimizers.SGD(),\n        metrics=[\'accuracy\'])\n\n    model.predict(np.random.rand(1000, 100))\n    model.evaluate(\n        np.random.rand(1000, 100),\n        keras.utils.to_categorical(np.random.randint(2, size=(1000, 1))))\n\n  def testPruneSequentialModel(self):\n    # No InputLayer\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(self._count_pruned_layers(pruned_model), 2)\n\n    # With InputLayer\n    model = keras.Sequential([\n        layers.Dense(10, input_shape=(10,)),\n        layers.Dense(10),\n    ])\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(self._count_pruned_layers(pruned_model), 2)\n\n  def testPruneSequentialModelPreservesBuiltState(self):\n    # No InputLayer\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n    self.assertEqual(model.built, False)\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(model.built, False)\n\n    # Test built state preserves across serialization\n    with prune.prune_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(pruned_model.to_json()))\n      self.assertEqual(loaded_model.built, False)\n\n    # With InputLayer\n    model = keras.Sequential([\n        layers.Dense(10, input_shape=(10,)),\n        layers.Dense(10),\n    ])\n    self.assertEqual(model.built, True)\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(model.built, True)\n\n    # Test built state preserves across serialization\n    with prune.prune_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(pruned_model.to_json()))\n    self.assertEqual(loaded_model.built, True)\n\n  def testPruneFunctionalModel(self):\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(self._count_pruned_layers(pruned_model), 3)\n\n  def testPruneFunctionalModelWithLayerReused(self):\n    # The model reuses the Dense() layer. Make sure it\'s only pruned once.\n    inp = keras.Input(shape=(10,))\n    dense_layer = layers.Dense(10)\n    x = dense_layer(inp)\n    x = dense_layer(x)\n    model = keras.Model(inputs=[inp], outputs=[x])\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(self._count_pruned_layers(pruned_model), 1)\n\n  def testPruneFunctionalModelPreservesBuiltState(self):\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n    self.assertEqual(model.built, True)\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(model.built, True)\n\n    # Test built state preserves across serialization\n    with prune.prune_scope():\n      loaded_model = keras.models.model_from_config(\n          json.loads(pruned_model.to_json()))\n    self.assertEqual(loaded_model.built, True)\n\n  def testPruneSubclassModel(self):\n    model = TestSubclassedModel()\n    with self.assertRaises(ValueError) as e:\n      _ = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(\n        str(e.exception),\n        self.INVALID_TO_PRUNE_PARAM_ERROR.format(input=\'TestSubclassedModel\'))\n\n  def testPruneMiscObject(self):\n\n    model = object()\n    with self.assertRaises(ValueError) as e:\n      _ = prune.prune_low_magnitude(model, **self.params)\n    self.assertEqual(\n        str(e.exception),\n        self.INVALID_TO_PRUNE_PARAM_ERROR.format(input=\'object\'))\n\n  def testStripPruningSequentialModel(self):\n    model = keras.Sequential([\n        layers.Dense(10),\n        layers.Dense(10),\n    ])\n\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    stripped_model = prune.strip_pruning(pruned_model)\n    self.assertEqual(self._count_pruned_layers(stripped_model), 0)\n    self.assertEqual(model.get_config(), stripped_model.get_config())\n\n  def testStripPruningFunctionalModel(self):\n    i1 = keras.Input(shape=(10,))\n    i2 = keras.Input(shape=(10,))\n    x1 = layers.Dense(10)(i1)\n    x2 = layers.Dense(10)(i2)\n    outputs = layers.Add()([x1, x2])\n    model = keras.Model(inputs=[i1, i2], outputs=outputs)\n\n    pruned_model = prune.prune_low_magnitude(model, **self.params)\n    stripped_model = prune.strip_pruning(pruned_model)\n\n    self.assertEqual(self._count_pruned_layers(stripped_model), 0)\n    self.assertEqual(model.get_config(), stripped_model.get_config())\n\n  def testPruneScope_NeededForKerasModel(self):\n    model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(model)\n\n    _, keras_model = tempfile.mkstemp(\'.h5\')\n    pruned_model.save(keras_model)\n\n    with self.assertRaises(ValueError):\n      tf.keras.models.load_model(keras_model)\n\n    # works with `prune_scope`\n    with prune.prune_scope():\n      tf.keras.models.load_model(keras_model)\n\n  def testPruneScope_NotNeededForKerasCheckpoint(self):\n    model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(model)\n\n    _, keras_weights = tempfile.mkstemp(\'.h5\')\n    pruned_model.save_weights(keras_weights)\n\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    same_architecture_model = prune.prune_low_magnitude(same_architecture_model)\n\n    # would error if `prune_scope` was needed.\n    same_architecture_model.load_weights(keras_weights)\n\n  def testPruneScope_NotNeededForTFCheckpoint(self):\n    model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(model)\n\n    _, tf_weights = tempfile.mkstemp(\'.tf\')\n    pruned_model.save_weights(tf_weights)\n\n    same_architecture_model = keras_test_utils.build_simple_dense_model()\n    same_architecture_model = prune.prune_low_magnitude(same_architecture_model)\n\n    # would error if `prune_scope` was needed.\n    same_architecture_model.load_weights(tf_weights)\n\n  def testPruneScope_NotNeededForTF2SavedModel(self):\n    # TODO(tfmot): replace with shared v1 test_util.\n    is_v1_apis = hasattr(tf, \'assign\')\n    if is_v1_apis:\n      return\n\n    model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(model)\n\n    saved_model_dir = tempfile.mkdtemp()\n\n    tf.saved_model.save(pruned_model, saved_model_dir)\n\n    # would error if `prune_scope` was needed.\n    tf.saved_model.load(saved_model_dir)\n\n  def testPruneScope_NeededForTF1SavedModel(self):\n    # TODO(tfmot): replace with shared v1 test_util.\n    is_v1_apis = hasattr(tf, \'assign\')\n    if not is_v1_apis:\n      return\n\n    model = keras_test_utils.build_simple_dense_model()\n    pruned_model = prune.prune_low_magnitude(model)\n\n    saved_model_dir = tempfile.mkdtemp()\n\n    tf.keras.experimental.export_saved_model(pruned_model, saved_model_dir)\n    with self.assertRaises(ValueError):\n      tf.keras.experimental.load_from_saved_model(saved_model_dir)\n\n    # works with `prune_scope`\n    with prune.prune_scope():\n      tf.keras.experimental.load_from_saved_model(saved_model_dir)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Keras callbacks for pruning.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# import g3\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\nK = tf.keras.backend\ncallbacks = tf.keras.callbacks\n\n\ndef _collect_prunable_layers(model):\n  """"""Recursively collect the prunable layers in the model.""""""\n  prunable_layers = []\n  for layer in model.layers:\n    # A keras model may have other models as layers.\n    if isinstance(layer, tf.keras.Model):\n      prunable_layers += _collect_prunable_layers(layer)\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      prunable_layers.append(layer)\n\n  return prunable_layers\n\n\nclass UpdatePruningStep(callbacks.Callback):\n  """"""Keras callback which updates pruning wrappers with the optimizer step.\n\n  This callback must be used when training a model which needs to be pruned. Not\n  doing so will throw an error.\n\n  Example:\n\n  ```python\n  model.fit(x, y,\n      callbacks=[UpdatePruningStep()])\n  ```\n  """"""\n\n  def __init__(self):\n    super(UpdatePruningStep, self).__init__()\n    self.prunable_layers = []\n\n  def on_train_begin(self, logs=None):\n    # Collect all the prunable layers in the model.\n    self.prunable_layers = _collect_prunable_layers(self.model)\n    self.step = K.get_value(self.model.optimizer.iterations)\n\n  def on_train_batch_begin(self, batch, logs=None):\n    tuples = []\n    for layer in self.prunable_layers:\n      tuples.append((layer.pruning_step, self.step))\n\n    K.batch_set_value(tuples)\n    self.step = self.step + 1\n\n  def on_epoch_end(self, batch, logs=None):\n    # At the end of every epoch, remask the weights. This ensures that when\n    # the model is saved after completion, the weights represent mask*weights.\n    weight_mask_ops = []\n\n    for layer in self.prunable_layers:\n      if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n        if tf.executing_eagerly():\n          layer.pruning_obj.weight_mask_op()\n        else:\n          weight_mask_ops.append(layer.pruning_obj.weight_mask_op())\n\n    K.batch_get_value(weight_mask_ops)\n\n\nclass PruningSummaries(callbacks.TensorBoard):\n  """"""A Keras callback for adding pruning summaries to tensorboard.\n\n  Logs the sparsity(%) and threshold at a given iteration step.\n  """"""\n\n  def __init__(self, log_dir, update_freq=\'epoch\', **kwargs):\n    super(PruningSummaries, self).__init__(\n        log_dir=log_dir, update_freq=update_freq, **kwargs)\n\n  def _log_pruning_metrics(self, logs, prefix, step):\n    if compat.is_v1_apis():\n      # Safely depend on TF 1.X private API given\n      # no more 1.X releases.\n      self._write_custom_summaries(step, logs)\n    else:  # TF 2.X\n      log_dir = self.log_dir + \'/metrics\'\n\n      file_writer = tf.summary.create_file_writer(log_dir)\n      file_writer.set_as_default()\n\n      for name, value in logs.items():\n        tf.summary.scalar(name, value, step=step)\n\n      file_writer.flush()\n\n  def on_epoch_begin(self, epoch, logs=None):\n    if logs is not None:\n      super(PruningSummaries, self).on_epoch_begin(epoch, logs)\n\n    pruning_logs = {}\n    params = []\n    prunable_layers = _collect_prunable_layers(self.model)\n    for layer in prunable_layers:\n      for _, mask, threshold in layer.pruning_vars:\n        params.append(mask)\n        params.append(threshold)\n\n    params.append(self.model.optimizer.iterations)\n\n    values = K.batch_get_value(params)\n    iteration = values[-1]\n    del values[-1]\n    del params[-1]\n\n    param_value_pairs = list(zip(params, values))\n\n    for mask, mask_value in param_value_pairs[::2]:\n      pruning_logs.update({\n          mask.name + \'/sparsity\': 1 - np.mean(mask_value)\n      })\n\n    for threshold, threshold_value in param_value_pairs[1::2]:\n      pruning_logs.update({threshold.name + \'/threshold\': threshold_value})\n\n    self._log_pruning_metrics(pruning_logs, \'\', iteration)\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks_test.py,10,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Pruning callbacks.""""""\n\nimport os\nimport tempfile\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n\nkeras = tf.keras\nerrors_impl = tf.errors\n\n\nclass PruneCallbacksTest(tf.test.TestCase, parameterized.TestCase):\n\n  _BATCH_SIZE = 20\n\n  def _assertLogsExist(self, log_dir):\n    self.assertNotEmpty(os.listdir(log_dir))\n\n  def _pruned_model_setup(self, custom_training_loop=False):\n    pruned_model = prune.prune_low_magnitude(\n        keras_test_utils.build_simple_dense_model())\n\n    x_train = np.random.rand(self._BATCH_SIZE, 10)\n    y_train = keras.utils.to_categorical(\n        np.random.randint(5, size=(self._BATCH_SIZE, 1)), 5)\n\n    loss = keras.losses.categorical_crossentropy\n    optimizer = keras.optimizers.SGD()\n\n    if custom_training_loop:\n      return pruned_model, loss, optimizer, x_train, y_train\n    else:\n      pruned_model.compile(loss=loss, optimizer=optimizer, metrics=[\'accuracy\'])\n      return pruned_model, x_train, y_train\n\n  @keras_parameterized.run_all_keras_modes\n  def testUpdatePruningStepsAndLogsSummaries(self):\n    log_dir = tempfile.mkdtemp()\n    pruned_model, x_train, y_train = self._pruned_model_setup()\n    pruned_model.fit(\n        x_train,\n        y_train,\n        batch_size=self._BATCH_SIZE,\n        epochs=3,\n        callbacks=[\n            pruning_callbacks.UpdatePruningStep(),\n            pruning_callbacks.PruningSummaries(log_dir=log_dir)\n        ])\n\n    self.assertEqual(\n        2, tf.keras.backend.get_value(pruned_model.layers[0].pruning_step))\n    self.assertEqual(\n        2, tf.keras.backend.get_value(pruned_model.layers[1].pruning_step))\n\n    self._assertLogsExist(log_dir)\n\n  # This style of custom training loop isn\'t available in graph mode.\n  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n  def testUpdatePruningStepsAndLogsSummaries_CustomTrainingLoop(self):\n    log_dir = tempfile.mkdtemp()\n    pruned_model, loss, optimizer, x_train, y_train = self._pruned_model_setup(\n        custom_training_loop=True)\n\n    unused_arg = -1\n\n    step_callback = pruning_callbacks.UpdatePruningStep()\n    log_callback = pruning_callbacks.PruningSummaries(log_dir=log_dir)\n    # TODO(tfmot): we need a separate API for custom training loops\n    # that doesn\'t rely on users setting the model and optimizer.\n    #\n    # Example is currently based on callbacks.py configure_callbacks\n    # and model.compile internals.\n    step_callback.set_model(pruned_model)\n    log_callback.set_model(pruned_model)\n    pruned_model.optimizer = optimizer\n\n    step_callback.on_train_begin()\n    for _ in range(3):\n      log_callback.on_epoch_begin(epoch=unused_arg)\n      # only one batch given batch_size = 20 and input shape.\n      step_callback.on_train_batch_begin(batch=unused_arg)\n      inp = np.reshape(x_train,\n                       [self._BATCH_SIZE, 10])  # original shape: from [10].\n      with tf.GradientTape() as tape:\n        logits = pruned_model(inp, training=True)\n        loss_value = loss(y_train, logits)\n        grads = tape.gradient(loss_value, pruned_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, pruned_model.trainable_variables))\n      step_callback.on_epoch_end(batch=unused_arg)\n\n    self.assertEqual(\n        2, tf.keras.backend.get_value(pruned_model.layers[0].pruning_step))\n    self.assertEqual(\n        2, tf.keras.backend.get_value(pruned_model.layers[1].pruning_step))\n    self._assertLogsExist(log_dir)\n\n  @keras_parameterized.run_all_keras_modes\n  def testPruneTrainingRaisesError_PruningStepCallbackMissing(self):\n    pruned_model, x_train, y_train = self._pruned_model_setup()\n\n    # Throws an error since UpdatePruningStep is missing.\n    with self.assertRaises(errors_impl.InvalidArgumentError):\n      pruned_model.fit(x_train, y_train)\n\n  # This style of custom training loop isn\'t available in graph mode.\n  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n  def testPruneTrainingLoopRaisesError_PruningStepCallbackMissing_CustomTrainingLoop(\n      self):\n    pruned_model, _, _, x_train, _ = self._pruned_model_setup(\n        custom_training_loop=True)\n\n    # Throws an error since UpdatePruningStep is missing.\n    with self.assertRaises(errors_impl.InvalidArgumentError):\n      inp = np.reshape(x_train, [self._BATCH_SIZE, 10])  # original shape: [10].\n      with tf.GradientTape():\n        pruned_model(inp, training=True)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py,32,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Helper functions to add support for magnitude-based model pruning.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow.python.ops import summary_ops_v2\nfrom tensorflow.python.summary import summary as summary_ops_v1\nfrom tensorflow_model_optimization.python.core.keras import compat as tf_compat\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_utils\n\n\nclass Pruning(object):\n  """"""Implementation of magnitude-based weight pruning.""""""\n\n  def __init__(self, training_step_fn, pruning_vars, pruning_schedule,\n               block_size, block_pooling_type):\n    """"""The logic for magnitude-based pruning weight tensors.\n\n    Args:\n      training_step_fn: A callable that returns the training step.\n      pruning_vars: A list of (weight, mask, threshold) tuples\n      pruning_schedule: A `PruningSchedule` object that controls pruning rate\n        throughout training.\n      block_size: The dimensions (height, weight) for the block sparse pattern\n        in rank-2 weight tensors.\n      block_pooling_type: (optional) The function to use to pool weights in the\n        block. Must be \'AVG\' or \'MAX\'.\n    """"""\n    self._pruning_vars = pruning_vars\n    self._pruning_schedule = pruning_schedule\n    self._block_size = list(block_size)\n    self._block_pooling_type = block_pooling_type\n    self._validate_block()\n\n    # Training step\n    self._step_fn = training_step_fn\n\n    self._validate_block()\n\n  def _validate_block(self):\n    if self._block_size != [1, 1]:\n      for weight, _, _ in self._pruning_vars:\n        if weight.get_shape().ndims != 2:\n          raise ValueError(\'Block Sparsity can only be used for layers which \'\n                           \'have 2-dimensional weights.\')\n\n  def _update_mask(self, weights):\n    """"""Updates the mask for a given weight tensor.\n\n    This functions first estimates the threshold value such that\n    a given fraction of weights have magnitude less than\n    the threshold.\n\n    Args:\n      weights: The weight tensor that needs to be masked.\n\n    Returns:\n      new_threshold: The new value of the threshold based on weights, and\n        sparsity at the current global_step\n      new_mask: A numpy array of the same size and shape as weights containing\n        0 or 1 to indicate which of the values in weights falls below\n        the threshold\n\n    Raises:\n      ValueError: if sparsity is not defined\n    """"""\n    sparsity = self._pruning_schedule(self._step_fn())[1]\n    with tf.name_scope(\'pruning_ops\'):\n      abs_weights = tf.math.abs(weights)\n      k = tf.dtypes.cast(\n          tf.math.round(\n              tf.dtypes.cast(tf.size(abs_weights), tf.float32) *\n              (1 - sparsity)), tf.int32)\n      # Sort the entire array\n      values, _ = tf.math.top_k(\n          tf.reshape(abs_weights, [-1]), k=tf.size(abs_weights))\n      # Grab the (k-1)th value\n\n      current_threshold = tf.gather(values, k - 1)\n      new_mask = tf.dtypes.cast(\n          tf.math.greater_equal(abs_weights, current_threshold), weights.dtype)\n    return current_threshold, new_mask\n\n  def _maybe_update_block_mask(self, weights):\n    """"""Performs block-granular masking of the weights.\n\n    Block pruning occurs only if the block_height or block_width is > 1 and\n    if the weight tensor, when squeezed, has ndims = 2. Otherwise, elementwise\n    pruning occurs.\n    Args:\n      weights: The weight tensor that needs to be masked.\n\n    Returns:\n      new_threshold: The new value of the threshold based on weights, and\n        sparsity at the current global_step\n      new_mask: A numpy array of the same size and shape as weights containing\n        0 or 1 to indicate which of the values in weights falls below\n        the threshold\n\n    Raises:\n      ValueError: if block pooling function is not AVG or MAX\n    """"""\n    if self._block_size == [1, 1]:\n      return self._update_mask(weights)\n\n    # TODO(pulkitb): Check if squeeze operations should now be removed since\n    # we are only accepting 2-D weights.\n\n    squeezed_weights = tf.squeeze(weights)\n    abs_weights = tf.math.abs(squeezed_weights)\n    pooled_weights = pruning_utils.factorized_pool(\n        abs_weights,\n        window_shape=self._block_size,\n        pooling_type=self._block_pooling_type,\n        strides=self._block_size,\n        padding=\'SAME\')\n\n    if pooled_weights.get_shape().ndims != 2:\n      pooled_weights = tf.squeeze(pooled_weights)\n\n    new_threshold, new_mask = self._update_mask(pooled_weights)\n\n    updated_mask = pruning_utils.expand_tensor(new_mask, self._block_size)\n    sliced_mask = tf.slice(\n        updated_mask, [0, 0],\n        [squeezed_weights.get_shape()[0],\n         squeezed_weights.get_shape()[1]])\n    return new_threshold, tf.reshape(sliced_mask, tf.shape(weights))\n\n  def _weight_assign_objs(self):\n    """"""Gather the assign objs for assigning weights<=weights*mask.\n\n    The objs are ops for graph execution and tensors for eager\n    execution.\n\n    Returns:\n      group of objs for weight assignment.\n    """"""\n\n    def update_fn(distribution, values_and_vars):\n      # TODO(yunluli): Need this ReduceOp because the weight is created by the\n      # layer wrapped, so we don\'t have control of its aggregation policy. May\n      # be able to optimize this when distribution strategy supports easier\n      # update to mirrored variables in replica context.\n      reduced_values = distribution.extended.batch_reduce_to(\n          tf.distribute.ReduceOp.MEAN, values_and_vars)\n      var_list = [v for _, v in values_and_vars]\n      values_and_vars = zip(reduced_values, var_list)\n\n      def update_var(variable, reduced_value):\n        return tf_compat.assign(variable, reduced_value)\n\n      update_objs = []\n      for value, var in values_and_vars:\n        update_objs.append(\n            distribution.extended.update(var, update_var, args=(value,)))\n\n      return tf.group(update_objs)\n\n    assign_objs = []\n\n    if tf.distribute.get_replica_context():\n      values_and_vars = []\n      for weight, mask, _ in self._pruning_vars:\n        masked_weight = tf.math.multiply(weight, mask)\n        values_and_vars.append((masked_weight, weight))\n      if values_and_vars:\n        assign_objs.append(tf.distribute.get_replica_context().merge_call(\n            update_fn, args=(values_and_vars,)))\n    else:\n      for weight, mask, _ in self._pruning_vars:\n        masked_weight = tf.math.multiply(weight, mask)\n        assign_objs.append(tf_compat.assign(weight, masked_weight))\n\n    return assign_objs\n\n  def weight_mask_op(self):\n    return tf.group(self._weight_assign_objs())\n\n  def conditional_mask_update(self):\n    """"""Returns an op to updates masks as per the pruning schedule.""""""\n\n    def maybe_update_masks():\n      return self._pruning_schedule(self._step_fn())[0]\n\n    def no_update():\n      return tf.no_op()\n\n    def mask_update():\n      """"""Updates mask without distribution strategy.""""""\n\n      def update():\n        assign_objs = []\n\n        for weight, mask, threshold in self._pruning_vars:\n          new_threshold, new_mask = self._maybe_update_block_mask(weight)\n          assign_objs.append(tf_compat.assign(threshold, new_threshold))\n          assign_objs.append(tf_compat.assign(mask, new_mask))\n\n        return tf.group(assign_objs)\n\n      return tf.cond(maybe_update_masks(), update, no_update)\n\n    def mask_update_distributed(distribution):\n      """"""Updates mask with distribution strategy.""""""\n\n      def update(var, value):\n        return tf_compat.assign(var, value)\n\n      def update_distributed():\n        """"""Gather distributed update objs.\n\n        The objs are ops for graph execution and tensors for eager\n        execution.\n        """"""\n        assign_objs = []\n\n        for weight, mask, threshold in self._pruning_vars:\n          new_threshold, new_mask = self._maybe_update_block_mask(weight)\n          assign_objs.append(\n              distribution.extended.update(mask, update, (new_mask,)))\n          assign_objs.append(\n              distribution.extended.update(threshold, update, (new_threshold,)))\n\n        return tf.group(assign_objs)\n\n      return tf.cond(maybe_update_masks(), update_distributed, no_update)\n\n    if tf.distribute.get_replica_context():\n      return tf.distribute.get_replica_context().merge_call(\n          mask_update_distributed)\n    else:\n      return mask_update()\n\n  def add_pruning_summaries(self):\n    """"""Adds summaries of weight sparsities and thresholds.""""""\n    # b/(139939526): update to use public API.\n    summary = summary_ops_v1\n    if tf.executing_eagerly():\n      summary = summary_ops_v2\n    summary.scalar(\'sparsity\', self._pruning_schedule(self._step_fn())[1])\n    for _, mask, threshold in self._pruning_vars:\n      summary.scalar(mask.name + \'/sparsity\', 1.0 - tf.math.reduce_mean(mask))\n      summary.scalar(threshold.name + \'/threshold\', threshold)\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl_test.py,27,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for the key functions in pruning library.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# import g3\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_impl\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_utils\n\nK = tf.keras.backend\ndtypes = tf.dtypes\ntest = tf.test\n\n\ndef assign_add(ref, value):\n  if hasattr(tf, ""assign_add""):\n    return tf.assign_add(ref, value)\n  else:\n    return ref.assign_add(value)\n\n\n@keras_parameterized.run_all_keras_modes\nclass PruningTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(PruningTest, self).setUp()\n    self.block_size = (1, 1)\n    self.block_pooling_type = ""AVG""\n\n    self.constant_sparsity = pruning_schedule.ConstantSparsity(0.5, 0, 100, 1)\n\n  # Variable initialization outside of setUp() is needed for compatibility with\n  # run_all_keras_modes.\n  #\n  # setUp() lies outside of the ""eager scope"" that wraps the test cases\n  # themselves, resulting in initializing graph tensors instead of eager\n  # tensors when testing eager execution.\n  def initialize(self):\n    self.global_step = tf.Variable(\n        tf.zeros([], dtype=dtypes.int32),\n        dtype=dtypes.int32,\n        name=""global_step"")\n\n    def training_step_fn():\n      return self.global_step\n    self.training_step_fn = training_step_fn\n\n    compat.initialize_variables(self)\n\n  def testUpdateSingleMask(self):\n    weight = tf.Variable(np.linspace(1.0, 100.0, 100), name=""weights"")\n    weight_dtype = weight.dtype.base_dtype\n    mask = tf.Variable(\n        tf.ones(weight.get_shape(), dtype=weight_dtype),\n        name=""mask"",\n        dtype=weight_dtype)\n    threshold = tf.Variable(\n        tf.zeros([], dtype=weight_dtype), name=""threshold"", dtype=weight_dtype)\n    self.initialize()\n\n    p = pruning_impl.Pruning(\n        pruning_vars=[(weight, mask, threshold)],\n        training_step_fn=self.training_step_fn,\n        pruning_schedule=self.constant_sparsity,\n        block_size=self.block_size,\n        block_pooling_type=self.block_pooling_type)\n\n    mask_before_pruning = K.get_value(mask)\n    self.assertAllEqual(np.count_nonzero(mask_before_pruning), 100)\n\n    if tf.executing_eagerly():\n      p.conditional_mask_update()\n    else:\n      K.get_session().run(p.conditional_mask_update())\n\n    mask_after_pruning = K.get_value(mask)\n    self.assertAllEqual(np.count_nonzero(mask_after_pruning), 50)\n\n  def testConstructsMaskAndThresholdCorrectly(self):\n    self.initialize()\n    p = pruning_impl.Pruning(\n        lambda: 0, None,\n        # Sparsity math often returns values with small tolerances.\n        lambda x: (True, 0.200000018),\n        (1, 1), None)\n\n    # input matrix is [ 1.0, 2.0, ..., 8.0, 9.0, 10.0 ]\n    threshold, mask = p._update_mask(np.arange(1, 11))\n\n    self.assertEqual(3, K.get_value(threshold))\n    self.assertAllEqual(\n        # expected matrix is [ 0.0, 0.0, 1.0, 1.0 ... 1.0 ]\n        np.concatenate((np.zeros(2), np.ones(8))), K.get_value(mask))\n\n  def _blockMasking(self, block_size, block_pooling_type, weight,\n                    expected_mask):\n    mask = tf.Variable(\n        tf.ones(weight.get_shape(), dtype=weight.dtype),\n        name=""mask"",\n        dtype=weight.dtype)\n    threshold = tf.Variable(\n        tf.zeros([], dtype=weight.dtype), name=""threshold"", dtype=weight.dtype)\n    self.initialize()\n\n    # Set up pruning\n    p = pruning_impl.Pruning(\n        pruning_vars=[(weight, mask, threshold)],\n        training_step_fn=self.training_step_fn,\n        pruning_schedule=self.constant_sparsity,\n        block_size=block_size,\n        block_pooling_type=block_pooling_type)\n\n    _, new_mask = p._maybe_update_block_mask(weight)\n    # Check if the mask is the same size as the weights\n    self.assertAllEqual(new_mask.get_shape(), weight.get_shape())\n    mask_after_pruning = K.get_value(new_mask)\n    self.assertAllEqual(mask_after_pruning, expected_mask)\n\n  def testBlockMaskingAvg(self):\n    block_size = (2, 2)\n    block_pooling_type = ""AVG""\n    weight = tf.constant([[0.1, 0.1, 0.2, 0.2], [0.1, 0.1, 0.2, 0.2],\n                          [0.3, 0.3, 0.4, 0.4], [0.3, 0.3, 0.4, 0.4]])\n    expected_mask = [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0],\n                     [1., 1., 1., 1.], [1., 1., 1., 1.]]\n\n    self._blockMasking(block_size, block_pooling_type, weight, expected_mask)\n\n  def testBlockMaskingMax(self):\n    block_size = (2, 2)\n    block_pooling_type = ""MAX""\n    weight = tf.constant([[0.1, 0.0, 0.2, 0.0], [0.0, -0.1, 0.0, -0.2],\n                                   [0.3, 0.0, 0.4, 0.0], [0.0, -0.3, 0.0,\n                                                          -0.4]])\n    expected_mask = [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0],\n                     [1., 1., 1., 1.], [1., 1., 1., 1.]]\n\n    self._blockMasking(block_size, block_pooling_type, weight, expected_mask)\n\n  def testBlockMaskingWithHigherDimensionsRaisesError(self):\n    self.initialize()\n    block_size = (2, 2)\n    block_pooling_type = ""AVG""\n    # Weights as in testBlockMasking, but with one extra dimension.\n    weight = tf.constant([[[0.1, 0.1, 0.2, 0.2], [0.1, 0.1, 0.2, 0.2],\n                                    [0.3, 0.3, 0.4, 0.4], [0.3, 0.3, 0.4,\n                                                           0.4]]])\n    expected_mask = [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0],\n                      [1., 1., 1., 1.], [1., 1., 1., 1.]]]\n\n    # Block masking should only be used with 2 Dimensional weights.\n    with self.assertRaises(ValueError):\n      self._blockMasking(block_size, block_pooling_type, weight, expected_mask)\n\n  def testConditionalMaskUpdate(self):\n    weight = tf.Variable(np.linspace(1.0, 100.0, 100), name=""weights"")\n    weight_dtype = weight.dtype.base_dtype\n    mask = tf.Variable(\n        tf.ones(weight.get_shape(), dtype=weight_dtype),\n        name=""mask"",\n        dtype=weight_dtype)\n    threshold = tf.Variable(\n        tf.zeros([], dtype=weight_dtype), name=""threshold"", dtype=weight_dtype)\n    self.initialize()\n\n    def linear_sparsity(step):\n      sparsity_val = tf.convert_to_tensor(\n          [0.0, 0.1, 0.1, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5])\n      return tf.convert_to_tensor(True), sparsity_val[step]\n\n    # Set up pruning\n    p = pruning_impl.Pruning(\n        pruning_vars=[(weight, mask, threshold)],\n        training_step_fn=self.training_step_fn,\n        pruning_schedule=linear_sparsity,\n        block_size=self.block_size,\n        block_pooling_type=self.block_pooling_type)\n\n    non_zero_count = []\n    for _ in range(10):\n      if tf.executing_eagerly():\n        p.conditional_mask_update()\n        p.weight_mask_op()\n        assign_add(self.global_step, 1)\n      else:\n        K.get_session().run(p.conditional_mask_update())\n        K.get_session().run(p.weight_mask_op())\n        K.get_session().run(assign_add(self.global_step, 1))\n\n      non_zero_count.append(np.count_nonzero(K.get_value(weight)))\n\n    # Weights pruned at steps 1,3,5\n    expected_non_zero_count = [100, 90, 90, 70, 70, 50, 50, 50, 50, 50]\n    self.assertAllEqual(expected_non_zero_count, non_zero_count)\n\n\nif __name__ == ""__main__"":\n  test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py,18,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Pruning Schedule classes to control pruning rate during training.""""""\n\nimport abc\nimport six\nimport tensorflow as tf\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass PruningSchedule(object):\n  """"""Specifies when to prune layer and the sparsity(%) at each training step.\n\n  PruningSchedule controls pruning during training by notifying at each step\n  whether the layer\'s weights should be pruned or not, and the sparsity(%) at\n  which they should be pruned.\n\n  It can be invoked as a `callable` by providing the training `step` Tensor. It\n  returns a tuple of bool and float tensors.\n\n  ```python\n    should_prune, sparsity = pruning_schedule(step)\n  ```\n\n  You can inherit this class to write your own custom pruning schedule.\n  """"""\n\n  @staticmethod\n  def _should_prune_in_step(step, begin_step, end_step, frequency):\n    """"""Checks if pruning should be applied in the current training step.\n\n    Pruning should only occur within the [`begin_step`, `end_step`] range every\n    `frequency` number of steps.\n\n    Args:\n      step: Current training step.\n      begin_step: Step at which to begin pruning.\n      end_step: Step at which to end pruning.\n      frequency: Only apply pruning every `frequency` steps.\n\n    Returns:\n      True/False, if pruning should be applied in current step.\n    """"""\n    is_in_pruning_range = tf.math.logical_and(\n        tf.math.greater_equal(step, begin_step),\n        # If end_pruning_step is negative, keep pruning forever!\n        tf.math.logical_or(\n            tf.math.less_equal(step, end_step), tf.math.less(end_step, 0)))\n\n    is_pruning_turn = tf.math.equal(\n        tf.math.floormod(tf.math.subtract(step, begin_step), frequency), 0)\n\n    return tf.math.logical_and(is_in_pruning_range, is_pruning_turn)\n\n  @staticmethod\n  def _validate_step(begin_step, end_step, frequency, allow_negative_1):\n    """"""Checks whether the parameters for pruning schedule are valid.\n\n    Args:\n      begin_step: Step at which to begin pruning.\n      end_step: Step at which to end pruning. Special value of `-1` implies\n        pruning can continue forever.\n      frequency: Only apply pruning every `frequency` steps.\n      allow_negative_1: Whether end_step is allowed to be `-1` or not.\n\n    Returns:\n      None\n    """"""\n\n    if begin_step < 0:\n      raise ValueError(\'begin_step should be >= 0\')\n\n    # In cases like PolynomialDecay, continuing to prune forever does not make\n    # sense. The function needs an end_step to decay the sparsity.\n    if not allow_negative_1 and end_step == -1:\n      raise ValueError(\'end_step cannot be -1.\')\n\n    if end_step != -1:\n      if end_step < 0:\n        raise ValueError(\'end_step can be -1 or >= 0\')\n      if end_step < begin_step:\n        raise ValueError(\'begin_step should be <= end_step if end_step != -1\')\n\n    if frequency <= 0:\n      raise ValueError(\'frequency should be > 0\')\n\n  @staticmethod\n  def _validate_sparsity(sparsity, variable_name):\n    if not 0.0 <= sparsity < 1.0:\n      raise ValueError(\'{} must be in range [0,1)\'.format(variable_name))\n\n  @abc.abstractmethod\n  def __call__(self, step):\n    """"""Returns the sparsity(%) to be applied.\n\n    If the returned sparsity(%) is 0, pruning is ignored for the step.\n\n    Args:\n      step: Current step in graph execution.\n\n    Returns:\n      Sparsity (%) that should be applied to the weights for the step.\n    """"""\n    raise NotImplementedError(\n        \'PruningSchedule implementation must override __call__\')\n\n  @abc.abstractmethod\n  def get_config(self):\n    raise NotImplementedError(\n        \'PruningSchedule implementation override get_config\')\n\n  @classmethod\n  def from_config(cls, config):\n    """"""Instantiates a `PruningSchedule` from its config.\n\n    Args:\n        config: Output of `get_config()`.\n\n    Returns:\n        A `PruningSchedule` instance.\n    """"""\n    return cls(**config)\n\n\nclass ConstantSparsity(PruningSchedule):\n  """"""Pruning schedule with constant sparsity(%) throughout training.""""""\n\n  def __init__(self,\n               target_sparsity,\n               begin_step,\n               end_step=-1,\n               frequency=100):\n    """"""Initializes a Pruning schedule with constant sparsity.\n\n    Sparsity is applied in the interval [`begin_step`, `end_step`] every\n    `frequency` steps. At each applicable step, the sparsity(%) is constant.\n\n    Args:\n      target_sparsity: A scalar float representing the target sparsity value.\n      begin_step: Step at which to begin pruning.\n      end_step: Step at which to end pruning. `-1` by default. `-1` implies\n        continuing to prune till the end of training.\n      frequency: Only apply pruning every `frequency` steps.\n    """"""\n\n    self.target_sparsity = target_sparsity\n    self.begin_step = begin_step\n    self.end_step = end_step\n    self.frequency = frequency\n\n    self._validate_step(self.begin_step, self.end_step, self.frequency, True)\n    self._validate_sparsity(target_sparsity, \'target_sparsity\')\n\n  def __call__(self, step):\n    return (self._should_prune_in_step(step, self.begin_step, self.end_step,\n                                       self.frequency),\n            tf.constant(self.target_sparsity, dtype=tf.float32))\n\n  def get_config(self):\n    return {\n        \'class_name\': self.__class__.__name__,\n        \'config\': {\n            \'target_sparsity\': self.target_sparsity,\n            \'begin_step\': self.begin_step,\n            \'end_step\': self.end_step,\n            \'frequency\': self.frequency\n        }\n    }\n\n\nclass PolynomialDecay(PruningSchedule):\n  """"""Pruning Schedule with a PolynomialDecay function.""""""\n\n  def __init__(self,\n               initial_sparsity,\n               final_sparsity,\n               begin_step,\n               end_step,\n               power=3,\n               frequency=100):\n    """"""Initializes a Pruning schedule with a PolynomialDecay function.\n\n    Pruning rate grows rapidly in the beginning from initial_sparsity, but then\n    plateaus slowly to the target sparsity. The function applied is\n\n    current_sparsity = final_sparsity + (initial_sparsity - final_sparsity)\n          * (1 - (step - begin_step)/(end_step - begin_step)) ^ exponent\n\n    which is a polynomial decay function. See\n    [paper](https://arxiv.org/abs/1710.01878).\n\n    Args:\n      initial_sparsity: Sparsity (%) at which pruning begins.\n      final_sparsity: Sparsity (%) at which pruning ends.\n      begin_step: Step at which to begin pruning.\n      end_step: Step at which to end pruning.\n      power: Exponent to be used in the sparsity function.\n      frequency: Only apply pruning every `frequency` steps.\n    """"""\n\n    self.initial_sparsity = initial_sparsity\n    self.final_sparsity = final_sparsity\n    self.power = power\n\n    self.begin_step = begin_step\n    self.end_step = end_step\n    self.frequency = frequency\n\n    self._validate_step(self.begin_step, self.end_step, self.frequency, False)\n    self._validate_sparsity(initial_sparsity, \'initial_sparsity\')\n    self._validate_sparsity(final_sparsity, \'final_sparsity\')\n\n  def __call__(self, step):\n    # TODO(tf-mot): consider switch to divide for 1.XX also.\n    if hasattr(tf, \'div\'):\n      divide = tf.div\n    else:\n      divide = tf.math.divide\n\n    # TODO(pulkitb): Replace function with tf.polynomial_decay\n    with tf.name_scope(\'polynomial_decay_pruning_schedule\'):\n      p = tf.math.minimum(\n          1.0,\n          tf.math.maximum(\n              0.0,\n              divide(\n                  tf.dtypes.cast(step - self.begin_step, tf.float32),\n                  self.end_step - self.begin_step)))\n      sparsity = tf.math.add(\n          tf.math.multiply(self.initial_sparsity - self.final_sparsity,\n                           tf.math.pow(1 - p, self.power)),\n          self.final_sparsity,\n          name=\'sparsity\')\n\n    return (self._should_prune_in_step(step, self.begin_step, self.end_step,\n                                       self.frequency),\n            sparsity)\n\n  def get_config(self):\n    return {\n        \'class_name\': self.__class__.__name__,\n        \'config\': {\n            \'initial_sparsity\': self.initial_sparsity,\n            \'final_sparsity\': self.final_sparsity,\n            \'power\': self.power,\n            \'begin_step\': self.begin_step,\n            \'end_step\': self.end_step,\n            \'frequency\': self.frequency\n        }\n    }\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule_test.py,27,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Pruning Schedule.""""""\n\nfrom absl.testing import parameterized\nimport tensorflow as tf\n\n# TODO(b/139939526): move to public API.\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n\n\nclass PruningScheduleTest(tf.test.TestCase, parameterized.TestCase):\n  """"""Test to verify PruningSchedule behavior for step parameters.\n\n  This is a parameterized test which runs over all PruningSchedule classes\n  to ensure they validate parameters such as begin_step, end_step and frequency\n  properly and also apply them correctly during execution.\n  """"""\n\n  # Argument Validation tests\n\n  @staticmethod\n  def _construct_pruning_schedule(\n      schedule_type, begin_step, end_step, frequency=10):\n    # Uses default values for sparsity. We\'re only testing begin_step, end_step\n    # and frequency here.\n    if schedule_type == \'constant_sparsity\':\n      return pruning_schedule.ConstantSparsity(\n          0.5, begin_step, end_step, frequency)\n    elif schedule_type == \'polynomial_decay\':\n      return pruning_schedule.PolynomialDecay(\n          0.2, 0.8, begin_step, end_step, 3, frequency)\n\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testBeginStepGreaterThanEqualsZero(self, schedule_type):\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, -1, 1000)\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, -5, 1000)\n\n    self._construct_pruning_schedule(schedule_type, 0, 1000)\n    self._construct_pruning_schedule(schedule_type, 1, 1000)\n    self._construct_pruning_schedule(schedule_type, 100, 1000)\n\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testEndStepGreaterThanEqualsZero(self, schedule_type):\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, 10, -5)\n\n    self._construct_pruning_schedule(schedule_type, 0, 0)\n    self._construct_pruning_schedule(schedule_type, 0, 1)\n    self._construct_pruning_schedule(schedule_type, 0, 100)\n\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testEndStepGreaterThanEqualsBeginStep(self, schedule_type):\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, 10, 5)\n\n    self._construct_pruning_schedule(schedule_type, 10, 10)\n    self._construct_pruning_schedule(schedule_type, 10, 20)\n\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testFrequencyIsPositive(self, schedule_type):\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, 10, 1000, 0)\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, 10, 1000, -1)\n    with self.assertRaises(ValueError):\n      self._construct_pruning_schedule(schedule_type, 10, 1000, -5)\n\n    self._construct_pruning_schedule(schedule_type, 10, 1000, 1)\n    self._construct_pruning_schedule(schedule_type, 10, 1000, 10)\n\n  def _validate_sparsity(self, schedule_construct_fn):\n    # Should not be < 0.0\n    with self.assertRaises(ValueError):\n      schedule_construct_fn(-0.001)\n    with self.assertRaises(ValueError):\n      schedule_construct_fn(-1.0)\n    with self.assertRaises(ValueError):\n      schedule_construct_fn(-10.0)\n\n    # Should not be >= 1.0\n    with self.assertRaises(ValueError):\n      schedule_construct_fn(1.0)\n    with self.assertRaises(ValueError):\n      schedule_construct_fn(10.0)\n\n    schedule_construct_fn(0.0)\n    schedule_construct_fn(0.001)\n    schedule_construct_fn(0.5)\n    schedule_construct_fn(0.99)\n\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testSparsityValueIsValid(self, schedule_type):\n    if schedule_type == \'constant_sparsity\':\n      # pylint: disable=unnecessary-lambda\n      self._validate_sparsity(lambda s: pruning_schedule.ConstantSparsity(s, 0))\n    elif schedule_type == \'polynomial_decay\':\n      self._validate_sparsity(\n          lambda s: pruning_schedule.PolynomialDecay(s, 0.8, 0, 10))\n      self._validate_sparsity(\n          lambda s: pruning_schedule.PolynomialDecay(0.2, s, 0, 10))\n\n  # Tests to ensure begin_step, end_step, frequency are used correctly.\n\n  @keras_parameterized.run_all_keras_modes\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testPrunesOnlyInBeginEndStepRange(self, schedule_type):\n    sparsity = self._construct_pruning_schedule(schedule_type, 100, 200, 1)\n\n    # Before begin step\n    step_90 = tf.Variable(90)\n    step_99 = tf.Variable(99)\n    # In range\n    step_100 = tf.Variable(100)\n    step_110 = tf.Variable(110)\n    step_200 = tf.Variable(200)\n    # After end step\n    step_201 = tf.Variable(201)\n    step_210 = tf.Variable(210)\n    compat.initialize_variables(self)\n\n    self.assertFalse(self.evaluate(sparsity(step_90))[0])\n    self.assertFalse(self.evaluate(sparsity(step_99))[0])\n\n    self.assertTrue(self.evaluate(sparsity(step_100))[0])\n    self.assertTrue(self.evaluate(sparsity(step_110))[0])\n    self.assertTrue(self.evaluate(sparsity(step_200))[0])\n\n    self.assertFalse(self.evaluate(sparsity(step_201))[0])\n    self.assertFalse(self.evaluate(sparsity(step_210))[0])\n\n  @keras_parameterized.run_all_keras_modes\n  @parameterized.named_parameters(\n      {\n          \'testcase_name\': \'ConstantSparsity\',\n          \'schedule_type\': \'constant_sparsity\'\n      }, {\n          \'testcase_name\': \'PolynomialDecay\',\n          \'schedule_type\': \'polynomial_decay\'\n      })\n  def testOnlyPrunesAtValidFrequencySteps(self, schedule_type):\n    sparsity = self._construct_pruning_schedule(schedule_type, 100, 200, 10)\n\n    step_100 = tf.Variable(100)\n    step_109 = tf.Variable(109)\n    step_110 = tf.Variable(110)\n    step_111 = tf.Variable(111)\n    compat.initialize_variables(self)\n\n    self.assertFalse(self.evaluate(sparsity(step_109))[0])\n    self.assertFalse(self.evaluate(sparsity(step_111))[0])\n\n    self.assertTrue(self.evaluate(sparsity(step_100))[0])\n    self.assertTrue(self.evaluate(sparsity(step_110))[0])\n\n\nclass ConstantSparsityTest(tf.test.TestCase, parameterized.TestCase):\n\n  @keras_parameterized.run_all_keras_modes\n  def testPrunesForeverIfEndStepIsNegativeOne(self):\n    sparsity = pruning_schedule.ConstantSparsity(0.5, 0, -1, 10)\n\n    step_10000 = tf.Variable(10000)\n    step_100000000 = tf.Variable(100000000)\n    compat.initialize_variables(self)\n\n    self.assertTrue(self.evaluate(sparsity(step_10000))[0])\n    self.assertTrue(self.evaluate(sparsity(step_100000000))[0])\n\n    self.assertAllClose(0.5, self.evaluate(sparsity(step_10000))[1])\n    self.assertAllClose(0.5, self.evaluate(sparsity(step_100000000))[1])\n\n  @keras_parameterized.run_all_keras_modes\n  def testPrunesWithConstantSparsity(self):\n    sparsity = pruning_schedule.ConstantSparsity(0.5, 100, 200, 10)\n\n    step_100 = tf.Variable(100)\n    step_110 = tf.Variable(110)\n    step_200 = tf.Variable(200)\n    compat.initialize_variables(self)\n\n    self.assertAllClose(0.5, self.evaluate(sparsity(step_100))[1])\n    self.assertAllClose(0.5, self.evaluate(sparsity(step_110))[1])\n    self.assertAllClose(0.5, self.evaluate(sparsity(step_200))[1])\n\n  def testSerializeDeserialize(self):\n    sparsity = pruning_schedule.ConstantSparsity(0.7, 10, 20, 10)\n\n    config = sparsity.get_config()\n    sparsity_deserialized = tf.keras.utils.deserialize_keras_object(\n        config,\n        custom_objects={\n            \'ConstantSparsity\': pruning_schedule.ConstantSparsity,\n            \'PolynomialDecay\': pruning_schedule.PolynomialDecay\n        })\n\n    self.assertEqual(sparsity.__dict__, sparsity_deserialized.__dict__)\n\n\nclass PolynomialDecayTest(tf.test.TestCase, parameterized.TestCase):\n\n  def testRaisesErrorIfEndStepIsNegative(self):\n    with self.assertRaises(ValueError):\n      pruning_schedule.PolynomialDecay(0.4, 0.8, 10, -1)\n\n  @keras_parameterized.run_all_keras_modes\n  def testPolynomialDecay_PrunesCorrectly(self):\n    sparsity = pruning_schedule.PolynomialDecay(0.2, 0.8, 100, 110, 3, 2)\n\n    step_100 = tf.Variable(100)\n    step_102 = tf.Variable(102)\n    step_105 = tf.Variable(105)\n    step_110 = tf.Variable(110)\n    compat.initialize_variables(self)\n\n    # These values were generated using tf.polynomial_decay with the same\n    # params in a colab to verify.\n    self.assertAllClose(0.2, self.evaluate(sparsity(step_100))[1])\n    self.assertAllClose(0.4928, self.evaluate(sparsity(step_102))[1])\n    self.assertAllClose(0.725, self.evaluate(sparsity(step_105))[1])\n    self.assertAllClose(0.8, self.evaluate(sparsity(step_110))[1])\n\n  def testSerializeDeserialize(self):\n    sparsity = pruning_schedule.PolynomialDecay(0.2, 0.6, 10, 20, 5, 10)\n\n    config = sparsity.get_config()\n    sparsity_deserialized = tf.keras.utils.deserialize_keras_object(\n        config,\n        custom_objects={\n            \'ConstantSparsity\': pruning_schedule.ConstantSparsity,\n            \'PolynomialDecay\': pruning_schedule.PolynomialDecay\n        })\n\n    self.assertEqual(sparsity.__dict__, sparsity_deserialized.__dict__)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_utils.py,14,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Utility functions for adding pruning related ops to the graph.\n\n""""""\n# pylint: disable=missing-docstring\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# import g3\nimport numpy as np\nimport tensorflow as tf\n\n\ndef kronecker_product(mat1, mat2):\n  """"""Computes the Kronecker product of two matrices mat1 and mat2.\n\n  Args:\n    mat1: A matrix of size m x n\n    mat2: A matrix of size p x q\n\n  Returns:\n    Kronecker product of matrices mat1 and mat2 of size mp x nq\n  """"""\n\n  m1, n1 = mat1.get_shape().as_list()\n  mat1_rsh = tf.reshape(mat1, [m1, 1, n1, 1])\n  m2, n2 = mat2.get_shape().as_list()\n  mat2_rsh = tf.reshape(mat2, [1, m2, 1, n2])\n  return tf.reshape(mat1_rsh * mat2_rsh, [m1 * m2, n1 * n2])\n\n\ndef expand_tensor(tensor, block_size):\n  """"""Expands a 2D tensor by replicating the tensor values.\n\n  This is equivalent to the kronecker product of the tensor and a matrix of\n  ones of size block_size.\n\n  Example:\n\n  tensor = [[1,2]\n            [3,4]]\n  block_size = [2,2]\n\n  result = [[1 1 2 2]\n            [1 1 2 2]\n            [3 3 4 4]\n            [3 3 4 4]]\n\n  Args:\n    tensor: A 2D tensor that needs to be expanded.\n    block_size: List of integers specifying the expansion factor.\n\n  Returns:\n    The expanded tensor\n\n  Raises:\n    ValueError: if tensor is not rank-2 or block_size is does not have 2\n    elements.\n  """"""\n  if tensor.get_shape().ndims != 2:\n    raise ValueError(\'Input tensor must be rank 2\')\n\n  if len(block_size) != 2:\n    raise ValueError(\'block_size must have 2 elements\')\n\n  block_height, block_width = block_size\n\n  def _tile_rows(tensor, multiple):\n    """"""Create a new tensor by tiling the tensor along rows.""""""\n    return tf.tile(tensor, [multiple, 1])\n\n  def _generate_indices(num_rows, block_dim):\n    indices = np.zeros(shape=[num_rows * block_dim, 1], dtype=np.int32)\n    for k in range(block_dim):\n      for r in range(num_rows):\n        indices[k * num_rows + r] = r * block_dim + k\n    return indices\n\n  def _replicate_rows(tensor, multiple):\n    tensor_shape = tensor.shape.as_list()\n    expanded_shape = [tensor_shape[0] * multiple, tensor_shape[1]]\n    indices = tf.constant(_generate_indices(tensor_shape[0], multiple))\n    return tf.scatter_nd(indices, _tile_rows(tensor, multiple), expanded_shape)\n\n  expanded_tensor = tensor\n\n  # Expand rows by factor block_height.\n  if block_height > 1:\n    expanded_tensor = _replicate_rows(tensor, block_height)\n\n  # Transpose and expand by factor block_width. Transpose the result.\n  if block_width > 1:\n    expanded_tensor = tf.transpose(\n        _replicate_rows(tf.transpose(expanded_tensor), block_width))\n\n  return expanded_tensor\n\n\ndef factorized_pool(input_tensor,\n                    window_shape,\n                    pooling_type,\n                    strides,\n                    padding,\n                    name=None):\n  """"""Performs m x n pooling through a combination of 1xm and 1xn pooling.\n\n  Args:\n    input_tensor: Input tensor. Must be rank 2\n    window_shape: Pooling window shape\n    pooling_type: Either \'MAX\' or \'AVG\'\n    strides: The stride of the pooling window\n    padding: \'SAME\' or \'VALID\'.\n    name: Name of the op\n\n  Returns:\n    A rank 2 tensor containing the pooled output\n\n  Raises:\n    ValueError: if the input tensor is not rank 2\n  """"""\n  if input_tensor.get_shape().ndims != 2:\n    raise ValueError(\'factorized_pool() accepts tensors of rank 2 only\')\n\n  [height, width] = input_tensor.get_shape()\n  if name is None:\n    name = \'factorized_pool\'\n  with tf.name_scope(name):\n    input_tensor_aligned = tf.reshape(input_tensor, [1, 1, height, width])\n\n    height_pooling = tf.nn.pool(\n        input_tensor_aligned,\n        window_shape=[1, window_shape[0]],\n        pooling_type=pooling_type,\n        strides=[1, strides[0]],\n        padding=padding)\n    swap_height_width = tf.transpose(height_pooling, perm=[0, 1, 3, 2])\n\n    width_pooling = tf.nn.pool(\n        swap_height_width,\n        window_shape=[1, window_shape[1]],\n        pooling_type=pooling_type,\n        strides=[1, strides[1]],\n        padding=padding)\n\n  return tf.squeeze(tf.transpose(width_pooling, perm=[0, 1, 3, 2]))\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_utils_test.py,10,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for utility functions in pruning_utils.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# import g3\nfrom absl.testing import parameterized\n\nimport tensorflow as tf\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_utils\n\nglorot_uniform_initializer = tf.keras.initializers.glorot_uniform\n\n\n@parameterized.named_parameters(\n    (""1x1"", [1, 1]), (""4x4"", [4, 4]), (""6x6"", [6, 6]), (""1x4"", [1, 4]),\n    (""4x1"", [4, 1]), (""1x8"", [1, 8]), (""8x1"", [8, 1]))\nclass PruningUtilsParameterizedTest(tf.test.TestCase, parameterized.TestCase):\n\n  def _compare_pooling_methods(self, weights, pooling_kwargs):\n    with self.cached_session():\n      compat.initialize_variables(self)\n      pooled_weights_tf = tf.squeeze(\n          tf.nn.pool(\n              tf.reshape(\n                  weights,\n                  [1, weights.get_shape()[0],\n                   weights.get_shape()[1], 1]), **pooling_kwargs))\n      pooled_weights_factorized_pool = pruning_utils.factorized_pool(\n          weights, **pooling_kwargs)\n      self.assertAllClose(self.evaluate(pooled_weights_tf),\n                          self.evaluate(pooled_weights_factorized_pool))\n\n  def _compare_expand_tensor_with_kronecker_product(self, tensor, block_dim):\n    with self.cached_session() as session:\n      compat.initialize_variables(self)\n      expanded_tensor = pruning_utils.expand_tensor(tensor, block_dim)\n      kronecker_product = pruning_utils.kronecker_product(\n          tensor, tf.ones(block_dim))\n      expanded_tensor_val, kronecker_product_val = session.run(\n          [expanded_tensor, kronecker_product])\n      self.assertAllEqual(expanded_tensor_val, kronecker_product_val)\n\n  def testFactorizedAvgPool(self, window_shape):\n    shape = [1024, 2048]\n    weights = tf.Variable(\n        glorot_uniform_initializer()(shape), shape=shape, name=""weights"")\n    pooling_kwargs = {\n        ""window_shape"": window_shape,\n        ""pooling_type"": ""AVG"",\n        ""strides"": window_shape,\n        ""padding"": ""SAME""\n    }\n    self._compare_pooling_methods(weights, pooling_kwargs)\n\n  def testFactorizedMaxPool(self, window_shape):\n    shape = [1024, 2048]\n    weights = tf.Variable(\n        glorot_uniform_initializer()(shape), shape=shape, name=""weights"")\n    pooling_kwargs = {\n        ""window_shape"": window_shape,\n        ""pooling_type"": ""MAX"",\n        ""strides"": window_shape,\n        ""padding"": ""SAME""\n    }\n    self._compare_pooling_methods(weights, pooling_kwargs)\n\n  def testExpandTensor(self, block_dim):\n    weights = tf.random.normal(shape=[1024, 512])\n    self._compare_expand_tensor_with_kronecker_product(weights, block_dim)\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py,17,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""A Keras wrapper to add pruning related variables to a layer.""""""\n\n# pylint: disable=missing-docstring,g-multiple-import,unused-import,protected-access\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport inspect\n# import g3\nimport numpy as np\nimport tensorflow as tf\n\n# b/(139939526): update to use public API.\nfrom tensorflow.python.keras.utils import generic_utils\nfrom tensorflow.python.keras.utils import tf_utils\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prunable_layer\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune_registry\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_impl\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule as pruning_sched\n\nkeras = tf.keras\nK = keras.backend\nWrapper = keras.layers.Wrapper\n\n\nclass PruneLowMagnitude(Wrapper):\n  """"""This wrapper augments a keras layer so the weight tensor may be pruned.\n\n  This wrapper implements magnitude-based pruning of the weight tensors.\n  Magnitude-based pruning achieves a target sparsity (s% of zeros) for a given\n  weight tensor by monitoring the distribution of the absolute values of the\n  weight tensor and determining the weight value (referred to as threshold)\n  below which s% of elements lie. For every weight tensor being pruned, the\n  wrapper maintains an identically shaped tensor (referred to as mask) which\n  stores 0 if the weight value lies below the threshold.\n  The mask and thresholds are computed during the training based on the\n  evolution of the weight values.\n\n  Block sparse patterns:\n  For certain SIMD hardware architectures, it may be beneficial to induce\n  spatially correlated sparsity. To train models in which the weight tensors\n  have block sparse structure, the pruning wrapper can be configured with\n  the block_height and block_width configuration parameters set to the desired\n  block configuration (2x2, 4x4, 4x1, 1x8, etc). This is applicable to\n  rank-2 weight tensor only and the tensor partitioned into non-overlapping\n  blocks of size [block_height, block_dim]. Either the average or max absolute\n  value in this block is taken as a proxy for the entire block\n  (set by block_pooling_function configuration parameter)\n  while computing the distribution of the weight values and\n  the threshold for pruning.\n\n  Custom keras layers:\n  The pruning wrapper can also be applied to a user-defined keras layer.\n  Such a layer may contain one or more weight tensors that may be pruned.\n  To apply pruning wrapper to such layers, set prunable_weight_names to mark\n  the weight tensors for pruning.\n\n  Sparsity function:\n  The target sparsity for the weight tensors are set through the\n  pruning_schedule parameter of the pruning wrapper. The user must create a\n  python callable that returns a scalar tensorflow tensor and pass this\n  callable to the sparsity_function parameter. This scalar tensor contains the\n  target sparsity value for the weight tensors in the layer.\n  The wrapper provides the following pre-built sparsity functions:\n\n  ConstantSparsity\n  GradualSparsity\n\n  Eg.\n  params = PruningParams(frequency=10,pruning_schedule=ConstantSparsity(0.9))\n  pruned_model = keras.model.Sequential()\n  pruned_model.add(\n      Prune(keras.layers.Dense(256), input_shape=(256,)))\n  pruned_model.add(Prune(keras.layers.Dense(1024), params=params))\n\n  """"""\n\n  _PRUNE_CALLBACK_ERROR_MSG = (\n      \'Prune() wrapper requires the UpdatePruningStep callback to be provided \'\n      \'during training. Please add it as a callback to your model.fit call.\')\n\n  def __init__(self,\n               layer,\n               pruning_schedule=pruning_sched.ConstantSparsity(0.5, 0),\n               block_size=(1, 1),\n               block_pooling_type=\'AVG\',\n               **kwargs):\n    """"""Create a pruning wrapper for a keras layer.\n\n    #TODO(pulkitb): Consider if begin_step should be 0 by default.\n\n    Args:\n      layer: The keras layer to be pruned.\n      pruning_schedule: A `PruningSchedule` object that controls pruning rate\n        throughout training.\n      block_size: (optional) The dimensions (height, weight) for the block\n        sparse pattern in rank-2 weight tensors.\n      block_pooling_type: (optional) The function to use to pool weights in the\n        block. Must be \'AVG\' or \'MAX\'.\n      **kwargs: Additional keyword arguments to be passed to the keras layer.\n    """"""\n    self.pruning_schedule = pruning_schedule\n    self.block_size = block_size\n    self.block_pooling_type = block_pooling_type\n\n    # An instance of the Pruning class. This class contains the logic to prune\n    # the weights of this layer.\n    self.pruning_obj = None\n\n    # A list of all (weight,mask,threshold) tuples for this layer\n    self.pruning_vars = []\n\n    if block_pooling_type not in [\'AVG\', \'MAX\']:\n      raise ValueError(\n          \'Unsupported pooling type \\\'{}\\\'. Should be \\\'AVG\\\' or \\\'MAX\\\'.\'\n          .format(block_pooling_type))\n\n    if not isinstance(layer, tf.keras.layers.Layer):\n      raise ValueError(\n          \'Please initialize `Prune` layer with a \'\n          \'`Layer` instance. You passed: {input}\'.format(input=layer))\n\n    # TODO(pulkitb): This should be pushed up to the wrappers.py\n    # Name the layer using the wrapper and underlying layer name.\n    # Prune(Dense) becomes prune_dense_1\n    kwargs.update({\'name\': \'{}_{}\'.format(\n        generic_utils.to_snake_case(self.__class__.__name__), layer.name)})\n\n    if isinstance(layer, prunable_layer.PrunableLayer):\n      # Custom layer in client code which supports pruning.\n      super(PruneLowMagnitude, self).__init__(layer, **kwargs)\n    elif prune_registry.PruneRegistry.supports(layer):\n      # Built-in keras layers which support pruning.\n      super(PruneLowMagnitude, self).__init__(\n          prune_registry.PruneRegistry.make_prunable(layer), **kwargs)\n    else:\n      raise ValueError(\n          \'Please initialize `Prune` with a supported layer. Layers should \'\n          \'either be a `PrunableLayer` instance, or should be supported by the \'\n          \'PruneRegistry. You passed: {input}\'.format(input=layer.__class__))\n\n    self._track_trackable(layer, name=\'layer\')\n\n    # TODO(yunluli): Work-around to handle the first layer of Sequential model\n    # properly. Can remove this when it is implemented in the Wrapper base\n    # class.\n    #\n    # Enables end-user to prune the first layer in Sequential models, while\n    # passing the input shape to the original layer.\n    #\n    # tf.keras.Sequential(\n    #   prune_low_magnitude(tf.keras.layers.Dense(2, input_shape=(3,)))\n    # )\n    #\n    # as opposed to\n    #\n    # tf.keras.Sequential(\n    #   prune_low_magnitude(tf.keras.layers.Dense(2), input_shape=(3,))\n    # )\n    #\n    # Without this code, the pruning wrapper doesn\'t have an input\n    # shape and being the first layer, this causes the model to not be\n    # built. Being not built is confusing since the end-user has passed an\n    # input shape.\n    if not hasattr(self, \'_batch_input_shape\') and hasattr(\n        layer, \'_batch_input_shape\'):\n      self._batch_input_shape = self.layer._batch_input_shape\n\n  def build(self, input_shape):\n    super(PruneLowMagnitude, self).build(input_shape)\n\n    weight_vars, mask_vars, threshold_vars = [], [], []\n\n    self.prunable_weights = self.layer.get_prunable_weights()\n\n    # For each of the prunable weights, add mask and threshold variables\n    for weight in self.prunable_weights:\n      mask = self.add_variable(\n          \'mask\',\n          shape=weight.shape,\n          initializer=tf.keras.initializers.get(\'ones\'),\n          dtype=weight.dtype,\n          trainable=False,\n          aggregation=tf.VariableAggregation.MEAN)\n      threshold = self.add_variable(\n          \'threshold\',\n          shape=[],\n          initializer=tf.keras.initializers.get(\'zeros\'),\n          dtype=weight.dtype,\n          trainable=False,\n          aggregation=tf.VariableAggregation.MEAN)\n\n      weight_vars.append(weight)\n      mask_vars.append(mask)\n      threshold_vars.append(threshold)\n    self.pruning_vars = list(zip(weight_vars, mask_vars, threshold_vars))\n\n    # Add a scalar tracking the number of updates to the wrapped layer.\n    self.pruning_step = self.add_variable(\n        \'pruning_step\',\n        shape=[],\n        initializer=tf.keras.initializers.Constant(-1),\n        dtype=tf.int64,\n        trainable=False)\n\n    def training_step_fn():\n      return self.pruning_step\n\n    # Create a pruning object\n    self.pruning_obj = pruning_impl.Pruning(\n        training_step_fn=training_step_fn,\n        pruning_vars=self.pruning_vars,\n        pruning_schedule=self.pruning_schedule,\n        block_size=self.block_size,\n        block_pooling_type=self.block_pooling_type)\n\n  def call(self, inputs, training=None):\n    if training is None:\n      training = K.learning_phase()\n\n    def add_update():\n      with tf.control_dependencies([\n          tf.debugging.assert_greater_equal(\n              self.pruning_step,\n              np.int64(0),\n              message=self._PRUNE_CALLBACK_ERROR_MSG)\n      ]):\n        with tf.control_dependencies(\n            [self.pruning_obj.conditional_mask_update()]):\n          return tf.no_op(\'update\')\n\n    def no_op():\n      return tf.no_op(\'no_update\')\n\n    update_op = tf_utils.smart_cond(training, add_update, no_op)\n    self.add_update(update_op)\n    # Always execute the op that performs weights = weights * mask\n    # Relies on UpdatePruningStep callback to ensure the weights\n    # are sparse after the final backpropagation.\n    #\n    # self.add_update does nothing during eager execution.\n    self.add_update(self.pruning_obj.weight_mask_op())\n    # TODO(evcu) remove this check after dropping py2 support. In py3 getargspec\n    # is deprecated.\n    if hasattr(inspect, \'getfullargspec\'):\n      args = inspect.getfullargspec(self.layer.call).args\n    else:\n      args = inspect.getargspec(self.layer.call).args\n    # Propagate the training bool to the underlying layer if it accepts\n    # training as an arg.\n    if \'training\' in args:\n      return self.layer.call(inputs, training=training)\n\n    return self.layer.call(inputs)\n\n  def compute_output_shape(self, input_shape):\n    return self.layer.compute_output_shape(input_shape)\n\n  def get_config(self):\n    base_config = super(PruneLowMagnitude, self).get_config()\n    config = {\n        \'pruning_schedule\': self.pruning_schedule.get_config(),\n        \'block_size\': self.block_size,\n        \'block_pooling_type\': self.block_pooling_type\n    }\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    config = config.copy()\n\n    pruning_schedule = config.pop(\'pruning_schedule\')\n    deserialize_keras_object = keras.utils.deserialize_keras_object  # pylint: disable=g-import-not-at-top\n    # TODO(pulkitb): This should ideally be fetched from pruning_schedule,\n    # which should maintain a list of all the pruning_schedules.\n    custom_objects = {\n        \'ConstantSparsity\': pruning_sched.ConstantSparsity,\n        \'PolynomialDecay\': pruning_sched.PolynomialDecay\n    }\n    config[\'pruning_schedule\'] = deserialize_keras_object(\n        pruning_schedule,\n        module_objects=globals(),\n        custom_objects=custom_objects)\n\n    from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top\n    layer = deserialize_layer(config.pop(\'layer\'))\n    config[\'layer\'] = layer\n\n    return cls(**config)\n\n  @property\n  def trainable(self):\n    return self.layer.trainable\n\n  @trainable.setter\n  def trainable(self, value):\n    self.layer.trainable = value\n\n  @property\n  def trainable_weights(self):\n    return self.layer.trainable_weights\n\n  @property\n  def non_trainable_weights(self):\n    return self.layer.non_trainable_weights + self._non_trainable_weights\n\n  @property\n  def updates(self):\n    return self.layer.updates + self._updates\n\n  @property\n  def losses(self):\n    return self.layer.losses + self._losses\n\n  def get_weights(self):\n    return self.layer.get_weights()\n\n  def set_weights(self, weights):\n    self.layer.set_weights(weights)\n'"
tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for keras pruning wrapper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\nkeras = tf.keras\nlayers = keras.layers\nPrune = pruning_wrapper.PruneLowMagnitude\n\n\nclass PruningWrapperTest(tf.test.TestCase):\n\n  def setUp(self):\n    self.model = keras.Sequential()\n    self.params = {\n        \'pruning_schedule\': pruning_schedule.ConstantSparsity(0.5, 0),\n        \'block_size\': (1, 1),\n        \'block_pooling_type\': \'AVG\'\n    }\n\n  def testPruneWrapperAllowsOnlyValidPoolingType(self):\n    layer = layers.Dense(10)\n    with self.assertRaises(ValueError):\n      pruning_wrapper.PruneLowMagnitude(layer, block_pooling_type=\'MIN\')\n\n    pruning_wrapper.PruneLowMagnitude(layer, block_pooling_type=\'AVG\')\n    pruning_wrapper.PruneLowMagnitude(layer, block_pooling_type=\'MAX\')\n\n  def _check_mask_count(self, expected_mask_count=0):\n    mask_count = 0\n    for l in self.model.layers:\n      mask_count += len(l.pruning_vars)\n    self.assertEqual(mask_count, expected_mask_count)\n\n  # TODO(suyoggupta): Randomize the layer dimensions\n  def testDense(self):\n    self.model.add(Prune(layers.Dense(10), **self.params))\n    self.model.build(input_shape=(10, 1))\n\n    self._check_mask_count(expected_mask_count=1)\n\n  def testEmbedding(self):\n    self.model.add(\n        Prune(\n            layers.Embedding(10, 10),\n            input_shape=(10,),\n            **self.params))\n    self.model.build(input_shape=(10, 1))\n\n    self._check_mask_count(expected_mask_count=1)\n\n  def testConv2D(self):\n    self.model.add(Prune(layers.Conv2D(4, (3, 3)), **self.params))\n    self.model.build(input_shape=(1, 16, 16, 4))\n\n    self._check_mask_count(expected_mask_count=1)\n\n  def testPruneModel(self):\n    self.model.add(Prune(layers.Conv2D(32, 5)))\n    self.model.add(\n        Prune(layers.MaxPooling2D((2, 2), (2, 2))))\n    self.model.add(Prune(layers.Conv2D(64, 5)))\n    self.model.add(\n        Prune(layers.MaxPooling2D((2, 2), (2, 2))))\n    self.model.add(Prune(layers.Flatten()))\n    self.model.add(Prune(layers.Dense(1024)))\n    self.model.add(Prune(layers.Dropout(0.4)))\n    self.model.add(Prune(layers.Dense(10)))\n    self.model.build(input_shape=(1, 28, 28, 1))\n\n    self._check_mask_count(expected_mask_count=4)\n\n    # Test serialization\n    model_config = self.model.get_config()\n    self.assertEqual(\n        model_config,\n        self.model.__class__.from_config(\n            model_config,\n            custom_objects={\n                \'PruneLowMagnitude\': pruning_wrapper.PruneLowMagnitude\n            }).get_config())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/sparsity/keras/test_utils.py,5,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Test utility to generate models for testing.""""""\n\nimport tempfile\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\nkeras = tf.keras\nl = keras.layers\n\n\ndef _build_mnist_layer_list():\n  return [\n      l.Conv2D(\n          32, 5, padding=\'same\', activation=\'relu\', input_shape=(28, 28, 1)),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.BatchNormalization(),\n      l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      l.Dense(1024, activation=\'relu\'),\n      l.Dropout(0.4),\n      l.Dense(10, activation=\'softmax\')\n  ]\n\n\ndef _build_mnist_sequential_model():\n  return keras.Sequential(_build_mnist_layer_list())\n\n\ndef _build_mnist_functional_model():\n  # pylint: disable=missing-docstring\n  inp = keras.Input(shape=(28, 28, 1))\n  x = l.Conv2D(32, 5, padding=\'same\', activation=\'relu\')(inp)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.BatchNormalization()(x)\n  x = l.Conv2D(64, 5, padding=\'same\', activation=\'relu\')(x)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.Flatten()(x)\n  x = l.Dense(1024, activation=\'relu\')(x)\n  x = l.Dropout(0.4)(x)\n  out = l.Dense(10, activation=\'softmax\')(x)\n\n  return keras.models.Model([inp], [out])\n\n\ndef _build_mnist_layerwise_pruned_model(pruning_params):\n  if pruning_params is None:\n    raise ValueError(\'pruning_params should be provided.\')\n\n  return keras.Sequential([\n      prune.prune_low_magnitude(\n          l.Conv2D(32, 5, padding=\'same\', activation=\'relu\'),\n          input_shape=(28, 28, 1),\n          **pruning_params),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.BatchNormalization(),\n      prune.prune_low_magnitude(\n          l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'), **pruning_params),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      prune.prune_low_magnitude(\n          l.Dense(1024, activation=\'relu\'), **pruning_params),\n      l.Dropout(0.4),\n      prune.prune_low_magnitude(\n          l.Dense(10, activation=\'softmax\'), **pruning_params)\n  ])\n\n\ndef build_mnist_model(model_type, pruning_params=None):\n  return {\n      \'sequential\': _build_mnist_sequential_model(),\n      \'functional\': _build_mnist_functional_model(),\n      \'layer_list\': _build_mnist_layer_list(),\n      \'layer_wise\': _build_mnist_layerwise_pruned_model(pruning_params),\n  }[model_type]\n\n\ndef model_type_keys():\n  return [\'sequential\', \'functional\', \'layer_list\', \'layer_wise\']\n\n\ndef list_to_named_parameters(param_name, options):\n  """"""Convert list of options for parameter to input to @parameterized.named_parameters.\n\n  Arguments:\n    param_name: name of parameter\n    options: list of options for parameter\n\n  Returns:\n    named_params: input to @parameterized.named_parameters\n\n  Needed to stack multiple parameters (e.g. with keras run_all_modes).\n  """"""\n\n  def snakecase_to_camelcase(value):\n    # Non-comprensive check for camelcase already.\n    if value[0].isupper() and \'_\' not in value:\n      return value\n\n    camelcase = \'\'\n    for s in value.split(\'_\'):\n      camelcase += s.capitalize()\n    return camelcase\n\n  def name(s):\n    if isinstance(s, str):\n      return s\n\n    return s.__name__\n\n  named_params = []\n  for key in options:\n    named_params.append({\n        \'testcase_name\': snakecase_to_camelcase(name(key)),\n        param_name: key\n    })\n  return named_params\n\n\ndef _save_restore_keras_model(model):\n  _, keras_file = tempfile.mkstemp(\'.h5\')\n  keras.models.save_model(model, keras_file)\n\n  with prune.prune_scope():\n    loaded_model = keras.models.load_model(keras_file)\n\n  return loaded_model\n\n\ndef _save_restore_tf_model(model):\n  tmpdir = tempfile.mkdtemp()\n  tf.keras.models.save_model(model, tmpdir, save_format=\'tf\')\n  with prune.prune_scope():\n    loaded_model = tf.keras.models.load_model(tmpdir)\n  return loaded_model\n\n\ndef save_restore_fns():\n  return [_save_restore_keras_model, _save_restore_tf_model]\n\n\n# Assertion/Sparsity Verification functions.\n\n\ndef _get_sparsity(weights):\n  return 1.0 - np.count_nonzero(weights) / float(weights.size)\n\n\ndef assert_model_sparsity(test_case, sparsity, model, rtol=1e-6, atol=1e-6):\n  for layer in model.layers:\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      for weight in layer.layer.get_prunable_weights():\n        test_case.assertAllClose(\n            sparsity, _get_sparsity(tf.keras.backend.get_value(weight)), rtol=rtol, atol=atol)\n\n\n# Check if model does not have target sparsity.\ndef is_model_sparsity_not(sparsity, model):\n  for layer in model.layers:\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      for weight in layer.layer.get_prunable_weights():\n        if sparsity != _get_sparsity(tf.keras.backend.get_value(weight)):\n          return True\n  return False\n'"
tensorflow_model_optimization/python/examples/quantization/keras/__init__.py,0,b''
tensorflow_model_optimization/python/examples/quantization/keras/mnist_cnn.py,12,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Train a simple convnet on the MNIST dataset.\n\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf  # pylint: disable=g-bad-import-order\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nif tf.keras.backend.image_data_format() == \'channels_first\':\n  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n  input_shape = (1, img_rows, img_cols)\nelse:\n  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n  input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# convert class vectors to binary class matrices\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\nl = tf.keras.layers\n\nmodel = tf.keras.Sequential([\n    quantize.quantize_annotate_layer(\n        l.Conv2D(32, 5, padding=\'same\', activation=\'relu\'),\n        input_shape=input_shape),\n    l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n    quantize.quantize_annotate_layer(\n        l.Conv2D(64, 5, padding=\'same\', activation=\'relu\')),\n    l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n    l.Flatten(),\n    quantize.quantize_annotate_layer(l.Dense(1024, activation=\'relu\')),\n    l.Dropout(0.4),\n    quantize.quantize_annotate_layer(l.Dense(num_classes)),\n    # TODO(alanchiao): fuse softmax once we\'ve handled it.\n    l.Softmax(),\n])\n\nmodel = quantize.quantize_apply(model)\n\n# Dump graph to /tmp for verification on tensorboard.\ngraph_def = tf.get_default_graph().as_graph_def()\nwith open(\'/tmp/mnist_model.pbtxt\', \'w\') as f:\n  f.write(str(graph_def))\n\nmodel.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=tf.keras.optimizers.Adadelta(),\n    metrics=[\'accuracy\'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n\n# Export to Keras.\nkeras_file = \'/tmp/quantized_mnist.h5\'\ntf.keras.models.save_model(model, keras_file)\n\n# Convert to TFLite model.\nwith quantize.quantize_scope():\n  converter = tf.lite.TFLiteConverter.from_keras_model_file(\n      keras_file)\nconverter.inference_type = tf.lite.constants.QUANTIZED_UINT8\ninput_arrays = converter.get_input_arrays()\nconverter.quantized_input_stats = {input_arrays[0]: (0., 255.)}  # mean, std_dev\ntflite_model = converter.convert()\nopen(\'/tmp/quantized_mnist.tflite\', \'wb\').write(tflite_model)\n'"
tensorflow_model_optimization/python/examples/quantization/keras/mnist_cnn_cont_quant.py,17,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Train a simple convnet on the MNISt dataset.\n\nOnly the first layer has quantization annotation and quantized trained. A\nrepresentative dataset is set to invoke the post-training quantization as well.\nThe model should be fully quantized at the end.\n""""""\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport tensorflow as tf  # pylint: disable=g-bad-import-order\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nif tf.keras.backend.image_data_format() == \'channels_first\':\n  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n  input_shape = (1, img_rows, img_cols)\nelse:\n  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n  input_shape = (img_rows, img_cols, 1)\n\nbatch_input_shape = (1,) + input_shape\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\nprint(\'x_train shape:\', x_train.shape)\nprint(x_train.shape[0], \'train samples\')\nprint(x_test.shape[0], \'test samples\')\n\n# convert class vectors to binary class matrices\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\nl = tf.keras.layers\n\nkeras_file = \'/tmp/quantized_mnist.h5\'\nif not os.path.exists(keras_file):\n  model = tf.keras.Sequential([\n      # Only the fisrt layer is quantized trained.\n      # The rest of the layers are not quantization-aware.\n      quantize.quantize_annotate_layer(\n          l.Conv2D(\n              32, 5, padding=\'same\', activation=\'relu\',\n              input_shape=input_shape)),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'),\n      l.BatchNormalization(),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      l.Dense(1024, activation=\'relu\'),\n      l.Dropout(0.4),\n      l.Dense(num_classes),\n      l.Softmax(),\n  ])\n  model = quantize.quantize_apply(model)\n  model.compile(\n      loss=tf.keras.losses.categorical_crossentropy,\n      optimizer=tf.keras.optimizers.Adadelta(),\n      metrics=[\'accuracy\'])\n\n  model.fit(\n      x_train,\n      y_train,\n      batch_size=batch_size,\n      epochs=epochs,\n      verbose=1,\n      validation_data=(x_test, y_test))\n\n  # Export to Keras.\n  tf.keras.models.save_model(model, keras_file)\n\nwith quantize.quantize_scope():\n  model = tf.keras.models.load_model(keras_file)\n\nscore = model.evaluate(x_test, y_test, verbose=1)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n\n\n# Use the first 300 images in the post-training quantization.\ndef calibration_gen():\n  for i in range(300):\n    image = x_train[i].reshape(batch_input_shape)\n    yield [image]\n\n# Convert to TFLite model.\nwith quantize.quantize_scope():\n  # It is complex to set the flags with converter v1:\n  #\n  #  converter = tf.lite.TFLiteConverter.from_keras_model_file(\n  #      keras_file, input_shapes={\'quant_conv2d_input\': batch_input_shape})\n  #\n  # Must set the inference_input_type to float, so we can still use the floating\n  # point training data. Set the inference_type to int8, to partially quantize\n  # the model.\n  # converter.inference_type = tf.lite.constants.INT8\n  # converter.inference_input_type = tf.lite.constants.FLOAT\n  # input_arrays = converter.get_input_arrays()\n  # print(input_arrays)\n  # converter.quantized_input_stats = {\n  #     input_arrays[0]: (-128., 255.)\n  # }  # mean, std_dev values for float [0, 1] quantized to [-128, 127]\n  # Set the representative dataset for post-training quantization.\n\n  model = tf.keras.models.load_model(keras_file)\n  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n\nconverter.representative_dataset = calibration_gen\nconverter._experimental_new_quantizer = True  # pylint: disable=protected-access\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n]  # to enable post-training quantization with the representative dataset\n\nprint(\'Convert TFLite model.\')\ntflite_model = converter.convert()\nprint(\'Write TFLite model.\')\ntflite_file = \'/tmp/quantized_mnist.tflite\'\nopen(tflite_file, \'wb\').write(tflite_model)\n\n# Evaluate the fully quantized model.\ninterpreter = tf.lite.Interpreter(model_path=tflite_file)\ninterpreter.allocate_tensors()\ninput_index = interpreter.get_input_details()[0][\'index\']\noutput_index = interpreter.get_output_details()[0][\'index\']\n\ntotal_seen = 0\nnum_correct = 0\n\n# Testing the entire dataset is too slow. Verifying only 300 of 10k samples.\nprint(\'Evaluate TFLite model.\')\nx_test = x_test[0:300, :]\ny_test = y_test[0:300, :]\nfor img, label in zip(x_test, y_test):\n  inp = img.reshape(batch_input_shape)\n  total_seen += 1\n  interpreter.set_tensor(input_index, inp)\n  interpreter.invoke()\n  predictions = interpreter.get_tensor(output_index)\n  if np.argmax(predictions) == np.argmax(label):\n    num_correct += 1\n\nquantized_score = float(num_correct) / float(total_seen)\nprint(\'Quantized accuracy:\', quantized_score)\n\n# Ensure accuracy for quantized TF and TFLite models are similar to original\n# model. There is no clear way to measure quantization, but for MNIST\n# results which differ a lot likely suggest an error in quantization.\nnp.testing.assert_allclose(score[1], quantized_score, rtol=0.2, atol=0.2)\n\n'"
tensorflow_model_optimization/python/core/api/quantization/keras/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Module containing quantization code built on Keras abstractions.""""""\n# pylint: disable=g-bad-import-order\n\n# submodules\nfrom tensorflow_model_optimization.python.core.api.quantization.keras import quantizers\n\n# quantize all layers with default quantization implementation.\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_model\n\n# quantize some layers with default or custom quantization implementation.\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_annotate_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_annotate_model\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_apply\n\n# quantize with custom quantization parameterization or implementation, or\n# handle custom Keras layers.\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize_config import QuantizeConfig\n\n# Deserialize quantized model for Keras h5 format.\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_scope\n\n# pylint: enable=g-bad-import-order\n'"
tensorflow_model_optimization/python/core/api/sparsity/keras/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Module containing sparsity code built on Keras abstractions.""""""\n# pylint: disable=wildcard-import\nfrom tensorflow_model_optimization.python.core.sparsity.keras.prunable_layer import PrunableLayer\nfrom tensorflow_model_optimization.python.core.sparsity.keras.prune import *\nfrom tensorflow_model_optimization.python.core.sparsity.keras.pruning_callbacks import *\nfrom tensorflow_model_optimization.python.core.sparsity.keras.pruning_schedule import *\n# pylint: enable=wildcard-import\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Core parts of the `tensor_encoding` package.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.core_encoder import Encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.core_encoder import EncoderComposer\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.encoding_stage import AdaptiveEncodingStageInterface\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.encoding_stage import EncodingStageInterface\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.encoding_stage import StateAggregationMode\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.encoding_stage import tf_style_adaptive_encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.encoding_stage import tf_style_encoding_stage\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.gather_encoder import GatherEncoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core.simple_encoder import SimpleEncoder\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/core_encoder.py,25,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Class responsible for composing individual encoding stages.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\n\n# OrderedEnum necessary for compatibility with tf.nest.\nclass EncoderKeys(py_utils.OrderedEnum):\n  """"""Constants for keys in nested structures in the `Encoder` class.""""""\n  CHILDREN = 1\n  PARAMS = 2\n  SHAPE = 3\n  STATE = 4\n  TENSORS = 5\n  COMMUTE = 6\n\n\nclass Encoder(object):\n  """"""Class for composing individual encoding stages.\n\n  This class provides functionality for arbitrarily composing individual\n  encoding stages (implementations of `EncodingStageInterface` or\n  `AdaptiveEncodingStageInterface`) into a tree, where an output `Tensor` of an\n  encoding stage can be further encoded by another encoding stage.\n\n  The interface is similar to that of `AdaptiveEncodingStageInterface`, with the\n  additional methods `decode_before_sum` and `decode_after_sum`. These methods\n  split the decoding functionality to two parts, based on commutativity with\n  summation.\n\n  Similar to the `AdaptiveEncodingStageInterface`, the methods are designed to\n  be functional transformations. That means, for instance, that the\n  `initial_state` and `update_state` methods do not modify any underlying state.\n  Rather, the user of the `Encoder` class is responsible for storing any values\n  if necessary, and providing them back to appropriate methods of this class.\n  """"""\n\n  def __init__(self, stage, children):\n    """"""Constructor of the `Encoder`.\n\n    If `stage` is an `EncodingStageInterface`, the constructor will wrap it as\n    an `AdaptiveEncodingStageInterface` with no state.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`.\n      children: A dictionary mapping a subset of\n        `stage.compressible_tensors_keys` to instances of `Encoder` objects,\n        which are to be used to further encode the corresponding encoded tensors\n        of `stage`.\n    """"""\n    stage = encoding_stage.as_adaptive_encoding_stage(stage)\n    self.stage = stage\n    self.children = children\n    self._commuting_structure = None\n    super(Encoder, self).__init__()\n\n  @property\n  def fully_commutes_with_sum(self):\n    """"""`True/False` based on whether the `Encoder` commutes with sum.\n\n    This property will return `True` iff the entire composition of encoding\n    stages controlled by this object commutes with sum. That is, the stage\n    wrapped by this object commutes with sum, and each of its children also\n    `fully_commutes_with_sum`.\n\n    Returns:\n      A boolean, `True` iff the `Encoder` commutes with sum.\n    """"""\n    result = True\n    for encoder in six.itervalues(self.children):\n      result &= encoder.fully_commutes_with_sum\n    return result & self.stage.commutes_with_sum\n\n  @property\n  def commuting_structure(self):\n    """"""Represents the structure of the `Encoder` which commutes with sum.\n\n    Returns:\n      A dictionary with two keys: `EncoderKeys.COMMUTE` and\n      `EncoderKeys.CHILDREN`. The `EncoderKeys.COMMUTE` key maps to `True` or\n      `False`, based on whether the encoding stage controlled by this class\n      comutes with sum. The `EncoderKeys.CHILDREN` key maps to a dictionary with\n      the same keys as `self.children`, each of which maps to an object like\n      this one, recursively.\n    """"""\n    if not self._commuting_structure:\n      self._commuting_structure = self._commuting_structure_impl(True)\n    return self._commuting_structure\n\n  def _commuting_structure_impl(self, previous):\n    """"""Implementation for the `commuting_structure` property.""""""\n    current = previous & self.stage.commutes_with_sum\n    commuting_structure = {\n        EncoderKeys.COMMUTE: current,\n        EncoderKeys.CHILDREN: {}\n    }\n    for key, encoder in six.iteritems(self.children):\n      commuting_structure[EncoderKeys.CHILDREN][key] = (\n          encoder._commuting_structure_impl(current))  # pylint: disable=protected-access\n    return commuting_structure\n\n  @property\n  def state_update_aggregation_modes(self):\n    """"""State aggregation modes of the Encoder.\n\n    Returns:\n      An object of the same structure as `state_update_tensors` returned by the\n      `encode` method, with values replaced by their corresponding\n      `StateAggregationMode` keys.\n    """"""\n    children_aggregation_modes = {}\n    for key, encoder in six.iteritems(self.children):\n      children_aggregation_modes[key] = encoder.state_update_aggregation_modes\n    return {\n        EncoderKeys.CHILDREN: children_aggregation_modes,\n        EncoderKeys.TENSORS: self.stage.state_update_aggregation_modes\n    }\n\n  def initial_state(self, name=None):\n    """"""Creates an initial state for the Encoder.\n\n    Args:\n      name: `string`, name of the operation.\n\n    Returns:\n      A dictionary with two keys: `EncoderKeys.STATE` and\n      `EncoderKeys.CHILDREN`. The `EncoderKeys.STATE` key maps to a dictionary\n      containing the initial state of the encoding stage controlled by this\n      class. The `EncoderKeys.CHILDREN` key maps to a dictionary with the same\n      keys as `self.children`, each of which maps to an object like this one,\n      recursively.\n    """"""\n    with tf.compat.v1.name_scope(name, \'encoder_initial_state\'):\n      return self._initial_state_impl()\n\n  def _initial_state_impl(self):\n    """"""Implementation for the `initial_state` method.""""""\n    children_state = {}\n    for key, encoder in six.iteritems(self.children):\n      with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n        children_state[key] = encoder._initial_state_impl()  # pylint: disable=protected-access\n    return {\n        EncoderKeys.STATE: self.stage.initial_state(),\n        EncoderKeys.CHILDREN: children_state\n    }\n\n  def update_state(self, state, state_update_tensors, name=None):\n    """"""Updates the state of the Encoder.\n\n    Args:\n      state: A dictionary of the same structure as returned by the\n        `initial_state` method, representing the current state.\n      state_update_tensors: A dictionary of the same structure as returned by\n        the `encode` method, representing the tensors needed for updating the\n        state. The values are possibly aggregated across multiple realizations\n        of the encoding.\n      name: `string`, name of the operation.\n\n    Returns:\n      A dictionary with two keys: `EncoderKeys.STATE` and\n      `EncoderKeys.CHILDREN`. The `EncoderKeys.STATE` key maps to a dictionary\n      containing the initial state of the encoding stage controlled by this\n      class. The `EncoderKeys.CHILDREN` key maps to a dictionary with the same\n      keys as `self.children`, each of which maps to an object like this one,\n      recursively.\n    """"""\n    values = tf.nest.flatten(state) + tf.nest.flatten(state_update_tensors)\n    with tf.compat.v1.name_scope(name, \'encoder_update_state\', values):\n      return self._update_state_impl(state, state_update_tensors)\n\n  def _update_state_impl(self, state, state_update_tensors):\n    """"""Implementation for the `update_state` method.""""""\n    children_states = {}\n    for key, encoder in six.iteritems(self.children):\n      with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n        children_states[key] = encoder._update_state_impl(  # pylint: disable=protected-access\n            state[EncoderKeys.CHILDREN][key],\n            state_update_tensors[EncoderKeys.CHILDREN][key])\n    return {\n        EncoderKeys.CHILDREN:\n            children_states,\n        EncoderKeys.STATE:\n            self.stage.update_state(state[EncoderKeys.STATE],\n                                    state_update_tensors[EncoderKeys.TENSORS])\n    }\n\n  def get_params(self, state, name=None):\n    """"""Gets parameters controlling the behavior of the Encoder.\n\n    Args:\n      state: A dictionary of the same structure as returned by the\n        `initial_state` and `update_state` methods.\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple `(encode_params, decode_params)`, where these are the parameters\n      expected by the `encode` and `decode` methods, respectively. Both of them\n      are dictionaries with two keys: `EncoderKeys.PARAMS` and\n      `EncoderKeys.CHILDREN`. The `EncoderKeys.PARAMS` key maps to a dictionary\n      containing the parameters of the encoding stage controlled by this class.\n      The `EncoderKeys.CHILDREN` key maps to a dictionary with the same keys as\n      `self.children`, each of which maps to an object like this one,\n      recursively.\n    """"""\n    with tf.compat.v1.name_scope(name, \'encoder_get_params\',\n                                 tf.nest.flatten(state)):\n      return self._get_params_impl(state)\n\n  def _get_params_impl(self, state):\n    """"""Implementation for the `get_params` method.""""""\n    encode_params = {}\n    decode_params = {}\n    encode_params[EncoderKeys.PARAMS], decode_params[EncoderKeys.PARAMS] = (\n        self.stage.get_params(state[EncoderKeys.STATE]))\n    children_encode_params = {}\n    children_decode_params = {}\n    for key, encoder in six.iteritems(self.children):\n      with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n        children_encode_params[key], children_decode_params[key] = (\n            encoder._get_params_impl(state[EncoderKeys.CHILDREN][key]))  # pylint: disable=protected-access\n    encode_params[EncoderKeys.CHILDREN] = children_encode_params\n    decode_params[EncoderKeys.CHILDREN] = children_decode_params\n    return encode_params, decode_params\n\n  def encode(self, x, encode_params, name=None):\n    """"""Encodes a given `Tensor`.\n\n    Args:\n      x: A `Tensor`, input to be encoded.\n      encode_params: A dictionary, containing the parameters needed for the\n        encoding. The structure needs to be the return structure of the\n        `get_params` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple `(encoded_tensors, state_update_tensors, input_shapes)`, where\n      these are:\n      `encoded_tensors`: A dictionary of `Tensor` objects representing the\n        encoded input `x`.\n      `state_update_tensors`: A dictionary of `Tensor` objects representing\n        information necessary for updating the state. The dictionary has two\n        keys: `EncoderKeys.TENSORS` and `EncoderKeys.CHILDREN`. The\n        `EncoderKeys.TENSORS` key maps to the state_update_tensors produced by\n        `self.stage`. The `EncoderKeys.CHILDREN` key maps to a dictionary with\n        the same keys as `self.children`, each of which maps to an object like\n        this one, recursively.\n      \'input_shapes\': A dictionary of the shapes of inputs to individual\n        encoding stages. The dictionary has two keys: `EncoderKeys.SHAPE` and\n        `EncoderKeys.CHILDREN`. The `EncoderKeys.SHAPE` key maps to the shape of\n        the input to `self.stage`. The `EncoderKeys.CHILDREN` key maps to a\n        dictionary with the same keys as `self.children`, each of which maps to\n        an object like this one, recursively. The values at the leaves of this\n        dictionary can be either `Tensor` objects, non-TensorFlow constants such\n        as a `list` or numpy value, or `None`, if the shape is not needed.\n    """"""\n    with tf.compat.v1.name_scope(name, \'encoder_encode\',\n                                 [x] + tf.nest.flatten(encode_params)):\n      return self._encode_impl(x, encode_params)\n\n  def _encode_impl(self, x, encode_params):\n    """"""Implementation for the `encode` method.""""""\n    encoded_tensors = {}\n    state_update_tensors = {}\n    input_shapes = {}\n    if self.stage.decode_needs_input_shape:\n      input_shapes[EncoderKeys.SHAPE] = py_utils.static_or_dynamic_shape(x)\n    else:\n      input_shapes[EncoderKeys.SHAPE] = None\n    encoded_tensors, state_update_tensors[EncoderKeys.TENSORS] = (\n        self.stage.encode(x, encode_params[EncoderKeys.PARAMS]))\n    children_state_update_tensors = {}\n    children_shapes = {}\n    for key, encoder in six.iteritems(self.children):\n      with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n        (encoded_tensors[key], children_state_update_tensors[key],\n         children_shapes[key]) = encoder._encode_impl(  # pylint: disable=protected-access\n             encoded_tensors[key], encode_params[EncoderKeys.CHILDREN][key])\n    state_update_tensors[EncoderKeys.CHILDREN] = children_state_update_tensors\n    input_shapes[EncoderKeys.CHILDREN] = children_shapes\n    return encoded_tensors, state_update_tensors, input_shapes\n\n  def decode(self, encoded_tensors, decode_params, shape, name=None):\n    """"""Decodes the encoded representation.\n\n    Args:\n      encoded_tensors: A dictionary representing the encoded value. The\n        structure needs to be the corresponding return structure of the `encode`\n        method.\n      decode_params: A dictionary containing the parameters needed for the\n        decoding. The structure needs to be the corresponding return structure\n        of the `get_params` method.\n      shape: A dictionary with the input shapes provided to the `encode` methods\n        of individual encoding stages. The structure needs to be the\n        corresponding return structure of the `encode` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A single decoded `Tensor`.\n    """"""\n    values = (\n        tf.nest.flatten(shape) + tf.nest.flatten(decode_params) +\n        tf.nest.flatten(encoded_tensors))\n    with tf.compat.v1.name_scope(name, \'encoder_decode\', values):\n      # Calling _decode_before_sum_impl with force_decode=True will decode the\n      # entire tree, regardless of potential commutativity with sum.\n      return self._decode_before_sum_impl(\n          encoded_tensors, decode_params, shape, force_decode=True)\n\n  def decode_before_sum(self, encoded_tensors, decode_params, shape, name=None):\n    """"""Decodes the part of encoded representation not commuting with sum.\n\n    This method represents part of the whole decoding logic, which does not\n    commute with sum. It can be an identity (if everything commutes with sum),\n    the full decoding (if nothing commutes with sum), or a partial decoding.\n\n    Args:\n      encoded_tensors: A dictionary representing the encoded value. The\n        structure needs to be the corresponding return structure of the `encode`\n        method.\n      decode_params: A dictionary containing the parameters needed for the\n        decoding. The structure needs to be the corresponding return structure\n        of the `get_params` method.\n      shape: A dictionary with the input shapes provided to the `encode` methods\n        of individual encoding stages. The structure needs to be the\n        corresponding return structure of the `encode` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      If `self.stage.commutes_with_sum` is `False`, returns a single decoded\n      `Tensor`. If it is `True`, returns partially decoded `encoded_tensors`,\n      i.e., dictionary with the same structure up to the part which does commute\n      with sum. This structure is also the expected input to the\n      `decode_after_sum` method.\n    """"""\n    values = (\n        tf.nest.flatten(shape) + tf.nest.flatten(decode_params) +\n        tf.nest.flatten(encoded_tensors))\n    with tf.compat.v1.name_scope(name, \'encoder_decode_before_sum\', values):\n      return self._decode_before_sum_impl(\n          encoded_tensors, decode_params, shape, force_decode=False)\n\n  def _decode_before_sum_impl(self, encoded_tensors, decode_params, shape,\n                              force_decode):\n    """"""Implementation for the `decode_before_sum` method.\n\n    The argument list of this method is different, to allow propagation of\n    information about commutativity higher up the chain of encodings. For\n    instance, consider an encoding consisting of three encoding stages, of which\n    the first and third individually commute with sum. As a chain, the third\n    stage does not commute with sum, because the second does not, and thus\n    everything else after it.\n\n    Args:\n      encoded_tensors: See the `decode_before_sum` method.\n      decode_params: See the `decode_before_sum` method.\n      shape: See the `decode_before_sum` method.\n      force_decode: If True, `self.stage.decode` will be called regardless of\n        whether it commutes with sum or not.\n\n    Returns:\n      A structure as described in the `decode_before_sum` method.\n    """"""\n    temp_encoded_tensors = {}\n    force_decode |= not self.stage.commutes_with_sum\n    for key, value in six.iteritems(encoded_tensors):\n      if key in self.children:\n        with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n          temp_encoded_tensors[key] = (\n              self.children[key]._decode_before_sum_impl(  # pylint: disable=protected-access\n                  value,\n                  decode_params[EncoderKeys.CHILDREN][key],\n                  shape[EncoderKeys.CHILDREN][key],\n                  force_decode=force_decode))\n      else:\n        temp_encoded_tensors[key] = value\n    if force_decode:\n      # We explicitly provide num_summands=None as this is explicitly decoding\n      # that happens *before* the sum.\n      return self.stage.decode(temp_encoded_tensors,\n                               decode_params[EncoderKeys.PARAMS],\n                               num_summands=None,\n                               shape=shape[EncoderKeys.SHAPE])\n    else:\n      return temp_encoded_tensors\n\n  def decode_after_sum(self,\n                       encoded_tensors,\n                       decode_params,\n                       num_summands,\n                       shape,\n                       name=None):\n    """"""Decodes the part of encoded representation commuting with sum.\n\n    This method is complementary to the `decode_before_sum` method in the sense\n    that `decode_after_sum(decode_before_sum(encoded_tensors), ...)` is always\n    equivalent to the full decoding of `encoded_tensors`.\n\n    Args:\n      encoded_tensors: A dictionary representing the encoded value. The\n        structure needs to be the return structure of the `decode_before_sum`\n        method.\n      decode_params: A dictionary containing the parameters needed for the\n        decoding. The structure needs to be the corresponding return structure\n        of the `get_params` method.\n      num_summands: The number of summands to be passed to individual encoding\n        stages.\n      shape: A dictionary with the input shapes provided to the `encode` methods\n        of individual encoding stages. The structure needs to be the\n        corresponding return structure of the `encode` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A single decoded `Tensor`.\n    """"""\n    values = (\n        tf.nest.flatten(shape) + tf.nest.flatten(decode_params) +\n        tf.nest.flatten(encoded_tensors) + [num_summands])\n    num_summands = tf.convert_to_tensor(num_summands)\n    with tf.compat.v1.name_scope(name, \'encoder_decode_after_sum\', values):\n      return self._decode_after_sum_impl(encoded_tensors, decode_params,\n                                         num_summands, shape)\n\n  def _decode_after_sum_impl(self, encoded_tensors, decode_params, num_summands,\n                             shape):\n    """"""Implementation for the `decode_after_sum` method.""""""\n    if not self.stage.commutes_with_sum:\n      # This should have been decoded earlier in the decode_before_sum method.\n      assert tf.is_tensor(encoded_tensors)\n      return encoded_tensors\n\n    temp_encoded_tensors = {}\n    for key, value in six.iteritems(encoded_tensors):\n      if key in self.children:\n        with tf.compat.v1.name_scope(None, \'/\'.join([self.stage.name, key])):\n          temp_encoded_tensors[key] = self.children[key]._decode_after_sum_impl(  # pylint: disable=protected-access\n              value, decode_params[EncoderKeys.CHILDREN][key], num_summands,\n              shape[EncoderKeys.CHILDREN][key])\n      else:\n        temp_encoded_tensors[key] = value\n    return self.stage.decode(temp_encoded_tensors,\n                             decode_params[EncoderKeys.PARAMS],\n                             num_summands=num_summands,\n                             shape=shape[EncoderKeys.SHAPE])\n\n\nclass EncoderComposer(object):\n  """"""Class for composing and creating `Encoder`.\n\n  This class is a utility for separating the creation of the `Encoder` from its\n  intended functionality. Each instance of `EncoderComposer` corresponds to a\n  node in a tree of encoding stages to be used for encoding.\n\n  The `make` method converts this object to an `Encoder`, which exposes the\n  encoding functionality.\n  """"""\n\n  def __init__(self, stage):\n    """"""Constructor for the `EncoderComposer`.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`.\n    """"""\n    if not isinstance(stage, (encoding_stage.EncodingStageInterface,\n                              encoding_stage.AdaptiveEncodingStageInterface)):\n      raise TypeError(\'The input argument is %s but must be an instance of \'\n                      \'EncodingStageInterface or of \'\n                      \'AdaptiveEncodingStageInterface\' % type(stage))\n    self._stage = stage\n    self._children = {}\n    super(EncoderComposer, self).__init__()\n\n  def add_child(self, stage, key):\n    """"""Adds a child node.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`.\n      key: `string`, specifying the output key of the encoding stage controlled\n        by this object, to be further encoded by `stage`.\n\n    Returns:\n      An `EncoderComposer`, the newly created child node.\n\n    Raises:\n      KeyError: If `key` is not a compressible tensor of the encoding stage\n        controlled by this object, or if it already has a child.\n    """"""\n    if key not in self._stage.compressible_tensors_keys:\n      raise KeyError(\'The specified key is either not compressible or not \'\n                     \'returned by the current encoding stage.\')\n    if key in self._children:\n      raise KeyError(\'The specified key is already used.\')\n    new_builder = EncoderComposer(stage)\n    self._children[key] = new_builder\n    return new_builder\n\n  def add_parent(self, stage, key):\n    """"""Adds a parent node.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`.\n      key: `string`, specifying the output key of `stage` to be further encoded\n        by the encoding stage controlled by this object.\n\n    Returns:\n      An `EncoderComposer`, the newly created parent node.\n\n    Raises:\n      KeyError: If `key` is not a compressible tensor of `stage`.\n    """"""\n    if key not in stage.compressible_tensors_keys:\n      raise KeyError(\'The specified key is either not compressible or not \'\n                     \'returned by the encoding stage.\')\n    new_builder = EncoderComposer(stage)\n    new_builder._children[key] = self  # pylint: disable=protected-access\n    return new_builder\n\n  def make(self):\n    """"""Recursively creates the `Encoder`.\n\n    This method also recursively creates all children, but not parents.\n\n    Returns:\n      An `Encoder` composing the encoding stages.\n    """"""\n    children = {}\n    for k, v in six.iteritems(self._children):\n      children[k] = v.make()\n    return Encoder(self._stage, children)\n\n\ndef split_params_by_commuting_structure(params, commuting_structure):\n  """"""Splits params by commuting_structure.\n\n  Args:\n    params: A structure to be split. This should be the value returned by the\n      `get_params` method of the `Encoder`.\n    commuting_structure: A structure describing the part of `Encoder` that\n      commutes with sum. This should be value returned by the\n      `commuting_structure` property of `Encoder`.\n\n  Returns:\n    A tuple `(before_sum_params, after_sum_params)`, where both values have the\n    same structure as `params`, with fields not relevant before/after summation\n    replaced by `None`.\n  """"""\n  return _split_value_by_commuting_structure(params, EncoderKeys.PARAMS,\n                                             commuting_structure)\n\n\ndef split_shapes_by_commuting_structure(shapes, commuting_structure):\n  """"""Splits shapes by commuting_structure.\n\n  Args:\n    shapes: A structure to be split. This should be the value returned as\n      `input_shapes` by the `encode` method of the `Encoder`.\n    commuting_structure: A structure describing the part of `Encoder` that\n      commutes with sum. This should be value returned by the\n      `commuting_structure` property of `Encoder`.\n\n  Returns:\n    A tuple `(before_sum_shapes, after_sum_shapes)`, where both values have the\n    same structure as `shapes`, with fields not relevant before/after summation\n    replaced by `None`.\n  """"""\n  return _split_value_by_commuting_structure(shapes, EncoderKeys.SHAPE,\n                                             commuting_structure)\n\n\ndef _split_value_by_commuting_structure(value, encoder_key,\n                                        commuting_structure):\n  """"""Utility for splitting value along commuting_structure of Encoder.""""""\n  before_sum_value = {}\n  after_sum_value = {}\n\n  if isinstance(value[encoder_key], dict):\n    empty_value = {k: None for k in value[encoder_key]}\n  else:\n    empty_value = None\n  full_value = value[encoder_key]\n  if commuting_structure[EncoderKeys.COMMUTE]:\n    before_sum_value[encoder_key] = empty_value\n    after_sum_value[encoder_key] = full_value\n  else:\n    before_sum_value[encoder_key] = full_value\n    after_sum_value[encoder_key] = empty_value\n\n  children_before_sum_value = {}\n  children_after_sum_value = {}\n  for key, val in six.iteritems(value[EncoderKeys.CHILDREN]):\n    children_before_sum_value[key], children_after_sum_value[key] = (\n        _split_value_by_commuting_structure(\n            val, encoder_key, commuting_structure[EncoderKeys.CHILDREN][key]))\n  before_sum_value[EncoderKeys.CHILDREN] = children_before_sum_value\n  after_sum_value[EncoderKeys.CHILDREN] = children_after_sum_value\n\n  return before_sum_value, after_sum_value\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/core_encoder_test.py,28,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n# Abbreviated constants used in tests.\nCHILDREN = core_encoder.EncoderKeys.CHILDREN\nPARAMS = core_encoder.EncoderKeys.PARAMS\nSHAPE = core_encoder.EncoderKeys.SHAPE\nSTATE = core_encoder.EncoderKeys.STATE\nTENSORS = core_encoder.EncoderKeys.TENSORS\nCOMMUTE = core_encoder.EncoderKeys.COMMUTE\n\nP1_VALS = test_utils.PlusOneEncodingStage.ENCODED_VALUES_KEY\nP1_ADD_PARAM = test_utils.PlusOneEncodingStage.ADD_PARAM_KEY\nT2_VALS = test_utils.TimesTwoEncodingStage.ENCODED_VALUES_KEY\nT2_FACTOR_PARAM = test_utils.TimesTwoEncodingStage.FACTOR_PARAM_KEY\nSL_VALS = test_utils.SimpleLinearEncodingStage.ENCODED_VALUES_KEY\nRM_VALS = test_utils.ReduceMeanEncodingStage.ENCODED_VALUES_KEY\nSIF_SIGNS = test_utils.SignIntFloatEncodingStage.ENCODED_SIGNS_KEY\nSIF_INTS = test_utils.SignIntFloatEncodingStage.ENCODED_INTS_KEY\nSIF_FLOATS = test_utils.SignIntFloatEncodingStage.ENCODED_FLOATS_KEY\nPN_VALS = test_utils.PlusOneOverNEncodingStage.ENCODED_VALUES_KEY\nPN_ITER_STATE = test_utils.PlusOneOverNEncodingStage.ITERATION_STATE_KEY\nPN_ADD_PARAM = test_utils.PlusOneOverNEncodingStage.ADD_PARAM_KEY\nAN_VALS = test_utils.AdaptiveNormalizeEncodingStage.ENCODED_VALUES_KEY\nAN_FACTOR_PARAM = test_utils.AdaptiveNormalizeEncodingStage.FACTOR_PARAM_KEY\nAN_FACTOR_STATE = test_utils.AdaptiveNormalizeEncodingStage.FACTOR_STATE_KEY\nAN_NORM_UPDATE = test_utils.AdaptiveNormalizeEncodingStage.NORM_STATE_UPDATE_KEY\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass EncoderTest(tf.test.TestCase):\n\n  def test_correct_structure(self):\n    """"""Tests that structured objects look like what they should.\n\n    This test creates the following encoding tree:\n    SignIntFloatEncodingStage\n        [SIF_SIGNS] -> TimesTwoEncodingStage\n        [SIF_INTS] -> PlusOneEncodingStage\n        [SIF_FLOATS] -> PlusOneOverNEncodingStage\n            [PN_VALS] -> AdaptiveNormalizeEncodingStage\n    And verifies that the structured objects created by the methods of `Encoder`\n    are of the expected structure.\n    """"""\n    sif_stage = test_utils.SignIntFloatEncodingStage()\n    times_two_stage = test_utils.TimesTwoEncodingStage()\n    plus_one_stage = test_utils.PlusOneEncodingStage()\n    plus_n_squared_stage = test_utils.PlusOneOverNEncodingStage()\n    adaptive_normalize_stage = test_utils.AdaptiveNormalizeEncodingStage()\n\n    encoder = core_encoder.EncoderComposer(sif_stage)\n    encoder.add_child(times_two_stage, SIF_SIGNS)\n    encoder.add_child(plus_one_stage, SIF_INTS)\n    encoder.add_child(plus_n_squared_stage, SIF_FLOATS).add_child(\n        adaptive_normalize_stage, PN_VALS)\n    encoder = encoder.make()\n\n    # Create all intermediary objects.\n    x = tf.constant(1.0)\n    initial_state = encoder.initial_state()\n    encode_params, decode_params = encoder.get_params(initial_state)\n    encoded_x, state_update_tensors, input_shapes = encoder.encode(\n        x, encode_params)\n    decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n    updated_state = encoder.update_state(initial_state, state_update_tensors)\n    commuting_structure = encoder.commuting_structure\n\n    # Verify the structure and naming of those objects is as expected.\n    for state in [initial_state, updated_state]:\n      tf.nest.assert_same_structure(\n          {\n              STATE: {},\n              CHILDREN: {\n                  SIF_INTS: {\n                      STATE: {},\n                      CHILDREN: {}\n                  },\n                  SIF_SIGNS: {\n                      STATE: {},\n                      CHILDREN: {}\n                  },\n                  SIF_FLOATS: {\n                      STATE: {\n                          PN_ITER_STATE: None\n                      },\n                      CHILDREN: {\n                          PN_VALS: {\n                              STATE: {\n                                  AN_FACTOR_STATE: None\n                              },\n                              CHILDREN: {}\n                          }\n                      }\n                  }\n              }\n          }, state)\n    self.assertIn(\n        \'encoder_initial_state/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + encoding_stage.INITIAL_STATE_SCOPE_SUFFIX,\n        initial_state[CHILDREN][SIF_FLOATS][STATE][PN_ITER_STATE].name)\n    self.assertIn(\n        \'encoder_initial_state/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + \'/\' + PN_VALS + \'/\' +\n        adaptive_normalize_stage.name +\n        encoding_stage.INITIAL_STATE_SCOPE_SUFFIX, initial_state[CHILDREN]\n        [SIF_FLOATS][CHILDREN][PN_VALS][STATE][AN_FACTOR_STATE].name)\n    self.assertIn(\n        \'encoder_update_state/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + encoding_stage.UPDATE_STATE_SCOPE_SUFFIX,\n        updated_state[CHILDREN][SIF_FLOATS][STATE][PN_ITER_STATE].name)\n    self.assertIn(\n        \'encoder_update_state/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + \'/\' + PN_VALS + \'/\' +\n        adaptive_normalize_stage.name +\n        encoding_stage.UPDATE_STATE_SCOPE_SUFFIX, updated_state[CHILDREN]\n        [SIF_FLOATS][CHILDREN][PN_VALS][STATE][AN_FACTOR_STATE].name)\n\n    for params in [encode_params, decode_params]:\n      tf.nest.assert_same_structure(\n          {\n              PARAMS: {},\n              CHILDREN: {\n                  SIF_INTS: {\n                      PARAMS: {\n                          P1_ADD_PARAM: None\n                      },\n                      CHILDREN: {}\n                  },\n                  SIF_SIGNS: {\n                      PARAMS: {\n                          T2_FACTOR_PARAM: None\n                      },\n                      CHILDREN: {}\n                  },\n                  SIF_FLOATS: {\n                      PARAMS: {\n                          PN_ADD_PARAM: None\n                      },\n                      CHILDREN: {\n                          PN_VALS: {\n                              PARAMS: {\n                                  AN_FACTOR_PARAM: None\n                              },\n                              CHILDREN: {}\n                          }\n                      }\n                  }\n              }\n          }, params)\n      self.assertIn(\n          \'encoder_get_params/\' + sif_stage.name + \'/\' + SIF_INTS + \'/\' +\n          plus_one_stage.name + encoding_stage.GET_PARAMS_SCOPE_SUFFIX,\n          params[CHILDREN][SIF_INTS][PARAMS][P1_ADD_PARAM].name)\n      self.assertIn(\n          \'encoder_get_params/\' + sif_stage.name + \'/\' + SIF_SIGNS + \'/\' +\n          times_two_stage.name + encoding_stage.GET_PARAMS_SCOPE_SUFFIX,\n          params[CHILDREN][SIF_SIGNS][PARAMS][T2_FACTOR_PARAM].name)\n      self.assertIn(\n          \'encoder_get_params/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n          plus_n_squared_stage.name + encoding_stage.GET_PARAMS_SCOPE_SUFFIX,\n          params[CHILDREN][SIF_FLOATS][PARAMS][PN_ADD_PARAM].name)\n      # Note: we do not check the value of\n      # params[CHILDREN][SIF_FLOATS][CHILDREN][PN_VALS][PARAMS][AN_FACTOR_PARAM]\n      # because the get_params method of adaptive_normalize_stage does not\n      # modify the graph, only passes through the provided state tensor.\n\n    tf.nest.assert_same_structure(\n        {\n            SIF_INTS: {\n                P1_VALS: None\n            },\n            SIF_SIGNS: {\n                T2_VALS: None\n            },\n            SIF_FLOATS: {\n                PN_VALS: {\n                    AN_VALS: None\n                }\n            }\n        }, encoded_x)\n    self.assertIn(\n        \'encoder_encode/\' + sif_stage.name + \'/\' + SIF_INTS + \'/\' +\n        plus_one_stage.name + encoding_stage.ENCODE_SCOPE_SUFFIX,\n        encoded_x[SIF_INTS][P1_VALS].name)\n    self.assertIn(\n        \'encoder_encode/\' + sif_stage.name + \'/\' + SIF_SIGNS + \'/\' +\n        times_two_stage.name + encoding_stage.ENCODE_SCOPE_SUFFIX,\n        encoded_x[SIF_SIGNS][T2_VALS].name)\n    self.assertIn(\n        \'encoder_encode/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + \'/\' + PN_VALS + \'/\' +\n        adaptive_normalize_stage.name + encoding_stage.ENCODE_SCOPE_SUFFIX,\n        encoded_x[SIF_FLOATS][PN_VALS][AN_VALS].name)\n\n    tf.nest.assert_same_structure(\n        {\n            TENSORS: {},\n            CHILDREN: {\n                SIF_INTS: {\n                    TENSORS: {},\n                    CHILDREN: {}\n                },\n                SIF_SIGNS: {\n                    TENSORS: {},\n                    CHILDREN: {}\n                },\n                SIF_FLOATS: {\n                    TENSORS: {},\n                    CHILDREN: {\n                        PN_VALS: {\n                            TENSORS: {\n                                AN_NORM_UPDATE: None\n                            },\n                            CHILDREN: {}\n                        }\n                    }\n                }\n            }\n        }, state_update_tensors)\n    tf.nest.assert_same_structure(state_update_tensors,\n                                  encoder.state_update_aggregation_modes)\n    self.assertIn(\n        \'encoder_encode/\' + sif_stage.name + \'/\' + SIF_FLOATS + \'/\' +\n        plus_n_squared_stage.name + \'/\' + PN_VALS + \'/\' +\n        adaptive_normalize_stage.name + encoding_stage.ENCODE_SCOPE_SUFFIX,\n        state_update_tensors[CHILDREN][SIF_FLOATS][CHILDREN][PN_VALS][TENSORS]\n        [AN_NORM_UPDATE].name)\n\n    tf.nest.assert_same_structure(\n        {\n            SHAPE: None,\n            CHILDREN: {\n                SIF_INTS: {\n                    SHAPE: None,\n                    CHILDREN: {}\n                },\n                SIF_SIGNS: {\n                    SHAPE: None,\n                    CHILDREN: {}\n                },\n                SIF_FLOATS: {\n                    SHAPE: None,\n                    CHILDREN: {\n                        PN_VALS: {\n                            SHAPE: None,\n                            CHILDREN: {}\n                        }\n                    }\n                }\n            }\n        }, input_shapes)\n    self.assertTrue(tf.is_tensor(decoded_x))\n    self.assertIn(\'encoder_decode/\', decoded_x.name)\n\n    tf.nest.assert_same_structure(\n        {\n            COMMUTE: None,\n            CHILDREN: {\n                SIF_INTS: {\n                    COMMUTE: None,\n                    CHILDREN: {}\n                },\n                SIF_SIGNS: {\n                    COMMUTE: None,\n                    CHILDREN: {}\n                },\n                SIF_FLOATS: {\n                    COMMUTE: None,\n                    CHILDREN: {\n                        PN_VALS: {\n                            COMMUTE: None,\n                            CHILDREN: {}\n                        }\n                    }\n                }\n            }\n        }, commuting_structure)\n    for item in tf.nest.flatten(commuting_structure):\n      self.assertEqual(False, item)\n\n  # A utility for tests testing commutation with sum works as expected.\n  commutation_test_data = collections.namedtuple(\n      \'comm_test_data\',\n      [\'x\', \'encoded_x\', \'decoded_x_before_sum\', \'decoded_x_after_sum\'])\n\n  def _data_for_test_decode_split(self, encoder, x):\n    encode_params, decode_params = encoder.get_params(encoder.initial_state())\n    encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n    decoded_x_before_sum = encoder.decode_before_sum(encoded_x, decode_params,\n                                                     input_shapes)\n    decoded_x_after_sum = encoder.decode_after_sum(decoded_x_before_sum,\n                                                   decode_params, 1,\n                                                   input_shapes)\n    data = self.commutation_test_data(x, encoded_x, decoded_x_before_sum,\n                                      decoded_x_after_sum)\n    return self.evaluate(data)\n\n  def test_decode_split_commutes_with_sum_false_false(self):\n    """"""Tests that splitting decode works as expected with commutes_with_sum.\n\n    This test chains two encoding stages, first *does not* commute with sum, the\n    second *does not*, either. Together, nothing should commute with sum.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneEncodingStage()).add_parent(\n            test_utils.PlusOneEncodingStage(), P1_VALS).make()\n    self.assertFalse(encoder.fully_commutes_with_sum)\n    data = self._data_for_test_decode_split(encoder, tf.constant(3.0))\n\n    # Test the encoding is as expected.\n    self.assertEqual(data.x, data.decoded_x_after_sum)\n    self.assertAllEqual({\n        P1_VALS: {\n            P1_VALS: data.x + 1.0 + 1.0\n        },\n    }, data.encoded_x)\n    # Nothing commutes with sum - decoded_x_before_sum should be fully decoded.\n    self.assertEqual(data.x, data.decoded_x_before_sum)\n    self.assertEqual(\n        {\n            COMMUTE: False,\n            CHILDREN: {\n                P1_VALS: {\n                    COMMUTE: False,\n                    CHILDREN: {}\n                }\n            }\n        }, encoder.commuting_structure)\n\n  def test_decode_split_commutes_with_sum_false_true(self):\n    """"""Tests that splitting decode works as expected with commutes_with_sum.\n\n    This test chains two encoding stages, first *does not* commute with sum, the\n    second *does*. Together, nothing should commute with sum.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.TimesTwoEncodingStage()).add_parent(\n            test_utils.PlusOneEncodingStage(), P1_VALS).make()\n    self.assertFalse(encoder.fully_commutes_with_sum)\n    data = self._data_for_test_decode_split(encoder, tf.constant(3.0))\n\n    # Test the encoding is as expected.\n    self.assertEqual(data.x, data.decoded_x_after_sum)\n    self.assertAllEqual({\n        P1_VALS: {\n            T2_VALS: (data.x + 1.0) * 2.0\n        },\n    }, data.encoded_x)\n    # Nothing commutes with sum - decoded_x_before_sum should be fully decoded.\n    self.assertEqual(data.x, data.decoded_x_before_sum)\n    self.assertEqual(\n        {\n            COMMUTE: False,\n            CHILDREN: {\n                P1_VALS: {\n                    COMMUTE: False,\n                    CHILDREN: {}\n                }\n            }\n        }, encoder.commuting_structure)\n\n  def test_decode_split_commutes_with_sum_true_true(self):\n    """"""Tests that splitting decode works as expected with commutes_with_sum.\n\n    This test chains two encoding stages, first *does* commute with sum, the\n    second *does*, too. Together, everything should commute with sum.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.TimesTwoEncodingStage()).add_parent(\n            test_utils.TimesTwoEncodingStage(), T2_VALS).make()\n    self.assertTrue(encoder.fully_commutes_with_sum)\n    data = self._data_for_test_decode_split(encoder, tf.constant(3.0))\n\n    # Test the encoding is as expected.\n    self.assertEqual(data.x, data.decoded_x_after_sum)\n    self.assertAllEqual({\n        T2_VALS: {\n            T2_VALS: data.x * 2.0 * 2.0\n        },\n    }, data.encoded_x)\n    # Everyting commutes with sum - decoded_x_before_sum should be intact.\n    self.assertAllEqual(data.encoded_x, data.decoded_x_before_sum)\n    self.assertEqual(\n        {\n            COMMUTE: True,\n            CHILDREN: {\n                T2_VALS: {\n                    COMMUTE: True,\n                    CHILDREN: {}\n                }\n            }\n        }, encoder.commuting_structure)\n\n  def test_decode_split_commutes_with_sum_true_false(self):\n    """"""Tests that splitting decode works as expected with commutes_with_sum.\n\n    This test chains two encoding stages, first *does* commute with sum, the\n    second *does not*. Together, only the first one should commute with sum.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneEncodingStage()).add_parent(\n            test_utils.TimesTwoEncodingStage(), T2_VALS).make()\n    self.assertFalse(encoder.fully_commutes_with_sum)\n    data = self._data_for_test_decode_split(encoder, tf.constant(3.0))\n\n    # Test the encoding is as expected.\n    self.assertEqual(data.x, data.decoded_x_after_sum)\n    self.assertAllEqual({\n        T2_VALS: {\n            P1_VALS: data.x * 2.0 + 1.0\n        },\n    }, data.encoded_x)\n    # Only first part commutes with sum.\n    self.assertAllEqual({T2_VALS: data.x * 2.0}, data.decoded_x_before_sum)\n    self.assertEqual(\n        {\n            COMMUTE: True,\n            CHILDREN: {\n                T2_VALS: {\n                    COMMUTE: False,\n                    CHILDREN: {}\n                }\n            }\n        }, encoder.commuting_structure)\n\n  def test_decode_split_commutes_with_sum_true_false_true(self):\n    """"""Tests that splitting decode works as expected with commutes_with_sum.\n\n    This test chains three encoding stages, first *does* commute with sum, the\n    second *does not*, and third *does*, again. Together, only the first one\n    should commute with sum, and the rest should not.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.TimesTwoEncodingStage()).add_parent(\n            test_utils.PlusOneEncodingStage(), P1_VALS).add_parent(\n                test_utils.TimesTwoEncodingStage(), T2_VALS).make()\n    self.assertFalse(encoder.fully_commutes_with_sum)\n    data = self._data_for_test_decode_split(encoder, tf.constant(3.0))\n\n    # Test the encoding is as expected.\n    self.assertEqual(data.x, data.decoded_x_after_sum)\n    self.assertAllEqual({\n        T2_VALS: {\n            P1_VALS: {\n                T2_VALS: (data.x * 2.0 + 1.0) * 2.0\n            }\n        },\n    }, data.encoded_x)\n    # Only first part commutes with sum.\n    self.assertAllEqual({T2_VALS: data.x * 2.0}, data.decoded_x_before_sum)\n    self.assertEqual(\n        {\n            COMMUTE: True,\n            CHILDREN: {\n                T2_VALS: {\n                    COMMUTE: False,\n                    CHILDREN: {\n                        P1_VALS: {\n                            COMMUTE: False,\n                            CHILDREN: {}\n                        },\n                    }\n                }\n            }\n        }, encoder.commuting_structure)\n\n  def test_commutes_with_sum(self):\n    """"""Tests that commutativity works, provided appropriate num_summands.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneEncodingStage()).add_parent(\n            test_utils.SimpleLinearEncodingStage(2.0, 3.0), SL_VALS).make()\n\n    x = tf.constant(3.0)\n    encode_params, decode_params = encoder.get_params(encoder.initial_state())\n    encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n    decoded_x_before_sum = encoder.decode_before_sum(encoded_x, decode_params,\n                                                     input_shapes)\n    # Trivial summing of the encoded - and partially decoded - values.\n    part_decoded_and_summed_x = tf.nest.map_structure(lambda x: x + x + x,\n                                                      decoded_x_before_sum)\n    num_summands = 3\n    decoded_x_after_sum = encoder.decode_after_sum(part_decoded_and_summed_x,\n                                                   decode_params, num_summands,\n                                                   input_shapes)\n    data = self.evaluate(\n        self.commutation_test_data(x, encoded_x, decoded_x_before_sum,\n                                   decoded_x_after_sum))\n    self.assertEqual(3.0, data.x)\n    expected_encoded_x = {SL_VALS: {P1_VALS: (data.x * 2.0 + 3.0) + 1.0}}\n    self.assertAllEqual(expected_encoded_x, data.encoded_x)\n    expected_decoded_x_before_sum = {SL_VALS: data.x * 2.0 + 3.0}\n    self.assertAllEqual(expected_decoded_x_before_sum,\n                        data.decoded_x_before_sum)\n    self.assertEqual(9.0, data.decoded_x_after_sum)\n\n  def test_decode_needs_input_shape(self):\n    """"""Tests that encoder works with stages that need input shape for decode.\n\n    This test chains two stages with this property.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.ReduceMeanEncodingStage()).add_parent(\n            test_utils.ReduceMeanEncodingStage(), RM_VALS).make()\n    x = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])\n    encode_params, decode_params = encoder.get_params(encoder.initial_state())\n    encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n    decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n    encoded_x, decoded_x = self.evaluate([encoded_x, decoded_x])\n\n    self.assertAllEqual([3.0] * 5, decoded_x)\n    self.assertAllEqual({RM_VALS: {RM_VALS: 3.0}}, encoded_x)\n\n  def test_decode_needs_input_shape_unknown_input_shape(self):\n    """"""Tests that encoder works with stages that need input shape for decode.\n\n    This test chains two stages with this property, and provides an input with\n    statically unknown shape information.\n    """"""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.ReduceMeanEncodingStage()).add_parent(\n            test_utils.ReduceMeanEncodingStage(), RM_VALS).make()\n    x = test_utils.get_tensor_with_random_shape()\n    encode_params, decode_params = encoder.get_params(encoder.initial_state())\n    encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n    decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n    assert x.shape.as_list()[0] is None  # Validate the premise of the test.\n    x, decoded_x = self.evaluate([x, decoded_x])\n\n    # Assert shape is correctly recovered, and finctionality is as expected.\n    self.assertAllEqual(x.shape, decoded_x.shape)\n    self.assertAllClose([x.mean()] * len(x), decoded_x)\n\n  def test_tree_encoder(self):\n    """"""Tests that the encoder works as a proper tree, not only a chain.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.SignIntFloatEncodingStage())\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_SIGNS)\n    encoder.add_child(test_utils.PlusOneEncodingStage(), SIF_INTS)\n    encoder.add_child(test_utils.PlusOneEncodingStage(), SIF_FLOATS).add_child(\n        test_utils.TimesTwoEncodingStage(), P1_VALS)\n    encoder = encoder.make()\n\n    x = tf.constant([0.0, 0.1, -0.1, 0.9, -0.9, 1.6, -2.2])\n    encode_params, decode_params = encoder.get_params(encoder.initial_state())\n    encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n    decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n    x, encoded_x, decoded_x = self.evaluate([x, encoded_x, decoded_x])\n\n    self.assertAllClose(x, decoded_x)\n    expected_encoded_x = {\n        SIF_SIGNS: {\n            T2_VALS: np.array([0.0, 2.0, -2.0, 2.0, -2.0, 2.0, -2.0])\n        },\n        SIF_INTS: {\n            P1_VALS: np.array([1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0])\n        },\n        SIF_FLOATS: {\n            P1_VALS: {\n                T2_VALS: np.array([2.0, 2.2, 2.2, 3.8, 3.8, 3.2, 2.4])\n            }\n        }\n    }\n    self.assertAllClose(expected_encoded_x, encoded_x)\n\n  def test_encoder_is_reusable(self):\n    """"""Tests that the same encoder can be used to encode multiple objects.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneEncodingStage()).add_parent(\n            test_utils.TimesTwoEncodingStage(), T2_VALS).make()\n    x_vals = [tf.random.normal(shape) for shape in [(3,), (3, 4), (3, 4, 5)]]\n    for x in x_vals:\n      encode_params, decode_params = encoder.get_params(\n          encoder.initial_state())\n      encoded_x, _, input_shapes = encoder.encode(x, encode_params)\n      decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n      x, encoded_x, decoded_x = self.evaluate([x, encoded_x, decoded_x])\n\n      self.assertAllClose(x, decoded_x)\n      self.assertAllClose({T2_VALS: {P1_VALS: x * 2.0 + 1.0}}, encoded_x)\n\n  def test_adaptive_stage(self):\n    """"""Tests composition of two adaptive encoding stages.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneOverNEncodingStage()).add_parent(\n            test_utils.PlusOneOverNEncodingStage(), PN_VALS).make()\n    x = tf.constant(1.0)\n    state = encoder.initial_state()\n\n    for i in range(1, 5):\n      initial_state = state\n      encode_params, decode_params = encoder.get_params(state)\n      encoded_x, state_update_tensors, input_shapes = encoder.encode(\n          x, encode_params)\n      decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n      state = encoder.update_state(initial_state, state_update_tensors)\n      data = self.evaluate(\n          test_utils.TestData(x, encoded_x, decoded_x, initial_state,\n                              state_update_tensors, state))\n\n      expected_initial_state = {\n          STATE: {\n              PN_ITER_STATE: i\n          },\n          CHILDREN: {\n              PN_VALS: {\n                  STATE: {\n                      PN_ITER_STATE: i\n                  },\n                  CHILDREN: {}\n              }\n          }\n      }\n      expected_state_update_tensors = {\n          TENSORS: {},\n          CHILDREN: {\n              PN_VALS: {\n                  TENSORS: {},\n                  CHILDREN: {}\n              }\n          }\n      }\n\n      self.assertAllClose(data.x, data.decoded_x)\n      self.assertAllEqual(expected_initial_state, data.initial_state)\n      self.assertDictEqual(expected_state_update_tensors,\n                           data.state_update_tensors)\n      self.assertAllClose(data.x + 2 * 1 / i, data.encoded_x[PN_VALS][PN_VALS])\n\n  def test_adaptive_stage_using_state_update_tensors(self):\n    """"""Tests adaptive encoding stage with state update tensors.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.AdaptiveNormalizeEncodingStage()).add_parent(\n            test_utils.PlusOneEncodingStage(), P1_VALS).make()\n    x = tf.constant(1.0)\n    state = encoder.initial_state()\n\n    for _ in range(1, 5):\n      initial_state = state\n      encode_params, decode_params = encoder.get_params(state)\n      encoded_x, state_update_tensors, input_shapes = encoder.encode(\n          x, encode_params)\n      decoded_x = encoder.decode(encoded_x, decode_params, input_shapes)\n      state = encoder.update_state(initial_state, state_update_tensors)\n      data = self.evaluate(\n          test_utils.TestData(x, encoded_x, decoded_x, initial_state,\n                              state_update_tensors, state))\n\n      self.assertAllClose(data.x, data.decoded_x)\n      self.assertLessEqual(\n          data.initial_state[CHILDREN][P1_VALS][STATE][AN_FACTOR_STATE], 1.0)\n      self.assertEqual(\n          data.state_update_tensors[CHILDREN][P1_VALS][TENSORS][AN_NORM_UPDATE],\n          2.0)\n      self.assertLessEqual(data.encoded_x[P1_VALS][AN_VALS], 2.0)\n\n\nclass EncoderComposerTest(tf.test.TestCase):\n\n  def test_add_parent(self):\n    encoder = core_encoder.EncoderComposer(\n        test_utils.ReduceMeanEncodingStage()).add_parent(\n            test_utils.PlusOneEncodingStage(), P1_VALS).add_parent(\n                test_utils.TimesTwoEncodingStage(), T2_VALS).make()\n\n    self.assertIsInstance(encoder, core_encoder.Encoder)\n    self.assertIsInstance(encoder.stage._wrapped_stage,\n                          test_utils.TimesTwoEncodingStage)\n    self.assertIsInstance(encoder.children[T2_VALS], core_encoder.Encoder)\n    self.assertIsInstance(encoder.children[T2_VALS].stage._wrapped_stage,\n                          test_utils.PlusOneEncodingStage)\n    self.assertIsInstance(encoder.children[T2_VALS].children[P1_VALS],\n                          core_encoder.Encoder)\n    self.assertIsInstance(\n        encoder.children[T2_VALS].children[P1_VALS].stage._wrapped_stage,\n        test_utils.ReduceMeanEncodingStage)\n\n  def test_add_child(self):\n    encoder = core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage())\n    encoder.add_child(test_utils.PlusOneEncodingStage(), T2_VALS).add_child(\n        test_utils.ReduceMeanEncodingStage(), P1_VALS)\n    encoder = encoder.make()\n\n    self.assertIsInstance(encoder, core_encoder.Encoder)\n    self.assertIsInstance(encoder.stage._wrapped_stage,\n                          test_utils.TimesTwoEncodingStage)\n    self.assertIsInstance(encoder.children[T2_VALS], core_encoder.Encoder)\n    self.assertIsInstance(encoder.children[T2_VALS].stage._wrapped_stage,\n                          test_utils.PlusOneEncodingStage)\n    self.assertIsInstance(encoder.children[T2_VALS].children[P1_VALS],\n                          core_encoder.Encoder)\n    self.assertIsInstance(\n        encoder.children[T2_VALS].children[P1_VALS].stage._wrapped_stage,\n        test_utils.ReduceMeanEncodingStage)\n\n  def test_add_child_semantics(self):\n    composer = core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage())\n    composer.add_child(test_utils.PlusOneEncodingStage(), T2_VALS)\n    encoder_1 = composer.make()\n    encoder_2 = core_encoder.EncoderComposer(\n        test_utils.TimesTwoEncodingStage()).add_child(\n            test_utils.PlusOneEncodingStage(), T2_VALS).make()\n\n    # Assert that these produce different trees. The add_child method returns\n    # the newly created node, and thus the make creates only the child node.\n    self.assertNotEqual(encoder_1.children.keys(), encoder_2.children.keys())\n\n  def test_constructor_raises(self):\n    with self.assertRaises(TypeError):\n      core_encoder.EncoderComposer(\'not an encoding stage\')\n\n  def test_add_child_parent_bad_key_raises(self):\n    encoder = core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage())\n    with self.assertRaises(KeyError):\n      encoder.add_child(test_utils.PlusOneEncodingStage(), \'___bad_key\')\n    with self.assertRaises(KeyError):\n      encoder.add_parent(test_utils.PlusOneEncodingStage(), \'___bad_key\')\n\n  def test_add_child_repeat_key_raises(self):\n    encoder = core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage())\n    encoder.add_child(test_utils.PlusOneEncodingStage(), T2_VALS)\n    with self.assertRaises(KeyError):\n      encoder.add_child(test_utils.PlusOneEncodingStage(), T2_VALS)\n\n\ndef _get_test_commuting_structure():\n  return {\n      COMMUTE: True,\n      CHILDREN: {\n          \'key_1\': {\n              COMMUTE: True,\n              CHILDREN: {\n                  \'key_4\': {\n                      COMMUTE: False,\n                      CHILDREN: {}\n                  }\n              }\n          },\n          \'key_2\': {\n              COMMUTE: False,\n              CHILDREN: {},\n          },\n          \'key_3\': {\n              COMMUTE: True,\n              CHILDREN: {},\n          }\n      }\n  }\n\n\nclass UtilsTest(tf.test.TestCase):\n  """"""Test for utilities created in core_encoder.py.""""""\n\n  def test_split_params_by_commuting_structure(self):\n    commuting_structure = _get_test_commuting_structure()\n    params = {\n        PARAMS: {\n            \'param_a\': 0.0,\n            \'param_b\': (-1.0, 1.0)\n        },\n        CHILDREN: {\n            \'key_1\': {\n                PARAMS: {\n                    \'param_c\': None\n                },\n                CHILDREN: {\n                    \'key_4\': {\n                        PARAMS: {\n                            \'param_e\': (-1.0, 1.0)\n                        },\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                PARAMS: {},\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                PARAMS: {\n                    \'param_d\': [1, 2]\n                },\n                CHILDREN: {},\n            }\n        }\n    }\n    expected_before_sum_params = {\n        PARAMS: {\n            \'param_a\': None,\n            \'param_b\': None\n        },\n        CHILDREN: {\n            \'key_1\': {\n                PARAMS: {\n                    \'param_c\': None\n                },\n                CHILDREN: {\n                    \'key_4\': {\n                        PARAMS: {\n                            \'param_e\': (-1.0, 1.0)\n                        },\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                PARAMS: {},\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                PARAMS: {\n                    \'param_d\': None\n                },\n                CHILDREN: {},\n            }\n        }\n    }\n    expected_after_sum_params = {\n        PARAMS: {\n            \'param_a\': 0.0,\n            \'param_b\': (-1.0, 1.0)\n        },\n        CHILDREN: {\n            \'key_1\': {\n                PARAMS: {\n                    \'param_c\': None\n                },\n                CHILDREN: {\n                    \'key_4\': {\n                        PARAMS: {\n                            \'param_e\': None\n                        },\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                PARAMS: {},\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                PARAMS: {\n                    \'param_d\': [1, 2]\n                },\n                CHILDREN: {},\n            }\n        }\n    }\n\n    before_sum_params, after_sum_params = (\n        core_encoder.split_params_by_commuting_structure(\n            params, commuting_structure))\n    self.assertEqual(expected_before_sum_params, before_sum_params)\n    self.assertEqual(expected_after_sum_params, after_sum_params)\n\n  def test_split_shapes_by_commuting_structure(self):\n    commuting_structure = _get_test_commuting_structure()\n    shapes = {\n        SHAPE: (5, 5),\n        CHILDREN: {\n            \'key_1\': {\n                SHAPE: None,\n                CHILDREN: {\n                    \'key_4\': {\n                        SHAPE: (1, 4),\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                SHAPE: (1, 2),\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                SHAPE: (1, 3),\n                CHILDREN: {},\n            }\n        }\n    }\n    expected_before_sum_shapes = {\n        SHAPE: None,\n        CHILDREN: {\n            \'key_1\': {\n                SHAPE: None,\n                CHILDREN: {\n                    \'key_4\': {\n                        SHAPE: (1, 4),\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                SHAPE: (1, 2),\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                SHAPE: None,\n                CHILDREN: {},\n            }\n        }\n    }\n    expected_after_sum_shapes = {\n        SHAPE: (5, 5),\n        CHILDREN: {\n            \'key_1\': {\n                SHAPE: None,\n                CHILDREN: {\n                    \'key_4\': {\n                        SHAPE: None,\n                        CHILDREN: {}\n                    }\n                }\n            },\n            \'key_2\': {\n                SHAPE: None,\n                CHILDREN: {},\n            },\n            \'key_3\': {\n                SHAPE: (1, 3),\n                CHILDREN: {},\n            }\n        }\n    }\n\n    before_sum_shapes, after_sum_shapes = (\n        core_encoder.split_shapes_by_commuting_structure(\n            shapes, commuting_structure))\n    self.assertEqual(expected_before_sum_shapes, before_sum_shapes)\n    self.assertEqual(expected_after_sum_shapes, after_sum_shapes)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/encoding_stage.py,19,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""EncodingStageInterface, its adaptive extension, and their implementations.\n\nThe interfaces are designed to support encoding and decoding that may happen\nin different locations, including possibly different TensorFlow `Session`\nobjects, without the implementer needing to understand how any communication is\nrealized. Example scenarios include\n* Both encoding and decoding can happen in the same location, such as for\n  experimental evaluation of efficiency, and no communication is necessary.\n* Both encoding and decoding can happen in different locations, but run in the\n  same `Session`, such as distributed datacenter training. The communication\n  between locations is handled by TensorFlow.\n* Encoding and decoding can happen on multiple locations, and communication\n  between them needs to happen outside of `TensorFlow`, such as encoding the\n  state of a model which is sent to a mobile device to be later decoded and used\n  for inference.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport enum\nimport six\nimport tensorflow as tf\n\nINITIAL_STATE_SCOPE_SUFFIX = \'_initial_state\'\nUPDATE_STATE_SCOPE_SUFFIX = \'_update_state\'\nGET_PARAMS_SCOPE_SUFFIX = \'_get_params\'\nENCODE_SCOPE_SUFFIX = \'_encode\'\nDECODE_SCOPE_SUFFIX = \'_decode\'\n\n\nclass StateAggregationMode(enum.Enum):\n  """"""Enum of available modes of aggregation for state.\n\n  This enum serves as a declaration of how the `state_update_tensors` returned\n  by the `encode` method of `StatefulEncodingStageInterface` should be\n  aggregated, before being passed to the `update_state` method.\n\n  This is primarily relevant for the setting where the encoding happens in\n  multiple locations, and a function of the encoded objects needs to be computed\n  at a central node. The implementation of these modes can differ depending on\n  the context. For instance, aggregation of these values in a star topology will\n  look differently from a multi-tier aggregation, which needs to know how some\n  intermediary representations is to be merged.\n\n  List of available values:\n  * `SUM`: Summation.\n  * `MIN`: Minimum.\n  * `MAX`: Maximum.\n  * `STACK`: Stacking along a new dimentsion. This can necessary for computing\n    arbitrary function of a collection of those values, such as a percentile.\n  """"""\n  SUM = 1\n  MIN = 2\n  MAX = 3\n  STACK = 4\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass EncodingStageInterface(object):\n  """"""Interface for the core of encoding logic.\n\n  This core interface should support encoding being executed in a variety of\n  contexts. For instance,\n  * Both encoding and decoding can happen in the same location, such as for\n    experimental evaluation of efficiency.\n  * Both encoding and decoding can happen in different locations, but run in the\n    same `Session`, such as distributed datacenter training.\n  * Encoding and decoding can happen in multiple locations, and communication\n    between them needs to happen outside of `TensorFlow`, such as compressing\n    a state of a model which is sent to a mobile device to be later used for\n    inference.\n\n  This interface is designed such that its implementer need not worry about the\n  potential communication patterns, and the implementation will support all.\n\n  Each implementation of this interface is supposed to be a relatively\n  elementary transformation. In particular, it does not need to realize any\n  representation savings by itself. Instead, a particular compositions of these\n  elementary transformations will realize the desired savings. These\n  compositions are realized by the `Encoder` class.\n\n  Each implementation should also be wrapped by `tf_style_encoding_stage` to\n  ensure adherence to the TensorFlow style guide. The adherence is enforced by\n  the `BaseEncodingStageTest` test class. See `test_utils.py` for more details.\n\n  For an adaptive version with a broader interface, see\n  `AdaptiveEncodingStageInterface`.\n  """"""\n\n  @abc.abstractproperty\n  def name(self):\n    """"""Name of the encoding stage.\n\n    This is a general name for the implementation of this interface, which is\n    used mainly by the `Encoder` class to create appropriate TensorFlow name\n    scopes when composing individual encoding stages.\n    """"""\n\n  @abc.abstractproperty\n  def compressible_tensors_keys(self):\n    """"""Keys of encoded tensors allowed to be further encoded.\n\n    These keys correspond to tensors in object returned by the `encode` method,\n    that are allowed to be further lossily compressed.\n\n    This property does not directly impact the functionality, but is used by the\n    `Encoder` class to validate composition.\n\n    Returns:\n      A list of `string` values.\n    """"""\n\n  @abc.abstractproperty\n  def commutes_with_sum(self):\n    """"""`True/False` based on whether the encoding commutes with sum.\n\n    Iff `True`, it means that given multiple inputs `x` with the same `shape`\n    and `dtype`, and the same `params` argument of the `encode` method, the\n    implementation is such that every value in the returned `encoded_tensors`\n    can be first summed, before being passed to the decoding functionality, and\n    the output should be identical (up to numerical precision) to summing the\n    fully decoded `Tensor` objects.\n\n    Note that this also assumes that each of the `decode` methods would be used\n    with the same values of `decode_params`.\n\n    Returns:\n      A boolean, `True` iff the encoding commutes with sum.\n    """"""\n\n  @abc.abstractproperty\n  def decode_needs_input_shape(self):\n    """"""Whether original shape of the encoded object is needed for decoding.\n\n    Iff `True`, it means that the `shape` of the `x` argument to the `encode`\n    method needs to be provided to the `decode` method. For instance, this is\n    needed for bitpacking, where inputs of multiple shapes can result in\n    identical bitpacked representations. Note however, the shape information\n    should not be stored in the return structure of the `encode` method.\n\n    This property will be used by `Encoder` to efficiently realize the\n    composition of implementations of this interface, and to make the necessary\n    shape information available.\n    """"""\n\n  @abc.abstractmethod\n  def get_params(self):\n    """"""Returns the parameters needed for encoding.\n\n    This method returns parameters controlling the behavior of the `encode` and\n    `decode` methods.\n\n    Implementation of this method should clearly document what are the keys of\n    parameters returned by this method, in order for a potential stateful\n    subclass being able to adaptively modify only existing keys.\n\n    Note that this method is not purely functional in terms of `TensorFlow`. The\n    params can be derived from an internal state of the compressor. For\n    instance, if a constructor optionally takes a `Variable` as an input\n    argument, which is allowed to change during iterative execution, that\n    `Variable`, or a function of it, would be exposed via this method. However,\n    only values that can be TensorFlow values should be exposed via params. If a\n    parameter always needs to be a Python constant, for instance used for Python\n    control flow, it should not be exposed via params, and accessed via `self`\n    instead.\n\n    Returns:\n      A tuple `(encode_params, decode_params)`, where\n      `encode_params`: A dictionary to be passed as argument to the `encode`\n        method.\n      `decode_params`: A dictionary to be passed as argument to the `decode`\n        method.\n      Each value of the dictionaries can be either a `Tensor` or any python\n      constant.\n    """"""\n\n  @abc.abstractmethod\n  def encode(self, x, encode_params):\n    """"""Encodes a given `Tensor`.\n\n    This method can create TensorFlow variables, which can be updated every time\n    the encoding is executed. An example is an encoder that internally remembers\n    the error incurred by previous encoding, and adds it to `x` in the next\n    iteration, before executing the encoding.\n\n    However, this method may be called in an entirely separate graph from all\n    other methods. That is, the implementer of this class can *only* assume such\n    variables can be accessed from this method but not from others.\n\n    Args:\n      x: A `Tensor`, input to be encoded.\n      encode_params: A dictionary, containing the parameters needed for the\n        encoding. The structure needs to be the return structure of the\n        `get_params` method.\n\n    Returns:\n      A dictionary of `Tensor` objects representing the encoded input `x`.\n    """"""\n\n  @abc.abstractmethod\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""Decodes the encoded representation.\n\n    This method is the inverse transformation of the `encode` method. The\n    `encoded_tensors` argument is expected to be the output structure of\n    `encode` method.\n\n    The `num_summands` argument is needed because the `decode` of some encoding\n    stages only commute with sum if the number of summands is known.\n\n    Consider the example of uniform quantization on a specified interval.\n    Encoding applies a pre-defined linear transformation to the input, and maps\n    the resulting values to a discrete set of values. Because of the linear\n    transformation, the decoding functionality does not immediately commute with\n    sum. However, if we knew how many summands are in the sum, we can determine\n    what is the appropriate inverse linear transformation, enabling the\n    commutativity.\n\n    A simple way to make this functionality available is to add a\n    `tf.constant(1, tf.int32)` to the encoded tensors returned by the `encode`\n    method.\n\n    The problem is that this approach will be often inefficient. Typically, we\n    are intereseted in encoding a collection of values, such as all weights of a\n    model, and multiple encoding stages might require this information. The\n    result will be a lot of redundant information being communicated. Moreover,\n    a user interested in this will always have the relevant information already\n    available.\n\n    Such information can thus be provided to the `decode` method of an encoding\n    stage via the `num_summands` argument, which will be handled by higher-level\n    interfaces.\n\n    Args:\n      encoded_tensors: A dictionary containing `Tensor` objects, representing\n        the encoded value.\n      decode_params: A dictionary, containing the parameters needed for the\n        decoding. The structure needs to be the return structure of the\n        `get_params` method.\n      num_summands: An integer representing the number of summands, if\n        `encoded_tensors` is a sum of the encoded representations. The default\n        value `None` refers to the case when no summation occurred, and can thus\n        be interpreted as `1`.\n      shape: Required if the `decode_needs_input_shape` property is `True`. A\n        shape of the original input to `encode`, if needed for decoding. Can be\n        either a `Tensor`, or a python object.\n\n    Returns:\n      A single decoded `Tensor`.\n    """"""\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass AdaptiveEncodingStageInterface(object):\n  """"""Adaptive version of the `EncodingStageInterface`.\n\n  This class has the same functionality as the `EncodingStageInterface`, but in\n  addition maintains a state, which is adaptive based on the values being\n  compressed and can parameterize the way encoding functionality works. Note\n  that this is useful only in case where the encoding is executed in multiple\n  iterations.\n\n  A typical implementation of this interface would be a wrapper of an\n  implementation of `EncodingStageInterface, which uses the existing stateless\n  transformations and adds state that controls some of the parameters returned\n  by the `get_params` method.\n\n  The important distinction is that in addition to `encoded_tensors`, the\n  `encode` method of this class returns an additional dictionary of\n  `state_update_tensors`. The `commutes_with_sum` property talks about summation\n  of only the `encoded_tensors`. The `state_update_tensors` can be aggregated\n  in more flexible ways, specified by the `state_update_aggregation_modes`\n  property, before being passed to the `update_state` method.\n\n  Each implementation should also be wrapped by `tf_style_encoding_stage` to\n  ensure adherence to the TensorFlow style guide. The adherence is enforced by\n  the `BaseEncodingStageTest` test class. See `test_utils.py` for more details.\n  """"""\n\n  @abc.abstractproperty\n  def name(self):\n    """"""Name of the encoding stage.\n\n    This is a general name for the implementation of this interface, which is\n    used mainly by the `Encoder` class to create appropriate TensorFlow name\n    scopes when composing individual encoding stages.\n    """"""\n\n  @abc.abstractproperty\n  def compressible_tensors_keys(self):\n    """"""Keys of encoded tensors allowed to be further encoded.\n\n    These keys correspond to tensors in object returned by the `encode` method,\n    that are allowed to be further lossily compressed.\n\n    This property does not directly impact the functionality, but is used by the\n    `Encoder` class to validate composition.\n\n    Returns:\n      A list of `string` values.\n    """"""\n\n  @abc.abstractproperty\n  def commutes_with_sum(self):\n    """"""`True/False` based on whether the encoding commutes with sum.\n\n    Iff `True`, it means that given multiple inputs `x` with the same `shape`\n    and `dtype`, and the same `params` argument of the `encode` method, the\n    implementation is such that every value in the returned `encoded_tensors`\n    can be first summed, before being passed to the decoding functionality, and\n    the output should be identical (up to numerical precision) to summing the\n    fully decoded `Tensor` objects.\n\n    Note that this also assumes that each of the `decode` methods would be used\n    with the same values of `decode_params`.\n\n    Returns:\n      A boolean, `True` iff the encoding commutes with sum.\n    """"""\n\n  @abc.abstractproperty\n  def decode_needs_input_shape(self):\n    """"""Whether original shape of the encoded object is needed for decoding.\n\n    Iff `True`, it means that the `shape` of the `x` argument to the `encode`\n    method needs to be provided to the `decode` method. For instance, this is\n    needed for bitpacking, where inputs of multiple shapes can result in\n    identical bitpacked representations.\n\n    This property will be used by `Encoder` to efficiently realize the\n    composition of implementations of this interface.\n    """"""\n\n  @abc.abstractproperty\n  def state_update_aggregation_modes(self):\n    """"""Aggregation mode of state update tensors.\n\n    Returns a dictionary mapping keys appearing in `state_update_tensors`\n    returned by the `encode` method to a `StateAggregationMode` object, which\n    declares how should the `Tensor` objects be aggreggated.\n    """"""\n\n  @abc.abstractmethod\n  def initial_state(self):\n    """"""Creates an initial state.\n\n    Returns:\n      A dictionary of `Tensor` objects, representing the initial state.\n    """"""\n\n  @abc.abstractmethod\n  def update_state(self, state, state_update_tensors):\n    """"""Updates the state.\n\n    This method updates the `state` based on the current value of `state`, and\n    (potentially aggregated) `state_update_tesors`, returned by the `encode`\n    method. This will typically happen at the end of a notion of iteration.\n\n    Args:\n      state: A dictionary of `Tensor` objects, representing the current state.\n        The dictionary has the same structure as return dictionary of the\n        `initial_state` method.\n      state_update_tensors: A dictionary of `Tensor` objects, representing the\n        `state_update_tensors` returned by the `encode` method and appropriately\n        aggregated.\n\n    Returns:\n      A dictionary of `Tensor` objects, representing the updated `state`.\n    """"""\n\n  @abc.abstractmethod\n  def get_params(self, state):\n    """"""Returns the parameters needed for encoding.\n\n    This method returns parameters controlling the behavior of the `encode` and\n    `decode` methods.\n\n    Note that this method is not purely functional in terms of `TensorFlow`. The\n    params can be derived from an internal state of the compressor. For\n    instance, if a constructor optionally takes a `Variable` as an input\n    argument, which is allowed to change during iterative execution, that\n    `Variable`, or a function of it, would be exposed via this method.However,\n    only values that can be TensorFlow values should be exposed via params. If a\n    parameter always needs to be a Python constant, for instance used for Python\n    control flow, it should not be exposed via params, and accessed via `self`\n    instead.\n\n    Args:\n      state: A dictionary of `Tensor` objects. This should be the object\n        controlled by the `initial_state` and `update_state` methods.\n\n    Returns:\n      A tuple `(encode_params, decode_params)`, where\n      `encode_params`: A dictionary to be passed as argument to the `encode`\n        method.\n      `decode_params`: A dictionary to be passed as argument to the `decode`\n        method.\n      Each value of the dictionaries can be either a `Tensor` or any python\n      constant.\n    """"""\n\n  @abc.abstractmethod\n  def encode(self, x, encode_params):\n    """"""Encodes a given `Tensor`.\n\n    This method can create TensorFlow variables, which can be updated every time\n    the encoding is executed. An example is an encoder that internally remembers\n    the error incurred by previous encoding, and adds it to `x` in the next\n    iteration, before executing the encoding.\n\n    However, this method may be called in an entirely separate graph from all\n    other methods. That is, the implementer of this class can *only* assume such\n    variables can be accessed from this method but not from others.\n\n    Args:\n      x: A `Tensor`, input to be encoded.\n      encode_params: A dictionary, containing the parameters needed for the\n        encoding. The structure needs to be the return structure of `get_params`\n        method.\n\n    Returns:\n      A tuple `(encoded_tensors, state_update_tensors)`, where these are:\n      `encoded_tensors`: A dictionary of `Tensor` objects representing the\n        encoded input `x`.\n      `state_update_tensors`: A dictionary of `Tensor` objects representing\n        information necessary for updating the state.\n    """"""\n\n  @abc.abstractmethod\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""Decodes the encoded representation.\n\n    This method is the inverse transformation of the `encode` method. The\n    `encoded_tensors` argument is expected to be the output structure of\n    `encode` method.\n\n    The `num_summands` argument is needed because the `decode` some encoding\n    stages only commute with sum if the number of summands is known. Consider\n    the example of uniform quantization on a specified interval.\n\n    Encoding applies a pre-defined linear transformation to the input, and\n    maps the resulting values to a discrete set of values. Because of the linear\n    transformation, the decoding functionality does not immediately commute with\n    sum. However, if we knew how many summands are in the sum, we can determine\n    what is the appropriate inverse linear transformation, enabling the\n    commutativity.\n\n    A simple way to make this functionality available is to add a\n    `tf.constant(1, tf.int32)` to the encoded tensors returned by the `encode`\n    method.\n\n    The problem is that this approach will be often inefficient. Typically, we\n    are intereseted in encoding a collection of values, such as all weights of a\n    model, and multiple encoding stages might require this information. The\n    result will be a lot of redundant information being communicated. Moreover,\n    a user interested in this will always have the relevant information already\n    available.\n\n    Such information can thus be provided to the `decode` method of an encoding\n    stage via the `num_summands` argument, which will be handled by higher-level\n    interfaces.\n\n    Args:\n      encoded_tensors: A dictionary containing `Tensor` objects, representing\n        the encoded value.\n      decode_params: A dictionary, containing the parameters needed for the\n        decoding. The structure needs to be the return structure of `get_params`\n        method.\n      num_summands: An integer representing number of summands, if\n        `encoded_tensors` is a sum of the encoded representations. The default\n        value `None` is to be interpreted as `1`.\n      shape: Required if the `decode_needs_input_shape` property is `True`. A\n        shape of the original input to `encode`, if needed for decoding. Can be\n        either a `Tensor`, or a python object.\n\n    Returns:\n      A single decoded `Tensor`.\n    """"""\n\n\ndef tf_style_encoding_stage(cls):\n  """"""Decorator for implementations of `EncodingStageInterface`.\n\n  This decorator ensures adherence to the TensorFlow style guide, and should be\n  used to decorate every implementation of `EncodingStageInterface`. In\n  particular, it captures the methods of the interface in appropriate name\n  scopes or variable scopes, and calls `tf.convert_to_tensor` on the provided\n  inputs.\n\n  For `get_params`, `encode` and `decode` methods, it adds an optional `name`\n  argument with default value `None`, as per the style guide.\n\n  Args:\n    cls: The class to be decorated. Must be an `EncodingStageInterface`.\n\n  Returns:\n    Decorated class.\n\n  Raises:\n    TypeError: If `cls` is not an `EncodingStageInterface`.\n  """"""\n\n  if not issubclass(cls, EncodingStageInterface):\n    raise TypeError(\'Unable to decorate %s. Provided class must be a subclass \'\n                    \'of EncodingStageInterface.\' % cls)\n\n  class TFStyleEncodingStage(cls):\n    """"""The decorated encoding stage.""""""\n\n    def __init__(self, *args, **kwargs):\n      self._wrapped_class = cls(*args, **kwargs)\n\n    def __getattr__(self, attr):\n      return self._wrapped_class.__getattribute__(attr)\n\n    @_tf_style_get_params\n    def get_params(self, name=None):\n      return super(TFStyleEncodingStage, self).get_params()\n\n    @_tf_style_encode\n    def encode(self, x, encode_params, name=None):\n      return super(TFStyleEncodingStage, self).encode(x, encode_params)\n\n    @_tf_style_decode\n    def decode(self,\n               encoded_tensors,\n               decode_params,\n               num_summands=None,\n               shape=None,\n               name=None):\n      return super(TFStyleEncodingStage,\n                   self).decode(encoded_tensors, decode_params, num_summands,\n                                shape)\n\n  return TFStyleEncodingStage\n\n\ndef tf_style_adaptive_encoding_stage(cls):\n  """"""Decorator for implementations of `AdaptiveEncodingStageInterface`.\n\n  This decorator ensures adherence to the TensorFlow style guide, and should be\n  used to decorate every implementation of `AdaptiveEncodingStageInterface`. In\n  particular, it captures the methods of the interface in appropriate name\n  scopes or variable scopes, and calls `tf.convert_to_tensor` on the provided\n  inputs.\n\n  For `initial_state`, `update_state`, `get_params`, `encode` and `decode`\n  methods, it adds an optional `name` argument with default value `None`, as per\n  the style guide.\n\n  Args:\n    cls: The class to be decorated. Must be an `AdaptiveEncodingStageInterface`.\n\n  Returns:\n    Decorated class.\n\n  Raises:\n    TypeError: If `cls` is not an `AdaptiveEncodingStageInterface`.\n  """"""\n\n  if not issubclass(cls, AdaptiveEncodingStageInterface):\n    raise TypeError(\'Unable to decorate %s. Provided class must be a subclass \'\n                    \'of AdaptiveEncodingStageInterface.\' % cls)\n\n  class TFStyleAdaptiveEncodingStage(cls):\n    """"""The decorated adaptive encoding stage.""""""\n\n    def __init__(self, *args, **kwargs):\n      self._wrapped_class = cls(*args, **kwargs)\n\n    def __getattr__(self, attr):\n      return self._wrapped_class.__getattribute__(attr)\n\n    @_tf_style_initial_state\n    def initial_state(self, name=None):\n      return super(TFStyleAdaptiveEncodingStage, self).initial_state()\n\n    @_tf_style_update_state\n    def update_state(self, state, state_update_tensors, name=None):\n      return super(TFStyleAdaptiveEncodingStage, self).update_state(\n          state, state_update_tensors)\n\n    @_tf_style_adaptive_get_params\n    def get_params(self, state, name=None):\n      return super(TFStyleAdaptiveEncodingStage, self).get_params(state)\n\n    @_tf_style_encode\n    def encode(self, x, encode_params, name=None):\n      return super(TFStyleAdaptiveEncodingStage, self).encode(x, encode_params)\n\n    @_tf_style_decode\n    def decode(self,\n               encoded_tensors,\n               decode_params,\n               num_summands=None,\n               shape=None,\n               name=None):\n      return super(TFStyleAdaptiveEncodingStage,\n                   self).decode(encoded_tensors, decode_params, num_summands,\n                                shape)\n\n  return TFStyleAdaptiveEncodingStage\n\n\ndef _tf_style_initial_state(initial_state_fn):\n  """"""Method decorator for `tf_style_adaptive_encoding_stage`.""""""\n\n  def actual_initial_state_fn(self, name=None):\n    """"""Modified `initial_state` method.""""""\n    with tf.compat.v1.name_scope(name, self.name + INITIAL_STATE_SCOPE_SUFFIX):\n      return initial_state_fn(self, name=name)\n\n  return actual_initial_state_fn\n\n\ndef _tf_style_update_state(update_state_fn):\n  """"""Method decorator for `tf_style_adaptive_encoding_stage`.""""""\n\n  def actual_initial_state_fn(self, state, state_update_tensors, name=None):\n    """"""Modified `update_state` method.""""""\n    values = list(state.values()) + list(state_update_tensors.values())\n    with tf.compat.v1.name_scope(name, self.name + UPDATE_STATE_SCOPE_SUFFIX,\n                                 values):\n      state = tf.nest.map_structure(tf.convert_to_tensor, state)\n      state_update_tensors = tf.nest.map_structure(tf.convert_to_tensor,\n                                                   state_update_tensors)\n      return update_state_fn(self, state, state_update_tensors, name=name)\n\n  return actual_initial_state_fn\n\n\ndef _tf_style_get_params(get_params_fn):\n  """"""Method decorator for `tf_style_encoding_stage`.""""""\n\n  def actual_get_params_fn(self, name=None):\n    """"""Modified `get_params` method.""""""\n    with tf.compat.v1.name_scope(name, self.name + GET_PARAMS_SCOPE_SUFFIX):\n      return get_params_fn(self, name=name)\n\n  return actual_get_params_fn\n\n\ndef _tf_style_adaptive_get_params(get_params_fn):\n  """"""Method decorator for `tf_style_adaptive_encoding_stage`.""""""\n\n  def actual_get_params_fn(self, state, name=None):\n    """"""Modified `get_params` method.""""""\n    with tf.compat.v1.name_scope(name, self.name + GET_PARAMS_SCOPE_SUFFIX,\n                                 state.values()):\n      state = tf.nest.map_structure(tf.convert_to_tensor, state)\n      return get_params_fn(self, state, name=name)\n\n  return actual_get_params_fn\n\n\ndef _tf_style_encode(encode_fn):\n  """"""Method decorator for `tf_style(_adaptive)_encoding_stage`.""""""\n\n  def actual_encode_fn(self, x, encode_params, name=None):\n    """"""Modified `encode` method.""""""\n    values = list(encode_params.values()) + [x]\n    with tf.compat.v1.variable_scope(name, self.name + ENCODE_SCOPE_SUFFIX,\n                                     values):\n      x = tf.convert_to_tensor(x)\n      encode_params = tf.nest.map_structure(tf.convert_to_tensor, encode_params)\n      return encode_fn(self, x, encode_params, name=name)\n\n  return actual_encode_fn\n\n\ndef _tf_style_decode(decode_fn):\n  """"""Method decorator for `tf_style(_adaptive)_encoding_stage`.""""""\n\n  def actual_decode_fn(self,\n                       encoded_tensors,\n                       decode_params,\n                       num_summands=None,\n                       shape=None,\n                       name=None):\n    """"""Modified `decode` method.""""""\n    values = list(encoded_tensors.values()) + list(decode_params.values())\n    with tf.compat.v1.variable_scope(name, self.name + DECODE_SCOPE_SUFFIX,\n                                     values):\n      encoded_tensors = tf.nest.map_structure(tf.convert_to_tensor,\n                                              encoded_tensors)\n      decode_params = tf.nest.map_structure(tf.convert_to_tensor, decode_params)\n      if shape is not None:\n        shape = tf.convert_to_tensor(shape)\n      if num_summands is not None:\n        num_summands = tf.convert_to_tensor(num_summands)\n      return decode_fn(\n          self,\n          encoded_tensors,\n          decode_params,\n          num_summands=num_summands,\n          shape=shape,\n          name=name)\n\n  return actual_decode_fn\n\n\ndef as_adaptive_encoding_stage(stage):\n  """"""Returns an instance of `AdaptiveEncodingStageInterface`.\n\n  If an `EncodingStageInterface` object is provided, the returned instance of\n  `AdaptiveEncodingStageInterface` is passing around an empty state, not\n  modifying the functionality of the `stage` in any way.\n\n  Args:\n    stage: An `EncodingStageInterface` or `AdaptiveEncodingStageInterface`\n      object.\n\n  Returns:\n    An instance of `AdaptiveEncodingStageInterface` with the same functionality\n    as `stage`.\n\n  Raises:\n    TypeError: If `stage` is not `EncodingStageInterface` or\n    `AdaptiveEncodingStageInterface`.\n  """"""\n\n  if isinstance(stage, EncodingStageInterface):\n    return NoneStateAdaptiveEncodingStage(stage)\n  elif isinstance(stage, AdaptiveEncodingStageInterface):\n    return stage\n  else:\n    raise TypeError\n\n\nclass NoneStateAdaptiveEncodingStage(AdaptiveEncodingStageInterface):\n  """"""Wraps an `EncodingStageInterface` as `AdaptiveEncodingStageInterface`.""""""\n\n  def __init__(self, wrapped_stage):\n    if not isinstance(wrapped_stage, EncodingStageInterface):\n      raise TypeError(\n          \'The provided stage must be an instance of EncodingStageInterface.\')\n    self._wrapped_stage = wrapped_stage\n\n  def __getattr__(self, attr):\n    return self._wrapped_stage.__getattr__(attr)\n\n  @property\n  def name(self):\n    return self._wrapped_stage.name\n\n  @property\n  def compressible_tensors_keys(self):\n    return self._wrapped_stage.compressible_tensors_keys\n\n  @property\n  def commutes_with_sum(self):\n    return self._wrapped_stage.commutes_with_sum\n\n  @property\n  def decode_needs_input_shape(self):\n    return self._wrapped_stage.decode_needs_input_shape\n\n  @property\n  def state_update_aggregation_modes(self):\n    return {}\n\n  def initial_state(self, name=None):\n    del name  # Unused.\n    return {}\n\n  def update_state(self, state, state_update_tensors, name=None):\n    del state  # Unused.\n    del state_update_tensors  # Unused.\n    del name  # Unused.\n    return {}\n\n  def get_params(self, state, name=None):\n    del state  # Unused.\n    return self._wrapped_stage.get_params(name)\n\n  def encode(self, x, encode_params, name=None):\n    return self._wrapped_stage.encode(x, encode_params, name), {}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None,\n             name=None):\n    return self._wrapped_stage.decode(encoded_tensors, decode_params,\n                                      num_summands, shape, name)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/encoding_stage_test.py,30,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport mock\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass TFStyleEncodeDecodeTest(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `_tf_style_*` decorators.\n\n  The class decorators, `tf_style_encoding_stage` and\n  `tf_style_adaptive_encoding_stage` are tested by the example implementations\n  of `EncodingStageInterface` and `AdaptiveEncodingStageInterface`, in\n  `test_utils.py`.\n  """"""\n\n  _DEFAULT_NAME = \'test_stage_name\'\n\n  def _get_mock_stage(self):\n    """"""Returns a mock stage with a name property.""""""\n    stage = mock.Mock()\n    type(stage).name = mock.PropertyMock(return_value=self._DEFAULT_NAME)\n    return stage\n\n  def _test_initial_state_fn(self):\n    """"""Returns decorated test `initial_state` method.""""""\n    return encoding_stage._tf_style_initial_state(\n        lambda _, name: {\'state\': tf.constant(1.0)})\n\n  def _test_update_state_fn(self):\n    """"""Returns decorated test `update_state` method.""""""\n    return encoding_stage._tf_style_update_state(\n        lambda _, s, sut, name: {\'state\': s[\'state\'] + sut[\'tensor\']})\n\n  def _test_get_params_fn(self):\n    """"""Returns decorated test `get_params` method.""""""\n    return encoding_stage._tf_style_get_params(\n        lambda _, name: ({\'param\': tf.constant(1.0)},) * 2)\n\n  def _test_adaptive_get_params_fn(self):\n    """"""Returns decorated test `get_params` method.""""""\n    return encoding_stage._tf_style_adaptive_get_params(\n        lambda _, state, name: ({\'param\': state[\'state\'] * 2.0},) * 2)\n\n  def _test_encode_fn(self):\n    """"""Returns decorated test `encode` method.""""""\n    return encoding_stage._tf_style_encode(lambda _, x, p, name: x + p[\'param\'])\n\n  def _test_decode_fn(self):\n    """"""Returns decorated test `decode` method.""""""\n    reshape_fn = lambda x, p, shape: tf.reshape(x[\'val\'] + p[\'param\'], shape)\n    return encoding_stage._tf_style_decode(\n        lambda _, x, p, num_summands, shape, name: reshape_fn(x, p, shape))\n\n  def _assert_all_graph_nodes_in_name_scope(self, graph, name):\n    """"""Asserts that names of all nodes in `graph` contain `name`.""""""\n    for node in graph.as_graph_def().node:\n      self.assertIn(name, node.name)\n\n  @parameterized.parameters(1.0, \'string\', object)\n  def test_tf_style_encoding_stage_raises(self, bad_stage):\n    with self.assertRaises(TypeError):\n      encoding_stage.tf_style_encoding_stage(bad_stage)\n\n  @parameterized.parameters(1.0, \'string\', object)\n  def test_tf_style_adaptive_encoding_stage_raises(self, bad_stage):\n    with self.assertRaises(TypeError):\n      encoding_stage.tf_style_adaptive_encoding_stage(bad_stage)\n\n  @parameterized.parameters(None, \'different_test_name_scope\')\n  def test_initial_state_decorator(self, name):\n    """"""Test initial_state decorator works as expected.""""""\n    test_initial_state_fn = self._test_initial_state_fn()\n    stage = self._get_mock_stage()\n    initial_state = self.evaluate(test_initial_state_fn(stage, name))\n\n    # The graph should contain a single node.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 1)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_initial_state\')\n    # The functionality is not modified.\n    self.assertEqual(1.0, initial_state[\'state\'])\n\n  @parameterized.parameters(None, \'different_test_name_scope\')\n  def test_update_state_decorator(self, name):\n    """"""Test initial_state decorator works as expected.""""""\n    test_update_state_fn = self._test_update_state_fn()\n    stage = self._get_mock_stage()\n    state = {\'state\': 1.0}\n    state_update_tensors = {\'tensor\': 2.0}\n    updated_state = self.evaluate(\n        test_update_state_fn(stage, state, state_update_tensors, name))\n\n    # The graph should contain three nodes. Two for the constants created, and\n    # one for their addition.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 3)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_update_state\')\n    # The functionality is not modified.\n    self.assertEqual(3.0, updated_state[\'state\'])\n\n  @parameterized.parameters(None, \'different_test_name_scope\')\n  def test_get_params_decorator(self, name):\n    """"""Test get_params decorator works as expected.""""""\n    test_get_params_fn = self._test_get_params_fn()\n    stage = self._get_mock_stage()\n    encode_params, decode_params = self.evaluate(\n        test_get_params_fn(stage, name))\n\n    # The graph should contain a single node.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 1)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_get_params\')\n    # The functionality is not modified.\n    self.assertEqual(1.0, encode_params[\'param\'])\n    self.assertEqual(1.0, decode_params[\'param\'])\n\n  @parameterized.parameters(None, \'different_test_name_scope\')\n  def test_adaptive_get_params_decorator(self, name):\n    """"""Test adaptive_get_params decorator works as expected.""""""\n    test_adaptive_get_params_fn = self._test_adaptive_get_params_fn()\n    stage = self._get_mock_stage()\n    state = {\'state\': 3.0}\n    encode_params, decode_params = self.evaluate(\n        test_adaptive_get_params_fn(stage, state, name))\n\n    # The graph should contain three nodes. Two for the constants created, and\n    # one for the multiplication to create the params.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 3)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_get_params\')\n    # The functionality is not modified.\n    self.assertEqual(6.0, encode_params[\'param\'])\n    self.assertEqual(6.0, decode_params[\'param\'])\n\n  @parameterized.parameters(None, \'different_test_variable_scope\')\n  def test_encode_decorator(self, name):\n    """"""Test encode decorator works as expected.""""""\n    test_encode_fn = self._test_encode_fn()\n    stage = self._get_mock_stage()\n    encoded_x = self.evaluate(test_encode_fn(stage, 2.5, {\'param\': 10.0}, name))\n\n    # The graph should contain three nodes. The two above Python constants\n    # converted to a Tensor object, and the resulting sum.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 3)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_encode\')\n    # The functionality (sum) is not modified.\n    self.assertEqual(12.5, encoded_x)\n\n  def test_encode_decorator_different_graphs(self):\n    """"""Input Tensors from different tf.Graph instances should raise an error.""""""\n    # The test method should not actually use the input values, to ensure the\n    # error is not raised in a different way.\n    test_encode_fn = encoding_stage._tf_style_encode(\n        lambda _, x, p, name: tf.constant(0.0))\n    stage = self._get_mock_stage()\n    graph_1, graph_2 = tf.Graph(), tf.Graph()\n    with graph_1.as_default():\n      x = tf.constant(2.5)\n    with graph_2.as_default():\n      params = {\'param\': tf.constant(10.0)}\n    with self.assertRaises(ValueError):\n      test_encode_fn(stage, x, params, None)\n\n  @parameterized.parameters(None, \'different_test_variable_scope\')\n  def test_decode_decorator(self, name):\n    """"""Test decode decorator works as expected.""""""\n    test_decode_fn = self._test_decode_fn()\n    stage = self._get_mock_stage()\n    decoded_x = self.evaluate(\n        test_decode_fn(stage,\n                       {\'val\': np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)},\n                       {\'param\': 1.0}, 1, [4], name))\n\n    # The graph should contain six nodes. The four above Python constants\n    # converted to a Tensor object, the subtraction, and the final reshape.\n    graph = tf.compat.v1.get_default_graph()\n    self.assertLen(graph.as_graph_def().node, 6)\n    if name is not None:\n      self._assert_all_graph_nodes_in_name_scope(graph, name)\n    else:\n      self._assert_all_graph_nodes_in_name_scope(\n          graph, self._DEFAULT_NAME + \'_decode\')\n    # The functionality (sum + reshape) is not modified.\n    self.assertAllEqual(np.array([2.0, 3.0, 4.0, 5.0]), decoded_x)\n\n  def test_decode_decorator_different_graphs(self):\n    """"""Input Tensors from different tf.Graph instances should raise an error.""""""\n    # The test method should not actually use the input values, to ensure the\n    # error is not raised in a different way.\n    test_decode_fn = encoding_stage._tf_style_decode(\n        lambda _, x, p, shape, name: tf.constant(0.0))\n    stage = self._get_mock_stage()\n    graph_1, graph_2 = tf.Graph(), tf.Graph()\n    with graph_1.as_default():\n      x = {\'val\': tf.constant(2.5)}\n    with graph_2.as_default():\n      params = {\'param\': tf.constant(10.0)}\n    with self.assertRaises(ValueError):\n      test_decode_fn(stage, x, params, [], None)\n\n\nclass NoneStateAdaptiveEncodingStageTest(tf.test.TestCase,\n                                         parameterized.TestCase):\n\n  def test_as_adaptive_encoding_stage(self):\n    """"""Tests correctness of the wrapped encoding stage.""""""\n    a_var = tf.compat.v1.get_variable(\'a\', initializer=2.0)\n    b_var = tf.compat.v1.get_variable(\'b\', initializer=3.0)\n    stage = test_utils.SimpleLinearEncodingStage(a_var, b_var)\n    wrapped_stage = encoding_stage.as_adaptive_encoding_stage(stage)\n    self.assertIsInstance(wrapped_stage,\n                          encoding_stage.AdaptiveEncodingStageInterface)\n\n    x = tf.constant(2.0)\n    state = wrapped_stage.initial_state()\n    encode_params, decode_params = wrapped_stage.get_params(state)\n    encoded_x, state_update_tensors = wrapped_stage.encode(x, encode_params)\n    updated_state = wrapped_stage.update_state(state, state_update_tensors)\n    decoded_x = wrapped_stage.decode(encoded_x, decode_params)\n\n    # Test that the added state functionality is empty.\n    self.assertDictEqual({}, state)\n    self.assertDictEqual({}, state_update_tensors)\n    self.assertDictEqual({}, updated_state)\n    self.assertDictEqual({}, wrapped_stage.state_update_aggregation_modes)\n    # Test that __getattr__ retrieves attributes of the wrapped stage.\n    self.assertIsInstance(wrapped_stage._a, tf.Variable)\n    self.assertIs(wrapped_stage._a, a_var)\n    self.assertIsInstance(wrapped_stage._b, tf.Variable)\n    self.assertIs(wrapped_stage._b, b_var)\n\n    # Test the functionality remain unchanged.\n    self.assertEqual(stage.name, wrapped_stage.name)\n    self.assertEqual(stage.compressible_tensors_keys,\n                     wrapped_stage.compressible_tensors_keys)\n    self.assertEqual(stage.commutes_with_sum, wrapped_stage.commutes_with_sum)\n    self.assertEqual(stage.decode_needs_input_shape,\n                     wrapped_stage.decode_needs_input_shape)\n\n    self.evaluate(tf.compat.v1.global_variables_initializer())\n    test_data = test_utils.TestData(*self.evaluate([x, encoded_x, decoded_x]))\n    self.assertEqual(2.0, test_data.x)\n    self.assertEqual(\n        7.0, test_data.encoded_x[\n            test_utils.SimpleLinearEncodingStage.ENCODED_VALUES_KEY])\n    self.assertEqual(2.0, test_data.decoded_x)\n\n  def test_as_adaptive_encoding_stage_identity(self):\n    """"""Tests that this acts as identity for an adaptive encoding stage.""""""\n    adaptive_stage = encoding_stage.NoneStateAdaptiveEncodingStage(\n        test_utils.PlusOneEncodingStage())\n    wrapped_stage = encoding_stage.as_adaptive_encoding_stage(adaptive_stage)\n    self.assertIs(adaptive_stage, wrapped_stage)\n\n  @parameterized.parameters(1.0, \'string\', object)\n  def test_as_adaptive_encoding_stage_raises(self, not_a_stage):\n    with self.assertRaises(TypeError):\n      encoding_stage.as_adaptive_encoding_stage(not_a_stage)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/gather_encoder.py,67,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base Encoder class for encoding in the ""many-to-one"" case.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\n_PARAMS = \'params\'\n_SHAPES = \'shapes\'\n_TENSORS = \'tensors\'\n\n\nclass GatherEncoder(object):\n  """"""A class for a gather-like operations with encoding.\n\n  This class provides functionality for encoding in the ""many-to-one"" case,\n  where multiple locations hold a `Tensor` of the same shape and dtype, and one\n  needs to compute their sum at a central location, while only encoded\n  representations are communicated between the locations.\n\n  An instance of `GatherEncoder` is capable of encoding only values of a shape\n  and dtype, as specified at construction time. For example, a separate\n  instance of this class should be used for encoding every `Variable` of a\n  model, as opposed to a single instance being reused for each `Variable`.\n\n  `GatherEncoder` exposes the state of the underlying encoder, and the user is\n  responsible for keeping track of the state in case the encoding should be\n  adaptive as part of an iterative process.\n\n  In the following illustration of a typical pattern of usage of this class, we\n  will refer to the ""one"" central location as `server` and the ""many"" locations\n  as `workers`. By `user`, we denote the parts that are the responsibility of\n  the user of this class -- for instance, the communication between the `server`\n  and `workers` might need to happen outside of TensorFlow, depending on the\n  target deployment.\n\n  1.  `[server]` Use the `initial_state` method to create an initial `state`.\n  2.  `[server]` Use the `get_params` method to derive `encode_params`,\n      `decode_before_sum_params` and `decode_after_sum_params` for the remaining\n      methods, based on the `state`.\n  3.  `[user]` Make the `encode_params` available to the `workers`.\n  4.  `[workers]` Use the `encode` method to get `encoded_x` and\n      `state_update_tensors`.\n  5.  `[user]` Make the `encoded_x` and `state_update_tensors` available to the\n      `server`.\n  6.  `[server]` Use the `decode_before_sum` method to partially decode all of\n      the `encoded_x` values.\n  7.  `[user]` Sum the partially decoded values.\n  8.  `[server]` Use the `decode_after_sum` method to finish decoding the summed\n      and partially decoded values.\n  9.  `[user]` Aggregate the `state_update_tensors` according to aggregation\n      modes declared by the `state_update_aggregation_modes` property.\n  10. `[server]` Use the `update_state` method to update the `state` based on\n      the existing `state` and aggregated `state_update_tensors`.\n\n  NOTE Step 5 could overlap with the steps 6--9, depending on the indended\n  deployment. For instnace, if communication is realized using a multi-tier\n  aggregation architecture, intermediary nodes would need to access\n  `decode_before_sum_params` and use the `decode_before_sum` method and sum the\n  part decoded representations. These would be then summed again at the\n  `server`, which would finish the decoding.\n\n  NOTE The use of the `state` is optional. It is needed only when the encoding\n  mechanism should adapt based on the values being encoded during an iterative\n  execution.\n  """"""\n\n  def __init__(self, tensorspec, commuting_structure,\n               state_update_aggregation_modes, initial_state_fn, get_params_fn,\n               encode_fn, decode_before_sum_fn, decode_after_sum_fn,\n               update_state_fn):\n    """"""Creates a `GatherEncoder` for encoding `tensorspec`-like values.\n\n    This class should not be instantiated directly. Instead, use the\n    provided `@classmethod`.\n\n    Args:\n      tensorspec: A `tf.TensorSpec`. The created `GatherEncoder` will be\n        constrained to only encode input values compatible with `tensorspec`.\n      commuting_structure: The commuting structure of the `GatherEncoder`.\n      state_update_aggregation_modes: The `StageAggregationMode` values to be\n        used to aggregate `state_update_tensors`\n      initial_state_fn: A `tf.function`.\n      get_params_fn: A `tf.function`.\n      encode_fn: A `tf.function`.\n      decode_before_sum_fn: A `tf.function`.\n      decode_after_sum_fn: A `tf.function`.\n      update_state_fn: A `tf.function`.\n\n    Returns:\n      A `GatherEncoder`.\n    """"""\n    self._tensorspec = tensorspec\n    self._commuting_structure = commuting_structure\n    self._state_update_aggregation_modes = state_update_aggregation_modes\n\n    self._initial_state_fn = initial_state_fn\n    self._get_params_fn = get_params_fn\n    self._encode_fn = encode_fn\n    self._decode_before_sum_fn = decode_before_sum_fn\n    self._decode_after_sum_fn = decode_after_sum_fn\n    self._update_state_fn = update_state_fn\n\n  @classmethod\n  def from_encoder(cls, encoder, tensorspec):\n    """"""Creates a `GatherEncoder` for encoding `tensorspec`-like values.\n\n    This method instantiates `GatherEncoder`, wrapping the functionality of\n    `encoder` and exposing necessary logic for encoding values compatible with\n    `tensorspec`. Note that the returned encoder will not accept inputs of other\n    properties.\n\n    Args:\n      encoder: An `Encoder` object to be used for encoding.\n      tensorspec: A `tf.TensorSpec`. The created `GatherEncoder` will be\n        constrained to only encode input values compatible with `tensorspec`.\n\n    Returns:\n      A `GatherEncoder`.\n\n    Raises:\n      TypeError:\n        If `encoder` is not an `Encoder` or `tensorspec` is not a\n        `tf.TensorSpec`.\n    """"""\n    if not isinstance(encoder, core_encoder.Encoder):\n      raise TypeError(\'The encoder must be an instance of `Encoder`.\')\n    if not isinstance(tensorspec, tf.TensorSpec):\n      raise TypeError(\'The tensorspec must be a tf.TensorSpec.\')\n    if not tensorspec.shape.is_fully_defined():\n      raise TypeError(\'The shape of provided tensorspec must be fully defined.\')\n\n    tensorspec = tensorspec\n    commuting_structure = encoder.commuting_structure\n    state_update_aggregation_modes = tf.nest.flatten(\n        encoder.state_update_aggregation_modes)\n\n    # The following dictionaries are used to carry information known statically\n    # during exectuion of the Python code (i.e., not the resulting TensorFlow\n    # computation) between the `tf.function`s created below.\n    #\n    # The motivation behind this pattern is the following.\n    #\n    # The implementers of the `EncodingStageInterface` should not need to worry\n    # about distinction between Python and TF values, when declaring certain\n    # parameters. For instance, the number of quantization bits, can be both a\n    # TenrosFlow value and a Python integer, and they should not need to be\n    # handled differently by the implementer.\n    #\n    # However, for the user of the `GatherEncoder`, we only want to expose\n    # values that are actually necessary to be handled outside of this tool.\n    # That means, only the TF values. We quietly carry the Python values around\n    # - in the internal_structure and internal_py_values dictionaries - and\n    # place them at appropriate places at graph building time.\n    #\n    # As a consequence, it is impossible to statically determine the user-facing\n    # signature of encode and decode methods, before we actually execute the\n    # `get_params` method - the TF structure can depend on internal\n    # configuration of the implementations of the `EncodingStageInterface`.\n    #\n    # A similar problem is we can\'t determine the signature of the decode\n    # methods, before executing the encode method, because some implementations\n    # of `EncodingStageInterface` need the original input_shape as an input to\n    # their respective `decode` method. Hence, the user facing signature can\n    # differ based on whether the shape is statically known or not. This\n    # difference, again, can\'t be statically determined, without executing the\n    # part of the relevant encoding tree above a given stage.\n    #\n    # The resulting complexity is of the good type, because either type of users\n    # of the tensor_encoding tool do not even need to be aware of it. This\n    # argument is well supported for instance in the book of John Ousterhout,\n    # ""A Philosophy of Software Design"".\n    internal_structure = {}\n    internal_py_values = {}\n\n    def _add_to_structure(key, value):\n      if key not in internal_structure:\n        internal_structure[key] = tf.nest.map_structure(lambda _: None, value)\n\n    def _add_to_py_values(key, value):\n      if key not in internal_py_values:\n        internal_py_values[key] = value\n\n    @tf.function\n    def initial_state_fn():\n      """"""See the `initial_state` method of this class.""""""\n      state = encoder.initial_state()\n      _add_to_structure(\'state\', state)\n      return tuple(tf.nest.flatten(state))\n\n    state = initial_state_fn()\n    flat_state_spec = tf.nest.map_structure(tf.TensorSpec.from_tensor, state)\n\n    @tf.function\n    def get_params_fn(flat_state):\n      """"""See the `get_params` method of this class.""""""\n      py_utils.assert_compatible(flat_state_spec, flat_state)\n      state = tf.nest.pack_sequence_as(internal_structure[\'state\'], flat_state)\n\n      encode_params, decode_params = encoder.get_params(state)\n      decode_before_sum_params, decode_after_sum_params = (\n          core_encoder.split_params_by_commuting_structure(\n              decode_params, commuting_structure))\n\n      # Get the portion of input_shapes that will be relevant in the\n      # decode_after_sum method and fold it into the params exposed to user.\n      _, _, input_shapes = encoder.encode(\n          tf.zeros(tensorspec.shape, tensorspec.dtype), encode_params)\n      _, input_shapes_after_sum = (\n          core_encoder.split_shapes_by_commuting_structure(\n              input_shapes, commuting_structure))\n      decode_after_sum_params = {\n          _PARAMS: decode_after_sum_params,\n          _SHAPES: input_shapes_after_sum\n      }\n\n      encode_params_py, encode_params_tf = py_utils.split_dict_py_tf(\n          encode_params)\n      decode_before_sum_params_py, decode_before_sum_params_tf = (\n          py_utils.split_dict_py_tf(decode_before_sum_params))\n      decode_after_sum_params_py, decode_after_sum_params_tf = (\n          py_utils.split_dict_py_tf(decode_after_sum_params))\n\n      _add_to_structure(\'encode_params\', encode_params_tf)\n      _add_to_structure(\'decode_before_sum_params\', decode_before_sum_params_tf)\n      _add_to_structure(\'decode_after_sum_params\', decode_after_sum_params_tf)\n      _add_to_py_values(\'encode_params\', encode_params_py)\n      _add_to_py_values(\'decode_before_sum_params\', decode_before_sum_params_py)\n      _add_to_py_values(\'decode_after_sum_params\', decode_after_sum_params_py)\n\n      return (tuple(tf.nest.flatten(encode_params_tf)),\n              tuple(tf.nest.flatten(decode_before_sum_params_tf)),\n              tuple(tf.nest.flatten(decode_after_sum_params_tf)))\n\n    encode_params, decode_before_sum_params, decode_after_sum_params = (\n        get_params_fn(state))\n    encode_params_spec = tf.nest.map_structure(tf.TensorSpec.from_tensor,\n                                               encode_params)\n    decode_before_sum_params_spec = tf.nest.map_structure(\n        tf.TensorSpec.from_tensor, decode_before_sum_params)\n    decode_after_sum_params_spec = tf.nest.map_structure(\n        tf.TensorSpec.from_tensor, decode_after_sum_params)\n\n    @tf.function\n    def encode_fn(x, params):\n      """"""See the `encode` method of this class.""""""\n      if not tensorspec.is_compatible_with(x):\n        raise ValueError(\n            \'The provided x is not compatible with the expected tensorspec.\')\n      py_utils.assert_compatible(encode_params_spec, params)\n\n      params = py_utils.merge_dicts(\n          tf.nest.pack_sequence_as(internal_structure[\'encode_params\'], params),\n          internal_py_values[\'encode_params\'])\n      encoded_x, state_update_tensors, input_shapes = encoder.encode(x, params)\n      input_shapes_before_sum, _ = (\n          core_encoder.split_shapes_by_commuting_structure(\n              input_shapes, commuting_structure))\n\n      encoded_structure = {\n          _TENSORS: encoded_x,\n          _SHAPES: input_shapes_before_sum\n      }\n      encoded_structure_py, encoded_structure_tf = py_utils.split_dict_py_tf(\n          encoded_structure)\n\n      _add_to_structure(\'encoded_structure\', encoded_structure_tf)\n      _add_to_structure(\'state_update_tensors\', state_update_tensors)\n      _add_to_py_values(\'encoded_structure\', encoded_structure_py)\n\n      return (dict(\n          py_utils.flatten_with_joined_string_paths(encoded_structure_tf)),\n              tuple(tf.nest.flatten(state_update_tensors)))\n\n    encoded_structure, state_update_tensors = encode_fn(\n        tf.zeros(tensorspec.shape, tensorspec.dtype), encode_params)\n    encoded_structure_spec = tf.nest.map_structure(tf.TensorSpec.from_tensor,\n                                                   encoded_structure)\n\n    @tf.function\n    def decode_before_sum_fn(encoded_structure, params):\n      """"""See the `decode_before_sum` method of this class.""""""\n      py_utils.assert_compatible(encoded_structure_spec, encoded_structure)\n      py_utils.assert_compatible(decode_before_sum_params_spec, params)\n\n      encoded_structure = py_utils.merge_dicts(\n          tf.nest.pack_sequence_as(internal_structure[\'encoded_structure\'],\n                                   tf.nest.flatten(encoded_structure)),\n          internal_py_values[\'encoded_structure\'])\n      params = py_utils.merge_dicts(\n          tf.nest.pack_sequence_as(\n              internal_structure[\'decode_before_sum_params\'], params),\n          internal_py_values[\'decode_before_sum_params\'])\n\n      encoded_tensors = encoded_structure[_TENSORS]\n      input_shapes = encoded_structure[_SHAPES]\n      part_decoded_structure = encoder.decode_before_sum(\n          encoded_tensors, params, input_shapes)\n\n      _add_to_structure(\'part_decoded_structure\', part_decoded_structure)\n      if isinstance(part_decoded_structure, dict):\n        return dict(\n            py_utils.flatten_with_joined_string_paths(part_decoded_structure))\n      else:\n        return part_decoded_structure\n\n    part_decoded_structure = decode_before_sum_fn(encoded_structure,\n                                                  decode_before_sum_params)\n    part_decoded_structure_spec = tf.nest.map_structure(\n        tf.TensorSpec.from_tensor, part_decoded_structure)\n\n    @tf.function\n    def decode_after_sum_fn(part_decoded_structure, params, num_summands):\n      """"""See the `decode_after_sum` method of this class.""""""\n      py_utils.assert_compatible(part_decoded_structure_spec,\n                                 part_decoded_structure)\n      py_utils.assert_compatible(decode_after_sum_params_spec, params)\n\n      part_decoded_structure = tf.nest.pack_sequence_as(\n          internal_structure[\'part_decoded_structure\'],\n          tf.nest.flatten(part_decoded_structure))\n      params = py_utils.merge_dicts(\n          tf.nest.pack_sequence_as(\n              internal_structure[\'decode_after_sum_params\'], params),\n          internal_py_values[\'decode_after_sum_params\'])\n      actual_params = params[_PARAMS]\n      shapes = params[_SHAPES]\n      decoded_x = encoder.decode_after_sum(part_decoded_structure,\n                                           actual_params, num_summands, shapes)\n      return decoded_x\n\n    decoded_x = decode_after_sum_fn(part_decoded_structure,\n                                    decode_after_sum_params, 1)\n    assert tensorspec.is_compatible_with(decoded_x)\n\n    @tf.function\n    def update_state_fn(flat_state, state_update_tensors):\n      """"""See the `update_state` method of this class.""""""\n      py_utils.assert_compatible(flat_state_spec, flat_state)\n      state = tf.nest.pack_sequence_as(internal_structure[\'state\'], flat_state)\n      state_update_tensors = tf.nest.pack_sequence_as(\n          internal_structure[\'state_update_tensors\'], state_update_tensors)\n      updated_state = encoder.update_state(state, state_update_tensors)\n      return tuple(tf.nest.flatten(updated_state))\n\n    # Ensures the update_state_fn is traced during initialization.\n    updated_state = update_state_fn(state, state_update_tensors)\n    tf.nest.assert_same_structure(state, updated_state)\n\n    return cls(tensorspec, commuting_structure, state_update_aggregation_modes,\n               initial_state_fn, get_params_fn, encode_fn, decode_before_sum_fn,\n               decode_after_sum_fn, update_state_fn)\n\n  @property\n  def input_tensorspec(self):\n    """"""Returns `tf.TensorSpec` describing input expected by `GatherEncoder`.""""""\n    return self._tensorspec\n\n  @property\n  def fully_commutes_with_sum(self):\n    # If any element is not True, the whole thing does not fully commute.\n    return sum(tf.nest.flatten(self._commuting_structure))\n\n  @property\n  def state_update_aggregation_modes(self):\n    """"""Returns `state_update_aggregation_modes` of the underlying `Encoder`.""""""\n    return self._state_update_aggregation_modes\n\n  def initial_state(self, name=None):\n    """"""Returns the initial state.\n\n    Args:\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple of `Tensor` values, representing the initial state.\n    """"""\n    with tf.compat.v1.name_scope(name, \'gather_encoder_initial_state\'):\n      return self._initial_state_fn()\n\n  def get_params(self, state=None, name=None):\n    """"""Returns parameters controlling the behavior of the `GatherEncoder`.\n\n    If `state` is not provided, the return value of the `initial_state` method\n    will be used.\n\n    Args:\n      state: The (optional) current state. A tuple, matching the structure\n        returned by the `initial_state` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple `(encode_params, decode_before_sum_params,\n      decode_after_sum_params)`, where all of these are tuples of `Tensor`\n      values, expected as inputs to the `encode`, `decode_before_sum` and\n      `decode_after_sum` methods, respectively.\n\n    Raises:\n      ValueError:\n        If `state` is not `None` and does not have the same structure as the\n        return value of the `initial_state` method.\n    """"""\n    if state is None:\n      state = self.initial_state()\n    with tf.compat.v1.name_scope(name, \'gather_encoder_get_params\',\n                                 list(state)):\n      state = tf.nest.map_structure(tf.convert_to_tensor, state)\n      return self._get_params_fn(state)\n\n  def encode(self, x, encode_params, name=None):\n    """"""Encodes the provided input.\n\n    Args:\n      x: A `Tensor` to be encoded.\n      encode_params: Parameters controlling the encoding. A tuple, matching the\n        corresponding structure returned by the `get_params` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A `(encoded_x, state_update_tensors)` tuple, where `encoded_x` is a\n      dictionary of `Tensor` values representing the encoded `x`, and\n      `state_update_tensors` is a tuple of `Tensor` values, which are expected\n      to be aggregated according to modes provided by the\n      `state_update_aggregation_modes` property, and afterwards passed to the\n      `update_state` method.\n\n    Raises:\n      ValueError:\n        If `x` does not have the expected shape or dtype, or if `encode_params`\n        does not have the same structure as corresponding return value of the\n        `get_params` method.\n    """"""\n    values = [x] + list(encode_params)\n    with tf.compat.v1.name_scope(name, \'gather_encoder_encode\', values):\n      x = tf.convert_to_tensor(x)\n      encode_params = tf.nest.map_structure(tf.convert_to_tensor, encode_params)\n      return self._encode_fn(x, encode_params)\n\n  def decode_before_sum(self, encoded_x, decode_before_sum_params, name=None):\n    """"""Decodes encoded value, up to the point which commutes with sum.\n\n    Args:\n      encoded_x: A dictionary of `Tensor` values to be decoded. Must be of the\n        same structure as the `encoded_x` returned by the `encode` method.\n      decode_before_sum_params: Parameters controlling the decoding. A tuple,\n        matching the corresponding structure returned by the `get_params`\n        method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A part-decoded structure, which is expected to be summed before being\n      passed to the `decode_after_sum` method. If no part of the underlying\n      `Encoder` commutes with sum, this is a `Tensor`. If the `Encoder`\n      partially or fully commutes with sum, this is a dictionary of `Tensor`\n      values.\n\n    Raises:\n      ValueError:\n        If `encoded_x` does not have the same structure as corresponding return\n        value of the `encode` method, or if `decode_before_sum_params` does not\n        have the same structure as corresponding return value of the\n        `get_params` method.\n    """"""\n    values = list(encoded_x.values()) + list(decode_before_sum_params)\n    with tf.compat.v1.name_scope(name, \'gather_encoder_decode_before_sum\',\n                                 values):\n      encoded_x = tf.nest.map_structure(tf.convert_to_tensor, encoded_x)\n      decode_before_sum_params = tf.nest.map_structure(\n          tf.convert_to_tensor, decode_before_sum_params)\n      return self._decode_before_sum_fn(encoded_x, decode_before_sum_params)\n\n  def decode_after_sum(self,\n                       part_decoded_x,\n                       decode_after_sum_params,\n                       num_summands,\n                       name=None):\n    """"""Finishes decoding of encoded value, after summing part-decoded values.\n\n    Args:\n      part_decoded_x: A dictionary of `Tensor` values to be decoded. Must be of\n        the same structure as the `encoded_x` returned by the `encode` method.\n      decode_after_sum_params: Parameters controlling the decoding. A tuple,\n        matching the corresponding structure returned by the `get_params`\n        method.\n      num_summands: A `Tensor` representing the number of `part_decoded_x`\n        values summed before passed into this method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A single `Tensor` of the same shape and dtype as the original input to the\n      `encode` method.\n\n    Raises:\n      ValueError:\n        If `part_decoded_x` does not have the same structure as the return value\n        of the `decode_before_sum` method, or if `decode_after_sum_params` does\n        not have the same structure as corresponding return value of the\n        `get_params` method.\n    """"""\n    values = list(part_decoded_x.values()) if isinstance(\n        part_decoded_x, dict) else [part_decoded_x]\n    values = (values + list(decode_after_sum_params) + [num_summands])\n    with tf.compat.v1.name_scope(name, \'gather_encoder_decode_after_sum\',\n                                 values):\n      part_decoded_x = tf.nest.map_structure(tf.convert_to_tensor,\n                                             part_decoded_x)\n      decode_after_sum_params = tf.nest.map_structure(tf.convert_to_tensor,\n                                                      decode_after_sum_params)\n      num_summands = tf.convert_to_tensor(num_summands)\n      return self._decode_after_sum_fn(part_decoded_x, decode_after_sum_params,\n                                       num_summands)\n\n  def update_state(self, state, state_update_tensors, name=None):\n    """"""Updates the state of the `GatherEncoder`.\n\n    Args:\n      state: The (optional) current state. A tuple, matching the structure\n        returned by the `initial_state` method.\n      state_update_tensors: A tuple of `Tensor` values returned by the `encode`\n        method, aggregated according to modes provided by the\n        `state_update_aggregation_modes` property. Note that the tuple has the\n        same structure, but the `Tensor` values it contains do not necessarily\n        have the same shapes.\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple of `Tensor` values of the same structure as `state`, representing\n      the updated state.\n\n    Raises:\n      ValueError:\n        If `state` is not `None` and does not have the same structure as the\n        return value of the `initial_state` method.\n    """"""\n    values = list(state) + list(state_update_tensors)\n    with tf.compat.v1.name_scope(name, \'gather_encoder_update_state\', values):\n      state = tf.nest.map_structure(tf.convert_to_tensor, state)\n      state_update_tensors = tf.nest.map_structure(tf.convert_to_tensor,\n                                                   state_update_tensors)\n      return self._update_state_fn(state, state_update_tensors)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/gather_encoder_test.py,36,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\n# TODO(b/139939526): Move to public API.\nfrom tensorflow.python.framework import test_util as tf_test_util\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import gather_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n# Abbreviated constants used in tests.\nTENSORS = gather_encoder._TENSORS\n\nP1_VALS = test_utils.PlusOneEncodingStage.ENCODED_VALUES_KEY\nT2_VALS = test_utils.TimesTwoEncodingStage.ENCODED_VALUES_KEY\nSL_VALS = test_utils.SimpleLinearEncodingStage.ENCODED_VALUES_KEY\nSIF_SIGNS = test_utils.SignIntFloatEncodingStage.ENCODED_SIGNS_KEY\nSIF_INTS = test_utils.SignIntFloatEncodingStage.ENCODED_INTS_KEY\nSIF_FLOATS = test_utils.SignIntFloatEncodingStage.ENCODED_FLOATS_KEY\nPN_VALS = test_utils.PlusOneOverNEncodingStage.ENCODED_VALUES_KEY\n\n\nclass GatherEncoderTest(tf.test.TestCase, parameterized.TestCase):\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_basic_encode_decode(self):\n    """"""Tests basic encoding and decoding works as expected.""""""\n    x_fn = lambda: tf.random.uniform((12,))\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x_fn()))\n\n    num_summands = 3\n    iteration = _make_iteration_function(encoder, x_fn, num_summands)\n    state = encoder.initial_state()\n\n    for i in range(1, 5):\n      data = self.evaluate(iteration(state))\n      for j in range(num_summands):\n        self.assertAllClose(\n            data.x[j] + 1 / i,\n            _encoded_x_field(data.encoded_x[j], [TENSORS, PN_VALS]))\n      self.assertEqual((i,), data.initial_state)\n      self.assertEqual((i + 1,), data.updated_state)\n      state = data.updated_state\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_composite_encoder(self):\n    """"""Tests functionality with a general, composite `Encoder`.""""""\n    x_fn = lambda: tf.constant(1.2)\n    encoder = core_encoder.EncoderComposer(\n        test_utils.SignIntFloatEncodingStage())\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_SIGNS)\n    encoder.add_child(test_utils.PlusOneEncodingStage(), SIF_INTS)\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_FLOATS).add_child(\n        test_utils.PlusOneOverNEncodingStage(), T2_VALS)\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        encoder.make(), tf.TensorSpec.from_tensor(x_fn()))\n\n    num_summands = 3\n    iteration = _make_iteration_function(encoder, x_fn, num_summands)\n    state = encoder.initial_state()\n\n    for i in range(1, 5):\n      data = self.evaluate(iteration(state))\n      for j in range(num_summands):\n        self.assertAllClose(\n            2.0,\n            _encoded_x_field(data.encoded_x[j], [TENSORS, SIF_SIGNS, T2_VALS]))\n        self.assertAllClose(\n            2.0,\n            _encoded_x_field(data.encoded_x[j], [TENSORS, SIF_INTS, P1_VALS]))\n        self.assertAllClose(\n            0.4 + 1 / i,\n            _encoded_x_field(data.encoded_x[j],\n                             [TENSORS, SIF_FLOATS, T2_VALS, PN_VALS]))\n        self.assertAllClose(data.x[j], data.part_decoded_x[j])\n        self.assertAllClose(data.x[j] * num_summands,\n                            data.summed_part_decoded_x)\n        self.assertAllClose(data.x[j] * num_summands, data.decoded_x)\n\n      self.assertEqual((i,), data.initial_state)\n      self.assertEqual((i + 1,), data.updated_state)\n      state = data.updated_state\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_none_state_equal_to_initial_state(self):\n    """"""Tests that not providing state is the same as initial_state.""""""\n    x_fn = lambda: tf.constant(1.0)\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x_fn()))\n\n    num_summands = 3\n    stateful_iteration = _make_iteration_function(encoder, x_fn, num_summands)\n    state = encoder.initial_state()\n    stateless_iteration = _make_stateless_iteration_function(\n        encoder, x_fn, num_summands)\n\n    stateful_data = self.evaluate(stateful_iteration(state))\n    stateless_data = self.evaluate(stateless_iteration())\n\n    self.assertAllClose(stateful_data.encoded_x, stateless_data.encoded_x)\n    self.assertAllClose(stateful_data.decoded_x, stateless_data.decoded_x)\n\n  def test_python_constants_not_exposed(self):\n    """"""Tests that only TensorFlow values are exposed to users.""""""\n    x_fn = lambda: tf.constant(1.0)\n    tensorspec = tf.TensorSpec.from_tensor(x_fn())\n    encoder_py = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.SimpleLinearEncodingStage(2.0, 3.0)).add_parent(\n                test_utils.PlusOneEncodingStage(), P1_VALS).add_parent(\n                    test_utils.SimpleLinearEncodingStage(2.0, 3.0),\n                    SL_VALS).make(), tensorspec)\n    a_var = tf.compat.v1.get_variable(\'a_var\', initializer=2.0)\n    b_var = tf.compat.v1.get_variable(\'b_var\', initializer=3.0)\n    encoder_tf = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.SimpleLinearEncodingStage(a_var, b_var)).add_parent(\n                test_utils.PlusOneEncodingStage(), P1_VALS).add_parent(\n                    test_utils.SimpleLinearEncodingStage(a_var, b_var),\n                    SL_VALS).make(), tensorspec)\n\n    (encode_params_py, decode_before_sum_params_py,\n     decode_after_sum_params_py) = encoder_py.get_params()\n    (encode_params_tf, decode_before_sum_params_tf,\n     decode_after_sum_params_tf) = encoder_tf.get_params()\n\n    # Params that are Python constants -- not tf.Tensors -- should be hidden\n    # from the user, and made statically available at appropriate locations.\n    self.assertLen(encode_params_py, 1)\n    self.assertLen(encode_params_tf, 5)\n    self.assertLen(decode_before_sum_params_py, 1)\n    self.assertLen(decode_before_sum_params_tf, 3)\n    self.assertEmpty(decode_after_sum_params_py)\n    self.assertLen(decode_after_sum_params_tf, 2)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_decode_needs_input_shape(self):\n    """"""Tests that mechanism for passing input shape works.""""""\n    x_fn = lambda: tf.reshape(list(range(15)), [3, 5])\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.ReduceMeanEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x_fn()))\n\n    iteration = _make_iteration_function(encoder, x_fn, 1)\n    data = self.evaluate(iteration(encoder.initial_state()))\n    self.assertAllEqual([[7.0] * 5] * 3, data.decoded_x)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_commutativity_with_sum(self):\n    """"""Tests that encoder that commutes with sum works.""""""\n    x_fn = lambda: tf.constant([1.0, 3.0])\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x_fn()))\n\n    for num_summands in [1, 3, 7]:\n      iteration = _make_iteration_function(encoder, x_fn, num_summands)\n      data = self.evaluate(iteration(encoder.initial_state()))\n      for i in range(num_summands):\n        self.assertAllClose([1.0, 3.0], data.x[i])\n        self.assertAllClose(\n            [2.0, 6.0], _encoded_x_field(data.encoded_x[i], [TENSORS, T2_VALS]))\n        self.assertAllClose(list(data.part_decoded_x[i].values())[0],\n                            list(data.encoded_x[i].values())[0])\n      self.assertAllClose(np.array([2.0, 6.0]) * num_summands,\n                          list(data.summed_part_decoded_x.values())[0])\n      self.assertAllClose(np.array([1.0, 3.0]) * num_summands, data.decoded_x)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_full_commutativity_with_sum(self):\n    """"""Tests that fully commutes with sum property works.""""""\n    spec = tf.TensorSpec((2,), tf.float32)\n\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(test_utils.TimesTwoEncodingStage()).make(),\n        spec)\n    self.assertTrue(encoder.fully_commutes_with_sum)\n\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.TimesTwoEncodingStage()).add_parent(\n                test_utils.TimesTwoEncodingStage(), T2_VALS).make(), spec)\n    self.assertTrue(encoder.fully_commutes_with_sum)\n\n    encoder = core_encoder.EncoderComposer(\n        test_utils.SignIntFloatEncodingStage())\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_SIGNS)\n    encoder.add_child(test_utils.PlusOneEncodingStage(), SIF_INTS)\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_FLOATS).add_child(\n        test_utils.PlusOneOverNEncodingStage(), T2_VALS)\n    encoder = gather_encoder.GatherEncoder.from_encoder(encoder.make(), spec)\n    self.assertFalse(encoder.fully_commutes_with_sum)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_state_aggregation_modes(self):\n    """"""Tests that all state updates tensors can be aggregated.""""""\n    x_fn = lambda: tf.random.uniform((5,))\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.StateUpdateTensorsEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x_fn()))\n\n    iteration = _make_iteration_function(encoder, x_fn, 3)\n    data = self.evaluate(iteration(encoder.initial_state()))\n\n    expected_sum = np.sum(data.x)\n    expected_min = np.amin(data.x)\n    expected_max = np.amax(data.x)\n    expected_stack_values = 15  # 3 values of shape 5.\n    expected_state = [\n        expected_sum, expected_min, expected_max, expected_stack_values\n    ]\n    # We are not in control of ordering of the elements in state tuple.\n    self.assertAllClose(sorted(expected_state), sorted(data.updated_state))\n\n  def test_input_tensorspec(self):\n    """"""Tests input_tensorspec property.""""""\n    x = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n    encoder = gather_encoder.GatherEncoder.from_encoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n    self.assertTrue(encoder.input_tensorspec.is_compatible_with(x))\n\n  def test_not_fully_defined_shape_raises(self):\n    """"""Tests tensorspec without fully defined shape.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneOverNEncodingStage()).make()\n    with self.assertRaisesRegex(TypeError, \'fully defined\'):\n      gather_encoder.GatherEncoder.from_encoder(\n          encoder, tf.TensorSpec((None,), tf.float32))\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_not_an_encoder_raises(self, not_an_encoder):\n    """"""Tests invalid type encoder argument.""""""\n    tensorspec = tf.TensorSpec((1,), tf.float32)\n    with self.assertRaisesRegex(TypeError, \'Encoder\'):\n      gather_encoder.GatherEncoder.from_encoder(not_an_encoder, tensorspec)\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_not_a_tensorspec_raises(self, not_a_tensorspec):\n    """"""Tests invalid type of tensorspec argument.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneOverNEncodingStage()).make()\n    with self.assertRaisesRegex(TypeError, \'TensorSpec\'):\n      gather_encoder.GatherEncoder.from_encoder(encoder, not_a_tensorspec)\n\n\nTestData = collections.namedtuple(\'TestData\', [\n    \'x\',\n    \'encoded_x\',\n    \'part_decoded_x\',\n    \'summed_part_decoded_x\',\n    \'decoded_x\',\n    \'initial_state\',\n    \'updated_state\',\n])\n\n\ndef _make_iteration_function(encoder, x_fn, num_summands):\n  """"""Returns a tf.function utility for testing.""""""\n\n  assert isinstance(encoder, gather_encoder.GatherEncoder)\n\n  @tf.function\n  def iteration(initial_state):\n    x = []\n    encoded_x = []\n    part_decoded_x = []\n    state_update_tensors = []\n\n    encode_params, decode_before_sum_params, decode_after_sum_params = (\n        encoder.get_params(initial_state))\n    for _ in range(num_summands):\n      x_value = x_fn()\n      enc_x, sut = encoder.encode(x_value, encode_params)\n      part_dec_x = encoder.decode_before_sum(enc_x, decode_before_sum_params)\n      x.append(x_value)\n      encoded_x.append(enc_x)\n      part_decoded_x.append(part_dec_x)\n      state_update_tensors.append(sut)\n\n    summed_part_decoded_x = part_decoded_x[0]\n    for addend in part_decoded_x[1:]:\n      summed_part_decoded_x = tf.nest.map_structure(lambda x, y: x + y,\n                                                    summed_part_decoded_x,\n                                                    addend)\n\n    decoded_x = encoder.decode_after_sum(summed_part_decoded_x,\n                                         decode_after_sum_params, num_summands)\n\n    aggregated_state_update_tensors = _aggregate_structure(\n        state_update_tensors, encoder.state_update_aggregation_modes)\n    updated_state = encoder.update_state(initial_state,\n                                         aggregated_state_update_tensors)\n    return TestData(x, encoded_x, part_decoded_x, summed_part_decoded_x,\n                    decoded_x, initial_state, updated_state)\n\n  return iteration\n\n\ndef _make_stateless_iteration_function(encoder, x_fn, num_summands):\n  """"""Returns a tf.function utility for testing, which does not use state.""""""\n\n  assert isinstance(encoder, gather_encoder.GatherEncoder)\n\n  @tf.function\n  def iteration():\n    x = []\n    encoded_x = []\n    part_decoded_x = []\n\n    encode_params, decode_before_sum_params, decode_after_sum_params = (\n        encoder.get_params())\n    for _ in range(num_summands):\n      x_value = x_fn()\n      enc_x, _ = encoder.encode(x_value, encode_params)\n      part_dec_x = encoder.decode_before_sum(enc_x, decode_before_sum_params)\n      x.append(x_value)\n      encoded_x.append(enc_x)\n      part_decoded_x.append(part_dec_x)\n\n    summed_part_decoded_x = part_decoded_x[0]\n    for addend in part_decoded_x[1:]:\n      summed_part_decoded_x = tf.nest.map_structure(lambda x, y: x + y,\n                                                    summed_part_decoded_x,\n                                                    addend)\n\n    decoded_x = encoder.decode_after_sum(summed_part_decoded_x,\n                                         decode_after_sum_params, num_summands)\n\n    dummy = tf.constant(0.0)  # Avoids having to separate TF/PY values.\n    return TestData(x, encoded_x, part_decoded_x, summed_part_decoded_x,\n                    decoded_x, dummy, dummy)\n\n  return iteration\n\n\ndef _aggregate_one(values, mode):\n  if mode == encoding_stage.StateAggregationMode.SUM:\n    return tf.reduce_sum(tf.stack(values), axis=0)\n  elif mode == encoding_stage.StateAggregationMode.MIN:\n    return tf.reduce_min(tf.stack(values), axis=0)\n  elif mode == encoding_stage.StateAggregationMode.MAX:\n    return tf.reduce_max(tf.stack(values), axis=0)\n  elif mode == encoding_stage.StateAggregationMode.STACK:\n    return tf.stack(values)\n\n\ndef _aggregate_structure(state_update_tensors, state_update_aggregation_modes):\n  aggregated_state_update_tensors = []\n  for i, mode in enumerate(state_update_aggregation_modes):\n    values = [t[i] for t in state_update_tensors]\n    aggregated_state_update_tensors.append(_aggregate_one(values, mode))\n  return tuple(aggregated_state_update_tensors)\n\n\ndef _encoded_x_field(encoded_x, path):\n  """"""Returns a field from `encoded_x` returned by the `encode` method.\n\n  In order to test the correctness of encoding, we also need to access the\n  encoded objects, which in turns depends on an implementation detail (the\n  specific use of `nest.flatten_with_joined_string_paths`). This dependence is\n  constrained to a single place in this utility.\n\n  Args:\n    encoded_x: The structure returned by the `encode` method.\n    path: A list of keys corresponding to the path in the nested dictionary\n      before it was flattened.\n\n  Returns:\n    A value from `encoded_x` corresponding to the `path`.\n  """"""\n  return encoded_x[\'/\'.join(path)]\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/simple_encoder.py,23,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base Encoder class for encoding in the ""one-to-many"" case.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\n_TENSORS = \'encoded_tensors\'\n_PARAMS = \'params\'\n_SHAPES = \'shapes\'\n\n\nclass SimpleEncoder(object):\n  """"""A simple class for encoding.\n\n  This class provides functionality for encoding in the ""one-to-many"" case,\n  where a `Tensor` is encoded in one location, and is to be decoded at\n  potentially many other locations, leaving the communication between encoding\n  and decoding up to the user.\n\n  An instance of `SimpleEncoder` is capable of encoding only values of a shape\n  and dtype, as specified at construction time. For example, an separate\n  instance of this class should be used for encoding every `Variable` of a\n  model, as opposed to a single instance being reused for each `Variable`.\n\n  `SimpleEncoder` exposes the state of the underlying encoder, and the user is\n  responsible for keeping track of the state in case the encoding should be\n  adaptive as part of an iterative process. If state is not needed, it can be\n  simply ignored when calling the `encode` method.\n  """"""\n\n  def __init__(self, encoder, tensorspec):\n    """"""Creates a `SimpleEncoder` for encoding `tensorspec`-like values.\n\n    This method instantiates `SimpleEncoder`, wrapping the functionality of\n    `encoder` and exposing necessary logic for encoding values compatible with\n    `tensorspec`. Note that the returned encoder will not accept inputs of other\n    properties.\n\n    Args:\n      encoder: An `Encoder` object to be used for encoding.\n      tensorspec: A `tf.TensorSpec`. The created `SimpleEncoder` will be\n        constrained to only encode input values compatible with `tensorspec`.\n\n    Returns:\n      A `SimpleEncoder`.\n\n    Raises:\n      TypeError:\n        If `encoder` is not an `Encoder` or `tensorspec` is not a\n        `tf.TensorSpec`.\n    """"""\n    if not isinstance(encoder, core_encoder.Encoder):\n      raise TypeError(\'The encoder must be an instance of `Encoder`.\')\n    if not isinstance(tensorspec, tf.TensorSpec):\n      raise TypeError(\'The tensorspec must be a tf.TensorSpec.\')\n    if not tensorspec.shape.is_fully_defined():\n      raise TypeError(\'The shape of provided tensorspec must be fully defined.\')\n    self._tensorspec = tensorspec\n\n    # These dictionaries are filled inside of the initial_state_fn and encode_fn\n    # methods, to be used in encode_fn and decode_fn methods, respectively.\n    # Decorated by tf.function, their necessary side effects are realized during\n    # call to get_concrete_function().\n    state_py_structure = {}\n    encoded_py_structure = {}\n\n    @tf.function\n    def initial_state_fn():\n      state = encoder.initial_state()\n      if not state_py_structure:\n        state_py_structure[\'state\'] = tf.nest.map_structure(\n            lambda _: None, state)\n      # Simplify the structure that needs to be manipulated by the user.\n      return tuple(tf.nest.flatten(state))\n\n    @tf.function(input_signature=[\n        tensorspec,\n        tf.nest.map_structure(\n            tf.TensorSpec.from_tensor,\n            initial_state_fn.get_concrete_function().structured_outputs)\n    ])  # pylint: disable=missing-docstring\n    def encode_fn(x, flat_state):\n      state = tf.nest.pack_sequence_as(state_py_structure[\'state\'], flat_state)\n      encode_params, decode_params = encoder.get_params(state)\n      encoded_x, state_update_tensors, input_shapes = encoder.encode(\n          x, encode_params)\n      updated_flat_state = tuple(\n          tf.nest.flatten(encoder.update_state(state, state_update_tensors)))\n\n      # The following code converts the nested structres necessary for the\n      # underlying encoder, to a single flat dictionary, which is simpler to\n      # manipulate by the users of SimpleEncoder.\n      full_encoded_structure = {\n          _TENSORS: encoded_x,\n          _PARAMS: decode_params,\n          _SHAPES: input_shapes\n      }\n      flat_encoded_structure = dict(\n          py_utils.flatten_with_joined_string_paths(full_encoded_structure))\n      flat_encoded_py_structure, flat_encoded_tf_structure = (\n          py_utils.split_dict_py_tf(flat_encoded_structure))\n\n      if not encoded_py_structure:\n        encoded_py_structure[\'full\'] = tf.nest.map_structure(\n            lambda _: None, full_encoded_structure)\n        encoded_py_structure[\'flat_py\'] = flat_encoded_py_structure\n      return flat_encoded_tf_structure, updated_flat_state\n\n    @tf.function(input_signature=[\n        tf.nest.map_structure(\n            tf.TensorSpec.from_tensor,\n            encode_fn.get_concrete_function().structured_outputs[0])\n    ])  # pylint: disable=missing-docstring\n    def decode_fn(encoded_structure):\n      encoded_structure = py_utils.merge_dicts(encoded_structure,\n                                               encoded_py_structure[\'flat_py\'])\n      encoded_structure = tf.nest.pack_sequence_as(\n          encoded_py_structure[\'full\'], tf.nest.flatten(encoded_structure))\n      return encoder.decode(encoded_structure[_TENSORS],\n                            encoded_structure[_PARAMS],\n                            encoded_structure[_SHAPES])\n\n    # Ensures the decode_fn is traced during initialization.\n    decode_fn.get_concrete_function()\n\n    self._initial_state_fn = initial_state_fn\n    self._encode_fn = encode_fn\n    self._decode_fn = decode_fn\n\n  @property\n  def input_tensorspec(self):\n    """"""Returns `tf.TensorSpec` describing input expected by `SimpleEncoder`.""""""\n    return self._tensorspec\n\n  def initial_state(self, name=None):\n    """"""Returns the initial state.\n\n    Args:\n      name: `string`, name of the operation.\n\n    Returns:\n      A tuple of `Tensor` values, representing the initial state.\n    """"""\n    with tf.compat.v1.name_scope(name, \'simple_encoder_initial_state\'):\n      return self._initial_state_fn()\n\n  def encode(self, x, state=None, name=None):\n    """"""Encodes the provided input.\n\n    If `state` is not provided, the return value of the `initial_state` method\n    will be used.\n\n    Args:\n      x: A `Tensor` to be encoded.\n      state: The (optional) current state. A tuple, matching the structure\n        returned by the `initial_state` method.\n      name: `string`, name of the operation.\n\n    Returns:\n      A `(encoded_x, updated_state)` tuple, where `encoded_x` is a dictionary of\n      `Tensor` values representing the encoded `x`, and `updated_state` is the\n      state updated after encoding, of the same structure as `state`.\n\n    Raises:\n      ValueError:\n        If `x` does not have the expected shape or dtype, or if `state` does not\n        have the same structure as return value of the `initial_state` method.\n    """"""\n    if state is None:\n      state = self.initial_state()\n    with tf.compat.v1.name_scope(name, \'simple_encoder_encode\',\n                                 [x] + list(state)):\n      return self._encode_fn(x, state)\n\n  def decode(self, encoded_x, name=None):\n    """"""Decodes the encoded value.\n\n    Args:\n      encoded_x: A dictionary of the same structure as returned by the `encode`\n        method. Represents the encoded value to be decoded.\n      name: `string`, name of the operation.\n\n    Returns:\n      A single `Tensor` of the same shape and dtype as the original input to the\n      `encode` method.\n\n    Raises:\n      ValueError:\n        If `encoded_x` is not of the same structure as returned by the `encode`\n        method.\n    """"""\n    with tf.compat.v1.name_scope(name, \'simple_encoder_decode\',\n                                 encoded_x.values()):\n      return self._decode_fn(encoded_x)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/core/simple_encoder_test.py,25,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport tensorflow as tf\n\n# TODO(b/139939526): Move to public API.\nfrom tensorflow.python.framework import test_util as tf_test_util\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import simple_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n# Abbreviated constants used in tests.\nTENSORS = simple_encoder._TENSORS\n\nP1_VALS = test_utils.PlusOneEncodingStage.ENCODED_VALUES_KEY\nT2_VALS = test_utils.TimesTwoEncodingStage.ENCODED_VALUES_KEY\nSIF_SIGNS = test_utils.SignIntFloatEncodingStage.ENCODED_SIGNS_KEY\nSIF_INTS = test_utils.SignIntFloatEncodingStage.ENCODED_INTS_KEY\nSIF_FLOATS = test_utils.SignIntFloatEncodingStage.ENCODED_FLOATS_KEY\nPN_VALS = test_utils.PlusOneOverNEncodingStage.ENCODED_VALUES_KEY\n\n\nclass SimpleEncoderTest(tf.test.TestCase, parameterized.TestCase):\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_basic_encode_decode(self):\n    """"""Tests basic encoding and decoding works as expected.""""""\n    x = tf.constant(1.0, tf.float32)\n    encoder = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n\n    state = encoder.initial_state()\n    iteration = _make_iteration_function(encoder)\n    for i in range(1, 10):\n      x, encoded_x, decoded_x, state = self.evaluate(iteration(x, state))\n      self.assertAllClose(x, decoded_x)\n      self.assertAllClose(1.0 + 1 / i,\n                          _encoded_x_field(encoded_x, [TENSORS, PN_VALS]))\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_composite_encoder(self):\n    """"""Tests functionality with a general, composite `Encoder`.""""""\n    x = tf.constant(1.2)\n    encoder = core_encoder.EncoderComposer(\n        test_utils.SignIntFloatEncodingStage())\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_SIGNS)\n    encoder.add_child(test_utils.PlusOneEncodingStage(), SIF_INTS)\n    encoder.add_child(test_utils.TimesTwoEncodingStage(), SIF_FLOATS).add_child(\n        test_utils.PlusOneOverNEncodingStage(), T2_VALS)\n    encoder = simple_encoder.SimpleEncoder(encoder.make(),\n                                           tf.TensorSpec.from_tensor(x))\n\n    state = encoder.initial_state()\n    iteration = _make_iteration_function(encoder)\n    for i in range(1, 10):\n      x, encoded_x, decoded_x, state = self.evaluate(iteration(x, state))\n      self.assertAllClose(x, decoded_x)\n      self.assertAllClose(\n          2.0, _encoded_x_field(encoded_x, [TENSORS, SIF_SIGNS, T2_VALS]))\n      self.assertAllClose(\n          2.0, _encoded_x_field(encoded_x, [TENSORS, SIF_INTS, P1_VALS]))\n      self.assertAllClose(\n          0.4 + 1 / i,\n          _encoded_x_field(encoded_x, [TENSORS, SIF_FLOATS, T2_VALS, PN_VALS]))\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_none_state_equal_to_initial_state(self):\n    """"""Tests that not providing state is the same as initial_state.""""""\n    x = tf.constant(1.0)\n    encoder = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n\n    state = encoder.initial_state()\n    stateful_iteration = _make_iteration_function(encoder)\n\n    @tf.function\n    def stateless_iteration(x):\n      encoded_x, _ = encoder.encode(x)\n      decoded_x = encoder.decode(encoded_x)\n      return encoded_x, decoded_x\n\n    _, encoded_x_stateful, decoded_x_stateful, _ = self.evaluate(\n        stateful_iteration(x, state))\n    encoded_x_stateless, decoded_x_stateless = self.evaluate(\n        stateless_iteration(x))\n\n    self.assertAllClose(encoded_x_stateful, encoded_x_stateless)\n    self.assertAllClose(decoded_x_stateful, decoded_x_stateless)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_python_constants_not_exposed(self):\n    """"""Tests that only TensorFlow values are exposed to users.""""""\n    x = tf.constant(1.0)\n    tensorspec = tf.TensorSpec.from_tensor(x)\n    encoder_py = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.SimpleLinearEncodingStage(2.0, 3.0)).make(), tensorspec)\n    a_var = tf.compat.v1.get_variable(\'a_var\', initializer=2.0)\n    b_var = tf.compat.v1.get_variable(\'b_var\', initializer=3.0)\n    encoder_tf = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.SimpleLinearEncodingStage(a_var, b_var)).make(),\n        tensorspec)\n\n    state_py = encoder_py.initial_state()\n    state_tf = encoder_tf.initial_state()\n    iteration_py = _make_iteration_function(encoder_py)\n    iteration_tf = _make_iteration_function(encoder_tf)\n\n    self.evaluate(tf.compat.v1.global_variables_initializer())\n    _, encoded_x_py, decoded_x_py, _ = self.evaluate(iteration_py(x, state_py))\n    _, encoded_x_tf, decoded_x_tf, _ = self.evaluate(iteration_tf(x, state_tf))\n\n    # The encoded_x_tf should have two elements that encoded_x_py does not.\n    # These correspond to the two variables created passed on to constructor of\n    # encoder_tf, which are exposed as params. For encoder_py, these are python\n    # integers, and should thus be hidden from users.\n    self.assertLen(encoded_x_tf, len(encoded_x_py) + 2)\n\n    # Make sure functionality is still the same.\n    self.assertAllClose(x, decoded_x_tf)\n    self.assertAllClose(x, decoded_x_py)\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_decode_needs_input_shape_static(self):\n    """"""Tests that mechanism for passing input shape works with static shape.""""""\n    x = tf.reshape(list(range(15)), [3, 5])\n    encoder = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.ReduceMeanEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n\n    state = encoder.initial_state()\n    iteration = _make_iteration_function(encoder)\n    _, _, decoded_x, _ = self.evaluate(iteration(x, state))\n    self.assertAllEqual([[7.0] * 5] * 3, decoded_x)\n\n  def test_not_fully_defined_shape_raises(self):\n    """"""Tests tensorspec without fully defined shape.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneOverNEncodingStage()).make()\n    with self.assertRaisesRegex(TypeError, \'fully defined\'):\n      simple_encoder.SimpleEncoder(encoder, tf.TensorSpec((None,), tf.float32))\n\n  @tf_test_util.run_all_in_graph_and_eager_modes\n  def test_input_signature_enforced(self):\n    """"""Tests that encode/decode input signature is enforced.""""""\n    x = tf.constant(1.0)\n    encoder = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n\n    state = encoder.initial_state()\n    with self.assertRaises(ValueError):\n      bad_x = tf.stack([x, x])\n      encoder.encode(bad_x, state)\n    with self.assertRaises(ValueError):\n      bad_state = state + (x,)\n      encoder.encode(x, bad_state)\n    encoded_x = encoder.encode(x, state)\n    with self.assertRaises(ValueError):\n      bad_encoded_x = dict(encoded_x)\n      bad_encoded_x.update({\'x\': x})\n      encoder.decode(bad_encoded_x)\n\n  def test_input_tensorspec(self):\n    """"""Tests input_tensorspec property.""""""\n    x = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n    encoder = simple_encoder.SimpleEncoder(\n        core_encoder.EncoderComposer(\n            test_utils.PlusOneOverNEncodingStage()).make(),\n        tf.TensorSpec.from_tensor(x))\n    self.assertTrue(encoder.input_tensorspec.is_compatible_with(x))\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_not_an_encoder_raises(self, not_an_encoder):\n    """"""Tests invalid encoder argument.""""""\n    tensorspec = tf.TensorSpec((1,), tf.float32)\n    with self.assertRaisesRegex(TypeError, \'Encoder\'):\n      simple_encoder.SimpleEncoder(not_an_encoder, tensorspec)\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_not_a_tensorspec_raises(self, not_a_tensorspec):\n    """"""Tests invalid type of tensorspec argument.""""""\n    encoder = core_encoder.EncoderComposer(\n        test_utils.PlusOneOverNEncodingStage()).make()\n    with self.assertRaisesRegex(TypeError, \'TensorSpec\'):\n      simple_encoder.SimpleEncoder(encoder, not_a_tensorspec)\n\n\ndef _make_iteration_function(encoder):\n  assert isinstance(encoder, simple_encoder.SimpleEncoder)\n\n  @tf.function\n  def iteration(x, state):\n    encoded_x, new_state = encoder.encode(x, state)\n    decoded_x = encoder.decode(encoded_x)\n    return x, encoded_x, decoded_x, new_state\n\n  return iteration\n\n\ndef _encoded_x_field(encoded_x, path):\n  """"""Returns a field from `encoded_x` returned by the `encode` method.\n\n  In order to test the correctness of encoding, we also need to access the\n  encoded objects, which in turns depends on an implementation detail (the\n  specific use of `nest.flatten_with_joined_string_paths`). This dependence is\n  constrained to a single place in this utility.\n\n  Args:\n    encoded_x: The structure returned by the `encode` method.\n    path: A list of keys corresponding to the path in the nested dictionary\n      before it was flattened.\n\n  Returns:\n    A value from `encoded_x` corresponding to the `path`.\n  """"""\n  return encoded_x[\'/\'.join(path)]\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/encoders/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A collection of common encoders.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders.common_encoders import as_gather_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders.common_encoders import as_simple_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders.common_encoders import hadamard_quantization\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders.common_encoders import identity\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders.common_encoders import uniform_quantization\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/encoders/common_encoders.py,4,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A collection of common encoders.\n\nMost users of the `tensor_encoding` package should only need to access symbols\nin this file, unless a specific advanced functionality is needed.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import gather_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import simple_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages import stages_impl\n\n\ndef as_simple_encoder(encoder, tensorspec):\n  """"""Wraps an `Encoder` object as a `SimpleEncoder`.\n\n  Args:\n    encoder: An `Encoder` object to be used to encoding.\n    tensorspec: A `TensorSpec`. The created `SimpleEncoder` will be constrained\n      to only encode input values compatible with `tensorspec`.\n\n  Returns:\n    A `SimpleEncoder`.\n\n  Raises:\n    TypeError:\n      If `encoder` is not an `Encoder` or `tensorspec` is not a `TensorSpec`.\n  """"""\n  if not isinstance(encoder, core_encoder.Encoder):\n    raise TypeError(\'The encoder must be an instance of `Encoder`.\')\n  if not isinstance(tensorspec, tf.TensorSpec):\n    raise TypeError(\'The tensorspec must be a tf.TensorSpec.\')\n  return simple_encoder.SimpleEncoder(encoder, tensorspec)\n\n\ndef as_gather_encoder(encoder, tensorspec):\n  """"""Wraps an `Encoder` object as a `GatherEncoder`.\n\n  Args:\n    encoder: An `Encoder` object to be used to encoding.\n    tensorspec: A `TensorSpec`. The created `GatherEncoder` will be constrained\n      to only encode input values compatible with `tensorspec`.\n\n  Returns:\n    A `GatherEncoder`.\n\n  Raises:\n    TypeError:\n      If `encoder` is not an `Encoder` or `tensorspec` is not a `TensorSpec`.\n  """"""\n  if not isinstance(encoder, core_encoder.Encoder):\n    raise TypeError(\'The encoder must be an instance of `Encoder`.\')\n  if not isinstance(tensorspec, tf.TensorSpec):\n    raise TypeError(\'The tensorspec must be a tf.TensorSpec.\')\n  return gather_encoder.GatherEncoder.from_encoder(encoder, tensorspec)\n\n\ndef identity():\n  """"""Returns identity `Encoder`.""""""\n  return core_encoder.EncoderComposer(\n      stages_impl.IdentityEncodingStage()).make()\n\n\ndef uniform_quantization(bits):\n  """"""Returns uniform quanitzation `Encoder`.\n\n  The `Encoder` first reshapes the input to a rank-1 `Tensor`, then applies\n  uniform quantization with the extreme values being the minimum and maximum of\n  the vector being encoded. Finally, the quantized values are bitpacked to an\n  integer type.\n\n  The `Encoder` is a composition of the following encoding stages:\n  * `FlattenEncodingStage`\n  * `UniformQuantizationEncodingStage`\n  * `BitpackingEncodingStage`\n\n  Args:\n    bits: Number of bits to quantize into.\n\n  Returns:\n    The quantization `Encoder`.\n  """"""\n  return core_encoder.EncoderComposer(\n      stages_impl.BitpackingEncodingStage(bits)).add_parent(\n          stages_impl.UniformQuantizationEncodingStage(bits), stages_impl\n          .UniformQuantizationEncodingStage.ENCODED_VALUES_KEY).add_parent(\n              stages_impl.FlattenEncodingStage(),\n              stages_impl.FlattenEncodingStage.ENCODED_VALUES_KEY).make()\n\n\ndef hadamard_quantization(bits):\n  """"""Returns hadamard quanitzation `Encoder`.\n\n  The `Encoder` first reshapes the input to a rank-1 `Tensor`, and applies the\n  Hadamard transform (rotation). It then applies uniform quantization with the\n  extreme values being the minimum and maximum of the rotated vector being\n  encoded. Finally, the quantized values are bitpacked to an integer type.\n\n  The `Encoder` is a composition of the following encoding stages:\n  * `FlattenEncodingStage` - reshaping the input to a vector.\n  * `HadamardEncodingStage` - applying the Hadamard transform.\n  * `UniformQuantizationEncodingStage` - applying uniform quantization.\n  * `BitpackingEncodingStage` - bitpacking the result into integer values.\n\n  Args:\n    bits: Number of bits to quantize into.\n\n  Returns:\n    The hadamard quantization `Encoder`.\n  """"""\n  return core_encoder.EncoderComposer(\n      stages_impl.BitpackingEncodingStage(bits)).add_parent(\n          stages_impl.UniformQuantizationEncodingStage(bits), stages_impl\n          .UniformQuantizationEncodingStage.ENCODED_VALUES_KEY).add_parent(\n              stages_impl.HadamardEncodingStage(),\n              stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY).add_parent(\n                  stages_impl.FlattenEncodingStage(),\n                  stages_impl.FlattenEncodingStage.ENCODED_VALUES_KEY).make()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/encoders/common_encoders_test.py,8,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import core_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import gather_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import simple_encoder\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.encoders import common_encoders\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\n_ENCODER_FNS = [\n    common_encoders.identity,\n    lambda: common_encoders.uniform_quantization(8),\n    lambda: common_encoders.hadamard_quantization(8),\n]\n\n\nclass EncoderLibraryTest(parameterized.TestCase):\n  """"""Tests for the `common_encoders` methods.""""""\n\n  @parameterized.parameters(_ENCODER_FNS)\n  def test_as_simple_encoder(self, encoder_fn):\n    encoder = common_encoders.as_simple_encoder(encoder_fn(),\n                                                tf.TensorSpec((2,), tf.float32))\n    self.assertIsInstance(encoder, simple_encoder.SimpleEncoder)\n\n  @parameterized.parameters(None, [[]], 2.0, \'string\')\n  def test_as_simple_encoder_raises_encoder(self, not_an_encoder):\n    with self.assertRaises(TypeError):\n      common_encoders.as_simple_encoder(not_an_encoder,\n                                        tf.TensorSpec((2,), tf.float32))\n\n  @parameterized.parameters(None, [[]], 2.0, \'string\')\n  def test_as_simple_encoder_raises_tensorspec(self, not_a_tensorspec):\n    with self.assertRaises(TypeError):\n      common_encoders.as_simple_encoder(common_encoders.identity(),\n                                        not_a_tensorspec)\n\n  @parameterized.parameters(_ENCODER_FNS)\n  def test_as_gather_encoder(self, encoder_fn):\n    encoder = common_encoders.as_gather_encoder(encoder_fn(),\n                                                tf.TensorSpec((2,), tf.float32))\n    self.assertIsInstance(encoder, gather_encoder.GatherEncoder)\n\n  @parameterized.parameters(None, [[]], 2.0, \'string\')\n  def test_as_gather_encoder_raises_encoder(self, not_an_encoder):\n    with self.assertRaises(TypeError):\n      common_encoders.as_gather_encoder(not_an_encoder,\n                                        tf.TensorSpec((2,), tf.float32))\n\n  @parameterized.parameters(None, [[]], 2.0, \'string\')\n  def test_as_gather_encoder_raises_tensorspec(self, not_a_tensorspec):\n    with self.assertRaises(TypeError):\n      common_encoders.as_gather_encoder(common_encoders.identity(),\n                                        not_a_tensorspec)\n\n  def test_identity(self):\n    encoder = common_encoders.identity()\n    self.assertIsInstance(encoder, core_encoder.Encoder)\n\n    params, _ = encoder.get_params(encoder.initial_state())\n    encoded_x, _, _ = encoder.encode(tf.constant(1.0), params)\n    keys = [k for k, _ in py_utils.flatten_with_joined_string_paths(encoded_x)]\n    self.assertSameElements([\'identity_values\'], keys)\n\n  def test_uniform_quantization(self):\n    encoder = common_encoders.uniform_quantization(8)\n    self.assertIsInstance(encoder, core_encoder.Encoder)\n\n    params, _ = encoder.get_params(encoder.initial_state())\n    encoded_x, _, _ = encoder.encode(tf.constant(1.0), params)\n    keys = [k for k, _ in py_utils.flatten_with_joined_string_paths(encoded_x)]\n    self.assertSameElements([\n        \'flattened_values/min_max\',\n        \'flattened_values/quantized_values/bitpacked_values\'\n    ], keys)\n\n  def test_hadamard_quantization(self):\n    encoder = common_encoders.hadamard_quantization(8)\n    self.assertIsInstance(encoder, core_encoder.Encoder)\n\n    params, _ = encoder.get_params(encoder.initial_state())\n    encoded_x, _, _ = encoder.encode(tf.constant(1.0), params)\n    keys = [k for k, _ in py_utils.flatten_with_joined_string_paths(encoded_x)]\n    self.assertSameElements([\n        \'flattened_values/hadamard_values/min_max\',\n        \'flattened_values/hadamard_values/quantized_values/bitpacked_values\'\n    ], keys)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Implementations of the (Adaptive)EncodingStageInterface.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages import research\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.stages_impl import BitpackingEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.stages_impl import FlattenEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.stages_impl import HadamardEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.stages_impl import IdentityEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.stages_impl import UniformQuantizationEncodingStage\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/stages_impl.py,39,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Implementations of the encoding stage interfaces.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import tf_utils\n\n\n@encoding_stage.tf_style_encoding_stage\nclass IdentityEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage acting as the identity.""""""\n\n  ENCODED_VALUES_KEY = \'identity_values\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'identity\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    return {self.ENCODED_VALUES_KEY: tf.identity(x)}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    return tf.identity(encoded_tensors[self.ENCODED_VALUES_KEY])\n\n\n@encoding_stage.tf_style_encoding_stage\nclass FlattenEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage reshaping the input to be a rank 1 `Tensor`.""""""\n\n  ENCODED_VALUES_KEY = \'flattened_values\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'flatten\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    return {self.ENCODED_VALUES_KEY: tf.reshape(x, [-1])}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands  # Unused.\n    return tf.reshape(encoded_tensors[self.ENCODED_VALUES_KEY], shape)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass HadamardEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage multiplying input by appropriate randomized Hadamard matrix.\n\n  This encoding stage implements the fast Walsh-Hadamard transform to\n  efficiently compute matrix-vector product in O(n log n) time.\n  https://en.wikipedia.org/wiki/Fast_Walsh%E2%80%93Hadamard_transform\n\n  The useful property of randomized Hadamard transform is that it spreads the\n  information in a vector more uniformly across its coefficients. This work well\n  together with uniform quantization, as it reduces the dynamic range of the\n  coefficients to be quantized, decreasing the error incurred by quantization.\n\n  The encoding works as follows:\n  The shape of the input `x` to the `encode` method must be either `(dim)` or\n  `(b, dim)`, where `dim` is the dimenion of the vector to which the transform\n  is to be applied, and must be statically known. `b` represents an optional\n  batch dimension, and does not need to be statically known.\n\n  If the shape of the input is `(dim)`, it is first expanded to `(1, dim)`. The\n  input of shape `(b, dim)` has signs randomly flipped (as determined by random\n  seed to be reused in decoding) and is padded with zeros to dimension\n  `(b, dim_2)`, where `dim_2` is the smallest power of 2 larger than or equal\n  to `dim`.\n\n  The same transform is then applied to each of the `b` vectors of shape\n  `dim_2`. If `H` represents the `(dim_2, dim_2)` Hadamard matrix and `D`\n  represents the `(dim, dim_2)` diagonal matrix with randomly sampled `+1/-1`\n  elements, the `encode` method computes `x[i, :]*D*H` for every `i`. In other\n  words, if the leading dimension represents a batch, the transform is applied\n  to every element in the batch. The encoded value then has shape `(b, dim_2)`,\n  where `dim_2` is the smallest power of 2 larger than or equal to `dim`.\n  """"""\n\n  ENCODED_VALUES_KEY = \'hadamard_values\'\n  SEED_PARAMS_KEY = \'seed\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'hadamard\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {\n        self.SEED_PARAMS_KEY:\n            tf.random.uniform((2,), maxval=tf.int64.max, dtype=tf.int64),\n    }\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    x = self._validate_and_expand_encode_input(x)\n    signs = self._random_signs(x.shape.as_list()[1],\n                               encode_params[self.SEED_PARAMS_KEY], x.dtype)\n    x = x * signs\n    x = self._pad(x)\n    rotated_x = tf_utils.fast_walsh_hadamard_transform(x)\n    return {self.ENCODED_VALUES_KEY: rotated_x}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands  # Unused.\n    rotated_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    unrotated_x = tf_utils.fast_walsh_hadamard_transform(rotated_x)\n\n    # Take slice corresponding to the input shape.\n    decoded_x = tf.slice(unrotated_x, [0, 0],\n                         [tf.shape(unrotated_x)[0], shape[-1]])\n    signs = self._random_signs(decoded_x.shape.as_list()[-1],\n                               decode_params[self.SEED_PARAMS_KEY],\n                               decoded_x.dtype)\n    decoded_x = decoded_x * signs\n    if shape.shape.num_elements() == 1:\n      decoded_x = tf.squeeze(decoded_x, [0])\n    return decoded_x\n\n  def _validate_and_expand_encode_input(self, x):\n    """"""Validates the input to encode and modifies it if necessary.""""""\n    if x.shape.ndims not in [1, 2]:\n      raise ValueError(\n          \'Number of dimensions must be 1 or 2. Shape of x: %s\' % x.shape)\n    if x.shape.ndims == 1:\n      # The input to the fast_walsh_hadamard_transform must have 2 dimensions.\n      x = tf.expand_dims(x, 0)\n    if x.shape.as_list()[1] is None:\n      raise ValueError(\n          \'The dimension of the object to be rotated must be fully known.\')\n    return x\n\n  def _pad(self, x):\n    """"""Pads with zeros to the next power of two.""""""\n    dim = x.shape.as_list()[1]\n    pad_dim = 2**int(np.ceil(np.log2(dim)))\n    if pad_dim != dim:\n      x = tf.pad(x, [[0, 0], [0, pad_dim - dim]])\n    return x\n\n  def _random_signs(self, num_elements, seed, dtype):\n    return tf_utils.random_signs(num_elements, seed, dtype)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass UniformQuantizationEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage performing uniform quantization.\n\n  This class performs quantization to uniformly spaced values, without realizing\n  any savings by itself.\n\n  In particular, given a floating point input `x` to the `encode` method, the\n  output will have the same `dtype` as `x`, with values being ""floating point\n  integers"" in the range `[0, 2**bits-1]`.\n\n  If `min_max` is not provided, the extreme points of the quantized interval\n  will correspond to the min and max values of the input `x`. If `min_max` is\n  provided, the input `x` is first clipped to this range, and the extreme points\n  of the quantized interval correspond to the provided `min_max` values.\n  """"""\n\n  ENCODED_VALUES_KEY = \'quantized_values\'\n  MIN_MAX_VALUES_KEY = \'min_max\'\n  MAX_INT_VALUE_PARAMS_KEY = \'max_value\'\n  # The allowed values for `bits` argument to initializer.\n  # We cap the allowed quantization bits at 16, as the randomized rounding could\n  # otherwise be numerically unstable for float32 values.\n  _ALLOWED_BITS_ARG = list(range(1, 17))\n\n  def __init__(self, bits=8, min_max=None, stochastic=True):\n    """"""Initializer for the UniformQuantizationEncodingStage.\n\n    Args:\n      bits: The number of bits to quantize to. Must be an integer between 1 and\n        16. Can be either a TensorFlow or a Python value.\n      min_max: A range to be used for quantization. If `None`, the range of the\n        vector to be encoded will be used. If provided, must be an array of 2\n        elements, corresponding to the min and max value, respectively. Can be\n        either a TensorFlow or a Python value.\n      stochastic: A Python bool, whether to use stochastic or deterministic\n        rounding. If `True`, the encoding is randomized and on expectation\n        unbiased. If `False`, the encoding is deterministic.\n\n    Raises:\n      ValueError: The inputs do not satisfy the above constraints.\n    """"""\n    if (not tf.is_tensor(bits) and bits not in self._ALLOWED_BITS_ARG):\n      raise ValueError(\'The bits argument must be an integer between 1 and 16.\')\n    self._bits = bits\n\n    if min_max is not None:\n      if tf.is_tensor(min_max):\n        if min_max.shape.as_list() != [2]:\n          raise ValueError(\n              \'The min_max argument must be Tensor with shape (2).\')\n      else:\n        if not isinstance(min_max, list) or len(min_max) != 2:\n          raise ValueError(\n              \'The min_max argument must be a list with two elements.\')\n        if min_max[0] >= min_max[1]:\n          raise ValueError(\'The first element of the min_max argument must be \'\n                           \'smaller than the second element.\')\n    self._min_max = min_max\n\n    if not isinstance(stochastic, bool):\n      raise TypeError(\'The stochastic argument must be a bool.\')\n    self._stochastic = stochastic\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'uniform_quantization\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    # The stage commutes with sum only if min_max values are shared.\n    if self._min_max is not None:\n      return True\n    else:\n      return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.MAX_INT_VALUE_PARAMS_KEY: 2**self._bits - 1}\n    if self._min_max is not None:\n      # If fixed min and max is provided, expose them via params.\n      params[self.MIN_MAX_VALUES_KEY] = self._min_max\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    if self.MIN_MAX_VALUES_KEY in encode_params:\n      min_max = tf.cast(encode_params[self.MIN_MAX_VALUES_KEY], x.dtype)\n      min_x, max_x = min_max[0], min_max[1]\n      x = tf.clip_by_value(x, min_x, max_x)\n    else:\n      min_x = tf.reduce_min(x)\n      max_x = tf.reduce_max(x)\n\n    max_value = tf.cast(encode_params[self.MAX_INT_VALUE_PARAMS_KEY], x.dtype)\n    # Shift the values to range [0, max_value].\n    # In the case of min_x == max_x, this will return all zeros.\n    x = tf.compat.v1.div_no_nan(x - min_x, max_x - min_x) * max_value\n    if self._stochastic:  # Randomized rounding.\n      floored_x = tf.floor(x)\n      bernoulli = tf.random.uniform(tf.shape(x), dtype=x.dtype)\n      bernoulli = bernoulli < (x - floored_x)\n      quantized_x = floored_x + tf.cast(bernoulli, x.dtype)\n    else:  # Deterministic rounding.\n      quantized_x = tf.round(x)\n\n    encoded_tensors = {self.ENCODED_VALUES_KEY: quantized_x}\n    if self.MIN_MAX_VALUES_KEY not in encode_params:\n      encoded_tensors[self.MIN_MAX_VALUES_KEY] = tf.stack([min_x, max_x])\n    return encoded_tensors\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del shape  # Unused.\n    quantized_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    if self.MIN_MAX_VALUES_KEY in decode_params:\n      min_max = tf.cast(decode_params[self.MIN_MAX_VALUES_KEY],\n                        quantized_x.dtype)\n    else:\n      min_max = encoded_tensors[self.MIN_MAX_VALUES_KEY]\n    min_x, max_x = min_max[0], min_max[1]\n    max_value = tf.cast(decode_params[self.MAX_INT_VALUE_PARAMS_KEY],\n                        quantized_x.dtype)\n\n    # If num_summands is None, it is to be interpreted as 1.\n    if self.commutes_with_sum and num_summands is not None:\n      shift = min_x * tf.cast(num_summands, min_x.dtype)\n    else:\n      shift = min_x\n\n    x = quantized_x / max_value * (max_x - min_x) + shift\n    return x\n\n\n@encoding_stage.tf_style_encoding_stage\nclass BitpackingEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage for bitpacking values into an integer type.\n\n  This class performs a lossless transformation, and realizes representation\n  savings.\n\n  The encode method expects integer values in range `[0, 2**input_bits-1]` in a\n  floating point type (`tf.float32` or `tf.float64`). It packs the values to\n  `tf.int32` type, and returns a rank 1 `Tensor` of packed values. The packed\n  values are in the range `[0, 2**28-1]`, as the serialization in protocol\n  buffer for this type is varint, and this thus ensures every element fits into\n  4 bytes.\n  """"""\n\n  ENCODED_VALUES_KEY = \'bitpacked_values\'\n  DUMMY_TYPE_VALUES_KEY = \'dummy_type_value\'\n  _ALLOWED_INPUT_BITS_ARG = list(range(1, 17))\n\n  def __init__(self, input_bits):\n    """"""Initializer for the UniformQuantizationEncodingStage.\n\n    Args:\n      input_bits: The number of bits expected to represent the input to the\n        `encode` method. Must be between 1 and 16. Cannot be a TensorFlow value.\n\n    Raises:\n      TypeError: If `input_bits` is a TensorFlow value.\n      ValueError: If `input_bits` is not between 1 and 16.\n    """"""\n    if tf.is_tensor(input_bits):\n      raise TypeError(\'The input_bits argument cannot be a TensorFlow value.\')\n    if input_bits not in self._ALLOWED_INPUT_BITS_ARG:\n      raise ValueError(\n          \'The input_bits argument must be an integer between 1 and 16.\')\n    self._input_bits = input_bits\n\n    # Because the proto serialization format for integers is varint, we pack to\n    # 28 bits, ensuring each serialized value is represented by 4 bytes.\n    self._target_bitrange = 28\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'bitpacking\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return []  # Bitpacked values should not be further modified.\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params\n    flat_x = tf.reshape(x, [-1])\n    packed_x = tf_utils.pack_into_int(\n        tf.cast(flat_x, tf.int32), self._input_bits, self._target_bitrange)\n\n    # The most common type will be tf.float32, which we keep as default.\n    # If another type is provided, return a Tensor with a single value of that\n    # type to be able to recover the type from encoded_tensors in decode method.\n    if x.dtype == tf.float32:\n      return {self.ENCODED_VALUES_KEY: packed_x}\n    elif x.dtype == tf.float64:\n      return {self.ENCODED_VALUES_KEY: packed_x,\n              self.DUMMY_TYPE_VALUES_KEY: tf.constant(0.0, dtype=tf.float64)}\n    else:\n      raise TypeError(\n          \'Unsupported packing type: %s. Supported types are tf.float32 and \'\n          \'tf.float64 values\' % x.dtype)\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands  # Unused.\n    unpacked_x = tf_utils.unpack_from_int(\n        encoded_tensors[self.ENCODED_VALUES_KEY], self._input_bits,\n        self._target_bitrange, shape)\n\n    dummy_type_value = encoded_tensors.get(self.DUMMY_TYPE_VALUES_KEY)\n    if dummy_type_value is not None:\n      return tf.cast(unpacked_x, dummy_type_value.dtype)\n    else:\n      return tf.cast(unpacked_x, tf.float32)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/stages_impl_test.py,35,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages import stages_impl\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass IdentityEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return stages_impl.IdentityEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(\n        data.x,\n        data.encoded_x[stages_impl.IdentityEncodingStage.ENCODED_VALUES_KEY])\n\n\nclass FlattenEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return stages_impl.FlattenEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([2, 3])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertLen(  # The Tensor rank of encoded_x should be 1.\n        data.encoded_x[\n            stages_impl.FlattenEncodingStage.ENCODED_VALUES_KEY].shape, 1)\n    self.assertAllClose(\n        data.x.flatten(),\n        data.encoded_x[stages_impl.FlattenEncodingStage.ENCODED_VALUES_KEY])\n\n  def test_one_to_many_with_unknown_shape(self):\n    """"""Tests that encoding works with statically not known input shape.""""""\n\n    def random_shape_2d_tensor():\n      # Returns Tensor of shape [3, <unknown>]\n      random_shape_vector = test_utils.get_tensor_with_random_shape()\n      return tf.stack([random_shape_vector] * 3)\n\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), random_shape_2d_tensor)\n    self.common_asserts_for_test_data(test_data)\n\n\nclass HadamardEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return stages_impl.HadamardEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([1, 12])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    encoded_x = data.encoded_x[\n        stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY]\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertLen(encoded_x.shape, 2)\n    # This is a rotation, hence, the norms should be the same.\n    # If the input has dimension 1, the transform is applied to the whole input.\n    # If the input has dimension 2, the transform is applied to every single\n    # vector separately.\n    if len(data.x.shape) == 1:\n      self.assertAllClose(np.linalg.norm(data.x), np.linalg.norm(encoded_x))\n    else:\n      for x, y in zip(data.x, encoded_x):\n        self.assertAllClose(np.linalg.norm(x), np.linalg.norm(y))\n\n  def test_encoding_randomized(self):\n    # The encoding stage declares a source of randomness (a random seed) in the\n    # get_params method, and different encoding should be produced for each\n    # random seed. This tests that this is the case, and that the encoding is\n    # still lossless.\n    stage = self.default_encoding_stage()\n    x = np.random.randn(20).astype(np.float32)\n    test_data_1 = self.run_one_to_many_encode_decode(stage, lambda: x)\n    test_data_2 = self.run_one_to_many_encode_decode(stage, lambda: x)\n    # Make sure we encode the same object.\n    self.assertAllClose(test_data_1.x, test_data_2.x)\n    self.assertAllClose(test_data_1.x, test_data_1.decoded_x)\n    self.assertAllClose(test_data_2.x, test_data_2.decoded_x)\n    encoded_x_1 = test_data_1.encoded_x[\n        stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY]\n    encoded_x_2 = test_data_2.encoded_x[\n        stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY]\n    self.assertGreater(np.linalg.norm(encoded_x_1 - encoded_x_2), 0.1)\n\n  @parameterized.parameters(\n      [((4,), (1, 4)),\n       ((7,), (1, 8)),\n       ((1, 5), (1, 8)),\n       ((1, 11), (1, 16)),\n       ((1, 20), (1, 32)),\n       ((1, 111), (1, 128)),\n       ((2, 7), (2, 8)),\n       ((4, 1), (4, 1)),\n       ((9, 7), (9, 8))])\n  def test_with_multiple_input_shapes(self, input_dims, expected_output_dims):\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), lambda: tf.random.normal(input_dims))\n    self.common_asserts_for_test_data(test_data)\n    # Make sure output shape is as expected.\n    self.assertEqual(\n        expected_output_dims, test_data.encoded_x[\n            stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY].shape)\n\n  def test_input_with_unknown_leading_dimension(self):\n\n    def get_random_shape_input():\n      # Returns a Tensor of shape (?, 6)\n      return tf.map_fn(lambda x: x * tf.random.normal([6]),\n                       test_utils.get_tensor_with_random_shape())\n\n    # Validate the premise of the test.\n    assert get_random_shape_input().shape.as_list() == [None, 6]\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), get_random_shape_input)\n    self.common_asserts_for_test_data(test_data)\n    encoded_shape = test_data.encoded_x[\n        stages_impl.HadamardEncodingStage.ENCODED_VALUES_KEY].shape\n    self.assertEqual(test_data.x.shape[0], encoded_shape[0])\n    self.assertEqual(8, encoded_shape[1])\n\n  @parameterized.parameters([tf.float32, tf.float64])\n  def test_input_types(self, x_dtype):\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(),\n        lambda: tf.random.normal([1, 12], dtype=x_dtype))\n    self.common_asserts_for_test_data(test_data)\n\n  def test_unknown_shape_raises(self):\n    x = test_utils.get_tensor_with_random_shape()\n    stage = self.default_encoding_stage()\n    params, _ = stage.get_params()\n    with self.assertRaisesRegexp(ValueError, \'fully known\'):\n      stage.encode(x, params)\n\n  @parameterized.parameters([((1, 1, 5),), ((1, 1, 1, 5),)])\n  def test_more_than_two_ndims_raises(self, dims):\n    x = tf.random.normal(dims)\n    stage = self.default_encoding_stage()\n    params, _ = stage.get_params()\n    with self.assertRaisesRegexp(ValueError, \'must be 1 or 2.\'):\n      stage.encode(x, params)\n\n\nclass UniformQuantizationEncodingStageStageTest(\n    test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return stages_impl.UniformQuantizationEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([50], minval=-1.0, maxval=1.0)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self._assert_is_integer_float(data.encoded_x[\n        stages_impl.UniformQuantizationEncodingStage.ENCODED_VALUES_KEY])\n\n  def _assert_is_integer_float(self, quantized_vals):\n    """"""Asserts that float type values are integers.""""""\n    assert quantized_vals.dtype == np.float32\n    self.assertAllClose(quantized_vals,\n                        tf.cast(tf.cast(quantized_vals, np.int32), np.float32))\n\n  @parameterized.parameters(\n      itertools.product([1, 2, 3, 4, 7, 8, 9, 16], [None, [-0.5, 0.5]]))\n  def test_quantization_bits_stochastic_rounding(self, bits, min_max):\n    stage = stages_impl.UniformQuantizationEncodingStage(\n        bits=bits, min_max=min_max, stochastic=True)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        stages_impl.UniformQuantizationEncodingStage.ENCODED_VALUES_KEY])\n    # For stochastic rounding, the potential error incurred by quantization\n    # is bounded by the range of the input values divided by the number of\n    # quantization buckets.\n    if min_max is None:\n      self.assertAllClose(\n          test_data.x, test_data.decoded_x, rtol=0.0, atol=2 / (2**bits - 1))\n    else:\n      self.assertAllClose(\n          np.clip(test_data.x, -0.5, 0.5),\n          test_data.decoded_x,\n          rtol=0.0,\n          atol=1 / (2**bits - 1))\n\n  @parameterized.parameters(\n      itertools.product([1, 2, 3, 4, 7, 8, 9, 16], [None, [-0.5, 0.5]]))\n  def test_quantization_bits_deterministic_rounding(self, bits, min_max):\n    stage = stages_impl.UniformQuantizationEncodingStage(\n        bits=bits, min_max=min_max, stochastic=False)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        stages_impl.UniformQuantizationEncodingStage.ENCODED_VALUES_KEY])\n    # For deterministic rounding, the potential error incurred by quantization\n    # is bounded by half of the range of the input values divided by the number\n    # of quantization buckets.\n    if min_max is None:\n      self.assertAllClose(\n          test_data.x, test_data.decoded_x, rtol=0.0, atol=1 / (2**bits - 1))\n    else:\n      self.assertAllClose(\n          np.clip(test_data.x, -0.5, 0.5),\n          test_data.decoded_x,\n          rtol=0.0,\n          atol=0.5 / (2**bits - 1))\n\n  def test_quantization_empirically_unbiased(self):\n    # Tests that the quantization with stochastic=True ""seems"" to be unbiased.\n    # Executing the encoding and decoding many times, the average error should\n    # be a lot larger than the error of average decoded value.\n    x = tf.constant(np.random.rand((50)).astype(np.float32))\n    stage = stages_impl.UniformQuantizationEncodingStage(\n        bits=2, stochastic=True)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data_list = [self.evaluate_test_data(test_data) for _ in range(200)]\n\n    norm_errors = []\n    errors = []\n    for data in test_data_list:\n      norm_errors.append(np.linalg.norm(data.x - data.decoded_x))\n      errors.append(data.x - data.decoded_x)\n    mean_of_errors = np.mean(norm_errors)\n    error_of_mean = np.linalg.norm(np.mean(errors, axis=0))\n    self.assertGreater(mean_of_errors, error_of_mean * 10)\n\n  @parameterized.parameters(\n      itertools.product([tf.float32, tf.float64], [tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype, min_max_dtype):\n    # Tests combinations of input dtypes.\n    stage = stages_impl.UniformQuantizationEncodingStage(\n        bits=8, min_max=tf.constant([-1.0, 1.0], min_max_dtype))\n    x = tf.random.normal([50], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n    self.assertLess(np.amin(test_data.x), -1.0)\n    self.assertGreater(np.amax(test_data.x), 1.0)\n    self.assertAllGreaterEqual(test_data.decoded_x, -1.0)\n    self.assertAllLessEqual(test_data.decoded_x, 1.0)\n\n  def test_all_zero_input_works(self):\n    # Tests that encoding does not blow up with all-zero input. With\n    # min_max=None, the derived min and max are identical, thus potential for\n    # division by zero.\n    stage = stages_impl.UniformQuantizationEncodingStage(bits=8, min_max=None)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.zeros([50]))\n    self.assertAllEqual(np.zeros((50)).astype(np.float32), test_data.decoded_x)\n\n  def test_commutes_with_sum_given_min_max(self):\n    stage = stages_impl.UniformQuantizationEncodingStage(bits=8,\n                                                         min_max=[-1.0, 1.0])\n    input_values = self.evaluate([tf.random.normal([50]) for _ in range(3)])\n    server_test_data, decode_params = self.run_many_to_one_encode_decode(\n        stage, input_values)\n    self.assert_commutes_with_sum(\n        server_test_data,\n        stage,\n        decode_params,\n        shape=input_values[0].shape)\n\n  @parameterized.parameters([0, 17, -1, 1.5])\n  def test_bits_out_of_range_raises(self, bits):\n    with self.assertRaisesRegexp(ValueError, \'integer between 1 and 16\'):\n      stages_impl.UniformQuantizationEncodingStage(bits=bits)\n\n  @parameterized.parameters([1.0, ([1.0, 2.0, 3.0],)])\n  def test_bad_min_max_tensor_raises(self, bad_min_max):\n    with self.assertRaisesRegexp(ValueError, r\'shape \\(2\\)\'):\n      stages_impl.UniformQuantizationEncodingStage(\n          min_max=tf.constant(bad_min_max))\n\n  @parameterized.parameters([([1.0],), ([1.0, 2.0, 3.0],)])\n  def test_bad_min_max_python_shape_raises(self, bad_min_max):\n    with self.assertRaisesRegexp(ValueError, \'list with two elements\'):\n      stages_impl.UniformQuantizationEncodingStage(min_max=bad_min_max)\n\n  @parameterized.parameters([([1.0, 1.0],), ([2.0, 1.0],)])\n  def test_bad_min_max_python_values_raises(self, bad_min_max):\n    with self.assertRaisesRegexp(ValueError, \'smaller than the second\'):\n      stages_impl.UniformQuantizationEncodingStage(min_max=bad_min_max)\n\n  def test_stochastic_tensor_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'stochastic\'):\n      stages_impl.UniformQuantizationEncodingStage(\n          stochastic=tf.constant(True, dtype=tf.bool))\n\n\nclass BitpackingEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return stages_impl.BitpackingEncodingStage(8)\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.cast(\n        tf.random.uniform([50], minval=0, maxval=255, dtype=tf.int32),\n        tf.float32)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    encoded_x = data.encoded_x[\n        stages_impl.BitpackingEncodingStage.ENCODED_VALUES_KEY]\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertEqual(np.int32, encoded_x.dtype)\n    self.assertGreaterEqual(data.x.size, encoded_x.size)\n\n  @parameterized.parameters(\n      itertools.product([1, 2, 3, 4, 7, 8, 9, 16],\n                        [(1,), (50,), (5, 5), (5, 6, 4)]))\n  def test_is_lossless(self, bits, shape):\n    # Tests that the encoding is lossless, for a variety of inputs.\n    def x_fn():\n      return tf.cast(\n          tf.random.uniform(\n              shape, minval=0, maxval=2**bits - 1, dtype=tf.int32), tf.float32)\n\n    stage = stages_impl.BitpackingEncodingStage(bits)\n    test_data = self.run_one_to_many_encode_decode(stage, x_fn)\n    self.assertAllClose(test_data.x, test_data.decoded_x)\n    self.assertEqual(test_data.x.dtype, test_data.decoded_x.dtype)\n\n  @parameterized.parameters([\n      (1, [[1 + 4 + 8]]),\n      (2, [[1 + 4**2 + 4**3]]),\n      (3, [[1 + 8**2 + 8**3]]),\n      (4, [[1 + 16**2 + 16**3]]),\n      (8, [[16842753], [0]])])\n  def test_encoded_values_as_expected(self, bits, expected_bitpacked_values):\n    # Tests that the packed values are as expected.\n    stage = stages_impl.BitpackingEncodingStage(bits)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.constant([1.0, 0.0, 1.0, 1.0, 0.0], dtype=tf.float32))\n    self.assertAllEqual(\n        expected_bitpacked_values, test_data.encoded_x[\n            stages_impl.BitpackingEncodingStage.ENCODED_VALUES_KEY])\n\n  def test_float_types(self):\n    # Tests that both float32 and float64 type work correctly.\n    stage = self.default_encoding_stage()\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.cast(self.default_input(), tf.float32))\n    self.assertAllClose(test_data.x, test_data.decoded_x)\n    self.assertEqual(np.float32, test_data.decoded_x.dtype)\n\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.cast(self.default_input(), tf.float64))\n    self.assertAllClose(test_data.x, test_data.decoded_x)\n    self.assertEqual(np.float64, test_data.decoded_x.dtype)\n\n  def test_bad_input_executes(self):\n    # Test that if input to encode is outside of the expected range, everything\n    # still executes, but the result is not correct.\n    x = np.array([2**9] * 5).astype(np.int32)\n    stage = stages_impl.BitpackingEncodingStage(8)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.constant(x, tf.float32))\n    self.assertNotAllClose(x, test_data.decoded_x.astype(np.int32))\n\n  @parameterized.parameters([tf.bool, tf.int32])\n  def test_encode_unsupported_type_raises(self, dtype):\n    stage = self.default_encoding_stage()\n    with self.assertRaisesRegexp(TypeError, \'Unsupported packing type\'):\n      self.run_one_to_many_encode_decode(\n          stage, lambda: tf.cast(self.default_input(), dtype))\n\n  def test_bad_input_bits_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'cannot be a TensorFlow value\'):\n      stages_impl.BitpackingEncodingStage(tf.constant(1, dtype=tf.int32))\n    with self.assertRaisesRegexp(ValueError, \'between 1 and 16\'):\n      stages_impl.BitpackingEncodingStage(0)\n    with self.assertRaisesRegexp(ValueError, \'between 1 and 16\'):\n      stages_impl.BitpackingEncodingStage(17)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/testing/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Testing utilities for the `tensor_encoding` package.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import AdaptiveNormalizeEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import aggregate_state_update_tensors\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import BaseEncodingStageTest\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import get_tensor_with_random_shape\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import is_adaptive_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import PlusOneEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import PlusOneOverNEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import PlusRandomNumEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import RandomAddSubtractOneEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import ReduceMeanEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import SignIntFloatEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import SimpleLinearEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import TestData\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing.test_utils import TimesTwoEncodingStage\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/testing/test_utils.py,65,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Testing utilities for the `tensor_encoding` package.\n\nThis file contains:\n* Base test class for testing implementations of the `EncodingStageInterface`.\n* Example implementations of the `EncodingStageInterface`. These example\nimplementations are used to test the base test class, and the `Encoder` class.\n* Other utilities useful for testing.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport collections\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport six\nfrom six.moves import range\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\nDEFAULT_RTOL = 1e-05\nDEFAULT_ATOL = 1e-05\n\n# Named tuple containing the values summarizing the results for a single\n# evaluation of an EncodingStageInterface or an AdaptiveEncodingStageInterface.\nTestData = collections.namedtuple(\n    \'TestData\',\n    [\n        \'x\',  # The input provided to encoding.\n        \'encoded_x\',  # A dictionary of values representing the encoded input x.\n        \'decoded_x\',  # Decoded value. Has the same shape as x.\n        # The fields below are only relevant for AdaptiveEncodingStageInterface,\n        # and will not be populated while testing an EncodingStageInterface.\n        \'initial_state\',  # Initial state used for encoding.\n        \'state_update_tensors\',  # State update tensors created by encoding.\n        \'updated_state\',  # Updated state after encoding.\n    ])\n# Set the dafault values to be None, to enable use of TestData while testing\n# EncodingStageInterface, without needing to be aware of the other fields.\nTestData.__new__.__defaults__ = (None,) * len(TestData._fields)\n\n\n# This metaclass enables adding abc.ABCMeta metaclass to a class inheriting from\n# parameterized.TestCase.\nclass ParameterizedABCMeta(abc.ABCMeta, parameterized.TestGeneratorMetaclass):\n  pass\n\n\n@six.add_metaclass(ParameterizedABCMeta)\nclass BaseEncodingStageTest(tf.test.TestCase, parameterized.TestCase):\n  """"""Abstract base class for testing encoding stage implementations.\n\n  Tests for each implementation of `EncodingStageInterface` and\n  `AdaptiveEncodingStageInterface` should implement this class, and add\n  additional tests specific to the behavior of the tested implementation.\n\n  This class contains basic tests, which every implementation of\n  `EncodingStageInterface` is expected to pass, and it contains a set of\n  utilities for testing.\n\n  In particular, the `test_one_to_many_encode_decode` and\n  `test_many_to_one_encode_decode` methods ensure the implementation does not\n  assume something that is not possible in scenarios where the class is meant to\n  be used.\n  """"""\n\n  # -----------------\n  # Abstract methods\n  # -----------------\n  @abc.abstractproperty\n  def is_lossless(self):\n    """"""Returns True if the encoding stage is lossless.\n\n    That is, if the `EncodingStageInterface` returned by\n    `default_encoding_stage` is such that encoding and decoding amounts to an\n    identity.\n\n    This property is used to determine whether to perform additional checks in\n    the test methods.\n    """"""\n\n  @abc.abstractmethod\n  def default_encoding_stage(self):\n    """"""Provides a default constructor for an encoding stage.\n\n    This is used for tests in the base class, which every implementation of\n    `EncodingStageInterface` is expected to pass.\n\n    Returns:\n      An instance of a concrete `EncodingStageInterface` to be tested.\n    """"""\n\n  @abc.abstractmethod\n  def default_input(self):\n    """"""Provides a default input for testing the encoding.\n\n    This is used for tests in the base class, which every implementation of\n    EncodingStageInterface is expected to pass.\n\n    The `shape` of the returned `Tensor` must be statically known.\n\n    Returns:\n      A `Tensor` object to be used as default testing input for encoding.\n    """"""\n\n  @abc.abstractmethod\n  def common_asserts_for_test_data(self, data):\n    """"""A collection of assertions for the results of encoding and decoding.\n\n    This method takes a `TestData` object and evaluates any user provided\n    expectations on the values. This method is used in multiple test methods and\n    should not use TensorFlow in any way, only perform the assertions.\n\n    Args:\n      data: A `TestData` tuple containing numpy values with results to be\n        evaluated.\n    """"""\n\n  # -------------\n  # Test methods\n  # -------------\n  def test_default_encoding_stage(self):\n    """"""Tests the correctness of `default_encoding_stage`.""""""\n    stage = self.default_encoding_stage()\n    self.assertIsInstance(stage,\n                          (encoding_stage.EncodingStageInterface,\n                           encoding_stage.AdaptiveEncodingStageInterface))\n    # Calling the method again should create a new instance.\n    new_stage = self.default_encoding_stage()\n    self.assertIsNot(stage, new_stage)\n\n  def test_encoding_stage_constructor_does_not_modify_graph(self):\n    """"""Tests that the constructor of encoding stage does not modify graph.""""""\n    graph_def = tf.compat.v1.get_default_graph().as_graph_def()\n    self.default_encoding_stage()\n    new_graph_def = tf.compat.v1.get_default_graph().as_graph_def()\n    tf.test.assert_equal_graph_def(graph_def, new_graph_def)\n\n  def test_encoding_stage_name(self):\n    """"""Tests that the `name` property returns a string.""""""\n    stage = self.default_encoding_stage()\n    self.assertIsInstance(stage.name, str)\n\n  def test_default_input_is_tensor_with_fully_defined_shape(self):\n    """"""Tests that `default_input` returns a `Tesnor` of fully defined shape.""""""\n    x = self.default_input()\n    self.assertIsInstance(x, tf.Tensor)\n    self.assertTrue(x.shape.is_fully_defined())\n\n  def test_basic_encode_decode(self):\n    """"""Tests the core functionality.\n\n    This test method uses the default encoding stage and default input, executes\n    encoding and decoding in the context of the same graph, and finally performs\n    custom asserts on the resulting data.\n    """"""\n    # Get Tensors representing the encoded and decoded values and perform\n    # generic type assertions.\n    x = self.default_input()\n    stage = self.default_encoding_stage()\n    if is_adaptive_stage(stage):\n      state = stage.initial_state()\n      encode_params, decode_params = stage.get_params(state)\n      encoded_x, decoded_x, state_update_tensors = self.encode_decode_x(\n          stage, x, encode_params, decode_params)\n      updated_state = stage.update_state(state, state_update_tensors)\n      test_data = TestData(x, encoded_x, decoded_x, state, state_update_tensors,\n                           updated_state)\n    else:\n      encode_params, decode_params = stage.get_params()\n      encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                  decode_params)\n      test_data = TestData(x, encoded_x, decoded_x)\n    self.generic_asserts(test_data, stage)\n\n    # Evaluate the Tensors and get numpy values.\n    test_data = self.evaluate_test_data(test_data)\n    if self.is_lossless:\n      self.assertAllClose(\n          test_data.x,\n          test_data.decoded_x,\n          rtol=DEFAULT_RTOL,\n          atol=DEFAULT_ATOL)\n    self.common_asserts_for_test_data(test_data)\n\n  def test_one_to_many_encode_decode(self):\n    """"""Tests the core functionality in the \'one-to-many\' case.\n\n    This method tests that the implementation can be used in a setting, where\n    the encoding happens in one location, decoding happens in anohter location,\n    and communication between these happens outside of TensorFlow.\n\n    In particular, this ensures that the implementation does not create\n    something incompatible with the use case, such as creating a TensorFlow\n    state during encoding, and accessing it during decoding.\n    """"""\n    # This just delegates to a utility, which can be used if the same needs to\n    # be tested with an input Tensor of specific properties, such as statically\n    # unknown shape, potentially with addional assertions.\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), self.default_input)\n    self.common_asserts_for_test_data(test_data)\n\n  def test_many_to_one_encode_decode(self):\n    """"""Tests the core functionality in the \'many-to-one\' case.\n\n    This method tests that the implementation can be used in a setting, where\n    the parameters are created in on location, communicated to a number of other\n    locations, where different inputs are encoded, and decoding happens in the\n    original location. The communication between these happens outside of\n    TensorFlow.\n\n    In particular, this ensures that the implementation does not create\n    something incompatible with the use case, such as creating a TensorFlow\n    state during encoding, and accessing it during decoding.\n    """"""\n    stage = self.default_encoding_stage()\n    input_values = self.evaluate([self.default_input() for _ in range(3)])\n    server_test_data, decode_params = self.run_many_to_one_encode_decode(\n        stage, input_values)\n\n    if self.is_lossless:\n      self.assertAllClose(\n          np.sum([d.x for d in server_test_data], axis=0),\n          np.sum([d.decoded_x for d in server_test_data], axis=0),\n          rtol=DEFAULT_RTOL,\n          atol=DEFAULT_ATOL)\n    if stage.commutes_with_sum:\n      self.assert_commutes_with_sum(server_test_data, stage, decode_params,\n                                    input_values[0].shape)\n    self.asserts_for_test_many_to_one_encode_decode(server_test_data)\n\n  # ------------------\n  # Testing utilities\n  # ------------------\n  def encode_decode_x(self, stage, x, encode_params, decode_params):\n    """"""Given params, encodes and decodes input `Tensor`.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`\n        to be used for encoding and decoding.\n      x: A `Tensor` to be encoded and decoded.\n      encode_params: Parameters to be provided to `stage.encode`\n      decode_params: Parameters to be provided to `stage.decode`\n\n    Returns:\n      A tuple (encoded_x, decoded_x) if `stage` is an `EncodingStageInterface`,\n      or a tuple (encoded_x, decoded_x, state_update_tensors) if `stage` is an\n      `AdaptiveEncodingStageInterface`, where these are:\n        encoded_x: A dictionary of `Tensor` objects representing the encoded\n          input `x`.\n        decoded_x: A single `Tensor`, representing decoded `encoded_x`.\n        state_update_tensors: A dictionary of `Tensor` objects representing the\n          information necessary for updating the state.\n    """"""\n    if is_adaptive_stage(stage):\n      encoded_x, state_update_tensors = stage.encode(x, encode_params)\n    else:\n      encoded_x = stage.encode(x, encode_params)\n\n    shape = None\n    if stage.decode_needs_input_shape:\n      shape = py_utils.static_or_dynamic_shape(x)\n    decoded_x = stage.decode(encoded_x, decode_params, shape=shape)\n\n    if is_adaptive_stage(stage):\n      return encoded_x, decoded_x, state_update_tensors\n    else:\n      return encoded_x, decoded_x\n\n  def run_one_to_many_encode_decode(self, stage, input_fn, state=None):\n    """"""Runs encoding and decoding in the one-to-many setting.\n\n    This method creates the input `Tensor` in the context of one graph, creates\n    and evaluates the encoded structure, along with `decode_params`. These are\n    used as Python constants in another graph to create and evaluate decoding.\n\n    The need for `input_fn`, as opposed to a simple numpy constant, is because\n    some stages need to work with `Tensor` objects that do not have statically\n    known shape. Such `Tensor` needs to be created in the context of the graph\n    in which it is to be evaluated, that is, inside of this method.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`\n        to be used for encoding.\n      input_fn: A callable object without arguments that creates and returns a\n        `Tensor` or numpy value to be used for encoding.\n      state: A dictionary representing the state. Can be set only if `stage` is\n        an `AdaptiveEncodingStageInterface`.\n\n    Returns:\n      A `TestData` tuple containing numpy values representing the results.\n    """"""\n\n    def _adaptive_one_to_many_encode_decode(state):\n      """"""Implementation of the method for `AdaptiveEncodingStageInterface`.""""""\n      server_graph = tf.Graph()\n      with server_graph.as_default():\n        x = input_fn()\n        shape = py_utils.static_or_dynamic_shape(x)\n        if state is None:\n          state = stage.initial_state()\n        encode_params, decode_params = stage.get_params(state)\n        encoded_x, state_update_tensors = stage.encode(x, encode_params)\n        updated_state = stage.update_state(state, state_update_tensors)\n\n        # Get all values out of TensorFlow as Python constants. This is a\n        # trivial example of communication happening outside of TensorFlow.\n        with self.session(graph=server_graph):\n          (x, decode_params, encoded_x, state, state_update_tensors,\n           updated_state, shape) = self.evaluate_tf_py_list([\n               x, decode_params, encoded_x, state, state_update_tensors,\n               updated_state, shape\n           ])\n\n      client_graph = tf.Graph()\n      with client_graph.as_default():\n        decoded_x = stage.decode(encoded_x, decode_params, shape=shape)\n        with self.session(graph=client_graph):\n          decoded_x = self.evaluate(decoded_x)\n\n      return TestData(x, encoded_x, decoded_x, state, state_update_tensors,\n                      updated_state)\n\n    def _non_adaptive_one_to_many_encode_decode():\n      """"""Implementation of the method for `EncodingStageInterface`.""""""\n      server_graph = tf.Graph()\n      with server_graph.as_default():\n        x = input_fn()\n        shape = py_utils.static_or_dynamic_shape(x)\n        encode_params, decode_params = stage.get_params()\n        encoded_x = stage.encode(x, encode_params)\n\n        # Get all values out of TensorFlow as Python constants. This is a\n        # trivial example of communication happening outside of TensorFlow.\n        with self.session(graph=server_graph):\n          x, decode_params, encoded_x, shape = self.evaluate_tf_py_list(\n              [x, decode_params, encoded_x, shape])\n\n      client_graph = tf.Graph()\n      with client_graph.as_default():\n        decoded_x = stage.decode(encoded_x, decode_params, shape=shape)\n        with self.session(graph=client_graph):\n          decoded_x = self.evaluate(decoded_x)\n\n      return TestData(x, encoded_x, decoded_x)\n\n    if is_adaptive_stage(stage):\n      return _adaptive_one_to_many_encode_decode(state)\n    else:\n      assert state is None\n      return _non_adaptive_one_to_many_encode_decode()\n\n  def run_many_to_one_encode_decode(self, stage, input_values, state=None):\n    """"""Runs encoding and decoding in the many-to-one setting.\n\n    This method creates and evaluates the parameters in the context of one\n    graph, which are used to create and evaluate encoding in a new graph for\n    every input value provided. These values are then decoded in the context of\n    the first graph. If the provided `stage` commutes with sum, this is in\n    addition verified.\n\n    Args:\n      stage: An `EncodingStageInterface` or an `AdaptiveEncodingStageInterface`\n        to be used for encoding.\n      input_values: A list of numpy values to be used for encoding. All must\n        have the same shape.\n      state: A dictionary representing the state. Can be set only if `stage` is\n        an `AdaptiveEncodingStageInterface`.\n\n    Returns:\n      A tuple `(server_test_data, decode_params)` where these are:\n      server_test_data: A `list` of `TestData` tuples containing numpy values\n        representing the results of encoding for each element of `input_values`.\n      decode_params: Numpy values of the decode parameters used. These are\n        values that should be used if additional decoding is to be done, such as\n        for `assert_commutes_with_sum`.\n    """"""\n\n    def _adaptive_many_to_one_encode_decode(state):\n      """"""Implementation of the method for `AdaptiveEncodingStageInterface`.""""""\n      server_graph = tf.Graph()\n      with server_graph.as_default():\n        shape = input_values[0].shape\n        if state is None:\n          state = stage.initial_state()\n        encode_params, decode_params = stage.get_params(state)\n        with self.session(server_graph) as sess:\n          encode_params, decode_params, state = self.evaluate_tf_py_list(\n              [encode_params, decode_params, state], sess)\n\n      client_test_data = []\n      for x in input_values:\n        client_graph = tf.Graph()\n        with client_graph.as_default():\n          encoded_x, state_update_tensors = stage.encode(x, encode_params)\n          with self.session(client_graph):\n            encoded_x, state_update_tensors = self.evaluate(\n                [encoded_x, state_update_tensors])\n            client_test_data.append(\n                TestData(\n                    x, encoded_x, state_update_tensors=state_update_tensors))\n\n      server_test_data = []\n      with server_graph.as_default():\n        with self.session(server_graph) as sess:\n          for test_data in client_test_data:\n            decoded_x = stage.decode(\n                test_data.encoded_x, decode_params, shape=shape)\n            server_test_data.append(\n                test_data._replace(\n                    decoded_x=sess.run(decoded_x), initial_state=state))\n          # Compute and append the updated state to all TestData objects.\n          all_state_update_tensors = [\n              d.state_update_tensors for d in server_test_data\n          ]\n          aggregated_state_update_tensors = aggregate_state_update_tensors(\n              stage, all_state_update_tensors)\n          updated_state = sess.run(\n              stage.update_state(state, aggregated_state_update_tensors))\n          server_test_data = [\n              d._replace(updated_state=updated_state) for d in server_test_data\n          ]\n\n      return server_test_data, decode_params\n\n    def _non_adaptive_many_to_one_encode_decode():\n      """"""Implementation of the method for `EncodingStageInterface`.""""""\n      server_graph = tf.Graph()\n      with server_graph.as_default():\n        shape = input_values[0].shape\n        encode_params, decode_params = stage.get_params()\n        with self.session(server_graph) as sess:\n          encode_params, decode_params = self.evaluate_tf_py_list(\n              [encode_params, decode_params], sess)\n\n      client_test_data = []\n      for x in input_values:\n        client_graph = tf.Graph()\n        with client_graph.as_default():\n          encoded_x = stage.encode(x, encode_params)\n          with self.session(client_graph):\n            encoded_x = self.evaluate(encoded_x)\n            client_test_data.append(TestData(x, encoded_x))\n\n      server_test_data = []\n      with server_graph.as_default():\n        with self.session(server_graph) as sess:\n          for test_data in client_test_data:\n            decoded_x = stage.decode(\n                test_data.encoded_x, decode_params, shape=shape)\n            server_test_data.append(\n                test_data._replace(decoded_x=sess.run(decoded_x)))\n      return server_test_data, decode_params\n\n    if is_adaptive_stage(stage):\n      return _adaptive_many_to_one_encode_decode(state)\n    else:\n      assert state is None\n      return _non_adaptive_many_to_one_encode_decode()\n\n  def evaluate_tf_py_list(self, fetches, session=None):\n    """"""Evaluates only provided `Tensor` objects and returns numpy values.\n\n    Different from `self.evaluate` or `session.run`, which only takes TensorFlow\n    objects to be evaluated, this method can take a combination of Python and\n    TensorFlow objects, separates them, evaluates only the TensorFlow objects,\n    and merges the resulting numpy values back with the original python values.\n\n    Args:\n      fetches: A `list` of fetches to be evalutated.\n      session: An optional `tf.Session` object to be used for evaluation, if\n        necessary to explicitly specify. If `None`, the default session will be\n        used.\n\n    Returns:\n      A list of the same structure as `fetches`, with TensorFlow objects\n      replaced by the result of single call to `self.evaluate` (or\n      `session.run`) with these TensorFlow objects as the input.\n    """"""\n    # Split the fetches to two structures.\n    py_fetches, tf_fetches = [], []\n    placeholder_empty_tuple = ()\n    assert isinstance(fetches, list), \'fetches should be a list.\'\n    for fetch in fetches:\n      if isinstance(fetch, dict):\n        d_py, d_tf = py_utils.split_dict_py_tf(fetch)\n        py_fetches.append(d_py)\n        tf_fetches.append(d_tf)\n      elif tf.is_tensor(fetch):\n        py_fetches.append(None)\n        tf_fetches.append(fetch)\n      else:\n        py_fetches.append(fetch)\n        # This empty tuple is here as a marker to retain the value from\n        # py_fetches, while keeping the list length same for simplicity of\n        # reconstruction. This is effectively None, but self.evaluate does not\n        # accept None as an input argument.\n        tf_fetches.append(placeholder_empty_tuple)\n\n    eval_fetches = self.maybe_evaluate(tf_fetches, session)\n    # Merge back the two structures, not containing Tensors.\n    for i, value in enumerate(eval_fetches):\n      if isinstance(value, dict):\n        eval_fetches[i] = py_utils.merge_dicts(value, py_fetches[i])\n      elif value == placeholder_empty_tuple:\n        eval_fetches[i] = py_fetches[i]\n    return eval_fetches\n\n  def evaluate_test_data(self, test_data, session=None):\n    """"""Evaluates a `TestData` object.\n\n    Args:\n      test_data: A `TestData` namedtuple.\n      session: Optional. A `tf.Session` object in the context of which the\n        evaluation is to happen.\n\n    Returns:\n      A new `TestData` object with `Tensor` objects in `test_data` replaced by\n      numpy values.\n\n    Raises:\n      TypeError: If `test_data` is not a `TestData` namedtuple.\n    """"""\n    if not isinstance(test_data, TestData):\n      raise TypeError(\'A TestData object must be provided.\')\n    _, data_tf = py_utils.split_dict_py_tf(test_data._asdict())\n    return test_data._replace(**self.maybe_evaluate(data_tf, session))\n\n  def maybe_evaluate(self, fetches, session=None):\n    """"""Evaluates `fetches`, if containing any `Tensor` objects.\n\n    Args:\n      fetches: Any nested structure compatible with `tf.nest`.\n      session: Optional. A `tf.Session` object in the context of which the\n        evaluation is to happen.\n\n    Returns:\n      `fetches` with any `Tensor` objects replaced by numpy values.\n    """"""\n    if any((tf.is_tensor(t) for t in tf.nest.flatten(fetches))):\n      if session:\n        fetches = session.run(fetches)\n      else:\n        fetches = self.evaluate(fetches)\n    return fetches\n\n  def generic_asserts(self, test_data, stage):\n    """"""Collection of static checks every implementation is expected to satisfy.\n\n    Args:\n      test_data: A `TestData` tuple. All values should contain `Tensor` objects.\n      stage: An `EncodingStageInterface` that generated the `test_data`.\n    """"""\n    # Every key in compressible_tensors_keys should be in encoded_x.\n    for key in stage.compressible_tensors_keys:\n      self.assertIn(key, test_data.encoded_x)\n\n    # The return structure of encode should only contain Tensor objects, and no\n    # Python constants.\n    for tensor in six.itervalues(test_data.encoded_x):\n      self.assertIsInstance(tensor, tf.Tensor)\n\n    # With a statically known input shape, the shape of decoded_x should be\n    # statically known. If not statically known, both should be unknown.\n    self.assertEqual(test_data.x.shape, test_data.decoded_x.shape)\n\n    # The encoding should always return the same dtype as the original dtype.\n    self.assertEqual(test_data.x.dtype, test_data.decoded_x.dtype)\n\n    # The encoded and decoded Tensors should have appropriate substrings in\n    # their names, as long as the encode or decode methods are not identities.\n    # If they are identities, encoded_x must be a dictionaty with a single key,\n    # mapping to the same Tensor as x or decoded_x, respectively. Note this is\n    # only relevant for graph execution mode.\n    if not tf.executing_eagerly():\n      if (len(test_data.encoded_x) > 1 or\n          test_data.x is not list(test_data.encoded_x.values())[0]):\n        for t in six.itervalues(test_data.encoded_x):\n          self.assertIn(encoding_stage.ENCODE_SCOPE_SUFFIX, t.name)\n      if (len(test_data.encoded_x) > 1 or\n          test_data.decoded_x is not list(test_data.encoded_x.values())[0]):\n        self.assertIn(encoding_stage.DECODE_SCOPE_SUFFIX,\n                      test_data.decoded_x.name)\n\n    if is_adaptive_stage(stage):\n      # The property should have keys matching those of state_update_tensors.\n      self.assertSameElements(stage.state_update_aggregation_modes.keys(),\n                              test_data.state_update_tensors.keys())\n      for mode in six.itervalues(stage.state_update_aggregation_modes):\n        self.assertIn(mode, encoding_stage.StateAggregationMode)\n\n      for tensor in six.itervalues(test_data.initial_state):\n        self.assertTrue(tf.is_tensor(tensor))\n      for tensor in six.itervalues(test_data.state_update_tensors):\n        self.assertTrue(tf.is_tensor(tensor))\n      for tensor in six.itervalues(test_data.updated_state):\n        self.assertTrue(tf.is_tensor(tensor))\n\n      # The state related Tensors should have appropriate substrings in their\n      # names.\n      if not tf.executing_eagerly():\n        for tensor in six.itervalues(test_data.initial_state):\n          self.assertIn(encoding_stage.INITIAL_STATE_SCOPE_SUFFIX, tensor.name)\n        for tensor in six.itervalues(test_data.updated_state):\n          self.assertIn(encoding_stage.UPDATE_STATE_SCOPE_SUFFIX, tensor.name)\n        for tensor in six.itervalues(test_data.state_update_tensors):\n          self.assertIn(encoding_stage.ENCODE_SCOPE_SUFFIX, tensor.name)\n\n  def asserts_for_test_many_to_one_encode_decode(self, data):\n    """"""Additional asserts for `test_many_to_one_encode_decode` method.\n\n    By default, this method simply calls `common_asserts_for_test_data` on every\n    element of `data`, but can be overridden by an implemented to provide custom\n    or additional checks.\n\n    Args:\n      data: A `list` of `TestData` tuples containing numpy values to be used for\n        the assertions.\n    """"""\n    for d in data:\n      self.common_asserts_for_test_data(d)\n\n  def assert_commutes_with_sum(self,\n                               server_test_data,\n                               stage,\n                               decode_params,\n                               shape=None):\n    """"""Asserts that provided `EncodingStageInterface` commutes with sum.\n\n    Given a list of `TestData` namedtuples containing numpy values of input and\n    corresponding encoded and decoded values, makes sure that the sum of the\n    decoded values is the same as first summing encoded values, and then\n    decoding.\n\n    Args:\n      server_test_data: A `list` of `TestData` namedtuples.\n      stage: An `EncodingStageInterface` object that was used to generate\n        `server_test_data` and is to be used in the assert.\n      decode_params: Parameters to be used for decoding by `stage`. Must be the\n        same values as used for generating `server_test_data`.\n      shape: An optional shape for the `decode` method of `stage`.\n    """"""\n    # This assert should be only used with an instance that commutes with sum.\n    assert stage.commutes_with_sum\n\n    num_summands = len(server_test_data)\n    expected_sum = np.sum([d.decoded_x for d in server_test_data], axis=0)\n    sum_encoded_x = {}\n    for k in server_test_data[0].encoded_x:\n      sum_encoded_x[k] = np.sum([d.encoded_x[k] for d in server_test_data],\n                                axis=0)\n    with tf.Graph().as_default():\n      with self.session() as sess:\n        decode_sum_encoded_x = sess.run(\n            stage.decode(sum_encoded_x, decode_params, num_summands, shape))\n    self.assertAllClose(\n        expected_sum,\n        decode_sum_encoded_x,\n        rtol=DEFAULT_RTOL,\n        atol=DEFAULT_ATOL)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass PlusOneEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, adding 1.\n\n  This is the simplest example implementation of an `EncodingStageInterface` -\n  no state, no constructor arguments, no shape information needed for decoding,\n  no commutativity with sum.\n  """"""\n\n  ENCODED_VALUES_KEY = \'p1_values\'\n  ADD_PARAM_KEY = \'p1_add\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'plus_one\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.ADD_PARAM_KEY: tf.constant(1.0)}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    return {self.ENCODED_VALUES_KEY: x + encode_params[self.ADD_PARAM_KEY]}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands, shape  # Unused.\n    decoded_x = (\n        encoded_tensors[self.ENCODED_VALUES_KEY] -\n        decode_params[self.ADD_PARAM_KEY])\n    return decoded_x\n\n\n@encoding_stage.tf_style_encoding_stage\nclass TimesTwoEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, multiplying by 2.\n\n  This is an example implementation of an `EncodingStageInterface` that commutes\n  with sum.\n  """"""\n\n  ENCODED_VALUES_KEY = \'t2_values\'\n  FACTOR_PARAM_KEY = \'t2_factor\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'times_two\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.FACTOR_PARAM_KEY: tf.constant(2.0)}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    return {self.ENCODED_VALUES_KEY: x * encode_params[self.FACTOR_PARAM_KEY]}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands, shape  # Unused.\n    decoded_x = (\n        encoded_tensors[self.ENCODED_VALUES_KEY] /\n        decode_params[self.FACTOR_PARAM_KEY])\n    return decoded_x\n\n\n@encoding_stage.tf_style_encoding_stage\nclass SimpleLinearEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, computing a simple linear transformation.\n\n  This is an example implementation of an `EncodingStageInterface` that can take\n  constructor arguments, which can be both python constants, or `tf.Variable`\n  objects, and subsequently expose those via `encode_params` / `decode_params`.\n\n  In addition, this is an example when commutativity with sum requires the\n  `num_summands` argument.\n  """"""\n\n  ENCODED_VALUES_KEY = \'sl_values\'\n  A_PARAM_KEY = \'sl_a_param\'\n  B_PARAM_KEY = \'sl_b_param\'\n\n  def __init__(self, a, b):\n    self._a = a\n    self._b = b\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'simple_linear\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.A_PARAM_KEY: self._a, self.B_PARAM_KEY: self._b}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    a, b = encode_params[self.A_PARAM_KEY], encode_params[self.B_PARAM_KEY]\n    return {self.ENCODED_VALUES_KEY: a * x + b}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del shape  # Unused.\n    a, b = decode_params[self.A_PARAM_KEY], decode_params[self.B_PARAM_KEY]\n    if num_summands is not None:\n      shift = b * tf.cast(num_summands, b.dtype)\n    else:\n      shift = b\n    return (encoded_tensors[self.ENCODED_VALUES_KEY] - shift) / a\n\n\n@encoding_stage.tf_style_encoding_stage\nclass ReduceMeanEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, computing a mean and remembering original shape.\n\n  This is an example implementation of an `EncodingStageInterface` that requires\n  the original shape information for decoding.\n\n  Note that the encoding does not store the shape in the return structure of the\n  `encode` method. Instead, the shape information will be handled separately by\n  the higher level `Encoder`.\n  """"""\n\n  ENCODED_VALUES_KEY = \'rm_values\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'reduce_mean\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    return {self.ENCODED_VALUES_KEY: tf.reduce_mean(x, keepdims=True)}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands, decode_params  # Unused.\n    return tf.tile(encoded_tensors[self.ENCODED_VALUES_KEY], shape)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass RandomAddSubtractOneEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, randomly adding or subtracting 1.\n\n  This is an example implementation of an `EncodingStageInterface` that is not\n  lossless, but unbiased on expectation. This is a propery of a variety\n  implementations of the interface, and this class serves as an example of how\n  the unbiasedness can be tested.\n  """"""\n\n  ENCODED_VALUES_KEY = \'ras_values\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'random_add_subtract\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    return {self.ENCODED_VALUES_KEY: x + tf.sign(tf.random.normal(tf.shape(x)))}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    return encoded_tensors[self.ENCODED_VALUES_KEY]\n\n\n@encoding_stage.tf_style_encoding_stage\nclass SignIntFloatEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, encoding input into multiple outputs.\n\n  This is an example implementation of an `EncodingStageInterface` that is\n  losless and splits the input into three components - the integer part, the\n  floating part and the signs.\n  """"""\n\n  ENCODED_SIGNS_KEY = \'sif_signs\'\n  ENCODED_INTS_KEY = \'sif_ints\'\n  ENCODED_FLOATS_KEY = \'sif_floats\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'sign_int_float\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [\n        self.ENCODED_SIGNS_KEY, self.ENCODED_INTS_KEY, self.ENCODED_FLOATS_KEY\n    ]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    signs = tf.sign(x)\n    abs_vals = tf.abs(x)\n    ints = tf.floor(abs_vals)\n    floats = abs_vals - ints\n    return {\n        self.ENCODED_SIGNS_KEY: signs,\n        self.ENCODED_INTS_KEY: ints,\n        self.ENCODED_FLOATS_KEY: floats\n    }\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    signs = encoded_tensors[self.ENCODED_SIGNS_KEY]\n    ints = encoded_tensors[self.ENCODED_INTS_KEY]\n    floats = encoded_tensors[self.ENCODED_FLOATS_KEY]\n    return signs * (ints + floats)\n\n\ndef dummy_rng_source(seed, num_elements):\n  """"""Dummy TensorFlow random number generator.\n\n  We need a custom random source, which would be always deterministic given a\n  random seed. That is not currently available available in TensorFlow. This\n  simple function serves an illustrative purpose. It is *not* a useful random\n  number generator, and should only be used in tests.\n\n  Args:\n    seed: A random seed.\n    num_elements: Number of random values to generate.\n\n  Returns:\n    A `Tensor` of shape `(num_elements)` containing pseudorandom values.\n  """"""\n\n  def next_num(num):\n    # This creates a cycle of length 136.\n    return tf.math.mod((num * 13), 137)\n\n  num = tf.reshape(tf.math.mod(seed, 136) + 1, (1,))\n  result = num\n  for _ in range(num_elements - 1):\n    num = next_num(num)\n    result = tf.concat([result, num], 0)\n  return tf.cast(result, tf.float32)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass PlusRandomNumEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""[Example] encoding stage, adding random values given a random seed.\n\n  This is an example implementation of an `EncodingStageInterface` that depends\n  on a shared random seed. The seed `Tensor` should be created in the\n  `get_params` method, and the same values should evantually be passed to both\n  `encode` and `decode` methods, making sure a randomized transform is\n  invertible.\n  """"""\n\n  ENCODED_VALUES_KEY = \'prn_values\'\n  SEED_PARAM_KEY = \'prn_seed\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'plus_random_num\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {\n        self.SEED_PARAM_KEY:\n            tf.random.uniform((), maxval=tf.int32.max, dtype=tf.int32)\n    }\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    addend = dummy_rng_source(encode_params[self.SEED_PARAM_KEY],\n                              x.shape.num_elements())\n    addend = tf.reshape(addend, x.shape)\n    return {self.ENCODED_VALUES_KEY: x + addend}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands, shape  # Unused.\n    x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    addend = dummy_rng_source(decode_params[self.SEED_PARAM_KEY],\n                              x.shape.num_elements())\n    addend = tf.reshape(addend, x.shape)\n    return x - addend\n\n\n@encoding_stage.tf_style_adaptive_encoding_stage\nclass PlusOneOverNEncodingStage(encoding_stage.AdaptiveEncodingStageInterface):\n  """"""[Example] adaptive encoding stage, adding 1/N in N-th iteration.\n\n  This is an example implementation of an `AdaptiveEncodingStageInterface` that\n  modifies state, which controls the creation of params. This is also a simple\n  example of how an `EncodingStageInterface` can be wrapped as an\n  `AdaptiveEncodingStageInterface`, without modifying the wrapped encode and\n  decode methods.\n  """"""\n\n  ENCODED_VALUES_KEY = PlusOneEncodingStage.ENCODED_VALUES_KEY\n  ADD_PARAM_KEY = PlusOneEncodingStage.ADD_PARAM_KEY\n  ITERATION_STATE_KEY = \'pn_iteration\'\n\n  def __init__(self):\n    self._stage = PlusOneEncodingStage()\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'plus_one_over_n\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def state_update_aggregation_modes(self):\n    """"""See base class.""""""\n    return {}\n\n  def initial_state(self):\n    """"""See base class.""""""\n    return {self.ITERATION_STATE_KEY: tf.constant(1, dtype=tf.int32)}\n\n  def update_state(self, state, state_update_tensors):\n    """"""See base class.""""""\n    del state_update_tensors  # Unused.\n    return {\n        self.ITERATION_STATE_KEY:\n            state[self.ITERATION_STATE_KEY] + tf.constant(1, dtype=tf.int32)\n    }\n\n  def get_params(self, state):\n    """"""See base class.""""""\n    params = {\n        self.ADD_PARAM_KEY:\n            1 / tf.cast(state[self.ITERATION_STATE_KEY], tf.float32)\n    }\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    return self._stage.encode(x, encode_params), {}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    return self._stage.decode(encoded_tensors, decode_params, num_summands,\n                              shape)\n\n\n@encoding_stage.tf_style_adaptive_encoding_stage\nclass AdaptiveNormalizeEncodingStage(\n    encoding_stage.AdaptiveEncodingStageInterface):\n  """"""[Example] encoding stage, adaptively normalizing data.\n\n  This is an example implementation of an `AdaptiveEncodingStageInterface` that\n  updates the state based on information stored in `state_update_tensors`. This\n  implementation wraps `TimesTwoEncodingStage`, and adaptively changes the\n  parameters that control the `encode` and `decode` methods.\n\n  It assumes that over iterations, the input values to be encoded come from\n  certain static distribution, and tries to find a good factor to normalize the\n  input to be of unit norm.\n  """"""\n\n  ENCODED_VALUES_KEY = TimesTwoEncodingStage.ENCODED_VALUES_KEY\n  FACTOR_PARAM_KEY = TimesTwoEncodingStage.FACTOR_PARAM_KEY\n  FACTOR_STATE_KEY = \'an_factor\'\n  NORM_STATE_UPDATE_KEY = \'an_norm\'\n\n  def __init__(self):\n    self._stage = TimesTwoEncodingStage()\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'adaptive_normalize\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def state_update_aggregation_modes(self):\n    """"""See base class.""""""\n    return {\n        self.NORM_STATE_UPDATE_KEY: encoding_stage.StateAggregationMode.STACK\n    }\n\n  def initial_state(self):\n    """"""See base class.""""""\n    return {self.FACTOR_STATE_KEY: tf.constant(1.0)}\n\n  # pylint: disable=g-doc-args,g-doc-return-or-yield\n  def update_state(self, state, state_update_tensors):\n    """"""Updates the state (see base class).\n\n    This method illustrates how the implementation can handle state update based\n    on a single encoding, or based on a multiple encodings collectively.\n\n    As specified by `self.state_update_aggregation_modes`, the\n    `NORM_STATE_UPDATE_KEY` from `state_update_tensors` are to be stacked. That\n    means, that the corresponding input to this method should be a `Tensor` with\n    each element corresponding to a single output of an encoding. So this can be\n    a single element, in the one-to-many setting, or multiple elements, in the\n    many-to-one setting.\n\n    The `update_state` method thus can compute arbitrary function of the\n    relevant values. In this case, it maintains a rolling average of previous\n    states, where the weight to be used depends on the number of updates\n    received. Note that the specific implementation is not necessarily useful or\n    efficient; it rather serves as an illustration of what can be done.\n    """"""\n    num_updates = state_update_tensors[\n        self.NORM_STATE_UPDATE_KEY].shape.num_elements()\n    norm_mean = tf.reduce_mean(state_update_tensors[self.NORM_STATE_UPDATE_KEY])\n    weight = 0.9**num_updates  # Use a stronger weight for more updates.\n    new_factor = (\n        weight * state[self.FACTOR_STATE_KEY] + (1 - weight) / norm_mean)\n    return {self.FACTOR_STATE_KEY: new_factor}\n\n  def get_params(self, state):\n    """"""See base class.""""""\n    params = {self.FACTOR_PARAM_KEY: state[self.FACTOR_STATE_KEY]}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    return (self._stage.encode(x, encode_params), {\n        self.NORM_STATE_UPDATE_KEY: tf.norm(x)\n    })\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    return self._stage.decode(encoded_tensors, decode_params, num_summands,\n                              shape)\n\n\n@encoding_stage.tf_style_adaptive_encoding_stage\nclass StateUpdateTensorsEncodingStage(\n    encoding_stage.AdaptiveEncodingStageInterface):\n  """"""[Example] encoding stage, using all `state_update_aggregation_modes`.""""""\n\n  ENCODED_VALUES_KEY = \'state_update_tensors_identity\'\n  SUM_STATE_UPDATE_KEY = \'state_update_tensors_update_sum\'\n  MIN_STATE_UPDATE_KEY = \'state_update_tensors_update_min\'\n  MAX_STATE_UPDATE_KEY = \'state_update_tensors_update_max\'\n  STACK_STATE_UPDATE_KEY = \'state_update_tensors_update_stack\'\n  LAST_SUM_STATE_KEY = \'state_update_tensors_state_sum\'\n  LAST_MIN_STATE_KEY = \'state_update_tensors_state_min\'\n  LAST_MAX_STATE_KEY = \'state_update_tensors_state_max\'\n  LAST_COUNT_STATE_KEY = \'state_update_tensors_state_stack\'\n\n  def __init__(self):\n    self._stage = TimesTwoEncodingStage()\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'state_update_tensors\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def state_update_aggregation_modes(self):\n    """"""See base class.""""""\n    return {\n        self.SUM_STATE_UPDATE_KEY: encoding_stage.StateAggregationMode.SUM,\n        self.MIN_STATE_UPDATE_KEY: encoding_stage.StateAggregationMode.MIN,\n        self.MAX_STATE_UPDATE_KEY: encoding_stage.StateAggregationMode.MAX,\n        self.STACK_STATE_UPDATE_KEY: encoding_stage.StateAggregationMode.STACK\n    }\n\n  def initial_state(self):\n    """"""See base class.""""""\n    return {\n        self.LAST_SUM_STATE_KEY: tf.constant(0.0),\n        self.LAST_MIN_STATE_KEY: tf.constant(0.0),\n        self.LAST_MAX_STATE_KEY: tf.constant(0.0),\n        self.LAST_COUNT_STATE_KEY: tf.constant(0, tf.int32)\n    }\n\n  def update_state(self, state, state_update_tensors):\n    """"""See base class.""""""\n    del state  # Unused.\n    return {\n        self.LAST_SUM_STATE_KEY:\n            tf.reduce_sum(state_update_tensors[self.SUM_STATE_UPDATE_KEY]),\n        self.LAST_MIN_STATE_KEY:\n            tf.reduce_min(state_update_tensors[self.MIN_STATE_UPDATE_KEY]),\n        self.LAST_MAX_STATE_KEY:\n            tf.reduce_max(state_update_tensors[self.MAX_STATE_UPDATE_KEY]),\n        self.LAST_COUNT_STATE_KEY:\n            tf.reduce_prod(\n                tf.shape(state_update_tensors[self.STACK_STATE_UPDATE_KEY]))\n    }\n\n  def get_params(self, state):\n    """"""See base class.""""""\n    del state  # Unused.\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    x = tf.identity(x)\n    return {\n        self.ENCODED_VALUES_KEY: x\n    }, {\n        self.SUM_STATE_UPDATE_KEY: x,\n        self.MIN_STATE_UPDATE_KEY: x,\n        self.MAX_STATE_UPDATE_KEY: x,\n        self.STACK_STATE_UPDATE_KEY: x\n    }\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    return tf.identity(encoded_tensors[self.ENCODED_VALUES_KEY])\n\n\ndef get_tensor_with_random_shape(expected_num_elements=10,\n                                 source_fn=tf.random.uniform):\n  """"""Returns a 1-D `Tensor` with random shape.\n\n  The `Tensor` is created by creating a `Tensor` with `2*expected_num_elements`\n  and inlcude each element in the rerurned `Tensor` with probability `0.5`.\n  Thus, the returned `Tensor` has unknown, and non-deterministic shape.\n\n  Args:\n    expected_num_elements: The number of elements the returned `Tensor` should\n      have on expectation.\n    source_fn: A Python callable that generates values for the returned\n      `Tensor`.\n\n  Returns:\n    A 1-D `Tensor` with random shape.\n  """"""\n  return tf.squeeze(\n      tf.gather(\n          source_fn([2 * expected_num_elements]),\n          tf.where(\n              tf.less(tf.random.uniform([2 * expected_num_elements]), 0.5))), 1)\n\n\ndef is_adaptive_stage(stage):\n  """"""Returns `True` if `stage` is an `AdaptiveEncodingStageInterface`.""""""\n  if isinstance(stage, encoding_stage.EncodingStageInterface):\n    assert not isinstance(stage, encoding_stage.AdaptiveEncodingStageInterface)\n    return False\n  elif isinstance(stage, encoding_stage.AdaptiveEncodingStageInterface):\n    return True\n  else:\n    raise TypeError(\n        \'The provided `stage` must be either `EncodingStageInterface` or \'\n        \'`AdaptiveEncodingStageInterface`.\')\n\n\ndef aggregate_state_update_tensors(stage, state_update_tensors):\n  """"""Aggregates a collection of values for state update.\n\n  This method in an trivial example of implementation of the aggregation modes,\n  when all the values are available as numpy values simultaneously.\n\n  Args:\n    stage: An `AdaptiveEncodingStageInterface` object.\n    state_update_tensors: A `list` of `dict` objects, each of which corresponds\n      to `state_update_tensors` generated by the `stage.encode` method. Each\n      dictionary thus needs to have the same structure, corresponding to\n      `stage.state_update_aggregation_modes`, and contain numpy values.\n\n  Returns:\n    A dictionary of aggregated values.\n\n  Raises:\n    TypeError: If `stage` is not an `AdaptiveEncodingStageInterface`.\n  """"""\n\n  def _aggregate(values, aggregation_mode):\n    """"""Aggregates values according to aggregation mode.""""""\n    if aggregation_mode == encoding_stage.StateAggregationMode.SUM:\n      return np.sum(np.stack(values), axis=0)\n    elif aggregation_mode == encoding_stage.StateAggregationMode.MAX:\n      return np.amax(np.stack(values), axis=0)\n    elif aggregation_mode == encoding_stage.StateAggregationMode.MIN:\n      return np.amin(np.stack(values), axis=0)\n    elif aggregation_mode == encoding_stage.StateAggregationMode.STACK:\n      return np.stack(values)\n\n  if not is_adaptive_stage(stage):\n    raise TypeError(\n        \'The provided `stage` must be an `AdaptiveEncodingStageInterface`.\')\n  aggregated_state_update_tensors = {}\n  for key, mode in six.iteritems(stage.state_update_aggregation_modes):\n    aggregated_state_update_tensors[key] = _aggregate(\n        [t[key] for t in state_update_tensors], mode)\n  return aggregated_state_update_tensors\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/testing/test_utils_test.py,30,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport mock\nimport numpy as np\nfrom six.moves import range\nfrom six.moves import zip\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass PlusOneEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.PlusOneEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(\n        data.x + 1.0,\n        data.encoded_x[test_utils.PlusOneEncodingStage.ENCODED_VALUES_KEY])\n\n\nclass TimesTwoEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.TimesTwoEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(\n        data.x * 2.0,\n        data.encoded_x[test_utils.TimesTwoEncodingStage.ENCODED_VALUES_KEY])\n\n\nclass SimpleLinearEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  _DEFAULT_A = 2.0\n  _DEFAULT_B = 3.0\n  _ENCODED_VALUES_KEY = test_utils.SimpleLinearEncodingStage.ENCODED_VALUES_KEY\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.SimpleLinearEncodingStage(self._DEFAULT_A,\n                                                self._DEFAULT_B)\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(data.x * self._DEFAULT_A + self._DEFAULT_B,\n                        data.encoded_x[self._ENCODED_VALUES_KEY])\n\n  def test_basic_encode_decode_tf_constructor_parameters(self):\n    """"""Tests the core funcionality with `tf.Variable` constructor parameters.""""""\n    a_var = tf.compat.v1.get_variable(\'a_var\', initializer=self._DEFAULT_A)\n    b_var = tf.compat.v1.get_variable(\'b_var\', initializer=self._DEFAULT_B)\n    stage = test_utils.SimpleLinearEncodingStage(a_var, b_var)\n\n    with self.cached_session() as sess:\n      sess.run(tf.compat.v1.global_variables_initializer())\n    x = self.default_input()\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n    self.common_asserts_for_test_data(test_data)\n\n    # Change the variables and verify the behavior of stage changes.\n    self.evaluate(\n        [tf.compat.v1.assign(a_var, 5.0),\n         tf.compat.v1.assign(b_var, 6.0)])\n    test_data = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n    self.assertAllClose(test_data.x * 5.0 + 6.0,\n                        test_data.encoded_x[self._ENCODED_VALUES_KEY])\n\n\nclass ReduceMeanEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.ReduceMeanEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(np.tile(np.mean(data.x), data.x.shape), data.decoded_x)\n    self.assertAllClose(\n        np.mean(data.x, keepdims=True),\n        data.encoded_x[test_utils.ReduceMeanEncodingStage.ENCODED_VALUES_KEY])\n\n  def test_one_to_many_with_unknown_shape(self):\n    """"""Tests that encoding works with statically not known input shape.""""""\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), test_utils.get_tensor_with_random_shape)\n    self.common_asserts_for_test_data(test_data)\n\n  @parameterized.parameters([2], [2, 3], [2, 3, 4], [2, 3, 4, 5])\n  def test_one_to_many_with_multiple_input_shapes(self, *shape):\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), lambda: tf.random.uniform(shape))\n    self.common_asserts_for_test_data(test_data)\n\n\nclass RandomAddSubtractOneEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  _VALUES_KEY = test_utils.RandomAddSubtractOneEncodingStage.ENCODED_VALUES_KEY\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.RandomAddSubtractOneEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    for x, decoded_x in zip(data.x, data.decoded_x):\n      self.assertTrue(\n          np.isclose(decoded_x, x - 1) or np.isclose(decoded_x, x) or\n          np.isclose(decoded_x, x + 1))\n    self.assertAllEqual(data.encoded_x[self._VALUES_KEY], data.decoded_x)\n\n  def test_approximately_unbiased_in_expectation(self):\n    """"""Tests that average of encodings is more accurate than a single one.""""""\n    # Use a constant input value.\n    x = self.evaluate(self.default_input())\n    stage = self.default_encoding_stage()\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = []\n    for _ in range(100):\n      test_data.append(\n          test_utils.TestData(\n              *self.evaluate_tf_py_list([x, encoded_x, decoded_x])))\n\n    # Check that the average error created by encoding is significantly larger\n    # than error of average of encodings. This is an simple (imperfect)\n    # empirical check that the encoding is unbiased.\n    mean_error = np.mean([np.linalg.norm(x - d.decoded_x) for d in test_data])\n    error_of_mean = np.linalg.norm(\n        x - np.mean([d.decoded_x for d in test_data], axis=0))\n    self.assertGreater(mean_error, error_of_mean * 5)\n\n\nclass SignIntFloatEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.SignIntFloatEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.constant([0.0, 0.1, -0.1, 0.9, -0.9, 1.6, -2.2])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    signs, ints, floats = (\n        data.encoded_x[test_utils.SignIntFloatEncodingStage.ENCODED_SIGNS_KEY],\n        data.encoded_x[test_utils.SignIntFloatEncodingStage.ENCODED_INTS_KEY],\n        data.encoded_x[test_utils.SignIntFloatEncodingStage.ENCODED_FLOATS_KEY])\n    self.assertAllEqual(np.array([0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0]), signs)\n    self.assertAllEqual(np.array([0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0]), ints)\n    self.assertAllClose(np.array([0.0, 0.1, 0.1, 0.9, 0.9, 0.6, 0.2]), floats)\n\n\nclass PlusRandomNumEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  _ENCODED_VALUES_KEY = test_utils.PlusRandomNumEncodingStage.ENCODED_VALUES_KEY\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.PlusRandomNumEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    frac_x, _ = np.modf(data.x)\n    frac_encoded_x, _ = np.modf(data.encoded_x[self._ENCODED_VALUES_KEY])\n    # The decimal places should be the same.\n    self.assertAllClose(\n        frac_x,\n        frac_encoded_x,\n        rtol=test_utils.DEFAULT_RTOL,\n        atol=test_utils.DEFAULT_ATOL)\n\n  def test_encoding_differs_given_different_seed(self):\n    """"""Tests that encoded_x is different in different evaluations.""""""\n    x = tf.constant(self.evaluate(self.default_input()))\n    stage = self.default_encoding_stage()\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data_1 = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n    test_data_2 = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n\n    # The decoded values should be the sam, but the encoded values not.\n    self.assertAllClose(\n        test_data_1.decoded_x,\n        test_data_2.decoded_x,\n        rtol=test_utils.DEFAULT_RTOL,\n        atol=test_utils.DEFAULT_ATOL)\n    self.assertNotAllClose(\n        test_data_1.encoded_x[self._ENCODED_VALUES_KEY],\n        test_data_2.encoded_x[self._ENCODED_VALUES_KEY],\n        rtol=test_utils.DEFAULT_RTOL,\n        atol=test_utils.DEFAULT_ATOL)\n\n\nclass PlusOneOverNEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  _ENCODED_VALUES_KEY = test_utils.PlusOneOverNEncodingStage.ENCODED_VALUES_KEY\n  _ADD_PARAM_KEY = test_utils.PlusOneOverNEncodingStage.ADD_PARAM_KEY\n  _ITERATION_KEY = test_utils.PlusOneOverNEncodingStage.ITERATION_STATE_KEY\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.PlusOneOverNEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(data.x + 1.0, data.encoded_x[self._ENCODED_VALUES_KEY])\n    self.assertAllClose(data.initial_state[self._ITERATION_KEY] + 1.0,\n                        data.updated_state[self._ITERATION_KEY])\n    self.assertDictEqual(data.state_update_tensors, {})\n\n  def test_one_to_many_few_rounds(self):\n    """"""Encoding and decoding in the one-to-many setting for a few rounds.\n\n    This is an example of how behavior of adaptive encoding stage can be tested\n    over multiple iterations of encoding. The one-to-many setting does not\n    include aggregation of state_update_tensors.\n    """"""\n    stage = self.default_encoding_stage()\n    state = self.evaluate(stage.initial_state())\n    for i in range(1, 5):\n      data = self.run_one_to_many_encode_decode(stage, self.default_input,\n                                                state)\n      self.assertAllClose(data.x, data.decoded_x)\n      self.assertAllClose(data.x + 1 / data.initial_state[self._ITERATION_KEY],\n                          data.encoded_x[self._ENCODED_VALUES_KEY])\n      self.assertEqual(data.initial_state[self._ITERATION_KEY], i)\n      self.assertDictEqual(data.state_update_tensors, {})\n      self.assertEqual(data.updated_state[self._ITERATION_KEY], i + 1.0)\n      state = data.updated_state\n\n  def test_many_to_one_few_rounds(self):\n    """"""Encoding and decoding in the many-to-one setting for a few rounds.\n\n    This is an example of how behavior of adaptive encoding stage can be tested\n    over multiple iterations of encoding, including the aggregation of\n    state_update_tensors.\n    """"""\n    stage = self.default_encoding_stage()\n    state = self.evaluate(stage.initial_state())\n    for i in range(1, 5):\n      input_values = self.evaluate([self.default_input() for _ in range(3)])\n      data, _ = self.run_many_to_one_encode_decode(stage, input_values, state)\n      for d in data:\n        self.assertAllClose(d.x, d.decoded_x)\n        self.assertAllClose(d.x + 1 / d.initial_state[self._ITERATION_KEY],\n                            d.encoded_x[self._ENCODED_VALUES_KEY])\n        self.assertEqual(d.initial_state[self._ITERATION_KEY], i)\n        self.assertDictEqual(d.state_update_tensors, {})\n        self.assertEqual(d.updated_state[self._ITERATION_KEY], i + 1.0)\n      state = data[0].updated_state\n\n\nclass AdaptiveNormalizeEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  _VALUES_KEY = test_utils.AdaptiveNormalizeEncodingStage.ENCODED_VALUES_KEY\n  _FACTOR_STATE_KEY = test_utils.AdaptiveNormalizeEncodingStage.FACTOR_STATE_KEY\n  _NORM_STATE_UPDATE_KEY = (\n      test_utils.AdaptiveNormalizeEncodingStage.NORM_STATE_UPDATE_KEY)\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.AdaptiveNormalizeEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([10])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertIn(self._NORM_STATE_UPDATE_KEY, data.state_update_tensors)\n\n  def test_one_to_many_few_rounds(self):\n    """"""Encoding and decoding in the one-to-many setting for a few rounds.\n\n    This is an example of how behavior of adaptive encoding stage can be tested\n    over multiple iterations of encoding. The one-to-many setting does not\n    include aggregation of state_update_tensors.\n    """"""\n    stage = self.default_encoding_stage()\n    state = self.evaluate(stage.initial_state())\n    for _ in range(5):\n      data = self.run_one_to_many_encode_decode(stage, lambda: tf.ones([10]),\n                                                state)\n      self.assertAllClose(data.x, data.decoded_x)\n      # Make sure the estimated factor is decreasing.\n      self.assertLess(data.updated_state[self._FACTOR_STATE_KEY],\n                      data.initial_state[self._FACTOR_STATE_KEY])\n      state = data.updated_state\n\n    # Run a few more times and verify that the factor is close to correct value.\n    # That means, the encoded values are close to having norm 1.\n    for _ in range(30):\n      data = self.run_one_to_many_encode_decode(stage, lambda: tf.ones([10]),\n                                                state)\n      state = data.updated_state\n    encoded_norm = np.linalg.norm(data.encoded_x[self._VALUES_KEY])\n    self.assertAllClose(1.0, encoded_norm, atol=0.1)\n\n  def test_many_to_one_few_rounds(self):\n    """"""Encoding and decoding in the many-to-one setting for a few rounds.\n\n    This is an example of how behavior of adaptive encoding stage can be tested\n    over multiple iterations of encoding, including the aggregation of\n    state_update_tensors.\n    """"""\n    stage = self.default_encoding_stage()\n    state = self.evaluate(stage.initial_state())\n    input_values = list(np.ones((3, 10), dtype=np.float32))\n    for _ in range(5):\n      data, _ = self.run_many_to_one_encode_decode(stage, input_values, state)\n      for d in data:\n        self.assertAllClose(d.x, d.decoded_x)\n        # Make sure the estimated factor is increasing.\n        self.assertLess(d.updated_state[self._FACTOR_STATE_KEY],\n                        d.initial_state[self._FACTOR_STATE_KEY])\n      state = data[0].updated_state\n\n    # Run a few more times and verify that the factor is close to correct value.\n    # That means, the encoded values are close to having norm 1.\n    for _ in range(20):\n      # input_values = self.evaluate([self.default_input() for _ in range(3)])\n      data, _ = self.run_many_to_one_encode_decode(stage, input_values, state)\n      state = data[0].updated_state\n    for d in data:\n      encoded_norm = np.linalg.norm(d.encoded_x[self._VALUES_KEY])\n      self.assertAllClose(1.0, encoded_norm, atol=0.002)\n\n\nclass StateUpdateTensorsEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return test_utils.StateUpdateTensorsEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([5])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllClose(data.x, data.decoded_x)\n    self.assertAllClose(\n        data.x, data.encoded_x[\n            test_utils.StateUpdateTensorsEncodingStage.ENCODED_VALUES_KEY])\n\n  def test_state_aggregation(self):\n    stage = self.default_encoding_stage()\n    # If a new StateAggregationMode is added, this test class should be updated.\n    self.assertSetEqual(\n        set(stage.state_update_aggregation_modes.values()),\n        set(encoding_stage.StateAggregationMode))\n\n    state = self.evaluate(stage.initial_state())\n    input_values = [\n        np.array([1.0, 5.0, 0.0]),\n        np.array([0.0, 0.0, 0.0]),\n        np.array([-3.0, 12.0, 0.1])\n    ]\n\n    data, _ = self.run_many_to_one_encode_decode(stage, input_values, state)\n    updated_state = data[0].updated_state\n    self.assertEqual(\n        15.1, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_SUM_STATE_KEY])\n    self.assertEqual(\n        -3.0, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_MIN_STATE_KEY])\n    self.assertEqual(\n        12.0, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_MAX_STATE_KEY])\n    self.assertEqual(\n        9, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_COUNT_STATE_KEY])\n\n    data, _ = self.run_many_to_one_encode_decode(stage,\n                                                 input_values + input_values,\n                                                 state)\n    updated_state = data[0].updated_state\n    self.assertEqual(\n        30.2, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_SUM_STATE_KEY])\n    self.assertEqual(\n        -3.0, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_MIN_STATE_KEY])\n    self.assertEqual(\n        12.0, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_MAX_STATE_KEY])\n    self.assertEqual(\n        18, updated_state[\n            test_utils.StateUpdateTensorsEncodingStage.LAST_COUNT_STATE_KEY])\n\n\nclass TestUtilsTest(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for other utilities in `test_utils.py`.""""""\n\n  def test_dummy_rng_source(self):\n    default_seed = 1\n    self.assertTrue(tf.is_tensor(test_utils.dummy_rng_source(default_seed, 1)))\n\n    # Test that the outputs are different given different seeds.\n    val_1 = self.evaluate(test_utils.dummy_rng_source(default_seed, 1))\n    val_2 = self.evaluate(test_utils.dummy_rng_source(default_seed + 1, 1))\n    self.assertNotEqual(val_1, val_2)\n\n    # Test the output Tensor has the correct shape.\n    self.assertEqual((3,), test_utils.dummy_rng_source(default_seed, 3).shape)\n    self.assertEqual((5,), test_utils.dummy_rng_source(default_seed, 5).shape)\n\n  def test_get_tensor_with_random_shape(self):\n    x = test_utils.get_tensor_with_random_shape()\n    self.assertIsInstance(x, tf.Tensor)\n    self.assertFalse(x.shape.is_fully_defined())\n    # Rank of the Tensor should be known, even though the dimension is not.\n    self.assertEqual(1, x.shape.ndims)\n\n    # Assert that unknown shape corresponds to a value of actually random shape\n    # at execution time.\n    samples = [self.evaluate(x) for _ in range(10)]\n    self.assertGreater(len(set([len(s) for s in samples])), 1)\n\n    # Test that source_fn has effect on the output values.\n    x_uniform = test_utils.get_tensor_with_random_shape(\n        expected_num_elements=50, source_fn=tf.random.uniform)\n    x_normal = test_utils.get_tensor_with_random_shape(\n        expected_num_elements=50, source_fn=tf.random.normal)\n    self.assertGreaterEqual(self.evaluate(tf.reduce_min(x_uniform)), 0.0)\n    self.assertLess(self.evaluate(tf.reduce_min(x_normal)), 0.0)\n\n  def test_is_adaptive_stage(self):\n    self.assertFalse(\n        test_utils.is_adaptive_stage(test_utils.PlusOneEncodingStage()))\n    self.assertTrue(\n        test_utils.is_adaptive_stage(test_utils.PlusOneOverNEncodingStage()))\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_is_adaptive_stage_raises(self, not_a_stage):\n    with self.assertRaises(TypeError):\n      test_utils.is_adaptive_stage(not_a_stage)\n\n  def test_aggregate_state_update_tensors(self):\n    test_state_update_aggregation_modes = {\n        \'sum\': encoding_stage.StateAggregationMode.SUM,\n        \'max\': encoding_stage.StateAggregationMode.MAX,\n        \'min\': encoding_stage.StateAggregationMode.MIN,\n        \'stack\': encoding_stage.StateAggregationMode.STACK\n    }\n    # Ensure every option is captured by this test.\n    self.assertSetEqual(\n        set(encoding_stage.StateAggregationMode),\n        set(test_state_update_aggregation_modes.values()))\n\n    mock_stage = mock.Mock(\n        spec=encoding_stage.AdaptiveEncodingStageInterface,\n        state_update_aggregation_modes=test_state_update_aggregation_modes)\n    array = np.array([[1.0, 2.0, -3.0], [-4.0, 5.0, 6.0]])\n    state_update_tensors = [{\n        \'sum\': array,\n        \'max\': array,\n        \'min\': array,\n        \'stack\': array\n    }, {\n        \'sum\': -array,\n        \'max\': -array,\n        \'min\': -array,\n        \'stack\': -array\n    }]\n    aggregated_tensors = test_utils.aggregate_state_update_tensors(\n        mock_stage, state_update_tensors)\n\n    self.assertAllEqual(aggregated_tensors[\'sum\'], np.zeros((2, 3)))\n    self.assertAllEqual(aggregated_tensors[\'max\'],\n                        np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]))\n    self.assertAllEqual(aggregated_tensors[\'min\'],\n                        np.array([[-1.0, -2.0, -3.0], [-4.0, -5.0, -6.0]]))\n    self.assertAllEqual(\n        aggregated_tensors[\'stack\'],\n        np.array([[[1.0, 2.0, -3.0], [-4.0, 5.0, 6.0]],\n                  [[-1.0, -2.0, 3.0], [4.0, -5.0, -6.0]]]))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/utils/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for the `tensor_encoding` package.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.py_utils import assert_compatible\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.py_utils import merge_dicts\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.py_utils import OrderedEnum\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.py_utils import split_dict_py_tf\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.py_utils import static_or_dynamic_shape\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import fast_walsh_hadamard_transform\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import pack_into_int\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import random_floats\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import random_floats_cmwc\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import random_signs\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import random_signs_cmwc\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils.tf_utils import unpack_from_int\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/utils/py_utils.py,11,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python utilities for the `tensor_encoding` package.\n\nThe methods in this file should not modify the TensorFlow graph.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\nimport numpy as np\nimport six\nimport tensorflow as tf\nimport tree\n\n\nclass OrderedEnum(enum.Enum):\n  """"""Ordered version of `Enum`.\n\n  As opposed to `IntEnum`, This class maintains other `Enum` invariants, such as\n  not being comparable to other enumerations.\n  """"""\n\n  def __ge__(self, other):\n    if self.__class__ is other.__class__:\n      return self.value >= other.value\n    return NotImplemented\n\n  def __gt__(self, other):\n    if self.__class__ is other.__class__:\n      return self.value > other.value\n    return NotImplemented\n\n  def __le__(self, other):\n    if self.__class__ is other.__class__:\n      return self.value <= other.value\n    return NotImplemented\n\n  def __lt__(self, other):\n    if self.__class__ is other.__class__:\n      return self.value < other.value\n    return NotImplemented\n\n\ndef static_or_dynamic_shape(value):\n  """"""Returns shape of the input `Tensor` or a `np.ndarray`.\n\n  If `value` is a `np.ndarray` or a `Tensor` with statically known shape, it\n  returns a Python object. Otherwise, returns result of `tf.shape(value)`.\n\n  Args:\n    value: A `Tensor` or a `np.ndarray` object.\n\n  Returns:\n    Static or dynamic shape of `value`.\n\n  Raises:\n    TypeError:\n      If the input is not a `Tensor` or a `np.ndarray` object.\n  """"""\n  if tf.is_tensor(value):\n    return value.shape if value.shape.is_fully_defined() else tf.shape(value)\n  elif isinstance(value, np.ndarray):\n    return value.shape\n  else:\n    raise TypeError(\'The provided input is not a Tensor or numpy array.\')\n\n\ndef split_dict_py_tf(dictionary):\n  """"""Splits dictionary based on Python and TensorFlow values.\n\n  Args:\n    dictionary: An arbitrary `dict`. Any `dict` objects in values will be\n      processed recursively.\n\n  Returns:\n    A tuple `(d_py, d_tf)`, where\n    d_py: A `dict` of the same structure as `dictionary`, with TensorFlow values\n      removed, recursively.\n    d_tf: A `dict` of the same structure as `dictionary`, with non-TensorFlow\n      values removed, recursively.\n\n  Raises:\n    TypeError:\n      If the input is not a `dict` object.\n  """"""\n  if not isinstance(dictionary, dict):\n    raise TypeError\n  d_py, d_tf = {}, {}\n  for k, v in six.iteritems(dictionary):\n    if isinstance(v, dict):\n      d_py[k], d_tf[k] = split_dict_py_tf(v)\n    else:\n      if tf.is_tensor(v):\n        d_tf[k] = v\n      else:\n        d_py[k] = v\n  return d_py, d_tf\n\n\ndef merge_dicts(dict1, dict2):\n  """"""Merges dictionaries of corresponding structure.\n\n  The inputs must be dictionaries, which have the same key only if the\n  corresponding values are also dictionaries, which will be processed\n  recursively.\n\n  This method is mainly to be used together with the `split_dict_py_tf` method.\n\n  Args:\n    dict1: An arbitrary `dict`.\n    dict2: A `dict`. A key is in both `dict1` and `dict2` iff both of the\n      corresponding values are also `dict` objects.\n\n  Returns:\n    A `dict` with values merged from the input dictionaries.\n\n  Raises:\n    TypeError:\n      If either of the input arguments is not a dictionary.\n    ValueError:\n      If the input dictionaries do not have corresponding structure.\n  """"""\n  merged_dict = {}\n  if not (isinstance(dict1, dict) and isinstance(dict2, dict)):\n    raise TypeError\n\n  for k, v in six.iteritems(dict1):\n    if isinstance(v, dict):\n      if not (k in dict2 and isinstance(dict2[k], dict)):\n        raise ValueError(\'Dictionaries must have the same structure.\')\n      merged_dict[k] = merge_dicts(v, dict2[k])\n    else:\n      merged_dict[k] = v\n\n  for k, v in six.iteritems(dict2):\n    if isinstance(v, dict):\n      if not (k in dict1 and isinstance(dict1[k], dict)):\n        # This should have been merged in previous loop.\n        raise ValueError(\'Dictionaries must have the same structure.\')\n    else:\n      if k in merged_dict:\n        raise ValueError(\'Dictionaries cannot contain the same key, unless the \'\n                         \'corresponding values are dictionaries.\')\n      merged_dict[k] = v\n\n  return merged_dict\n\n\ndef flatten_with_joined_string_paths(structure, separator=\'/\'):\n  """"""Replacement for deprecated tf.nest.flatten_with_joined_string_paths.""""""\n  return [(separator.join(map(str, path)), item)\n          for path, item in tree.flatten_with_path(structure)]\n\n\ndef assert_compatible(spec, value):\n  """"""Asserts that values are compatible with given specs.\n\n  Args:\n    spec: A structure compatible with `tf.nest`, with `tf.TensorSpec` values.\n    value: A collection of values that should be compatible with `spec`. Must be\n      the same structure as `spec`.\n\n  Raises:\n    TypeError: If `spec` does not contain only `tf.TensorSpec` objects.\n    ValueError: If the provided `value` is not compatible with `spec`.\n  """"""\n\n  def validate_spec(s, v):\n    if not isinstance(s, tf.TensorSpec):\n      raise TypeError(\'Each value in `spec` must be a tf.TensorSpec.\')\n    return s.is_compatible_with(v)\n\n  compatible = tf.nest.map_structure(validate_spec, spec, value)\n  if not all(tf.nest.flatten(compatible)):\n    raise ValueError(\'The provided value is not compatible with spec.\')\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/utils/py_utils_test.py,23,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import py_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass OrderedEnumTest(parameterized.TestCase):\n\n  def test_ordered_enum(self):\n    class Grade(py_utils.OrderedEnum):\n      A = 5\n      B = 4\n      C = 3\n      D = 2\n      F = 1\n\n    self.assertGreater(Grade.A, Grade.B)\n    self.assertLessEqual(Grade.F, Grade.C)\n    self.assertLess(Grade.D, Grade.A)\n    self.assertGreaterEqual(Grade.B, Grade.B)\n    self.assertEqual(Grade.B, Grade.B)\n    self.assertNotEqual(Grade.C, Grade.D)\n\n\nclass StaticOrDynamicShapeTest(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `static_or_dynamic_shape` method.""""""\n\n  def test_static_or_dynamic_shape(self):\n    # Tensor with statically known shape.\n    x = tf.constant([0.0, 2.0, -1.5])\n    self.assertAllEqual((3,), py_utils.static_or_dynamic_shape(x))\n\n    # Tensor without statically known shape.\n    x = tf.squeeze(tf.where(tf.less(tf.random.uniform([10]), 0.5)))\n    shape = py_utils.static_or_dynamic_shape(x)\n    self.assertIsInstance(shape, tf.Tensor)\n    x, shape = self.evaluate([x, shape])\n    self.assertLen(x, shape)\n\n    # Numpy value.\n    x = np.array([0.0, 2.0, -1.5])\n    self.assertAllEqual((3,), py_utils.static_or_dynamic_shape(x))\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_static_or_dynamic_shape_raises(self, bad_input):\n    with self.assertRaises(TypeError):\n      py_utils.static_or_dynamic_shape(bad_input)\n\n\nclass SplitMergeDictTest(parameterized.TestCase):\n  """"""Tests for `split_dict_py_tf` and `merge_dicts` methods.""""""\n\n  def test_split_dict_py_tf_empty(self):\n    """"""Tests that `split_dict_py_tf` works with empty dictionary.""""""\n    d_py, d_tf = py_utils.split_dict_py_tf({})\n    self.assertDictEqual({}, d_py)\n    self.assertDictEqual({}, d_tf)\n\n  def test_split_dict_py_tf_basic(self):\n    """"""Tests that `split_dict_py_tf` works with flat dictionary.""""""\n    const = tf.constant(2.0)\n    test_dict = {\'py\': 1.0, \'tf\': const}\n    expected_d_py = {\'py\': 1.0}\n    expected_d_tf = {\'tf\': const}\n    d_py, d_tf = py_utils.split_dict_py_tf(test_dict)\n    self.assertDictEqual(expected_d_py, d_py)\n    self.assertDictEqual(expected_d_tf, d_tf)\n\n  def test_split_dict_py_tf_nested(self):\n    """"""Tests that `split_dict_py_tf` works with nested dictionary.""""""\n    const_1, const_2 = tf.constant(1.0), tf.constant(2.0)\n    test_dict = {\n        \'nested\': {\n            \'a\': 1.0,\n            \'b\': const_1\n        },\n        \'py\': \'string\',\n        \'tf\': const_2\n    }\n    expected_d_py = {\n        \'nested\': {\n            \'a\': 1.0,\n        },\n        \'py\': \'string\',\n    }\n    expected_d_tf = {\'nested\': {\'b\': const_1}, \'tf\': const_2}\n    d_py, d_tf = py_utils.split_dict_py_tf(test_dict)\n    self.assertDictEqual(expected_d_py, d_py)\n    self.assertDictEqual(expected_d_tf, d_tf)\n\n  @parameterized.parameters(None, [[]], 2.0, \'string\')\n  def test_split_dict_py_tf_raises(self, bad_input):\n    """"""Tests that `split_dict_py_tf` raises `TypeError`.""""""\n    with self.assertRaises(TypeError):\n      py_utils.split_dict_py_tf(bad_input)\n\n  # pyformat: disable\n  @parameterized.parameters(\n      ({}, {}, {}),\n      ({\'a\': {\'b\': None}}, {\'a\': {\'c\': None}}, {\'a\': {\'b\': None, \'c\': None}}),\n      ({\'a\': 1}, {\'b\': None}, {\'a\': 1, \'b\': None}),\n      ({\'a\': 1}, {\'b\': 2}, {\'a\': 1, \'b\': 2}),\n      ({\'a\': {\'aa\': 11}, \'b\': 2},\n       {\'a\': {\'ab\': 12}},\n       {\'a\': {\'aa\': 11, \'ab\': 12}, \'b\': 2})\n      )\n  # pyformat: enable\n  def test_merge_dicts(self, dict1, dict2, expected_dict):\n    """"""Tests that `merge_dicts` works as expected.""""""\n    self.assertDictEqual(expected_dict, py_utils.merge_dicts(dict1, dict2))\n    self.assertDictEqual(expected_dict, py_utils.merge_dicts(dict2, dict1))\n\n  # pyformat: disable\n  @parameterized.parameters(\n      ({}),\n      ({\'py\': 1.0, \'tf\': tf.constant(1.0)}),\n      ({\'nested\': {\'a\': 1.0, \'b\': tf.constant(1.0)},\n        \'py\': \'string\', \'tf\': tf.constant(2.0)}))\n  # pyformat: enable\n  def test_split_merge_identity(self, **test_dict):\n    """"""Tests that spliting and merging amounts to identity.\n\n    This test method tests that using the `split_dict_py_tf` and `merge_dicts`\n    methods together amounts to an identity.\n\n    Args:\n      **test_dict: A dictionary to be used for the test.\n    """"""\n    new_dict = py_utils.merge_dicts(*py_utils.split_dict_py_tf(test_dict))\n    self.assertDictEqual(new_dict, test_dict)\n\n  # pyformat: disable\n  @parameterized.parameters(\n      (\'not_a_dict\', {\'a\': None}, TypeError),  # Not a dictionary.\n      ({\'a\': {\'b\': 0}}, {\'a\': None}, ValueError),  # Bad structure.\n      ({\'a\': {}}, {\'b\': {}}, ValueError),  # Bad structure.\n      ({\'a\': 1.0}, {\'a\': 2.0}, ValueError),  # Both values are set.\n      ({1: None}, {1.0: \'value\'}, ValueError))  # 1 and 1.0 are not the same.\n  # pyformat: enable\n  def test_merge_dicts_raises(self, bad_dict1, bad_dict2, error_type):\n    """"""Tests that `merge_dicts` raises appropriate error.""""""\n    with self.assertRaises(error_type):\n      py_utils.merge_dicts(bad_dict1, bad_dict2)\n    with self.assertRaises(error_type):\n      py_utils.merge_dicts(bad_dict2, bad_dict1)\n\n\nFoo = collections.namedtuple(\'Foo\', [\'a\', \'b\'])\nBar = collections.namedtuple(\'Bar\', [\'c\', \'d\'])\n\n\nclass NestReplacementTests(parameterized.TestCase):\n  """"""Tests for replacements of deprecated tf.nest symbols.""""""\n\n  @parameterized.parameters([\n      dict(inputs=[], expected=[]),\n      dict(inputs=[23, \'42\'], expected=[(\'0\', 23), (\'1\', \'42\')]),\n      dict(inputs=[[[[108]]]], expected=[(\'0/0/0/0\', 108)]),\n      dict(inputs=Foo(a=3, b=Bar(c=23, d=42)),\n           expected=[(\'a\', 3), (\'b/c\', 23), (\'b/d\', 42)]),\n      dict(inputs=Foo(a=Bar(c=23, d=42), b=Bar(c=0, d=\'thing\')),\n           expected=[(\'a/c\', 23), (\'a/d\', 42), (\'b/c\', 0), (\'b/d\', \'thing\')]),\n      dict(inputs=Bar(c=42, d=43),\n           expected=[(\'c\', 42), (\'d\', 43)]),\n      dict(inputs=Bar(c=[42], d=43),\n           expected=[(\'c/0\', 42), (\'d\', 43)]),\n  ])\n  def test_flatten_with_joined_string_paths(self, inputs, expected):\n    self.assertEqual(\n        py_utils.flatten_with_joined_string_paths(inputs, separator=\'/\'),\n        expected)\n\n\nclass AssertionsTest(parameterized.TestCase):\n  """"""Tests for custom assertions.""""""\n\n  def test_assert_compatible(self):\n    spec = [\n        tf.TensorSpec((2,), tf.int32),\n        (tf.TensorSpec((2, 3), tf.float64), tf.TensorSpec((), tf.float32))\n    ]\n    value = [\n        tf.zeros((2,), tf.int32),\n        (tf.zeros((2, 3), tf.float64), tf.zeros((), tf.float32))\n    ]\n    py_utils.assert_compatible(spec, value)\n    py_utils.assert_compatible(\n        tf.TensorSpec(None, tf.int32), tf.zeros((2,), tf.int32))\n\n  @parameterized.parameters([(2,), (2, 3), (2, 3, 4)])\n  def test_assert_compatible_raises_incompatible_dtype(self, *shape):\n    spec = tf.TensorSpec(shape, tf.float32)\n    value = tf.zeros(shape, tf.float64)\n    with self.assertRaises(ValueError):  # pylint: disable=g-error-prone-assert-raises\n      py_utils.assert_compatible(spec, value)\n\n  @parameterized.parameters([tf.float32, tf.float64, tf.int32, tf.int64])\n  def test_assert_compatible_raises_incompatible_shapes(self, dtype):\n    spec = tf.TensorSpec((2,), dtype)\n    value = tf.zeros((3,), dtype)\n    with self.assertRaises(ValueError):  # pylint: disable=g-error-prone-assert-raises\n      py_utils.assert_compatible(spec, value)\n\n  @parameterized.parameters([1.0, \'str\', object])\n  def test_assert_compatible_raises_type_error(self, not_a_spec):\n    with self.assertRaises(TypeError):  # pylint: disable=g-error-prone-assert-raises\n      py_utils.assert_compatible(not_a_spec, None)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/utils/tf_utils.py,85,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TensorFlow utilities for the `tensor_encoding` package.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef fast_walsh_hadamard_transform(x):\n  """"""Applies the fast Walsh-Hadamard transform to a set of vectors.\n\n  This method uses a composition of existing TensorFlow operations to implement\n  the transform.\n\n  Args:\n    x: A `Tensor`. Must be of shape `[a, b]`, where `a` can be anything (not\n      necessarily known), and `b` must be a power of two, not required to be\n      statically known.\n\n  Returns:\n    A `Tensor` of shape `[a, b]`, where `[i, :]` is the product `x[i, :]*H`,\n      where `H` is the Hadamard matrix.\n\n  Raises:\n    ValueError: If the input is not rank 2 `Tensor`, and if the second dimension\n      is statically known and is not a power of two.\n    OpError: If the second dimension is not statically known and is not a power\n      of two. Note that in graph execution, this error is not raised during the\n      execution of the Python function, but during execution of the resulting\n      computation.\n  """"""\n  with tf.compat.v1.name_scope(None, \'fast_walsh_hadamard_transform\'):\n    # Validate input.\n    x = tf.convert_to_tensor(x)\n    if x.shape.ndims != 2:\n      raise ValueError(\n          \'Number of dimensions of x must be 2. Shape of x: %s\' % x.shape)\n\n    original_x_shape = x.shape.as_list()\n    dim = x.shape.as_list()[-1]\n\n    if dim is None:  # dim is not statically known.\n      dim = tf.shape(x)[-1]\n      log2 = tf.cast(\n          tf.math.round(\n              tf.math.log(tf.cast(dim, tf.float32)) / tf.math.log(2.)),\n          tf.int32)\n      with tf.control_dependencies([\n          tf.compat.v1.assert_equal(\n              dim,\n              tf.math.pow(2, log2),\n              message=\'The dimension of x must be a power of two.\'\n              \'Provided dimension is: %s\' % dim)\n      ]):\n        x = tf.identity(x)\n    else:  # dim is statically known.\n      if not (dim and ((dim & (dim - 1)) == 0)):\n        raise ValueError(\'The dimension of x must be a power of two. \'\n                         \'Provided dimension is: %s\' % dim)\n      log2 = int(np.ceil(np.log2(dim)))\n      if dim == 1:  # Equivalent to identity.\n        return tf.identity(x)\n\n    h_core = tf.constant([[1., 1.], [1., -1.]],\n                         dtype=x.dtype,\n                         name=\'hadamard_weights_2x2\')\n    permutation = tf.constant([0, 2, 1], name=\'hadamard_permutation\')\n\n    # A step of the fast Walsh-Hadamard algorithm.\n    def _hadamard_step(x, dim):\n      """"""A single step in the fast Walsh-Hadamard transform.""""""\n      x_shape = x.shape.as_list()\n      x = tf.reshape(x, [-1, 2])  # Reshape so that we have a matrix.\n      x = tf.matmul(x, h_core)  # Multiply.\n      x = tf.reshape(x, [-1, dim // 2, 2])  # Reshape to rank-3.\n      x = tf.transpose(x, perm=permutation)  # Swap last two dimensions.\n      x.set_shape(x_shape)  # Failed shape inference in tf.while_loop.\n      return x\n\n    def _fwht(x, dim, log2):\n      x = tf.reshape(x, [-1, 2, dim // 2])\n      # The fast Walsh-Hadamard transform.\n\n      i = tf.constant(0)\n      c = lambda i, x: tf.less(i, log2)\n      b = lambda i, x: [i + 1, _hadamard_step(x, dim)]\n      i, x = tf.while_loop(c, b, [i, x])\n      return x\n\n    x = tf.cond(\n        tf.equal(dim, 1), lambda: tf.identity(x), lambda: _fwht(x, dim, log2))\n\n    x = tf.reshape(x, [-1, dim])\n    x /= tf.sqrt(tf.cast(dim, x.dtype))  # Normalize.\n    x.set_shape(original_x_shape)  # Failed shape inference after tf.while_loop.\n    return x\n\n\ndef _cmwc_random_sequence(num_elements, seed):\n  """"""Implements a version of the Complementary Multiply with Carry algorithm.\n\n  http://en.wikipedia.org/wiki/Multiply-with-carry\n\n  This implementation serves as a purely TensorFlow implementation of a fully\n  deterministic source of pseudo-random number sequence. That is given a\n  `Tensor` `seed`, this method will output a `Tensor` with `n` elements, that\n  will produce the same sequence when evaluated (assuming the same value of the\n  `Tensor` `seed`).\n\n  This method is not particularly efficient, does not come with any guarantee of\n  the period length, and should be replaced by appropriate alternative in\n  TensorFlow 2.x. In a test in general colab runtime, it took ~0.5s to generate\n  1 million values.\n\n  Args:\n    num_elements: A Python integer. The number of random values to be generated.\n    seed: A scalar `Tensor` of type `tf.int64`.\n\n  Returns:\n    A `Tensor` of shape `(num_elements)` and dtype tf.float64, containing random\n    values in the range `[0, 1)`.\n  """"""\n  if not isinstance(num_elements, int):\n    raise TypeError(\'The num_elements argument must be a Python integer.\')\n  if num_elements <= 0:\n    raise ValueError(\'The num_elements argument must be positive.\')\n  if not tf.is_tensor(seed) or seed.dtype != tf.int64:\n    raise TypeError(\'The seed argument must be a tf.int64 Tensor.\')\n\n  # For better efficiency of tf.while_loop, we generate `parallelism` random\n  # sequences in parallel. The specific constant (sqrt(num_elements) / 10) is\n  # hand picked after simple benchmarking for large values of num_elements.\n  parallelism = int(math.ceil(math.sqrt(num_elements) / 10))\n  num_iters = num_elements // parallelism + 1\n\n  # Create constants needed for the algorithm. The constants and notation\n  # follows from the above reference.\n  a = tf.tile(tf.constant([3636507990], tf.int64), [parallelism])\n  b = tf.tile(tf.constant([2**32], tf.int64), [parallelism])\n  logb_scalar = tf.constant(32, tf.int64)\n  logb = tf.tile([logb_scalar], [parallelism])\n  f = tf.tile(tf.constant([0], dtype=tf.int64), [parallelism])\n  bits = tf.constant(0, dtype=tf.int64, name=\'bits\')\n\n  # TensorArray used in tf.while_loop for efficiency.\n  values = tf.TensorArray(\n      dtype=tf.float64, size=num_iters, element_shape=[parallelism])\n  # Iteration counter.\n  num = tf.constant(0, dtype=tf.int32, name=\'num\')\n  # TensorFlow constant to be used at multiple places.\n  val_53 = tf.constant(53, tf.int64, name=\'val_53\')\n\n  # Construct initial sequence of seeds.\n  # From a single input seed, we construct multiple starting seeds for the\n  # sequences to be computed in parallel.\n  def next_seed_fn(i, val, q):\n    val = val**7 + val**6 + 1  # PRBS7.\n    q = q.write(i, val)\n    return i + 1, val, q\n\n  q = tf.TensorArray(dtype=tf.int64, size=parallelism, element_shape=())\n  _, _, q = tf.while_loop(lambda i, _, __: i < parallelism,\n                          next_seed_fn,\n                          [tf.constant(0), seed, q])\n  c = q = q.stack()\n\n  # The random sequence generation code.\n  def cmwc_step(f, bits, q, c, num, values):\n    """"""A single step of the modified CMWC algorithm.""""""\n    t = a * q + c\n    c = b - 1 - tf.bitwise.right_shift(t, logb)\n    x = q = tf.bitwise.bitwise_and(t, (b - 1))\n    f = tf.bitwise.bitwise_or(tf.bitwise.left_shift(f, logb), x)\n    if parallelism == 1:\n      f.set_shape((1,))  # Correct for failed shape inference.\n    bits += logb_scalar\n    def add_val(bits, f, values, num):\n      new_val = tf.cast(\n          tf.bitwise.bitwise_and(f, (2**val_53 - 1)),\n          dtype=tf.float64) * (1 / 2**val_53)\n      values = values.write(num, new_val)\n      f += tf.bitwise.right_shift(f, val_53)\n      bits -= val_53\n      num += 1\n      return bits, f, values, num\n    bits, f, values, num = tf.cond(bits >= val_53,\n                                   lambda: add_val(bits, f, values, num),\n                                   lambda: (bits, f, values, num))\n    return f, bits, q, c, num, values\n\n  def condition(f, bits, q, c, num, values):  # pylint: disable=unused-argument\n    return num < num_iters\n\n  _, _, _, _, _, values = tf.while_loop(\n      condition,\n      cmwc_step,\n      [f, bits, q, c, num, values],\n  )\n\n  values = tf.reshape(values.stack(), [-1])\n  # We generated parallelism * num_iters random values. Take a slice of the\n  # first num_elements for the requested Tensor.\n  values = values[:num_elements]\n  values.set_shape((num_elements,))  # Correct for failed shape inference.\n  return  values\n\n\ndef random_signs(num_elements, seed, dtype=tf.float32):\n  """"""Returns a Tensor of `num_elements` random +1/-1 values as `dtype`.\n\n  If run twice with the same seeds, it will produce the same pseudorandom\n  numbers. The output is consistent across multiple runs on the same hardware\n  (and between CPU and GPU), but may change between versions of TensorFlow or\n  on non-CPU/GPU hardware.\n\n  If consistency is required, use `random_signs_cmwc` instead.\n\n  Args:\n    num_elements: A Python integer. The number of random values to be generated.\n    seed: A shape [2] integer Tensor of seeds to the random number generator.\n    dtype: The type of the output.\n\n  Returns:\n    A Tensor of `num_elements` random +1/-1 values as `dtype`.\n  """"""\n  return tf.cast(\n      tf.sign(tf.random.stateless_uniform([num_elements], seed) - 0.5), dtype)\n\n\ndef random_floats(num_elements, seed, dtype=tf.float32):\n  """"""Returns a Tensor of `num_elements` random values in [0, 1) as `dtype`.\n\n  If run twice with the same seeds, it will produce the same pseudorandom\n  numbers. The output is consistent across multiple runs on the same hardware\n  (and between CPU and GPU), but may change between versions of TensorFlow or\n  on non-CPU/GPU hardware.\n\n  If consistency is required, use `random_floats_cmwc` instead.\n\n  Args:\n    num_elements: A Python integer. The number of random values to be generated.\n    seed: A shape [2] integer Tensor of seeds to the random number generator.\n    dtype: The type of the output.\n\n  Returns:\n    A Tensor of `num_elements` random values in [0, 1) as `dtype`.\n  """"""\n  if dtype not in [tf.float32, tf.float64]:\n    raise TypeError(\'Unsupported type: %s. Supported types are tf.float32 and \'\n                    \'tf.float64 values\' % dtype)\n  return tf.random.stateless_uniform([num_elements], seed, dtype=dtype)\n\n\ndef random_signs_cmwc(num_elements, seed, dtype=tf.float32):\n  """"""Returns a Tensor of `num_elements` random +1/-1 values as `dtype`.""""""\n  return tf.cast(\n      tf.sign(_cmwc_random_sequence(num_elements, seed) - 0.5), dtype)\n\n\ndef random_floats_cmwc(num_elements, seed, dtype=tf.float32):\n  """"""Returns a Tensor of `num_elements` random values in [0, 1) as `dtype`.""""""\n  if dtype not in [tf.float32, tf.float64]:\n    raise TypeError(\n        \'Unsupported type: %s. Supported types are tf.float32 and \'\n        \'tf.float64 values\' % dtype)\n  return tf.cast(_cmwc_random_sequence(num_elements, seed), dtype)\n\n\ndef pack_into_int(value, input_bitrange, target_bitrange):\n  """"""Pack integers in range [0, 2**`input_bitrange`-1] into integer values.\n\n  This utility simply concatenates the relevant bits of the input values into\n  a sequence of integer values.\n\n  The `target_bitrange` can be used to not use all bits of the return type.\n  This can be useful for instance when the resulting values can be serialized as\n  a varint. In such case, using only 7 bits per byte could be more desirable.\n\n  NOTE: This only uses basic math operations to implement the bit manipulation,\n  not any bitwise operations, which is relevant in environments where only a\n  subset of TensorFlow ops/kernels are available. If values outside of the\n  expected range are provided at runtime, an error will *not* be raised,\n  possibly returning an incorrect value.\n\n  Args:\n    value: An integer Tensor to be packed.\n    input_bitrange: An integer. The number of relevant bits in `value`.\n    target_bitrange: An integer. The number of bits to be used in packed\n      representation.\n\n  Returns:\n    An integer Tensor representing `value` of the same dtype as `value`.\n  """"""\n  if input_bitrange > 1:\n    value = tf.reshape(value, [-1, 1])\n    value = _expand_to_binary_form(value, input_bitrange)\n  return _pack_binary_form(value, target_bitrange)\n\n\ndef unpack_from_int(value, original_bitrange, target_bitrange, shape):\n  """"""Unpack integers into the range of [0, 2**`original_bitrange`-1].\n\n  This utility is to be used as the inverse of `pack_into_int` utility.\n\n  The shape of the original input is needed for uniqueness of the inverse\n  operation -- inputs of different shapes can be packed into the same\n  representation.\n\n  Args:\n    value: An integer Tensor to be unpacked.\n    original_bitrange: An integer. The number of bits used in the original\n      representation.\n    target_bitrange: An integer. The number of bits used in the packed\n      representation.\n    shape: The shape of the original input.\n\n  Returns:\n    An integer Tensor representing the unpacked `value` of the same dtype as\n    `value`.\n  """"""\n  value = _expand_to_binary_form(value, target_bitrange)\n  value = tf.slice(value, [0], [tf.reduce_prod(shape) * original_bitrange])\n  if original_bitrange > 1:\n    return tf.reshape(_pack_binary_form(value, original_bitrange), shape)\n  else:\n    return tf.reshape(value, shape)\n\n\ndef _pack_binary_form(value, target_bits):\n  # Reshape the binary input to have target_bits columns, padding with zeros if\n  # necessary to fit the dimension. The bitpacked representation is computed\n  # as product with vector [1, 2, 4, ..., 2**target_bits].\n  packing_vector = tf.constant([[2**i] for i in range(target_bits)],\n                               value.dtype)\n  extra_zeros = tf.zeros(\n      tf.math.mod(-tf.shape(value), target_bits), value.dtype)\n  reshaped_x = tf.reshape(tf.concat([value, extra_zeros], 0), [-1, target_bits])\n  return tf.matmul(reshaped_x, packing_vector)\n\n\ndef _expand_to_binary_form(value, input_bits):\n  # This operation is inverse of _pack_binary_form, except padded zeros are not\n  # removed.\n  expand_vector = tf.constant([2**i for i in range(input_bits)], value.dtype)\n  bits = tf.math.mod(tf.math.floordiv(value, expand_vector), 2)\n  return tf.reshape(bits, [-1])\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/utils/tf_utils_test.py,76,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport scipy.linalg\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import tf_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass FastWalshHadamardTransformTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `fast_walsh_hadamard_transform` method.""""""\n\n  @parameterized.parameters([2, 4, 8, 16])\n  def test_is_rotation(self, dim):\n    """"""Tests the transform acts as a rotation.""""""\n    x = tf.random.normal([1, dim])\n    hx = tf_utils.fast_walsh_hadamard_transform(x)\n    x, hx = self.evaluate([x, hx])\n    # Check that x and hx are not the same, but have equal norm.\n    self.assertGreater(np.linalg.norm(x - hx), 1e-3)\n    self.assertAllClose(np.linalg.norm(x), np.linalg.norm(hx))\n\n  @parameterized.parameters([1, 2, 5, 11])\n  def test_apply_twice_equals_identity(self, first_dim):\n    """"""Tests applying the transform twice is equal to identity.""""""\n    x = tf.random.normal([first_dim, 8])\n    hx = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx = tf_utils.fast_walsh_hadamard_transform(hx)\n    x, hhx = self.evaluate([x, hhx])\n    self.assertAllEqual(x.shape, hhx.shape)\n    self.assertAllClose(x, hhx)\n\n  @parameterized.parameters([[1], [1, 4, 4], [1, 1, 1, 4]])\n  def test_illegal_inputs_shape(self, *dims):\n    """"""Tests incorrect rank of the input.""""""\n    x = tf.random.normal(dims)\n    with self.assertRaisesRegexp(ValueError,\n                                 \'Number of dimensions of x must be 2.\'):\n      tf_utils.fast_walsh_hadamard_transform(x)\n\n  @parameterized.parameters([[1, 3], [1, 7], [1, 9], [4, 3]])\n  def test_illegal_inputs_static_power_of_two(self, *dims):\n    """"""Tests incorrect static shape of the rank 2 input.""""""\n    x = tf.random.normal(dims)\n    with self.assertRaisesRegexp(ValueError,\n                                 \'The dimension of x must be a power of two.\'):\n      tf_utils.fast_walsh_hadamard_transform(x)\n\n  def test_illegal_inputs_dynamic_power_of_two(self):\n    """"""Tests incorrect dynamic shape of the rank 2 input.""""""\n    rand = tf.random.uniform((), maxval=3, dtype=tf.int32) + 1\n    # The created x has shape (3, 3) or (3, 9) or (3, 27), chosen randomly and\n    # thus statically not known. In all cases, it is not a power of two.\n    x = tf.random.normal((3, 3**rand))\n    hx = tf_utils.fast_walsh_hadamard_transform(x)\n    with self.assertRaisesOpError(\'The dimension of x must be a power of two.\'):\n      hx = self.evaluate(hx)\n\n  @parameterized.parameters([[1, 1], [4, 1], [2, 2], [1, 8], [1, 4]])\n  def test_static_input_shape(self, *dims):\n    """"""Tests static input shape.""""""\n    x = tf.random.normal(dims)\n    hx_tf = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx_tf = tf_utils.fast_walsh_hadamard_transform(hx_tf)\n\n    x, hx_tf, hhx_tf = self.evaluate([x, hx_tf, hhx_tf])\n    self.assertAllEqual(x.shape, hhx_tf.shape)\n    self.assertAllClose(x, hhx_tf)\n\n  @parameterized.parameters([[1, 1], [4, 1], [2, 2], [1, 8], [1, 4]])\n  def test_static_input_output_shape(self, *dims):\n    """"""Tests static output shape is identical to static input shape.""""""\n    x = tf.random.normal(dims)\n    hx_tf = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx_tf = tf_utils.fast_walsh_hadamard_transform(hx_tf)\n    self.assertEqual(list(dims), hx_tf.shape.as_list())\n    self.assertEqual(list(dims), hhx_tf.shape.as_list())\n\n  def test_dynamic_input_shape(self):\n    """"""Tests dynamic input shape.""""""\n    rand = tf.random.uniform((), maxval=4, dtype=tf.int32)\n    x = tf.random.normal((3, 2**rand))\n    hx_tf = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx_tf = tf_utils.fast_walsh_hadamard_transform(hx_tf)\n    x, hx_tf, hhx_tf = self.evaluate([x, hx_tf, hhx_tf])\n    self.assertAllEqual(x.shape, hhx_tf.shape)\n    self.assertAllClose(x, hhx_tf)\n\n  def test_dynamic_input_shape_dim_one(self):\n    """"""Tests input shape where the second dimension is 1, dynamically known.""""""\n    rand = tf.random.uniform((), maxval=1, dtype=tf.int32)\n    x = tf.random.normal((3, 2**rand))\n    hx_tf = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx_tf = tf_utils.fast_walsh_hadamard_transform(hx_tf)\n    x, hx_tf, hhx_tf = self.evaluate([x, hx_tf, hhx_tf])\n    self.assertAllEqual(x.shape, hhx_tf.shape)\n    self.assertAllClose(x, hhx_tf)\n\n  @parameterized.parameters([2, 4, 8, 16])\n  def test_output_same_as_simple_python_implementation(self, dim):\n    """"""Tests result is identical to inefficient implementation using scipy.""""""\n    x = tf.random.normal([3, dim])\n    hx_tf = tf_utils.fast_walsh_hadamard_transform(x)\n    hhx_tf = tf_utils.fast_walsh_hadamard_transform(hx_tf)\n    x, hx_tf, hhx_tf = self.evaluate([x, hx_tf, hhx_tf])\n\n    hadamard_matrix = scipy.linalg.hadamard(dim)\n    hx_py = np.dot(x, hadamard_matrix) / np.sqrt(dim)\n    hhx_py = np.dot(hx_py, hadamard_matrix) / np.sqrt(dim)\n    self.assertAllClose(hx_py, hx_tf)\n    self.assertAllClose(hhx_py, hhx_tf)\n\n\nclass CMWCRandomSequenceTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `_cmwc_random_sequence` method.""""""\n\n  @parameterized.parameters([1, 2, 99, 100, 101, 12345])\n  def test_expected_output_shape(self, num_elements):\n    sequence = tf_utils._cmwc_random_sequence(num_elements,\n                                              tf.constant(123, tf.int64))\n    self.assertAllEqual([num_elements], sequence.shape.as_list())\n    self.assertEqual(tf.float64, sequence.dtype)\n    sequence = self.evaluate(sequence)\n    self.assertAllGreaterEqual(sequence, 0.0)\n    self.assertAllLessEqual(sequence, 1.0)\n\n  def test_deterministic_given_seed(self):\n    sequence_1 = tf_utils._cmwc_random_sequence(10, tf.constant(123, tf.int64))\n    sequence_2 = tf_utils._cmwc_random_sequence(10,\n                                                tf.constant(120 + 3, tf.int64))\n    sequence_1, sequence_2 = self.evaluate([sequence_1, sequence_2])\n    self.assertAllEqual(sequence_1, sequence_2)\n\n  def test_differs_given_different_seed(self):\n    sequence_1 = tf_utils._cmwc_random_sequence(100, tf.constant(123, tf.int64))\n    sequence_2 = tf_utils._cmwc_random_sequence(100, tf.constant(\n        1234, tf.int64))\n    sequence_1, sequence_2 = self.evaluate([sequence_1, sequence_2])\n    self.assertFalse(np.array_equal(sequence_1, sequence_2))\n\n  def test_approximately_uniform_distribution(self):\n    sequence = tf_utils._cmwc_random_sequence(100000, tf.constant(\n        123, tf.int64))\n    sequence = self.evaluate(sequence)\n    bucket_counts, _ = np.histogram(sequence, bins=10, range=(0, 1))\n    self.assertAllGreaterEqual(bucket_counts, 9750)\n    self.assertAllLessEqual(bucket_counts, 10250)\n\n  def test_tensor_num_elements_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'must be a Python integer\'):\n      tf_utils._cmwc_random_sequence(\n          tf.constant(10), tf.constant(123, tf.int64))\n\n  def test_negative_num_elements_raises(self):\n    with self.assertRaisesRegexp(ValueError, \'must be positive\'):\n      tf_utils._cmwc_random_sequence(-10, tf.constant(123, tf.int64))\n\n  def test_python_seed_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'tf.int64 Tensor\'):\n      tf_utils._cmwc_random_sequence(10, 123)\n\n  def test_tf_int32_seed_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'tf.int64 Tensor\'):\n      tf_utils._cmwc_random_sequence(10, tf.constant(123, tf.int32))\n\n\nclass RandomSignsCMWCTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `random_signs_cmwc` method.""""""\n\n  @parameterized.parameters([1, 10, 101])\n  def test_expected_output_values(self, num_elements):\n    signs = tf_utils.random_signs_cmwc(num_elements, tf.constant(123, tf.int64))\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n\n  def test_both_values_present(self):\n    signs = tf_utils.random_signs_cmwc(1000, tf.constant(123, tf.int64))\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n    self.assertGreater(sum(np.isclose(1.0, signs)), 400)\n    self.assertGreater(sum(np.isclose(-1.0, signs)), 400)\n\n  @parameterized.parameters([tf.float32, tf.float64, tf.int32, tf.int64])\n  def test_expected_dtype(self, dtype):\n    signs = tf_utils.random_signs_cmwc(10, tf.constant(123, tf.int64), dtype)\n    self.assertEqual(dtype, signs.dtype)\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n\n  def test_differs_given_different_seed(self):\n    signs_1 = tf_utils.random_signs_cmwc(100, tf.constant(123, tf.int64))\n    signs_2 = tf_utils.random_signs_cmwc(100, tf.constant(1234, tf.int64))\n    signs_1, signs_2 = self.evaluate([signs_1, signs_2])\n    self.assertFalse(np.array_equal(signs_1, signs_2))\n\n  def _assert_signs(self, x):\n    size = len(x)\n    self.assertAllEqual([True] * size,\n                        np.logical_or(np.isclose(1.0, x), np.isclose(-1.0, x)))\n\n\nclass RandomFloatsCMWCTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `random_floats_cmwc` method.""""""\n\n  @parameterized.parameters([tf.float32, tf.float64])\n  def test_expected_dtype(self, dtype):\n    floats = tf_utils.random_floats_cmwc(10, tf.constant(456, tf.int64), dtype)\n    self.assertEqual(dtype, floats.dtype)\n\n  @parameterized.parameters([tf.int32, tf.int64])\n  def test_type_error_raises(self, dtype):\n    with self.assertRaisesRegexp(\n        TypeError, \'Supported types are tf.float32 and \'\n        \'tf.float64 values\'):\n      tf_utils.random_floats_cmwc(10, tf.constant(456, tf.int64), dtype)\n\n  def test_differs_given_different_seed(self):\n    floats_1 = tf_utils.random_floats_cmwc(100, tf.constant(123, tf.int64))\n    floats_2 = tf_utils.random_floats_cmwc(100, tf.constant(122, tf.int64))\n    floats_1, floats_2 = self.evaluate([floats_1, floats_2])\n    self.assertFalse(np.array_equal(floats_1, floats_2))\n\n\nclass RandomSignsTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `random_signs` method.""""""\n\n  @parameterized.parameters([1, 10, 101])\n  def test_expected_output_values(self, num_elements):\n    signs = tf_utils.random_signs(num_elements, tf.constant([123, 456],\n                                                            tf.int64))\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n\n  def test_both_values_present(self):\n    signs = tf_utils.random_signs(1000, tf.constant([123, 456], tf.int64))\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n    self.assertGreater(sum(np.isclose(1.0, signs)), 400)\n    self.assertGreater(sum(np.isclose(-1.0, signs)), 400)\n\n  @parameterized.parameters([tf.float32, tf.float64, tf.int32, tf.int64])\n  def test_expected_dtype(self, dtype):\n    signs = tf_utils.random_signs(10, tf.constant([123, 456], tf.int64), dtype)\n    self.assertEqual(dtype, signs.dtype)\n    signs = self.evaluate(signs)\n    self._assert_signs(signs)\n\n  def test_differs_given_different_seed(self):\n    signs_1 = tf_utils.random_signs(100, tf.constant([123, 456], tf.int64))\n    signs_2 = tf_utils.random_signs(100, tf.constant([1234, 456], tf.int64))\n    signs_1, signs_2 = self.evaluate([signs_1, signs_2])\n    self.assertFalse(np.array_equal(signs_1, signs_2))\n\n  def _assert_signs(self, x):\n    size = len(x)\n    self.assertAllEqual([True] * size,\n                        np.logical_or(np.isclose(1.0, x), np.isclose(-1.0, x)))\n\n\nclass RandomFloatsTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for `random_floats` method.""""""\n\n  @parameterized.parameters([tf.float32, tf.float64])\n  def test_expected_dtype(self, dtype):\n    floats = tf_utils.random_floats(10, tf.constant([456, 123], tf.int64),\n                                    dtype)\n    self.assertEqual(dtype, floats.dtype)\n\n  @parameterized.parameters([tf.int32, tf.int64])\n  def test_type_error_raises(self, dtype):\n    with self.assertRaisesRegexp(TypeError,\n                                 \'Supported types are tf.float32 and \'\n                                 \'tf.float64 values\'):\n      tf_utils.random_floats(10, tf.constant([456, 123], tf.int64), dtype)\n\n  def test_differs_given_different_seed(self):\n    floats_1 = tf_utils.random_floats(100, tf.constant([123, 456], tf.int64))\n    floats_2 = tf_utils.random_floats(100, tf.constant([122, 456], tf.int64))\n    floats_1, floats_2 = self.evaluate([floats_1, floats_2])\n    self.assertFalse(np.array_equal(floats_1, floats_2))\n\n\nclass PackingUtilsTests(tf.test.TestCase, parameterized.TestCase):\n  """"""Tests for bit-packing utilities.""""""\n\n  @parameterized.parameters(\n      itertools.product([\n          (1, [[1 + 4 + 8]]),\n          (2, [[1 + 4**2 + 4**3]]),\n          (3, [[1 + 8**2 + 8**3]]),\n          (4, [[1 + 16**2 + 16**3]]),\n          (8, [[16842753], [0]])\n      ], [tf.int32, tf.int64])\n      )\n  def test_pack_into_int(self, test_values, dtype):\n    input_bitrange, expected_packed_value = test_values\n    value = tf.constant([1, 0, 1, 1, 0], dtype)\n    packed_value = tf_utils.pack_into_int(\n        value, input_bitrange, target_bitrange=28)\n    self.assertEqual(dtype, packed_value.dtype)\n    self.assertAllEqual(expected_packed_value, self.evaluate(packed_value))\n\n  @parameterized.parameters(\n      itertools.product([\n          (1, [[1 + 4 + 8]]),\n          (2, [[1 + 4**2 + 4**3]]),\n          (3, [[1 + 8**2 + 8**3]]),\n          (4, [[1 + 16**2 + 16**3]]),\n          (8, [[16842753], [0]])\n      ], [tf.int32, tf.int64])\n      )\n  def test_unpack_from_int(self, test_values, dtype):\n    original_bitrange, packed_value = test_values\n    packed_value = tf.constant(packed_value, dtype)\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange, target_bitrange=28, shape=(5,))\n    self.assertEqual(dtype, unpacked_value.dtype)\n    self.assertAllEqual([1, 0, 1, 1, 0], self.evaluate(unpacked_value))\n\n  def test_unpack_from_int_different_outputs(self):\n    packed_value = tf.constant([[1 + 2**3]], tf.int32)\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=1, target_bitrange=28, shape=(4,))\n    self.assertAllEqual([1, 0, 0, 1], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=1, target_bitrange=28, shape=(5,))\n    self.assertAllEqual([1, 0, 0, 1, 0], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=2, target_bitrange=28, shape=(2,))\n    self.assertAllEqual([1, 2], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=2, target_bitrange=28, shape=(3,))\n    self.assertAllEqual([1, 2, 0], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=3, target_bitrange=28, shape=(2,))\n    self.assertAllEqual([1, 1], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=3, target_bitrange=28, shape=(3,))\n    self.assertAllEqual([1, 1, 0], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=4, target_bitrange=28, shape=(1,))\n    self.assertAllEqual([9], self.evaluate(unpacked_value))\n\n    unpacked_value = tf_utils.unpack_from_int(\n        packed_value, original_bitrange=4, target_bitrange=28, shape=(2,))\n    self.assertAllEqual([9, 0], self.evaluate(unpacked_value))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_configs.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Default 8-bit QuantizeConfigs.""""""\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\n\nclass Default8BitOutputQuantizeConfig(quantize_config.QuantizeConfig):\n  """"""QuantizeConfig which only quantizes the output from a layer.""""""\n\n  def get_weights_and_quantizers(self, layer):\n    return []\n\n  def get_activations_and_quantizers(self, layer):\n    return []\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    pass\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    pass\n\n  def get_output_quantizers(self, layer):\n    return [quantizers.MovingAverageQuantizer(\n        num_bits=8, per_axis=False, symmetric=False, narrow_range=False)]\n\n  def get_config(self):\n    return {}\n\n\nclass NoOpQuantizeConfig(quantize_config.QuantizeConfig):\n  """"""QuantizeConfig which does not quantize any part of the layer.""""""\n\n  def get_weights_and_quantizers(self, layer):\n    return []\n\n  def get_activations_and_quantizers(self, layer):\n    return []\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    pass\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    pass\n\n  def get_output_quantizers(self, layer):\n    return []\n\n  def get_config(self):\n    return {}\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_layout_transform.py,1,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Default 8-bit layout transformation for quantization.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layout_transform\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_transforms\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import model_transformer\n\nkeras = tf.keras\n\n\nclass QuantizeLayoutTransform(\n    quantize_layout_transform.QuantizeLayoutTransform):\n  """"""Default model transformations.""""""\n\n  def apply(self, model, layer_quantize_map):\n    """"""Implement default 8-bit transforms.\n\n    Currently this means the following.\n      1. Pull activations into layers, and apply fuse activations. (TODO)\n      2. Modify range in incoming layers for Concat. (TODO)\n      3. Fuse Conv2D/DepthwiseConv2D + BN into single layer.\n\n    Args:\n      model: Keras model to be quantized.\n      layer_quantize_map: Map with keys as layer names, and values as dicts\n        containing custom `QuantizeConfig`s which may have been passed with\n        layers.\n\n    Returns:\n      (Transformed Keras model to better match TensorFlow Lite backend, updated\n      layer quantize map.)\n    """"""\n\n    transforms = [\n        default_8bit_transforms.InputLayerQuantize(),\n        default_8bit_transforms.Conv2DBatchNormReLUQuantize(),\n        default_8bit_transforms.Conv2DBatchNormActivationQuantize(),\n        default_8bit_transforms.Conv2DBatchNormQuantize(),\n        default_8bit_transforms.ConcatTransform6Inputs(),\n        default_8bit_transforms.ConcatTransform5Inputs(),\n        default_8bit_transforms.ConcatTransform4Inputs(),\n        default_8bit_transforms.ConcatTransform3Inputs(),\n        default_8bit_transforms.ConcatTransform(),\n    ]\n\n    return model_transformer.ModelTransformer(\n        model, transforms,\n        layer_quantize_map.keys(), layer_quantize_map).transform()\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_registry.py,5,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantization registry which specifies how layers should be quantized.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_config\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_registry\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_configs\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm\n\nQuantizeConfig = quantize_config.QuantizeConfig\n\nlayers = tf.keras.layers\n\n\nclass _QuantizeInfo(object):\n  """"""QuantizeInfo.""""""\n\n  def __init__(self,\n               layer_type,\n               weight_attrs,\n               activation_attrs,\n               quantize_output=False):\n    """"""QuantizeInfo.\n\n    Args:\n      layer_type: Type of keras layer.\n      weight_attrs: List of quantizable weight attributes of layer.\n      activation_attrs: List of quantizable activation attributes of layer.\n      quantize_output: Bool. Should we quantize the output of the layer.\n    """"""\n    self.layer_type = layer_type\n    self.weight_attrs = weight_attrs\n    self.activation_attrs = activation_attrs\n    self.quantize_output = quantize_output\n\n\ndef _no_quantize(layer_type):\n  return _QuantizeInfo(layer_type, [], [], False)\n\n\nclass _RNNHelper(object):\n  """"""Helper functions for working with RNNs.""""""\n\n  def _get_rnn_cells(self, rnn_layer):\n    """"""Returns the list of cells in an RNN layer.""""""\n    if isinstance(rnn_layer.cell, layers.StackedRNNCells):\n      return rnn_layer.cell.cells\n    else:\n      return [rnn_layer.cell]\n\n\nclass QuantizeRegistry(quantize_registry.QuantizeRegistry, _RNNHelper):\n  """"""QuantizationRegistry for built-in Keras classes for default 8-bit scheme.""""""\n\n  # TODO(tfmot): expand layers test in quantize_functional_test.py\n  # to add more layers to whitelist.\n  _LAYER_QUANTIZE_INFO = [\n      # Activation Layers\n      _QuantizeInfo(layers.ReLU, [], [], True),\n      _QuantizeInfo(layers.Softmax, [], []),\n      # Enable once verified.\n      # layers.ELU,\n      # layers.LeakyReLU,\n      # layers.PReLU,\n      # layers.ThresholdedReLU,\n\n      # Convolution Layers\n      # _QuantizeInfo(layers.Conv1D, [\'kernel\'], [\'activation\']),\n\n      # layers.Conv2D is supported and handled in code below.\n      # layers.DepthwiseConv2D is supported and handled in code below.\n\n      # _QuantizeInfo(layers.Conv3D, [\'kernel\'], [\'activation\']),\n      # _QuantizeInfo(layers.Conv2DTranspose, [\'kernel\'], [\'activation\']),\n      # _QuantizeInfo(layers.Conv3DTranspose, [\'kernel\'], [\'activation\']),\n      _no_quantize(layers.Cropping1D),\n      _no_quantize(layers.Cropping2D),\n      _no_quantize(layers.Cropping3D),\n      # _no_quantize(layers.UpSampling1D),\n      # _no_quantize(layers.UpSampling2D),\n      # _no_quantize(layers.UpSampling3D),\n      _no_quantize(layers.ZeroPadding1D),\n      _no_quantize(layers.ZeroPadding2D),\n      # _no_quantize(layers.ZeroPadding3D),\n      # Enable once verified.\n      # layers.SeparableConv1D,\n      # layers.SeparableConv2D,\n\n      # Core Layers\n      _no_quantize(layers.ActivityRegularization),\n      _QuantizeInfo(layers.Dense, [\'kernel\'], [\'activation\']),\n      _no_quantize(layers.Dropout),\n      _no_quantize(layers.Flatten),\n      # _no_quantize(layers.Masking),\n      _no_quantize(layers.Permute),\n      # _no_quantize(layers.RepeatVector),\n      _no_quantize(layers.Reshape),\n      _no_quantize(layers.SpatialDropout1D),\n      _no_quantize(layers.SpatialDropout2D),\n      _no_quantize(layers.SpatialDropout3D),\n      # layers.Lambda needs custom handling by the user.\n\n      # Pooling Layers\n      _QuantizeInfo(layers.AveragePooling1D, [], [], True),\n      _QuantizeInfo(layers.AveragePooling2D, [], [], True),\n      # _QuantizeInfo(layers.AveragePooling3D, [], [], True),\n      _QuantizeInfo(layers.GlobalAveragePooling1D, [], [], True),\n      _QuantizeInfo(layers.GlobalAveragePooling2D, [], [], True),\n      _QuantizeInfo(layers.GlobalAveragePooling3D, [], [], True),\n      _no_quantize(layers.GlobalMaxPooling1D),\n      _no_quantize(layers.GlobalMaxPooling2D),\n      _no_quantize(layers.GlobalMaxPooling3D),\n      # _no_quantize(layers.MaxPooling1D),\n      _no_quantize(layers.MaxPooling2D),\n      # _no_quantize(layers.MaxPooling3D),\n\n      # _QuantizeInfo(layers.LocallyConnected1D, [\'kernel\'], [\'activation\']),\n      # _QuantizeInfo(layers.LocallyConnected2D, [\'kernel\'], [\'activation\']),\n      _QuantizeInfo(layers.Add, [], [], True),\n\n      # Enable once verified with TFLite behavior.\n      # layers.Embedding: [\'embeddings\'],\n\n      # BatchNormalization is handled elsewhere, in the cases\n      # where it\'s preceded by convolutional layers or a Dense layer.\n      #   layers.BatchNormalization: [],\n\n      # Merge layers to be added.\n\n      # RNN Cells\n      # TODO(pulkitb): Verify RNN layers behavior.\n      # TODO(tfmot): check if we still need to whitelist via compat.v1 and\n      # compat.v2 to support legacy TensorFlow 2.X\n      # behavior where the v2 RNN uses the v1 RNNCell instead of the v2 RNNCell.\n      # See b/145939875 for details.\n      # _QuantizeInfo(tf.keras.layers.GRUCell, [\'kernel\', \'recurrent_kernel\'],\n      #               [\'activation\', \'recurrent_activation\']),\n      # _QuantizeInfo(tf.keras.layers.LSTMCell, [\'kernel\', \'recurrent_kernel\'],\n      #               [\'activation\', \'recurrent_activation\']),\n      # _QuantizeInfo(tf.keras.experimental.PeepholeLSTMCell,\n      #               [\'kernel\', \'recurrent_kernel\'],\n      #               [\'activation\', \'recurrent_activation\']),\n      # _QuantizeInfo(tf.keras.layers.SimpleRNNCell,\n      #               [\'kernel\', \'recurrent_kernel\'],\n      #               [\'activation\', \'recurrent_activation\']),\n\n      # TODO(tf-mot): Move layers out once Transforms indicate quantization.\n      _no_quantize(conv_batchnorm._ConvBatchNorm2D),  # pylint: disable=protected-access\n      _no_quantize(conv_batchnorm._DepthwiseConvBatchNorm2D),  # pylint: disable=protected-access\n  ]\n\n  def __init__(self):\n    self._layer_quantize_map = {}\n    for quantize_info in self._LAYER_QUANTIZE_INFO:\n      self._layer_quantize_map[quantize_info.layer_type] = quantize_info\n\n    # Hack for `Activation` layer. That is the only layer with a separate\n    # QuantizeConfig.\n    self._layer_quantize_map[\n        layers.Activation] = Default8BitActivationQuantizeConfig()\n    self._layer_quantize_map[layers.Conv2D] = Default8BitConvQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n    self._layer_quantize_map[\n        layers.DepthwiseConv2D] = Default8BitConvQuantizeConfig(\n            [\'depthwise_kernel\'], [\'activation\'], False)\n\n  def _is_supported_layer(self, layer_class):\n    return layer_class in self._layer_quantize_map\n\n  def _is_rnn_layer(self, layer):\n    return layer.__class__ in {\n        layers.GRU,\n        layers.LSTM,\n        layers.RNN,\n        layers.SimpleRNN,\n    }\n\n  def _get_quantize_info(self, layer_class):\n    return self._layer_quantize_map[layer_class]\n\n  # Interface functions.\n\n  def supports(self, layer):\n    """"""Returns whether the registry supports this layer type.\n\n    # TODO(pulkitb): Consider pushing this function up to the registry.\n\n    Args:\n      layer: The layer to check for support.\n\n    Returns:\n      True/False whether the layer type is supported.\n\n    """"""\n    if self._is_supported_layer(layer.__class__):\n      return True\n\n    if self._is_rnn_layer(layer):\n      for rnn_cell in self._get_rnn_cells(layer):\n        # All cells in the RNN layer should be supported.\n        if not self._is_supported_layer(rnn_cell.__class__):\n          return False\n      return True\n\n    return False\n\n  def _get_quantize_config(self, layer_type):\n    quantize_info = self._get_quantize_info(layer_type)\n\n    # In case of `Activation`, there is no `_QuantizeInfo` object. It\n    # directly stores a `QuantizeConfig`.\n    if isinstance(quantize_info, QuantizeConfig):\n      return quantize_info\n\n    return Default8BitQuantizeConfig(quantize_info.weight_attrs,\n                                     quantize_info.activation_attrs,\n                                     quantize_info.quantize_output)\n\n  def get_quantize_config(self, layer):\n    """"""Returns the quantization config for the given layer.\n\n    Args:\n      layer: input layer to return quantize config for.\n\n    Returns:\n      Returns the QuantizeConfig for the given layer.\n    """"""\n    if not self.supports(layer):\n      raise ValueError(\n          \'`get_quantize_config()` called on an unsupported layer {}. Check \'\n          \'if layer is supported by calling `supports()`. Alternatively, you \'\n          \'can use `QuantizeConfig` to specify a behavior for your layer.\'\n          .format(layer.__class__))\n\n    if self._is_supported_layer(layer.__class__):\n      return self._get_quantize_config(layer.__class__)\n\n    if self._is_rnn_layer(layer):\n      weight_attrs = []\n      activation_attrs = []\n      for rnn_cell in self._get_rnn_cells(layer):\n        quantize_info = self._get_quantize_info(rnn_cell.__class__)\n        weight_attrs.append(quantize_info.weight_attrs)\n        activation_attrs.append(quantize_info.activation_attrs)\n\n      # Result quantization for RNN isn\'t straight-forward like regular layers.\n      # To implement during full RNN support.\n      return Default8BitQuantizeConfigRNN(weight_attrs, activation_attrs, False)\n\n    # Should never come here.\n    raise ValueError(\'Invalid Layer type {}\'.format(layer.__class__))\n\n\nclass Default8BitQuantizeConfig(QuantizeConfig):\n  """"""QuantizeConfig for non recurrent Keras layers.""""""\n\n  def __init__(self, weight_attrs, activation_attrs, quantize_output):\n    self.weight_attrs = weight_attrs\n    self.activation_attrs = activation_attrs\n    self.quantize_output = quantize_output\n\n    # TODO(pulkitb): For some layers such as Conv2D, per_axis should be True.\n    # Add mapping for which layers support per_axis.\n    self.weight_quantizer = quantizers.LastValueQuantizer(\n        num_bits=8, per_axis=False, symmetric=True, narrow_range=True)\n    self.activation_quantizer = quantizers.MovingAverageQuantizer(\n        num_bits=8, per_axis=False, symmetric=False, narrow_range=False)\n\n  def get_weights_and_quantizers(self, layer):\n    return [(getattr(layer, weight_attr), self.weight_quantizer)\n            for weight_attr in self.weight_attrs]\n\n  def get_activations_and_quantizers(self, layer):\n    return [(getattr(layer, activation_attr), self.activation_quantizer)\n            for activation_attr in self.activation_attrs]\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    if len(self.weight_attrs) != len(quantize_weights):\n      raise ValueError(\n          \'`set_quantize_weights` called on layer {} with {} \'\n          \'weight parameters, but layer expects {} values.\'.format(\n              layer.name, len(quantize_weights), len(self.weight_attrs)))\n\n    for weight_attr, weight in zip(self.weight_attrs, quantize_weights):\n      current_weight = getattr(layer, weight_attr)\n      if current_weight.shape != weight.shape:\n        raise ValueError(\'Existing layer weight shape {} is incompatible with\'\n                         \'provided weight shape {}\'.format(\n                             current_weight.shape, weight.shape))\n\n      setattr(layer, weight_attr, weight)\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    if len(self.activation_attrs) != len(quantize_activations):\n      raise ValueError(\n          \'`set_quantize_activations` called on layer {} with {} \'\n          \'activation parameters, but layer expects {} values.\'.format(\n              layer.name, len(quantize_activations),\n              len(self.activation_attrs)))\n\n    for activation_attr, activation in \\\n        zip(self.activation_attrs, quantize_activations):\n      setattr(layer, activation_attr, activation)\n\n  def get_output_quantizers(self, layer):\n    if self.quantize_output:\n      return [self.activation_quantizer]\n    return []\n\n  @classmethod\n  def from_config(cls, config):\n    """"""Instantiates a `Default8BitQuantizeConfig` from its config.\n\n    Args:\n        config: Output of `get_config()`.\n\n    Returns:\n        A `Default8BitQuantizeConfig` instance.\n    """"""\n    return cls(**config)\n\n  def get_config(self):\n    # TODO(pulkitb): Add weight and activation quantizer to config.\n    # Currently it\'s created internally, but ideally the quantizers should be\n    # part of the constructor and passed in from the registry.\n    return {\n        \'weight_attrs\': self.weight_attrs,\n        \'activation_attrs\': self.activation_attrs,\n        \'quantize_output\': self.quantize_output\n    }\n\n  def __eq__(self, other):\n    if not isinstance(other, Default8BitQuantizeConfig):\n      return False\n\n    return (self.weight_attrs == other.weight_attrs and\n            self.activation_attrs == self.activation_attrs and\n            self.weight_quantizer == other.weight_quantizer and\n            self.activation_quantizer == other.activation_quantizer and\n            self.quantize_output == other.quantize_output)\n\n  def __ne__(self, other):\n    return not self.__eq__(other)\n\n\nclass Default8BitQuantizeConfigRNN(Default8BitQuantizeConfig, _RNNHelper):\n  """"""QuantizeConfig for RNN layers.""""""\n\n  def get_weights_and_quantizers(self, layer):\n    weights_quantizers = []\n    for weight_attrs_cell, rnn_cell in \\\n        zip(self.weight_attrs, self._get_rnn_cells(layer)):\n      for weight_attr in weight_attrs_cell:\n        weights_quantizers.append(\n            (getattr(rnn_cell, weight_attr), self.weight_quantizer))\n\n    return weights_quantizers\n\n  def get_activations_and_quantizers(self, layer):\n    activations_quantizers = []\n    for activation_attrs_cell, rnn_cell in \\\n        zip(self.activation_attrs, self._get_rnn_cells(layer)):\n      for activation_attr in activation_attrs_cell:\n        activations_quantizers.append(\n            (getattr(rnn_cell, activation_attr), self.activation_quantizer))\n\n    return activations_quantizers\n\n  def _flatten(self, list_of_lists):\n    flat_list = []\n    for sublist in list_of_lists:\n      for item in sublist:\n        flat_list.append(item)\n    return flat_list\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    flattened_weight_attrs = self._flatten(self.weight_attrs)\n    if len(flattened_weight_attrs) != len(quantize_weights):\n      raise ValueError(\n          \'`set_quantize_weights` called on layer {} with {} \'\n          \'weight parameters, but layer expects {} values.\'.format(\n              layer.name, len(quantize_weights), len(flattened_weight_attrs)))\n\n    i = 0\n    for weight_attrs_cell, rnn_cell in \\\n        zip(self.weight_attrs, self._get_rnn_cells(layer)):\n      for weight_attr in weight_attrs_cell:\n        current_weight = getattr(rnn_cell, weight_attr)\n        quantize_weight = quantize_weights[i]\n\n        if current_weight.shape != quantize_weight.shape:\n          raise ValueError(\'Existing layer weight shape {} is incompatible with\'\n                           \'provided weight shape {}\'.format(\n                               current_weight.shape, quantize_weight.shape))\n\n        setattr(rnn_cell, weight_attr, quantize_weight)\n        i += 1\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    flattened_activation_attrs = self._flatten(self.activation_attrs)\n    if len(flattened_activation_attrs) != len(quantize_activations):\n      raise ValueError(\n          \'`set_quantize_activations` called on layer {} with {} \'\n          \'activation parameters, but layer expects {} values.\'.format(\n              layer.name, len(quantize_activations),\n              len(flattened_activation_attrs)))\n\n    i = 0\n    for activation_attrs_cell, rnn_cell in \\\n        zip(self.activation_attrs, self._get_rnn_cells(layer)):\n      for activation_attr in activation_attrs_cell:\n        setattr(rnn_cell, activation_attr, quantize_activations[i])\n        i += 1\n\n\nclass Default8BitActivationQuantizeConfig(QuantizeConfig):\n  """"""QuantizeConfig for keras.layers.Activation.\n\n  `keras.layers.Activation` needs a separate `QuantizeConfig` since the\n  decision to quantize depends on the specific activation type.\n  """"""\n\n  def _assert_activation_layer(self, layer):\n    if not isinstance(layer, layers.Activation):\n      raise RuntimeError(\n          \'Default8BitActivationQuantizeConfig can only be used with \'\n          \'`keras.layers.Activation`.\')\n\n  def get_weights_and_quantizers(self, layer):\n    self._assert_activation_layer(layer)\n    return []\n\n  def get_activations_and_quantizers(self, layer):\n    self._assert_activation_layer(layer)\n    return []\n\n  def set_quantize_weights(self, layer, quantize_weights):\n    self._assert_activation_layer(layer)\n\n  def set_quantize_activations(self, layer, quantize_activations):\n    self._assert_activation_layer(layer)\n\n  def get_output_quantizers(self, layer):\n    self._assert_activation_layer(layer)\n\n    if not hasattr(layer.activation, \'__name__\'):\n      raise ValueError(\'Activation {} not supported by \'\n                       \'Default8BitActivationQuantizeConfig.\'.format(\n                           layer.activation))\n\n    if layer.activation.__name__ in [\'relu\']:\n      # \'relu\' should generally get fused into the previous layer.\n      return [quantizers.MovingAverageQuantizer(\n          num_bits=8, per_axis=False, symmetric=False, narrow_range=False)]\n    elif layer.activation.__name__ in [\'linear\', \'softmax\']:\n      return []\n\n    raise ValueError(\'Activation {} not supported by \'\n                     \'Default8BitActivationQuantizeConfig.\'.format(\n                         layer.activation))\n\n  def get_config(self):\n    return {}\n\n\nclass Default8BitConvQuantizeConfig(Default8BitQuantizeConfig):\n  """"""QuantizeConfig for Conv2D/DepthwiseConv2D layers.""""""\n\n  def __init__(self, weight_attrs, activation_attrs, quantize_output):\n    super(Default8BitConvQuantizeConfig,\n          self).__init__(weight_attrs, activation_attrs, quantize_output)\n\n    self.weight_quantizer = default_8bit_quantizers.Default8BitConvWeightsQuantizer(\n    )\n\n\ndef _types_dict():\n  return {\n      \'Default8BitQuantizeConfig\':\n          Default8BitQuantizeConfig,\n      \'Default8BitQuantizeConfigRNN\':\n          Default8BitQuantizeConfigRNN,\n      \'Default8BitActivationQuantizeConfig\':\n          Default8BitActivationQuantizeConfig,\n      \'Default8BitConvQuantizeConfig\':\n          Default8BitConvQuantizeConfig,\n      \'NoOpQuantizeConfig\':\n          default_8bit_quantize_configs.NoOpQuantizeConfig,\n      \'Default8BitOutputQuantizeConfig\':\n          default_8bit_quantize_configs.Default8BitOutputQuantizeConfig\n  }\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_registry_test.py,10,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for QuantizeRegistry.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport unittest\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\n\nkeras = tf.keras\nK = tf.keras.backend\nl = tf.keras.layers\n\ndeserialize_keras_object = tf.keras.utils.deserialize_keras_object\nserialize_keras_object = tf.keras.utils.serialize_keras_object\n\n\nclass _TestHelper(object):\n\n  def _convert_list(self, list_of_tuples):\n    """"""Transforms a list of 2-tuples to a tuple of 2 lists.\n\n    `QuantizeConfig` methods return a list of 2-tuples in the form\n    [(weight1, quantizer1), (weight2, quantizer2)]. This function converts\n    it into a 2-tuple of lists. ([weight1, weight2]), (quantizer1, quantizer2).\n\n    Args:\n      list_of_tuples: List of 2-tuples.\n\n    Returns:\n      2-tuple of lists.\n    """"""\n    list1 = []\n    list2 = []\n    for a, b in list_of_tuples:\n      list1.append(a)\n      list2.append(b)\n\n    return list1, list2\n\n  # TODO(pulkitb): Consider asserting on full equality for quantizers.\n\n  def _assert_weight_quantizers(self, quantizer_list):\n    for quantizer in quantizer_list:\n      self.assertIsInstance(quantizer, quantizers.LastValueQuantizer)\n\n  def _assert_activation_quantizers(self, quantizer_list):\n    for quantizer in quantizer_list:\n      self.assertIsInstance(quantizer, quantizers.MovingAverageQuantizer)\n\n  def _assert_kernel_equality(self, a, b):\n    self.assertAllEqual(a.numpy(), b.numpy())\n\n\n@keras_parameterized.run_all_keras_modes\nclass QuantizeRegistryTest(\n    tf.test.TestCase, parameterized.TestCase, _TestHelper):\n\n  def setUp(self):\n    super(QuantizeRegistryTest, self).setUp()\n    self.quantize_registry = default_8bit_quantize_registry.QuantizeRegistry(\n    )\n\n  class CustomLayer(l.Layer):\n    pass\n\n  # supports() tests.\n\n  def testSupports_KerasLayer(self):\n    self.assertTrue(self.quantize_registry.supports(l.Dense(10)))\n    self.assertTrue(self.quantize_registry.supports(l.Conv2D(10, (2, 2))))\n\n  @unittest.skip\n  def testSupports_KerasRNNLayers(self):\n    self.assertTrue(self.quantize_registry.supports(l.LSTM(10)))\n    self.assertTrue(self.quantize_registry.supports(l.GRU(10)))\n\n  @unittest.skip\n  def testSupports_KerasRNNLayerWithKerasRNNCells(self):\n    self.assertTrue(self.quantize_registry.supports(l.RNN(cell=l.LSTMCell(10))))\n    self.assertTrue(\n        self.quantize_registry.supports(\n            l.RNN(cell=[l.LSTMCell(10), l.GRUCell(10)])))\n\n  def testDoesNotSupport_CustomLayer(self):\n    self.assertFalse(self.quantize_registry.supports(self.CustomLayer()))\n\n  @unittest.skip\n  def testDoesNotSupport_RNNLayerWithCustomRNNCell(self):\n\n    class MinimalRNNCell(l.Layer):\n\n      def __init__(self, units, **kwargs):\n        self.units = units\n        self.state_size = units\n        super(MinimalRNNCell, self).__init__(**kwargs)\n\n    self.assertFalse(\n        self.quantize_registry.supports(l.RNN(cell=MinimalRNNCell(10))))\n    self.assertFalse(\n        self.quantize_registry.supports(\n            l.RNN(cell=[l.LSTMCell(10), MinimalRNNCell(10)])))\n\n  # get_quantize_config() tests.\n\n  def testRaisesError_UnsupportedLayer(self):\n    with self.assertRaises(ValueError):\n      self.quantize_registry.get_quantize_config(self.CustomLayer())\n\n  def testReturnsConfig_KerasLayer(self):\n    model = keras.Sequential([(\n        l.Dense(2, input_shape=(3,)))])\n    layer = model.layers[0]\n\n    quantize_config = self.quantize_registry.get_quantize_config(layer)\n\n    (weights, weight_quantizers) = self._convert_list(\n        quantize_config.get_weights_and_quantizers(layer))\n    (activations, activation_quantizers) = self._convert_list(\n        quantize_config.get_activations_and_quantizers(layer))\n\n    self._assert_weight_quantizers(weight_quantizers)\n    self.assertEqual([layer.kernel], weights)\n\n    self._assert_activation_quantizers(activation_quantizers)\n    self.assertEqual([layer.activation], activations)\n\n    quantize_kernel = keras.backend.variable(\n        np.ones(layer.kernel.shape.as_list()))\n    quantize_activation = keras.activations.relu\n    quantize_config.set_quantize_weights(layer, [quantize_kernel])\n    quantize_config.set_quantize_activations(layer, [quantize_activation])\n\n    self._assert_kernel_equality(layer.kernel, quantize_kernel)\n    self.assertEqual(layer.activation, quantize_activation)\n\n  def testReturnsConfig_LayerWithResultQuantizer(self):\n    layer = l.ReLU()\n    quantize_config = self.quantize_registry.get_quantize_config(layer)\n\n    output_quantizers = quantize_config.get_output_quantizers(layer)\n\n    self.assertLen(output_quantizers, 1)\n    self._assert_activation_quantizers(output_quantizers)\n\n  @unittest.skip\n  def testReturnsConfig_KerasRNNLayer(self):\n    model = keras.Sequential([(\n        l.LSTM(2, input_shape=(3, 2)))])\n    layer = model.layers[0]\n\n    quantize_config = self.quantize_registry.get_quantize_config(layer)\n\n    (weights, weight_quantizers) = self._convert_list(\n        quantize_config.get_weights_and_quantizers(layer))\n    (activations, activation_quantizers) = self._convert_list(\n        quantize_config.get_activations_and_quantizers(layer))\n\n    self._assert_weight_quantizers(weight_quantizers)\n    self.assertEqual([layer.cell.kernel, layer.cell.recurrent_kernel], weights)\n\n    self._assert_activation_quantizers(activation_quantizers)\n    self.assertEqual(\n        [layer.cell.activation, layer.cell.recurrent_activation], activations)\n\n  @unittest.skip\n  def testReturnsConfig_KerasRNNLayerWithKerasRNNCells(self):\n    lstm_cell = l.LSTMCell(3)\n    gru_cell = l.GRUCell(2)\n    model = keras.Sequential([l.RNN([lstm_cell, gru_cell], input_shape=(3, 2))])\n    layer = model.layers[0]\n\n    quantize_config = self.quantize_registry.get_quantize_config(layer)\n\n    (weights, weight_quantizers) = self._convert_list(\n        quantize_config.get_weights_and_quantizers(layer))\n    (activations, activation_quantizers) = self._convert_list(\n        quantize_config.get_activations_and_quantizers(layer))\n\n    self._assert_weight_quantizers(weight_quantizers)\n    self.assertEqual(\n        [lstm_cell.kernel, lstm_cell.recurrent_kernel,\n         gru_cell.kernel, gru_cell.recurrent_kernel],\n        weights)\n\n    self._assert_activation_quantizers(activation_quantizers)\n    self.assertEqual(\n        [lstm_cell.activation, lstm_cell.recurrent_activation,\n         gru_cell.activation, gru_cell.recurrent_activation],\n        activations)\n\n  def testReturnsActivationConfig_Activation(self):\n    activation_layer = keras.layers.Activation(\'relu\')\n\n    quantize_config = self.quantize_registry.get_quantize_config(\n        activation_layer)\n\n    self.assertIsInstance(\n        quantize_config,\n        default_8bit_quantize_registry.Default8BitActivationQuantizeConfig)\n    self._assert_activation_quantizers(\n        quantize_config.get_output_quantizers(activation_layer))\n\n\nclass Default8BitQuantizeConfigTest(tf.test.TestCase, _TestHelper):\n\n  def _simple_dense_layer(self):\n    layer = l.Dense(2)\n    layer.build(input_shape=(3,))\n    return layer\n\n  def testGetsQuantizeWeightsAndQuantizers(self):\n    layer = self._simple_dense_layer()\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n    (weights, weight_quantizers) = self._convert_list(\n        quantize_config.get_weights_and_quantizers(layer))\n\n    self._assert_weight_quantizers(weight_quantizers)\n    self.assertEqual([layer.kernel], weights)\n\n  def testGetsQuantizeActivationsAndQuantizers(self):\n    layer = self._simple_dense_layer()\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n    (activations, activation_quantizers) = self._convert_list(\n        quantize_config.get_activations_and_quantizers(layer))\n\n    self._assert_activation_quantizers(activation_quantizers)\n    self.assertEqual([layer.activation], activations)\n\n  def testSetsQuantizeWeights(self):\n    layer = self._simple_dense_layer()\n    quantize_kernel = K.variable(np.ones(layer.kernel.shape.as_list()))\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n    quantize_config.set_quantize_weights(layer, [quantize_kernel])\n\n    self._assert_kernel_equality(layer.kernel, quantize_kernel)\n\n  def testSetsQuantizeActivations(self):\n    layer = self._simple_dense_layer()\n    quantize_activation = keras.activations.relu\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n    quantize_config.set_quantize_activations(layer, [quantize_activation])\n\n    self.assertEqual(layer.activation, quantize_activation)\n\n  def testSetsQuantizeWeights_ErrorOnWrongNumberOfWeights(self):\n    layer = self._simple_dense_layer()\n    quantize_kernel = K.variable(np.ones(layer.kernel.shape.as_list()))\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n\n    with self.assertRaises(ValueError):\n      quantize_config.set_quantize_weights(layer, [])\n\n    with self.assertRaises(ValueError):\n      quantize_config.set_quantize_weights(layer,\n                                           [quantize_kernel, quantize_kernel])\n\n  def testSetsQuantizeWeights_ErrorOnWrongShapeOfWeight(self):\n    layer = self._simple_dense_layer()\n    quantize_kernel = K.variable(np.ones([1, 2]))\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n\n    with self.assertRaises(ValueError):\n      quantize_config.set_quantize_weights(layer, [quantize_kernel])\n\n  def testSetsQuantizeActivations_ErrorOnWrongNumberOfActivations(self):\n    layer = self._simple_dense_layer()\n    quantize_activation = keras.activations.relu\n\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n\n    with self.assertRaises(ValueError):\n      quantize_config.set_quantize_activations(layer, [])\n\n    with self.assertRaises(ValueError):\n      quantize_config.set_quantize_activations(\n          layer, [quantize_activation, quantize_activation])\n\n  def testGetsResultQuantizers_ReturnsQuantizer(self):\n    layer = self._simple_dense_layer()\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [], [], True)\n\n    output_quantizers = quantize_config.get_output_quantizers(layer)\n\n    self.assertLen(output_quantizers, 1)\n    self._assert_activation_quantizers(output_quantizers)\n\n  def testGetsResultQuantizers_EmptyWhenFalse(self):\n    layer = self._simple_dense_layer()\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [], [], False)\n\n    output_quantizers = quantize_config.get_output_quantizers(layer)\n\n    self.assertEqual([], output_quantizers)\n\n  def testSerialization(self):\n    quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfig(\n        [\'kernel\'], [\'activation\'], False)\n\n    expected_config = {\n        \'class_name\': \'Default8BitQuantizeConfig\',\n        \'config\': {\n            \'weight_attrs\': [\'kernel\'],\n            \'activation_attrs\': [\'activation\'],\n            \'quantize_output\': False\n        }\n    }\n    serialized_quantize_config = serialize_keras_object(quantize_config)\n\n    self.assertEqual(expected_config, serialized_quantize_config)\n\n    quantize_config_from_config = deserialize_keras_object(\n        serialized_quantize_config,\n        module_objects=globals(),\n        custom_objects=default_8bit_quantize_registry._types_dict())\n\n    self.assertEqual(quantize_config, quantize_config_from_config)\n\n\nclass Default8BitQuantizeConfigRNNTest(tf.test.TestCase, _TestHelper):\n\n  def setUp(self):\n    super(Default8BitQuantizeConfigRNNTest, self).setUp()\n\n    self.cell1 = l.LSTMCell(3)\n    self.cell2 = l.GRUCell(2)\n    self.layer = l.RNN([self.cell1, self.cell2])\n    self.layer.build(input_shape=(3, 2))\n\n    self.quantize_config = default_8bit_quantize_registry.Default8BitQuantizeConfigRNN(\n        [[\'kernel\', \'recurrent_kernel\'], [\'kernel\', \'recurrent_kernel\']],\n        [[\'activation\', \'recurrent_activation\'],\n         [\'activation\', \'recurrent_activation\']], False)\n\n  def _expected_weights(self):\n    return [self.cell1.kernel, self.cell1.recurrent_kernel,\n            self.cell2.kernel, self.cell2.recurrent_kernel]\n\n  def _expected_activations(self):\n    return [self.cell1.activation, self.cell1.recurrent_activation,\n            self.cell2.activation, self.cell2.recurrent_activation]\n\n  def _dummy_weights(self, weight):\n    return K.variable(np.ones(weight.shape.as_list()))\n\n  def testGetsQuantizeWeightsAndQuantizers(self):\n    (weights, weight_quantizers) = self._convert_list(\n        self.quantize_config.get_weights_and_quantizers(self.layer))\n\n    self._assert_weight_quantizers(weight_quantizers)\n    self.assertEqual(self._expected_weights(), weights)\n\n  def testGetsQuantizeActivationsAndQuantizers(self):\n    (activations, activation_quantizers) = self._convert_list(\n        self.quantize_config.get_activations_and_quantizers(self.layer))\n\n    self._assert_activation_quantizers(activation_quantizers)\n    self.assertEqual(self._expected_activations(), activations)\n\n  def testSetsQuantizeWeights(self):\n    quantize_weights = [\n        self._dummy_weights(self.cell1.kernel),\n        self._dummy_weights(self.cell1.recurrent_kernel),\n        self._dummy_weights(self.cell2.kernel),\n        self._dummy_weights(self.cell2.recurrent_kernel)\n    ]\n\n    self.quantize_config.set_quantize_weights(self.layer, quantize_weights)\n\n    self.assertEqual(self._expected_weights(), quantize_weights)\n\n  def testSetsQuantizeActivations(self):\n    quantize_activations = [keras.activations.relu, keras.activations.softmax,\n                            keras.activations.relu, keras.activations.softmax]\n\n    self.quantize_config.set_quantize_activations(self.layer,\n                                                  quantize_activations)\n\n    self.assertEqual(self._expected_activations(), quantize_activations)\n\n  def testSetsQuantizeWeights_ErrorOnWrongNumberOfWeights(self):\n    with self.assertRaises(ValueError):\n      self.quantize_config.set_quantize_weights(self.layer, [])\n\n    quantize_weights = [\n        self._dummy_weights(self.cell1.kernel),\n        self._dummy_weights(self.cell1.recurrent_kernel),\n    ]\n    with self.assertRaises(ValueError):\n      self.quantize_config.set_quantize_weights(self.layer, quantize_weights)\n\n  def testSetsQuantizeWeights_ErrorOnWrongShapeOfWeight(self):\n    quantize_weights = [\n        self._dummy_weights(self.cell1.kernel),\n        self._dummy_weights(self.cell1.recurrent_kernel),\n        K.variable(np.ones([1, 2])),  # Incorrect shape.\n        self._dummy_weights(self.cell2.recurrent_kernel)\n    ]\n\n    with self.assertRaises(ValueError):\n      self.quantize_config.set_quantize_weights(self.layer, quantize_weights)\n\n  def testSetsQuantizeActivations_ErrorOnWrongNumberOfActivations(self):\n    quantize_activation = keras.activations.relu\n\n    with self.assertRaises(ValueError):\n      self.quantize_config.set_quantize_activations(self.layer, [])\n\n    with self.assertRaises(ValueError):\n      self.quantize_config.set_quantize_activations(\n          self.layer, [quantize_activation, quantize_activation])\n\n  def testSerialization(self):\n    expected_config = {\n        \'class_name\': \'Default8BitQuantizeConfigRNN\',\n        \'config\': {\n            \'weight_attrs\': [[\'kernel\', \'recurrent_kernel\'],\n                             [\'kernel\', \'recurrent_kernel\']],\n            \'activation_attrs\': [[\'activation\', \'recurrent_activation\'],\n                                 [\'activation\', \'recurrent_activation\']],\n            \'quantize_output\': False\n        }\n    }\n    serialized_quantize_config = serialize_keras_object(self.quantize_config)\n\n    self.assertEqual(expected_config, serialized_quantize_config)\n\n    quantize_config_from_config = deserialize_keras_object(\n        serialized_quantize_config,\n        module_objects=globals(),\n        custom_objects=default_8bit_quantize_registry._types_dict())\n\n    self.assertEqual(self.quantize_config, quantize_config_from_config)\n\n\nclass ActivationQuantizeConfigTest(tf.test.TestCase):\n\n  def testRaisesErrorUnsupportedActivation(self):\n    quantize_config = default_8bit_quantize_registry.Default8BitActivationQuantizeConfig(\n    )\n\n    with self.assertRaises(ValueError):\n      quantize_config.get_output_quantizers(keras.layers.Activation(\'tanh\'))\n\n    with self.assertRaises(ValueError):\n      quantize_config.get_output_quantizers(\n          keras.layers.Activation(lambda x: x))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantizers.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Quantizers specific to default 8-bit behavior.""""""\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\n\n\nclass Default8BitConvWeightsQuantizer(quantizers.LastValueQuantizer):\n  """"""Quantizer for handling weights in Conv2D/DepthwiseConv2D layers.""""""\n\n  def __init__(self):\n    """"""Construct LastValueQuantizer with params specific for TFLite Convs.""""""\n\n    super(Default8BitConvWeightsQuantizer, self).__init__(\n        num_bits=8, per_axis=True, symmetric=True, narrow_range=True)\n\n  def build(self, tensor_shape, name, layer):\n    min_weight = layer.add_weight(\n        name + \'_min\',\n        shape=(tensor_shape[-1],),\n        initializer=tf.keras.initializers.Constant(-6.0),\n        trainable=False)\n    max_weight = layer.add_weight(\n        name + \'_max\',\n        shape=(tensor_shape[-1],),\n        initializer=tf.keras.initializers.Constant(6.0),\n        trainable=False)\n\n    return {\'min_var\': min_weight, \'max_var\': max_weight}\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantizers_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for default Quantizers.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nimport tensorflow as tf\n\nfrom tensorflow.python.keras import keras_parameterized\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantizers\n\nDefault8BitConvWeightsQuantizer = default_8bit_quantizers.Default8BitConvWeightsQuantizer\n\nkeras = tf.keras\n\n\n@keras_parameterized.run_all_keras_modes\nclass Default8BitConvWeightsQuantizerTest(tf.test.TestCase,\n                                          parameterized.TestCase):\n\n  @parameterized.parameters(\n      (keras.layers.Conv2D, {\n          \'filters\': 5,\n          \'kernel_size\': (2, 2)\n      }),\n      (keras.layers.DepthwiseConv2D, {\n          \'kernel_size\': (2, 2),\n          \'depth_multiplier\': 5,\n      })\n  )\n  def testConstructsMinMaxVarsCorrectShape(self, layer_type, kwargs):\n    quantizer = Default8BitConvWeightsQuantizer()\n\n    model = keras.Sequential([\n        layer_type(input_shape=(5, 2, 3), **kwargs)])\n    layer = model.layers[0]\n\n    min_max_vars = quantizer.build(\n        layer.weights[0].shape, \'kernel\', layer)\n    # TODO(pulkitb): Add value test to ensure per-axis quantization is\n    # happening properly. Probably to quant_ops_test.py\n    quantized_weight = quantizer(layer.weights[0], True,  # pylint: disable=unused-variable\n                                 weights=min_max_vars)\n\n    min_var = min_max_vars[\'min_var\']\n    max_var = min_max_vars[\'max_var\']\n    self.assertEqual(5, min_var.shape)\n    self.assertEqual(5, max_var.shape)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_transforms.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Default 8-bit transforms.""""""\n\nimport collections\nimport inspect\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_configs\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import transforms\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm\n\nLayerNode = transforms.LayerNode\nLayerPattern = transforms.LayerPattern\n\n_ConvBatchNorm2D = conv_batchnorm._ConvBatchNorm2D  # pylint: disable=protected-access\n_DepthwiseConvBatchNorm2D = conv_batchnorm._DepthwiseConvBatchNorm2D  # pylint: disable=protected-access\n\nkeras = tf.keras\n\n\ndef _get_conv_bn_layers(bn_layer_node):\n  bn_layer = bn_layer_node.layer\n  conv_layer = bn_layer_node.input_layers[0].layer\n  return conv_layer, bn_layer\n\n\ndef _get_weights(bn_layer_node):\n  """"""Returns weight values for fused layer, including copying original values in unfused version.""""""\n\n  return collections.OrderedDict(\n      list(bn_layer_node.input_layers[0].weights.items())\n      + list(bn_layer_node.weights.items()))\n\n\ndef _get_params(conv_layer, bn_layer, relu_layer=None):\n  """"""Retrieve conv_bn params within wrapped layers.""""""\n  if \'use_bias\' in conv_layer[\'config\']:\n    if conv_layer[\'config\'][\'use_bias\']:\n      raise ValueError(\n          \'use_bias should not be set to True in a Conv layer when followed \'\n          \'by BatchNormalization. The bias in the Conv would be redundant \'\n          \'with the one in the BatchNormalization.\')\n\n    del conv_layer[\'config\'][\'use_bias\']\n\n  if \'name\' in bn_layer[\'config\']:\n    del bn_layer[\'config\'][\'name\']\n\n  # TODO(pulkitb): remove key conflicts\n  params = dict(\n      list(conv_layer[\'config\'].items()) + list(bn_layer[\'config\'].items()))\n\n  if relu_layer is not None:\n    params[\'post_activation\'] = keras.layers.deserialize(relu_layer)\n\n  return params\n\n\ndef _get_layer_node(fused_layer, weights):\n  layer_config = keras.layers.serialize(fused_layer)\n  layer_config[\'name\'] = layer_config[\'config\'][\'name\']\n  # This config tracks which layers get quantized, and whether they have a\n  # custom QuantizeConfig.\n  layer_metadata = {\'quantize_config\': None}\n\n  return LayerNode(layer_config, weights, metadata=layer_metadata)\n\n\nclass Conv2DBatchNormFold(transforms.Transform):\n  """"""Conv2DBatchNormFold.""""""\n\n  def pattern(self):\n    return LayerPattern(\'BatchNormalization\', {},\n                        [LayerPattern(\'Conv2D\', {}, [])])\n\n  def replacement(self, match_layer):\n    conv_layer, bn_layer = _get_conv_bn_layers(match_layer)\n\n    fused_params = _get_params(conv_layer, bn_layer)\n    fused_layer = _ConvBatchNorm2D(**fused_params)\n\n    weights = _get_weights(match_layer)\n    return _get_layer_node(fused_layer, weights)\n\n  def custom_objects(self):\n    return {\'_ConvBatchNorm2D\': _ConvBatchNorm2D}\n\n\nclass Conv2DBatchNormReLU6Fold(Conv2DBatchNormFold):\n  """"""Conv2DBatchNormReLU6Fold.""""""\n\n  def pattern(self):\n    return LayerPattern(\'ReLU\', {\'max_value\': 6}, [\n        LayerPattern(\'BatchNormalization\', {},\n                     [LayerPattern(\'Conv2D\', {}, [])])\n    ])\n\n  def replacement(self, match_layer):\n    relu_layer = match_layer.layer\n    conv_layer, bn_layer = _get_conv_bn_layers(match_layer.input_layers[0])\n\n    fused_params = _get_params(conv_layer, bn_layer, relu_layer)\n    fused_layer = _ConvBatchNorm2D(**fused_params)\n\n    weights = _get_weights(match_layer.input_layers[0])\n    return _get_layer_node(fused_layer, weights)\n\n\nclass DepthwiseConv2DBatchNormReLU6Fold(transforms.Transform):\n  """"""DepthwiseConv2DBatchNormReLU6Fold.""""""\n\n  def pattern(self):\n    return LayerPattern(\'ReLU\', {\'max_value\': 6}, [\n        LayerPattern(\'BatchNormalization\', {},\n                     [LayerPattern(\'DepthwiseConv2D\', {}, [])])\n    ])\n\n  def replacement(self, match_layer):\n    relu_layer = match_layer.layer\n    conv_layer, bn_layer = _get_conv_bn_layers(match_layer.input_layers[0])\n\n    fused_params = _get_params(conv_layer, bn_layer, relu_layer)\n    fused_layer = _DepthwiseConvBatchNorm2D(**fused_params)\n\n    weights = _get_weights(match_layer.input_layers[0])\n    return _get_layer_node(fused_layer, weights)\n\n  def custom_objects(self):\n    return {\'_DepthwiseConvBatchNorm2D\': _DepthwiseConvBatchNorm2D}\n\n\nclass Conv2DBatchNormQuantize(transforms.Transform):\n  """"""Ensure FQ does not get placed between Conv and BatchNorm.""""""\n\n  def pattern(self):\n    return LayerPattern(\n        \'BatchNormalization\',\n        inputs=[LayerPattern(\n            \'Conv2D|DepthwiseConv2D\', config={\'activation\': \'linear\'})])\n\n  @staticmethod\n  def _get_quantize_config(layer_node):\n    return layer_node.metadata.get(\'quantize_config\')\n\n  def _has_custom_quantize_config(self, *layer_nodes):\n    for layer_node in layer_nodes:\n      if self._get_quantize_config(layer_node) is not None:\n        return True\n    return False\n\n  def replacement(self, match_layer):\n    bn_layer_node, conv_layer_node = match_layer, match_layer.input_layers[0]\n\n    if self._has_custom_quantize_config(bn_layer_node, conv_layer_node):\n      return match_layer\n\n    conv_layer_node.layer[\'config\'][\'activation\'] = \\\n      keras.activations.serialize(quantize_aware_activation.NoOpActivation())\n    bn_layer_node.metadata[\'quantize_config\'] = \\\n      default_8bit_quantize_configs.Default8BitOutputQuantizeConfig()\n\n    return match_layer\n\n  def custom_objects(self):\n    return {\n        \'NoOpQuantizeConfig\': default_8bit_quantize_configs.NoOpQuantizeConfig,\n        \'NoOpActivation\': quantize_aware_activation.NoOpActivation\n    }\n\n\nclass Conv2DBatchNormReLUQuantize(Conv2DBatchNormQuantize):\n  """"""Ensure FQ does not get placed between Conv, BatchNorm and ReLU.""""""\n\n  def pattern(self):\n    return LayerPattern(\n        # TODO(pulkitb): Enhance match to only occur for relu, relu1 and relu6\n        \'ReLU\',\n        inputs=[super(Conv2DBatchNormReLUQuantize, self).pattern()])\n\n  def replacement(self, match_layer):\n    relu_layer_node = match_layer\n    bn_layer_node = relu_layer_node.input_layers[0]\n    conv_layer_node = bn_layer_node.input_layers[0]\n\n    if self._has_custom_quantize_config(relu_layer_node, bn_layer_node,\n                                        conv_layer_node):\n      return match_layer\n\n    conv_layer_node.layer[\'config\'][\'activation\'] = \\\n      keras.activations.serialize(quantize_aware_activation.NoOpActivation())\n    bn_layer_node.metadata[\'quantize_config\'] = \\\n      default_8bit_quantize_configs.NoOpQuantizeConfig()\n\n    return match_layer\n\n  def custom_objects(self):\n    return {\n        \'NoOpQuantizeConfig\': default_8bit_quantize_configs.NoOpQuantizeConfig,\n        \'NoOpActivation\': quantize_aware_activation.NoOpActivation\n    }\n\n\nclass Conv2DBatchNormActivationQuantize(Conv2DBatchNormReLUQuantize):\n  """"""Ensure FQ does not get placed between Conv, BatchNorm and ReLU.""""""\n\n  def pattern(self):\n    return LayerPattern(\n        \'Activation\',\n        config={\'activation\': \'relu\'},\n        inputs=[Conv2DBatchNormQuantize.pattern(self)])\n\n\nclass InputLayerQuantize(transforms.Transform):\n  """"""Quantizes InputLayer, by adding QuantizeLayer after it.\n\n  InputLayer => InputLayer -> QuantizeLayer\n  """"""\n\n  def pattern(self):\n    return LayerPattern(\'InputLayer\')\n\n  def replacement(self, match_layer):\n    # TODO(pulkitb): Replace quantizer with InputLayer specific quantizer.\n    quant_layer = quantize_layer.QuantizeLayer(\n        quantizers.MovingAverageQuantizer(\n            num_bits=8, per_axis=False, symmetric=False, narrow_range=False))\n    layer_config = keras.layers.serialize(quant_layer)\n    layer_config[\'name\'] = quant_layer.name\n\n    quant_layer_node = LayerNode(\n        layer_config,\n        input_layers=[match_layer])\n\n    return quant_layer_node\n\n  def custom_objects(self):\n    return {\n        \'QuantizeLayer\': quantize_layer.QuantizeLayer,\n        \'MovingAverageQuantizer\': quantizers.MovingAverageQuantizer\n    }\n\n\nclass ConcatTransform(transforms.Transform):\n  """"""Transform for Concatenate. Quantize only after concatenation.""""""\n\n  # pylint:disable=protected-access\n\n  def pattern(self):\n    # TODO(pulkitb): Write a clean way to handle arbitrary length patterns.\n    return LayerPattern(\n        \'Concatenate\', inputs=[LayerPattern(\'.*\'), LayerPattern(\'.*\')])\n\n  def _get_layer_type(self, layer_class_name):\n    keras_layers = inspect.getmembers(tf.keras.layers, inspect.isclass)\n    for layer_name, layer_type in keras_layers:\n      if layer_name == layer_class_name:\n        return layer_type\n    return None\n\n  def _disable_output_quantize(self, quantize_config):\n    # TODO(pulkitb): Disabling quantize_config may also require handling\n    # activation quantizers. Handle that properly.\n    quantize_config.get_output_quantizers = lambda layer: []\n\n  def replacement(self, match_layer):\n    concat_layer_node = match_layer\n    feeding_layer_nodes = match_layer.input_layers\n\n    default_registry = default_8bit_quantize_registry.QuantizeRegistry(\n    )\n\n    feed_quantize_configs = []\n    for feed_layer_node in feeding_layer_nodes:\n      quantize_config = feed_layer_node.metadata.get(\'quantize_config\')\n      if not quantize_config:\n        layer_class = self._get_layer_type(feed_layer_node.layer[\'class_name\'])\n        if layer_class is None:\n          # Concat has an input layer we don\'t recognize. Return.\n          return match_layer\n\n        if layer_class == keras.layers.Concatenate:\n          # Input layer to Concat is also Concat. Don\'t quantize it.\n          feed_layer_node.metadata[\'quantize_config\'] = \\\n            default_8bit_quantize_configs.NoOpQuantizeConfig()\n          continue\n\n        if not default_registry._is_supported_layer(layer_class):\n          # Feeding layer is not supported by registry\n          return match_layer\n\n        quantize_config = default_registry._get_quantize_config(layer_class)\n        feed_layer_node.metadata[\'quantize_config\'] = quantize_config\n\n      feed_quantize_configs.append(quantize_config)\n\n    # TODO(pulkitb): this currently only disables output quantize config, but\n    # cannot properly handle if the FQ was added to the activation. Hand this\n    # properly.\n    for quantize_config in feed_quantize_configs:\n      self._disable_output_quantize(quantize_config)\n\n    if not concat_layer_node.metadata.get(\'quantize_config\'):\n      concat_layer_node.metadata[\'quantize_config\'] = \\\n        default_8bit_quantize_configs.Default8BitOutputQuantizeConfig()\n\n    return concat_layer_node\n\n  # pylint:enable=protected-access\n\n\nclass ConcatTransform3Inputs(ConcatTransform):\n\n  def pattern(self):\n    return LayerPattern(\n        \'Concatenate\',\n        inputs=[LayerPattern(\'.*\'), LayerPattern(\'.*\'), LayerPattern(\'.*\')])\n\n\nclass ConcatTransform4Inputs(ConcatTransform):\n\n  def pattern(self):\n    return LayerPattern(\n        \'Concatenate\',\n        inputs=[LayerPattern(\'.*\'), LayerPattern(\'.*\'), LayerPattern(\'.*\'),\n                LayerPattern(\'.*\')])\n\n\nclass ConcatTransform5Inputs(ConcatTransform):\n\n  def pattern(self):\n    return LayerPattern(\n        \'Concatenate\',\n        inputs=[LayerPattern(\'.*\'), LayerPattern(\'.*\'), LayerPattern(\'.*\'),\n                LayerPattern(\'.*\'), LayerPattern(\'.*\')])\n\n\nclass ConcatTransform6Inputs(ConcatTransform):\n\n  def pattern(self):\n    return LayerPattern(\n        \'Concatenate\',\n        inputs=[LayerPattern(\'.*\'), LayerPattern(\'.*\'), LayerPattern(\'.*\'),\n                LayerPattern(\'.*\'), LayerPattern(\'.*\'), LayerPattern(\'.*\')])\n'"
tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_transforms_test.py,3,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Default Transforms.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_aware_activation\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize_layer\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_configs\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_transforms\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import model_transformer\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm_test_utils\n\nModelTransformer = model_transformer.ModelTransformer\n\nConv2DModel = conv_batchnorm_test_utils.Conv2DModel\nDepthwiseConv2DModel = conv_batchnorm_test_utils.DepthwiseConv2DModel\n\nkeras = tf.keras\n\nConv2DBatchNormActivationQuantize = default_8bit_transforms.Conv2DBatchNormActivationQuantize\nConv2DBatchNormReLUQuantize = default_8bit_transforms.Conv2DBatchNormReLUQuantize\n\n\n# TODO(alanchiao): reduce redundancy by parameterizing on Depthwise vs Conv.\nclass DefaultTransformsTest(tf.test.TestCase, parameterized.TestCase):\n\n  def testTransformsConvBNReLUPattern(self):\n    model = Conv2DModel.get_nonfolded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0), model_type=\'functional\')\n    folded_model = Conv2DModel.get_folded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0), is_quantized=True)\n\n    transformed_model, _ = ModelTransformer(\n        model,\n        [default_8bit_transforms.Conv2DBatchNormReLU6Fold()]).transform()\n\n    inputs = np.random.standard_normal(Conv2DModel.get_batched_input_shape())\n    self.assertAllClose(\n        transformed_model.predict(inputs), folded_model.predict(inputs))\n\n  def testTransformsConvBNReLUPatternPreservesWeights(self):\n    # random_init to prevent non-random initialization in resulting\n    # in same weights between transformed and non-transformed models.\n    model = Conv2DModel.get_nonfolded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0),\n        model_type=\'functional\',\n        random_init=True)\n\n    transformed_model, _ = ModelTransformer(\n        model,\n        [default_8bit_transforms.Conv2DBatchNormReLU6Fold()]).transform()\n\n    transformed_weights = transformed_model.get_weights()\n    # Remove quantization related weights.\n    del transformed_weights[3:8]\n\n    self.assertEqual(len(transformed_weights), len(model.get_weights()))\n    for i in range(len(transformed_weights)):\n      self.assertAllEqual(transformed_weights[i], model.get_weights()[i])\n\n  def testTransformsConvBNPattern(self):\n    model = Conv2DModel.get_nonfolded_batchnorm_model(\n        model_type=\'functional\')\n    folded_model = Conv2DModel.get_folded_batchnorm_model(\n        is_quantized=True)\n\n    with quantize.quantize_scope():\n      transformed_model, _ = ModelTransformer(\n          model, [default_8bit_transforms.Conv2DBatchNormFold()]).transform()\n\n    inputs = np.random.standard_normal(Conv2DModel.get_batched_input_shape())\n    self.assertAllClose(\n        transformed_model.predict(inputs), folded_model.predict(inputs))\n\n  def testTransformsConvBNPatternPreservesWeights(self):\n    # random_init to prevent non-random initialization in resulting\n    # in same weights between transformed and non-transformed models.\n    model = Conv2DModel.get_nonfolded_batchnorm_model(\n        model_type=\'functional\',\n        random_init=True)\n\n    transformed_model, _ = ModelTransformer(\n        model, [default_8bit_transforms.Conv2DBatchNormFold()]).transform()\n\n    transformed_weights = transformed_model.get_weights()\n    # Remove quantization related weights.\n    del transformed_weights[3:8]\n\n    self.assertEqual(len(transformed_weights), len(model.get_weights()))\n    for i in range(len(transformed_weights)):\n      self.assertAllEqual(transformed_weights[i], model.get_weights()[i])\n\n  def testTransformsDepthwiseConvBNReLUPattern(self):\n    model = DepthwiseConv2DModel.get_nonfolded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0), model_type=\'functional\')\n    folded_model = DepthwiseConv2DModel.get_folded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0), is_quantized=True)\n\n    transformed_model, _ = ModelTransformer(\n        model, [default_8bit_transforms.DepthwiseConv2DBatchNormReLU6Fold()\n               ]).transform()\n\n    inputs = np.random.standard_normal(\n        DepthwiseConv2DModel.get_batched_input_shape())\n    self.assertAllClose(\n        transformed_model.predict(inputs), folded_model.predict(inputs))\n\n  def testTransformsDepthwiseConvBNReLUPatternPreservesWeights(self):\n    # random_init to prevent non-random initialization in resulting\n    # in same weights between transformed and non-transformed models.\n    model = DepthwiseConv2DModel.get_nonfolded_batchnorm_model(\n        post_bn_activation=keras.layers.ReLU(6.0),\n        model_type=\'functional\',\n        random_init=True)\n\n    transformed_model, _ = ModelTransformer(\n        model, [default_8bit_transforms.DepthwiseConv2DBatchNormReLU6Fold()\n               ]).transform()\n\n    transformed_weights = transformed_model.get_weights()\n    # Remove quantization related weights.\n    del transformed_weights[3:8]\n\n    self.assertEqual(len(transformed_weights), len(model.get_weights()))\n    for i in range(len(transformed_weights)):\n      self.assertAllEqual(transformed_weights[i], model.get_weights()[i])\n\n  @staticmethod\n  def _get_model(layer_type, activation_type):\n    activation = None\n    if activation_type == \'relu\':\n      activation = keras.layers.ReLU(6.0)\n    elif activation_type == \'act_relu\':\n      activation = keras.layers.Activation(\'relu\')\n\n    if layer_type == \'Conv2D\':\n      return Conv2DModel.get_nonfolded_batchnorm_model(\n          model_type=\'functional\', post_bn_activation=activation)\n    elif layer_type == \'DepthwiseConv2D\':\n      return DepthwiseConv2DModel.get_nonfolded_batchnorm_model(\n          model_type=\'functional\', post_bn_activation=activation)\n\n  @staticmethod\n  def _get_input_shape(layer_type):\n    if layer_type == \'Conv2D\':\n      return Conv2DModel.get_batched_input_shape()\n    elif layer_type == \'DepthwiseConv2D\':\n      return DepthwiseConv2DModel.get_batched_input_shape()\n\n  @parameterized.parameters(\'Conv2D\', \'DepthwiseConv2D\')\n  def testConv2DBatchNormQuantize(self, layer_type):\n    model = self._get_model(layer_type, False)\n    input_shape = self._get_input_shape(layer_type)\n\n    transformed_model, updated_metadata = ModelTransformer(\n        model,\n        [default_8bit_transforms.Conv2DBatchNormQuantize()],\n    ).transform()\n\n    conv_layer = transformed_model.layers[1]\n    bn_layer = transformed_model.layers[2]\n\n    self.assertIsInstance(\n        conv_layer.activation, quantize_aware_activation.NoOpActivation)\n    self.assertIsInstance(\n        updated_metadata.get(bn_layer.name).get(\'quantize_config\'),\n        default_8bit_quantize_configs.Default8BitOutputQuantizeConfig)\n\n    inputs = np.random.standard_normal(input_shape)\n    self.assertAllClose(\n        transformed_model.predict(inputs), model.predict(inputs))\n\n  @parameterized.parameters(\n      (\'Conv2D\', \'relu\', Conv2DBatchNormReLUQuantize),\n      (\'Conv2D\', \'act_relu\', Conv2DBatchNormActivationQuantize),\n      (\'DepthwiseConv2D\', \'relu\', Conv2DBatchNormReLUQuantize),\n      (\'DepthwiseConv2D\', \'act_relu\',\n       Conv2DBatchNormActivationQuantize),\n  )\n  def testConv2DBatchNormReLUQuantize(\n      self, layer_type, activation_type, transform_type):\n    model = self._get_model(layer_type, activation_type)\n    input_shape = self._get_input_shape(layer_type)\n\n    transformed_model, updated_metadata = ModelTransformer(\n        model,\n        [transform_type()],\n    ).transform()\n\n    conv_layer = transformed_model.layers[1]\n    bn_layer = transformed_model.layers[2]\n\n    self.assertIsInstance(\n        conv_layer.activation, quantize_aware_activation.NoOpActivation)\n    self.assertIsInstance(\n        updated_metadata.get(bn_layer.name).get(\'quantize_config\'),\n        default_8bit_quantize_configs.NoOpQuantizeConfig)\n\n    inputs = np.random.standard_normal(input_shape)\n    self.assertAllClose(\n        transformed_model.predict(inputs), model.predict(inputs))\n\n  def testAddsQuantizeLayerAfterInputLayer(self):\n    inp1 = keras.layers.Input((3,))\n    inp2 = keras.layers.Input((3,))\n    x = keras.layers.Concatenate()([inp1, inp2])\n    model = keras.Model([inp1, inp2], x)\n\n    transformed_model, _ = ModelTransformer(\n        model,\n        [default_8bit_transforms.InputLayerQuantize()]).transform()\n\n    for input_layer in transformed_model._input_layers:\n      layer_after_input = input_layer._outbound_nodes[0].outbound_layer\n      self.assertIsInstance(\n          layer_after_input,\n          quantize_layer.QuantizeLayer)\n      self.assertIsInstance(\n          layer_after_input.quantizer, quantizers.MovingAverageQuantizer)\n\n  def testConcatTransform(self):\n    r""""""Tests the Concat Transform.\n\n               Input\n              /     \\\n         Dense       Dense\n             \\      /\n              Concat\n\n      One Dense layer has a pre-specified QuantizeConfig, whereas the other does\n      not. The Transform should ensure both the output FakeQuants are disabled,\n      and only a FakeQuant after Concat is present.\n    """"""\n    dense_1 = keras.layers.Dense(3)\n    dense_2 = keras.layers.Dense(3)\n    concat = keras.layers.Concatenate()\n\n    inp = keras.layers.Input((2,))\n    x1 = dense_1(inp)\n    x2 = dense_2(inp)\n    x = concat([x1, x2])\n    model = keras.Model(inp, x)\n\n    layer_metadata = {\n        # dense_1 has an existing quantize_config.\n        dense_1.name: {\n            \'quantize_config\':\n                default_8bit_quantize_configs.Default8BitOutputQuantizeConfig()\n        }\n    }\n    _, updated_metadata = ModelTransformer(\n        model, [default_8bit_transforms.ConcatTransform()],\n        layer_metadata=layer_metadata).transform()\n\n    concat_quantize_config = updated_metadata.get(\n        concat.name).get(\'quantize_config\')\n    # Concat should quantize the output.\n    self.assertIsInstance(\n        concat_quantize_config,\n        default_8bit_quantize_configs.Default8BitOutputQuantizeConfig)\n    self.assertNotEmpty(concat_quantize_config.get_output_quantizers(None))\n\n    dense_1_quantize_config = updated_metadata.get(\n        dense_1.name).get(\'quantize_config\')\n    # The existing quantize_config should do nothing for outputs.\n    self.assertIsInstance(\n        dense_1_quantize_config,\n        default_8bit_quantize_configs.Default8BitOutputQuantizeConfig)\n    self.assertEmpty(dense_1_quantize_config.get_output_quantizers(None))\n\n    dense_2_quantize_config = updated_metadata.get(\n        dense_2.name).get(\'quantize_config\')\n    # The quantize_config from registry should do nothing at output.\n    self.assertEqual(\'Default8BitQuantizeConfig\',\n                     dense_2_quantize_config.__class__.__name__)\n    self.assertEmpty(dense_2_quantize_config.get_output_quantizers(None))\n\n  def testConcatMultipleLevels(self):\n    r""""""Tests case when concats applied to concats.\n\n            Input --------------.\n           /      \\      |      |\n         Dense   Dense   |      |\n            \\    /       |      |\n             Concat    Dense   Dense\n                 \\     /        |\n                  Concat        |\n                        \\      /\n                         Concat\n\n    The last Concat layer should be quantized but the rest\n    of the outputs should just feed into it.\n    """"""\n    inp = keras.layers.Input((3,))\n    x1 = keras.layers.Dense(3)(inp)\n    x2 = keras.layers.Dense(3)(inp)\n    x3 = keras.layers.Dense(3)(inp)\n    x4 = keras.layers.Dense(3)(inp)\n    c1 = keras.layers.Concatenate()([x1, x2])\n    c2 = keras.layers.Concatenate()([c1, x3])\n    c3 = keras.layers.Concatenate()([c2, x4])\n    model = keras.Model(inp, c3)\n    model.summary()\n\n    _, layer_metadata = ModelTransformer(\n        model,\n        [default_8bit_transforms.ConcatTransform()]).transform()\n\n    for layer in model.layers[1:-1]:\n      quantize_config = layer_metadata[layer.name].get(\'quantize_config\')\n      self.assertEmpty(quantize_config.get_output_quantizers(None))\n\n    c3_layer = model.layers[-1]\n    quantize_config = layer_metadata[c3_layer.name].get(\'quantize_config\')\n    self.assertIsInstance(\n        quantize_config,\n        default_8bit_quantize_configs.Default8BitOutputQuantizeConfig)\n    self.assertNotEmpty(quantize_config.get_output_quantizers(None))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer.py,5,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=g-explicit-length-test\n""""""Apply graph transformations to a tf.keras model.""""""\n\nimport collections\nimport copy\nimport re\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import transforms as transforms_mod\n\nLayerNode = transforms_mod.LayerNode\n\nkeras = tf.keras\nK = tf.keras.backend\n\n\nclass ModelTransformer(object):\n  """"""Matches patterns to apply transforms in a tf.keras model graph.""""""\n\n  def __init__(\n      self, model, transforms, candidate_layers=None, layer_metadata=None):\n    """"""Construct ModelTransformer.\n\n    Args:\n      model: Keras model to be transformed.\n      transforms: List of transforms to be applied to the model.\n      candidate_layers: Names of layers which may be transformed. Only layers\n        whose names are in candidate_layers are matched against patterns. The\n        default is that all layers may be transformed.\n      layer_metadata: Dictionary of metadata associated with each layer in the\n        model. The keys are layer names.\n    """"""\n    if not self._is_sequential_or_functional_model(model):\n      raise ValueError(\n          \'Only tf.keras sequential or functional models can be transformed.\')\n\n    if layer_metadata is None:\n      layer_metadata = {}\n\n    self.model = model\n    self.transforms = transforms\n    self.candidate_layers = candidate_layers\n    self.layer_metadata = layer_metadata\n\n  @staticmethod\n  def _is_sequential_or_functional_model(model):\n    return ModelTransformer._is_functional_model(model) or isinstance(\n        model, keras.Sequential)\n\n  @staticmethod\n  def _is_functional_model(model):\n    return isinstance(model, keras.Model) \\\n           and not isinstance(model, keras.Sequential) \\\n           and model._is_graph_network    # pylint: disable=protected-access\n\n  def _get_consuming_layers(self, check_layer):\n    """"""Returns all the layers which are out nodes from the layer.""""""\n    consuming_layers = []\n    for layer in self._config[\'layers\']:\n      for inbound_node in layer[\'inbound_nodes\']:\n        for connection_info in inbound_node:\n          if connection_info[0] == check_layer[\'config\'][\'name\']:\n            consuming_layers.append(layer)\n    return consuming_layers\n\n  def _get_output_consumers(self, check_layer):\n    """"""Returns if any tensors from the layer are outputs of the model.""""""\n    output_consumers = []\n    for output_layer in self._config[\'output_layers\']:\n      if output_layer[0] == check_layer[\'config\'][\'name\']:\n        output_consumers.append(output_layer)\n    return output_consumers\n\n  def _get_layers(self, layer_names):\n    return [\n        layer for layer in self._config[\'layers\']\n        if layer[\'config\'][\'name\'] in layer_names\n    ]\n\n  def _get_layer_weights(self, layer_name):\n    return self._layer_weights_map.get(layer_name, {})\n\n  def _get_layer_metadata(self, layer_name):\n    return self._layer_metadata_map.get(layer_name, {})\n\n  def _match_pattern(self, target, pattern):\n    return re.match(\'^\' + pattern + \'$\', target) is not None\n\n  def _match_layer(self, layer, pattern):\n    """"""Check if specific layer matches the pattern.""""""\n\n    if self.candidate_layers and layer[\'config\'][\n        \'name\'] not in self.candidate_layers:\n      return False\n\n    if not self._match_pattern(layer[\'class_name\'], pattern.class_name):\n      return False\n\n    layer_config = layer[\'config\']\n    for key, value in pattern.config.items():\n      # This comparison should probably use the serialized value.\n      # Consider adding regex support to key/values as well. This will allow\n      # negative matches as well.\n      if layer_config.get(key) != value:\n        return False\n\n    return True\n\n  def _is_match_supported(self, layer, is_head_node):\n    """"""Check if ModelTransformer supports transformations given number of inputs and outputs at a layer.\n\n    Args:\n      layer: layer for pattern matching. Must come from a Functional model.\n      is_head_node: whether this is the head node (e.g. in A -> B , B is the\n        head node).\n\n    Returns:\n      whether match is supported.\n    """"""\n\n    inbound_nodes = layer[\'inbound_nodes\']\n\n    if len(inbound_nodes) > 1:\n      # `layer` is re-used for more than 1 connection from previous layers. If\n      # a pattern matches one set of inputs and is replaced, it will break the\n      # other connection.\n      #\n      # Note that theoretically it\'s possible to have multiple connections have\n      # exactly the same pattern, and in that case the transform might be\n      # applied. But that\'s a very complicated edge case not worth handling.\n      return False\n\n    # If a layer has multiple inbound nodes, it will produce multiple outbound\n    # connections as well. Hence no need to explicitly check that.\n\n    consuming_layers = self._get_consuming_layers(layer)\n    output_consumers = self._get_output_consumers(layer)\n    if len(consuming_layers) + len(output_consumers) > 1:\n      # Even if a layer has only 1 incoming connection, multiple layers may\n      # still consume the output. Having multiple consumers is only supported\n      # for the head node, and not intermediate layers. Replacing intermediate\n      # nodes with >1 consumer will lead to dangling nodes.\n      #\n      # Note that theoretically, intermediate layers can supported, as a part\n      # of a general layer transform tool. This is not supported given no\n      # motivating use case.\n      if not is_head_node:\n        return False\n\n    return True\n\n  def _get_input_layer_names(self, layer):\n    """"""Get the names of a layer\'s input layers.""""""\n    if self._is_functional_model(self.model):\n      inbound_nodes = layer[\'inbound_nodes\']\n      return [connection_info[0] for connection_info in inbound_nodes[0]]\n    else:  # Sequential model.\n      layers = self._config[\'layers\']\n      i = layers.index(layer)\n      if i == 0:\n        # First layer has no inputs.\n        return []\n      else:\n        return [layers[i - 1][\'config\'][\'name\']]\n\n  def _match_layer_with_inputs(self, layer, pattern, is_head_node):\n    """"""Match pattern at this layer, and continue to match at its inputs.""""""\n\n    if not self._match_layer(layer, pattern):\n      return None\n\n    if self._is_functional_model(\n        self.model) and not self._is_match_supported(layer, is_head_node):\n      return None\n\n    if len(pattern.inputs) == 0:\n      # Leaf layer in pattern.\n      return LayerNode(layer, self._get_layer_weights(layer[\'config\'][\'name\']),\n                       [], self._get_layer_metadata(layer[\'config\'][\'name\']))\n\n    # There is a possible edge case where a single layer may output multiple\n    # tensors and multiple tensors from that layer may be used by the\n    # connection. Ignoring those for now.\n    input_layer_names = self._get_input_layer_names(layer)\n    input_layers = self._get_layers(input_layer_names)\n\n    if len(input_layers) != len(pattern.inputs):\n      # Number of inputs this layer takes is different from the number of\n      # inputs in the pattern.\n      #\n      # This path currently has the limitation that it requires an exact number\n      # of inputs to match a pattern. For example, if a user wants to match\n      # 2 Convs -> Concat and 3 Convs -> Concat, they would need to write\n      # 2 different patterns.\n      return None\n\n    # Inbound layers can have different order from the list of input patterns.\n    # TODO(pulkitb): Fix by checking all permutations.\n    input_match_layer_nodes = []\n    for input_layer, pattern in zip(input_layers, pattern.inputs):\n      match_layer_node = self._match_layer_with_inputs(\n          input_layer, pattern, is_head_node=False)\n      if not match_layer_node:\n        return None\n      input_match_layer_nodes.append(match_layer_node)\n\n    return LayerNode(layer, self._get_layer_weights(layer[\'config\'][\'name\']),\n                     input_match_layer_nodes,\n                     self._get_layer_metadata(layer[\'config\'][\'name\']))\n\n  def _find_pattern(self, pattern, matched_layers=None):\n    for layer in self._config[\'layers\']:\n      if matched_layers and layer[\'config\'][\'name\'] in matched_layers:\n        continue\n      match_layer = self._match_layer_with_inputs(\n          layer, pattern, is_head_node=True)\n      if match_layer:\n        return match_layer\n\n    return None\n\n  def _get_leaf_layers(self, match_layer):\n    """"""Return leaf layers from this sub-graph tree.""""""\n\n    if not match_layer.input_layers:\n      return [match_layer.layer]\n\n    # If 2 different layers point to the same input, or if a layer uses the\n    # same input multiple times, the input layer can be repeated. But it\n    # preserves a bit of structure.\n\n    leaf_layers = []\n    for inp in match_layer.input_layers:\n      leaf_layers.extend(self._get_leaf_layers(inp))\n\n    return leaf_layers\n\n  @staticmethod\n  def _get_layer_names(layer_node):\n    result = [layer_node.layer[\'config\'][\'name\']]\n    for input_layer in layer_node.input_layers:\n      result.extend(ModelTransformer._get_layer_names(input_layer))\n    return result\n\n  def _remove_layers(self, layers_to_remove, layers_to_remove_names):\n    # Remove layers.\n    for layer_to_remove in layers_to_remove:\n      self._config[\'layers\'].remove(layer_to_remove)\n    # Remove entry from weight and metadata maps,\n    # now that layer has been removed.\n    for layer_name in layers_to_remove_names:\n      self._layer_weights_map.pop(layer_name, None)\n      self._layer_metadata_map.pop(layer_name, None)\n\n  def _replace(self, match_layer_node, replacement_layer_node):\n    """"""Replace the tree or chain of match_layer_node with replacement_layer_node.""""""\n    if self._is_functional_model(self.model):\n      self._replace_functional(match_layer_node, replacement_layer_node)\n    else:\n      self._replace_sequential(match_layer_node, replacement_layer_node)\n\n  def _replace_functional(self, match_layer_node, replacement_layer_node):\n    """"""Functional model: replace the tree of match_layer_node with replacement_layer_node.""""""\n\n    # 1. Point all consumers of the head of the matching sub-tree to the head\n    # replacement layer.\n    #\n    # There are some assumptions baked in. The head layer only has 1 inbound and\n    # outbound node. The resulting number and shape of tensors from the\n    # replaced layer should equal the original layer.\n\n    consuming_layers = self._get_consuming_layers(match_layer_node.layer)\n    for consumer in consuming_layers:\n      for inbound_node in consumer[\'inbound_nodes\']:\n        for connection_info in inbound_node:\n          if connection_info[0] == match_layer_node.layer[\'config\'][\'name\']:\n            connection_info[0] = replacement_layer_node.layer[\'config\'][\'name\']\n\n    output_consumers = self._get_output_consumers(match_layer_node.layer)\n    for output_consumer in output_consumers:\n      output_consumer[0] = replacement_layer_node.layer[\'config\'][\'name\']\n\n    # 2. Create inbound nodes for the replacement layers. This connects all\n    # the replacement layers.\n\n    def _assign_inbounds_for_replacement(layer_node):\n      """"""_assign_inbounds_for_replacement.""""""\n\n      if not layer_node.input_layers:\n        return\n\n      layer_node.layer[\'inbound_nodes\'] = [[]]\n      for input_layer in layer_node.input_layers:\n        # inbound_nodes can be specific tensors from multiple inbound\n        # connections. We make the following assumptions.\n        # - Only 1 inbound node for each replacement layer.\n        # - Only 1 tensor output from the previous layer which is connected.\n        # - call() method during construction does not have any args.\n        # These are reasonable assumptions for almost all case we are\n        # interested in.\n        layer_node.layer[\'inbound_nodes\'][0].append(\n            [input_layer.layer[\'config\'][\'name\'], 0, 0, {}])\n\n        _assign_inbounds_for_replacement(input_layer)\n\n    _assign_inbounds_for_replacement(replacement_layer_node)\n\n    # 3. Connect the leaves of the replacement_layers to the inbound_nodes of\n    # the leaves in the original layer.\n\n    original_leaf_layers = self._get_leaf_layers(match_layer_node)\n    original_inbound_nodes = [\n        layer[\'inbound_nodes\'] for layer in original_leaf_layers\n    ]\n\n    replacement_leaf_layers = self._get_leaf_layers(replacement_layer_node)\n\n    # The original pattern and the replacement pattern can potentially have\n    # different number of leaf nodes and differences in how they consume these\n    # input layers. Matching them will require sophisticated hackery to recreate\n    # the new layers with the original input structure.\n\n    # Given our existing transforms, we can assume they match.\n\n    if len(original_leaf_layers) != len(replacement_leaf_layers):\n      raise RuntimeError(\'Different size of leaf layers not supported yet.\')\n\n    for original_inbound_nodes, replacement_leaf_layer in zip(\n        original_inbound_nodes, replacement_leaf_layers):\n      replacement_leaf_layer[\'inbound_nodes\'] = original_inbound_nodes\n\n    # 4. Remove the original matched layers\n    layers_to_remove_names = self._get_layer_names(match_layer_node)\n    layers_to_remove = self._get_layers(layers_to_remove_names)\n\n    self._remove_layers(layers_to_remove, layers_to_remove_names)\n\n    # 5. Add in the new layers.\n    def _add_replacement_layer(layer_node):\n      """"""Recursively add new layers.""""""\n      self._config[\'layers\'].append(layer_node.layer)\n      if layer_node.weights:\n        self._layer_weights_map[layer_node.layer[\'config\']\n                                [\'name\']] = layer_node.weights\n      if layer_node.metadata:\n        self._layer_metadata_map[layer_node.layer[\'config\']\n                                 [\'name\']] = layer_node.metadata\n\n      for input_layer in layer_node.input_layers:\n        _add_replacement_layer(input_layer)\n\n    _add_replacement_layer(replacement_layer_node)\n\n  def _replace_sequential(self, match_layer_node, replacement_layer_node):\n    """"""Sequential model: replace the chain of match_layer_node with replacement_layer_node.""""""\n    # 1. Remove the original matched layers.\n    layers_to_remove_names = self._get_layer_names(match_layer_node)\n    layers_to_remove = self._get_layers(layers_to_remove_names)\n\n    # These variables are needed when adding the new layers\n    # and must be set before _remove_layers removes them.\n    first_layer_removed = layers_to_remove[0]\n    first_layer_removed_index = self._config[\'layers\'].index(\n        first_layer_removed)\n\n    self._remove_layers(layers_to_remove, layers_to_remove_names)\n\n    # 2. Add in the new layers.\n    def _get_replacement_nodes(replacement_node):\n      """"""Get list of replacement nodes in Sequential order.""""""\n      replacement_nodes = []\n\n      for input_layer in replacement_node.input_layers:\n        replacement_nodes.extend(_get_replacement_nodes(input_layer))\n\n      replacement_nodes.append(replacement_node)\n\n      return replacement_nodes\n\n    def _add_replacement_nodes(first_layer_removed_index, replacement_nodes):\n      """"""Add replacement nodes to Sequential model.""""""\n\n      # Potentially insert nodes into middle of model.\n      i = first_layer_removed_index\n      for replacement_node in replacement_nodes:\n        self._config[\'layers\'].insert(i, replacement_node.layer)\n        if replacement_node.weights:\n          self._layer_weights_map[replacement_node.layer[\'config\']\n                                  [\'name\']] = replacement_node.weights\n        if replacement_node.metadata:\n          self._layer_metadata_map[replacement_node.layer[\'config\']\n                                   [\'name\']] = replacement_node.metadata\n        i += 1\n\n    replacement_nodes = _get_replacement_nodes(replacement_layer_node)\n    _add_replacement_nodes(first_layer_removed_index, replacement_nodes)\n\n  @staticmethod\n  def _weight_name(name):\n    """"""Extracts the weight name by removing layer from TF variable name.\n\n    For example, returns \'kernel:0\' for \'dense_2/kernel:0\'.\n\n    Args:\n      name: TensorFlow variable name.\n\n    Returns:\n      Extracted weight name.\n    """"""\n    return name.split(\'/\')[-1]\n\n  def _get_keras_layer_weights(self, keras_layer):\n    """"""Returns a map of weight name, weight matrix. Keeps keras ordering.""""""\n    weights_map = collections.OrderedDict()\n    for weight_tensor, weight_numpy in \\\n        zip(keras_layer.weights, keras_layer.get_weights()):\n      weights_map[self._weight_name(weight_tensor.name)] = weight_numpy\n\n    return weights_map\n\n  def _set_layer_weights(self, layer, weights_map):\n    """"""Sets the values of weights in a Keras layer.""""""\n\n    weight_value_tuples = []\n    for weight_tensor in layer.weights:\n      weight_name = self._weight_name(weight_tensor.name)\n      if weight_name in weights_map:\n        weight_value_tuples.append(\n            (weight_tensor, weights_map[weight_name]))\n\n    K.batch_set_value(weight_value_tuples)\n\n  @staticmethod\n  def _name(obj):\n    return obj.__class__.__name__\n\n  def _get_matched_layers(self, transform):\n    return self._transform_matched_layers_map.get(self._name(transform), [])\n\n  def _store_successful_match(self, transform, layer_node):\n    if self._name(transform) not in self._transform_matched_layers_map:\n      self._transform_matched_layers_map[self._name(transform)] = []\n\n    self._transform_matched_layers_map[self._name(transform)].append(\n        layer_node.layer[\'config\'][\'name\'])\n\n  def transform(self):\n    """"""Transforms the Keras model by applying all the specified transforms.\n\n    This is the main entry point function used to apply the transformations to\n    the Keras model.\n\n    Not suitable for multi-threaded use. Creates and manipulates internal state.\n\n    Returns:\n      (Keras model after transformation, Updated layer metadata map)\n    """"""\n\n    # Gets a serialized dict representation of the model, containing all its\n    # layers, their connections and configuration. This is the main structure\n    # which is used to understand model structure, and also manipulate it.\n    #\n    # config = {\n    #   \'input_layers\': [ ... ],\n    #   \'layers\': [{\n    #       \'inbound_nodes\': [INPUT CONFIG OF LAYER],\n    #       \'name\': \'LAYER_NAME\',\n    #       \'config\': { LAYER_CONFIG }\n    #     }, {\n    #     ...\n    #   }],\n    #   \'output_layers\': [ ... ],\n    #   \'name\': \'MODEL_NAME\',\n    #\n    self._config = self.model.get_config()\n\n    # Stores map of Transform -> List of layer names matched by transform.\n    # Same transform should not match+replace the same layer more than once\n    # to prevent infinite loops.\n    self._transform_matched_layers_map = {}\n    self._layer_weights_map = {}\n    for layer in self.model.layers:\n      self._layer_weights_map[layer.name] = self._get_keras_layer_weights(layer)\n\n    # Maintains a current mutable copy of the metadata through transformation.\n    self._layer_metadata_map = copy.deepcopy(self.layer_metadata)\n\n    # We run an infinite loop and keep applying transformations as long as\n    # patterns are found. This allows recursive pattern matching where a\n    # modification by one transform may lead to another match.\n    #\n    # TODO(pulkitb): This leads to infinite loops with poor patterns which may\n    # match their replacement. Add counters with limits to fix it.\n    while True:\n      match_found = False\n      for transform in self.transforms:\n        # A transform may find multiple instances of a pattern in the model.\n        # Keep finding and replacing till done.\n        while True:\n          match_layer_node = self._find_pattern(\n              transform.pattern(), self._get_matched_layers(transform))\n\n          # Pattern did not match any layer. Move to next transform.\n          if not match_layer_node:\n            break\n\n          self._store_successful_match(transform, match_layer_node)\n\n          # Copying the match_layer_node ensures the replacement code can\n          # freely modify the match.\n          replacement_layer_node = transform.replacement(\n              copy.deepcopy(match_layer_node))\n\n          # If equal, the matched layers are being replaced with exactly the\n          # same set of layers that were matched with the same config.\n          # For Transforms, that may inadvertently do this we can end up in\n          # an infinite loop. Move on if no meaningful change has been made.\n          if match_layer_node == replacement_layer_node:\n            continue\n\n          match_found = True\n          self._replace(match_layer_node, replacement_layer_node)\n\n      # None of the transforms found a pattern. We can stop now.\n      if not match_found:\n        break\n\n    custom_objects = {}\n    for transform in self.transforms:\n      custom_objects.update(transform.custom_objects())\n\n    # Reconstruct model from the config, using the cloned layers.\n    if self._is_functional_model(self.model):\n      transformed_model = keras.Model.from_config(self._config, custom_objects)\n    else:\n      transformed_model = keras.Sequential.from_config(self._config,\n                                                       custom_objects)\n\n    for layer in transformed_model.layers:\n      weights = self._layer_weights_map.get(layer.name)\n      if weights:\n        self._set_layer_weights(layer, weights)\n\n    return transformed_model, copy.deepcopy(self._layer_metadata_map)\n'"
tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer_test.py,7,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for Model Transformation.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import model_transformer\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import transforms\n\nModelTransformer = model_transformer.ModelTransformer\nTransform = transforms.Transform\nLayerPattern = transforms.LayerPattern\nLayerNode = transforms.LayerNode\n\nkeras = tf.keras\n\n\nclass ModelTransformerTest(tf.test.TestCase, parameterized.TestCase):\n\n  @staticmethod\n  def _batch(dims, batch_size):\n    """"""Adds provided batch_size to existing dims.\n\n    If dims is (None, 5, 2), returns (batch_size, 5, 2)\n\n    Args:\n      dims: Dimensions\n      batch_size: batch_size\n\n    Returns:\n      dims with batch_size added as first parameter of list.\n    """"""\n    if dims[0] is None:\n      dims[0] = batch_size\n    return dims\n\n  @staticmethod\n  def _get_layer(model, n_excluding_input, model_type):\n    # Argument n excludes the input layer.\n    if model_type == \'functional\':\n      return model.layers[n_excluding_input + 1]\n    else:\n      return model.layers[n_excluding_input]\n\n  def _create_model_inputs(self, model):\n    return np.random.randn(*self._batch(model.input.get_shape().as_list(), 1))\n\n  def _simple_dense_model(self, model_type=\'functional\'):\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      x = keras.layers.Dense(2)(inp)\n      out = keras.layers.ReLU(6.0)(x)\n      return keras.Model(inp, out)\n    elif model_type == \'sequential\':\n      return keras.Sequential(\n          [keras.layers.Dense(2, input_shape=(3,)),\n           keras.layers.ReLU(6.0)])\n\n  def _assert_config(self, expected_config, actual_config, exclude_keys=None):\n    """"""Asserts that the two config dictionaries are equal.\n\n    This method is used to compare keras Model and Layer configs. It provides\n    the ability to exclude the keys we don\'t want compared.\n\n    Args:\n      expected_config: Config which we expect.\n      actual_config: Actual received config.\n      exclude_keys: List of keys to not check against.\n    """"""\n    expected_config = expected_config.copy()\n    actual_config = actual_config.copy()\n\n    def _remove_keys(config):\n      """"""Removes all exclude_keys (including nested) from the dict.""""""\n      for key in exclude_keys:\n        if key in config:\n          del config[key]\n\n      for _, v in config.items():\n        if isinstance(v, dict):\n          _remove_keys(v)\n\n        if isinstance(v, list):\n          for item in v:\n            if isinstance(item, dict):\n              _remove_keys(item)\n\n    if exclude_keys:\n      _remove_keys(expected_config)\n      _remove_keys(actual_config)\n\n    self.assertDictEqual(expected_config, actual_config)\n\n  def _assert_model_results_equal(self, model, transformed_model):\n    inputs = self._create_model_inputs(model)\n    self.assertAllClose(\n        model.predict(inputs), transformed_model.predict(inputs))\n\n  # Transform classes for testing.\n\n  class ReplaceDenseLayer(transforms.Transform):\n    """"""Replaces `Dense` layers with `MyDense`, a simple inherited layer.\n\n    This `Transform` class replaces `Dense` layers with a class `MyDense`\n    which is simply an empty inheritance of `Dense`. This makes it easy to test\n    the transformation code.\n    """"""\n\n    class MyDense(keras.layers.Dense):\n      pass\n\n    def pattern(self):\n      return LayerPattern(\'Dense\')\n\n    def replacement(self, match_layer):\n      match_layer_config = match_layer.layer[\'config\']\n      my_dense_layer = self.MyDense(**match_layer_config)\n\n      replace_layer = keras.layers.serialize(my_dense_layer)\n      replace_layer[\'name\'] = replace_layer[\'config\'][\'name\']\n\n      return LayerNode(replace_layer, match_layer.weights, [])\n\n    def custom_objects(self):\n      return {\'MyDense\': self.MyDense}\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceSingleLayerWithSingleLayer_OneOccurrence(self, model_type):\n    model = self._simple_dense_model(model_type)\n\n    transformed_model, _ = ModelTransformer(\n        model, [self.ReplaceDenseLayer()]).transform()\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'class_name\', \'build_input_shape\'])\n\n    self.assertEqual(\n        \'MyDense\',\n        self._get_layer(transformed_model, 0, model_type).__class__.__name__)\n\n    self._assert_model_results_equal(model, transformed_model)\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceSingleLayerWithSingleLayer_MultipleOccurrences(\n      self, model_type):\n    # Note that the functional and sequential model architectures\n    # are different. The first is a tree and the second is a chain.\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      x1 = keras.layers.Dense(2)(inp)\n      x2 = keras.layers.Dense(2)(inp)\n      out1 = keras.layers.ReLU(6.0)(x1)\n      out2 = keras.layers.ReLU(6.0)(x2)\n      model = keras.Model(inp, [out1, out2])\n    else:\n      model = keras.Sequential([\n          keras.layers.Dense(2, input_shape=(3,)),\n          keras.layers.Dense(2),\n          keras.layers.ReLU(6.0)\n      ])\n\n    transformed_model, _ = ModelTransformer(\n        model, [self.ReplaceDenseLayer()]).transform()\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'class_name\', \'build_input_shape\'])\n\n    self.assertEqual(\n        \'MyDense\',\n        self._get_layer(transformed_model, 0, model_type).__class__.__name__)\n    self.assertEqual(\n        \'MyDense\',\n        self._get_layer(transformed_model, 1, model_type).__class__.__name__)\n\n    self._assert_model_results_equal(model, transformed_model)\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceSingleLayerWithSingleLayer_MatchParameters(self, model_type):\n\n    class RemoveBiasInDense(transforms.Transform):\n      """"""Replaces Dense layers with matching layers with `use_bias=False`.""""""\n\n      def pattern(self):\n        return LayerPattern(\'Dense\', {\'use_bias\': True})\n\n      def replacement(self, match_layer):\n        match_layer_config = match_layer.layer[\'config\']\n        # Remove bias\n        match_layer_weights = match_layer.weights\n        match_layer_weights.popitem()\n\n        match_layer_config[\'use_bias\'] = False\n        new_dense_layer = keras.layers.Dense(**match_layer_config)\n\n        replace_layer = keras.layers.serialize(new_dense_layer)\n        replace_layer[\'name\'] = replace_layer[\'config\'][\'name\']\n\n        return LayerNode(replace_layer, match_layer_weights, [])\n\n    model = self._simple_dense_model(model_type)\n\n    transformed_model, _ = ModelTransformer(\n        model, [RemoveBiasInDense()]).transform()\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'use_bias\', \'build_input_shape\'])\n\n    first_noninput_layer = self._get_layer(transformed_model, 0, model_type)\n    self.assertFalse(first_noninput_layer.use_bias)\n\n    # Should match since bias is initialized with zeros.\n    self._assert_model_results_equal(model, transformed_model)\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceSingleLayer_WithMultipleLayers(self, model_type):\n\n    class ReplaceDenseWithDenseAndActivation(transforms.Transform):\n      """"""Dense => (Dense -> ReLU).""""""\n\n      def pattern(self):\n        return LayerPattern(\'Dense\')\n\n      def replacement(self, match_layer):\n        activation_layer = keras.layers.Activation(\'linear\')\n        layer_config = keras.layers.serialize(activation_layer)\n        layer_config[\'name\'] = activation_layer.name\n\n        activation_layer_node = LayerNode(\n            layer_config, input_layers=[match_layer])\n\n        return activation_layer_node\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      out = keras.layers.Dense(2)(inp)\n      model = keras.Model(inp, out)\n    elif model_type == \'sequential\':\n      model = keras.Sequential([keras.layers.Dense(2, input_shape=(3,))])\n\n    transformed_model, _ = ModelTransformer(\n        model, [ReplaceDenseWithDenseAndActivation()]).transform()\n\n    if model_type == \'functional\':\n      # Extra Input layer over Sequential.\n      num_expected_layers = 3\n    elif model_type == \'sequential\':\n      num_expected_layers = 2\n\n    self.assertLen(transformed_model.layers, num_expected_layers)\n\n    self.assertIsInstance(\n        self._get_layer(transformed_model, 0, model_type), keras.layers.Dense)\n    self.assertIsInstance(\n        self._get_layer(transformed_model, 1, model_type),\n        keras.layers.Activation)\n\n  def testReplaceSingleLayer_WithMultipleLayers_InputLayer(self):\n\n    class ReplaceInputWithInputAndActivation(transforms.Transform):\n      """"""InputLayer => (InputLayer -> Activation).""""""\n\n      def pattern(self):\n        return LayerPattern(\'InputLayer\')\n\n      def replacement(self, match_layer):\n        activation_layer = keras.layers.Activation(\'linear\')\n        layer_config = keras.layers.serialize(activation_layer)\n        layer_config[\'name\'] = activation_layer.name\n\n        activation_layer_node = LayerNode(\n            layer_config,\n            input_layers=[match_layer])\n\n        return activation_layer_node\n\n    inp1 = keras.layers.Input((3,))\n    inp2 = keras.layers.Input((3,))\n    out = keras.layers.Concatenate()([inp1, inp2])\n    model = keras.Model([inp1, inp2], out)\n\n    transformed_model, _ = ModelTransformer(\n        model, [ReplaceInputWithInputAndActivation()]).transform()\n\n    self.assertLen(transformed_model.layers, 5)\n    self.assertIsInstance(transformed_model.layers[0], keras.layers.InputLayer)\n    self.assertIsInstance(transformed_model.layers[1], keras.layers.InputLayer)\n    self.assertIsInstance(transformed_model.layers[2], keras.layers.Activation)\n    self.assertIsInstance(transformed_model.layers[3], keras.layers.Activation)\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceChainOfLayers_WithSingleLayer(self, model_type):\n\n    class FuseReLUIntoDense(transforms.Transform):\n      """"""Fuse ReLU into Dense layers.""""""\n\n      def pattern(self):\n        return LayerPattern(\'ReLU\', inputs=[LayerPattern(\'Dense\')])\n\n      def replacement(self, match_layer):\n        dense_layer_config = match_layer.input_layers[0].layer[\'config\']\n        dense_layer_weights = match_layer.input_layers[0].weights\n        dense_layer_config[\'activation\'] = \'relu\'\n\n        new_dense_layer = keras.layers.Dense(**dense_layer_config)\n\n        replace_layer = keras.layers.serialize(new_dense_layer)\n        replace_layer[\'name\'] = replace_layer[\'config\'][\'name\']\n\n        return LayerNode(replace_layer, dense_layer_weights, [])\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      out = keras.layers.Dense(2, activation=\'relu\')(inp)\n      model_fused = keras.Model(inp, out)\n    else:\n      model_fused = keras.Sequential(\n          [keras.layers.Dense(2, activation=\'relu\', input_shape=(3,))])\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      x = keras.layers.Dense(2)(inp)\n      out = keras.layers.ReLU()(x)\n      model = keras.Model(inp, out)\n    else:\n      model = keras.Sequential(\n          [keras.layers.Dense(2, input_shape=(3,)),\n           keras.layers.ReLU()])\n    model.set_weights(model_fused.get_weights())\n\n    transformed_model, _ = ModelTransformer(\n        model, [FuseReLUIntoDense()]).transform()\n\n    self._assert_config(\n        model_fused.get_config(),\n        transformed_model.get_config(),\n        # Layers have different names in the models, but same config.\n        # Consider verifying the names loosely.\n        #\n        # build_input_shape is a TensorShape object and the two objects are not\n        # considered the same even though the shapes are the same.\n        [\n            \'input_layers\', \'output_layers\', \'name\', \'inbound_nodes\',\n            \'build_input_shape\'\n        ])\n\n    self._assert_model_results_equal(model, transformed_model)\n    self._assert_model_results_equal(model_fused, transformed_model)\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testReplaceChainOfLayers_WithChainOfLayers(self, model_type):\n\n    class Replace2DenseLayers(transforms.Transform):\n      """"""Replaces 2 Dense layers with the same dense layers.\n\n      Doesn\'t make any meaningful change to the layer. Just verifies that\n      replacing multiple layers works as expected.\n      """"""\n\n      def pattern(self):\n        return LayerPattern(\'Dense\', inputs=[LayerPattern(\'Dense\')])\n\n      def replacement(self, match_layer):\n        # Adds a modification so the transform happens. If the layers are\n        # exactly the same, they get ignored by transformer.\n        match_layer.metadata[\'key\'] = \'value\'\n        return match_layer\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3,))\n      x = keras.layers.Dense(3)(inp)\n      x = keras.layers.Dense(2)(x)\n      model = keras.Model(inp, x)\n    else:\n      model = keras.Sequential(\n          [keras.layers.Dense(3, input_shape=(3,)),\n           keras.layers.Dense(2)])\n\n    transformed_model, _ = ModelTransformer(\n        model, [Replace2DenseLayers()]).transform()\n\n    self._assert_model_results_equal(model, transformed_model)\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'build_input_shape\'])\n\n  def testReplaceListOfLayers_Sequential(self):\n    class ReplaceConvBatchNorm(transforms.Transform):\n      """"""Replaces a ConvBatchNorm pattern with the same set of layers.\n\n      Doesn\'t make any meaningful change to the layer. Just verifies that\n      replacing multiple layers works as expected.\n      """"""\n\n      def pattern(self):\n        return LayerPattern(\'BatchNormalization\',\n                            inputs=[LayerPattern(\'Conv2D\')])\n\n      def replacement(self, match_layer):\n        # Adds a modification so the transform happens. If the layers are\n        # exactly the same, they get ignored by transformer.\n        match_layer.metadata[\'key\'] = \'value\'\n        return match_layer\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.ReLU(),\n    ])\n    model_layer_names = [layer.name for layer in model.layers]\n\n    transformed_model, _ = ModelTransformer(\n        model, [ReplaceConvBatchNorm()]).transform()\n    transformed_model_layer_names = [\n        layer.name for layer in transformed_model.layers]\n\n    self.assertEqual(model_layer_names, transformed_model_layer_names)\n\n  def testReplaceTreeOfLayers_WithSingleLayer(self):\n    # TODO(pulkitb): Implement\n    pass\n\n  def testReplaceTreeOfLayers_WithTreeOfLayers(self):\n    # TODO(pulkitb): Implement\n    pass\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testDoesNotMatchForever_IfReplacementEqualsMatch(self, model_type):\n\n    class ReplaceWithSelf(Transform):\n\n      def pattern(self):\n        return LayerPattern(\'ReLU\', inputs=[LayerPattern(\'Dense\')])\n\n      def replacement(self, match_layer):\n        return match_layer\n\n    model = self._simple_dense_model(model_type)\n\n    transformed_model, _ = ModelTransformer(\n        model, [ReplaceWithSelf()]).transform()\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'build_input_shape\'])\n\n  # Negative Tests\n  # TODO(pulkitb): Add negative tests\n  # 1. Handles layer being part of multiple models.\n\n  class VerifyMatch(Transform):\n\n    def __init__(self, pattern):\n      self._pattern = pattern\n      self._matched = False\n\n    def pattern(self):\n      return self._pattern\n\n    def replacement(self, match_layer):\n      self._matched = True\n      return match_layer\n\n    def matched(self):\n      return self._matched\n\n    def reset(self):\n      self._matched = False\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testPatternShouldOnlyMatch_CandidateLayers(self, model_type):\n    pattern = LayerPattern(\'ReLU\', inputs=[LayerPattern(\'Dense\')])\n    transform = self.VerifyMatch(pattern)\n\n    model = self._simple_dense_model(model_type)\n    layer_names = [layer.name for layer in model.layers]\n\n    # By default matches everything.\n    ModelTransformer(model, [transform]).transform()\n    self.assertTrue(transform.matched())\n\n    # Matches when all layers passed in.\n    transform.reset()\n    ModelTransformer(model, [transform], layer_names).transform()\n    self.assertTrue(transform.matched())\n\n    # Fails. Dense missing.\n    transform.reset()\n    ModelTransformer(model, [transform], [model.layers[-2].name]).transform()\n    self.assertFalse(transform.matched())\n\n    # Fails. ReLU missing.\n    transform.reset()\n    ModelTransformer(model, [transform], [model.layers[-1].name]).transform()\n    self.assertFalse(transform.matched())\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testPatternCanMatch_MultipleLayers(self, model_type):\n    pattern = LayerPattern(\'Conv2D|DepthwiseConv2D\')\n    transform = self.VerifyMatch(pattern)\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3, 3, 3))\n      x = keras.layers.Conv2D(3, (2, 2))(inp)\n      conv_model = keras.Model(inp, x)\n    else:\n      conv_model = keras.Sequential(\n          [keras.layers.Conv2D(3, (2, 2), input_shape=(3, 3, 3))])\n\n    ModelTransformer(conv_model, [transform]).transform()\n    self.assertTrue(transform.matched())\n\n    if model_type == \'functional\':\n      inp = keras.layers.Input((3, 3, 3))\n      x = keras.layers.DepthwiseConv2D((2, 2))(inp)\n      depth_conv_model = keras.Model(inp, x)\n    else:\n      depth_conv_model = keras.Sequential(\n          [keras.layers.DepthwiseConv2D((2, 2), input_shape=(3, 3, 3))])\n\n    transform.reset()\n    ModelTransformer(depth_conv_model, [transform]).transform()\n    self.assertTrue(transform.matched())\n\n  def testPatternCanMatch_HeadNodeWithMultipleConsumers(self):\n    # Dense -> Dense2  -> ReLU\n    #                  -> ReLU2\n    #\n    # where Dense2, the head node in the pattern, has multiple consumers\n    # (ReLU and ReLU2).\n    pattern = LayerPattern(\'Dense\', inputs=[LayerPattern(\'Dense\')])\n    transform = self.VerifyMatch(pattern)\n\n    inp = keras.layers.Input(3)\n    x = keras.layers.Dense(2)(inp)\n    y = keras.layers.Dense(2)(x)\n    out1 = keras.layers.ReLU(6.0)(y)\n    out2 = keras.layers.ReLU(6.0)(y)\n\n    model = keras.Model(inp, [out1, out2])\n\n    ModelTransformer(model, [transform]).transform()\n    self.assertTrue(transform.matched())\n\n  def testPatternDoesNotSupportMatch_IntermediateNodeWithMultipleConsumers(\n      self):\n    # Dense -> Dense2  -> ReLU\n    #                  -> ReLU2\n    #\n    # where Dense2, an intermediate node in the pattern, has multiple consumers\n    # (ReLU and ReLU2).\n    pattern = LayerPattern(\n        \'ReLU\', inputs=[LayerPattern(\'Dense\', inputs=[LayerPattern(\'Dense\')])])\n    transform = self.VerifyMatch(pattern)\n\n    inp = keras.layers.Input(3)\n    x = keras.layers.Dense(2)(inp)\n    y = keras.layers.Dense(2)(x)\n    out1 = keras.layers.ReLU(6.0)(y)\n    out2 = keras.layers.ReLU(6.0)(y)\n\n    model = keras.Model(inp, [out1, out2])\n\n    ModelTransformer(model, [transform]).transform()\n    self.assertFalse(transform.matched())\n\n  @parameterized.parameters([\'sequential\', \'functional\'])\n  def testLayerMetadataPassedAndReplacedInTransforms(self, model_type):\n\n    class ReplaceLayerMetadata(Transform):\n\n      def pattern(self):\n        return LayerPattern(\'Dense\')\n\n      def replacement(self, match_layer):\n        if match_layer.metadata[\'key\'] == \'Hello\':\n          match_layer.metadata[\'key\'] = \'World\'\n        return match_layer\n\n    model = self._simple_dense_model(model_type)\n\n    dense_layer = self._get_layer(model, 0, model_type)\n    relu_layer = self._get_layer(model, 1, model_type)\n\n    layer_metadata = {\n        dense_layer.name: {\n            \'key\': \'Hello\'\n        },\n        relu_layer.name: {\n            \'key\': \'Hello\'\n        },\n    }\n\n    expected_metadata = {\n        dense_layer.name: {\n            \'key\': \'World\'\n        },\n        relu_layer.name: {\n            \'key\': \'Hello\'\n        }\n    }\n\n    transformer = ModelTransformer(\n        model, [ReplaceLayerMetadata()], None, layer_metadata)\n    transformed_model, updated_metadata = transformer.transform()\n\n    self.assertEqual(expected_metadata, updated_metadata)\n\n    # build_input_shape is a TensorShape object and the two objects are not\n    # considered the same even though the shapes are the same.\n    self._assert_config(model.get_config(), transformed_model.get_config(),\n                        [\'build_input_shape\'])\n\n  # Validation Tests\n\n  def testRaisesErrorForSubclassModels(self):\n    class MyModel(keras.Model):\n      pass\n\n    with self.assertRaises(ValueError):\n      ModelTransformer(MyModel(), [self.ReplaceDenseLayer()]).transform()\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/transforms.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Defines core classes for expressing keras model transformations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport collections\nimport six\n\n\nclass LayerPattern(object):\n  """"""Defines a tree sub-graph pattern of Keras layers to match in a model.\n\n  `LayerPattern` can be used to describe various common patterns in model\n  graphs that we need to find.\n\n  Examples:\n    Matches a Conv+BN+ReLU6 and DepthwiseConv+BN+ReLU6 pattern.\n    pattern = LayerPattern(\'ReLU\', {\'max_value\': 6.0}, [\n        LayerPattern(\'BatchNormalization\', {}, [\n            LayerPattern(\'Conv2D|DepthwiseConv2D\', {} [])\n        ])\n    ])\n\n    Matches multiple Conv2Ds feeding into a Concat.\n    pattern = LayerPattern(\'Concat\', {}, [\n        LayerPattern(\'Conv2D\', {}, []),\n        LayerPattern(\'Conv2D\', {}, [])\n    )\n  """"""\n\n  def __init__(self, class_name, config=None, inputs=None):\n    """"""Construct pattern to match.\n\n    Args:\n      class_name: Type of keras layer (such as Conv2D, Dense etc.)\n      config: Map of arguments of the layer to match. For eg., for ReLU(6.0)\n          it would be {\'max_value\': 6.0}.\n      inputs: input layers to the layer.\n    """"""\n    if config is None:\n      config = {}\n    if inputs is None:\n      inputs = []\n\n    self.class_name = class_name\n    self.config = config\n    self.inputs = inputs\n\n\nclass LayerNode(object):\n  """"""Represents a Node in a tree containing a layer.\n\n  `LayerNode` is used to represent a tree of layers in a model. It contains\n  config which describes the layer, and other input layers feeding into it.\n\n  It is used as a generic class to represent both sets of layers which have\n  been found in a model, and layers which should be replaced inside the model.\n  """"""\n\n  def __init__(self, layer, weights=None, input_layers=None, metadata=None):\n    """"""Construct a LayerNode representing a tree of layers.\n\n    Args:\n      layer: layer config of this node.\n      weights: An OrderedDict of weight name => value for the layer.\n      input_layers: List of `LayerNode`s that feed into this layer.\n      metadata: Dictionary of metadata for a given layer.\n    """"""\n    if weights is None:\n      weights = collections.OrderedDict()\n    if input_layers is None:\n      input_layers = []\n    if metadata is None:\n      metadata = {}\n\n    self.layer = layer\n    self.weights = weights\n    self.input_layers = input_layers\n    self.metadata = metadata\n\n  def __str__(self):\n    return \'{} <- [{}]\'.format(\n        self.layer,\n        \', \'.join([str(input_layer) for input_layer in self.input_layers]))\n\n  def _eq(self, ordered_dict1, ordered_dict2):\n    """"""Built-in equality test for OrderedDict fails when value is NP array.""""""\n\n    if len(ordered_dict1) != len(ordered_dict2):\n      return False\n\n    for item1, item2 in zip(ordered_dict1.items(), ordered_dict2.items()):\n      if item1[0] != item2[0] or not (item1[1] == item2[1]).all():\n        return False\n\n    return True\n\n  def __eq__(self, other):\n    if not other or not isinstance(other, LayerNode):\n      return False\n\n    if self.layer != other.layer \\\n        or not self._eq(self.weights, other.weights) \\\n        or self.metadata != other.metadata:\n      return False\n\n    if len(self.input_layers) != len(other.input_layers):\n      return False\n\n    for first_input_layer, second_input_layer in zip(\n        self.input_layers, other.input_layers):\n      if first_input_layer != second_input_layer:\n        return False\n\n    return True\n\n  def __ne__(self, other):\n    """"""Ensure this works on Python2.""""""\n    return not self.__eq__(other)\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Transform(object):\n  """"""Defines a transform to be applied to a keras model graph.\n\n  A transform is a combination of \'Find + Replace\' which describes how to find\n  a pattern of layers in a model, and what to replace those layers with.\n\n  A pattern is described using `LayerPattern`. The replacement function receives\n  a `LayerNode` which contains the matched layers and should return a\n  `LayerNode` which contains the set of layers which replaced the matched\n  layers.\n  """"""\n\n  @abc.abstractmethod\n  def pattern(self):\n    """"""Return the `LayerPattern` to find in the model graph.""""""\n    raise NotImplementedError()\n\n  @abc.abstractmethod\n  def replacement(self, match_layer):\n    """"""Generate a replacement sub-graph for the matched sub-graph.\n\n    The fundamental constraint of the replacement is that the replacement\n    sub-graph should consume the same input tensors as the original sub-graph\n    and also produce a final list of tensors which are same in number and shape\n    as the original sub-graph. Not following this could crash model creation,\n    or introduce bugs in the new model graph.\n\n    TODO(pulkitb): Consider adding list of input layers feeding into the\n    sub-graph, and output layers feeding from the tip of the tree as parameters.\n    These would be needed for complex replace cases.\n\n    Args:\n      match_layer: Matched sub-graph based on `self.pattern()`.\n    """"""\n    raise NotImplementedError()\n\n  def custom_objects(self):\n    """"""Dictionary of custom objects introduced by the `replacement` function.\n\n    A `Transform` may introduce custom Classes and types unknown to Keras. This\n    function should return a dictionary containing these objects in case such\n    types are introduced. It allows model construction to serialize/deserialize\n    these objects.\n\n    Returns:\n      Custom objects introduced by the transform as a dictionary.\n    """"""\n    return {}\n'"
tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/transforms_test.py,2,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Tests for transforms.py API code.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras.graph_transformations import transforms\n\nLayerNode = transforms.LayerNode\n\n\nclass LayerNodeTest(tf.test.TestCase):\n\n  def testEqualityLayerNode(self):\n    conv_layer = {\n        \'name\': \'conv2d\',\n        \'class_name\': \'Conv2D\',\n        \'config\': {\n            \'name\': \'conv2d\',\n        }\n    }\n    dense_layer = {\n        \'name\': \'dense\',\n        \'class_name\': \'Dense\',\n        \'config\': {\n            \'name\': \'dense\',\n        }\n    }\n\n    self.assertNotEqual(LayerNode(conv_layer), LayerNode(dense_layer))\n\n    self.assertEqual(LayerNode(conv_layer), LayerNode(conv_layer))\n    self.assertEqual(\n        LayerNode(conv_layer), LayerNode(copy.deepcopy(conv_layer)))\n\n    self.assertNotEqual(\n        LayerNode(conv_layer,\n                  input_layers=[LayerNode(conv_layer), LayerNode(dense_layer)]),\n        LayerNode(conv_layer,\n                  input_layers=[LayerNode(conv_layer), LayerNode(conv_layer)]))\n\n    self.assertEqual(\n        LayerNode(conv_layer,\n                  input_layers=[LayerNode(conv_layer), LayerNode(dense_layer)]),\n        LayerNode(conv_layer,\n                  input_layers=[LayerNode(conv_layer), LayerNode(dense_layer)]))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/layers/__init__.py,0,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/core/quantization/keras/layers/conv_batchnorm.py,1,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Convolution with folded batch normalization layer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.keras import activations\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras import initializers\nfrom tensorflow.python.keras.layers import convolutional\nfrom tensorflow.python.keras.layers import deserialize as deserialize_layer\nfrom tensorflow.python.keras.layers import normalization\nfrom tensorflow.python.keras.utils import conv_utils\nfrom tensorflow.python.keras.utils import tf_utils\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn\nfrom tensorflow.python.ops import nn_ops\n\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantizers\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantizers\n\nkeras = tf.keras\n\n\nclass _ConvBatchNormMixin(object):\n  """"""Provides shared functionality between fused batchnorm layers.""""""\n\n  def _build_for_quantization(self):\n    """"""All Keras build() logic for quantization for fused layers.""""""\n    if not self.is_quantized:\n      return\n\n    self._weight_quantizer_vars = self.weight_quantizer.build(\n        self.weights[0].shape, \'weight\', self)\n\n    self.optimizer_step = self.add_weight(\n        \'optimizer_step\',\n        initializer=initializers.Constant(-1),\n        dtype=dtypes.int32,\n        trainable=False)\n\n    # TODO(alanchiao): re-explore if we can handle this with\n    # QuantizeAwareActivation.\n    self._activation_min_var = self.add_variable(  # pylint: disable=protected-access\n        \'activation_min\',\n        initializer=initializers.Constant(-6.0),\n        trainable=False)\n    self._activation_max_var = self.add_variable(  # pylint: disable=protected-access\n        \'activation_max\',\n        initializer=initializers.Constant(6.0),\n        trainable=False)\n\n  def _apply_weight_quantizer(self, training, folded_conv_kernel):\n    """"""All Keras call() logic for applying weight quantization.""""""\n\n    def make_quantizer_fn(training):\n      """"""Return quantizer conditioned on whether training or not.""""""\n\n      def quantizer_fn():\n        return self.weight_quantizer(\n            folded_conv_kernel,\n            training,\n            weights=self._weight_quantizer_vars)  # pylint: disable=protected-access\n\n      return quantizer_fn\n\n    return tf_utils.smart_cond(training, make_quantizer_fn(True),\n                               make_quantizer_fn(False))\n\n  def _apply_activation_quantizer(self, training, activation_output):\n    """"""All Keras call() logic for applying weight quantization.""""""\n\n    def make_quantizer_fn(training):\n      """"""Return quantizer conditioned on whether training or not.""""""\n\n      def quantizer_fn():\n        weights = {\n            \'min_var\': self._activation_min_var,  # pylint: disable=protected-access\n            \'max_var\': self._activation_max_var}  # pylint: disable=protected-access\n        return self.activation_quantizer(\n            activation_output,\n            training,\n            weights=weights)\n\n      return quantizer_fn\n\n    return tf_utils.smart_cond(training, make_quantizer_fn(True),\n                               make_quantizer_fn(False))\n\n  @staticmethod\n  def _from_config(cls_initializer, config):\n    """"""All shared from_config logic for fused layers.""""""\n    config = config.copy()\n    # use_bias is not an argument of this class, as explained by\n    # comment in __init__.\n    config.pop(\'use_bias\')\n    is_advanced_activation = \'class_name\' in config[\'post_activation\']\n    if is_advanced_activation:\n      config[\'post_activation\'] = deserialize_layer(config[\'post_activation\'])\n    else:\n      config[\'post_activation\'] = activations.deserialize(\n          config[\'post_activation\'])\n\n    return cls_initializer(**config)\n\n  def _get_config(self, conv_config):\n    """"""All shared get_config logic for fused layers.""""""\n    batchnorm_config = self.batchnorm.get_config()\n\n    # Both BatchNorm and Conv2D have config items from base layer. Since\n    # _ConvBatchNorm2D inherits from Conv2D, we should use base layer config\n    # items from self, rather than self.batchnorm.\n    # For now, deleting \'name\', but ideally all base_config items should be\n    # removed.\n    # TODO(pulkitb): Raise error if base_configs in both layers incompatible.\n    batchnorm_config.pop(\'name\')\n\n    is_advanced_activation = isinstance(self.post_activation,\n                                        keras.layers.Layer)\n    if is_advanced_activation:\n      serialized_activation = keras.utils.serialize_keras_object(\n          self.post_activation)\n    else:\n      serialized_activation = activations.serialize(self.post_activation)\n    config = {\n        \'is_quantized\': self.is_quantized,\n        \'post_activation\': serialized_activation\n    }\n\n    return dict(\n        list(conv_config.items()) + list(batchnorm_config.items()) +\n        list(config.items()))\n\n\nclass _ConvBatchNorm2D(_ConvBatchNormMixin, convolutional.Conv2D):\n  """"""Layer for emulating the folding of batch normalization into Conv during serving.\n\n  Implements the emulation, as described in https://arxiv.org/abs/1712.05877.\n  Note that in the\n  emulated form, there are two convolutions for each convolution in the original\n  model.\n\n  Notably, this layer adds the quantization ops  itself, instead of relying on\n  the wrapper. The reason is that the weight (folded_conv_kernel) is an\n  intermediate tensor instead of a variable tensor, and therefore not accessible\n  to the wrapper at build() time.\n  """"""\n\n  # TODO(alanchiao): remove these defaults since in practice,\n  # they will be provided by the unfolded layers.\n  #\n  # Note: the following are not parameters even though they are for Conv2D.\n  # 1. use_bias. This is because a Conv2D bias would be redundant with\n  # BatchNormalization\'s bias.\n  # 2. activation. We can only mathematically fold through linear operations,\n  # so an activation in the Conv2D prevents batchnorm folding.\n  def __init__(\n      self,\n      # Conv2D params\n      filters,\n      kernel_size,\n      strides=(1, 1),\n      padding=\'valid\',\n      data_format=None,\n      dilation_rate=(1, 1),\n      kernel_initializer=\'glorot_uniform\',\n      kernel_regularizer=None,\n      bias_regularizer=None,\n      activity_regularizer=None,\n      kernel_constraint=None,\n      bias_constraint=None,\n      name=None,\n      # BatchNormalization params\n      axis=-1,\n      momentum=0.99,\n      epsilon=1e-3,\n      center=True,\n      scale=True,\n      beta_initializer=\'zeros\',\n      gamma_initializer=\'ones\',\n      moving_mean_initializer=\'zeros\',\n      moving_variance_initializer=\'ones\',\n      beta_regularizer=None,\n      gamma_regularizer=None,\n      beta_constraint=None,\n      gamma_constraint=None,\n      renorm=False,\n      renorm_clipping=None,\n      renorm_momentum=0.99,\n      fused=None,\n      trainable=True,\n      virtual_batch_size=None,\n      adjustment=None,\n      # Post-batchnorm activation.\n      post_activation=None,\n      # quantization params\n      is_quantized=True,\n      **kwargs):\n    super(_ConvBatchNorm2D, self).__init__(\n        filters,\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        use_bias=False,\n        kernel_initializer=kernel_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        name=name,\n        **kwargs)\n\n    self.batchnorm = normalization.BatchNormalization(\n        axis=axis,\n        momentum=momentum,\n        epsilon=epsilon,\n        center=center,\n        scale=scale,\n        beta_initializer=beta_initializer,\n        gamma_initializer=gamma_initializer,\n        moving_mean_initializer=moving_mean_initializer,\n        moving_variance_initializer=moving_variance_initializer,\n        beta_regularizer=beta_regularizer,\n        gamma_regularizer=gamma_regularizer,\n        beta_constraint=beta_constraint,\n        gamma_constraint=gamma_constraint,\n        renorm=renorm,\n        renorm_clipping=renorm_clipping,\n        renorm_momentum=renorm_momentum,\n        fused=fused,\n        trainable=trainable,\n        virtual_batch_size=virtual_batch_size,\n        adjustment=adjustment,\n    )\n\n    # Named as post_activation to not conflict with Layer self.activation.\n    self.post_activation = activations.get(post_activation)\n\n    self.is_quantized = is_quantized\n    if self.is_quantized:\n      self.weight_quantizer = default_8bit_quantizers.Default8BitConvWeightsQuantizer(\n      )\n\n      self.activation_quantizer = quantizers.MovingAverageQuantizer(\n          num_bits=8, per_axis=False, symmetric=False, narrow_range=False)\n\n  def build(self, input_shape):\n    # responsible for trainable self.kernel weights\n    super(_ConvBatchNorm2D, self).build(input_shape)\n\n    # resposible for trainable gamma and beta weights\n    self.batchnorm.build(self.compute_output_shape(input_shape))\n\n    self._build_for_quantization()\n\n  def call(self, inputs, training=None):\n    if training is None:\n      training = K.learning_phase()\n\n    conv_out = super(_ConvBatchNorm2D, self).call(inputs)\n\n    # Not all the computations in the batchnorm need to happen,\n    # but this avoids duplicating code (e.g. moving_average).\n    self.batchnorm.call(conv_out)\n\n    folded_conv_kernel_multiplier = self.batchnorm.gamma * math_ops.rsqrt(\n        self.batchnorm.moving_variance + self.batchnorm.epsilon)\n    folded_conv_kernel = math_ops.mul(\n        folded_conv_kernel_multiplier, self.kernel, name=\'folded_conv_kernel\')\n\n    folded_conv_bias = math_ops.subtract(\n        self.batchnorm.beta,\n        self.batchnorm.moving_mean * folded_conv_kernel_multiplier,\n        name=\'folded_conv_bias\')\n\n    if self.is_quantized:\n      folded_conv_kernel = self._apply_weight_quantizer(training,\n                                                        folded_conv_kernel)\n\n    # Second convolution doesn\'t need new trainable weights, so we\n    # cannot reuse Conv2D layer.\n    # TODO(alanchiao):\n    # 1. See if we can at least reuse the bias logic.\n    # 2. See if we need to fork between conv2d and conv2d_v2 for\n    #    TensorFlow 1.XX and 2.XX.\n\n    # Taken from keras/layers/convolutional.py:183\n    if self.padding == \'causal\':\n      op_padding = \'valid\'\n    else:\n      op_padding = self.padding\n    if not isinstance(op_padding, (list, tuple)):\n      op_padding = op_padding.upper()\n\n    folded_conv_out = nn_ops.conv2d(\n        inputs,\n        folded_conv_kernel,\n        strides=self.strides,\n        padding=op_padding,\n        data_format=conv_utils.convert_data_format(self.data_format,\n                                                   self.rank + 2),\n        dilations=self.dilation_rate,\n        name=\'folded_conv_out\',\n    )\n\n    # Taken from keras/layers/convolutional.py:200\n    if self.data_format == \'channels_first\':\n      if self.rank == 1:\n        # nn.bias_add does not accept a 1D input tensor.\n        bias = array_ops.reshape(folded_conv_bias, (1, self.filters, 1))\n        folded_conv_out += bias\n      else:\n        outputs = nn.bias_add(\n            folded_conv_out, folded_conv_bias, data_format=\'NCHW\')\n    else:\n      outputs = nn.bias_add(\n          folded_conv_out, folded_conv_bias, data_format=\'NHWC\')\n\n    if self.post_activation is not None:\n      outputs = self.post_activation(outputs)\n    if self.is_quantized:\n      outputs = self._apply_activation_quantizer(training, outputs)\n    return outputs\n\n  def get_config(self):\n    conv_config = super(_ConvBatchNorm2D, self).get_config()\n    return self._get_config(conv_config)\n\n  @classmethod\n  def from_config(cls, config):\n    return _ConvBatchNormMixin._from_config(cls, config)\n\n\nclass _DepthwiseConvBatchNorm2D(_ConvBatchNormMixin,\n                                convolutional.DepthwiseConv2D):\n  """"""Layer for emulating the folding of batch normalization into DepthwiseConv during serving.\n\n  See ConvBatchNorm2D for detailed comments.\n  """"""\n\n  def __init__(\n      self,\n      # DepthwiseConv2D params\n      kernel_size,\n      strides=(1, 1),\n      padding=\'valid\',\n      depth_multiplier=1,\n      data_format=None,\n      depthwise_initializer=\'glorot_uniform\',\n      depthwise_regularizer=None,\n      bias_regularizer=None,\n      activity_regularizer=None,\n      depthwise_constraint=None,\n      bias_constraint=None,\n      name=None,\n      # BatchNormalization params\n      axis=-1,\n      momentum=0.99,\n      epsilon=1e-3,\n      center=True,\n      scale=True,\n      beta_initializer=\'zeros\',\n      gamma_initializer=\'ones\',\n      moving_mean_initializer=\'zeros\',\n      moving_variance_initializer=\'ones\',\n      beta_regularizer=None,\n      gamma_regularizer=None,\n      beta_constraint=None,\n      gamma_constraint=None,\n      renorm=False,\n      renorm_clipping=None,\n      renorm_momentum=0.99,\n      fused=None,\n      trainable=True,\n      virtual_batch_size=None,\n      adjustment=None,\n      # Post-batchnorm activation instance.\n      post_activation=None,\n      # quantization params\n      is_quantized=True,\n      **kwargs):\n    super(_DepthwiseConvBatchNorm2D, self).__init__(\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        depth_multiplier=depth_multiplier,\n        data_format=data_format,\n        use_bias=False,\n        depthwise_initializer=depthwise_initializer,\n        depthwise_regularizer=depthwise_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        depthwise_constraint=depthwise_constraint,\n        bias_constraint=bias_constraint,\n        name=name,\n        **kwargs)\n\n    self.batchnorm = normalization.BatchNormalization(\n        axis=axis,\n        momentum=momentum,\n        epsilon=epsilon,\n        center=center,\n        scale=scale,\n        beta_initializer=beta_initializer,\n        gamma_initializer=gamma_initializer,\n        moving_mean_initializer=moving_mean_initializer,\n        moving_variance_initializer=moving_variance_initializer,\n        beta_regularizer=beta_regularizer,\n        gamma_regularizer=gamma_regularizer,\n        beta_constraint=beta_constraint,\n        gamma_constraint=gamma_constraint,\n        renorm=renorm,\n        renorm_clipping=renorm_clipping,\n        renorm_momentum=renorm_momentum,\n        fused=fused,\n        trainable=trainable,\n        virtual_batch_size=virtual_batch_size,\n        adjustment=adjustment,\n    )\n    self.post_activation = activations.get(post_activation)\n\n    self.is_quantized = is_quantized\n    if self.is_quantized:\n      self.weight_quantizer = default_8bit_quantizers.Default8BitConvWeightsQuantizer(\n      )\n\n      self.activation_quantizer = quantizers.MovingAverageQuantizer(\n          num_bits=8, per_axis=False, symmetric=False, narrow_range=False)\n\n  def build(self, input_shape):\n    # responsible for trainable self.kernel weights\n    super(_DepthwiseConvBatchNorm2D, self).build(input_shape)\n\n    # resposible for trainable gamma and beta weights\n    self.batchnorm.build(self.compute_output_shape(input_shape))\n\n    self._build_for_quantization()\n\n  def call(self, inputs, training=None):\n    if training is None:\n      training = K.learning_phase()\n\n    conv_out = super(_DepthwiseConvBatchNorm2D, self).call(inputs)\n\n    self.batchnorm.call(conv_out)\n\n    folded_conv_kernel_multiplier = self.batchnorm.gamma * math_ops.rsqrt(\n        self.batchnorm.moving_variance + self.batchnorm.epsilon)\n\n    folded_conv_bias = math_ops.subtract(\n        self.batchnorm.beta,\n        self.batchnorm.moving_mean * folded_conv_kernel_multiplier,\n        name=\'folded_conv_bias\')\n\n    depthwise_weights_shape = [\n        self.depthwise_kernel.get_shape().as_list()[2],\n        self.depthwise_kernel.get_shape().as_list()[3]\n    ]\n    folded_conv_kernel_multiplier = array_ops.reshape(\n        folded_conv_kernel_multiplier, depthwise_weights_shape)\n\n    folded_conv_kernel = math_ops.mul(\n        folded_conv_kernel_multiplier,\n        self.depthwise_kernel,\n        name=\'folded_conv_kernel\')\n\n    if self.is_quantized:\n      folded_conv_kernel = self._apply_weight_quantizer(training,\n                                                        folded_conv_kernel)\n\n    # TODO(alanchiao): this is an internal API.\n    # See if Keras would make this public, like\n    # backend.conv2d is.\n    #\n    # From DepthwiseConv2D layer call() function.\n    folded_conv_out = K.depthwise_conv2d(\n        inputs,\n        folded_conv_kernel,\n        strides=self.strides,\n        padding=self.padding,\n        dilation_rate=self.dilation_rate,\n        data_format=self.data_format,\n    )\n\n    outputs = K.bias_add(\n        folded_conv_out, folded_conv_bias, data_format=self.data_format)\n\n    if self.post_activation is not None:\n      outputs = self.post_activation(outputs)\n    if self.is_quantized:\n      outputs = self._apply_activation_quantizer(training, outputs)\n    return outputs\n\n  def get_config(self):\n    conv_config = super(_DepthwiseConvBatchNorm2D, self).get_config()\n    return self._get_config(conv_config)\n\n  @classmethod\n  def from_config(cls, config):\n    return _ConvBatchNormMixin._from_config(cls, config)\n'"
tensorflow_model_optimization/python/core/quantization/keras/layers/conv_batchnorm_test.py,6,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""ConvBatchNorm layer tests.\n\nSee FoldedBatchNormTest for shared test cases between different\nclasses.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\n\nimport numpy as np\nfrom six.moves import range\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import compat\nfrom tensorflow_model_optimization.python.core.quantization.keras import quantize\nfrom tensorflow_model_optimization.python.core.quantization.keras import utils\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm_test_utils\n\nactivations = tf.keras.activations\nkeras = tf.keras\n\n_ConvBatchNorm2D = conv_batchnorm._ConvBatchNorm2D\n_DepthwiseConvBatchNorm2D = conv_batchnorm._DepthwiseConvBatchNorm2D\nConv2DModel = conv_batchnorm_test_utils.Conv2DModel\nDepthwiseConv2DModel = conv_batchnorm_test_utils.DepthwiseConv2DModel\n\n\nclass FoldedBatchNormTestBase(tf.test.TestCase):\n\n  @staticmethod\n  def _get_asymmetric_quant_params(real_min, real_max, quant_min, quant_max):\n    # TODO(alanchiao): remove this once the converter for training-time\n    # quantization supports producing a TFLite model with a float input/output.\n\n    # Code clones quantization logic from TFLite.\n    # third_party/tensorflow/lite/tools/optimize/quantization_utils.cc\n\n    real_min = min(real_min, 0.0)\n    real_max = max(real_max, 0.0)\n\n    scale = (real_max - real_min) / (quant_max - quant_min)\n\n    zero_point_from_min = quant_min\n    if scale != 0:\n      zero_point_from_min = quant_min - real_min / scale\n\n    if zero_point_from_min < quant_min:\n      zero_point = quant_min\n    elif zero_point_from_min > quant_max:\n      zero_point = quant_max\n    else:\n      zero_point = round(zero_point_from_min)\n\n    return scale, zero_point\n\n  # This does a basic serialize/deserialize test since deserialization\n  # occurs during conversion to TFLite.\n  def _test_equal_tf_and_tflite_outputs(self,\n                                        tf_model,\n                                        is_tflite_quantized=False):\n    _, tflite_file = tempfile.mkstemp(\'.tflite\')\n\n    batched_input_shape = self._get_batched_input_shape()\n    output_shape = self._get_output_shape()\n\n    tf_model.compile(\n        loss=\'categorical_crossentropy\', optimizer=\'sgd\', metrics=[\'accuracy\'])\n\n    tf_model.fit(\n        np.random.uniform(0, 1, size=batched_input_shape),\n        np.random.uniform(0, 10, size=output_shape),\n        epochs=1,\n        callbacks=[])\n    # Prepare for inference.\n    inp = np.random.uniform(0, 1, size=batched_input_shape)\n    inp = inp.astype(np.float32)\n\n    if is_tflite_quantized:\n      real_min = keras.backend.eval(tf_model.layers[-1]._activation_min_var)\n      real_max = keras.backend.eval(tf_model.layers[-1]._activation_max_var)\n      scale, zero_point = self._get_asymmetric_quant_params(\n          real_min, real_max, -128.0, 127.0)\n\n      # TFLite input needs to be quantized.\n      real_input_min = 0.0\n      real_input_max = 1.0\n      inp_scale, inp_zp = self._get_asymmetric_quant_params(\n          real_input_min, real_input_max, -128.0, 127.0)\n\n      inp8 = np.round(inp / inp_scale + inp_zp)\n      inp8 = inp8.astype(np.int8)\n\n      # Dequant\n      inp = (inp8.astype(np.float32) - inp_zp) * inp_scale\n\n    # TensorFlow inference.\n    tf_out = tf_model.predict(inp)\n\n    # TensorFlow Lite inference.\n    with quantize.quantize_scope():\n      utils.convert_keras_to_tflite(\n          tf_model,\n          tflite_file,\n          custom_objects={\n              \'_ConvBatchNorm2D\': _ConvBatchNorm2D,\n              \'_DepthwiseConvBatchNorm2D\': _DepthwiseConvBatchNorm2D,\n          },\n          is_quantized=is_tflite_quantized,\n          inference_input_type=tf.lite.constants.INT8)\n\n    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n    interpreter.allocate_tensors()\n    input_index = interpreter.get_input_details()[0][\'index\']\n    output_index = interpreter.get_output_details()[0][\'index\']\n\n    if is_tflite_quantized:\n      interpreter.set_tensor(input_index, inp8)\n    else:\n      interpreter.set_tensor(input_index, inp)\n\n    interpreter.invoke()\n    tflite_out = interpreter.get_tensor(output_index)\n\n    if is_tflite_quantized:\n      # dequantize outputs\n      tflite_out = [scale * (x - zero_point) for x in tflite_out]\n\n      # TODO(pulkitb): DConv quantized test somehow has a single value (0.065%)\n      # of total values, which falls off by 1 scale. Investigate further and\n      # introduce stricter testing by removing atol=scale.\n      self.assertAllClose(tf_out, tflite_out, atol=scale)\n    else:\n      # Taken from testFoldFusedBatchNorms from\n      # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference_test.py#L230\n      self.assertAllClose(tf_out, tflite_out, rtol=1e-04, atol=1e-06)\n\n  def _test_equal_outputs(self, model, model2):\n    for _ in range(2):\n      inp = np.random.uniform(0, 10, size=self._get_batched_input_shape())\n      model_out = model.predict(inp)\n      model2_out = model2.predict(inp)\n\n      # Taken from testFoldFusedBatchNorms from\n      # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference_test.py#L230\n      self.assertAllClose(model_out, model2_out, rtol=1e-04, atol=1e-06)\n\n\nclass ConvBatchNorm2DTest(FoldedBatchNormTestBase):\n\n  def _get_folded_batchnorm_model(self,\n                                  is_quantized=False,\n                                  post_bn_activation=None):\n    return Conv2DModel.get_folded_batchnorm_model(\n        is_quantized=is_quantized, post_bn_activation=post_bn_activation)\n\n  def _get_nonfolded_batchnorm_model(self):\n    return Conv2DModel.get_nonfolded_batchnorm_model()\n\n  def _get_batched_input_shape(self):\n    return Conv2DModel.get_batched_input_shape()\n\n  def _get_output_shape(self):\n    return Conv2DModel.get_output_shape()\n\n  def testEquivalentToNonFoldedBatchNorm(self):\n    self._test_equal_outputs(\n        self._get_folded_batchnorm_model(is_quantized=False),\n        self._get_nonfolded_batchnorm_model())\n\n  def testEquivalentToFloatTFLite(self):\n    if not compat.is_v1_apis():\n      return\n\n    tf_model = self._get_folded_batchnorm_model(is_quantized=False)\n    self._test_equal_tf_and_tflite_outputs(tf_model)\n\n  def testQuantizedEquivalentToQuantizedTFLite(self):\n    if not compat.is_v1_apis():\n      return\n\n    tf_model = self._get_folded_batchnorm_model(is_quantized=True)\n    self._test_equal_tf_and_tflite_outputs(tf_model, is_tflite_quantized=True)\n\n  # TODO(pulkitb): Implement FakeQuant addition for keras Input layers.\n  # That will remove the need to do Int8 tests for TFLite, and push input\n  # quantization into the kernels, and remove the need for quantized_input_stats\n\n  # TODO(pulkitb): Enable tests once TFLite converter supports new spec.\n  # TFLite Converter does not support quantizing/de-quantizing based on\n  # per-channel FakeQuants.\n  #\n  # def testQuantizedEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(is_quantized=True)\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithReLUEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True, post_bn_activation=activations.get(\'relu\'))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithAdvancedReLUEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True,\n  #       post_bn_activation=keras.layers.ReLU(max_value=6.0))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithSoftmaxEquivalentToFloatTfLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True, post_bn_activation=activations.get(\'softmax\'))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n\n\nclass DepthwiseConvBatchNorm2DTest(FoldedBatchNormTestBase):\n\n  def _get_folded_batchnorm_model(self,\n                                  is_quantized=False,\n                                  post_bn_activation=None):\n    return DepthwiseConv2DModel.get_folded_batchnorm_model(\n        is_quantized=is_quantized, post_bn_activation=post_bn_activation)\n\n  def _get_nonfolded_batchnorm_model(self):\n    return DepthwiseConv2DModel.get_nonfolded_batchnorm_model()\n\n  def _get_batched_input_shape(self):\n    return DepthwiseConv2DModel.get_batched_input_shape()\n\n  def _get_output_shape(self):\n    return DepthwiseConv2DModel.get_output_shape()\n\n  def testEquivalentToNonFoldedBatchNorm(self):\n    self._test_equal_outputs(\n        self._get_folded_batchnorm_model(is_quantized=False),\n        self._get_nonfolded_batchnorm_model())\n\n  def testEquivalentToFloatTFLite(self):\n    if not compat.is_v1_apis():\n      return\n\n    tf_model = self._get_folded_batchnorm_model(is_quantized=False)\n    self._test_equal_tf_and_tflite_outputs(tf_model)\n\n  def testQuantizedEquivalentToQuantizedTFLite(self):\n    if not compat.is_v1_apis():\n      return\n\n    tf_model = self._get_folded_batchnorm_model(is_quantized=True)\n    self._test_equal_tf_and_tflite_outputs(tf_model, is_tflite_quantized=True)\n\n  # TODO(pulkitb): Enable tests once TFLite converter supports new spec.\n  # TFLite Converter does not support quantizing/de-quantizing based on\n  # per-channel FakeQuants.\n\n  # def testQuantizedEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(is_quantized=True)\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithSoftmaxEquivalentToFloatTfLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True, post_bn_activation=activations.get(\'softmax\'))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithReLUEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True, post_bn_activation=activations.get(\'relu\'))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n  #\n  # def testQuantizedWithAdvancedReLUEquivalentToFloatTFLite(self):\n  #   tf_model = self._get_folded_batchnorm_model(\n  #       is_quantized=True,\n  #       post_bn_activation=keras.layers.ReLU(max_value=6.0))\n  #   self._test_equal_tf_and_tflite_outputs(tf_model)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/quantization/keras/layers/conv_batchnorm_test_utils.py,7,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Test utils for conv batchnorm folding.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.quantization.keras.layers import conv_batchnorm\n\nkeras = tf.keras\n\n_ConvBatchNorm2D = conv_batchnorm._ConvBatchNorm2D  # pylint: disable=protected-access\n_DepthwiseConvBatchNorm2D = conv_batchnorm._DepthwiseConvBatchNorm2D  # pylint: disable=protected-access\n\n\ndef _get_conv2d_params():\n  return {\n      \'kernel_size\': (3, 3),\n      \'input_shape\': (10, 10, 3),\n      \'batch_size\': 8,\n  }\n\n\ndef _get_initializer(random_init):\n  if random_init:\n    kernel_initializer = keras.initializers.glorot_uniform()\n  else:\n    kernel_initializer = keras.initializers.glorot_uniform(seed=0)\n  return kernel_initializer\n\n\nclass Conv2DModel(object):\n  """"""Construct and access Conv + BatchNorm + activation models.""""""\n\n  params = {\n      \'filters\': 2,\n      \'kernel_size\': (2, 2),\n      \'input_shape\': (3, 3, 3),\n      \'batch_size\': 1,\n  }\n\n  @classmethod\n  def get_batched_input_shape(cls):\n    """"""Return input shape with batch size.""""""\n    shape = [cls.params[\'batch_size\']]\n    shape.extend(cls.params[\'input_shape\'])\n    return shape\n\n  @classmethod\n  def get_output_shape(cls):\n    return [cls.params[\'batch_size\'], 2, 2, 2]\n\n  @classmethod\n  def get_folded_batchnorm_model(cls,\n                                 is_quantized=False,\n                                 post_bn_activation=None):\n    """"""Return folded Conv2D + BN + optional activation model.""""""\n    return tf.keras.Sequential([\n        _ConvBatchNorm2D(\n            kernel_initializer=_get_initializer(random_init=False),\n            is_quantized=is_quantized,\n            post_activation=post_bn_activation,\n            **cls.params)\n    ])\n\n  @classmethod\n  def get_nonfolded_batchnorm_model(cls,\n                                    post_bn_activation=None,\n                                    model_type=\'sequential\',\n                                    random_init=False):\n    """"""Return nonfolded Conv2D + BN + optional activation model.""""""\n    if model_type == \'sequential\':\n      layers = [\n          keras.layers.Conv2D(\n              kernel_initializer=_get_initializer(random_init),\n              use_bias=False,\n              **cls.params),\n          keras.layers.BatchNormalization(axis=-1),\n      ]\n      if post_bn_activation is not None:\n        layers += post_bn_activation\n      return tf.keras.Sequential(layers)\n    else:\n      inp = keras.layers.Input(cls.params[\'input_shape\'],\n                               cls.params[\'batch_size\'])\n      x = keras.layers.Conv2D(\n          cls.params[\'filters\'],\n          cls.params[\'kernel_size\'],\n          kernel_initializer=_get_initializer(random_init),\n          use_bias=False)(\n              inp)\n      out = keras.layers.BatchNormalization(axis=-1)(x)\n      if post_bn_activation is not None:\n        out = post_bn_activation(out)\n      return tf.keras.Model(inp, out)\n\n\nclass DepthwiseConv2DModel(Conv2DModel):\n  """"""Construct and access DepthwiseConv + BatchNorm + activation models.""""""\n\n  params = {\n      \'kernel_size\': (3, 3),\n      \'input_shape\': (10, 10, 3),\n      \'batch_size\': 8,\n  }\n\n  @classmethod\n  def get_output_shape(cls):\n    return [cls.params[\'batch_size\'], 8, 8, 3]\n\n  @classmethod\n  def get_folded_batchnorm_model(cls,\n                                 is_quantized=False,\n                                 post_bn_activation=None):\n    return tf.keras.Sequential([\n        _DepthwiseConvBatchNorm2D(\n            depthwise_initializer=_get_initializer(random_init=False),\n            is_quantized=is_quantized,\n            post_activation=post_bn_activation,\n            **cls.params)\n    ])\n\n  @classmethod\n  def get_nonfolded_batchnorm_model(cls,\n                                    post_bn_activation=None,\n                                    model_type=\'sequential\',\n                                    random_init=False):\n    if model_type == \'sequential\':\n      layers = [\n          keras.layers.DepthwiseConv2D(\n              depthwise_initializer=_get_initializer(random_init),\n              use_bias=False,\n              **cls.params),\n          keras.layers.BatchNormalization(axis=-1),\n      ]\n      if post_bn_activation is not None:\n        layers += post_bn_activation\n      return tf.keras.Sequential(layers)\n    else:\n      inp = keras.layers.Input(cls.params[\'input_shape\'],\n                               cls.params[\'batch_size\'])\n      x = keras.layers.DepthwiseConv2D(\n          cls.params[\'kernel_size\'],\n          depthwise_initializer=_get_initializer(random_init),\n          use_bias=False)(\n              inp)\n      out = keras.layers.BatchNormalization(axis=-1)(x)\n      if post_bn_activation is not None:\n        out = post_bn_activation(out)\n      return tf.keras.Model(inp, out)\n'"
tensorflow_model_optimization/python/examples/clustering/keras/mnist/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/examples/clustering/keras/mnist/mnist_cnn.py,12,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=missing-docstring\n""""""Train a simple convnet on the MNIST dataset.""""""\n\nfrom __future__ import print_function\n\nimport tempfile\n\nfrom absl import app as absl_app\nfrom absl import flags\n\nimport tensorflow.compat.v1 as tf\nfrom tensorflow.python import keras\nfrom tensorflow_model_optimization.python.core.clustering.keras import cluster\n\nl = keras.layers\n\nFLAGS = flags.FLAGS\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\nepochs_fine_tuning = 4\n\nflags.DEFINE_boolean(\'enable_eager\', True, \'Trains in eager mode.\')\nflags.DEFINE_string(\'output_dir\', \'/tmp/mnist_train/\',\n                    \'Output directory to hold tensorboard events\')\n\n\ndef build_sequential_model(input_shape):\n  return tf.keras.Sequential([\n      l.Conv2D(\n          32, 5, padding=\'same\', activation=\'relu\', input_shape=input_shape),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.BatchNormalization(),\n      l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      l.Dense(1024, activation=\'relu\'),\n      l.Dropout(0.4),\n      l.Dense(num_classes, activation=\'softmax\')\n  ])\n\n\ndef build_functional_model(input_shape):\n  inp = tf.keras.Input(shape=input_shape)\n  x = l.Conv2D(32, 5, padding=\'same\', activation=\'relu\')(inp)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.BatchNormalization()(x)\n  x = l.Conv2D(64, 5, padding=\'same\', activation=\'relu\')(x)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.Flatten()(x)\n  x = l.Dense(1024, activation=\'relu\')(x)\n  x = l.Dropout(0.4)(x)\n  out = l.Dense(num_classes, activation=\'softmax\')(x)\n\n  return tf.keras.models.Model([inp], [out])\n\ndef train_and_save(models, x_train, y_train, x_test, y_test):\n  for model in models:\n    model.compile(\n        loss=tf.keras.losses.categorical_crossentropy,\n        optimizer=\'adam\',\n        metrics=[\'accuracy\'])\n\n    # Print the model summary.\n    model.summary()\n\n    # Model needs to be clustered after initial training\n    # and having achieved good accuracy\n    model.fit(\n        x_train,\n        y_train,\n        batch_size=batch_size,\n        epochs=epochs,\n        verbose=1,\n        validation_data=(x_test, y_test))\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print(\'Test loss:\', score[0])\n    print(\'Test accuracy:\', score[1])\n\n    print(\'Clustering model\')\n\n    clustering_params = {\n      \'number_of_clusters\': 8,\n      \'cluster_centroids_init\': \'density-based\'\n    }\n\n    # Cluster model\n    clustered_model = cluster.cluster_weights(model, **clustering_params)\n\n    # Use smaller learning rate for fine-tuning\n    # clustered model\n    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n\n    clustered_model.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=opt,\n    metrics=[\'accuracy\'])\n\n    # Fine-tune model\n    clustered_model.fit(\n        x_train,\n        y_train,\n        batch_size=batch_size,\n        epochs=epochs_fine_tuning,\n        verbose=1,\n        validation_data=(x_test, y_test))\n\n    score = clustered_model.evaluate(x_test, y_test, verbose=0)\n    print(\'Clustered Model Test loss:\', score[0])\n    print(\'Clustered Model Test accuracy:\', score[1])\n\n    #Ensure accuracy persists after stripping the model\n    stripped_model = cluster.strip_clustering(clustered_model)\n\n    stripped_model.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=\'adam\',\n    metrics=[\'accuracy\'])\n    stripped_model.save(\'stripped_model.h5\')\n\n    # To acquire the stripped model,\n    # deserialize with clustering scope\n    with cluster.cluster_scope():\n      loaded_model = keras.models.load_model(\'stripped_model.h5\')\n\n    # Checking that the stripped model\'s accuracy matches the clustered model\n    score = loaded_model.evaluate(x_test, y_test, verbose=0)\n    print(\'Stripped Model Test loss:\', score[0])\n    print(\'Stripped Model Test accuracy:\', score[1])\n\ndef main(unused_argv):\n  if FLAGS.enable_eager:\n    print(\'Running in Eager mode.\')\n    tf.compat.v1.enable_eager_execution()\n\n  # input image dimensions\n  img_rows, img_cols = 28, 28\n\n  # the data, shuffled and split between train and test sets\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n  if tf.keras.backend.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\n  else:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\n  x_train = x_train.astype(\'float32\')\n  x_test = x_test.astype(\'float32\')\n  x_train /= 255\n  x_test /= 255\n  print(\'x_train shape:\', x_train.shape)\n  print(x_train.shape[0], \'train samples\')\n  print(x_test.shape[0], \'test samples\')\n\n  # convert class vectors to binary class matrices\n  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n  sequential_model = build_sequential_model(input_shape)\n  functional_model = build_functional_model(input_shape)\n  models = [sequential_model, functional_model]\n  train_and_save(models, x_train, y_train, x_test, y_test)\n\n\nif __name__ == \'__main__\':\n  absl_app.run(main)\n'"
tensorflow_model_optimization/python/examples/sparsity/keras/imdb/imdb_lstm.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Train a LSTM on the IMDB sentiment classification task.\n\nThe dataset is actually too small for LSTM to be of any advantage\ncompared to simpler, much faster methods such as TF-IDF+LogReg.\n""""""\n\nfrom __future__ import print_function\n# import g3\nimport numpy as np\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.preprocessing.sequence as sequence\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n\n\ndef print_model_sparsity(pruned_model):\n  """"""Prints sparsity for the pruned layers in the model.\n\n  Model Sparsity Summary\n  --\n  prune_lstm_1: (kernel, 0.5), (recurrent_kernel, 0.6)\n  prune_dense_1: (kernel, 0.5)\n\n  Args:\n    pruned_model: keras model to summarize.\n\n  Returns:\n    None\n  """"""\n  def _get_sparsity(weights):\n    return 1.0 - np.count_nonzero(weights) / float(weights.size)\n\n  print(""Model Sparsity Summary ({})"".format(pruned_model.name))\n  print(""--"")\n  for layer in pruned_model.layers:\n    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n      prunable_weights = layer.layer.get_prunable_weights()\n      if prunable_weights:\n        print(""{}: {}"".format(\n            layer.name, "", "".join([\n                ""({}, {})"".format(weight.name,\n                                  str(_get_sparsity(K.get_value(weight))))\n                for weight in prunable_weights\n            ])))\n  print(""\\n"")\n\n\nmax_features = 20000\nmaxlen = 100  # cut texts after this number of words\nbatch_size = 32\n\nprint(""Loading data..."")\n(x_train,\n y_train), (x_test,\n            y_test) = keras.datasets.imdb.load_data(num_words=max_features)\nprint(len(x_train), ""train sequences"")\nprint(len(x_test), ""test sequences"")\n\nprint(""Pad sequences (samples x time)"")\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint(""x_train shape:"", x_train.shape)\nprint(""x_test shape:"", x_test.shape)\n\nprint(""Build model..."")\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Embedding(max_features, 128, input_length=maxlen))\nmodel.add(keras.layers.LSTM(128))  # try using a GRU instead, for fun\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(1))\nmodel.add(keras.layers.Activation(""sigmoid""))\n\nmodel = prune.prune_low_magnitude(model, pruning_schedule.PolynomialDecay(\n    initial_sparsity=0.3, final_sparsity=0.7, begin_step=1000, end_step=3000))\n\n# try using different optimizers and different optimizer configs\nmodel.compile(loss=""binary_crossentropy"",\n              optimizer=""adam"",\n              metrics=[""accuracy""])\nprint_model_sparsity(model)\n\nprint(""Train..."")\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=3,\n          callbacks=[pruning_callbacks.UpdatePruningStep()],\n          validation_data=(x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test,\n                            batch_size=batch_size)\nprint_model_sparsity(model)\nprint(""Test score:"", score)\nprint(""Test accuracy:"", acc)\n'"
tensorflow_model_optimization/python/examples/sparsity/keras/mnist/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n'"
tensorflow_model_optimization/python/examples/sparsity/keras/mnist/mnist_cnn.py,12,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=missing-docstring\n""""""Train a simple convnet on the MNIST dataset.""""""\nfrom __future__ import print_function\n\nfrom absl import app as absl_app\nfrom absl import flags\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n\nConstantSparsity = pruning_schedule.ConstantSparsity\nkeras = tf.keras\nl = keras.layers\n\nFLAGS = flags.FLAGS\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\nflags.DEFINE_string(\'output_dir\', \'/tmp/mnist_train/\',\n                    \'Output directory to hold tensorboard events\')\n\n\ndef build_sequential_model(input_shape):\n  return tf.keras.Sequential([\n      l.Conv2D(\n          32, 5, padding=\'same\', activation=\'relu\', input_shape=input_shape),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.BatchNormalization(),\n      l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      l.Dense(1024, activation=\'relu\'),\n      l.Dropout(0.4),\n      l.Dense(num_classes, activation=\'softmax\')\n  ])\n\n\ndef build_functional_model(input_shape):\n  inp = tf.keras.Input(shape=input_shape)\n  x = l.Conv2D(32, 5, padding=\'same\', activation=\'relu\')(inp)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.BatchNormalization()(x)\n  x = l.Conv2D(64, 5, padding=\'same\', activation=\'relu\')(x)\n  x = l.MaxPooling2D((2, 2), (2, 2), padding=\'same\')(x)\n  x = l.Flatten()(x)\n  x = l.Dense(1024, activation=\'relu\')(x)\n  x = l.Dropout(0.4)(x)\n  out = l.Dense(num_classes, activation=\'softmax\')(x)\n\n  return tf.keras.models.Model([inp], [out])\n\n\ndef build_layerwise_model(input_shape, **pruning_params):\n  return tf.keras.Sequential([\n      prune.prune_low_magnitude(\n          l.Conv2D(32, 5, padding=\'same\', activation=\'relu\'),\n          input_shape=input_shape,\n          **pruning_params),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.BatchNormalization(),\n      prune.prune_low_magnitude(\n          l.Conv2D(64, 5, padding=\'same\', activation=\'relu\'), **pruning_params),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      prune.prune_low_magnitude(\n          l.Dense(1024, activation=\'relu\'), **pruning_params),\n      l.Dropout(0.4),\n      prune.prune_low_magnitude(\n          l.Dense(num_classes, activation=\'softmax\'), **pruning_params)\n  ])\n\n\ndef train_and_save(models, x_train, y_train, x_test, y_test):\n  for model in models:\n    model.compile(\n        loss=tf.keras.losses.categorical_crossentropy,\n        optimizer=\'adam\',\n        metrics=[\'accuracy\'])\n\n    # Print the model summary.\n    model.summary()\n\n    # Add a pruning step callback to peg the pruning step to the optimizer\'s\n    # step. Also add a callback to add pruning summaries to tensorboard\n    callbacks = [\n        pruning_callbacks.UpdatePruningStep(),\n        pruning_callbacks.PruningSummaries(log_dir=FLAGS.output_dir)\n    ]\n\n    model.fit(\n        x_train,\n        y_train,\n        batch_size=batch_size,\n        epochs=epochs,\n        verbose=1,\n        callbacks=callbacks,\n        validation_data=(x_test, y_test))\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print(\'Test loss:\', score[0])\n    print(\'Test accuracy:\', score[1])\n\n    # Export and import the model. Check that accuracy persists.\n    saved_model_dir = \'/tmp/saved_model\'\n    print(\'Saving model to: \', saved_model_dir)\n    tf.keras.models.save_model(model, saved_model_dir, save_format=\'tf\')\n    print(\'Loading model from: \', saved_model_dir)\n    loaded_model = tf.keras.models.load_model(saved_model_dir)\n\n    score = loaded_model.evaluate(x_test, y_test, verbose=0)\n    print(\'Test loss:\', score[0])\n    print(\'Test accuracy:\', score[1])\n\n\ndef main(unused_argv):\n  # input image dimensions\n  img_rows, img_cols = 28, 28\n\n  # the data, shuffled and split between train and test sets\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n  if tf.keras.backend.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\n  else:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\n  x_train = x_train.astype(\'float32\')\n  x_test = x_test.astype(\'float32\')\n  x_train /= 255\n  x_test /= 255\n  print(\'x_train shape:\', x_train.shape)\n  print(x_train.shape[0], \'train samples\')\n  print(x_test.shape[0], \'test samples\')\n\n  # convert class vectors to binary class matrices\n  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n  pruning_params = {\n      \'pruning_schedule\': ConstantSparsity(0.75, begin_step=2000, frequency=100)\n  }\n\n  layerwise_model = build_layerwise_model(input_shape, **pruning_params)\n  sequential_model = build_sequential_model(input_shape)\n  sequential_model = prune.prune_low_magnitude(\n      sequential_model, **pruning_params)\n  functional_model = build_functional_model(input_shape)\n  functional_model = prune.prune_low_magnitude(\n      functional_model, **pruning_params)\n\n  models = [layerwise_model, sequential_model, functional_model]\n  train_and_save(models, x_train, y_train, x_test, y_test)\n\n\nif __name__ == \'__main__\':\n  absl_app.run(main)\n'"
tensorflow_model_optimization/python/examples/sparsity/keras/mnist/mnist_e2e.py,5,"b'# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=missing-docstring,protected-access\n""""""Train a simple convnet on the MNIST dataset.""""""\nfrom __future__ import print_function\n\nfrom absl import app as absl_app\nfrom absl import flags\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.keras import test_utils as keras_test_utils\nfrom tensorflow_model_optimization.python.core.sparsity.keras import prune\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\nfrom tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n\nConstantSparsity = pruning_schedule.ConstantSparsity\nkeras = tf.keras\nl = keras.layers\n\nFLAGS = flags.FLAGS\n\nbatch_size = 128\nnum_classes = 10\nepochs = 1\n\nflags.DEFINE_float(\'sparsity\', \'0.0\', \'Target sparsity level.\')\n\n\ndef build_layerwise_model(input_shape, **pruning_params):\n  return tf.keras.Sequential([\n      l.Conv2D(\n          32, 5, padding=\'same\', activation=\'relu\', input_shape=input_shape),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Conv2D(64, 5, padding=\'same\'),\n      l.BatchNormalization(),\n      l.ReLU(),\n      l.MaxPooling2D((2, 2), (2, 2), padding=\'same\'),\n      l.Flatten(),\n      prune.prune_low_magnitude(\n          l.Dense(1024, activation=\'relu\'), **pruning_params),\n      l.Dropout(0.4),\n      prune.prune_low_magnitude(\n          l.Dense(num_classes, activation=\'softmax\'), **pruning_params)\n  ])\n\n\ndef train(model, x_train, y_train, x_test, y_test):\n  model.compile(\n      loss=tf.keras.losses.categorical_crossentropy,\n      optimizer=\'adam\',\n      metrics=[\'accuracy\'])\n\n  # Print the model summary.\n  model.summary()\n\n  # Add a pruning step callback to peg the pruning step to the optimizer\'s\n  # step. Also add a callback to add pruning summaries to tensorboard\n  callbacks = [\n      pruning_callbacks.UpdatePruningStep(),\n      pruning_callbacks.PruningSummaries(log_dir=\'/tmp/logs\')\n  ]\n\n  model.fit(\n      x_train,\n      y_train,\n      batch_size=batch_size,\n      epochs=epochs,\n      verbose=1,\n      callbacks=callbacks,\n      validation_data=(x_test, y_test))\n  score = model.evaluate(x_test, y_test, verbose=0)\n  print(\'Test loss:\', score[0])\n  print(\'Test accuracy:\', score[1])\n\n  model = prune.strip_pruning(model)\n  return model\n\n\ndef main(unused_argv):\n  ##############################################################################\n  # Prepare training and testing data\n  ##############################################################################\n  (x_train, y_train), (\n      x_test,\n      y_test), input_shape = keras_test_utils.get_preprocessed_mnist_data()\n\n  ##############################################################################\n  # Train and convert a model with 2x2 block config. There\'s no kernel in tflite\n  # supporting this block configuration, so the sparse tensor is densified and\n  # the model falls back to dense execution.\n  ##############################################################################\n  pruning_params = {\n      \'pruning_schedule\':\n          ConstantSparsity(FLAGS.sparsity, begin_step=0, frequency=100),\n      \'block_size\': (2, 2)\n  }\n\n  model = build_layerwise_model(input_shape, **pruning_params)\n  model = train(model, x_train, y_train, x_test, y_test)\n\n  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n  converter.experimental_new_converter = True\n\n  # Get a dense model as baseline\n  tflite_model_dense = converter.convert()\n  tflite_model_path = \'/tmp/dense_mnist.tflite\'\n  with open(tflite_model_path, \'wb\') as f:\n    f.write(tflite_model_dense)\n\n  # The _experimental_sparsify_model is to enable sparse tensor encoding,\n  # otherwise the model is converted as dense.\n  converter._experimental_sparsify_model = True\n\n  tflite_model = converter.convert()\n\n  # Check the model is compressed\n  print(\'Compression ratio: \', len(tflite_model) / len(tflite_model_dense))\n\n  tflite_model_path = \'/tmp/sparse_mnist_%s_2x2.tflite\' % FLAGS.sparsity\n  with open(tflite_model_path, \'wb\') as f:\n    f.write(tflite_model)\n\n  print(\'evaluate 2x2 model\')\n  print(keras_test_utils.eval_mnist_tflite(model_content=tflite_model))\n\n  ##############################################################################\n  # Train and convert a model with 1x4 block config. There\'s kernel in tflite\n  # with this block configuration, so the model can take advantage of sparse\n  # execution and see inference speed-up.\n  ##############################################################################\n  pruning_params = {\n      \'pruning_schedule\':\n          ConstantSparsity(FLAGS.sparsity, begin_step=0, frequency=100),\n      # TFLite transposes the weight during conversion, so we need to specify\n      # the block as (4, 1) in the training API.\n      \'block_size\': (4, 1)\n  }\n\n  model = build_layerwise_model(input_shape, **pruning_params)\n  model = train(model, x_train, y_train, x_test, y_test)\n\n  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n  converter.experimental_new_converter = True\n  converter._experimental_sparsify_model = True\n\n  tflite_model = converter.convert()\n  # Check the model is compressed\n  print(\'Compression ratio: \', len(tflite_model) / len(tflite_model_dense))\n\n  tflite_model_path = \'/tmp/sparse_mnist_%s_1x4.tflite\' % FLAGS.sparsity\n  with open(tflite_model_path, \'wb\') as f:\n    f.write(tflite_model)\n\n  print(\'evaluate 1x4 model\')\n  print(keras_test_utils.eval_mnist_tflite(model_content=tflite_model))\n\n\nif __name__ == \'__main__\':\n  absl_app.run(main)\n'"
tensorflow_model_optimization/python/core/api/quantization/keras/quantizers/__init__.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Module containing Quantization abstraction and quantizers.""""""\n\n# quantize with custom quantization parameterization or implementation, or\n# handle custom Keras layers.\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantizers import LastValueQuantizer\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantizers import MovingAverageQuantizer\nfrom tensorflow_model_optimization.python.core.quantization.keras.quantizers import Quantizer\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/__init__.py,0,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Experimental implementations of encoding stages.\n\nThese encoding stages can possibly change without guarantees on backward\ncompatibility.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.clipping import ClipByNormEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.clipping import ClipByValueEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.kashin import KashinHadamardEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.misc import DifferenceBetweenIntegersEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.misc import SplitBySmallValueEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.quantization import PerChannelPRNGUniformQuantizationEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.quantization import PerChannelUniformQuantizationEncodingStage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research.quantization import PRNGUniformQuantizationEncodingStage\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/clipping.py,9,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Encoding stages implementing various clipping strategies.\n\nThe base classes, `ClipByNormEncodingStage` and `ClipByValueEncodingStage`, are\nexpected to be subclassed as implementations of\n`AdaptiveEncodingStageInterface`, to realize a variety of clipping strategies\nthat are adaptive to the data being processed in an iterative execution.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\n\n\n@encoding_stage.tf_style_encoding_stage\nclass ClipByNormEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage applying clipping by norm (L-2 ball projection).\n\n  See `tf.clip_by_norm` for more information.\n  """"""\n\n  ENCODED_VALUES_KEY = \'clipped_values\'\n  NORM_PARAMS_KEY = \'norm_param\'\n\n  def __init__(self, clip_norm):\n    """"""Initializer for the `ClipByNormEncodingStage`.\n\n    Args:\n      clip_norm: A scalar, norm of the ball onto which to project.\n    """"""\n    self._clip_norm = clip_norm\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'clip_by_norm\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {self.NORM_PARAMS_KEY: self._clip_norm}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    clipped_x = tf.clip_by_norm(\n        x, tf.cast(encode_params[self.NORM_PARAMS_KEY], x.dtype))\n    return {self.ENCODED_VALUES_KEY: clipped_x}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    return tf.identity(encoded_tensors[self.ENCODED_VALUES_KEY])\n\n\n@encoding_stage.tf_style_encoding_stage\nclass ClipByValueEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage applying clipping by value (L-infinity ball projection).\n\n  See `tf.clip_by_value` for more information.\n  """"""\n\n  ENCODED_VALUES_KEY = \'clipped_values\'\n  MIN_PARAMS_KEY = \'min_param\'\n  MAX_PARAMS_KEY = \'max_param\'\n\n  def __init__(self, clip_value_min, clip_value_max):\n    """"""Initializer for the `ClipByValueEncodingStage`.\n\n    Args:\n      clip_value_min: A scalar, the minimum value to which to clip.\n      clip_value_max: A scalar, the maximum value to which to clip.\n    """"""\n    self._clip_value_min = clip_value_min\n    self._clip_value_max = clip_value_max\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'clip_by_value\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {\n        self.MIN_PARAMS_KEY: self._clip_value_min,\n        self.MAX_PARAMS_KEY: self._clip_value_max\n    }\n    return params, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    clipped_x = tf.clip_by_value(\n        x,\n        tf.cast(encode_params[self.MIN_PARAMS_KEY], x.dtype),\n        tf.cast(encode_params[self.MAX_PARAMS_KEY], x.dtype))\n    return {self.ENCODED_VALUES_KEY: clipped_x}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused.\n    return tf.identity(encoded_tensors[self.ENCODED_VALUES_KEY])\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/clipping_test.py,18,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research import clipping\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass ClipByNormEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return clipping.ClipByNormEncodingStage(1.0)\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([20])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    encoded_x = data.encoded_x[\n        clipping.ClipByNormEncodingStage.ENCODED_VALUES_KEY]\n    # The encoding should not change the shape...\n    self.assertAllEqual(data.x.shape, encoded_x.shape)\n    # The decoding should be identity.\n    self.assertAllEqual(encoded_x, data.decoded_x)\n\n  def test_clipping_effective(self):\n    stage = clipping.ClipByNormEncodingStage(1.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.constant([1.0, 1.0, 1.0, 1.0]))\n    self.common_asserts_for_test_data(test_data)\n    self.assertAllEqual([1.0, 1.0, 1.0, 1.0], test_data.x)\n    # The decoded values should have norm 1.\n    self.assertAllClose([0.5, 0.5, 0.5, 0.5], test_data.decoded_x)\n\n  def test_clipping_large_norm_identity(self):\n    stage = clipping.ClipByNormEncodingStage(1000.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.constant([1.0, 1.0, 1.0, 1.0]))\n    self.common_asserts_for_test_data(test_data)\n    # The encoding should act as an identity, if input value has smaller norm.\n    self.assertAllEqual(test_data.x, test_data.decoded_x)\n\n  @parameterized.parameters(([2,],), ([2, 3],), ([2, 3, 4],))\n  def test_different_shapes(self, shape):\n    stage = clipping.ClipByNormEncodingStage(1.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.random.uniform(shape) + 1.0)\n    self.common_asserts_for_test_data(test_data)\n    self.assertAllClose(1.0, np.linalg.norm(test_data.decoded_x))\n\n  @parameterized.parameters(\n      itertools.product([tf.float32, tf.float64], [tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype, clip_norm_dtype):\n    # Tests combinations of input dtypes.\n    stage = clipping.ClipByNormEncodingStage(\n        tf.constant(1.0, clip_norm_dtype))\n    x = tf.constant([1.0, 1.0, 1.0, 1.0], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n    self.assertAllEqual([1.0, 1.0, 1.0, 1.0], test_data.x)\n    # The decoded values should have norm 1.\n    self.assertAllClose([0.5, 0.5, 0.5, 0.5], test_data.decoded_x)\n\n\nclass ClipByValueEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return clipping.ClipByValueEncodingStage(-1.0, 1.0)\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([20])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    encoded_x = data.encoded_x[\n        clipping.ClipByValueEncodingStage.ENCODED_VALUES_KEY]\n    # The encoding should not change the shape...\n    self.assertAllEqual(data.x.shape, encoded_x.shape)\n    # The decoding should be identity.\n    self.assertAllEqual(encoded_x, data.decoded_x)\n\n  def test_clipping_effective(self):\n    stage = clipping.ClipByValueEncodingStage(-1.0, 1.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.constant([-2.0, -1.0, 0.0, 1.0, 2.0]))\n    self.common_asserts_for_test_data(test_data)\n    self.assertAllEqual([-2.0, -1.0, 0.0, 1.0, 2.0], test_data.x)\n    self.assertAllClose([-1.0, -1.0, 0.0, 1.0, 1.0], test_data.decoded_x)\n\n  def test_clipping_large_min_max_identity(self):\n    stage = clipping.ClipByValueEncodingStage(-1000.0, 1000.0)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self.common_asserts_for_test_data(test_data)\n    # The encoding should act as an identity, if input has smaller values.\n    self.assertAllEqual(test_data.x, test_data.decoded_x)\n\n  @parameterized.parameters(([2,],), ([2, 3],), ([2, 3, 4],))\n  def test_different_shapes(self, shape):\n    stage = clipping.ClipByValueEncodingStage(-1.0, 1.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.random.normal(shape))\n    self.common_asserts_for_test_data(test_data)\n    self.assertGreaterEqual(1.0, np.amax(test_data.decoded_x))\n    self.assertLessEqual(-1.0, np.amin(test_data.decoded_x))\n\n  @parameterized.parameters(\n      itertools.product([tf.float32, tf.float64], [tf.float32, tf.float64],\n                        [tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype, clip_value_min_dtype,\n                       clip_value_max_dtype):\n    # Tests combinations of input dtypes.\n    stage = clipping.ClipByValueEncodingStage(\n        tf.constant(-1.0, clip_value_min_dtype),\n        tf.constant(1.0, clip_value_max_dtype))\n    x = tf.constant([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n    self.common_asserts_for_test_data(test_data)\n    self.assertAllEqual([-2.0, -1.0, 0.0, 1.0, 2.0], test_data.x)\n    self.assertAllClose([-1.0, -1.0, 0.0, 1.0, 1.0], test_data.decoded_x)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/kashin.py,19,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Experimental implementations of the encoding stage interfaces.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import tf_utils\n\n\n@encoding_stage.tf_style_encoding_stage\nclass KashinHadamardEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage computing Kashin\'s representation from Hadamard transform.\n\n  This class is inspired by the work ""Uncertainty Principle and Vector\n  Quantization"" (https://arxiv.org/pdf/math/0611343.pdf), and the algorithm\n  presented therein.\n\n  The encoding stage builds upon the `HadamardEncodingStage` and uses the\n  overcomplete base to compute representation with a smaller dynamic range of\n  coefficients. One of the benefits is that it incurrs a smaller error in\n  subsequent uniform quantization, smaller even compared to using the\n  `HadamardEncodingStage`.\n\n  The idea is that certain overcomplete bases, or tight frames, admit what is\n  called ""Kashin\'s representation"" for every vector. Kashin\'s representation is\n  such that the dynamic range of coefficients is as small as (asymptotically)\n  possible. In this case, the overcomplete base consists of subsampled Hadamard\n  matrix.\n\n  The algorithm iteratively computes coefficients of input vector in rotated\n  space (or projected space), projects onto a L-infinity ball, computes the\n  residual error incurred by the projection, and repeats the same procedure with\n  the residual and a smaller ball.\n\n  For the meaning of the parameters `eta` and `delta`, see Section III.A in the\n  referenced paper. The main pseudocode presented there is as follows:\n    Input:\n      projection, parameters eta, delta (should be derived from the projection).\n      vector x of which representation needs to be computed.\n    Initialize:\n      kashin_coefficients <- [0, 0, ..., 0]\n      M <- norm(x) / sqrt(delta * output_dim)  # [initial clipping level]\n    Repeat num_iter times:\n      b <- frame representation of x\n      b <- clip b at level M\n      kashin_coefficients <- kashin_coefficients + b\n      x\' <- recover from frame representation b\n      x <- x - x\'\n      M <- M * eta\n    Output:\n      kashin_coefficients\n\n  The actual implementation of the encoding works as follows:\n  The shape of the input `x` to the `encode` method must be either `(dim)` or\n  `(b, dim)`, where `dim` is the dimenion of the vector to which the transform\n  is to be applied, and must be statically known. `b` represents an optional\n  batch dimension, and does not need to be statically known.\n\n  If the shape of the input is `(dim)`, it is first expanded to `(1, dim)`. The\n  input of shape `(b, dim)` is then padded with zeros to dimension `(b, dim_2)`,\n  where `dim_2` is the smallest power of 2 larger than or equal to `dim`. In the\n  case of `dim / dim_2 > pad_extra_level_threshold`, an extra factor of 2 is\n  added to `dim_2`. Otherwise, the algorithm does not have enough leeway to\n  realize benefits over only applying the randomized Hadamard transform.\n\n  The Kashin\'s representation is then computed for each of the `b` vectors of\n  shape `dim_2`. The encoded value thus has shape `(b, dim_2)`.\n  """"""\n\n  ENCODED_VALUES_KEY = \'kashin_hadamard_values\'\n  ETA_PARAMS_KEY = \'eta\'\n  DELTA_PARAMS_KEY = \'delta\'\n  SEED_PARAMS_KEY = \'seed\'\n\n  def __init__(self,\n               num_iters=3,\n               eta=0.9,\n               delta=1.0,\n               last_iter_clip=False,\n               pad_extra_level_threshold=0.85):\n    """"""Initializer for the `KashinHadamardEncodingStage`.\n\n    Args:\n      num_iters: An integer number of iterations to run to compute the\n        representation. Cannot be a TensorFlow value.\n      eta: A scalar parameter of the encoding algorithm. Determines the\n        shrinkage of the clipping level in each iteration. Must be between 0 and\n        1. Can be either a TensorFlow or a Python value.\n      delta: A scalar parameter of the encoding algorithm. Determines the\n        initial clipping level. Must be greater than 0. Can be either a\n        TensorFlow or a Python value.\n      last_iter_clip: A boolean, determining whether to apply clipping in last\n        iteration of the encoding algorithm. If set to False, the encoded\n        representation is always lossless. If set to True, the resulting\n        representation can be lossy, although not necessarily. Cannot be a\n        TensorFlow value.\n      pad_extra_level_threshold: A scalar parameter determining the threshold,\n        at which padding with zeros is to be expanded by an additional power of\n        2. See class documentation for why this is needed. Cannot be a\n        TensorFlow value.\n\n    Raises:\n      ValueError: The inputs do not satisfy the above constraints.\n    """"""\n    if tf.is_tensor(num_iters):\n      raise ValueError(\'Parameter num_iters cannot be a TensorFlow value.\')\n    if not isinstance(num_iters, int) or num_iters <= 0:\n      raise ValueError(\'Number of iterations must be a positive integer.\'\n                       \'num_iters provided: %s\' % num_iters)\n    self._num_iters = num_iters\n\n    if not tf.is_tensor(eta) and not 0.0 < eta < 1.0:\n      raise ValueError(\'Parameter eta must be between 0 and 1. \'\n                       \'Provided eta: %s\' % eta)\n    self._eta = eta\n\n    if not tf.is_tensor(delta) and delta <= 0.0:\n      raise ValueError(\'Parameter delta must be greater than 0. \'\n                       \'Provided delta: %s\' % delta)\n    self._delta = delta\n\n    if tf.is_tensor(last_iter_clip):\n      raise ValueError(\'Parameter last_iter_clip cannot be a TensorFlow value.\')\n    if not isinstance(last_iter_clip, bool):\n      raise ValueError(\'Parameter last_iter_clip must be a bool.\')\n    self._last_iter_clip = last_iter_clip\n\n    if tf.is_tensor(pad_extra_level_threshold):\n      raise ValueError(\n          \'Parameter pad_extra_level_threshold cannot be a TensorFlow value.\')\n    self._pad_extra_level_threshold = pad_extra_level_threshold\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'kashin_hadamard\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return True\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    seed = tf.random.uniform((2,), maxval=tf.int64.max, dtype=tf.int64)\n    encode_params = {\n        self.ETA_PARAMS_KEY: self._eta,\n        self.DELTA_PARAMS_KEY: self._delta,\n        self.SEED_PARAMS_KEY: seed,\n    }\n    decode_params = {self.SEED_PARAMS_KEY: seed}\n    return encode_params, decode_params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    x = self._validate_and_expand_encode_input(x)\n    dims = x.shape.as_list()\n    # Get static or dynamic leading dimension if static not available.\n    dim_0 = dims[0] if dims[0] else tf.shape(x)[0]\n    dim_1 = dims[1]\n    kashin_coefficients = tf.zeros([dim_0, self._get_pad_dim(dim_1)],\n                                   dtype=x.dtype)\n    clip_level = tf.norm(x, axis=1, keepdims=True) / tf.math.sqrt(\n        tf.cast(encode_params[self.DELTA_PARAMS_KEY], x.dtype) * dim_1)\n    last_iter_clip = self._last_iter_clip\n    residual = x\n    signs = self._random_signs(dim_1, encode_params[self.SEED_PARAMS_KEY],\n                               x.dtype)\n\n    # Compute the Kashin coefficients.\n    for _ in range(self._num_iters - 1):\n      residual, kashin_coefficients = self._kashin_iter(\n          residual, kashin_coefficients, signs, clip_level)\n      clip_level *= tf.cast(encode_params[self.ETA_PARAMS_KEY], x.dtype)\n    # The last iteration can be with or without clipping.\n    kashin_coefficients += self._kashin_forward(residual, signs, clip_level,\n                                                last_iter_clip)\n    if last_iter_clip:\n      # If there is clipping in the last iteration, this can result in\n      # biased representation of smaller magnitude. We compensate for this\n      # by scaling such that the norm is preserved.\n      kashin_coefficients *= tf.compat.v1.div_no_nan(\n          tf.norm(x, axis=1, keepdims=True),\n          tf.norm(kashin_coefficients, axis=1, keepdims=True))\n\n    return {self.ENCODED_VALUES_KEY: kashin_coefficients}\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands  # Unused.\n    kashin_coefficients = encoded_tensors[self.ENCODED_VALUES_KEY]\n    decoded_x = self._kashin_backward(kashin_coefficients, shape[-1])\n    signs = self._random_signs(decoded_x.shape.as_list()[-1],\n                               decode_params[self.SEED_PARAMS_KEY],\n                               decoded_x.dtype)\n    decoded_x = decoded_x * signs\n\n    if shape.shape.num_elements() == 1:\n      decoded_x = tf.squeeze(decoded_x, [0])\n    return decoded_x\n\n  def _kashin_forward(self, x, signs, clip_level, clip):\n    """"""Forward step of the algorithm to obtain Kashin\'s representation.""""""\n    x = x * signs\n    x = self._pad(x)\n    x = tf_utils.fast_walsh_hadamard_transform(x)\n    if clip:\n      x = tf.clip_by_value(x, -clip_level, clip_level)\n    return x\n\n  def _kashin_backward(self, x, shape, signs=None):\n    """"""Backward step of the algorithm to obtain Kashin\'s representation.""""""\n    x = tf_utils.fast_walsh_hadamard_transform(x)\n    # Take the slice corresponding to the original object that was encoded.\n    # Consistency in specific coordinates for padding and slicing is what makes\n    # inverse transformation unique.\n    x = tf.slice(x, [0, 0], [tf.shape(x)[0], shape])\n    if signs is not None:\n      x = x * signs\n    return x\n\n  def _kashin_iter(self, x, kashin_coefficients, signs, clip_level):\n    """"""A single iteration of the algorithm to obtain Kashin\'s representation.""""""\n    x_init = x\n    x = self._kashin_forward(x, signs, clip_level, clip=True)\n    kashin_coefficients += x\n    # x_init.shape.as_list()[1] is the dimension of objects to be encoded.\n    x = self._kashin_backward(x, x_init.shape.as_list()[1], signs)\n    residual = x_init - x\n    return residual, kashin_coefficients\n\n  def _validate_and_expand_encode_input(self, x):\n    """"""Validates the input to encode and modifies it if necessary.""""""\n    if x.shape.ndims not in [1, 2]:\n      raise ValueError(\n          \'Number of dimensions must be 1 or 2. Shape of x: %s\' % x.shape)\n    if x.shape.ndims == 1:\n      # The input to the fast_walsh_hadamard_transform must have 2 dimensions.\n      x = tf.expand_dims(x, 0)\n    if x.shape.as_list()[1] is None:\n      raise ValueError(\n          \'The dimension of the object to be rotated must be fully known.\')\n    return x\n\n  def _get_pad_dim(self, dim):\n    """"""Computes the dimension the input needs to be padded into.""""""\n    pad_dim = 2**int(np.ceil(np.log2(dim)))\n    if dim / pad_dim > self._pad_extra_level_threshold:\n      pad_dim *= 2\n    return pad_dim\n\n  def _pad(self, x):\n    """"""Pads with zeros to the next power of two.""""""\n    dim = x.shape.as_list()[1]\n    pad_dim = self._get_pad_dim(dim)\n    if pad_dim != dim:\n      x = tf.pad(x, [[0, 0], [0, pad_dim - dim]])\n    return x\n\n  def _random_signs(self, num_elements, seed, dtype):\n    return tf_utils.random_signs(num_elements, seed, dtype)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/kashin_test.py,20,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research import kashin\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass KashinHadamardEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return kashin.KashinHadamardEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.normal([3, 12])\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertLen(\n        data.encoded_x[\n            kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY].shape,\n        2)\n    # No other common asserts, as based on input properties, this transformation\n    # can be lossy or lossless.\n\n  def test_encoding_randomized(self):\n    # The encoding stage declares a source of randomness (a random seed) in the\n    # get_params method, and different encoding should be produced for each\n    # random seed. This tests that this is the case, and that the encoding is\n    # still lossless.\n    stage = self.default_encoding_stage()\n    x = np.random.randn(20).astype(np.float32)\n    test_data_1 = self.run_one_to_many_encode_decode(stage, lambda: x)\n    test_data_2 = self.run_one_to_many_encode_decode(stage, lambda: x)\n    # Make sure we encode the same object.\n    self.assertAllClose(test_data_1.x, test_data_2.x)\n    self.assertAllClose(test_data_1.x, test_data_1.decoded_x)\n    self.assertAllClose(test_data_2.x, test_data_2.decoded_x)\n    encoded_x_1 = test_data_1.encoded_x[\n        kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY]\n    encoded_x_2 = test_data_2.encoded_x[\n        kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY]\n    self.assertGreater(np.linalg.norm(encoded_x_1 - encoded_x_2), 0.1)\n\n  @parameterized.parameters(\n      [((4,), (1, 4)),\n       ((6,), (1, 8)),\n       ((1, 5), (1, 8)),\n       ((1, 11), (1, 16)),\n       ((1, 20), (1, 32)),\n       ((1, 111), (1, 128)),\n       ((2, 7), (2, 8)),\n       ((4, 1), (4, 1)),\n       ((9, 7), (9, 8))])\n  def test_with_multiple_input_shapes_pad_1_0(self, input_dims,\n                                              expected_output_dims):\n    stage = kashin.KashinHadamardEncodingStage(pad_extra_level_threshold=1.0)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.random.normal(input_dims))\n    self.common_asserts_for_test_data(test_data)\n    # Make sure output shape is as expected.\n    self.assertEqual(\n        expected_output_dims, test_data.encoded_x[\n            kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY].shape)\n\n  @parameterized.parameters(\n      [((4,), (1, 8)),\n       ((6,), (1, 8)),\n       ((1, 5), (1, 8)),\n       ((1, 11), (1, 16)),\n       ((1, 20), (1, 32)),\n       ((1, 111), (1, 256)),\n       ((2, 7), (2, 16)),\n       ((4, 1), (4, 2)),\n       ((9, 7), (9, 16))])\n  def test_with_multiple_input_shapes_pad_0_8(self, input_dims,\n                                              expected_output_dims):\n    stage = kashin.KashinHadamardEncodingStage(pad_extra_level_threshold=0.8)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.random.normal(input_dims))\n    self.common_asserts_for_test_data(test_data)\n    # Make sure output shape is as expected.\n    self.assertEqual(\n        expected_output_dims, test_data.encoded_x[\n            kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY].shape)\n\n  @parameterized.parameters([True, False])\n  def test_all_zero_input_works(self, last_iter_clip):\n    # Tests that encoding does not blow up with all-zero input.\n    stage = kashin.KashinHadamardEncodingStage(\n        num_iters=3, eta=0.9, delta=1.0, last_iter_clip=last_iter_clip)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.zeros([3, 12]))\n    self.common_asserts_for_test_data(test_data)\n    self.assertAllEqual(\n        np.zeros((3, 12)).astype(np.float32), test_data.decoded_x)\n\n  def test_input_with_unknown_leading_dimension(self):\n\n    def get_random_shape_input():\n      # Returns a Tensor of shape (?, 6)\n      return tf.map_fn(lambda x: x * tf.random.normal([6]),\n                       test_utils.get_tensor_with_random_shape())\n\n    # Validate the premise of the test.\n    assert get_random_shape_input().shape.as_list() == [None, 6]\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), get_random_shape_input)\n    self.common_asserts_for_test_data(test_data)\n    encoded_shape = test_data.encoded_x[\n        kashin.KashinHadamardEncodingStage.ENCODED_VALUES_KEY].shape\n    self.assertEqual(test_data.x.shape[0], encoded_shape[0])\n    self.assertEqual(8, encoded_shape[1])\n\n  def test_larger_num_iters_improves_accuracy(self):\n    # If last_iter_clip = True, this potentially computes lossy representation.\n    # Set delta large, to measure the effect of changing num_iters on accuracy.\n    x = np.random.randn(3, 12).astype(np.float32)\n    errors = []\n    seed = tf.constant([1, 2], tf.int64)\n    for num_iters in [2, 3, 4, 5]:\n      stage = kashin.KashinHadamardEncodingStage(\n          num_iters=num_iters, eta=0.9, delta=100.0, last_iter_clip=True)\n      encode_params, decode_params = stage.get_params()\n      # To keep the experiment consistent, we always need to use fixed seed.\n      encode_params[kashin.KashinHadamardEncodingStage.SEED_PARAMS_KEY] = seed\n      decode_params[kashin.KashinHadamardEncodingStage.SEED_PARAMS_KEY] = seed\n      encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                  decode_params)\n      test_data = test_utils.TestData(x, encoded_x, decoded_x)\n      test_data = self.evaluate_test_data(test_data)\n      errors.append(np.linalg.norm(test_data.x - test_data.decoded_x))\n    for e1, e2 in zip(errors[:-1], errors[1:]):\n      # The incurred error with less iterations should be greater.\n      self.assertGreater(e1, e2)\n\n  def test_last_iter_clip_false_is_lossless(self):\n    # Make sure to set delta to something large so that there is something to\n    # clip in the last iteration. Otherwise the test does not make sense.\n    stage = kashin.KashinHadamardEncodingStage(\n        num_iters=2, eta=0.9, delta=100.0, last_iter_clip=False)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.random.normal([3, 12]))\n    self.assertAllClose(test_data.x, test_data.decoded_x)\n\n  def test_eta_delta_take_tf_values(self):\n    x = self.default_input()\n    stage = kashin.KashinHadamardEncodingStage(\n        eta=tf.constant(0.9), delta=tf.constant(1.0))\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    self.generic_asserts(test_data, stage)\n    self.common_asserts_for_test_data(test_data)\n\n  @parameterized.parameters(\n      itertools.product([tf.float32, tf.float64],\n                        [tf.float32, tf.float64],\n                        [tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype, eta_dtype, delta_dtype):\n    stage = kashin.KashinHadamardEncodingStage(\n        eta=tf.constant(0.9, eta_dtype), delta=tf.constant(1.0, delta_dtype))\n    x = tf.random.normal([3, 12], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n    self.assertAllEqual(test_data.x.shape, test_data.decoded_x.shape)\n\n  def test_unknown_shape_raises(self):\n    x = test_utils.get_tensor_with_random_shape()\n    stage = self.default_encoding_stage()\n    params, _ = stage.get_params()\n    with self.assertRaisesRegexp(ValueError, \'fully known\'):\n      stage.encode(x, params)\n\n  @parameterized.parameters([((1, 1, 5),), ((1, 1, 1, 5),)])\n  def test_more_than_two_ndims_raises(self, dims):\n    x = tf.random.normal(dims)\n    stage = self.default_encoding_stage()\n    params, _ = stage.get_params()\n    with self.assertRaisesRegexp(ValueError, \'must be 1 or 2.\'):\n      stage.encode(x, params)\n\n  @parameterized.parameters([0.0, 1.0, -1.0, 2.5])\n  def test_eta_out_of_bounds_raises(self, eta):\n    with self.assertRaisesRegexp(ValueError, \'between 0 and 1\'):\n      kashin.KashinHadamardEncodingStage(eta=eta)\n\n  @parameterized.parameters([0.0, -1.0])\n  def test_delta_small_raises(self, delta):\n    with self.assertRaisesRegexp(ValueError, \'greater than 0\'):\n      kashin.KashinHadamardEncodingStage(delta=delta)\n\n  @parameterized.parameters([0, -1, -10])\n  def test_num_iters_small_raises(self, num_iters):\n    with self.assertRaisesRegexp(ValueError, \'positive\'):\n      kashin.KashinHadamardEncodingStage(num_iters=num_iters)\n\n  def test_num_iters_tensor_raises(self):\n    with self.assertRaisesRegexp(ValueError, \'num_iters\'):\n      kashin.KashinHadamardEncodingStage(\n          num_iters=tf.constant(2, dtype=tf.int32))\n\n  def test_last_iter_clip_tensor_raises(self):\n    with self.assertRaisesRegexp(ValueError, \'last_iter_clip\'):\n      kashin.KashinHadamardEncodingStage(\n          last_iter_clip=tf.constant(True, dtype=tf.bool))\n\n  @parameterized.parameters([0, 1, 0.0, 1.0])\n  def test_last_iter_clip_not_bool_raises(self, last_iter_clip):\n    with self.assertRaisesRegexp(ValueError, \'last_iter_clip must be a bool\'):\n      kashin.KashinHadamardEncodingStage(last_iter_clip=last_iter_clip)\n\n  def test_pad_extra_level_threshold_tensor_raises(self):\n    with self.assertRaisesRegexp(ValueError, \'pad_extra_level_threshold\'):\n      kashin.KashinHadamardEncodingStage(\n          pad_extra_level_threshold=tf.constant(0.8, dtype=tf.float32))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/misc.py,9,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Misc.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\n\n\n@encoding_stage.tf_style_encoding_stage\nclass SplitBySmallValueEncodingStage(encoding_stage.EncodingStageInterface):\n  """"""Encoding stage splitting the input by small values.\n\n  This encoding stage will split the input into two outputs: the value and the\n  indices of the elements whose absolute value is larger than a certain\n  threshold. The elements smaller than the threshold is then decoded to zero.\n  """"""\n\n  ENCODED_INDICES_KEY = \'indices\'\n  ENCODED_VALUES_KEY = \'non_zero_floats\'\n  THRESHOLD_PARAMS_KEY = \'threshold\'\n\n  def __init__(self, threshold=1e-8):\n    """"""Initializer for the SplitBySmallValueEncodingStage.\n\n    Args:\n      threshold: The threshold of the small weights to be set to zero.\n    """"""\n    self._threshold = threshold\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'split_by_small_value\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [\n        self.ENCODED_VALUES_KEY,\n        self.ENCODED_INDICES_KEY,\n    ]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {self.THRESHOLD_PARAMS_KEY: self._threshold}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n\n    threshold = tf.cast(encode_params[self.THRESHOLD_PARAMS_KEY], x.dtype)\n    indices = tf.cast(tf.compat.v2.where(tf.abs(x) > threshold), tf.int32)\n    non_zero_x = tf.gather_nd(x, indices)\n    indices = tf.squeeze(indices, axis=1)\n    return {\n        self.ENCODED_INDICES_KEY: indices,\n        self.ENCODED_VALUES_KEY: non_zero_x,\n    }\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands  # Unused.\n\n    indices = encoded_tensors[self.ENCODED_INDICES_KEY]\n    non_zero_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n\n    indices = tf.expand_dims(indices, 1)\n    shape = tf.cast(shape, indices.dtype)\n    decoded_x = tf.scatter_nd(indices=indices, updates=non_zero_x, shape=shape)\n\n    return decoded_x\n\n\n@encoding_stage.tf_style_encoding_stage\nclass DifferenceBetweenIntegersEncodingStage(\n    encoding_stage.EncodingStageInterface):\n  """"""Encoding stage taking the difference between a sequence of integers.\n\n  This encoding stage can be useful when the original integers can be large, but\n  the difference of the integers are much smaller values and have a more compact\n  representation. For example, it can be combined with the\n  `SplitBySmallValueEncodingStage` to further compress the increasing sequence\n  of indices.\n\n  The encode method expects a tensor with 1 dimension and with integer dtype.\n  """"""\n\n  ENCODED_VALUES_KEY = \'difference_between_integers\'\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'difference_between_integers\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [\n        self.ENCODED_VALUES_KEY,\n    ]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    return {}, {}\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    del encode_params  # Unused.\n    if x.shape.ndims != 1:\n      raise ValueError(\'Number of dimensions must be 1. Shape of x: %s\' %\n                       x.shape)\n    if not x.dtype.is_integer:\n      raise TypeError(\n          \'Unsupported input type: %s. Support only integer types.\' % x.dtype)\n\n    diff_x = x - tf.concat([[0], x[:-1]], 0)\n    return {\n        self.ENCODED_VALUES_KEY: diff_x,\n    }\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del decode_params, num_summands, shape  # Unused\n    return tf.cumsum(encoded_tensors[self.ENCODED_VALUES_KEY])\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/misc_test.py,19,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research import misc\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass SplitBySmallValueEncodingStageTest(test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return misc.SplitBySmallValueEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([50], minval=-1.0, maxval=1.0)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self._assert_is_integer(\n        data.encoded_x[misc.SplitBySmallValueEncodingStage.ENCODED_INDICES_KEY])\n\n  def _assert_is_integer(self, indices):\n    """"""Asserts that indices values are integers.""""""\n    assert indices.dtype == np.int32\n\n  @parameterized.parameters([tf.float32, tf.float64])\n  def test_input_types(self, x_dtype):\n    # Tests different input dtypes.\n    x = tf.constant([1.0, 0.1, 0.01, 0.001, 0.0001], dtype=x_dtype)\n    threshold = 0.05\n    stage = misc.SplitBySmallValueEncodingStage(threshold=threshold)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n    self._assert_is_integer(test_data.encoded_x[\n        misc.SplitBySmallValueEncodingStage.ENCODED_INDICES_KEY])\n\n    # The numpy arrays must have the same dtype as the arrays from test_data.\n    expected_encoded_values = np.array([1.0, 0.1], dtype=x.dtype.as_numpy_dtype)\n    expected_encoded_indices = np.array([0, 1], dtype=np.int32)\n    expected_decoded_x = np.array([1.0, 0.1, 0., 0., 0.],\n                                  dtype=x_dtype.as_numpy_dtype)\n    self.assertAllEqual(test_data.encoded_x[stage.ENCODED_VALUES_KEY],\n                        expected_encoded_values)\n    self.assertAllEqual(test_data.encoded_x[stage.ENCODED_INDICES_KEY],\n                        expected_encoded_indices)\n    self.assertAllEqual(test_data.decoded_x, expected_decoded_x)\n\n  def test_all_zero_input_works(self):\n    # Tests that encoding does not blow up with all-zero input. With all-zero\n    # input, both of the encoded values will be empty arrays.\n    stage = misc.SplitBySmallValueEncodingStage()\n    test_data = self.run_one_to_many_encode_decode(stage,\n                                                   lambda: tf.zeros([50]))\n\n    self.assertAllEqual(np.zeros((50)).astype(np.float32), test_data.decoded_x)\n\n  def test_all_below_threshold_works(self):\n    # Tests that encoding does not blow up with all-below-threshold input. In\n    # this case, both of the encoded values will be empty arrays.\n    stage = misc.SplitBySmallValueEncodingStage(threshold=0.1)\n    x = tf.random.uniform([50], minval=-0.01, maxval=0.01)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n    expected_encoded_indices = np.array([], dtype=np.int32).reshape([0])\n    self.assertAllEqual(test_data.encoded_x[stage.ENCODED_VALUES_KEY], [])\n    self.assertAllEqual(test_data.encoded_x[stage.ENCODED_INDICES_KEY],\n                        expected_encoded_indices)\n    self.assertAllEqual(test_data.decoded_x,\n                        np.zeros([50], dtype=x.dtype.as_numpy_dtype))\n\n\nclass DifferenceBetweenIntegersEncodingStageTest(\n    test_utils.BaseEncodingStageTest):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return misc.DifferenceBetweenIntegersEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([10], minval=0, maxval=10, dtype=tf.int64)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return True\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self.assertAllEqual(data.x, data.decoded_x)\n\n  @parameterized.parameters(\n      itertools.product([[1,], [2,], [10,]], [tf.int32, tf.int64]))\n  def test_with_multiple_input_shapes(self, input_dims, dtype):\n\n    def x_fn():\n      return tf.random.uniform(input_dims, minval=0, maxval=10, dtype=dtype)\n\n    test_data = self.run_one_to_many_encode_decode(\n        self.default_encoding_stage(), x_fn)\n    self.common_asserts_for_test_data(test_data)\n\n  def test_empty_input_static(self):\n    # Tests that the encoding works when the input shape is [0].\n    x = []\n    x = tf.convert_to_tensor(x, dtype=tf.int32)\n    assert x.shape.as_list() == [0]\n\n    stage = self.default_encoding_stage()\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n\n    test_data = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n    self.common_asserts_for_test_data(test_data)\n\n  def test_empty_input_dynamic(self):\n    # Tests that the encoding works when the input shape is [0], but not\n    # statically known.\n    y = tf.zeros((10,))\n    indices = tf.compat.v2.where(tf.abs(y) > 1e-8)\n    x = tf.gather_nd(y, indices)\n    x = tf.cast(x, tf.int32)  # Empty tensor.\n    assert x.shape.as_list() == [None]\n    stage = self.default_encoding_stage()\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n\n    test_data = self.evaluate_test_data(\n        test_utils.TestData(x, encoded_x, decoded_x))\n    assert test_data.x.shape == (0,)\n    assert test_data.encoded_x[stage.ENCODED_VALUES_KEY].shape == (0,)\n    assert test_data.decoded_x.shape == (0,)\n\n  @parameterized.parameters([tf.bool, tf.float32])\n  def test_encode_unsupported_type_raises(self, dtype):\n    stage = self.default_encoding_stage()\n    with self.assertRaisesRegexp(TypeError, \'Unsupported input type\'):\n      self.run_one_to_many_encode_decode(\n          stage, lambda: tf.cast(self.default_input(), dtype))\n\n  def test_encode_unsupported_input_shape_raises(self):\n    x = tf.random.uniform((3, 4), maxval=10, dtype=tf.int32)\n    stage = self.default_encoding_stage()\n    params, _ = stage.get_params()\n    with self.assertRaisesRegexp(ValueError, \'Number of dimensions must be 1\'):\n      stage.encode(x, params)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/quantization.py,49,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Implementations of ideas related to quantization.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.core import encoding_stage\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.utils import tf_utils\n\n\n@encoding_stage.tf_style_encoding_stage\nclass PRNGUniformQuantizationEncodingStage(encoding_stage.EncodingStageInterface\n                                          ):\n  """"""Encoding stage performing uniform quantization using PRNG.\n\n  Different from `UniformQuantizationEncodingStage`, which uses deterministic\n  decoding, this stage uses a single integer seed as the same source of\n  randomness in encode and decode methods, in order to, in the decode method,\n  differently estimate the original values before encoding was applied.\n\n  In particular, given a floating point input `x` to the `encode` method, the\n  output will have the same `dtype` as `x`, with values being ""floating point\n  integers"" in the range `[0, 2**bits-1]`.\n\n  The shape of the input `x` to the `encode` method must be statically known.\n\n  The extreme points of the quantized interval will correspond to the min and\n  max values of the input `x`.\n\n  The output of the `decode` method is an unbiased estimation of the original\n  values before quantization, but note that it is possible for some of the\n  decoded values to be outside of the original range.\n  """"""\n\n  ENCODED_VALUES_KEY = \'quantized_values\'\n  MIN_MAX_VALUES_KEY = \'min_max\'\n  MAX_INT_VALUE_PARAMS_KEY = \'max_value\'\n  SEED_PARAMS_KEY = \'seed\'\n  # The allowed values for `bits` argument to initializer.\n  # We cap the allowed quantization bits at 16, as the randomized rounding could\n  # otherwise be numerically unstable for float32 values.\n  _ALLOWED_BITS_ARG = list(range(1, 17))\n\n  def __init__(self, bits=8):\n    """"""Initializer for the PRNGUniformQuantizationEncodingStage.\n\n    Args:\n      bits: The number of bits to quantize to. Must be an integer between 1 and\n        16. Can be either a TensorFlow or a Python value.\n\n    Raises:\n      ValueError: The inputs do not satisfy the above constraints.\n    """"""\n    if (not tf.is_tensor(bits) and bits not in self._ALLOWED_BITS_ARG):\n      raise ValueError(\'The bits argument must be an integer between 1 and 16.\')\n    self._bits = bits\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'PRNG_uniform_quantization\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return False\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.MAX_INT_VALUE_PARAMS_KEY: 2**self._bits - 1}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    min_x = tf.reduce_min(x)\n    max_x = tf.reduce_max(x)\n\n    max_value = tf.cast(encode_params[self.MAX_INT_VALUE_PARAMS_KEY], x.dtype)\n    # Shift the values to range [0, max_value].\n    # In the case of min_x == max_x, this will return all zeros.\n    x = tf.compat.v1.div_no_nan(x - min_x, max_x - min_x) * max_value\n\n    # Randomized rounding.\n    floored_x = tf.floor(x)\n    random_seed = tf.random.uniform((2,), maxval=tf.int64.max, dtype=tf.int64)\n    num_elements = tf.reduce_prod(tf.shape(x))\n    rounding_floats = tf.reshape(\n        self._random_floats(num_elements, random_seed, x.dtype), tf.shape(x))\n\n    bernoulli = rounding_floats < (x - floored_x)\n    quantized_x = floored_x + tf.cast(bernoulli, x.dtype)\n\n    # Include the random seed in the encoded tensors so that it can be used to\n    # generate the same random sequence in the decode method.\n    encoded_tensors = {\n        self.ENCODED_VALUES_KEY: quantized_x,\n        self.SEED_PARAMS_KEY: random_seed,\n        self.MIN_MAX_VALUES_KEY: tf.stack([min_x, max_x])\n    }\n\n    return encoded_tensors\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands, shape  # Unused.\n    quantized_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    random_seed = encoded_tensors[self.SEED_PARAMS_KEY]\n    min_max = encoded_tensors[self.MIN_MAX_VALUES_KEY]\n    min_x, max_x = min_max[0], min_max[1]\n    max_value = tf.cast(decode_params[self.MAX_INT_VALUE_PARAMS_KEY],\n                        quantized_x.dtype)\n\n    num_elements = tf.reduce_prod(tf.shape(quantized_x))\n    # The rounding_floats are identical to those used in the encode method.\n    rounding_floats = tf.reshape(\n        self._random_floats(num_elements, random_seed, min_x.dtype),\n        tf.shape(quantized_x))\n\n    # Regenerating the random values used in encode, enables us to determine a\n    # narrower range of possible original values, before quantization was\n    # applied. We shift the quantized values into the middle of this range,\n    # corresponding to the intersection of\n    # [quantized_x - 1 + rounding_floats, quantized_x + rounding_floats]\n    # in the quantized range. This shifted value can be out of the range\n    # [0, max_value] and therefore the decoded value can be out of the range\n    # [min_x, max_x], which is impossible, but it ensures that the decoded x\n    # is an unbiased estimator of the original values before quantization.\n    q_shifted = quantized_x + rounding_floats - 0.5\n\n    x = q_shifted / max_value * (max_x - min_x) + min_x\n    return x\n\n  def _random_floats(self, num_elements, seed, dtype):\n    return tf_utils.random_floats(num_elements, seed, dtype)\n\n\n@encoding_stage.tf_style_encoding_stage\nclass PerChannelUniformQuantizationEncodingStage(\n    encoding_stage.EncodingStageInterface):\n  """"""Encoding stage performing uniform quantization per channel in conv layers.\n\n  This encoding stage will first reshape the input `x` to `(-1, dim)`, where\n  `dim` is the size of the last dimension of `x`. Then each of the `dim`\n  vectors will be quantized independently.\n\n  This encoding stage does not require the shape of the input `x` to the\n  `encode` method to be statically known.\n\n  In particular, given a floating point input `x` to the `encode` method, the\n  output will have the same `dtype` as `x`, with values being ""floating point\n  integers"" in the range `[0, 2**bits-1]`.\n\n  The extreme points of the quantized interval will correspond to the min and\n  max values of the input `x`.\n  """"""\n\n  ENCODED_VALUES_KEY = \'quantized_values\'\n  MIN_MAX_VALUES_KEY = \'min_max\'\n  MAX_INT_VALUE_PARAMS_KEY = \'max_value\'\n  SEED_PARAMS_KEY = \'seed\'\n  # The allowed values for `bits` argument to initializer.\n  # We cap the allowed quantization bits at 16, as the randomized rounding could\n  # otherwise be numerically unstable for float32 values.\n  _ALLOWED_BITS_ARG = list(range(1, 17))\n\n  def __init__(self, bits=8, stochastic=True):\n    """"""Initializer for the PerChannelUniformQuantizationEncodingStage.\n\n    Args:\n      bits: The number of bits to quantize to. Must be an integer between 1 and\n        16. Can be either a TensorFlow or a Python value.\n      stochastic: A Python bool, whether to use stochastic or deterministic\n        rounding. If `True`, the encoding is randomized and on expectation\n        unbiased. If `False`, the encoding is deterministic.\n\n    Raises:\n      ValueError: The inputs do not satisfy the above constraints.\n    """"""\n    if (not tf.is_tensor(bits) and bits not in self._ALLOWED_BITS_ARG):\n      raise ValueError(\'The bits argument must be an integer between 1 and 16.\')\n    self._bits = bits\n\n    if not isinstance(stochastic, bool):\n      raise TypeError(\'The stochastic argument must be a bool.\')\n    self._stochastic = stochastic\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'per_channel_uniform_quantization\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.MAX_INT_VALUE_PARAMS_KEY: 2**self._bits - 1}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    dim = tf.shape(x)[-1]\n    x = tf.reshape(x, [-1, dim])\n\n    # Per-channel min and max.\n    min_x = tf.reduce_min(x, axis=0)\n    max_x = tf.reduce_max(x, axis=0)\n\n    max_value = tf.cast(encode_params[self.MAX_INT_VALUE_PARAMS_KEY], x.dtype)\n    # Shift the values to range [0, max_value].\n    # In the case of min_x == max_x, this will return all zeros.\n    x = tf.compat.v1.div_no_nan(x - min_x, max_x - min_x) * max_value\n    if self._stochastic:  # Randomized rounding.\n      floored_x = tf.floor(x)\n      bernoulli = tf.random.uniform(tf.shape(x), dtype=x.dtype)\n      bernoulli = bernoulli < (x - floored_x)\n      quantized_x = floored_x + tf.cast(bernoulli, x.dtype)\n    else:  # Deterministic rounding.\n      quantized_x = tf.round(x)\n\n    encoded_tensors = {\n        self.ENCODED_VALUES_KEY: quantized_x,\n        self.MIN_MAX_VALUES_KEY: tf.stack([min_x, max_x])\n    }\n\n    return encoded_tensors\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands  # Unused.\n    quantized_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    min_max = encoded_tensors[self.MIN_MAX_VALUES_KEY]\n    min_x, max_x = min_max[0], min_max[1]\n    max_value = tf.cast(decode_params[self.MAX_INT_VALUE_PARAMS_KEY],\n                        quantized_x.dtype)\n\n    x = quantized_x / max_value * (max_x - min_x) + min_x\n\n    x = tf.reshape(x, shape)\n\n    return x\n\n\n@encoding_stage.tf_style_encoding_stage\nclass PerChannelPRNGUniformQuantizationEncodingStage(\n    encoding_stage.EncodingStageInterface):\n  """"""Encoding stage performing uniform quantization per channel in conv layers.\n\n  This encoding stage will first reshape the input `x` to `(-1, dim)`, where\n  `dim` is the size of the last dimension of `x`. Then each of the `dim`\n  vectors will be quantized independently, using PRNG uniform quantization.\n\n  PRNG uniform quantization uses a single integer seed as the same source of\n  randomness in encode and decode methods, in order to, in the decode method,\n  differently estimate the original values before encoding was applied.\n\n  This encoding stage does not require the shape of the input `x` to the\n  `encode` method to be statically known.\n\n  In particular, given a floating point input `x` to the `encode` method, the\n  output will have the same `dtype` as `x`, with values being ""floating point\n  integers"" in the range `[0, 2**bits-1]`.\n\n  The extreme points of the quantized interval will correspond to the min and\n  max values of the input `x`.\n\n  The output of the `decode` method is an unbiased estimation of the original\n  values before quantization, but note that it is possible for some of the\n  decoded values to be outside of the original range.\n  """"""\n\n  ENCODED_VALUES_KEY = \'quantized_values\'\n  MIN_MAX_VALUES_KEY = \'min_max\'\n  MAX_INT_VALUE_PARAMS_KEY = \'max_value\'\n  SEED_PARAMS_KEY = \'seed\'\n  # The allowed values for `bits` argument to initializer.\n  # We cap the allowed quantization bits at 16, as the randomized rounding could\n  # otherwise be numerically unstable for float32 values.\n  _ALLOWED_BITS_ARG = list(range(1, 17))\n\n  def __init__(self, bits=8):\n    """"""Initializer for the `PerChannelPRNGUniformQuantizationEncodingStage`.\n\n    Args:\n      bits: The number of bits to quantize to. Must be an integer between 1 and\n        16. Can be either a TensorFlow or a Python value.\n\n    Raises:\n      ValueError: The inputs do not satisfy the above constraints.\n    """"""\n    if (not tf.is_tensor(bits) and bits not in self._ALLOWED_BITS_ARG):\n      raise ValueError(\'The bits argument must be an integer between 1 and 16.\')\n    self._bits = bits\n\n  @property\n  def name(self):\n    """"""See base class.""""""\n    return \'per_channel_prng_uniform_quantization\'\n\n  @property\n  def compressible_tensors_keys(self):\n    """"""See base class.""""""\n    return [self.ENCODED_VALUES_KEY]\n\n  @property\n  def commutes_with_sum(self):\n    """"""See base class.""""""\n    return False\n\n  @property\n  def decode_needs_input_shape(self):\n    """"""See base class.""""""\n    return True\n\n  def get_params(self):\n    """"""See base class.""""""\n    params = {self.MAX_INT_VALUE_PARAMS_KEY: 2**self._bits - 1}\n    return params, params\n\n  def encode(self, x, encode_params):\n    """"""See base class.""""""\n    dim = tf.shape(x)[-1]\n    x = tf.reshape(x, [-1, dim])\n\n    # Per-channel min and max.\n    min_x = tf.reduce_min(x, axis=0)\n    max_x = tf.reduce_max(x, axis=0)\n\n    max_value = tf.cast(encode_params[self.MAX_INT_VALUE_PARAMS_KEY], x.dtype)\n    # Shift the values to range [0, max_value].\n    # In the case of min_x == max_x, this will return all zeros.\n    x = tf.compat.v1.div_no_nan(x - min_x, max_x - min_x) * max_value\n\n    # Randomized rounding.\n    floored_x = tf.floor(x)\n    random_seed = tf.random.uniform((2,), maxval=tf.int64.max, dtype=tf.int64)\n    num_elements = tf.reduce_prod(tf.shape(x))\n    rounding_floats = tf.reshape(\n        self._random_floats(num_elements, random_seed, x.dtype), tf.shape(x))\n\n    bernoulli = rounding_floats < (x - floored_x)\n    quantized_x = floored_x + tf.cast(bernoulli, x.dtype)\n\n    # Include the random seed in the encoded tensors so that it can be used to\n    # generate the same random sequence in the decode method.\n    encoded_tensors = {\n        self.ENCODED_VALUES_KEY: quantized_x,\n        self.SEED_PARAMS_KEY: random_seed,\n        self.MIN_MAX_VALUES_KEY: tf.stack([min_x, max_x])\n    }\n\n    return encoded_tensors\n\n  def decode(self,\n             encoded_tensors,\n             decode_params,\n             num_summands=None,\n             shape=None):\n    """"""See base class.""""""\n    del num_summands  # Unused.\n    quantized_x = encoded_tensors[self.ENCODED_VALUES_KEY]\n    random_seed = encoded_tensors[self.SEED_PARAMS_KEY]\n    min_max = encoded_tensors[self.MIN_MAX_VALUES_KEY]\n    min_x, max_x = min_max[0], min_max[1]\n    max_value = tf.cast(decode_params[self.MAX_INT_VALUE_PARAMS_KEY],\n                        quantized_x.dtype)\n\n    num_elements = tf.reduce_prod(tf.shape(quantized_x))\n    # The rounding_floats are identical to those used in the encode method.\n    rounding_floats = tf.reshape(\n        self._random_floats(num_elements, random_seed, min_x.dtype),\n        tf.shape(quantized_x))\n\n    # Regenerating the random values used in encode, enables us to determine a\n    # narrower range of possible original values, before quantization was\n    # applied. We shift the quantized values into the middle of this range,\n    # corresponding to the intersection of\n    # [quantized_x - 1 + rounding_floats, quantized_x + rounding_floats]\n    # in the quantized range. This shifted value can be out of the range\n    # [0, max_value] and therefore the decoded value can be out of the range\n    # [min_x, max_x], which is impossible, but it ensures that the decoded x\n    # is an unbiased estimator of the original values before quantization.\n    q_shifted = quantized_x + rounding_floats - 0.5\n\n    x = q_shifted / max_value * (max_x - min_x) + min_x\n\n    x = tf.reshape(x, shape)\n\n    return x\n\n  def _random_floats(self, num_elements, seed, dtype):\n    return tf_utils.random_floats(num_elements, seed, dtype)\n'"
tensorflow_model_optimization/python/core/internal/tensor_encoding/stages/research/quantization_test.py,40,"b'# Copyright 2019, The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.stages.research import quantization\nfrom tensorflow_model_optimization.python.core.internal.tensor_encoding.testing import test_utils\n\n\nif tf.executing_eagerly():\n  tf.compat.v1.disable_eager_execution()\n\n\nclass PRNGUniformQuantizationEncodingStageTest(test_utils.BaseEncodingStageTest\n                                              ):\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return quantization.PRNGUniformQuantizationEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([50], minval=-1.0, maxval=1.0)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self._assert_is_integer_float(data.encoded_x[\n        quantization.PRNGUniformQuantizationEncodingStage.ENCODED_VALUES_KEY])\n\n  def _assert_is_integer_float(self, quantized_vals):\n    """"""Asserts that float type values are integers.""""""\n    assert quantized_vals.dtype == np.float32\n    self.assertAllClose(quantized_vals,\n                        tf.cast(tf.cast(quantized_vals, np.int32), np.float32))\n\n  @parameterized.parameters(itertools.product([1, 2, 3, 4, 7, 8, 9, 16]))\n  def test_quantization_bits_stochastic_rounding(self, bits):\n    stage = quantization.PRNGUniformQuantizationEncodingStage(bits=bits)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        quantization.PRNGUniformQuantizationEncodingStage.ENCODED_VALUES_KEY])\n    # For stochastic rounding, the potential error incurred by quantization\n    # is bounded by the range of the input values divided by the number of\n    # quantization buckets.\n    self.assertAllClose(\n        test_data.x, test_data.decoded_x, rtol=0.0, atol=2 / (2**bits - 1))\n\n  def test_quantization_empirically_unbiased(self):\n    # Tests that the quantization ""seems"" to be unbiased.\n    # Executing the encoding and decoding many times, the average error should\n    # be a lot larger than the error of average decoded value.\n    x = tf.constant(np.random.rand((50)).astype(np.float32))\n    stage = quantization.PRNGUniformQuantizationEncodingStage(bits=2)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data_list = [self.evaluate_test_data(test_data) for _ in range(200)]\n\n    norm_errors = []\n    errors = []\n    for data in test_data_list:\n      norm_errors.append(np.linalg.norm(data.x - data.decoded_x))\n      errors.append(data.x - data.decoded_x)\n    mean_of_errors = np.mean(norm_errors)\n    error_of_mean = np.linalg.norm(np.mean(errors, axis=0))\n    self.assertGreater(mean_of_errors, error_of_mean * 10)\n\n  @parameterized.parameters(itertools.product([tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype):\n    # Tests combinations of input dtypes.\n    stage = quantization.PRNGUniformQuantizationEncodingStage(bits=8)\n    x = tf.random.normal([50], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n  def test_all_zero_input_works(self):\n    # Tests that encoding does not blow up with all-zero input. With\n    # min_max=None, the derived min and max are identical, thus potential for\n    # division by zero.\n    stage = quantization.PRNGUniformQuantizationEncodingStage(bits=8)\n    test_data = self.run_one_to_many_encode_decode(\n        stage, lambda: tf.zeros([50]))\n    self.assertAllEqual(np.zeros((50)).astype(np.float32), test_data.decoded_x)\n\n  @parameterized.parameters([0, 17, -1, 1.5])\n  def test_bits_out_of_range_raises(self, bits):\n    with self.assertRaisesRegexp(ValueError, \'integer between 1 and 16\'):\n      quantization.PRNGUniformQuantizationEncodingStage(bits=bits)\n\n  def test_dynamic_input_shape(self):\n    # Tests that encoding works when the input shape is not statically known.\n    stage = quantization.PRNGUniformQuantizationEncodingStage(bits=8)\n    shape = [10, 5, 7]\n    prob = [0.5, 0.8, 0.6]\n    original_x = tf.random.uniform(shape, dtype=tf.float32)\n    rand = [tf.random.uniform([shape[i],]) for i in range(3)]\n    sample_indices = [\n        tf.reshape(tf.where(rand[i] < prob[i]), [-1]) for i in range(3)\n    ]\n    x = tf.gather(original_x, sample_indices[0], axis=0)\n    x = tf.gather(x, sample_indices[1], axis=1)\n    x = tf.gather(x, sample_indices[2], axis=2)\n\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n\nclass PerChannelUniformQuantizationEncodingStageTest(\n    test_utils.BaseEncodingStageTest):\n  """"""Test for PerChannelUniformQuantizationEncodingStage.""""""\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return quantization.PerChannelUniformQuantizationEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([50], minval=-1.0, maxval=1.0)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self._assert_is_integer_float(\n        data.encoded_x[quantization.PerChannelUniformQuantizationEncodingStage\n                       .ENCODED_VALUES_KEY])\n\n  def _assert_is_integer_float(self, quantized_vals):\n    """"""Asserts that float type values are integers.""""""\n    assert quantized_vals.dtype == np.float32\n    self.assertAllClose(quantized_vals,\n                        tf.cast(tf.cast(quantized_vals, np.int32), np.float32))\n\n  @parameterized.parameters(itertools.product([1, 2, 3, 4, 7, 8, 9, 16]))\n  def test_quantization_bits_stochastic_rounding(self, bits):\n    stage = quantization.PerChannelUniformQuantizationEncodingStage(\n        bits=bits, stochastic=True)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        quantization.PerChannelUniformQuantizationEncodingStage\n        .ENCODED_VALUES_KEY])\n    # For stochastic rounding, the potential error incurred by quantization\n    # is bounded by the range of the input values divided by the number of\n    # quantization buckets.\n    self.assertAllClose(\n        test_data.x, test_data.decoded_x, rtol=0.0, atol=2 / (2**bits - 1))\n\n  @parameterized.parameters(itertools.product([1, 2, 3, 4, 7, 8, 9, 16]))\n  def test_quantization_bits_deterministic_rounding(self, bits):\n    stage = quantization.PerChannelUniformQuantizationEncodingStage(\n        bits=bits, stochastic=False)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        quantization.PerChannelUniformQuantizationEncodingStage\n        .ENCODED_VALUES_KEY])\n    # For deterministic rounding, the potential error incurred by quantization\n    # is bounded by half of the range of the input values divided by the number\n    # of quantization buckets.\n    self.assertAllClose(\n        test_data.x, test_data.decoded_x, rtol=0.0, atol=1 / (2**bits - 1))\n\n  def test_quantization_empirically_unbiased(self):\n    # Tests that the quantization with stochastic=True ""seems"" to be unbiased.\n    # Executing the encoding and decoding many times, the average error should\n    # be a lot larger than the error of average decoded value.\n    x = tf.constant(np.random.rand((50)).astype(np.float32))\n    stage = quantization.PerChannelUniformQuantizationEncodingStage(\n        bits=2, stochastic=True)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data_list = [self.evaluate_test_data(test_data) for _ in range(200)]\n\n    norm_errors = []\n    errors = []\n    for data in test_data_list:\n      norm_errors.append(np.linalg.norm(data.x - data.decoded_x))\n      errors.append(data.x - data.decoded_x)\n    mean_of_errors = np.mean(norm_errors)\n    error_of_mean = np.linalg.norm(np.mean(errors, axis=0))\n    self.assertGreaterEqual(mean_of_errors, error_of_mean * 10)\n\n  def test_all_zero_input_works(self):\n    # Tests that encoding does not blow up with all-zero input. With\n    # min_max=None, the derived min and max are identical, thus potential for\n    # division by zero.\n    stage = quantization.PerChannelUniformQuantizationEncodingStage(bits=8)\n    test_data = self.run_one_to_many_encode_decode(stage,\n                                                   lambda: tf.zeros([50]))\n    self.assertAllEqual(np.zeros((50)).astype(np.float32), test_data.decoded_x)\n\n  @parameterized.parameters([0, 17, -1, 1.5])\n  def test_bits_out_of_range_raises(self, bits):\n    with self.assertRaisesRegexp(ValueError, \'integer between 1 and 16\'):\n      quantization.PerChannelUniformQuantizationEncodingStage(bits=bits)\n\n  def test_stochastic_tensor_raises(self):\n    with self.assertRaisesRegexp(TypeError, \'stochastic\'):\n      quantization.PerChannelUniformQuantizationEncodingStage(\n          stochastic=tf.constant(True, dtype=tf.bool))\n\n  def test_dynamic_input_shape(self):\n    # Tests that encoding works when the input shape is not statically known.\n    stage = quantization.PerChannelUniformQuantizationEncodingStage(bits=8)\n    shape = [10, 5, 7]\n    prob = [0.5, 0.8, 0.6]\n    original_x = tf.compat.v1.random.poisson(1.5, shape, dtype=tf.float32)\n    rand = [tf.random.uniform([\n        shape[i],\n    ], dtype=tf.float32) for i in range(3)]\n    sample_indices = [\n        tf.reshape(tf.where(rand[i] < prob[i]), [-1]) for i in range(3)\n    ]\n    x = tf.gather(original_x, sample_indices[0], axis=0)\n    x = tf.gather(x, sample_indices[1], axis=1)\n    x = tf.gather(x, sample_indices[2], axis=2)\n\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n\nclass PerChannelPRNGUniformQuantizationEncodingStageTest(\n    test_utils.BaseEncodingStageTest):\n  """"""Test for PerChannelPRNGUniformQuantizationEncodingStage.""""""\n\n  def default_encoding_stage(self):\n    """"""See base class.""""""\n    return quantization.PerChannelPRNGUniformQuantizationEncodingStage()\n\n  def default_input(self):\n    """"""See base class.""""""\n    return tf.random.uniform([50], minval=-1.0, maxval=1.0)\n\n  @property\n  def is_lossless(self):\n    """"""See base class.""""""\n    return False\n\n  def common_asserts_for_test_data(self, data):\n    """"""See base class.""""""\n    self._assert_is_integer_float(data.encoded_x[\n        quantization.PerChannelPRNGUniformQuantizationEncodingStage\n        .ENCODED_VALUES_KEY])\n\n  def _assert_is_integer_float(self, quantized_vals):\n    """"""Asserts that float type values are integers.""""""\n    assert quantized_vals.dtype == np.float32\n    self.assertAllClose(quantized_vals,\n                        tf.cast(tf.cast(quantized_vals, np.int32), np.float32))\n\n  @parameterized.parameters(itertools.product([1, 2, 3, 4, 7, 8, 9, 16]))\n  def test_quantization_bits_stochastic_rounding(self, bits):\n    stage = quantization.PerChannelPRNGUniformQuantizationEncodingStage(\n        bits=bits)\n    test_data = self.run_one_to_many_encode_decode(stage, self.default_input)\n    self._assert_is_integer_float(test_data.encoded_x[\n        quantization.PerChannelPRNGUniformQuantizationEncodingStage\n        .ENCODED_VALUES_KEY])\n    # For stochastic rounding, the potential error incurred by quantization\n    # is bounded by the range of the input values divided by the number of\n    # quantization buckets.\n    self.assertAllClose(\n        test_data.x, test_data.decoded_x, rtol=0.0, atol=2 / (2**bits - 1))\n\n  def test_quantization_empirically_unbiased(self):\n    # Tests that the quantization ""seems"" to be unbiased.\n    # Executing the encoding and decoding many times, the average error should\n    # be a lot larger than the error of average decoded value.\n    x = tf.constant(np.random.rand((50)).astype(np.float32))\n    stage = quantization.PerChannelPRNGUniformQuantizationEncodingStage(bits=2)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data_list = [self.evaluate_test_data(test_data) for _ in range(200)]\n\n    norm_errors = []\n    errors = []\n    for data in test_data_list:\n      norm_errors.append(np.linalg.norm(data.x - data.decoded_x))\n      errors.append(data.x - data.decoded_x)\n    mean_of_errors = np.mean(norm_errors)\n    error_of_mean = np.linalg.norm(np.mean(errors, axis=0))\n    self.assertGreaterEqual(mean_of_errors, error_of_mean * 10)\n\n  @parameterized.parameters(itertools.product([tf.float32, tf.float64]))\n  def test_input_types(self, x_dtype):\n    # Tests combinations of input dtypes.\n    stage = quantization.PerChannelPRNGUniformQuantizationEncodingStage(bits=8)\n    x = tf.random.normal([50], dtype=x_dtype)\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n  def test_all_zero_input_works(self):\n    # Tests that encoding does not blow up with all-zero input. With\n    # min_max=None, the derived min and max are identical, thus potential for\n    # division by zero.\n    stage = quantization.PerChannelPRNGUniformQuantizationEncodingStage(bits=8)\n    test_data = self.run_one_to_many_encode_decode(stage,\n                                                   lambda: tf.zeros([50]))\n    self.assertAllEqual(np.zeros((50)).astype(np.float32), test_data.decoded_x)\n\n  @parameterized.parameters([0, 17, -1, 1.5])\n  def test_bits_out_of_range_raises(self, bits):\n    with self.assertRaisesRegexp(ValueError, \'integer between 1 and 16\'):\n      quantization.PerChannelPRNGUniformQuantizationEncodingStage(bits=bits)\n\n  def test_dynamic_input_shape(self):\n    # Tests that encoding works when the input shape is not statically known.\n    stage = quantization.PerChannelPRNGUniformQuantizationEncodingStage(bits=8)\n    shape = [10, 5, 7]\n    prob = [0.5, 0.8, 0.6]\n    original_x = tf.compat.v1.random.poisson(1.5, shape, dtype=tf.float32)\n    rand = [tf.random.uniform([\n        shape[i],\n    ], dtype=tf.float32) for i in range(3)]\n    sample_indices = [\n        tf.reshape(tf.where(rand[i] < prob[i]), [-1]) for i in range(3)\n    ]\n    x = tf.gather(original_x, sample_indices[0], axis=0)\n    x = tf.gather(x, sample_indices[1], axis=1)\n    x = tf.gather(x, sample_indices[2], axis=2)\n\n    encode_params, decode_params = stage.get_params()\n    encoded_x, decoded_x = self.encode_decode_x(stage, x, encode_params,\n                                                decode_params)\n    test_data = test_utils.TestData(x, encoded_x, decoded_x)\n    test_data = self.evaluate_test_data(test_data)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
