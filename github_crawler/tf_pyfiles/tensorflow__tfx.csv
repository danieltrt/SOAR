file_path,api_count,code
conftest.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Settings for pytest.""""""\n\nimport sys\n\ncollect_ignore = []\nif sys.version_info.major == 2:\n  collect_ignore.append(\n      \'tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_test.py\')\n  collect_ignore.append(\'tfx/orchestration/kubeflow\')\n'"
setup.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package Setup script for TFX.""""""\n\nfrom __future__ import print_function\n\nfrom distutils import spawn\nimport glob\nimport os\nimport subprocess\nimport sys\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nfrom tfx import dependencies\nfrom tfx import version\n\n\n# Find the Protocol Compiler.\nif \'PROTOC\' in os.environ and os.path.exists(os.environ[\'PROTOC\']):\n  protoc = os.environ[\'PROTOC\']\nelif os.path.exists(\'../src/protoc\'):\n  protoc = \'../src/protoc\'\nelif os.path.exists(\'../src/protoc.exe\'):\n  protoc = \'../src/protoc.exe\'\nelif os.path.exists(\'../vsprojects/Debug/protoc.exe\'):\n  protoc = \'../vsprojects/Debug/protoc.exe\'\nelif os.path.exists(\'../vsprojects/Release/protoc.exe\'):\n  protoc = \'../vsprojects/Release/protoc.exe\'\nelse:\n  protoc = spawn.find_executable(\'protoc\')\n\n\ndef generate_proto(source):\n  """"""Invokes the Protocol Compiler to generate a _pb2.py.""""""\n\n  output = source.replace(\'.proto\', \'_pb2.py\')\n\n  if (not os.path.exists(output) or\n      (os.path.exists(source) and\n       os.path.getmtime(source) > os.path.getmtime(output))):\n    print(\'Generating %s...\' % output)\n\n    if not os.path.exists(source):\n      sys.stderr.write(\'Cannot find required file: %s\\n\' % source)\n      sys.exit(-1)\n\n    if protoc is None:\n      sys.stderr.write(\n          \'protoc is not installed nor found in ../src.  Please compile it \'\n          \'or install the binary package.\\n\')\n      sys.exit(-1)\n\n    protoc_command = [protoc, \'-I.\', \'--python_out=.\', source]\n    if subprocess.call(protoc_command) != 0:\n      sys.exit(-1)\n\n\n_PROTO_FILE_PATTERNS = [\n    \'tfx/proto/*.proto\',\n    \'tfx/orchestration/kubeflow/proto/*.proto\',\n]\n\nfor file_pattern in _PROTO_FILE_PATTERNS:\n  for proto_file in glob.glob(file_pattern):\n    generate_proto(proto_file)\n\n# Get the long description from the README file.\nwith open(\'README.md\') as fp:\n  _LONG_DESCRIPTION = fp.read()\n\n\nsetup(\n    name=\'tfx\',\n    version=version.__version__,\n    author=\'Google LLC\',\n    author_email=\'tensorflow-extended-dev@googlegroups.com\',\n    license=\'Apache 2.0\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3 :: Only\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development\',\n        \'Topic :: Software Development :: Libraries\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n    ],\n    namespace_packages=[],\n    install_requires=dependencies.make_required_install_packages(),\n    extras_require={\n        # In order to use \'docker-image\' or \'all\', system libraries specified\n        # under \'tfx/tools/docker/Dockerfile\' are required\n        \'docker-image\': dependencies.make_extra_packages_docker_image(),\n        \'tfjs\': dependencies.make_extra_packages_tfjs(),\n        \'all\': dependencies.make_all_dependency_packages(),\n    },\n    setup_requires=[\'pytest-runner\'],\n    python_requires=\'>=3.5,<4\',\n    packages=find_packages(),\n    include_package_data=True,\n    description=\'TensorFlow Extended (TFX) is a TensorFlow-based general-purpose machine learning platform implemented at Google\',\n    long_description=_LONG_DESCRIPTION,\n    long_description_content_type=\'text/markdown\',\n    keywords=\'tensorflow tfx\',\n    url=\'https://www.tensorflow.org/tfx\',\n    download_url=\'https://github.com/tensorflow/tfx/tags\',\n    requires=[],\n    # Below console_scripts, each line identifies one console script. The first\n    # part before the equals sign (=) which is \'tfx\', is the name of the script\n    # that should be generated, the second part is the import path followed by a\n    # colon (:) with the Click command group. After installation, the user can\n    # invoke the CLI using ""tfx <command_group> <sub_command> <flags>""\n    entry_points=""""""\n        [console_scripts]\n        tfx=tfx.tools.cli.cli_main:cli_group\n    """""")\n\n'"
tfx/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Init module for TFX.""""""\n\n# Import version string.\nfrom tfx.version import __version__\n'"
tfx/dependencies.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package dependencies for TFX.""""""\n\n\ndef make_required_install_packages():\n  # Make sure to sync the versions of common dependencies (absl-py, numpy,\n  # six, and protobuf) with TF.\n  # TODO(b/130767399): add flask once the frontend is exposed externally.\n  return [\n      \'absl-py>=0.1.6,<0.9\',\n      # LINT.IfChange\n      \'apache-beam[gcp]>=2.21,<3\',\n      # LINT.ThenChange(examples/chicago_taxi_pipeline/setup/setup_beam.sh)\n      # TODO(b/149399451): remove once avro has a healthy release.\n      (\'avro-python3>=1.8.1,!=1.9.2.*,<2.0.0; \'\n       \'python_version==""3.5"" and platform_system==""Darwin""\'),\n      \'click>=7,<8\',\n      \'docker>=4.1,<5\',\n      \'google-api-python-client>=1.7.8,<2\',\n      \'grpcio>=1.28.1,<2\',\n      \'jinja2>=2.7.3,<3\',\n      \'keras-tuner>=1,<2\',\n      \'kubernetes>=10.0.1,<12\',\n      # LINT.IfChange\n      \'ml-metadata>=0.22,<0.23\',\n      # LINT.ThenChange(//tfx/workspace.bzl)\n      \'protobuf>=3.7,<4\',\n      \'pyarrow>=0.16,<0.17\',\n      \'pyyaml>=3.12,<6\',\n      \'six>=1.10,<2\',\n      \'tensorflow>=1.15,!=2.0.*,<3\',\n      \'tensorflow-data-validation>=0.22,<0.23\',\n      \'tensorflow-model-analysis>=0.22.1,<0.23\',\n      \'tensorflow-serving-api>=1.15,<3\',\n      \'tensorflow-transform>=0.22,<0.23\',\n      \'tfx-bsl>=0.22,<0.23\',\n  ]\n\n\ndef make_required_test_packages():\n  """"""Prepare extra packages needed for running unit tests.""""""\n  # Note: It is okay to pin packages to exact verions in this list to minimize\n  # conflicts.\n  return [\n      \'apache-airflow[mysql]>=1.10.10,<2\',\n      # TODO(b/157208532): Remove pinned version of Werkzeug when we don\'t\n      # support Python 3.5.\n      \'Werkzeug==0.16.1; python_version == ""3.5""\',\n      # TODO(b/157033885): Remove pinned version of WTForms after newer version\n      # of Apache Airflow.\n      \'WTForms==2.2.1\',\n      \'kfp>=0.4,<0.5\',\n      \'pytest>=5,<6\',\n  ]\n\n\ndef make_extra_packages_docker_image():\n  # Packages needed for tfx docker image.\n  return [\n      \'python-snappy>=0.5,<0.6\',\n  ]\n\n\ndef make_extra_packages_tfjs():\n  # Packages needed for tfjs.\n  return [\n      \'tensorflowjs>=1.7.3,<2\',\n      # TODO(b/158034704): Remove prompt-toolkit pin resulted from\n      # tfjs -> PyInquirer dependency chain.\n      \'prompt-toolkit>=2.0.10,<3\',\n  ]\n\n\ndef make_all_dependency_packages():\n  # All extra dependencies.\n  return make_required_test_packages() + make_extra_packages_tfjs()\n'"
tfx/version.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Contains the version string of TFX.""""""\n\n# Note that setup.py uses this version.\n__version__ = \'0.23.0.dev\'\n'"
tfx/benchmarks/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/benchmarks/benchmark_base.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for benchmarks.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import flags\nimport apache_beam as beam\nfrom tensorflow.python.platform import test  # pylint: disable=g-direct-tensorflow-import\n\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\n    ""beam_runner"", ""DirectRunner"",\n    ""Beam runner to use - any runner name accepted by ""\n    ""apache_beam.runners.create_runner"")\n\n\nclass BenchmarkBase(test.Benchmark):\n\n  def _create_beam_pipeline(self):\n    return beam.Pipeline(runner=beam.runners.create_runner(FLAGS.beam_runner))\n'"
tfx/benchmarks/benchmark_dataset.py,12,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for classes representing a dataset for the benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\n\nclass BenchmarkDataset(object):\n  """"""Base class for classes representing a dataset for the benchmark.""""""\n\n  def __init__(self, base_dir=None):\n    """"""Construct a dataset instance.\n\n    Args:\n      base_dir: The directory in which datasets artifacts are located. This will\n        be used for reading during benchmark execution, as well as writing\n        during benchmark regeneration. By default, the directory in which this\n        file is located at runtime will be used to infer the location of\n        `tfx/benchmarks/datasets`.\n    """"""\n    self._base_dir = (\n        base_dir if base_dir else os.path.join(\n            os.path.dirname(__file__), ""datasets""))\n\n  def datasets_dir(self, subdir=""""):\n    """"""Returns the path to the datasets directory.\n\n    Args:\n      subdir: Subdirectory to join at the end of the datasets directory.\n\n    Returns:\n      The path to the datasets directory, with the subdir joined at the end.\n    """"""\n    return os.path.join(self._base_dir, subdir)\n\n  def dataset_path(self):\n    """"""Returns the path to the dataset file.""""""\n    raise NotImplementedError()\n\n  def tf_metadata_schema_path(self):\n    """"""Returns the path to the tf.Metadata schema file.""""""\n    raise NotImplementedError()\n\n  def trained_saved_model_path(self):\n    """"""Returns the path to the inference format SavedModel.""""""\n    raise NotImplementedError()\n\n  def tft_saved_model_path(self):\n    """"""Returns the path to the tf.Transform SavedModel.""""""\n    raise NotImplementedError()\n\n  def tfma_saved_model_path(self):\n    """"""Returns the path to the tf.ModelAnalysis SavedModel.""""""\n    raise NotImplementedError()\n\n  def num_examples(self, limit=None):\n    """"""Returns the number of examples in the dataset.\n\n    Args:\n      limit: If set, returns min(limit, number of examples in dataset).\n\n    Returns:\n      The number of examples in the dataset.\n    """"""\n    raise NotImplementedError()\n\n  def read_raw_dataset(self, deserialize=True, limit=None):\n    """"""Read the raw dataset of tf.train.Examples.\n\n    Args:\n      deserialize: If False, return the raw serialized bytes. If True, return\n        the tf.train.Example parsed from the serialized bytes.\n      limit: If set, yields no more than the given number of examples (might be\n        less if the dataset has less examples than the limit).\n\n    Yields:\n      Serialized/unserialized (depending on deserialize) tf.train.Examples.\n    """"""\n    for count, example_bytes in enumerate(\n        tf.compat.v1.io.tf_record_iterator(\n            self.dataset_path(),\n            tf.compat.v1.io.TFRecordOptions(\n                tf.compat.v1.io.TFRecordCompressionType.GZIP))):\n      if limit and count >= limit:\n        break\n      if not deserialize:\n        yield example_bytes\n      else:\n        yield tf.train.Example().FromString(example_bytes)\n\n  def generate_raw_dataset(self, args):\n    """"""Generate the raw dataset.\n\n    Args:\n      args: String of extra arguments to use when generating the raw dataset.\n    """"""\n    raise NotImplementedError()\n\n  def generate_models(self, args):\n    """"""Generate the inference and tf.ModelAnalysis format SavedModels.\n\n    This is usually done by running a Trainer on the raw dataset and exporting\n    the inference and tf.ModelAnalysis format SavedModels.\n\n    Args:\n      args: String of extra arguments to use when generating the models.\n    """"""\n    raise NotImplementedError()\n'"
tfx/benchmarks/benchmark_utils.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utility functions shared across the different benchmarks.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\nfrom google.protobuf import text_format\nfrom tensorflow_metadata.proto.v0 import schema_pb2\n\n\ndef read_schema(proto_path):\n  """"""Reads a TF Metadata schema from the given text proto file.""""""\n  result = schema_pb2.Schema()\n  with open(proto_path) as fp:\n    text_format.Parse(fp.read(), result)\n  return result\n\n\ndef get_dataset(name, base_dir=None):\n  """"""Imports the given dataset and returns an instance of it.""""""\n  lib = importlib.import_module(""..datasets.%s.dataset"" % name, __name__)\n  return lib.get_dataset(base_dir)\n\n\ndef batched_iterator(records, batch_size):\n  """"""Groups elements in the given list into batches of the given size.\n\n  Args:\n    records: List of elements to batch.\n    batch_size: Size of each batch.\n\n  Yields:\n    Lists with batch_size elements from records. Every list yielded except the\n    last will contain exactly batch_size elements.\n  """"""\n  batch = []\n  for i, x in enumerate(records):\n    batch.append(x)\n    if (i + 1) % batch_size == 0:\n      yield batch\n      batch = []\n  if batch:\n    yield batch\n'"
tfx/benchmarks/regenerate_datasets.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tool to regenerate datasets used in benchmarks.""""""\n\n# Standard Imports\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\n\nfrom tfx.benchmarks import benchmark_utils\nfrom tfx.benchmarks import tft_benchmark_base\n\nFLAGS = flags.FLAGS\n\n\ndef main(argv):\n  del argv\n  dataset = benchmark_utils.get_dataset(FLAGS.dataset,\n                                        base_dir=FLAGS.output_base_dir)\n\n  # Regenerate the dataset and models.\n  logging.info(""Using dataset: %s"", FLAGS.dataset)\n  logging.info(""Generating raw dataset"")\n  dataset.generate_raw_dataset(args=FLAGS.generate_dataset_args)\n  logging.info(""Generating models"")\n  dataset.generate_models(args=FLAGS.generate_dataset_args)\n\n  # Regenerate intermediate outputs for TFT benchmarks.\n  logging.info(""Generating intermediate outputs for TFT benchmarks"")\n  tft_benchmark_base.regenerate_intermediates_for_dataset(dataset)\n\n\nif __name__ == ""__main__"":\n  flags.DEFINE_string(""dataset"", ""chicago_taxi"", ""Dataset to run on."")\n  flags.DEFINE_string(""output_base_dir"", """", ""Base directory under which to ""\n                      ""write generated Dataset artifacts."")\n  flags.DEFINE_string(\n      ""generate_dataset_args"", """",\n      ""Arguments to pass to the dataset when regenerating the raw dataset or ""\n      ""the models."")\n  app.run(main)\n'"
tfx/benchmarks/tfma_benchmark_base.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFMA benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\n\n# Standard Imports\n\nimport apache_beam as beam\nimport tensorflow_model_analysis as tfma\nfrom tensorflow_model_analysis.eval_saved_model import load\n\nimport tfx\nfrom tfx.benchmarks import benchmark_utils\nfrom tfx.benchmarks import benchmark_base\n\n# Maximum number of examples to read from the dataset.\n# TFMA is much slower than TFT, so we may have to read a smaller subset of the\n# dataset.\nMAX_NUM_EXAMPLES = 100000\n\n\nclass TFMABenchmarkBase(benchmark_base.BenchmarkBase):\n  """"""TFMA benchmark base class.""""""\n\n  def __init__(self, dataset, **kwargs):\n    # Benchmark runners may pass extraneous arguments we don\'t care about.\n    del kwargs\n    super(TFMABenchmarkBase, self).__init__()\n    self._dataset = dataset\n\n  def report_benchmark(self, **kwargs):\n    if ""extras"" not in kwargs:\n      kwargs[""extras""] = {}\n    # Note that the GIT_COMMIT_ID is not included in the packages themselves:\n    # it must be injected by an external script.\n    kwargs[""extras""][""commit_tfx""] = getattr(tfx, ""GIT_COMMIT_ID"",\n                                             tfx.__version__)\n    kwargs[""extras""][""commit_tfma""] = getattr(tfma, ""GIT_COMMIT_ID"",\n                                              tfma.__version__)\n    super(TFMABenchmarkBase, self).report_benchmark(**kwargs)\n\n  def benchmarkMiniPipeline(self):\n    """"""Benchmark a ""mini"" version of TFMA - predict, slice and compute metrics.\n\n    Runs a ""mini"" version of TFMA in a Beam pipeline. Records the wall time\n    taken for the whole pipeline.\n    """"""\n    pipeline = self._create_beam_pipeline()\n    raw_data = (\n        pipeline\n        | ""Examples"" >> beam.Create(\n            self._dataset.read_raw_dataset(\n                deserialize=False, limit=MAX_NUM_EXAMPLES))\n        | ""InputsToExtracts"" >> tfma.InputsToExtracts())\n\n    eval_shared_model = tfma.default_eval_shared_model(\n        eval_saved_model_path=self._dataset.tfma_saved_model_path())\n\n    _ = (\n        raw_data\n        | ""PredictExtractor"" >> tfma.extractors.PredictExtractor(\n            eval_shared_model=eval_shared_model).ptransform\n        | ""SliceKeyExtractor"" >> tfma.extractors.SliceKeyExtractor().ptransform\n        | ""ComputeMetricsAndPlots"" >> tfma.evaluators.MetricsAndPlotsEvaluator(\n            eval_shared_model=eval_shared_model).ptransform)\n\n    start = time.time()\n    result = pipeline.run()\n    result.wait_until_finish()\n    end = time.time()\n    delta = end - start\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def benchmarkPredict(self):\n    """"""Benchmark the predict and aggregate combine stages ""manually"".\n\n    Runs _TFMAPredictionDoFn ""manually"" outside a Beam pipeline. Records the\n    wall time taken.\n    """"""\n    # Run InputsToExtracts manually.\n    records = []\n    for x in self._dataset.read_raw_dataset(\n        deserialize=False, limit=MAX_NUM_EXAMPLES):\n      records.append({tfma.constants.INPUT_KEY: x})\n\n    fn = tfma.extractors.predict_extractor._TFMAPredictionDoFn(  # pylint: disable=protected-access\n        eval_shared_models={"""": tfma.default_eval_shared_model(\n            eval_saved_model_path=self._dataset.tfma_saved_model_path())},\n        eval_config=None)\n    fn.setup()\n\n    # Predict\n    predict_batch_size = 1000\n    predict_result = []\n    start = time.time()\n    for batch in benchmark_utils.batched_iterator(records, predict_batch_size):\n      predict_result.extend(fn.process(batch))\n    end = time.time()\n    delta = end - start\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""batch_size"": predict_batch_size,\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def benchmarkAggregateCombineManualActuation(self):\n    """"""Benchmark the aggregate combine stage ""manually"".\n\n    Runs _AggregateCombineFn ""manually"" outside a Beam pipeline. Records the\n    wall time taken.\n    """"""\n\n    # Run InputsToExtracts manually.\n    records = []\n    for x in self._dataset.read_raw_dataset(\n        deserialize=False, limit=MAX_NUM_EXAMPLES):\n      records.append({tfma.constants.INPUT_KEY: x})\n\n    fn = tfma.extractors.predict_extractor._TFMAPredictionDoFn(  # pylint: disable=protected-access\n        eval_shared_models={"""": tfma.default_eval_shared_model(\n            eval_saved_model_path=self._dataset.tfma_saved_model_path())},\n        eval_config=None)\n    fn.setup()\n\n    # Predict\n    predict_batch_size = 1000\n    predict_result = []\n    for batch in benchmark_utils.batched_iterator(records, predict_batch_size):\n      predict_result.extend(fn.process(batch))\n\n    # AggregateCombineFn\n    #\n    # We simulate accumulating records into multiple different accumulators,\n    # each with inputs_per_accumulator records, and then merging the resulting\n    # accumulators together at one go.\n\n    # Number of elements to feed into a single accumulator.\n    # (This means we will have len(records) / inputs_per_accumulator\n    # accumulators to merge).\n    inputs_per_accumulator = 1000\n\n    combiner = tfma.evaluators.aggregate._AggregateCombineFn(  # pylint: disable=protected-access\n        eval_shared_model=tfma.default_eval_shared_model(\n            eval_saved_model_path=self._dataset.tfma_saved_model_path()))\n    accumulators = []\n\n    start = time.time()\n    for batch in benchmark_utils.batched_iterator(predict_result,\n                                                  inputs_per_accumulator):\n      accumulator = combiner.create_accumulator()\n      for elem in batch:\n        combiner.add_input(accumulator, elem)\n      accumulators.append(accumulator)\n    final_accumulator = combiner.merge_accumulators(accumulators)\n    final_output = combiner.extract_output(final_accumulator)\n    end = time.time()\n    delta = end - start\n\n    # Extract output to sanity check example count. This is not timed.\n    extract_fn = tfma.evaluators.aggregate._ExtractOutputDoFn(  # pylint: disable=protected-access\n        eval_shared_model=tfma.default_eval_shared_model(\n            eval_saved_model_path=self._dataset.tfma_saved_model_path()))\n    extract_fn.setup()\n    interpreted_output = list(extract_fn.process(((), final_output)))\n    if len(interpreted_output) != 1:\n      raise ValueError(""expecting exactly 1 interpreted output, got %d"" %\n                       (len(interpreted_output)))\n    got_example_count = interpreted_output[0][1].get(\n        ""post_export_metrics/example_count"")\n    if got_example_count != self._dataset.num_examples(limit=MAX_NUM_EXAMPLES):\n      raise ValueError(""example count mismatch: expecting %d got %d"" %\n                       (self._dataset.num_examples(limit=MAX_NUM_EXAMPLES),\n                        got_example_count))\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""inputs_per_accumulator"": inputs_per_accumulator,\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def benchmarkEvalSavedModelPredict(self):\n    """"""Benchmark using the EvalSavedModel to make predictions.\n\n    Runs EvalSavedModel.predict_list and records the wall time taken.\n    """"""\n    batch_size = 1000\n\n    eval_saved_model = load.EvalSavedModel(\n        path=self._dataset.tfma_saved_model_path(),\n        include_default_metrics=True)\n\n    records = self._dataset.read_raw_dataset(\n        deserialize=False, limit=MAX_NUM_EXAMPLES)\n\n    start = time.time()\n    for batch in benchmark_utils.batched_iterator(records, batch_size):\n      eval_saved_model.predict_list(batch)\n    end = time.time()\n    delta = end - start\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""batch_size"": batch_size,\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def benchmarkEvalSavedModelMetricsResetUpdateGetList(self):\n    """"""Benchmark using the EvalSavedModel to compute metrics.\n\n    Runs EvalSavedModel.metrics_reset_update_get_list and records the wall time\n    taken.\n    """"""\n    batch_size = 1000\n\n    eval_saved_model = load.EvalSavedModel(\n        path=self._dataset.tfma_saved_model_path(),\n        include_default_metrics=True)\n\n    records = self._dataset.read_raw_dataset(\n        deserialize=False, limit=MAX_NUM_EXAMPLES)\n\n    start = time.time()\n    accumulators = []\n    for batch in benchmark_utils.batched_iterator(records, batch_size):\n      accumulators.append(eval_saved_model.metrics_reset_update_get_list(batch))\n    end = time.time()\n    delta = end - start\n\n    # Sanity check\n    metric_variables_sum = accumulators[0]\n    for acc in accumulators[1:]:\n      if len(metric_variables_sum) != len(acc):\n        raise ValueError(\n            ""all metric variable value lists should have the same length, but ""\n            ""got lists with different lengths: %d and %d"" %\n            (len(metric_variables_sum), len(acc)))\n      metric_variables_sum = [a + b for a, b in zip(metric_variables_sum, acc)]\n\n    metrics = eval_saved_model.metrics_set_variables_and_get_values(\n        metric_variables_sum)\n    if ""average_loss"" not in metrics:\n      raise ValueError(\n          ""metrics should contain average_loss metric, but it did not. ""\n          ""metrics were: %s"" % metrics)\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""batch_size"": batch_size,\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n'"
tfx/benchmarks/tfma_benchmark_chicago_taxi.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFMA benchmark for Chicago Taxi dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.platform import test  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.benchmarks import tfma_benchmark_base\nfrom tfx.benchmarks.datasets.chicago_taxi import dataset\n\n\nclass TFMABenchmarkChicagoTaxi(tfma_benchmark_base.TFMABenchmarkBase):\n\n  def __init__(self, **kwargs):\n    super(TFMABenchmarkChicagoTaxi, self).__init__(\n        dataset=dataset.get_dataset(), **kwargs)\n\n\nif __name__ == ""__main__"":\n  test.main()\n'"
tfx/benchmarks/tfma_v2_benchmark_base.py,7,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFMA v2 benchmark.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\n\n# Standard Imports\n\nimport apache_beam as beam\n\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nfrom tensorflow_model_analysis import constants\nfrom tensorflow_model_analysis.evaluators import metrics_and_plots_evaluator_v2\nfrom tensorflow_model_analysis.extractors import batched_input_extractor\nfrom tensorflow_model_analysis.extractors import batched_predict_extractor_v2\nfrom tensorflow_model_analysis.extractors import input_extractor\nfrom tensorflow_model_analysis.extractors import predict_extractor_v2\nfrom tensorflow_model_analysis.extractors import unbatch_extractor\nfrom tensorflow_model_analysis.metrics import metric_specs\nfrom tensorflow_model_analysis.metrics import metric_types\nfrom tfx_bsl.tfxio import test_util\n\nimport tfx\nfrom tfx.benchmarks import benchmark_utils\nfrom tfx.benchmarks import benchmark_base\n\n# Maximum number of examples to read from the dataset.\n# TFMA is much slower than TFT, so we may have to read a smaller subset of the\n# dataset.\nMAX_NUM_EXAMPLES = 100000\n\n\n# TODO(b/147827582): Also add ""TF-level"" Keras benchmarks for how TFMAv2\n# gets predictions / computes metrics.\nclass TFMAV2BenchmarkBase(benchmark_base.BenchmarkBase):\n  """"""TFMA benchmark.""""""\n\n  def __init__(self, dataset, **kwargs):\n    # Benchmark runners may pass extraneous arguments we don\'t care about.\n    del kwargs\n    super(TFMAV2BenchmarkBase, self).__init__()\n    self._dataset = dataset\n\n  def _init_model(self):\n    # The benchmark runner will instantiate this class twice - once to determine\n    # the benchmarks to run, and once to actually to run them. However, Keras\n    # freezes if we try to load the same model twice. As such, we have to pull\n    # the model loading out of the constructor into a separate method which we\n    # call before each benchmark.\n    self._eval_config = tfma.EvalConfig(\n        model_specs=[tfma.ModelSpec(label_key=""tips"")],\n        metrics_specs=metric_specs.specs_from_metrics([\n            tf.keras.metrics.AUC(name=""auc"", num_thresholds=10000),\n        ]))\n    # metrics_specs=metric_specs.example_count_specs())\n\n    self._eval_shared_model = tfma.default_eval_shared_model(\n        self._dataset.trained_saved_model_path(), eval_config=self._eval_config)\n\n  def report_benchmark(self, **kwargs):\n    if ""extras"" not in kwargs:\n      kwargs[""extras""] = {}\n    # Note that the GIT_COMMIT_ID is not included in the packages themselves:\n    # it must be injected by an external script.\n    kwargs[""extras""][""commit_tfx""] = getattr(tfx, ""GIT_COMMIT_ID"",\n                                             tfx.__version__)\n    kwargs[""extras""][""commit_tfma""] = getattr(tfma, ""GIT_COMMIT_ID"",\n                                              tfma.__version__)\n    super(TFMAV2BenchmarkBase, self).report_benchmark(**kwargs)\n\n  def benchmarkMiniPipelineUnbatched(self):\n    """"""Benchmark an unbatched ""mini"" TFMA - predict, slice and compute metrics.\n\n    Runs a ""mini"" version of TFMA in a Beam pipeline. Records the wall time\n    taken for the whole pipeline.\n    """"""\n    self._init_model()\n    pipeline = self._create_beam_pipeline()\n    raw_data = (\n        pipeline\n        | ""Examples"" >> beam.Create(\n            self._dataset.read_raw_dataset(\n                deserialize=False, limit=MAX_NUM_EXAMPLES))\n        | ""InputsToExtracts"" >> tfma.InputsToExtracts())\n\n    _ = (\n        raw_data\n        | ""InputExtractor"" >>\n        input_extractor.InputExtractor(eval_config=self._eval_config).ptransform\n        | ""V2PredictExtractor"" >> predict_extractor_v2.PredictExtractor(\n            eval_config=self._eval_config,\n            eval_shared_model=self._eval_shared_model).ptransform\n        | ""SliceKeyExtractor"" >> tfma.extractors.SliceKeyExtractor().ptransform\n        | ""V2ComputeMetricsAndPlots"" >>\n        metrics_and_plots_evaluator_v2.MetricsAndPlotsEvaluator(\n            eval_config=self._eval_config,\n            eval_shared_model=self._eval_shared_model).ptransform)\n\n    start = time.time()\n    result = pipeline.run()\n    result.wait_until_finish()\n    end = time.time()\n    delta = end - start\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def benchmarkMiniPipelineBatched(self):\n    """"""Benchmark a batched ""mini"" TFMA - predict, slice and compute metrics.\n\n    Runs a ""mini"" version of TFMA in a Beam pipeline. Records the wall time\n    taken for the whole pipeline.\n    """"""\n    self._init_model()\n    pipeline = self._create_beam_pipeline()\n    tfx_io = test_util.InMemoryTFExampleRecord(\n        schema=benchmark_utils.read_schema(\n            self._dataset.tf_metadata_schema_path()),\n        raw_record_column_name=constants.ARROW_INPUT_COLUMN)\n    raw_data = (\n        pipeline\n        | ""Examples"" >> beam.Create(\n            self._dataset.read_raw_dataset(\n                deserialize=False, limit=MAX_NUM_EXAMPLES))\n        | ""BatchExamples"" >> tfx_io.BeamSource()\n        | ""InputsToExtracts"" >> tfma.BatchedInputsToExtracts())\n\n    _ = (\n        raw_data\n        | ""BatchedInputExtractor"" >> batched_input_extractor\n        .BatchedInputExtractor(eval_config=self._eval_config).ptransform\n        | ""V2BatchedPredictExtractor"" >>\n        batched_predict_extractor_v2.BatchedPredictExtractor(\n            eval_config=self._eval_config,\n            eval_shared_model=self._eval_shared_model).ptransform\n        | ""UnbatchExtractor"" >> unbatch_extractor.UnbatchExtractor().ptransform\n        | ""SliceKeyExtractor"" >> tfma.extractors.SliceKeyExtractor().ptransform\n        | ""V2ComputeMetricsAndPlots"" >>\n        metrics_and_plots_evaluator_v2.MetricsAndPlotsEvaluator(\n            eval_config=self._eval_config,\n            eval_shared_model=self._eval_shared_model).ptransform)\n\n    start = time.time()\n    result = pipeline.run()\n    result.wait_until_finish()\n    end = time.time()\n    delta = end - start\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""num_examples"": self._dataset.num_examples(limit=MAX_NUM_EXAMPLES)\n        })\n\n  def _readDatasetIntoExtracts(self):\n    """"""Read the raw dataset and massage examples into Extracts.""""""\n    records = []\n    # No limit here, the microbenchmarks are relatively fast.\n    for x in self._dataset.read_raw_dataset(deserialize=False):\n      records.append({tfma.INPUT_KEY: x, tfma.SLICE_KEY_TYPES_KEY: ()})\n    return records\n\n  # ""Manual"" micro-benchmarks\n  def benchmarkInputExtractorManualActuation(self):\n    """"""Benchmark PredictExtractorV2 ""manually"".""""""\n    self._init_model()\n    records = self._readDatasetIntoExtracts()\n    extracts = []\n\n    start = time.time()\n    for elem in records:\n      extracts.append(input_extractor._ParseExample(elem, self._eval_config))  # pylint: disable=protected-access\n    end = time.time()\n    delta = end - start\n    self.report_benchmark(\n        iters=1, wall_time=delta, extras={""num_examples"": len(records)})\n\n  def benchmarkPredictExtractorManualActuation(self):\n    """"""Benchmark PredictExtractorV2 ""manually"".""""""\n    self._init_model()\n    records = self._readDatasetIntoExtracts()\n    extracts = []\n    for elem in records:\n      extracts.append(input_extractor._ParseExample(elem, self._eval_config))  # pylint: disable=protected-access\n\n    prediction_do_fn = predict_extractor_v2._PredictionDoFn(  # pylint: disable=protected-access\n        eval_config=self._eval_config,\n        eval_shared_models={"""": self._eval_shared_model})\n    prediction_do_fn.setup()\n\n    start = time.time()\n    predict_result = []\n    predict_batch_size = 1000\n    for batch in benchmark_utils.batched_iterator(extracts, predict_batch_size):\n      predict_result.extend(prediction_do_fn.process(batch))\n\n    end = time.time()\n    delta = end - start\n    self.report_benchmark(\n        iters=1, wall_time=delta, extras={""num_examples"": len(records)})\n\n  def _runMetricsAndPlotsEvaluatorManualActuation(self,\n                                                  with_confidence_intervals,\n                                                  metrics_specs=None):\n    """"""Benchmark MetricsAndPlotsEvaluatorV2 ""manually"".""""""\n    self._init_model()\n    if not metrics_specs:\n      metrics_specs = self._eval_config.metrics_specs\n\n    records = self._readDatasetIntoExtracts()\n    extracts = []\n    for elem in records:\n      extracts.append(input_extractor._ParseExample(elem, self._eval_config))  # pylint: disable=protected-access\n\n    prediction_do_fn = predict_extractor_v2._PredictionDoFn(  # pylint: disable=protected-access\n        eval_config=self._eval_config,\n        eval_shared_models={"""": self._eval_shared_model})\n    prediction_do_fn.setup()\n\n    # Have to predict first\n    predict_result = []\n    predict_batch_size = 1000\n    for batch in benchmark_utils.batched_iterator(extracts, predict_batch_size):\n      predict_result.extend(prediction_do_fn.process(batch))\n\n    # Now Evaluate\n    inputs_per_accumulator = 1000\n    start = time.time()\n\n    computations, _ = (\n        metrics_and_plots_evaluator_v2._filter_and_separate_computations(  # pylint: disable=protected-access\n            metric_specs.to_computations(\n                metrics_specs, eval_config=self._eval_config)))\n\n    processed = []\n    for elem in predict_result:\n      processed.append(\n          next(\n              metrics_and_plots_evaluator_v2._PreprocessorDoFn(  # pylint: disable=protected-access\n                  computations).process(elem)))\n\n    combiner = metrics_and_plots_evaluator_v2._ComputationsCombineFn(  # pylint: disable=protected-access\n        computations=computations,\n        compute_with_sampling=with_confidence_intervals)\n\n    accumulators = []\n    for batch in benchmark_utils.batched_iterator(processed,\n                                                  inputs_per_accumulator):\n      accumulator = combiner.create_accumulator()\n      for elem in batch:\n        accumulator = combiner.add_input(accumulator, elem)\n      accumulators.append(accumulator)\n\n    final_accumulator = combiner.merge_accumulators(accumulators)\n    final_output = combiner.extract_output(final_accumulator)\n    end = time.time()\n    delta = end - start\n\n    # Sanity check the example count. This is not timed.\n    example_count_key = metric_types.MetricKey(name=""example_count"")\n    example_count = None\n    for x in final_output:\n      if example_count_key in x:\n        example_count = x[example_count_key]\n        break\n\n    if example_count is None:\n      raise ValueError(""example_count was not in the final list of metrics. ""\n                       ""metrics were: %s"" % str(final_output))\n\n    if with_confidence_intervals:\n      # If we\'re computing using confidence intervals, the example count will\n      # not be exact.\n      lower_bound = int(0.9 * len(records))\n      upper_bound = int(1.1 * len(records))\n      if example_count < lower_bound or example_count > upper_bound:\n        raise ValueError(""example count out of bounds: expecting ""\n                         ""%d < example_count < %d, but got %d"" %\n                         (lower_bound, upper_bound, example_count))\n    else:\n      # If we\'re not using confidence intervals, we expect the example count to\n      # be exact.\n      if example_count != len(records):\n        raise ValueError(""example count mismatch: expecting %d got %d"" %\n                         (len(records), example_count))\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""inputs_per_accumulator"": inputs_per_accumulator,\n            ""num_examples"": len(records)\n        })\n\n  def benchmarkMetricsAndPlotsEvaluatorManualActuationNoConfidenceIntervals(\n      self):\n    self._runMetricsAndPlotsEvaluatorManualActuation(\n        with_confidence_intervals=False)\n\n  def benchmarkMetricsAndPlotsEvaluatorManualActuationWithConfidenceIntervals(\n      self):\n    self._runMetricsAndPlotsEvaluatorManualActuation(\n        with_confidence_intervals=True)\n\n  def benchmarkMetricsAndPlotsEvaluatorAUC10k(self):\n    self._runMetricsAndPlotsEvaluatorManualActuation(\n        with_confidence_intervals=False,\n        metrics_specs=metric_specs.specs_from_metrics([\n            tf.keras.metrics.AUC(name=""auc"", num_thresholds=10000),\n        ]))\n\n  def benchmarkMetricsAndPlotsEvaluatorBinaryClassification(self):\n    self._runMetricsAndPlotsEvaluatorManualActuation(\n        with_confidence_intervals=False,\n        metrics_specs=metric_specs.specs_from_metrics([\n            tf.keras.metrics.BinaryAccuracy(name=""accuracy""),\n            tf.keras.metrics.AUC(\n                name=""auc"",\n                num_thresholds=10000\n            ),\n            tf.keras.metrics.AUC(\n                name=""auc_precison_recall"",\n                curve=""PR"",\n                num_thresholds=10000\n            ),\n            tf.keras.metrics.Precision(name=""precision""),\n            tf.keras.metrics.Recall(name=""recall""),\n            tfma.metrics.MeanLabel(name=""mean_label""),\n            tfma.metrics.MeanPrediction(name=""mean_prediction""),\n            tfma.metrics.Calibration(name=""calibration""),\n            tfma.metrics.ConfusionMatrixPlot(\n                name=""confusion_matrix_plot""),\n            tfma.metrics.CalibrationPlot(name=""calibration_plot""),\n        ]))\n'"
tfx/benchmarks/tfma_v2_benchmark_chicago_taxi.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFMA v2 benchmark for Chicago Taxi dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.platform import test  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.benchmarks import tfma_v2_benchmark_base\nfrom tfx.benchmarks.datasets.chicago_taxi import dataset\n\n\nclass TFMAV2BenchmarkChicagoTaxi(tfma_v2_benchmark_base.TFMAV2BenchmarkBase):\n\n  def __init__(self, **kwargs):\n    super(TFMAV2BenchmarkChicagoTaxi, self).__init__(\n        dataset=dataset.get_dataset(), **kwargs)\n\n\nif __name__ == ""__main__"":\n  test.main()\n'"
tfx/benchmarks/tft_benchmark_base.py,6,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFT benchmark base.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport shutil\nimport tempfile\nimport time\n\n# Standard Imports\n\nfrom absl import logging\nimport apache_beam as beam\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom tensorflow_transform import graph_tools\nfrom tensorflow_transform import impl_helper\nimport tensorflow_transform.beam as tft_beam\nfrom tensorflow_transform.beam import impl as tft_beam_impl\nfrom tensorflow_transform.saved import saved_transform_io\nfrom tensorflow_transform.tf_metadata import dataset_metadata\nfrom tensorflow_transform.tf_metadata import schema_utils\nfrom tfx_bsl.beam import shared\n\nimport tfx\nfrom tfx.benchmarks import benchmark_utils\nfrom tfx.benchmarks import benchmark_base\n\n\nclass _CopySavedModel(beam.PTransform):\n  """"""Copies the TFT SavedModel to another directory.""""""\n\n  def __init__(self, dest_path):\n    self._dest_path = dest_path\n\n  def expand(self, transform_fn):\n\n    def copy_saved_model(unused_element, source_path, dest_path):\n      shutil.rmtree(dest_path, ignore_errors=True)\n      shutil.copytree(source_path, dest_path)\n      logging.info(""Copied SavedModel from %s to %s"", source_path, dest_path)\n\n    return (transform_fn.pipeline\n            | ""CreateSole"" >> beam.Create([None])\n            | ""CopySavedModel"" >> beam.Map(\n                copy_saved_model,\n                source_path=beam.pvalue.AsSingleton(transform_fn),\n                dest_path=self._dest_path))\n\n\nclass _AnalyzeAndTransformDataset(beam.PTransform):\n  """"""PTransform to run AnalyzeAndTransformDataset.""""""\n\n  def __init__(self,\n               dataset,\n               tf_metadata_schema,\n               preprocessing_fn,\n               transform_input_dataset_metadata,\n               generate_dataset=False):\n    """"""Constructor.\n\n    Args:\n      dataset: BenchmarkDataset object.\n      tf_metadata_schema: tf.Metadata schema.\n      preprocessing_fn: preprocessing_fn.\n      transform_input_dataset_metadata: dataset_metadata.DatasetMetadata.\n      generate_dataset: If True, generates the raw dataset and appropriate\n        intermediate outputs (just the TFT SavedModel for now) necessary for\n        other benchmarks.\n    """"""\n    self._dataset = dataset\n    self._tf_metadata_schema = tf_metadata_schema\n    self._preprocessing_fn = preprocessing_fn\n    self._transform_input_dataset_metadata = transform_input_dataset_metadata\n    self._generate_dataset = generate_dataset\n\n  def expand(self, pipeline):\n    # TODO(b/147620802): Consider making this (and other parameters)\n    # configurable to test more variants (e.g. with and without deep-copy\n    # optimisation, with and without cache, etc).\n    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n      converter = tft.coders.ExampleProtoCoder(\n          self._tf_metadata_schema, serialized=False)\n      raw_data = (\n          pipeline\n          | ""ReadDataset"" >> beam.Create(self._dataset.read_raw_dataset())\n          | ""Decode"" >> beam.Map(converter.decode))\n      transform_fn, output_metadata = (\n          (raw_data, self._transform_input_dataset_metadata)\n          | ""AnalyzeDataset"" >> tft_beam.AnalyzeDataset(self._preprocessing_fn))\n\n      if self._generate_dataset:\n        _ = transform_fn | ""CopySavedModel"" >> _CopySavedModel(\n            dest_path=self._dataset.tft_saved_model_path())\n\n      (transformed_dataset, transformed_metadata) = (\n          ((raw_data, self._transform_input_dataset_metadata),\n           (transform_fn, output_metadata))\n          | ""TransformDataset"" >> tft_beam.TransformDataset())\n      return transformed_dataset, transformed_metadata\n\n\n# Tuple for variables common to all benchmarks.\nCommonVariablesTuple = collections.namedtuple(""CommonVariablesTuple"", [\n    ""tf_metadata_schema"", ""preprocessing_fn"", ""transform_input_dataset_metadata""\n])\n\n\ndef _get_common_variables(dataset):\n  """"""Returns metadata schema, preprocessing fn, input dataset metadata.""""""\n\n  tf_metadata_schema = benchmark_utils.read_schema(\n      dataset.tf_metadata_schema_path())\n\n  preprocessing_fn = dataset.tft_preprocessing_fn()\n\n  feature_spec = schema_utils.schema_as_feature_spec(\n      tf_metadata_schema).feature_spec\n  transform_input_columns = (\n      tft.get_transform_input_columns(preprocessing_fn, feature_spec))\n  transform_input_dataset_metadata = dataset_metadata.DatasetMetadata(\n      schema_utils.schema_from_feature_spec({\n          feature: feature_spec[feature] for feature in transform_input_columns\n      }))\n\n  return CommonVariablesTuple(\n      tf_metadata_schema=tf_metadata_schema,\n      preprocessing_fn=preprocessing_fn,\n      transform_input_dataset_metadata=transform_input_dataset_metadata)\n\n\ndef regenerate_intermediates_for_dataset(dataset):\n  """"""Regenerate intermediate outputs required for the benchmark.""""""\n\n  common_variables = _get_common_variables(dataset)\n\n  logging.info(""Regenerating intermediate outputs required for benchmark."")\n  with beam.Pipeline() as p:\n    _ = p | _AnalyzeAndTransformDataset(\n        dataset,\n        common_variables.tf_metadata_schema,\n        common_variables.preprocessing_fn,\n        common_variables.transform_input_dataset_metadata,\n        generate_dataset=True)\n  logging.info(""Intermediate outputs regenerated."")\n\n\ndef _get_batched_records(dataset):\n  """"""Returns a (batch_size, iterator for batched records) tuple for the dataset.\n\n  Args:\n    dataset: BenchmarkDataset object.\n\n  Returns:\n    Tuple of (batch_size, iterator for batched records), where records are\n    decoded tf.train.Examples.\n  """"""\n  batch_size = 1000\n  common_variables = _get_common_variables(dataset)\n  converter = tft.coders.ExampleProtoCoder(\n      common_variables.tf_metadata_schema, serialized=False)\n  records = [converter.decode(x) for x in dataset.read_raw_dataset()]\n  return batch_size, benchmark_utils.batched_iterator(records, batch_size)\n\n\nclass TFTBenchmarkBase(benchmark_base.BenchmarkBase):\n  """"""TFT benchmark base class.""""""\n\n  def __init__(self, dataset, **kwargs):\n    # Benchmark runners may pass extraneous arguments we don\'t care about.\n    del kwargs\n    super(TFTBenchmarkBase, self).__init__()\n    self._dataset = dataset\n\n  def report_benchmark(self, **kwargs):\n    if ""extras"" not in kwargs:\n      kwargs[""extras""] = {}\n    # Note that the GIT_COMMIT_ID is not included in the packages themselves:\n    # it must be injected by an external script.\n    kwargs[""extras""][""commit_tfx""] = getattr(tfx, ""GIT_COMMIT_ID"",\n                                             tfx.__version__)\n    kwargs[""extras""][""commit_tft""] = getattr(tft, ""GIT_COMMIT_ID"",\n                                             tft.__version__)\n    super(TFTBenchmarkBase, self).report_benchmark(**kwargs)\n\n  def benchmarkAnalyzeAndTransformDataset(self):\n    """"""Benchmark AnalyzeAndTransformDataset.\n\n    Runs AnalyzeAndTransformDataset in a Beam pipeline. Records the wall time\n    taken for the whole pipeline.\n    """"""\n    common_variables = _get_common_variables(self._dataset)\n\n    pipeline = self._create_beam_pipeline()\n    _ = pipeline | _AnalyzeAndTransformDataset(\n        self._dataset, common_variables.tf_metadata_schema,\n        common_variables.preprocessing_fn,\n        common_variables.transform_input_dataset_metadata)\n    start = time.time()\n    result = pipeline.run()\n    result.wait_until_finish()\n    end = time.time()\n    delta = end - start\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={""num_examples"": self._dataset.num_examples()})\n\n  def benchmarkRunMetaGraphDoFnManualActuation(self):\n    """"""Benchmark RunMetaGraphDoFn ""manually"".\n\n    Runs RunMetaGraphDoFn ""manually"" outside of a Beam pipeline. Records the\n    wall time taken.\n    """"""\n    common_variables = _get_common_variables(self._dataset)\n    batch_size, batched_records = _get_batched_records(self._dataset)\n\n    fn = tft_beam_impl._RunMetaGraphDoFn(  # pylint: disable=protected-access\n        input_schema=common_variables.transform_input_dataset_metadata.schema,\n        tf_config=None,\n        shared_graph_state_handle=shared.Shared(),\n        passthrough_keys=set(),\n        exclude_outputs=None,\n        use_tfxio=False)\n\n    start = time.time()\n    for batch in batched_records:\n      _ = list(\n          fn.process(\n              batch, saved_model_dir=self._dataset.tft_saved_model_path()))\n    end = time.time()\n    delta = end - start\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""batch_size"": batch_size,\n            ""num_examples"": self._dataset.num_examples()\n        })\n\n  def benchmarkRunMetagraphDoFnAtTFLevel(self):\n    """"""Benchmark RunMetaGraphDoFn at the TF level.\n\n    Benchmarks the parts of RunMetaGraphDoFn that involve feeding and\n    fetching from the TFT SavedModel. Records the wall time taken.\n\n    Note that this benchmark necessarily duplicates code directly from TFT\n    since it\'s benchmarking the low-level internals of TFT, which are not\n    exposed for use in this way.\n    """"""\n    common_variables = _get_common_variables(self._dataset)\n    tf_config = tft_beam_impl._FIXED_PARALLELISM_TF_CONFIG  # pylint: disable=protected-access\n    input_schema = common_variables.transform_input_dataset_metadata.schema\n\n    # This block copied from _GraphState.__init__\n    with tf.compat.v1.Graph().as_default() as graph:\n      session = tf.compat.v1.Session(graph=graph, config=tf_config)\n      with session.as_default():\n        # TODO(b/148082271): Revert back to unpacking the result directly once\n        # TFX depends on TFT 0.22.\n        apply_saved_model_result = (\n            saved_transform_io.partially_apply_saved_transform_internal(\n                self._dataset.tft_saved_model_path(), {}))\n        inputs, outputs = apply_saved_model_result[:2]\n        session.run(tf.compat.v1.global_variables_initializer())\n        session.run(tf.compat.v1.tables_initializer())\n        graph.finalize()\n      # We ignore the schema, and assume there are no excluded outputs.\n      outputs_tensor_keys = sorted(set(outputs.keys()))\n      fetches = [outputs[key] for key in outputs_tensor_keys]\n      tensor_inputs = graph_tools.get_dependent_inputs(graph, inputs, fetches)\n      input_tensor_keys = sorted(tensor_inputs.keys())\n      feed_list = [inputs[key] for key in input_tensor_keys]\n      callable_get_outputs = session.make_callable(fetches, feed_list=feed_list)\n\n    batch_size, batched_records = _get_batched_records(self._dataset)\n\n    # This block copied from _RunMetaGraphDoFn._handle_batch\n    start = time.time()\n    for batch in batched_records:\n      feed_list = impl_helper.make_feed_list(input_tensor_keys, input_schema,\n                                             batch)\n      outputs_list = callable_get_outputs(*feed_list)\n      _ = {key: value for key, value in zip(outputs_tensor_keys, outputs_list)}\n    end = time.time()\n    delta = end - start\n\n    self.report_benchmark(\n        iters=1,\n        wall_time=delta,\n        extras={\n            ""batch_size"": batch_size,\n            ""num_examples"": self._dataset.num_examples()\n        })\n'"
tfx/benchmarks/tft_benchmark_chicago_taxi.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFT benchmark for Chicago Taxi dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.platform import test  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.benchmarks import tft_benchmark_base\nfrom tfx.benchmarks.datasets.chicago_taxi import dataset\n\n\nclass TFTBenchmarkChicagoTaxi(tft_benchmark_base.TFTBenchmarkBase):\n\n  def __init__(self, **kwargs):\n    super(TFTBenchmarkChicagoTaxi, self).__init__(\n        dataset=dataset.get_dataset(), **kwargs)\n\n\nif __name__ == ""__main__"":\n  test.main()\n'"
tfx/components/__init__.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Subpackage for TFX components.""""""\n\nimport tensorflow as tf\n\n# For component user to direct use tfx.components.[...] as an alias.\nfrom tfx.components.bulk_inferrer.component import BulkInferrer\nfrom tfx.components.common_nodes.importer_node import ImporterNode\nfrom tfx.components.common_nodes.resolver_node import ResolverNode\nfrom tfx.components.evaluator.component import Evaluator\nfrom tfx.components.example_gen.big_query_example_gen.component import BigQueryExampleGen\nfrom tfx.components.example_gen.component import FileBasedExampleGen\nfrom tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\nfrom tfx.components.example_gen.import_example_gen.component import ImportExampleGen\nfrom tfx.components.example_validator.component import ExampleValidator\nfrom tfx.components.infra_validator.component import InfraValidator\nfrom tfx.components.model_validator.component import ModelValidator\nfrom tfx.components.pusher.component import Pusher\nfrom tfx.components.schema_gen.component import SchemaGen\nfrom tfx.components.statistics_gen.component import StatisticsGen\nfrom tfx.components.trainer.component import Trainer\nfrom tfx.components.transform.component import Transform\nfrom tfx.components.tuner.component import Tuner\n\n# Prevents double logging: TFX and TF uses `tf.logging` but Beam uses standard\n# logging, both logging modules add its own handler. Following setting disables\n# tf.logging to propagate up to the parent logging handlers. This is a global\n# behavior (perhaps thread hostile) which affects all code that uses component\n# libaray.\ntf.get_logger().propagate = False\n'"
tfx/dsl/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/extensions/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/data_types.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common data types for orchestration.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Optional, Text, Type, Union\nimport warnings\n\nfrom tfx import types\nfrom tfx.utils import json_utils\n\n# Regex pattern of RuntimeParameter.\n# Use \\\\* to deal with escaping in json-serialized version of objects.\nRUNTIME_PARAMETER_PATTERN = (r\'({\\\\*""__class__\\\\*"": \\\\*""RuntimeParameter\\\\*"", \'\n                             r\'.*?})\')\n\nPARAMETER_NAME_LITERAL = r\'(\\\\*""RuntimeParameter\\\\*"")\'\n\n\nclass ExecutionDecision(object):\n  """"""ExecutionDecision records how executor should perform next execution.\n\n  Attributes:\n    input_dict: Updated key -> types.Artifact for inputs that will be used by\n      actual execution.\n    output_dict: Updated key -> types.Artifact for outputs that will be used by\n      actual execution.\n    exec_properties: Updated dict of other execution properties that will be\n      used by actual execution.\n    execution_id: Registered execution_id for the upcoming execution.\n    use_cached_results: Whether or not to use a cached result.\n  """"""\n\n  def __init__(self,\n               input_dict: Dict[Text, List[types.Artifact]],\n               output_dict: Dict[Text, List[types.Artifact]],\n               exec_properties: Dict[Text, Any],\n               execution_id: int = None,\n               use_cached_results: Optional[bool] = False):\n    self.input_dict = input_dict\n    self.output_dict = output_dict\n    self.exec_properties = exec_properties\n    self.execution_id = execution_id\n    self.use_cached_results = use_cached_results\n\n\nclass ExecutionInfo(object):\n  """"""ExecutionInfo contains information populated during execution phase.\n\n  Attributes:\n    input_dict: Updated key -> List of types.Artifact for inputs that was used\n      during the actual execution.\n    output_dict: Updated key -> List of types.Artifact for outputs that was\n      generated during the actual execution.\n    exec_properties: execution properties used in this execution.\n    execution_id: Registered execution_id for the execution.\n  """"""\n\n  def __init__(self, input_dict: Dict[Text, List[types.Artifact]],\n               output_dict: Dict[Text, List[types.Artifact]],\n               exec_properties: Dict[Text, Any], execution_id: int):\n    self.input_dict = input_dict\n    self.output_dict = output_dict\n    self.exec_properties = exec_properties\n    self.execution_id = execution_id\n\n\nclass DriverArgs(object):\n  """"""Args to driver from orchestration system.\n\n  Attributes:\n    enable_cache: whether cache is enabled in current execution.\n    interactive_resolution: whether to skip MLMD channel artifact resolution, if\n      artifacts are already resolved for a channel when running in interactive\n      mode.\n  """"""\n\n  def __init__(self,\n               enable_cache: bool = True,\n               interactive_resolution: bool = False):\n    self.enable_cache = enable_cache\n    self.interactive_resolution = interactive_resolution\n\n\nclass PipelineInfo(object):\n  """"""Pipeline info from orchestration system.\n\n  Attributes:\n    pipeline_name: name of the pipeline. We expect this to be unique for\n      different pipelines.\n    pipeline_root: root directory of the pipeline. We expect this to be unique\n      for different pipelines.\n    run_id: optional uuid for a single run of the pipeline.\n  """"""\n\n  def __init__(self,\n               pipeline_name: Text,\n               pipeline_root: Text,\n               run_id: Optional[Text] = None):\n    self.pipeline_name = pipeline_name\n    self.pipeline_root = pipeline_root\n    self.run_id = run_id\n\n  def __repr__(self):\n    return (\'PipelineInfo(\'\n            \'pipeline_name: %s, \'\n            \'pipeline_root: %s, \'\n            \'run_id: %s)\') % (self.pipeline_name, self.pipeline_root,\n                              self.run_id)\n\n  @property\n  def pipeline_run_context_name(self) -> Text:\n    """"""Context name for the current pipeline run.""""""\n    return \'{}.{}\'.format(self.pipeline_name, self.run_id)\n\n  @property\n  def pipeline_context_name(self) -> Text:\n    """"""Context name for the pipeline.""""""\n    return self.pipeline_name\n\n\nclass ComponentInfo(object):\n  """"""Component info.\n\n  Attributes:\n    component_type: type of the component. Usually determined by the executor\n      python path or image uri of.\n    component_id: a unique identifier of the component instance within pipeline.\n    pipeline_info: the pipeline info of the current pipeline run.\n  """"""\n\n  def __init__(self, component_type: Text, component_id: Text,\n               pipeline_info: PipelineInfo):\n    self.component_type = component_type\n    self.component_id = component_id\n    self.pipeline_info = pipeline_info\n\n  def __repr__(self):\n    return (\'ComponentInfo(\'\n            \'component_type: %s, \'\n            \'component_id: %s, \'\n            \'pipeline_info: %s)\') % (self.component_type, self.component_id,\n                                     self.pipeline_info)\n\n  @property\n  def component_run_context_name(self) -> Text:\n    """"""""Context name for current component run.""""""\n    if self.pipeline_info.run_id:\n      return \'{}.{}\'.format(self.pipeline_info.pipeline_run_context_name,\n                            self.component_id)\n    else:\n      return \'{}.{}\'.format(self.pipeline_info.pipeline_context_name,\n                            self.component_id)\n\n\n# TODO(b/146361011): Implement a checking mechanism preventing users from using\n# RuntimeParameter in DAG runner other than Kubeflow Pipelines.\nclass RuntimeParameter(json_utils.Jsonable):\n  """"""Runtime parameter.\n\n  Currently only supported on KubeflowDagRunner.\n\n  Attributes:\n    name: The name of the runtime parameter.\n    default: Default value for runtime params when it\'s not explicitly\n      specified.\n    ptype: The type of the runtime parameter.\n    description: Description of the usage of the parameter.\n  """"""\n\n  def __init__(\n      self,\n      name: Text,\n      ptype: Type = None,  # pylint: disable=g-bare-generic\n      default: Optional[Union[int, float, bool, Text]] = None,\n      description: Optional[Text] = None):\n    warnings.warn(\'RuntimeParameter is only supported on KubeflowDagRunner \'\n                  \'currently.\')\n\n    if ptype and ptype not in [int, float, bool, Text]:\n      raise RuntimeError(\'Only str and scalar runtime parameters are supported\')\n    if (default and ptype) and not isinstance(default, ptype):\n      raise TypeError(\'Default value must be consistent with specified ptype\')\n    self.name = name\n    self.default = default\n    self.ptype = ptype\n    self.description = description\n\n  def __repr__(self):\n    """"""Easily convert RuntimeParameter to str.\n\n    This provides a unified way to call str(x) when x can be either str or\n    RuntimeParameter. Note: if ptype == Text or None, the serialization will be\n    wrapped in double quotes.\n\n    Returns:\n      The json serialized version of RuntimeParameter.\n    """"""\n    return json_utils.dumps(self)\n\n  def __eq__(self, other):\n    return (isinstance(other.__class__, self.__class__) and\n            self.name == other.name and self.default == other.default and\n            self.ptype == other.ptype and self.description == other.description)\n\n  def __hash__(self):\n    """"""RuntimeParameter is uniquely identified by its name.""""""\n    return self.name.__hash__()\n'"
tfx/orchestration/data_types_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.data_types.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nfrom typing import Dict, List, Text\nimport tensorflow as tf\n\nfrom google.protobuf.json_format import ParseError\nfrom tfx.orchestration import data_types\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ComponentSpec\nfrom tfx.types.component_spec import ExecutionParameter\n\n\nclass _InputArtifact(Artifact):\n  TYPE_NAME = \'InputArtifact\'\n\n\nclass _OutputArtifact(Artifact):\n  TYPE_NAME = \'OutputArtifact\'\n\n\nclass _BasicComponentSpec(ComponentSpec):\n\n  PARAMETERS = {\n      \'folds\': ExecutionParameter(type=int),\n      \'proto\': ExecutionParameter(type=example_gen_pb2.Input, optional=True),\n  }\n  INPUTS = {\n      \'input\': ChannelParameter(type=_InputArtifact),\n  }\n  OUTPUTS = {\n      \'output\': ChannelParameter(type=_OutputArtifact),\n  }\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'future_input_name\': \'input\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'future_output_name\': \'output\',\n  }\n\n\nclass DataTypesTest(tf.test.TestCase):\n\n  def testComponentSpecWithRuntimeParam(self):\n    param = data_types.RuntimeParameter(name=\'split-1\', ptype=Text)\n    serialized_param = str(param)\n    # Dict representation of a example_gen_pb2.Input proto message.\n    proto = dict(splits=[\n        dict(name=param, pattern=\'pattern1\'),\n        dict(name=\'name2\', pattern=\'pattern2\'),\n        dict(name=\'name3\', pattern=\'pattern3\'),\n    ])\n    input_channel = Channel(type=_InputArtifact)\n    output_channel = Channel(type=_OutputArtifact)\n    spec = _BasicComponentSpec(\n        folds=10, proto=proto, input=input_channel, output=output_channel)\n    # Verify proto property.\n    self.assertIsInstance(spec.exec_properties[\'proto\'], str)\n    decoded_proto = json.loads(spec.exec_properties[\'proto\'])\n    self.assertCountEqual([\'splits\'], decoded_proto.keys())\n    self.assertEqual(3, len(decoded_proto[\'splits\']))\n    self.assertCountEqual([serialized_param, \'name2\', \'name3\'],\n                          list(s[\'name\'] for s in decoded_proto[\'splits\']))\n    self.assertCountEqual([\'pattern1\', \'pattern2\', \'pattern3\'],\n                          list(s[\'pattern\'] for s in decoded_proto[\'splits\']))\n\n  def testProtoTypeCheck(self):\n    param = data_types.RuntimeParameter(name=\'split-1\', ptype=Text)\n    # Dict representation of a example_gen_pb2.Input proto message.\n    # The second split has int-typed pattern, which is wrong.\n    proto = dict(splits=[\n        dict(name=param, pattern=\'pattern1\'),\n        dict(name=\'name2\', pattern=42),\n        dict(name=\'name3\', pattern=\'pattern3\'),\n    ])\n    input_channel = Channel(type=_InputArtifact)\n    output_channel = Channel(type=_OutputArtifact)\n\n    with self.assertRaisesRegexp(\n        ParseError, \'Failed to parse .* field: expected string or \'\n        \'(bytes-like object|buffer)\'):\n      _ = _BasicComponentSpec(\n          folds=10, proto=proto, input=input_channel, output=output_channel)\n\n  def testTypeCheckWithRuntimeParameter(self):\n\n    class SimpleComponentSpec(ComponentSpec):\n      INPUTS = {}\n      OUTPUTS = {}\n      PARAMETERS = {\n          \'x\': ExecutionParameter(type=int),\n          \'y\': ExecutionParameter(type=int, optional=True),\n      }\n\n    parameter_int = data_types.RuntimeParameter(name=\'int\', ptype=int)\n    parameter_str = data_types.RuntimeParameter(name=\'str\', ptype=Text)\n\n    _ = SimpleComponentSpec(x=parameter_int)\n    with self.assertRaisesRegexp(TypeError, \'Expected type\'):\n      _ = SimpleComponentSpec(x=42, y=parameter_str)\n\n    class ComponentSpecWithContainer(ComponentSpec):\n      INPUTS = {}\n      OUTPUTS = {}\n      PARAMETERS = {\n          \'x\': ExecutionParameter(type=Dict[Text, Text]),\n          \'y\': ExecutionParameter(type=List[int]),\n      }\n\n    _ = ComponentSpecWithContainer(x={u\'key\': parameter_str}, y=[parameter_int])\n    with self.assertRaisesRegexp(TypeError, \'Expecting value type\'):\n      _ = ComponentSpecWithContainer(x={u\'key\': parameter_int}, y=[])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/metadata.py,17,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ml metadata library.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport copy\nimport hashlib\nimport itertools\nimport os\nimport random\nimport time\nimport types\n\nfrom typing import Any, Dict, List, Optional, Set, Text, Tuple, Type, Union\n\nimport absl\nimport six\nimport tensorflow as tf\n\nfrom ml_metadata.metadata_store import metadata_store\nfrom ml_metadata.proto import metadata_store_pb2\nfrom ml_metadata.proto import metadata_store_service_pb2\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.orchestration import data_types\nfrom tfx.types import artifact_utils\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.artifact import ArtifactState\n\n# Number of times to retry initialization of connection.\n_MAX_INIT_RETRY = 10\n\n# Maximum number of executions we look at for previous result.\nMAX_EXECUTIONS_FOR_CACHE = 100\n# Execution state constant. We should replace this with MLMD enum once that is\n# ready.\nEXECUTION_STATE_CACHED = \'cached\'\nEXECUTION_STATE_COMPLETE = \'complete\'\nEXECUTION_STATE_NEW = \'new\'\nFINAL_EXECUTION_STATES = frozenset(\n    (EXECUTION_STATE_CACHED, EXECUTION_STATE_COMPLETE))\n# Context type, the following three types of contexts are supported:\n#  - pipeline level context is shared within one pipeline, across multiple\n#    pipeline runs.\n#  - pipeline run level context is shared within one pipeline run, across\n#    all component executions in that pipeline run.\n#  - component run level context is shared within one component run.\n_CONTEXT_TYPE_PIPELINE = \'pipeline\'\n_CONTEXT_TYPE_PIPELINE_RUN = \'run\'\n_CONTEXT_TYPE_COMPONENT_RUN = \'component_run\'\n# Keys of context type properties.\n_CONTEXT_TYPE_KEY_COMPONENT_ID = \'component_id\'\n_CONTEXT_TYPE_KEY_PIPELINE_NAME = \'pipeline_name\'\n_CONTEXT_TYPE_KEY_RUN_ID = \'run_id\'\n# Keys of execution type properties.\n_EXECUTION_TYPE_KEY_CHECKSUM = \'checksum_md5\'\n_EXECUTION_TYPE_KEY_COMPONENT_ID = \'component_id\'\n_EXECUTION_TYPE_KEY_PIPELINE_NAME = \'pipeline_name\'\n_EXECUTION_TYPE_KEY_PIPELINE_ROOT = \'pipeline_root\'\n_EXECUTION_TYPE_KEY_RUN_ID = \'run_id\'\n_EXECUTION_TYPE_KEY_STATE = \'state\'\n_EXECUTION_TYPE_RESERVED_KEYS = frozenset(\n    (_EXECUTION_TYPE_KEY_CHECKSUM, _EXECUTION_TYPE_KEY_PIPELINE_NAME,\n     _EXECUTION_TYPE_KEY_PIPELINE_ROOT, _EXECUTION_TYPE_KEY_RUN_ID,\n     _EXECUTION_TYPE_KEY_COMPONENT_ID, _EXECUTION_TYPE_KEY_STATE))\n# Keys for artifact properties.\n_ARTIFACT_TYPE_KEY_STATE = \'state\'\n\n\ndef sqlite_metadata_connection_config(\n    metadata_db_uri: Text) -> metadata_store_pb2.ConnectionConfig:\n  """"""Convenience function to create file based metadata connection config.\n\n  Args:\n    metadata_db_uri: uri to metadata db.\n\n  Returns:\n    A metadata_store_pb2.ConnectionConfig based on given metadata db uri.\n  """"""\n  tf.io.gfile.makedirs(os.path.dirname(metadata_db_uri))\n  connection_config = metadata_store_pb2.ConnectionConfig()\n  connection_config.sqlite.filename_uri = metadata_db_uri\n  connection_config.sqlite.connection_mode = \\\n    metadata_store_pb2.SqliteMetadataSourceConfig.READWRITE_OPENCREATE\n  return connection_config\n\n\ndef mysql_metadata_connection_config(\n    host: Text, port: int, database: Text, username: Text,\n    password: Text) -> metadata_store_pb2.ConnectionConfig:\n  """"""Convenience function to create mysql-based metadata connection config.\n\n  Args:\n    host: The name or network address of the instance of MySQL to connect to.\n    port: The port MySQL is using to listen for connections.\n    database: The name of the database to use.\n    username: The MySQL login account being used.\n    password: The password for the MySQL account being used.\n\n  Returns:\n    A metadata_store_pb2.ConnectionConfig based on given metadata db uri.\n  """"""\n  return metadata_store_pb2.ConnectionConfig(\n      mysql=metadata_store_pb2.MySQLDatabaseConfig(\n          host=host,\n          port=port,\n          database=database,\n          user=username,\n          password=password))\n\n\n# TODO(ruoyu): Figure out the story mutable UDFs. We should not reuse previous\n# run when having different UDFs.\nclass Metadata(object):\n  """"""Helper class to handle metadata I/O.""""""\n\n  def __init__(\n      self,\n      connection_config: Union[metadata_store_pb2.ConnectionConfig,\n                               metadata_store_pb2.MetadataStoreClientConfig]\n  ) -> None:\n    self._connection_config = connection_config\n    self._store = None\n\n  def __enter__(self) -> \'Metadata\':\n    # TODO(ruoyu): Establishing a connection pool instead of newing\n    # a connection every time. Until then, check self._store before usage\n    # in every method.\n    connection_error = None\n    for _ in range(_MAX_INIT_RETRY):\n      try:\n        self._store = metadata_store.MetadataStore(self._connection_config)\n      except RuntimeError as err:\n        # MetadataStore could raise Aborted error if multiple concurrent\n        # connections try to execute initialization DDL in database.\n        # This is safe to retry.\n        connection_error = err\n        time.sleep(random.random())\n        continue\n      else:\n        return self\n\n    raise RuntimeError(\n        \'Failed to establish connection to Metadata storage with error: %s\' %\n        connection_error)\n\n  def __exit__(self, exc_type: Optional[Type[Exception]],\n               exc_value: Optional[Exception],\n               exc_tb: Optional[types.TracebackType]) -> None:\n    self._store = None\n\n  @property\n  def store(self) -> metadata_store.MetadataStore:\n    """"""Returns underlying MetadataStore.\n\n    Raises:\n      RuntimeError: if this instance is not in enter state.\n    """"""\n    if self._store is None:\n      raise RuntimeError(\'Metadata object is not in enter state\')\n    return self._store\n\n  def _prepare_artifact_type(\n      self, artifact_type: metadata_store_pb2.ArtifactType\n  ) -> metadata_store_pb2.ArtifactType:\n    if artifact_type.id:\n      return artifact_type\n    type_id = self.store.put_artifact_type(\n        artifact_type=artifact_type, can_add_fields=True)\n    artifact_type.id = type_id\n    return artifact_type\n\n  def update_artifact_state(self, artifact: metadata_store_pb2.Artifact,\n                            new_state: Text) -> None:\n    """"""Update the state of a given artifact.""""""\n    if not artifact.id:\n      raise ValueError(\'Artifact id missing for %s\' % artifact)\n    # TODO(b/146936257): unify artifact access logic by wrapping raw MLMD\n    # artifact protos into tfx.types.Artifact objects at a lower level.\n    if _ARTIFACT_TYPE_KEY_STATE in artifact.properties:\n      artifact.properties[_ARTIFACT_TYPE_KEY_STATE].string_value = new_state\n    else:\n      artifact.custom_properties[\n          _ARTIFACT_TYPE_KEY_STATE].string_value = new_state\n    self.store.put_artifacts([artifact])\n\n  def _upsert_artifacts(self, tfx_artifact_list: List[Artifact],\n                        state: Text) -> None:\n    """"""Updates or inserts a list of artifacts.\n\n    This call will also update original tfx artifact list to contain the\n    artifact type info and artifact id.\n\n    Args:\n      tfx_artifact_list: A list of tfx.types.Artifact. This will be updated with\n        MLMD artifact type info and MLMD artifact id.\n      state: the artifact state to set.\n    """"""\n    for raw_artifact in tfx_artifact_list:\n      if not raw_artifact.type_id:\n        artifact_type = self._prepare_artifact_type(raw_artifact.artifact_type)\n        raw_artifact.set_mlmd_artifact_type(artifact_type)\n      raw_artifact.state = state\n    artifact_ids = self.store.put_artifacts(\n        [x.mlmd_artifact for x in tfx_artifact_list])\n    for a, aid in zip(tfx_artifact_list, artifact_ids):\n      a.id = aid\n\n  def publish_artifacts(self, tfx_artifact_list: List[Artifact]) -> None:\n    """"""Publishes artifacts to MLMD.\n\n    This call will also update original tfx artifact list to contain the\n    artifact type info and artifact id.\n\n    Args:\n      tfx_artifact_list: A list of tfx.types.Artifact which will be updated\n    """"""\n    self._upsert_artifacts(tfx_artifact_list, ArtifactState.PUBLISHED)\n\n  def get_artifacts_by_uri(self,\n                           uri: Text) -> List[metadata_store_pb2.Artifact]:\n    """"""Fetches artifacts given uri.""""""\n    return self.store.get_artifacts_by_uri(uri)\n\n  def get_artifacts_by_type(\n      self, type_name: Text) -> List[metadata_store_pb2.Artifact]:\n    """"""Fetches artifacts given artifact type name.""""""\n    return self.store.get_artifacts_by_type(type_name)\n\n  # TODO(b/145751019): Remove this once migrated to use MLMD built-in states.\n  def _get_artifact_state(\n      self, artifact: metadata_store_pb2.Artifact) -> Optional[Text]:\n    """"""Gets artifact state string if available.""""""\n    if _ARTIFACT_TYPE_KEY_STATE in artifact.properties:\n      return artifact.properties[_ARTIFACT_TYPE_KEY_STATE].string_value\n    elif _ARTIFACT_TYPE_KEY_STATE in artifact.custom_properties:\n      return artifact.custom_properties[_ARTIFACT_TYPE_KEY_STATE].string_value\n    else:\n      return None\n\n  def get_published_artifacts_by_type_within_context(\n      self, type_names: List[Text],\n      context_id: int) -> Dict[Text, List[metadata_store_pb2.Artifact]]:\n    """"""Fetches artifacts given artifact type name and context id.""""""\n    result = dict((type_name, []) for type_name in type_names)\n    all_artifacts_in_context = self.store.get_artifacts_by_context(context_id)\n    for type_name in type_names:\n      try:\n        artifact_type = self.store.get_artifact_type(type_name)\n        if artifact_type is None:\n          raise tf.errors.NotFoundError(None, None, \'No type found.\')\n      except tf.errors.NotFoundError:\n        absl.logging.warning(\'Artifact type %s not registered\' % type_name)\n        continue\n\n      result[type_name] = [\n          a for a in all_artifacts_in_context\n          if a.type_id == artifact_type.id and\n          self._get_artifact_state(a) == ArtifactState.PUBLISHED\n      ]\n    return result\n\n  def get_qualified_artifacts(\n      self,\n      contexts: List[metadata_store_pb2.Context],\n      type_name: Text,\n      producer_component_id: Optional[Text] = None,\n      output_key: Optional[Text] = None,\n  ) -> List[metadata_store_service_pb2.ArtifactAndType]:\n    """"""Gets qualified artifacts that have the right producer info.\n\n    Args:\n      contexts: context constraints to filter artifacts\n      type_name: type constraint to filter artifacts\n      producer_component_id: producer constraint to filter artifacts\n      output_key: output key constraint to filter artifacts\n\n    Returns:\n      A list of ArtifactAndType, containing qualified artifacts.\n    """"""\n\n    def _match_producer_component_id(execution, component_id):\n      if component_id:\n        return execution.properties[\n            _EXECUTION_TYPE_KEY_COMPONENT_ID].string_value == component_id\n      else:\n        return True\n\n    def _match_output_key(event, key):\n      if key:\n        assert len(event.path.steps) == 2, \'Event must have two path steps.\'\n        return (event.type == metadata_store_pb2.Event.OUTPUT and\n                event.path.steps[0].key == key)\n      else:\n        return event.type == metadata_store_pb2.Event.OUTPUT\n\n    try:\n      artifact_type = self.store.get_artifact_type(type_name)\n      if not artifact_type:\n        raise tf.errors.NotFoundError(\n            None, None, \'No artifact type found for %s.\' % type_name)\n    except tf.errors.NotFoundError:\n      return []\n\n    # Gets the executions that are associated with all contexts.\n    assert contexts, \'Must have at least one context.\'\n    executions_dict = {}\n    for context in contexts:\n      executions = self.store.get_executions_by_context(context.id)\n      executions_dict.update(dict((e.id, e) for e in executions))\n\n    executions_within_context = executions_dict.values()\n\n    # Filters the executions to match producer component id.\n    qualified_producer_executions = [\n        e.id\n        for e in executions_within_context\n        if _match_producer_component_id(e, producer_component_id)\n    ]\n    # Gets the output events that have the matched output key.\n    qualified_output_events = [\n        ev for ev in self.store.get_events_by_execution_ids(\n            qualified_producer_executions) if _match_output_key(ev, output_key)\n    ]\n\n    # Gets the candidate artifacts from output events.\n    candidate_artifacts = self.store.get_artifacts_by_id(\n        list(set(ev.artifact_id for ev in qualified_output_events)))\n    # Filters the artifacts that have the right artifact type and state.\n    qualified_artifacts = [\n        a for a in candidate_artifacts if a.type_id == artifact_type.id and\n        self._get_artifact_state(a) == ArtifactState.PUBLISHED\n    ]\n    return [\n        metadata_store_service_pb2.ArtifactAndType(\n            artifact=a, type=artifact_type) for a in qualified_artifacts\n    ]\n\n  def _prepare_event(self,\n                     event_type: metadata_store_pb2.Event.Type,\n                     execution_id: Optional[int] = None,\n                     artifact_id: Optional[int] = None,\n                     key: Optional[Text] = None,\n                     index: Optional[int] = None) -> metadata_store_pb2.Event:\n    """"""Commits a single event to the repository.""""""\n    event = metadata_store_pb2.Event()\n    event.type = event_type\n    if execution_id:\n      event.execution_id = execution_id\n    if artifact_id:\n      event.artifact_id = artifact_id\n    if key is not None:\n      step = event.path.steps.add()\n      step.key = key\n    if index is not None:\n      step = event.path.steps.add()\n      step.index = index\n    return event\n\n  # TODO(b/143081379): We might need to revisit schema evolution story.\n  def _prepare_execution_type(self, type_name: Text,\n                              exec_properties: Dict[Text, Any]) -> int:\n    """"""Gets execution type given execution type name and properties.\n\n    Uses existing type if schema is superset of what is needed. Otherwise tries\n    to register new execution type.\n\n    Args:\n      type_name: the name of the execution type\n      exec_properties: the execution properties included by the execution\n\n    Returns:\n      execution type id\n    Raises:\n      ValueError if new execution type conflicts with existing schema in MLMD.\n    """"""\n    try:\n      existing_execution_type = self.store.get_execution_type(type_name)\n      if existing_execution_type is None:\n        raise RuntimeError(\'Execution type is None for %s.\' % type_name)\n      if all(k in existing_execution_type.properties\n             for k in exec_properties.keys()):\n        return existing_execution_type.id\n      else:\n        raise tf.errors.NotFoundError(None, None,\n                                      \'No qualified execution type found.\')\n    except tf.errors.NotFoundError:\n      execution_type = metadata_store_pb2.ExecutionType(name=type_name)\n      execution_type.properties[\n          _EXECUTION_TYPE_KEY_STATE] = metadata_store_pb2.STRING\n      # If exec_properties contains new entries, execution type schema will be\n      # updated in MLMD.\n      for k in exec_properties.keys():\n        assert k not in _EXECUTION_TYPE_RESERVED_KEYS, (\n            \'execution properties with reserved key %s\') % k\n        execution_type.properties[k] = metadata_store_pb2.STRING\n      # TODO(ruoyu): Find a better place / solution to the checksum logic.\n      if \'module_file\' in exec_properties:\n        execution_type.properties[\n            _EXECUTION_TYPE_KEY_CHECKSUM] = metadata_store_pb2.STRING\n      execution_type.properties[\n          _EXECUTION_TYPE_KEY_PIPELINE_NAME] = metadata_store_pb2.STRING\n      execution_type.properties[\n          _EXECUTION_TYPE_KEY_PIPELINE_ROOT] = metadata_store_pb2.STRING\n      execution_type.properties[\n          _EXECUTION_TYPE_KEY_RUN_ID] = metadata_store_pb2.STRING\n      execution_type.properties[\n          _EXECUTION_TYPE_KEY_COMPONENT_ID] = metadata_store_pb2.STRING\n\n      try:\n        execution_type_id = self.store.put_execution_type(\n            execution_type=execution_type, can_add_fields=True)\n        absl.logging.debug(\'Registering a new execution type with id %s.\' %\n                           execution_type_id)\n        return execution_type_id\n      except tf.errors.AlreadyExistsError:\n        warning_str = (\n            \'missing or modified key in exec_properties comparing with \'\n            \'existing execution type with the same type name. Existing type: \'\n            \'%s, New type: %s\') % (existing_execution_type, execution_type)\n        absl.logging.warning(warning_str)\n        raise ValueError(warning_str)\n\n  def _update_execution_proto(\n      self,\n      execution: metadata_store_pb2.Execution,\n      pipeline_info: Optional[data_types.PipelineInfo] = None,\n      component_info: Optional[data_types.ComponentInfo] = None,\n      state: Optional[Text] = None,\n      exec_properties: Optional[Dict[Text, Any]] = None,\n  ) -> metadata_store_pb2.Execution:\n    """"""Updates the execution proto with given type and state.""""""\n    if state is not None:\n      execution.properties[\n          _EXECUTION_TYPE_KEY_STATE].string_value = tf.compat.as_text(state)\n    exec_properties = exec_properties or {}\n    # TODO(ruoyu): Enforce a formal rule for execution schema change.\n    for k, v in exec_properties.items():\n      # We always convert execution properties to unicode.\n      execution.properties[k].string_value = tf.compat.as_text(\n          tf.compat.as_str_any(v))\n    # We also need to checksum UDF file to identify different binary being\n    # used. Do we have a better way to checksum a file than hashlib.md5?\n    # TODO(ruoyu): Find a better place / solution to the checksum logic.\n    # TODO(ruoyu): SHA instead of MD5.\n    if \'module_file\' in exec_properties and exec_properties[\n        \'module_file\'] and tf.io.gfile.exists(exec_properties[\'module_file\']):\n      contents = file_io.read_file_to_string(exec_properties[\'module_file\'])\n      execution.properties[\'checksum_md5\'].string_value = tf.compat.as_text(\n          tf.compat.as_str_any(\n              hashlib.md5(tf.compat.as_bytes(contents)).hexdigest()))\n    if pipeline_info:\n      execution.properties[\n          \'pipeline_name\'].string_value = pipeline_info.pipeline_name\n      execution.properties[\n          \'pipeline_root\'].string_value = pipeline_info.pipeline_root\n      if pipeline_info.run_id:\n        execution.properties[\'run_id\'].string_value = pipeline_info.run_id\n    if component_info:\n      execution.properties[\n          \'component_id\'].string_value = component_info.component_id\n    return execution\n\n  def _prepare_execution(\n      self,\n      state: Text,\n      exec_properties: Dict[Text, Any],\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> metadata_store_pb2.Execution:\n    """"""Creates an execution proto based on the information provided.""""""\n    execution = metadata_store_pb2.Execution()\n    execution.type_id = self._prepare_execution_type(\n        component_info.component_type, exec_properties)\n    self._update_execution_proto(\n        execution=execution,\n        pipeline_info=pipeline_info,\n        component_info=component_info,\n        exec_properties=exec_properties,\n        state=state)\n    absl.logging.debug(\'Prepared EXECUTION:\\n %s\', execution)\n    return execution\n\n  def _artifact_and_event_pairs(\n      self,\n      artifact_dict: Dict[Text, List[Artifact]],\n      event_type: metadata_store_pb2.Event.Type,\n      new_state: Optional[Text] = None,\n      registered_artifacts_ids: Optional[Set[int]] = None\n  ) -> List[Tuple[metadata_store_pb2.Artifact,\n                  Optional[metadata_store_pb2.Event]]]:\n    """"""Creates a list of [Artifact, [Optional]Event] tuples.\n\n    The result of this function will be used in a MLMD put_execution() call. The\n    artifacts will be linked to certain contexts. If an artifact is attached\n    with an event, it will be linked with the execution through the event\n    created.\n\n    When the id of an artifact is in the registered_artifacts_ids, no event is\n    attached to it. Otherwise, an event with given type will be attached to the\n    artifact.\n\n    Args:\n      artifact_dict: the source of artifacts to work on. For each artifact in\n        the dict, creates a tuple for that\n      event_type: the event type of the event to be attached to the artifact\n      new_state: new state of the artifacts\n      registered_artifacts_ids: artifact ids to bypass event creation since they\n        are regarded already registered\n\n    Returns:\n      A list of [Artifact, [Optional]Event] tuples\n    """"""\n    registered_artifacts_ids = registered_artifacts_ids or {}\n    result = []\n    for key, a_list in artifact_dict.items():\n      for index, a in enumerate(a_list):\n        if new_state:\n          a.state = new_state\n        if a.id and a.id in registered_artifacts_ids:\n          result.append(tuple([a.mlmd_artifact]))\n        else:\n          a.set_mlmd_artifact_type(self._prepare_artifact_type(a.artifact_type))\n          result.append(\n              (a.mlmd_artifact,\n               self._prepare_event(event_type=event_type, key=key,\n                                   index=index)))\n    return result\n\n  def update_execution(\n      self,\n      execution: metadata_store_pb2.Execution,\n      component_info: data_types.ComponentInfo,\n      input_artifacts: Optional[Dict[Text, List[Artifact]]] = None,\n      output_artifacts: Optional[Dict[Text, List[Artifact]]] = None,\n      exec_properties: Optional[Dict[Text, Any]] = None,\n      execution_state: Optional[Text] = None,\n      artifact_state: Optional[Text] = None,\n      contexts: Optional[List[metadata_store_pb2.Context]] = None) -> None:\n    """"""Updates the given execution in MLMD based on given information.\n\n    All artifacts provided will be registered if not already. Registered id will\n    be reflected inline.\n\n    Args:\n      execution: the execution to be updated. It is required that the execution\n        passed in has an id.\n      component_info: the information of the current running component\n      input_artifacts: artifacts to be declared as inputs of the execution\n      output_artifacts: artifacts to be declared as outputs of the execution\n      exec_properties: execution properties of the execution\n      execution_state: state the execution to be updated to\n      artifact_state: state the artifacts to be updated to\n      contexts: a list of contexts the execution and artifacts to be linked to\n\n    Raises:\n      RuntimeError: if the execution to be updated has no id.\n    """"""\n    if not execution.id:\n      raise RuntimeError(\'No id attached to the execution to be updated.\')\n    events = self.store.get_events_by_execution_ids([execution.id])\n    registered_input_artifact_ids = set(\n        e.artifact_id\n        for e in events\n        if e.type == metadata_store_pb2.Event.INPUT)\n    registered_output_artifact_ids = set(\n        e.artifact_id\n        for e in events\n        if e.type == metadata_store_pb2.Event.OUTPUT)\n    artifacts_and_events = []\n    if input_artifacts:\n      artifacts_and_events.extend(\n          self._artifact_and_event_pairs(\n              artifact_dict=input_artifacts,\n              event_type=metadata_store_pb2.Event.INPUT,\n              new_state=artifact_state,\n              registered_artifacts_ids=registered_input_artifact_ids))\n    if output_artifacts:\n      artifacts_and_events.extend(\n          self._artifact_and_event_pairs(\n              artifact_dict=output_artifacts,\n              event_type=metadata_store_pb2.Event.OUTPUT,\n              new_state=artifact_state,\n              registered_artifacts_ids=registered_output_artifact_ids))\n    # If execution properties change, we need to potentially update execution\n    # schema.\n    if exec_properties:\n      execution.type_id = self._prepare_execution_type(\n          component_info.component_type, exec_properties)\n    if exec_properties or execution_state:\n      self._update_execution_proto(\n          execution=execution,\n          exec_properties=exec_properties,\n          state=execution_state,\n          pipeline_info=component_info.pipeline_info,\n          component_info=component_info)\n    _, a_ids, _ = self.store.put_execution(execution, artifacts_and_events,\n                                           contexts or [])\n    for artifact_and_event, a_id in zip(artifacts_and_events, a_ids):\n      artifact_and_event[0].id = a_id\n\n  def register_execution(\n      self,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n      contexts: List[metadata_store_pb2.Context],\n      exec_properties: Optional[Dict[Text, Any]] = None,\n      input_artifacts: Optional[Dict[Text, List[Artifact]]] = None\n  ) -> metadata_store_pb2.Execution:\n    """"""Registers a new execution in metadata.\n\n    Args:\n      pipeline_info: optional pipeline info of the execution.\n      component_info: optional component info of the execution.\n      contexts: contexts for current run, all contexts will be linked to the\n        execution. In addition, a component run context will be added to the\n        contexts list.\n      exec_properties: the execution properties of the execution.\n      input_artifacts: input artifacts of the execution.\n\n    Returns:\n      execution id of the new execution.\n    """"""\n    input_artifacts = input_artifacts or {}\n    exec_properties = exec_properties or {}\n    execution = self._prepare_execution(EXECUTION_STATE_NEW, exec_properties,\n                                        pipeline_info, component_info)\n    artifacts_and_events = self._artifact_and_event_pairs(\n        artifact_dict=input_artifacts,\n        event_type=metadata_store_pb2.Event.INPUT)\n    component_run_context = self._prepare_context(\n        context_type_name=_CONTEXT_TYPE_COMPONENT_RUN,\n        context_name=component_info.component_run_context_name,\n        properties={\n            _CONTEXT_TYPE_KEY_PIPELINE_NAME: pipeline_info.pipeline_name,\n            _CONTEXT_TYPE_KEY_RUN_ID: pipeline_info.run_id,\n            _CONTEXT_TYPE_KEY_COMPONENT_ID: component_info.component_id\n        })\n    # Tries to register the execution along with a component run context. If the\n    # context already exists, reuse the context and update the existing\n    # execution.\n    try:\n      execution_id, a_ids, context_ids = self.store.put_execution(\n          execution=execution,\n          artifact_and_events=artifacts_and_events,\n          contexts=contexts + [component_run_context])\n      execution.id = execution_id\n      component_run_context.id = context_ids[-1]\n    except tf.errors.AlreadyExistsError:\n      component_run_context = self.get_component_run_context(component_info)\n      absl.logging.debug(\n          \'Component run context already exists. Reusing the context %s.\',\n          component_run_context.name)\n      [previous_execution] = self.store.get_executions_by_context(\n          context_id=component_run_context.id)\n      execution.id = previous_execution.id\n      _, a_ids, _ = self.store.put_execution(\n          execution=execution,\n          artifact_and_events=artifacts_and_events,\n          contexts=contexts + [component_run_context])\n    contexts.append(component_run_context)\n    for artifact_and_event, a_id in zip(artifacts_and_events, a_ids):\n      artifact_and_event[0].id = a_id\n    return execution\n\n  def publish_execution(\n      self,\n      component_info: data_types.ComponentInfo,\n      output_artifacts: Optional[Dict[Text, List[Artifact]]] = None,\n      exec_properties: Optional[Dict[Text, Any]] = None) -> None:\n    """"""Publishes an execution with input and output artifacts info.\n\n    This method will publish any execution with non-final states. It will\n    register unseen artifacts and publish events for them.\n\n    Args:\n      component_info: component information.\n      output_artifacts: output artifacts produced by the execution.\n      exec_properties: execution properties for the execution to be published.\n    """"""\n    component_run_context = self.get_component_run_context(component_info)\n    [execution] = self.store.get_executions_by_context(component_run_context.id)\n    contexts = [\n        component_run_context,\n        self.get_pipeline_run_context(component_info.pipeline_info),\n        self.get_pipeline_context(component_info.pipeline_info)\n    ]\n    contexts = [ctx for ctx in contexts if ctx is not None]\n    # If execution state is already in final state, skips publishing.\n    if execution.properties[\n        _EXECUTION_TYPE_KEY_STATE].string_value in FINAL_EXECUTION_STATES:\n      return\n    self.update_execution(\n        execution=execution,\n        component_info=component_info,\n        output_artifacts=output_artifacts,\n        exec_properties=exec_properties,\n        execution_state=EXECUTION_STATE_COMPLETE,\n        artifact_state=ArtifactState.PUBLISHED,\n        contexts=contexts)\n\n  def _is_eligible_previous_execution(\n      self, current_execution: metadata_store_pb2.Execution,\n      target_execution: metadata_store_pb2.Execution) -> bool:\n    """"""Compare if the previous execution is same as current execution.\n\n    This method will ignore ID and time related fields.\n\n    Args:\n      current_execution: the current execution.\n      target_execution: the previous execution to be compared with.\n\n    Returns:\n      whether the previous and current executions are the same.\n    """"""\n    current_execution.properties[\'run_id\'].string_value = \'\'\n    target_execution.properties[\'run_id\'].string_value = \'\'\n    current_execution.id = target_execution.id\n    # Skip comparing time sensitive fields.\n    # The execution might not have the create_time_since_epoch or\n    # create_time_since_epoch field if the execution is created by an old\n    # version before this field is introduced.\n    if hasattr(current_execution, \'create_time_since_epoch\'):\n      current_execution.ClearField(\'create_time_since_epoch\')\n    if hasattr(target_execution, \'create_time_since_epoch\'):\n      target_execution.ClearField(\'create_time_since_epoch\')\n    if hasattr(current_execution, \'last_update_time_since_epoch\'):\n      current_execution.ClearField(\'last_update_time_since_epoch\')\n    if hasattr(target_execution, \'last_update_time_since_epoch\'):\n      target_execution.ClearField(\'last_update_time_since_epoch\')\n    return current_execution == target_execution\n\n  def get_cached_outputs(\n      self, input_artifacts: Dict[Text, List[Artifact]],\n      exec_properties: Dict[Text, Any], pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo\n  ) -> Optional[Dict[Text, List[Artifact]]]:\n    """"""Fetches cached output artifacts if any.\n\n    Returns the output artifacts of a cached execution if any. An eligible\n    cached execution should take the same input artifacts, execution properties\n    and is associated with the same pipeline context.\n\n    Args:\n      input_artifacts: inputs used by the run.\n      exec_properties: execution properties used by the run.\n      pipeline_info: info of the current pipeline run.\n      component_info: info of the current component.\n\n    Returns:\n      Dict of cached output artifacts if eligible cached execution is found.\n      Otherwise, return None.\n    """"""\n    absl.logging.debug(\n        (\'Trying to fetch cached output artifacts with the following info: \\n\'\n         \'input_artifacts: %s \\n\'\n         \'exec_properties: %s \\n\'\n         \'component_info %s\') %\n        (input_artifacts, exec_properties, component_info))\n\n    # Step 0: Finds the context of the pipeline. No context means no valid cache\n    # results.\n    context = self.get_pipeline_context(pipeline_info)\n    if context is None:\n      absl.logging.warning(\'Pipeline context not available for %s\' %\n                           pipeline_info)\n      return None\n\n    # Step 1: Finds historical executions related to the context in step 0.\n    historical_executions = dict(\n        (e.id, e) for e in self._store.get_executions_by_context(context.id))\n\n    # Step 2: Filters historical executions to find those that used all the\n    # given inputs as input artifacts. The result of this step is a set of\n    # reversely sorted execution ids.\n    input_ids = collections.defaultdict(set)\n    for key, input_list in input_artifacts.items():\n      for single_input in input_list:\n        input_ids[key].add(single_input.mlmd_artifact.id)\n    artifact_to_executions = collections.defaultdict(set)\n    for event in self.store.get_events_by_artifact_ids(\n        list(set(itertools.chain.from_iterable(input_ids.values())))):\n      if event.type == metadata_store_pb2.Event.INPUT:\n        artifact_to_executions[event.artifact_id].add(event.execution_id)\n    common_execution_ids = sorted(\n        set.intersection(\n            set(historical_executions.keys()),\n            *(artifact_to_executions.values())),\n        reverse=True)\n\n    # Step 3: Filters candidate executions further based on the followings:\n    #   - Shares the given properties\n    #   - Is in complete state\n    # The maximum number of candidates is capped by MAX_EXECUTIONS_FOR_CACHE.\n    expected_previous_execution = self._prepare_execution(\n        EXECUTION_STATE_COMPLETE,\n        exec_properties,\n        pipeline_info=pipeline_info,\n        component_info=component_info)\n\n    candidate_execution_ids = [\n        e_id for e_id in common_execution_ids  # pylint: disable=g-complex-comprehension\n        if self._is_eligible_previous_execution(\n            copy.deepcopy(expected_previous_execution),\n            copy.deepcopy(historical_executions[e_id]))\n    ]\n    candidate_execution_ids = candidate_execution_ids[\n        0:min(len(candidate_execution_ids), MAX_EXECUTIONS_FOR_CACHE)]\n\n    # Step 4: Traverse all candidates, if the input artifacts of a candidate\n    # match given input artifacts, return the output artifacts of that execution\n    # as result. Note that this is necessary since a candidate execution might\n    # use more than the given artifacts.\n    candidate_execution_to_events = collections.defaultdict(list)\n    for event in self.store.get_events_by_execution_ids(\n        candidate_execution_ids):\n      candidate_execution_to_events[event.execution_id].append(event)\n    for execution_id, events in candidate_execution_to_events.items():\n      # Creates the {key -> artifact id set} for the candidate execution.\n      current_input_ids = collections.defaultdict(set)\n      for event in events:\n        if event.type == metadata_store_pb2.Event.INPUT:\n          current_input_ids[event.path.steps[0].key].add(event.artifact_id)\n      # If all inputs match, tries to get the outputs of the execution and uses\n      # as the cached outputs of the current execution.\n      if current_input_ids == input_ids:\n        cached_outputs = self._get_outputs_of_execution(\n            execution_id=execution_id, events=events)\n        if cached_outputs is not None:\n          return cached_outputs\n\n    return None\n\n  def _get_outputs_of_execution(\n      self, execution_id: int, events: List[metadata_store_pb2.Event]\n  ) -> Optional[Dict[Text, List[Artifact]]]:\n    """"""Fetches outputs produced by a historical execution.\n\n    Args:\n      execution_id: the id of the execution that produced the outputs.\n      events: events related to the execution id.\n\n    Returns:\n      A dict of key -> List[Artifact] as the result\n    """"""\n\n    absl.logging.debug(\'Execution %s matches all inputs\' % execution_id)\n    result = collections.defaultdict(list)\n\n    output_events = [\n        event for event in events\n        if event.type in [metadata_store_pb2.Event.OUTPUT]\n    ]\n    output_events.sort(key=lambda e: e.path.steps[1].index)\n    cached_output_artifacts = self.store.get_artifacts_by_id(\n        [e.artifact_id for e in output_events])\n    artifact_types = self.store.get_artifact_types_by_id(\n        [a.type_id for a in cached_output_artifacts])\n\n    for event, mlmd_artifact, artifact_type in zip(output_events,\n                                                   cached_output_artifacts,\n                                                   artifact_types):\n      key = event.path.steps[0].key\n      tfx_artifact = artifact_utils.deserialize_artifact(\n          artifact_type, mlmd_artifact)\n      result[key].append(tfx_artifact)\n\n    return result\n\n  def search_artifacts(self, artifact_name: Text,\n                       pipeline_info: data_types.PipelineInfo,\n                       producer_component_id: Text) -> List[Artifact]:\n    """"""Search artifacts that matches given info.\n\n    Args:\n      artifact_name: the name of the artifact that set by producer component.\n        The name is logged both in artifacts and the events when the execution\n        being published.\n      pipeline_info: the information of the current pipeline\n      producer_component_id: the id of the component that produces the artifact\n\n    Returns:\n      A list of Artifacts that matches the given info\n\n    Raises:\n      RuntimeError: when no matching execution is found given producer info.\n    """"""\n    producer_execution = None\n    matching_artifact_ids = set()\n    # TODO(ruoyu): We need to revisit this when adding support for async\n    # execution.\n    context = self.get_pipeline_run_context(pipeline_info)\n    if context is None:\n      raise RuntimeError(\'Pipeline run context for %s does not exist\' %\n                         pipeline_info)\n    for execution in self.store.get_executions_by_context(context.id):\n      if execution.properties[\n          \'component_id\'].string_value == producer_component_id:\n        producer_execution = execution\n        break\n    if not producer_execution:\n      raise RuntimeError(\'Cannot find matching execution with pipeline name %s,\'\n                         \'run id %s and component id %s\' %\n                         (pipeline_info.pipeline_name, pipeline_info.run_id,\n                          producer_component_id))\n    for event in self.store.get_events_by_execution_ids([producer_execution.id\n                                                        ]):\n      if (event.type == metadata_store_pb2.Event.OUTPUT and\n          event.path.steps[0].key == artifact_name):\n        matching_artifact_ids.add(event.artifact_id)\n\n    # Get relevant artifacts along with their types.\n    artifacts_by_id = self.store.get_artifacts_by_id(\n        list(matching_artifact_ids))\n    matching_artifact_type_ids = list(set(a.type_id for a in artifacts_by_id))\n    matching_artifact_types = self.store.get_artifact_types_by_id(\n        matching_artifact_type_ids)\n    artifact_types = dict(\n        zip(matching_artifact_type_ids, matching_artifact_types))\n\n    result_artifacts = []\n    for a in artifacts_by_id:\n      tfx_artifact = artifact_utils.deserialize_artifact(\n          artifact_types[a.type_id], a)\n      result_artifacts.append(tfx_artifact)\n    return result_artifacts\n\n  def _register_context_type_if_not_exist(\n      self, context_type_name: Text,\n      properties: Dict[Text, \'metadata_store_pb2.PropertyType\']) -> int:\n    """"""Registers a context type if not exist, otherwise returns existing one.\n\n    Args:\n      context_type_name: the name of the context.\n      properties: properties of the context.\n\n    Returns:\n      id of the desired context type.\n    """"""\n    context_type = metadata_store_pb2.ContextType(name=context_type_name)\n    for k, t in properties.items():\n      context_type.properties[k] = t\n    context_type_id = self.store.put_context_type(\n        context_type, can_add_fields=True)\n\n    return context_type_id\n\n  def _prepare_context(\n      self,\n      context_type_name: Text,\n      context_name: Text,\n      properties: Optional[Dict[Text, Union[int, float, Text]]] = None\n  ) -> metadata_store_pb2.Context:\n    """"""Prepares a context proto.""""""\n    # TODO(ruoyu): Centralize the type definition / mapping along with Artifact\n    # property types.\n    properties = properties or {}\n    property_type_mapping = {\n        int: metadata_store_pb2.INT,\n        six.binary_type: metadata_store_pb2.STRING,\n        six.text_type: metadata_store_pb2.STRING,\n        float: metadata_store_pb2.DOUBLE\n    }\n    context_type_id = self._register_context_type_if_not_exist(\n        context_type_name,\n        dict(\n            (k, property_type_mapping[type(k)]) for k, v in properties.items()))\n\n    context = metadata_store_pb2.Context(\n        type_id=context_type_id, name=context_name)\n    for k, v in properties.items():\n      if isinstance(v, int):\n        context.properties[k].int_value = v\n      elif isinstance(v, six.string_types):\n        context.properties[k].string_value = v\n      elif isinstance(v, float):\n        context.properties[k].double_value = v\n      else:\n        raise RuntimeError(\'Unexpected property type: %s\' % type(v))\n    return context\n\n  def _register_context_if_not_exist(\n      self, context_type_name: Text, context_name: Text,\n      properties: Dict[Text, Union[int, float, Text]]\n  ) -> metadata_store_pb2.Context:\n    """"""Registers a context if not exist, otherwise returns the existing one.\n\n    Args:\n      context_type_name: the name of the context type desired.\n      context_name: the name of the context.\n      properties: properties to set in the context.\n\n    Returns:\n      id of the desired context\n\n    Raises:\n      RuntimeError: when meeting unexpected property type.\n    """"""\n    context = self._prepare_context(\n        context_type_name=context_type_name,\n        context_name=context_name,\n        properties=properties)\n    try:\n      [context_id] = self.store.put_contexts([context])\n      context.id = context_id\n    except tf.errors.AlreadyExistsError:\n      absl.logging.debug(\'Run context %s already exists.\', context_name)\n      context = self.store.get_context_by_type_and_name(context_type_name,\n                                                        context_name)\n      assert context is not None, \'Run context is missing for %s.\' % (\n          context_name)\n\n    absl.logging.debug(\'ID of run context %s is %s.\', context_name, context.id)\n    return context\n\n  def get_component_run_context(\n      self, component_info: data_types.ComponentInfo\n  ) -> Optional[metadata_store_pb2.Context]:\n    """"""Gets the context for the component run.\n\n    Args:\n      component_info: component information for the current component run.\n\n    Returns:\n      a matched context or None\n    """"""\n    return self.store.get_context_by_type_and_name(\n        _CONTEXT_TYPE_COMPONENT_RUN, component_info.component_run_context_name)\n\n  def get_pipeline_context(\n      self, pipeline_info: data_types.PipelineInfo\n  ) -> Optional[metadata_store_pb2.Context]:\n    """"""Gets the context for the pipeline run.\n\n    Args:\n      pipeline_info: pipeline information for the current pipeline run.\n\n    Returns:\n      a matched context or None\n    """"""\n    return self.store.get_context_by_type_and_name(\n        _CONTEXT_TYPE_PIPELINE, pipeline_info.pipeline_context_name)\n\n  def get_pipeline_run_context(\n      self, pipeline_info: data_types.PipelineInfo\n  ) -> Optional[metadata_store_pb2.Context]:\n    """"""Gets the context for the pipeline run.\n\n    Args:\n      pipeline_info: pipeline information for the current pipeline run.\n\n    Returns:\n      a matched context or None\n    """"""\n    if pipeline_info.run_id:\n      return self.store.get_context_by_type_and_name(\n          _CONTEXT_TYPE_PIPELINE_RUN, pipeline_info.pipeline_run_context_name)\n    else:\n      return None\n\n  def register_pipeline_contexts_if_not_exists(\n      self,\n      pipeline_info: data_types.PipelineInfo,\n  ) -> List[metadata_store_pb2.Context]:\n    """"""Creates or fetches the pipeline contexts needed for the run.\n\n    There are two potential contexts:\n      - Context for the pipeline.\n      - Context for the current pipeline run. This is optional, only available\n        when run_id is specified.\n\n    Args:\n      pipeline_info: pipeline information for current run.\n\n    Returns:\n      a list (of size one or two) of context.\n    """"""\n    # Gets the pipeline level context.\n    result = []\n    pipeline_context = self._register_context_if_not_exist(\n        context_type_name=_CONTEXT_TYPE_PIPELINE,\n        context_name=pipeline_info.pipeline_context_name,\n        properties={\n            _CONTEXT_TYPE_KEY_PIPELINE_NAME: pipeline_info.pipeline_name\n        })\n    result.append(pipeline_context)\n    absl.logging.debug(\'Pipeline context [%s : %s]\',\n                       pipeline_info.pipeline_context_name, pipeline_context.id)\n    # If run id exists, gets the pipeline run level context.\n    if pipeline_info.run_id:\n      pipeline_run_context = self._register_context_if_not_exist(\n          context_type_name=_CONTEXT_TYPE_PIPELINE_RUN,\n          context_name=pipeline_info.pipeline_run_context_name,\n          properties={\n              _CONTEXT_TYPE_KEY_PIPELINE_NAME: pipeline_info.pipeline_name,\n              _CONTEXT_TYPE_KEY_RUN_ID: pipeline_info.run_id\n          })\n      result.append(pipeline_run_context)\n      absl.logging.debug(\'Pipeline run context [%s : %s]\',\n                         pipeline_info.pipeline_run_context_name,\n                         pipeline_run_context.id)\n    return result\n'"
tfx/orchestration/metadata_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.metadata.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\n# Standard Imports\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.types.artifact import ArtifactState\n\n\nclass MetadataTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(MetadataTest, self).setUp()\n    self._connection_config = metadata_store_pb2.ConnectionConfig()\n    self._connection_config.sqlite.SetInParent()\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline\', pipeline_root=\'/tmp\', run_id=\'my_run_id\')\n    self._pipeline_info2 = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline\', pipeline_root=\'/tmp\', run_id=\'my_run_id2\')\n    self._pipeline_info3 = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline2\', pipeline_root=\'/tmp\', run_id=\'my_run_id\')\n    self._pipeline_info4 = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline2\', pipeline_root=\'/tmp\', run_id=\'my_run_id2\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component\',\n        pipeline_info=self._pipeline_info)\n    self._component_info2 = data_types.ComponentInfo(\n        component_type=\'a.b.d\',\n        component_id=\'my_component_2\',\n        pipeline_info=self._pipeline_info)\n    self._component_info3 = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component\',\n        pipeline_info=self._pipeline_info3)\n\n  def _check_artifact_state(self, metadata_handler: metadata.Metadata,\n                            target: types.Artifact, state: Text):\n    [artifact] = metadata_handler.store.get_artifacts_by_id([target.id])\n    if \'state\' in artifact.properties:\n      current_artifact_state = artifact.properties[\'state\'].string_value\n    else:\n      # This is for forward compatible for the artifact type cleanup.\n      current_artifact_state = artifact.custom_properties[\'state\'].string_value\n    self.assertEqual(current_artifact_state, state)\n\n  def _get_all_runs(self, metadata_handler: metadata.Metadata,\n                    pipeline_name: Text):\n    result = []\n    for context in metadata_handler.store.get_contexts_by_type(\n        metadata._CONTEXT_TYPE_PIPELINE_RUN):\n      if context.properties[\'pipeline_name\'].string_value == pipeline_name:\n        result.append(context.properties[\'run_id\'].string_value)\n    return result\n\n  def _get_execution_states(self, metadata_handler: metadata.Metadata,\n                            pipeline_info: data_types.PipelineInfo):\n    pipeline_run_context = metadata_handler.store.get_context_by_type_and_name(\n        metadata._CONTEXT_TYPE_PIPELINE_RUN,\n        pipeline_info.pipeline_run_context_name)\n    result = {}\n    if not pipeline_run_context:\n      return result\n    for execution in metadata_handler.store.get_executions_by_context(\n        pipeline_run_context.id):\n      result[execution.properties[\'component_id\']\n             .string_value] = execution.properties[\'state\'].string_value\n    return result\n\n  def testArtifact(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      self.assertListEqual([], m.store.get_artifacts())\n\n      # Test publish artifact.\n      artifact = standard_artifacts.Examples()\n      artifact.uri = \'uri\'\n      artifact.split_names = artifact_utils.encode_split_names(\n          [\'train\', \'eval\'])\n      m.publish_artifacts([artifact])\n      [artifact] = m.store.get_artifacts()\n      # Skip verifying time sensitive fields.\n      artifact.ClearField(\'create_time_since_epoch\')\n      artifact.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""id: 1\n        type_id: 1\n        uri: ""uri""\n        properties {\n          key: ""split_names""\n          value {\n            string_value: ""[\\\\""train\\\\"", \\\\""eval\\\\""]""\n          }\n        }\n        custom_properties {\n          key: ""state""\n          value {\n            string_value: ""published""\n          }\n        }\n        """""", artifact)\n\n      # Test get artifact.\n      [artifact] = m.store.get_artifacts()\n      self.assertListEqual([artifact], m.get_artifacts_by_uri(\'uri\'))\n      self.assertListEqual([artifact],\n                           m.get_artifacts_by_type(\n                               standard_artifacts.Examples.TYPE_NAME))\n\n      # Test artifact state.\n      self._check_artifact_state(m, artifact, ArtifactState.PUBLISHED)\n      m.update_artifact_state(artifact, ArtifactState.DELETED)\n      self._check_artifact_state(m, artifact, ArtifactState.DELETED)\n\n  def testExecution(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      # Test prepare_execution.\n      exec_properties = {\'arg_one\': 1}\n      input_artifact = standard_artifacts.Examples()\n      output_artifact = standard_artifacts.Examples()\n      input_artifacts = {\'input\': [input_artifact]}\n      output_artifacts = {\'output\': [output_artifact]}\n      m.register_execution(\n          input_artifacts=input_artifacts,\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      [execution] = m.store.get_executions_by_context(contexts[0].id)\n      # Skip verifying time sensitive fields.\n      execution.ClearField(\'create_time_since_epoch\')\n      execution.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 1\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""my_pipeline""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/tmp""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""my_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""my_component""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }"""""", execution)\n\n      # Test publish_execution.\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts=output_artifacts)\n      # Make sure artifacts in output_dict are published.\n      self.assertEqual(ArtifactState.PUBLISHED, output_artifact.state)\n      # Make sure execution state are changed.\n      [execution] = m.store.get_executions_by_id([execution.id])\n      self.assertEqual(metadata.EXECUTION_STATE_COMPLETE,\n                       execution.properties[\'state\'].string_value)\n      # Make sure events are published.\n      events = m.store.get_events_by_execution_ids([execution.id])\n      self.assertEqual(2, len(events))\n      self.assertEqual(input_artifact.id, events[0].artifact_id)\n      self.assertEqual(metadata_store_pb2.Event.INPUT, events[0].type)\n      self.assertProtoEquals(\n          """"""\n          steps {\n            key: ""input""\n          }\n          steps {\n            index: 0\n          }"""""", events[0].path)\n      self.assertEqual(output_artifact.id, events[1].artifact_id)\n      self.assertEqual(metadata_store_pb2.Event.OUTPUT, events[1].type)\n      self.assertProtoEquals(\n          """"""\n          steps {\n            key: ""output""\n          }\n          steps {\n            index: 0\n          }"""""", events[1].path)\n\n  def testRegisterExecutionUpdatedExecutionType(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts_one = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info)\n      contexts_two = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info3)\n\n      # Puts in execution with less columns needed in MLMD schema first and\n      # puts in execution with more columns needed next. Verifies the schema\n      # update will not be breaking change.\n      exec_properties_one = {\'arg_one\': 1}\n      exec_properties_two = {\'arg_one\': 1, \'arg_two\': 2}\n      execution_one = m.register_execution(\n          input_artifacts={},\n          exec_properties=exec_properties_one,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts_one)\n      execution_two = m.register_execution(\n          input_artifacts={},\n          exec_properties=exec_properties_two,\n          pipeline_info=self._pipeline_info3,\n          component_info=self._component_info3,\n          contexts=contexts_two)\n      [execution_one, execution_two\n      ] = m.store.get_executions_by_id([execution_one.id, execution_two.id])\n      # Skip verifying time sensitive fields.\n      execution_one.ClearField(\'create_time_since_epoch\')\n      execution_one.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 1\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""my_pipeline""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/tmp""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""my_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""my_component""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }"""""", execution_one)\n      # Skip verifying time sensitive fields.\n      execution_two.ClearField(\'create_time_since_epoch\')\n      execution_two.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 2\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""my_pipeline2""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/tmp""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""my_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""my_component""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }\n        properties {\n          key: ""arg_two""\n          value {\n            string_value: ""2""\n          }\n        }"""""", execution_two)\n\n  def testRegisterExecutionIdempotency(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      m.register_execution(\n          exec_properties={\'a\': 1},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      execution = m.register_execution(\n          exec_properties={\'a\': 1},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      self.assertEqual(execution.id, 1)\n      self.assertEqual(len(m.store.get_executions()), 1)\n\n  def testRegisterExecutionBackwardCompatibility(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n\n      # Puts in execution with more columns needed in MLMD schema first and\n      # puts in execution with less columns needed next. Verifies the schema\n      # update will not affect backward compatibility.\n      exec_properties_one = {\'arg_one\': 1, \'arg_two\': 2}\n      exec_properties_two = {\'arg_one\': 1}\n      execution_one = m.register_execution(\n          input_artifacts={},\n          exec_properties=exec_properties_one,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      execution_two = m.register_execution(\n          input_artifacts={},\n          exec_properties=exec_properties_two,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info3,\n          contexts=contexts)\n      [execution_one, execution_two\n      ] = m.store.get_executions_by_id([execution_one.id, execution_two.id])\n      # Skip verifying time sensitive fields.\n      execution_one.ClearField(\'create_time_since_epoch\')\n      execution_one.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 1\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""my_pipeline""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/tmp""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""my_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""my_component""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }\n        properties {\n          key: ""arg_two""\n          value {\n            string_value: ""2""\n          }\n        }"""""", execution_one)\n      # Skip verifying time sensitive fields.\n      execution_two.ClearField(\'create_time_since_epoch\')\n      execution_two.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 2\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""my_pipeline""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/tmp""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""my_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""my_component""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }"""""", execution_two)\n\n  def testFetchPreviousResult(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n\n      # Create an \'previous\' execution.\n      exec_properties = {\'log_root\': \'path\'}\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      input_artifacts = {\'input\': [standard_artifacts.Examples()]}\n      output_artifact = standard_artifacts.Examples()\n      output_artifact.uri = \'my_uri\'\n      output_artifacts = {\'output\': [output_artifact]}\n      m.register_execution(\n          input_artifacts=input_artifacts,\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts=output_artifacts)\n\n      # Test previous_run.\n      self.assertEqual(\n          None,\n          m.get_cached_outputs(\n              input_artifacts={},\n              exec_properties=exec_properties,\n              pipeline_info=self._pipeline_info,\n              component_info=self._component_info))\n      self.assertEqual(\n          None,\n          m.get_cached_outputs(\n              input_artifacts=input_artifacts,\n              exec_properties=exec_properties,\n              pipeline_info=self._pipeline_info,\n              component_info=data_types.ComponentInfo(\n                  component_id=\'unique\',\n                  component_type=\'a.b.c\',\n                  pipeline_info=self._pipeline_info)))\n      # Having the same set of input artifact ids, but duplicated.\n      self.assertEqual(\n          None,\n          m.get_cached_outputs(\n              input_artifacts={\n                  \'input\': input_artifacts[\'input\'],\n                  \'another_input\': input_artifacts[\'input\']\n              },\n              exec_properties=exec_properties,\n              pipeline_info=self._pipeline_info,\n              component_info=self._component_info))\n      cached_output_artifacts = m.get_cached_outputs(\n          input_artifacts=input_artifacts,\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info)\n      self.assertEqual(len(cached_output_artifacts), 1)\n      self.assertEqual(len(cached_output_artifacts[\'output\']), 1)\n      cached_output_artifact = cached_output_artifacts[\'output\'][\n          0].mlmd_artifact\n      # Skip verifying time sensitive fields.\n      cached_output_artifact.ClearField(\'create_time_since_epoch\')\n      cached_output_artifact.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(cached_output_artifact,\n                             output_artifact.mlmd_artifact)\n\n  def testGetCachedOutputNoInput(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n\n      # Create an \'previous\' execution.\n      exec_properties = {\'log_root\': \'path\'}\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      output_artifact = standard_artifacts.Examples()\n      output_artifact.uri = \'my_uri\'\n      output_artifacts = {\'output\': [output_artifact]}\n      m.register_execution(\n          input_artifacts={},\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts=output_artifacts)\n\n      cached_output_artifacts = m.get_cached_outputs(\n          input_artifacts={},\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info)\n      self.assertEqual(len(cached_output_artifacts), 1)\n      self.assertEqual(len(cached_output_artifacts[\'output\']), 1)\n      cached_output_artifact = cached_output_artifacts[\'output\'][\n          0].mlmd_artifact\n      # Skip verifying time sensitive fields.\n      cached_output_artifact.ClearField(\'create_time_since_epoch\')\n      cached_output_artifact.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(cached_output_artifact,\n                             output_artifact.mlmd_artifact)\n\n  def testSearchArtifacts(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      exec_properties = {\'log_root\': \'path\'}\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      m.register_execution(\n          input_artifacts={\'input\': [standard_artifacts.Examples()]},\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      output_artifact = standard_artifacts.Examples()\n      output_artifact.uri = \'my/uri\'\n      output_dict = {\'output\': [output_artifact]}\n      m.publish_execution(\n          component_info=self._component_info, output_artifacts=output_dict)\n      [artifact] = m.search_artifacts(\n          artifact_name=\'output\',\n          pipeline_info=self._pipeline_info,\n          producer_component_id=self._component_info.component_id)\n      self.assertEqual(artifact.uri, output_artifact.uri)\n\n  def testPublishSkippedExecution(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      exec_properties = {\'log_root\': \'path\'}\n      output_artifact = standard_artifacts.Examples()\n      output_artifact.uri = \'my/uri\'\n      output_artifacts = {\'output\': [output_artifact]}\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      execution = m.register_execution(\n          input_artifacts={\'input\': [standard_artifacts.Examples()]},\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      m.update_execution(\n          execution=execution,\n          component_info=self._component_info,\n          output_artifacts=output_artifacts,\n          execution_state=metadata.EXECUTION_STATE_CACHED,\n          contexts=contexts)\n      m.publish_execution(component_info=self._component_info)\n\n  def testGetExecutionStates(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts_one = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info)\n      contexts_two = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info)\n      contexts_three = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info2)\n\n      self.assertListEqual(\n          [self._pipeline_info.run_id, self._pipeline_info2.run_id],\n          self._get_all_runs(m, \'my_pipeline\'))\n\n      m.register_execution(\n          input_artifacts={},\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts_one)\n      m.publish_execution(component_info=self._component_info)\n      m.register_execution(\n          input_artifacts={},\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info2,\n          contexts=contexts_two)\n      m.register_execution(\n          input_artifacts={},\n          exec_properties={},\n          pipeline_info=self._pipeline_info2,\n          component_info=self._component_info3,\n          contexts=contexts_three)\n      states = self._get_execution_states(m, self._pipeline_info)\n      self.assertDictEqual(\n          {\n              self._component_info.component_id:\n                  metadata.EXECUTION_STATE_COMPLETE,\n              self._component_info2.component_id:\n                  metadata.EXECUTION_STATE_NEW,\n          }, states)\n\n  def testUpdateExecution(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      m.register_execution(\n          input_artifacts={},\n          exec_properties={\'k\': \'v1\'},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      [execution] = m.store.get_executions_by_context(\n          m.get_component_run_context(self._component_info).id)\n      self.assertEqual(execution.properties[\'k\'].string_value, \'v1\')\n      self.assertEqual(execution.properties[\'state\'].string_value,\n                       metadata.EXECUTION_STATE_NEW)\n\n      m.update_execution(\n          execution,\n          self._component_info,\n          input_artifacts={\'input_a\': [standard_artifacts.Examples()]},\n          exec_properties={\'k\': \'v2\'},\n          contexts=contexts)\n\n      [execution] = m.store.get_executions_by_context(\n          m.get_component_run_context(self._component_info).id)\n      self.assertEqual(execution.properties[\'k\'].string_value, \'v2\')\n      self.assertEqual(execution.properties[\'state\'].string_value,\n                       metadata.EXECUTION_STATE_NEW)\n      [event] = m.store.get_events_by_execution_ids([execution.id])\n      self.assertEqual(event.artifact_id, 1)\n      [artifact] = m.store.get_artifacts_by_context(\n          m.get_component_run_context(self._component_info).id)\n      self.assertEqual(artifact.id, 1)\n\n      aa = standard_artifacts.Examples()\n      aa.set_mlmd_artifact(artifact)\n      m.update_execution(\n          execution, self._component_info, input_artifacts={\'input_a\': [aa]})\n      [event] = m.store.get_events_by_execution_ids([execution.id])\n      self.assertEqual(event.type, metadata_store_pb2.Event.INPUT)\n\n      m.publish_execution(\n          self._component_info,\n          output_artifacts={\'output\': [standard_artifacts.Model()]},\n          exec_properties={\'k\': \'v3\'})\n\n      [execution] = m.store.get_executions_by_context(\n          m.get_component_run_context(self._component_info).id)\n      self.assertEqual(execution.properties[\'k\'].string_value, \'v3\')\n      self.assertEqual(execution.properties[\'state\'].string_value,\n                       metadata.EXECUTION_STATE_COMPLETE)\n      [_, event_b] = m.store.get_events_by_execution_ids([execution.id])\n      self.assertEqual(event_b.artifact_id, 2)\n      self.assertEqual(event_b.type, metadata_store_pb2.Event.OUTPUT)\n      [_, artifact_b] = m.store.get_artifacts_by_context(\n          m.get_component_run_context(self._component_info).id)\n      self.assertEqual(artifact_b.id, 2)\n      self._check_artifact_state(m, artifact_b, ArtifactState.PUBLISHED)\n\n  def testGetQualifiedArtifacts(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts_one = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info)\n      contexts_two = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info3)\n      # The first execution, with matched:\n      #   - pipeline context\n      #   - producer component id\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=list(contexts_one))\n      # artifact_one will be output with matched artifact type and output key\n      artifact_one = standard_artifacts.Model()\n      # artifact_one will be output with matched artifact type only\n      artifact_two = standard_artifacts.Model()\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts={\n              \'k1\': [artifact_one],\n              \'k2\': [artifact_two]\n          })\n      # The second execution, with matched pipeline context only\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info2,\n          contexts=list(contexts_one))\n      # artifact_three will be output with matched artifact type and output key\n      artifact_three = standard_artifacts.Model()\n      m.publish_execution(\n          component_info=self._component_info2,\n          output_artifacts={\'k1\': [artifact_three]})\n      # The third execution, with matched producer component id only\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self._pipeline_info3,\n          component_info=self._component_info3,\n          contexts=list(contexts_two))\n      # artifact_three will be output with matched artifact type and output key\n      artifact_four = standard_artifacts.Model()\n      m.publish_execution(\n          component_info=self._component_info3,\n          output_artifacts={\'k1\': [artifact_four]})\n\n      result = m.get_qualified_artifacts(\n          contexts=contexts_one,\n          type_name=standard_artifacts.Model().type_name,\n          producer_component_id=self._component_info.component_id,\n          output_key=\'k1\')\n      self.assertEqual(len(result), 1)\n      self.assertEqual(result[0].artifact.id, artifact_one.id)\n\n  def testContext(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      # Duplicated call should succeed.\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n\n      self.assertProtoEquals(\n          """"""\n          id: 1\n          name: \'pipeline\'\n          properties {\n            key: ""pipeline_name""\n            value: STRING\n          }\n          """""", m.store.get_context_type(metadata._CONTEXT_TYPE_PIPELINE))\n      self.assertProtoEquals(\n          """"""\n          id: 2\n          name: \'run\'\n          properties {\n            key: ""pipeline_name""\n            value: STRING\n          }\n          properties {\n            key: ""run_id""\n            value: STRING\n          }\n          """""", m.store.get_context_type(metadata._CONTEXT_TYPE_PIPELINE_RUN))\n      self.assertEqual(len(contexts), 2)\n      self.assertEqual(\n          contexts[0],\n          m.store.get_context_by_type_and_name(\n              metadata._CONTEXT_TYPE_PIPELINE,\n              self._pipeline_info.pipeline_context_name))\n      self.assertEqual(\n          contexts[1],\n          m.store.get_context_by_type_and_name(\n              metadata._CONTEXT_TYPE_PIPELINE_RUN,\n              self._pipeline_info.pipeline_run_context_name))\n\n  def testInvalidConnection(self):\n    # read only connection to a unknown file\n    invalid_config = metadata_store_pb2.ConnectionConfig()\n    invalid_config.sqlite.filename_uri = \'unknown_file\'\n    invalid_config.sqlite.connection_mode = 1\n    # test the runtime error contains detailed information\n    with self.assertRaisesRegex(RuntimeError, \'unable to open database file\'):\n      with metadata.Metadata(connection_config=invalid_config) as m:\n        m.store()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition and related classes for TFX pipeline.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport collections\nimport json\nimport os\nfrom typing import List, Optional, Text\n\nfrom absl import logging\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\n\n# Argo\'s workflow name cannot exceed 63 chars:\n# see https://github.com/argoproj/argo/issues/1324.\n# MySQL\'s database name cannot exceed 64 chars:\n# https://dev.mysql.com/doc/refman/5.6/en/identifiers.html\nMAX_PIPELINE_NAME_LENGTH = 63\n\n# Name of pipeline_root parameter.\n_PIPELINE_ROOT = \'pipeline-root\'\n\n\n# Pipeline root is by default specified as a RuntimeParameter when runnning on\n# KubeflowDagRunner. This constant offers users an easy access to the pipeline\n# root placeholder when defining a pipeline. For example,\n#\n# pusher = Pusher(\n#     model_export=trainer.outputs[\'model\'],\n#     model_blessing=evaluator.outputs[\'blessing\'],\n#     push_destination=pusher_pb2.PushDestination(\n#         filesystem=pusher_pb2.PushDestination.Filesystem(\n#             base_directory=os.path.join(\n#                 str(pipeline.ROOT_PARAMETER), \'model_serving\'))))\nROOT_PARAMETER = data_types.RuntimeParameter(name=_PIPELINE_ROOT, ptype=Text)\n\n\nclass Pipeline(object):\n  """"""Logical TFX pipeline object.\n\n  Attributes:\n    pipeline_args: kwargs used to create real pipeline implementation. This is\n      forwarded to PipelineRunners instead of consumed in this class. This\n      should include:\n      - pipeline_name: Required. The unique name of this pipeline.\n      - pipeline_root: Required. The root of the pipeline outputs.\n    components: logical components of this pipeline.\n    pipeline_info: An instance of data_types.PipelineInfo that contains basic\n      properties of the pipeline.\n    enable_cache: whether or not cache is enabled for this run.\n    metadata_connection_config: the config to connect to ML metadata.\n    beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n      Executor will use beam DirectRunner as Default.\n    additional_pipeline_args: other pipeline args.\n  """"""\n\n  def __init__(self,\n               pipeline_name: Text,\n               pipeline_root: Text,\n               metadata_connection_config: Optional[\n                   metadata_store_pb2.ConnectionConfig] = None,\n               components: Optional[List[base_node.BaseNode]] = None,\n               enable_cache: Optional[bool] = False,\n               beam_pipeline_args: Optional[List[Text]] = None,\n               **kwargs):\n    """"""Initialize pipeline.\n\n    Args:\n      pipeline_name: name of the pipeline;\n      pipeline_root: path to root directory of the pipeline;\n      metadata_connection_config: the config to connect to ML metadata.\n      components: a list of components in the pipeline (optional only for\n        backward compatible purpose to be used with deprecated\n        PipelineDecorator).\n      enable_cache: whether or not cache is enabled for this run.\n      beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n        Executor will use beam DirectRunner as Default.\n      **kwargs: additional kwargs forwarded as pipeline args.\n    """"""\n    if len(pipeline_name) > MAX_PIPELINE_NAME_LENGTH:\n      raise ValueError(\'pipeline name %s exceeds maximum allowed lenght\' %\n                       pipeline_name)\n    pipeline_args = dict(kwargs)\n\n    self.pipeline_info = data_types.PipelineInfo(\n        pipeline_name=pipeline_name, pipeline_root=pipeline_root)\n    self.enable_cache = enable_cache\n    self.metadata_connection_config = metadata_connection_config\n\n    self.beam_pipeline_args = beam_pipeline_args or []\n\n    self.additional_pipeline_args = pipeline_args.get(\n        \'additional_pipeline_args\', {})\n\n    # TODO(jyzhao): deprecate beam_pipeline_args of additional_pipeline_args.\n    if \'beam_pipeline_args\' in self.additional_pipeline_args:\n      logging.warning(\n          \'Please use the top level beam_pipeline_args instead of the one in additional_pipeline_args.\'\n      )\n      self.beam_pipeline_args = self.additional_pipeline_args[\n          \'beam_pipeline_args\']\n\n    # Store pipeline_args in a json file only when temp file exists.\n    pipeline_args.update({\n        \'pipeline_name\': pipeline_name,\n        \'pipeline_root\': pipeline_root,\n    })\n    if \'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\' in os.environ:\n      pipeline_args_path = os.environ.get(\'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\')\n      with open(pipeline_args_path, \'w\') as f:\n        json.dump(pipeline_args, f)\n\n    # Calls property setter.\n    self.components = components or []\n\n  @property\n  def components(self):\n    """"""A list of logical components that are deduped and topological sorted.""""""\n    return self._components\n\n  @components.setter\n  def components(self, components: List[base_node.BaseNode]):\n    deduped_components = set(components)\n    producer_map = {}\n    instances_per_component_type = collections.defaultdict(set)\n\n    # Fills in producer map.\n    for component in deduped_components:\n      # Guarantees every component of a component type has unique component_id.\n      if component.id in instances_per_component_type[component.type]:\n        raise RuntimeError(\'Duplicated component_id %s for component type %s\' %\n                           (component.id, component.type))\n      instances_per_component_type[component.type].add(component.id)\n      for key, output_channel in component.outputs.items():\n        assert not producer_map.get(\n            output_channel), \'{} produced more than once\'.format(output_channel)\n        producer_map[output_channel] = component\n        output_channel.producer_component_id = component.id\n        output_channel.output_key = key\n        # TODO(ruoyu): Remove after switching to context-based resolution.\n        for artifact in output_channel.get():\n          artifact.name = key\n          artifact.pipeline_name = self.pipeline_info.pipeline_name\n          artifact.producer_component = component.id\n\n    # Connects nodes based on producer map.\n    for component in deduped_components:\n      for i in component.inputs.values():\n        if producer_map.get(i):\n          component.add_upstream_node(producer_map[i])\n          producer_map[i].add_downstream_node(component)\n\n    self._components = []\n    visited = set()\n\n    # Finds the nodes with indegree 0.\n    current_layer = [c for c in deduped_components if not c.upstream_nodes]\n    # Sorts component in topological order.\n    while current_layer:\n      next_layer = []\n      for component in current_layer:\n        self._components.append(component)\n        visited.add(component)\n        for downstream_node in component.downstream_nodes:\n          if downstream_node.upstream_nodes.issubset(visited):\n            next_layer.append(downstream_node)\n      current_layer = next_layer\n    # If there is a cycle in the graph, upon visiting the cycle, no node will be\n    # ready to be processed because it is impossible to find a single node that\n    # has all its dependencies visited.\n    if len(self._components) < len(deduped_components):\n      raise RuntimeError(\'There is a cycle in the pipeline\')\n'"
tfx/orchestration/pipeline_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.pipeline.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport itertools\nimport os\nimport tempfile\nfrom typing import Any, Dict, Text, Type\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import base_node\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.types import node_common\nfrom tfx.types.component_spec import ChannelParameter\n\n\nclass _OutputArtifact(types.Artifact):\n  TYPE_NAME = \'OutputArtifact\'\n\n\ndef _make_fake_node_instance(name: Text):\n\n  class _FakeNode(base_node.BaseNode):\n\n    @property\n    def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n      return node_common._PropertyDictWrapper({})  # pylint: disable=protected-access\n\n    @property\n    def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n      return node_common._PropertyDictWrapper({})  # pylint: disable=protected-access\n\n    @property\n    def exec_properties(self) -> Dict[Text, Any]:\n      return {}\n\n  return _FakeNode(instance_name=name)\n\n\ndef _make_fake_component_instance(name: Text, output_type: Type[types.Artifact],\n                                  inputs: Dict[Text, types.Channel],\n                                  outputs: Dict[Text, types.Channel]):\n\n  class _FakeComponentSpec(types.ComponentSpec):\n    PARAMETERS = {}\n    INPUTS = dict([(arg, ChannelParameter(type=channel.type))\n                   for arg, channel in inputs.items()])\n    OUTPUTS = dict([(arg, ChannelParameter(type=channel.type))\n                    for arg, channel in outputs.items()] +\n                   [(\'output\', ChannelParameter(type=output_type))])\n\n  class _FakeComponent(base_component.BaseComponent):\n\n    SPEC_CLASS = _FakeComponentSpec\n    EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n    def __init__(\n        self,\n        type: Type[types.Artifact],  # pylint: disable=redefined-builtin\n        spec_kwargs: Dict[Text, Any]):\n      spec = _FakeComponentSpec(output=types.Channel(type=type), **spec_kwargs)\n      super(_FakeComponent, self).__init__(spec=spec, instance_name=name)\n\n  spec_kwargs = dict(itertools.chain(inputs.items(), outputs.items()))\n  return _FakeComponent(output_type, spec_kwargs)\n\n\nclass _ArtifactTypeOne(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeOne\'\n\n\nclass _ArtifactTypeTwo(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeTwo\'\n\n\nclass _ArtifactTypeThree(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeThree\'\n\n\nclass _OutputTypeA(types.Artifact):\n  TYPE_NAME = \'OutputTypeA\'\n\n\nclass _OutputTypeB(types.Artifact):\n  TYPE_NAME = \'OutputTypeB\'\n\n\nclass _OutputTypeC(types.Artifact):\n  TYPE_NAME = \'OutputTypeC\'\n\n\nclass _OutputTypeD(types.Artifact):\n  TYPE_NAME = \'OutputTypeD\'\n\n\nclass _OutputTypeE(types.Artifact):\n  TYPE_NAME = \'OutputTypeE\'\n\n\nclass PipelineTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(PipelineTest, self).setUp()\n    tmp_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir())\n    self._tmp_file = os.path.join(tmp_dir, self._testMethodName,\n                                  tempfile.mkstemp(prefix=\'cli_tmp_\')[1])\n    self._tmp_dir = os.path.join(tmp_dir, self._testMethodName,\n                                 tempfile.mkdtemp(prefix=\'cli_tmp_\')[1])\n    self._original_tmp_value = os.environ.get(\n        \'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\', \'\')\n    self._metadata_connection_config = metadata.sqlite_metadata_connection_config(\n        os.path.join(self._tmp_dir, \'metadata\'))\n\n  def tearDown(self):\n    super(PipelineTest, self).tearDown()\n    os.environ[\'TFX_TMP_DIR\'] = self._original_tmp_value\n\n  def testPipeline(self):\n    component_a = _make_fake_component_instance(\'component_a\', _OutputTypeA, {},\n                                                {})\n    component_b = _make_fake_component_instance(\n        \'component_b\', _OutputTypeB, {\'a\': component_a.outputs[\'output\']}, {})\n    component_c = _make_fake_component_instance(\n        \'component_c\', _OutputTypeC, {\'a\': component_a.outputs[\'output\']}, {})\n    component_d = _make_fake_component_instance(\'component_d\', _OutputTypeD, {\n        \'b\': component_b.outputs[\'output\'],\n        \'c\': component_c.outputs[\'output\']\n    }, {})\n    component_e = _make_fake_component_instance(\n        \'component_e\', _OutputTypeE, {\n            \'a\': component_a.outputs[\'output\'],\n            \'b\': component_b.outputs[\'output\'],\n            \'d\': component_d.outputs[\'output\']\n        }, {})\n\n    my_pipeline = pipeline.Pipeline(\n        pipeline_name=\'a\',\n        pipeline_root=\'b\',\n        components=[\n            component_d, component_c, component_a, component_b, component_e,\n            component_a\n        ],\n        enable_cache=True,\n        metadata_connection_config=self._metadata_connection_config,\n        beam_pipeline_args=[\'--runner=PortableRunner\'],\n        additional_pipeline_args={})\n    self.assertCountEqual(\n        my_pipeline.components,\n        [component_a, component_b, component_c, component_d, component_e])\n    self.assertCountEqual(my_pipeline.components[0].downstream_nodes,\n                          [component_b, component_c, component_e])\n    self.assertEqual(my_pipeline.components[-1], component_e)\n    self.assertEqual(my_pipeline.pipeline_info.pipeline_name, \'a\')\n    self.assertEqual(my_pipeline.pipeline_info.pipeline_root, \'b\')\n    self.assertEqual(my_pipeline.metadata_connection_config,\n                     self._metadata_connection_config)\n    self.assertTrue(my_pipeline.enable_cache)\n    self.assertCountEqual(my_pipeline.beam_pipeline_args,\n                          [\'--runner=PortableRunner\'])\n    self.assertDictEqual(my_pipeline.additional_pipeline_args, {})\n\n  def testPipelineWithLongname(self):\n    with self.assertRaises(ValueError):\n      pipeline.Pipeline(\n          pipeline_name=\'a\' * (1 + pipeline.MAX_PIPELINE_NAME_LENGTH),\n          pipeline_root=\'root\',\n          components=[],\n          metadata_connection_config=self._metadata_connection_config)\n\n  def testPipelineWithNode(self):\n    my_pipeline = pipeline.Pipeline(\n        pipeline_name=\'my_pipeline\',\n        pipeline_root=\'root\',\n        components=[_make_fake_node_instance(\'my_node\')],\n        metadata_connection_config=self._metadata_connection_config)\n    self.assertEqual(1, len(my_pipeline.components))\n\n  def testPipelineWithLoop(self):\n    channel_one = types.Channel(type=_ArtifactTypeOne)\n    channel_two = types.Channel(type=_ArtifactTypeTwo)\n    channel_three = types.Channel(type=_ArtifactTypeThree)\n    component_a = _make_fake_component_instance(\'component_a\', _OutputTypeA, {},\n                                                {})\n    component_b = _make_fake_component_instance(\n        name=\'component_b\',\n        output_type=_OutputTypeB,\n        inputs={\n            \'a\': component_a.outputs[\'output\'],\n            \'one\': channel_one\n        },\n        outputs={\'two\': channel_two})\n    component_c = _make_fake_component_instance(\n        name=\'component_b\',\n        output_type=_OutputTypeB,\n        inputs={\n            \'a\': component_a.outputs[\'output\'],\n            \'two\': channel_two\n        },\n        outputs={\'three\': channel_three})\n    component_d = _make_fake_component_instance(\n        name=\'component_b\',\n        output_type=_OutputTypeB,\n        inputs={\n            \'a\': component_a.outputs[\'output\'],\n            \'three\': channel_three\n        },\n        outputs={\'one\': channel_one})\n\n    with self.assertRaises(RuntimeError):\n      pipeline.Pipeline(\n          pipeline_name=\'a\',\n          pipeline_root=\'b\',\n          components=[component_c, component_d, component_b, component_a],\n          metadata_connection_config=self._metadata_connection_config)\n\n  def testPipelineWithDuplicatedComponentId(self):\n    component_a = _make_fake_component_instance(\'component_a\', _OutputTypeA, {},\n                                                {})\n    component_b = _make_fake_component_instance(\'component_a\', _OutputTypeA, {},\n                                                {})\n    component_c = _make_fake_component_instance(\'component_a\', _OutputTypeA, {},\n                                                {})\n\n    with self.assertRaises(RuntimeError):\n      pipeline.Pipeline(\n          pipeline_name=\'a\',\n          pipeline_root=\'b\',\n          components=[component_c, component_b, component_a],\n          metadata_connection_config=self._metadata_connection_config)\n\n  def testPipelineWithArtifactInfo(self):\n    artifacts_collection = [_ArtifactTypeOne()]\n    channel_one = types.Channel(\n        type=_ArtifactTypeOne, artifacts=artifacts_collection)\n    component_a = _make_fake_component_instance(\n        name=\'component_a\',\n        output_type=_OutputTypeA,\n        inputs={},\n        outputs={\'one\': channel_one})\n    component_b = _make_fake_component_instance(\n        name=\'component_b\',\n        output_type=_OutputTypeB,\n        inputs={\n            \'a\': component_a.outputs[\'one\'],\n        },\n        outputs={})\n\n    my_pipeline = pipeline.Pipeline(\n        pipeline_name=\'a\',\n        pipeline_root=\'b\',\n        components=[component_b, component_a],\n        metadata_connection_config=self._metadata_connection_config)\n    expected_artifact = _ArtifactTypeOne()\n    expected_artifact.name = \'one\'\n    expected_artifact.pipeline_name = \'a\'\n    expected_artifact.producer_component = \'component_a\'\n    self.assertCountEqual(my_pipeline.components, [component_a, component_b])\n    self.assertEqual(component_a.outputs[\'one\']._artifacts[0].pipeline_name,\n                     \'a\')\n    self.assertEqual(\n        component_a.outputs[\'one\']._artifacts[0].producer_component,\n        component_a.id)\n    self.assertEqual(component_a.outputs[\'one\']._artifacts[0].name, \'one\')\n    self.assertEqual(component_b.inputs[\'a\']._artifacts[0].pipeline_name, \'a\')\n    self.assertEqual(component_b.inputs[\'a\']._artifacts[0].producer_component,\n                     component_a.id)\n    self.assertEqual(component_b.inputs[\'a\']._artifacts[0].name, \'one\')\n    self.assertEqual(component_a.outputs[\'one\'].producer_component_id,\n                     component_a.id)\n    self.assertEqual(component_a.outputs[\'one\'].output_key, \'one\')\n    self.assertEqual(component_b.inputs[\'a\'].producer_component_id,\n                     component_a.id)\n    self.assertEqual(component_b.inputs[\'a\'].output_key, \'one\')\n\n  def testPipelineSavePipelineArgs(self):\n    os.environ[\'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\'] = self._tmp_file\n    pipeline.Pipeline(\n        pipeline_name=\'a\',\n        pipeline_root=\'b\',\n        log_root=\'c\',\n        components=[\n            _make_fake_component_instance(\'component_a\', _OutputTypeA, {}, {})\n        ],\n        metadata_connection_config=self._metadata_connection_config)\n    self.assertTrue(tf.io.gfile.exists(self._tmp_file))\n\n  def testPipelineNoTmpFolder(self):\n    pipeline.Pipeline(\n        pipeline_name=\'a\',\n        pipeline_root=\'b\',\n        log_root=\'c\',\n        components=[\n            _make_fake_component_instance(\'component_a\', _OutputTypeA, {}, {})\n        ],\n        metadata_connection_config=self._metadata_connection_config)\n    self.assertNotIn(\'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\', os.environ)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/publisher.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX publisher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Optional, Text\n\nfrom absl import logging\n\nfrom tfx import types\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\n\n\nclass Publisher(object):\n  """"""Publish execution to metadata.\n\n  Attributes:\n    _metadata_handler: An instance of Metadata.\n  """"""\n\n  def __init__(self, metadata_handler: metadata.Metadata):\n    self._metadata_handler = metadata_handler\n\n  def publish_execution(\n      self,\n      component_info: data_types.ComponentInfo,\n      output_artifacts: Optional[Dict[Text, List[types.Artifact]]] = None,\n      exec_properties: Optional[Dict[Text, Any]] = None):\n    """"""Publishes a component execution to metadata.\n\n    This function will do two things:\n    1. update the execution that was previously registered before execution to\n       complete or skipped state, depending on whether cached results are used.\n    2. for each input and output artifact, publish an event that associate the\n       artifact to the execution, with type INPUT or OUTPUT respectively\n\n    Args:\n      component_info: the information of the component\n      output_artifacts: optional key -> Artifacts to be published as outputs\n        of the execution\n      exec_properties: optional execution properties to be published for the\n        execution\n\n    Returns:\n      A dict containing output artifacts.\n    """"""\n    logging.debug(\'Outputs: %s\', output_artifacts)\n    logging.debug(\'Execution properties: %s\', exec_properties)\n\n    self._metadata_handler.publish_execution(\n        component_info=component_info,\n        output_artifacts=output_artifacts,\n        exec_properties=exec_properties)\n'"
tfx/orchestration/publisher_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.publisher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx import types\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import publisher\n\n\nclass _InputType(types.Artifact):\n  TYPE_NAME = \'InputType\'\n\n\nclass _OutputType(types.Artifact):\n  TYPE_NAME = \'OutputType\'\n\n\nclass PublisherTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(PublisherTest, self).setUp()\n    self._mock_metadata = tf.compat.v1.test.mock.Mock()\n    self._mock_metadata.publish_execution = tf.compat.v1.test.mock.Mock()\n    self._output_dict = {\n        \'output_data\': [_OutputType()],\n    }\n    self._exec_properties = {\'k\': \'v\'}\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline\', pipeline_root=\'/tmp\', run_id=\'my_run_id\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component\',\n        pipeline_info=self._pipeline_info)\n\n  def testPrepareExecutionComplete(self):\n    p = publisher.Publisher(metadata_handler=self._mock_metadata)\n    p.publish_execution(\n        component_info=self._component_info,\n        output_artifacts=self._output_dict,\n        exec_properties=self._exec_properties)\n    self._mock_metadata.publish_execution.assert_called_with(\n        component_info=self._component_info,\n        output_artifacts=self._output_dict,\n        exec_properties=self._exec_properties)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/test_utils.py,0,"b'# Lint as: python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common utilities for testing various runners.""""""\n\nimport datetime\nimport random\nimport string\nimport time\n\nfrom absl import logging\nimport docker\n\nfrom google.cloud import storage\n\n\nclass Timer:\n  """"""Helper class to time operations in pipeline e2e tests.""""""\n\n  def __init__(self, operation: str):\n    """"""Creates a context object to measure time taken.\n\n    Args:\n      operation: A description of the operation being measured.\n    """"""\n    self._operation = operation\n\n  def __enter__(self):\n    self._start = time.time()\n\n  def __exit__(self, *unused_args):\n    self._end = time.time()\n\n    logging.info(\n        \'Timing Info >> Operation: %s Elapsed time in seconds: %d\',\n        self._operation, self._end - self._start)\n\n\ndef random_id() -> str:\n  """"""Generates a random string that is also a valid Kubernetes DNS name.\n\n  Returns:\n    A random string valid for Kubernetes DNS name.\n  """"""\n  random.seed(datetime.datetime.now())\n\n  choices = string.ascii_lowercase + string.digits\n  return \'{}-{}\'.format(datetime.datetime.now().strftime(\'%s\'),\n                        \'\'.join([random.choice(choices) for _ in range(10)]))\n\n\ndef build_and_push_docker_image(container_image: str, repo_base: str):\n  """"""Build and push docker image using `tfx/tools/docker/Dockerfile`.\n\n  Args:\n    container_image: Docker container image name.\n    repo_base: The src path to use to build docker image.\n  """"""\n  client = docker.from_env()\n\n  logging.info(\'Building image %s\', container_image)\n  with Timer(\'BuildingTFXContainerImage\'):\n    _ = client.images.build(\n        path=repo_base,\n        dockerfile=\'tfx/tools/docker/Dockerfile\',\n        tag=container_image,\n        buildargs={\n            # Skip license gathering for tests.\n            \'gather_third_party_licenses\': \'false\',\n        },\n    )\n\n  logging.info(\'Pushing image %s\', container_image)\n  with Timer(\'PushingTFXContainerImage\'):\n    client.images.push(repository=container_image)\n\n\ndef delete_gcs_files(gcp_project_id: str, bucket_name: str, path: str):\n  """"""Deletes files under specified path in the test bucket.\n\n  Args:\n    gcp_project_id: GCP project ID.\n    bucket_name: GCS bucket name.\n    path: path(or prefix) of the file to delete.\n  """"""\n  client = storage.Client(project=gcp_project_id)\n  bucket = client.get_bucket(bucket_name)\n  logging.info(\'Deleting files under GCS bucket path: %s\', path)\n\n  with Timer(\'ListingAndDeletingFilesFromGCS\'):\n    blobs = bucket.list_blobs(prefix=path)\n    bucket.delete_blobs(blobs)\n'"
tfx/orchestration/tfx_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition of TFX runner base class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom typing import Any, Optional\n\nimport six\n\nfrom tfx.orchestration.config import pipeline_config\n\n\nclass TfxRunner(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Base runner class for TFX.\n\n  This is the base class for every TFX runner.\n  """"""\n\n  def __init__(self, config: Optional[pipeline_config.PipelineConfig] = None):\n    """"""Initializes a TfxRunner instance.\n\n    Args:\n      config: Optional pipeline config for customizing the launching\n        of each component.\n    """"""\n    self._config = config or pipeline_config.PipelineConfig()\n\n  @abc.abstractmethod\n  def run(self, pipeline) -> Optional[Any]:\n    """"""Runs logical TFX pipeline on specific platform.\n\n    Args:\n      pipeline: logical TFX pipeline definition.\n\n    Returns:\n      Platform-specific object.\n    """"""\n    pass\n'"
tfx/proto/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/scripts/__init__.py,0,b''
tfx/scripts/run_component.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Script to invoke TFX components using simple command-line.\n\nNo backwards compatibility guarantees.\n""""""\n\n# TODO(b/149535307): Remove __future__ imports\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nimport sys\nfrom typing import List, Text\n\nfrom google.protobuf import json_format\nfrom google.protobuf import message\nfrom tfx.components.base import base_executor\nfrom tfx.types import channel_utils\nfrom tfx.utils import import_utils\n\n\ndef run_component(\n    full_component_class_name: Text,\n    temp_directory_path: Text = None,\n    beam_pipeline_args: List[Text] = None,\n    **arguments\n):\n  r""""""Loads a component, instantiates it with arguments and runs its executor.\n\n  The component class is instantiated, so the component code is executed,\n  not just the executor code.\n\n  To pass artifact URI, use <input_name>_uri argument name.\n  To pass artifact property, use <input_name>_<property> argument name.\n  Protobuf property values can be passed as JSON-serialized protobufs.\n\n  # pylint: disable=line-too-long\n\n  Example::\n\n    # When run as a script:\n    python3 scripts/run_component.py \\\n      --full-component-class-name tfx.components.StatisticsGen \\\n      --examples-uri gs://my_bucket/chicago_taxi_simple/CsvExamplesGen/examples/1/ \\\n      --examples-split-names \'[""train"", ""eval""]\' \\\n      --output-uri gs://my_bucket/chicago_taxi_simple/StatisticsGen/output/1/\n\n    # When run as a function:\n    run_component(\n      full_component_class_name=\'tfx.components.StatisticsGen\',\n      examples_uri=\'gs://my_bucket/chicago_taxi_simple/CsvExamplesGen/sxamples/1/\',\n      examples_split_names=\'[""train"", ""eval""]\',\n      output_uri=\'gs://my_bucket/chicago_taxi_simple/StatisticsGen/output/1/\',\n    )\n\n  Args:\n    full_component_class_name: The component class name including module name.\n    temp_directory_path: Optional. Temporary directory path for the executor.\n    beam_pipeline_args: Optional. Arguments to pass to the Beam pipeline.\n    **arguments: Key-value pairs with component arguments.\n  """"""\n  component_class = import_utils.import_class_by_path(full_component_class_name)\n\n  component_arguments = {}\n\n  for name, execution_param in component_class.SPEC_CLASS.PARAMETERS.items():\n    argument_value = arguments.get(name, None)\n    if argument_value is None:\n      continue\n    param_type = execution_param.type\n    if (isinstance(param_type, type) and\n        issubclass(param_type, message.Message)):\n      argument_value_obj = param_type()\n      json_format.Parse(argument_value, argument_value_obj)\n    else:\n      argument_value_obj = argument_value\n    component_arguments[name] = argument_value_obj\n\n  for input_name, channel_param in component_class.SPEC_CLASS.INPUTS.items():\n    uri = (arguments.get(input_name + \'_uri\') or\n           arguments.get(input_name + \'_path\'))\n    if uri:\n      artifact = channel_param.type()\n      artifact.uri = uri\n      # Setting the artifact properties\n      for property_name in channel_param.type.PROPERTIES:\n        property_arg_name = input_name + \'_\' + property_name\n        if property_arg_name in arguments:\n          setattr(artifact, property_name, arguments[property_arg_name])\n      component_arguments[input_name] = channel_utils.as_channel([artifact])\n\n  component_instance = component_class(**component_arguments)\n\n  input_dict = channel_utils.unwrap_channel_dict(\n      component_instance.inputs.get_all())\n  output_dict = channel_utils.unwrap_channel_dict(\n      component_instance.outputs.get_all())\n  exec_properties = component_instance.exec_properties\n\n  # Generating paths for output artifacts\n  for output_name, artifacts in output_dict.items():\n    uri = (arguments.get(\'output_\' + output_name + \'_uri\') or\n           arguments.get(output_name + \'_uri\') or\n           arguments.get(output_name + \'_path\'))\n    if uri:\n      for artifact in artifacts:\n        artifact.uri = uri\n\n  executor_context = base_executor.BaseExecutor.Context(\n      beam_pipeline_args=beam_pipeline_args,\n      tmp_dir=temp_directory_path,\n      unique_id=\'\',\n  )\n  executor = component_instance.executor_spec.executor_class(executor_context)\n  executor.Do(\n      input_dict=input_dict,\n      output_dict=output_dict,\n      exec_properties=exec_properties,\n  )\n\n\nif __name__ == \'__main__\':\n  params = sys.argv[1::2]\n  values = sys.argv[2::2]\n  args = {\n      param.lstrip(\'-\').replace(\'-\', \'_\'): value\n      for param, value in zip(params, values)\n  }\n  run_component(**args)\n'"
tfx/scripts/run_component_test.py,3,"b'# Lint as: python3\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.scripts.run_component.""""""\n\n# TODO(b/149535307): Remove __future__ imports\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nfrom absl.testing import absltest\nimport tensorflow as tf\nfrom tfx.scripts import run_component\nfrom tfx.types import artifact_utils\n\n\nclass RunComponentTest(absltest.TestCase):\n\n  def testRunStatisticsGen(self):\n    # Prepare the paths\n    test_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'../components/testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', tempfile.mkdtemp()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(output_data_dir)\n\n    # Run StatisticsGen\n    run_component.run_component(\n        full_component_class_name=\'tfx.components.StatisticsGen\',\n        examples_uri=os.path.join(test_data_dir, \'csv_example_gen\'),\n        examples_split_names=artifact_utils.encode_split_names(\n            [\'train\', \'eval\']),\n        stats_uri=output_data_dir,\n    )\n\n    # Check the statistics_gen outputs\n    self.assertTrue(tf.io.gfile.exists(\n        os.path.join(output_data_dir, \'train\', \'stats_tfrecord\')))\n    self.assertTrue(tf.io.gfile.exists(\n        os.path.join(output_data_dir, \'eval\', \'stats_tfrecord\')))\n'"
tfx/scripts/run_executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common script to invoke TFX executors.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport base64\nimport json\n\nimport absl\n\nfrom tensorflow.python.platform import app  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.components.base import base_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import import_utils\n\n\ndef _run_executor(args, pipeline_args) -> None:\n  r""""""Select a particular executor and run it based on name.\n\n  # pylint: disable=line-too-long\n  _run_executor() is used to invoke a class subclassing\n  tfx.components.base.base_executor.BaseExecutor.  This function can be used for\n  both invoking the executor on remote environments as well as for unit testing\n  of executors.\n\n  How to invoke an executor as standalone:\n  # TODO(b/132958430): Create utility script to generate arguments for run_executor.py\n  First, the input data needs to be prepared.  An easy way to generate the test\n  data is to fully run the pipeline once.  This will generate the data to be\n  used for testing as well as log the artifacts to be used as input parameters.\n  In each executed component, three log entries will be generated similar to the\n  below:\n  ```\n  [2019-05-16 08:59:27,117] {logging_mixin.py:95} INFO - [2019-05-16 08:59:27,116] {base_executor.py:72} INFO - Starting Executor execution.\n  [2019-05-16 08:59:27,117] {logging_mixin.py:95} INFO - [2019-05-16 08:59:27,117] {base_executor.py:74} INFO - Inputs for Executor is: {""input_base"": [{""artifact"": {""id"": ""1"", ""typeId"": ""1"", ""uri"": ""/usr/local/google/home/khaas/taxi/data/simple"", ""properties"": {""split"": {""stringValue"": """"}, ""state"": {""stringValue"": ""published""}, ""span"": {""intValue"": ""1""}, ""type_name"": {""stringValue"": ""ExternalPath""}}}, ""artifact_type"": {""id"": ""1"", ""name"": ""ExternalPath"", ""properties"": {""span"": ""INT"", ""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING""}}}]}\n  [2019-05-16 08:59:27,117] {logging_mixin.py:95} INFO - [2019-05-16 08:59:27,117] {base_executor.py:76} INFO - Outputs for Executor is: {""examples"": [{""artifact"": {""uri"": ""/usr/local/google/home/khaas/tfx/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/train/"", ""properties"": {""type_name"": {""stringValue"": ""ExamplesPath""}, ""split"": {""stringValue"": ""train""}, ""span"": {""intValue"": ""1""}}}, ""artifact_type"": {""name"": ""ExamplesPath"", ""properties"": {""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING"", ""span"": ""INT""}}}, {""artifact"": {""uri"": ""/usr/local/google/home/khaas/tfx/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/eval/"", ""properties"": {""type_name"": {""stringValue"": ""ExamplesPath""}, ""split"": {""stringValue"": ""eval""}, ""span"": {""intValue"": ""1""}}}, ""artifact_type"": {""name"": ""ExamplesPath"", ""properties"": {""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING"", ""span"": ""INT""}}}]}\n  [2019-05-16 08:59:27,117] {logging_mixin.py:95} INFO - [2019-05-16 08:59:27,117] {base_executor.py:78} INFO - Execution properties for Executor is: {""output"": ""{  \\""splitConfig\\"": {\\""splits\\"": [{\\""name\\"": \\""train\\"", \\""hashBuckets\\"": 2}, {\\""name\\"": \\""eval\\"",\\""hashBuckets\\"": 1}]}}""}\n  ```\n  Each of these map directly to the input parameters expected by run_executor():\n  ```\n  python scripts/run_executor.py \\\n      --executor_class_path=tfx.components.example_gen.big_query_example_gen.executor.Executor \\\n      --inputs={""input_base"": [{""artifact"": {""id"": ""1"", ""typeId"": ""1"", ""uri"": ""/usr/local/google/home/khaas/taxi/data/simple"", ""properties"": {""split"": {""stringValue"": """"}, ""state"": {""stringValue"": ""published""}, ""span"": {""intValue"": ""1""}, ""type_name"": {""stringValue"": ""ExternalPath""}}}, ""artifact_type"": {""id"": ""1"", ""name"": ""ExternalPath"", ""properties"": {""span"": ""INT"", ""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING""}}}]} \\\n      --outputs={""examples"": [{""artifact"": {""uri"": ""/usr/local/google/home/khaas/tfx/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/train/"", ""properties"": {""type_name"": {""stringValue"": ""ExamplesPath""}, ""split"": {""stringValue"": ""train""}, ""span"": {""intValue"": ""1""}}}, ""artifact_type"": {""name"": ""ExamplesPath"", ""properties"": {""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING"", ""span"": ""INT""}}}, {""artifact"": {""uri"": ""/usr/local/google/home/khaas/tfx/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/eval/"", ""properties"": {""type_name"": {""stringValue"": ""ExamplesPath""}, ""split"": {""stringValue"": ""eval""}, ""span"": {""intValue"": ""1""}}}, ""artifact_type"": {""name"": ""ExamplesPath"", ""properties"": {""name"": ""STRING"", ""type_name"": ""STRING"", ""split"": ""STRING"", ""state"": ""STRING"", ""span"": ""INT""}}}]} \\\n      --exec-properties={""output"": ""{  \\""splitConfig\\"": {\\""splits\\"": [{\\""name\\"": \\""train\\"", \\""hashBuckets\\"": 2}, {\\""name\\"": \\""eval\\"",\\""hashBuckets\\"": 1}]}}""}\n  ```\n  # pylint: disable=line-too-long\n\n  Args:\n    args:\n      - inputs: The input artifacts for this execution, serialized as JSON.\n      - outputs: The output artifacts to be generated by this execution,\n        serialized as JSON.\n      - exec_properties: The execution properties to be used by this execution,\n        serialized as JSON.\n    pipeline_args: Optional parameter that maps to the optional_pipeline_args\n    parameter in the pipeline, which provides additional configuration options\n    for apache-beam and tensorflow.logging.\n\n  Returns:\n    None\n\n  Raises:\n    None\n  """"""\n\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  (inputs_str, outputs_str,\n   exec_properties_str) = (args.inputs or base64.b64decode(args.inputs_base64),\n                           args.outputs or\n                           base64.b64decode(args.outputs_base64),\n                           args.exec_properties or\n                           base64.b64decode(args.exec_properties_base64))\n\n  inputs = artifact_utils.parse_artifact_dict(inputs_str)\n  outputs = artifact_utils.parse_artifact_dict(outputs_str)\n  exec_properties = json.loads(exec_properties_str)\n  absl.logging.info(\n      \'Executor {} do: inputs: {}, outputs: {}, exec_properties: {}\'.format(\n          args.executor_class_path, inputs, outputs, exec_properties))\n  executor_cls = import_utils.import_class_by_path(args.executor_class_path)\n  executor_context = base_executor.BaseExecutor.Context(\n      beam_pipeline_args=pipeline_args,\n      tmp_dir=args.temp_directory_path,\n      unique_id=\'\')\n  executor = executor_cls(executor_context)\n  absl.logging.info(\'Starting executor\')\n  executor.Do(inputs, outputs, exec_properties)\n\n  # The last line of stdout will be pushed to xcom by Airflow.\n  if args.write_outputs_stdout:\n    print(artifact_utils.jsonify_artifact_dict(outputs))\n\n\ndef main(argv):\n  """"""Parses  the arguments for _run_executor() then invokes it.\n\n  # pylint: disable=line-too-long\n  Args:\n    argv: Unparsed arguments for run_executor.py\n      --executor_class_path: Python class of executor in format of <module>.<class>.\n      --temp_directory_path: Common temp directory path for executors.\n      --inputs: JSON serialized dict of input artifacts.  If the input needs to be base64-encoded, use --inputs-base64 instead.\n      --inputs-base64: base64-encoded JSON serialized dict of input artifacts.  If the input is not base64-encoded, use --inputs instead.\n      --outputs: JSON serialized dict of output artifacts.  If the output needs to be base64-encoded, use --outputs-base64 instead.\n      --outputs-base64: base64-encoded JSON serialized dict of output artifacts.  If the output is not base64-encoded, use --outputs instead.\n      --exec_properties: JSON serialized dict of (non artifact) execution properties.  If the execution properties need to be base64-encoded, use --exec_properties-base64 instead.\n      --exec_properties-base64: base64-encoded JSON serialized dict of (non artifact) execution properties.  If the execution properties are not base64-encoded, use --exec_properties instead.\n      --write_outputs_stdout: Write outputs to last line of stdout, which will be pushed to xcom in Airflow. Please ignore by other users or orchestrators.\n  # pylint: disable=line-too-long\n\n  Returns:\n    None\n\n  Raises:\n    None\n  """"""\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      \'--executor_class_path\',\n      type=str,\n      required=True,\n      help=\'Python class of executor in format of <module>.<class>.\')\n  parser.add_argument(\n      \'--temp_directory_path\',\n      type=str,\n      help=\'common temp directory path for executors\')\n  inputs_group = parser.add_mutually_exclusive_group(required=True)\n  inputs_group.add_argument(\n      \'--inputs\',\n      type=str,\n      help=\'json serialized dict of input artifacts.\')\n  inputs_group.add_argument(\n      \'--inputs-base64\',\n      type=str,\n      help=\'base64 encoded json serialized dict of input artifacts.\')\n\n  outputs_group = parser.add_mutually_exclusive_group(required=True)\n  outputs_group.add_argument(\n      \'--outputs\',\n      type=str,\n      help=\'json serialized dict of output artifacts.\')\n  outputs_group.add_argument(\n      \'--outputs-base64\',\n      type=str,\n      help=\'base64 encoded json serialized dict of output artifacts.\')\n\n  execution_group = parser.add_mutually_exclusive_group(required=True)\n  execution_group.add_argument(\n      \'--exec-properties\',\n      type=str,\n      help=\'json serialized dict of (non artifact) execution properties.\')\n  execution_group.add_argument(\n      \'--exec-properties-base64\',\n      type=str,\n      help=\'json serialized dict of (non artifact) execution properties.\')\n\n  parser.add_argument(\n      \'--write-outputs-stdout\',\n      dest=\'write_outputs_stdout\',\n      action=\'store_true\',\n      help=\'Write outputs to last line of stdout, which will \'\n      \'be pushed to xcom in Airflow. Please ignore by other users or \'\n      \'orchestrators.\')\n\n  args, beam_pipeline_args = parser.parse_known_args(argv)\n  _run_executor(args, beam_pipeline_args)\n\n\nif __name__ == \'__main__\':\n  app.run(main=main)\n'"
tfx/scripts/run_executor_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.scripts.run_executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nfrom typing import Any, Dict, List, Text\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.scripts import run_executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ArgsCapture(object):\n  instance = None\n\n  def __enter__(self):\n    ArgsCapture.instance = self\n    return self\n\n  def __exit__(self, exception_type, exception_value, traceback):\n    ArgsCapture.instance = None\n\n\nclass FakeExecutor(base_executor.BaseExecutor):\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Overrides BaseExecutor.Do().""""""\n    args_capture = ArgsCapture.instance\n    args_capture.input_dict = input_dict\n    args_capture.output_dict = output_dict\n    args_capture.exec_properties = exec_properties\n\n\nclass RunExecutorTest(tf.test.TestCase):\n\n  def testMainEmptyInputs(self):\n    """"""Test executor class import under empty inputs/outputs.""""""\n    inputs = {\n        \'x\': [\n            standard_artifacts.ExternalArtifact(),\n            standard_artifacts.ExternalArtifact()\n        ]\n    }\n    outputs = {\'y\': [standard_artifacts.Examples()]}\n    exec_properties = {\'a\': \'b\'}\n    args = [\n        \'--executor_class_path=%s.%s\' %\n        (FakeExecutor.__module__, FakeExecutor.__name__),\n        \'--inputs=%s\' % artifact_utils.jsonify_artifact_dict(inputs),\n        \'--outputs=%s\' % artifact_utils.jsonify_artifact_dict(outputs),\n        \'--exec-properties=%s\' % json.dumps(exec_properties),\n    ]\n    with ArgsCapture() as args_capture:\n      run_executor.main(args)\n      # TODO(b/131417512): Add equal comparison to types.Artifact class so we\n      # can use asserters.\n      self.assertSetEqual(\n          set(args_capture.input_dict.keys()), set(inputs.keys()))\n      self.assertSetEqual(\n          set(args_capture.output_dict.keys()), set(outputs.keys()))\n      self.assertDictEqual(args_capture.exec_properties, exec_properties)\n\n\n# TODO(zhitaoli): Add tests for:\n# - base64 decoding of flags;\n# - write output.\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/scripts/strip_type_hints.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Helper script to strip python hint annotations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport strip_hints\n\n\ndef strip_all_type_hints(root_dir):\n  """"""Strip all type hints in place from the directory rooted from root_dir.""""""\n  for root, _, files in os.walk(root_dir):\n    for filename in files:\n      if not filename.endswith(\'.py\'):\n        continue\n      filepath = os.path.join(root, filename)\n      print(\'Processing python file %s\' % filepath)\n      code_string = strip_hints.strip_file_to_string(\n          filepath,\n          to_empty=False,\n          no_ast=False,\n          no_colon_move=False,\n          only_assigns_and_defs=False,\n          only_test_for_changes=False)\n      with open(filepath, \'w\') as f:\n        f.write(code_string)\n\n\ndef main():\n  if sys.version_info.major != 2:\n    print(\'Not running python 2, skipping stripping\')\n    return\n\n  repo_base = os.path.dirname(os.path.dirname(__file__))\n  print(\'Stripping python 3 type hints under {}\'.format(repo_base))\n  strip_all_type_hints(repo_base)\n\n\nif __name__ == \'__main__\':\n  main()\n'"
tfx/tools/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/build_docs.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Script to generate api_docs for tfx.\n\n# How to run\n\nInstall tensorflow_docs (if necessary):\n\n```\npip install git+https://github.com/tensorflow/docs\n```\n\nRun the script:\n\n```shell\npython build_docs.py \\\n--output_dir=/tmp/tfx_api\n```\n\nNote:\n  If duplicate or spurious docs are generated, consider\n  blacklisting them via the `private_map` argument below. Or\n  `api_generator.doc_controls`\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\nfrom absl import app\nfrom absl import flags\n\nimport tensorflow_docs.api_generator as api_generator\nfrom tensorflow_docs.api_generator import doc_controls\nfrom tensorflow_docs.api_generator import generate_lib\n\n\n# Standard Imports.third_party.tfx as tfx\n# pylint: disable=unused-import\nfrom tfx import components\nfrom tfx import orchestration\nimport tfx.version\n# pylint: enable=unused-import\n\nGITHUB_URL_PREFIX = (""https://github.com/tensorflow/tfx/blob/{}/tfx"".format(\n    tfx.version.__version__))\n\nflags.DEFINE_string(""output_dir"", ""/tmp/tfx_api"", ""Where to output the docs"")\nflags.DEFINE_string(\n    ""code_url_prefix"",\n    ""https://github.com/tensorflow/tfx/blob/master/tfx/"",\n    ""The url prefix for links to code."")\nflags.DEFINE_bool(""search_hints"", True,\n                  ""Include metadata search hints in the generated files"")\nflags.DEFINE_string(""site_path"", ""tfx/api_docs/python"",\n                    ""Path prefix in the _toc.yaml"")\nFLAGS = flags.FLAGS\n\n\ndef ignore_test_objects(path, parent, children):\n  """"""Removes all ""test"" modules. These are not part of the public api.\n\n  Arguments:\n    path: A tuple of name parts forming the attribute-lookup path to this\n      object. For `tf.keras.layers.Dense` path is:\n        (""tf"",""keras"",""layers"",""Dense"")\n    parent: The parent object.\n    children: A list of (name, value) pairs. The attributes of the patent.\n\n  Returns:\n    A filtered list of children `(name, value)` pairs. With all test modules\n    removed.\n  """"""\n  del path\n  del parent\n  return [(name, obj) for (name, obj) in children\n          if not (name.endswith(""_test"") or name == ""testdata"")]\n\n\ndef main(_):\n  # These make up for the empty __init__.py files.\n  api_generator.utils.recursive_import(tfx.orchestration)\n  api_generator.utils.recursive_import(tfx.components)\n\n  do_not_generate_docs_for = []\n  for name in [""utils"", ""proto"", ""dependencies"", ""version""]:\n    submodule = getattr(tfx, name, None)\n    if submodule is not None:\n      do_not_generate_docs_for.append(submodule)\n\n  for obj in do_not_generate_docs_for:\n    doc_controls.do_not_generate_docs(obj)\n\n  doc_generator = generate_lib.DocGenerator(\n      root_title=""TFX"",\n      py_modules=[(""tfx"", tfx)],\n      code_url_prefix=FLAGS.code_url_prefix,\n      search_hints=FLAGS.search_hints,\n      site_path=FLAGS.site_path,\n      private_map={},\n      # local_definitions_filter ensures that shared modules are only\n      # documented in the location that defines them, instead of every location\n      # that imports them.\n      callbacks=[\n          api_generator.public_api.local_definitions_filter, ignore_test_objects\n      ])\n  doc_generator.build(output_dir=FLAGS.output_dir)\n\n\nif __name__ == ""__main__"":\n  app.run(main)\n'"
tfx/types/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Subpackage for TFX pipeline types.""""""\n\nfrom typing import Text, Union\n\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.artifact import ValueArtifact\nfrom tfx.types.channel import Channel\nfrom tfx.types.component_spec import ComponentSpec\n\n# Property type for artifacts, executions and contexts.\nPropertyType = Union[int, float, Text]\n'"
tfx/types/artifact.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX artifact type definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport builtins\nimport copy\nimport enum\nimport importlib\nimport json\nimport os\nfrom typing import Any, Dict, Optional, Text, Type\n\nimport absl\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.utils import json_utils\n\n\nclass ArtifactState(object):\n  """"""Enumeration of possible Artifact states.""""""\n\n  # Indicates that there is a pending execution producing the artifact.\n  PENDING = \'pending\'\n  # Indicates that the artifact ready to be consumed.\n  PUBLISHED = \'published\'\n  # Indicates that the no data at the artifact uri, though the artifact is not\n  # marked as deleted.\n  MISSING = \'missing\'\n  # Indicates that the artifact should be garbage collected.\n  MARKED_FOR_DELETION = \'MARKED_FOR_DELETION\'\n  # Indicates that the artifact has been garbage collected.\n  DELETED = \'deleted\'\n\n\n# Default split of examples data.\nDEFAULT_EXAMPLE_SPLITS = [\'train\', \'eval\']\n\n# Prefix for custom properties to prevent name collision.\n# TODO(b/152444458): Revisit this part after we have a better aligned type\n# system.\nCUSTOM_PROPERTIES_PREFIX = \'custom:\'\n\n\nclass PropertyType(enum.Enum):\n  INT = 1\n  FLOAT = 2\n  STRING = 3\n\n\nclass Property(object):\n  """"""Property specified for an Artifact.""""""\n  _ALLOWED_MLMD_TYPES = {\n      PropertyType.INT: metadata_store_pb2.INT,\n      PropertyType.FLOAT: metadata_store_pb2.DOUBLE,\n      PropertyType.STRING: metadata_store_pb2.STRING,\n  }\n\n  def __init__(self, type):  # pylint: disable=redefined-builtin\n    if type not in Property._ALLOWED_MLMD_TYPES:\n      raise ValueError(\'Property type must be one of %s.\' %\n                       list(Property._ALLOWED_MLMD_TYPES.keys()))\n    self.type = type\n\n  def mlmd_type(self):\n    return Property._ALLOWED_MLMD_TYPES[self.type]\n\n\nclass Artifact(json_utils.Jsonable):\n  """"""TFX artifact used for orchestration.\n\n  This is used for type-checking and inter-component communication. Currently,\n  it wraps a tuple of (ml_metadata.proto.Artifact,\n  ml_metadata.proto.ArtifactType) with additional property accessors for\n  internal state.\n\n  A user may create a subclass of Artifact and override the TYPE_NAME property\n  with the type for this artifact subclass. Users of the subclass may then omit\n  the ""type_name"" field when construction the object.\n\n  A user may specify artifact type-specific properties for an Artifact subclass\n  by overriding the PROPERTIES dictionary, as detailed below.\n\n  Note: the behavior of this class is experimental, without backwards\n  compatibility guarantees, and may change in upcoming releases.\n  """"""\n\n  # String artifact type name used to identify the type in ML Metadata\n  # database. Must be overridden by subclass.\n  #\n  # Example usage:\n  #\n  # TYPE_NAME = \'MyTypeName\'\n  TYPE_NAME = None\n\n  # Optional dictionary of property name strings as keys and `Property`\n  # objects as values, used to specify the artifact type\'s properties.\n  # Subsequently, this artifact property may be accessed as Python attributes\n  # of the artifact object.\n  #\n  # Example usage:\n  #\n  # PROPERTIES = {\n  #   \'span\': Property(type=PropertyType.INT),\n  #   # Comma separated of splits for an artifact. Empty string means artifact\n  #   # has no split.\n  #   \'split_names\': Property(type=PropertyType.STRING),\n  # }\n  #\n  # Subsequently, these properties can be stored and accessed as\n  # `myartifact.span` and `myartifact.split_name`, respectively.\n  PROPERTIES = None\n\n  # Initialization flag to support setattr / getattr behavior.\n  _initialized = False\n\n  def __init__(\n      self,\n      mlmd_artifact_type: Optional[metadata_store_pb2.ArtifactType] = None):\n    """"""Construct an instance of Artifact.\n\n    Used by TFX internal implementation: create an empty Artifact with\n    type_name and optional split info specified. The remaining info will be\n    filled in during compiling and running time. The Artifact should be\n    transparent to end users and should not be initiated directly by pipeline\n    users.\n\n    Args:\n      mlmd_artifact_type: Proto message defining the underlying ArtifactType.\n        Optional and intended for internal use.\n    """"""\n    if self.__class__ == Artifact:\n      if not mlmd_artifact_type:\n        raise ValueError(\n            \'The ""mlmd_artifact_type"" argument must be passed to specify a \'\n            \'type for this Artifact.\')\n      if not isinstance(mlmd_artifact_type, metadata_store_pb2.ArtifactType):\n        raise ValueError(\n            \'The ""mlmd_artifact_type"" argument must be an instance of the \'\n            \'proto message ml_metadata.proto.metadata_store_pb2.ArtifactType.\')\n    else:\n      if mlmd_artifact_type:\n        raise ValueError(\n            \'The ""mlmd_artifact_type"" argument must not be passed for \'\n            \'Artifact subclass %s.\' % self.__class__)\n      mlmd_artifact_type = self._get_artifact_type()\n\n    # MLMD artifact type proto object.\n    self._artifact_type = mlmd_artifact_type\n    # Underlying MLMD artifact proto object.\n    self._artifact = metadata_store_pb2.Artifact()\n    # Initialization flag to prevent recursive getattr / setattr errors.\n    self._initialized = True\n\n  @classmethod\n  def _get_artifact_type(cls):\n    if not getattr(cls, \'_MLMD_ARTIFACT_TYPE\', None):\n      type_name = cls.TYPE_NAME\n      if not (type_name and isinstance(type_name, (str, Text))):\n        raise ValueError(\n            (\'The Artifact subclass %s must override the TYPE_NAME attribute \'\n             \'with a string type name identifier (got %r instead).\') %\n            (cls, type_name))\n      artifact_type = metadata_store_pb2.ArtifactType()\n      artifact_type.name = type_name\n      if cls.PROPERTIES:\n        # Perform validation on PROPERTIES dictionary.\n        if not isinstance(cls.PROPERTIES, dict):\n          raise ValueError(\n              \'Artifact subclass %s.PROPERTIES is not a dictionary.\' % cls)\n        for key, value in cls.PROPERTIES.items():\n          if not (isinstance(key,\n                             (Text, bytes)) and isinstance(value, Property)):\n            raise ValueError(\n                (\'Artifact subclass %s.PROPERTIES dictionary must have keys of \'\n                 \'type string and values of type artifact.Property.\') % cls)\n\n        # Populate ML Metadata artifact properties dictionary.\n        for key, value in cls.PROPERTIES.items():\n          artifact_type.properties[key] = value.mlmd_type()\n      cls._MLMD_ARTIFACT_TYPE = artifact_type\n    return copy.deepcopy(cls._MLMD_ARTIFACT_TYPE)\n\n  def __getattr__(self, name: Text) -> Any:\n    """"""Custom __getattr__ to allow access to artifact properties.""""""\n    if name == \'_artifact_type\':\n      # Prevent infinite recursion when used with copy.deepcopy().\n      raise AttributeError()\n    if name not in self._artifact_type.properties:\n      raise AttributeError(\'Artifact has no property %r.\' % name)\n    property_mlmd_type = self._artifact_type.properties[name]\n    if property_mlmd_type == metadata_store_pb2.STRING:\n      if name not in self._artifact.properties:\n        # Avoid populating empty property protobuf with the [] operator.\n        return \'\'\n      return self._artifact.properties[name].string_value\n    elif property_mlmd_type == metadata_store_pb2.INT:\n      if name not in self._artifact.properties:\n        # Avoid populating empty property protobuf with the [] operator.\n        return 0\n      return self._artifact.properties[name].int_value\n    elif property_mlmd_type == metadata_store_pb2.DOUBLE:\n      if name not in self._artifact.properties:\n        # Avoid populating empty property protobuf with the [] operator.\n        return 0.0\n      return self._artifact.properties[name].double_value\n    else:\n      raise Exception(\'Unknown MLMD type %r for property %r.\' %\n                      (property_mlmd_type, name))\n\n  def __setattr__(self, name: Text, value: Any):\n    """"""Custom __setattr__ to allow access to artifact properties.""""""\n    if not self._initialized:\n      object.__setattr__(self, name, value)\n      return\n    if name not in self._artifact_type.properties:\n      if (name in self.__dict__ or\n          any(name in c.__dict__ for c in self.__class__.mro())):\n        # Use any provided getter / setter if available.\n        object.__setattr__(self, name, value)\n        return\n      # In the case where we do not handle this via an explicit getter /\n      # setter, we assume that the user implied an artifact attribute store,\n      # and we raise an exception since such an attribute was not explicitly\n      # defined in the Artifact PROPERTIES dictionary.\n      raise AttributeError(\'Cannot set unknown property %r on artifact %r.\' %\n                           (name, self))\n    property_mlmd_type = self._artifact_type.properties[name]\n    if property_mlmd_type == metadata_store_pb2.STRING:\n      if not isinstance(value, (Text, bytes)):\n        raise Exception(\n            \'Expected string value for property %r; got %r instead.\' %\n            (name, value))\n      self._artifact.properties[name].string_value = value\n    elif property_mlmd_type == metadata_store_pb2.INT:\n      if not isinstance(value, int):\n        raise Exception(\n            \'Expected integer value for property %r; got %r instead.\' %\n            (name, value))\n      self._artifact.properties[name].int_value = value\n    elif property_mlmd_type == metadata_store_pb2.DOUBLE:\n      if not isinstance(value, float):\n        raise Exception(\n            \'Expected integer value for property %r; got %r instead.\' %\n            (name, value))\n      self._artifact.properties[name].double_value = value\n    else:\n      raise Exception(\'Unknown MLMD type %r for property %r.\' %\n                      (property_mlmd_type, name))\n\n  def set_mlmd_artifact(self, artifact: metadata_store_pb2.Artifact):\n    """"""Replace the MLMD artifact object on this artifact.""""""\n    if not isinstance(artifact, metadata_store_pb2.Artifact):\n      raise ValueError(\n          (\'Expected instance of metadata_store_pb2.Artifact, got %s \'\n           \'instead.\') % (artifact,))\n    self._artifact = artifact\n\n  def set_mlmd_artifact_type(self,\n                             artifact_type: metadata_store_pb2.ArtifactType):\n    """"""Set entire ArtifactType in this object.""""""\n    if not isinstance(artifact_type, metadata_store_pb2.ArtifactType):\n      raise ValueError(\n          (\'Expected instance of metadata_store_pb2.ArtifactType, got %s \'\n           \'instead.\') % (artifact_type,))\n    self._artifact_type = artifact_type\n    self._artifact.type_id = artifact_type.id\n\n  def __repr__(self):\n    return \'Artifact(type_name: {}, uri: {}, id: {})\'.format(\n        self._artifact_type.name, self.uri, str(self.id))\n\n  def to_json_dict(self) -> Dict[Text, Any]:\n    return {\n        \'artifact\':\n            json.loads(\n                json_format.MessageToJson(\n                    message=self._artifact, preserving_proto_field_name=True)),\n        \'artifact_type\':\n            json.loads(\n                json_format.MessageToJson(\n                    message=self._artifact_type,\n                    preserving_proto_field_name=True)),\n        \'__artifact_class_module__\':\n            self.__class__.__module__,\n        \'__artifact_class_name__\':\n            self.__class__.__name__,\n    }\n\n  @classmethod\n  def from_json_dict(cls, dict_data: Dict[Text, Any]) -> Any:\n    module_name = dict_data[\'__artifact_class_module__\']\n    class_name = dict_data[\'__artifact_class_name__\']\n    artifact = metadata_store_pb2.Artifact()\n    artifact_type = metadata_store_pb2.ArtifactType()\n    json_format.Parse(json.dumps(dict_data[\'artifact\']), artifact)\n    json_format.Parse(json.dumps(dict_data[\'artifact_type\']), artifact_type)\n\n    # First, try to resolve the specific class used for the artifact; if this\n    # is not possible, use a generic artifact.Artifact object.\n    result = None\n    try:\n      artifact_cls = getattr(importlib.import_module(module_name), class_name)\n      # If the artifact type is the base Artifact class, do not construct the\n      # object here since that constructor requires the mlmd_artifact_type\n      # argument.\n      if artifact_cls != Artifact:\n        result = artifact_cls()\n    except (AttributeError, ImportError, ValueError):\n      absl.logging.warning((\n          \'Could not load artifact class %s.%s; using fallback deserialization \'\n          \'for the relevant artifact. Please make sure that any artifact \'\n          \'classes can be imported within your container or environment.\') %\n                           (module_name, class_name))\n    if not result:\n      result = Artifact(mlmd_artifact_type=artifact_type)\n    result.set_mlmd_artifact_type(artifact_type)\n    result.set_mlmd_artifact(artifact)\n    return result\n\n  # Read-only properties.\n  @property\n  def type(self):\n    return self.__class__\n\n  @property\n  def type_name(self):\n    return self._artifact_type.name\n\n  @property\n  def artifact_type(self):\n    return self._artifact_type\n\n  @property\n  def mlmd_artifact(self):\n    return self._artifact\n\n  # Settable properties for all artifact types.\n  @property\n  def uri(self) -> Text:\n    """"""Artifact URI.""""""\n    return self._artifact.uri\n\n  @uri.setter\n  def uri(self, uri: Text):\n    """"""Setter for artifact URI.""""""\n    self._artifact.uri = uri\n\n  @property\n  def id(self) -> int:\n    """"""Id of underlying artifact.""""""\n    return self._artifact.id\n\n  @id.setter\n  def id(self, artifact_id: int):\n    """"""Set id of underlying artifact.""""""\n    self._artifact.id = artifact_id\n\n  @property\n  def type_id(self) -> int:\n    """"""Id of underlying artifact type.""""""\n    return self._artifact.type_id\n\n  @type_id.setter\n  def type_id(self, type_id: int):\n    """"""Set id of underlying artifact type.""""""\n    self._artifact.type_id = type_id\n\n  # System-managed properties for all artifact types. Will be deprecated soon\n  # in favor of a unified getter / setter interface and MLMD context.\n  #\n  # TODO(b/135056715): Rely on MLMD context for pipeline grouping for\n  # artifacts once it\'s ready.\n  #\n  # The following system properties are used:\n  #   - name: The name of the artifact, used to differentiate same type of\n  #       artifact produced by the same component (in a subsequent change, this\n  #       information will move to the associated ML Metadata Event object).\n  #   - state: The state of an artifact; can be one of PENDING, PUBLISHED,\n  #       MISSING, DELETING, DELETED (in a subsequent change, this information\n  #       will move to a top-level ML Metadata Artifact attribute).\n  #   - pipeline_name: The name of the pipeline that produces the artifact (in\n  #       a subsequent change, this information will move to an associated ML\n  #       Metadata Context attribute).\n  #   - producer_component: The name of the component that produces the\n  #       artifact (in a subsequent change, this information will move to the\n  #       associated ML Metadata Event object).\n  def _get_system_property(self, key: Text) -> Text:\n    if (key in self._artifact_type.properties and\n        key in self._artifact.properties):\n      # Legacy artifact types which have explicitly defined system properties.\n      return self._artifact.properties[key].string_value\n    return self._artifact.custom_properties[key].string_value\n\n  def _set_system_property(self, key: Text, value: Text):\n    if (key in self._artifact_type.properties and\n        key in self._artifact.properties):\n      # Clear non-custom property in legacy artifact types.\n      del self._artifact.properties[key]\n    self._artifact.custom_properties[key].string_value = value\n\n  @property\n  def name(self) -> Text:\n    """"""Name of the underlying artifact.""""""\n    return self._get_system_property(\'name\')\n\n  @name.setter\n  def name(self, name: Text):\n    """"""Set name of the underlying artifact.""""""\n    self._set_system_property(\'name\', name)\n\n  @property\n  def state(self) -> Text:\n    """"""State of the underlying artifact.""""""\n    return self._get_system_property(\'state\')\n\n  @state.setter\n  def state(self, state: Text):\n    """"""Set state of the underlying artifact.""""""\n    self._set_system_property(\'state\', state)\n\n  @property\n  def pipeline_name(self) -> Text:\n    """"""Name of the pipeline that produce the artifact.""""""\n    return self._get_system_property(\'pipeline_name\')\n\n  @pipeline_name.setter\n  def pipeline_name(self, pipeline_name: Text):\n    """"""Set name of the pipeline that produce the artifact.""""""\n    self._set_system_property(\'pipeline_name\', pipeline_name)\n\n  @property\n  def producer_component(self) -> Text:\n    """"""Producer component of the artifact.""""""\n    return self._get_system_property(\'producer_component\')\n\n  @producer_component.setter\n  def producer_component(self, producer_component: Text):\n    """"""Set producer component of the artifact.""""""\n    self._set_system_property(\'producer_component\', producer_component)\n\n  # Custom property accessors.\n  def set_string_custom_property(self, key: Text, value: Text):\n    """"""Set a custom property of string type.""""""\n    self._artifact.custom_properties[key].string_value = value\n\n  def set_int_custom_property(self, key: Text, value: int):\n    """"""Set a custom property of int type.""""""\n    self._artifact.custom_properties[key].int_value = builtins.int(value)\n\n  def get_string_custom_property(self, key: Text) -> Text:\n    """"""Get a custom property of string type.""""""\n    return self._artifact.custom_properties[key].string_value\n\n  def get_int_custom_property(self, key: Text) -> int:\n    """"""Get a custom property of int type.""""""\n    return self._artifact.custom_properties[key].int_value\n\n\nclass ValueArtifact(Artifact):\n  """"""Artifacts of small scalar-values that can be easily loaded into memory.""""""\n\n  VALUE_FILE = \'value\'  # File name storing the actual value under uri.\n\n  def __init__(self, *args, **kwargs):\n    self._has_value = False\n    self._modified = False\n    self._value = None\n    super(ValueArtifact, self).__init__(*args, **kwargs)\n\n  def read(self):\n    if not self._has_value:\n      file_path = os.path.join(self.uri, self.__class__.VALUE_FILE)\n      # Assert there is a file exists.\n      if (not tf.io.gfile.exists(file_path)) or tf.io.gfile.isdir(file_path):\n        raise RuntimeError(\n            \'Given path does not exist or is not a valid file: %s\' % file_path)\n\n      serialized_value = tf.io.gfile.GFile(file_path, \'rb\').read()\n      self._has_value = True\n      self._value = self.decode(serialized_value)\n    return self._value\n\n  def write(self, value):\n    serialized_value = self.encode(value)\n    tf.io.gfile.GFile(os.path.join(self.uri, self.__class__.VALUE_FILE),\n                      \'wb\').write(serialized_value)\n\n  @property\n  def value(self):\n    if not self._has_value:\n      raise ValueError(\'The artifact value has not yet been read from storage.\')\n    return self._value\n\n  @value.setter\n  def value(self, value):\n    self._modified = True\n    self._value = value\n    self.write(value)\n\n  # Note: behavior of decode() method should not be changed to provide\n  # backward/forward compatibility.\n  @abc.abstractmethod\n  def decode(self, serialized_value) -> bytes:\n    """"""Method decoding the file content. Implemented by subclasses.""""""\n    pass\n\n  # Note: behavior of encode() method should not be changed to provide\n  # backward/forward compatibility.\n  @abc.abstractmethod\n  def encode(self, value) -> Any:\n    """"""Method encoding the file content. Implemented by subclasses.""""""\n    pass\n\n\ndef _ArtifactType(  # pylint: disable=invalid-name\n    name: Optional[str] = None,  # pylint: disable=g-ambiguous-str-annotation\n    properties: Optional[Dict[Text, Property]] = None,\n    mlmd_artifact_type: Optional[metadata_store_pb2.ArtifactType] = None\n) -> Type[Artifact]:\n  """"""Experimental interface: internal use only.\n\n  Construct an artifact type.\n\n  Equivalent to subclassing Artifact and providing relevant properties. The user\n  must either provide (1) a type ""name"" and ""properties"" or (2) a MLMD\n  metadata_store_pb2.ArtifactType protobuf message as the ""mlmd_artifact_type""\n  parameter.\n\n  Args:\n    name: Name of the artifact type in MLMD. Must be provided unless a protobuf\n      message is provided in the ""mlmd_artifact_type"" parameter.\n    properties: Dictionary of properties mapping property name keys to\n      `Parameter` object instances. Must be provided unless a protobuf message\n      is provided in the ""mlmd_artifact_type"" parameter.\n    mlmd_artifact_type: A ML Metadata metadata_store_pb2.ArtifactType protobuf\n      message corresponding to the type being created.\n\n  Returns:\n    An Artifact class corresponding to the specified type.\n  """"""\n  if mlmd_artifact_type:\n    if name or properties:\n      raise ValueError(\n          \'The ""name"" and ""properties"" fields should not be passed when the \'\n          \'""mlmd_artifact_type"" parameter is set, in _ArtifactType call.\')\n    if not mlmd_artifact_type.name:\n      raise ValueError(\'Artifact type proto must have ""name"" field set.\')\n    properties = {}\n    for name, property_type in mlmd_artifact_type.properties.items():\n      if property_type == metadata_store_pb2.PropertyType.INT:\n        properties[name] = Property(PropertyType.INT)\n      elif property_type == metadata_store_pb2.PropertyType.DOUBLE:\n        properties[name] = Property(PropertyType.FLOAT)\n      elif property_type == metadata_store_pb2.PropertyType.STRING:\n        properties[name] = Property(PropertyType.STRING)\n      else:\n        raise ValueError(\'Unsupported MLMD property type: %s.\' % property_type)\n    return type(\n        str(mlmd_artifact_type.name), (Artifact,), {\n            \'TYPE_NAME\': mlmd_artifact_type.name,\n            \'PROPERTIES\': properties,\n        })\n  else:\n    if not name:\n      raise ValueError(\n          \'""name"" parameter must be passed to _ArtifactType when a \'\n          \'metadata_store_pb2.ArtifactType object is not passed for the \'\n          \'""mlmd_artifact_type"" parameter.\')\n    return type(name, (Artifact,), {\n        \'TYPE_NAME\': name,\n        \'PROPERTIES\': properties\n    })\n'"
tfx/types/artifact_test.py,10,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.types.artifact.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Text\n\n# Standard Imports\n\nimport absl\nimport mock\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.types import artifact\nfrom tfx.utils import json_utils\n\n\nclass _MyArtifact(artifact.Artifact):\n  TYPE_NAME = \'MyTypeName\'\n  PROPERTIES = {\n      \'int1\': artifact.Property(type=artifact.PropertyType.INT),\n      \'int2\': artifact.Property(type=artifact.PropertyType.INT),\n      \'float1\': artifact.Property(type=artifact.PropertyType.FLOAT),\n      \'float2\': artifact.Property(type=artifact.PropertyType.FLOAT),\n      \'string1\': artifact.Property(type=artifact.PropertyType.STRING),\n      \'string2\': artifact.Property(type=artifact.PropertyType.STRING),\n  }\n\n_MyArtifact2 = artifact._ArtifactType(  # pylint: disable=invalid-name\n    name=\'MyTypeName2\',\n    properties={\n        \'int1\': artifact.Property(type=artifact.PropertyType.INT),\n        \'int2\': artifact.Property(type=artifact.PropertyType.INT),\n        \'float1\': artifact.Property(type=artifact.PropertyType.FLOAT),\n        \'float2\': artifact.Property(type=artifact.PropertyType.FLOAT),\n        \'string1\': artifact.Property(type=artifact.PropertyType.STRING),\n        \'string2\': artifact.Property(type=artifact.PropertyType.STRING),\n    })\n\n_mlmd_artifact_type = metadata_store_pb2.ArtifactType()\njson_format.Parse(\n    json.dumps({\n        \'name\': \'MyTypeName3\',\n        \'properties\': {\n            \'int1\': \'INT\',\n            \'int2\': \'INT\',\n            \'float1\': \'DOUBLE\',\n            \'float2\': \'DOUBLE\',\n            \'string1\': \'STRING\',\n            \'string2\': \'STRING\'\n        }\n    }), _mlmd_artifact_type)\n_MyArtifact3 = artifact._ArtifactType(mlmd_artifact_type=_mlmd_artifact_type)  # pylint: disable=invalid-name\n\n\nclass _MyValueArtifact(artifact.ValueArtifact):\n  TYPE_NAME = \'MyValueTypeName\'\n\n  def encode(self, value: Text):\n    assert isinstance(value, Text), value\n    return value.encode(\'utf-8\')\n\n  def decode(self, value: bytes):\n    return value.decode(\'utf-8\')\n\n\n# Mock values for string artifact.\n_STRING_VALUE = u\'This is a string\'\n_BYTE_VALUE = b\'This is a string\'\n\n# Mock paths for string artifact.\n_VALID_URI = \'/tmp/uri\'\n_VALID_FILE_URI = os.path.join(_VALID_URI, artifact.ValueArtifact.VALUE_FILE)\n\n# Mock invalid paths. _BAD_URI points to a valid dir but there\'s no file within.\n_BAD_URI = \'/tmp/to/a/bad/dir\'\n_BAD_FILE_URI = os.path.join(_BAD_URI, artifact.ValueArtifact.VALUE_FILE)\n\n\ndef fake_exist(path: Text) -> bool:\n  """"""Mock behavior of tf.io.gfile.exists.""""""\n  return path in [_VALID_URI, _VALID_FILE_URI, _BAD_URI]\n\n\ndef fake_isdir(path: Text) -> bool:\n  """"""Mock behavior of tf.io.gfile.isdir.""""""\n  return path in [_VALID_URI, _BAD_URI]\n\n\nclass ArtifactTest(tf.test.TestCase):\n\n  def testArtifact(self):\n    instance = _MyArtifact()\n\n    # Test property getters.\n    self.assertEqual(\'\', instance.uri)\n    self.assertEqual(0, instance.id)\n    self.assertEqual(0, instance.type_id)\n    self.assertEqual(\'MyTypeName\', instance.type_name)\n    self.assertEqual(\'\', instance.state)\n\n    # Default property does not have span or split_names.\n    with self.assertRaisesRegexp(AttributeError, ""has no property \'span\'""):\n      instance.span  # pylint: disable=pointless-statement\n    with self.assertRaisesRegexp(AttributeError,\n                                 ""has no property \'split_names\'""):\n      instance.split_names  # pylint: disable=pointless-statement\n\n    # Test property setters.\n    instance.uri = \'/tmp/uri2\'\n    self.assertEqual(\'/tmp/uri2\', instance.uri)\n\n    instance.id = 1\n    self.assertEqual(1, instance.id)\n\n    instance.type_id = 2\n    self.assertEqual(2, instance.type_id)\n\n    instance.state = artifact.ArtifactState.DELETED\n    self.assertEqual(artifact.ArtifactState.DELETED, instance.state)\n\n    # Default artifact does not have span.\n    with self.assertRaisesRegexp(AttributeError, ""unknown property \'span\'""):\n      instance.span = 20190101\n    # Default artifact does not have span.\n    with self.assertRaisesRegexp(AttributeError,\n                                 ""unknown property \'split_names\'""):\n      instance.split_names = \'\'\n\n    instance.set_int_custom_property(\'int_key\', 20)\n    self.assertEqual(\n        20, instance.mlmd_artifact.custom_properties[\'int_key\'].int_value)\n\n    instance.set_string_custom_property(\'string_key\', \'string_value\')\n    self.assertEqual(\n        \'string_value\',\n        instance.mlmd_artifact.custom_properties[\'string_key\'].string_value)\n\n    self.assertEqual(\'Artifact(type_name: MyTypeName, uri: /tmp/uri2, id: 1)\',\n                     str(instance))\n\n    # Test json serialization.\n    json_dict = json_utils.dumps(instance)\n    other_instance = json_utils.loads(json_dict)\n    self.assertEqual(instance.mlmd_artifact, other_instance.mlmd_artifact)\n    self.assertEqual(instance.artifact_type, other_instance.artifact_type)\n\n  def testArtifactTypeFunctionAndProto(self):\n    # Test usage of _MyArtifact2 and _MyArtifact3, which were defined using the\n    # _ArtifactType function.\n    types_and_names = [\n        (_MyArtifact2, \'MyTypeName2\'),\n        (_MyArtifact3, \'MyTypeName3\'),\n    ]\n    for type_cls, name in types_and_names:\n      self.assertEqual(type_cls.TYPE_NAME, name)\n      my_artifact = type_cls()\n      self.assertEqual(0, my_artifact.int1)\n      self.assertEqual(0, my_artifact.int2)\n      my_artifact.int1 = 111\n      my_artifact.int2 = 222\n      self.assertEqual(0.0, my_artifact.float1)\n      self.assertEqual(0.0, my_artifact.float2)\n      my_artifact.float1 = 111.1\n      my_artifact.float2 = 222.2\n      self.assertEqual(\'\', my_artifact.string1)\n      self.assertEqual(\'\', my_artifact.string2)\n      my_artifact.string1 = \'111\'\n      my_artifact.string2 = \'222\'\n      self.assertEqual(my_artifact.int1, 111)\n      self.assertEqual(my_artifact.int2, 222)\n      self.assertEqual(my_artifact.float1, 111.1)\n      self.assertEqual(my_artifact.float2, 222.2)\n      self.assertEqual(my_artifact.string1, \'111\')\n      self.assertEqual(my_artifact.string2, \'222\')\n\n  def testInvalidArtifact(self):\n    with self.assertRaisesRegexp(\n        ValueError, \'The ""mlmd_artifact_type"" argument must be passed\'):\n      artifact.Artifact()\n\n    class MyBadArtifact(artifact.Artifact):\n      # No TYPE_NAME\n      pass\n\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The Artifact subclass .* must override the TYPE_NAME attribute \'):\n      MyBadArtifact()\n\n    class MyNewArtifact(artifact.Artifact):\n      TYPE_NAME = \'MyType\'\n\n    # Okay without additional type_name argument.\n    MyNewArtifact()\n\n    # Not okay to pass type_name on subclass.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The ""mlmd_artifact_type"" argument must not be passed for Artifact \'\n        \'subclass\'):\n      MyNewArtifact(mlmd_artifact_type=metadata_store_pb2.ArtifactType())\n\n  def testArtifactProperties(self):\n    my_artifact = _MyArtifact()\n    self.assertEqual(0, my_artifact.int1)\n    self.assertEqual(0, my_artifact.int2)\n    my_artifact.int1 = 111\n    my_artifact.int2 = 222\n    self.assertEqual(\'\', my_artifact.string1)\n    self.assertEqual(\'\', my_artifact.string2)\n    my_artifact.string1 = \'111\'\n    my_artifact.string2 = \'222\'\n    self.assertEqual(my_artifact.int1, 111)\n    self.assertEqual(my_artifact.int2, 222)\n    self.assertEqual(my_artifact.string1, \'111\')\n    self.assertEqual(my_artifact.string2, \'222\')\n\n    with self.assertRaisesRegexp(\n        AttributeError, ""Cannot set unknown property \'invalid\' on artifact""):\n      my_artifact.invalid = 1\n\n    with self.assertRaisesRegexp(\n        AttributeError, ""Cannot set unknown property \'invalid\' on artifact""):\n      my_artifact.invalid = \'x\'\n\n    with self.assertRaisesRegexp(AttributeError,\n                                 ""Artifact has no property \'invalid\'""):\n      my_artifact.invalid  # pylint: disable=pointless-statement\n\n  def testStringTypeNameNotAllowed(self):\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The ""mlmd_artifact_type"" argument must be an instance of the proto \'\n        \'message\'):\n      artifact.Artifact(\'StringTypeName\')\n\n  @mock.patch(\'absl.logging.warning\')\n  def testDeserialize(self, *unused_mocks):\n    original = _MyArtifact()\n    original.uri = \'/my/path\'\n    original.int1 = 111\n    original.int2 = 222\n    original.string1 = \'111\'\n    original.string2 = \'222\'\n\n    serialized = original.to_json_dict()\n\n    rehydrated = artifact.Artifact.from_json_dict(serialized)\n    absl.logging.warning.assert_not_called()\n    self.assertIs(rehydrated.__class__, _MyArtifact)\n    self.assertEqual(rehydrated.int1, 111)\n    self.assertEqual(rehydrated.int2, 222)\n    self.assertEqual(rehydrated.string1, \'111\')\n    self.assertEqual(rehydrated.string2, \'222\')\n\n  @mock.patch(\'absl.logging.warning\')\n  def testDeserializeUnknownArtifactClass(self, *unused_mocks):\n    original = _MyArtifact()\n    original.uri = \'/my/path\'\n    original.int1 = 111\n    original.int2 = 222\n    original.string1 = \'111\'\n    original.string2 = \'222\'\n\n    serialized = original.to_json_dict()\n    serialized[\'__artifact_class_name__\'] = \'MissingClassName\'\n\n    rehydrated = artifact.Artifact.from_json_dict(serialized)\n    absl.logging.warning.assert_called_once()\n    self.assertIs(rehydrated.__class__, artifact.Artifact)\n    self.assertEqual(rehydrated.int1, 111)\n    self.assertEqual(rehydrated.int2, 222)\n    self.assertEqual(rehydrated.string1, \'111\')\n    self.assertEqual(rehydrated.string2, \'222\')\n\n    serialized2 = rehydrated.to_json_dict()\n    rehydrated = artifact.Artifact.from_json_dict(serialized2)\n    self.assertIs(rehydrated.__class__, artifact.Artifact)\n    self.assertEqual(rehydrated.int1, 111)\n    self.assertEqual(rehydrated.int2, 222)\n    self.assertEqual(rehydrated.string1, \'111\')\n    self.assertEqual(rehydrated.string2, \'222\')\n\n\nclass ValueArtifactTest(tf.test.TestCase):\n  """"""Tests for ValueArtifact.""""""\n\n  def setUp(self):\n    super(ValueArtifactTest, self).setUp()\n    self.addCleanup(mock.patch.stopall)\n\n    self._mock_gfile_readfn = mock.patch.object(\n        tf.io.gfile.GFile,\n        \'read\',\n        autospec=True,\n        return_value=_BYTE_VALUE,\n    ).start()\n\n  @mock.patch.object(tf.io.gfile, \'exists\', fake_exist)\n  @mock.patch.object(tf.io.gfile, \'isdir\', fake_isdir)\n  def testValueArtifact(self):\n    instance = _MyValueArtifact()\n    # Test property setters.\n    instance.uri = _VALID_URI\n    self.assertEqual(_VALID_URI, instance.uri)\n\n    with self.assertRaisesRegexp(\n        ValueError, \'The artifact value has not yet been read from storage.\'):\n      instance.value  # pylint: disable=pointless-statement\n\n    instance.read()\n    self.assertEqual(_STRING_VALUE, instance.value)\n\n  @mock.patch.object(tf.io.gfile, \'exists\', fake_exist)\n  @mock.patch.object(tf.io.gfile, \'isdir\', fake_isdir)\n  def testValueArtifactWithBadUri(self):\n    instance = _MyValueArtifact()\n    instance.uri = _BAD_URI\n\n    with self.assertRaisesRegexp(\n        RuntimeError, \'Given path does not exist or is not a valid file\'):\n      instance.read()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/artifact_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Artifact utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport itertools\nimport json\nimport os\nimport re\n\nfrom typing import Dict, List, Optional, Text, Type\n\nimport absl\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.types.artifact import _ArtifactType\nfrom tfx.types.artifact import Artifact\n\n\n# TODO(ruoyu): Deprecate this function since it is no longer needed.\ndef parse_artifact_dict(json_str: Text) -> Dict[Text, List[Artifact]]:\n  """"""Parse a dict from key to list of Artifact from its json format.""""""\n  tfx_artifacts = {}\n  for k, l in json.loads(json_str).items():\n    tfx_artifacts[k] = [Artifact.from_json_dict(v) for v in l]\n  return tfx_artifacts\n\n\n# TODO(ruoyu): Deprecate this function since it is no longer needed.\ndef jsonify_artifact_dict(artifact_dict: Dict[Text, List[Artifact]]) -> Text:\n  """"""Serialize a dict from key to list of Artifact into json format.""""""\n  d = {}\n  for k, l in artifact_dict.items():\n    d[k] = [v.to_json_dict() for v in l]\n  return json.dumps(d)\n\n\ndef get_single_instance(artifact_list: List[Artifact]) -> Artifact:\n  """"""Get a single instance of Artifact from a list of length one.\n\n  Args:\n    artifact_list: A list of Artifact objects whose length must be one.\n\n  Returns:\n    The single Artifact object in artifact_list.\n\n  Raises:\n    ValueError: If length of artifact_list is not one.\n  """"""\n  if len(artifact_list) != 1:\n    raise ValueError(\'expected list length of one but got {}\'.format(\n        len(artifact_list)))\n  return artifact_list[0]\n\n\ndef get_single_uri(artifact_list: List[Artifact]) -> Text:\n  """"""Get the uri of Artifact from a list of length one.\n\n  Args:\n    artifact_list: A list of Artifact objects whose length must be one.\n\n  Returns:\n    The uri of the single Artifact object in artifact_list.\n\n  Raises:\n    ValueError: If length of artifact_list is not one.\n  """"""\n  return get_single_instance(artifact_list).uri\n\n\ndef get_split_uri(artifact_list: List[Artifact], split: Text) -> Text:\n  """"""Get the uri of Artifact with matching split from given list.\n\n  Args:\n    artifact_list: A list of Artifact objects whose length must be one.\n    split: Name of split.\n\n  Returns:\n    The uri of Artifact object in artifact_list with matching split.\n\n  Raises:\n    ValueError: If number with matching split in artifact_list is not one.\n  """"""\n  matching_artifacts = []\n  for artifact in artifact_list:\n    split_names = decode_split_names(artifact.split_names)\n    if split in split_names:\n      matching_artifacts.append(artifact)\n  if len(matching_artifacts) != 1:\n    raise ValueError(\n        (\'Expected exactly one artifact with split %r, but found matching \'\n         \'artifacts %s.\') % (split, matching_artifacts))\n  return os.path.join(matching_artifacts[0].uri, split)\n\n\ndef encode_split_names(splits: List[Text]) -> Text:\n  """"""Get the encoded representation of a list of split names.""""""\n  rewritten_splits = []\n  for split in splits:\n    # TODO(b/146759051): Remove workaround for RuntimeParameter object once\n    # this bug is clarified.\n    if split.__class__.__name__ == \'RuntimeParameter\':\n      absl.logging.warning(\n          \'RuntimeParameter provided for split name: this functionality may \'\n          \'not be supported in the future.\')\n      split = str(split)\n      # Intentionally ignore split format check to pass through the template for\n      # now. This behavior is very fragile and should be fixed (see\n      # b/146759051).\n    elif not re.match(\'^([A-Za-z0-9][A-Za-z0-9_-]*)?$\', split):\n      # TODO(ccy): Disallow empty split names once the importer removes split as\n      # a property for all artifacts.\n      raise ValueError(\n          (\'Split names are expected to be alphanumeric (allowing dashes and \'\n           \'underscores, provided they are not the first character); got %r \'\n           \'instead.\') % (split,))\n    rewritten_splits.append(split)\n  return json.dumps(rewritten_splits)\n\n\ndef decode_split_names(split_names: Text) -> List[Text]:\n  """"""Decode an encoded list of split names.""""""\n  if not split_names:\n    return []\n  return json.loads(split_names)\n\n\ndef _get_subclasses(cls: Type[Artifact]) -> List[Type[Artifact]]:\n  """"""Internal method. Get transitive subclasses of an Artifact subclass.""""""\n  all_subclasses = []\n  for subclass in cls.__subclasses__():\n    all_subclasses.append(subclass)\n    all_subclasses.extend(_get_subclasses(subclass))\n  return all_subclasses\n\n\ndef get_artifact_type_class(\n    artifact_type: metadata_store_pb2.ArtifactType) -> Type[Artifact]:\n  """"""Get the artifact type class corresponding to an MLMD type proto.""""""\n\n  # Make sure this module path containing the standard Artifact subclass\n  # definitions is imported. Modules containing custom artifact subclasses that\n  # need to be deserialized should be imported by the entrypoint of the\n  # application or container.\n  from tfx.types import standard_artifacts  # pylint: disable=g-import-not-at-top,import-outside-toplevel,unused-import,unused-variable\n\n  # Enumerate the Artifact type ontology, separated into auto-generated and\n  # natively-defined classes.\n  artifact_classes = _get_subclasses(Artifact)\n  native_artifact_classes = []\n  generated_artifact_classes = []\n  for cls in artifact_classes:\n    if not cls.TYPE_NAME:\n      # Skip abstract classes.\n      continue\n    if getattr(cls, \'_AUTOGENERATED\', False):\n      generated_artifact_classes.append(cls)\n    else:\n      native_artifact_classes.append(cls)\n\n  # Try to find an existing class for the artifact type, if it exists. Prefer\n  # to use a native artifact class.\n  for cls in itertools.chain(native_artifact_classes,\n                             generated_artifact_classes):\n    candidate_type = cls._get_artifact_type()  # pylint: disable=protected-access\n    # We need to compare `.name` and `.properties` (and not the entire proto\n    # directly), because the proto `.id` field will be populated when the type\n    # is read from MLMD.\n    if (artifact_type.name == candidate_type.name and\n        artifact_type.properties == candidate_type.properties):\n      return cls\n\n  # Generate a class for the artifact type on the fly.\n  absl.logging.warning(\n      (\'Could not find matching artifact class for type %r (proto: %r); \'\n       \'generating an ephemeral artifact class on-the-fly. If this is not \'\n       \'intended, please make sure that the artifact class for this type can \'\n       \'be imported within your container or environment where a component \'\n       \'is executed to consume this type.\') %\n      (artifact_type.name, str(artifact_type)))\n  new_artifact_class = _ArtifactType(mlmd_artifact_type=artifact_type)\n  setattr(new_artifact_class, \'_AUTOGENERATED\', True)\n  return new_artifact_class\n\n\ndef deserialize_artifact(\n    artifact_type: metadata_store_pb2.ArtifactType,\n    artifact: Optional[metadata_store_pb2.Artifact] = None) -> Artifact:\n  """"""Reconstruct Artifact object from MLMD proto descriptors.\n\n  Internal method, no backwards compatibility guarantees.\n\n  Args:\n    artifact_type: A metadata_store_pb2.ArtifactType proto object describing the\n      type of the artifact.\n    artifact: A metadata_store_pb2.Artifact proto object describing the contents\n      of the artifact.  If not provided, an Artifact of the desired type with\n      empty contents is created.\n\n  Returns:\n    Artifact subclass object for the given MLMD proto descriptors.\n  """"""\n  # Validate inputs.\n  if not isinstance(artifact_type, metadata_store_pb2.ArtifactType):\n    raise ValueError(\n        (\'Expected metadata_store_pb2.ArtifactType for artifact_type, got %s \'\n         \'instead\') % (artifact_type,))\n  if artifact and not isinstance(artifact, metadata_store_pb2.Artifact):\n    raise ValueError(\n        (\'Expected metadata_store_pb2.Artifact for artifact, got %s \'\n         \'instead\') % (artifact,))\n\n  # Get the artifact\'s class and construct the Artifact object.\n  artifact_cls = get_artifact_type_class(artifact_type)\n  result = artifact_cls()\n  result.set_mlmd_artifact(artifact)\n  return result\n'"
tfx/types/artifact_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.types.artifact_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport copy\n\n# Standard Imports\n\nimport absl\nimport mock\nimport tensorflow as tf\nfrom tfx.types import artifact\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass _MyArtifact(artifact.Artifact):\n  TYPE_NAME = \'ArtifactUtilsTypeName\'\n  PROPERTIES = {\n      \'dummy_int\': artifact.Property(artifact.PropertyType.INT),\n      \'dummy_string\': artifact.Property(artifact.PropertyType.STRING),\n  }\n\n\nclass ArtifactUtilsTest(tf.test.TestCase):\n\n  def testGetFromSingleList(self):\n    """"""Test various retrieval utilities on a single list of Artifact.""""""\n    artifacts = [standard_artifacts.Examples()]\n    artifacts[0].uri = \'/tmp/evaluri\'\n    artifacts[0].split_names = \'[""eval""]\'\n    self.assertEqual(artifacts[0],\n                     artifact_utils.get_single_instance(artifacts))\n    self.assertEqual(\'/tmp/evaluri\', artifact_utils.get_single_uri(artifacts))\n    self.assertEqual(\'/tmp/evaluri/eval\',\n                     artifact_utils.get_split_uri(artifacts, \'eval\'))\n    with self.assertRaises(ValueError):\n      artifact_utils.get_split_uri(artifacts, \'train\')\n\n  def testGetFromSplits(self):\n    """"""Test various retrieval utilities on a list of split Artifact.""""""\n    artifacts = [standard_artifacts.Examples()]\n    artifacts[0].uri = \'/tmp\'\n    artifacts[0].split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n\n    self.assertEqual(artifacts[0].split_names, \'[""train"", ""eval""]\')\n\n    self.assertIs(artifact_utils.get_single_instance(artifacts), artifacts[0])\n    self.assertEqual(\'/tmp\', artifact_utils.get_single_uri(artifacts))\n    self.assertEqual(\'/tmp/train\',\n                     artifact_utils.get_split_uri(artifacts, \'train\'))\n    self.assertEqual(\'/tmp/eval\',\n                     artifact_utils.get_split_uri(artifacts, \'eval\'))\n\n  def testArtifactTypeRoundTrip(self):\n    mlmd_artifact_type = standard_artifacts.Examples._get_artifact_type()\n    self.assertIs(standard_artifacts.Examples,\n                  artifact_utils.get_artifact_type_class(mlmd_artifact_type))\n    mlmd_artifact_type = _MyArtifact._get_artifact_type()\n    # Test that the ID is ignored for type comparison purposes during\n    # deserialization.\n    mlmd_artifact_type.id = 123\n    self.assertIs(_MyArtifact,\n                  artifact_utils.get_artifact_type_class(mlmd_artifact_type))\n\n  @mock.patch(\'absl.logging.warning\')\n  def testArtifactTypeRoundTripUnknownArtifactClass(self, *unused_mocks):\n    mlmd_artifact_type = copy.deepcopy(\n        standard_artifacts.Examples._get_artifact_type())\n    self.assertIs(standard_artifacts.Examples,\n                  artifact_utils.get_artifact_type_class(mlmd_artifact_type))\n    mlmd_artifact_type.name = \'UnknownTypeName\'\n\n    reconstructed_class = artifact_utils.get_artifact_type_class(\n        mlmd_artifact_type)\n    absl.logging.warning.assert_called_once()\n\n    self.assertIsNot(standard_artifacts.Examples, reconstructed_class)\n    self.assertTrue(issubclass(reconstructed_class, artifact.Artifact))\n    self.assertEqual(\'UnknownTypeName\', reconstructed_class.TYPE_NAME)\n    self.assertEqual(mlmd_artifact_type,\n                     reconstructed_class._get_artifact_type())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/channel.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Channel definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport inspect\nimport json\n\nfrom typing import Any, Dict, Iterable, Optional, Text, Type\n\nfrom google.protobuf import json_format\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types.artifact import Artifact\nfrom tfx.utils import json_utils\n\n\nclass Channel(json_utils.Jsonable):\n  """"""Tfx Channel.\n\n  TFX Channel is an abstract concept that connects data producers and data\n  consumers. It contains restriction of the artifact type that should be fed\n  into or read from it.\n\n  Attributes:\n    type: The artifact type class that the Channel takes.\n  """"""\n\n  # TODO(b/125348988): Add support for real Channel in addition to static ones.\n  def __init__(\n      self,\n      type: Optional[Type[Artifact]] = None,  # pylint: disable=redefined-builtin\n      artifacts: Optional[Iterable[Artifact]] = None,\n      producer_component_id: Optional[Text] = None,\n      output_key: Optional[Text] = None):\n    """"""Initialization of Channel.\n\n    Args:\n      type: Subclass of Artifact that represents the type of this Channel.\n      artifacts: (Optional) A collection of artifacts as the values that can be\n        read from the Channel. This is used to construct a static Channel.\n      producer_component_id: (Optional) Producer component id of the Channel.\n      output_key: (Optional) The output key when producer component produces\n        the artifacts in this Channel.\n    """"""\n    if not (inspect.isclass(type) and issubclass(type, Artifact)):  # pytype: disable=wrong-arg-types\n      raise ValueError(\n          \'Argument ""type"" of Channel constructor must be a subclass of \'\n          \'tfx.Artifact (got %r).\' % (type,))\n\n    self.type = type\n    self._artifacts = artifacts or []\n    self._validate_type()\n    # The following fields will be populated during compilation time.\n    self.producer_component_id = producer_component_id\n    self.output_key = output_key\n\n  @property\n  def type_name(self):\n    return self.type.TYPE_NAME\n\n  def __repr__(self):\n    artifacts_str = \'\\n    \'.join(repr(a) for a in self._artifacts)\n    return \'Channel(\\n    type_name: {}\\n    artifacts: [{}]\\n)\'.format(\n        self.type_name, artifacts_str)\n\n  def _validate_type(self) -> None:\n    for artifact in self._artifacts:\n      if artifact.type_name != self.type_name:\n        raise ValueError(\n            ""Artifacts provided do not match Channel\'s artifact type {}"".format(\n                self.type_name))\n\n  def get(self) -> Iterable[Artifact]:\n    """"""Returns all artifacts that can be get from this Channel.\n\n    Returns:\n      An artifact collection.\n    """"""\n    # TODO(b/125037186): We should support dynamic query against a Channel\n    # instead of a static Artifact collection.\n    return self._artifacts\n\n  def to_json_dict(self) -> Dict[Text, Any]:\n    return {\n        \'type\':\n            json.loads(\n                json_format.MessageToJson(\n                    message=self.type._get_artifact_type(),  # pylint: disable=protected-access\n                    preserving_proto_field_name=True)),\n        \'artifacts\':\n            list(a.to_json_dict() for a in self._artifacts),\n        \'producer_component_id\':\n            (self.producer_component_id if self.producer_component_id else None\n            ),\n        \'output_key\': (self.output_key if self.output_key else None),\n    }\n\n  @classmethod\n  def from_json_dict(cls, dict_data: Dict[Text, Any]) -> Any:\n    artifact_type = metadata_store_pb2.ArtifactType()\n    json_format.Parse(json.dumps(dict_data[\'type\']), artifact_type)\n    type_cls = artifact_utils.get_artifact_type_class(artifact_type)\n    artifacts = list(Artifact.from_json_dict(a) for a in dict_data[\'artifacts\'])\n    producer_component_id = dict_data.get(\'producer_component_id\', None)\n    output_key = dict_data.get(\'output_key\', None)\n    return Channel(\n        type=type_cls,\n        artifacts=artifacts,\n        producer_component_id=producer_component_id,\n        output_key=output_key)\n'"
tfx/types/channel_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.channel.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.artifact import Property\nfrom tfx.types.artifact import PropertyType\nfrom tfx.types.channel import Channel\n\n\nclass _MyType(Artifact):\n  TYPE_NAME = \'MyTypeName\'\n  PROPERTIES = {\n      \'string_value\': Property(PropertyType.STRING),\n  }\n\n\nclass _AnotherType(Artifact):\n  TYPE_NAME = \'AnotherTypeName\'\n\n\nclass ChannelTest(tf.test.TestCase):\n\n  def testValidChannel(self):\n    instance_a = _MyType()\n    instance_b = _MyType()\n    chnl = Channel(_MyType, artifacts=[instance_a, instance_b])\n    self.assertEqual(chnl.type_name, \'MyTypeName\')\n    self.assertCountEqual(chnl.get(), [instance_a, instance_b])\n\n  def testInvalidChannelType(self):\n    instance_a = _MyType()\n    instance_b = _MyType()\n    with self.assertRaises(ValueError):\n      Channel(_AnotherType, artifacts=[instance_a, instance_b])\n\n  def testStringTypeNameNotAllowed(self):\n    with self.assertRaises(ValueError):\n      Channel(\'StringTypeName\')\n\n  def testJsonRoundTrip(self):\n    channel = Channel(type=_MyType, artifacts=[_MyType()])\n    serialized = channel.to_json_dict()\n    rehydrated = Channel.from_json_dict(serialized)\n    self.assertIs(channel.type, rehydrated.type)\n    self.assertEqual(channel.type_name, rehydrated.type_name)\n\n  def testJsonRoundTripUnknownArtifactClass(self):\n    channel = Channel(type=_MyType)\n\n    serialized = channel.to_json_dict()\n    serialized[\'type\'][\'name\'] = \'UnknownTypeName\'\n\n    rehydrated = Channel.from_json_dict(serialized)\n    self.assertEqual(\'UnknownTypeName\', rehydrated.type_name)\n    self.assertEqual(channel.type._get_artifact_type().properties,\n                     rehydrated.type._get_artifact_type().properties)\n    self.assertTrue(rehydrated.type._AUTOGENERATED)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/channel_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Channel utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Iterable, List, Text\n\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\n\n\ndef as_channel(artifacts: Iterable[Artifact]) -> Channel:\n  """"""Converts artifact collection of the same artifact type into a Channel.\n\n  Args:\n    artifacts: An iterable of Artifact.\n\n  Returns:\n    A static Channel containing the source artifact collection.\n\n  Raises:\n    ValueError when source is not a non-empty iterable of Artifact.\n  """"""\n  try:\n    first_element = next(iter(artifacts))\n    if isinstance(first_element, Artifact):\n      return Channel(type=first_element.type, artifacts=artifacts)\n    else:\n      raise ValueError(\'Invalid artifact iterable: {}\'.format(artifacts))\n  except StopIteration:\n    raise ValueError(\'Cannot convert empty artifact iterable into Channel\')\n\n\ndef unwrap_channel_dict(\n    channel_dict: Dict[Text, Channel]) -> Dict[Text, List[Artifact]]:\n  """"""Unwrap dict of channels to dict of lists of Artifact.\n\n  Args:\n    channel_dict: a dict of Text -> Channel\n\n  Returns:\n    a dict of Text -> List[Artifact]\n  """"""\n  return dict((k, list(v.get())) for k, v in channel_dict.items())\n'"
tfx/types/channel_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.channel.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.types import channel_utils\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\n\n\nclass _MyArtifact(Artifact):\n  TYPE_NAME = \'MyTypeName\'\n\n\nclass ChannelUtilsTest(tf.test.TestCase):\n\n  def testArtifactCollectionAsChannel(self):\n    instance_a = _MyArtifact()\n    instance_b = _MyArtifact()\n    chnl = channel_utils.as_channel([instance_a, instance_b])\n    self.assertEqual(chnl.type, _MyArtifact)\n    self.assertEqual(chnl.type_name, \'MyTypeName\')\n    self.assertCountEqual(chnl.get(), [instance_a, instance_b])\n\n  def testEmptyArtifactCollectionAsChannelFail(self):\n    with self.assertRaises(ValueError):\n      channel_utils.as_channel([])\n\n  def testInvalidSourceAsChannelFail(self):\n    with self.assertRaises(ValueError):\n      channel_utils.as_channel(artifacts=\'invalid artifacts\')\n\n  def testUnwrapChannelDict(self):\n    instance_a = _MyArtifact()\n    instance_b = _MyArtifact()\n    channel_dict = {\n        \'id\': Channel(_MyArtifact, artifacts=[instance_a, instance_b])\n    }\n    result = channel_utils.unwrap_channel_dict(channel_dict)\n    self.assertDictEqual(result, {\'id\': [instance_a, instance_b]})\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/component_spec.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""ComponentSpec for defining inputs/outputs/properties of TFX components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport copy\nimport inspect\nimport itertools\nfrom typing import Any, Dict, List, Optional, Text, Type\n\nfrom six import with_metaclass\n\nfrom google.protobuf import json_format\nfrom google.protobuf import message\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\nfrom tfx.types.node_common import _PropertyDictWrapper\nfrom tfx.utils import abc_utils\nfrom tfx.utils import json_utils\n\n\ndef _make_default(data: Any) -> Any:\n  """"""Replaces RuntimeParameter by its ptype\'s default.\n\n  Args:\n    data: an object possibly containing RuntimeParameter.\n\n  Returns:\n    A version of input data where RuntimeParameters are replaced with\n    the default values of their ptype.\n  """"""\n  if isinstance(data, dict):\n    copy_data = copy.deepcopy(data)\n    _put_default_dict(copy_data)\n    return copy_data\n  if isinstance(data, list):\n    copy_data = copy.deepcopy(data)\n    _put_default_list(copy_data)\n    return copy_data\n  if data.__class__.__name__ == \'RuntimeParameter\':\n    ptype = data.ptype\n    return ptype.__new__(ptype)\n\n  return data\n\n\ndef _put_default_dict(dict_data: Dict[Text, Any]) -> None:\n  """"""Helper function to replace RuntimeParameter with its default value.""""""\n  for k, v in dict_data.items():\n    if isinstance(v, dict):\n      _put_default_dict(v)\n    elif isinstance(v, list):\n      _put_default_list(v)\n    elif v.__class__.__name__ == \'RuntimeParameter\':\n      # Currently supporting int, float, bool, Text\n      ptype = v.ptype\n      dict_data[k] = ptype.__new__(ptype)\n\n\ndef _put_default_list(list_data: List[Any]) -> None:\n  """"""Helper function to replace RuntimeParameter with its default value.""""""\n  for index, item in enumerate(list_data):\n    if isinstance(item, dict):\n      _put_default_dict(item)\n    elif isinstance(item, list):\n      _put_default_list(item)\n    elif item.__class__.__name__ == \'RuntimeParameter\':\n      # Currently supporting int, float, bool, Text\n      ptype = item.ptype\n      list_data[index] = ptype.__new__(ptype)\n\n\nclass ComponentSpec(with_metaclass(abc.ABCMeta, json_utils.Jsonable)):\n  """"""A specification of the inputs, outputs and parameters for a component.\n\n  Components should have a corresponding ComponentSpec inheriting from this\n  class and must override:\n\n    - PARAMETERS (as a dict of string keys and ExecutionParameter values),\n    - INPUTS (as a dict of string keys and ChannelParameter values) and\n    - OUTPUTS (also a dict of string keys and ChannelParameter values).\n\n  Here is an example of how a ComponentSpec may be defined:\n\n  class MyCustomComponentSpec(ComponentSpec):\n    PARAMETERS = {\n        \'internal_option\': ExecutionParameter(type=str),\n    }\n    INPUTS = {\n        \'input_examples\': ChannelParameter(type=standard_artifacts.Examples),\n    }\n    OUTPUTS = {\n        \'output_examples\': ChannelParameter(type=standard_artifacts.Examples),\n    }\n\n  To create an instance of a subclass, call it directly with any execution\n  parameters / inputs / outputs as kwargs.  For example:\n\n  spec = MyCustomComponentSpec(\n      internal_option=\'abc\',\n      input_examples=input_examples_channel,\n      output_examples=output_examples_channel)\n\n  Attributes:\n    PARAMETERS: a dict of string keys and ExecutionParameter values.\n    INPUTS: a dict of string keys and ChannelParameter values.\n    OUTPUTS: a dict of string keys and ChannelParameter values.\n  """"""\n\n  PARAMETERS = abc_utils.abstract_property()\n  INPUTS = abc_utils.abstract_property()\n  OUTPUTS = abc_utils.abstract_property()\n\n  def __init__(self, **kwargs):\n    """"""Initialize a ComponentSpec.\n\n    Args:\n      **kwargs: Any inputs, outputs and execution parameters for this instance\n        of the component spec.\n    """"""\n    self._raw_args = kwargs\n    self._validate_spec()\n    self._verify_parameter_types()\n    self._parse_parameters()\n\n  def __eq__(self, other):\n    return (isinstance(other.__class__, self.__class__) and\n            self.to_json_dict() == other.to_json_dict())\n\n  def _validate_spec(self):\n    """"""Check the parameters and types passed to this ComponentSpec.""""""\n    for param_name, param in [(\'PARAMETERS\', self.PARAMETERS),\n                              (\'INPUTS\', self.INPUTS),\n                              (\'OUTPUTS\', self.OUTPUTS)]:\n      if not isinstance(param, dict):\n        raise TypeError(\n            (\'Subclass %s of ComponentSpec must override %s with a \'\n             \'dict; got %s instead.\') % (self.__class__, param_name, param))\n\n    # Validate that the ComponentSpec class is well-formed.\n    seen_arg_names = set()\n    for arg_name, arg in itertools.chain(self.PARAMETERS.items(),\n                                         self.INPUTS.items(),\n                                         self.OUTPUTS.items()):\n      if not isinstance(arg, _ComponentParameter):\n        raise ValueError(\n            (\'The ComponentSpec subclass %s expects that the values of its \'\n             \'PARAMETERS, INPUTS, and OUTPUTS dicts are _ComponentParameter \'\n             \'objects (i.e. ChannelParameter or ExecutionParameter objects); \'\n             \'got %s (for argument %s) instead.\') %\n            (self.__class__, arg, arg_name))\n      if arg_name in seen_arg_names:\n        raise ValueError(\n            (\'The ComponentSpec subclass %s has a duplicate argument with \'\n             \'name %s. Argument names should be unique across the PARAMETERS, \'\n             \'INPUTS and OUTPUTS dicts.\') % (self.__class__, arg_name))\n      seen_arg_names.add(arg_name)\n\n  def _verify_parameter_types(self):\n    """"""Verify spec parameter types.""""""\n    for arg in self.PARAMETERS.values():\n      if not isinstance(arg, ExecutionParameter):\n        raise TypeError(\n            (\'PARAMETERS dict expects values of type ExecutionParameter, \'\n             \'got {}.\').format(arg))\n    for arg in itertools.chain(self.INPUTS.values(), self.OUTPUTS.values()):\n      if not isinstance(arg, ChannelParameter):\n        raise TypeError(\n            (\'INPUTS and OUTPUTS dicts expect values of type ChannelParameter, \'\n             \' got {}.\').format(arg))\n\n  def _parse_parameters(self):\n    """"""Parse arguments to ComponentSpec.""""""\n    unparsed_args = set(self._raw_args.keys())\n    inputs = {}\n    outputs = {}\n    self.exec_properties = {}\n\n    # First, check that the arguments are set.\n    for arg_name, arg in itertools.chain(self.PARAMETERS.items(),\n                                         self.INPUTS.items(),\n                                         self.OUTPUTS.items()):\n      if arg_name not in unparsed_args:\n        if arg.optional:\n          continue\n        else:\n          raise ValueError(\'Missing argument %r to %s.\' %\n                           (arg_name, self.__class__))\n      unparsed_args.remove(arg_name)\n\n      # Type check the argument.\n      value = self._raw_args[arg_name]\n      if arg.optional and value is None:\n        continue\n      arg.type_check(arg_name, value)\n\n    # Populate the appropriate dictionary for each parameter type.\n    for arg_name, arg in self.PARAMETERS.items():\n      if arg.optional and arg_name not in self._raw_args:\n        continue\n      value = self._raw_args[arg_name]\n\n      if (inspect.isclass(arg.type) and\n          issubclass(arg.type, message.Message) and value):\n        # Create deterministic json string as it will be stored in metadata for\n        # cache check.\n        if isinstance(value, dict):\n          value = json_utils.dumps(value)\n        else:\n          value = json_format.MessageToJson(\n              message=value, sort_keys=True, preserving_proto_field_name=True)\n\n      self.exec_properties[arg_name] = value\n\n    for arg_name, arg in self.INPUTS.items():\n      if arg.optional and not self._raw_args.get(arg_name):\n        continue\n      value = self._raw_args[arg_name]\n      inputs[arg_name] = value\n    for arg_name, arg in self.OUTPUTS.items():\n      value = self._raw_args[arg_name]\n      outputs[arg_name] = value\n\n    # Note: for forwards compatibility, ComponentSpec objects may provide an\n    # attribute mapping virtual keys to physical keys in the outputs dictionary,\n    # and when the value for a virtual key is accessed, the value for the\n    # physical key will be returned instead. This is intended to provide\n    # forwards compatibility. This feature will be removed once attribute\n    # renaming is completed and *should not* be used by ComponentSpec authors\n    # outside the TFX package.\n    #\n    # TODO(b/139281215): remove this functionality.\n    self.inputs = _PropertyDictWrapper(\n        inputs,\n        compat_aliases=getattr(self, \'_INPUT_COMPATIBILITY_ALIASES\', None))\n    self.outputs = _PropertyDictWrapper(\n        outputs,\n        compat_aliases=getattr(self, \'_OUTPUT_COMPATIBILITY_ALIASES\', None))\n\n  def to_json_dict(self) -> Dict[Text, Any]:\n    """"""Convert from an object to a JSON serializable dictionary.""""""\n    return {\n        \'inputs\': self.inputs,\n        \'outputs\': self.outputs,\n        \'exec_properties\': self.exec_properties,\n    }\n\n\nclass _ComponentParameter(object):\n  """"""An abstract parameter that forms a part of a ComponentSpec.\n\n  Properties:\n    optional: whether the given parameter is optional.\n  """"""\n  pass\n\n\nclass ExecutionParameter(_ComponentParameter):\n  """"""An execution parameter in a ComponentSpec.\n\n  This type of parameter should be specified in the PARAMETERS dict of a\n  ComponentSpec:\n\n  class MyCustomComponentSpec(ComponentSpec):\n    # ...\n    PARAMETERS = {\n        \'internal_option\': ExecutionParameter(type=str),\n    }\n    # ...\n  """"""\n\n  def __init__(self, type=None, optional=False):  # pylint: disable=redefined-builtin\n    self.type = type\n    self.optional = optional\n\n  def __repr__(self):\n    return \'ExecutionParameter(type: %s, optional: %s)\' % (self.type,\n                                                           self.optional)\n\n  def __eq__(self, other):\n    return (isinstance(other.__class__, self.__class__) and\n            other.type == self.type and other.optional == self.optional)\n\n  def type_check(self, arg_name: Text, value: Any):\n    """"""Perform type check to the parameter passed in.""""""\n\n    # Following helper function is needed due to the lack of subscripted\n    # type check support in Python 3.7. Here we hold the assumption that no\n    # nested container type is declared as the parameter type.\n    # For example:\n    # Dict[Text, List[str]] <------ Not allowed.\n    # Dict[Text, Any] <------ Okay.\n    def _type_check_helper(value: Any, declared: Type):  # pylint: disable=g-bare-generic\n      """"""Helper type-checking function.""""""\n      if declared == Any:\n        return\n      if declared.__class__.__name__ in (\'_GenericAlias\', \'GenericMeta\'):\n        # Should be dict or list\n        if declared.__origin__ in [Dict, dict]:  # pylint: disable=protected-access\n          key_type, val_type = declared.__args__[0], declared.__args__[1]\n          if not isinstance(value, dict):\n            raise TypeError(\'Expecting a dict for parameter %r, but got %s \'\n                            \'instead\' % (arg_name, type(value)))\n          for k, v in value.items():\n            if key_type != Any and not isinstance(k, key_type):\n              raise TypeError(\'Expecting key type %s for parameter %r, \'\n                              \'but got %s instead.\' %\n                              (str(key_type), arg_name, type(k)))\n            if val_type != Any and not isinstance(v, val_type):\n              raise TypeError(\'Expecting value type %s for parameter %r, \'\n                              \'but got %s instead.\' % (\n                                  str(val_type), arg_name, type(v)))\n        elif declared.__origin__ in [List, list]:  # pylint: disable=protected-access\n          val_type = declared.__args__[0]\n          if not isinstance(value, list):\n            raise TypeError(\'Expecting a list for parameter %r, \'\n                            \'but got %s instead.\' % (arg_name, type(value)))\n          if val_type == Any:\n            return\n          for item in value:\n            if not isinstance(item, val_type):\n              raise TypeError(\'Expecting item type %s for parameter %r, \'\n                              \'but got %s instead.\' % (\n                                  str(val_type), arg_name, type(item)))\n        else:\n          raise TypeError(\'Unexpected type of parameter: %r\' % arg_name)\n      elif isinstance(value, dict) and issubclass(declared, message.Message):\n        # If a dict is passed in and is compared against a pb message,\n        # do the type-check by converting it to pb message.\n        dict_with_default = _make_default(value)\n        json_format.ParseDict(dict_with_default, declared())\n      else:\n        if not isinstance(value, declared):\n          raise TypeError(\'Expected type %s for parameter %r \'\n                          \'but got %s instead.\' % (\n                              str(declared), arg_name, value))\n\n    value_with_default = _make_default(value)\n    _type_check_helper(value_with_default, self.type)\n\n\nclass ChannelParameter(_ComponentParameter):\n  """"""An channel parameter that forms part of a ComponentSpec.\n\n  This type of parameter should be specified in the INPUTS and OUTPUTS dict\n  fields of a ComponentSpec:\n\n  class MyCustomComponentSpec(ComponentSpec):\n    # ...\n    INPUTS = {\n        \'input_examples\': ChannelParameter(type=standard_artifacts.Examples),\n    }\n    OUTPUTS = {\n        \'output_examples\': ChannelParameter(type=standard_artifacts.Examples),\n    }\n    # ...\n  """"""\n\n  def __init__(\n      self,\n      type: Optional[Type[Artifact]] = None,  # pylint: disable=redefined-builtin\n      optional: Optional[bool] = False):\n    if not (inspect.isclass(type) and issubclass(type, Artifact)):  # pytype: disable=wrong-arg-types\n      raise ValueError(\n          \'Argument ""type"" of Channel constructor must be a subclass of\'\n          \'tfx.types.Artifact.\')\n    self.type = type\n    self.optional = optional\n\n  def __repr__(self):\n    return \'ChannelParameter(type: %s)\' % (self.type,)\n\n  def __eq__(self, other):\n    return (isinstance(other.__class__, self.__class__) and\n            other.type == self.type and other.optional == self.optional)\n\n  def type_check(self, arg_name: Text, value: Channel):\n    if not isinstance(value, Channel) or value.type != self.type:\n      raise TypeError(\'Argument %s should be a Channel of type %r (got %s).\' %\n                      (arg_name, self.type, value))\n'"
tfx/types/component_spec_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.types.artifact_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport json\nfrom typing import Dict, List, Text\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ComponentSpec\nfrom tfx.types.component_spec import ExecutionParameter\nfrom tfx.types.standard_artifacts import Examples\n\n\nclass _InputArtifact(Artifact):\n  TYPE_NAME = \'InputArtifact\'\n\n\nclass _OutputArtifact(Artifact):\n  TYPE_NAME = \'OutputArtifact\'\n\n\nclass _X(Artifact):\n  TYPE_NAME = \'X\'\n\n\nclass _Z(Artifact):\n  TYPE_NAME = \'Z\'\n\n\nclass _BasicComponentSpec(ComponentSpec):\n\n  PARAMETERS = {\n      \'folds\': ExecutionParameter(type=int),\n      \'proto\': ExecutionParameter(type=example_gen_pb2.Input, optional=True),\n  }\n  INPUTS = {\n      \'input\': ChannelParameter(type=_InputArtifact),\n  }\n  OUTPUTS = {\n      \'output\': ChannelParameter(type=_OutputArtifact),\n  }\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'future_input_name\': \'input\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'future_output_name\': \'output\',\n  }\n\n\nclass ComponentSpecTest(tf.test.TestCase):\n\n  def testComponentspecEmpty(self):\n\n    class EmptyComponentSpec(ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {}\n      OUTPUTS = {}\n\n    _ = EmptyComponentSpec()\n\n  def testComponentspecBasic(self):\n    proto = example_gen_pb2.Input()\n    proto.splits.extend([\n        example_gen_pb2.Input.Split(name=\'name1\', pattern=\'pattern1\'),\n        example_gen_pb2.Input.Split(name=\'name2\', pattern=\'pattern2\'),\n        example_gen_pb2.Input.Split(name=\'name3\', pattern=\'pattern3\'),\n    ])\n    input_channel = Channel(type=_InputArtifact)\n    output_channel = Channel(type=_OutputArtifact)\n    spec = _BasicComponentSpec(\n        folds=10, proto=proto, input=input_channel, output=output_channel)\n    # Verify proto property.\n    self.assertIsInstance(spec.exec_properties[\'proto\'], str)\n    decoded_proto = json.loads(spec.exec_properties[\'proto\'])\n    self.assertCountEqual([\'splits\'], decoded_proto.keys())\n    self.assertEqual(3, len(decoded_proto[\'splits\']))\n    self.assertCountEqual([\'name1\', \'name2\', \'name3\'],\n                          list(s[\'name\'] for s in decoded_proto[\'splits\']))\n    self.assertCountEqual([\'pattern1\', \'pattern2\', \'pattern3\'],\n                          list(s[\'pattern\'] for s in decoded_proto[\'splits\']))\n\n    # Verify other properties.\n    self.assertEqual(10, spec.exec_properties[\'folds\'])\n    self.assertIs(spec.inputs[\'input\'], input_channel)\n    self.assertIs(spec.outputs[\'output\'], output_channel)\n\n    # Verify compatibility aliasing behavior.\n    self.assertIs(spec.inputs[\'future_input_name\'], spec.inputs[\'input\'])\n    self.assertIs(spec.outputs[\'future_output_name\'], spec.outputs[\'output\'])\n\n    with self.assertRaisesRegexp(\n        TypeError,\n        ""Expected type <(class|type) \'int\'> for parameter u?\'folds\' but got ""\n        \'string.\'):\n      spec = _BasicComponentSpec(\n          folds=\'string\', input=input_channel, output=output_channel)\n\n    with self.assertRaisesRegexp(\n        TypeError,\n        \'.*should be a Channel of .*InputArtifact.*got (.|\\\\s)*Examples.*\'):\n      spec = _BasicComponentSpec(\n          folds=10, input=Channel(type=Examples), output=output_channel)\n\n    with self.assertRaisesRegexp(\n        TypeError,\n        \'.*should be a Channel of .*OutputArtifact.*got (.|\\\\s)*Examples.*\'):\n      spec = _BasicComponentSpec(\n          folds=10, input=input_channel, output=Channel(type=Examples))\n\n  def testInvalidComponentspecMissingProperties(self):\n\n    with self.assertRaisesRegexp(TypeError, ""Can\'t instantiate abstract class""):\n\n      class InvalidComponentSpecA(ComponentSpec):\n        # Missing PARAMETERS.\n        INPUTS = {}\n        OUTPUTS = {}\n\n      InvalidComponentSpecA()\n\n    with self.assertRaisesRegexp(TypeError, ""Can\'t instantiate abstract class""):\n\n      class InvalidComponentSpecB(ComponentSpec):\n        PARAMETERS = {}\n        # Missing INPUTS.\n        OUTPUTS = {}\n\n      InvalidComponentSpecB()\n\n    with self.assertRaisesRegexp(TypeError, ""Can\'t instantiate abstract class""):\n\n      class InvalidComponentSpecC(ComponentSpec):\n        PARAMETERS = {}\n        INPUTS = {}\n        # Missing OUTPUTS.\n\n      InvalidComponentSpecC()\n\n  def testInvalidComponentspecWrongProperties(self):\n\n    with self.assertRaisesRegexp(TypeError,\n                                 \'must override PARAMETERS with a dict\'):\n\n      class InvalidComponentSpecA(ComponentSpec):\n        PARAMETERS = object()\n        INPUTS = {}\n        OUTPUTS = {}\n\n      InvalidComponentSpecA()\n\n    with self.assertRaisesRegexp(TypeError, \'must override INPUTS with a dict\'):\n\n      class InvalidComponentSpecB(ComponentSpec):\n        PARAMETERS = {}\n        INPUTS = object()\n        OUTPUTS = {}\n\n      InvalidComponentSpecB()\n\n    with self.assertRaisesRegexp(TypeError,\n                                 \'must override OUTPUTS with a dict\'):\n\n      class InvalidComponentSpecC(ComponentSpec):\n        PARAMETERS = {}\n        INPUTS = {}\n        OUTPUTS = object()\n\n      InvalidComponentSpecC()\n\n  def testInvalidComponentspecWrongType(self):\n\n    class WrongTypeComponentSpecA(ComponentSpec):\n      PARAMETERS = {\'x\': object()}\n      INPUTS = {}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(ValueError,\n                                 \'expects .* dicts are _ComponentParameter\'):\n      _ = WrongTypeComponentSpecA()\n\n    class WrongTypeComponentSpecB(ComponentSpec):\n      PARAMETERS = {\'x\': ChannelParameter(type=_X)}\n      INPUTS = {}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(TypeError,\n                                 \'expects values of type ExecutionParameter\'):\n      _ = WrongTypeComponentSpecB()\n\n    class WrongTypeComponentSpecC(ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {\'x\': ExecutionParameter(type=int)}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(TypeError,\n                                 \'expect values of type ChannelParameter\'):\n      _ = WrongTypeComponentSpecC()\n\n    class WrongTypeComponentSpecD(ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {\'x\': ExecutionParameter(type=int)}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(TypeError,\n                                 \'expect values of type ChannelParameter\'):\n      _ = WrongTypeComponentSpecD()\n\n  def testInvalidComponentspecDuplicateProperty(self):\n\n    class DuplicatePropertyComponentSpec(ComponentSpec):\n      PARAMETERS = {\'x\': ExecutionParameter(type=int)}\n      INPUTS = {\'x\': ChannelParameter(type=_X)}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(ValueError, \'has a duplicate argument\'):\n      _ = DuplicatePropertyComponentSpec()\n\n  def testComponentspecMissingArguments(self):\n\n    class SimpleComponentSpec(ComponentSpec):\n      PARAMETERS = {\n          \'x\': ExecutionParameter(type=int),\n          \'y\': ExecutionParameter(type=int, optional=True),\n      }\n      INPUTS = {\'z\': ChannelParameter(type=_Z)}\n      OUTPUTS = {}\n\n    with self.assertRaisesRegexp(ValueError, \'Missing argument\'):\n      _ = SimpleComponentSpec(x=10)\n\n    with self.assertRaisesRegexp(ValueError, \'Missing argument\'):\n      _ = SimpleComponentSpec(z=Channel(type=_Z))\n\n    # Okay since y is optional.\n    _ = SimpleComponentSpec(x=10, z=Channel(type=_Z))\n\n  def testExecutionParameterTypeCheck(self):\n    int_parameter = ExecutionParameter(type=int)\n    int_parameter.type_check(\'int_parameter\', 8)\n    with self.assertRaisesRegexp(TypeError, ""Expected type <(class|type) \'int\'>""\n                                 "" for parameter u?\'int_parameter\'""):\n      int_parameter.type_check(\'int_parameter\', \'string\')\n\n    list_parameter = ExecutionParameter(type=List[int])\n    list_parameter.type_check(\'list_parameter\', [])\n    list_parameter.type_check(\'list_parameter\', [42])\n    with self.assertRaisesRegexp(TypeError, \'Expecting a list for parameter\'):\n      list_parameter.type_check(\'list_parameter\', 42)\n\n    with self.assertRaisesRegexp(TypeError, ""Expecting item type <(class|type) ""\n                                 ""\'int\'> for parameter u?\'list_parameter\'""):\n      list_parameter.type_check(\'list_parameter\', [42, \'wrong item\'])\n\n    dict_parameter = ExecutionParameter(type=Dict[Text, int])\n    dict_parameter.type_check(\'dict_parameter\', {})\n    dict_parameter.type_check(\'dict_parameter\', {\'key1\': 1, \'key2\': 2})\n    with self.assertRaisesRegexp(TypeError, \'Expecting a dict for parameter\'):\n      dict_parameter.type_check(\'dict_parameter\', \'simple string\')\n\n    with self.assertRaisesRegexp(TypeError, ""Expecting value type ""\n                                 ""<(class|type) \'int\'>""):\n      dict_parameter.type_check(\'dict_parameter\', {\'key1\': \'1\'})\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/node_common.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""ComponentSpec for defining inputs/outputs/properties of TFX components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Optional, Text\n\nfrom tfx.types.channel import Channel\nfrom tfx.utils import json_utils\n\n\nclass _PropertyDictWrapper(json_utils.Jsonable):\n  """"""Helper class to wrap inputs/outputs from TFX nodes.\n\n  Currently, this class is read-only (setting properties is not implemented).\n\n  Internal class: no backwards compatibility guarantees. Will be deprecated\n  after 0.15 release.\n  """"""\n\n  def __init__(self,\n               data: Dict[Text, Channel],\n               compat_aliases: Optional[Dict[Text, Text]] = None):\n    self._data = data\n    self._compat_aliases = compat_aliases or {}\n\n  def __getitem__(self, key):\n    if key in self._compat_aliases:\n      key = self._compat_aliases[key]\n    return self._data[key]\n\n  def __getattr__(self, key):\n    if key in self._compat_aliases:\n      key = self._compat_aliases[key]\n    try:\n      return self._data[key]\n    except KeyError:\n      raise AttributeError\n\n  def __repr__(self):\n    return repr(self._data)\n\n  def get_all(self) -> Dict[Text, Channel]:\n    return self._data\n\n  def keys(self):\n    return self._data.keys()\n\n  def values(self):\n    return self._data.values()\n\n  def items(self):\n    return self._data.items()\n'"
tfx/types/standard_artifacts.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A set of standard TFX Artifact types.\n\nNote: the artifact definitions here are expected to change.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport decimal\nimport math\nfrom typing import Text\n\nimport absl\n\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.artifact import Property\nfrom tfx.types.artifact import PropertyType\nfrom tfx.types.artifact import ValueArtifact\n\n# Span for an artifact.\nSPAN_PROPERTY = Property(type=PropertyType.INT)\n# Comma separated of splits for an artifact. Empty string means artifact\n# has no split.\nSPLIT_NAMES_PROPERTY = Property(type=PropertyType.STRING)\n# Value for a string-typed artifact.\nSTRING_VALUE_PROPERTY = Property(type=PropertyType.STRING)\n\n\nclass Examples(Artifact):\n  TYPE_NAME = \'Examples\'\n  PROPERTIES = {\n      \'span\': SPAN_PROPERTY,\n      \'split_names\': SPLIT_NAMES_PROPERTY,\n  }\n\n\nclass ExampleAnomalies(Artifact):\n  TYPE_NAME = \'ExampleAnomalies\'\n  PROPERTIES = {\n      \'span\': SPAN_PROPERTY,\n  }\n\n\nclass ExampleStatistics(Artifact):\n  TYPE_NAME = \'ExampleStatistics\'\n  PROPERTIES = {\n      \'span\': SPAN_PROPERTY,\n      \'split_names\': SPLIT_NAMES_PROPERTY,\n  }\n\n\nclass ExternalArtifact(Artifact):\n  TYPE_NAME = \'ExternalArtifact\'\n\n\nclass InferenceResult(Artifact):\n  TYPE_NAME = \'InferenceResult\'\n\n\nclass InfraBlessing(Artifact):\n  TYPE_NAME = \'InfraBlessing\'\n\n\nclass Model(Artifact):\n  TYPE_NAME = \'Model\'\n\n\nclass ModelBlessing(Artifact):\n  TYPE_NAME = \'ModelBlessing\'\n\n\nclass ModelEvaluation(Artifact):\n  TYPE_NAME = \'ModelEvaluation\'\n\n\nclass PushedModel(Artifact):\n  TYPE_NAME = \'PushedModel\'\n\n\nclass Schema(Artifact):\n  TYPE_NAME = \'Schema\'\n\n\nclass Bytes(ValueArtifact):\n  """"""Artifacts representing raw bytes.""""""\n  TYPE_NAME = \'Bytes\'\n\n  def encode(self, value: bytes):\n    if not isinstance(value, bytes):\n      raise TypeError(\'Expecting bytes but got value %s of type %s\' %\n                      (str(value), type(value)))\n    return value\n\n  def decode(self, serialized_value: bytes):\n    return serialized_value\n\n\nclass String(ValueArtifact):\n  """"""String-typed artifact.""""""\n  TYPE_NAME = \'String\'\n\n  # Note, currently we enforce unicode-encoded string.\n  def encode(self, value: Text) -> bytes:\n    if not isinstance(value, Text):\n      raise TypeError(\'Expecting Text but got value %s of type %s\' %\n                      (str(value), type(value)))\n    return value.encode(\'utf-8\')\n\n  def decode(self, serialized_value: bytes) -> Text:\n    return serialized_value.decode(\'utf-8\')\n\n\nclass Integer(ValueArtifact):\n  """"""Integer-typed artifact.""""""\n  TYPE_NAME = \'Integer\'\n\n  def encode(self, value: int) -> bytes:\n    if not isinstance(value, int):\n      raise TypeError(\'Expecting int but got value %s of type %s\' %\n                      (str(value), type(value)))\n    return str(value).encode(\'utf-8\')\n\n  def decode(self, serialized_value: bytes) -> int:\n    return int(serialized_value)\n\n\nclass Float(ValueArtifact):\n  """"""Float-typed artifact.""""""\n  TYPE_NAME = \'Float\'\n\n  _POSITIVE_INFINITY = float(\'Inf\')\n  _NEGATIVE_INFINITY = float(\'-Inf\')\n\n  _ENCODED_POSITIVE_INFINITY = \'Infinity\'\n  _ENCODED_NEGATIVE_INFINITY = \'-Infinity\'\n  _ENCODED_NAN = \'NaN\'\n\n  def encode(self, value: float) -> bytes:\n    if not isinstance(value, float):\n      raise TypeError(\'Expecting float but got value %s of type %s\' %\n                      (str(value), type(value)))\n    if math.isinf(value) or math.isnan(value):\n      absl.logging.warning(\n          \'! The number ""%s"" may be unsupported by non-python components.\' %\n          value)\n    str_value = str(value)\n    # Special encoding for infinities and NaN to increase comatibility with\n    # other languages.\n    # Decoding works automatically.\n    if math.isinf(value):\n      if value >= 0:\n        str_value = Float._ENCODED_POSITIVE_INFINITY\n      else:\n        str_value = Float._ENCODED_NEGATIVE_INFINITY\n    if math.isnan(value):\n      str_value = Float._ENCODED_NAN\n\n    return str_value.encode(\'utf-8\')\n\n  def decode(self, serialized_value: bytes) -> float:\n    result = float(serialized_value)\n\n    # Check that the decoded value exactly matches the encoded string.\n    # Note that float() can handle bytes, but Decimal() cannot.\n    serialized_string = serialized_value.decode(\'utf-8\')\n    reserialized_string = str(result)\n    is_exact = (decimal.Decimal(serialized_string) ==\n                decimal.Decimal(reserialized_string))\n    if not is_exact:\n      absl.logging.warning(\n          \'The number ""%s"" has lost precision when converted to float ""%s""\' %\n          (serialized_value, reserialized_string))\n\n    return result\n\n\nclass TransformGraph(Artifact):\n  TYPE_NAME = \'TransformGraph\'\n\n\n# Still WIP and subject to change.\nclass HyperParameters(Artifact):\n  TYPE_NAME = \'HyperParameters\'\n'"
tfx/types/standard_artifacts_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for standard TFX Artifact types.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport absl\nimport mock\nimport tensorflow as tf\n\nfrom tfx.types import standard_artifacts\n\n# Define constant value for tests.\n_TEST_BYTE_RAW = b\'hello world\'\n_TEST_BYTE_DECODED = b\'hello world\'\n\n_TEST_STRING_RAW = b\'hello world\'\n_TEST_STRING_DECODED = u\'hello world\'\n\n_TEST_INT_RAW = b\'19260817\'\n_TEST_INT_DECODED = 19260817\n\n_TEST_FLOAT_RAW = b\'3.1415926535\'\n_TEST_FLOAT_DECODED = 3.1415926535\n\n_TEST_FLOAT128_RAW = b\'3.14159265358979323846264338327950288\'\n_TEST_FLOAT128 = 3.14159265358979323846264338327950288  # Too precise\n\n\nclass StandardArtifactsTest(tf.test.TestCase):\n\n  def testBytesType(self):\n    instance = standard_artifacts.Bytes()\n    self.assertEqual(_TEST_BYTE_RAW, instance.encode(_TEST_BYTE_DECODED))\n    self.assertEqual(_TEST_BYTE_DECODED, instance.decode(_TEST_BYTE_RAW))\n\n  def testStringType(self):\n    instance = standard_artifacts.String()\n    self.assertEqual(_TEST_STRING_RAW, instance.encode(_TEST_STRING_DECODED))\n    self.assertEqual(_TEST_STRING_DECODED, instance.decode(_TEST_STRING_RAW))\n\n  def testIntegerType(self):\n    instance = standard_artifacts.Integer()\n    self.assertEqual(_TEST_INT_RAW, instance.encode(_TEST_INT_DECODED))\n    self.assertEqual(_TEST_INT_DECODED, instance.decode(_TEST_INT_RAW))\n\n  def testFloatType(self):\n    instance = standard_artifacts.Float()\n    self.assertEqual(_TEST_FLOAT_RAW, instance.encode(_TEST_FLOAT_DECODED))\n    self.assertAlmostEqual(_TEST_FLOAT_DECODED,\n                           instance.decode(_TEST_FLOAT_RAW))\n\n  @mock.patch(\'absl.logging.warning\')\n  def testFloatTypePrecisionLossWarning(self, *unused_mocks):\n    instance = standard_artifacts.Float()\n    # TODO(b/156776413): with self.assertWarnsRegex(\'lost precision\'):\n    self.assertAlmostEqual(\n        instance.decode(_TEST_FLOAT128_RAW), _TEST_FLOAT128)\n    # Lost precision warning\n    absl.logging.warning.assert_called_once()\n\n  @mock.patch(\'absl.logging.warning\')\n  def testFloatInfNanEncodingWarning(self, *unused_mocks):\n    instance = standard_artifacts.Float()\n    instance.encode(float(\'inf\'))\n    # Non-portable encoding warning\n    absl.logging.warning.assert_called_once()\n\n  def testSpecialFloatValues(self):\n    coder = standard_artifacts.Float()\n    positive_infinity_float = float(\'inf\')\n    negative_infinity_float = float(\'-inf\')\n    nan_float = float(\'nan\')\n\n    encoded_positive_infinity = coder.encode(positive_infinity_float)\n    encoded_negative_infinity = coder.encode(negative_infinity_float)\n    encoded_nan = coder.encode(nan_float)\n\n    decoded_positive_infinity = coder.decode(encoded_positive_infinity)\n    decoded_negative_infinity = coder.decode(encoded_negative_infinity)\n    decoded_nan = coder.decode(encoded_nan)\n\n    self.assertEqual(encoded_positive_infinity, b\'Infinity\')\n    self.assertEqual(encoded_negative_infinity, b\'-Infinity\')\n    self.assertEqual(encoded_nan, b\'NaN\')\n\n    self.assertEqual(decoded_positive_infinity, positive_infinity_float)\n    self.assertEqual(decoded_negative_infinity, negative_infinity_float)\n\n    self.assertTrue(math.isinf(decoded_positive_infinity))\n    self.assertTrue(math.isinf(decoded_negative_infinity))\n    self.assertTrue(math.isnan(decoded_nan))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/types/standard_component_specs.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Component specifications for the standard set of TFX Components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text\n\nimport tensorflow_model_analysis as tfma\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import example_gen_pb2\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.proto import tuner_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ComponentSpec\nfrom tfx.types.component_spec import ExecutionParameter\n\n\nclass BulkInferrerSpec(ComponentSpec):\n  """"""BulkInferrer component spec.""""""\n\n  PARAMETERS = {\n      \'model_spec\':\n          ExecutionParameter(type=bulk_inferrer_pb2.ModelSpec, optional=True),\n      \'data_spec\':\n          ExecutionParameter(type=bulk_inferrer_pb2.DataSpec, optional=True),\n  }\n  INPUTS = {\n      \'examples\':\n          ChannelParameter(type=standard_artifacts.Examples),\n      \'model\':\n          ChannelParameter(type=standard_artifacts.Model, optional=True),\n      \'model_blessing\':\n          ChannelParameter(\n              type=standard_artifacts.ModelBlessing, optional=True),\n  }\n  OUTPUTS = {\n      \'inference_result\':\n          ChannelParameter(type=standard_artifacts.InferenceResult),\n  }\n\n\nclass EvaluatorSpec(ComponentSpec):\n  """"""Evaluator component spec.""""""\n\n  PARAMETERS = {\n      \'eval_config\':\n          ExecutionParameter(type=tfma.EvalConfig, optional=True),\n      # TODO(mdreves): Deprecated, use eval_config.slicing_specs.\n      \'feature_slicing_spec\':\n          ExecutionParameter(\n              type=evaluator_pb2.FeatureSlicingSpec, optional=True),\n      # This parameter is experimental: its interface and functionality may\n      # change at any time.\n      \'fairness_indicator_thresholds\':\n          ExecutionParameter(type=List[float], optional=True),\n  }\n  INPUTS = {\n      \'examples\':\n          ChannelParameter(type=standard_artifacts.Examples),\n      \'model\':\n          ChannelParameter(type=standard_artifacts.Model),\n      \'baseline_model\':\n          ChannelParameter(type=standard_artifacts.Model, optional=True),\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema, optional=True),\n  }\n  OUTPUTS = {\n      \'evaluation\': ChannelParameter(type=standard_artifacts.ModelEvaluation),\n      \'blessing\': ChannelParameter(type=standard_artifacts.ModelBlessing),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'model_exports\': \'model\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'output\': \'evaluation\',\n  }\n\n\nclass ExampleValidatorSpec(ComponentSpec):\n  """"""ExampleValidator component spec.""""""\n\n  PARAMETERS = {}\n  INPUTS = {\n      \'statistics\': ChannelParameter(type=standard_artifacts.ExampleStatistics),\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema),\n  }\n  OUTPUTS = {\n      \'anomalies\': ChannelParameter(type=standard_artifacts.ExampleAnomalies),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'stats\': \'statistics\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'output\': \'anomalies\',\n  }\n\n\nclass FileBasedExampleGenSpec(ComponentSpec):\n  """"""File-based ExampleGen component spec.""""""\n\n  PARAMETERS = {\n      \'input_config\':\n          ExecutionParameter(type=example_gen_pb2.Input),\n      \'output_config\':\n          ExecutionParameter(type=example_gen_pb2.Output),\n      \'custom_config\':\n          ExecutionParameter(type=example_gen_pb2.CustomConfig, optional=True),\n  }\n  INPUTS = {\n      \'input\': ChannelParameter(type=standard_artifacts.ExternalArtifact),\n  }\n  OUTPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'input_base\': \'input\',\n  }\n\n\nclass InfraValidatorSpec(ComponentSpec):\n  """"""InfraValidator component spec.""""""\n\n  PARAMETERS = {\n      \'serving_spec\':\n          ExecutionParameter(type=infra_validator_pb2.ServingSpec),\n      \'validation_spec\':\n          ExecutionParameter(type=infra_validator_pb2.ValidationSpec,\n                             optional=True),\n      \'request_spec\':\n          ExecutionParameter(type=infra_validator_pb2.RequestSpec,\n                             optional=True)\n  }\n\n  INPUTS = {\n      \'model\':\n          ChannelParameter(type=standard_artifacts.Model),\n      \'examples\':\n          ChannelParameter(type=standard_artifacts.Examples, optional=True),\n  }\n\n  OUTPUTS = {\n      \'blessing\': ChannelParameter(type=standard_artifacts.InfraBlessing),\n  }\n\n\nclass ModelValidatorSpec(ComponentSpec):\n  """"""ModelValidator component spec.""""""\n\n  PARAMETERS = {}\n  INPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n      \'model\': ChannelParameter(type=standard_artifacts.Model),\n  }\n  OUTPUTS = {\n      \'blessing\': ChannelParameter(type=standard_artifacts.ModelBlessing),\n  }\n\n\nclass PusherSpec(ComponentSpec):\n  """"""Pusher component spec.""""""\n\n  PARAMETERS = {\n      \'push_destination\':\n          ExecutionParameter(type=pusher_pb2.PushDestination, optional=True),\n      \'custom_config\':\n          ExecutionParameter(type=(str, Text), optional=True),\n  }\n  INPUTS = {\n      \'model\': ChannelParameter(type=standard_artifacts.Model),\n      \'model_blessing\': ChannelParameter(type=standard_artifacts.ModelBlessing),\n      \'infra_blessing\': ChannelParameter(type=standard_artifacts.InfraBlessing,\n                                         optional=True),\n  }\n  OUTPUTS = {\n      \'pushed_model\': ChannelParameter(type=standard_artifacts.PushedModel),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'model_export\': \'model\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'model_push\': \'pushed_model\',\n  }\n\n\nclass QueryBasedExampleGenSpec(ComponentSpec):\n  """"""Query-based ExampleGen component spec.""""""\n\n  PARAMETERS = {\n      \'input_config\':\n          ExecutionParameter(type=example_gen_pb2.Input),\n      \'output_config\':\n          ExecutionParameter(type=example_gen_pb2.Output),\n      \'custom_config\':\n          ExecutionParameter(type=example_gen_pb2.CustomConfig, optional=True),\n  }\n  INPUTS = {}\n  OUTPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n  }\n\n\nclass SchemaGenSpec(ComponentSpec):\n  """"""SchemaGen component spec.""""""\n\n  PARAMETERS = {\n      \'infer_feature_shape\': ExecutionParameter(type=bool, optional=True)\n  }\n  INPUTS = {\n      \'statistics\': ChannelParameter(type=standard_artifacts.ExampleStatistics),\n  }\n  OUTPUTS = {\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'stats\': \'statistics\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'output\': \'schema\',\n  }\n\n\nclass StatisticsGenSpec(ComponentSpec):\n  """"""StatisticsGen component spec.""""""\n\n  PARAMETERS = {\n      \'stats_options_json\':\n          ExecutionParameter(type=(str, Text), optional=True),\n  }\n  INPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema, optional=True),\n  }\n  OUTPUTS = {\n      \'statistics\': ChannelParameter(type=standard_artifacts.ExampleStatistics),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'input_data\': \'examples\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'output\': \'statistics\',\n  }\n\n\nclass TrainerSpec(ComponentSpec):\n  """"""Trainer component spec.""""""\n\n  PARAMETERS = {\n      \'train_args\': ExecutionParameter(type=trainer_pb2.TrainArgs),\n      \'eval_args\': ExecutionParameter(type=trainer_pb2.EvalArgs),\n      \'module_file\': ExecutionParameter(type=(str, Text), optional=True),\n      \'run_fn\': ExecutionParameter(type=(str, Text), optional=True),\n      \'trainer_fn\': ExecutionParameter(type=(str, Text), optional=True),\n      \'custom_config\': ExecutionParameter(type=(str, Text), optional=True),\n  }\n  INPUTS = {\n      \'examples\':\n          ChannelParameter(type=standard_artifacts.Examples),\n      \'transform_graph\':\n          ChannelParameter(\n              type=standard_artifacts.TransformGraph, optional=True),\n      \'schema\':\n          ChannelParameter(type=standard_artifacts.Schema),\n      \'base_model\':\n          ChannelParameter(type=standard_artifacts.Model, optional=True),\n      \'hyperparameters\':\n          ChannelParameter(\n              type=standard_artifacts.HyperParameters, optional=True),\n  }\n  OUTPUTS = {\n      \'model\': ChannelParameter(type=standard_artifacts.Model),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'transform_output\': \'transform_graph\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'output\': \'model\',\n  }\n\n\nclass TunerSpec(ComponentSpec):\n  """"""ComponentSpec for TFX Tuner Component.""""""\n\n  PARAMETERS = {\n      \'module_file\': ExecutionParameter(type=(str, Text), optional=True),\n      \'tuner_fn\': ExecutionParameter(type=(str, Text), optional=True),\n      \'train_args\': ExecutionParameter(type=trainer_pb2.TrainArgs),\n      \'eval_args\': ExecutionParameter(type=trainer_pb2.EvalArgs),\n      \'tune_args\': ExecutionParameter(type=tuner_pb2.TuneArgs, optional=True),\n  }\n  INPUTS = {\n      \'examples\':\n          ChannelParameter(type=standard_artifacts.Examples),\n      \'schema\':\n          ChannelParameter(type=standard_artifacts.Schema, optional=True),\n      \'transform_graph\':\n          ChannelParameter(\n              type=standard_artifacts.TransformGraph, optional=True),\n  }\n  OUTPUTS = {\n      \'best_hyperparameters\':\n          ChannelParameter(type=standard_artifacts.HyperParameters),\n  }\n\n\nclass TransformSpec(ComponentSpec):\n  """"""Transform component spec.""""""\n\n  PARAMETERS = {\n      \'module_file\': ExecutionParameter(type=(str, Text), optional=True),\n      \'preprocessing_fn\': ExecutionParameter(type=(str, Text), optional=True),\n      \'custom_config\': ExecutionParameter(type=Dict[Text, Any], optional=True),\n  }\n  INPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema),\n  }\n  OUTPUTS = {\n      \'transform_graph\':\n          ChannelParameter(type=standard_artifacts.TransformGraph),\n      \'transformed_examples\':\n          ChannelParameter(type=standard_artifacts.Examples),\n  }\n  # TODO(b/139281215): these input / output names have recently been renamed.\n  # These compatibility aliases are temporarily provided for backwards\n  # compatibility.\n  _INPUT_COMPATIBILITY_ALIASES = {\n      \'input_data\': \'examples\',\n  }\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'transform_output\': \'transform_graph\',\n  }\n'"
tfx/utils/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/utils/abc_utils.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilies for abstract classes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Any\n\n\ndef abstract_property() -> Any:\n  """"""Returns an abstract property for use in an ABC abstract class.""""""\n  return abc.abstractmethod(lambda: None)\n'"
tfx/utils/channel.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition of TFX Channel type.\n\nDeprecated: please see the new location of this module at `tfx.types.channel`\nand `tfx.types.channel_utils`.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Iterable, List, Union, Text\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx import types\nfrom tfx.types import channel_utils\n\n\n@deprecation.deprecated(\n    None, \'tfx.utils.types.Channel has been renamed to tfx.types.Channel as of \'\n    \'TFX 0.14.0.\')\nclass Channel(types.Channel):\n  pass\n\n\n@deprecation.deprecated(None,\n                        \'tfx.utils.channel.as_channel has been renamed to \'\n                        \'tfx.types.channel_utils.as_channel as of TFX 0.14.0.\')\ndef as_channel(source: Union[Channel, Iterable[types.Artifact]]) -> Channel:\n  return channel_utils.as_channel(source)\n\n\n@deprecation.deprecated(\n    None, \'tfx.utils.channel.unwrap_channel_dict has been renamed to \'\n    \'tfx.types.channel_utils.unwrap_channel_dict as of TFX 0.14.0.\')\ndef unwrap_channel_dict(\n    channel_dict: Dict[Text, Channel]) -> Dict[Text, List[types.Artifact]]:\n  return channel_utils.unwrap_channel_dict(channel_dict)\n'"
tfx/utils/channel_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.types.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\n# Standard Imports\n\nimport mock\nimport tensorflow as tf\nfrom tensorflow.python.platform import tf_logging  # pylint:disable=g-direct-tensorflow-import\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import channel\n\n\nclass ChannelTest(tf.test.TestCase):\n\n  def testChannelDeprecated(self):\n    with mock.patch.object(tf_logging, \'warning\'):\n      warn_mock = mock.MagicMock()\n      tf_logging.warning = warn_mock\n      channel.Channel(type=standard_artifacts.Examples)\n      warn_mock.assert_called_once()\n      self.assertIn(\n          \'tfx.utils.types.Channel has been renamed to tfx.types.Channel\',\n          warn_mock.call_args[0][5])\n\n  def testAsChannelDeprecated(self):\n    with mock.patch.object(tf_logging, \'warning\'):\n      warn_mock = mock.MagicMock()\n      tf_logging.warning = warn_mock\n      channel.as_channel([standard_artifacts.Model()])\n      warn_mock.assert_called_once()\n      self.assertIn(\'tfx.utils.channel.as_channel has been renamed to\',\n                    warn_mock.call_args[0][5])\n\n  def testUnwrapChannelDictDeprecated(self):\n    with mock.patch.object(tf_logging, \'warning\'):\n      warn_mock = mock.MagicMock()\n      tf_logging.warning = warn_mock\n      channel.unwrap_channel_dict({})\n      warn_mock.assert_called_once()\n      self.assertIn(\'tfx.utils.channel.unwrap_channel_dict has been renamed to\',\n                    warn_mock.call_args[0][5])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/dependency_utils.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for Python dependency and package management.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nfrom typing import List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom tfx import dependencies\nfrom tfx import version\nfrom tfx.utils import io_utils\n\n\ndef make_beam_dependency_flags(beam_pipeline_args: List[Text]) -> List[Text]:\n  """"""Make beam arguments for TFX python dependencies, if latter was not set.\n\n  When TFX executors are used with non-local beam runners (Dataflow, Flink, etc)\n  the remote runner needs to have access to TFX executors.\n  This function acts as a helper to provide TFX source package to Beam if user\n  does not provide that through Beam pipeline args.\n\n  Args:\n    beam_pipeline_args: original Beam pipeline args.\n\n  Returns:\n    updated Beam pipeline args with TFX dependencies added.\n  """"""\n  pipeline_options = beam.options.pipeline_options.PipelineOptions(\n      flags=beam_pipeline_args)\n  all_options = pipeline_options.get_all_options()\n  for flag_name in [\'extra_packages\', \'setup_file\', \'requirements_file\']:\n    if all_options.get(flag_name):\n      absl.logging.info(\'Nonempty beam arg %s already includes dependency\',\n                        flag_name)\n      return beam_pipeline_args\n  absl.logging.info(\'Attempting to infer TFX Python dependency for beam\')\n  dependency_flags = []\n  sdist_file = build_ephemeral_package()\n  absl.logging.info(\'Added --extra_package=%s to beam args\', sdist_file)\n  dependency_flags.append(\'--extra_package=%s\' % sdist_file)\n  return beam_pipeline_args + dependency_flags\n\n\n_ephemeral_setup_file = """"""\nimport setuptools\n\nif __name__ == \'__main__\':\n  setuptools.setup(\n      name=\'tfx_ephemeral\',\n      version=\'{version}\',\n      packages=setuptools.find_packages(),\n      install_requires=[{install_requires}],\n      )\n""""""\n\n\ndef build_ephemeral_package() -> Text:\n  """"""Repackage current installation of TFX into a tfx_ephemeral sdist.\n\n  Returns:\n    Path to ephemeral sdist package.\n  Raises:\n    RuntimeError: if dist directory has zero or multiple files.\n  """"""\n  tmp_dir = os.path.join(tempfile.mkdtemp(), \'build\', \'tfx\')\n  # Find the last directory named \'tfx\' in this file\'s path and package it.\n  path_split = __file__.split(os.path.sep)\n  last_index = -1\n  for i in range(len(path_split)):\n    if path_split[i] == \'tfx\':\n      last_index = i\n  if last_index < 0:\n    raise RuntimeError(\'Cannot locate directory \\\'tfx\\\' in the path %s\' %\n                       __file__)\n  tfx_root_dir = os.path.sep.join(path_split[0:last_index + 1])\n  absl.logging.info(\'Copying all content from install dir %s to temp dir %s\',\n                    tfx_root_dir, tmp_dir)\n  shutil.copytree(tfx_root_dir, os.path.join(tmp_dir, \'tfx\'))\n  # Source directory default permission is 0555 but we need to be able to create\n  # new setup.py file.\n  os.chmod(tmp_dir, 0o720)\n  setup_file = os.path.join(tmp_dir, \'setup.py\')\n  absl.logging.info(\'Generating a temp setup file at %s\', setup_file)\n  install_requires = dependencies.make_required_install_packages()\n  io_utils.write_string_file(\n      setup_file,\n      _ephemeral_setup_file.format(\n          version=version.__version__, install_requires=install_requires))\n\n  # Create the package\n  curdir = os.getcwd()\n  os.chdir(tmp_dir)\n  temp_log = os.path.join(tmp_dir, \'setup.log\')\n  with open(temp_log, \'w\') as f:\n    absl.logging.info(\'Creating temporary sdist package, logs available at %s\',\n                      temp_log)\n    cmd = [sys.executable, setup_file, \'sdist\']\n    subprocess.call(cmd, stdout=f, stderr=f)\n  os.chdir(curdir)\n\n  # Return the package dir+filename\n  dist_dir = os.path.join(tmp_dir, \'dist\')\n  files = tf.io.gfile.listdir(dist_dir)\n  if not files:\n    raise RuntimeError(\'Found no package files in %s\' % dist_dir)\n  elif len(files) > 1:\n    raise RuntimeError(\'Found multiple package files in %s\' % dist_dir)\n\n  return os.path.join(dist_dir, files[0])\n'"
tfx/utils/dependency_utils_test.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.dependency_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\n# Standard Imports\n\nimport absl\nimport mock\nimport tensorflow as tf\nfrom tfx.utils import dependency_utils\n\n\nclass DependencyUtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(tf.test.TestCase, self).setUp()\n    self._tmp_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n  @mock.patch(\'tempfile.mkdtemp\')\n  def testEphemeralPackage(self, mock_mkdtemp):\n    mock_mkdtemp.return_value = self._tmp_dir\n    if os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\'):\n      # This test requires setuptools which is not available.\n      absl.logging.info(\'Skipping testEphemeralPackage\')\n      return\n    package = dependency_utils.build_ephemeral_package()\n    self.assertRegexpMatches(\n        os.path.basename(package), r\'tfx_ephemeral-.*\\.tar.gz\')\n\n  @mock.patch(\'tempfile.mkdtemp\')\n  @mock.patch(\'subprocess.call\')\n  def testEphemeralPackageMocked(self, mock_subprocess_call, mock_mkdtemp):\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    test_file = os.path.join(source_data_dir, \'test.csv\')\n    expected_package = \'mypackage.tar.gz\'\n\n    def side_effect(cmd, stdout, stderr):\n      self.assertEqual(3, len(cmd))\n      self.assertEqual(sys.executable, cmd[0])\n      self.assertEqual(\'sdist\', cmd[2])\n      self.assertEqual(stdout, stderr)\n      setup_file = cmd[1]\n      dist_dir = os.path.join(os.path.dirname(setup_file), \'dist\')\n      tf.io.gfile.makedirs(dist_dir)\n      dest_file = os.path.join(dist_dir, expected_package)\n      tf.io.gfile.copy(test_file, dest_file)\n\n    mock_subprocess_call.side_effect = side_effect\n    mock_mkdtemp.return_value = self._tmp_dir\n    package = dependency_utils.build_ephemeral_package()\n    self.assertEqual(expected_package, os.path.basename(package))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/dsl_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for DSL.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx import types\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\ndef external_input(uri: Any) -> types.Channel:\n  """"""Helper function to declare external input.\n\n  Args:\n    uri: external path, can be RuntimeParameter\n\n  Returns:\n    input channel.\n  """"""\n  instance = standard_artifacts.ExternalArtifact()\n  instance.uri = str(uri)\n  return channel_utils.as_channel([instance])\n\n\ncsv_input = deprecation.deprecated_alias(\n    deprecated_name=\'csv_input\',\n    name=\'external_input\',\n    func_or_class=external_input)\n\ntfrecord_input = deprecation.deprecated_alias(\n    deprecated_name=\'tfrecord_input\',\n    name=\'external_input\',\n    func_or_class=external_input)\n'"
tfx/utils/dsl_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.dsl_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import dsl_utils\n\n\nclass DslUtilsTest(tf.test.TestCase):\n\n  def testExternalInput(self):\n    [input_artifact] = dsl_utils.external_input(uri=\'path\').get()\n    self.assertEqual(standard_artifacts.ExternalArtifact.TYPE_NAME,\n                     input_artifact.type_name)\n    self.assertEqual(\'path\', input_artifact.uri)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/import_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX type definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\nimport types\nfrom typing import Any, Callable, Text, Type\n\nimport six\n\nfrom tfx.utils import io_utils\n\n\ndef import_class_by_path(class_path: Text) -> Type[Any]:\n  """"""Import a class by its <module>.<name> path.\n\n  Args:\n    class_path: <module>.<name> for a class.\n\n  Returns:\n    Class object for the given class_path.\n  """"""\n  classname = class_path.split(\'.\')[-1]\n  modulename = \'.\'.join(class_path.split(\'.\')[0:-1])\n  mod = importlib.import_module(modulename)\n  return getattr(mod, classname)\n\n\ndef import_func_from_source(source_path: Text, fn_name: Text) -> Callable:  # pylint: disable=g-bare-generic\n  """"""Imports a function from a module provided as source file.""""""\n\n  # If module path is not local, download to local file-system first,\n  # because importlib can\'t import from GCS\n  source_path = io_utils.ensure_local(source_path)\n\n  try:\n    if six.PY2:\n      import imp  # pylint: disable=g-import-not-at-top\n      try:\n        user_module = imp.load_source(\'user_module\', source_path)\n        return getattr(user_module, fn_name)\n      except IOError:\n        raise\n\n    else:\n      loader = importlib.machinery.SourceFileLoader(\n          fullname=\'user_module\',\n          path=source_path,\n      )\n      user_module = types.ModuleType(loader.name)\n      loader.exec_module(user_module)\n      return getattr(user_module, fn_name)\n\n  except IOError:\n    raise ImportError(\'{} in {} not found in import_func_from_source()\'.format(\n        fn_name, source_path))\n\n\ndef import_func_from_module(module_path: Text, fn_name: Text) -> Callable:  # pylint: disable=g-bare-generic\n  """"""Imports a function from a module provided as source file or module path.""""""\n  user_module = importlib.import_module(module_path)\n  return getattr(user_module, fn_name)\n'"
tfx/utils/import_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.import_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.utils import import_utils\nfrom tfx.utils.testdata import test_fn\n\n\nclass ImportUtilsTest(tf.test.TestCase):\n\n  def testImportClassByPath(self):\n    test_class = test_fn.TestClass\n    class_path = \'%s.%s\' % (test_class.__module__, test_class.__name__)\n    imported_class = import_utils.import_class_by_path(class_path)\n    self.assertEqual(test_class, imported_class)\n\n  def testImportFuncFromSource(self):\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    test_fn_file = os.path.join(source_data_dir, \'test_fn.ext\')\n    fn = import_utils.import_func_from_source(test_fn_file, \'test_fn\')\n    self.assertEqual(10, fn([1, 2, 3, 4]))\n\n  def testImportFuncFromSourceMissingFile(self):\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    test_fn_file = os.path.join(source_data_dir, \'non_existing.py\')\n    with self.assertRaises(ImportError):\n      import_utils.import_func_from_source(test_fn_file, \'test_fn\')\n\n  def testImportFuncFromSourceMissingFunction(self):\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    test_fn_file = os.path.join(source_data_dir, \'test_fn.ext\')\n    with self.assertRaises(AttributeError):\n      import_utils.import_func_from_source(test_fn_file, \'non_existing\')\n\n  def testImportFuncFromModule(self):\n    imported_fn = import_utils.import_func_from_module(\n        test_fn.test_fn.__module__, test_fn.test_fn.__name__)\n    self.assertEqual(10, imported_fn([1, 2, 3, 4]))\n\n  def testImportFuncFromModuleUnknownModule(self):\n    with self.assertRaises(ImportError):\n      _ = import_utils.import_func_from_module(\'non_existing_module\', \'test_fn\')\n\n  def testImportFuncFromModuleModuleMissingFunction(self):\n    with self.assertRaises(AttributeError):\n      _ = import_utils.import_func_from_module(test_fn.test_fn.__module__,\n                                               \'non_existing_fn\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/io_utils.py,20,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utility class for I/O.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import List, Text\n\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom google.protobuf import text_format\nfrom google.protobuf.message import Message\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow_metadata.proto.v0 import schema_pb2\n\n\n# Nano seconds per second.\nNANO_PER_SEC = 1000 * 1000 * 1000\n\n# If path starts with one of those, consider files are in remote filesystem.\n_REMOTE_FS_PREFIX = [\'gs://\', \'hdfs://\', \'s3://\']\n\n\ndef ensure_local(file_path: Text) -> Text:\n  """"""Ensures that the given file path is made available locally.""""""\n  if not any([file_path.startswith(prefix) for prefix in _REMOTE_FS_PREFIX]):\n    return file_path\n\n  local_path = os.path.basename(file_path)\n  copy_file(file_path, local_path, True)\n  return local_path\n\n\ndef copy_file(src: Text, dst: Text, overwrite: bool = False):\n  """"""Copies a single file from source to destination.""""""\n\n  if overwrite and tf.io.gfile.exists(dst):\n    tf.io.gfile.remove(dst)\n  dst_dir = os.path.dirname(dst)\n  tf.io.gfile.makedirs(dst_dir)\n  tf.io.gfile.copy(src, dst, overwrite=overwrite)\n\n\ndef copy_dir(src: Text, dst: Text) -> None:\n  """"""Copies the whole directory recursively from source to destination.""""""\n\n  if tf.io.gfile.exists(dst):\n    tf.io.gfile.rmtree(dst)\n  tf.io.gfile.makedirs(dst)\n\n  for dir_name, sub_dirs, leaf_files in tf.io.gfile.walk(src):\n    for leaf_file in leaf_files:\n      leaf_file_path = os.path.join(dir_name, leaf_file)\n      new_file_path = os.path.join(dir_name.replace(src, dst, 1), leaf_file)\n      tf.io.gfile.copy(leaf_file_path, new_file_path)\n\n    for sub_dir in sub_dirs:\n      tf.io.gfile.makedirs(os.path.join(dir_name.replace(src, dst, 1), sub_dir))\n\n\ndef get_only_uri_in_dir(dir_path: Text) -> Text:\n  """"""Gets the only uri from given directory.""""""\n\n  files = tf.io.gfile.listdir(dir_path)\n  if len(files) != 1:\n    raise RuntimeError(\n        \'Only one file per dir is supported: {}.\'.format(dir_path))\n  filename = os.path.dirname(os.path.join(files[0], \'\'))\n  return os.path.join(dir_path, filename)\n\n\ndef delete_dir(path: Text) -> None:\n  """"""Deletes a directory if exists.""""""\n\n  if tf.io.gfile.isdir(path):\n    tf.io.gfile.rmtree(path)\n\n\ndef write_string_file(file_name: Text, string_value: Text) -> None:\n  """"""Writes a string to file.""""""\n\n  tf.io.gfile.makedirs(os.path.dirname(file_name))\n  file_io.write_string_to_file(file_name, string_value)\n\n\ndef write_pbtxt_file(file_name: Text, proto: Message) -> None:\n  """"""Writes a text protobuf to file.""""""\n\n  write_string_file(file_name, text_format.MessageToString(proto))\n\n\ndef write_tfrecord_file(file_name: Text, proto: Message) -> None:\n  """"""Writes a serialized tfrecord to file.""""""\n\n  tf.io.gfile.makedirs(os.path.dirname(file_name))\n  with tf.io.TFRecordWriter(file_name) as writer:\n    writer.write(proto.SerializeToString())\n\n\ndef parse_pbtxt_file(file_name: Text, message: Message) -> Message:\n  """"""Parses a protobuf message from a text file and return message itself.""""""\n  contents = file_io.read_file_to_string(file_name)\n  text_format.Parse(contents, message)\n  return message\n\n\ndef parse_json_file(file_name: Text, message: Message) -> Message:\n  """"""Parses a protobuf message from a JSON file and return itself.""""""\n  contents = file_io.read_file_to_string(file_name)\n  json_format.Parse(contents, message)\n  return message\n\n\ndef load_csv_column_names(csv_file: Text) -> List[Text]:\n  """"""Parse the first line of a csv file as column names.""""""\n  with file_io.FileIO(csv_file, \'r\') as f:\n    return f.readline().strip().split(\',\')\n\n\ndef all_files_pattern(file_pattern: Text) -> Text:\n  """"""Returns file pattern suitable for Beam to locate multiple files.""""""\n  return os.path.join(file_pattern, \'*\')\n\n\ndef generate_fingerprint(split_name: Text, file_pattern: Text) -> Text:\n  """"""Generates a fingerprint for all files that match the pattern.""""""\n  files = tf.io.gfile.glob(file_pattern)\n  total_bytes = 0\n  # Checksum used here is based on timestamp (mtime).\n  # Checksums are xor\'ed and sum\'ed over the files so that they are order-\n  # independent.\n  xor_checksum = 0\n  sum_checksum = 0\n  for f in files:\n    stat = tf.io.gfile.stat(f)\n    total_bytes += stat.length\n    # Take mtime only up to second-granularity.\n    mtime = int(stat.mtime_nsec / NANO_PER_SEC)\n    xor_checksum ^= mtime\n    sum_checksum += mtime\n\n  return \'split:%s,num_files:%d,total_bytes:%d,xor_checksum:%d,sum_checksum:%d\' % (\n      split_name, len(files), total_bytes, xor_checksum, sum_checksum)\n\n\nclass SchemaReader(object):\n  """"""Schema reader.""""""\n\n  def read(self, schema_path: Text) -> schema_pb2.Schema:\n    """"""Gets a tf.metadata schema.\n\n    Args:\n      schema_path: Path to schema file.\n\n    Returns:\n      A tf.metadata schema.\n    """"""\n\n    result = schema_pb2.Schema()\n    contents = file_io.read_file_to_string(schema_path)\n    text_format.Parse(contents, result)\n    return result\n'"
tfx/utils/io_utils_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.io_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n# Standard Imports\nimport mock\n\nimport tensorflow as tf\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.utils import io_utils\n\n\nclass IoUtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    self._base_dir = os.path.join(self.get_temp_dir(), \'base_dir\')\n    file_io.create_dir(self._base_dir)\n    super(IoUtilsTest, self).setUp()\n\n  def tearDown(self):\n    file_io.delete_recursively(self._base_dir)\n    super(IoUtilsTest, self).tearDown()\n\n  def testEnsureLocal(self):\n    file_path = os.path.join(\n        os.path.dirname(__file__), \'testdata\', \'test_fn.py\')\n    self.assertEqual(file_path, io_utils.ensure_local(file_path))\n\n  @mock.patch.object(io_utils, \'copy_file\')\n  def testEnsureLocalFromGCS(self, mock_copy_file):\n    file_path = \'gs://path/to/testdata/test_fn.py\'\n    self.assertEqual(\'test_fn.py\', io_utils.ensure_local(file_path))\n    mock_copy_file.assert_called_once_with(file_path, \'test_fn.py\', True)\n\n  def testCopyFile(self):\n    file_path = os.path.join(self._base_dir, \'temp_file\')\n    io_utils.write_string_file(file_path, \'testing\')\n    copy_path = os.path.join(self._base_dir, \'copy_file\')\n    io_utils.copy_file(file_path, copy_path)\n    self.assertTrue(file_io.file_exists(copy_path))\n    f = file_io.FileIO(file_path, mode=\'r\')\n    self.assertEqual(\'testing\', f.read())\n    self.assertEqual(7, f.tell())\n\n  def testCopyDir(self):\n    old_path = os.path.join(self._base_dir, \'old\')\n    old_path_file1 = os.path.join(old_path, \'file1\')\n    old_path_file2 = os.path.join(old_path, \'dir\', \'dir2\', \'file2\')\n    new_path = os.path.join(self._base_dir, \'new\')\n    new_path_file1 = os.path.join(new_path, \'file1\')\n    new_path_file2 = os.path.join(new_path, \'dir\', \'dir2\', \'file2\')\n\n    io_utils.write_string_file(old_path_file1, \'testing\')\n    io_utils.write_string_file(old_path_file2, \'testing2\')\n    io_utils.copy_dir(old_path, new_path)\n\n    self.assertTrue(file_io.file_exists(new_path_file1))\n    f = file_io.FileIO(new_path_file1, mode=\'r\')\n    self.assertEqual(\'testing\', f.readline())\n\n    self.assertTrue(file_io.file_exists(new_path_file2))\n    f = file_io.FileIO(new_path_file2, mode=\'r\')\n    self.assertEqual(\'testing2\', f.readline())\n\n  def testGetOnlyFileInDir(self):\n    file_path = os.path.join(self._base_dir, \'file\', \'path\')\n    io_utils.write_string_file(file_path, \'testing\')\n    self.assertEqual(file_path,\n                     io_utils.get_only_uri_in_dir(os.path.dirname(file_path)))\n\n  def testGetOnlyDirInDir(self):\n    top_level_dir = os.path.join(self._base_dir, \'dir_1\')\n    dir_path = os.path.join(top_level_dir, \'dir_2\')\n    file_path = os.path.join(dir_path, \'file\')\n    io_utils.write_string_file(file_path, \'testing\')\n    self.assertEqual(\'dir_2\', os.path.basename(\n        io_utils.get_only_uri_in_dir(top_level_dir)))\n\n  def testDeleteDir(self):\n    file_path = os.path.join(self._base_dir, \'file\', \'path\')\n    io_utils.write_string_file(file_path, \'testing\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n    io_utils.delete_dir(os.path.dirname(file_path))\n    self.assertFalse(tf.io.gfile.exists(file_path))\n\n  def testAllFilesPattern(self):\n    self.assertEqual(\'model/*\', io_utils.all_files_pattern(\'model\'))\n\n  def testLoadCsvColumnNames(self):\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    test_file = os.path.join(source_data_dir, \'test.csv\')\n    column_names = io_utils.load_csv_column_names(test_file)\n    self.assertListEqual([\'a\', \'b\', \'c\', \'d\'], column_names)\n\n  def testGeneratesFingerprint(self):\n    d1_path = os.path.join(self._base_dir, \'fp\', \'data1\')\n    io_utils.write_string_file(d1_path, \'testing\')\n    os.utime(d1_path, (0, 1))\n    d2_path = os.path.join(self._base_dir, \'fp\', \'data2\')\n    io_utils.write_string_file(d2_path, \'testing2\')\n    os.utime(d2_path, (0, 3))\n    fingerprint = io_utils.generate_fingerprint(\n        \'split\', os.path.join(self._base_dir, \'fp\', \'*\'))\n    self.assertEqual(\n        \'split:split,num_files:2,total_bytes:15,xor_checksum:2,sum_checksum:4\',\n        fingerprint)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/json_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities to dump and load Jsonable object to/from JSONs.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport importlib\nimport inspect\nimport json\nfrom typing import Any, Dict, List, Text, Type, Union\n\nfrom six import with_metaclass\n\nfrom google.protobuf import json_format\nfrom google.protobuf import message\n\n# This is the special key to indicate the serialized object type.\n# Depending on which, the utility knows how to deserialize it back to its\n# original type.\n_TFX_OBJECT_TYPE_KEY = \'__tfx_object_type__\'\n_MODULE_KEY = \'__module__\'\n_CLASS_KEY = \'__class__\'\n_PROTO_VALUE_KEY = \'__proto_value__\'\n\nRUNTIME_PARAMETER_PATTERN = (r\'({\\\\*""__class__\\\\*"": \\\\*""RuntimeParameter\\\\*"", \'\n                             r\'.*?})\')\n\n\nclass _ObjectType(object):\n  """"""Internal class to hold supported types.""""""\n  # Indicates that the JSON dictionary is an instance of Jsonable type.\n  # The dictionary has the states of the object and the object type info is\n  # stored as __module__ and __class__ fields.\n  JSONABLE = \'jsonable\'\n  # Indicates that the JSON dictionary is a python class.\n  # The class info is stored as __module__ and __class__ fields in the\n  # dictionary.\n  CLASS = \'class\'\n  # Indicates that the JSON dictionary is an instance of a proto.Message\n  # subclass. The class info of the proto python class is stored as __module__\n  # and __class__ fields in the dictionary. The serialized value of the proto is\n  # stored in the dictionary with key of _PROTO_VALUE_KEY.\n  PROTO = \'proto\'\n\n\nclass Jsonable(with_metaclass(abc.ABCMeta, object)):\n  """"""Base class for serializing and deserializing objects to/from JSON.\n\n  The default implementation assumes that the subclass can be restored by\n  updating `self.__dict__` without invoking `self.__init__` function.. If the\n  subclass cannot hold the assumption, it should\n  override `to_json_dict` and `from_json_dict` to customize the implementation.\n  """"""\n\n  def to_json_dict(self) -> Dict[Text, Any]:\n    """"""Convert from an object to a JSON serializable dictionary.""""""\n    return self.__dict__\n\n  @classmethod\n  def from_json_dict(cls, dict_data: Dict[Text, Any]) -> Any:\n    """"""Convert from dictionary data to an object.""""""\n    instance = cls.__new__(cls)\n    instance.__dict__ = dict_data\n    return instance\n\n\nJsonableValue = Union[bool, bytes, float, int, Jsonable, message.Message, Text,\n                      Type]\nJsonableList = List[JsonableValue]\nJsonableDict = Dict[Union[bytes, Text], Union[JsonableValue, JsonableList]]\nJsonableType = Union[JsonableValue, JsonableList, JsonableDict]\n\n\nclass _DefaultEncoder(json.JSONEncoder):\n  """"""Default JSON Encoder which encodes Jsonable object to JSON.""""""\n\n  def encode(self, obj: Any) -> Text:\n    """"""Override encode to prevent redundant dumping.""""""\n    if obj.__class__.__name__ == \'RuntimeParameter\' and obj.ptype == Text:\n      return self.default(obj)\n\n    return super(_DefaultEncoder, self).encode(obj)\n\n  def default(self, obj: Any) -> Any:\n    # If obj is a str-typed RuntimeParameter, serialize it in place.\n    if obj.__class__.__name__ == \'RuntimeParameter\' and obj.ptype == Text:\n      dict_data = {\n          _TFX_OBJECT_TYPE_KEY: _ObjectType.JSONABLE,\n          _MODULE_KEY: obj.__class__.__module__,\n          _CLASS_KEY: obj.__class__.__name__,\n      }\n      dict_data.update(obj.to_json_dict())\n      return dumps(dict_data)\n\n    if isinstance(obj, Jsonable):\n      dict_data = {\n          _TFX_OBJECT_TYPE_KEY: _ObjectType.JSONABLE,\n          _MODULE_KEY: obj.__class__.__module__,\n          _CLASS_KEY: obj.__class__.__name__,\n      }\n      # Need to first check the existence of str-typed runtime parameter.\n      data_patch = obj.to_json_dict()\n      for k, v in data_patch.items():\n        if v.__class__.__name__ == \'RuntimeParameter\' and v.ptype == Text:\n          data_patch[k] = dumps(v)\n      dict_data.update(data_patch)\n      return dict_data\n\n    if inspect.isclass(obj):\n      return {\n          _TFX_OBJECT_TYPE_KEY: _ObjectType.CLASS,\n          _MODULE_KEY: obj.__module__,\n          _CLASS_KEY: obj.__name__,\n      }\n\n    if isinstance(obj, message.Message):\n      return {\n          _TFX_OBJECT_TYPE_KEY:\n              _ObjectType.PROTO,\n          _MODULE_KEY:\n              obj.__class__.__module__,\n          _CLASS_KEY:\n              obj.__class__.__name__,\n          _PROTO_VALUE_KEY:\n              json_format.MessageToJson(\n                  message=obj, sort_keys=True, preserving_proto_field_name=True)\n      }\n\n    return super(_DefaultEncoder, self).default(obj)\n\n\nclass _DefaultDecoder(json.JSONDecoder):\n  """"""Default JSON Decoder which decodes JSON to Jsonable object.""""""\n\n  def __init__(self, *args, **kwargs):\n    super(_DefaultDecoder, self).__init__(\n        object_hook=self._dict_to_object, *args, **kwargs)\n\n  def _dict_to_object(self, dict_data: Dict[Text, Any]) -> Any:\n    """"""Converts a dictionary to an object.""""""\n    if _TFX_OBJECT_TYPE_KEY not in dict_data:\n      return dict_data\n\n    object_type = dict_data.pop(_TFX_OBJECT_TYPE_KEY)\n\n    def _extract_class(d):\n      module_name = d.pop(_MODULE_KEY)\n      class_name = d.pop(_CLASS_KEY)\n      return getattr(importlib.import_module(module_name), class_name)\n\n    if object_type == _ObjectType.JSONABLE:\n      jsonable_class_type = _extract_class(dict_data)\n      if not issubclass(jsonable_class_type, Jsonable):\n        raise ValueError(\'Class %s must be a subclass of Jsonable\' %\n                         jsonable_class_type)\n      return jsonable_class_type.from_json_dict(dict_data)\n\n    if object_type == _ObjectType.CLASS:\n      return _extract_class(dict_data)\n\n    if object_type == _ObjectType.PROTO:\n      proto_class_type = _extract_class(dict_data)\n      if not issubclass(proto_class_type, message.Message):\n        raise ValueError(\'Class %s must be a subclass of proto.Message\' %\n                         proto_class_type)\n      if _PROTO_VALUE_KEY not in dict_data:\n        raise ValueError(\'Missing proto value in json dict\')\n      return json_format.Parse(dict_data[_PROTO_VALUE_KEY], proto_class_type())\n\n\ndef dumps(obj: Any) -> Text:\n  """"""Dumps an object to JSON with Jsonable encoding.""""""\n  return json.dumps(obj, cls=_DefaultEncoder, sort_keys=True)\n\n\ndef loads(s: Text) -> Any:\n  """"""Loads a JSON into an object with Jsonable decoding.""""""\n  return json.loads(s, cls=_DefaultDecoder)\n'"
tfx/utils/json_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.json_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils import json_utils\n\n\nclass _DefaultJsonableObject(json_utils.Jsonable):\n\n  def __init__(self, a, b, c):\n    self.a = a\n    self.b = b\n    self.c = c\n\n\nclass JsonUtilsTest(tf.test.TestCase):\n\n  def testDumpsJsonableObjectRoundtrip(self):\n    obj = _DefaultJsonableObject(1, {\'a\': \'b\'}, [True])\n\n    json_text = json_utils.dumps(obj)\n\n    actual_obj = json_utils.loads(json_text)\n    self.assertEqual(1, actual_obj.a)\n    self.assertDictEqual({\'a\': \'b\'}, actual_obj.b)\n    self.assertCountEqual([True], actual_obj.c)\n\n  def testDumpsNestedJsonableObject(self):\n    nested_obj = _DefaultJsonableObject(1, 2,\n                                        trainer_pb2.TrainArgs(num_steps=100))\n    obj = _DefaultJsonableObject(nested_obj, None, None)\n\n    json_text = json_utils.dumps(obj)\n\n    actual_obj = json_utils.loads(json_text)\n    self.assertEqual(1, actual_obj.a.a)\n    self.assertEqual(2, actual_obj.a.b)\n    self.assertProtoEquals(trainer_pb2.TrainArgs(num_steps=100), actual_obj.a.c)\n    self.assertIsNone(actual_obj.b)\n    self.assertIsNone(actual_obj.c)\n\n  def testDumpsNestedClass(self):\n    obj = _DefaultJsonableObject(_DefaultJsonableObject, None, None)\n\n    json_text = json_utils.dumps(obj)\n\n    actual_obj = json_utils.loads(json_text)\n    self.assertEqual(_DefaultJsonableObject, actual_obj.a)\n    self.assertIsNone(actual_obj.b)\n    self.assertIsNone(actual_obj.c)\n\n  def testDumpsClass(self):\n    json_text = json_utils.dumps(_DefaultJsonableObject)\n\n    actual_obj = json_utils.loads(json_text)\n    self.assertEqual(_DefaultJsonableObject, actual_obj)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/kube_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for the kubernetes related functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\nimport os\nfrom typing import Text\n\nfrom kubernetes import client as k8s_client\nfrom kubernetes import config as k8s_config\n\n# Name of the main container that Argo workflow launches. As KFP internally uses\n# Argo, container name for the KFP Pod is also the same.\n# https://github.com/argoproj/argo/blob/master/workflow/common/common.go#L14\nARGO_MAIN_CONTAINER_NAME = \'main\'\n\n# Set of environment variables that are set in the KubeFlow Pipelines pods.\nKFP_POD_NAME = \'KFP_POD_NAME\'\nKFP_NAMESPACE = \'KFP_NAMESPACE\'\n\n\nclass PodPhase(enum.Enum):\n  """"""Phase of the Kubernetes Pod.\n\n  Pod phases are defined in\n  https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase.\n  """"""\n\n  PENDING = \'Pending\'\n  RUNNING = \'Running\'\n  SUCCEEDED = \'Succeeded\'\n  FAILED = \'Failed\'\n  UNKNOWN = \'Unknown\'\n\n  @property\n  def is_done(self):\n    return self == self.SUCCEEDED or self == self.FAILED\n\n\nclass RestartPolicy(enum.Enum):\n  """"""Restart policy of the Kubernetes Pod container.\n\n  Restart policies are defined in\n  https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy\n  """"""\n\n  ALWAYS = \'Always\'\n  ON_FAILURE = \'OnFailure\'\n  NEVER = \'Never\'\n\n\nclass PersistentVolumeAccessMode(enum.Enum):\n  """"""Access mode of the Kubernetes Persistent Volume.\n\n  Access modes are defined in\n  https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes\n  """"""\n\n  READ_WRITE_ONCE = \'ReadWriteOnce\'\n  READ_ONLY_MANY = \'ReadOnlyMany\'\n  READ_WRITE_MANY = \'ReadWriteMany\'\n\n\nclass _KubernetesClientFactory(object):\n  """"""Factory class for creating kubernetes API client.""""""\n\n  def __init__(self):\n    self._config_loaded = False\n    self._inside_cluster = False\n\n  @property\n  def inside_cluster(self):\n    """"""Whether current environment is inside the kubernetes cluster.""""""\n    if not self._config_loaded:\n      self._LoadConfig()\n    return self._inside_cluster\n\n  def _LoadConfig(self) -> None:  # pylint: disable=invalid-name\n    """"""Load the kubernetes client config.\n\n    Depending on the environment (whether it is inside the running kubernetes\n    cluster or remote host), different location will be searched for the config\n    file. The loaded config will be used as a default value for the clients this\n    factory is creating.\n\n    If config is already loaded, it is a no-op.\n\n    Raises:\n      kubernetes.config.ConfigException: If fails to locate configuration in\n          current environment.\n    """"""\n    try:\n      # If this code is running inside Kubernetes Pod, service account admission\n      # controller [1] sets volume mounts in which the service account tokens\n      # and certificates exists, and it can be loaded using\n      # `load_incluster_config()`.\n      #\n      # [1]\n      # https://kubernetes.io/docs/reference/access-authn-authz/service-accounts-admin/#service-account-admission-controller\n      self._inside_cluster = True\n      k8s_config.load_incluster_config()\n    except k8s_config.ConfigException:\n      # If loading incluster config fails, it means we\'re not running the code\n      # inside Kubernetes cluster. We try to load ~/.kube/config file, or the\n      # filename from the KUBECONFIG environment variable.\n      # It will raise kubernetes.config.ConfigException if no kube config file\n      # is found.\n      self._inside_cluster = False\n      k8s_config.load_kube_config()\n\n    self._config_loaded = True\n\n  def MakeCoreV1Api(self) -> k8s_client.CoreV1Api:  # pylint: disable=invalid-name\n    """"""Make a kubernetes CoreV1Api client.""""""\n    if not self._config_loaded:\n      self._LoadConfig()\n    return k8s_client.CoreV1Api()\n\n_factory = _KubernetesClientFactory()\n\n\ndef make_core_v1_api() -> k8s_client.CoreV1Api:\n  """"""Make a kubernetes CoreV1Api client.""""""\n  return _factory.MakeCoreV1Api()\n\n\ndef is_inside_cluster() -> bool:\n  """"""Whether current running environment is inside the kubernetes cluster.""""""\n  return _factory.inside_cluster\n\n\ndef is_inside_kfp() -> bool:\n  """"""Whether current running environment is inside the KFP runtime.""""""\n  return (\n      is_inside_cluster()\n      and KFP_POD_NAME in os.environ\n      and KFP_NAMESPACE in os.environ\n  )\n\n\ndef get_kfp_namespace() -> Text:\n  """"""Get kubernetes namespace for the KFP.\n\n  Raises:\n    RuntimeError: If KFP pod cannot be determined from the environment, i.e.\n        this program is not running inside the KFP.\n  Returns:\n    The namespace of the KFP app, to which the pod this program is running on\n    belongs.\n  """"""\n  try:\n    return os.environ[KFP_NAMESPACE]\n  except KeyError:\n    raise RuntimeError(\'Cannot determine KFP namespace from the environment.\')\n\n\ndef get_current_kfp_pod(client: k8s_client.CoreV1Api) -> k8s_client.V1Pod:\n  """"""Get manifest of the KFP pod in which this program is running.\n\n  Args:\n    client: A kubernetes CoreV1Api client.\n  Raises:\n    RuntimeError: If KFP pod cannot be determined from the environment, i.e.\n        this program is not running inside the KFP.\n  Returns:\n    The manifest of the pod this program is running on.\n  """"""\n  try:\n    namespace = os.environ[KFP_NAMESPACE]\n    pod_name = os.environ[KFP_POD_NAME]\n    return client.read_namespaced_pod(name=pod_name, namespace=namespace)\n  except KeyError:\n    raise RuntimeError(\'Cannot determine KFP pod from the environment.\')\n'"
tfx/utils/logging_utils.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utils for TFX-specific logger.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport logging\nimport os\nfrom typing import Any, Dict, Optional, Text\n\nimport tensorflow as tf\n\n\nclass LoggerConfig(object):\n  """"""Logger configuration class.\n\n  Logger configuration consists of:\n    - pipeline_name: name of active pipeline\n    - worker_name: name of component/object doing the logging\n    - log_root: path for log directory\n    - log_level: logger\'s level, default to INFO.\n  """"""\n\n  def __init__(self,\n               log_root: Optional[Text] = \'/var/tmp/tfx/logs\',\n               log_level: Optional[int] = logging.INFO,\n               pipeline_name: Optional[Text] = \'\',\n               worker_name: Optional[Text] = \'\'):\n    self.log_root = log_root\n    self.log_level = log_level\n    self.pipeline_name = pipeline_name\n    self.worker_name = worker_name\n\n  def update(self, config: Optional[Dict[Text, Any]] = None):\n    """"""Updates the log config parameters via elements in a dict.\n\n    Args:\n      config: Dict of parameter tuples to assign to the logging config.\n    Raises:\n      ValueError if key is not a supported logging parameter.\n    """"""\n    if config:\n      for k, v in config.items():\n        if k in (\'log_root\', \'log_level\', \'pipeline_name\', \'worker_name\'):\n          setattr(self, k, v)\n        else:\n          raise ValueError(\'%s not expected in logger config.\' % k)\n\n  def copy(self):\n    """"""Returns a shallow copy of this config.""""""\n    return copy.copy(self)\n\n\ndef get_logger(config):\n  """"""Create and configure a TFX-specific logger.\n\n  Args:\n    config: LoggingConfig class used to configure logger\n  Returns:\n    A logger that outputs to log_dir/log_file_name.\n  Raises:\n    RuntimeError: if log dir exists as a file.\n\n  """"""\n  log_path = os.path.join(config.log_root, \'tfx.log\')\n  logger = logging.getLogger(log_path)\n  logger.setLevel(config.log_level)\n\n  if not tf.io.gfile.exists(config.log_root):\n    tf.io.gfile.makedirs(config.log_root)\n  if not tf.io.gfile.isdir(config.log_root):\n    raise RuntimeError(\'Log dir exists as a file: {}\'.format(config.log_root))\n\n  # Create logfile handler.\n  fh = logging.FileHandler(log_path)\n  # Define logmsg format.\n  formatter = logging.Formatter(\n      \'%(asctime)s - {}:{} (%(filename)s:%(lineno)s) - %(levelname)s: %(message)s\'\n      .format(config.pipeline_name, config.worker_name))\n  fh.setFormatter(formatter)\n  # Add handler to logger.\n  logger.addHandler(fh)\n\n  return logger\n'"
tfx/utils/logging_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.logging_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport logging\nimport os\n# Standard Imports\nimport tensorflow as tf\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.utils import logging_utils\n\n\nclass LoggingUtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(LoggingUtilsTest, self).setUp()\n    self._log_root = os.path.join(self.get_temp_dir(), \'log_dir\')\n    self._logger_config = logging_utils.LoggerConfig(log_root=self._log_root)\n\n  def testLogging(self):\n    """"""Ensure a logged string actually appears in the log file.""""""\n    logger = logging_utils.get_logger(self._logger_config)\n    logger.info(\'Test\')\n    log_file_path = os.path.join(self._log_root)\n    f = file_io.FileIO(os.path.join(log_file_path, \'tfx.log\'), mode=\'r\')\n    self.assertRegexpMatches(\n        f.read(),\n        r\'^\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d,\\d\\d\\d - : \\(logging_utils_test.py:\\d\\d\\) - INFO: Test$\'\n    )\n\n  def testDefaultSettings(self):\n    """"""Ensure log defaults are set correctly.""""""\n    config = logging_utils.LoggerConfig()\n    self.assertEqual(config.log_root, \'/var/tmp/tfx/logs\')\n    self.assertEqual(config.log_level, logging.INFO)\n    self.assertEqual(config.pipeline_name, \'\')\n    self.assertEqual(config.worker_name, \'\')\n\n  def testOverrideSettings(self):\n    """"""Ensure log overrides are set correctly.""""""\n    config = logging_utils.LoggerConfig(log_root=\'path\', log_level=logging.WARN,\n                                        pipeline_name=\'pipe\', worker_name=\'wrk\')\n    self.assertEqual(config.log_root, \'path\')\n    self.assertEqual(config.log_level, logging.WARN)\n    self.assertEqual(config.pipeline_name, \'pipe\')\n    self.assertEqual(config.worker_name, \'wrk\')\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/path_utils.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for retrieving paths for various types of artifacts.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.utils import io_utils\n\nEVAL_MODEL_DIR = \'eval_model_dir\'\nSERVING_MODEL_DIR = \'serving_model_dir\'\n\n# TODO(b/127149760): simplify this PPP-esque structure.\n#\n# Directory structure of exported model for estimator based trainer:\n#   |-- <ModelExportPath>\n#       |-- EVAL_MODEL_DIR  <- eval_model_dir\n#           |-- <timestamped model>  <- eval_model_path\n#               |-- saved_model.pb\n#               |-- ...\n#       |-- SERVING_MODEL_DIR  <- serving_model_dir\n#           |-- export\n#               |-- <exporter name>\n#                   |-- <timestamped model>  <- serving_model_path\n#                       |-- saved_model.pb\n#                       |-- ...\n#           |-- ...\n#\n# For generic trainer with Keras, there won\'t be eval model:\n#   |-- <ModelExportPath>\n#       |-- SERVING_MODEL_DIR  <- serving_model_dir\n#           |-- saved_model.pb\n#           |-- ...\n\n\ndef eval_model_dir(output_uri: Text) -> Text:\n  """"""Returns directory for exported model for evaluation purpose.""""""\n  return os.path.join(output_uri, EVAL_MODEL_DIR)\n\n\ndef eval_model_path(output_uri: Text) -> Text:\n  """"""Returns path to timestamped exported model for evaluation purpose.""""""\n  model_dir = eval_model_dir(output_uri)\n  if tf.io.gfile.exists(model_dir):\n    return io_utils.get_only_uri_in_dir(model_dir)\n  else:\n    # If eval model doesn\'t exist, use serving model for eval.\n    return serving_model_dir(output_uri)\n\n\ndef serving_model_dir(output_uri: Text) -> Text:\n  """"""Returns directory for exported model for serving purpose.""""""\n  return os.path.join(output_uri, SERVING_MODEL_DIR)\n\n\ndef serving_model_path(output_uri: Text) -> Text:\n  """"""Returns path for timestamped and named serving model exported.""""""\n  export_dir = os.path.join(serving_model_dir(output_uri), \'export\')\n  if tf.io.gfile.exists(export_dir):\n    model_dir = io_utils.get_only_uri_in_dir(export_dir)\n    return io_utils.get_only_uri_in_dir(model_dir)\n  else:\n    # If dir doesn\'t match estimator structure, use serving model root directly.\n    return serving_model_dir(output_uri)\n'"
tfx/utils/path_utils_test.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.path_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n# Standard Imports\n\nimport tensorflow as tf\nfrom tfx.utils import path_utils\n\n\nclass PathUtilsTest(tf.test.TestCase):\n\n  def testEstimatorModelPath(self):\n    # Create folders based on Estimator based Trainer output model directory.\n    output_uri = os.path.join(self.get_temp_dir(), \'model_dir\')\n    eval_model_path = os.path.join(output_uri, \'eval_model_dir\', \'123\')\n    tf.io.gfile.makedirs(eval_model_path)\n    serving_model_path = os.path.join(output_uri, \'serving_model_dir\', \'export\',\n                                      \'taxi\', \'123\')\n    tf.io.gfile.makedirs(serving_model_path)\n    # Test retrieving model folder.\n    self.assertEqual(eval_model_path, path_utils.eval_model_path(output_uri))\n    self.assertEqual(serving_model_path,\n                     path_utils.serving_model_path(output_uri))\n\n  def testKerasModelPath(self):\n    # Create folders based on Keras based Trainer output model directory.\n    output_uri = os.path.join(self.get_temp_dir(), \'model_dir\')\n    serving_model_path = os.path.join(output_uri, \'serving_model_dir\')\n    tf.io.gfile.makedirs(serving_model_path)\n    # Test retrieving model folder.\n    self.assertEqual(serving_model_path, path_utils.eval_model_path(output_uri))\n    self.assertEqual(serving_model_path,\n                     path_utils.serving_model_path(output_uri))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/telemetry_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for gathering telemetry for TFX components and pipelines.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport re\nimport sys\nfrom typing import Dict, List, Text\n\nfrom tfx import version\n\n# Common label names used.\nLABEL_TFX_RUNNER = \'tfx_runner\'\nLABEL_TFX_EXECUTOR = \'tfx_executor\'\n_LABEL_TFX_VERSION = \'tfx_version\'\n_LABEL_TFX_PY_VERSION = \'tfx_py_version\'\n\n# The GKE pod label indicating the SDK environment.\nLABEL_KFP_SDK_ENV = \'pipelines.kubeflow.org/pipeline-sdk-type\'\n\n# A list of global labels registered so far.\n_labels = {}\n\n\n@contextlib.contextmanager\ndef scoped_labels(labels: Dict[Text, Text]):\n  for key, value in labels.items():\n    _labels[key] = _normalize_label(value)\n  try:\n    yield\n  finally:\n    for key in labels:\n      _labels.pop(key)\n\n\ndef _normalize_label(value: Text) -> Text:\n  """"""Lowercase and replace illegal characters in labels.""""""\n  # See https://cloud.google.com/compute/docs/labeling-resources.\n  return re.sub(r\'[^a-z0-9\\_\\-]\', \'-\', value.lower())[-63:]\n\n\ndef get_labels_dict() -> Dict[Text, Text]:\n  """"""Get all registered and system generated labels as a dict.\n\n  Returns:\n    All registered and system generated labels as a dict.\n  """"""\n  result = dict(\n      {\n          _LABEL_TFX_VERSION:\n              version.__version__,\n          _LABEL_TFX_PY_VERSION:\n              \'%d.%d\' % (sys.version_info.major, sys.version_info.minor),\n      }, **_labels)\n  for k, v in result.items():\n    result[k] = _normalize_label(v)\n  return result\n\n\ndef make_beam_labels_args() -> List[Text]:\n  """"""Make Beam arguments for common labels used in TFX pipelines.\n\n  Returns:\n    New Beam pipeline args with labels.\n  """"""\n  labels = get_labels_dict()\n  # See following file for reference to the \'--labes \' flag.\n  # https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py\n  result = []\n  for k in sorted(labels):\n    result.extend([\'--labels\', \'%s=%s\' % (k, labels[k])])\n  return result\n'"
tfx/utils/telemetry_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.telemetry_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\n# Standard Imports\nimport tensorflow as tf\n\nfrom tfx import version\nfrom tfx.utils import telemetry_utils\n\n\nclass TelemetryUtilsTest(tf.test.TestCase):\n\n  def testMakeBeamLabelsArgs(self):\n    """"""Test for make_beam_labels_args.""""""\n    beam_pipeline_args = telemetry_utils.make_beam_labels_args()\n    self.assertListEqual([\n        \'--labels\',\n        \'tfx_py_version=%d-%d\' %\n        (sys.version_info.major, sys.version_info.minor),\n        \'--labels\',\n        \'tfx_version=%s\' % version.__version__.replace(\'.\', \'-\'),\n    ], beam_pipeline_args)\n\n  def testScopedLabels(self):\n    """"""Test for scoped_labels.""""""\n    orig_labels = telemetry_utils.get_labels_dict()\n    with telemetry_utils.scoped_labels({\'foo\': \'bar\'}):\n      self.assertDictEqual(telemetry_utils.get_labels_dict(),\n                           dict({\'foo\': \'bar\'}, **orig_labels))\n      with telemetry_utils.scoped_labels({\'inner\': \'baz\'}):\n        self.assertDictEqual(\n            telemetry_utils.get_labels_dict(),\n            dict({\n                \'foo\': \'bar\',\n                \'inner\': \'baz\'\n            }, **orig_labels))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/benchmarks/datasets/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/base/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/base/base_component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for TFX components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport inspect\nfrom typing import Any, Dict, Optional, Text\n\nfrom six import with_metaclass\n\nfrom tfx import types\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import base_node\nfrom tfx.components.base import executor_spec\nfrom tfx.types import node_common\nfrom tfx.utils import abc_utils\n\n# Constants that used for serializing and de-serializing components.\n_DRIVER_CLASS_KEY = \'driver_class\'\n_EXECUTOR_SPEC_KEY = \'executor_spec\'\n_INSTANCE_NAME_KEY = \'_instance_name\'\n_SPEC_KEY = \'spec\'\n\n\nclass BaseComponent(with_metaclass(abc.ABCMeta, base_node.BaseNode)):\n  """"""Base class for a TFX pipeline component.\n\n  An instance of a subclass of BaseComponent represents the parameters for a\n  single execution of that TFX pipeline component.\n\n  All subclasses of BaseComponent must override the SPEC_CLASS field with the\n  ComponentSpec subclass that defines the interface of this component.\n\n  Attributes:\n    SPEC_CLASS: a subclass of types.ComponentSpec used by this component\n      (required).\n    EXECUTOR_SPEC: an instance of executor_spec.ExecutorSpec which describes how\n      to execute this component (required).\n    DRIVER_CLASS: a subclass of base_driver.BaseDriver as a custom driver for\n      this component (optional, defaults to base_driver.BaseDriver).\n  """"""\n\n  # Subclasses must override this property (by specifying a types.ComponentSpec\n  # class, e.g. ""SPEC_CLASS = MyComponentSpec"").\n  SPEC_CLASS = abc_utils.abstract_property()\n  # Subclasses must also override the executor spec.\n  #\n  # Note: EXECUTOR_CLASS has been replaced with EXECUTOR_SPEC. A custom\n  # component\'s existing executor class definition ""EXECUTOR_CLASS = MyExecutor""\n  # should be replaced with ""EXECUTOR_SPEC = ExecutorClassSpec(MyExecutor).\n  EXECUTOR_SPEC = abc_utils.abstract_property()\n  # Subclasses will usually use the default driver class, but may override this\n  # property as well.\n  DRIVER_CLASS = base_driver.BaseDriver\n\n  def __init__(\n      self,\n      spec: types.ComponentSpec,\n      custom_executor_spec: Optional[executor_spec.ExecutorSpec] = None,\n      instance_name: Optional[Text] = None):\n    """"""Initialize a component.\n\n    Args:\n      spec: types.ComponentSpec object for this component instance.\n      custom_executor_spec: Optional custom executor spec overriding the default\n        executor specified in the component attribute.\n      instance_name: Optional unique identifying name for this instance of the\n        component in the pipeline. Required if two instances of the same\n        component is used in the pipeline.\n    """"""\n    executor_spec_obj = (custom_executor_spec or self.__class__.EXECUTOR_SPEC)\n    driver_class = self.__class__.DRIVER_CLASS\n    super(BaseComponent, self).__init__(\n        instance_name=instance_name,\n        executor_spec=executor_spec_obj,\n        driver_class=driver_class,\n    )\n    self.spec = spec\n    if custom_executor_spec:\n      if not isinstance(custom_executor_spec, executor_spec.ExecutorSpec):\n        raise TypeError(\n            (\'Custom executor spec override %s for %s should be an instance of \'\n             \'ExecutorSpec\') % (custom_executor_spec, self.__class__))\n    self._validate_component_class()\n    self._validate_spec(spec)\n\n  @classmethod\n  def _validate_component_class(cls):\n    """"""Validate that the SPEC_CLASSES property of this class is set properly.""""""\n    if not (inspect.isclass(cls.SPEC_CLASS) and\n            issubclass(cls.SPEC_CLASS, types.ComponentSpec)):\n      raise TypeError(\n          (\'Component class %s expects SPEC_CLASS property to be a subclass \'\n           \'of types.ComponentSpec; got %s instead.\') % (cls, cls.SPEC_CLASS))\n    if not isinstance(cls.EXECUTOR_SPEC, executor_spec.ExecutorSpec):\n      raise TypeError((\n          \'Component class %s expects EXECUTOR_SPEC property to be an instance \'\n          \'of ExecutorSpec; got %s instead.\') % (cls, type(cls.EXECUTOR_SPEC)))\n    if not (inspect.isclass(cls.DRIVER_CLASS) and\n            issubclass(cls.DRIVER_CLASS, base_driver.BaseDriver)):\n      raise TypeError(\n          (\'Component class %s expects DRIVER_CLASS property to be a subclass \'\n           \'of base_driver.BaseDriver; got %s instead.\') %\n          (cls, cls.DRIVER_CLASS))\n\n  def _validate_spec(self, spec):\n    """"""Verify given spec is valid given the component\'s SPEC_CLASS.""""""\n    if not isinstance(spec, types.ComponentSpec):\n      raise ValueError((\n          \'BaseComponent (parent class of %s) expects ""spec"" argument to be an \'\n          \'instance of types.ComponentSpec, got %s instead.\') %\n                       (self.__class__, spec))\n    if not isinstance(spec, self.__class__.SPEC_CLASS):\n      raise ValueError(\n          (\'%s expects the ""spec"" argument to be an instance of %s; \'\n           \'got %s instead.\') %\n          (self.__class__, self.__class__.SPEC_CLASS, spec))\n\n  def __repr__(self):\n    return (\'%s(spec: %s, executor_spec: %s, driver_class: %s, \'\n            \'component_id: %s, inputs: %s, outputs: %s)\') % (\n                self.__class__.__name__, self.spec, self.executor_spec,\n                self.driver_class, self.id, self.inputs, self.outputs)\n\n  @property\n  def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return self.spec.inputs\n\n  @property\n  def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return self.spec.outputs\n\n  @property\n  def exec_properties(self) -> Dict[Text, Any]:\n    return self.spec.exec_properties\n'"
tfx/components/base/base_component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.base_component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import component_spec\nfrom tfx.utils import json_utils\n\n\nclass _InputArtifact(types.Artifact):\n  TYPE_NAME = ""InputArtifact""\n\n\nclass _OutputArtifact(types.Artifact):\n  TYPE_NAME = ""OutputArtifact""\n\n\nclass _BasicComponentSpec(types.ComponentSpec):\n\n  PARAMETERS = {\n      ""folds"":\n          component_spec.ExecutionParameter(type=int),\n      ""proto"":\n          component_spec.ExecutionParameter(\n              type=example_gen_pb2.Input, optional=True),\n  }\n  INPUTS = {\n      ""input"": component_spec.ChannelParameter(type=_InputArtifact),\n  }\n  OUTPUTS = {\n      ""output"": component_spec.ChannelParameter(type=_OutputArtifact),\n  }\n\n\nclass _BasicComponent(base_component.BaseComponent):\n\n  SPEC_CLASS = _BasicComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n  def __init__(self,\n               spec: types.ComponentSpec = None,\n               folds: int = None,\n               input: types.Channel = None):  # pylint: disable=redefined-builtin\n    if not spec:\n      output = types.Channel(type=_OutputArtifact)\n      spec = _BasicComponentSpec(folds=folds, input=input, output=output)\n    super(_BasicComponent, self).__init__(spec=spec)\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testComponentBasic(self):\n    input_channel = types.Channel(type=_InputArtifact)\n    component = _BasicComponent(folds=10, input=input_channel)\n    self.assertEqual(component.id, ""_BasicComponent"")\n    self.assertIs(input_channel, component.inputs[""input""])\n    self.assertIsInstance(component.outputs[""output""], types.Channel)\n    self.assertEqual(component.outputs[""output""].type, _OutputArtifact)\n    self.assertEqual(component.outputs[""output""].type_name, ""OutputArtifact"")\n\n  def testComponentSpecType(self):\n\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'expects ""spec"" argument to be an instance of types.ComponentSpec\'):\n      _ = _BasicComponent(spec=object())  # pytype: disable=wrong-arg-types\n\n  def testComponentSpecClass(self):\n\n    class MissingSpecComponent(base_component.BaseComponent):\n\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(\n          base_executor.BaseExecutor)\n\n    with self.assertRaisesRegexp(TypeError, ""Can\'t instantiate abstract class""):\n      MissingSpecComponent(spec=object())  # pytype: disable=wrong-arg-types\n\n    with self.assertRaisesRegexp(\n        TypeError, ""expects SPEC_CLASS property to be a subclass of ""\n        ""types.ComponentSpec""):\n      MissingSpecComponent._validate_component_class()\n\n    class InvalidSpecComponent(base_component.BaseComponent):\n\n      SPEC_CLASSES = object()\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(\n          base_executor.BaseExecutor)\n\n    with self.assertRaisesRegexp(\n        TypeError, ""expects SPEC_CLASS property to be a subclass of ""\n        ""types.ComponentSpec""):\n      InvalidSpecComponent._validate_component_class()\n\n  def testComponentExecutorClass(self):\n\n    class MissingExecutorComponent(base_component.BaseComponent):\n\n      SPEC_CLASS = _BasicComponentSpec\n\n    with self.assertRaisesRegexp(TypeError, ""Can\'t instantiate abstract class""):\n      MissingExecutorComponent(spec=object())  # pytype: disable=wrong-arg-types\n\n    with self.assertRaisesRegexp(\n        TypeError, ""expects EXECUTOR_SPEC property to be an instance of ""\n        ""ExecutorSpec""):\n      MissingExecutorComponent._validate_component_class()\n\n    class InvalidExecutorComponent(base_component.BaseComponent):\n\n      SPEC_CLASS = _BasicComponentSpec\n      EXECUTOR_SPEC = object()\n\n    with self.assertRaisesRegexp(\n        TypeError, ""expects EXECUTOR_SPEC property to be an instance of ""\n        ""ExecutorSpec""):\n      InvalidExecutorComponent._validate_component_class()\n\n  def testComponentCustomExecutor(self):\n\n    class EmptyComponentSpec(types.ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {}\n      OUTPUTS = {}\n\n    class MyComponent(base_component.BaseComponent):\n\n      SPEC_CLASS = EmptyComponentSpec\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(\n          base_executor.BaseExecutor)\n\n    class MyCustomExecutor(base_executor.BaseExecutor):\n      pass\n\n    custom_executor_component = MyComponent(\n        spec=EmptyComponentSpec(),\n        custom_executor_spec=executor_spec.ExecutorClassSpec(MyCustomExecutor))\n    self.assertEqual(custom_executor_component.executor_spec.executor_class,\n                     MyCustomExecutor)\n\n    with self.assertRaisesRegexp(TypeError,\n                                 ""should be an instance of ExecutorSpec""):\n      MyComponent(spec=EmptyComponentSpec(), custom_executor_spec=object)\n\n  def testComponentDriverClass(self):\n\n    class InvalidDriverComponent(base_component.BaseComponent):\n\n      SPEC_CLASS = _BasicComponentSpec\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(\n          base_executor.BaseExecutor)\n      DRIVER_CLASS = object()\n\n    with self.assertRaisesRegexp(\n        TypeError, ""expects DRIVER_CLASS property to be a subclass of ""\n        ""base_driver.BaseDriver""):\n      InvalidDriverComponent._validate_component_class()\n\n  def testJsonify(self):\n    input_channel = types.Channel(\n        type=_InputArtifact, artifacts=[_InputArtifact()])\n    component = _BasicComponent(folds=10, input=input_channel)\n    json_dict = json_utils.dumps(component)\n    recovered_component = json_utils.loads(json_dict)\n    self.assertEqual(recovered_component.__class__, component.__class__)\n    self.assertEqual(recovered_component.component_id, ""_BasicComponent"")\n    self.assertEqual(input_channel.type,\n                     recovered_component.inputs[""input""].type)\n    self.assertEqual(len(recovered_component.inputs[""input""].get()), 1)\n    self.assertIsInstance(recovered_component.outputs[""output""], types.Channel)\n    self.assertEqual(recovered_component.outputs[""output""].type,\n                     _OutputArtifact)\n    self.assertEqual(recovered_component.outputs[""output""].type_name,\n                     ""OutputArtifact"")\n    self.assertEqual(recovered_component.driver_class, component.driver_class)\n    # Test re-dump.\n    new_json_dict = json_utils.dumps(recovered_component)\n    self.assertEqual(new_json_dict, json_dict)\n\n  def testGetId(self):\n    self.assertEqual(_BasicComponent.get_id(), ""_BasicComponent"")\n    self.assertEqual(\n        _BasicComponent.get_id(instance_name=""my_instance""),\n        ""_BasicComponent.my_instance"")\n\n  def testTaskDependency(self):\n    channel_1 = types.Channel(type=_InputArtifact)\n    component_1 = _BasicComponent(folds=10, input=channel_1)\n    channel_2 = types.Channel(type=_InputArtifact)\n    component_2 = _BasicComponent(folds=10, input=channel_2)\n    self.assertEqual(False, component_2 in component_1.downstream_nodes)\n    self.assertEqual(False, component_1 in component_2.upstream_nodes)\n    component_1.add_downstream_node(component_2)\n    self.assertEqual(True, component_2 in component_1.downstream_nodes)\n    self.assertEqual(True, component_1 in component_2.upstream_nodes)\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
tfx/components/base/base_driver.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Abstract TFX driver class.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\n\n\ndef _generate_output_uri(base_output_dir: Text, name: Text,\n                         execution_id: int) -> Text:\n  """"""Generate uri for output artifact.""""""\n  return os.path.join(base_output_dir, name, str(execution_id))\n\n\ndef _prepare_output_paths(artifact: types.Artifact):\n  """"""Create output directories for output artifact.""""""\n  if tf.io.gfile.exists(artifact.uri):\n    msg = \'Output artifact uri %s already exists\' % artifact.uri\n    absl.logging.error(msg)\n    raise RuntimeError(msg)\n\n  # TODO(zhitaoli): Consider refactoring this out into something\n  # which can handle permission bits.\n  absl.logging.debug(\'Creating output artifact uri %s as directory\',\n                     artifact.uri)\n  tf.io.gfile.makedirs(artifact.uri)\n  # TODO(b/147242148): Avoid special-casing the ""split_names"" property.\n  if artifact.type.PROPERTIES and \'split_names\' in artifact.type.PROPERTIES:\n    split_names = artifact_utils.decode_split_names(artifact.split_names)\n    for split in split_names:\n      split_dir = os.path.join(artifact.uri, split)\n      absl.logging.debug(\'Creating output split %s as directory\', split_dir)\n      tf.io.gfile.makedirs(split_dir)\n\n\nclass BaseDriver(object):\n  """"""BaseDriver is the base class of all custom drivers.\n\n  This can also be used as the default driver of a component if no custom logic\n  is needed.\n\n  Attributes:\n    _metadata_handler: An instance of Metadata.\n  """"""\n\n  def __init__(self, metadata_handler: metadata.Metadata):\n    self._metadata_handler = metadata_handler\n\n  def verify_input_artifacts(\n      self, artifacts_dict: Dict[Text, List[types.Artifact]]) -> None:\n    """"""Verify that all artifacts have existing uri.\n\n    Args:\n      artifacts_dict: key -> types.Artifact for inputs.\n\n    Raises:\n      RuntimeError: if any input as an empty or non-existing uri.\n    """"""\n    for single_artifacts_list in artifacts_dict.values():\n      for artifact in single_artifacts_list:\n        if not artifact.uri:\n          raise RuntimeError(\'Artifact %s does not have uri\' % artifact)\n        if not tf.io.gfile.exists(artifact.uri):\n          raise RuntimeError(\'Artifact uri %s is missing\' % artifact.uri)\n\n  def _log_properties(self, input_dict: Dict[Text, List[types.Artifact]],\n                      output_dict: Dict[Text, List[types.Artifact]],\n                      exec_properties: Dict[Text, Any]):\n    """"""Log inputs, outputs, and executor properties in a standard format.""""""\n    absl.logging.debug(\'Starting %s driver.\', self.__class__.__name__)\n    absl.logging.debug(\'Inputs for %s are: %s\', self.__class__.__name__,\n                       input_dict)\n    absl.logging.debug(\'Execution properties for %s are: %s\',\n                       self.__class__.__name__, exec_properties)\n    absl.logging.debug(\'Outputs for %s are: %s\', self.__class__.__name__,\n                       output_dict)\n\n  def resolve_input_artifacts(\n      self,\n      input_dict: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n  ) -> Dict[Text, List[types.Artifact]]:\n    """"""Resolve input artifacts from metadata.\n\n    Subclasses might override this function for customized artifact properties\n    resolution logic. However please note that this function is supposed to be\n    called in normal cases (except head of the pipeline) since it handles\n    artifact info passing from upstream components.\n\n    Args:\n      input_dict: key -> Channel mapping for inputs generated in logical\n        pipeline.\n      exec_properties: Dict of other execution properties, e.g., configs.\n      driver_args: An instance of data_types.DriverArgs with driver\n        configuration properties.\n      pipeline_info: An instance of data_types.PipelineInfo, holding pipeline\n        related properties including component_type and component_id.\n\n    Returns:\n      Final artifacts that will be used in execution.\n\n    Raises:\n      ValueError: if in interactive mode, the given input channels have not been\n        resolved.\n    """"""\n    result = {}\n    for name, input_channel in input_dict.items():\n      if driver_args.interactive_resolution:\n        artifacts = list(input_channel.get())\n        for artifact in artifacts:\n          # Note: when not initialized, artifact.uri is \'\' and artifact.id is 0.\n          if not artifact.uri or not artifact.id:\n            raise ValueError((\n                \'Unresolved input channel %r for input %r was passed in \'\n                \'interactive mode. When running in interactive mode, upstream \'\n                \'components must first be run with \'\n                \'`interactive_context.run(component)` before their outputs can \'\n                \'be used in downstream components.\') % (artifact, name))\n        result[name] = artifacts\n      else:\n        result[name] = self._metadata_handler.search_artifacts(\n            artifact_name=input_channel.output_key,\n            pipeline_info=pipeline_info,\n            producer_component_id=input_channel.producer_component_id)\n        # TODO(ccy): add this code path to interactive resolution.\n        for artifact in result[name]:\n          if isinstance(artifact, types.ValueArtifact):\n            # Resolve the content of file into value field for value artifacts.\n            _ = artifact.read()\n    return result\n\n  def resolve_exec_properties(\n      self,\n      exec_properties: Dict[Text, Any],\n      pipeline_info: data_types.PipelineInfo,  # pylint: disable=unused-argument\n      component_info: data_types.ComponentInfo,  # pylint: disable=unused-argument\n  ) -> Dict[Text, Any]:\n    """"""Resolve execution properties.\n\n    Subclasses might override this function for customized execution properties\n    resolution logic.\n\n    Args:\n      exec_properties: Original execution properties passed in.\n      pipeline_info: An instance of data_types.PipelineInfo, holding pipeline\n        related properties including pipeline_name, pipeline_root and run_id\n      component_info: An instance of data_types.ComponentInfo, holding component\n        related properties including component_type and component_id.\n\n    Returns:\n      Final execution properties that will be used in execution.\n    """"""\n    return exec_properties\n\n  def _prepare_output_artifacts(\n      self,\n      output_dict: Dict[Text, types.Channel],\n      execution_id: int,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> Dict[Text, List[types.Artifact]]:\n    """"""Prepare output artifacts by assigning uris to each artifact.""""""\n    result = channel_utils.unwrap_channel_dict(output_dict)\n    base_output_dir = os.path.join(pipeline_info.pipeline_root,\n                                   component_info.component_id)\n    for name, output_list in result.items():\n      for artifact in output_list:\n        artifact.uri = _generate_output_uri(base_output_dir, name, execution_id)\n        _prepare_output_paths(artifact)\n\n    return result\n\n  def pre_execution(\n      self,\n      input_dict: Dict[Text, types.Channel],\n      output_dict: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> data_types.ExecutionDecision:\n    """"""Handle pre-execution logic.\n\n    There are four steps:\n      1. Fetches input artifacts from metadata and checks whether uri exists.\n      2. Registers execution.\n      3. Decides whether a new execution is needed.\n      4a. If (3), prepare output artifacts.\n      4b. If not (3), fetch cached output artifacts.\n\n    Args:\n      input_dict: key -> Channel for inputs.\n      output_dict: key -> Channel for outputs. Uris of the outputs are not\n        assigned.\n      exec_properties: Dict of other execution properties.\n      driver_args: An instance of data_types.DriverArgs class.\n      pipeline_info: An instance of data_types.PipelineInfo, holding pipeline\n        related properties including pipeline_name, pipeline_root and run_id\n      component_info: An instance of data_types.ComponentInfo, holding component\n        related properties including component_type and component_id.\n\n    Returns:\n      data_types.ExecutionDecision object.\n\n    Raises:\n      RuntimeError: if any input as an empty uri.\n    """"""\n    # Step 1. Fetch inputs from metadata.\n    exec_properties = self.resolve_exec_properties(exec_properties,\n                                                   pipeline_info,\n                                                   component_info)\n    input_artifacts = self.resolve_input_artifacts(input_dict, exec_properties,\n                                                   driver_args, pipeline_info)\n    self.verify_input_artifacts(artifacts_dict=input_artifacts)\n    absl.logging.debug(\'Resolved input artifacts are: %s\', input_artifacts)\n    # Step 2. Register execution in metadata.\n    contexts = self._metadata_handler.register_pipeline_contexts_if_not_exists(\n        pipeline_info)\n    execution = self._metadata_handler.register_execution(\n        input_artifacts=input_artifacts,\n        exec_properties=exec_properties,\n        pipeline_info=pipeline_info,\n        component_info=component_info,\n        contexts=contexts)\n    use_cached_results = False\n    output_artifacts = None\n\n    if driver_args.enable_cache:\n      # Step 3. Decide whether a new execution is needed.\n      output_artifacts = self._metadata_handler.get_cached_outputs(\n          input_artifacts=input_artifacts,\n          exec_properties=exec_properties,\n          pipeline_info=pipeline_info,\n          component_info=component_info)\n    if output_artifacts is not None:\n      # If cache should be used, updates execution to reflect that. Note that\n      # with this update, publisher should / will be skipped.\n      self._metadata_handler.update_execution(\n          execution=execution,\n          component_info=component_info,\n          output_artifacts=output_artifacts,\n          execution_state=metadata.EXECUTION_STATE_CACHED,\n          contexts=contexts)\n      use_cached_results = True\n    else:\n      absl.logging.debug(\'Cached results not found, move on to new execution\')\n      # Step 4a. New execution is needed. Prepare output artifacts.\n      output_artifacts = self._prepare_output_artifacts(\n          output_dict=output_dict,\n          execution_id=execution.id,\n          pipeline_info=pipeline_info,\n          component_info=component_info)\n      absl.logging.debug(\n          \'Output artifacts skeleton for the upcoming execution are: %s\',\n          output_artifacts)\n      # Updates the execution to reflect refreshed output artifacts and\n      # execution properties.\n      self._metadata_handler.update_execution(\n          execution=execution,\n          component_info=component_info,\n          output_artifacts=output_artifacts,\n          exec_properties=exec_properties,\n          contexts=contexts)\n      absl.logging.debug(\n          \'Execution properties for the upcoming execution are: %s\',\n          exec_properties)\n\n    return data_types.ExecutionDecision(input_artifacts, output_artifacts,\n                                        exec_properties, execution.id,\n                                        use_cached_results)\n'"
tfx/components/base/base_driver_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.base_driver.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport mock\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.base import base_driver\nfrom tfx.orchestration import data_types\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n# Mock value for string artifact.\n_STRING_VALUE = u\'This is a string\'\n\n# Mock byte value for string artifact.\n_BYTE_VALUE = b\'This is a string\'\n\n\ndef fake_read(self):\n  """"""Mock read method for ValueArtifact.""""""\n  if not self._has_value:\n    self._has_value = True\n    self._value = self.decode(_BYTE_VALUE)\n  return self._value\n\n\nclass _InputArtifact(types.Artifact):\n  TYPE_NAME = \'InputArtifact\'\n\n\nclass _OutputArtifact(types.Artifact):\n  TYPE_NAME = \'OutputArtifact\'\n\n\nclass BaseDriverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(BaseDriverTest, self).setUp()\n    self._mock_metadata = tf.compat.v1.test.mock.Mock()\n    self._string_artifact = standard_artifacts.String()\n    self._input_dict = {\n        \'input_data\':\n            types.Channel(\n                type=_InputArtifact,\n                artifacts=[_InputArtifact()],\n                producer_component_id=\'c\',\n                output_key=\'k\'),\n        \'input_string\':\n            types.Channel(\n                type=standard_artifacts.String,\n                artifacts=[self._string_artifact],\n                producer_component_id=\'c2\',\n                output_key=\'k2\')\n    }\n    input_dir = os.path.join(\n        os.environ.get(\'TEST_TMP_DIR\', self.get_temp_dir()),\n        self._testMethodName, \'input_dir\')\n    # valid input artifacts must have a uri pointing to an existing directory.\n    for key, input_channel in self._input_dict.items():\n      for index, artifact in enumerate(input_channel.get()):\n        artifact.id = index + 1\n        uri = os.path.join(input_dir, key, str(artifact.id))\n        artifact.uri = uri\n        tf.io.gfile.makedirs(uri)\n    self._output_dict = {\n        \'output_data\':\n            types.Channel(type=_OutputArtifact, artifacts=[_OutputArtifact()])\n    }\n    self._input_artifacts = channel_utils.unwrap_channel_dict(self._input_dict)\n    self._output_artifacts = channel_utils.unwrap_channel_dict(\n        self._output_dict)\n    self._exec_properties = {\n        \'key\': \'value\',\n    }\n    self._execution_id = 100\n    self._execution = metadata_store_pb2.Execution()\n    self._execution.id = self._execution_id\n    self._context_id = 123\n    self._driver_args = data_types.DriverArgs(enable_cache=True)\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline_name\',\n        pipeline_root=os.environ.get(\'TEST_TMP_DIR\', self.get_temp_dir()),\n        run_id=\'my_run_id\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component_id\',\n        pipeline_info=self._pipeline_info)\n\n  @mock.patch(\n      \'tfx.components.base.base_driver.BaseDriver.verify_input_artifacts\'\n  )\n  @mock.patch.object(types.ValueArtifact, \'read\', fake_read)\n  def testPreExecutionNewExecution(self, mock_verify_input_artifacts_fn):\n    self._mock_metadata.search_artifacts.return_value = list(\n        self._input_dict[\'input_string\'].get())\n    self._mock_metadata.get_artifacts_by_info.side_effect = list(\n        self._input_dict[\'input_data\'].get()) + list(\n            self._input_dict[\'input_string\'].get())\n    self._mock_metadata.register_execution.side_effect = [self._execution]\n    self._mock_metadata.get_cached_outputs.side_effect = [None]\n    self._mock_metadata.register_run_context_if_not_exists.side_effect = [\n        metadata_store_pb2.Context()\n    ]\n\n    driver = base_driver.BaseDriver(metadata_handler=self._mock_metadata)\n    execution_decision = driver.pre_execution(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=self._exec_properties,\n        driver_args=self._driver_args,\n        pipeline_info=self._pipeline_info,\n        component_info=self._component_info)\n    self.assertFalse(execution_decision.use_cached_results)\n    self.assertEqual(execution_decision.execution_id, self._execution_id)\n    self.assertCountEqual(execution_decision.exec_properties,\n                          self._exec_properties)\n    self.assertEqual(\n        execution_decision.output_dict[\'output_data\'][0].uri,\n        os.path.join(self._pipeline_info.pipeline_root,\n                     self._component_info.component_id, \'output_data\',\n                     str(self._execution_id)))\n    self.assertEqual(execution_decision.input_dict[\'input_string\'][0].value,\n                     _STRING_VALUE)\n\n  @mock.patch(\n      \'tfx.components.base.base_driver.BaseDriver.verify_input_artifacts\'\n  )\n  @mock.patch.object(types.ValueArtifact, \'read\', fake_read)\n  def testPreExecutionCached(self, mock_verify_input_artifacts_fn):\n    self._mock_metadata.search_artifacts.return_value = list(\n        self._input_dict[\'input_string\'].get())\n    self._mock_metadata.get_artifacts_by_info.side_effect = list(\n        self._input_dict[\'input_data\'].get()) + list(\n            self._input_dict[\'input_string\'].get())\n    self._mock_metadata.register_run_context_if_not_exists.side_effect = [\n        metadata_store_pb2.Context()\n    ]\n    self._mock_metadata.register_execution.side_effect = [self._execution]\n    self._mock_metadata.get_cached_outputs.side_effect = [\n        self._output_artifacts\n    ]\n\n    driver = base_driver.BaseDriver(metadata_handler=self._mock_metadata)\n    execution_decision = driver.pre_execution(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=self._exec_properties,\n        driver_args=self._driver_args,\n        pipeline_info=self._pipeline_info,\n        component_info=self._component_info)\n    self.assertTrue(execution_decision.use_cached_results)\n    self.assertEqual(execution_decision.execution_id, self._execution_id)\n    self.assertCountEqual(execution_decision.exec_properties,\n                          self._exec_properties)\n    self.assertCountEqual(execution_decision.output_dict,\n                          self._output_artifacts)\n\n  def testVerifyInputArtifactsOk(self):\n    driver = base_driver.BaseDriver(metadata_handler=self._mock_metadata)\n    driver.verify_input_artifacts(self._input_artifacts)\n\n  def testVerifyInputArtifactsNotExists(self):\n    driver = base_driver.BaseDriver(metadata_handler=self._mock_metadata)\n    with self.assertRaises(RuntimeError):\n      driver.verify_input_artifacts({\'artifact\': [_InputArtifact()]})\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/base/base_executor.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Abstract TFX executor class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport json\nimport multiprocessing\nimport os\nfrom typing import Any, Dict, List, Optional, Text\n\nimport absl\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import DirectOptions\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nfrom apache_beam.runners.portability import fn_api_runner\nfrom future.utils import with_metaclass\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.types import artifact_utils\nfrom tfx.utils import telemetry_utils\nfrom tfx.utils import dependency_utils\n\n\nclass BaseExecutor(with_metaclass(abc.ABCMeta, object)):\n  """"""Abstract TFX executor class.""""""\n\n  class Context(object):\n    """"""A context class for all excecutors.""""""\n\n    def __init__(self,\n                 beam_pipeline_args: Optional[List[Text]] = None,\n                 tmp_dir: Optional[Text] = None,\n                 unique_id: Optional[Text] = None):\n      self.beam_pipeline_args = beam_pipeline_args\n      # Base temp directory for the pipeline\n      self._tmp_dir = tmp_dir\n      # A unique id to distinguish every execution run\n      self._unique_id = unique_id\n\n    def get_tmp_path(self) -> Text:\n      if not self._tmp_dir or not self._unique_id:\n        raise RuntimeError(\'Temp path not available\')\n      return os.path.join(self._tmp_dir, str(self._unique_id), \'\')\n\n  @abc.abstractmethod\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Execute underlying component implementation.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts. These are\n        often outputs of another component in the pipeline and passed to the\n        component by the orchestration system.\n      output_dict: Output dict from output key to a list of Artifacts. These are\n        often consumed by a dependent component.\n      exec_properties: A dict of execution properties. These are inputs to\n        pipeline with primitive types (int, string, float) and fully\n        materialized when a pipeline is constructed. No dependency to other\n        component or later injection from orchestration systems is necessary or\n        possible on these values.\n\n    Returns:\n      None.\n    """"""\n    pass\n\n  def __init__(self, context: Optional[Context] = None):\n    """"""Constructs a beam based executor.""""""\n    self._context = context\n    self._beam_pipeline_args = context.beam_pipeline_args if context else None\n\n    if self._beam_pipeline_args:\n      self._beam_pipeline_args = dependency_utils.make_beam_dependency_flags(\n          self._beam_pipeline_args)\n      executor_class_path = \'%s.%s\' % (self.__class__.__module__,\n                                       self.__class__.__name__)\n      # TODO(zhitaoli): Rethink how we can add labels and only normalize them\n      # if the job is submitted against GCP.\n      with telemetry_utils.scoped_labels(\n          {telemetry_utils.LABEL_TFX_EXECUTOR: executor_class_path}):\n        self._beam_pipeline_args.extend(telemetry_utils.make_beam_labels_args())\n\n  # TODO(b/126182711): Look into how to support fusion of multiple executors\n  # into same pipeline.\n  def _make_beam_pipeline(self) -> beam.Pipeline:\n    """"""Makes beam pipeline.""""""\n    # TODO(b/142684737): refactor when beam support multi-processing by args,\n    # possibly starting with apache-beam 2.22.\n    pipeline_options = PipelineOptions(self._beam_pipeline_args)\n    if pipeline_options.view_as(StandardOptions).runner:\n      return beam.Pipeline(argv=self._beam_pipeline_args)\n\n    parallelism = pipeline_options.view_as(DirectOptions).direct_num_workers\n    if parallelism == 0:\n      try:\n        parallelism = multiprocessing.cpu_count()\n      except NotImplementedError as e:\n        absl.logging.warning(\'Cannot get cpu count: %s\' % e)\n        parallelism = 1\n\n    absl.logging.info(\'Using %d process(es) for Beam pipeline execution.\' %\n                      parallelism)\n\n    pipeline_options.view_as(DirectOptions).direct_num_workers = parallelism\n    # When using default value \'in_memory\' and parallelism is great than\n    # one, use \'multi_processing\' instead.\n    if parallelism > 1 and pipeline_options.view_as(\n        DirectOptions).direct_running_mode == \'in_memory\':\n      pipeline_options.view_as(\n          DirectOptions).direct_running_mode = \'multi_processing\'\n    return beam.Pipeline(\n        options=pipeline_options, runner=fn_api_runner.FnApiRunner())\n\n  def _get_tmp_dir(self) -> Text:\n    """"""Get the temporary directory path.""""""\n    if not self._context:\n      raise RuntimeError(\'No context for the executor\')\n    tmp_path = self._context.get_tmp_path()\n    if not tf.io.gfile.exists(tmp_path):\n      absl.logging.info(\'Creating temp directory at %s\', tmp_path)\n      tf.io.gfile.makedirs(tmp_path)\n    return tmp_path\n\n  def _log_startup(self, inputs: Dict[Text, List[types.Artifact]],\n                   outputs: Dict[Text, List[types.Artifact]],\n                   exec_properties: Dict[Text, Any]) -> None:\n    """"""Log inputs, outputs, and executor properties in a standard format.""""""\n    absl.logging.debug(\'Starting %s execution.\', self.__class__.__name__)\n    absl.logging.debug(\'Inputs for %s are: %s\', self.__class__.__name__,\n                       artifact_utils.jsonify_artifact_dict(inputs))\n    absl.logging.debug(\'Outputs for %s are: %s\', self.__class__.__name__,\n                       artifact_utils.jsonify_artifact_dict(outputs))\n    absl.logging.debug(\'Execution properties for %s are: %s\',\n                       self.__class__.__name__, json.dumps(exec_properties))\n\n\nclass EmptyExecutor(BaseExecutor):\n  """"""An empty executor that does nothing.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    pass\n'"
tfx/components/base/base_executor_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.base_executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text\n\nfrom apache_beam.options.pipeline_options import DirectOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\n\n\nclass _TestExecutor(base_executor.BaseExecutor):\n  """"""Fake executor for testing purpose only.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    pass\n\n\nclass BaseExecutorTest(tf.test.TestCase):\n\n  def testBeamSettings(self):\n    executor_context = base_executor.BaseExecutor.Context(\n        beam_pipeline_args=[\'--runner=DirectRunner\'])\n    executor = _TestExecutor(executor_context)\n    options = executor._make_beam_pipeline().options.view_as(StandardOptions)\n    self.assertEqual(\'DirectRunner\', options.runner)\n\n    executor_context = base_executor.BaseExecutor.Context(\n        beam_pipeline_args=[\'--direct_num_workers=2\'])\n    executor = _TestExecutor(executor_context)\n    options = executor._make_beam_pipeline().options.view_as(DirectOptions)\n    self.assertEqual(2, options.direct_num_workers)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/base/base_node.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for TFX nodes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Any, Dict, Optional, Text, Type\n\nfrom six import with_metaclass\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec as executor_spec_module\nfrom tfx.types import node_common\nfrom tfx.utils import json_utils\n\n\ndef _abstract_property() -> Any:\n  """"""Returns an abstract property for use in an ABC abstract class.""""""\n  return abc.abstractmethod(lambda: None)\n\n\nclass BaseNode(with_metaclass(abc.ABCMeta, json_utils.Jsonable)):\n  """"""Base class for a node in TFX pipeline.""""""\n\n  @classmethod\n  def get_id(cls, instance_name: Optional[Text] = None):\n    """"""Gets the id of a node.\n\n    This can be used during pipeline authoring time. For example:\n    from tfx.components import Trainer\n\n    resolver = ResolverNode(..., model=Channel(\n        type=Model, producer_component_id=Trainer.get_id(\'my_trainer\')))\n\n    Args:\n      instance_name: (Optional) instance name of a node. If given, the instance\n        name will be taken into consideration when generating the id.\n\n    Returns:\n      an id for the node.\n    """"""\n    node_class_name = cls.__name__\n    if instance_name:\n      return \'{}.{}\'.format(node_class_name, instance_name)\n    else:\n      return node_class_name\n\n  def __init__(\n      self,\n      instance_name: Optional[Text] = None,\n      executor_spec: Optional[executor_spec_module.ExecutorSpec] = None,\n      driver_class: Optional[Type[base_driver.BaseDriver]] = None,\n  ):\n    """"""Initialize a node.\n\n    Args:\n      instance_name: Optional unique identifying name for this instance of node\n        in the pipeline. Required if two instances of the same node are used in\n        the pipeline.\n      executor_spec: Optional instance of executor_spec.ExecutorSpec which\n        describes how to execute this node (optional, defaults to an empty\n        executor indicates no-op.\n      driver_class: Optional subclass of base_driver.BaseDriver as a custom\n        driver for this node (optional, defaults to base_driver.BaseDriver).\n        Nodes usually use the default driver class, but may override it.\n    """"""\n    if executor_spec is None:\n      executor_spec = executor_spec_module.ExecutorClassSpec(\n          base_executor.EmptyExecutor)\n    if driver_class is None:\n      driver_class = base_driver.BaseDriver\n    self._instance_name = instance_name\n    self.executor_spec = executor_spec\n    self.driver_class = driver_class\n    self._upstream_nodes = set()\n    self._downstream_nodes = set()\n\n  def to_json_dict(self) -> Dict[Text, Any]:\n    """"""Convert from an object to a JSON serializable dictionary.""""""\n    return dict((k, v)\n                for k, v in self.__dict__.items()\n                if k not in [\'_upstream_nodes\', \'_downstream_nodes\'])\n\n  @property\n  def type(self) -> Text:\n    return \'.\'.join([self.__class__.__module__, self.__class__.__name__])\n\n  @property\n  @deprecation.deprecated(None,\n                          \'component_type is deprecated, use type instead\')\n  def component_type(self) -> Text:\n    return self.type\n\n  @property\n  def id(self) -> Text:\n    """"""Node id, unique across all TFX nodes in a pipeline.\n\n    If instance name is available, node_id will be:\n      <node_class_name>.<instance_name>\n    otherwise, node_id will be:\n      <node_class_name>\n\n    Returns:\n      node id.\n    """"""\n    node_class_name = self.__class__.__name__\n    if self._instance_name:\n      return \'{}.{}\'.format(node_class_name, self._instance_name)\n    else:\n      return node_class_name\n\n  @property\n  @deprecation.deprecated(None, \'component_id is deprecated, use id instead\')\n  def component_id(self) -> Text:\n    return self.id\n\n  @property\n  @abc.abstractmethod\n  def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    pass\n\n  @property\n  @abc.abstractmethod\n  def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    pass\n\n  @property\n  @abc.abstractmethod\n  def exec_properties(self) -> Dict[Text, Any]:\n    pass\n\n  @property\n  def upstream_nodes(self):\n    return self._upstream_nodes\n\n  def add_upstream_node(self, upstream_node):\n    """"""Experimental: Add another component that must run before this one.\n\n    This method enables task-based dependencies by enforcing execution order for\n    synchronous pipelines on supported platforms. Currently, the supported\n    platforms are Airflow, Beam, and Kubeflow Pipelines.\n\n    Note that this API call should be considered experimental, and may not work\n    with asynchronous pipelines, sub-pipelines and pipelines with conditional\n    nodes. We also recommend relying on data for capturing dependencies where\n    possible to ensure data lineage is fully captured within MLMD.\n\n    It is symmetric with `add_downstream_node`.\n\n    Args:\n      upstream_node: a component that must run before this node.\n    """"""\n    self._upstream_nodes.add(upstream_node)\n    if self not in upstream_node.downstream_nodes:\n      upstream_node.add_downstream_node(self)\n\n  @property\n  def downstream_nodes(self):\n    return self._downstream_nodes\n\n  def add_downstream_node(self, downstream_node):\n    """"""Experimental: Add another component that must run after this one.\n\n    This method enables task-based dependencies by enforcing execution order for\n    synchronous pipelines on supported platforms. Currently, the supported\n    platforms are Airflow, Beam, and Kubeflow Pipelines.\n\n    Note that this API call should be considered experimental, and may not work\n    with asynchronous pipelines, sub-pipelines and pipelines with conditional\n    nodes. We also recommend relying on data for capturing dependencies where\n    possible to ensure data lineage is fully captured within MLMD.\n\n    It is symmetric with `add_upstream_node`.\n\n    Args:\n      downstream_node: a component that must run after this node.\n    """"""\n    self._downstream_nodes.add(downstream_node)\n    if self not in downstream_node.upstream_nodes:\n      downstream_node.add_upstream_node(self)\n'"
tfx/components/base/executor_spec.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Executor specifications for defining what to to execute.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import List, Text, Type\n\nfrom six import with_metaclass\n\nfrom tfx.components.base import base_executor\nfrom tfx.utils import import_utils\nfrom tfx.utils import json_utils\n\n\nclass ExecutorSpec(with_metaclass(abc.ABCMeta, json_utils.Jsonable)):\n  """"""A specification for a component executor.\n\n  An instance of ExecutorSpec describes the implementation of a component.\n  """"""\n\n\nclass ExecutorClassSpec(ExecutorSpec):\n  """"""A specification of executor class.\n\n  Attributes:\n    executor_class: a subclass of base_executor.BaseExecutor used to execute\n      this component (required).\n  """"""\n\n  def __init__(self, executor_class: Type[base_executor.BaseExecutor]):\n    if not executor_class:\n      raise ValueError(\'executor_class is required\')\n    self.executor_class = executor_class\n    super(ExecutorClassSpec, self).__init__()\n\n  def __reduce__(self):\n    # When executing on the Beam DAG runner, the ExecutorClassSpec instance\n    # is pickled using the ""dill"" library. To make sure that the executor code\n    # itself is not pickled, we save the class path which will be reimported\n    # by the worker in this custom __reduce__ function.\n    #\n    # See https://docs.python.org/3/library/pickle.html#object.__reduce__ for\n    # more details.\n    executor_class_path = \'%s.%s\' % (self.executor_class.__module__,\n                                     self.executor_class.__name__)\n    return (ExecutorClassSpec._reconstruct_from_executor_class_path,\n            (executor_class_path,))\n\n  @staticmethod\n  def _reconstruct_from_executor_class_path(executor_class_path):\n    executor_class = import_utils.import_class_by_path(executor_class_path)\n    return ExecutorClassSpec(executor_class)\n\n\nclass ExecutorContainerSpec(ExecutorSpec):\n  """"""A specification of a container.\n\n  The spec includes image, command line entrypoint and arguments for a\n  container. For example:\n\n  spec = ExecutorContainerSpec(\n    image=\'docker/whalesay\',\n    command=[\'cowsay\'],\n    args=[\'hello wolrd\'])\n\n  Attributes:\n    image: Container image that has executor application. Assumption is that\n      this container image is separately release-managed, and tagged/versioned\n      accordingly.\n    command: Container entrypoint array. Not executed within a shell. The docker\n      image\'s ENTRYPOINT is used if this is not provided. The Jinja templating\n      mechanism is used for constructing a user-specified command-line\n      invocation based on input and output metadata at runtime.\n    args: Arguments to the container entrypoint. The docker image\'s CMD is used\n      if this is not provided. The Jinja templating mechanism is used for\n      constructing a user-specified command-line invocation based on input and\n      output metadata at runtime.\n  """"""\n\n  def __init__(self,\n               image: Text,\n               command: List[Text] = None,\n               args: List[Text] = None):\n    if not image:\n      raise ValueError(\'image cannot be None or empty.\')\n    self.image = image\n    self.command = command\n    self.args = args\n    super(ExecutorContainerSpec, self).__init__()\n'"
tfx/components/bulk_inferrer/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/bulk_inferrer/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX BulkInferrer component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.bulk_inferrer import executor\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import BulkInferrerSpec\n\n\nclass BulkInferrer(base_component.BaseComponent):\n  """"""A TFX component to do batch inference on a model with unlabelled examples.\n\n  BulkInferrer consumes examples data and a model, and produces the inference\n  results to an external location as PredictionLog proto.\n\n  BulkInferrer will infer on validated model.\n\n  ## Example\n  ```\n    # Uses BulkInferrer to inference on examples.\n    bulk_inferrer = BulkInferrer(\n        examples=example_gen.outputs[\'examples\'],\n        model=trainer.outputs[\'model\'])\n  ```\n  """"""\n\n  SPEC_CLASS = BulkInferrerSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               examples: types.Channel = None,\n               model: Optional[types.Channel] = None,\n               model_blessing: Optional[types.Channel] = None,\n               data_spec: Optional[Union[bulk_inferrer_pb2.DataSpec,\n                                         Dict[Text, Any]]] = None,\n               model_spec: Optional[Union[bulk_inferrer_pb2.ModelSpec,\n                                          Dict[Text, Any]]] = None,\n               inference_result: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct an BulkInferrer component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, usually\n        produced by an ExampleGen component. _required_\n      model: A Channel of type `standard_artifacts.Model`, usually produced by\n        a Trainer component.\n      model_blessing: A Channel of type `standard_artifacts.ModelBlessing`,\n        usually produced by a ModelValidator component.\n      data_spec: bulk_inferrer_pb2.DataSpec instance that describes data\n        selection. If any field is provided as a RuntimeParameter, data_spec\n        should be constructed as a dict with the same field names as DataSpec\n        proto message.\n      model_spec: bulk_inferrer_pb2.ModelSpec instance that describes model\n        specification. If any field is provided as a RuntimeParameter,\n        model_spec should be constructed as a dict with the same field names as\n        ModelSpec proto message.\n      inference_result: Channel of type `standard_artifacts.InferenceResult`\n        to store the inference results.\n      instance_name: Optional name assigned to this specific instance of\n        BulkInferrer. Required only if multiple BulkInferrer components are\n        declared in the same pipeline.\n    """"""\n    inference_result = inference_result or types.Channel(\n        type=standard_artifacts.InferenceResult,\n        artifacts=[standard_artifacts.InferenceResult()])\n    spec = BulkInferrerSpec(\n        examples=examples,\n        model=model,\n        model_blessing=model_blessing,\n        data_spec=data_spec or bulk_inferrer_pb2.DataSpec(),\n        model_spec=model_spec or bulk_inferrer_pb2.ModelSpec(),\n        inference_result=inference_result)\n    super(BulkInferrer, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/bulk_inferrer/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.bulk_inferrer.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx.components.bulk_inferrer import component\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    examples = standard_artifacts.Examples()\n    model = standard_artifacts.Model()\n    model_blessing = standard_artifacts.ModelBlessing()\n    bulk_inferrer = component.BulkInferrer(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model]),\n        model_blessing=channel_utils.as_channel([model_blessing]))\n    self.assertEqual(\'InferenceResult\',\n                     bulk_inferrer.outputs[\'inference_result\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/bulk_inferrer/executor.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX bulk_inferrer executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport importlib\nimport os\nfrom typing import Any, Dict, List, Mapping, Text\n\nfrom absl import logging\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tensorflow_serving.apis import prediction_log_pb2\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.util import model_utils\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\n_PREDICTION_LOGS_DIR_NAME = \'prediction_logs\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TFX bulk inferer executor.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Runs batch inference on a given model with given input examples.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts.\n        - examples: examples for inference.\n        - model: exported model.\n        - model_blessing: model blessing result\n      output_dict: Output dict from output key to a list of Artifacts.\n        - output: bulk inference results.\n      exec_properties: A dict of execution properties.\n        - model_spec: JSON string of bulk_inferrer_pb2.ModelSpec instance.\n        - data_spec: JSON string of bulk_inferrer_pb2.DataSpec instance.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    if \'examples\' not in input_dict:\n      raise ValueError(\'\\\'examples\\\' is missing in input dict.\')\n    if \'inference_result\' not in output_dict:\n      raise ValueError(\'\\\'inference_result\\\' is missing in output dict.\')\n    output = artifact_utils.get_single_instance(output_dict[\'inference_result\'])\n    if \'model\' not in input_dict:\n      raise ValueError(\'Input models are not valid, model \'\n                       \'need to be specified.\')\n    if \'model_blessing\' in input_dict:\n      model_blessing = artifact_utils.get_single_instance(\n          input_dict[\'model_blessing\'])\n      if not model_utils.is_model_blessed(model_blessing):\n        output.set_int_custom_property(\'inferred\', 0)\n        logging.info(\'Model on %s was not blessed\', model_blessing.uri)\n        return\n    else:\n      logging.info(\'Model blessing is not provided, exported model will be \'\n                   \'used.\')\n\n    model = artifact_utils.get_single_instance(\n        input_dict[\'model\'])\n    model_path = path_utils.serving_model_path(model.uri)\n    logging.info(\'Use exported model from %s.\', model_path)\n\n    data_spec = bulk_inferrer_pb2.DataSpec()\n    json_format.Parse(exec_properties[\'data_spec\'], data_spec)\n    example_uris = {}\n    if data_spec.example_splits:\n      for example in input_dict[\'examples\']:\n        for split in artifact_utils.decode_split_names(example.split_names):\n          if split in data_spec.example_splits:\n            example_uris[split] = os.path.join(example.uri, split)\n    else:\n      for example in input_dict[\'examples\']:\n        for split in artifact_utils.decode_split_names(example.split_names):\n          example_uris[split] = os.path.join(example.uri, split)\n    model_spec = bulk_inferrer_pb2.ModelSpec()\n    json_format.Parse(exec_properties[\'model_spec\'], model_spec)\n    output_path = os.path.join(output.uri, _PREDICTION_LOGS_DIR_NAME)\n    self._run_model_inference(model_path, example_uris, output_path,\n                              model_spec)\n    logging.info(\'BulkInferrer generates prediction log to %s\', output_path)\n    output.set_int_custom_property(\'inferred\', 1)\n\n  def _run_model_inference(self, model_path: Text,\n                           example_uris: Mapping[Text, Text],\n                           output_path: Text,\n                           model_spec: bulk_inferrer_pb2.ModelSpec) -> None:\n    """"""Runs model inference on given example data.\n\n    Args:\n      model_path: Path to model.\n      example_uris: Mapping of example split name to example uri.\n      output_path: Path to output generated prediction logs.\n      model_spec: bulk_inferrer_pb2.ModelSpec instance.\n\n    Returns:\n      None\n    """"""\n\n    try:\n      from tfx_bsl.public.beam import run_inference\n      from tfx_bsl.public.proto import model_spec_pb2\n    except ImportError:\n      # TODO(b/151468119): Remove this branch after next release.\n      run_inference = importlib.import_module(\'tfx_bsl.beam.run_inference\')\n      model_spec_pb2 = importlib.import_module(\'tfx_bsl.proto.model_spec_pb2\')\n    saved_model_spec = model_spec_pb2.SavedModelSpec(\n        model_path=model_path,\n        tag=model_spec.tag,\n        signature_name=model_spec.model_signature_name)\n    # TODO(b/151468119): Remove this branch after next release.\n    if getattr(model_spec_pb2, \'InferenceEndpoint\', False):\n      inference_endpoint = getattr(model_spec_pb2, \'InferenceEndpoint\')()\n    else:\n      inference_endpoint = model_spec_pb2.InferenceSpecType()\n    inference_endpoint.saved_model_spec.CopyFrom(saved_model_spec)\n    with self._make_beam_pipeline() as pipeline:\n      data_list = []\n      for split, example_uri in example_uris.items():\n        data = (\n            pipeline | \'ReadData[{}]\'.format(split) >> beam.io.ReadFromTFRecord(\n                file_pattern=io_utils.all_files_pattern(example_uri)))\n        data_list.append(data)\n      _ = (\n          [data for data in data_list]\n          | \'FlattenExamples\' >> beam.Flatten(pipeline=pipeline)\n          | \'ParseExamples\' >> beam.Map(tf.train.Example.FromString)\n          | \'RunInference\' >> run_inference.RunInference(inference_endpoint)\n          | \'WritePredictionLogs\' >> beam.io.WriteToTFRecord(\n              output_path,\n              file_name_suffix=\'.gz\',\n              coder=beam.coders.ProtoCoder(prediction_log_pb2.PredictionLog)))\n    logging.info(\'Inference result written to %s.\', output_path)\n'"
tfx/components/bulk_inferrer/executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for bulk_inferrer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tensorflow_serving.apis import prediction_log_pb2\nfrom tfx.components.bulk_inferrer import executor\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self.component_id = \'test_component\'\n\n    # Create input dict.\n    self._examples = standard_artifacts.Examples()\n    self._examples.uri = os.path.join(self._source_data_dir, \'csv_example_gen\')\n    self._examples.split_names = artifact_utils.encode_split_names(\n        [\'unlabelled\'])\n    self._model = standard_artifacts.Model()\n    self._model.uri = os.path.join(self._source_data_dir, \'trainer/current\')\n\n    self._model_blessing = standard_artifacts.ModelBlessing()\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)\n\n    self._inference_result = standard_artifacts.InferenceResult()\n    self._prediction_log_dir = os.path.join(self._output_data_dir,\n                                            \'prediction_logs\')\n    self._inference_result.uri = self._prediction_log_dir\n\n    # Create context\n    self._tmp_dir = os.path.join(self._output_data_dir, \'.temp\')\n    self._context = executor.Executor.Context(\n        tmp_dir=self._tmp_dir, unique_id=\'2\')\n\n  def _get_results(self, prediction_log_path):\n    results = []\n    filepattern = os.path.join(\n        prediction_log_path,\n        executor._PREDICTION_LOGS_DIR_NAME) + \'-?????-of-?????.gz\'\n    for f in tf.io.gfile.glob(filepattern):\n      record_iterator = tf.compat.v1.python_io.tf_record_iterator(\n          path=f,\n          options=tf.compat.v1.python_io.TFRecordOptions(\n              tf.compat.v1.python_io.TFRecordCompressionType.GZIP))\n      for record_string in record_iterator:\n        prediction_log = prediction_log_pb2.PredictionLog()\n        prediction_log.MergeFromString(record_string)\n        results.append(prediction_log)\n    return results\n\n  def testDoWithBlessedModel(self):\n    input_dict = {\n        \'examples\': [self._examples],\n        \'model\': [self._model],\n        \'model_blessing\': [self._model_blessing],\n    }\n    output_dict = {\n        \'inference_result\': [self._inference_result],\n    }\n    # Create exe properties.\n    exec_properties = {\n        \'data_spec\':\n            json_format.MessageToJson(\n                bulk_inferrer_pb2.DataSpec(), preserving_proto_field_name=True),\n        \'model_spec\':\n            json_format.MessageToJson(\n                bulk_inferrer_pb2.ModelSpec(),\n                preserving_proto_field_name=True),\n        \'component_id\':\n            self.component_id,\n    }\n\n    # Run executor.\n    bulk_inferrer = executor.Executor(self._context)\n    bulk_inferrer.Do(input_dict, output_dict, exec_properties)\n\n    # Check outputs.\n    self.assertTrue(tf.io.gfile.exists(self._prediction_log_dir))\n    results = self._get_results(self._prediction_log_dir)\n    self.assertTrue(results)\n    self.assertEqual(\n        len(results[0].classify_log.response.result.classifications), 1)\n    self.assertEqual(\n        len(results[0].classify_log.response.result.classifications[0].classes),\n        2)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/common_nodes/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/common_nodes/importer_node.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Importer definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Type, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import channel_utils\nfrom tfx.types import node_common\n\n# Constant to access importer importing result from importer output dict.\nIMPORT_RESULT_KEY = \'result\'\n# Constant to access artifact uri from importer exec_properties dict.\nSOURCE_URI_KEY = \'artifact_uri\'\n# Constant to access artifact properties from importer exec_properties dict.\nPROPERTIES_KEY = \'properties\'\n# Constant to access artifact properties from importer exec_properties dict.\nCUSTOM_PROPERTIES_KEY = \'custom_properties\'\n# Constant to access re-import option from importer exec_properties dict.\nREIMPORT_OPTION_KEY = \'reimport\'\n\n\nclass ImporterDriver(base_driver.BaseDriver):\n  """"""Driver for Importer.""""""\n\n  def _prepare_artifact(self, uri: Text, properties: Dict[Text, Any],\n                        custom_properties: Dict[Text, Any], reimport: bool,\n                        destination_channel: types.Channel) -> types.Artifact:\n    """"""Prepares the Importer\'s output artifact.\n\n    If there is already an artifact in MLMD with the same URI and properties /\n    custom properties, that artifact will be reused unless the `reimport`\n    argument is set to True.\n\n    Args:\n      uri: The uri of the artifact.\n      properties: The properties of the artifact, given as a dictionary from\n        string keys to integer / string values. Must conform to the declared\n        properties of the destination channel\'s output type.\n      custom_properties: The custom properties of the artifact, given as a\n        dictionary from string keys to integer / string values.\n      reimport: If set to True, will register a new artifact even if it already\n        exists in the database.\n      destination_channel: Destination channel for the imported artifact.\n\n    Returns:\n      An Artifact object representing the imported artifact.\n    """"""\n    absl.logging.info(\n        \'Processing source uri: %s, properties: %s, custom_properties: %s\' %\n        (uri, properties, custom_properties))\n\n    # Check types of custom properties.\n    for key, value in custom_properties.items():\n      if not isinstance(value, (int, Text, bytes)):\n        raise ValueError(\n            (\'Custom property value for key %r must be a string or integer \'\n             \'(got %r instead)\') % (key, value))\n\n    unfiltered_previous_artifacts = self._metadata_handler.get_artifacts_by_uri(\n        uri)\n    # Only consider previous artifacts as candidates to reuse, if the properties\n    # of the imported artifact match those of the existing artifact.\n    previous_artifacts = []\n    for candidate_mlmd_artifact in unfiltered_previous_artifacts:\n      is_candidate = True\n      candidate_artifact = destination_channel.type()\n      candidate_artifact.set_mlmd_artifact(candidate_mlmd_artifact)\n      for key, value in properties.items():\n        if getattr(candidate_artifact, key) != value:\n          is_candidate = False\n          break\n      for key, value in custom_properties.items():\n        if isinstance(value, int):\n          if candidate_artifact.get_int_custom_property(key) != value:\n            is_candidate = False\n            break\n        elif isinstance(value, (Text, bytes)):\n          if candidate_artifact.get_string_custom_property(key) != value:\n            is_candidate = False\n            break\n      if is_candidate:\n        previous_artifacts.append(candidate_mlmd_artifact)\n\n    result = destination_channel.type()\n    result.uri = uri\n    for key, value in properties.items():\n      setattr(result, key, value)\n    for key, value in custom_properties.items():\n      if isinstance(value, int):\n        result.set_int_custom_property(key, value)\n      elif isinstance(value, (Text, bytes)):\n        result.set_string_custom_property(key, value)\n\n    # If a registered artifact has the same uri and properties and the user does\n    # not explicitly ask for reimport, reuse that artifact.\n    if bool(previous_artifacts) and not reimport:\n      absl.logging.info(\'Reusing existing artifact\')\n      result.set_mlmd_artifact(max(previous_artifacts, key=lambda m: m.id))\n\n    return result\n\n  def pre_execution(\n      self,\n      input_dict: Dict[Text, types.Channel],\n      output_dict: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> data_types.ExecutionDecision:\n    # Registers contexts and execution.\n    contexts = self._metadata_handler.register_pipeline_contexts_if_not_exists(\n        pipeline_info)\n    execution = self._metadata_handler.register_execution(\n        exec_properties=exec_properties,\n        pipeline_info=pipeline_info,\n        component_info=component_info,\n        contexts=contexts)\n    # Create imported artifacts.\n    output_artifacts = {\n        IMPORT_RESULT_KEY: [\n            self._prepare_artifact(\n                uri=exec_properties[SOURCE_URI_KEY],\n                properties=exec_properties[PROPERTIES_KEY],\n                custom_properties=exec_properties[CUSTOM_PROPERTIES_KEY],\n                destination_channel=output_dict[IMPORT_RESULT_KEY],\n                reimport=exec_properties[REIMPORT_OPTION_KEY])\n        ]\n    }\n    # Update execution with imported artifacts.\n    self._metadata_handler.update_execution(\n        execution=execution,\n        component_info=component_info,\n        output_artifacts=output_artifacts,\n        execution_state=metadata.EXECUTION_STATE_CACHED,\n        contexts=contexts)\n\n    output_dict[IMPORT_RESULT_KEY] = channel_utils.as_channel(\n        output_artifacts[IMPORT_RESULT_KEY])\n\n    return data_types.ExecutionDecision(\n        input_dict={},\n        output_dict=output_artifacts,\n        exec_properties=exec_properties,\n        execution_id=execution.id,\n        use_cached_results=False)\n\n\nclass ImporterNode(base_node.BaseNode):\n  """"""Definition for TFX ImporterNode.\n\n  ImporterNode is a special TFX node which registers an external resource into\n  MLMD\n  so that downstream nodes can use the registered artifact as input.\n\n  Here is an example to use ImporterNode:\n\n  ...\n  importer = ImporterNode(\n      instance_name=\'import_schema\',\n      source_uri=\'uri/to/schema\'\n      artifact_type=standard_artifacts.Schema,\n      reimport=False)\n  schema_gen = SchemaGen(\n      fixed_schema=importer.outputs[\'result\'],\n      examples=...)\n  ...\n\n  Attributes:\n    _source_uri: the source uri to import.\n    _reimport: whether or not to re-import the URI even if it already exists in\n      MLMD.\n  """"""\n\n  def __init__(self,\n               instance_name: Text,\n               source_uri: Text,\n               artifact_type: Type[types.Artifact],\n               reimport: Optional[bool] = False,\n               properties: Optional[Dict[Text, Union[Text, int]]] = None,\n               custom_properties: Optional[Dict[Text, Union[Text,\n                                                            int]]] = None):\n    """"""Init function for ImporterNode.\n\n    Args:\n      instance_name: the name of the ImporterNode instance.\n      source_uri: the URI of the resource that needs to be registered.\n      artifact_type: the type of the artifact to import.\n      reimport: whether or not to re-import as a new artifact if the URI has\n        been imported in before.\n      properties: Dictionary of properties for the imported Artifact. These\n        properties should be ones declared for the given artifact_type (see the\n        PROPERTIES attribute of the definition of the type for details).\n      custom_properties: Dictionary of custom properties for the imported\n        Artifact. These properties should be of type Text or int.\n    """"""\n    self._source_uri = source_uri\n    self._reimport = reimport\n    self._properties = properties or {}\n    self._custom_properties = custom_properties or {}\n\n    artifact = artifact_type()\n    for key, value in self._properties.items():\n      setattr(artifact, key, value)\n    self._output_dict = {\n        IMPORT_RESULT_KEY:\n            types.Channel(type=artifact_type, artifacts=[artifact])\n    }\n\n    super(ImporterNode, self).__init__(\n        instance_name=instance_name,\n        driver_class=ImporterDriver,\n    )\n\n  @property\n  def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return node_common._PropertyDictWrapper({})  # pylint: disable=protected-access\n\n  @property\n  def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return node_common._PropertyDictWrapper(self._output_dict)  # pylint: disable=protected-access\n\n  @property\n  def exec_properties(self) -> Dict[Text, Any]:\n    return {\n        SOURCE_URI_KEY: self._source_uri,\n        REIMPORT_OPTION_KEY: self._reimport,\n        PROPERTIES_KEY: self._properties,\n        CUSTOM_PROPERTIES_KEY: self._custom_properties,\n    }\n'"
tfx/components/common_nodes/importer_node_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.common_nodes.importer_node.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.common_nodes import importer_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import json_utils\n\n\nclass ImporterNodeTest(tf.test.TestCase):\n\n  def testImporterDefinitionWithSingleUri(self):\n    impt = importer_node.ImporterNode(\n        instance_name=\'my_importer\',\n        source_uri=\'m/y/u/r/i\',\n        properties={\n            \'split_names\': \'[""train"", ""eval""]\',\n        },\n        custom_properties={\n            \'str_custom_property\': \'abc\',\n            \'int_custom_property\': 123,\n        },\n        artifact_type=standard_artifacts.Examples)\n    self.assertDictEqual(\n        impt.exec_properties, {\n            importer_node.SOURCE_URI_KEY: \'m/y/u/r/i\',\n            importer_node.REIMPORT_OPTION_KEY: False,\n            importer_node.PROPERTIES_KEY: {\n                \'split_names\': \'[""train"", ""eval""]\',\n            },\n            importer_node.CUSTOM_PROPERTIES_KEY: {\n                \'str_custom_property\': \'abc\',\n                \'int_custom_property\': 123,\n            },\n        })\n    self.assertEmpty(impt.inputs.get_all())\n    self.assertEqual(impt.outputs[importer_node.IMPORT_RESULT_KEY].type,\n                     standard_artifacts.Examples)\n\n  def testImporterNodeDumpsJsonRoundtrip(self):\n    instance_name = \'my_importer\'\n    source_uris = [\'m/y/u/r/i\']\n    impt = importer_node.ImporterNode(\n        instance_name=instance_name,\n        source_uri=source_uris,\n        artifact_type=standard_artifacts.Examples)\n\n    # The following line will raise an assertion if object not JSONable.\n    json_text = json_utils.dumps(impt)\n\n    actual_obj = json_utils.loads(json_text)\n    self.assertEqual(actual_obj._instance_name, instance_name)\n    self.assertEqual(actual_obj._source_uri, source_uris)\n\n\nclass ImporterDriverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ImporterDriverTest, self).setUp()\n    self.connection_config = metadata_store_pb2.ConnectionConfig()\n    self.connection_config.sqlite.SetInParent()\n    self.output_dict = {\n        importer_node.IMPORT_RESULT_KEY:\n            types.Channel(type=standard_artifacts.Examples)\n    }\n    self.source_uri = \'m/y/u/r/i\'\n    self.properties = {\n        \'split_names\': artifact_utils.encode_split_names([\'train\', \'eval\'])\n    }\n    self.custom_properties = {\n        \'string_custom_property\': \'abc\',\n        \'int_custom_property\': 123,\n    }\n\n    self.existing_artifacts = []\n    existing_artifact = standard_artifacts.Examples()\n    existing_artifact.uri = self.source_uri\n    existing_artifact.split_names = self.properties[\'split_names\']\n    self.existing_artifacts.append(existing_artifact)\n\n    self.pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'p_name\', pipeline_root=\'p_root\', run_id=\'run_id\')\n    self.component_info = data_types.ComponentInfo(\n        component_type=\'c_type\',\n        component_id=\'c_id\',\n        pipeline_info=self.pipeline_info)\n    self.driver_args = data_types.DriverArgs(enable_cache=True)\n\n  def _callImporterDriver(self, reimport: bool):\n    with metadata.Metadata(connection_config=self.connection_config) as m:\n      m.publish_artifacts(self.existing_artifacts)\n      driver = importer_node.ImporterDriver(metadata_handler=m)\n      execution_result = driver.pre_execution(\n          component_info=self.component_info,\n          pipeline_info=self.pipeline_info,\n          driver_args=self.driver_args,\n          input_dict={},\n          output_dict=self.output_dict,\n          exec_properties={\n              importer_node.SOURCE_URI_KEY: self.source_uri,\n              importer_node.REIMPORT_OPTION_KEY: reimport,\n              importer_node.PROPERTIES_KEY: self.properties,\n              importer_node.CUSTOM_PROPERTIES_KEY: self.custom_properties,\n          })\n      self.assertFalse(execution_result.use_cached_results)\n      self.assertEmpty(execution_result.input_dict)\n      self.assertEqual(\n          1, len(execution_result.output_dict[importer_node.IMPORT_RESULT_KEY]))\n      self.assertEqual(\n          execution_result.output_dict[importer_node.IMPORT_RESULT_KEY][0].uri,\n          self.source_uri)\n\n      self.assertNotEmpty(\n          self.output_dict[importer_node.IMPORT_RESULT_KEY].get())\n\n      results = self.output_dict[importer_node.IMPORT_RESULT_KEY].get()\n      self.assertEqual(1, len(results))\n      result = results[0]\n      self.assertEqual(result.uri, result.uri)\n      for key, value in self.properties.items():\n        self.assertEqual(value, getattr(result, key))\n      for key, value in self.custom_properties.items():\n        if isinstance(value, int):\n          self.assertEqual(value, result.get_int_custom_property(key))\n        elif isinstance(value, (Text, bytes)):\n          self.assertEqual(value, result.get_string_custom_property(key))\n        else:\n          raise ValueError(\'Invalid custom property value: %r.\' % value)\n\n  def testImportArtifact(self):\n    self._callImporterDriver(reimport=True)\n\n  def testReuseArtifact(self):\n    self._callImporterDriver(reimport=False)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/common_nodes/resolver_node.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Resolver definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Text, Type\n\nfrom tfx import types\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import base_node\nfrom tfx.dsl.resolvers import base_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import node_common\nfrom tfx.utils import json_utils\n\n# Constant to access resolver class from resolver exec_properties.\nRESOLVER_CLASS = \'resolver_class\'\n# Constant to access resolver config from resolver exec_properties.\nRESOLVER_CONFIGS = \'source_uri\'\n\n\nclass ResolverDriver(base_driver.BaseDriver):\n  """"""Driver for Resolver.\n\n  Constructs an instance of the resolver_class specified by user with configs\n  passed in by user and marks the resolved artifacts as the output of the\n  ResolverNode.\n  """"""\n\n  # TODO(ruoyu): We need a better approach to let ResolverNode fail on\n  # incomplete data.\n  def pre_execution(\n      self,\n      input_dict: Dict[Text, types.Channel],\n      output_dict: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> data_types.ExecutionDecision:\n    # Registers contexts and execution\n    contexts = self._metadata_handler.register_pipeline_contexts_if_not_exists(\n        pipeline_info)\n    execution = self._metadata_handler.register_execution(\n        exec_properties=exec_properties,\n        pipeline_info=pipeline_info,\n        component_info=component_info,\n        contexts=contexts)\n    # Gets resolved artifacts.\n    resolver_class = exec_properties[RESOLVER_CLASS]\n    if exec_properties[RESOLVER_CONFIGS]:\n      resolver = resolver_class(**exec_properties[RESOLVER_CONFIGS])\n    else:\n      resolver = resolver_class()\n    resolve_result = resolver.resolve(\n        pipeline_info=pipeline_info,\n        metadata_handler=self._metadata_handler,\n        source_channels=input_dict.copy())\n    # TODO(b/148828122): This is a temporary walkaround for interactive mode.\n    for k, c in output_dict.items():\n      output_dict[k] = types.Channel(\n          type=c.type, artifacts=resolve_result.per_key_resolve_result[k])\n    # Updates execution to reflect artifact resolution results and mark\n    # as cached.\n    self._metadata_handler.update_execution(\n        execution=execution,\n        component_info=component_info,\n        output_artifacts=resolve_result.per_key_resolve_result,\n        execution_state=metadata.EXECUTION_STATE_CACHED,\n        contexts=contexts)\n\n    return data_types.ExecutionDecision(\n        input_dict={},\n        output_dict=resolve_result.per_key_resolve_result,\n        exec_properties=exec_properties,\n        execution_id=execution.id,\n        use_cached_results=True)\n\n\nclass ResolverNode(base_node.BaseNode):\n  """"""Definition for TFX ResolverNode.\n\n  ResolverNode is a special TFX node which handles special artifact resolution\n  logics that will be used as inputs for downstream nodes.\n\n  To use ResolverNode, pass the followings to the ResolverNode constructor:\n    a. name of the ResolverNode instance\n    g. a subclass of BaseResolver\n    c. the configs that will be used to construct an instance of (a)\n    d. channels to resolve with their tag, in the form of kwargs\n  Here is an example:\n\n  ...\n  example_gen = ImportExampleGen(...)\n  latest_five_examples_resolver = ResolverNode(\n      instance_name=\'latest_five_examples_resolver\',\n      resolver_class=latest_artifacts_resolver.LatestArtifactsResolver,\n      resolver_config={\'desired_num_of_artifacts\' : 5},\n      examples=example_gen.outputs[\'examples\'])\n  trainer = MyTrainer(\n      examples=latest_model_resolver.outputs[\'examples\'],\n      user_module=...)\n  ...\n\n  Attributes:\n    _resolver_class: the class of the resolver.\n    _resolver_configs: the configs that will be used to construct an instance of\n      _resolver_class.\n  """"""\n\n  def __init__(self,\n               instance_name: Text,\n               resolver_class: Type[base_resolver.BaseResolver],\n               resolver_configs: Dict[Text, json_utils.JsonableType] = None,\n               **kwargs: types.Channel):\n    """"""Init function for ResolverNode.\n\n    Args:\n      instance_name: the name of the ResolverNode instance.\n      resolver_class: a BaseResolver subclass which contains the artifact\n        resolution logic.\n      resolver_configs: a dict of key to Jsonable type representing configs that\n        will be used to construct the resolver.\n      **kwargs: a key -> Channel dict, describing what are the Channels to be\n        resolved. This is set by user through keyword args.\n    """"""\n    self._resolver_class = resolver_class\n    self._resolver_configs = resolver_configs or {}\n    self._input_dict = kwargs\n    self._output_dict = {}\n    for k, c in self._input_dict.items():\n      self._output_dict[k] = types.Channel(type=c.type, artifacts=[c.type()])\n    super(ResolverNode, self).__init__(\n        instance_name=instance_name,\n        driver_class=ResolverDriver,\n    )\n\n  @property\n  def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return node_common._PropertyDictWrapper(self._input_dict)  # pylint: disable=protected-access\n\n  @property\n  def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return node_common._PropertyDictWrapper(self._output_dict)  # pylint: disable=protected-access\n\n  @property\n  def exec_properties(self) -> Dict[Text, Any]:\n    return {\n        RESOLVER_CLASS: self._resolver_class,\n        RESOLVER_CONFIGS: self._resolver_configs\n    }\n'"
tfx/components/common_nodes/resolver_node_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.common_nodes.resolver_node.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.common_nodes import resolver_node\nfrom tfx.dsl.experimental import latest_artifacts_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import standard_artifacts\n\n\nclass ResolverNodeTest(tf.test.TestCase):\n\n  def testResolverDefinition(self):\n    channel_to_resolve = types.Channel(type=standard_artifacts.Examples)\n    rnode = resolver_node.ResolverNode(\n        instance_name=\'my_resolver\',\n        resolver_class=latest_artifacts_resolver.LatestArtifactsResolver,\n        resolver_configs={\'desired_num_of_artifacts\': 5},\n        channel_to_resolve=channel_to_resolve)\n    self.assertDictEqual(\n        rnode.exec_properties, {\n            resolver_node.RESOLVER_CLASS:\n                latest_artifacts_resolver.LatestArtifactsResolver,\n            resolver_node.RESOLVER_CONFIGS: {\'desired_num_of_artifacts\': 5}\n        })\n    self.assertEqual(rnode.inputs.get_all()[\'channel_to_resolve\'],\n                     channel_to_resolve)\n    self.assertEqual(rnode.outputs.get_all()[\'channel_to_resolve\'].type_name,\n                     channel_to_resolve.type_name)\n\n\nclass ResolverDriverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ResolverDriverTest, self).setUp()\n    self.connection_config = metadata_store_pb2.ConnectionConfig()\n    self.connection_config.sqlite.SetInParent()\n    self.pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'p_name\', pipeline_root=\'p_root\', run_id=\'run_id\')\n    self.component_info = data_types.ComponentInfo(\n        component_type=\'c_type\',\n        component_id=\'c_id\',\n        pipeline_info=self.pipeline_info)\n    self.driver_args = data_types.DriverArgs(enable_cache=True)\n    self.source_channel_key = \'source_channel\'\n    self.source_channels = {\n        self.source_channel_key: types.Channel(type=standard_artifacts.Examples)\n    }\n\n  def testResolveArtifactSuccess(self):\n    existing_artifact = standard_artifacts.Examples()\n    existing_artifact.uri = \'my/uri\'\n    with metadata.Metadata(connection_config=self.connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self.pipeline_info)\n      m.publish_artifacts([existing_artifact])\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self.pipeline_info,\n          component_info=self.component_info,\n          contexts=contexts)\n      m.publish_execution(\n          component_info=self.component_info,\n          output_artifacts={\'key\': [existing_artifact]})\n      driver = resolver_node.ResolverDriver(metadata_handler=m)\n      output_dict = self.source_channels.copy()\n      execution_result = driver.pre_execution(\n          component_info=self.component_info,\n          pipeline_info=self.pipeline_info,\n          driver_args=self.driver_args,\n          input_dict=self.source_channels,\n          output_dict=output_dict,\n          exec_properties={\n              resolver_node.RESOLVER_CLASS:\n                  latest_artifacts_resolver.LatestArtifactsResolver,\n              resolver_node.RESOLVER_CONFIGS: {\n                  \'desired_num_of_artifacts\': 1\n              }\n          })\n      self.assertTrue(execution_result.use_cached_results)\n      self.assertEmpty(execution_result.input_dict)\n      self.assertDictEqual(\n          execution_result.exec_properties, {\n              resolver_node.RESOLVER_CLASS:\n                  latest_artifacts_resolver.LatestArtifactsResolver,\n              resolver_node.RESOLVER_CONFIGS: {\n                  \'desired_num_of_artifacts\': 1\n              }\n          })\n      self.assertEqual(\n          execution_result.output_dict[self.source_channel_key][0].uri,\n          existing_artifact.uri)\n      # TODO(b/148828122): Remove this after b/148828122 resolved.\n      self.assertEqual(output_dict[self.source_channel_key].get()[0].uri,\n                       existing_artifact.uri)\n\n  def testResolveArtifactFailIncompleteResult(self):\n    with metadata.Metadata(connection_config=self.connection_config) as m:\n      driver = resolver_node.ResolverDriver(metadata_handler=m)\n      driver.pre_execution(\n          component_info=self.component_info,\n          pipeline_info=self.pipeline_info,\n          driver_args=self.driver_args,\n          input_dict=self.source_channels,\n          output_dict=self.source_channels.copy(),\n          exec_properties={\n              resolver_node.RESOLVER_CLASS:\n                  latest_artifacts_resolver.LatestArtifactsResolver,\n              resolver_node.RESOLVER_CONFIGS: {}\n          })\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/evaluator/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/evaluator/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Evaluator component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Optional, Text, Union\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.evaluator import executor\nfrom tfx.orchestration import data_types\nfrom tfx.proto import evaluator_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import EvaluatorSpec\n\n\nclass Evaluator(base_component.BaseComponent):\n  """"""A TFX component to evaluate models trained by a TFX Trainer component.\n\n  The Evaluator component performs model evaluations in the TFX pipeline and\n  the resultant metrics can be viewed in a Jupyter notebook.  It uses the\n  input examples generated from the\n  [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)\n  component to evaluate the models.\n\n  Specifically, it can provide:\n    - metrics computed on entire training and eval dataset\n    - tracking metrics over time\n    - model quality performance on different feature slices\n\n  ## Exporting the EvalSavedModel in Trainer\n\n  In order to setup Evaluator in a TFX pipeline, an EvalSavedModel needs to be\n  exported during training, which is a special SavedModel containing\n  annotations for the metrics, features, labels, and so on in your model.\n  Evaluator uses this EvalSavedModel to compute metrics.\n\n  As part of this, the Trainer component creates eval_input_receiver_fn,\n  analogous to the serving_input_receiver_fn, which will extract the features\n  and labels from the input data. As with serving_input_receiver_fn, there are\n  utility functions to help with this.\n\n  Please see https://www.tensorflow.org/tfx/model_analysis for more details.\n\n  ## Example\n  ```\n    # Uses TFMA to compute a evaluation statistics over features of a model.\n    model_analyzer = Evaluator(\n        examples=example_gen.outputs[\'examples\'],\n        model=trainer.outputs[\'model\'],\n        eval_config=tfma.EvalConfig(...))\n  ```\n  """"""\n\n  SPEC_CLASS = EvaluatorSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      examples: types.Channel = None,\n      model: types.Channel = None,\n      baseline_model: Optional[types.Channel] = None,\n      # TODO(b/148618405): deprecate feature_slicing_spec.\n      feature_slicing_spec: Optional[Union[evaluator_pb2.FeatureSlicingSpec,\n                                           Dict[Text, Any]]] = None,\n      fairness_indicator_thresholds: Optional[List[Union[\n          float, data_types.RuntimeParameter]]] = None,\n      output: Optional[types.Channel] = None,\n      model_exports: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None,\n      eval_config: Optional[tfma.EvalConfig] = None,\n      blessing: Optional[types.Channel] = None,\n      schema: Optional[types.Channel] = None):\n    """"""Construct an Evaluator component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, usually\n        produced by an ExampleGen component. _required_\n      model: A Channel of type `standard_artifacts.Model`, usually produced by\n        a Trainer component.\n      baseline_model: An optional channel of type \'standard_artifacts.Model\' as\n        the baseline model for model diff and model validation purpose.\n      feature_slicing_spec:\n        Deprecated, please use eval_config instead. Only support estimator.\n        [evaluator_pb2.FeatureSlicingSpec](https://github.com/tensorflow/tfx/blob/master/tfx/proto/evaluator.proto)\n          instance that describes how Evaluator should slice the data. If any\n          field is provided as a RuntimeParameter, feature_slicing_spec should\n          be constructed as a dict with the same field names as\n          FeatureSlicingSpec proto message.\n      fairness_indicator_thresholds: Optional list of float (or\n        RuntimeParameter) threshold values for use with TFMA fairness\n          indicators. Experimental functionality: this interface and\n          functionality may change at any time. TODO(b/142653905): add a link to\n          additional documentation for TFMA fairness indicators here.\n      output: Channel of `ModelEvalPath` to store the evaluation results.\n      model_exports: Backwards compatibility alias for the `model` argument.\n      instance_name: Optional name assigned to this specific instance of\n        Evaluator. Required only if multiple Evaluator components are declared\n        in the same pipeline.  Either `model_exports` or `model` must be present\n        in the input arguments.\n      eval_config: Instance of tfma.EvalConfig containg configuration settings\n        for running the evaluation. This config has options for both estimator\n        and Keras.\n      blessing: Output channel of \'ModelBlessingPath\' that contains the\n        blessing result.\n      schema: A `Schema` channel to use for TFXIO.\n    """"""\n    if eval_config is not None and feature_slicing_spec is not None:\n      raise ValueError(""Exactly one of \'eval_config\' or \'feature_slicing_spec\' ""\n                       ""must be supplied."")\n    if eval_config is None and feature_slicing_spec is None:\n      feature_slicing_spec = evaluator_pb2.FeatureSlicingSpec()\n      absl.logging.info(\'Neither eval_config nor feature_slicing_spec is \'\n                        \'passed, the model is treated as estimator.\')\n\n    if model_exports:\n      absl.logging.warning(\n          \'The ""model_exports"" argument to the Evaluator component has \'\n          \'been renamed to ""model"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      model = model_exports\n\n    if feature_slicing_spec:\n      absl.logging.warning(\'feature_slicing_spec is deprecated, please use \'\n                           \'eval_config instead.\')\n\n    blessing = blessing or types.Channel(\n        type=standard_artifacts.ModelBlessing,\n        artifacts=[standard_artifacts.ModelBlessing()])\n\n    evaluation = output or types.Channel(\n        type=standard_artifacts.ModelEvaluation,\n        artifacts=[standard_artifacts.ModelEvaluation()])\n    spec = EvaluatorSpec(\n        examples=examples,\n        model=model,\n        baseline_model=baseline_model,\n        feature_slicing_spec=feature_slicing_spec,\n        fairness_indicator_thresholds=fairness_indicator_thresholds,\n        evaluation=evaluation,\n        eval_config=eval_config,\n        blessing=blessing,\n        schema=schema)\n    super(Evaluator, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/evaluator/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.evaluator.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components.evaluator import component\nfrom tfx.orchestration import data_types\nfrom tfx.proto import evaluator_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model_exports]))\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'evaluation\'].type_name)\n    self.assertEqual(standard_artifacts.ModelBlessing.TYPE_NAME,\n                     evaluator.outputs[\'blessing\'].type_name)\n\n  def testConstructWithBaselineModel(self):\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    baseline_model = standard_artifacts.Model()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model_exports]),\n        baseline_model=channel_utils.as_channel([baseline_model]))\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'evaluation\'].type_name)\n\n  def testConstructWithSliceSpec(self):\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model_exports]),\n        feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n            evaluator_pb2.SingleSlicingSpec(\n                column_for_slicing=[\'trip_start_hour\'])\n        ]))\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'evaluation\'].type_name)\n\n  def testConstructWithFairnessThresholds(self):\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model_exports]),\n        feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n            evaluator_pb2.SingleSlicingSpec(\n                column_for_slicing=[\'trip_start_hour\'])\n        ]),\n        fairness_indicator_thresholds=[0.1, 0.3, 0.5, 0.9])\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'evaluation\'].type_name)\n\n  def testConstructWithParameter(self):\n    column_name = data_types.RuntimeParameter(name=\'column-name\', ptype=Text)\n    threshold = data_types.RuntimeParameter(name=\'threshold\', ptype=float)\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model_exports]),\n        feature_slicing_spec={\'specs\': [{\n            \'column_for_slicing\': [column_name]\n        }]},\n        fairness_indicator_thresholds=[threshold])\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'evaluation\'].type_name)\n\n  def testConstructWithEvalConfig(self):\n    examples = standard_artifacts.Examples()\n    model_exports = standard_artifacts.Model()\n    schema = standard_artifacts.Schema()\n    evaluator = component.Evaluator(\n        examples=channel_utils.as_channel([examples]),\n        model_exports=channel_utils.as_channel([model_exports]),\n        eval_config=tfma.EvalConfig(\n            slicing_specs=[tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])]),\n        schema=channel_utils.as_channel([schema]),)\n    self.assertEqual(standard_artifacts.ModelEvaluation.TYPE_NAME,\n                     evaluator.outputs[\'output\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/evaluator/constants.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Constant values for Evaluator.""""""\n\n# Key for examples in executor input_dict.\nEXAMPLES_KEY = \'examples\'\n# Key for model in executor input_dict.\nMODEL_KEY = \'model\'\n# Key for baseline model in executor input_dict.\nBASELINE_MODEL_KEY = \'baseline_model\'\n# Key for schema in executor input_dict.\nSCHEMA_KEY = \'schema\'\n\n# Key for model blessing in executor output_dict.\nBLESSING_KEY = \'blessing\'\n\n# Keys for artifact (custom) properties.\nARTIFACT_PROPERTY_BLESSED_KEY = \'blessed\'\nARTIFACT_PROPERTY_CURRENT_MODEL_URI_KEY = \'current_model\'\nARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY = \'current_model_id\'\nARTIFACT_PROPERTY_BASELINE_MODEL_URI_KEY = \'baseline_model\'\nARTIFACT_PROPERTY_BASELINE_MODEL_ID_KEY = \'baseline_model_id\'\n\n# Values for blessing results.\nBLESSED_VALUE = 1\nNOT_BLESSED_VALUE = 0\n\n# File names for blessing results.\nBLESSED_FILE_NAME = \'BLESSED\'\nNOT_BLESSED_FILE_NAME = \'NOT_BLESSED\'\n\n# Key for evaluation results in executor output_dict.\nEVALUATION_KEY = \'evaluation\'\n'"
tfx/components/evaluator/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX model evaluator executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow_model_analysis as tfma\nfrom tensorflow_model_analysis import constants as tfma_constants\nfrom tfx_bsl.tfxio import tensor_adapter\nfrom tfx_bsl.tfxio import tf_example_record\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.evaluator import constants\nfrom tfx.proto import evaluator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\n# TODO(pachristopher): After TFMA is released, make TFXIO as the default path.\n_USE_TFXIO = False\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Generic TFX model evaluator executor.""""""\n\n  def _get_slice_spec_from_feature_slicing_spec(\n      self, spec: evaluator_pb2.FeatureSlicingSpec\n  ) -> List[tfma.slicer.SingleSliceSpec]:\n    """"""Given a feature slicing spec, returns a List of SingleSliceSpecs.\n\n    Args:\n      spec: slice specification.\n\n    Returns:\n      List of corresponding SingleSliceSpecs. Always includes the overall slice,\n      even if it was not specified in the given spec.\n    """"""\n    result = []\n    for single_spec in spec.specs:\n      columns = single_spec.column_for_slicing\n      result.append(tfma.slicer.SingleSliceSpec(columns=columns))\n    # Always include the overall slice.\n    if tfma.slicer.SingleSliceSpec() not in result:\n      result.append(tfma.slicer.SingleSliceSpec())\n    return result\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Runs a batch job to evaluate the eval_model against the given input.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts.\n        - model_exports: exported model.\n        - examples: examples for eval the model.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - output: model evaluation results.\n      exec_properties: A dict of execution properties.\n        - eval_config: JSON string of tfma.EvalConfig.\n        - feature_slicing_spec: JSON string of evaluator_pb2.FeatureSlicingSpec\n          instance, providing the way to slice the data. Deprecated, use\n          eval_config.slicing_specs instead.\n\n    Returns:\n      None\n    """"""\n    if constants.EXAMPLES_KEY not in input_dict:\n      raise ValueError(\'EXAMPLES_KEY is missing from input dict.\')\n    if constants.MODEL_KEY not in input_dict:\n      raise ValueError(\'MODEL_KEY is missing from input dict.\')\n    if constants.EVALUATION_KEY not in output_dict:\n      raise ValueError(\'EVALUATION_KEY is missing from output dict.\')\n    if len(input_dict[constants.MODEL_KEY]) > 1:\n      raise ValueError(\n          \'There can be only one candidate model, there are {}.\'.format(\n              len(input_dict[constants.MODEL_KEY])))\n    if constants.BASELINE_MODEL_KEY in input_dict and len(\n        input_dict[constants.BASELINE_MODEL_KEY]) > 1:\n      raise ValueError(\n          \'There can be only one baseline model, there are {}.\'.format(\n              len(input_dict[constants.BASELINE_MODEL_KEY])))\n\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    # Add fairness indicator metric callback if necessary.\n    fairness_indicator_thresholds = exec_properties.get(\n        \'fairness_indicator_thresholds\', None)\n    add_metrics_callbacks = None\n    if fairness_indicator_thresholds:\n      # Need to import the following module so that the fairness indicator\n      # post-export metric is registered.\n      import tensorflow_model_analysis.addons.fairness.post_export_metrics.fairness_indicators  # pylint: disable=g-import-not-at-top, unused-variable\n      add_metrics_callbacks = [\n          tfma.post_export_metrics.fairness_indicators(  # pytype: disable=module-attr\n              thresholds=fairness_indicator_thresholds),\n      ]\n\n    output_uri = artifact_utils.get_single_uri(\n        output_dict[constants.EVALUATION_KEY])\n\n    run_validation = False\n    models = []\n    if \'eval_config\' in exec_properties and exec_properties[\'eval_config\']:\n      slice_spec = None\n      has_baseline = bool(input_dict.get(constants.BASELINE_MODEL_KEY))\n      eval_config = tfma.EvalConfig()\n      json_format.Parse(exec_properties[\'eval_config\'], eval_config)\n      eval_config = tfma.update_eval_config_with_defaults(\n          eval_config,\n          maybe_add_baseline=has_baseline,\n          maybe_remove_baseline=not has_baseline)\n      tfma.verify_eval_config(eval_config)\n      # Do not validate model when there is no thresholds configured. This is to\n      # avoid accidentally blessing models when users forget to set thresholds.\n      run_validation = bool(tfma.metrics.metric_thresholds_from_metrics_specs(\n          eval_config.metrics_specs))\n      if len(eval_config.model_specs) > 2:\n        raise ValueError(\n            """"""Cannot support more than two models. There are {} models in this\n             eval_config."""""".format(len(eval_config.model_specs)))\n      # Extract model artifacts.\n      for model_spec in eval_config.model_specs:\n        if model_spec.is_baseline:\n          model_uri = artifact_utils.get_single_uri(\n              input_dict[constants.BASELINE_MODEL_KEY])\n        else:\n          model_uri = artifact_utils.get_single_uri(\n              input_dict[constants.MODEL_KEY])\n        if tfma.get_model_type(model_spec) == tfma.TF_ESTIMATOR:\n          model_path = path_utils.eval_model_path(model_uri)\n        else:\n          model_path = path_utils.serving_model_path(model_uri)\n        absl.logging.info(\'Using {} as {} model.\'.format(\n            model_path, model_spec.name))\n        models.append(tfma.default_eval_shared_model(\n            model_name=model_spec.name,\n            eval_saved_model_path=model_path,\n            add_metrics_callbacks=add_metrics_callbacks,\n            eval_config=eval_config))\n    else:\n      eval_config = None\n      assert (\'feature_slicing_spec\' in exec_properties and\n              exec_properties[\'feature_slicing_spec\']\n             ), \'both eval_config and feature_slicing_spec are unset.\'\n      feature_slicing_spec = evaluator_pb2.FeatureSlicingSpec()\n      json_format.Parse(exec_properties[\'feature_slicing_spec\'],\n                        feature_slicing_spec)\n      slice_spec = self._get_slice_spec_from_feature_slicing_spec(\n          feature_slicing_spec)\n      model_uri = artifact_utils.get_single_uri(input_dict[constants.MODEL_KEY])\n      model_path = path_utils.eval_model_path(model_uri)\n      absl.logging.info(\'Using {} for model eval.\'.format(model_path))\n      models.append(tfma.default_eval_shared_model(\n          eval_saved_model_path=model_path,\n          add_metrics_callbacks=add_metrics_callbacks))\n\n    file_pattern = io_utils.all_files_pattern(\n        artifact_utils.get_split_uri(input_dict[constants.EXAMPLES_KEY], \'eval\')\n    )\n    eval_shared_model = models[0] if len(models) == 1 else models\n    schema = None\n    if constants.SCHEMA_KEY in input_dict:\n      schema = io_utils.SchemaReader().read(\n          io_utils.get_only_uri_in_dir(\n              artifact_utils.get_single_uri(input_dict[constants.SCHEMA_KEY])))\n\n    absl.logging.info(\'Evaluating model.\')\n    with self._make_beam_pipeline() as pipeline:\n      # pylint: disable=expression-not-assigned\n      if _USE_TFXIO:\n        tensor_adapter_config = None\n        if tfma.is_batched_input(eval_shared_model, eval_config):\n          tfxio = tf_example_record.TFExampleRecord(\n              file_pattern=file_pattern,\n              schema=schema,\n              raw_record_column_name=tfma_constants.ARROW_INPUT_COLUMN)\n          if schema is not None:\n            tensor_adapter_config = tensor_adapter.TensorAdapterConfig(\n                arrow_schema=tfxio.ArrowSchema(),\n                tensor_representations=tfxio.TensorRepresentations())\n          data = pipeline | \'ReadFromTFRecordToArrow\' >> tfxio.BeamSource()\n        else:\n          data = pipeline | \'ReadFromTFRecord\' >> beam.io.ReadFromTFRecord(\n              file_pattern=file_pattern)\n        (data\n         | \'ExtractEvaluateAndWriteResults\' >>\n         tfma.ExtractEvaluateAndWriteResults(\n             eval_shared_model=models[0] if len(models) == 1 else models,\n             eval_config=eval_config,\n             output_path=output_uri,\n             slice_spec=slice_spec,\n             tensor_adapter_config=tensor_adapter_config))\n      else:\n        data = pipeline | \'ReadFromTFRecord\' >> beam.io.ReadFromTFRecord(\n            file_pattern=file_pattern)\n        (data\n         | \'ExtractEvaluateAndWriteResults\' >>\n         tfma.ExtractEvaluateAndWriteResults(\n             eval_shared_model=models[0] if len(models) == 1 else models,\n             eval_config=eval_config,\n             output_path=output_uri,\n             slice_spec=slice_spec))\n    absl.logging.info(\n        \'Evaluation complete. Results written to {}.\'.format(output_uri))\n\n    if not run_validation:\n      # TODO(jinhuang): delete the BLESSING_KEY from output_dict when supported.\n      absl.logging.info(\'No threshold configured, will not validate model.\')\n      return\n    # Set up blessing artifact\n    blessing = artifact_utils.get_single_instance(\n        output_dict[constants.BLESSING_KEY])\n    blessing.set_string_custom_property(\n        constants.ARTIFACT_PROPERTY_CURRENT_MODEL_URI_KEY,\n        artifact_utils.get_single_uri(input_dict[constants.MODEL_KEY]))\n    blessing.set_int_custom_property(\n        constants.ARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY,\n        input_dict[constants.MODEL_KEY][0].id)\n    if input_dict.get(constants.BASELINE_MODEL_KEY):\n      baseline_model = input_dict[constants.BASELINE_MODEL_KEY][0]\n      blessing.set_string_custom_property(\n          constants.ARTIFACT_PROPERTY_BASELINE_MODEL_URI_KEY,\n          baseline_model.uri)\n      blessing.set_int_custom_property(\n          constants.ARTIFACT_PROPERTY_BASELINE_MODEL_ID_KEY, baseline_model.id)\n    if \'current_component_id\' in exec_properties:\n      blessing.set_string_custom_property(\n          \'component_id\', exec_properties[\'current_component_id\'])\n    # Check validation result and write BLESSED file accordingly.\n    absl.logging.info(\'Checking validation results.\')\n    validation_result = tfma.load_validation_result(output_uri)\n    if validation_result.validation_ok:\n      io_utils.write_string_file(\n          os.path.join(blessing.uri, constants.BLESSED_FILE_NAME), \'\')\n      blessing.set_int_custom_property(constants.ARTIFACT_PROPERTY_BLESSED_KEY,\n                                       constants.BLESSED_VALUE)\n    else:\n      io_utils.write_string_file(\n          os.path.join(blessing.uri, constants.NOT_BLESSED_FILE_NAME), \'\')\n      blessing.set_int_custom_property(constants.ARTIFACT_PROPERTY_BLESSED_KEY,\n                                       constants.NOT_BLESSED_VALUE)\n    absl.logging.info(\'Blessing result {} written to {}.\'.format(\n        validation_result.validation_ok, blessing.uri))\n'"
tfx/components/evaluator/executor_test.py,17,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.evaluator.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport absl\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nfrom google.protobuf import json_format\nfrom tfx.components.evaluator import constants\nfrom tfx.components.evaluator import executor\nfrom tfx.proto import evaluator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase, absl.testing.parameterized.TestCase):\n\n  @absl.testing.parameterized.named_parameters((\'evaluation_w_eval_config\', {\n      \'eval_config\':\n          json_format.MessageToJson(\n              tfma.EvalConfig(slicing_specs=[\n                  tfma.SlicingSpec(feature_keys=[\'trip_start_hour\']),\n                  tfma.SlicingSpec(\n                      feature_keys=[\'trip_start_day\', \'trip_miles\']),\n              ]),\n              preserving_proto_field_name=True)\n  }))\n  def testEvalution(self, exec_properties):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    model = standard_artifacts.Model()\n    baseline_model = standard_artifacts.Model()\n    model.uri = os.path.join(source_data_dir, \'trainer/current\')\n    baseline_model.uri = os.path.join(source_data_dir, \'trainer/previous/\')\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(source_data_dir, \'schema_gen\')\n    input_dict = {\n        constants.EXAMPLES_KEY: [examples],\n        constants.MODEL_KEY: [model],\n        constants.SCHEMA_KEY: [schema],\n    }\n\n    # Create output dict.\n    eval_output = standard_artifacts.ModelEvaluation()\n    eval_output.uri = os.path.join(output_data_dir, \'eval_output\')\n    blessing_output = standard_artifacts.ModelBlessing()\n    blessing_output.uri = os.path.join(output_data_dir, \'blessing_output\')\n    output_dict = {\n        constants.EVALUATION_KEY: [eval_output],\n        constants.BLESSING_KEY: [blessing_output],\n    }\n\n    # Run executor.\n    evaluator = executor.Executor()\n    evaluator.Do(input_dict, output_dict, exec_properties)\n\n    # Check evaluator outputs.\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'eval_config.json\')))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'metrics\')))\n    self.assertTrue(tf.io.gfile.exists(os.path.join(eval_output.uri, \'plots\')))\n    self.assertFalse(\n        tf.io.gfile.exists(os.path.join(blessing_output.uri, \'BLESSED\')))\n\n  @absl.testing.parameterized.named_parameters((\'legacy_feature_slicing\', {\n      \'feature_slicing_spec\':\n          json_format.MessageToJson(\n              evaluator_pb2.FeatureSlicingSpec(specs=[\n                  evaluator_pb2.SingleSlicingSpec(\n                      column_for_slicing=[\'trip_start_hour\']),\n                  evaluator_pb2.SingleSlicingSpec(\n                      column_for_slicing=[\'trip_start_day\', \'trip_miles\']),\n              ]),\n              preserving_proto_field_name=True),\n  }))\n  def testDoLegacySingleEvalSavedModelWFairness(self, exec_properties):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    model = standard_artifacts.Model()\n    model.uri = os.path.join(source_data_dir, \'trainer/current\')\n    input_dict = {\n        constants.EXAMPLES_KEY: [examples],\n        constants.MODEL_KEY: [model],\n    }\n\n    # Create output dict.\n    eval_output = standard_artifacts.ModelEvaluation()\n    eval_output.uri = os.path.join(output_data_dir, \'eval_output\')\n    blessing_output = standard_artifacts.ModelBlessing()\n    blessing_output.uri = os.path.join(output_data_dir, \'blessing_output\')\n    output_dict = {\n        constants.EVALUATION_KEY: [eval_output],\n        constants.BLESSING_KEY: [blessing_output],\n    }\n\n    try:\n      # Need to import the following module so that the fairness indicator\n      # post-export metric is registered.  This may raise an ImportError if the\n      # currently-installed version of TFMA does not support fairness\n      # indicators.\n      import tensorflow_model_analysis.addons.fairness.post_export_metrics.fairness_indicators  # pylint: disable=g-import-not-at-top, unused-variable\n      exec_properties[\'fairness_indicator_thresholds\'] = [\n          0.1, 0.3, 0.5, 0.7, 0.9\n      ]\n    except ImportError:\n      absl.logging.warning(\n          \'Not testing fairness indicators because a compatible TFMA version \'\n          \'is not installed.\')\n\n    # Run executor.\n    evaluator = executor.Executor()\n    evaluator.Do(input_dict, output_dict, exec_properties)\n\n    # Check evaluator outputs.\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'eval_config.json\')))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'metrics\')))\n    self.assertTrue(tf.io.gfile.exists(os.path.join(eval_output.uri, \'plots\')))\n    self.assertFalse(\n        tf.io.gfile.exists(os.path.join(blessing_output.uri, \'BLESSED\')))\n\n  @absl.testing.parameterized.named_parameters(\n      (\n          \'eval_config_w_validation\',\n          {\n              \'eval_config\':\n                  json_format.MessageToJson(\n                      tfma.EvalConfig(\n                          model_specs=[\n                              tfma.ModelSpec(label_key=\'tips\'),\n                          ],\n                          metrics_specs=[\n                              tfma.MetricsSpec(metrics=[\n                                  tfma.config.MetricConfig(\n                                      class_name=\'ExampleCount\',\n                                      # Count > 0, OK.\n                                      threshold=tfma.config.MetricThreshold(\n                                          value_threshold=tfma\n                                          .GenericValueThreshold(\n                                              lower_bound={\'value\': 0}))),\n                              ]),\n                          ],\n                          slicing_specs=[tfma.SlicingSpec()]),\n                      preserving_proto_field_name=True)\n          },\n          True,\n          True),\n      (\n          \'eval_config_w_validation_fail\',\n          {\n              \'eval_config\':\n                  json_format.MessageToJson(\n                      tfma.EvalConfig(\n                          model_specs=[\n                              tfma.ModelSpec(\n                                  name=\'baseline1\',\n                                  label_key=\'tips\',\n                                  is_baseline=True),\n                              tfma.ModelSpec(\n                                  name=\'candidate1\', label_key=\'tips\'),\n                          ],\n                          metrics_specs=[\n                              tfma.MetricsSpec(metrics=[\n                                  tfma.config.MetricConfig(\n                                      class_name=\'ExampleCount\',\n                                      # Count < -1, NOT OK.\n                                      threshold=tfma.config.MetricThreshold(\n                                          value_threshold=tfma\n                                          .GenericValueThreshold(\n                                              upper_bound={\'value\': -1}))),\n                              ]),\n                          ],\n                          slicing_specs=[tfma.SlicingSpec()]),\n                      preserving_proto_field_name=True)\n          },\n          False,\n          True),\n      (\n          \'no_baseline_model_ignore_change_threshold_validation_pass\',\n          {\n              \'eval_config\':\n                  json_format.MessageToJson(\n                      tfma.EvalConfig(\n                          model_specs=[\n                              tfma.ModelSpec(\n                                  name=\'baseline\',\n                                  label_key=\'tips\',\n                                  is_baseline=True),\n                              tfma.ModelSpec(\n                                  name=\'candidate\', label_key=\'tips\'),\n                          ],\n                          metrics_specs=[\n                              tfma.MetricsSpec(metrics=[\n                                  tfma.config.MetricConfig(\n                                      class_name=\'ExampleCount\',\n                                      # Count > 0, OK.\n                                      threshold=tfma.config.MetricThreshold(\n                                          value_threshold=tfma\n                                          .GenericValueThreshold(\n                                              lower_bound={\'value\': 0}))),\n                                  tfma.config.MetricConfig(\n                                      class_name=\'Accuracy\',\n                                      # Should be ignored due to no baseline.\n                                      threshold=tfma.config.MetricThreshold(\n                                          change_threshold=tfma\n                                          .GenericChangeThreshold(\n                                              relative={\'value\': 0},\n                                              direction=tfma.MetricDirection\n                                              .LOWER_IS_BETTER))),\n                              ]),\n                          ],\n                          slicing_specs=[tfma.SlicingSpec()]),\n                      preserving_proto_field_name=True)\n          },\n          True,\n          False))\n  def testDoValidation(self, exec_properties, blessed, has_baseline):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    model = standard_artifacts.Model()\n    baseline_model = standard_artifacts.Model()\n    model.uri = os.path.join(source_data_dir, \'trainer/current\')\n    baseline_model.uri = os.path.join(source_data_dir, \'trainer/previous/\')\n    blessing_output = standard_artifacts.ModelBlessing()\n    blessing_output.uri = os.path.join(output_data_dir, \'blessing_output\')\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(source_data_dir, \'schema_gen\')\n    input_dict = {\n        constants.EXAMPLES_KEY: [examples],\n        constants.MODEL_KEY: [model],\n        constants.SCHEMA_KEY: [schema],\n    }\n    if has_baseline:\n      input_dict[constants.BASELINE_MODEL_KEY] = [baseline_model]\n\n    # Create output dict.\n    eval_output = standard_artifacts.ModelEvaluation()\n    eval_output.uri = os.path.join(output_data_dir, \'eval_output\')\n    blessing_output = standard_artifacts.ModelBlessing()\n    blessing_output.uri = os.path.join(output_data_dir, \'blessing_output\')\n    output_dict = {\n        constants.EVALUATION_KEY: [eval_output],\n        constants.BLESSING_KEY: [blessing_output],\n    }\n\n    # Run executor.\n    evaluator = executor.Executor()\n    evaluator.Do(input_dict, output_dict, exec_properties)\n\n    # Check evaluator outputs.\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'eval_config.json\')))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'metrics\')))\n    self.assertTrue(tf.io.gfile.exists(os.path.join(eval_output.uri, \'plots\')))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(eval_output.uri, \'validations\')))\n    if blessed:\n      self.assertTrue(\n          tf.io.gfile.exists(os.path.join(blessing_output.uri, \'BLESSED\')))\n    else:\n      self.assertTrue(\n          tf.io.gfile.exists(os.path.join(blessing_output.uri, \'NOT_BLESSED\')))\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_v2_behavior()\n  tf.test.main()\n'"
tfx/components/example_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_gen/base_example_gen_executor.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX example gen base executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport bisect\nimport hashlib\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nfrom six import with_metaclass\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.example_gen import utils\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\n\n# Default file name for TFRecord output file prefix.\nDEFAULT_FILE_NAME = \'data_tfrecord\'\n# Key for input in executor input_dict.\nINPUT_KEY = \'input\'\n\n# Key for output examples in executor output_dict.\nEXAMPLES_KEY = \'examples\'\n\n\ndef _PartitionFn(record: bytes, num_partitions: int, buckets: List[int]) -> int:\n  assert num_partitions == len(\n      buckets), \'Partitions do not match bucket number.\'\n  bucket = int(hashlib.sha256(record).hexdigest(), 16) % buckets[-1]\n  # For example, if buckets is [10,50,80], there will be 3 splits:\n  #   bucket >=0 && < 10, returns 0\n  #   bucket >=10 && < 50, returns 1\n  #   bucket >=50 && < 80, returns 2\n  return bisect.bisect(buckets, bucket)\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(bytes)\n@beam.typehints.with_output_types(beam.pvalue.PDone)\ndef _WriteSplit(example_split: beam.pvalue.PCollection,\n                output_split_path: Text) -> beam.pvalue.PDone:\n  """"""Shuffles and writes output split.""""""\n  return (example_split\n          # TODO(jyzhao): make shuffle optional.\n          | \'Shuffle\' >> beam.transforms.Reshuffle()\n          # TODO(jyzhao): multiple output format.\n          | \'Write\' >> beam.io.WriteToTFRecord(\n              os.path.join(output_split_path, DEFAULT_FILE_NAME),\n              file_name_suffix=\'.gz\'))\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(bytes)\ndef _InputToSerializedExample(pipeline: beam.Pipeline,\n                              input_to_example: beam.PTransform,\n                              input_dict: Dict[Text, List[types.Artifact]],\n                              exec_properties: Dict[Text, Any],\n                              split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Converts input to serialized TF examples.""""""\n  return (pipeline\n          | \'InputSourceToExample\' >> input_to_example(\n              input_dict, exec_properties, split_pattern)\n          # Returns deterministic string as partition is based on it.\n          | \'SerializeDeterministically\' >>\n          beam.Map(lambda x: x.SerializeToString(deterministic=True)))\n\n\nclass BaseExampleGenExecutor(\n    with_metaclass(abc.ABCMeta, base_executor.BaseExecutor)):\n  """"""Generic TFX example gen base executor.\n\n  The base ExampleGen executor takes a configuration and converts external data\n  sources to TensorFlow Examples (tf.Example).\n\n  The common configuration (defined in\n  https://github.com/tensorflow/tfx/blob/master/tfx/proto/example_gen.proto#L44.)\n  describes the general properties of input data and shared instructions when\n  producing output data.\n\n  The conversion is done in `GenerateExamplesByBeam` as a Beam pipeline, which\n  validates the configuration, reads the external data sources, converts the\n  record in the input source to tf.Example if needed, and splits the examples if\n  the output split config is given. Then the executor\'s `Do` writes the results\n  in splits to the output path.\n\n  For simple custom ExampleGens, the details of transforming input data\n  record(s) to a tf.Example is expected to be given in\n  `GetInputSourceToExamplePTransform`, which returns a Beam PTransform with the\n  actual implementation. For complex use cases, such as joining multiple data\n  sources and different interpretations of the configurations, the custom\n  ExampleGen can override `GenerateExamplesByBeam`.\n  """"""\n\n  @abc.abstractmethod\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for converting input source to TF examples.\n\n    Note that each input split will be transformed by this function separately.\n    For complex use case, consider override \'GenerateExamplesByBeam\' instead.\n\n    Here is an example PTransform:\n      @beam.ptransform_fn\n      @beam.typehints.with_input_types(beam.Pipeline)\n      @beam.typehints.with_output_types(tf.train.Example)\n      def ExamplePTransform(\n          pipeline: beam.Pipeline,\n          input_dict: Dict[Text, List[types.Artifact]],\n          exec_properties: Dict[Text, Any],\n          split_pattern: Text) -> beam.pvalue.PCollection\n    """"""\n    pass\n\n  def GenerateExamplesByBeam(\n      self, pipeline: beam.Pipeline, input_dict: Dict[Text,\n                                                      List[types.Artifact]],\n      exec_properties: Dict[Text, Any]) -> Dict[Text, beam.pvalue.PCollection]:\n    """"""Converts input source to TF example splits based on configs.\n\n    Custom ExampleGen executor should provide GetInputSourceToExamplePTransform\n    for converting input split to TF Examples. Overriding this\n    \'GenerateExamplesByBeam\' method instead if complex logic is need, e.g.,\n    custom spliting logic.\n\n    Args:\n      pipeline: beam pipeline.\n      input_dict: Input dict from input key to a list of Artifacts. Depends on\n        detailed example gen implementation.\n      exec_properties: A dict of execution properties. Depends on detailed\n        example gen implementation.\n        - input: JSON string of example_gen_pb2.Input instance, providing input\n          configuration.\n        - output: JSON string of example_gen_pb2.Output instance, providing\n          output configuration.\n\n    Returns:\n      Dict of beam PCollection with split name as key, each PCollection is a\n      single output split that contains serialized TF Examples.\n    """"""\n    # Get input split information.\n    input_config = example_gen_pb2.Input()\n    json_format.Parse(exec_properties[\'input_config\'], input_config)\n    # Get output split information.\n    output_config = example_gen_pb2.Output()\n    json_format.Parse(exec_properties[\'output_config\'], output_config)\n    # Get output split names.\n    split_names = utils.generate_output_split_names(input_config, output_config)\n    # Make beam_pipeline_args available in exec_properties since certain\n    # example_gen executors need this information.\n    # TODO(b/155441037): Revisit necessity of this when BigQueryExampleGen\n    # does not branch on project or runner anymore.\n    exec_properties[\'_beam_pipeline_args\'] = self._beam_pipeline_args or []\n\n    example_splits = []\n    input_to_example = self.GetInputSourceToExamplePTransform()\n    if output_config.split_config.splits:\n      # Use output splits, input must have only one split.\n      assert len(\n          input_config.splits\n      ) == 1, \'input must have only one split when output split is specified.\'\n      # Calculate split buckets.\n      buckets = []\n      total_buckets = 0\n      for split in output_config.split_config.splits:\n        total_buckets += split.hash_buckets\n        buckets.append(total_buckets)\n      example_splits = (\n          pipeline\n          | \'InputToSerializedExample\' >> _InputToSerializedExample(  # pylint: disable=no-value-for-parameter\n              input_to_example, input_dict, exec_properties,\n              input_config.splits[0].pattern)\n          | \'SplitData\' >> beam.Partition(_PartitionFn, len(buckets), buckets))\n    else:\n      # Use input splits.\n      for split in input_config.splits:\n        examples = (\n            pipeline\n            | \'InputToSerializedExample[{}]\'.format(split.name) >>\n            _InputToSerializedExample(  # pylint: disable=no-value-for-parameter\n                input_to_example, input_dict, exec_properties, split.pattern))\n        example_splits.append(examples)\n\n    result = {}\n    for index, example_split in enumerate(example_splits):\n      result[split_names[index]] = example_split\n    return result\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Take input data source and generates TF Example splits.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts. Depends on\n        detailed example gen implementation.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - examples: splits of tf examples.\n      exec_properties: A dict of execution properties. Depends on detailed\n        example gen implementation.\n        - input: JSON string of example_gen_pb2.Input instance, providing input\n          configuration.\n        - output: JSON string of example_gen_pb2.Output instance, providing\n          output configuration.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    absl.logging.info(\'Generating examples.\')\n    with self._make_beam_pipeline() as pipeline:\n      example_splits = self.GenerateExamplesByBeam(pipeline, input_dict,\n                                                   exec_properties)\n\n      # pylint: disable=expression-not-assigned, no-value-for-parameter\n      for split_name, example_split in example_splits.items():\n        (example_split\n         | \'WriteSplit[{}]\'.format(split_name) >> _WriteSplit(\n             artifact_utils.get_split_uri(output_dict[\'examples\'], split_name)))\n      # pylint: enable=expression-not-assigned, no-value-for-parameter\n\n    absl.logging.info(\'Examples generated.\')\n'"
tfx/components/example_gen/base_example_gen_executor_test.py,21,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.base_example_gen_executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\nimport apache_beam as beam\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen import base_example_gen_executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\n@beam.ptransform_fn\ndef _TestInputSourceToExamplePTransform(\n    pipeline,\n    input_dict,  # pylint: disable=unused-argument\n    exec_properties,  # pylint: disable=unused-argument\n    split_pattern):\n  mock_examples = []\n  size = 0\n  if split_pattern == \'single/*\':\n    size = 30000\n  elif split_pattern == \'train/*\':\n    size = 20000\n  elif split_pattern == \'eval/*\':\n    size = 10000\n  assert size != 0\n  for i in range(size):\n    feature = {}\n    feature[\'i\'] = tf.train.Feature() if random.randrange(\n        10) == 0 else tf.train.Feature(\n            int64_list=tf.train.Int64List(value=[i]))\n    feature[\'f\'] = tf.train.Feature() if random.randrange(\n        10) == 0 else tf.train.Feature(\n            float_list=tf.train.FloatList(value=[float(i)]))\n    feature[\'s\'] = tf.train.Feature() if random.randrange(\n        10) == 0 else tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(str(i))]))\n    example_proto = tf.train.Example(\n        features=tf.train.Features(feature=feature))\n    mock_examples.append(example_proto)\n  return pipeline | beam.Create(mock_examples)\n\n\nclass TestExampleGenExecutor(base_example_gen_executor.BaseExampleGenExecutor):\n\n  def GetInputSourceToExamplePTransform(self):\n    return _TestInputSourceToExamplePTransform\n\n\nclass BaseExampleGenExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(BaseExampleGenExecutorTest, self).setUp()\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    self._output_dict = {\'examples\': [examples]}\n\n    self._train_output_file = os.path.join(examples.uri, \'train\',\n                                           \'data_tfrecord-00000-of-00001.gz\')\n    self._eval_output_file = os.path.join(examples.uri, \'eval\',\n                                          \'data_tfrecord-00000-of-00001.gz\')\n\n  def testDoInputSplit(self):\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'train\', pattern=\'train/*\'),\n                    example_gen_pb2.Input.Split(name=\'eval\', pattern=\'eval/*\')\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(), preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    example_gen = TestExampleGenExecutor()\n    example_gen.Do({}, self._output_dict, exec_properties)\n\n    # Check example gen outputs.\n    self.assertTrue(tf.io.gfile.exists(self._train_output_file))\n    self.assertTrue(tf.io.gfile.exists(self._eval_output_file))\n    # Input train split is bigger than eval split.\n    self.assertGreater(\n        tf.io.gfile.GFile(self._train_output_file).size(),\n        tf.io.gfile.GFile(self._eval_output_file).size())\n\n  def testDoOutputSplit(self):\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'single\', pattern=\'single/*\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])))\n    }\n\n    # Run executor.\n    example_gen = TestExampleGenExecutor()\n    example_gen.Do({}, self._output_dict, exec_properties)\n\n    # Check example gen outputs.\n    self.assertTrue(tf.io.gfile.exists(self._train_output_file))\n    self.assertTrue(tf.io.gfile.exists(self._eval_output_file))\n    # Output split ratio: train:eval=2:1.\n    self.assertGreater(\n        tf.io.gfile.GFile(self._train_output_file).size(),\n        tf.io.gfile.GFile(self._eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/component.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ExampleGen component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import driver\nfrom tfx.components.example_gen import utils\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import FileBasedExampleGenSpec\nfrom tfx.types.standard_component_specs import QueryBasedExampleGenSpec\n\n\nclass _QueryBasedExampleGen(base_component.BaseComponent):\n  """"""A TFX component to ingest examples from a file system.\n\n  The _QueryBasedExampleGen component can be extended to ingest examples from\n  query based systems such as Presto or Bigquery. The component will also\n  convert the input data into\n  tf.record](https://www.tensorflow.org/tutorials/load_data/tf_records)\n  and generate train and eval example splits for downsteam components.\n\n  ## Example\n  ```\n  _query = ""SELECT * FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`""\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = BigQueryExampleGen(query=_query)\n  ```\n  """"""\n\n  SPEC_CLASS = QueryBasedExampleGenSpec\n  # EXECUTOR_SPEC should be overridden by subclasses.\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n  def __init__(self,\n               input_config: Union[example_gen_pb2.Input, Dict[Text, Any]],\n               output_config: Optional[Union[example_gen_pb2.Output,\n                                             Dict[Text, Any]]] = None,\n               custom_config: Optional[Union[example_gen_pb2.CustomConfig,\n                                             Dict[Text, Any]]] = None,\n               example_artifacts: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct an QueryBasedExampleGen component.\n\n    Args:\n      input_config: An\n        [example_gen_pb2.Input](https://github.com/tensorflow/tfx/blob/master/tfx/proto/example_gen.proto)\n          instance, providing input configuration. If any field is provided as a\n        RuntimeParameter, input_config should be constructed as a dict with the\n        same field names as Input proto message. _required_\n      output_config: An\n        [example_gen_pb2.Output](https://github.com/tensorflow/tfx/blob/master/tfx/proto/example_gen.proto)\n          instance, providing output configuration. If unset, the default splits\n        will be labeled as \'train\' and \'eval\' with a distribution ratio of 2:1.\n        If any field is provided as a RuntimeParameter, output_config should be\n        constructed as a dict with the same field names as Output proto message.\n      custom_config: An\n        [example_gen_pb2.CustomConfig](https://github.com/tensorflow/tfx/blob/master/tfx/proto/example_gen.proto)\n          instance, providing custom configuration for ExampleGen. If any field\n          is provided as a RuntimeParameter, output_config should be\n          constructed as a dict.\n      example_artifacts: Channel of `standard_artifacts.Examples` for output\n        train and eval examples.\n      instance_name: Optional unique instance name. Required only if multiple\n        ExampleGen components are declared in the same pipeline.\n    """"""\n    # Configure outputs.\n    output_config = output_config or utils.make_default_output_config(\n        input_config)\n    if not example_artifacts:\n      artifact = standard_artifacts.Examples()\n      artifact.split_names = artifact_utils.encode_split_names(\n          utils.generate_output_split_names(input_config, output_config))\n      example_artifacts = channel_utils.as_channel([artifact])\n    spec = QueryBasedExampleGenSpec(\n        input_config=input_config,\n        output_config=output_config,\n        custom_config=custom_config,\n        examples=example_artifacts)\n    super(_QueryBasedExampleGen, self).__init__(\n        spec=spec, instance_name=instance_name)\n\n\nclass FileBasedExampleGen(base_component.BaseComponent):\n  """"""A TFX component to ingest examples from a file system.\n\n  The FileBasedExampleGen component is an API for getting file-based records\n  into TFX pipelines. It consumes external files to generate examples which will\n  be used by other internal components like StatisticsGen or Trainers.  The\n  component will also convert the input data into\n  [tf.record](https://www.tensorflow.org/tutorials/load_data/tf_records)\n  and generate train and eval example splits for downsteam components.\n\n  ## Example\n  ```\n  from tfx.utils.dsl_utils import external_input\n\n  _taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n  _data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = FileBasedExampleGen(input=external_input(_data_root))\n  ```\n  """"""\n\n  SPEC_CLASS = FileBasedExampleGenSpec\n  # EXECUTOR_SPEC should be overridden by subclasses.\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n  DRIVER_CLASS = driver.Driver\n\n  def __init__(\n      self,\n      input: types.Channel = None,  # pylint: disable=redefined-builtin\n      input_config: Optional[Union[example_gen_pb2.Input, Dict[Text,\n                                                               Any]]] = None,\n      output_config: Optional[Union[example_gen_pb2.Output, Dict[Text,\n                                                                 Any]]] = None,\n      custom_config: Optional[Union[example_gen_pb2.CustomConfig,\n                                    Dict[Text, Any]]] = None,\n      example_artifacts: Optional[types.Channel] = None,\n      custom_executor_spec: Optional[executor_spec.ExecutorSpec] = None,\n      input_base: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a FileBasedExampleGen component.\n\n    Args:\n      input: A Channel of type `standard_artifacts.ExternalArtifact`, which\n        includes one artifact whose uri is an external directory containing the\n        data files. _required_\n      input_config: An\n        [`example_gen_pb2.Input`](https://github.com/tensorflow/tfx/blob/master/tfx/proto/example_gen.proto)\n          instance, providing input configuration. If unset, the files under\n          input_base will be treated as a single dataset.\n      output_config: An example_gen_pb2.Output instance, providing the output\n        configuration. If unset, default splits will be \'train\' and\n        \'eval\' with size 2:1.\n      custom_config: An optional example_gen_pb2.CustomConfig instance,\n        providing custom configuration for executor.\n      example_artifacts: Channel of \'ExamplesPath\' for output train and eval\n        examples.\n      custom_executor_spec: Optional custom executor spec overriding the default\n        executor spec specified in the component attribute.\n      input_base: Backwards compatibility alias for the \'input\' argument.\n      instance_name: Optional unique instance name. Required only if multiple\n        ExampleGen components are declared in the same pipeline.  Either\n        `input_base` or `input` must be present in the input arguments.\n    """"""\n    if input_base:\n      absl.logging.warning(\n          \'The ""input_base"" argument to the ExampleGen component has \'\n          \'been renamed to ""input"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      input = input_base\n    # Configure inputs and outputs.\n    input_config = input_config or utils.make_default_input_config()\n    output_config = output_config or utils.make_default_output_config(\n        input_config)\n    if not example_artifacts:\n      artifact = standard_artifacts.Examples()\n      artifact.split_names = artifact_utils.encode_split_names(\n          utils.generate_output_split_names(input_config, output_config))\n      example_artifacts = channel_utils.as_channel([artifact])\n    spec = FileBasedExampleGenSpec(\n        input=input,\n        input_config=input_config,\n        output_config=output_config,\n        custom_config=custom_config,\n        examples=example_artifacts)\n    super(FileBasedExampleGen, self).__init__(\n        spec=spec,\n        custom_executor_spec=custom_executor_spec,\n        instance_name=instance_name)\n'"
tfx/components/example_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom google.protobuf import any_pb2\nfrom google.protobuf import json_format\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import base_example_gen_executor\nfrom tfx.components.example_gen import component\nfrom tfx.components.example_gen import driver\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass TestExampleGenExecutor(base_example_gen_executor.BaseExampleGenExecutor):\n\n  def GetInputSourceToExamplePTransform(self):\n    pass\n\n\nclass TestQueryBasedExampleGenComponent(component._QueryBasedExampleGen):\n\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(TestExampleGenExecutor)\n\n  def __init__(self,\n               input_config,\n               output_config=None,\n               example_artifacts=None,\n               instance_name=None):\n    super(TestQueryBasedExampleGenComponent, self).__init__(\n        input_config=input_config,\n        output_config=output_config,\n        example_artifacts=example_artifacts,\n        instance_name=instance_name)\n\n\nclass TestFileBasedExampleGenComponent(component.FileBasedExampleGen):\n\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(TestExampleGenExecutor)\n\n  def __init__(\n      self,\n      input,  # pylint: disable=redefined-builtin\n      input_config=None,\n      output_config=None,\n      example_artifacts=None,\n      instance_name=None):\n    super(TestFileBasedExampleGenComponent, self).__init__(\n        input=input,\n        input_config=input_config,\n        output_config=output_config,\n        example_artifacts=example_artifacts,\n        instance_name=instance_name)\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstructSubclassQueryBased(self):\n    example_gen = TestQueryBasedExampleGenComponent(\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'single\', pattern=\'query\'),\n        ]))\n    self.assertEqual({}, example_gen.inputs.get_all())\n    self.assertEqual(base_driver.BaseDriver, example_gen.driver_class)\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     example_gen.outputs[\'examples\'].type_name)\n    self.assertIsNone(example_gen.exec_properties.get(\'custom_config\'))\n    artifact_collection = example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructSubclassFileBased(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    example_gen = TestFileBasedExampleGenComponent(\n        input=channel_utils.as_channel([input_base]))\n    self.assertIn(\'input\', example_gen.inputs.get_all())\n    self.assertEqual(driver.Driver, example_gen.driver_class)\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     example_gen.outputs[\'examples\'].type_name)\n    self.assertIsNone(example_gen.exec_properties.get(\'custom_config\'))\n    artifact_collection = example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructCustomExecutor(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    example_gen = component.FileBasedExampleGen(\n        input=channel_utils.as_channel([input_base]),\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            TestExampleGenExecutor))\n    self.assertEqual(driver.Driver, example_gen.driver_class)\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithOutputConfig(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    example_gen = TestFileBasedExampleGenComponent(\n        input=channel_utils.as_channel([input_base]),\n        output_config=example_gen_pb2.Output(\n            split_config=example_gen_pb2.SplitConfig(splits=[\n                example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n                example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1),\n                example_gen_pb2.SplitConfig.Split(name=\'test\', hash_buckets=1)\n            ])))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithInputConfig(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    example_gen = TestFileBasedExampleGenComponent(\n        input=channel_utils.as_channel([input_base]),\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'train\', pattern=\'train/*\'),\n            example_gen_pb2.Input.Split(name=\'eval\', pattern=\'eval/*\'),\n            example_gen_pb2.Input.Split(name=\'test\', pattern=\'test/*\')\n        ]))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithCustomConfig(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    custom_config = example_gen_pb2.CustomConfig(custom_config=any_pb2.Any())\n    example_gen = component.FileBasedExampleGen(\n        input=channel_utils.as_channel([input_base]),\n        custom_config=custom_config,\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            TestExampleGenExecutor))\n\n    stored_custom_config = example_gen_pb2.CustomConfig()\n    json_format.Parse(example_gen.exec_properties[\'custom_config\'],\n                      stored_custom_config)\n    self.assertEqual(custom_config, stored_custom_config)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/driver.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX ExampleGen custom driver.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text\n\nimport absl\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.base import base_driver\nfrom tfx.components.example_gen import utils\nfrom tfx.orchestration import data_types\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import channel_utils\n\n\nclass Driver(base_driver.BaseDriver):\n  """"""Custom driver for ExampleGen.\n\n  This driver supports file based ExampleGen, it registers external file path as\n  an artifact, e.g., for CsvExampleGen and ImportExampleGen.\n  """"""\n\n  def resolve_input_artifacts(\n      self,\n      input_channels: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n  ) -> Dict[Text, List[types.Artifact]]:\n    """"""Overrides BaseDriver.resolve_input_artifacts().""""""\n    del driver_args  # unused\n    del pipeline_info  # unused\n\n    input_config = example_gen_pb2.Input()\n    json_format.Parse(exec_properties[\'input_config\'], input_config)\n\n    input_dict = channel_utils.unwrap_channel_dict(input_channels)\n    for input_list in input_dict.values():\n      for single_input in input_list:\n        absl.logging.debug(\'Processing input %s.\' % single_input.uri)\n        absl.logging.debug(\'single_input %s.\' % single_input)\n        absl.logging.debug(\'single_input.mlmd_artifact %s.\' %\n                           single_input.mlmd_artifact)\n\n        # Set the fingerprint of input.\n        fingerprint, select_span = utils.calculate_splits_fingerprint_and_span(\n            single_input.uri, input_config.splits)\n        single_input.set_string_custom_property(utils.FINGERPRINT_PROPERTY_NAME,\n                                                fingerprint)\n        single_input.set_string_custom_property(utils.SPAN_PROPERTY_NAME,\n                                                select_span)\n\n        matched_artifacts = []\n        for artifact in self._metadata_handler.get_artifacts_by_uri(\n            single_input.uri):\n          if (artifact.custom_properties[utils.FINGERPRINT_PROPERTY_NAME]\n              .string_value == fingerprint) and (artifact.custom_properties[\n                  utils.SPAN_PROPERTY_NAME].string_value == select_span):\n            matched_artifacts.append(artifact)\n\n        if matched_artifacts:\n          # TODO(b/138845899): consider use span instead of id.\n          # If there are multiple matches, get the latest one for caching.\n          # Using id because spans are the same for matched artifacts.\n          latest_artifact = max(\n              matched_artifacts, key=lambda artifact: artifact.id)\n          absl.logging.debug(\'latest_artifact %s.\' % (latest_artifact))\n          absl.logging.debug(\'type(latest_artifact) %s.\' %\n                             type(latest_artifact))\n\n          single_input.set_mlmd_artifact(latest_artifact)\n        else:\n          # TODO(jyzhao): whether driver should be read-only for metadata.\n          self._metadata_handler.publish_artifacts([single_input])\n          absl.logging.debug(\'Registered new input: %s\' % single_input)\n\n    exec_properties[\'input_config\'] = json_format.MessageToJson(\n        input_config, sort_keys=True, preserving_proto_field_name=True)\n    return input_dict\n'"
tfx/components/example_gen/driver_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.driver.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.example_gen import driver\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import io_utils\n\n\nclass DriverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(DriverTest, self).setUp()\n    # Create input splits.\n    test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._input_base_path = os.path.join(test_dir, \'input_base\')\n    tf.io.gfile.makedirs(self._input_base_path)\n\n    # Mock metadata.\n    self._mock_metadata = tf.compat.v1.test.mock.Mock()\n    self._example_gen_driver = driver.Driver(self._mock_metadata)\n\n    # Create input dict.\n    input_base = standard_artifacts.ExternalArtifact()\n    input_base.uri = self._input_base_path\n    self._input_channels = {\n        \'input_base\': channel_utils.as_channel([input_base])\n    }\n    # Create exec proterties.\n    self._exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'s1\', pattern=\'span{SPAN}/split1/*\'),\n                    example_gen_pb2.Input.Split(\n                        name=\'s2\', pattern=\'span{SPAN}/split2/*\')\n                ]),\n                preserving_proto_field_name=True),\n    }\n\n  def testResolveInputArtifacts(self):\n    # Create input splits.\n    split1 = os.path.join(self._input_base_path, \'split1\', \'data\')\n    io_utils.write_string_file(split1, \'testing\')\n    os.utime(split1, (0, 1))\n    split2 = os.path.join(self._input_base_path, \'split2\', \'data\')\n    io_utils.write_string_file(split2, \'testing2\')\n    os.utime(split2, (0, 3))\n\n    # Mock artifact.\n    artifacts = []\n    for i in [4, 3, 2, 1]:\n      artifact = metadata_store_pb2.Artifact()\n      artifact.id = i\n      artifact.uri = self._input_base_path\n      artifact.custom_properties[\'span\'].string_value = \'0\'\n      # Only odd ids will be matched\n      if i % 2 == 1:\n        artifact.custom_properties[\n            \'input_fingerprint\'].string_value = \'split:s1,num_files:1,total_bytes:7,xor_checksum:1,sum_checksum:1\\nsplit:s2,num_files:1,total_bytes:8,xor_checksum:3,sum_checksum:3\'\n      else:\n        artifact.custom_properties[\n            \'input_fingerprint\'].string_value = \'not_match\'\n      artifacts.append(artifact)\n\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(name=\'s1\', pattern=\'split1/*\'),\n                    example_gen_pb2.Input.Split(name=\'s2\', pattern=\'split2/*\')\n                ]),\n                preserving_proto_field_name=True),\n    }\n\n    # Cache not hit.\n    self._mock_metadata.get_artifacts_by_uri.return_value = [artifacts[0]]\n    self._mock_metadata.publish_artifacts.return_value = [artifacts[3]]\n    updated_input_dict = self._example_gen_driver.resolve_input_artifacts(\n        self._input_channels, exec_properties, None, None)\n    self.assertEqual(1, len(updated_input_dict))\n    self.assertEqual(1, len(updated_input_dict[\'input_base\']))\n    updated_input_base = updated_input_dict[\'input_base\'][0]\n    self.assertEqual(self._input_base_path, updated_input_base.uri)\n\n    # Cache hit.\n    self._mock_metadata.get_artifacts_by_uri.return_value = artifacts\n    self._mock_metadata.publish_artifacts.return_value = []\n    updated_input_dict = self._example_gen_driver.resolve_input_artifacts(\n        self._input_channels, exec_properties, None, None)\n    self.assertEqual(1, len(updated_input_dict))\n    self.assertEqual(1, len(updated_input_dict[\'input_base\']))\n    updated_input_base = updated_input_dict[\'input_base\'][0]\n    self.assertEqual(3, updated_input_base.id)\n    self.assertEqual(self._input_base_path, updated_input_base.uri)\n\n  def testResolveInputArtifactsWithSpan(self):\n    # Test align of span number.\n    span1_split1 = os.path.join(self._input_base_path, \'span01\', \'split1\',\n                                \'data\')\n    io_utils.write_string_file(span1_split1, \'testing11\')\n    span1_split2 = os.path.join(self._input_base_path, \'span01\', \'split2\',\n                                \'data\')\n    io_utils.write_string_file(span1_split2, \'testing12\')\n    span2_split1 = os.path.join(self._input_base_path, \'span02\', \'split1\',\n                                \'data\')\n    io_utils.write_string_file(span2_split1, \'testing21\')\n\n    with self.assertRaisesRegexp(\n        ValueError, \'Latest span should be the same for each split\'):\n      self._example_gen_driver.resolve_input_artifacts(self._input_channels,\n                                                       self._exec_properties,\n                                                       None, None)\n\n    # Test if latest span is selected when span aligns for each split.\n    span2_split2 = os.path.join(self._input_base_path, \'span02\', \'split2\',\n                                \'data\')\n    io_utils.write_string_file(span2_split2, \'testing22\')\n\n    self._mock_metadata.get_artifacts_by_uri.return_value = []\n    self._mock_metadata.publish_artifacts.return_value = [\n        metadata_store_pb2.Artifact()\n    ]\n    self._example_gen_driver.resolve_input_artifacts(self._input_channels,\n                                                     self._exec_properties,\n                                                     None, None)\n    updated_input_config = example_gen_pb2.Input()\n    json_format.Parse(self._exec_properties[\'input_config\'],\n                      updated_input_config)\n    # Check if latest span is selected.\n    self.assertProtoEquals(\n        """"""\n        splits {\n          name: ""s1""\n          pattern: ""span02/split1/*""\n        }\n        splits {\n          name: ""s2""\n          pattern: ""span02/split2/*""\n        }"""""", updated_input_config)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/utils.py,17,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for ExampleGen components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nfrom typing import Any, Dict, Iterable, List, Text, Tuple, Union\n\nimport absl\nimport six\nimport tensorflow as tf\n\nfrom tfx.proto import example_gen_pb2\nfrom tfx.utils import io_utils\nfrom google.protobuf import json_format\n\n# Fingerprint custom property.\nFINGERPRINT_PROPERTY_NAME = \'input_fingerprint\'\n# Span custom property.\nSPAN_PROPERTY_NAME = \'span\'\n# Span spec used in split pattern.\nSPAN_SPEC = \'{SPAN}\'\n\n_DEFAULT_ENCODING = \'utf-8\'\n\n\ndef dict_to_example(instance: Dict[Text, Any]) -> tf.train.Example:\n  """"""Converts dict to tf example.""""""\n  feature = {}\n  for key, value in instance.items():\n    # TODO(jyzhao): support more types.\n    if value is None:\n      feature[key] = tf.train.Feature()\n    elif isinstance(value, six.integer_types):\n      feature[key] = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[value]))\n    elif isinstance(value, float):\n      feature[key] = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[value]))\n    elif isinstance(value, six.text_type) or isinstance(value, str):\n      feature[key] = tf.train.Feature(\n          bytes_list=tf.train.BytesList(\n              value=[value.encode(_DEFAULT_ENCODING)]))\n    elif isinstance(value, list):\n      if not value:\n        feature[key] = tf.train.Feature()\n      elif isinstance(value[0], six.integer_types):\n        feature[key] = tf.train.Feature(\n            int64_list=tf.train.Int64List(value=value))\n      elif isinstance(value[0], float):\n        feature[key] = tf.train.Feature(\n            float_list=tf.train.FloatList(value=value))\n      elif isinstance(value[0], six.text_type) or isinstance(value[0], str):\n        feature[key] = tf.train.Feature(\n            bytes_list=tf.train.BytesList(\n                value=[v.encode(_DEFAULT_ENCODING) for v in value]))\n      else:\n        raise RuntimeError(\'Column type `list of {}` is not supported.\'.format(\n            type(value[0])))\n    else:\n      raise RuntimeError(\'Column type {} is not supported.\'.format(type(value)))\n  return tf.train.Example(features=tf.train.Features(feature=feature))\n\n\ndef generate_output_split_names(\n    input_config: Union[example_gen_pb2.Input, Dict[Text, Any]],\n    output_config: Union[example_gen_pb2.Output, Dict[Text,\n                                                      Any]]) -> List[Text]:\n  """"""Return output split name based on input and output config.\n\n  Return output split name if it\'s specified and input only contains one split,\n  otherwise output split will be same as input.\n\n  Args:\n    input_config: example_gen_pb2.Input instance. If any field is provided as a\n      RuntimeParameter, input_config should be constructed as a dict with the\n      same field names as Input proto message.\n    output_config: example_gen_pb2.Output instance. If any field is provided as\n      a RuntimeParameter, output_config should be constructed as a dict with the\n      same field names as Output proto message.\n\n  Returns:\n    List of split names.\n\n  Raises:\n    RuntimeError: if configs are not valid, including:\n      - Missing field.\n      - Duplicated split.\n      - Output split is specified while input has more than one split.\n      - Missing train and eval split.\n  """"""\n  result = []\n  # Convert proto to dict for easy sanity check. Otherwise we need to branch the\n  # logic based on parameter types.\n  if isinstance(output_config, example_gen_pb2.Output):\n    output_config = json_format.MessageToDict(\n        output_config,\n        including_default_value_fields=True,\n        preserving_proto_field_name=True)\n  if isinstance(input_config, example_gen_pb2.Input):\n    input_config = json_format.MessageToDict(\n        input_config,\n        including_default_value_fields=True,\n        preserving_proto_field_name=True)\n\n  if \'split_config\' in output_config and \'splits\' in output_config[\n      \'split_config\']:\n    if \'splits\' not in input_config:\n      raise RuntimeError(\n          \'ExampleGen instance specified output splits but no input split \'\n          \'is specified.\')\n    if len(input_config[\'splits\']) != 1:\n      # If output is specified, then there should only be one input split.\n      raise RuntimeError(\n          \'ExampleGen instance specified output splits but at the same time \'\n          \'input has more than one split.\')\n    for split in output_config[\'split_config\'][\'splits\']:\n      if not split[\'name\'] or (isinstance(split[\'hash_buckets\'], int) and\n                               split[\'hash_buckets\'] <= 0):\n        raise RuntimeError(\'Str-typed output split name and int-typed \'\n                           \'hash buckets are required.\')\n      result.append(split[\'name\'])\n  else:\n    # If output is not specified, it will have the same split as the input.\n    if \'splits\' in input_config:\n      for split in input_config[\'splits\']:\n        if not split[\'name\'] or not split[\'pattern\']:\n          raise RuntimeError(\'Str-typed input split name and pattern \'\n                             \'are required.\')\n        result.append(split[\'name\'])\n\n  if not result:\n    raise RuntimeError(\'ExampleGen splits are missing.\')\n  if len(result) != len(set(result)):\n    raise RuntimeError(\'Duplicated split name {}.\'.format(result))\n\n  return result\n\n\ndef make_default_input_config(\n    split_pattern: Text = \'*\') -> example_gen_pb2.Input:\n  """"""Returns default input config.""""""\n  # Treats input base dir as a single split.\n  return example_gen_pb2.Input(splits=[\n      example_gen_pb2.Input.Split(name=\'single_split\', pattern=split_pattern)\n  ])\n\n\ndef make_default_output_config(\n    input_config: Union[example_gen_pb2.Input, Dict[Text, Any]]\n) -> example_gen_pb2.Output:\n  """"""Returns default output config based on input config.""""""\n  if isinstance(input_config, example_gen_pb2.Input):\n    input_config = json_format.MessageToDict(\n        input_config,\n        including_default_value_fields=True,\n        preserving_proto_field_name=True)\n\n  if len(input_config[\'splits\']) > 1:\n    # Returns empty output split config as output split will be same as input.\n    return example_gen_pb2.Output()\n  else:\n    # Returns \'train\' and \'eval\' splits with size 2:1.\n    return example_gen_pb2.Output(\n        split_config=example_gen_pb2.SplitConfig(splits=[\n            example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n            example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1)\n        ]))\n\n\ndef _glob_to_regex(glob_pattern: Text) -> Text:\n  """"""Changes glob pattern to regex pattern.""""""\n  regex_pattern = glob_pattern\n  regex_pattern = regex_pattern.replace(\'.\', \'\\\\.\')\n  regex_pattern = regex_pattern.replace(\'+\', \'\\\\+\')\n  regex_pattern = regex_pattern.replace(\'*\', \'[^/]*\')\n  regex_pattern = regex_pattern.replace(\'?\', \'[^/]\')\n  regex_pattern = regex_pattern.replace(\'(\', \'\\\\(\')\n  regex_pattern = regex_pattern.replace(\')\', \'\\\\)\')\n  return regex_pattern\n\n\ndef _retrieve_latest_span(uri: Text,\n                          split: example_gen_pb2.Input.Split) -> Text:\n  """"""Retrieves the most recently updated span matching a given split pattern.""""""\n  split_pattern = os.path.join(uri, split.pattern)\n  if split_pattern.count(SPAN_SPEC) != 1:\n    raise ValueError(\'Only one {SPAN} is allowed in %s\' % split_pattern)\n\n  split_glob_pattern = split_pattern.replace(SPAN_SPEC, \'*\')\n  absl.logging.info(\'Glob pattern for split %s: %s\' %\n                    (split.name, split_glob_pattern))\n  split_regex_pattern = _glob_to_regex(split_pattern).replace(SPAN_SPEC, \'(.*)\')\n  absl.logging.info(\'Regex pattern for split %s: %s\' %\n                    (split.name, split_regex_pattern))\n  if re.compile(split_regex_pattern).groups != 1:\n    raise ValueError(\'Regex should have only one group\')\n\n  files = tf.io.gfile.glob(split_glob_pattern)\n  latest_span = None\n  for file_path in files:\n    result = re.search(split_regex_pattern, file_path)\n    if result is None:\n      raise ValueError(\'Glob pattern does not match regex pattern\')\n    try:\n      span = int(result.group(1))\n    except ValueError:\n      raise ValueError(\'Cannot not find span number from %s based on %s\' %\n                       (file_path, split_regex_pattern))\n    if latest_span is None or span >= int(latest_span):\n      # Uses str instead of int because of zero padding digits.\n      latest_span = result.group(1)\n\n  if latest_span is None:\n    raise ValueError(\'Cannot not find matching for split %s based on %s\' %\n                     (split.name, split.pattern))\n  return latest_span\n\n\ndef calculate_splits_fingerprint_and_span(\n    input_base_uri: Text,\n    splits: Iterable[example_gen_pb2.Input.Split]) -> Tuple[Text, Any]:\n  """"""Calculates the fingerprint of files in a URI matching split patterns.\n\n  If a pattern has the {SPAN} placeholder, attempts to find an identical value\n  across splits that results in all splits having the most recently updated\n  files.\n\n  Args:\n    input_base_uri: The base path from which files will be searched\n    splits: An iterable collection of example_gen_pb2.Input.Split objects\n\n  Returns:\n    A Tuple of [fingerprint, select_span], where select_span is either\n    the value matched with the {SPAN} placeholder, or None if the placeholder\n    wasn\'t specified.\n  """"""\n\n  split_fingerprints = []\n  select_span = None\n  # Calculate the fingerprint of files under input_base_uri.\n  for split in splits:\n    absl.logging.info(\'select span = %s\' % select_span)\n    if SPAN_SPEC in split.pattern:\n      latest_span = _retrieve_latest_span(input_base_uri, split)\n      absl.logging.info(\'latest span = %s\' % latest_span)\n      if select_span is None:\n        select_span = latest_span\n      if select_span != latest_span:\n        raise ValueError(\n            \'Latest span should be the same for each split: %s != %s\' %\n            (select_span, latest_span))\n      split.pattern = split.pattern.replace(SPAN_SPEC, select_span)\n    if select_span is None:\n      select_span = \'0\'\n    # Calculate fingerprint\n    pattern = os.path.join(input_base_uri, split.pattern)\n    fingerprint = io_utils.generate_fingerprint(split.name, pattern)\n    split_fingerprints.append(fingerprint)\n  fingerprint = \'\\n\'.join(split_fingerprints)\n  return fingerprint, select_span\n'"
tfx/components/example_gen/utils_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nfrom typing import Text\n# Standard Imports\n\nimport tensorflow as tf\n\nfrom tfx.components.example_gen import utils\nfrom tfx.orchestration import data_types\nfrom tfx.proto import example_gen_pb2\nfrom tfx.utils import io_utils\nfrom tfx.utils import json_utils\n\n\nclass UtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(UtilsTest, self).setUp()\n    # Create input splits.\n    test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._input_base_path = os.path.join(test_dir, \'input_base\')\n    tf.io.gfile.makedirs(self._input_base_path)\n\n  def testDictToExample(self):\n    instance_dict = {\n        \'int\': 10,\n        \'float\': 5.0,\n        \'str\': \'abc\',\n        \'int_list\': [1, 2],\n        \'float_list\': [3.0],\n        \'str_list\': [\'ab\', \'cd\'],\n        \'none\': None,\n        \'empty_list\': [],\n    }\n    example = utils.dict_to_example(instance_dict)\n    self.assertProtoEquals(\n        """"""\n        features {\n          feature {\n            key: ""empty_list""\n            value {\n            }\n          }\n          feature {\n            key: ""float""\n            value {\n              float_list {\n                value: 5.0\n              }\n            }\n          }\n          feature {\n            key: ""float_list""\n            value {\n              float_list {\n                value: 3.0\n              }\n            }\n          }\n          feature {\n            key: ""int""\n            value {\n              int64_list {\n                value: 10\n              }\n            }\n          }\n          feature {\n            key: ""int_list""\n            value {\n              int64_list {\n                value: 1\n                value: 2\n              }\n            }\n          }\n          feature {\n            key: ""none""\n            value {\n            }\n          }\n          feature {\n            key: ""str""\n            value {\n              bytes_list {\n                value: ""abc""\n              }\n            }\n          }\n          feature {\n            key: ""str_list""\n            value {\n              bytes_list {\n                value: ""ab""\n                value: ""cd""\n              }\n            }\n          }\n        }\n        """""", example)\n\n  def testMakeOutputSplitNames(self):\n    split_names = utils.generate_output_split_names(\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'train\', pattern=\'train/*\'),\n            example_gen_pb2.Input.Split(name=\'eval\', pattern=\'eval/*\')\n        ]),\n        output_config=example_gen_pb2.Output())\n    self.assertListEqual([\'train\', \'eval\'], split_names)\n\n    split_names = utils.generate_output_split_names(\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'single\', pattern=\'single/*\')\n        ]),\n        output_config=example_gen_pb2.Output(\n            split_config=example_gen_pb2.SplitConfig(splits=[\n                example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n                example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1)\n            ])))\n    self.assertListEqual([\'train\', \'eval\'], split_names)\n\n  def testMakeDefaultOutputConfig(self):\n    output_config = utils.make_default_output_config(\n        utils.make_default_input_config())\n    self.assertEqual(2, len(output_config.split_config.splits))\n\n    output_config = utils.make_default_output_config(\n        example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'train\', pattern=\'train/*\'),\n            example_gen_pb2.Input.Split(name=\'eval\', pattern=\'eval/*\')\n        ]))\n    self.assertEqual(0, len(output_config.split_config.splits))\n\n  def testMakeOutputSplitNamesWithParameter(self):\n    split_name_param = data_types.RuntimeParameter(\n        name=\'split-name\', ptype=Text, default=u\'train\')\n    split_names = utils.generate_output_split_names(\n        input_config={\n            \'splits\': [{\n                \'name\': split_name_param,\n                \'pattern\': \'train/*\'\n            }, {\n                \'name\': \'eval\',\n                \'pattern\': \'eval/*\'\n            }]\n        },\n        output_config=example_gen_pb2.Output())\n    # Assert the json serialized version because RuntimeParameters only get\n    # serialized after that.\n    self.assertEqual(\n        json_utils.dumps([split_name_param, \'eval\']),\n        json_utils.dumps(split_names))\n\n    split_names = utils.generate_output_split_names(\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'single\', pattern=\'single/*\')\n        ]),\n        output_config={\n            \'split_config\': {\n                \'splits\': [{\n                    \'name\': split_name_param,\n                    \'hash_buckets\': 2\n                }, {\n                    \'name\': \'eval\',\n                    \'hash_buckets\': 1\n                }]\n            }\n        })\n    # Assert the json serialized version because RuntimeParameters only get\n    # serialized after that.\n    self.assertEqual(\n        json_utils.dumps([split_name_param, \'eval\']),\n        json_utils.dumps(split_names))\n\n  def testMakeDefaultOutputConfigWithParameter(self):\n    split_name_param = data_types.RuntimeParameter(\n        name=\'split-name\', ptype=Text, default=u\'train\')\n    output_config = utils.make_default_output_config({\n        \'splits\': [{\n            \'name\': split_name_param,\n            \'pattern\': \'train/*\'\n        }, {\n            \'name\': \'eval\',\n            \'pattern\': \'eval/*\'\n        }]\n    })\n    self.assertEqual(0, len(output_config.split_config.splits))\n\n  def testGlobToRegex(self):\n    glob_pattern = \'a(b)c\'\n    self.assertEqual(1, re.compile(glob_pattern).groups)\n    regex_pattern = utils._glob_to_regex(glob_pattern)\n    self.assertEqual(0, re.compile(regex_pattern).groups)\n    self.assertEqual(glob_pattern,\n                     re.match(regex_pattern, glob_pattern).group())\n\n  def testCalculateSplitsFingerprint(self):\n    split1 = os.path.join(self._input_base_path, \'split1\', \'data\')\n    io_utils.write_string_file(split1, \'testing\')\n    os.utime(split1, (0, 1))\n    split2 = os.path.join(self._input_base_path, \'split2\', \'data\')\n    io_utils.write_string_file(split2, \'testing2\')\n    os.utime(split2, (0, 3))\n\n    splits = [\n        example_gen_pb2.Input.Split(name=\'s1\', pattern=\'split1/*\'),\n        example_gen_pb2.Input.Split(name=\'s2\', pattern=\'split2/*\')\n    ]\n    fingerprint, span = utils.calculate_splits_fingerprint_and_span(\n        self._input_base_path, splits)\n    self.assertEqual(\n        fingerprint,\n        \'split:s1,num_files:1,total_bytes:7,xor_checksum:1,sum_checksum:1\\n\'\n        \'split:s2,num_files:1,total_bytes:8,xor_checksum:3,sum_checksum:3\')\n    self.assertEqual(span, \'0\')\n\n  def testSpanNoMatching(self):\n    splits = [\n        example_gen_pb2.Input.Split(name=\'s1\', pattern=\'span{SPAN}/split1/*\'),\n        example_gen_pb2.Input.Split(name=\'s2\', pattern=\'span{SPAN}/split2/*\')\n    ]\n    with self.assertRaisesRegexp(ValueError,\n                                 \'Cannot not find matching for split\'):\n      utils.calculate_splits_fingerprint_and_span(self._input_base_path, splits)\n\n  def testSpanWrongFormat(self):\n    wrong_span = os.path.join(self._input_base_path, \'spanx\', \'split1\', \'data\')\n    io_utils.write_string_file(wrong_span, \'testing_wrong_span\')\n\n    splits = [\n        example_gen_pb2.Input.Split(name=\'s1\', pattern=\'span{SPAN}/split1/*\'),\n        example_gen_pb2.Input.Split(name=\'s2\', pattern=\'span{SPAN}/split2/*\')\n    ]\n    with self.assertRaisesRegexp(ValueError, \'Cannot not find span number\'):\n      utils.calculate_splits_fingerprint_and_span(self._input_base_path, splits)\n\n  def testSpanMatches(self):\n    # Test align of span number.\n    span1_split1 = os.path.join(self._input_base_path, \'span01\', \'split1\',\n                                \'data\')\n    io_utils.write_string_file(span1_split1, \'testing11\')\n    span1_split2 = os.path.join(self._input_base_path, \'span01\', \'split2\',\n                                \'data\')\n    io_utils.write_string_file(span1_split2, \'testing12\')\n    span2_split1 = os.path.join(self._input_base_path, \'span02\', \'split1\',\n                                \'data\')\n    io_utils.write_string_file(span2_split1, \'testing21\')\n\n    splits = [\n        example_gen_pb2.Input.Split(name=\'s1\', pattern=\'span{SPAN}/split1/*\'),\n        example_gen_pb2.Input.Split(name=\'s2\', pattern=\'span{SPAN}/split2/*\')\n    ]\n    with self.assertRaisesRegexp(\n        ValueError, \'Latest span should be the same for each split\'):\n      utils.calculate_splits_fingerprint_and_span(self._input_base_path, splits)\n\n    # Test if latest span is selected when span aligns for each split.\n    span2_split2 = os.path.join(self._input_base_path, \'span02\', \'split2\',\n                                \'data\')\n    io_utils.write_string_file(span2_split2, \'testing22\')\n\n    splits = [\n        example_gen_pb2.Input.Split(name=\'s1\', pattern=\'span{SPAN}/split1/*\'),\n        example_gen_pb2.Input.Split(name=\'s2\', pattern=\'span{SPAN}/split2/*\')\n    ]\n    _, span = utils.calculate_splits_fingerprint_and_span(\n        self._input_base_path, splits)\n    self.assertEqual(span, \'02\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_validator/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_validator/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ExampleValidator component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_validator import executor\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import ExampleValidatorSpec\n\n\nclass ExampleValidator(base_component.BaseComponent):\n  """"""A TFX component to validate input examples.\n\n  The ExampleValidator component uses [Tensorflow Data\n  Validation](https://www.tensorflow.org/tfx/data_validation) to\n  validate the statistics of some splits on input examples against a schema.\n\n  The ExampleValidator component identifies anomalies in training and serving\n  data. The component can be configured to detect different classes of anomalies\n  in the data. It can:\n    - perform validity checks by comparing data statistics against a schema that\n      codifies expectations of the user.\n    - detect data drift by looking at a series of data.\n    - detect changes in dataset-wide data (i.e., num_examples) across spans or\n      versions.\n\n  Schema Based Example Validation\n  The ExampleValidator component identifies any anomalies in the example data by\n  comparing data statistics computed by the StatisticsGen component against a\n  schema. The schema codifies properties which the input data is expected to\n  satisfy, and is provided and maintained by the user.\n\n  Please see https://www.tensorflow.org/tfx/data_validation for more details.\n\n  ## Example\n  ```\n  # Performs anomaly detection based on statistics and data schema.\n  validate_stats = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=infer_schema.outputs[\'schema\'])\n  ```\n  """"""\n\n  SPEC_CLASS = ExampleValidatorSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               statistics: types.Channel = None,\n               schema: types.Channel = None,\n               output: Optional[types.Channel] = None,\n               stats: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct an ExampleValidator component.\n\n    Args:\n      statistics: A Channel of type `standard_artifacts.ExampleStatistics`. This\n        should contain at least \'eval\' split. Other splits are currently\n        ignored.\n      schema: A Channel of type `standard_artifacts.Schema`. _required_\n      output: Output channel of type `standard_artifacts.ExampleAnomalies`.\n      stats: Backwards compatibility alias for the \'statistics\' argument.\n      instance_name: Optional name assigned to this specific instance of\n        ExampleValidator. Required only if multiple ExampleValidator components\n        are declared in the same pipeline.  Either `stats` or `statistics` must\n        be present in the arguments.\n    """"""\n    if stats:\n      absl.logging.warning(\n          \'The ""stats"" argument to the StatisticsGen component has \'\n          \'been renamed to ""statistics"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      statistics = stats\n    anomalies = output or types.Channel(\n        type=standard_artifacts.ExampleAnomalies,\n        artifacts=[standard_artifacts.ExampleAnomalies()])\n    spec = ExampleValidatorSpec(\n        statistics=statistics, schema=schema, anomalies=anomalies)\n    super(ExampleValidator, self).__init__(\n        spec=spec, instance_name=instance_name)\n'"
tfx/components/example_validator/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_validator.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.example_validator import component\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExampleValidatorTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    statistics_artifact = standard_artifacts.ExampleStatistics()\n    statistics_artifact.split_names = artifact_utils.encode_split_names(\n        [\'eval\'])\n    example_validator = component.ExampleValidator(\n        statistics=channel_utils.as_channel([statistics_artifact]),\n        schema=channel_utils.as_channel([standard_artifacts.Schema()]),\n    )\n    self.assertEqual(standard_artifacts.ExampleAnomalies.TYPE_NAME,\n                     example_validator.outputs[\'anomalies\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_validator/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX example_validator executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport tensorflow_data_validation as tfdv\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.example_validator import labels\nfrom tfx.components.util import value_utils\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n\n# Key for statistics in executor input_dict.\nSTATISTICS_KEY = \'statistics\'\n# Key for schema in executor input_dict.\nSCHEMA_KEY = \'schema\'\n\n# Key for anomalies in executor output_dict.\nANOMALIES_KEY = \'anomalies\'\n\n# Default file name for anomalies output.\nDEFAULT_FILE_NAME = \'anomalies.pbtxt\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TensorFlow ExampleValidator component executor.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""TensorFlow ExampleValidator executor entrypoint.\n\n    This validates the statistics on the \'eval\' split against the schema.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - stats: A list of type `standard_artifacts.ExampleStatistics` which\n          should contain the \'eval\' split. Stats on other splits are ignored.\n        - schema: A list of type `standard_artifacts.Schema` which should\n          contain a single schema artifact.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - output: A list of \'ExampleValidationPath\' artifact of size one. It\n          will include a single pbtxt file which contains all anomalies found.\n      exec_properties: A dict of execution properties. Not used yet.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    absl.logging.info(\'Validating schema against the computed statistics.\')\n    label_inputs = {\n        labels.STATS:\n            tfdv.load_statistics(\n                io_utils.get_only_uri_in_dir(\n                    artifact_utils.get_split_uri(input_dict[STATISTICS_KEY],\n                                                 \'eval\'))),\n        labels.SCHEMA:\n            io_utils.SchemaReader().read(\n                io_utils.get_only_uri_in_dir(\n                    artifact_utils.get_single_uri(input_dict[SCHEMA_KEY])))\n    }\n    output_uri = artifact_utils.get_single_uri(output_dict[ANOMALIES_KEY])\n    label_outputs = {labels.SCHEMA_DIFF_PATH: output_uri}\n    self._Validate(label_inputs, label_outputs)\n    absl.logging.info(\n        \'Validation complete. Anomalies written to {}.\'.format(output_uri))\n\n  def _Validate(self, inputs: Dict[Text, Any], outputs: Dict[Text,\n                                                             Any]) -> None:\n    """"""Validate the inputs and put validate result into outputs.\n\n      This is the implementation part of example validator executor. This is\n      intended for using or extending the executor without artifact dependecy.\n\n    Args:\n      inputs: A dictionary of labeled input values, including:\n        - labels.STATS: the feature statistics to validate\n        - labels.SCHEMA: the schema to respect\n        - (Optional) labels.ENVIRONMENT: if an environment is specified, only\n          validate the feature statistics of the fields in that environment.\n          Otherwise, validate all fields.\n        - (Optional) labels.PREV_SPAN_FEATURE_STATISTICS: the feature\n          statistics of a previous span.\n        - (Optional) labels.PREV_VERSION_FEATURE_STATISTICS: the feature\n          statistics of a previous version.\n        - (Optional) labels.FEATURES_NEEDED: the feature needed to be\n          validated on.\n        - (Optional) labels.VALIDATION_CONFIG: the configuration of this\n          validation.\n        - (Optional) labels.EXTERNAL_CONFIG_VERSION: the version number of\n          external config file.\n      outputs: A dictionary of labeled output values, including:\n          - labels.SCHEMA_DIFF_PATH: the path to write the schema diff to\n    """"""\n    schema = value_utils.GetSoleValue(inputs, labels.SCHEMA)\n    stats = value_utils.GetSoleValue(inputs, labels.STATS)\n    schema_diff_path = value_utils.GetSoleValue(\n        outputs, labels.SCHEMA_DIFF_PATH)\n    anomalies = tfdv.validate_statistics(stats, schema)\n    io_utils.write_pbtxt_file(\n        os.path.join(schema_diff_path, DEFAULT_FILE_NAME), anomalies)\n'"
tfx/components/example_validator/executor_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_validator.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom tensorflow_metadata.proto.v0 import anomalies_pb2\nfrom tfx.components.example_validator import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import io_utils\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def testDo(self):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n    eval_stats_artifact = standard_artifacts.ExampleStatistics()\n    eval_stats_artifact.uri = os.path.join(source_data_dir, \'statistics_gen\')\n    eval_stats_artifact.split_names = artifact_utils.encode_split_names(\n        [\'eval\'])\n\n    schema_artifact = standard_artifacts.Schema()\n    schema_artifact.uri = os.path.join(source_data_dir, \'schema_gen\')\n\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    validation_output = standard_artifacts.ExampleAnomalies()\n    validation_output.uri = os.path.join(output_data_dir, \'output\')\n\n    input_dict = {\n        executor.STATISTICS_KEY: [eval_stats_artifact],\n        executor.SCHEMA_KEY: [schema_artifact],\n    }\n    output_dict = {\n        executor.ANOMALIES_KEY: [validation_output],\n    }\n\n    exec_properties = {}\n\n    example_validator_executor = executor.Executor()\n    example_validator_executor.Do(input_dict, output_dict, exec_properties)\n    self.assertEqual([\'anomalies.pbtxt\'],\n                     tf.io.gfile.listdir(validation_output.uri))\n    anomalies = io_utils.parse_pbtxt_file(\n        os.path.join(validation_output.uri, \'anomalies.pbtxt\'),\n        anomalies_pb2.Anomalies())\n    self.assertNotEqual(0, len(anomalies.anomaly_info))\n    # TODO(zhitaoli): Add comparison to expected anomolies.\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_validator/labels.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Labels recoginized by the example validator executor.""""""\n\n# Input lables\nSTATS = \'stats\'\nSCHEMA = \'schema\'\nENVIRONMENT = \'environment\'\nPREV_SPAN_FEATURE_STATISTICS = \'prev_span_feature_statistics\'\nPREV_VERSION_FEATURE_STATISTICS = \'prev_version_feature_statistics\'\nFEATURES_NEEDED = \'features_needed\'\nVALIDATION_CONFIG = \'validation_config\'\nEXTERNAL_CONFIG_VERSION = \'external_config_version\'\n\n# Output labels\nSCHEMA_DIFF_PATH = \'schema_diff_path\'\n'"
tfx/components/infra_validator/__init__.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/infra_validator/component.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX InfraValidator component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import executor_spec\nfrom tfx.components.infra_validator import executor\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types import standard_component_specs\n\n\nclass InfraValidator(base_component.BaseComponent):\n  """"""A TFX component to validate the model against the serving infrastructure.\n\n  An infra validation is done by loading the model to the exactly same serving\n  binary that is used in production, and additionaly sending some requests to\n  the model server. Such requests can be specified from Examples artifact.\n\n  ## Examples\n\n  Full example using TensorFlowServing binary running on local docker.\n\n  ```\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=test_example_gen.outputs[\'examples\'],\n      serving_spec=ServingSpec(\n          tensorflow_serving=TensorFlowServing(  # Using TF Serving.\n              tags=[\'latest\']\n          ),\n          local_docker=LocalDockerConfig(),  # Running on local docker.\n      ),\n      validation_spec=ValidationSpec(\n          max_loading_time_seconds=60,\n          num_tries=5,\n      ),\n      request_spec=RequestSpec(\n          tensorflow_serving=TensorFlowServingRequestSpec(),\n          num_examples=1,\n      )\n  )\n  ```\n\n  Minimal example when running on Kubernetes.\n\n  ```\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=test_example_gen.outputs[\'examples\'],\n      serving_spec=ServingSpec(\n          tensorflow_serving=TensorFlowServing(\n              tags=[\'latest\']\n          ),\n          kubernetes=KubernetesConfig(),  # Running on Kubernetes.\n      ),\n  )\n  ```\n  """"""\n\n  SPEC_CLASS = standard_component_specs.InfraValidatorSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n  DRIVER_CLASS = base_driver.BaseDriver\n\n  def __init__(\n      self,\n      model: types.Channel,\n      serving_spec: infra_validator_pb2.ServingSpec,\n      examples: Optional[types.Channel] = None,\n      blessing: Optional[types.Channel] = None,\n      request_spec: Optional[infra_validator_pb2.RequestSpec] = None,\n      validation_spec: Optional[infra_validator_pb2.ValidationSpec] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a InfraValidator component.\n\n    Args:\n      model: A `Channel` of `ModelExportPath` type, usually produced by\n        [Trainer](https://www.tensorflow.org/tfx/guide/trainer) component.\n        _required_\n      serving_spec: A `ServingSpec` configuration about serving binary and\n        test platform config to launch model server for validation. _required_\n      examples: A `Channel` of `ExamplesPath` type, usually produced by\n        [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) component.\n        If not specified, InfraValidator does not issue requests for validation.\n      blessing: Output `Channel` of `InfraBlessingPath` that contains the\n        validation result.\n      request_spec: Optional `RequestSpec` configuration about making requests\n        from `examples` input. If not specified, InfraValidator does not issue\n        requests for validation.\n      validation_spec: Optional `ValidationSpec` configuration.\n      instance_name: Optional name assigned to this specific instance of\n        InfraValidator.  Required only if multiple InfraValidator components are\n        declared in the same pipeline.\n    """"""\n    blessing = blessing or types.Channel(\n        type=standard_artifacts.InfraBlessing,\n        artifacts=[standard_artifacts.InfraBlessing()])\n    spec = standard_component_specs.InfraValidatorSpec(\n        model=model,\n        examples=examples,\n        blessing=blessing,\n        serving_spec=serving_spec,\n        validation_spec=validation_spec,\n        request_spec=request_spec\n    )\n    super(InfraValidator, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/infra_validator/component_test.py,2,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.infra_validator.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.infra_validator import component\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    model = standard_artifacts.Model()\n    serving_spec = infra_validator_pb2.ServingSpec()\n    validation_spec = infra_validator_pb2.ValidationSpec()\n    infra_validator = component.InfraValidator(\n        model=channel_utils.as_channel([model]),\n        serving_spec=serving_spec,\n        validation_spec=validation_spec)\n\n    # Check channels have been created with proper type.\n    self.assertEqual(standard_artifacts.Model,\n                     infra_validator.inputs[\'model\'].type)\n    self.assertEqual(standard_artifacts.InfraBlessing,\n                     infra_validator.outputs[\'blessing\'].type)\n\n    # Check exec_properties have been populated.\n    self.assertIn(\'serving_spec\', infra_validator.exec_properties)\n    self.assertIn(\'validation_spec\', infra_validator.exec_properties)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/error_types.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Error types for infra validator.""""""\n\n\nclass InfraValidationError(Exception):\n  """"""Base exception for all infra validation related errors.""""""\n  pass\n\n\nclass DeadlineExceeded(InfraValidationError):  # pylint: disable=g-bad-exception-name\n  """"""Infra validation deadline exceeded.""""""\n  pass\n\n\nclass JobAborted(InfraValidationError):  # pylint: disable=g-bad-exception-name\n  """"""Job running the model server has been aborted.\n\n  Abortion can be caused by non-infra-validation reason (e.g. preemption by the\n  scheduler, node failure, etc.) thus we give it a retry.\n  """"""\n  pass\n\n\nclass ValidationFailed(InfraValidationError):  # pylint: disable=g-bad-exception-name\n  """"""Infra validation has failed.""""""\n  pass\n\n\nclass GracefulShutdown(InfraValidationError):  # pylint: disable=g-bad-exception-name\n  """"""Graceful shutdown was requested and validation would be aborted.""""""\n  pass\n'"
tfx/components/infra_validator/executor.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX InfraValidator executor definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport functools\nimport os\nimport signal\nimport threading\nimport time\n\nfrom absl import logging\nfrom typing import Any, Dict, List, Optional, Text\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import request_builder\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.components.infra_validator import types as iv_types\nfrom tfx.components.infra_validator.model_server_runners import kubernetes_runner\nfrom tfx.components.infra_validator.model_server_runners import local_docker_runner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\nfrom tfx.utils.model_paths import tf_serving_flavor\n\n_DEFAULT_NUM_TRIES = 5\n_DEFAULT_POLLING_INTERVAL_SEC = 1\n_DEFAULT_MAX_LOADING_TIME_SEC = 300\n_DEFAULT_MODEL_NAME = \'infra-validation-model\'\n\n# Proto message keys for oneof block.\n_TENSORFLOW_SERVING = \'tensorflow_serving\'\n_LOCAL_DOCKER = \'local_docker\'\n_KUBERNETES = \'kubernetes\'\n\n# Artifact and exec_properties keys\n_MODEL_KEY = \'model\'\n_EXAMPLES_KEY = \'examples\'\n_BLESSING_KEY = \'blessing\'\n_SERVING_SPEC_KEY = \'serving_spec\'\n_VALIDATION_SPEC_KEY = \'validation_spec\'\n_REQUEST_SPEC_KEY = \'request_spec\'\n\n# Artifact property keys\n_BLESSED_KEY = \'blessed\'\n# Filename of infra blessing artifact on succeed.\n_BLESSED_FILENAME = \'INFRA_BLESSED\'\n# Filename of infra blessing artifact on fail.\n_NOT_BLESSED_FILENAME = \'INFRA_NOT_BLESSED\'\n\n\ndef _create_model_server_runner(\n    model_path: Text,\n    serving_binary: serving_bins.ServingBinary,\n    serving_spec: infra_validator_pb2.ServingSpec):\n  """"""Create a ModelServerRunner from a model, a ServingBinary and a ServingSpec.\n\n  Args:\n    model_path: An IV-flavored model path. (See model_path_utils.py)\n    serving_binary: One of ServingBinary instances parsed from the\n        `serving_spec`.\n    serving_spec: A ServingSpec instance of this infra validation.\n\n  Returns:\n    A ModelServerRunner.\n  """"""\n  platform = serving_spec.WhichOneof(\'serving_platform\')\n  if platform == \'local_docker\':\n    return local_docker_runner.LocalDockerRunner(\n        model_path=model_path,\n        serving_binary=serving_binary,\n        serving_spec=serving_spec\n    )\n  elif platform == \'kubernetes\':\n    return kubernetes_runner.KubernetesRunner(\n        model_path=model_path,\n        serving_binary=serving_binary,\n        serving_spec=serving_spec\n    )\n  else:\n    raise NotImplementedError(\'Invalid serving_platform {}\'.format(platform))\n\n\ndef _mark_blessed(blessing: types.Artifact) -> None:\n  logging.info(\'Model passed infra validation.\')\n  io_utils.write_string_file(\n      os.path.join(blessing.uri, _BLESSED_FILENAME), \'\')\n  blessing.set_int_custom_property(_BLESSED_KEY, 1)\n\n\ndef _mark_not_blessed(blessing: types.Artifact) -> None:\n  logging.info(\'Model failed infra validation.\')\n  io_utils.write_string_file(\n      os.path.join(blessing.uri, _NOT_BLESSED_FILENAME), \'\')\n  blessing.set_int_custom_property(_BLESSED_KEY, 0)\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TFX infra validator executor.""""""\n\n  def __init__(self,\n               context: Optional[base_executor.BaseExecutor.Context] = None):\n    super(Executor, self).__init__(context)\n    self._cleanups = []\n\n  def _AddCleanup(self, function, *args, **kwargs):\n    self._cleanups.append(functools.partial(function, *args, **kwargs))\n\n  def _Cleanup(self):\n    for cleanup in self._cleanups:\n      try:\n        cleanup()\n      except:  # pylint: disable=broad-except, bare-except\n        logging.warning(\'Error occurred during cleanup.\', exc_info=True)\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Contract for running InfraValidator Executor.\n\n    Args:\n      input_dict:\n        - `model`: Single `Model` artifact that we\'re validating.\n        - `examples`: `Examples` artifacts to be used for test requests.\n      output_dict:\n        - `blessing`: Single `InfraBlessing` artifact containing the validated\n          result. It is an empty file with the name either of INFRA_BLESSED or\n          INFRA_NOT_BLESSED.\n      exec_properties:\n        - `serving_spec`: Serialized `ServingSpec` configuration.\n        - `validation_spec`: Serialized `ValidationSpec` configuration.\n        - `request_spec`: Serialized `RequestSpec` configuration.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    model = artifact_utils.get_single_instance(input_dict[_MODEL_KEY])\n    blessing = artifact_utils.get_single_instance(output_dict[_BLESSING_KEY])\n\n    if input_dict.get(_EXAMPLES_KEY):\n      examples = artifact_utils.get_single_instance(input_dict[_EXAMPLES_KEY])\n    else:\n      examples = None\n\n    serving_spec = infra_validator_pb2.ServingSpec()\n    json_format.Parse(exec_properties[_SERVING_SPEC_KEY], serving_spec)\n    if not serving_spec.model_name:\n      serving_spec.model_name = _DEFAULT_MODEL_NAME\n\n    validation_spec = infra_validator_pb2.ValidationSpec()\n    if exec_properties.get(_VALIDATION_SPEC_KEY):\n      json_format.Parse(exec_properties[_VALIDATION_SPEC_KEY], validation_spec)\n    if not validation_spec.num_tries:\n      validation_spec.num_tries = _DEFAULT_NUM_TRIES\n    if not validation_spec.max_loading_time_seconds:\n      validation_spec.max_loading_time_seconds = _DEFAULT_MAX_LOADING_TIME_SEC\n\n    if exec_properties.get(_REQUEST_SPEC_KEY):\n      request_spec = infra_validator_pb2.RequestSpec()\n      json_format.Parse(exec_properties[_REQUEST_SPEC_KEY], request_spec)\n    else:\n      request_spec = None\n\n    with self._InstallGracefulShutdownHandler():\n      self._Do(\n          model=model,\n          examples=examples,\n          blessing=blessing,\n          serving_spec=serving_spec,\n          validation_spec=validation_spec,\n          request_spec=request_spec,\n      )\n\n  @contextlib.contextmanager\n  def _InstallGracefulShutdownHandler(self):\n    # pylint: disable=g-doc-return-or-yield\n    """"""Install graceful shutdown behavior.\n\n    Caveat: InfraValidator currently only recognizes SIGTERM signal as a\n    graceful shutdown. Furthermore, SIGTERM can be handled only if the executor\n    is running on the MainThread (the thread that runs the python interpreter)\n    due to the limitation of Python API.\n\n    When the executor is running on Kubernetes, SIGTERM is a standard way to\n    signal the graceful shutdown. Python default behavior for receiving SIGTERM\n    is to terminate the process without raising any exception. By registering a\n    handler that raises on signal, we can effectively transform the signal to an\n    exception, and we can reuse our cleanup code inside ""except"" or ""finally""\n    block during the grace period.\n\n    When the executor is run by the local Beam DirectRunner, the executor thread\n    is one of the worker threads (not a MainThread) therefore SIGTERM cannot\n    be recognized. If either of MainThread or worker thread receives SIGTERM,\n    executor will die immediately without grace period.\n\n    Even if the executor fails to shutdown gracefully, external resources that\n    are created by model server runner can be cleaned up if the platform\n    supports such mechanism (e.g. activeDeadlineSeconds in Kubernetes).\n    """"""\n\n    def _handler(signum, frame):\n      del frame  # Unused.\n      raise error_types.GracefulShutdown(\'Got signal {}.\'.format(signum))\n\n    try:\n      old_handler = signal.signal(signal.SIGTERM, _handler)\n    except ValueError:\n      # If current thread is not a MainThread, it is not allowed to register\n      # the signal handler (ValueError raised).\n      logging.info(\'Unable to register signal handler for non-MainThread \'\n                   \'(name=%s). SIGTERM will not be handled.\',\n                   threading.current_thread().name)\n      old_handler = None\n\n    try:\n      yield\n    finally:\n      self._Cleanup()\n      if old_handler:\n        signal.signal(signal.SIGTERM, old_handler)\n\n  def _Do(\n      self,\n      model: types.Artifact,\n      examples: Optional[types.Artifact],\n      blessing: types.Artifact,\n      serving_spec: infra_validator_pb2.ServingSpec,\n      validation_spec: infra_validator_pb2.ValidationSpec,\n      request_spec: Optional[infra_validator_pb2.RequestSpec],\n  ):\n\n    if examples and request_spec:\n      logging.info(\'InfraValidator will be run in LOAD_AND_QUERY mode.\')\n      requests = request_builder.build_requests(\n          model_name=serving_spec.model_name,\n          model=model,\n          examples=examples,\n          request_spec=request_spec)\n    else:\n      logging.info(\'InfraValidator will be run in LOAD_ONLY mode.\')\n      requests = []\n\n    model_path = self._PrepareModelPath(model.uri, serving_spec)\n    # TODO(jjong): Make logic parallel.\n    all_passed = True\n    for serving_binary in serving_bins.parse_serving_binaries(serving_spec):\n      all_passed &= self._ValidateWithRetry(\n          model_path=model_path,\n          serving_binary=serving_binary,\n          serving_spec=serving_spec,\n          validation_spec=validation_spec,\n          requests=requests)\n\n    if all_passed:\n      _mark_blessed(blessing)\n    else:\n      _mark_not_blessed(blessing)\n\n  def _PrepareModelPath(\n      self, model_uri: Text,\n      serving_spec: infra_validator_pb2.ServingSpec) -> Text:\n    model_path = path_utils.serving_model_path(model_uri)\n    serving_binary = serving_spec.WhichOneof(\'serving_binary\')\n    if serving_binary == _TENSORFLOW_SERVING:\n      # TensorFlow Serving requires model to be stored in its own directory\n      # structure flavor. If current model_path does not conform to the flavor,\n      # we need to make a copy to the temporary path.\n      try:\n        # Check whether current model_path conforms to the tensorflow serving\n        # model path flavor. (Parsed without exception)\n        tf_serving_flavor.parse_model_path(\n            model_path,\n            expected_model_name=serving_spec.model_name)\n      except ValueError:\n        # Copy the model to comply with the tensorflow serving model path\n        # flavor.\n        temp_model_path = tf_serving_flavor.make_model_path(\n            model_base_path=self._get_tmp_dir(),\n            model_name=serving_spec.model_name,\n            version=int(time.time()))\n        io_utils.copy_dir(src=model_path, dst=temp_model_path)\n        self._AddCleanup(io_utils.delete_dir, self._context.get_tmp_path())\n        return temp_model_path\n\n    return model_path\n\n  def _ValidateWithRetry(\n      self, model_path: Text,\n      serving_binary: serving_bins.ServingBinary,\n      serving_spec: infra_validator_pb2.ServingSpec,\n      validation_spec: infra_validator_pb2.ValidationSpec,\n      requests: List[iv_types.Request]):\n\n    for i in range(validation_spec.num_tries):\n      logging.info(\'Starting infra validation (attempt %d/%d).\', i + 1,\n                   validation_spec.num_tries)\n      try:\n        self._ValidateOnce(\n            model_path=model_path,\n            serving_binary=serving_binary,\n            serving_spec=serving_spec,\n            validation_spec=validation_spec,\n            requests=requests)\n      except error_types.GracefulShutdown:\n        # GracefulShutdown means infra validation aborted. No more retry and\n        # escalate the error.\n        raise\n      except Exception as e:  # pylint: disable=broad-except\n        # Other exceptions indicates validation failure. Log the error and\n        # retry.\n        logging.exception(\'Infra validation (attempt %d/%d) failed.\', i + 1,\n                          validation_spec.num_tries)\n        if isinstance(e, error_types.DeadlineExceeded):\n          logging.info(\'Consider increasing the value of \'\n                       \'ValidationSpec.max_loading_time_seconds.\')\n      else:\n        # If validation has passed without any exception, succeeded.\n        return True\n\n    # Every trial has failed. Marking model as not blessed.\n    return False\n\n  def _ValidateOnce(\n      self, model_path: Text,\n      serving_binary: serving_bins.ServingBinary,\n      serving_spec: infra_validator_pb2.ServingSpec,\n      validation_spec: infra_validator_pb2.ValidationSpec,\n      requests: List[iv_types.Request]):\n\n    deadline = time.time() + validation_spec.max_loading_time_seconds\n    runner = _create_model_server_runner(\n        model_path=model_path,\n        serving_binary=serving_binary,\n        serving_spec=serving_spec)\n\n    try:\n      logging.info(\'Starting %r.\', runner)\n      runner.Start()\n\n      # Check model is successfully loaded.\n      runner.WaitUntilRunning(deadline)\n      client = serving_binary.MakeClient(runner.GetEndpoint())\n      client.WaitUntilModelLoaded(\n          deadline, polling_interval_sec=_DEFAULT_POLLING_INTERVAL_SEC)\n\n      # Check model can be successfully queried.\n      if requests:\n        client.SendRequests(requests)\n    finally:\n      logging.info(\'Stopping %r.\', runner)\n      runner.Stop()\n'"
tfx/components/infra_validator/executor_test.py,3,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.infra_validator.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport signal\nimport threading\n\nimport mock\nimport tensorflow as tf\nfrom typing import Any, Dict, Text\n\nfrom google.protobuf import json_format\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import executor\nfrom tfx.components.infra_validator import request_builder\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import path_utils\n\n\ndef _make_serving_spec(\n    payload: Dict[Text, Any]) -> infra_validator_pb2.ServingSpec:\n  result = infra_validator_pb2.ServingSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\ndef _make_validation_spec(\n    payload: Dict[Text, Any]) -> infra_validator_pb2.ValidationSpec:\n  result = infra_validator_pb2.ValidationSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\ndef _make_request_spec(\n    payload: Dict[Text, Any]) -> infra_validator_pb2.RequestSpec:\n  result = infra_validator_pb2.RequestSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n\n    # Setup Mocks\n\n    patcher = mock.patch.object(request_builder, \'build_requests\')\n    self.build_requests_mock = patcher.start()\n    self.addCleanup(patcher.stop)\n\n    # Setup directories\n\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    base_output_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\',\n                                     self.get_temp_dir())\n    output_data_dir = os.path.join(base_output_dir, self._testMethodName)\n\n    # Setup input_dict.\n\n    self._model = standard_artifacts.Model()\n    self._model.uri = os.path.join(source_data_dir, \'trainer\', \'current\')\n    self._model_path = path_utils.serving_model_path(self._model.uri)\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'transform\',\n                                \'transformed_examples\', \'eval\')\n    examples.split_names = artifact_utils.encode_split_names([\'eval\'])\n\n    self._input_dict = {\n        \'model\': [self._model],\n        \'examples\': [examples],\n    }\n    self._blessing = standard_artifacts.InfraBlessing()\n    self._blessing.uri = os.path.join(output_data_dir, \'blessing\')\n    self._output_dict = {\'blessing\': [self._blessing]}\n    temp_dir = os.path.join(output_data_dir, \'.temp\')\n    self._context = executor.Executor.Context(tmp_dir=temp_dir, unique_id=\'1\')\n    self._serving_spec = _make_serving_spec({\n        \'tensorflow_serving\': {\n            \'tags\': [\'1.15.0\']\n        },\n        \'local_docker\': {},\n        \'model_name\': \'chicago-taxi\',\n    })\n    self._serving_binary = serving_bins.parse_serving_binaries(\n        self._serving_spec)[0]\n    self._validation_spec = _make_validation_spec({\n        \'max_loading_time_seconds\': 10,\n        \'num_tries\': 3\n    })\n    self._request_spec = _make_request_spec({\n        \'tensorflow_serving\': {\n            \'signature_names\': [\'serving_default\'],\n        },\n        \'num_examples\': 1\n    })\n    self._exec_properties = {\n        \'serving_spec\': json_format.MessageToJson(self._serving_spec),\n        \'validation_spec\': json_format.MessageToJson(self._validation_spec),\n        \'request_spec\': json_format.MessageToJson(self._request_spec),\n    }\n\n  def testDo_BlessedIfNoError(self):\n    # Run executor.\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(infra_validator, \'_ValidateOnce\'):\n      infra_validator.Do(self._input_dict, self._output_dict,\n                         self._exec_properties)\n\n    # Check blessed.\n    self.assertBlessed()\n\n  def testDo_NotBlessedIfError(self):\n    # Run executor.\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(infra_validator, \'_ValidateOnce\') as validate_mock:\n      # Validation will raise error.\n      validate_mock.side_effect = ValueError\n      infra_validator.Do(self._input_dict, self._output_dict,\n                         self._exec_properties)\n\n    # Check not blessed.\n    self.assertNotBlessed()\n\n  def testDo_BlessedIfEventuallyNoError(self):\n    # Run executor.\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(infra_validator, \'_ValidateOnce\') as validate_mock:\n      # Validation will raise error at first, succeeded at the following.\n      # Infra validation will be tried 3 times, so 2 failures are tolerable.\n      validate_mock.side_effect = [ValueError, ValueError, None]\n      infra_validator.Do(self._input_dict, self._output_dict,\n                         self._exec_properties)\n\n    # Check blessed.\n    self.assertBlessed()\n\n  def testDo_NotBlessedIfErrorContinues(self):\n    # Run executor.\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(infra_validator, \'_ValidateOnce\') as validate_mock:\n      # 3 Errors are not tolerable.\n      validate_mock.side_effect = [ValueError, ValueError, ValueError, None]\n      infra_validator.Do(self._input_dict, self._output_dict,\n                         self._exec_properties)\n\n    # Check not blessed.\n    self.assertNotBlessed()\n\n  def testValidateOnce_LoadOnly_Succeed(self):\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(self._serving_binary, \'MakeClient\'):\n      with mock.patch.object(executor, \'_create_model_server_runner\'):\n        # Should not raise any error.\n        infra_validator._ValidateOnce(\n            model_path=self._model_path,\n            serving_binary=self._serving_binary,\n            serving_spec=self._serving_spec,\n            validation_spec=self._validation_spec,\n            requests=[])\n\n  def testValidateOnce_LoadOnly_FailIfRunnerWaitRaises(self):\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(self._serving_binary, \'MakeClient\'):\n      with mock.patch.object(\n          executor, \'_create_model_server_runner\') as mock_runner_factory:\n        mock_runner = mock_runner_factory.return_value\n        mock_runner.WaitUntilRunning.side_effect = ValueError\n        with self.assertRaises(ValueError):\n          infra_validator._ValidateOnce(\n              model_path=self._model_path,\n              serving_binary=self._serving_binary,\n              serving_spec=self._serving_spec,\n              validation_spec=self._validation_spec,\n              requests=[])\n\n  def testValidateOnce_LoadOnly_FailIfClientWaitRaises(self):\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(self._serving_binary,\n                           \'MakeClient\') as mock_client_factory:\n      mock_client = mock_client_factory.return_value\n      with mock.patch.object(\n          executor, \'_create_model_server_runner\') as mock_runner_factory:\n        mock_client.WaitUntilModelLoaded.side_effect = ValueError\n        with self.assertRaises(ValueError):\n          infra_validator._ValidateOnce(\n              model_path=self._model_path,\n              serving_binary=self._serving_binary,\n              serving_spec=self._serving_spec,\n              validation_spec=self._validation_spec,\n              requests=[])\n        mock_runner_factory.return_value.WaitUntilRunning.assert_called()\n\n  def testValidateOnce_LoadAndQuery_Succeed(self):\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(self._serving_binary,\n                           \'MakeClient\') as mock_client_factory:\n      mock_client = mock_client_factory.return_value\n      with mock.patch.object(\n          executor, \'_create_model_server_runner\') as mock_runner_factory:\n        infra_validator._ValidateOnce(\n            model_path=self._model_path,\n            serving_binary=self._serving_binary,\n            serving_spec=self._serving_spec,\n            validation_spec=self._validation_spec,\n            requests=[\'my_request\'])\n        mock_runner_factory.return_value.WaitUntilRunning.assert_called()\n        mock_client.WaitUntilModelLoaded.assert_called()\n        mock_client.SendRequests.assert_called()\n\n  def testValidateOnce_LoadAndQuery_FailIfSendRequestsRaises(self):\n    infra_validator = executor.Executor(self._context)\n    with mock.patch.object(self._serving_binary,\n                           \'MakeClient\') as mock_client_factory:\n      mock_client = mock_client_factory.return_value\n      with mock.patch.object(\n          executor, \'_create_model_server_runner\') as mock_runner_factory:\n        mock_client.SendRequests.side_effect = ValueError\n        with self.assertRaises(ValueError):\n          infra_validator._ValidateOnce(\n              model_path=self._model_path,\n              serving_binary=self._serving_binary,\n              serving_spec=self._serving_spec,\n              validation_spec=self._validation_spec,\n              requests=[\'my_request\'])\n        mock_runner_factory.return_value.WaitUntilRunning.assert_called()\n        mock_client.WaitUntilModelLoaded.assert_called()\n\n  def testSignalHandling(self):\n    infra_validator = executor.Executor(self._context)\n    ready_to_kill_event = threading.Event()\n\n    def send_sigterm(pid):\n      ready_to_kill_event.wait()\n      os.kill(pid, signal.SIGTERM)\n\n    def validate_side_effect(*args, **kwargs):\n      del args, kwargs  # Unused.\n      ready_to_kill_event.set()\n      while True:  # Wait until killed.\n        pass\n\n    with mock.patch.object(infra_validator, \'_ValidateOnce\') as mock_validate:\n      mock_validate.side_effect = validate_side_effect\n      killer = threading.Thread(target=send_sigterm, args=(os.getpid(),))\n      killer.start()\n\n      # SIGTERM should raise GracefulShutdown error.\n      with self.assertRaises(error_types.GracefulShutdown):\n        infra_validator.Do(\n            self._input_dict,\n            self._output_dict,\n            self._exec_properties)\n\n  def assertBlessed(self):\n    self.assertFileExists(os.path.join(self._blessing.uri, \'INFRA_BLESSED\'))\n    self.assertEqual(1, self._blessing.get_int_custom_property(\'blessed\'))\n\n  def assertNotBlessed(self):\n    self.assertFileExists(os.path.join(self._blessing.uri, \'INFRA_NOT_BLESSED\'))\n    self.assertEqual(0, self._blessing.get_int_custom_property(\'blessed\'))\n\n  def assertFileExists(self, path: Text):\n    self.assertTrue(tf.io.gfile.exists(path))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/request_builder.py,22,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utility functions for building requests.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport os\n\nfrom absl import logging\nimport enum\nimport six\nimport tensorflow as tf\nfrom typing import Any, Iterable, List, Mapping, Optional, Text\n\n# TODO(b/140306674): Stop using the internal TF API\nfrom tensorflow.python.saved_model import loader_impl  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import regression_pb2\nfrom tfx import types\nfrom tfx.components.infra_validator import types as iv_types\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import path_utils\n\n_TENSORFLOW_SERVING = \'tensorflow_serving\'\n_DEFAULT_NUM_EXAMPLES = 1\n\n_DEFAULT_TAG_SET = frozenset([tf.saved_model.SERVING])\n\n# We define the following aliases of Any because the actual types are not\n# public.\n_SavedModel = Any\n_SignatureDef = Any\n\n\ndef build_requests(  # pylint: disable=invalid-name\n    model_name: Text,\n    model: types.Artifact,\n    examples: types.Artifact,\n    request_spec: infra_validator_pb2.RequestSpec\n) -> List[iv_types.Request]:\n  """"""Build model server requests.\n\n  Examples artifact will be used as a data source to build requests. Caller\n  should guarantee that the logical format of the Examples artifact should be\n  compatible with request type to build.\n\n  Args:\n    model_name: A model name that model server recognizes.\n    model: A model artifact for model signature analysis.\n    examples: An `Examples` artifact for request data source.\n    request_spec: A `RequestSpec` config.\n\n  Returns:\n    A list of request protos.\n  """"""\n  split_name = request_spec.split_name or None\n  num_examples = request_spec.num_examples or _DEFAULT_NUM_EXAMPLES\n\n  kind = request_spec.WhichOneof(\'kind\')\n  if kind == _TENSORFLOW_SERVING:\n    spec = request_spec.tensorflow_serving\n    signatures = _parse_saved_model_signatures(\n        model_path=path_utils.serving_model_path(model.uri),\n        tag_set=spec.tag_set,\n        signature_names=spec.signature_names)\n    builder = _TFServingRpcRequestBuilder(\n        model_name=model_name,\n        signatures=signatures)\n  else:\n    raise NotImplementedError(\'Unsupported RequestSpec kind {!r}\'.format(kind))\n\n  builder.ReadExamplesArtifact(\n      examples,\n      split_name=split_name,\n      num_examples=num_examples)\n\n  return builder.BuildRequests()\n\n\n# TODO(b/151790176): Move to tfx_bsl, or keep it if TF adds a proper public API.\ndef _parse_saved_model_signatures(\n    model_path: Text,\n    tag_set: Iterable[Text],\n    signature_names: Iterable[Text]) -> Mapping[Text, _SignatureDef]:\n  """"""Parse SignatureDefs of given signature names from SavedModel.\n\n  Among one or more MetaGraphDefs in SavedModel, the first one that has all the\n  tag_set elements is chosen. Selected MetaGraphDef should have signatures for\n  all given signature names.\n\n  Args:\n    model_path: A path to the SavedModel directory.\n    tag_set: A set of tags MetaGraphDef should have.\n    signature_names: A list of signature names to retrieve.\n\n  Returns:\n    A mapping from signature name to SignatureDef.\n  """"""\n  if not tag_set:\n    tag_set = {tf.saved_model.SERVING}\n    logging.info(\'tag_set is not given. Using %r instead.\', tag_set)\n  if not signature_names:\n    signature_names = [tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n    logging.info(\'signature_names are not given. Using %r instead.\',\n                 signature_names)\n  loader = loader_impl.SavedModelLoader(model_path)\n  meta_graph_def = loader.get_meta_graph_def_from_tags(tag_set)\n  result = {}\n  for signature_name in signature_names:\n    if signature_name not in meta_graph_def.signature_def:\n      raise ValueError(\'SignatureDef of name {} could not be found in \'\n                       \'MetaGraphDef\'.format(signature_name))\n    result[signature_name] = meta_graph_def.signature_def[signature_name]\n  return result\n\n\nclass _LogicalFormat(enum.Enum):\n  UNKNOWN = 0\n  TF_EXAMPLE = 1\n\n\nclass _BaseRequestBuilder(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Base class for all RequestBuilders.""""""\n\n  def __init__(self):\n    self._records = []  # type: List[bytes]\n    self._record_format = _LogicalFormat.UNKNOWN\n\n  # TODO(jjong): The method strongly assumes that the output of ExampleGen is\n  # a gzipped TFRecords of tf.Example. We need a better abstraction (e.g. TFXIO)\n  # to accept arbitrary file format and convert it to appropriate request types.\n  def ReadExamplesArtifact(self, examples: types.Artifact, num_examples: int,\n                           split_name: Optional[Text] = None):\n    """"""Read records from Examples artifact.\n\n    Currently it assumes Examples artifact contains serialized tf.Example in\n    gzipped TFRecord files.\n\n    Args:\n      examples: `Examples` artifact.\n      num_examples: Number of examples to read. If the specified value is larger\n          than the actual number of examples, all examples would be read.\n      split_name: Name of the split to read from the Examples artifact.\n\n    Raises:\n      RuntimeError: If read twice.\n    """"""\n    if self._records:\n      raise RuntimeError(\'Cannot read records twice.\')\n\n    if num_examples < 1:\n      raise ValueError(\'num_examples < 1 (got {})\'.format(num_examples))\n\n    available_splits = artifact_utils.decode_split_names(examples.split_names)\n    if not available_splits:\n      raise ValueError(\'No split_name is available in given Examples artifact.\')\n    if split_name is None:\n      split_name = available_splits[0]\n    if split_name not in available_splits:\n      raise ValueError(\n          \'No split_name {}; available split names: {}\'.format(\n              split_name, \', \'.join(available_splits)))\n\n    # ExampleGen generates artifacts under each split_name directory.\n    glob_pattern = os.path.join(examples.uri, split_name, \'*.gz\')\n    try:\n      filenames = tf.io.gfile.glob(glob_pattern)\n    except tf.errors.NotFoundError:\n      filenames = []\n    if not filenames:\n      raise ValueError(\'Unable to find examples matching {}.\'.format(\n          glob_pattern))\n\n    # Assume we have a tf.Example logical format.\n    self._record_format = _LogicalFormat.TF_EXAMPLE\n\n    self._ReadFromDataset(\n        tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\'),\n        num_examples=num_examples)\n\n  def _ReadFromDataset(self, dataset: tf.data.TFRecordDataset,\n                       num_examples: int):\n    dataset = dataset.take(num_examples)\n    if tf.executing_eagerly():\n      for raw_example in dataset:\n        self._records.append(raw_example.numpy())\n    else:\n      it = tf.compat.v1.data.make_one_shot_iterator(dataset)\n      next_el = it.get_next()\n      with tf.Session() as sess:\n        while True:\n          try:\n            raw_example = sess.run(next_el)\n            self._records.append(raw_example)\n          except tf.errors.OutOfRangeError:\n            break\n\n  @abc.abstractmethod\n  def BuildRequests(self) -> List[iv_types.Request]:\n    """"""Transform read records (bytes) to the request type.""""""\n\n\nclass _TFServingRpcRequestBuilder(_BaseRequestBuilder):\n  """"""RequestBuilder for TF Serving RPC requests.\n\n  There are three kinds of request the builder can make:\n  -   ClassificationRequest\n  -   RegressionRequest\n  -   PredictRequest\n\n  Types of request to build is determined by inspecting SavedModel and getting\n  SignatureDef from it. What user can configure is the signature names to use.\n\n  To build a ClassificationRequest or a RegressionRequest, logical format of\n  the record should be TF_EXAMPLE.\n\n  To build a PredictRequest, its corresponding SignatureDef should have a single\n  input argument that accepts serialized record inputs. Its logical format does\n  not matter as long as user have a correct parsing logic.\n  """"""\n\n  def __init__(self,\n               model_name: Text,\n               signatures: Mapping[Text, _SignatureDef]):\n    super(_TFServingRpcRequestBuilder, self).__init__()\n    self._model_name = model_name\n    self._signatures = signatures\n    self._examples = []\n\n  @property\n  def examples(self) -> List[tf.train.Example]:\n    if not self._examples:\n      if self._record_format != _LogicalFormat.TF_EXAMPLE:\n        raise ValueError(\'Record format should be TF_EXAMPLE.\')\n      for record in self._records:\n        example = tf.train.Example()\n        example.ParseFromString(record)\n        self._examples.append(example)\n    return self._examples\n\n  def BuildRequests(self) -> List[iv_types.TensorFlowServingRequest]:\n    assert self._records, \'Records are empty.\'\n    result = []\n    for signature_name, signature_def in self._signatures.items():\n      if signature_def.method_name == tf.saved_model.PREDICT_METHOD_NAME:\n        result.extend(\n            self._BuildPredictRequests(\n                signature_name, self._GetSerializedInputKey(signature_def)))\n      elif signature_def.method_name == tf.saved_model.CLASSIFY_METHOD_NAME:\n        result.extend(self._BuildClassificationRequests(signature_name))\n      elif signature_def.method_name == tf.saved_model.REGRESS_METHOD_NAME:\n        result.extend(self._BuildRegressionRequests(signature_name))\n      else:\n        raise ValueError(\'Unknown method name {}\'.format(\n            signature_def.method_name))\n    return result\n\n  def _GetSerializedInputKey(self, signature_def: _SignatureDef):\n    """"""Gets key for SignatureDef input that consumes serialized record.\n\n    To build a PredictRequest, SignatureDef inputs should have a single input\n    argument that accepts serialized record inputs. The input TensorSpec should\n    have dtype=DT_STRING and shape=TensorShape([None]).\n\n    Args:\n      signature_def: A SignatureDef proto message.\n\n    Returns:\n      An input key for the serialized input.\n    """"""\n    signature_input_keys = list(signature_def.inputs.keys())\n    if len(signature_input_keys) == 1:\n      input_key = signature_input_keys[0]\n      input_spec = signature_def.inputs[input_key]\n      if (input_spec.dtype == tf.dtypes.string.as_datatype_enum\n          and input_spec.tensor_shape == tf.TensorShape([None]).as_proto()):\n        return input_key\n    # TODO(b/151697719): General Predict method signature support.\n    raise ValueError(\n        \'Unable to find valid input key from SignatureDef. In order to make \'\n        \'PredictRequest, model should define signature that accepts serialized \'\n        \'record inputs, i.e. signature with single input whose dtype=DT_STRING \'\n        \'and shape=TensorShape([None]).\')\n\n  def _BuildClassificationRequests(self, signature_name: Text):\n    for example in self.examples:\n      request = classification_pb2.ClassificationRequest()\n      request.model_spec.name = self._model_name\n      request.model_spec.signature_name = signature_name\n      request.input.example_list.examples.append(example)\n      yield request\n\n  def _BuildRegressionRequests(self, signature_name: Text):\n    for example in self.examples:\n      request = regression_pb2.RegressionRequest()\n      request.model_spec.name = self._model_name\n      request.model_spec.signature_name = signature_name\n      request.input.example_list.examples.append(example)\n      yield request\n\n  def _BuildPredictRequests(self, signature_name: Text,\n                            serialized_input_key: Text):\n    for record in self._records:\n      request = predict_pb2.PredictRequest()\n      request.model_spec.name = self._model_name\n      request.model_spec.signature_name = signature_name\n      request.inputs[serialized_input_key].CopyFrom(\n          tf.make_tensor_proto([record]))\n      yield request\n'"
tfx/components/infra_validator/request_builder_test.py,12,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.request_builder.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport mock\nimport tensorflow as tf\nfrom typing import Any, Dict, Text\n\nfrom google.protobuf import json_format\n# TODO(b/140306674): Stop using the internal TF API\nfrom tensorflow.core.protobuf import meta_graph_pb2  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow.core.protobuf import saved_model_pb2  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import regression_pb2\nfrom tfx.components.infra_validator import request_builder\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import path_utils\n\n_TEST_DATA_ROOT = os.path.join(\n    os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n_CSV_EXAMPLE_GEN_URI = os.path.join(_TEST_DATA_ROOT, \'csv_example_gen\')\n_ESTIMATOR_MODEL_URI = os.path.join(_TEST_DATA_ROOT, \'trainer\', \'current\')\n_KERAS_MODEL_URI = os.path.join(_TEST_DATA_ROOT, \'trainer\', \'keras\')\n\n\ndef _make_saved_model(payload: Dict[Text, Any]):\n  result = saved_model_pb2.SavedModel()\n  json_format.ParseDict(payload, result)\n  return result\n\n\ndef _make_signature_def(payload: Dict[Text, Any]):\n  result = meta_graph_pb2.SignatureDef()\n  json_format.ParseDict(payload, result)\n  return result\n\n\ndef _make_request_spec(payload: Dict[Text, Any]):\n  result = infra_validator_pb2.RequestSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\nclass TestParseSavedModelSignature(tf.test.TestCase):\n\n  def _MockSavedModel(self, saved_model_dict):\n    saved_model_proto = _make_saved_model(saved_model_dict)\n    saved_model_path = os.path.join(self.get_temp_dir(), \'saved_model.pb\')\n    with open(saved_model_path, \'wb\') as f:\n      f.write(saved_model_proto.SerializeToString())\n    return os.path.dirname(saved_model_path)\n\n  def testParseSavedModelSignature(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': [\n            {\n                \'meta_info_def\': {\n                    \'tags\': [\'serve\']\n                },\n                \'signature_def\': {\n                    \'foo\': {\n                        \'method_name\': \'tensorflow/serving/predict\',\n                        \'inputs\': {\n                            \'x\': {\n                                \'name\': \'serving_default_input:0\',\n                                \'dtype\': \'DT_FLOAT\',\n                                \'tensor_shape\': {\n                                    \'dim\': [\n                                        {\'size\': -1},\n                                        {\'size\': 784},\n                                    ]\n                                }\n                            }\n                        },\n                        \'outputs\': {\n                            \'y\': {\n                                \'name\': \'StatefulPartitionedCall:0\',\n                                \'dtype\': \'DT_FLOAT\',\n                                \'tensor_shape\': {\n                                    \'dim\': [\n                                        {\'size\': -1},\n                                        {\'size\': 10},\n                                    ]\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        ]\n    })\n\n    signatures = request_builder._parse_saved_model_signatures(\n        model_path, tag_set={\'serve\'}, signature_names=[\'foo\'])\n\n    self.assertEqual(signatures[\'foo\'].inputs[\'x\'].dtype,\n                     tf.dtypes.float32.as_datatype_enum)\n    self.assertEqual(signatures[\'foo\'].inputs[\'x\'].tensor_shape,\n                     tf.TensorShape([None, 784]).as_proto())\n    self.assertEqual(signatures[\'foo\'].outputs[\'y\'].dtype,\n                     tf.dtypes.float32.as_datatype_enum)\n    self.assertEqual(signatures[\'foo\'].outputs[\'y\'].tensor_shape,\n                     tf.TensorShape([None, 10]).as_proto())\n\n  def testParseSavedModelSignature_FailIfNoMetaGraph(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': []\n    })\n\n    with self.assertRaisesRegex(\n        RuntimeError,\n        \'MetaGraphDef associated with tags .* could not be found\'):\n      request_builder._parse_saved_model_signatures(\n          model_path, tag_set={\'serve\'}, signature_names=[\'foo\'])\n\n  def testParseSavedModelSignature_FailIfTagSetNotMatch(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': [\n            {\n                \'meta_info_def\': {\n                    \'tags\': [\'a\', \'b\']\n                }\n            }\n        ]\n    })\n\n    with self.assertRaisesRegex(\n        RuntimeError,\n        \'MetaGraphDef associated with tags .* could not be found\'):\n      request_builder._parse_saved_model_signatures(\n          model_path, tag_set={\'a\', \'c\'}, signature_names=[\'foo\'])\n\n  def testParseSavedModelSignature_FailIfSignatureNotFound(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': [\n            {\n                \'meta_info_def\': {\n                    \'tags\': [\'serve\']\n                },\n                \'signature_def\': {\n                    \'foo\': {}\n                }\n            }\n        ]\n    })\n\n    with self.assertRaisesRegex(\n        ValueError, \'SignatureDef of name bar could not be found\'):\n      request_builder._parse_saved_model_signatures(\n          model_path, tag_set={\'serve\'}, signature_names=[\'foo\', \'bar\'])\n\n  def testParseSavedModelSignature_DefaultTagSet(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': [\n            {\n                \'meta_info_def\': {\n                    \'tags\': [\'serve\']\n                },\n                \'signature_def\': {\n                    \'foo\': {}\n                }\n            }\n        ]\n    })\n\n    signatures = request_builder._parse_saved_model_signatures(\n        model_path, tag_set=set(), signature_names=[\'foo\'])\n\n    self.assertTrue(signatures)\n\n  def testParseSavedModelSignature_DefaultSignatureName(self):\n    model_path = self._MockSavedModel({\n        \'meta_graphs\': [\n            {\n                \'meta_info_def\': {\n                    \'tags\': [\'foo\']\n                },\n                \'signature_def\': {\n                    \'serving_default\': {},\n                }\n            }\n        ]\n    })\n\n    signatures = request_builder._parse_saved_model_signatures(\n        model_path, tag_set={\'foo\'}, signature_names=[])\n\n    self.assertTrue(signatures)\n\n\nclass _MockBuilder(request_builder._BaseRequestBuilder):\n\n  def BuildRequests(self):\n    raise NotImplementedError()\n\n\nclass BaseRequestBuilderTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(BaseRequestBuilderTest, self).setUp()\n    self._examples = standard_artifacts.Examples()\n    self._examples.uri = _CSV_EXAMPLE_GEN_URI\n    self._examples.split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n\n  def testReadExamplesArtifact(self):\n    builder = _MockBuilder()\n\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    self.assertEqual(len(builder._records), 1)\n    self.assertIsInstance(builder._records[0], bytes)\n\n  def testReadExamplesArtifact_FailIfSplitNamesEmpty(self):\n    builder = _MockBuilder()\n    examples = standard_artifacts.Examples()\n    examples.uri = self._examples.uri\n\n    with self.assertRaises(ValueError):\n      builder.ReadExamplesArtifact(examples, num_examples=1)\n\n  def testReadExamplesArtifact_FailIfSplitNameInvalid(self):\n    builder = _MockBuilder()\n\n    with self.assertRaises(ValueError):\n      builder.ReadExamplesArtifact(self._examples, num_examples=1,\n                                   split_name=\'non-existing-split\')\n\n  def testReadExamplesArtifact_FailReadTwice(self):\n    builder = _MockBuilder()\n\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n    with self.assertRaises(RuntimeError):\n      builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n\nclass TFServingRpcRequestBuilderTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TFServingRpcRequestBuilderTest, self).setUp()\n    self._examples = standard_artifacts.Examples()\n    self._examples.uri = _CSV_EXAMPLE_GEN_URI\n    self._examples.split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n\n  def _GetEstimatorModelSignature(self, signature_names=()):\n    model_path = path_utils.serving_model_path(_ESTIMATOR_MODEL_URI)\n    return request_builder._parse_saved_model_signatures(\n        model_path, tag_set={\'serve\'}, signature_names=signature_names)\n\n  def _GetKerasModelSignature(self):\n    model_path = path_utils.serving_model_path(_KERAS_MODEL_URI)\n    return request_builder._parse_saved_model_signatures(\n        model_path, tag_set={\'serve\'}, signature_names=[\'serving_default\'])\n\n  def testBuildRequests_EstimatorModel_ServingDefault(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures=self._GetEstimatorModelSignature())\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], classification_pb2.ClassificationRequest)\n    self.assertEqual(result[0].model_spec.name, \'foo\')\n    self.assertEqual(result[0].model_spec.signature_name, \'serving_default\')\n\n  def testBuildRequests_EstimatorModel_Classification(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures=self._GetEstimatorModelSignature(\n            signature_names=[\'classification\']))\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], classification_pb2.ClassificationRequest)\n    self.assertEqual(result[0].model_spec.name, \'foo\')\n    self.assertEqual(result[0].model_spec.signature_name, \'classification\')\n\n  def testBuildRequests_EstimatorModel_Regression(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures=self._GetEstimatorModelSignature(\n            signature_names=[\'regression\']))\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], regression_pb2.RegressionRequest)\n    self.assertEqual(result[0].model_spec.name, \'foo\')\n    self.assertEqual(result[0].model_spec.signature_name, \'regression\')\n\n  def testBuildRequests_EstimatorModel_Predict(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures=self._GetEstimatorModelSignature(\n            signature_names=[\'predict\']))\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], predict_pb2.PredictRequest)\n    self.assertEqual(result[0].model_spec.name, \'foo\')\n    self.assertEqual(result[0].model_spec.signature_name, \'predict\')\n    self.assertEqual(len(result[0].inputs), 1)\n    input_key = list(result[0].inputs.keys())[0]\n    self.assertEqual(result[0].inputs[input_key].dtype,\n                     tf.dtypes.string.as_datatype_enum)\n\n  def testBuildRequests_KerasModel(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures=self._GetKerasModelSignature())\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], predict_pb2.PredictRequest)\n    self.assertEqual(result[0].model_spec.name, \'foo\')\n    self.assertEqual(result[0].model_spec.signature_name, \'serving_default\')\n\n  def testBuildRequests_PredictMethod(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures={\n            # Has only one argument with dtype=DT_STRING and shape=(None,).\n            # This is the only valid form that InfraValidator accepts today.\n            \'serving_default\': _make_signature_def({\n                \'method_name\': \'tensorflow/serving/predict\',\n                \'inputs\': {\n                    \'x\': {\n                        \'name\': \'serving_default_examples:0\',\n                        \'dtype\': \'DT_STRING\',\n                        \'tensor_shape\': {\n                            \'dim\': [\n                                {\'size\': -1},\n                            ]\n                        }\n                    }\n                },\n                \'outputs\': {\n                    \'y\': {\n                        \'name\': \'StatefulPartitionedCall:0\',\n                        \'dtype\': \'DT_FLOAT\',\n                        \'tensor_shape\': {\n                            \'dim\': [\n                                {\'size\': -1},\n                                {\'size\': 10},\n                            ]\n                        }\n                    }\n                },\n            })\n        })\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    result = builder.BuildRequests()\n\n    self.assertEqual(len(result), 1)\n    self.assertIsInstance(result[0], predict_pb2.PredictRequest)\n    self.assertEqual(result[0].inputs[\'x\'].dtype,\n                     tf.dtypes.string.as_datatype_enum)\n\n  def testBuildRequests_PredictMethod_FailOnInvalidSignature(self):\n    builder = request_builder._TFServingRpcRequestBuilder(\n        model_name=\'foo\',\n        signatures={\n            # Signature argument is not for serialized tf.Example (i.e. dtype !=\n            # DT_STRING or shape != (None,)).\n            \'serving_default\': _make_signature_def({\n                \'method_name\': \'tensorflow/serving/predict\',\n                \'inputs\': {\n                    \'x\': {\n                        \'name\': \'serving_default_input:0\',\n                        \'dtype\': \'DT_FLOAT\',\n                        \'tensor_shape\': {\n                            \'dim\': [\n                                {\'size\': -1},\n                                {\'size\': 784},\n                            ]\n                        }\n                    }\n                },\n                \'outputs\': {\n                    \'y\': {\n                        \'name\': \'StatefulPartitionedCall:0\',\n                        \'dtype\': \'DT_FLOAT\',\n                        \'tensor_shape\': {\n                            \'dim\': [\n                                {\'size\': -1},\n                                {\'size\': 10},\n                            ]\n                        }\n                    }\n                },\n            })\n        })\n    builder.ReadExamplesArtifact(self._examples, num_examples=1)\n\n    with self.assertRaisesRegex(\n        ValueError, \'Unable to find valid input key from SignatureDef\'):\n      builder.BuildRequests()\n\n\nclass TestBuildRequests(tf.test.TestCase):\n\n  def setUp(self):\n    super(TestBuildRequests, self).setUp()\n    self._model_name = \'foo\'\n    self._examples = standard_artifacts.Examples()\n    self._examples.uri = _CSV_EXAMPLE_GEN_URI\n    self._examples.split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n    self._model = standard_artifacts.Model()\n    self._model.uri = _ESTIMATOR_MODEL_URI\n\n  def _PrepareTFServingRequestBuilder(self):\n    patcher = mock.patch.object(\n        request_builder, \'_TFServingRpcRequestBuilder\',\n        wraps=request_builder._TFServingRpcRequestBuilder)\n    builder_cls = patcher.start()\n    self.addCleanup(patcher.stop)\n    return builder_cls\n\n  def testBuildRequests_TFServing(self):\n    builder_cls = self._PrepareTFServingRequestBuilder()\n    builder = builder_cls.return_value\n\n    request_builder.build_requests(\n        model_name=\'foo\',\n        model=self._model,\n        examples=self._examples,\n        request_spec=_make_request_spec({\n            \'tensorflow_serving\': {\n                \'signature_names\': [\'serving_default\']\n            },\n            \'split_name\': \'eval\',\n            \'num_examples\': 1\n        })\n    )\n\n    builder_cls.assert_called_with(\n        model_name=\'foo\',\n        signatures={\'serving_default\': mock.ANY})\n    builder.ReadExamplesArtifact.assert_called_with(\n        self._examples,\n        split_name=\'eval\',\n        num_examples=1)\n    builder.BuildRequests.assert_called()\n\n  def testBuildRequests_NumberOfRequests(self):\n    result = request_builder.build_requests(\n        model_name=\'foo\',\n        model=self._model,\n        examples=self._examples,\n        request_spec=_make_request_spec({\n            \'tensorflow_serving\': {\n                \'signature_names\': [\'classification\', \'regression\']\n            },\n            \'split_name\': \'eval\',\n            \'num_examples\': 3\n        })\n    )\n\n    # Total 6 requests (3 requests for each signature)\n    self.assertEqual(len(result), 6)\n    self.assertEqual(\n        len([r for r in result\n             if r.model_spec.signature_name == \'classification\']), 3)\n    self.assertEqual(\n        len([r for r in result\n             if r.model_spec.signature_name == \'regression\']), 3)\n\n  def testBuildRequests_DefaultArgument(self):\n    builder_cls = self._PrepareTFServingRequestBuilder()\n    builder = builder_cls.return_value\n\n    request_builder.build_requests(\n        model_name=\'foo\',\n        model=self._model,\n        examples=self._examples,\n        request_spec=_make_request_spec({\n            \'tensorflow_serving\': {\n                # \'signature_names\': [\'serving_default\']\n            },\n            # \'split_name\': \'eval\',\n            # \'num_examples\': 1\n        })\n    )\n\n    builder.ReadExamplesArtifact.assert_called_with(\n        self._examples,\n        split_name=None,  # Without split_name (will choose any split).\n        num_examples=1)   # Default num_examples = 1.\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/serving_bins.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Modules for organizing various model server binaries.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport os\nfrom typing import Any, Dict, List, Optional, Text\n\nfrom docker import types as docker_types\nimport six\n\nfrom tfx.components.infra_validator.model_server_clients import base_client\nfrom tfx.components.infra_validator.model_server_clients import tensorflow_serving_client\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.utils.model_paths import tf_serving_flavor\n\n\ndef parse_serving_binaries(  # pylint: disable=invalid-name\n    serving_spec: infra_validator_pb2.ServingSpec) -> List[\'ServingBinary\']:\n  """"""Parse `ServingBinary`s from `ServingSpec`.""""""\n  result = []\n  serving_binary = serving_spec.WhichOneof(\'serving_binary\')\n  if serving_binary == \'tensorflow_serving\':\n    config = serving_spec.tensorflow_serving\n    for tag in config.tags:\n      result.append(TensorFlowServing(model_name=serving_spec.model_name,\n                                      tag=tag))\n    for digest in config.digests:\n      result.append(TensorFlowServing(model_name=serving_spec.model_name,\n                                      digest=digest))\n    return result\n  else:\n    raise ValueError(\'Invalid serving_binary {}\'.format(serving_binary))\n\n\nclass ServingBinary(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Base class for serving binaries.""""""\n\n  @abc.abstractproperty\n  def container_port(self) -> int:\n    """"""Container port of the model server.\n\n    Only applies to docker compatible serving binaries.\n    """"""\n    raise NotImplementedError(\'{} is not docker compatible.\'.format(\n        type(self).__name__))\n\n  @abc.abstractproperty\n  def image(self) -> Text:\n    """"""Container image of the model server.\n\n    Only applies to docker compatible serving binaries.\n    """"""\n    raise NotImplementedError(\'{} is not docker compatible.\'.format(\n        type(self).__name__))\n\n  @abc.abstractmethod\n  def MakeEnvVars(self, *args: Any) -> Dict[Text, Text]:\n    """"""Construct environment variables to be used in container image.\n\n    Only applies to docker compatible serving binaries.\n\n    Args:\n      *args: List of unresolved variables to configure environment variables.\n\n    Returns:\n      A dictionary of environment variables inside container.\n    """"""\n    raise NotImplementedError(\'{} is not docker compatible.\'.format(\n        type(self).__name__))\n\n  @abc.abstractmethod\n  def MakeDockerRunParams(self, *args: Any) -> Dict[Text, Text]:\n    """"""Make parameters for docker `client.containers.run`.\n\n    Only applies to docker compatible serving binaries.\n\n    Args:\n      *args: List of unresolved variables to configure docker run parameters.\n\n    Returns:\n      A dictionary of docker run parameters.\n    """"""\n    raise NotImplementedError(\'{} is not docker compatible.\'.format(\n        type(self).__name__))\n\n  @abc.abstractmethod\n  def MakeClient(self, endpoint: Text) -> base_client.BaseModelServerClient:\n    """"""Create a model server client of this serving binary.""""""\n    raise NotImplementedError(\'{} does not implement MakeClient.\'.format(\n        type(self).__name__))\n\n\nclass TensorFlowServing(ServingBinary):\n  """"""TensorFlow Serving binary.""""""\n\n  _BASE_DOCKER_RUN_PARAMS = {\n      # Enable auto-removal of the container on docker daemon after container\n      # process exits.\n      \'auto_remove\': True,\n      # Run container in the background instead of streaming its output.\n      \'detach\': True,\n      # Publish all ports to the host.\n      \'publish_all_ports\': True,\n  }\n  _DEFAULT_IMAGE_NAME = \'tensorflow/serving\'\n  _DEFAULT_GRPC_PORT = 8500\n  _DEFAULT_MODEL_BASE_PATH = \'/model\'\n\n  def __init__(\n      self,\n      model_name: Text,\n      tag: Optional[Text] = None,\n      digest: Optional[Text] = None,\n  ):\n    super(TensorFlowServing, self).__init__()\n    self._model_name = model_name\n    if (tag is None) == (digest is None):\n      raise ValueError(\'Exactly one of `tag` or `digest` should be used.\')\n    if tag is not None:\n      self._image = \'{}:{}\'.format(self._DEFAULT_IMAGE_NAME, tag)\n    else:\n      self._image = \'{}@{}\'.format(self._DEFAULT_IMAGE_NAME, digest)\n\n  @property\n  def container_port(self) -> int:\n    return self._DEFAULT_GRPC_PORT\n\n  @property\n  def image(self) -> Text:\n    return self._image\n\n  def MakeEnvVars(\n      self, model_path: Optional[Text] = None) -> Dict[Text, Text]:\n    if model_path is None:\n      model_base_path = self._DEFAULT_MODEL_BASE_PATH\n    else:\n      model_base_path = tf_serving_flavor.parse_model_base_path(model_path)\n    return {\n        \'MODEL_NAME\': self._model_name,\n        \'MODEL_BASE_PATH\': model_base_path\n    }\n\n  def MakeDockerRunParams(\n      self,\n      model_path: Text,\n      needs_mount: bool) -> Dict[Text, Any]:\n    """"""Make parameters for docker `client.containers.run`.\n\n    Args:\n      model_path: A path to the model.\n      needs_mount: If True, model_path will be mounted to the container.\n\n    Returns:\n      A dictionary of docker run parameters.\n    """"""\n    result = dict(\n        self._BASE_DOCKER_RUN_PARAMS,\n        image=self._image)\n\n    if needs_mount:\n      # model_path should be a local directory. In order to make TF Serving see\n      # the host model path, we need to mount model path volume to the\n      # container.\n      assert os.path.isdir(model_path), \'{} does not exist\'.format(model_path)\n      container_model_path = tf_serving_flavor.make_model_path(\n          model_base_path=self._DEFAULT_MODEL_BASE_PATH,\n          model_name=self._model_name,\n          version=1)\n      result.update(\n          environment=self.MakeEnvVars(),\n          mounts=[\n              docker_types.Mount(\n                  type=\'bind\',\n                  target=container_model_path,\n                  source=model_path,\n                  read_only=True)\n          ])\n    else:\n      # model_path is presumably a remote URI. TF Serving is able to pickup\n      # model in remote directly using gfile, so all we need to do is setting\n      # environment variables correctly.\n      result.update(\n          environment=self.MakeEnvVars(model_path=model_path))\n\n    return result\n\n  def MakeClient(self, endpoint: Text) -> base_client.BaseModelServerClient:\n    return tensorflow_serving_client.TensorFlowServingClient(\n        endpoint=endpoint, model_name=self._model_name)\n'"
tfx/components/infra_validator/types.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common types that are used across infra_validator implementation.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\nfrom typing import Union\n\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import regression_pb2\n\nTensorFlowServingRequest = Union[\n    classification_pb2.ClassificationRequest,\n    regression_pb2.RegressionRequest,\n    predict_pb2.PredictRequest,\n]\n\nRequest = Union[TensorFlowServingRequest]\n\n\nclass ModelServingStatus(enum.Enum):\n  """"""Serving status of the model in the model server.""""""\n  # Model is not ready yet but will be ready soon.\n  NOT_READY = 1\n  # Model is ready.\n  READY = 2\n  # Failed to load a model and will not be recovered. Indicates infra validation\n  # failure.\n  UNAVAILABLE = 3\n'"
tfx/components/model_validator/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/model_validator/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ModelValidator component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.model_validator import driver\nfrom tfx.components.model_validator import executor\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import ModelValidatorSpec\n\n\nclass ModelValidator(base_component.BaseComponent):\n  """"""DEPRECATED: Please use `Evaluator` instead.\n\n  The model validator component can be used to check model metrics threshold\n  and validate current model against a previously validated model. If there\n  isn\'t a prior validated model, model validator will just make sure the\n  threshold passed.  Otherwise, ModelValidator compares a newly trained models\n  against a known good model, specifically the last model ""blessed"" by this\n  component.  A model is ""blessed"" if the exported model\'s metrics are within\n  predefined thresholds around the prior model\'s metrics.\n\n  *Note:* This component includes a driver to resolve last blessed model.\n\n  ## Possible causes why model validation fails\n  Model validation can fail for many reasons, but these are the most common:\n\n  - problems with training data.  For example, negative examples are dropped or\n    features are missing.\n  - problems with the test or evaluation data.  For example, skew exists between\n    the training and evaluation data.\n  - changes in data distribution.  This indicates the user behavior may have\n    changed over time.\n  - problems with the trainer.  For example, the trainer was stopped before\n    model is converged or the model is unstable.\n\n  ## Example\n  ```\n    # Performs quality validation of a candidate model (compared to a baseline).\n    model_validator = ModelValidator(\n        examples=example_gen.outputs[\'examples\'],\n        model=trainer.outputs[\'model\'])\n  ```\n  """"""\n\n  SPEC_CLASS = ModelValidatorSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n  DRIVER_CLASS = driver.Driver\n\n  @deprecation.deprecated(\n      None, \'ModelValidator is deprecated, use Evaluator instead.\')\n  def __init__(self,\n               examples: types.Channel,\n               model: types.Channel,\n               blessing: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct a ModelValidator component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, usually\n        produced by an\n        [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) component.\n        _required_\n      model: A Channel of type `standard_artifacts.Model`, usually produced by\n        a [Trainer](https://www.tensorflow.org/tfx/guide/trainer) component.\n        _required_\n      blessing: Output channel of \'ModelBlessingPath\' that contains the\n        validation result.\n      instance_name: Optional name assigned to this specific instance of\n        ModelValidator.  Required only if multiple ModelValidator components are\n        declared in the same pipeline.\n    """"""\n    blessing = blessing or types.Channel(\n        type=standard_artifacts.ModelBlessing,\n        artifacts=[standard_artifacts.ModelBlessing()])\n    spec = ModelValidatorSpec(examples=examples, model=model, blessing=blessing)\n    super(ModelValidator, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/model_validator/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.model_validator.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.model_validator import component\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    examples = standard_artifacts.Examples()\n    model = standard_artifacts.Model()\n    model_validator = component.ModelValidator(\n        examples=channel_utils.as_channel([examples]),\n        model=channel_utils.as_channel([model]))\n    self.assertEqual(standard_artifacts.ModelBlessing.TYPE_NAME,\n                     model_validator.outputs[\'blessing\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/model_validator/constants.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Constant values for ModelValidator.""""""\n\n# Key for examples in executor input_dict.\nEXAMPLES_KEY = \'examples\'\n# Key for model in executor input_dict.\nMODEL_KEY = \'model\'\n\n# Key for model blessing in executor output_dict.\nBLESSING_KEY = \'blessing\'\n\n# Keys for artifact (custom) properties.\nARTIFACT_PROPERTY_BLESSED_KEY = \'blessed\'\nARTIFACT_PROPERTY_CURRENT_MODEL_URI_KEY = \'current_model\'\nARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY = \'current_model_id\'\nARTIFACT_PROPERTY_BLESSED_MODEL_URI_KEY = \'blessed_model\'\nARTIFACT_PROPERTY_BLESSED_MODEL_ID_KEY = \'blessed_model_id\'\n\n# Paths to store model eval results for validation.\nCURRENT_MODEL_EVAL_RESULT_PATH = \'eval_results/current_model\'\nBLESSED_MODEL_EVAL_RESULT_PATH = \'eval_results/blessed_model\'\n\n# Values for blessing results.\nBLESSED_VALUE = 1\nNOT_BLESSED_VALUE = 0\n\n# File names for blessing results.\nBLESSED_FILE_NAME = \'BLESSED\'\nNOT_BLESSED_FILE_NAME = \'NOT_BLESSED\'\n'"
tfx/components/model_validator/driver.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX model validator custom driver.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Tuple\n\nimport absl\n\nfrom tfx.components.base import base_driver\nfrom tfx.orchestration import data_types\n\n\nclass Driver(base_driver.BaseDriver):\n  """"""Custom driver for model validator.""""""\n\n  def _fetch_last_blessed_model(\n      self,\n      pipeline_name: Text,\n      component_id: Text,\n  ) -> Tuple[Optional[Text], Optional[int]]:\n    """"""Fetch last blessed model in metadata based on span.""""""\n    previous_blessed_models = []\n    for a in self._metadata_handler.get_artifacts_by_type(\'ModelBlessing\'):\n      # TODO(ccy): get pipeline name from MLMD context.\n      if \'pipeline_name\' in a.properties:\n        p = a.properties[\'pipeline_name\'].string_value\n      else:\n        p = a.custom_properties[\'pipeline_name\'].string_value\n      if (p == pipeline_name and\n          a.custom_properties[\'blessed\'].int_value == 1 and\n          a.custom_properties[\'component_id\'].string_value == component_id):\n        previous_blessed_models.append(a)\n\n    if previous_blessed_models:\n      # TODO(b/138845899): consider use span instead of id.\n      last_blessed_model = max(\n          previous_blessed_models, key=lambda artifact: artifact.id)\n      return (\n          last_blessed_model.custom_properties[\'current_model\'].string_value,\n          last_blessed_model.custom_properties[\'current_model_id\'].int_value)\n    else:\n      return None, None\n\n  # pyformat: disable\n  def resolve_exec_properties(\n      self, exec_properties: Dict[Text, Any],\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo) -> Dict[Text, Any]:\n    # pyformat: enable\n    """"""Overrides BaseDriver.resolve_exec_properties().""""""\n    (exec_properties[\'blessed_model\'],\n     exec_properties[\'blessed_model_id\']) = self._fetch_last_blessed_model(\n         pipeline_info.pipeline_name, component_info.component_id)\n    exec_properties[\'current_component_id\'] = component_info.component_id\n    absl.logging.info(\'Resolved last blessed model {}\'.format(\n        exec_properties[\'blessed_model\']))\n    return exec_properties\n'"
tfx/components/model_validator/driver_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.model_validator.driver.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.components.model_validator import driver\nfrom tfx.types import standard_artifacts\n\n\nclass DriverTest(tf.test.TestCase):\n\n  def _create_mock_artifact(self, aid: int, is_blessed: bool,\n                            pipeline_name: Text, component_id: Text):\n    model_blessing = standard_artifacts.ModelBlessing()\n    model_blessing.id = aid\n    model_blessing.pipeline_name = pipeline_name\n    model_blessing.set_string_custom_property(\'current_model\', \'uri-%d\' % aid)\n    model_blessing.set_int_custom_property(\'current_model_id\', aid)\n    model_blessing.set_string_custom_property(\'component_id\', component_id)\n    model_blessing.set_int_custom_property(\'blessed\', is_blessed)\n    return model_blessing.mlmd_artifact\n\n  def testFetchLastBlessedModel(self):\n    # Mock metadata.\n    mock_metadata = tf.compat.v1.test.mock.Mock()\n    model_validator_driver = driver.Driver(mock_metadata)\n    component_id = \'test_component\'\n    pipeline_name = \'test_pipeline\'\n\n    # No blessed model.\n    mock_metadata.get_artifacts_by_type.return_value = []\n    self.assertEqual((None, None),\n                     model_validator_driver._fetch_last_blessed_model(\n                         pipeline_name, component_id))\n\n    # Mock blessing artifacts.\n    artifacts = [\n        self._create_mock_artifact(aid, aid % 2, pipeline_name, component_id)\n        for aid in [4, 3, 2, 1]\n    ]\n\n    # Mock blessing artifact produced by another component.\n    artifacts.append(\n        self._create_mock_artifact(\n            aid=5,\n            is_blessed=True,\n            pipeline_name=pipeline_name,\n            component_id=\'different_component\'))\n\n    mock_metadata.get_artifacts_by_type.return_value = artifacts\n    self.assertEqual((\'uri-3\', 3),\n                     model_validator_driver._fetch_last_blessed_model(\n                         pipeline_name, component_id))\n\n    # Mock blessing artifact produced by another pipeline.\n    artifacts.append(\n        self._create_mock_artifact(\n            aid=6,\n            is_blessed=True,\n            pipeline_name=\'different_pipeline\',\n            component_id=component_id))\n\n    mock_metadata.get_artifacts_by_type.return_value = artifacts\n    self.assertEqual((\'uri-3\', 3),\n                     model_validator_driver._fetch_last_blessed_model(\n                         pipeline_name, component_id))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/model_validator/executor.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX model validator executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.model_validator import constants\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""DEPRECATED: Please use `Evaluator` instead.\n\n  The model validator helps prevent bad models from being pushed to production.\n  It does this by validating exported models against known good models (e.g. the\n  current production model), and marking the exported model as good (""blessing\n  it"") only if the exported model\'s metrics are within predefined thresholds\n  around the good model\'s metrics.\n\n  The model validator will validate tf.serving format exported models produced\n  by the Trainer component. The validator evaluates the models on examples\n  created by the ExampleGen component. The validator will also automatically\n  read data written by the Pusher component regarding the latest pushed models\n  by using ml.metadata to query the previously pushed artifacts.\n\n  To include ModelValidator in a TFX pipeline, configure your pipeline similar\n  to\n  https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple.py#L110.\n\n  """"""\n\n  # TODO(jyzhao): customized threshold support.\n  def _pass_threshold(self, eval_result: tfma.EvalResult) -> bool:\n    """"""Check threshold.""""""\n    return True\n\n  # TODO(jyzhao): customized validation support.\n  def _compare_eval_result(self, current_model_eval_result: tfma.EvalResult,\n                           blessed_model_eval_result: tfma.EvalResult) -> bool:\n    """"""Compare accuracy of all metrics and return true if current is better or equal.""""""\n    for current_metric, blessed_metric in zip(\n        current_model_eval_result.slicing_metrics,\n        blessed_model_eval_result.slicing_metrics):\n      # slicing_metric is a tuple, index 0 is slice, index 1 is its value.\n      if current_metric[0] != blessed_metric[0]:\n        raise RuntimeError(\'EvalResult not match {} vs {}.\'.format(\n            current_metric[0], blessed_metric[0]))\n      # TODO(b/140455644): TFMA introduced breaking change post 0.14 release.\n      # Remove this forward compatibility change after 0.15 release.\n      current_model_metrics = current_metric[1]\n      blessed_model_metrics = blessed_metric[1]\n      try:\n        current_model_accuracy = current_model_metrics[\'accuracy\']\n        blessed_model_accuracy = blessed_model_metrics[\'accuracy\']\n      except KeyError:\n        current_model_accuracy = current_model_metrics[\'\'][\'\'][\'accuracy\']\n        blessed_model_accuracy = blessed_model_metrics[\'\'][\'\'][\'accuracy\']\n      if (current_model_accuracy[\'doubleValue\'] <\n          blessed_model_accuracy[\'doubleValue\']):\n        absl.logging.info(\n            \'Current model accuracy is worse than blessed model: {}\'.format(\n                current_metric[0]))\n        return False\n    return True\n\n  def _generate_blessing_result(self, eval_examples_uri: Text,\n                                slice_spec: List[tfma.slicer.SingleSliceSpec],\n                                current_model_dir: Text,\n                                blessed_model_dir: Text) -> bool:\n    current_model_eval_result_path = os.path.join(\n        self._temp_path, constants.CURRENT_MODEL_EVAL_RESULT_PATH)\n    blessed_model_eval_result_path = os.path.join(\n        self._temp_path, constants.BLESSED_MODEL_EVAL_RESULT_PATH)\n\n    with self._make_beam_pipeline() as pipeline:\n      eval_data = (\n          pipeline | \'ReadData\' >> beam.io.ReadFromTFRecord(\n              file_pattern=io_utils.all_files_pattern(eval_examples_uri)))\n\n      current_model = tfma.default_eval_shared_model(\n          eval_saved_model_path=path_utils.eval_model_path(current_model_dir))\n      (eval_data | \'EvalCurrentModel\' >> tfma.ExtractEvaluateAndWriteResults(  # pylint: disable=expression-not-assigned\n          eval_shared_model=current_model,\n          slice_spec=slice_spec,\n          output_path=current_model_eval_result_path))\n\n      if blessed_model_dir is not None:\n        blessed_model = tfma.default_eval_shared_model(\n            eval_saved_model_path=path_utils.eval_model_path(blessed_model_dir))\n        (eval_data | \'EvalBlessedModel\' >> tfma.ExtractEvaluateAndWriteResults(  # pylint: disable=expression-not-assigned\n            eval_shared_model=blessed_model,\n            slice_spec=slice_spec,\n            output_path=blessed_model_eval_result_path))\n\n    absl.logging.info(\'all files in current_model_eval_result_path: [%s]\',\n                      str(tf.io.gfile.listdir(current_model_eval_result_path)))\n    current_model_eval_result = tfma.load_eval_result(\n        output_path=current_model_eval_result_path)\n\n    if not self._pass_threshold(current_model_eval_result):\n      absl.logging.info(\'Current model does not pass threshold.\')\n      return False\n    absl.logging.info(\'Current model passes threshold.\')\n\n    if blessed_model_dir is None:\n      absl.logging.info(\'No blessed model yet.\')\n      return True\n    absl.logging.info(\'all files in blessed_model_eval_result: [%s]\',\n                      str(tf.io.gfile.listdir(blessed_model_eval_result_path)))\n    blessed_model_eval_result = tfma.load_eval_result(\n        output_path=blessed_model_eval_result_path)\n\n    if (self._compare_eval_result(current_model_eval_result,\n                                  blessed_model_eval_result)):\n      absl.logging.info(\'Current model better than blessed model.\')\n      return True\n    else:\n      absl.logging.info(\'Current model worse than blessed model.\')\n      return False\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Validate current model against last blessed model.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts.\n        - examples: examples for eval the model.\n        - model: current model for validation.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - blessing: model blessing result.\n      exec_properties: A dict of execution properties.\n        - blessed_model: last blessed model for validation.\n        - blessed_model_id: last blessed model id.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n    self._temp_path = self._get_tmp_dir()\n    absl.logging.info(\'Using temp path {} for tft.beam\'.format(self._temp_path))\n\n    eval_examples_uri = artifact_utils.get_split_uri(\n        input_dict[constants.EXAMPLES_KEY], \'eval\')\n    blessing = artifact_utils.get_single_instance(\n        output_dict[constants.BLESSING_KEY])\n\n    # Current model to be validated.\n    current_model = artifact_utils.get_single_instance(\n        input_dict[constants.MODEL_KEY])\n    absl.logging.info(\'Using {} as current model.\'.format(current_model.uri))\n    blessing.set_string_custom_property(\n        constants.ARTIFACT_PROPERTY_CURRENT_MODEL_URI_KEY, current_model.uri)\n    blessing.set_int_custom_property(\n        constants.ARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY, current_model.id)\n\n    # Denote model component_name.\n    component_id = exec_properties[\'current_component_id\']\n    blessing.set_string_custom_property(\'component_id\', component_id)\n\n    # Previous blessed model to be validated against.\n    blessed_model_dir = exec_properties[\'blessed_model\']\n    blessed_model_id = exec_properties[\'blessed_model_id\']\n    absl.logging.info(\'Using {} as blessed model.\'.format(blessed_model_dir))\n    if blessed_model_dir:\n      blessing.set_string_custom_property(\n          constants.ARTIFACT_PROPERTY_BLESSED_MODEL_URI_KEY, blessed_model_dir)\n      blessing.set_int_custom_property(\n          constants.ARTIFACT_PROPERTY_BLESSED_MODEL_ID_KEY, blessed_model_id)\n\n    absl.logging.info(\'Validating model.\')\n    # TODO(b/125853306): support customized slice spec.\n    blessed = self._generate_blessing_result(\n        eval_examples_uri=eval_examples_uri,\n        slice_spec=[tfma.slicer.SingleSliceSpec()],\n        current_model_dir=current_model.uri,\n        blessed_model_dir=blessed_model_dir)\n\n    if blessed:\n      io_utils.write_string_file(\n          os.path.join(blessing.uri, constants.BLESSED_FILE_NAME), \'\')\n      blessing.set_int_custom_property(constants.ARTIFACT_PROPERTY_BLESSED_KEY,\n                                       constants.BLESSED_VALUE)\n    else:\n      io_utils.write_string_file(\n          os.path.join(blessing.uri, constants.NOT_BLESSED_FILE_NAME), \'\')\n      blessing.set_int_custom_property(constants.ARTIFACT_PROPERTY_BLESSED_KEY,\n                                       constants.NOT_BLESSED_VALUE)\n    absl.logging.info(\'Blessing result {} written to {}.\'.format(\n        blessed, blessing.uri))\n\n    io_utils.delete_dir(self._temp_path)\n    absl.logging.info(\'Cleaned up temp path {} on executor success.\'.format(\n        self._temp_path))\n'"
tfx/components/model_validator/executor_test.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.model_validator.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\nfrom tfx.components.model_validator import constants\nfrom tfx.components.model_validator import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self.component_id = \'test_component\'\n\n    # Create input dict.\n    eval_examples = standard_artifacts.Examples()\n    eval_examples.split_names = artifact_utils.encode_split_names([\'eval\'])\n    eval_examples.uri = os.path.join(self._source_data_dir, \'csv_example_gen\')\n    model = standard_artifacts.Model()\n    model.uri = os.path.join(self._source_data_dir, \'trainer/current\')\n    self._input_dict = {\n        constants.EXAMPLES_KEY: [eval_examples],\n        constants.MODEL_KEY: [model],\n    }\n\n    # Create output dict.\n    self._blessing = standard_artifacts.ModelBlessing()\n    self._blessing.uri = os.path.join(output_data_dir, \'blessing\')\n    self._output_dict = {constants.BLESSING_KEY: [self._blessing]}\n\n    # Create context\n    self._tmp_dir = os.path.join(output_data_dir, \'.temp\')\n    self._context = executor.Executor.Context(tmp_dir=self._tmp_dir,\n                                              unique_id=\'2\')\n\n  def testDoWithBlessedModel(self):\n    # Create exe properties.\n    exec_properties = {\n        \'blessed_model\': os.path.join(self._source_data_dir, \'trainer/blessed\'),\n        \'blessed_model_id\': 123,\n        \'current_component_id\': self.component_id,\n    }\n\n    # Run executor.\n    model_validator = executor.Executor(self._context)\n    model_validator.Do(self._input_dict, self._output_dict, exec_properties)\n\n    # Check model validator outputs.\n    self.assertTrue(tf.io.gfile.exists(os.path.join(self._tmp_dir)))\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(self._blessing.uri, constants.BLESSED_FILE_NAME)))\n\n  def testDoWithoutBlessedModel(self):\n    # Create exe properties.\n    exec_properties = {\n        \'blessed_model\': None,\n        \'blessed_model_id\': None,\n        \'current_component_id\': self.component_id,\n    }\n\n    # Run executor.\n    model_validator = executor.Executor(self._context)\n    model_validator.Do(self._input_dict, self._output_dict, exec_properties)\n\n    # Check model validator outputs.\n    self.assertTrue(tf.io.gfile.exists(os.path.join(self._tmp_dir)))\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(self._blessing.uri, constants.BLESSED_FILE_NAME)))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/pusher/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/pusher/component.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Pusher component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.pusher import executor\nfrom tfx.proto import pusher_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import PusherSpec\nfrom tfx.utils import json_utils\n\n\n# TODO(b/133845381): Investigate other ways to keep push destination converged.\nclass Pusher(base_component.BaseComponent):\n  """"""A TFX component to push validated TensorFlow models to a model serving platform.\n\n  The `Pusher` component can be used to push an validated SavedModel from output\n  of the [Trainer component](https://www.tensorflow.org/tfx/guide/trainer) to\n  [TensorFlow Serving](https://www.tensorflow.org/tfx/serving).  The Pusher\n  will check the validation results from the [Evaluator\n  component](https://www.tensorflow.org/tfx/guide/evaluator) and [InfraValidator\n  component](https://www.tensorflow.org/tfx/guide/infra_validator)\n  before deploying the model.  If the model has not been blessed, then the model\n  will not be pushed.\n\n  *Note:* The executor for this component can be overriden to enable the model\n  to be pushed to other serving platforms than tf.serving.  The [Cloud AI\n  Platform custom\n  executor](https://github.com/tensorflow/tfx/tree/master/tfx/extensions/google_cloud_ai_platform/pusher)\n  provides an example how to implement this.\n\n  ## Example\n  ```\n    # Checks whether the model passed the validation steps and pushes the model\n    # to a file destination if check passed.\n    pusher = Pusher(\n        model=trainer.outputs[\'model\'],\n        model_blessing=evaluator.outputs[\'blessing\'],\n        push_destination=pusher_pb2.PushDestination(\n            filesystem=pusher_pb2.PushDestination.Filesystem(\n                base_directory=serving_model_dir)))\n  ```\n  """"""\n\n  SPEC_CLASS = PusherSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      model: types.Channel = None,\n      model_blessing: types.Channel = None,\n      infra_blessing: Optional[types.Channel] = None,\n      push_destination: Optional[Union[pusher_pb2.PushDestination,\n                                       Dict[Text, Any]]] = None,\n      custom_config: Optional[Dict[Text, Any]] = None,\n      custom_executor_spec: Optional[executor_spec.ExecutorSpec] = None,\n      output: Optional[types.Channel] = None,\n      model_export: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a Pusher component.\n\n    Args:\n      model: A Channel of type `standard_artifacts.Model`, usually produced by\n        a Trainer component.\n      model_blessing: A Channel of type `standard_artifacts.ModelBlessing`,\n        usually produced by a Evaluator component. _required_\n      infra_blessing: An optional Channel of type\n        `standard_artifacts.InfraBlessing`, usually produced from an\n        InfraValidator component.\n      push_destination: A pusher_pb2.PushDestination instance, providing info\n        for tensorflow serving to load models. Optional if executor_class\n        doesn\'t require push_destination. If any field is provided as a\n        RuntimeParameter, push_destination should be constructed as a dict with\n        the same field names as PushDestination proto message.\n      custom_config: A dict which contains the deployment job parameters to be\n        passed to cloud-based training platforms. The [Kubeflow example](\n          https://github.com/tensorflow/tfx/blob/6ff57e36a7b65818d4598d41e584a42584d361e6/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_gcp.py#L278-L285)\n          contains an example how this can be used by custom executors.\n      custom_executor_spec: Optional custom executor spec.\n      output: Optional output `standard_artifacts.PushedModel` channel with\n        result of push.\n      model_export: Backwards compatibility alias for the \'model\' argument.\n      instance_name: Optional unique instance name. Necessary if multiple Pusher\n        components are declared in the same pipeline.\n    """"""\n    if model_export:\n      absl.logging.warning(\n          \'The ""model_export"" argument to the Pusher component has \'\n          \'been renamed to ""model"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      model = model_export\n    output = output or types.Channel(\n        type=standard_artifacts.PushedModel,\n        artifacts=[standard_artifacts.PushedModel()])\n    if push_destination is None and not custom_executor_spec:\n      raise ValueError(\'push_destination is required unless a \'\n                       \'custom_executor_spec is supplied that does not require \'\n                       \'it.\')\n    spec = PusherSpec(\n        model=model,\n        model_blessing=model_blessing,\n        infra_blessing=infra_blessing,\n        push_destination=push_destination,\n        custom_config=json_utils.dumps(custom_config),\n        pushed_model=output)\n    super(Pusher, self).__init__(\n        spec=spec,\n        custom_executor_spec=custom_executor_spec,\n        instance_name=instance_name)\n'"
tfx/components/pusher/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.pusher.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\nimport tensorflow as tf\nfrom tfx.components.base import executor_spec\nfrom tfx.components.pusher import component\nfrom tfx.components.pusher import executor\nfrom tfx.orchestration import data_types\nfrom tfx.proto import pusher_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  class _MyCustomPusherExecutor(executor.Executor):\n    """"""Mock class to test custom executor injection.""""""\n    pass\n\n  def setUp(self):\n    super(ComponentTest, self).setUp()\n    self.model = channel_utils.as_channel([standard_artifacts.Model()])\n    self.model_blessing = channel_utils.as_channel(\n        [standard_artifacts.ModelBlessing()])\n\n  def testConstruct(self):\n    pusher = component.Pusher(\n        model=self.model,\n        model_blessing=self.model_blessing,\n        push_destination=pusher_pb2.PushDestination(\n            filesystem=pusher_pb2.PushDestination.Filesystem(\n                base_directory=\'push_destination\')))\n    self.assertEqual(standard_artifacts.PushedModel.TYPE_NAME,\n                     pusher.outputs[\'pushed_model\'].type_name)\n\n  def testConstructWithParameter(self):\n    push_dir = data_types.RuntimeParameter(name=\'push-dir\', ptype=Text)\n    pusher = component.Pusher(\n        model=self.model,\n        model_blessing=self.model_blessing,\n        push_destination={\'filesystem\': {\n            \'base_directory\': push_dir\n        }})\n    self.assertEqual(standard_artifacts.PushedModel.TYPE_NAME,\n                     pusher.outputs[\'pushed_model\'].type_name)\n\n  def testConstructNoDestination(self):\n    with self.assertRaises(ValueError):\n      _ = component.Pusher(\n          model=self.model,\n          model_blessing=self.model_blessing,\n      )\n\n  def testConstructNoDestinationCustomExecutor(self):\n    pusher = component.Pusher(\n        model=self.model,\n        model_blessing=self.model_blessing,\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            self._MyCustomPusherExecutor),\n    )\n    self.assertEqual(standard_artifacts.PushedModel.TYPE_NAME,\n                     pusher.outputs[\'pushed_model\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/pusher/executor.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX pusher executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport time\nfrom typing import Any, Dict, List, Optional, Text\n\nfrom absl import logging\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.util import model_utils\nfrom tfx.proto import pusher_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n# Aliasing of enum for better readability.\n_Versioning = pusher_pb2.Versioning\n\n# Key for model in executor input_dict.\nMODEL_KEY = \'model\'\n# Key for model blessing in executor input_dict.\nMODEL_BLESSING_KEY = \'model_blessing\'\n# Key for infra blessing in executor input_dict.\nINFRA_BLESSING_KEY = \'infra_blessing\'\n# Key for pushed model in executor output_dict.\nPUSHED_MODEL_KEY = \'pushed_model\'\n\n# Key for PushedModel artifact properties.\n_PUSHED_KEY = \'pushed\'\n_PUSHED_DESTINATION_KEY = \'pushed_destination\'\n_PUSHED_VERSION_KEY = \'pushed_version\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TFX Pusher executor to push the new TF model to a filesystem target.\n\n  The Pusher component is used to deploy a validated model to a filesystem\n  target or serving environment using tf.serving.  Pusher depends on the outputs\n  of ModelValidator to determine if a model is ready to push. A model is\n  considered to be safe to push only if ModelValidator has marked it as BLESSED.\n  A push action delivers the model exports produced by Trainer to the\n  destination defined in the ``push_destination`` of the component config.\n\n  To include Pusher in a TFX pipeline, configure your pipeline similar to\n  https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple.py#L104.\n\n  For more details on tf.serving itself, please refer to\n  https://tensorflow.org/tfx/guide/pusher.  For a tutuorial on TF Serving,\n  please refer to https://www.tensorflow.org/tfx/guide/serving.\n  """"""\n\n  def CheckBlessing(self, input_dict: Dict[Text, List[types.Artifact]]) -> bool:\n    """"""Check that model is blessed by upstream validators.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts:\n        - model_blessing: A `ModelBlessing` artifact from model validator or\n          evaluator.\n          Pusher looks for a custom property `blessed` in the artifact to check\n          it is safe to push.\n        - infra_blessing: An `InfraBlessing` artifact from infra validator.\n          Pusher looks for a custom proeprty `blessed` in the artifact to\n          determine whether the model is mechanically servable from the model\n          server to which Pusher is going to push.\n\n    Returns:\n      True if the model is blessed by validator.\n    """"""\n    model_blessing = artifact_utils.get_single_instance(\n        input_dict[MODEL_BLESSING_KEY])\n    # TODO(jyzhao): should this be in driver or executor.\n    if not model_utils.is_model_blessed(model_blessing):\n      logging.info(\'Model on %s was not blessed by model validation\',\n                   model_blessing.uri)\n      return False\n    if INFRA_BLESSING_KEY in input_dict:\n      infra_blessing = artifact_utils.get_single_instance(\n          input_dict[INFRA_BLESSING_KEY])\n      if not model_utils.is_infra_validated(infra_blessing):\n        logging.info(\'Model on %s was not blessed by infra validator\',\n                     model_blessing.uri)\n        return False\n    return True\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Push model to target directory if blessed.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - model_export: exported model from trainer.\n        - model_blessing: model blessing path from model_validator.  A push\n          action delivers the model exports produced by Trainer to the\n          destination defined in component config.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - model_push: A list of \'ModelPushPath\' artifact of size one. It will\n          include the model in this push execution if the model was pushed.\n      exec_properties: A dict of execution properties, including:\n        - push_destination: JSON string of pusher_pb2.PushDestination instance,\n          providing instruction of destination to push model.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n    model_push = artifact_utils.get_single_instance(\n        output_dict[PUSHED_MODEL_KEY])\n    if not self.CheckBlessing(input_dict):\n      self._MarkNotPushed(model_push)\n      return\n    model_export = artifact_utils.get_single_instance(input_dict[MODEL_KEY])\n    model_path = path_utils.serving_model_path(model_export.uri)\n\n    # Push model to the destination, which can be listened by a model server.\n    #\n    # If model is already successfully copied to outside before, stop copying.\n    # This is because model validator might blessed same model twice (check\n    # mv driver) with different blessing output, we still want Pusher to\n    # handle the mv output again to keep metadata tracking, but no need to\n    # copy to outside path again..\n    # TODO(jyzhao): support rpc push and verification.\n    push_destination = pusher_pb2.PushDestination()\n    json_format.Parse(exec_properties[\'push_destination\'], push_destination)\n\n    destination_kind = push_destination.WhichOneof(\'destination\')\n    if destination_kind == \'filesystem\':\n      fs_config = push_destination.filesystem\n      if fs_config.versioning == _Versioning.AUTO:\n        fs_config.versioning = _Versioning.UNIX_TIMESTAMP\n      if fs_config.versioning == _Versioning.UNIX_TIMESTAMP:\n        model_version = str(int(time.time()))\n      else:\n        raise NotImplementedError(\n            \'Invalid Versioning {}\'.format(fs_config.versioning))\n      logging.info(\'Model version: %s\', model_version)\n      serving_path = os.path.join(fs_config.base_directory, model_version)\n\n      if tf.io.gfile.exists(serving_path):\n        logging.info(\n            \'Destination directory %s already exists, skipping current push.\',\n            serving_path)\n      else:\n        # tf.serving won\'t load partial model, it will retry until fully copied.\n        io_utils.copy_dir(model_path, serving_path)\n        logging.info(\'Model written to serving path %s.\', serving_path)\n    else:\n      raise NotImplementedError(\n          \'Invalid push destination {}\'.format(destination_kind))\n\n    # Copy the model to pushing uri for archiving.\n    io_utils.copy_dir(model_path, model_push.uri)\n    self._MarkPushed(model_push,\n                     pushed_destination=serving_path,\n                     pushed_version=model_version)\n    logging.info(\'Model pushed to %s.\', model_push.uri)\n\n  def _MarkPushed(self, model_push: types.Artifact, pushed_destination: Text,\n                  pushed_version: Optional[Text] = None) -> None:\n    model_push.set_int_custom_property(\'pushed\', 1)\n    model_push.set_string_custom_property(\n        _PUSHED_DESTINATION_KEY, pushed_destination)\n    if pushed_version is not None:\n      model_push.set_string_custom_property(_PUSHED_VERSION_KEY, pushed_version)\n\n  def _MarkNotPushed(self, model_push: types.Artifact):\n    model_push.set_int_custom_property(\'pushed\', 0)\n'"
tfx/components/pusher/executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.pusher.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport tensorflow as tf\n\nfrom tfx.components.pusher import executor\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(self._output_data_dir)\n    self._model_export = standard_artifacts.Model()\n    self._model_export.uri = os.path.join(self._source_data_dir,\n                                          \'trainer/current\')\n    self._model_blessing = standard_artifacts.ModelBlessing()\n    self._input_dict = {\n        executor.MODEL_KEY: [self._model_export],\n        executor.MODEL_BLESSING_KEY: [self._model_blessing],\n    }\n\n    self._model_push = standard_artifacts.PushedModel()\n    self._model_push.uri = os.path.join(self._output_data_dir, \'model_push\')\n    tf.io.gfile.makedirs(self._model_push.uri)\n    self._output_dict = {\n        executor.PUSHED_MODEL_KEY: [self._model_push],\n    }\n    self._serving_model_dir = os.path.join(self._output_data_dir,\n                                           \'serving_model_dir\')\n    tf.io.gfile.makedirs(self._serving_model_dir)\n    self._exec_properties = self._MakeExecProperties()\n    self._executor = executor.Executor()\n\n  def _MakeExecProperties(self, versioning=\'AUTO\'):\n    return {\n        \'push_destination\': json.dumps({\n            \'filesystem\': {\n                \'base_directory\': self._serving_model_dir,\n                \'versioning\': versioning\n            }\n        })\n    }\n\n  def assertDirectoryEmpty(self, path):\n    self.assertEqual(len(tf.io.gfile.listdir(path)), 0)\n\n  def assertDirectoryNotEmpty(self, path):\n    self.assertGreater(len(tf.io.gfile.listdir(path)), 0)\n\n  def assertPushed(self):\n    self.assertDirectoryNotEmpty(self._serving_model_dir)\n    self.assertDirectoryNotEmpty(self._model_push.uri)\n    self.assertEqual(1, self._model_push.get_int_custom_property(\'pushed\'))\n\n  def assertNotPushed(self):\n    self.assertDirectoryEmpty(self._serving_model_dir)\n    self.assertDirectoryEmpty(self._model_push.uri)\n    self.assertEqual(0, self._model_push.get_int_custom_property(\'pushed\'))\n\n  def testDoBlessed(self):\n    # Prepare blessed ModelBlessing.\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)\n\n    # Run executor with blessed.\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._exec_properties)\n\n    # Check model successfully pushed.\n    self.assertPushed()\n    version = self._model_push.get_string_custom_property(\'pushed_version\')\n    self.assertTrue(version.isdigit())\n    self.assertEqual(\n        self._model_push.get_string_custom_property(\'pushed_destination\'),\n        os.path.join(self._serving_model_dir, version))\n\n  def testDoNotBlessed(self):\n    # Prepare not blessed ModelBlessing.\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/not_blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 0)\n\n    # Run executor with not blessed.\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._exec_properties)\n\n    # Check model not pushed.\n    self.assertNotPushed()\n\n  def testDo_ModelBlessedAndInfraBlessed_Pushed(self):\n    # Prepare blessed ModelBlessing and blessed InfraBlessing.\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)  # Blessed.\n    infra_blessing = standard_artifacts.InfraBlessing()\n    infra_blessing.set_int_custom_property(\'blessed\', 1)  # Blessed.\n    input_dict = {\'infra_blessing\': [infra_blessing]}\n    input_dict.update(self._input_dict)\n\n    # Run executor\n    self._executor.Do(input_dict, self._output_dict, self._exec_properties)\n\n    # Check model is pushed.\n    self.assertPushed()\n\n  def testDo_InfraNotBlessed_NotPushed(self):\n    # Prepare blessed ModelBlessing and **not** blessed InfraBlessing.\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)  # Blessed.\n    infra_blessing = standard_artifacts.InfraBlessing()\n    infra_blessing.set_int_custom_property(\'blessed\', 0)  # Not blessed.\n    input_dict = {\'infra_blessing\': [infra_blessing]}\n    input_dict.update(self._input_dict)\n\n    # Run executor\n    self._executor.Do(input_dict, self._output_dict, self._exec_properties)\n\n    # Check model is not pushed.\n    self.assertNotPushed()\n\n  def testDo_KerasModelPath(self):\n    # Prepare blessed ModelBlessing.\n    self._model_export.uri = os.path.join(self._source_data_dir,\n                                          \'trainer/keras\')\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)\n\n    # Run executor\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._exec_properties)\n\n    # Check model is pushed.\n    self.assertPushed()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/schema_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/schema_gen/component.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ExampleValidator component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.schema_gen import executor\nfrom tfx.orchestration import data_types\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import SchemaGenSpec\n\n\nclass SchemaGen(base_component.BaseComponent):\n  """"""A TFX SchemaGen component to generate a schema from the training data.\n\n  The SchemaGen component uses [TensorFlow Data\n  Validation](https://www.tensorflow.org/tfx/data_validation) to\n  generate a schema from input statistics.  The following TFX libraries use the\n  schema:\n    - TensorFlow Data Validation\n    - TensorFlow Transform\n    - TensorFlow Model Analysis\n\n  In a typical TFX pipeline, the SchemaGen component generates a schema which is\n  is consumed by the other pipeline components.\n\n  Please see https://www.tensorflow.org/tfx/data_validation for more details.\n\n  ## Example\n  ```\n    # Generates schema based on statistics files.\n    infer_schema = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n  ```\n  """"""\n  # TODO(b/123941608): Update pydoc about how to use a user provided schema\n\n  SPEC_CLASS = SchemaGenSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      statistics: Optional[types.Channel] = None,\n      infer_feature_shape: Optional[Union[bool,\n                                          data_types.RuntimeParameter]] = False,\n      output: Optional[types.Channel] = None,\n      stats: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Constructs a SchemaGen component.\n\n    Args:\n      statistics: A Channel of `ExampleStatistics` type (required if spec is not\n        passed). This should contain at least a `train` split. Other splits are\n        currently ignored. _required_\n      infer_feature_shape: Boolean (or RuntimeParameter) value indicating\n        whether or not to infer the shape of features. If the feature shape is\n        not inferred, downstream Tensorflow Transform component using the schema\n        will parse input as tf.SparseTensor.\n      output: Output `Schema` channel for schema result.\n      stats: Backwards compatibility alias for the \'statistics\' argument.\n      instance_name: Optional name assigned to this specific instance of\n        SchemaGen.  Required only if multiple SchemaGen components are declared\n        in the same pipeline.  Either `statistics` or `stats` must be present in\n        the input arguments.\n    """"""\n    if stats:\n      absl.logging.warning(\n          \'The ""stats"" argument to the SchemaGen component has \'\n          \'been renamed to ""statistics"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      statistics = stats\n    schema = output or types.Channel(\n        type=standard_artifacts.Schema, artifacts=[standard_artifacts.Schema()])\n\n    spec = SchemaGenSpec(\n        statistics=statistics,\n        infer_feature_shape=infer_feature_shape,\n        schema=schema)\n    super(SchemaGen, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/schema_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.schema_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.schema_gen import component\nfrom tfx.orchestration import data_types\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass SchemaGenTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    statistics_artifact = standard_artifacts.ExampleStatistics()\n    statistics_artifact.split_names = artifact_utils.encode_split_names(\n        [\'train\'])\n    schema_gen = component.SchemaGen(\n        statistics=channel_utils.as_channel([statistics_artifact]))\n    self.assertEqual(standard_artifacts.Schema.TYPE_NAME,\n                     schema_gen.outputs[\'schema\'].type_name)\n    self.assertFalse(schema_gen.spec.exec_properties[\'infer_feature_shape\'])\n\n  def testConstructWithParameter(self):\n    statistics_artifact = standard_artifacts.ExampleStatistics()\n    statistics_artifact.split_names = artifact_utils.encode_split_names(\n        [\'train\'])\n    infer_shape = data_types.RuntimeParameter(name=\'infer-shape\', ptype=bool)\n    schema_gen = component.SchemaGen(\n        statistics=channel_utils.as_channel([statistics_artifact]),\n        infer_feature_shape=infer_shape)\n    self.assertEqual(standard_artifacts.Schema.TYPE_NAME,\n                     schema_gen.outputs[\'schema\'].type_name)\n    self.assertJsonEqual(\n        str(schema_gen.spec.exec_properties[\'infer_feature_shape\']),\n        str(infer_shape))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/schema_gen/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX schema_gen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport tensorflow_data_validation as tfdv\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n# Key for statistics in executor input_dict.\nSTATISTICS_KEY = \'statistics\'\n\n# Key for output schema in executor output_dict.\nSCHEMA_KEY = \'schema\'\n\n# Default file name for generated schema file.\n_DEFAULT_FILE_NAME = \'schema.pbtxt\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Generic TFX schema_gen executor.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""TensorFlow SchemaGen executor entrypoint.\n\n    This infers the schema using tensorflow_data_validation on the precomputed\n    stats of \'train\' split.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - \'stats\': A list of \'ExampleStatistics\' type which must contain\n          split \'train\'. Stats on other splits are ignored.\n        - \'statistics\': Synonym for \'stats\'.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - output: A list of \'Schema\' artifact of size one.\n      exec_properties: A dict of execution properties, includes:\n        - infer_feature_shape: Whether or not to infer the shape of the feature.\n\n    Returns:\n      None\n    """"""\n    # TODO(zhitaoli): Move constants between this file and component.py to a\n    # constants.py.\n    train_stats_uri = io_utils.get_only_uri_in_dir(\n        artifact_utils.get_split_uri(input_dict[STATISTICS_KEY], \'train\'))\n    output_uri = os.path.join(\n        artifact_utils.get_single_uri(output_dict[SCHEMA_KEY]),\n        _DEFAULT_FILE_NAME)\n\n    infer_feature_shape = exec_properties[\'infer_feature_shape\']\n    absl.logging.info(\'Infering schema from statistics.\')\n    schema = tfdv.infer_schema(\n        tfdv.load_statistics(train_stats_uri), infer_feature_shape)\n    io_utils.write_pbtxt_file(output_uri, schema)\n    absl.logging.info(\'Schema written to %s.\' % output_uri)\n'"
tfx/components/schema_gen/executor_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.schema_gen.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom tfx.components.schema_gen import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def testDo(self):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n    statistics_artifact = standard_artifacts.ExampleStatistics()\n    statistics_artifact.uri = os.path.join(source_data_dir, \'statistics_gen\')\n    statistics_artifact.split_names = artifact_utils.encode_split_names(\n        [\'train\'])\n\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    schema_output = standard_artifacts.Schema()\n    schema_output.uri = os.path.join(output_data_dir, \'schema_output\')\n\n    input_dict = {\n        executor.STATISTICS_KEY: [statistics_artifact],\n    }\n    output_dict = {\n        executor.SCHEMA_KEY: [schema_output],\n    }\n\n    exec_properties = {\'infer_feature_shape\': False}\n\n    schema_gen_executor = executor.Executor()\n    schema_gen_executor.Do(input_dict, output_dict, exec_properties)\n    self.assertNotEqual(0, len(tf.io.gfile.listdir(schema_output.uri)))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/statistics_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/statistics_gen/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX StatisticsGen component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nimport absl\nimport tensorflow_data_validation as tfdv\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.statistics_gen import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import StatisticsGenSpec\n\n\nclass StatisticsGen(base_component.BaseComponent):\n  """"""Official TFX StatisticsGen component.\n\n  The StatisticsGen component generates features statistics and random samples\n  over training data, which can be used for visualization and validation.\n  StatisticsGen uses Apache Beam and approximate algorithms to scale to large\n  datasets.\n\n  Please see https://www.tensorflow.org/tfx/data_validation for more details.\n\n  ## Example\n  ```\n    # Computes statistics over data for visualization and example validation.\n    statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n  ```\n  """"""\n\n  SPEC_CLASS = StatisticsGenSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               examples: types.Channel = None,\n               schema: Optional[types.Channel] = None,\n               stats_options: Optional[tfdv.StatsOptions] = None,\n               output: Optional[types.Channel] = None,\n               input_data: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct a StatisticsGen component.\n\n    Args:\n      examples: A Channel of `ExamplesPath` type, likely generated by the\n        [ExampleGen component](https://www.tensorflow.org/tfx/guide/examplegen).\n        This needs to contain two splits labeled `train` and `eval`. _required_\n      schema: A `Schema` channel to use for automatically configuring the value\n        of stats options passed to TFDV.\n      stats_options: The StatsOptions instance to configure optional TFDV\n        behavior. When stats_options.schema is set, it will be used instead of\n        the `schema` channel input. Due to the requirement that stats_options be\n        serialized, the slicer functions and custom stats generators are dropped\n        and are therefore not usable.\n      output: `ExampleStatisticsPath` channel for statistics of each split\n        provided in the input examples.\n      input_data: Backwards compatibility alias for the `examples` argument.\n      instance_name: Optional name assigned to this specific instance of\n        StatisticsGen.  Required only if multiple StatisticsGen components are\n        declared in the same pipeline.\n    """"""\n    if input_data:\n      absl.logging.warning(\n          \'The ""input_data"" argument to the StatisticsGen component has \'\n          \'been renamed to ""examples"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      examples = input_data\n    if not output:\n      statistics_artifact = standard_artifacts.ExampleStatistics()\n      statistics_artifact.split_names = artifact_utils.get_single_instance(\n          list(examples.get())).split_names\n      output = types.Channel(\n          type=standard_artifacts.ExampleStatistics,\n          artifacts=[statistics_artifact])\n    # TODO(b/150802589): Move jsonable interface to tfx_bsl and use json_utils.\n    stats_options_json = stats_options.to_json() if stats_options else None\n    spec = StatisticsGenSpec(\n        examples=examples,\n        schema=schema,\n        stats_options_json=stats_options_json,\n        statistics=output)\n    super(StatisticsGen, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/statistics_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.statistics_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow_data_validation as tfdv\nfrom tfx.components.statistics_gen import component\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    examples = standard_artifacts.Examples()\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    statistics_gen = component.StatisticsGen(\n        examples=channel_utils.as_channel([examples]))\n    self.assertEqual(standard_artifacts.ExampleStatistics.TYPE_NAME,\n                     statistics_gen.outputs[\'statistics\'].type_name)\n\n  def testConstructWithSchemaAndStatsOptions(self):\n    examples = standard_artifacts.Examples()\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    schema = standard_artifacts.Schema()\n    stats_options = tfdv.StatsOptions(\n        weight_feature=\'weight\',\n        generators=[  # generators should be dropped\n            tfdv.LiftStatsGenerator(\n                schema=None,\n                y_path=tfdv.FeaturePath([\'label\']),\n                x_paths=[tfdv.FeaturePath([\'feature\'])])\n        ])\n    statistics_gen = component.StatisticsGen(\n        examples=channel_utils.as_channel([examples]),\n        schema=channel_utils.as_channel([schema]),\n        stats_options=stats_options)\n    self.assertEqual(standard_artifacts.ExampleStatistics.TYPE_NAME,\n                     statistics_gen.outputs[\'statistics\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/statistics_gen/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX statistics_gen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nfrom tensorflow_data_validation.api import stats_api\nfrom tensorflow_data_validation.statistics import stats_options as options\nfrom tfx_bsl.tfxio import tf_example_record\n\nfrom tensorflow_metadata.proto.v0 import statistics_pb2\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n\n# Keys for input_dict.\nEXAMPLES_KEY = \'examples\'\nSCHEMA_KEY = \'schema\'\n\n# Keys for exec_properties dict.\nSTATS_OPTIONS_JSON_KEY = \'stats_options_json\'\n\n# Keys for output_dict\nSTATISTICS_KEY = \'statistics\'\n\n# Default file name for stats generated.\n_DEFAULT_FILE_NAME = \'stats_tfrecord\'\n\n_TELEMETRY_DESCRIPTORS = [\'StatisticsGen\']\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Computes statistics over input training data for example validation.\n\n  The StatisticsGen component generates features statistics and random samples\n  over training data, which can be used for visualization and validation.\n  StatisticsGen uses Beam and appropriate algorithms to scale to large datasets.\n\n  To include StatisticsGen in a TFX pipeline, configure your pipeline similar to\n  https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple.py#L75.\n  """"""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Computes stats for each split of input using tensorflow_data_validation.\n\n    Args:\n      input_dict: Input dict from input key to a list of Artifacts.\n        - input_data: A list of type `standard_artifacts.Examples`. This should\n          contain both \'train\' and \'eval\' split.\n        - schema: Optionally, a list of type `standard_artifacts.Schema`. When\n          the stats_options exec_property also contains a schema, this input\n          should not be provided.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - output: A list of type `standard_artifacts.ExampleStatistics`. This\n          should contain both the \'train\' and \'eval\' splits.\n      exec_properties: A dict of execution properties.\n        - stats_options_json: Optionally, a JSON representation of StatsOptions.\n          When a schema is provided as an input, the StatsOptions value should\n          not also contain a schema.\n\n    Raises:\n      ValueError when a schema is provided both as an input and as part of the\n      StatsOptions exec_property.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    stats_options = options.StatsOptions()\n    if STATS_OPTIONS_JSON_KEY in exec_properties:\n      stats_options_json = exec_properties[STATS_OPTIONS_JSON_KEY]\n      if stats_options_json:\n        # TODO(b/150802589): Move jsonable interface to tfx_bsl and use\n        # json_utils\n        stats_options = options.StatsOptions.from_json(stats_options_json)\n    if input_dict.get(SCHEMA_KEY):\n      if stats_options.schema:\n        raise ValueError(\'A schema was provided as an input and the \'\n                         \'stats_options exec_property also contains a schema \'\n                         \'value. At most one of these may be set.\')\n      else:\n        schema = io_utils.SchemaReader().read(\n            io_utils.get_only_uri_in_dir(\n                artifact_utils.get_single_uri(input_dict[SCHEMA_KEY])))\n        stats_options.schema = schema\n\n    split_uris = []\n    for artifact in input_dict[EXAMPLES_KEY]:\n      for split in artifact_utils.decode_split_names(artifact.split_names):\n        uri = os.path.join(artifact.uri, split)\n        split_uris.append((split, uri))\n    with self._make_beam_pipeline() as p:\n      for split, uri in split_uris:\n        absl.logging.info(\'Generating statistics for split {}\'.format(split))\n        input_uri = io_utils.all_files_pattern(uri)\n        input_tfxio = tf_example_record.TFExampleRecord(\n            file_pattern=input_uri,\n            telemetry_descriptors=_TELEMETRY_DESCRIPTORS)\n        output_uri = artifact_utils.get_split_uri(output_dict[STATISTICS_KEY],\n                                                  split)\n        output_path = os.path.join(output_uri, _DEFAULT_FILE_NAME)\n        data = p | \'TFXIORead[{}]\'.format(split) >> input_tfxio.BeamSource()\n        _ = (\n            data\n            | \'GenerateStatistics[{}]\'.format(split) >>\n            stats_api.GenerateStatistics(stats_options)\n            | \'WriteStatsOutput[{}]\'.format(split) >> beam.io.WriteToTFRecord(\n                output_path,\n                shard_name_template=\'\',\n                coder=beam.coders.ProtoCoder(\n                    statistics_pb2.DatasetFeatureStatisticsList)))\n        absl.logging.info(\'Statistics for split {} written to {}.\'.format(\n            split, output_uri))\n'"
tfx/components/statistics_gen/executor_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.statistics_gen.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nfrom absl.testing import absltest\nimport tensorflow as tf\nimport tensorflow_data_validation as tfdv\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.statistics_gen import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\n# TODO(b/133421802): Investigate why tensorflow.TestCase could cause a crash\n# when used with tfdv.\nclass ExecutorTest(absltest.TestCase):\n\n  def get_temp_dir(self):\n    return tempfile.mkdtemp()\n\n  def _validate_stats_output(self, stats_path):\n    self.assertTrue(tf.io.gfile.exists(stats_path))\n    stats = tfdv.load_statistics(stats_path)\n    self.assertLen(stats.datasets, 1)\n    data_set = stats.datasets[0]\n    self.assertGreater(data_set.num_examples, 0)\n    self.assertNotEmpty(data_set.features)\n    # TODO(b/126245422): verify content of generated stats after we have stable\n    # test data set.\n\n  def testDo(self):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(output_data_dir)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n\n    stats = standard_artifacts.ExampleStatistics()\n    stats.uri = output_data_dir\n    stats.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    input_dict = {\n        executor.EXAMPLES_KEY: [examples],\n    }\n\n    output_dict = {\n        executor.STATISTICS_KEY: [stats],\n    }\n\n    # Run executor.\n    stats_gen_executor = executor.Executor()\n    stats_gen_executor.Do(input_dict, output_dict, exec_properties={})\n\n    # Check statistics_gen outputs.\n    self._validate_stats_output(\n        os.path.join(stats.uri, \'train\', \'stats_tfrecord\'))\n    self._validate_stats_output(\n        os.path.join(stats.uri, \'eval\', \'stats_tfrecord\'))\n\n  def testDoWithSchemaAndStatsOptions(self):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(output_data_dir)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(source_data_dir, \'schema_gen\')\n\n    input_dict = {\n        executor.EXAMPLES_KEY: [examples],\n        executor.SCHEMA_KEY: [schema]\n    }\n\n    exec_properties = {\n        executor.STATS_OPTIONS_JSON_KEY:\n            tfdv.StatsOptions(label_feature=\'company\').to_json(),\n    }\n\n    # Create output dict.\n    stats = standard_artifacts.ExampleStatistics()\n    stats.uri = output_data_dir\n    stats.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\n        executor.STATISTICS_KEY: [stats],\n    }\n\n    # Run executor.\n    stats_gen_executor = executor.Executor()\n    stats_gen_executor.Do(\n        input_dict, output_dict, exec_properties=exec_properties)\n\n    # Check statistics_gen outputs.\n    self._validate_stats_output(\n        os.path.join(stats.uri, \'train\', \'stats_tfrecord\'))\n    self._validate_stats_output(\n        os.path.join(stats.uri, \'eval\', \'stats_tfrecord\'))\n\n  def testDoWithTwoSchemas(self):\n    source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(output_data_dir)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(source_data_dir, \'schema_gen\')\n\n    input_dict = {\n        executor.EXAMPLES_KEY: [examples],\n        executor.SCHEMA_KEY: [schema]\n    }\n\n    exec_properties = {\n        executor.STATS_OPTIONS_JSON_KEY:\n            tfdv.StatsOptions(label_feature=\'company\',\n                              schema=schema_pb2.Schema()).to_json(),\n    }\n\n    # Create output dict.\n    stats = standard_artifacts.ExampleStatistics()\n    stats.uri = output_data_dir\n    stats.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\n        executor.STATISTICS_KEY: [stats],\n    }\n\n    # Run executor.\n    stats_gen_executor = executor.Executor()\n    with self.assertRaises(ValueError):\n      stats_gen_executor.Do(\n          input_dict, output_dict, exec_properties=exec_properties)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
tfx/components/testdata/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/trainer/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/trainer/component.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Trainer component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer import executor\nfrom tfx.orchestration import data_types\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import TrainerSpec\nfrom tfx.utils import json_utils\n\n\n# TODO(b/147702778): update when switch generic executor as default.\nclass Trainer(base_component.BaseComponent):\n  """"""A TFX component to train a TensorFlow model.\n\n  The Trainer component is used to train and eval a model using given inputs and\n  a user-supplied estimator.\n\n  ## Providing an estimator\n  The TFX executor will use the estimator provided in the `module_file` file\n  to train the model.  The Trainer executor will look specifically for the\n  `trainer_fn()` function within that file.  Before training, the executor will\n  call that function expecting the following returned as a dictionary:\n\n    - estimator: The\n    [estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator)\n    to be used by TensorFlow to train the model.\n    - train_spec: The\n    [configuration](https://www.tensorflow.org/api_docs/python/tf/estimator/TrainSpec)\n    to be used by the ""train"" part of the TensorFlow `train_and_evaluate()`\n    call.\n    - eval_spec: The\n    [configuration](https://www.tensorflow.org/api_docs/python/tf/estimator/EvalSpec)\n    to be used by the ""eval"" part of the TensorFlow `train_and_evaluate()` call.\n    - eval_input_receiver_fn: The\n    [configuration](https://www.tensorflow.org/tfx/model_analysis/get_started#modify_an_existing_model)\n    to be used\n    by the [ModelValidator](https://www.tensorflow.org/tfx/guide/modelval)\n    component when validating the model.\n\n  An example of `trainer_fn()` can be found in the [user-supplied\n  code]((https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_utils.py))\n  of the TFX Chicago Taxi pipeline example.\n\n  *Note:* The default executor for this component trains locally.  This can be\n  overriden to enable the model to be trained on other platforms.  The [Cloud AI\n  Platform custom\n  executor](https://github.com/tensorflow/tfx/tree/master/tfx/extensions/google_cloud_ai_platform/trainer)\n  provides an example how to implement this.\n\n  Please see https://www.tensorflow.org/guide/estimators for more details.\n\n  ## Example 1: Training locally\n  ```\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=infer_schema.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n  ```\n\n  ## Example 2: Training through a cloud provider\n  ```\n  # Train using Google Cloud AI Platform.\n  trainer = Trainer(\n      executor_class=ai_platform_trainer_executor.Executor,\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=infer_schema.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n  ```\n  """"""\n\n  SPEC_CLASS = TrainerSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      examples: types.Channel = None,\n      transformed_examples: Optional[types.Channel] = None,\n      transform_graph: Optional[types.Channel] = None,\n      schema: types.Channel = None,\n      base_model: Optional[types.Channel] = None,\n      hyperparameters: Optional[types.Channel] = None,\n      module_file: Optional[Union[Text, data_types.RuntimeParameter]] = None,\n      run_fn: Optional[Union[Text, data_types.RuntimeParameter]] = None,\n      # TODO(b/147702778): deprecate trainer_fn.\n      trainer_fn: Optional[Union[Text, data_types.RuntimeParameter]] = None,\n      train_args: Union[trainer_pb2.TrainArgs, Dict[Text, Any]] = None,\n      eval_args: Union[trainer_pb2.EvalArgs, Dict[Text, Any]] = None,\n      custom_config: Optional[Dict[Text, Any]] = None,\n      custom_executor_spec: Optional[executor_spec.ExecutorSpec] = None,\n      output: Optional[types.Channel] = None,\n      transform_output: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a Trainer component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, serving as\n        the source of examples used in training (required). May be raw or\n        transformed.\n      transformed_examples: Deprecated field. Please set \'examples\' instead.\n      transform_graph: An optional Channel of type\n        `standard_artifacts.TransformGraph`, serving as the input transform\n        graph if present.\n      schema:  A Channel of type `standard_artifacts.Schema`, serving as the\n        schema of training and eval data.\n      base_model: A Channel of type `Model`, containing model that will be used\n        for training. This can be used for warmstart, transfer learning or\n        model ensembling.\n      hyperparameters: A Channel of type `standard_artifacts.HyperParameters`,\n        serving as the hyperparameters for training module. Tuner\'s output best\n        hyperparameters can be feed into this.\n      module_file: A path to python module file containing UDF model definition.\n\n        For default executor, The module_file must implement a function named\n        `trainer_fn` at its top level. The function must have the following\n        signature.\n\n        def trainer_fn(trainer.executor.TrainerFnArgs,\n                       tensorflow_metadata.proto.v0.schema_pb2) -> Dict:\n          ...\n\n        where the returned Dict has the following key-values.\n          \'estimator\': an instance of tf.estimator.Estimator\n          \'train_spec\': an instance of tf.estimator.TrainSpec\n          \'eval_spec\': an instance of tf.estimator.EvalSpec\n          \'eval_input_receiver_fn\': an instance of\n            tfma.export.EvalInputReceiver. Exactly one of \'module_file\' or\n            \'trainer_fn\' must be supplied.\n\n        For generic executor, The module_file must implement a function named\n        `run_fn` at its top level with function signature:\n        `def run_fn(trainer.executor.TrainerFnArgs)`, and the trained model must\n        be saved to TrainerFnArgs.serving_model_dir when execute this function.\n      run_fn:  A python path to UDF model definition function for generic\n        trainer. See \'module_file\' for details. Exactly one of \'module_file\' or\n        \'run_fn\' must be supplied if Trainer uses GenericExecutor.\n      trainer_fn:  A python path to UDF model definition function for estimator\n        based trainer. See \'module_file\' for the required signature of the UDF.\n        Exactly one of \'module_file\' or \'trainer_fn\' must be supplied.\n      train_args: A trainer_pb2.TrainArgs instance or a dict, containing args\n        used for training. Current only num_steps is available. If it\'s provided\n        as a dict and any field is a RuntimeParameter, it should have the same\n        field names as a TrainArgs proto message.\n      eval_args: A trainer_pb2.EvalArgs instance or a dict, containing args\n        used for evaluation. Current only num_steps is available. If it\'s\n        provided as a dict and any field is a RuntimeParameter, it should have\n        the same field names as a EvalArgs proto message.\n      custom_config: A dict which contains addtional training job parameters\n        that will be passed into user module.\n      custom_executor_spec: Optional custom executor spec.\n      output: Optional `Model` channel for result of exported models.\n      transform_output: Backwards compatibility alias for the \'transform_graph\'\n        argument.\n      instance_name: Optional unique instance name. Necessary iff multiple\n        Trainer components are declared in the same pipeline.\n\n    Raises:\n      ValueError:\n        - When both or neither of \'module_file\' and user function\n          (e.g., trainer_fn and run_fn) is supplied.\n        - When both or neither of \'examples\' and \'transformed_examples\'\n            is supplied.\n        - When \'transformed_examples\' is supplied but \'transform_graph\'\n            is not supplied.\n    """"""\n    if [bool(module_file), bool(run_fn), bool(trainer_fn)].count(True) != 1:\n      raise ValueError(\n          ""Exactly one of \'module_file\', \'trainer_fn\', or \'run_fn\' must be supplied.""\n      )\n\n    if bool(examples) == bool(transformed_examples):\n      raise ValueError(\n          ""Exactly one of \'example\' or \'transformed_example\' must be supplied."")\n\n    if transform_output:\n      absl.logging.warning(\n          \'The ""transform_output"" argument to the Trainer component has \'\n          \'been renamed to ""transform_graph"" and is deprecated. Please update \'\n          ""your usage as support for this argument will be removed soon."")\n      transform_graph = transform_output\n    if transformed_examples and not transform_graph:\n      raise ValueError(""If \'transformed_examples\' is supplied, ""\n                       ""\'transform_graph\' must be supplied too."")\n    examples = examples or transformed_examples\n    output = output or types.Channel(\n        type=standard_artifacts.Model, artifacts=[standard_artifacts.Model()])\n    spec = TrainerSpec(\n        examples=examples,\n        transform_graph=transform_graph,\n        schema=schema,\n        base_model=base_model,\n        hyperparameters=hyperparameters,\n        train_args=train_args,\n        eval_args=eval_args,\n        module_file=module_file,\n        run_fn=run_fn,\n        trainer_fn=trainer_fn,\n        custom_config=json_utils.dumps(custom_config),\n        model=output)\n    super(Trainer, self).__init__(\n        spec=spec,\n        custom_executor_spec=custom_executor_spec,\n        instance_name=instance_name)\n'"
tfx/components/trainer/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.trainer.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\nimport tensorflow as tf\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer import component\nfrom tfx.components.trainer import executor\nfrom tfx.orchestration import data_types\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ComponentTest, self).setUp()\n\n    self.examples = channel_utils.as_channel([standard_artifacts.Examples()])\n    self.transform_output = channel_utils.as_channel(\n        [standard_artifacts.TransformGraph()])\n    self.schema = channel_utils.as_channel([standard_artifacts.Schema()])\n    self.hyperparameters = channel_utils.as_channel(\n        [standard_artifacts.HyperParameters()])\n    self.train_args = trainer_pb2.TrainArgs(num_steps=100)\n    self.eval_args = trainer_pb2.EvalArgs(num_steps=50)\n\n  def _verify_outputs(self, trainer):\n    self.assertEqual(standard_artifacts.Model.TYPE_NAME,\n                     trainer.outputs[\'model\'].type_name)\n\n  def testConstructFromModuleFile(self):\n    module_file = \'/path/to/module/file\'\n    trainer = component.Trainer(\n        module_file=module_file,\n        transformed_examples=self.examples,\n        transform_graph=self.transform_output,\n        schema=self.schema,\n        train_args=self.train_args,\n        eval_args=self.eval_args)\n    self._verify_outputs(trainer)\n    self.assertEqual(module_file, trainer.spec.exec_properties[\'module_file\'])\n\n  def testConstructWithParameter(self):\n    module_file = data_types.RuntimeParameter(name=\'module-file\', ptype=Text)\n    n_steps = data_types.RuntimeParameter(name=\'n-steps\', ptype=int)\n    trainer = component.Trainer(\n        module_file=module_file,\n        transformed_examples=self.examples,\n        transform_graph=self.transform_output,\n        schema=self.schema,\n        train_args=dict(num_steps=n_steps),\n        eval_args=dict(num_steps=n_steps))\n    self._verify_outputs(trainer)\n    self.assertJsonEqual(\n        str(module_file), str(trainer.spec.exec_properties[\'module_file\']))\n\n  def testConstructFromTrainerFn(self):\n    trainer_fn = \'path.to.my_trainer_fn\'\n    trainer = component.Trainer(\n        trainer_fn=trainer_fn,\n        transformed_examples=self.examples,\n        transform_graph=self.transform_output,\n        schema=self.schema,\n        train_args=self.train_args,\n        eval_args=self.eval_args)\n    self._verify_outputs(trainer)\n    self.assertEqual(trainer_fn, trainer.spec.exec_properties[\'trainer_fn\'])\n\n  def testConstructFromRunFn(self):\n    run_fn = \'path.to.my_run_fn\'\n    trainer = component.Trainer(\n        run_fn=run_fn,\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            executor.GenericExecutor),\n        transformed_examples=self.examples,\n        transform_graph=self.transform_output,\n        schema=self.schema,\n        train_args=self.train_args,\n        eval_args=self.eval_args)\n    self._verify_outputs(trainer)\n    self.assertEqual(run_fn, trainer.spec.exec_properties[\'run_fn\'])\n\n  def testConstructWithoutTransformOutput(self):\n    module_file = \'/path/to/module/file\'\n    trainer = component.Trainer(\n        module_file=module_file,\n        examples=self.examples,\n        schema=self.schema,\n        train_args=self.train_args,\n        eval_args=self.eval_args)\n    self._verify_outputs(trainer)\n    self.assertEqual(module_file, trainer.spec.exec_properties[\'module_file\'])\n\n  def testConstructDuplicateExamples(self):\n    with self.assertRaises(ValueError):\n      _ = component.Trainer(\n          module_file=\'/path/to/module/file\',\n          examples=self.examples,\n          transformed_examples=self.examples,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args)\n\n  def testConstructMissingTransformOutput(self):\n    with self.assertRaises(ValueError):\n      _ = component.Trainer(\n          module_file=\'/path/to/module/file\',\n          transformed_examples=self.examples,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args)\n\n  def testConstructMissingUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Trainer(\n          examples=self.examples,\n          transform_graph=self.transform_output,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args)\n\n  def testConstructDuplicateUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Trainer(\n          module_file=\'/path/to/module/file\',\n          trainer_fn=\'path.to.my_trainer_fn\',\n          examples=self.examples,\n          transform_graph=self.transform_output,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args)\n\n    with self.assertRaises(ValueError):\n      _ = component.Trainer(\n          module_file=\'/path/to/module/file\',\n          run_fn=\'path.to.my_run_fn\',\n          examples=self.examples,\n          transform_graph=self.transform_output,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args)\n\n  def testConstructWithHParams(self):\n    trainer = component.Trainer(\n        trainer_fn=\'path.to.my_trainer_fn\',\n        transformed_examples=self.examples,\n        transform_graph=self.transform_output,\n        schema=self.schema,\n        hyperparameters=self.hyperparameters,\n        train_args=self.train_args,\n        eval_args=self.eval_args)\n    self._verify_outputs(trainer)\n    self.assertEqual(standard_artifacts.HyperParameters.TYPE_NAME,\n                     trainer.inputs[\'hyperparameters\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/trainer/constants.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Constant values for Trainer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Key for examples in executor input_dict.\nEXAMPLES_KEY = \'examples\'\n# Key for schema in executor input_dict.\nSCHEMA_KEY = \'schema\'\n# Key for transform graph in executor input_dict.\nTRANSFORM_GRAPH_KEY = \'transform_graph\'\n# Key for base model in executor input_dict.\nBASE_MODEL_KEY = \'base_model\'\n# Key for hyperparameters in executor input_dict.\nHYPERPARAMETERS_KEY = \'hyperparameters\'\n\n# Key for train args.\nTRAIN_ARGS_KEY = \'train_args\'\n# Key for eval args.\nEVAL_ARGS_KEY = \'eval_args\'\n# Key for custom config.\nCUSTOM_CONFIG_KEY = \'custom_config\'\n\n# Key for output model in executor output_dict.\nOUTPUT_MODEL_KEY = \'model\'\n\n# The name of environment variable to indicate distributed training cluster.\nTF_CONFIG_ENV = \'TF_CONFIG\'\n'"
tfx/components/trainer/executor.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX local trainer executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\n\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.trainer import constants\nfrom tfx.components.trainer import fn_args_utils\nfrom tfx.components.util import udf_utils\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import json_utils\nfrom tfx.utils import path_utils\n\n\ndef _all_files_pattern(file_pattern: Text) -> Text:\n  return os.path.join(file_pattern, \'*\')\n\n\ndef _is_chief():\n  """"""Returns true if this is run in the master (chief) of training cluster.""""""\n  tf_config = json.loads(os.environ.get(constants.TF_CONFIG_ENV) or \'{}\')\n\n  # If non distributed mode, current process should always behave as chief.\n  if not tf_config or not tf_config.get(\'cluster\', {}):\n    return True\n\n  task_type = tf_config[\'task\'][\'type\']\n  task_index = tf_config[\'task\'][\'index\']\n\n  # \'master\' is a legacy notation of chief node in distributed training flock.\n  return task_type == \'chief\' or (task_type == \'master\' and task_index == 0)\n\n\nclass TrainerFnArgs(object):\n  """"""Wrapper class to help migrate from contrib.HParam to new data structure.""""""\n\n  def __init__(self, **kwargs):\n    self._data = kwargs\n\n  def __getitem__(self, key):\n    return self._data[key]\n\n  def __getattr__(self, key):\n    return self._data[key]\n\n\nclass GenericExecutor(base_executor.BaseExecutor):\n  """"""Local generic trainer executor for the TFX Trainer component.\n\n  The Trainer executor supplements TensorFlow training with a component to\n  enable warm-start training of any user-specified TF model. The Trainer is\n  a library built on top of TensorFlow that is expected to be integrated into a\n  custom user-specified binary.\n\n  To include Trainer in a TFX pipeline, configure your pipeline similar to\n  https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple.py#L104.\n\n  For more details on the Trainer component itself, please refer to\n  https://tensorflow.org/tfx/guide/trainer.  For a tutorial on Tensorflow,\n  please refer to https://www.tensorflow.org/tutorials.\n\n  How to create a trainer callback function to be used by this Trainer executor:\n  A model training can be executed by TFX by first creating a run_fn callback\n  method that defines, trains an TF Model and saves it to the provided location,\n  This becomes the basis of the Executor for GenericTrainer. This Executor will\n  then execute the run_fn with correct parameters by resolving the input\n  artifacts, output artifacts and execution properties.\n  """"""\n\n  # Name of subdirectory which contains checkpoints from prior runs\n  _CHECKPOINT_FILE_NAME = \'checkpoint\'\n\n  def _GetFnArgs(self, input_dict: Dict[Text, List[types.Artifact]],\n                 output_dict: Dict[Text, List[types.Artifact]],\n                 exec_properties: Dict[Text, Any]) -> TrainerFnArgs:\n    fn_args = fn_args_utils.get_common_fn_args(input_dict, exec_properties)\n\n    # Load and deserialize custom config from execution properties.\n    # Note that in the component interface the default serialization of custom\n    # config is \'null\' instead of \'{}\'. Therefore we need to default the\n    # json_utils.loads to \'null\' then populate it with an empty dict when\n    # needed.\n    custom_config = json_utils.loads(\n        exec_properties.get(constants.CUSTOM_CONFIG_KEY, \'null\')) or {}\n    if not isinstance(custom_config, Dict):\n      raise ValueError(\'custom_config in execution properties needs to be a \'\n                       \'dict. Got %s instead.\' % type(custom_config))\n\n    # TODO(ruoyu): Make this a dict of tag -> uri instead of list.\n    if input_dict.get(constants.BASE_MODEL_KEY):\n      base_model = path_utils.serving_model_path(\n          artifact_utils.get_single_uri(input_dict[constants.BASE_MODEL_KEY]))\n    else:\n      base_model = None\n\n    if input_dict.get(constants.HYPERPARAMETERS_KEY):\n      hyperparameters_file = io_utils.get_only_uri_in_dir(\n          artifact_utils.get_single_uri(\n              input_dict[constants.HYPERPARAMETERS_KEY]))\n      hyperparameters_config = json.loads(\n          file_io.read_file_to_string(hyperparameters_file))\n    else:\n      hyperparameters_config = None\n\n    output_path = artifact_utils.get_single_uri(\n        output_dict[constants.OUTPUT_MODEL_KEY])\n    serving_model_dir = path_utils.serving_model_dir(output_path)\n    eval_model_dir = path_utils.eval_model_dir(output_path)\n\n    # TODO(b/126242806) Use PipelineInputs when it is available in third_party.\n    return TrainerFnArgs(\n        # A list of uris for train files.\n        train_files=fn_args.train_files,\n        # An optional single uri for transform graph produced by TFT. Will be\n        # None if not specified.\n        transform_output=fn_args.transform_graph_path,\n        # A single uri for the output directory of the serving model.\n        serving_model_dir=serving_model_dir,\n        # A single uri for the output directory of the eval model.\n        # Note that this is estimator only, Keras doesn\'t require it for TFMA.\n        eval_model_dir=eval_model_dir,\n        # A list of uris for eval files.\n        eval_files=fn_args.eval_files,\n        # A single uri for schema file.\n        schema_file=fn_args.schema_path,\n        # Number of train steps.\n        train_steps=fn_args.train_steps,\n        # Number of eval steps.\n        eval_steps=fn_args.eval_steps,\n        # Base model that will be used for this training job.\n        base_model=base_model,\n        # An optional kerastuner.HyperParameters config.\n        hyperparameters=hyperparameters_config,\n        # Additional parameters to pass to trainer function.\n        **custom_config)\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Uses a user-supplied run_fn to train a TensorFlow model locally.\n\n    The Trainer Executor invokes a run_fn callback function provided by\n    the user via the module_file parameter. In this function, user defines the\n    model and train it, then save the model to the provided location.\n\n    Args:\n      input_dict: Input dict from input key to a list of ML-Metadata Artifacts.\n        - examples: Examples used for training, must include \'train\' and \'eval\'\n          splits.\n        - transform_output: Optional input transform graph.\n        - schema: Schema of the data.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - output: Exported model.\n      exec_properties: A dict of execution properties.\n        - train_args: JSON string of trainer_pb2.TrainArgs instance, providing\n          args for training.\n        - eval_args: JSON string of trainer_pb2.EvalArgs instance, providing\n          args for eval.\n        - module_file: Python module file containing UDF model definition.\n        - warm_starting: Whether or not we need to do warm starting.\n        - warm_start_from: Optional. If warm_starting is True, this is the\n          directory to find previous model to warm start on.\n        - custom_config: Optional. JSON-serialized dict of additional parameters\n          to pass to trainer function.\n\n    Returns:\n      None\n\n    Raises:\n      ValueError: When neither or both of \'module_file\' and \'run_fn\'\n        are present in \'exec_properties\'.\n      RuntimeError: If run_fn failed to generate model in desired location.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    fn_args = self._GetFnArgs(input_dict, output_dict, exec_properties)\n    run_fn = udf_utils.get_fn(exec_properties, \'run_fn\')\n\n    # Train the model\n    absl.logging.info(\'Training model.\')\n    run_fn(fn_args)\n\n    # Note: If trained with multi-node distribution workers, it is the user\n    # module\'s responsibility to export the model only once.\n    if not tf.io.gfile.exists(fn_args.serving_model_dir):\n      raise RuntimeError(\'run_fn failed to generate model.\')\n    absl.logging.info(\'Training complete. Model written to %s\',\n                      fn_args.serving_model_dir)\n\n\nclass Executor(GenericExecutor):\n  """"""Local estimator based trainer executor used by the TFX Trainer component.\n\n  How to create a trainer callback function to be used by this Trainer executor:\n  An estimator can be executed by TFX by first creating a trainer_fn callback\n  method that returns an estimator and some additional parameters, similar to\n  https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_utils.py#L285.\n  This becomes the basis of the new Executor for Trainer. This Executor will\n  then train and evaluate this estimator using the\n  tf.estimator.train_and_evaluate API to train locally.\n  """"""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Uses a user-supplied tf.estimator to train a TensorFlow model locally.\n\n    The Trainer Executor invokes a training_fn callback function provided by\n    the user via the module_file parameter.  With the tf.estimator returned by\n    this function, the Trainer Executor then builds a TensorFlow model using the\n    user-provided tf.estimator.\n\n    Args:\n      input_dict: Input dict from input key to a list of ML-Metadata Artifacts.\n        - examples: Examples used for training, must include \'train\' and \'eval\'\n          splits.\n        - transform_output: Optional input transform graph.\n        - schema: Schema of the data.\n      output_dict: Output dict from output key to a list of Artifacts.\n        - output: Exported model.\n      exec_properties: A dict of execution properties.\n        - train_args: JSON string of trainer_pb2.TrainArgs instance, providing\n          args for training.\n        - eval_args: JSON string of trainer_pb2.EvalArgs instance, providing\n          args for eval.\n        - module_file: Python module file containing UDF model definition.\n        - warm_starting: Whether or not we need to do warm starting.\n        - warm_start_from: Optional. If warm_starting is True, this is the\n          directory to find previous model to warm start on.\n        - custom_config: Optional. JSON-serialized dict of additional parameters\n          to pass to trainer function.\n\n    Returns:\n      None\n\n    Raises:\n      ValueError: When neither or both of \'module_file\' and \'trainer_fn\'\n        are present in \'exec_properties\'.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    fn_args = self._GetFnArgs(input_dict, output_dict, exec_properties)\n    trainer_fn = udf_utils.get_fn(exec_properties, \'trainer_fn\')\n\n    schema = io_utils.parse_pbtxt_file(fn_args.schema_file, schema_pb2.Schema())\n\n    training_spec = trainer_fn(fn_args, schema)\n\n    # Train the model\n    absl.logging.info(\'Training model.\')\n    tf.estimator.train_and_evaluate(training_spec[\'estimator\'],\n                                    training_spec[\'train_spec\'],\n                                    training_spec[\'eval_spec\'])\n    absl.logging.info(\'Training complete.  Model written to %s\',\n                      fn_args.serving_model_dir)\n\n    # Export an eval savedmodel for TFMA. If distributed training, it must only\n    # be written by the chief worker, as would be done for serving savedmodel.\n    if _is_chief():\n      absl.logging.info(\'Exporting eval_savedmodel for TFMA.\')\n      tfma.export.export_eval_savedmodel(\n          estimator=training_spec[\'estimator\'],\n          export_dir_base=fn_args.eval_model_dir,\n          eval_input_receiver_fn=training_spec[\'eval_input_receiver_fn\'])\n\n      absl.logging.info(\'Exported eval_savedmodel to %s.\',\n                        fn_args.eval_model_dir)\n    else:\n      absl.logging.info(\n          \'eval_savedmodel export for TFMA is skipped because \'\n          \'this is not the chief worker.\'\n      )\n'"
tfx/components/trainer/executor_test.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.trainer.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\n# Standard Imports\nimport mock\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx.components.testdata.module_file import trainer_module\nfrom tfx.components.trainer import constants\nfrom tfx.components.trainer import executor\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(self._source_data_dir,\n                                \'transform/transformed_examples\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    transform_output = standard_artifacts.TransformGraph()\n    transform_output.uri = os.path.join(self._source_data_dir,\n                                        \'transform/transform_graph\')\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(self._source_data_dir, \'schema_gen\')\n    previous_model = standard_artifacts.Model()\n    previous_model.uri = os.path.join(self._source_data_dir, \'trainer/previous\')\n\n    self._input_dict = {\n        constants.EXAMPLES_KEY: [examples],\n        constants.TRANSFORM_GRAPH_KEY: [transform_output],\n        constants.SCHEMA_KEY: [schema],\n        constants.BASE_MODEL_KEY: [previous_model]\n    }\n\n    # Create output dict.\n    self._model_exports = standard_artifacts.Model()\n    self._model_exports.uri = os.path.join(self._output_data_dir,\n                                           \'model_export_path\')\n    self._output_dict = {constants.OUTPUT_MODEL_KEY: [self._model_exports]}\n\n    # Create exec properties skeleton.\n    self._exec_properties = {\n        \'train_args\':\n            json_format.MessageToJson(\n                trainer_pb2.TrainArgs(num_steps=1000),\n                preserving_proto_field_name=True),\n        \'eval_args\':\n            json_format.MessageToJson(\n                trainer_pb2.EvalArgs(num_steps=500),\n                preserving_proto_field_name=True),\n        \'warm_starting\':\n            False,\n    }\n\n    self._module_file = os.path.join(self._source_data_dir, \'module_file\',\n                                     \'trainer_module.py\')\n    self._trainer_fn = \'%s.%s\' % (trainer_module.trainer_fn.__module__,\n                                  trainer_module.trainer_fn.__name__)\n\n    # Executors for test.\n    self._trainer_executor = executor.Executor()\n    self._generic_trainer_executor = executor.GenericExecutor()\n\n  def _verify_model_exports(self):\n    self.assertTrue(\n        tf.io.gfile.exists(path_utils.eval_model_dir(self._model_exports.uri)))\n    self.assertTrue(\n        tf.io.gfile.exists(\n            path_utils.serving_model_dir(self._model_exports.uri)))\n\n  def _verify_no_eval_model_exports(self):\n    self.assertFalse(\n        tf.io.gfile.exists(path_utils.eval_model_dir(self._model_exports.uri)))\n\n  def _do(self, test_executor):\n    test_executor.Do(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=self._exec_properties)\n\n  def testGenericExecutor(self):\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._do(self._generic_trainer_executor)\n    self._verify_model_exports()\n\n  @mock.patch(\'tfx.components.trainer.executor._is_chief\')\n  def testDoChief(self, mock_is_chief):\n    mock_is_chief.return_value = True\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._do(self._trainer_executor)\n    self._verify_model_exports()\n\n  @mock.patch(\'tfx.components.trainer.executor._is_chief\')\n  def testDoNonChief(self, mock_is_chief):\n    mock_is_chief.return_value = False\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._do(self._trainer_executor)\n    self._verify_no_eval_model_exports()\n\n  def testDoWithModuleFile(self):\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._do(self._trainer_executor)\n    self._verify_model_exports()\n\n  def testDoWithTrainerFn(self):\n    self._exec_properties[\'trainer_fn\'] = self._trainer_fn\n    self._do(self._trainer_executor)\n    self._verify_model_exports()\n\n  def testDoWithNoTrainerFn(self):\n    with self.assertRaises(ValueError):\n      self._do(self._trainer_executor)\n\n  def testDoWithDuplicateTrainerFn(self):\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._exec_properties[\'trainer_fn\'] = self._trainer_fn\n    with self.assertRaises(ValueError):\n      self._do(self._trainer_executor)\n\n  def testDoWithHyperParameters(self):\n    hp_artifact = standard_artifacts.HyperParameters()\n    hp_artifact.uri = os.path.join(self._output_data_dir, \'hyperparameters/\')\n\n    # TODO(jyzhao): use real kerastuner.HyperParameters instead of dict.\n    hyperparameters = {}\n    hyperparameters[\'first_dnn_layer_size\'] = 100\n    hyperparameters[\'num_dnn_layers\'] = 4\n    hyperparameters[\'dnn_decay_factor\'] = 0.7\n    io_utils.write_string_file(\n        os.path.join(hp_artifact.uri, \'hyperparameters.txt\'),\n        json.dumps(hyperparameters))\n\n    self._input_dict[constants.HYPERPARAMETERS_KEY] = [hp_artifact]\n\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._do(self._trainer_executor)\n    self._verify_model_exports()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/trainer/fn_args_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""FnArgs for passing information to UDF.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text, NamedTuple\n\nfrom google.protobuf import json_format\n\nfrom tfx import types\nfrom tfx.components.trainer import constants\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n# TODO(b/156929910): Change TrainerFnArgs to this FnArgs.\n#\n# working_dir: Working dir.\n# train_files: A list of patterns for train files.\n# eval_files: A list of patterns for eval files.\n# train_steps: Number of train steps.\n# eval_steps: Number of eval steps.\n# schema_path: A single uri for schema file. Will be None if not specified.\n# transform_graph_path: An optional single uri for transform graph produced by\n#                       TFT. Will be None if not specified.\nFnArgs = NamedTuple(\'FnArgs\', [(\'working_dir\', Text),\n                               (\'train_files\', List[Text]),\n                               (\'eval_files\', List[Text]), (\'train_steps\', int),\n                               (\'eval_steps\', int), (\'schema_path\', Text),\n                               (\'transform_graph_path\', Text)])\n# Set default value to None.\nFnArgs.__new__.__defaults__ = (None,) * len(FnArgs._fields)\n\n\ndef get_common_fn_args(input_dict: Dict[Text, List[types.Artifact]],\n                       exec_properties: Dict[Text, Any],\n                       working_dir: Text = None) -> FnArgs:\n  """"""Get common args of training and tuning.""""""\n  train_files = [\n      io_utils.all_files_pattern(\n          artifact_utils.get_split_uri(input_dict[constants.EXAMPLES_KEY],\n                                       \'train\'))\n  ]\n  eval_files = [\n      io_utils.all_files_pattern(\n          artifact_utils.get_split_uri(input_dict[constants.EXAMPLES_KEY],\n                                       \'eval\'))\n  ]\n\n  if input_dict.get(constants.TRANSFORM_GRAPH_KEY):\n    transform_graph_path = artifact_utils.get_single_uri(\n        input_dict[constants.TRANSFORM_GRAPH_KEY])\n  else:\n    transform_graph_path = None\n\n  if input_dict.get(constants.SCHEMA_KEY):\n    schema_path = io_utils.get_only_uri_in_dir(\n        artifact_utils.get_single_uri(input_dict[constants.SCHEMA_KEY]))\n  else:\n    schema_path = None\n\n  train_args = trainer_pb2.TrainArgs()\n  eval_args = trainer_pb2.EvalArgs()\n  json_format.Parse(exec_properties[constants.TRAIN_ARGS_KEY], train_args)\n  json_format.Parse(exec_properties[constants.EVAL_ARGS_KEY], eval_args)\n\n  # https://github.com/tensorflow/tfx/issues/45: Replace num_steps=0 with\n  # num_steps=None.  Conversion of the proto to python will set the default\n  # value of an int as 0 so modify the value here.  Tensorflow will raise an\n  # error if num_steps <= 0.\n  train_steps = train_args.num_steps or None\n  eval_steps = eval_args.num_steps or None\n\n  return FnArgs(\n      working_dir=working_dir,\n      train_files=train_files,\n      eval_files=eval_files,\n      train_steps=train_steps,\n      eval_steps=eval_steps,\n      schema_path=schema_path,\n      transform_graph_path=transform_graph_path,\n  )\n'"
tfx/components/transform/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/transform/component.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Transform component definition.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text, Union\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.transform import executor\nfrom tfx.orchestration import data_types\nfrom tfx.types import artifact\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import TransformSpec\n\n\nclass Transform(base_component.BaseComponent):\n  """"""A TFX component to transform the input examples.\n\n  The Transform component wraps TensorFlow Transform (tf.Transform) to\n  preprocess data in a TFX pipeline. This component will load the\n  preprocessing_fn from input module file, preprocess both \'train\' and \'eval\'\n  splits of input examples, generate the `tf.Transform` output, and save both\n  transform function and transformed examples to orchestrator desired locations.\n\n  ## Providing a preprocessing function\n  The TFX executor will use the estimator provided in the `module_file` file\n  to train the model.  The Transform executor will look specifically for the\n  `preprocessing_fn()` function within that file.\n\n  An example of `preprocessing_fn()` can be found in the [user-supplied\n  code]((https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/taxi_utils.py))\n  of the TFX Chicago Taxi pipeline example.\n\n  ## Example\n  ```\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=infer_schema.outputs[\'schema\'],\n      module_file=module_file)\n  ```\n\n  Please see https://www.tensorflow.org/tfx/transform for more details.\n  """"""\n\n  SPEC_CLASS = TransformSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      examples: types.Channel = None,\n      schema: types.Channel = None,\n      module_file: Optional[Union[Text, data_types.RuntimeParameter]] = None,\n      preprocessing_fn: Optional[Union[Text,\n                                       data_types.RuntimeParameter]] = None,\n      transform_graph: Optional[types.Channel] = None,\n      transformed_examples: Optional[types.Channel] = None,\n      input_data: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a Transform component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples` (required).\n        This should contain the two splits \'train\' and \'eval\'.\n      schema: A Channel of type `standard_artifacts.Schema`. This should\n        contain a single schema artifact.\n      module_file: The file path to a python module file, from which the\n        \'preprocessing_fn\' function will be loaded. The function must have the\n        following signature.\n\n        def preprocessing_fn(inputs: Dict[Text, Any]) -> Dict[Text, Any]:\n          ...\n\n        where the values of input and returned Dict are either tf.Tensor or\n        tf.SparseTensor.  Exactly one of \'module_file\' or \'preprocessing_fn\'\n        must be supplied.\n      preprocessing_fn: The path to python function that implements a\n        \'preprocessing_fn\'. See \'module_file\' for expected signature of the\n        function. Exactly one of \'module_file\' or \'preprocessing_fn\' must be\n        supplied.\n      transform_graph: Optional output \'TransformPath\' channel for output of\n        \'tf.Transform\', which includes an exported Tensorflow graph suitable for\n        both training and serving;\n      transformed_examples: Optional output \'ExamplesPath\' channel for\n        materialized transformed examples, which includes both \'train\' and\n        \'eval\' splits.\n      input_data: Backwards compatibility alias for the \'examples\' argument.\n      instance_name: Optional unique instance name. Necessary iff multiple\n        transform components are declared in the same pipeline.\n\n    Raises:\n      ValueError: When both or neither of \'module_file\' and \'preprocessing_fn\'\n        is supplied.\n    """"""\n    if input_data:\n      absl.logging.warning(\n          \'The ""input_data"" argument to the Transform component has \'\n          \'been renamed to ""examples"" and is deprecated. Please update your \'\n          \'usage as support for this argument will be removed soon.\')\n      examples = input_data\n    if bool(module_file) == bool(preprocessing_fn):\n      raise ValueError(\n          ""Exactly one of \'module_file\' or \'preprocessing_fn\' must be supplied.""\n      )\n\n    transform_graph = transform_graph or types.Channel(\n        type=standard_artifacts.TransformGraph,\n        artifacts=[standard_artifacts.TransformGraph()])\n    if not transformed_examples:\n      example_artifact = standard_artifacts.Examples()\n      example_artifact.split_names = artifact_utils.encode_split_names(\n          artifact.DEFAULT_EXAMPLE_SPLITS)\n      transformed_examples = types.Channel(\n          type=standard_artifacts.Examples, artifacts=[example_artifact])\n    spec = TransformSpec(\n        examples=examples,\n        schema=schema,\n        module_file=module_file,\n        preprocessing_fn=preprocessing_fn,\n        transform_graph=transform_graph,\n        transformed_examples=transformed_examples)\n    super(Transform, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/transform/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.transform.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\nimport tensorflow as tf\nfrom tfx.components.transform import component\nfrom tfx.orchestration import data_types\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ComponentTest, self).setUp()\n    examples_artifact = standard_artifacts.Examples()\n    examples_artifact.split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n    self.examples = channel_utils.as_channel([examples_artifact])\n    self.schema = channel_utils.as_channel(\n        [standard_artifacts.Schema()])\n\n  def _verify_outputs(self, transform):\n    self.assertEqual(standard_artifacts.TransformGraph.TYPE_NAME,\n                     transform.outputs[\'transform_graph\'].type_name)\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     transform.outputs[\'transformed_examples\'].type_name)\n\n  def testConstructFromModuleFile(self):\n    module_file = \'/path/to/preprocessing.py\'\n    transform = component.Transform(\n        examples=self.examples,\n        schema=self.schema,\n        module_file=module_file,\n    )\n    self._verify_outputs(transform)\n    self.assertEqual(module_file, transform.spec.exec_properties[\'module_file\'])\n\n  def testConstructWithParameter(self):\n    module_file = data_types.RuntimeParameter(name=\'module-file\', ptype=Text)\n    transform = component.Transform(\n        examples=self.examples,\n        schema=self.schema,\n        module_file=module_file,\n    )\n    self._verify_outputs(transform)\n    self.assertJsonEqual(\n        str(module_file), str(transform.spec.exec_properties[\'module_file\']))\n\n  def testConstructFromPreprocessingFn(self):\n    preprocessing_fn = \'path.to.my_preprocessing_fn\'\n    transform = component.Transform(\n        examples=self.examples,\n        schema=self.schema,\n        preprocessing_fn=preprocessing_fn,\n    )\n    self._verify_outputs(transform)\n    self.assertEqual(preprocessing_fn,\n                     transform.spec.exec_properties[\'preprocessing_fn\'])\n\n  def testConstructMissingUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Transform(\n          examples=self.examples,\n          schema=self.schema,\n      )\n\n  def testConstructDuplicateUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Transform(\n          examples=self.examples,\n          schema=self.schema,\n          module_file=\'/path/to/preprocessing.py\',\n          preprocessing_fn=\'path.to.my_preprocessing_fn\',\n      )\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/transform/executor.py,23,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Executor for TensorFlow Transform.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, Generator, Iterable, List, Mapping, Optional, Sequence, Set, Text, Tuple, Union\n\nimport absl\nimport apache_beam as beam\nimport pyarrow as pa\nimport tensorflow as tf\nimport tensorflow_data_validation as tfdv\nimport tensorflow_transform as tft\nfrom tensorflow_transform import impl_helper\nimport tensorflow_transform.beam as tft_beam\nfrom tensorflow_transform.beam import analyzer_cache\nfrom tensorflow_transform.beam import common as tft_beam_common\nfrom tensorflow_transform.saved import saved_transform_io\nfrom tensorflow_transform.tf_metadata import dataset_metadata\nfrom tensorflow_transform.tf_metadata import dataset_schema\nfrom tensorflow_transform.tf_metadata import metadata_io\nfrom tensorflow_transform.tf_metadata import schema_utils\nimport tfx_bsl\nfrom tfx_bsl.tfxio import raw_tf_record\nfrom tfx_bsl.tfxio import tf_example_record\nfrom tfx_bsl.tfxio import tfxio\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tensorflow_metadata.proto.v0 import statistics_pb2\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.transform import labels\nfrom tfx.components.transform import stats_options as transform_stats_options\nfrom tfx.components.transform import messages\nfrom tfx.components.util import value_utils\nfrom tfx.types import artifact_utils\nfrom tfx.utils import import_utils\nfrom tfx.utils import io_utils\n\n# Key for examples in executor input_dict.\nEXAMPLES_KEY = \'examples\'\n# Key for schema in executor input_dict.\nSCHEMA_KEY = \'schema\'\n\n# Key for temp path, for internal use only.\nTEMP_PATH_KEY = \'temp_path\'\n\n# Key for transform graph in executor output_dict.\nTRANSFORM_GRAPH_KEY = \'transform_graph\'\n# Key for output model in executor output_dict.\nTRANSFORMED_EXAMPLES_KEY = \'transformed_examples\'\n\nRAW_EXAMPLE_KEY = \'raw_example\'\n\n# Schema to use if the input data should be decoded as raw example.\n_RAW_EXAMPLE_SCHEMA = schema_utils.schema_from_feature_spec(\n    {RAW_EXAMPLE_KEY: tf.io.FixedLenFeature([], tf.string)})\n\n# TODO(b/123519698): Simplify the code by removing the key structure.\n_TRANSFORM_INTERNAL_FEATURE_FOR_KEY = \'__TFT_PASS_KEY__\'\n\n# Default file name prefix for transformed_examples.\n_DEFAULT_TRANSFORMED_EXAMPLES_PREFIX = \'transformed_examples\'\n\n# Temporary path inside transform_output used for tft.beam\n# TODO(b/125451545): Provide a safe temp path from base executor instead.\n_TEMP_DIR_IN_TRANSFORM_OUTPUT = \'.temp_path\'\n\n_TRANSFORM_COMPONENT_DESCRIPTOR = \'Transform\'\n\n\n# TODO(b/122478841): Move it to a common place that is shared across components.\nclass _Status(object):\n  """"""Status that reports success or error status of an execution.""""""\n\n  def __init__(self, is_error, error_message=None):\n    self._is_error = is_error\n    self._error_message = error_message\n\n  @classmethod\n  def OK(cls):\n    """"""Returns an ok Status.""""""\n\n    return _Status(False)\n\n  @classmethod\n  def Error(cls, error_message):\n    """"""Returns an error Status with error message.""""""\n\n    return _Status(True, error_message)\n\n  @property\n  def error_message(self):\n    return self._error_message\n\n\nclass _Dataset(object):\n  """"""Dataset to be analyzed and/or transformed.\n\n  It also contains bundle of stages of a single dataset through the transform\n  pipeline.\n  """"""\n  # TODO(b/37788560): This seems like a brittle way of creating dataset keys.\n  # In particular there are no guarantees that there won\'t be colissions.\n  # A better approach might be something like ArtifactID, or perhaps\n  # SHA256(file_pattern) which might also be a lot less verbose (even if it\n  # might not be as self-describing).\n  _FILE_PATTERN_SUFFIX_LENGTH = 6\n\n  def __init__(self, file_pattern: Text,\n               file_format: Union[Text, int],\n               data_format: Union[Text, int],\n               stats_output_path: Optional[Text] = None,\n               materialize_output_path: Optional[Text] = None):\n    """"""Initialize a Dataset.\n\n    Args:\n      file_pattern: The file pattern of the dataset.\n      file_format: The file format of the dataset.\n      data_format: The data format of the dataset.\n      stats_output_path: The file path where to write stats for the dataset.\n      materialize_output_path: The file path where to write the dataset.\n    """"""\n    self._file_pattern = file_pattern\n    file_pattern_suffix = os.path.join(\n        *file_pattern.split(os.sep)[-self._FILE_PATTERN_SUFFIX_LENGTH:])\n    # TODO(b/148082271, b/148212028, b/37788560): Just use\n    # analyzer_cache.DatasetKey when we stop supporting TFT 0.21.2.\n    if hasattr(analyzer_cache, \'DatasetKey\'):\n      self._dataset_key = analyzer_cache.DatasetKey(file_pattern_suffix)\n    else:\n      self._dataset_key = analyzer_cache.make_dataset_key(file_pattern_suffix)\n    self._file_format = file_format\n    self._data_format = data_format\n    self._stats_output_path = stats_output_path\n    self._materialize_output_path = materialize_output_path\n    self._index = None\n    self._serialized = None\n    self._decoded = None\n    self._standardized = None\n    self._transformed = None\n    self._transformed_and_serialized = None\n    self._transformed_and_standardized = None\n    self._tfxio = None\n\n  @property\n  def file_pattern(self):\n    assert self._file_pattern\n    return self._file_pattern\n\n  @property\n  def stats_output_path(self):\n    assert self._stats_output_path\n    return self._stats_output_path\n\n  @property\n  def materialize_output_path(self):\n    assert self._materialize_output_path\n    return self._materialize_output_path\n\n  @property\n  def index(self):\n    assert self._index is not None\n    return self._index\n\n  @property\n  def dataset_key(self):\n    assert self._dataset_key\n    return self._dataset_key\n\n  @property\n  def data_format(self):\n    assert self._data_format\n    return self._data_format\n\n  @property\n  def file_format(self):\n    assert self._file_format\n    return self._file_format\n\n  @property\n  def serialized(self):\n    assert self._serialized is not None\n    return self._serialized\n\n  @property\n  def decoded(self):\n    assert self._decoded is not None\n    return self._decoded\n\n  @property\n  def standardized(self):\n    assert self._standardized is not None\n    return self._standardized\n\n  @property\n  def transformed(self):\n    assert self._transformed is not None\n    return self._transformed\n\n  @property\n  def transformed_and_serialized(self):\n    assert self._transformed_and_serialized is not None\n    return self._transformed_and_serialized\n\n  @property\n  def transformed_and_standardized(self):\n    assert self._transformed_and_standardized is not None\n    return self._transformed_and_standardized\n\n  @property\n  def tfxio(self):\n    assert self._tfxio is not None\n    return self._tfxio\n\n  @index.setter\n  def index(self, val):\n    self._index = val\n\n  @serialized.setter\n  def serialized(self, val):\n    self._serialized = val\n\n  @decoded.setter\n  def decoded(self, val):\n    self._decoded = val\n\n  @standardized.setter\n  def standardized(self, val):\n    self._standardized = val\n\n  @transformed.setter\n  def transformed(self, val):\n    self._transformed = val\n\n  @transformed_and_serialized.setter\n  def transformed_and_serialized(self, val):\n    self._transformed_and_serialized = val\n\n  @transformed_and_standardized.setter\n  def transformed_and_standardized(self, val):\n    self._transformed_and_standardized = val\n\n  @tfxio.setter\n  def tfxio(self, val):\n    self._tfxio = val\n\n\ndef _GetSchemaProto(\n    metadata: dataset_metadata.DatasetMetadata) -> schema_pb2.Schema:\n  """"""Gets the schema proto associated with a DatasetMetadata.\n\n  This is needed because tensorflow_transform 0.13 and tensorflow_transform 0.14\n  have a different API for DatasetMetadata.\n\n  Args:\n    metadata: A dataset_metadata.DatasetMetadata.\n\n  Returns:\n    A schema_pb2.Schema.\n  """"""\n  # `schema` is either a Schema proto or dataset_schema.Schema.\n  schema = metadata.schema\n  # In the case where it\'s a dataset_schema.Schema, fetch the schema proto.\n  return getattr(schema, \'_schema_proto\', schema)\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Transform executor.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""TensorFlow Transform executor entrypoint.\n\n    This implements BaseExecutor.Do() and is invoked by orchestration systems.\n    This is not inteded for manual usage or further customization. Please use\n    the Transform() function which takes an input format with no artifact\n    dependency.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - input_data: A list of type `standard_artifacts.Examples` which\n          should contain two splits \'train\' and \'eval\'.\n        - schema: A list of type `standard_artifacts.Schema` which should\n          contain a single schema artifact.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - transform_output: Output of \'tf.Transform\', which includes an exported\n          Tensorflow graph suitable for both training and serving;\n        - transformed_examples: Materialized transformed examples, which\n          includes both \'train\' and \'eval\' splits.\n      exec_properties: A dict of execution properties, including either one of:\n        - module_file: The file path to a python module file, from which the\n          \'preprocessing_fn\' function will be loaded.\n        - preprocessing_fn: The module path to a python function that\n          implements \'preprocessing_fn\'.\n\n    Returns:\n      None\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n    train_data_uri = artifact_utils.get_split_uri(input_dict[EXAMPLES_KEY],\n                                                  \'train\')\n    eval_data_uri = artifact_utils.get_split_uri(input_dict[EXAMPLES_KEY],\n                                                 \'eval\')\n    schema_file = io_utils.get_only_uri_in_dir(\n        artifact_utils.get_single_uri(input_dict[SCHEMA_KEY]))\n    transform_output = artifact_utils.get_single_uri(\n        output_dict[TRANSFORM_GRAPH_KEY])\n    transformed_train_output = artifact_utils.get_split_uri(\n        output_dict[TRANSFORMED_EXAMPLES_KEY], \'train\')\n    transformed_eval_output = artifact_utils.get_split_uri(\n        output_dict[TRANSFORMED_EXAMPLES_KEY], \'eval\')\n    temp_path = os.path.join(transform_output, _TEMP_DIR_IN_TRANSFORM_OUTPUT)\n    absl.logging.debug(\'Using temp path %s for tft.beam\', temp_path)\n\n    def _GetCachePath(label, params_dict):\n      if label not in params_dict:\n        return None\n      else:\n        return artifact_utils.get_single_uri(params_dict[label])\n\n    label_inputs = {\n        labels.COMPUTE_STATISTICS_LABEL:\n            False,\n        labels.SCHEMA_PATH_LABEL:\n            schema_file,\n        labels.EXAMPLES_DATA_FORMAT_LABEL:\n            labels.FORMAT_TF_EXAMPLE,\n        labels.ANALYZE_DATA_PATHS_LABEL:\n            io_utils.all_files_pattern(train_data_uri),\n        labels.ANALYZE_PATHS_FILE_FORMATS_LABEL:\n            labels.FORMAT_TFRECORD,\n        labels.TRANSFORM_DATA_PATHS_LABEL: [\n            io_utils.all_files_pattern(train_data_uri),\n            io_utils.all_files_pattern(eval_data_uri)\n        ],\n        labels.TRANSFORM_PATHS_FILE_FORMATS_LABEL: [\n            labels.FORMAT_TFRECORD, labels.FORMAT_TFRECORD\n        ],\n        labels.MODULE_FILE:\n            exec_properties.get(\'module_file\', None),\n        labels.PREPROCESSING_FN:\n            exec_properties.get(\'preprocessing_fn\', None),\n        # TODO(b/149754658): switch to True once the TFXIO integration is\n        # complete.\n        labels.USE_TFXIO_LABEL: False,\n    }\n    cache_input = _GetCachePath(\'cache_input_path\', input_dict)\n    if cache_input is not None:\n      label_inputs[labels.CACHE_INPUT_PATH_LABEL] = cache_input\n\n    label_outputs = {\n        labels.TRANSFORM_METADATA_OUTPUT_PATH_LABEL: transform_output,\n        labels.TRANSFORM_MATERIALIZE_OUTPUT_PATHS_LABEL: [\n            os.path.join(transformed_train_output,\n                         _DEFAULT_TRANSFORMED_EXAMPLES_PREFIX),\n            os.path.join(transformed_eval_output,\n                         _DEFAULT_TRANSFORMED_EXAMPLES_PREFIX),\n        ],\n        labels.TEMP_OUTPUT_LABEL: str(temp_path),\n    }\n    cache_output = _GetCachePath(\'cache_output_path\', output_dict)\n    if cache_output is not None:\n      label_outputs[labels.CACHE_OUTPUT_PATH_LABEL] = cache_output\n    status_file = \'status_file\'  # Unused\n    self.Transform(label_inputs, label_outputs, status_file)\n    absl.logging.debug(\'Cleaning up temp path %s on executor success\',\n                       temp_path)\n    io_utils.delete_dir(temp_path)\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(beam.Pipeline)\n  @beam.typehints.with_output_types(beam.pvalue.PDone)\n  def _IncrementColumnUsageCounter(pipeline: beam.Pipeline,\n                                   total_columns_count: int,\n                                   analyze_columns_count: int,\n                                   transform_columns_count: int):\n    """"""A beam PTransform to increment counters of column usage.""""""\n\n    def _MakeAndIncrementCounters(unused_element):\n      """"""Increment column usage counters.""""""\n      del unused_element\n      beam.metrics.Metrics.counter(\n          tft_beam_common.METRICS_NAMESPACE,\n          \'total_columns_count\').inc(total_columns_count)\n      beam.metrics.Metrics.counter(\n          tft_beam_common.METRICS_NAMESPACE,\n          \'analyze_columns_count\').inc(analyze_columns_count)\n      beam.metrics.Metrics.counter(\n          tft_beam_common.METRICS_NAMESPACE,\n          \'transform_columns_count\').inc(transform_columns_count)\n      return beam.pvalue.PDone(pipeline)\n\n    return (\n        pipeline\n        | \'CreateSole\' >> beam.Create([None])\n        | \'Count\' >> beam.Map(_MakeAndIncrementCounters))\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(beam.Pipeline)\n  # TODO(b/38376110): Obviate the first bytes (ie the key part).\n  @beam.typehints.with_output_types(Tuple[None, bytes])\n  def _ReadExamples(\n      pipeline: beam.Pipeline, dataset: _Dataset,\n      input_dataset_metadata: dataset_metadata.DatasetMetadata\n  ) -> beam.pvalue.PCollection:\n    """"""Reads examples from the given `dataset`.\n\n    Args:\n      pipeline: beam pipeline.\n      dataset: A `_Dataset` object that represents the data to read.\n      input_dataset_metadata: A `dataset_metadata.DatasetMetadata`. Not used.\n\n    Returns:\n      A PCollection containing KV pairs of bytes.\n    """"""\n    del input_dataset_metadata\n    assert dataset.file_format == labels.FORMAT_TFRECORD, dataset.file_format\n\n    return (\n        pipeline\n        | \'Read\' >> beam.io.ReadFromTFRecord(\n            dataset.file_pattern,\n            coder=beam.coders.BytesCoder(),\n            # TODO(b/114938612): Eventually remove this override.\n            validate=False)\n        | \'AddKey\' >> beam.Map(lambda x: (None, x)))\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(Tuple[Optional[bytes], bytes])\n  @beam.typehints.with_output_types(beam.pvalue.PDone)\n  def _WriteExamples(pcoll: beam.pvalue.PCollection, file_format: Text,\n                     transformed_example_path: Text) -> beam.pvalue.PDone:\n    """"""Writes transformed examples compressed in gzip format.\n\n    Args:\n      pcoll: PCollection of serialized transformed examples.\n      file_format: The output file format.\n      transformed_example_path: path to write to.\n\n    Returns:\n      beam.pvalue.PDone.\n    """"""\n    assert file_format == labels.FORMAT_TFRECORD, file_format\n\n    # TODO(b/139538871): Implement telemetry, on top of pa.Table once available.\n    return (\n        pcoll\n        | \'Values\' >> beam.Values()\n        | \'Write\' >> beam.io.WriteToTFRecord(\n            transformed_example_path, file_name_suffix=\'.gz\'))\n\n  def _GetSchema(self, schema_path: Text) -> schema_pb2.Schema:\n    """"""Gets a tf.metadata schema.\n\n    Args:\n      schema_path: Path to schema file.\n\n    Returns:\n      A tf.metadata schema.\n    """"""\n    schema_reader = io_utils.SchemaReader()\n    return schema_reader.read(schema_path)\n\n  def _ReadMetadata(self, data_format: Text,\n                    schema_path: Text) -> dataset_metadata.DatasetMetadata:\n    """"""Returns a dataset_metadata.DatasetMetadata for the input data.\n\n    Args:\n      data_format: name of the input data format.\n      schema_path: path to schema file.\n\n    Returns:\n      A dataset_metadata.DatasetMetadata representing the provided set of\n          columns.\n    """"""\n\n    if self._ShouldDecodeAsRawExample(data_format):\n      return dataset_metadata.DatasetMetadata(_RAW_EXAMPLE_SCHEMA)\n    schema_proto = self._GetSchema(schema_path)\n    # For compatibility with tensorflow_transform 0.13 and 0.14, we create and\n    # then update a DatasetMetadata.\n    result = dataset_metadata.DatasetMetadata(dataset_schema.Schema({}))\n    _GetSchemaProto(result).CopyFrom(schema_proto)\n    return result\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(pa.RecordBatch)\n  @beam.typehints.with_output_types(beam.pvalue.PDone)\n  def _GenerateStats(\n      pcoll: beam.pvalue.PCollection,\n      stats_output_path: Text,\n      schema: schema_pb2.Schema,\n      stats_options: tfdv.StatsOptions,\n  ) -> beam.pvalue.PDone:\n    """"""Generates statistics.\n\n    Args:\n      pcoll: PCollection of examples.\n      stats_output_path: path where statistics is written to.\n      schema: schema.\n      stats_options: An instance of `tfdv.StatsOptions()` used when computing\n        statistics.\n\n    Returns:\n      beam.pvalue.PDone.\n    """"""\n    def _FilterInternalColumn(record_batch):\n      filtered_column_names = []\n      filtered_columns = []\n      for i, column_name in enumerate(record_batch.schema.names):\n        if column_name != _TRANSFORM_INTERNAL_FEATURE_FOR_KEY:\n          filtered_column_names.append(column_name)\n          filtered_columns.append(record_batch.column(i))\n      return pa.RecordBatch.from_arrays(filtered_columns, filtered_column_names)\n\n    pcoll |= \'FilterInternalColumn\' >> beam.Map(_FilterInternalColumn)\n    stats_options.schema = schema\n    # pylint: disable=no-value-for-parameter\n    return (\n        pcoll\n        | \'GenerateStatistics\' >> tfdv.GenerateStatistics(stats_options)\n        | \'WriteStats\' >> Executor._WriteStats(stats_output_path))\n\n  # TODO(b/150456345): Obviate this once TFXIO-in-Transform rollout is\n  # completed.\n  @beam.typehints.with_input_types(List[bytes])\n  @beam.typehints.with_output_types(pa.RecordBatch)\n  class _ToArrowRecordBatchesFn(beam.DoFn):\n    """"""Converts a batch of serialized examples to an Arrow RecordBatch.""""""\n\n    def __init__(self, schema: Optional[schema_pb2.Schema]):\n      self._serialized_schema = schema.SerializeToString() if schema else None\n\n    def setup(self):\n      args = ([] if self._serialized_schema is None\n              else [self._serialized_schema])\n      self._decoder = (\n          tfx_bsl.coders.example_coder.ExamplesToRecordBatchDecoder(*args))\n\n    def process(self, element: List[bytes]) -> Iterable[pa.RecordBatch]:\n      yield self._decoder.DecodeBatch(element)\n\n  # TODO(zhuo): Obviate this once TFXIO is used.\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(Tuple[Optional[bytes], bytes])\n  @beam.typehints.with_output_types(pa.RecordBatch)\n  def _ToArrowRecordBatches(\n      pcoll: beam.pvalue.PCollection,\n      schema: Optional[schema_pb2.Schema]) -> beam.pvalue.PCollection:\n    """"""Converts serialized examples to Arrow RecordBatches.\n\n    Args:\n      pcoll: PCollection of Transformed data.\n      schema: schema.\n\n    Returns:\n      PCollection of `DatasetFeatureStatisticsList`.\n    """"""\n    kwargs = tfdv.utils.batch_util.GetBeamBatchKwargs(\n        tft_beam.Context.get_desired_batch_size())\n    return (\n        pcoll\n        | \'Values\' >> beam.Values()\n        | \'BatchElements\' >> beam.BatchElements(**kwargs)\n        | \'ToArrowRecordBatches\' >> beam.ParDo(\n            Executor._ToArrowRecordBatchesFn(schema)))\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(statistics_pb2.DatasetFeatureStatisticsList)\n  @beam.typehints.with_output_types(beam.pvalue.PDone)\n  def _WriteStats(pcollection_stats: beam.pvalue.PCollection,\n                  stats_output_path: Text) -> beam.pvalue.PDone:\n    """"""Writs Statistics outputs.\n\n    Args:\n      pcollection_stats: pcollection of statistics.\n      stats_output_path: path to write statistics.\n\n    Returns:\n      beam.pvalue.PDone.\n    """"""\n\n    # TODO(b/68765333): Investigate if this can be avoided.\n    tf.io.gfile.makedirs(os.path.dirname(stats_output_path))\n    # TODO(b/117601471): Replace with utility method to write stats.\n    return (pcollection_stats | \'Write\' >> beam.io.WriteToText(\n        stats_output_path,\n        append_trailing_newlines=False,\n        shard_name_template=\'\',  # To force unsharded output.\n        coder=beam.coders.ProtoCoder(\n            statistics_pb2.DatasetFeatureStatisticsList)))\n\n  @staticmethod\n  @beam.ptransform_fn\n  @beam.typehints.with_input_types(Tuple[Optional[bytes], bytes])\n  @beam.typehints.with_output_types(Dict[Text, Any])\n  def _DecodeInputs(pcoll: beam.pvalue.PCollection,\n                    decode_fn: Any) -> beam.pvalue.PCollection:\n    """"""Decodes the given PCollection while handling KV data.\n\n    Args:\n      pcoll: PCollection of data.\n      decode_fn: Function used to decode data.\n\n    Returns:\n      PCollection of decoded data.\n    """"""\n\n    def decode_example(kv: Tuple[Optional[bytes], bytes]) -> Dict[Text, Any]:  # pylint: disable=invalid-name\n      """"""Decodes a single example.""""""\n      (key, value) = kv\n      result = decode_fn(value)\n      if _TRANSFORM_INTERNAL_FEATURE_FOR_KEY in result:\n        raise ValueError(\'""{}"" is a reserved feature name, \'\n                         \'it should not be present in the dataset.\'.format(\n                             _TRANSFORM_INTERNAL_FEATURE_FOR_KEY))\n      result[_TRANSFORM_INTERNAL_FEATURE_FOR_KEY] = key\n      return result\n\n    return pcoll | \'ApplyDecodeFn\' >> beam.Map(decode_example)\n\n  @beam.typehints.with_input_types(Dict[Text, Any], schema=schema_pb2.Schema)\n  @beam.typehints.with_output_types(Tuple[Optional[bytes], bytes])\n  class _EncodeAsSerializedExamples(beam.DoFn):\n    """"""Encodes data as serialized tf.Examples based on the given metadata.""""""\n\n    def __init__(self):\n      self._coder = None\n\n    def process(self, element: Dict[Text, Any], schema: schema_pb2.Schema\n               ) -> Generator[Tuple[Any, Any], None, None]:\n      if self._coder is None:\n        self._coder = tft.coders.ExampleProtoCoder(schema, serialized=True)\n\n      # Make sure that the synthetic key feature doesn\'t get encoded.\n      key = element.get(_TRANSFORM_INTERNAL_FEATURE_FOR_KEY, None)\n      if key is not None:\n        element = element.copy()\n        del element[_TRANSFORM_INTERNAL_FEATURE_FOR_KEY]\n      yield (key, self._coder.encode(element))\n\n  @beam.typehints.with_input_types(beam.Pipeline)\n  class _OptimizeRun(beam.PTransform):\n    """"""Utilizes TFT cache if applicable and removes unused datasets.""""""\n\n    # pyformat: disable\n    def __init__(self,\n                 input_cache_dir: Text,\n                 output_cache_dir: Text,\n                 analyze_data_list: List[_Dataset],\n                 feature_spec_or_typespec: Mapping[Text, Any],\n                 preprocessing_fn: Any,\n                 cache_source: beam.PTransform):\n      # pyformat: enable\n      self._input_cache_dir = input_cache_dir\n      self._output_cache_dir = output_cache_dir\n      self._analyze_data_list = analyze_data_list\n      self._feature_spec_or_typespec = feature_spec_or_typespec\n      self._preprocessing_fn = preprocessing_fn\n      self._cache_source = cache_source\n\n    # TODO(zoy): Remove this method once beam no longer pickles PTransforms,\n    # once https://issues.apache.org/jira/browse/BEAM-3812 is resolved.\n    def to_runner_api_pickled(self, context):\n      # Overriding to_runner_api_pickled and calling to_runner_api_parameter\n      # instead to make sure that beam doesn\'t try to pickle the\n      # preprocessing_fn with the PTransform instance since it may not be\n      # picklable.\n      return self.to_runner_api_parameter(context)\n\n    def expand(\n        self, pipeline\n    ) -> Tuple[Dict[Text, Optional[_Dataset]], Optional[Dict[Text, Dict[\n        Text, beam.pvalue.PCollection]]]]:\n      dataset_keys_list = [\n          dataset.dataset_key for dataset in self._analyze_data_list\n      ]\n      if self._input_cache_dir is not None:\n        # TODO(b/148082271, b/148212028, b/37788560): pass all kwargs directly\n        # when we stop supporting TFT 0.21.2.\n        read_cache_kwargs = dict(source=self._cache_source)\n        if hasattr(analyzer_cache, \'DatasetKey\'):\n          read_cache_kwargs[\'cache_entry_keys\'] = (\n              tft_beam.analysis_graph_builder.get_analysis_cache_entry_keys(\n                  self._preprocessing_fn, self._feature_spec_or_typespec,\n                  dataset_keys_list))\n        input_cache = (\n            pipeline\n            | \'ReadCache\' >> analyzer_cache.ReadAnalysisCacheFromFS(\n                self._input_cache_dir, dataset_keys_list, **read_cache_kwargs))\n      elif self._output_cache_dir is not None:\n        input_cache = {}\n      else:\n        # Using None here to indicate that this pipeline will not read or write\n        # cache.\n        input_cache = None\n\n      if input_cache is None:\n        # Cache is disabled so we won\'t be filtering out any datasets, and will\n        # always perform a flatten over all of them.\n        filtered_analysis_dataset_keys = dataset_keys_list\n      else:\n        filtered_analysis_dataset_keys = (\n            tft_beam.analysis_graph_builder.get_analysis_dataset_keys(\n                self._preprocessing_fn, self._feature_spec_or_typespec,\n                dataset_keys_list, input_cache))\n        # TODO(b/148082271, b/148212028, b/37788560): Remove this when we stop\n        # supporting TFT 0.21.2.\n        if isinstance(filtered_analysis_dataset_keys, tuple):\n          filtered_analysis_dataset_keys = filtered_analysis_dataset_keys[0]\n\n      new_analyze_data_dict = {}\n      for dataset in self._analyze_data_list:\n        if dataset.dataset_key in filtered_analysis_dataset_keys:\n          new_analyze_data_dict[dataset.dataset_key] = dataset\n        else:\n          new_analyze_data_dict[dataset.dataset_key] = None\n\n      return (new_analyze_data_dict, input_cache)\n\n  def _GetPreprocessingFn(self, inputs: Mapping[Text, Any],\n                          unused_outputs: Mapping[Text, Any]) -> Any:\n    """"""Returns a user defined preprocessing_fn.\n\n    Args:\n      inputs: A dictionary of labelled input values.\n      unused_outputs: A dictionary of labelled output values.\n\n    Returns:\n      User defined function.\n\n    Raises:\n      ValueError: When neither or both of MODULE_FILE and PREPROCESSING_FN\n        are present in inputs.\n    """"""\n    has_module_file = bool(\n        value_utils.GetSoleValue(inputs, labels.MODULE_FILE, strict=False))\n    has_preprocessing_fn = bool(\n        value_utils.GetSoleValue(inputs, labels.PREPROCESSING_FN, strict=False))\n\n    if has_module_file == has_preprocessing_fn:\n      raise ValueError(\n          \'Neither or both of MODULE_FILE and PREPROCESSING_FN have been \'\n          \'supplied in inputs.\')\n\n    if has_module_file:\n      return import_utils.import_func_from_source(\n          value_utils.GetSoleValue(inputs, labels.MODULE_FILE),\n          \'preprocessing_fn\')\n\n    preprocessing_fn_path_split = value_utils.GetSoleValue(\n        inputs, labels.PREPROCESSING_FN).split(\'.\')\n    return import_utils.import_func_from_module(\n        \'.\'.join(preprocessing_fn_path_split[0:-1]),\n        preprocessing_fn_path_split[-1])\n\n  # TODO(b/122478841): Refine this API in following cls.\n  # Note: This API is up to change.\n  def Transform(self, inputs: Mapping[Text, Any], outputs: Mapping[Text, Any],\n                status_file: Text) -> None:\n    """"""Executes on request.\n\n    This is the implementation part of transform executor. This is intended for\n    using or extending the executor without artifact dependency.\n\n    Args:\n      inputs: A dictionary of labelled input values, including:\n        - labels.COMPUTE_STATISTICS_LABEL: Whether compute statistics.\n        - labels.SCHEMA_PATH_LABEL: Path to schema file.\n        - labels.EXAMPLES_DATA_FORMAT_LABEL: Example data format.\n        - labels.ANALYZE_DATA_PATHS_LABEL: Paths or path patterns to analyze\n          data.\n        - labels.ANALYZE_PATHS_FILE_FORMATS_LABEL: File formats of paths to\n          analyze data.\n        - labels.TRANSFORM_DATA_PATHS_LABEL: Paths or path patterns to transform\n          data.\n        - labels.TRANSFORM_PATHS_FILE_FORMATS_LABEL: File formats of paths to\n          transform data.\n        - labels.MODULE_FILE: Path to a Python module that contains the\n          preprocessing_fn, optional.\n        - labels.PREPROCESSING_FN: Path to a Python function that implements\n          preprocessing_fn, optional.\n        - labels.USE_TFXIO_LABEL: Whether use the TFXIO-based TFT APIs.\n      outputs: A dictionary of labelled output values, including:\n        - labels.PER_SET_STATS_OUTPUT_PATHS_LABEL: Paths to statistics output,\n          optional.\n        - labels.TRANSFORM_METADATA_OUTPUT_PATH_LABEL: A path to\n          TFTransformOutput output.\n        - labels.TRANSFORM_MATERIALIZE_OUTPUT_PATHS_LABEL: Paths to transform\n          materialization.\n        - labels.TEMP_OUTPUT_LABEL: A path to temporary directory.\n      status_file: Where the status should be written (not yet implemented)\n    """"""\n    del status_file  # unused\n\n    absl.logging.debug(\n        \'Inputs to executor.Transform function: {}\'.format(inputs))\n    absl.logging.debug(\n        \'Outputs to executor.Transform function: {}\'.format(outputs))\n\n    compute_statistics = value_utils.GetSoleValue(\n        inputs, labels.COMPUTE_STATISTICS_LABEL)\n    transform_output_path = value_utils.GetSoleValue(\n        outputs, labels.TRANSFORM_METADATA_OUTPUT_PATH_LABEL)\n    raw_examples_data_format = value_utils.GetSoleValue(\n        inputs, labels.EXAMPLES_DATA_FORMAT_LABEL)\n    schema = value_utils.GetSoleValue(inputs, labels.SCHEMA_PATH_LABEL)\n    input_dataset_metadata = self._ReadMetadata(raw_examples_data_format,\n                                                schema)\n    use_tfxio = value_utils.GetSoleValue(inputs, labels.USE_TFXIO_LABEL)\n    materialize_output_paths = value_utils.GetValues(\n        outputs, labels.TRANSFORM_MATERIALIZE_OUTPUT_PATHS_LABEL)\n    preprocessing_fn = self._GetPreprocessingFn(inputs, outputs)\n    per_set_stats_output_paths = value_utils.GetValues(\n        outputs, labels.PER_SET_STATS_OUTPUT_PATHS_LABEL)\n    analyze_data_paths = value_utils.GetValues(inputs,\n                                               labels.ANALYZE_DATA_PATHS_LABEL)\n    analyze_paths_file_formats = value_utils.GetValues(\n        inputs, labels.ANALYZE_PATHS_FILE_FORMATS_LABEL)\n    transform_data_paths = value_utils.GetValues(\n        inputs, labels.TRANSFORM_DATA_PATHS_LABEL)\n    transform_paths_file_formats = value_utils.GetValues(\n        inputs, labels.TRANSFORM_PATHS_FILE_FORMATS_LABEL)\n    input_cache_dir = value_utils.GetSoleValue(\n        inputs, labels.CACHE_INPUT_PATH_LABEL, strict=False)\n    output_cache_dir = value_utils.GetSoleValue(\n        outputs, labels.CACHE_OUTPUT_PATH_LABEL, strict=False)\n    per_set_stats_output_paths = value_utils.GetValues(\n        outputs, labels.PER_SET_STATS_OUTPUT_PATHS_LABEL)\n    temp_path = value_utils.GetSoleValue(outputs, labels.TEMP_OUTPUT_LABEL)\n\n    absl.logging.debug(\'Analyze data patterns: %s\',\n                       list(enumerate(analyze_data_paths)))\n    absl.logging.debug(\'Transform data patterns: %s\',\n                       list(enumerate(transform_data_paths)))\n    absl.logging.debug(\'Transform materialization output paths: %s\',\n                       list(enumerate(materialize_output_paths)))\n    absl.logging.debug(\'Transform output path: %s\', transform_output_path)\n\n    if len(analyze_data_paths) != len(analyze_paths_file_formats):\n      raise ValueError(\n          \'size of analyze_data_paths and \'\n          \'analyze_paths_file_formats do not match: {} v.s {}\'.format(\n              len(analyze_data_paths), len(analyze_paths_file_formats)))\n    if len(transform_data_paths) != len(transform_paths_file_formats):\n      raise ValueError(\n          \'size of transform_data_paths and \'\n          \'transform_paths_file_formats do not match: {} v.s {}\'.format(\n              len(transform_data_paths), len(transform_paths_file_formats)))\n\n    can_process_analysis_jointly = not bool(output_cache_dir)\n    analyze_data_list = self._MakeDatasetList(analyze_data_paths,\n                                              analyze_paths_file_formats,\n                                              raw_examples_data_format,\n                                              can_process_analysis_jointly)\n    if not analyze_data_list:\n      raise ValueError(\'Analyze data list must not be empty.\')\n\n    can_process_transform_jointly = not bool(per_set_stats_output_paths or\n                                             materialize_output_paths)\n    transform_data_list = self._MakeDatasetList(transform_data_paths,\n                                                transform_paths_file_formats,\n                                                raw_examples_data_format,\n                                                can_process_transform_jointly,\n                                                per_set_stats_output_paths,\n                                                materialize_output_paths)\n\n    if use_tfxio:\n      all_datasets = analyze_data_list + transform_data_list\n      for d in all_datasets:\n        d.tfxio = self._CreateTFXIO(d, input_dataset_metadata.schema)\n      self._AssertSameTFXIOSchema(all_datasets)\n      feature_spec_or_typespecs = (\n          all_datasets[0].tfxio.TensorAdapter().OriginalTypeSpecs())\n    else:\n      feature_spec_or_typespecs = schema_utils.schema_as_feature_spec(\n          _GetSchemaProto(input_dataset_metadata)).feature_spec\n\n      # NOTE: We disallow an empty schema, which we detect by testing the\n      # number of columns.  While in principal an empty schema is valid, in\n      # practice this is a sign of a user error, and this is a convenient\n      # place to catch that error.\n      if (not feature_spec_or_typespecs and\n          not self._ShouldDecodeAsRawExample(raw_examples_data_format)):\n        raise ValueError(messages.SCHEMA_EMPTY)\n\n    # Inspecting the preprocessing_fn even if we know we need a full pass in\n    # order to fail faster if it fails.\n    analyze_input_columns = tft.get_analyze_input_columns(\n        preprocessing_fn, feature_spec_or_typespecs)\n\n    if not compute_statistics and not materialize_output_paths:\n      if analyze_input_columns:\n        absl.logging.warning(\n            \'Not using the in-place Transform because the following features \'\n            \'require analyzing: {}\'.format(\n                tuple(c for c in analyze_input_columns)))\n      else:\n        absl.logging.warning(\n            \'Using the in-place Transform since compute_statistics=False, \'\n            \'it does not materialize transformed data, and the configured \'\n            \'preprocessing_fn appears to not require analyzing the data.\')\n        self._RunInPlaceImpl(preprocessing_fn, input_dataset_metadata,\n                             feature_spec_or_typespecs, transform_output_path)\n        # TODO(b/122478841): Writes status to status file.\n        return\n\n    materialization_format = (\n        transform_paths_file_formats[-1] if materialize_output_paths else None)\n    self._RunBeamImpl(use_tfxio, analyze_data_list, transform_data_list,\n                      preprocessing_fn, input_dataset_metadata,\n                      transform_output_path, raw_examples_data_format,\n                      temp_path, input_cache_dir, output_cache_dir,\n                      compute_statistics,\n                      per_set_stats_output_paths,\n                      materialization_format)\n  # TODO(b/122478841): Writes status to status file.\n\n  def _RunBeamImpl(self,\n                   use_tfxio: bool,\n                   analyze_data_list: List[_Dataset],\n                   transform_data_list: List[_Dataset],\n                   preprocessing_fn: Any,\n                   input_dataset_metadata: dataset_metadata.DatasetMetadata,\n                   transform_output_path: Text,\n                   raw_examples_data_format: Text,\n                   temp_path: Text,\n                   input_cache_dir: Optional[Text],\n                   output_cache_dir: Optional[Text],\n                   compute_statistics: bool,\n                   per_set_stats_output_paths: Sequence[Text],\n                   materialization_format: Optional[Text]) -> _Status:\n    """"""Perform data preprocessing with TFT.\n\n    Args:\n      use_tfxio: if True, use the TFXIO-based TFT APIs.\n      analyze_data_list: List of datasets for analysis.\n      transform_data_list: List of datasets for transform.\n      preprocessing_fn: The tf.Transform preprocessing_fn.\n      input_dataset_metadata: A DatasetMetadata object for the input data.\n      transform_output_path: An absolute path to write the output to.\n      raw_examples_data_format: A string describing the raw data format.\n      temp_path: A path to a temporary dir.\n      input_cache_dir: A dir containing the input analysis cache. May be None.\n      output_cache_dir: A dir to write the analysis cache to. May be None.\n      compute_statistics: A bool indicating whether or not compute statistics.\n      per_set_stats_output_paths: Paths to per-set statistics output. If empty,\n        per-set statistics is not produced.\n      materialization_format: A string describing the format of the materialized\n        data or None if materialization is not enabled.\n\n    Returns:\n      Status of the execution.\n    """"""\n    if use_tfxio:\n      self._AssertSameTFXIOSchema(analyze_data_list)\n      feature_spec_or_typespec = (\n          analyze_data_list[0].tfxio.TensorAdapter().OriginalTypeSpecs())\n    else:\n      feature_spec_or_typespec = schema_utils.schema_as_feature_spec(\n          _GetSchemaProto(input_dataset_metadata)).feature_spec\n\n    # TODO(zhuo): no need to convert the return values to list once TFT post\n    # 0.21.2 is released.\n    analyze_input_columns = list(tft.get_analyze_input_columns(\n        preprocessing_fn, feature_spec_or_typespec))\n    transform_input_columns = list(tft.get_transform_input_columns(\n        preprocessing_fn, feature_spec_or_typespec))\n    # Use the same dataset (same columns) for AnalyzeDataset and computing\n    # pre-transform stats so that the data will only be read once for these\n    # two operations.\n    if compute_statistics:\n      analyze_input_columns = list(\n          set(list(analyze_input_columns) + list(transform_input_columns)))\n\n    if use_tfxio:\n      for d in analyze_data_list:\n        d.tfxio = d.tfxio.Project(analyze_input_columns)\n      for d in transform_data_list:\n        d.tfxio = d.tfxio.Project(transform_input_columns)\n      analyze_data_tensor_adapter_config = (\n          analyze_data_list[0].tfxio.TensorAdapterConfig())\n    else:\n      if input_dataset_metadata.schema is _RAW_EXAMPLE_SCHEMA:\n        analyze_input_dataset_metadata = input_dataset_metadata\n        transform_input_dataset_metadata = input_dataset_metadata\n      else:\n        analyze_input_dataset_metadata = dataset_metadata.DatasetMetadata(\n            schema_utils.schema_from_feature_spec({\n                feature: feature_spec_or_typespec[feature]\n                for feature in analyze_input_columns\n            }))\n        transform_input_dataset_metadata = dataset_metadata.DatasetMetadata(\n            schema_utils.schema_from_feature_spec({\n                feature: feature_spec_or_typespec[feature]\n                for feature in transform_input_columns\n            }))\n\n    desired_batch_size = self._GetDesiredBatchSize(raw_examples_data_format)\n\n    # Build a kwargs dict instead of passing the keyword arguments directly\n    # to tft_beam.Context() because older TFT version doesn\'t not have the\n    # argument `use_tfxio`.\n    beam_context_kwargs = {\n        \'temp_dir\': temp_path,\n        \'desired_batch_size\': desired_batch_size,\n        \'passthrough_keys\': {_TRANSFORM_INTERNAL_FEATURE_FOR_KEY},\n        \'use_deep_copy_optimization\': True\n    }\n    if use_tfxio:\n      beam_context_kwargs[\'passthrough_keys\'] = self._GetTFXIOPassthroughKeys()  # pylint: disable=assignment-from-none\n      beam_context_kwargs[\'use_tfxio\'] = True\n\n    with self._CreatePipeline(transform_output_path) as pipeline:\n      with tft_beam.Context(**beam_context_kwargs):\n        # pylint: disable=expression-not-assigned\n        # pylint: disable=no-value-for-parameter\n        _ = (\n            pipeline\n            | \'IncrementColumnUsageCounter\'\n            >> self._IncrementColumnUsageCounter(\n                len(feature_spec_or_typespec), len(analyze_input_columns),\n                len(transform_input_columns)))\n\n        (new_analyze_data_dict, input_cache) = (\n            pipeline\n            | \'OptimizeRun\' >> self._OptimizeRun(\n                input_cache_dir, output_cache_dir, analyze_data_list,\n                feature_spec_or_typespec, preprocessing_fn,\n                self._GetCacheSource()))\n\n        if input_cache:\n          absl.logging.debug(\'Analyzing data with cache.\')\n\n        full_analyze_dataset_keys_list = [\n            dataset.dataset_key for dataset in analyze_data_list\n        ]\n\n        # Removing unneeded datasets if they won\'t be needed for statistics or\n        # materialization.\n        if materialization_format is None and not compute_statistics:\n          if None in new_analyze_data_dict.values():\n            absl.logging.debug(\n                \'Not reading the following datasets due to cache: %s\', [\n                    dataset.file_pattern\n                    for dataset in analyze_data_list\n                    if new_analyze_data_dict[dataset.dataset_key] is None\n                ])\n          analyze_data_list = [\n              d for d in new_analyze_data_dict.values() if d is not None\n          ]\n\n        for dataset in analyze_data_list:\n          infix = \'AnalysisIndex{}\'.format(dataset.index)\n          if use_tfxio:\n            dataset.standardized = (\n                pipeline\n                | \'TFXIOReadAndDecode[{}]\'.format(infix) >>\n                dataset.tfxio.BeamSource(desired_batch_size))\n          else:\n            dataset.serialized = (\n                pipeline\n                | \'ReadDataset[{}]\'.format(infix) >> self._ReadExamples(\n                    dataset, analyze_input_dataset_metadata))\n\n        if not use_tfxio:\n          analyze_decode_fn = (\n              self._GetDecodeFunction(raw_examples_data_format,\n                                      analyze_input_dataset_metadata.schema))\n\n        input_analysis_data = {}\n        for key, dataset in new_analyze_data_dict.items():\n          if dataset is None:\n            input_analysis_data[key] = None\n          else:\n            infix = \'AnalysisIndex{}\'.format(dataset.index)\n            if use_tfxio:\n              input_analysis_data[key] = dataset.standardized\n            else:\n              dataset.decoded = (\n                  dataset.serialized\n                  | \'Decode[{}]\'.format(infix) >>\n                  self._DecodeInputs(analyze_decode_fn))\n              input_analysis_data[key] = dataset.decoded\n\n        analyze_input_metadata = (\n            analyze_data_tensor_adapter_config\n            if use_tfxio else input_dataset_metadata)\n        if not hasattr(tft_beam.analyzer_cache, \'DatasetKey\'):\n          # TODO(b/148082271, b/148212028, b/37788560): Remove this when we stop\n          # supporting TFT 0.21.2.\n          flat_input_analysis_data = (\n              [\n                  dataset for dataset in input_analysis_data.values()\n                  if dataset is not None\n              ]\n              | \'FlattenAnalysisDatasetsBecauseItIsRequired\' >>\n              beam.Flatten(pipeline=pipeline))\n          analysis_inputs = (flat_input_analysis_data, input_analysis_data,\n                             input_cache, analyze_input_metadata)\n        else:\n          analysis_inputs = (input_analysis_data, input_cache,\n                             analyze_input_metadata)\n        transform_fn, cache_output = (\n            analysis_inputs\n            | \'Analyze\' >> tft_beam.AnalyzeDatasetWithCache(\n                preprocessing_fn, pipeline=pipeline))\n\n        # Write the raw/input metadata.\n        (input_dataset_metadata\n         | \'WriteMetadata\' >> tft_beam.WriteMetadata(\n             os.path.join(transform_output_path,\n                          tft.TFTransformOutput.RAW_METADATA_DIR), pipeline))\n\n        # WriteTransformFn writes transform_fn and metadata to subdirectories\n        # tensorflow_transform.SAVED_MODEL_DIR and\n        # tensorflow_transform.TRANSFORMED_METADATA_DIR respectively.\n        (transform_fn\n         | \'WriteTransformFn\'\n         >> tft_beam.WriteTransformFn(transform_output_path))\n\n        if output_cache_dir is not None and cache_output is not None:\n          tf.io.gfile.makedirs(output_cache_dir)\n          absl.logging.debug(\'Using existing cache in: %s\', input_cache_dir)\n          if input_cache_dir is not None:\n            # Only copy cache that is relevant to this iteration. This is\n            # assuming that this pipeline operates on rolling ranges, so those\n            # cache entries may also be relevant for future iterations.\n            for span_cache_dir in input_analysis_data:\n              # TODO(b/148082271, b/148212028, b/37788560): Remove this\n              # condition when we stop supporting TFT 0.21.2.\n              if isinstance(span_cache_dir, tuple):\n                span_cache_dir = span_cache_dir.key\n              full_span_cache_dir = os.path.join(input_cache_dir,\n                                                 span_cache_dir)\n              if tf.io.gfile.isdir(full_span_cache_dir):\n                self._CopyCache(full_span_cache_dir,\n                                os.path.join(output_cache_dir, span_cache_dir))\n\n          (cache_output\n           | \'WriteCache\' >> analyzer_cache.WriteAnalysisCacheToFS(\n               pipeline=pipeline,\n               cache_base_dir=output_cache_dir,\n               sink=self._GetCacheSink(),\n               dataset_keys=full_analyze_dataset_keys_list))\n\n        if compute_statistics or materialization_format is not None:\n          # Do not compute pre-transform stats if the input format is raw proto,\n          # as StatsGen would treat any input as tf.Example. Note that\n          # tf.SequenceExamples are wire-format compatible with tf.Examples.\n          if (compute_statistics and\n              not self._IsDataFormatProto(raw_examples_data_format)):\n            # Aggregated feature stats before transformation.\n            pre_transform_feature_stats_path = os.path.join(\n                transform_output_path,\n                tft.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH)\n\n            if self._IsDataFormatSequenceExample(raw_examples_data_format):\n              schema_proto = None\n            else:\n              schema_proto = _GetSchemaProto(\n                  input_dataset_metadata\n                  if use_tfxio else analyze_input_dataset_metadata)\n\n            if not use_tfxio:\n              for dataset in analyze_data_list:\n                infix = \'AnalysisIndex{}\'.format(dataset.index)\n                dataset.standardized = (\n                    dataset.serialized\n                    | \'ToArrowRecordBatches[{}]\'.format(infix)\n                    >> self._ToArrowRecordBatches(schema_proto))\n\n            if use_tfxio and self._IsDataFormatSequenceExample(\n                raw_examples_data_format):\n              def _ExtractRawExampleBatches(record_batch):\n                return record_batch.column(\n                    record_batch.schema.get_field_index(\n                        RAW_EXAMPLE_KEY)).flatten().to_pylist()\n              # Make use of the fact that tf.SequenceExample is wire-format\n              # compatible with tf.Example\n              stats_input = []\n              for dataset in analyze_data_list:\n                infix = \'AnalysisIndex{}\'.format(dataset.index)\n                stats_input.append(\n                    dataset.standardized\n                    | \'ExtractRawExampleBatches[{}]\'.format(infix) >> beam.Map(\n                        _ExtractRawExampleBatches)\n                    | \'DecodeSequenceExamplesAsExamplesIntoRecordBatches[{}]\'\n                    .format(infix) >> beam.ParDo(\n                        self._ToArrowRecordBatchesFn(schema_proto)))\n            else:\n              stats_input = [\n                  dataset.standardized for dataset in analyze_data_list]\n\n            pre_transform_stats_options = (\n                transform_stats_options.get_pre_transform_stats_options())\n            (stats_input\n             | \'FlattenAnalysisDatasets\' >> beam.Flatten(pipeline=pipeline)\n             | \'GenerateStats[FlattenedAnalysisDataset]\' >> self._GenerateStats(\n                 pre_transform_feature_stats_path,\n                 schema_proto,\n                 stats_options=pre_transform_stats_options))\n\n          # transform_data_list is a superset of analyze_data_list, we pay the\n          # cost to read the same dataset (analyze_data_list) again here to\n          # prevent certain beam runner from doing large temp materialization.\n          for dataset in transform_data_list:\n            infix = \'TransformIndex{}\'.format(dataset.index)\n            if use_tfxio:\n              dataset.standardized = (\n                  pipeline | \'TFXIOReadAndDecode[{}]\'.format(infix) >>\n                  dataset.tfxio.BeamSource(desired_batch_size))\n            else:\n              transform_decode_fn = (\n                  self._GetDecodeFunction(\n                      raw_examples_data_format,\n                      transform_input_dataset_metadata.schema))\n              dataset.serialized = (\n                  pipeline\n                  | \'ReadDataset[{}]\'.format(infix) >> self._ReadExamples(\n                      dataset, transform_input_dataset_metadata))\n              dataset.decoded = (\n                  dataset.serialized\n                  | \'Decode[{}]\'.format(infix)\n                  >> self._DecodeInputs(transform_decode_fn))\n            tft_transform_input_metadata = (\n                dataset.tfxio.TensorAdapterConfig() if use_tfxio else\n                transform_input_dataset_metadata)\n            data = dataset.standardized if use_tfxio else dataset.decoded\n            (dataset.transformed, metadata) = (\n                ((data, tft_transform_input_metadata), transform_fn)\n                | \'Transform[{}]\'.format(infix) >> tft_beam.TransformDataset())\n\n            dataset.transformed_and_serialized = (\n                dataset.transformed\n                | \'EncodeAndSerialize[{}]\'.format(infix)\n                >> beam.ParDo(self._EncodeAsSerializedExamples(),\n                              _GetSchemaProto(metadata)))\n\n          if compute_statistics:\n            # Aggregated feature stats after transformation.\n            _, metadata = transform_fn\n\n            # TODO(b/70392441): Retain tf.Metadata (e.g., IntDomain) in\n            # schema. Currently input dataset schema only contains dtypes,\n            # and other metadata is dropped due to roundtrip to tensors.\n            transformed_schema_proto = _GetSchemaProto(metadata)\n\n            for dataset in transform_data_list:\n              infix = \'TransformIndex{}\'.format(dataset.index)\n              dataset.transformed_and_standardized = (\n                  dataset.transformed_and_serialized\n                  | \'FromTransformedToArrowRecordBatches[{}]\'\n                  .format(infix)\n                  >> self._ToArrowRecordBatches(\n                      schema=transformed_schema_proto))\n\n            post_transform_feature_stats_path = os.path.join(\n                transform_output_path,\n                tft.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH)\n\n            post_transform_stats_options = (\n                transform_stats_options.get_post_transform_stats_options())\n            ([dataset.transformed_and_standardized\n              for dataset in transform_data_list]\n             | \'FlattenTransformedDatasets\' >> beam.Flatten()\n             | \'GenerateStats[FlattenedTransformedDatasets]\' >>\n             self._GenerateStats(\n                 post_transform_feature_stats_path,\n                 transformed_schema_proto,\n                 stats_options=post_transform_stats_options))\n\n            if per_set_stats_output_paths:\n              # TODO(b/130885503): Remove duplicate stats gen compute that is\n              # done both on a flattened view of the data, and on each span\n              # below.\n              for dataset in transform_data_list:\n                infix = \'TransformIndex{}\'.format(dataset.index)\n                (dataset.transformed_and_standardized\n                 | \'GenerateStats[{}]\'.format(infix) >> self._GenerateStats(\n                     dataset.stats_output_path,\n                     transformed_schema_proto,\n                     stats_options=post_transform_stats_options))\n\n          if materialization_format is not None:\n            for dataset in transform_data_list:\n              infix = \'TransformIndex{}\'.format(dataset.index)\n              (dataset.transformed_and_serialized\n               | \'Materialize[{}]\'.format(infix) >> self._WriteExamples(\n                   materialization_format,\n                   dataset.materialize_output_path))\n\n    return _Status.OK()\n\n  def _RunInPlaceImpl(\n      self, preprocessing_fn: Any,\n      metadata: dataset_metadata.DatasetMetadata,\n      feature_spec_or_typespecs: Dict[Text, Any],\n      transform_output_path: Text) -> _Status:\n    """"""Runs a transformation iteration in-place without looking at the data.\n\n    Args:\n      preprocessing_fn: The tf.Transform preprocessing_fn.\n      metadata: A DatasetMetadata object for the input data.\n      feature_spec_or_typespecs: a Dict[Text, Union[FeatureSpec, tf.TypeSpec]]\n      transform_output_path: An absolute path to write the output to.\n\n    Returns:\n      Status of the execution.\n    """"""\n\n    absl.logging.debug(\'Processing an in-place transform\')\n\n    raw_metadata_dir = os.path.join(transform_output_path,\n                                    tft.TFTransformOutput.RAW_METADATA_DIR)\n    metadata_io.write_metadata(metadata, raw_metadata_dir)\n\n    with tf.compat.v1.Graph().as_default() as graph:\n      with tf.compat.v1.Session(graph=graph) as sess:\n\n        input_signature = impl_helper.batched_placeholders_from_specs(\n            schema_utils.schema_as_feature_spec(\n                _GetSchemaProto(metadata)).feature_spec)\n\n        # In order to avoid a bug where import_graph_def fails when the\n        # input_map and return_elements of an imported graph are the same\n        # (b/34288791), we avoid using the placeholder of an input column as an\n        # output of a graph. We do this by applying tf.identity to all inputs of\n        # the preprocessing_fn.  Note this applies at the level of raw tensors.\n        # TODO(b/34288791): Remove this workaround and use a shallow copy of\n        # inputs instead.  A shallow copy is needed in case\n        # self._preprocessing_fn mutates its input.\n        copied_inputs = impl_helper.copy_tensors(input_signature)\n\n        output_signature = preprocessing_fn(copied_inputs)\n        sess.run(tf.compat.v1.global_variables_initializer())\n        sess.run(tf.compat.v1.tables_initializer())\n        transform_fn_path = os.path.join(transform_output_path,\n                                         tft.TFTransformOutput.TRANSFORM_FN_DIR)\n        saved_transform_io.write_saved_transform_from_session(\n            sess, input_signature, output_signature, transform_fn_path)\n\n        transformed_metadata = dataset_metadata.DatasetMetadata(\n            schema=tft.schema_inference.infer_feature_schema(\n                output_signature, graph, sess))\n\n    transformed_metadata_dir = os.path.join(\n        transform_output_path, tft.TFTransformOutput.TRANSFORMED_METADATA_DIR)\n    metadata_io.write_metadata(transformed_metadata, transformed_metadata_dir)\n\n    return _Status.OK()\n\n  def _CreatePipeline(\n      self, unused_transform_output_path: Text) -> beam.Pipeline:\n    """"""Creates beam pipeline.\n\n    Args:\n      unused_transform_output_path: unused.\n\n    Returns:\n      Beam pipeline.\n    """"""\n    return self._make_beam_pipeline()\n\n  # TODO(b/114444977): Remove the unused can_process_jointly argument.\n  def _MakeDatasetList(\n      self,\n      file_patterns: Sequence[Union[Text, int]],\n      file_formats: Sequence[Union[Text, int]],\n      data_format: Text,\n      can_process_jointly: bool,\n      stats_output_paths: Optional[Sequence[Text]] = None,\n      materialize_output_paths: Optional[Sequence[Text]] = None\n  ) -> List[_Dataset]:\n    """"""Makes a list of Dataset from the given `file_patterns`.\n\n    Args:\n      file_patterns: A list of file patterns where each pattern corresponds to\n        one `_Dataset`.\n      file_formats: A list of file format where each format corresponds to one\n        `_Dataset`. Must have the same size as `file_patterns`.\n      data_format: The data format of the datasets.\n      can_process_jointly: Whether paths can be processed jointly, unused.\n      stats_output_paths: The statistics output paths, if applicable.\n      materialize_output_paths: The materialization output paths, if applicable.\n\n    Returns:\n      A list of `_Dataset` sorted by their dataset_key property.\n    """"""\n    assert len(file_patterns) == len(file_formats)\n    if stats_output_paths:\n      assert len(file_patterns) == len(stats_output_paths)\n    else:\n      stats_output_paths = [None] * len(file_patterns)\n    if materialize_output_paths:\n      assert len(file_patterns) == len(materialize_output_paths)\n    else:\n      materialize_output_paths = [None] * len(file_patterns)\n\n    datasets = [\n        _Dataset(p, f, data_format, s, m)\n        for p, f, s, m in zip(file_patterns, file_formats, stats_output_paths,\n                              materialize_output_paths)\n    ]\n    result = sorted(datasets, key=lambda dataset: dataset.dataset_key)\n    for index, dataset in enumerate(result):\n      dataset.index = index\n    return result\n\n  def _ShouldDecodeAsRawExample(self, data_format: Union[Text, int]) -> bool:\n    """"""Returns true if data format should be decoded as raw example.\n\n    Args:\n      data_format: name of data format.\n\n    Returns:\n      True if data format should be decoded as raw example.\n    """"""\n    return (self._IsDataFormatSequenceExample(data_format) or\n            self._IsDataFormatProto(data_format))\n\n  @staticmethod\n  def _IsDataFormatSequenceExample(data_format: Union[Text, int]) -> bool:\n    """"""Returns true if data format is sequence example.\n\n    Args:\n      data_format: name of data format.\n\n    Returns:\n      True if data format is sequence example.\n    """"""\n    assert not isinstance(data_format, int), data_format\n    return data_format == labels.FORMAT_TF_SEQUENCE_EXAMPLE\n\n  @staticmethod\n  def _IsDataFormatProto(data_format: Union[Text, int]) -> bool:\n    """"""Returns true if data format is protocol buffer.\n\n    Args:\n      data_format: name of data format.\n\n    Returns:\n      True if data format is protocol buffer.\n    """"""\n    assert not isinstance(data_format, int), data_format\n    return data_format == labels.FORMAT_PROTO\n\n  def _GetDesiredBatchSize(\n      self, data_format: Union[Text, int]) -> Optional[int]:\n    """"""Returns batch size.\n\n    Args:\n      data_format: name of data format.\n\n    Returns:\n      Batch size or None.\n    """"""\n    if self._IsDataFormatSequenceExample(data_format):\n      return 1\n    return None\n\n  def _GetDecodeFunction(self, data_format: Union[Text, int],\n                         schema: dataset_schema.Schema) -> Any:\n    """"""Returns the decode function for `data_format`.\n\n    Args:\n      data_format: name of data format.\n      schema: a dataset_schema.Schema for the data.\n\n    Returns:\n      Function for decoding examples.\n    """"""\n    if self._ShouldDecodeAsRawExample(data_format):\n      if self._IsDataFormatSequenceExample(data_format):\n        absl.logging.warning(\n            \'TFX Transform doesn\\\'t officially support tf.SequenceExample, \'\n            \'follow b/38235367 to track official support progress. We do not \'\n            \'guarantee not to break your pipeline if you use Transform with a \'\n            \'tf.SequenceExample data type. Use at your own risk.\')\n      return lambda x: {RAW_EXAMPLE_KEY: x}\n    else:\n      return tft.coders.ExampleProtoCoder(schema, serialized=True).decode\n\n  @staticmethod\n  def _GetCacheSource():\n    return None\n\n  @staticmethod\n  def _GetCacheSink():\n    return None\n\n  @staticmethod\n  def _CopyCache(src, dst):\n    # TODO(b/37788560): Make this more efficient.\n    io_utils.copy_dir(src, dst)\n\n  def _CreateTFXIO(self, dataset: _Dataset,\n                   schema: schema_pb2.Schema) -> tfxio.TFXIO:\n    """"""Creates a TFXIO instance for `dataset`.""""""\n    if self._ShouldDecodeAsRawExample(dataset.data_format):\n      return raw_tf_record.RawTfRecordTFXIO(\n          file_pattern=dataset.file_pattern,\n          raw_record_column_name=RAW_EXAMPLE_KEY,\n          telemetry_descriptors=[_TRANSFORM_COMPONENT_DESCRIPTOR])\n    else:\n      return tf_example_record.TFExampleRecord(\n          file_pattern=dataset.file_pattern,\n          validate=False,\n          telemetry_descriptors=[_TRANSFORM_COMPONENT_DESCRIPTOR],\n          schema=schema)\n\n  def _AssertSameTFXIOSchema(self, datasets: Sequence[_Dataset]) -> None:\n    if not datasets:\n      return\n    for dataset in datasets[1:]:\n      assert (datasets[0].tfxio.ArrowSchema().equals(\n          dataset.tfxio.ArrowSchema()))\n\n  @staticmethod\n  def _GetTFXIOPassthroughKeys() -> Optional[Set[Text]]:\n    """"""Always returns None.""""""\n    return None\n'"
tfx/components/transform/executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.transform.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom tensorflow_transform.beam import tft_unit\nfrom tfx import types\nfrom tfx.components.testdata.module_file import transform_module\nfrom tfx.components.transform import executor\nfrom tfx.components.transform import labels\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass _TempPath(types.Artifact):\n  TYPE_NAME = \'TempPath\'\n\n\nclass ExecutorForTesting(executor.Executor):\n\n  def __init__(self, use_tfxio):\n    super(ExecutorForTesting, self).__init__()\n    self._use_tfxio = use_tfxio\n\n  def Transform(self, inputs, outputs, status_file):\n    inputs[labels.USE_TFXIO_LABEL] = self._use_tfxio\n    super(ExecutorForTesting, self).Transform(inputs, outputs, status_file)\n\n\n# TODO(b/122478841): Add more detailed tests.\nclass ExecutorTest(tft_unit.TransformTestCase):\n\n  # executor_with_tfxio_test.py overrides this to True.\n  def _use_tfxio(self):\n    return False\n\n  def _get_source_data_dir(self):\n    return os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n  def _get_output_data_dir(self, sub_dir=None):\n    test_dir = self._testMethodName\n    if sub_dir is not None:\n      test_dir = os.path.join(test_dir, sub_dir)\n    return os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        test_dir)\n\n  def _make_base_do_params(self, source_data_dir, output_data_dir):\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(source_data_dir, \'csv_example_gen\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    schema_artifact = standard_artifacts.Schema()\n    schema_artifact.uri = os.path.join(source_data_dir, \'schema_gen\')\n\n    self._input_dict = {\n        executor.EXAMPLES_KEY: [examples],\n        executor.SCHEMA_KEY: [schema_artifact],\n    }\n\n    # Create output dict.\n    self._transformed_output = standard_artifacts.TransformGraph()\n    self._transformed_output.uri = os.path.join(output_data_dir,\n                                                \'transformed_graph\')\n    self._transformed_examples = standard_artifacts.Examples()\n    self._transformed_examples.uri = output_data_dir\n    self._transformed_examples.split_names = artifact_utils.encode_split_names(\n        [\'train\', \'eval\'])\n    temp_path_output = _TempPath()\n    temp_path_output.uri = tempfile.mkdtemp()\n\n    self._output_dict = {\n        executor.TRANSFORM_GRAPH_KEY: [self._transformed_output],\n        executor.TRANSFORMED_EXAMPLES_KEY: [self._transformed_examples],\n        executor.TEMP_PATH_KEY: [temp_path_output],\n    }\n\n    # Create exec properties skeleton.\n    self._exec_properties = {}\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n\n    self._source_data_dir = self._get_source_data_dir()\n    self._output_data_dir = self._get_output_data_dir()\n\n    self._make_base_do_params(self._source_data_dir, self._output_data_dir)\n\n    # Create exec properties skeleton.\n    self._module_file = os.path.join(self._source_data_dir,\n                                     \'module_file/transform_module.py\')\n    self._preprocessing_fn = \'%s.%s\' % (\n        transform_module.preprocessing_fn.__module__,\n        transform_module.preprocessing_fn.__name__)\n\n    # Executor for test.\n    self._transform_executor = ExecutorForTesting(self._use_tfxio())\n\n  def _verify_transform_outputs(self):\n    self.assertNotEqual(\n        0,\n        len(\n            tf.io.gfile.listdir(\n                os.path.join(self._transformed_examples.uri, \'train\'))))\n    self.assertNotEqual(\n        0,\n        len(\n            tf.io.gfile.listdir(\n                os.path.join(self._transformed_examples.uri, \'eval\'))))\n    path_to_saved_model = os.path.join(\n        self._transformed_output.uri, tft.TFTransformOutput.TRANSFORM_FN_DIR,\n        tf.saved_model.SAVED_MODEL_FILENAME_PB)\n    self.assertTrue(tf.io.gfile.exists(path_to_saved_model))\n\n  # TODO(b/143355786): Remove _makeTestPipeline once TFX depends on TFT 0.16 and\n  # use self._makeTestPipeline instead.\n  def _makeTestPipeline(self):\n\n    class _TestPipeline(tft_unit.beam.Pipeline):\n      """"""Test pipeline class that retains pipeline metrics.""""""\n\n      @property\n      def metrics(self):\n        return self._run_result.metrics()\n\n      def __exit__(self, exc_type, exc_val, exc_tb):\n        if not exc_type:\n          self._run_result = self.run()\n          self._run_result.wait_until_finish()\n\n    return _TestPipeline(\n        **tft_unit.test_helpers.make_test_beam_pipeline_kwargs())\n\n  # TODO(b/143355786): Remove _assertMetricsCounterEqual once TFX depends on TFT\n  # 0.16 and use self.assertMetricsCounterEqual instead.\n  def _assertMetricsCounterEqual(self, metrics, name, expected_count):\n    metric = metrics.query(\n        tft_unit.beam.metrics.metric.MetricsFilter().with_name(\n            name))[\'counters\']\n    committed = sum([r.committed for r in metric])\n    attempted = sum([r.attempted for r in metric])\n    self.assertEqual(committed, attempted)\n    self.assertEqual(committed, expected_count)\n\n  def _runPipelineGetMetrics(self, inputs, outputs, exec_properties):\n    pipelines = []\n\n    def _create_pipeline_wrapper(*_):\n      result = self._makeTestPipeline()\n      pipelines.append(result)\n      return result\n\n    with tft_unit.mock.patch.object(\n        ExecutorForTesting,\n        \'_CreatePipeline\',\n        autospec=True,\n        side_effect=_create_pipeline_wrapper):\n      transform_executor = ExecutorForTesting(self._use_tfxio())\n      transform_executor.Do(self._input_dict, self._output_dict,\n                            self._exec_properties)\n    assert len(pipelines) == 1\n    return pipelines[0].metrics\n\n  def testDoWithModuleFile(self):\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._transform_executor.Do(self._input_dict, self._output_dict,\n                                self._exec_properties)\n    self._verify_transform_outputs()\n\n  def testDoWithPreprocessingFn(self):\n    self._exec_properties[\'preprocessing_fn\'] = self._preprocessing_fn\n    self._transform_executor.Do(self._input_dict, self._output_dict,\n                                self._exec_properties)\n    self._verify_transform_outputs()\n\n  def testDoWithNoPreprocessingFn(self):\n    with self.assertRaises(ValueError):\n      self._transform_executor.Do(self._input_dict, self._output_dict,\n                                  self._exec_properties)\n\n  def testDoWithDuplicatePreprocessingFn(self):\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._exec_properties[\'preprocessing_fn\'] = self._preprocessing_fn\n    with self.assertRaises(ValueError):\n      self._transform_executor.Do(self._input_dict, self._output_dict,\n                                  self._exec_properties)\n\n  def testCounters(self):\n    self._exec_properties[\'preprocessing_fn\'] = self._preprocessing_fn\n    metrics = self._runPipelineGetMetrics(self._input_dict, self._output_dict,\n                                          self._exec_properties)\n\n    # The test data has 10036 instances in the train dataset, and 4964 instances\n    # in the eval dataset (obtained by running:\n    #   gqui third_party/tfx/components/testdata/csv_example_gen/train/data* \\\n    #     \'select count(*)\'\n    # )\n    # Since the analysis dataset (train) is read twice (once for analysis and\n    # once for transform), the expected value of the num_instances counter is:\n    # 10036 * 2 + 4964 = 25036.\n    self._assertMetricsCounterEqual(metrics, \'num_instances\', 24909)\n\n    # We expect 2 saved_models to be created because this is a 1 phase analysis\n    # preprocessing_fn.\n    self._assertMetricsCounterEqual(metrics, \'saved_models_created\', 2)\n\n    # This should be the size of the preprocessing_fn\'s inputs dictionary which\n    # is 18 according to the schema.\n    self._assertMetricsCounterEqual(metrics, \'total_columns_count\', 18)\n\n    # There are 9 features that are passed into tft analyzers in the\n    # preprocessing_fn.\n    self._assertMetricsCounterEqual(metrics, \'analyze_columns_count\', 9)\n\n    # In addition, 7 features go through a pure TF map, not including the label,\n    # so we expect 9 + 7 + 1 = 17 transform columns.\n    self._assertMetricsCounterEqual(metrics, \'transform_columns_count\', 17)\n\n  def testDoWithCache(self):\n\n    class InputCache(types.Artifact):\n      TYPE_NAME = \'InputCache\'\n\n    class OutputCache(types.Artifact):\n      TYPE_NAME = \'OutputCache\'\n\n    # First run that creates cache.\n    output_cache_artifact = OutputCache()\n    output_cache_artifact.uri = os.path.join(self._output_data_dir, \'CACHE\')\n\n    self._output_dict[\'cache_output_path\'] = [output_cache_artifact]\n\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._transform_executor.Do(self._input_dict, self._output_dict,\n                                self._exec_properties)\n    self._verify_transform_outputs()\n    self.assertNotEqual(0,\n                        len(tf.io.gfile.listdir(output_cache_artifact.uri)))\n\n    # Second run from cache.\n    self._output_data_dir = self._get_output_data_dir(\'2nd_run\')\n    input_cache_artifact = InputCache()\n    input_cache_artifact.uri = output_cache_artifact.uri\n\n    output_cache_artifact = OutputCache()\n    output_cache_artifact.uri = os.path.join(self._output_data_dir, \'CACHE\')\n\n    self._make_base_do_params(self._source_data_dir, self._output_data_dir)\n\n    self._input_dict[\'cache_input_path\'] = [input_cache_artifact]\n    self._output_dict[\'cache_output_path\'] = [output_cache_artifact]\n\n    self._exec_properties[\'module_file\'] = self._module_file\n    self._transform_executor.Do(self._input_dict, self._output_dict,\n                                self._exec_properties)\n\n    self._verify_transform_outputs()\n    self.assertNotEqual(0,\n                        len(tf.io.gfile.listdir(output_cache_artifact.uri)))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/transform/executor_with_tfxio_test.py,1,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.transform.executor.\n\nWith the TFXIO code path being exercised.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\n\nfrom tfx.components.transform import executor_test\n\n\nclass ExecutorWithTFXIOTest(executor_test.ExecutorTest):\n\n  def _use_tfxio(self):\n    return True\n\n  def _get_source_data_dir(self):\n    return os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/transform/labels.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Labels recognized by the transform executor.""""""\n\n# Input labels.\nEXAMPLES_DATA_FORMAT_LABEL = \'examples_data_format\'\nSCHEMA_PATH_LABEL = \'schema_path\'\nANALYZE_DATA_PATHS_LABEL = \'analyze_data_paths\'\nANALYZE_PATHS_FILE_FORMATS_LABEL = \'analyze_paths_file_formats\'\nTRANSFORM_DATA_PATHS_LABEL = \'transform_data_paths\'\nTRANSFORM_PATHS_FILE_FORMATS_LABEL = \'transform_paths_file_formats\'\nCOMPUTE_STATISTICS_LABEL = \'compute_statistics\'\nMODULE_FILE = \'module_file\'\nPREPROCESSING_FN = \'preprocessing_fn\'\nBEAM_PIPELINE_ARGS = \'pipeline_args\'\n# This label is currently not used externally.\nEXAMPLES_METADATA_LABEL = \'examples_metadata\'\nCACHE_INPUT_PATH_LABEL = \'cache_input_path\'\nUSE_TFXIO_LABEL = \'use_tfxio\'\n\n# Output labels.\n# TODO(b/72214804): Ideally per-set stats and materialization output paths\n# should be output labels, but they require multiple values. Change this if/when\n# we can add multiple outputs to a single processor label.\nPER_SET_STATS_OUTPUT_PATHS_LABEL = \'per_set_stats_output_paths\'\nTRANSFORM_MATERIALIZE_OUTPUT_PATHS_LABEL = (\n    \'transform_materialize_output_paths\')\nTRANSFORM_METADATA_OUTPUT_PATH_LABEL = \'transform_output_path\'\nCACHE_OUTPUT_PATH_LABEL = \'cache_output_path\'\nTEMP_OUTPUT_LABEL = \'temp_path\'\n\n# Examples File Format\nFORMAT_TFRECORD = \'FORMAT_TFRECORD\'\n\n# Examples Data Format\n# Indicates that the data format is tf.Example.\nFORMAT_TF_EXAMPLE = \'FORMAT_TF_EXAMPLE\'\n# Indicates that the data format is tf.SequenceExample.\nFORMAT_TF_SEQUENCE_EXAMPLE = \'FORMAT_TF_SEQUENCE_EXAMPLE\'\n# Indicates the data format is a custom proto.\nFORMAT_PROTO = \'FORMAT_PROTO\'\n'"
tfx/components/transform/messages.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Messages used in transform executor.""""""\n\nSCHEMA_EMPTY = (\'Schema was empty.  The Transform component requires a full \'\n                \'schema to be provided as an external config.\')\n'"
tfx/components/transform/run_executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Invoke transform executor for data transformation.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport absl\n# pylint: disable=g-direct-tensorflow-import\nfrom tensorflow.python.platform import app\n# pylint: enable=g-direct-tensorflow-import\nfrom tfx.components.transform import labels\nfrom tfx.components.transform.executor import Executor\n\n\ndef _run_transform(args, beam_pipeline_args):\n  """"""Construct and run transform executor.""""""\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  inputs = {\n      labels.ANALYZE_DATA_PATHS_LABEL:\n          args.analyze_examples,\n      labels.ANALYZE_PATHS_FILE_FORMATS_LABEL: [labels.FORMAT_TFRECORD] *\n                                               len(args.analyze_examples),\n      labels.TRANSFORM_DATA_PATHS_LABEL: [\n          args.analyze_examples + args.transform_only_examples\n      ],\n      labels.TRANSFORM_PATHS_FILE_FORMATS_LABEL:\n          [labels.FORMAT_TFRECORD] *\n          (len(args.analyze_examples) + len(args.transform_only_examples)),\n      labels.SCHEMA_PATH_LABEL:\n          args.input_schema_path,\n      labels.PREPROCESSING_FN:\n          args.preprocessing_fn_path,\n      labels.EXAMPLES_DATA_FORMAT_LABEL:\n          args.example_data_format,\n      labels.COMPUTE_STATISTICS_LABEL:\n          args.compute_statistics,\n      labels.BEAM_PIPELINE_ARGS:\n          beam_pipeline_args,\n  }\n  outputs = {\n      labels.TRANSFORM_METADATA_OUTPUT_PATH_LABEL: args.transform_fn,\n      labels.TRANSFORM_MATERIALIZE_OUTPUT_PATHS_LABEL: (\n          args.transformed_examples),\n      labels.PER_SET_STATS_OUTPUT_PATHS_LABEL: (args.per_set_stats_outputs),\n      labels.TEMP_OUTPUT_LABEL: args.tmp_location,\n  }\n  executor = Executor(Executor.Context(beam_pipeline_args=beam_pipeline_args))\n  executor.Transform(inputs, outputs, args.status_file)\n\n\ndef main(argv):\n  parser = argparse.ArgumentParser()\n  # Arguments in inputs\n  parser.add_argument(\n      \'--input_schema_path\',\n      type=str,\n      required=True,\n      help=\'Path to input schema\')\n  parser.add_argument(\n      \'--preprocessing_fn_path\',\n      type=str,\n      default=\'\',\n      required=True,\n      help=\'Path to a preprocessing_fn module\')\n  parser.add_argument(\n      \'--use_tfdv\',\n      type=bool,\n      default=True,\n      help=\'Deprecated and ignored. DO NOT SET.\')\n  parser.add_argument(\n      \'--compute_statistics\',\n      type=bool,\n      default=False,\n      help=\'Whether computes statistics\')\n  parser.add_argument(\n      \'--analyze_examples\',\n      nargs=\'+\',\n      default=\'\',\n      type=str,\n      help=\'A space-separated list of paths to examples to be analyzed \'\n      \'and transformed\')\n  parser.add_argument(\n      \'--transform_only_examples\',\n      nargs=\'+\',\n      default=\'\',\n      type=str,\n      help=\'A space-separated list of paths to examples to be transformed only\')\n  parser.add_argument(\n      \'--example_data_format\',\n      type=str,\n      default=labels.FORMAT_TF_EXAMPLE,\n      help=\'Example data format\')\n  # Arguments in outputs\n  parser.add_argument(\n      \'--transform_fn\',\n      type=str,\n      required=True,\n      help=\'Path that TFTransformOutput will write to\')\n  parser.add_argument(\n      \'--tmp_location\',\n      type=str,\n      required=True,\n      help=\'Path to write temporary files. Executor does not own this \'\n      \'directory. User or caller is responsible for cleanup\')\n  parser.add_argument(\n      \'--transformed_examples\',\n      nargs=\'+\',\n      type=str,\n      default=[],\n      help=\'A space-separated list of paths to write transformed examples\')\n  parser.add_argument(\n      \'--per_set_stats_outputs\',\n      nargs=\'+\',\n      type=str,\n      default=[],\n      help=\'Paths to statistics output\')\n  parser.add_argument(\n      \'--status_file\', type=str, default=\'\', help=\'Path to write status\')\n  args, beam_args = parser.parse_known_args(argv)\n  _run_transform(args, beam_args)\n\n\nif __name__ == \'__main__\':\n  app.run(main=main)\n'"
tfx/components/transform/stats_options.py,0,"b'# Lint as: python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Stats Options for customizing TFDV in TFT.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow_data_validation as tfdv\n\n\n# An instance of `tfdv.StatsOptions()` used when computing pre-transform\n# statistics. If not specified, default options are used.\n_PRE_TRANSFORM_STATS_OPTIONS = None\n\n# An instance of `tfdv.StatsOptions()` used when computing post-transform\n# statistics. If not specified, default options are used.\n_POST_TRANSFORM_STATS_OPTIONS = None\n\n\ndef set_pre_transform_stats_options(stats_options: tfdv.StatsOptions):\n  global _PRE_TRANSFORM_STATS_OPTIONS\n  _PRE_TRANSFORM_STATS_OPTIONS = stats_options\n\n\ndef set_post_transform_stats_options(stats_options: tfdv.StatsOptions):\n  global _POST_TRANSFORM_STATS_OPTIONS\n  _POST_TRANSFORM_STATS_OPTIONS = stats_options\n\n\ndef get_pre_transform_stats_options() -> tfdv.StatsOptions:\n  return (tfdv.StatsOptions() if _PRE_TRANSFORM_STATS_OPTIONS is None\n          else _PRE_TRANSFORM_STATS_OPTIONS)\n\n\ndef get_post_transform_stats_options() -> tfdv.StatsOptions:\n  return (tfdv.StatsOptions() if _POST_TRANSFORM_STATS_OPTIONS is None\n          else _POST_TRANSFORM_STATS_OPTIONS)\n'"
tfx/components/tuner/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/tuner/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Tuner component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, NamedTuple\nfrom kerastuner.engine import base_tuner\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.components.tuner import executor\nfrom tfx.proto import trainer_pb2\nfrom tfx.proto import tuner_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_component_specs import TunerSpec\n\n# tuner: A BaseTuner that will be used for tuning.\n# fit_kwargs: Args to pass to tuner\'s run_trial function for fitting the\n#             model , e.g., the training and validation dataset. Required\n#             args depend on the tuner\'s implementation.\nTunerFnResult = NamedTuple(\'TunerFnResult\', [(\'tuner\', base_tuner.BaseTuner),\n                                             (\'fit_kwargs\', Dict[Text, Any])])\nTunerFnResult.__doc__ = """"""\ntuner_fn returns a TunerFnResult that contains:\n- tuner: A BaseTuner that will be used for tuning.\n- fit_kwargs: Args to pass to tuner\'s run_trial function for fitting the\n              model , e.g., the training and validation dataset. Required\n              args depend on the tuner\'s implementation.\n""""""\n\n\nclass Tuner(base_component.BaseComponent):\n  """"""A TFX component for model hyperparameter tuning.""""""\n\n  SPEC_CLASS = TunerSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               examples: types.Channel = None,\n               schema: Optional[types.Channel] = None,\n               transform_graph: Optional[types.Channel] = None,\n               module_file: Optional[Text] = None,\n               tuner_fn: Optional[Text] = None,\n               train_args: trainer_pb2.TrainArgs = None,\n               eval_args: trainer_pb2.EvalArgs = None,\n               tune_args: Optional[tuner_pb2.TuneArgs] = None,\n               best_hyperparameters: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct a Tuner component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, serving as the\n        source of examples that are used in tuning (required).\n      schema:  An optional Channel of type `standard_artifacts.Schema`, serving\n        as the schema of training and eval data. This is used when raw examples\n        are provided.\n      transform_graph: An optional Channel of type\n        `standard_artifacts.TransformGraph`, serving as the input transform\n        graph if present. This is used when transformed examples are provided.\n      module_file: A path to python module file containing UDF tuner definition.\n        The module_file must implement a function named `tuner_fn` at its top\n        level. The function must have the following signature.\n            def tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n        Exactly one of \'module_file\' or \'tuner_fn\' must be supplied.\n      tuner_fn:  A python path to UDF model definition function. See\n        \'module_file\' for the required signature of the UDF. Exactly one of\n        \'module_file\' or \'tuner_fn\' must be supplied.\n      train_args: A trainer_pb2.TrainArgs instance, containing args used for\n        training. Current only num_steps is available.\n      eval_args: A trainer_pb2.EvalArgs instance, containing args used for eval.\n        Current only num_steps is available.\n      tune_args: A tuner_pb2.TuneArgs instance, containing args used for tuning.\n        Current only num_parallel_trials is available.\n      best_hyperparameters: Optional Channel of type\n        `standard_artifacts.HyperParameters` for result of the best hparams.\n      instance_name: Optional unique instance name. Necessary if multiple Tuner\n        components are declared in the same pipeline.\n    """"""\n    if bool(module_file) == bool(tuner_fn):\n      raise ValueError(\n          ""Exactly one of \'module_file\' or \'tuner_fn\' must be supplied"")\n\n    best_hyperparameters = best_hyperparameters or types.Channel(\n        type=standard_artifacts.HyperParameters,\n        artifacts=[standard_artifacts.HyperParameters()])\n    spec = TunerSpec(\n        examples=examples,\n        schema=schema,\n        transform_graph=transform_graph,\n        module_file=module_file,\n        tuner_fn=tuner_fn,\n        train_args=train_args,\n        eval_args=eval_args,\n        tune_args=tune_args,\n        best_hyperparameters=best_hyperparameters)\n    super(Tuner, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/components/tuner/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.tuner.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.tuner import component\nfrom tfx.proto import trainer_pb2\nfrom tfx.proto import tuner_pb2\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass TunerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TunerTest, self).setUp()\n    self.examples = channel_utils.as_channel([standard_artifacts.Examples()])\n    self.schema = channel_utils.as_channel([standard_artifacts.Schema()])\n    self.transform_graph = channel_utils.as_channel(\n        [standard_artifacts.TransformGraph()])\n    self.train_args = trainer_pb2.TrainArgs(num_steps=100)\n    self.eval_args = trainer_pb2.EvalArgs(num_steps=50)\n    self.tune_args = tuner_pb2.TuneArgs(num_parallel_trials=3)\n\n  def _verify_output(self, tuner):\n    self.assertEqual(standard_artifacts.HyperParameters.TYPE_NAME,\n                     tuner.outputs[\'best_hyperparameters\'].type_name)\n\n  def testConstructWithModuleFile(self):\n    tuner = component.Tuner(\n        examples=self.examples,\n        schema=self.schema,\n        train_args=self.train_args,\n        eval_args=self.eval_args,\n        tune_args=self.tune_args,\n        module_file=\'/path/to/module/file\')\n    self._verify_output(tuner)\n\n  def testConstructWithTunerFn(self):\n    tuner = component.Tuner(\n        examples=self.examples,\n        transform_graph=self.transform_graph,\n        train_args=self.train_args,\n        eval_args=self.eval_args,\n        tuner_fn=\'path.to.tuner_fn\')\n    self._verify_output(tuner)\n\n  def testConstructDuplicateUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Tuner(\n          examples=self.examples,\n          schema=self.schema,\n          train_args=self.train_args,\n          eval_args=self.eval_args,\n          module_file=\'/path/to/module/file\',\n          tuner_fn=\'path.to.tuner_fn\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/tuner/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX tuner executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, List, Text\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.trainer import fn_args_utils\nfrom tfx.components.util import udf_utils\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n# Key for best hyperparameters in executor output_dict.\n_BEST_HYPERPARAMETERS_KEY = \'best_hyperparameters\'\n# Key for tune args in executor exec_properties.\n_TUNE_ARGS_KEY = \'tune_args\'\n# Default file name for generated best hyperparameters file.\n_DEFAULT_FILE_NAME = \'best_hyperparameters.txt\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TFX Tuner component executor.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    if exec_properties.get(_TUNE_ARGS_KEY):\n      raise ValueError(\n          ""TuneArgs is not supported for default Tuner\'s Executor."")\n\n    tuner_fn = udf_utils.get_fn(exec_properties, \'tuner_fn\')\n    fn_args = fn_args_utils.get_common_fn_args(input_dict, exec_properties,\n                                               self._get_tmp_dir())\n\n    tuner_fn_result = tuner_fn(fn_args)\n    tuner = tuner_fn_result.tuner\n    fit_kwargs = tuner_fn_result.fit_kwargs\n\n    # TODO(b/156966497): set logger for printing.\n    tuner.search_space_summary()\n    absl.logging.info(\'Start tuning...\')\n    tuner.search(**fit_kwargs)\n    tuner.results_summary()\n    best_hparams_config = tuner.get_best_hyperparameters()[0].get_config()\n    absl.logging.info(\'Best hyperParameters: %s\' % best_hparams_config)\n    best_hparams_path = os.path.join(\n        artifact_utils.get_single_uri(output_dict[_BEST_HYPERPARAMETERS_KEY]),\n        _DEFAULT_FILE_NAME)\n    io_utils.write_string_file(best_hparams_path,\n                               json.dumps(best_hparams_config))\n    absl.logging.info(\'Best Hyperparameters are written to %s.\' %\n                      best_hparams_path)\n'"
tfx/components/tuner/executor_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.tuner.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom kerastuner import HyperParameters\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.components.testdata.module_file import tuner_module\nfrom tfx.components.tuner import executor\nfrom tfx.proto import trainer_pb2\nfrom tfx.proto import tuner_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._testdata_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._context = executor.Executor.Context(\n        tmp_dir=self._output_data_dir, unique_id=\'1\')\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(self._testdata_dir, \'iris\', \'data\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(self._testdata_dir, \'iris\', \'schema\')\n\n    self._input_dict = {\n        \'examples\': [examples],\n        \'schema\': [schema],\n    }\n\n    # Create output dict.\n    self._best_hparams = standard_artifacts.Model()\n    self._best_hparams.uri = os.path.join(self._output_data_dir, \'best_hparams\')\n\n    self._output_dict = {\n        \'best_hyperparameters\': [self._best_hparams],\n    }\n\n    # Create exec properties.\n    self._exec_properties = {\n        \'train_args\':\n            json_format.MessageToJson(\n                trainer_pb2.TrainArgs(num_steps=100),\n                preserving_proto_field_name=True),\n        \'eval_args\':\n            json_format.MessageToJson(\n                trainer_pb2.EvalArgs(num_steps=50),\n                preserving_proto_field_name=True),\n    }\n\n  def _verify_output(self):\n    # Test best hparams.\n    best_hparams_path = os.path.join(self._best_hparams.uri,\n                                     \'best_hyperparameters.txt\')\n    self.assertTrue(tf.io.gfile.exists(best_hparams_path))\n    best_hparams_config = json.loads(\n        file_io.read_file_to_string(best_hparams_path))\n    best_hparams = HyperParameters.from_config(best_hparams_config)\n    self.assertIn(best_hparams.get(\'learning_rate\'), (1e-1, 1e-3))\n    self.assertBetween(best_hparams.get(\'num_layers\'), 1, 5)\n\n  def testDoWithModuleFile(self):\n    self._exec_properties[\'module_file\'] = os.path.join(self._testdata_dir,\n                                                        \'module_file\',\n                                                        \'tuner_module.py\')\n\n    tuner = executor.Executor(self._context)\n    tuner.Do(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=self._exec_properties)\n\n    self._verify_output()\n\n  def testDoWithTunerFn(self):\n    self._exec_properties[\'tuner_fn\'] = \'%s.%s\' % (\n        tuner_module.tuner_fn.__module__, tuner_module.tuner_fn.__name__)\n\n    tuner = executor.Executor(self._context)\n    tuner.Do(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=self._exec_properties)\n\n    self._verify_output()\n\n  def testTuneArgs(self):\n    with self.assertRaises(ValueError):\n      self._exec_properties[\'tune_args\'] = tuner_pb2.TuneArgs(\n          num_parallel_trials=3)\n\n      tuner = executor.Executor(self._context)\n      tuner.Do(\n          input_dict=self._input_dict,\n          output_dict=self._output_dict,\n          exec_properties=self._exec_properties)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/util/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/util/model_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common functionalities used in several components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tfx import types\n\n\ndef is_model_blessed(model_blessing: types.Artifact) -> bool:\n  """"""Returns whether model is blessed by upstream ModelValidator.\n\n  Args:\n    model_blessing: model blessing artifact from model_validator.\n\n  Returns:\n    True if the model is blessed by validator.\n  """"""\n  return model_blessing.get_int_custom_property(\'blessed\') == 1\n\n\n# TODO(jjong): Current pusher doesn\'t check whether the infra validated\n# environment is identical to the pushing environment, and it is a user\'s\n# responsibility to ensure the alignment. We need to provide a better mechanism.\ndef is_infra_validated(infra_blessing: types.Artifact) -> bool:\n  """"""Returns whether model is infra blessed by upstream InfraValidator.\n\n  Args:\n    infra_blessing: A `InfraBlessing` artifact from infra validator.\n\n  Returns:\n    Whether model is infra validated or not.\n  """"""\n  return infra_blessing.get_int_custom_property(\'blessed\') == 1\n'"
tfx/components/util/udf_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilies for user defined functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Callable, Dict, Text\n\nfrom tfx.utils import import_utils\n\n# Key for module file.\n_MODULE_FILE_KEY = \'module_file\'\n\n\n# TODO(b/157155972): improve user code support.\ndef get_fn(exec_properties: Dict[Text, Any],\n           fn_name: Text) -> Callable[..., Any]:\n  """"""Loads and returns user-defined function.""""""\n\n  has_module_file = bool(exec_properties.get(_MODULE_FILE_KEY))\n  has_fn = bool(exec_properties.get(fn_name))\n\n  if has_module_file == has_fn:\n    raise ValueError(\n        \'Neither or both of module file and user function have been supplied \'\n        ""in \'exec_properties\'."")\n\n  if has_module_file:\n    return import_utils.import_func_from_source(\n        exec_properties[_MODULE_FILE_KEY], fn_name)\n\n  fn_path_split = exec_properties[fn_name].split(\'.\')\n  return import_utils.import_func_from_module(\'.\'.join(fn_path_split[0:-1]),\n                                              fn_path_split[-1])\n'"
tfx/components/util/udf_utils_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.util.udf_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\nimport tensorflow as tf\n\nfrom tfx.components.util import udf_utils\nfrom tfx.utils import import_utils\n\n\nclass UdfUtilsTest(tf.test.TestCase):\n\n  @mock.patch.object(import_utils, \'import_func_from_source\')\n  def testGetFnFromSource(self, mock_import_func):\n    exec_properties = {\'module_file\': \'path/to/module_file.py\'}\n    udf_utils.get_fn(exec_properties, \'test_fn\')\n    mock_import_func.assert_called_once_with(\'path/to/module_file.py\',\n                                             \'test_fn\')\n\n  @mock.patch.object(import_utils, \'import_func_from_module\')\n  def testGetFnFromModule(self, mock_import_func):\n    exec_properties = {\'test_fn\': \'path.to.test_fn\'}\n    udf_utils.get_fn(exec_properties, \'test_fn\')\n    mock_import_func.assert_called_once_with(\'path.to\', \'test_fn\')\n\n  def testGetFnFailure(self):\n    exec_properties = {\n        \'module_file\': \'path/to/module_file.py\',\n        \'test_fn\': \'path.to.test_fn\',\n    }\n\n    with self.assertRaises(ValueError):\n      udf_utils.get_fn(exec_properties, \'test_fn\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/util/value_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common functionalities used in transform executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Text, Sequence, Mapping\n\n\ndef GetValues(inputs: Mapping[Text, Sequence[Any]],\n              label: Text) -> Sequence[Any]:\n  """"""Retrieves the value of the given labeled input.\n\n  Args:\n    inputs: Dict from label to a value list.\n    label: Label of the value to retrieve.\n\n  Returns:\n    A list of values, or empty list if there\'s no value.\n\n  Raises:\n    ValueError: If label is not one of the valid input labels.\n  """"""\n  if label not in inputs:\n    return []\n  values = inputs.get(label)\n  if not isinstance(values, list):\n    return [values]\n  return values\n\n\ndef GetSoleValue(inputs: Mapping[Text, Sequence[Any]], label: Text,\n                 strict=True) -> Any:\n  """"""Helper method for retrieving a sole labeled input.\n\n  Args:\n    inputs: Dict from label to a value list.\n    label: Label of the value to retrieve.\n    strict: If true, exact one value should exist for label.\n\n  Returns:\n    A sole labeled value.\n\n  Raises:\n    ValueError: If there is no/multiple input associated with the label.\n  """"""\n  values = GetValues(inputs, label)\n  if len(values) > 1:\n    raise ValueError(\n        \'There should not be more than one value for label {}\'.format(label))\n  if strict:\n    if len(values) != 1:\n      raise ValueError(\n          \'There should be one and only one value for label {}\'.format(label))\n  else:\n    if not values:\n      return None\n  return values[0]\n'"
tfx/dsl/component/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/dsl/experimental/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/dsl/experimental/latest_artifacts_resolver.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Experimental Resolver for getting the latest artifact.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Optional, Text\n\nfrom tfx import types\nfrom tfx.dsl.resolvers import base_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import artifact_utils\n\n\nclass LatestArtifactsResolver(base_resolver.BaseResolver):\n  """"""Resolver that return the latest n artifacts in a given channel.\n\n  Note that this Resolver is experimental and is subject to change in terms of\n  both interface and implementation.\n  """"""\n\n  def __init__(self, desired_num_of_artifacts: Optional[int] = 1):\n    self._desired_num_of_artifact = desired_num_of_artifacts\n\n  def resolve(\n      self,\n      pipeline_info: data_types.PipelineInfo,\n      metadata_handler: metadata.Metadata,\n      source_channels: Dict[Text, types.Channel],\n  ) -> base_resolver.ResolveResult:\n    artifacts_dict = {}\n    resolve_state_dict = {}\n    pipeline_context = metadata_handler.get_pipeline_context(pipeline_info)\n    if pipeline_context is None:\n      raise RuntimeError(\'Pipeline context absent for %s\' % pipeline_context)\n    for k, c in source_channels.items():\n      candidate_artifacts = metadata_handler.get_qualified_artifacts(\n          contexts=[pipeline_context],\n          type_name=c.type_name,\n          producer_component_id=c.producer_component_id,\n          output_key=c.output_key)\n      previous_artifacts = sorted(\n          candidate_artifacts, key=lambda a: a.artifact.id, reverse=True)\n      if len(previous_artifacts) >= self._desired_num_of_artifact:\n        artifacts_dict[k] = [\n            artifact_utils.deserialize_artifact(a.type, a.artifact)\n            for a in previous_artifacts[:self._desired_num_of_artifact]\n        ]\n        resolve_state_dict[k] = True\n      else:\n        artifacts_dict[k] = [\n            artifact_utils.deserialize_artifact(a.type, a.artifact)\n            for a in previous_artifacts\n        ]\n        resolve_state_dict[k] = False\n\n    return base_resolver.ResolveResult(\n        per_key_resolve_result=artifacts_dict,\n        per_key_resolve_state=resolve_state_dict)\n'"
tfx/dsl/experimental/latest_artifacts_resolver_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Resolver for getting latest n artifacts.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.dsl.experimental import latest_artifacts_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import standard_artifacts\n\n\nclass LatestArtifactsResolverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(LatestArtifactsResolverTest, self).setUp()\n    self._connection_config = metadata_store_pb2.ConnectionConfig()\n    self._connection_config.sqlite.SetInParent()\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline\', pipeline_root=\'/tmp\', run_id=\'my_run_id\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component\',\n        pipeline_info=self._pipeline_info)\n\n  def testGetLatestArtifact(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      artifact_one = standard_artifacts.Examples()\n      artifact_one.uri = \'uri_one\'\n      m.publish_artifacts([artifact_one])\n      artifact_two = standard_artifacts.Examples()\n      artifact_two.uri = \'uri_two\'\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts={\'key\': [artifact_one, artifact_two]})\n      expected_artifact = max(artifact_one, artifact_two, key=lambda a: a.id)\n\n      resolver = latest_artifacts_resolver.LatestArtifactsResolver()\n      resolve_result = resolver.resolve(\n          pipeline_info=self._pipeline_info,\n          metadata_handler=m,\n          source_channels={\n              \'input\':\n                  types.Channel(\n                      type=artifact_one.type,\n                      producer_component_id=self._component_info.component_id,\n                      output_key=\'key\')\n          })\n\n      self.assertTrue(resolve_result.has_complete_result)\n      self.assertEqual([\n          artifact.uri\n          for artifact in resolve_result.per_key_resolve_result[\'input\']\n      ], [expected_artifact.uri])\n      self.assertTrue(resolve_result.per_key_resolve_state[\'input\'])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/experimental/latest_blessed_model_resolver.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Experimental Resolver for getting the latest artifact.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Text\n\nfrom tfx import types\nfrom tfx.components.evaluator import constants as evaluator\nfrom tfx.dsl.resolvers import base_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass LatestBlessedModelResolver(base_resolver.BaseResolver):\n  """"""Special Resolver that return the latest blessed model.\n\n  Note that this Resolver is experimental and is subject to change in terms of\n  both interface and implementation.\n  """"""\n\n  def resolve(\n      self,\n      pipeline_info: data_types.PipelineInfo,\n      metadata_handler: metadata.Metadata,\n      source_channels: Dict[Text, types.Channel],\n  ) -> base_resolver.ResolveResult:\n    # First, checks whether we have exactly Model and ModelBlessing Channels.\n    model_channel_key = None\n    model_blessing_channel_key = None\n    assert len(source_channels) == 2, \'Expecting 2 input Channels\'\n    for k, c in source_channels.items():\n      if issubclass(c.type, standard_artifacts.Model):\n        model_channel_key = k\n      elif issubclass(c.type, standard_artifacts.ModelBlessing):\n        model_blessing_channel_key = k\n      else:\n        raise RuntimeError(\'Only expecting Model or ModelBlessing, got %s\' %\n                           c.type)\n    assert model_channel_key is not None, \'Expecting Model as input\'\n    assert model_blessing_channel_key is not None, (\'Expecting ModelBlessing as\'\n                                                    \' input\')\n\n    model_channel = source_channels[model_channel_key]\n    model_blessing_channel = source_channels[model_blessing_channel_key]\n    # Gets the pipeline context as the artifact search space.\n    pipeline_context = metadata_handler.get_pipeline_context(pipeline_info)\n    if pipeline_context is None:\n      raise RuntimeError(\'Pipeline context absent for %s\' % pipeline_context)\n\n    # Gets all models in the search space and sort in reverse order by id.\n    all_models = metadata_handler.get_qualified_artifacts(\n        contexts=[pipeline_context],\n        type_name=model_channel.type_name,\n        producer_component_id=model_channel.producer_component_id,\n        output_key=model_channel.output_key)\n    all_models.sort(key=lambda a: a.artifact.id, reverse=True)\n    # Gets all ModelBlessing artifacts in the search space.\n    all_model_blessings = metadata_handler.get_qualified_artifacts(\n        contexts=[pipeline_context],\n        type_name=model_blessing_channel.type_name,\n        producer_component_id=model_blessing_channel.producer_component_id,\n        output_key=model_blessing_channel.output_key)\n    # Makes a dict of {model_id : ModelBlessing artifact} for blessed models.\n    all_blessed_model_ids = dict(\n        (  # pylint: disable=g-complex-comprehension\n            a.artifact.custom_properties[\n                evaluator.ARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY].int_value, a)\n        for a in all_model_blessings\n        if a.artifact.custom_properties[\n            evaluator.ARTIFACT_PROPERTY_BLESSED_KEY].int_value == 1)\n\n    artifacts_dict = {model_channel_key: [], model_blessing_channel_key: []}\n    resolve_state_dict = {\n        model_channel_key: False,\n        model_blessing_channel_key: False\n    }\n    # Iterates all models, if blessed, set as result. As the model list was\n    # sorted, it is guaranteed to get the latest blessed model.\n    for model in all_models:\n      if model.artifact.id in all_blessed_model_ids:\n        artifacts_dict[model_channel_key] = [\n            artifact_utils.deserialize_artifact(model.type, model.artifact)\n        ]\n        model_blessing = all_blessed_model_ids[model.artifact.id]\n        artifacts_dict[model_blessing_channel_key] = [\n            artifact_utils.deserialize_artifact(model_blessing.type,\n                                                model_blessing.artifact)\n        ]\n        resolve_state_dict[model_channel_key] = True\n        resolve_state_dict[model_blessing_channel_key] = True\n        break\n\n    return base_resolver.ResolveResult(\n        per_key_resolve_result=artifacts_dict,\n        per_key_resolve_state=resolve_state_dict)\n'"
tfx/dsl/experimental/latest_blessed_model_resolver_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Resolver for getting latest n artifacts.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.model_validator import constants as model_validator\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.types import standard_artifacts\n\n\nclass LatestBlessedModelResolverTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(LatestBlessedModelResolverTest, self).setUp()\n    self._connection_config = metadata_store_pb2.ConnectionConfig()\n    self._connection_config.sqlite.SetInParent()\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'my_pipeline\', pipeline_root=\'/tmp\', run_id=\'my_run_id\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'a.b.c\',\n        component_id=\'my_component\',\n        pipeline_info=self._pipeline_info)\n\n  def _set_model_blessing_bit(self, artifact: types.Artifact, model_id: int,\n                              is_blessed: int):\n    artifact.mlmd_artifact.custom_properties[\n        model_validator.ARTIFACT_PROPERTY_BLESSED_KEY].int_value = is_blessed\n    artifact.mlmd_artifact.custom_properties[\n        model_validator\n        .ARTIFACT_PROPERTY_CURRENT_MODEL_ID_KEY].int_value = model_id\n\n  def testGetLatestBlessedModelArtifact(self):\n    with metadata.Metadata(connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      # Model with id 1, will be blessed.\n      model_one = standard_artifacts.Model()\n      model_one.uri = \'model_one\'\n      m.publish_artifacts([model_one])\n      # Model with id 2, will be blessed.\n      model_two = standard_artifacts.Model()\n      model_two.uri = \'model_two\'\n      m.publish_artifacts([model_two])\n      # Model with id 3, will not be blessed.\n      model_three = standard_artifacts.Model()\n      model_three.uri = \'model_three\'\n      m.publish_artifacts([model_three])\n\n      model_blessing_one = standard_artifacts.ModelBlessing()\n      self._set_model_blessing_bit(model_blessing_one, model_one.id, 1)\n      model_blessing_two = standard_artifacts.ModelBlessing()\n      self._set_model_blessing_bit(model_blessing_two, model_two.id, 1)\n      m.publish_artifacts([model_blessing_one, model_blessing_two])\n\n      m.register_execution(\n          exec_properties={},\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      m.publish_execution(\n          component_info=self._component_info,\n          output_artifacts={\n              \'a\': [model_one, model_two, model_three],\n              \'b\': [model_blessing_one, model_blessing_two]\n          })\n\n      resolver = latest_blessed_model_resolver.LatestBlessedModelResolver()\n      resolve_result = resolver.resolve(\n          pipeline_info=self._pipeline_info,\n          metadata_handler=m,\n          source_channels={\n              \'model\':\n                  types.Channel(\n                      type=standard_artifacts.Model,\n                      producer_component_id=self._component_info.component_id,\n                      output_key=\'a\'),\n              \'model_blessing\':\n                  types.Channel(\n                      type=standard_artifacts.ModelBlessing,\n                      producer_component_id=self._component_info.component_id,\n                      output_key=\'b\')\n          })\n      self.assertTrue(resolve_result.has_complete_result)\n      self.assertEqual([\n          a.uri\n          for a in resolve_result.per_key_resolve_result[\'model\']\n      ], [\'model_two\'])\n      self.assertTrue(resolve_result.per_key_resolve_state[\'model\'])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/resolvers/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/dsl/resolvers/base_resolver.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for TFX resolvers.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Dict, List, Text\n\nfrom six import with_metaclass\n\nfrom tfx import types\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\n\n\nclass ResolveResult(object):\n  """"""The data structure to hold results from Resolver.\n\n  Attributes:\n    per_key_resolve_result: a key -> List[Artifact] dict containing the resolved\n      artifacts for each source channel with the key as tag.\n    per_key_resolve_state: a key -> bool dict containing whether or not the\n      resolved artifacts for the channel are considered complete.\n    has_complete_result: bool value indicating whether all desired artifacts\n      have been resolved.\n  """"""\n\n  def __init__(self, per_key_resolve_result: Dict[Text, List[types.Artifact]],\n               per_key_resolve_state: Dict[Text, bool]):\n    self.per_key_resolve_result = per_key_resolve_result\n    self.per_key_resolve_state = per_key_resolve_state\n    self.has_complete_result = all([s for s in per_key_resolve_state.values()])\n\n\nclass BaseResolver(with_metaclass(abc.ABCMeta, object)):\n  """"""Base class for resolver.\n\n  Resolver is the logical unit that will be used optionally for input selection.\n  A resolver subclass must override the resolve() function which takes a\n  read-only MLMD handler and a dict of <key, Channel> as parameters and produces\n  a ResolveResult instance.\n  """"""\n\n  @abc.abstractmethod\n  def resolve(\n      self,\n      pipeline_info: data_types.PipelineInfo,\n      metadata_handler: metadata.Metadata,\n      source_channels: Dict[Text, types.Channel],\n  ) -> ResolveResult:\n    """"""Resolves artifacts from channels by querying MLMD.\n\n    Args:\n      pipeline_info: PipelineInfo of the current pipeline. We do not want to\n        query artifacts across pipeline boundary.\n      metadata_handler: a read-only handler to query MLMD.\n      source_channels: a key -> channel dict which contains the info of the\n        source channels.\n\n    Returns:\n      a ResolveResult instance.\n\n    """"""\n    raise NotImplementedError\n'"
tfx/examples/bigquery_ml/taxi_pipeline_kubeflow_gcp_bqml.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago Taxi example using TFX DSL on Kubeflow with Google Cloud services.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Dict, List, Text\nfrom tfx.components import BigQueryExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ModelValidator\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor as ai_platform_trainer_executor\nfrom tfx.extensions.google_cloud_big_query_ml.pusher import executor as bigquery_ml_pusher_executor\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import trainer_pb2\n\n_pipeline_name = \'chicago_taxi_pipeline_kubeflow_gcp\'\n\n# Directory and data locations (uses Google Cloud Storage).\n_input_bucket = \'gs://my-bucket\'\n_output_bucket = \'gs://my-bucket\'\n_tfx_root = os.path.join(_output_bucket, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, _pipeline_name)\n\n# Google Cloud Platform project id to use when deploying this pipeline.\n_project_id = \'my-gcp-project\'\n\n# BigQuery dataset where the model will be deployed, needs to be created prior\n# to execution.\n_bq_dataset_id = \'my-bigquery-dataset\'\n\n# Name for the model to use in BigQuery, this name is used when quering the\n# model.\n_model_name = \'chicago_taxi\'\n\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n# Copy this from the current directory to a GCS bucket and update the location\n# below.\n_module_file = os.path.join(_input_bucket, \'taxi_utils_bqml.py\')\n\n# Region to use for Dataflow jobs and AI Platform training jobs.\n#   Dataflow: https://cloud.google.com/dataflow/docs/concepts/regional-endpoints\n#   AI Platform: https://cloud.google.com/ml-engine/docs/tensorflow/regions\n_gcp_region = \'us-central1\'\n\n# A dict which contains the training job parameters to be passed to Google\n# Cloud AI Platform. For the full set of parameters supported by Google Cloud AI\n# Platform, refer to\n# https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#Job\n_ai_platform_training_args = {\n    \'project\': _project_id,\n    \'region\': _gcp_region,\n    # Starting from TFX 0.14, training on AI Platform uses custom containers:\n    # https://cloud.google.com/ml-engine/docs/containers-overview\n    # You can specify a custom container here. If not specified, TFX will use a\n    # a public container image matching the installed version of TFX.\n    # \'masterConfig\': { \'imageUri\': \'gcr.io/my-project/my-container\' },\n    # Note that if you do specify a custom container, ensure the entrypoint\n    # calls into TFX\'s run_executor script (tfx/scripts/run_executor.py)\n}\n\n# A dict which contains the serving job parameters for Google BigQuery ML.\n_bigquery_serving_args = {\n    \'bq_dataset_id\': _bq_dataset_id,\n    \'model_name\': _model_name,\n    \'project_id\': _project_id,\n}\n\n# Beam args to run data processing on DataflowRunner.\n#\n# TODO(b/151114974): Remove `disk_size_gb` flag after default is increased.\n# TODO(b/151116587): Remove `shuffle_mode` flag after default is changed.\n# TODO(b/156874687): Remove `machine_type` after IP addresses are no longer a\n#                    scaling bottleneck.\n_beam_pipeline_args = [\n    \'--runner=DataflowRunner\',\n    \'--project=\' + _project_id,\n    \'--temp_location=\' + os.path.join(_output_bucket, \'tmp\'),\n    \'--region=\' + _gcp_region,\n\n    # Temporary overrides of defaults.\n    \'--disk_size_gb=50\',\n    \'--experiments=shuffle_mode=auto\',\n    \'--machine_type=n1-standard-8\',\n]\n\n# The rate at which to sample rows from the Chicago Taxi dataset using BigQuery.\n# The full taxi dataset is > 120M record.  In the interest of resource\n# savings and time, we\'ve set the default for this example to be much smaller.\n# Feel free to crank it up and process the full dataset!\n_query_sample_rate = 0.001  # Generate a 0.1% random sample.\n\n# This is the upper bound of FARM_FINGERPRINT in Bigquery (ie the max value of\n# signed int64).\n_max_int64 = \'0x7FFFFFFFFFFFFFFF\'\n\n# The query that extracts the examples from BigQuery.  The Chicago Taxi dataset\n# used for this example is a public dataset available on Google AI Platform.\n# https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips\n\n# TODO(b/145772608) switch to use \'optional dense\' feature instead of IFNULL\n# Note: TFT\'s feature spec generation currently does not support parsing spec\n# for ""optional dense"" input ie.dense tensor inputs with missing values. Any\n# input with missing values is interpreted as a sparse tensor. This does not\n# work for BigQuery as it only supports dense input for model serving. Here we\n# fill in the missing values before TFX pipeline starts as a result. This is not\n# a good practice as feature transformation should always be done in the graph\n# to prevent training / serving skew.\n\n_query = """"""\n         SELECT\n           IFNULL(pickup_community_area, 0) as pickup_community_area,\n           fare,\n           EXTRACT(MONTH FROM trip_start_timestamp) AS trip_start_month,\n           EXTRACT(HOUR FROM trip_start_timestamp) AS trip_start_hour,\n           EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS trip_start_day,\n           UNIX_SECONDS(trip_start_timestamp) AS trip_start_timestamp,\n           IFNULL(pickup_latitude, 0) as pickup_latitude,\n           IFNULL(pickup_longitude, 0) as pickup_longitude,\n           IFNULL(dropoff_latitude, 0) as dropoff_latitude,\n           IFNULL(dropoff_longitude, 0) as dropoff_longitude,\n           trip_miles,\n           IFNULL(pickup_census_tract, 0) as pickup_census_tract,\n           IFNULL(dropoff_census_tract, 0) as dropoff_census_tract,\n           payment_type,\n           IFNULL(company, \'NA\') as company,\n           IFNULL(trip_seconds, 0) as trip_seconds,\n           IFNULL(dropoff_community_area, 0) as dropoff_community_area,\n           tips\n         FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n         WHERE (ABS(FARM_FINGERPRINT(unique_key)) / {max_int64})\n           < {query_sample_rate}"""""".format(\n               max_int64=_max_int64, query_sample_rate=_query_sample_rate)\n\n\ndef _create_pipeline(\n    pipeline_name: Text, pipeline_root: Text, query: Text, module_file: Text,\n    beam_pipeline_args: List[Text], ai_platform_training_args: Dict[Text, Text],\n    bigquery_serving_args: Dict[Text, Text]) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX and Kubeflow Pipelines.""""""\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = BigQueryExampleGen(query=query)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn\n  # to train a model on Google Cloud AI Platform.\n  trainer = Trainer(\n      custom_executor_spec=executor_spec.ExecutorClassSpec(\n          ai_platform_trainer_executor.Executor),\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000),\n      custom_config={\'ai_platform_training_args\': ai_platform_training_args})\n\n  # Uses TFMA to compute a evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n          evaluator_pb2.SingleSlicingSpec(\n              column_for_slicing=[\'trip_start_hour\'])\n      ]))\n\n  # Performs quality validation of a candidate model (compared to a baseline).\n  model_validator = ModelValidator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to  Google Cloud BigQuery ML if check passed.\n  pusher = Pusher(\n      custom_executor_spec=executor_spec.ExecutorClassSpec(\n          bigquery_ml_pusher_executor.Executor),\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_validator.outputs[\'blessing\'],\n      custom_config={\'bigquery_serving_args\': bigquery_serving_args})\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, evaluator, model_validator, pusher\n      ],\n      beam_pipeline_args=beam_pipeline_args,\n  )\n\n\nif __name__ == \'__main__\':\n  # Metadata config. The defaults works work with the installation of\n  # KF Pipelines using Kubeflow. If installing KF Pipelines using the\n  # lightweight deployment option, you may need to override the defaults.\n  metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=metadata_config,\n      # Specify custom docker image to use.\n      tfx_image=tfx_image\n  )\n\n  kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          query=_query,\n          module_file=_module_file,\n          beam_pipeline_args=_beam_pipeline_args,\n          ai_platform_training_args=_ai_platform_training_args,\n          bigquery_serving_args=_bigquery_serving_args,\n      ))\n'"
tfx/examples/bigquery_ml/taxi_utils_bqml.py,31,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necessary utils.\n\nFor a TFX pipeline to successfully run, a preprocessing_fn and a\n_build_estimator function needs to be provided.  This file contains both.\n\nThis file is equivalent to examples/chicago_taxi/trainer/model.py and\nexamples/chicago_taxi/preprocess.py.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform.tf_metadata import schema_utils\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensors.\n\n  If x is a SparseTensors, fills in missing values of `x` with \'\' or 0, and\n  converts to a dense tensor. Otherwise it returns x as is.\n\n  Args:\n    x: A `SparseTensor` of rank 2 or a tensor that is not an instance of\n      `SparseTensor`.  If input is a `SparseTensor` its dense shape should have\n      size at most 1 in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in, or x as is\n    if x is not an instance of `SparseTensor`\n  """"""\n  if not isinstance(x, tf.SparseTensor):\n    return x\n\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.sparse.to_dense(\n          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n          default_value),\n      axis=1)\n\n\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n\n\ndef _build_estimator(config, hidden_units=None, warm_start_from=None):\n  """"""Build an estimator for predicting the tipping behavior of taxi riders.\n\n  Args:\n    config: tf.estimator.RunConfig defining the runtime environment for the\n      estimator (including model_dir).\n    hidden_units: [int], the layer sizes of the DNN (input layer first)\n    warm_start_from: Optional directory to warm start from.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  return tf.estimator.DNNLinearCombinedClassifier(\n      config=config,\n      linear_feature_columns=categorical_columns,\n      dnn_feature_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n      warm_start_from=warm_start_from)\n\n\ndef _flat_input_serving_receiver_fn(tf_transform_output, schema):\n  """"""Build the serving function for flat list of Dense tensors as input.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    Tensorflow graph which parses examples, applying tf-transform to them.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  transformed_features = tf_transform_output.transform_raw_features(\n      serving_input_receiver.features)\n\n  # We construct a receiver function that receives flat list of Dense tensors as\n  # features. This is as per BigQuery ML serving requirements.\n  return tf.estimator.export.ServingInputReceiver(\n      transformed_features, serving_input_receiver.features)\n\n\ndef _eval_input_receiver_fn(tf_transform_output, schema):\n  """"""Build everything needed for the tf-model-analysis to run the model.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Tensorflow graph which parses raw untransformed features, applies the\n        tf-transform preprocessing operators.\n      - Set of raw, untransformed features.\n      - Label against which predictions will be compared.\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  serialized_tf_example = tf.compat.v1.placeholder(\n      dtype=tf.string, shape=[None], name=\'input_example_tensor\')\n\n  # Add a parse_example operator to the tensorflow graph, which will parse\n  # raw, untransformed, tf examples.\n  features = tf.io.parse_example(\n      serialized=serialized_tf_example, features=raw_feature_spec)\n\n  # Now that we have our raw examples, process them through the tf-transform\n  # function computed during the preprocessing step.\n  transformed_features = tf_transform_output.transform_raw_features(features)\n\n  # The key name MUST be \'examples\'.\n  receiver_tensors = {\'examples\': serialized_tf_example}\n\n  # NOTE: Model is driven by transformed features (since training works on the\n  # materialized output of TFT, but slicing will happen on raw features.\n  features.update(transformed_features)\n\n  return tfma.export.EvalInputReceiver(\n      features=features,\n      receiver_tensors=receiver_tensors,\n      labels=transformed_features[_transformed_name(_LABEL_KEY)])\n\n\ndef _input_fn(filenames, tf_transform_output, batch_size=200):\n  """"""Generates features and labels for training or evaluation.\n\n  Args:\n    filenames: [str] list of CSV files to read data from.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: int First dimension size of the Tensors returned by input_fn\n\n  Returns:\n    A (features, indices) tuple where features is a dictionary of\n      Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn)\n\n  transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n      dataset).get_next()\n  # We pop the label because we do not want to use it as a feature while we\'re\n  # training.\n  return transformed_features, transformed_features.pop(\n      _transformed_name(_LABEL_KEY))\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  # Number of nodes in the first layer of the DNN\n  first_dnn_layer_size = 100\n  num_dnn_layers = 4\n  dnn_decay_factor = 0.7\n\n  train_batch_size = 40\n  eval_batch_size = 40\n\n  tf_transform_output = tft.TFTransformOutput(trainer_fn_args.transform_output)\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      tf_transform_output,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      tf_transform_output,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n      train_input_fn,\n      max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _flat_input_serving_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  exporter = tf.estimator.FinalExporter(\'chicago-taxi\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'chicago-taxi-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=1)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n\n  estimator = _build_estimator(\n      # Construct layers sizes with exponential decay\n      hidden_units=[\n          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n          for i in range(num_dnn_layers)\n      ],\n      config=run_config,\n      warm_start_from=trainer_fn_args.base_model)\n\n  # Create an input receiver for TFMA processing\n  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': receiver_fn\n  }\n'"
tfx/examples/bigquery_ml/taxi_utils_bqml_test.py,12,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for taxi_utils_bqml.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport types\n\nimport apache_beam as beam\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform import beam as tft_beam\nfrom tensorflow_transform.tf_metadata import dataset_metadata\nfrom tensorflow_transform.tf_metadata import dataset_schema\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer import executor as trainer_executor\nfrom tfx.examples.bigquery_ml import taxi_utils_bqml\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\nclass TaxiUtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiUtilsTest, self).setUp()\n    self._testdata_path = os.path.join(os.path.dirname(__file__), \'testdata\')\n\n  def testUtils(self):\n    key = \'fare\'\n    xfm_key = taxi_utils_bqml._transformed_name(key)\n    self.assertEqual(xfm_key, \'fare_xf\')\n\n  def testPreprocessingFn(self):\n    schema_file = os.path.join(self._testdata_path, \'schema_gen/schema.pbtxt\')\n    schema = io_utils.parse_pbtxt_file(schema_file, schema_pb2.Schema())\n    feature_spec = taxi_utils_bqml._get_raw_feature_spec(schema)\n    working_dir = self.get_temp_dir()\n    transform_output_path = os.path.join(working_dir, \'transform_output\')\n    transformed_examples_path = os.path.join(\n        working_dir, \'transformed_examples\')\n\n    # Run very simplified version of executor logic.\n    # TODO(kestert): Replace with tft_unit.assertAnalyzeAndTransformResults.\n    # Generate legacy `DatasetMetadata` object.  Future version of Transform\n    # will accept the `Schema` proto directly.\n    legacy_metadata = dataset_metadata.DatasetMetadata(\n        dataset_schema.from_feature_spec(feature_spec))\n    decoder = tft.coders.ExampleProtoCoder(legacy_metadata.schema)\n    with beam.Pipeline() as p:\n      with tft_beam.Context(temp_dir=os.path.join(working_dir, \'tmp\')):\n        examples = (\n            p\n            | \'ReadTrainData\' >> beam.io.ReadFromTFRecord(\n                os.path.join(self._testdata_path, \'csv_example_gen/train/*\'),\n                coder=beam.coders.BytesCoder(),\n                # TODO(b/114938612): Eventually remove this override.\n                validate=False)\n            | \'DecodeTrainData\' >> beam.Map(decoder.decode))\n        (transformed_examples, transformed_metadata), transform_fn = (\n            (examples, legacy_metadata)\n            | \'AnalyzeAndTransform\' >> tft_beam.AnalyzeAndTransformDataset(\n                taxi_utils_bqml.preprocessing_fn))\n\n        # WriteTransformFn writes transform_fn and metadata to subdirectories\n        # tensorflow_transform.SAVED_MODEL_DIR and\n        # tensorflow_transform.TRANSFORMED_METADATA_DIR respectively.\n        # pylint: disable=expression-not-assigned\n        (transform_fn\n         | \'WriteTransformFn\' >> tft_beam.WriteTransformFn(\n             transform_output_path))\n\n        encoder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\n        (transformed_examples\n         | \'EncodeTrainData\' >> beam.Map(encoder.encode)\n         | \'WriteTrainData\' >> beam.io.WriteToTFRecord(\n             os.path.join(transformed_examples_path,\n                          \'train/transformed_examples.gz\'),\n             coder=beam.coders.BytesCoder()))\n        # pylint: enable=expression-not-assigned\n\n    # Verify the output matches golden output.\n    # NOTE: we don\'t verify that transformed examples match golden output.\n    expected_transformed_schema = io_utils.parse_pbtxt_file(\n        os.path.join(\n            self._testdata_path,\n            \'transform/transform_output/transformed_metadata/schema.pbtxt\'),\n        schema_pb2.Schema())\n    transformed_schema = io_utils.parse_pbtxt_file(\n        os.path.join(transform_output_path,\n                     \'transformed_metadata/schema.pbtxt\'),\n        schema_pb2.Schema())\n    # Clear annotations so we only have to test main schema.\n    for feature in transformed_schema.feature:\n      feature.ClearField(\'annotation\')\n    transformed_schema.ClearField(\'annotation\')\n    self.assertEqual(transformed_schema, expected_transformed_schema)\n\n  def testTrainerFn(self):\n    temp_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    schema_file = os.path.join(self._testdata_path, \'schema_gen/schema.pbtxt\')\n    output_dir = os.path.join(temp_dir, \'output_dir\')\n    trainer_fn_args = trainer_executor.TrainerFnArgs(\n        train_files=os.path.join(self._testdata_path,\n                                 \'transform/transformed_examples/train/*.gz\'),\n        transform_output=os.path.join(self._testdata_path,\n                                      \'transform/transform_output/\'),\n        output_dir=output_dir,\n        serving_model_dir=os.path.join(temp_dir, \'serving_model_dir\'),\n        eval_files=os.path.join(self._testdata_path,\n                                \'transform/transformed_examples/eval/*.gz\'),\n        schema_file=schema_file,\n        train_steps=1,\n        eval_steps=1,\n        verbosity=\'INFO\',\n        base_model=os.path.join(self._testdata_path,\n                                \'trainer/current/serving_model_dir\'))\n    schema = io_utils.parse_pbtxt_file(schema_file, schema_pb2.Schema())\n    training_spec = taxi_utils_bqml.trainer_fn(trainer_fn_args, schema)\n\n    estimator = training_spec[\'estimator\']\n    train_spec = training_spec[\'train_spec\']\n    eval_spec = training_spec[\'eval_spec\']\n    eval_input_receiver_fn = training_spec[\'eval_input_receiver_fn\']\n\n    self.assertIsInstance(estimator, tf.estimator.Estimator)\n    self.assertIsInstance(train_spec, tf.estimator.TrainSpec)\n    self.assertIsInstance(eval_spec, tf.estimator.EvalSpec)\n    self.assertIsInstance(eval_input_receiver_fn, types.FunctionType)\n\n    # Train for one step, then eval for one step.\n    eval_result, exports = tf.estimator.train_and_evaluate(\n        estimator, train_spec, eval_spec)\n    self.assertGreater(eval_result[\'loss\'], 0.0)\n    self.assertEqual(len(exports), 1)\n    self.assertGreaterEqual(len(tf.io.gfile.listdir(exports[0])), 1)\n\n    # Export the eval saved model.\n    eval_savedmodel_path = tfma.export.export_eval_savedmodel(\n        estimator=estimator,\n        export_dir_base=path_utils.eval_model_dir(output_dir),\n        eval_input_receiver_fn=eval_input_receiver_fn)\n    self.assertGreaterEqual(len(tf.io.gfile.listdir(eval_savedmodel_path)), 1)\n\n    # Test exported serving graph.\n    with tf.compat.v1.Session() as sess:\n      metagraph_def = tf.compat.v1.saved_model.loader.load(\n          sess, [tf.saved_model.SERVING], exports[0])\n      self.assertIsInstance(metagraph_def, tf.compat.v1.MetaGraphDef)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_beam.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_beam\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          model_resolver,\n          evaluator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_beam.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_beam_e2e_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_beam\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineBeamEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineBeamEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'beam_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\', \'simple\')\n    self._module_file = os.path.join(os.path.dirname(__file__), \'taxi_utils.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testTaxiPipelineBeam(self):\n    BeamDagRunner().run(\n        taxi_pipeline_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(9, execution_count)\n\n    self.assertPipelineExecution()\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(\n        taxi_pipeline_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # All executions but Evaluator and Pusher are cached.\n    # Note that Resolver will always execute.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      self.assertEqual(18, len(m.store.get_executions()))\n\n    # Runs pipeline the third time.\n    BeamDagRunner().run(\n        taxi_pipeline_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      self.assertEqual(27, len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_beam_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_beam\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n\nclass TaxiPipelineBeamTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineBeamTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n  def testTaxiPipelineCheckDagConstruction(self):\n    logical_pipeline = taxi_pipeline_beam._create_pipeline(\n        pipeline_name=\'Test\',\n        pipeline_root=self._test_dir,\n        data_root=self._test_dir,\n        module_file=self._test_dir,\n        serving_model_dir=self._test_dir,\n        metadata_path=self._test_dir,\n        direct_num_workers=1)\n    self.assertEqual(9, len(logical_pipeline.components))\n\n  def testTaxiPipelineNewStyleCompatibility(self):\n    examples = external_input(\'/tmp/fake/path\')\n    example_gen = CsvExampleGen(input=examples)\n    self.assertIs(example_gen.inputs[\'input\'],\n                  example_gen.inputs[\'input_base\'])\n    statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n    self.assertIs(statistics_gen.inputs[\'examples\'],\n                  statistics_gen.inputs[\'input_data\'])\n    schema_gen = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n    self.assertIs(schema_gen.inputs[\'statistics\'],\n                  schema_gen.inputs[\'stats\'])\n    self.assertIs(schema_gen.outputs[\'schema\'],\n                  schema_gen.outputs[\'output\'])\n    example_validator = ExampleValidator(\n        statistics=statistics_gen.outputs[\'statistics\'],\n        schema=schema_gen.outputs[\'schema\'])\n    self.assertIs(example_validator.inputs[\'statistics\'],\n                  example_validator.inputs[\'stats\'])\n    self.assertIs(example_validator.outputs[\'anomalies\'],\n                  example_validator.outputs[\'output\'])\n    transform = Transform(\n        examples=example_gen.outputs[\'examples\'],\n        schema=schema_gen.outputs[\'schema\'],\n        module_file=\'/tmp/fake/module/file\')\n    self.assertIs(transform.inputs[\'examples\'],\n                  transform.inputs[\'input_data\'])\n    self.assertIs(transform.outputs[\'transform_graph\'],\n                  transform.outputs[\'transform_output\'])\n    trainer = Trainer(\n        module_file=\'/tmp/fake/module/file\',\n        transformed_examples=transform.outputs[\'transformed_examples\'],\n        schema=schema_gen.outputs[\'schema\'],\n        transform_graph=transform.outputs[\'transform_graph\'],\n        train_args=trainer_pb2.TrainArgs(num_steps=10000),\n        eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n    self.assertIs(trainer.inputs[\'transform_graph\'],\n                  trainer.inputs[\'transform_output\'])\n    self.assertIs(trainer.outputs[\'model\'],\n                  trainer.outputs[\'output\'])\n    model_resolver = ResolverNode(\n        instance_name=\'latest_blessed_model_resolver\',\n        resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n        model=Channel(type=Model),\n        model_blessing=Channel(type=ModelBlessing))\n    eval_config = tfma.EvalConfig(\n        model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n        slicing_specs=[\n            tfma.SlicingSpec(),\n            tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n        ],\n        metrics_specs=[\n            tfma.MetricsSpec(\n                thresholds={\n                    \'accuracy\':\n                        tfma.config.MetricThreshold(\n                            value_threshold=tfma.GenericValueThreshold(\n                                lower_bound={\'value\': 0.6}),\n                            change_threshold=tfma.GenericChangeThreshold(\n                                direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                                absolute={\'value\': -1e-10}))\n                })\n        ])\n    evaluator = Evaluator(\n        examples=example_gen.outputs[\'examples\'],\n        model=trainer.outputs[\'model\'],\n        baseline_model=model_resolver.outputs[\'model\'],\n        eval_config=eval_config)\n    self.assertIs(evaluator.inputs[\'model\'],\n                  evaluator.inputs[\'model_exports\'])\n    self.assertIs(evaluator.outputs[\'evaluation\'],\n                  evaluator.outputs[\'output\'])\n    pusher = Pusher(\n        model=trainer.outputs[\'output\'],\n        model_blessing=evaluator.outputs[\'blessing\'],\n        push_destination=pusher_pb2.PushDestination(\n            filesystem=pusher_pb2.PushDestination.Filesystem(\n                base_directory=\'/fake/serving/dir\')))\n    self.assertIs(pusher.inputs[\'model\'],\n                  pusher.inputs[\'model_export\'])\n    self.assertIs(pusher.outputs[\'pushed_model\'],\n                  pusher.outputs[\'model_push\'])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_importer.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\nfrom tfx_bsl.version import __version__ as tfx_bsl_version\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ImporterNode\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.types.standard_artifacts import Schema\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_importer\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n_user_schema_path = os.path.join(_taxi_root, \'data\', \'user_provided_schema\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     user_schema_path: Text, module_file: Text,\n                     serving_model_dir: Text, metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Import user-provided schema.\n  user_schema_importer = ImporterNode(\n      instance_name=\'import_user_schema\',\n      source_uri=user_schema_path,\n      artifact_type=Schema)\n\n  # Generates schema based on statistics files. Even we use user-provided schema\n  # in downstream components, we still want to generate the schema of the newest\n  # data so that user can compare and optionally update the schema to use.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=user_schema_importer.outputs[\'result\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=user_schema_importer.outputs[\'result\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=user_schema_importer.outputs[\'result\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, user_schema_importer, schema_gen,\n          example_validator, transform, trainer, model_resolver, evaluator,\n          pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_beam.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          user_schema_path=_user_schema_path,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_importer_e2e_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_importer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\nfrom tfx_bsl.version import __version__ as tfx_bsl_version\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_importer\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineImporterEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineImporterEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'beam_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\', \'simple\')\n    self._user_schema_path = os.path.join(\n        os.path.dirname(__file__), \'data\', \'user_provided_schema\')\n    self._module_file = os.path.join(os.path.dirname(__file__), \'taxi_utils.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testTaxiPipelineWithImporter(self):\n    BeamDagRunner().run(\n        taxi_pipeline_importer._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            user_schema_path=self._user_schema_path,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(10, execution_count)\n\n    self.assertPipelineExecution()\n\n    # Runs the pipeline again.\n    BeamDagRunner().run(\n        taxi_pipeline_importer._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            user_schema_path=self._user_schema_path,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # All executions but Evaluator and Pusher are cached.\n    # Note that Resolver will always execute.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      self.assertEqual(20, len(m.store.get_executions()))\n\n    # Runs the pipeline the third time.\n    BeamDagRunner().run(\n        taxi_pipeline_importer._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            user_schema_path=self._user_schema_path,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      self.assertEqual(30, len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_infraval_beam.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl.logging\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import InfraValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_infraval_beam\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Performs infra validation of a candidate model to prevent unservable model\n  # from being pushed.\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=example_gen.outputs[\'examples\'],\n      serving_spec=infra_validator_pb2.ServingSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n              tags=[\'latest\']),\n          local_docker=infra_validator_pb2.LocalDockerConfig()),\n      request_spec=infra_validator_pb2.RequestSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec())\n  )\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      infra_blessing=infra_validator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          model_resolver,\n          evaluator,\n          infra_validator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_beam.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_infraval_beam_e2e_test.py,9,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_infraval_beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_infraval_beam\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineInfravalBeamEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineInfravalBeamEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'beam_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\', \'simple\')\n    self._module_file = os.path.join(os.path.dirname(__file__), \'taxi_utils.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertInfraValidatorPassed(self) -> None:\n    blessing_path = os.path.join(self._pipeline_root, \'InfraValidator\',\n                                 \'blessing\')\n    executions = tf.io.gfile.listdir(blessing_path)\n    self.assertGreaterEqual(len(executions), 1)\n    for exec_id in executions:\n      blessed = os.path.join(blessing_path, exec_id, \'INFRA_BLESSED\')\n      self.assertTrue(tf.io.gfile.exists(blessed))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'InfraValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testTaxiPipelineBeam(self):\n    num_components = 10\n\n    BeamDagRunner().run(\n        taxi_pipeline_infraval_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(num_components, execution_count)\n\n    self.assertPipelineExecution()\n    self.assertInfraValidatorPassed()\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(\n        taxi_pipeline_infraval_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # All executions but Evaluator and Pusher are cached.\n    # Note that Resolver will always execute.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      # 10 more cached executions.\n      self.assertEqual(num_components * 2, len(m.store.get_executions()))\n\n    # Runs pipeline the third time.\n    BeamDagRunner().run(\n        taxi_pipeline_infraval_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      # 10 more cached executions.\n      self.assertEqual(num_components * 3, len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_gcp.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago Taxi example using TFX DSL on Kubeflow with Google Cloud services.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport os\nfrom typing import Dict, List, Optional, Text\nfrom absl import app\nfrom absl import flags\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import BigQueryExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.extensions.google_cloud_ai_platform.pusher import executor as ai_platform_pusher_executor\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor as ai_platform_trainer_executor\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\n\nFLAGS = flags.FLAGS\nflags.DEFINE_bool(\'distributed_training\', False,\n                  \'If True, enable distributed training.\')\n\n_pipeline_name = \'chicago_taxi_pipeline_kubeflow_gcp\'\n\n# Directory and data locations (uses Google Cloud Storage).\n_input_bucket = \'gs://my-bucket\'\n_output_bucket = \'gs://my-bucket\'\n_tfx_root = os.path.join(_output_bucket, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, _pipeline_name)\n\n# Google Cloud Platform project id to use when deploying this pipeline.\n_project_id = \'my-gcp-project\'\n\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n# Copy this from the current directory to a GCS bucket and update the location\n# below.\n_module_file = os.path.join(_input_bucket, \'taxi_utils.py\')\n\n# Region to use for Dataflow jobs and AI Platform jobs.\n#   Dataflow: https://cloud.google.com/dataflow/docs/concepts/regional-endpoints\n#   AI Platform: https://cloud.google.com/ml-engine/docs/tensorflow/regions\n_gcp_region = \'us-central1\'\n\n# A dict which contains the training job parameters to be passed to Google\n# Cloud AI Platform. For the full set of parameters supported by Google Cloud AI\n# Platform, refer to\n# https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#Job\n_ai_platform_training_args = {\n    \'project\': _project_id,\n    \'region\': _gcp_region,\n    # Starting from TFX 0.14, training on AI Platform uses custom containers:\n    # https://cloud.google.com/ml-engine/docs/containers-overview\n    # You can specify a custom container here. If not specified, TFX will use a\n    # a public container image matching the installed version of TFX.\n    # \'masterConfig\': { \'imageUri\': \'gcr.io/my-project/my-container\' },\n    # Note that if you do specify a custom container, ensure the entrypoint\n    # calls into TFX\'s run_executor script (tfx/scripts/run_executor.py)\n}\n\n# A dict which contains the serving job parameters to be passed to Google\n# Cloud AI Platform. For the full set of parameters supported by Google Cloud AI\n# Platform, refer to\n# https://cloud.google.com/ml-engine/reference/rest/v1/projects.models\n_ai_platform_serving_args = {\n    \'model_name\': \'chicago_taxi\',\n    \'project_id\': _project_id,\n    # The region to use when serving the model. See available regions here:\n    # https://cloud.google.com/ml-engine/docs/regions\n    # Note that serving currently only supports a single region:\n    # https://cloud.google.com/ml-engine/reference/rest/v1/projects.models#Model\n    \'regions\': [_gcp_region],\n}\n\n\ndef create_pipeline(\n    pipeline_name: Text,\n    pipeline_root: Text,\n    module_file: Text,\n    ai_platform_training_args: Dict[Text, Text],\n    ai_platform_serving_args: Dict[Text, Text],\n    beam_pipeline_args: Optional[List[Text]] = None) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX and Kubeflow Pipelines.\n\n  Args:\n    pipeline_name: name of the TFX pipeline being created.\n    pipeline_root: root directory of the pipeline. Should be a valid GCS path.\n    module_file: uri of the module files used in Trainer and Transform\n      components.\n    ai_platform_training_args: Args of CAIP training job. Please refer to\n      https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#Job\n      for detailed description.\n    ai_platform_serving_args: Args of CAIP model deployment. Please refer to\n      https://cloud.google.com/ml-engine/reference/rest/v1/projects.models\n      for detailed description.\n    beam_pipeline_args: Optional list of beam pipeline options. Please refer to\n      https://cloud.google.com/dataflow/docs/guides/specifying-exec-params#setting-other-cloud-dataflow-pipeline-options.\n      When this argument is not provided, the default is to use GCP\n      DataflowRunner with 50GB disk size as specified in this function. If an\n      empty list is passed in, default specified by Beam will be used, which can\n      be found at\n      https://cloud.google.com/dataflow/docs/guides/specifying-exec-params#setting-other-cloud-dataflow-pipeline-options\n\n  Returns:\n    A TFX pipeline object.\n  """"""\n\n  # The rate at which to sample rows from the Taxi dataset using BigQuery.\n  # The full taxi dataset is > 200M record.  In the interest of resource\n  # savings and time, we\'ve set the default for this example to be much smaller.\n  # Feel free to crank it up and process the full dataset!\n  # By default it generates a 0.1% random sample.\n  query_sample_rate = data_types.RuntimeParameter(\n      name=\'query_sample_rate\', ptype=float, default=0.001)\n\n  # This is the upper bound of FARM_FINGERPRINT in Bigquery (ie the max value of\n  # signed int64).\n  max_int64 = \'0x7FFFFFFFFFFFFFFF\'\n\n  # The query that extracts the examples from BigQuery. The Chicago Taxi dataset\n  # used for this example is a public dataset available on Google AI Platform.\n  # https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips\n  query = """"""\n          SELECT\n            pickup_community_area,\n            fare,\n            EXTRACT(MONTH FROM trip_start_timestamp) AS trip_start_month,\n            EXTRACT(HOUR FROM trip_start_timestamp) AS trip_start_hour,\n            EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS trip_start_day,\n            UNIX_SECONDS(trip_start_timestamp) AS trip_start_timestamp,\n            pickup_latitude,\n            pickup_longitude,\n            dropoff_latitude,\n            dropoff_longitude,\n            trip_miles,\n            pickup_census_tract,\n            dropoff_census_tract,\n            payment_type,\n            company,\n            trip_seconds,\n            dropoff_community_area,\n            tips\n          FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n          WHERE (ABS(FARM_FINGERPRINT(unique_key)) / {max_int64})\n            < {query_sample_rate}"""""".format(\n                max_int64=max_int64, query_sample_rate=str(query_sample_rate))\n\n  # Beam args to run data processing on DataflowRunner.\n  #\n  # TODO(b/151114974): Remove `disk_size_gb` flag after default is increased.\n  # TODO(b/151116587): Remove `shuffle_mode` flag after default is changed.\n  # TODO(b/156874687): Remove `machine_type` after IP addresses are no longer a\n  #                    scaling bottleneck.\n  if beam_pipeline_args is None:\n    beam_pipeline_args = [\n        \'--runner=DataflowRunner\',\n        \'--project=\' + _project_id,\n        \'--temp_location=\' + os.path.join(_output_bucket, \'tmp\'),\n        \'--region=\' + _gcp_region,\n\n        # Temporary overrides of defaults.\n        \'--disk_size_gb=50\',\n        \'--experiments=shuffle_mode=auto\',\n        \'--machine_type=n1-standard-8\',\n    ]\n\n  # Number of epochs in training.\n  train_steps = data_types.RuntimeParameter(\n      name=\'train_steps\',\n      default=10000,\n      ptype=int,\n  )\n\n  # Number of epochs in evaluation.\n  eval_steps = data_types.RuntimeParameter(\n      name=\'eval_steps\',\n      default=5000,\n      ptype=int,\n  )\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = BigQueryExampleGen(query=query)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Update ai_platform_training_args if distributed training was enabled.\n  # Number of worker machines used in distributed training.\n  worker_count = data_types.RuntimeParameter(\n      name=\'worker_count\',\n      default=2,\n      ptype=int,\n  )\n\n  # Type of worker machines used in distributed training.\n  worker_type = data_types.RuntimeParameter(\n      name=\'worker_type\',\n      default=\'standard\',\n      ptype=str,\n  )\n\n  local_training_args = copy.deepcopy(ai_platform_training_args)\n\n  if FLAGS.distributed_training:\n    local_training_args.update({\n        # You can specify the machine types, the number of replicas for workers\n        # and parameter servers.\n        # https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#ScaleTier\n        \'scaleTier\': \'CUSTOM\',\n        \'masterType\': \'large_model\',\n        \'workerType\': worker_type,\n        \'parameterServerType\': \'standard\',\n        \'workerCount\': worker_count,\n        \'parameterServerCount\': 1\n    })\n\n  # Uses user-provided Python function that implements a model using TF-Learn\n  # to train a model on Google Cloud AI Platform.\n  trainer = Trainer(\n      custom_executor_spec=executor_spec.ExecutorClassSpec(\n          ai_platform_trainer_executor.Executor),\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args={\'num_steps\': train_steps},\n      eval_args={\'num_steps\': eval_steps},\n      custom_config={\n          ai_platform_trainer_executor.TRAINING_ARGS_KEY:\n              local_training_args\n      })\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to  Google Cloud AI Platform if check passed.\n  pusher = Pusher(\n      custom_executor_spec=executor_spec.ExecutorClassSpec(\n          ai_platform_pusher_executor.Executor),\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      custom_config={\n          ai_platform_pusher_executor.SERVING_ARGS_KEY: ai_platform_serving_args\n      })\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, model_resolver, evaluator, pusher\n      ],\n      beam_pipeline_args=beam_pipeline_args,\n  )\n\n\ndef main(unused_argv):\n  # Metadata config. The defaults works work with the installation of\n  # KF Pipelines using Kubeflow. If installing KF Pipelines using the\n  # lightweight deployment option, you may need to override the defaults.\n  metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=metadata_config,\n      # Specify custom docker image to use.\n      tfx_image=tfx_image)\n\n  kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n      create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          module_file=_module_file,\n          ai_platform_training_args=_ai_platform_training_args,\n          ai_platform_serving_args=_ai_platform_serving_args,\n      ))\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_gcp_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_kubeflow_gcp.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_kubeflow_gcp\nfrom tfx.orchestration.kubeflow.kubeflow_dag_runner import KubeflowDagRunner\n\n\nclass TaxiPipelineKubeflowTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineKubeflowTest, self).setUp()\n    self._tmp_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\',\n                                   self.get_temp_dir())\n    self._olddir = os.getcwd()\n    os.chdir(self._tmp_dir)\n\n  def tearDown(self):\n    super(TaxiPipelineKubeflowTest, self).tearDown()\n    os.chdir(self._olddir)\n\n  def testTaxiPipelineConstructionAndDefinitionFileExists(self):\n    logical_pipeline = taxi_pipeline_kubeflow_gcp.create_pipeline(\n        pipeline_name=taxi_pipeline_kubeflow_gcp._pipeline_name,\n        pipeline_root=taxi_pipeline_kubeflow_gcp._pipeline_root,\n        module_file=taxi_pipeline_kubeflow_gcp._module_file,\n        ai_platform_training_args=taxi_pipeline_kubeflow_gcp\n        ._ai_platform_training_args,\n        ai_platform_serving_args=taxi_pipeline_kubeflow_gcp\n        ._ai_platform_serving_args)\n    self.assertEqual(9, len(logical_pipeline.components))\n\n    KubeflowDagRunner().run(logical_pipeline)\n    file_path = os.path.join(self._tmp_dir,\n                             \'chicago_taxi_pipeline_kubeflow_gcp.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_local.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago Taxi example using TFX DSL on Kubeflow (runs locally on cluster).""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nfrom kfp import onprem\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import InfraValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_pipeline_kubeflow_local\'\n\n# This sample assumes a persistent volume (PV) is mounted as follows. To use\n# InfraValidator with PVC, its access mode should be ReadWriteMany.\n_persistent_volume_claim = \'my-pvc\'\n_persistent_volume = \'my-pv\'\n_persistent_volume_mount = \'/mnt\'\n\n# All input and output data are kept in the PV.\n_input_base = os.path.join(_persistent_volume_mount, \'tfx\')\n_output_base = os.path.join(_persistent_volume_mount, \'pipelines\')\n_tfx_root = os.path.join(_output_base, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, _pipeline_name)\n\n# Training data is assumed to be in ./data/simple/*.csv in the PV.\n_data_root = os.path.join(_input_base, \'data\', \'simple\')\n\n# Python module file to inject customized logic into the TFX components.\n# The Transform and Trainer both require user-defined functions to run\n# successfully. Copy taxi_utils.py to the PV in this directory.\n_module_file = os.path.join(_input_base, \'taxi_utils.py\')\n\n# Path which can be listened to by the model server.\n# Pusher will output the trained model here.\n_serving_model_dir = os.path.join(_output_base, _pipeline_name, \'serving_model\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX and Kubeflow Pipelines.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn\n  # to train a model on Google Cloud AI Platform.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000),\n  )\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Performs infra validation of a candidate model to prevent unservable model\n  # from being pushed. In order to use InfraValidator component, persistent\n  # volume and its claim that the pipeline is using should be a ReadWriteMany\n  # access mode.\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=example_gen.outputs[\'examples\'],\n      serving_spec=infra_validator_pb2.ServingSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n              tags=[\'latest\']),\n          kubernetes=infra_validator_pb2.KubernetesConfig()),\n      request_spec=infra_validator_pb2.RequestSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec())\n  )\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to  Google Cloud AI Platform if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      infra_blessing=infra_validator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          model_resolver,\n          evaluator,\n          infra_validator,\n          pusher,\n      ],\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\nif __name__ == \'__main__\':\n  # Metadata config. The defaults works work with the installation of\n  # KF Pipelines using Kubeflow. If installing KF Pipelines using the\n  # lightweight deployment option, you may need to override the defaults.\n  metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=metadata_config,\n      # Specify custom docker image to use.\n      tfx_image=tfx_image,\n      pipeline_operator_funcs=(\n          # If running on K8s Engine (GKE) on Google Cloud Platform (GCP),\n          # kubeflow_dag_runner.get_default_pipeline_operator_funcs() provides\n          # default configurations specifically for GKE on GCP, such as secrets.\n          [\n              onprem.mount_pvc(_persistent_volume_claim, _persistent_volume,\n                               _persistent_volume_mount)\n          ]))\n\n  kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_local_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_kubeflow_local.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_kubeflow_local\nfrom tfx.orchestration.kubeflow.kubeflow_dag_runner import KubeflowDagRunner\n\n\nclass TaxiPipelineKubeflowTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineKubeflowTest, self).setUp()\n    self._tmp_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\',\n                                   self.get_temp_dir())\n    self._olddir = os.getcwd()\n    os.chdir(self._tmp_dir)\n\n  def tearDown(self):\n    super(TaxiPipelineKubeflowTest, self).tearDown()\n    os.chdir(self._olddir)\n\n  def testTaxiPipelineConstructionAndDefinitionFileExists(self):\n    logical_pipeline = taxi_pipeline_kubeflow_local._create_pipeline(\n        pipeline_name=taxi_pipeline_kubeflow_local._pipeline_name,\n        pipeline_root=taxi_pipeline_kubeflow_local._pipeline_root,\n        data_root=taxi_pipeline_kubeflow_local._data_root,\n        module_file=taxi_pipeline_kubeflow_local._module_file,\n        serving_model_dir=taxi_pipeline_kubeflow_local._serving_model_dir,\n        direct_num_workers=1)\n    self.assertEqual(10, len(logical_pipeline.components))\n\n    KubeflowDagRunner().run(logical_pipeline)\n    file_path = os.path.join(self._tmp_dir,\n                             \'chicago_taxi_pipeline_kubeflow_local.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_native_keras.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_native_keras\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'big_tipper_label\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils_native_keras.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=transform.outputs[\'transformed_examples\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      schema=schema_gen.outputs[\'schema\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'big_tipper\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'BinaryAccuracy\',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': 0.6}),\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={\'value\': -1e-10})))\n          ])\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          model_resolver,\n          evaluator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_native_keras.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          metadata_path=_metadata_path,\n          serving_model_dir=_serving_model_dir,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_native_keras_e2e_test.py,8,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_native_keras.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_native_keras\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineNativeKerasEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineNativeKerasEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'native_keras_test\'\n    self._data_root = os.path.join(\n        os.path.dirname(__file__), \'data\', \'big_tipper_label\')\n    self._module_file = os.path.join(\n        os.path.dirname(__file__), \'taxi_utils_native_keras.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testTaxiPipelineNativeKeras(self):\n    BeamDagRunner().run(\n        taxi_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    expected_execution_count = 9  # 8 components + 1 resolver\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(expected_execution_count, execution_count)\n\n    self.assertPipelineExecution()\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(\n        taxi_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # All executions but Evaluator and Pusher are cached.\n    # Note that Resolver will always execute.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      self.assertEqual(expected_execution_count * 2,\n                       len(m.store.get_executions()))\n\n    # Runs pipeline the third time.\n    BeamDagRunner().run(\n        taxi_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      self.assertEqual(expected_execution_count * 3,\n                       len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_v2_behavior()\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_portable_beam.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport multiprocessing\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n\n_pipeline_name = \'chicago_taxi_portable_beam\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     worker_parallelism: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, model_resolver, evaluator, pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # LINT.IfChange\n      beam_pipeline_args=[\n          # -------------------------- Beam Args --------------------------.\n          \'--runner=PortableRunner\',\n\n          # Points to the job server started in\n          # setup_beam_on_{flink, spark}.sh\n          \'--job_endpoint=localhost:8099\',\n          \'--environment_type=LOOPBACK\',\n          \'--sdk_worker_parallelism=%d\' % worker_parallelism,\n          \'--experiments=use_loopback_process_worker=True\',\n\n          # Setting environment_cache_millis to practically infinity enables\n          # continual reuse of Beam SDK workers, improving performance.\n          \'--environment_cache_millis=1000000\',\n\n          # TODO(BEAM-7199): Obviate the need for setting pre_optimize=all.  # pylint: disable=g-bad-todo\n          \'--experiments=pre_optimize=all\',\n\n          # Note; We use 100 worker threads to mitigate the issue with\n          # scheduling work between the Beam runner and SDK harness. Flink\n          # and Spark can process unlimited work items concurrently while\n          # SdkHarness can only process 1 work item per worker thread.\n          # Having 100 threads will let 100 tasks execute concurrently\n          # avoiding scheduling issue in most cases. In case the threads are\n          # exhausted, beam prints the relevant message in the log.\n          # TODO(BEAM-8151) Remove worker_threads=100 after we start using a  # pylint: disable=g-bad-todo\n          # virtually unlimited thread pool by default.\n          \'--experiments=worker_threads=100\',\n          # ---------------------- End of Beam Args -----------------------.\n\n          # --------- Flink runner Args (ignored by Spark runner) ---------.\n          \'--parallelism=%d\' % worker_parallelism,\n\n          # TODO(FLINK-10672): Obviate setting BATCH_FORCED.  # pylint: disable=g-bad-todo\n          \'--execution_mode_for_batch=BATCH_FORCED\',\n          # ------------------ End of Flink runner Args -------------------.\n      ],\n      # LINT.ThenChange(setup/setup_beam_on_spark.sh)\n      # LINT.ThenChange(setup/setup_beam_on_flink.sh)\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_portable_beam.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  # LINT.IfChange\n  try:\n    parallelism = multiprocessing.cpu_count()\n  except NotImplementedError:\n    parallelism = 1\n  absl.logging.info(\'Using %d process(es) for Beam pipeline execution.\' %\n                    parallelism)\n  # LINT.ThenChange(setup/setup_beam_on_flink.sh)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          worker_parallelism=parallelism))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_portable_beam_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_portable_beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_portable_beam\n\n\nclass TaxiPipelinePortableBeamTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelinePortableBeamTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n  def testTaxiPipelineCheckDagConstruction(self):\n    logical_pipeline = taxi_pipeline_portable_beam._create_pipeline(\n        pipeline_name=\'Test\',\n        pipeline_root=self._test_dir,\n        data_root=self._test_dir,\n        module_file=self._test_dir,\n        serving_model_dir=self._test_dir,\n        metadata_path=self._test_dir,\n        worker_parallelism=1)\n    self.assertEqual(9, len(logical_pipeline.components))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_runtime_parameter.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago Taxi example demonstrating the usage of RuntimeParameter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Optional, Text\n\nimport kfp\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.proto import pusher_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'taxi_pipeline_with_parameters\'\n\n# Path of pipeline root, should be a GCS path.\n_pipeline_root = os.path.join(\'gs://my-bucket\', \'tfx_taxi_simple\',\n                              kfp.dsl.RUN_ID_PLACEHOLDER)\n\n\ndef _create_parameterized_pipeline(\n    pipeline_name: Text,\n    pipeline_root: Optional[Text] = _pipeline_root,\n    enable_cache: Optional[bool] = True,\n    direct_num_workers: Optional[int] = 1) -> pipeline.Pipeline:\n  """"""Creates a simple TFX pipeline with RuntimeParameter.\n\n  Args:\n    pipeline_name: The name of the pipeline.\n    pipeline_root: The root of the pipeline output.\n    enable_cache: Whether to enable cache in this pipeline.\n    direct_num_workers: Number of workers executing the underlying beam pipeline\n      in the executors.\n\n  Returns:\n    A logical TFX pipeline.Pipeline object.\n  """"""\n  # First, define the pipeline parameters.\n  # Path to the CSV data file, under which there should be a data.csv file.\n  data_root = data_types.RuntimeParameter(\n      name=\'data-root\',\n      default=\'gs://my-bucket/data\',\n      ptype=Text,\n  )\n\n  # Path to the transform module file.\n  transform_module_file = data_types.RuntimeParameter(\n      name=\'transform-module\',\n      default=\'gs://my-bucket/modules/transform_module.py\',\n      ptype=Text,\n  )\n\n  # Path to the trainer module file.\n  trainer_module_file = data_types.RuntimeParameter(\n      name=\'trainer-module\',\n      default=\'gs://my-bucket/modules/trainer_module.py\',\n      ptype=Text,\n  )\n\n  # Number of epochs in training.\n  train_steps = data_types.RuntimeParameter(\n      name=\'train-steps\',\n      default=10,\n      ptype=int,\n  )\n\n  # Number of epochs in evaluation.\n  eval_steps = data_types.RuntimeParameter(\n      name=\'eval-steps\',\n      default=5,\n      ptype=int,\n  )\n\n  # The input data location is parameterized by data_root\n  examples = external_input(data_root)\n  example_gen = CsvExampleGen(input=examples)\n\n  statistics_gen = StatisticsGen(input_data=example_gen.outputs[\'examples\'])\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # The module file used in Transform and Trainer component is paramterized by\n  # transform_module_file.\n  transform = Transform(\n      input_data=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=transform_module_file)\n\n  # The numbers of steps in train_args are specified as RuntimeParameter with\n  # name \'train-steps\' and \'eval-steps\', respectively.\n  trainer = Trainer(\n      module_file=trainer_module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_output=transform.outputs[\'transform_graph\'],\n      train_args={\'num_steps\': train_steps},\n      eval_args={\'num_steps\': eval_steps})\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  pusher = Pusher(\n      model_export=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=os.path.join(\n                  str(pipeline.ROOT_PARAMETER), \'model_serving\'))))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, model_resolver, evaluator, pusher\n      ],\n      enable_cache=enable_cache,\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\nif __name__ == \'__main__\':\n  _enable_cache = True\n  pipeline = _create_parameterized_pipeline(\n      _pipeline_name, _pipeline_root, enable_cache=_enable_cache)\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=kubeflow_dag_runner\n      .get_default_kubeflow_metadata_config(),\n      tfx_image=tfx_image)\n  kfp_runner = kubeflow_dag_runner.KubeflowDagRunner(config=config)\n\n  kfp_runner.run(pipeline)\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_runtime_parameter_e2e_test.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""End-to-end tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_runtime_parameter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_runtime_parameter\nfrom tfx.orchestration import test_utils\nfrom tfx.orchestration.kubeflow import test_utils as kubeflow_test_utils\n\n\nclass TaxiPipelineRuntimeParameterEndToEndTest(\n    kubeflow_test_utils.BaseKubeflowTest):\n\n  def testEndToEndPipelineRun(self):\n    """"""End-to-end test for pipeline with RuntimeParameter.""""""\n    pipeline_name = \'kubeflow-e2e-test-parameter-{}\'.format(\n        test_utils.random_id())\n    pipeline = taxi_pipeline_runtime_parameter._create_parameterized_pipeline(\n        pipeline_name=pipeline_name, direct_num_workers=4)\n\n    parameters = {\n        \'pipeline-root\': self._pipeline_root(pipeline_name),\n        \'transform-module\': self._transform_module,\n        \'trainer-module\': self._trainer_module,\n        \'data-root\': self._data_root,\n        \'train-steps\': 10,\n        \'eval-steps\': 5,\n        \'slicing-column\': \'trip_start_hour\',\n    }\n\n    self._compile_and_run_pipeline(pipeline=pipeline, parameters=parameters)\n\n\nif __name__ == \'__main__\':\n  logging.set_verbosity(logging.INFO)\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom typing import Text\nimport tensorflow_model_analysis as tfma\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n# TODO(jyzhao): rename to chicago_taxi_airflow.\n_pipeline_name = \'chicago_taxi_simple\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, model_resolver, evaluator, pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# \'DAG\' below need to be kept for Airflow to detect dag.\nDAG = AirflowDagRunner(AirflowPipelineConfig(_airflow_config)).run(\n    _create_pipeline(\n        pipeline_name=_pipeline_name,\n        pipeline_root=_pipeline_root,\n        data_root=_data_root,\n        module_file=_module_file,\n        serving_model_dir=_serving_model_dir,\n        metadata_path=_metadata_path,\n        # 0 means auto-detect based on the number of CPUs available during\n        # execution time.\n        direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple_airflow_e2e_test.py,8,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""End to end test for tfx.orchestration.airflow.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\nimport tempfile\nimport time\nfrom typing import Sequence, Set, Text\n\nimport absl\nimport tensorflow as tf\n\nfrom tfx.orchestration.airflow import test_utils as airflow_test_utils\nfrom tfx.tools.cli.e2e import test_utils\nfrom tfx.utils import io_utils\n\n\nclass AirflowSubprocess(object):\n  """"""Launch an Airflow command.""""""\n\n  def __init__(self, airflow_args):\n    self._args = [\'airflow\'] + airflow_args\n    self._sub_process = None\n\n  def __enter__(self):\n    self._sub_process = subprocess.Popen(self._args)\n    return self\n\n  def __exit__(self, exception_type, exception_value, traceback):  # pylint: disable=unused-argument\n    if self._sub_process:\n      self._sub_process.terminate()\n\n\n# Number of seconds between polling pending task states.\n_TASK_POLLING_INTERVAL_SEC = 10\n# Maximum duration to allow no task state change.\n_MAX_TASK_STATE_CHANGE_SEC = 120\n\n# Any task state not listed as success or pending will be considered as failure.\n_SUCCESS_TASK_STATES = set([\'success\'])\n_PENDING_TASK_STATES = set([\'queued\', \'scheduled\', \'running\', \'none\'])\n\n\nclass AirflowEndToEndTest(tf.test.TestCase):\n  """"""An end to end test using fully orchestrated Airflow.""""""\n\n  def _GetState(self, task_name: Text) -> Text:\n    """"""Get a task state as a string.""""""\n    try:\n      output = subprocess.check_output([\n          \'airflow\', \'task_state\', self._dag_id, task_name, self._execution_date\n      ]).split()\n      # Some logs are emitted to stdout, so we take the last word as state.\n      return tf.compat.as_str(output[-1])\n    except subprocess.CalledProcessError:\n      # For multi-processing, state checking might fail because database lock\n      # has not been released. \'none\' will be treated as a pending state, so\n      # this state checking will be retried later.\n      return \'none\'\n\n  # TODO(b/130882241): Add validation on output artifact type and content.\n  def _CheckOutputArtifacts(self, task: Text) -> None:\n    pass\n\n  def _PrintTaskLogsOnError(self, task):\n    task_log_dir = os.path.join(self._airflow_home, \'logs\',\n                                \'%s.%s\' % (self._dag_id, task))\n    for dir_name, _, leaf_files in tf.io.gfile.walk(task_log_dir):\n      for leaf_file in leaf_files:\n        leaf_file_path = os.path.join(dir_name, leaf_file)\n        absl.logging.error(\'Print task log %s:\', leaf_file_path)\n        with tf.io.gfile.GFile(leaf_file_path, \'r\') as f:\n          lines = f.readlines()\n          for line in lines:\n            absl.logging.error(line)\n\n  def _CheckPendingTasks(self, pending_task_names: Sequence[Text]) -> Set[Text]:\n    unknown_tasks = set(pending_task_names) - set(self._all_tasks)\n    assert not unknown_tasks, \'Unknown task name {}\'.format(unknown_tasks)\n    still_pending = set()\n    failed = dict()\n    for task in pending_task_names:\n      task_state = self._GetState(task).lower()\n      if task_state in _SUCCESS_TASK_STATES:\n        absl.logging.info(\'Task %s succeeded, checking output artifacts\', task)\n        self._CheckOutputArtifacts(task)\n      elif task_state in _PENDING_TASK_STATES:\n        still_pending.add(task)\n      else:\n        failed[task] = task_state\n    for task, state in failed.items():\n      absl.logging.error(\'Retrieving logs for %s task %s\', state, task)\n      self._PrintTaskLogsOnError(task)\n    self.assertFalse(failed)\n    return still_pending\n\n  def setUp(self):\n    super(AirflowEndToEndTest, self).setUp()\n    # setup airflow_home in a temp directory, config and init db.\n    self._airflow_home = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', tempfile.mkdtemp()),\n        self._testMethodName)\n    self._old_airflow_home = os.environ.get(\'AIRFLOW_HOME\')\n    os.environ[\'AIRFLOW_HOME\'] = self._airflow_home\n    self._old_home = os.environ.get(\'HOME\')\n    os.environ[\'HOME\'] = self._airflow_home\n    absl.logging.info(\'Using %s as AIRFLOW_HOME and HOME in this e2e test\',\n                      self._airflow_home)\n\n    self._mysql_container_name = \'airflow_\' + test_utils.generate_random_id()\n    db_port = airflow_test_utils.create_mysql_container(\n        self._mysql_container_name)\n    self.addCleanup(airflow_test_utils.delete_mysql_container,\n                    self._mysql_container_name)\n    os.environ[\'AIRFLOW__CORE__SQL_ALCHEMY_CONN\'] = (\n        \'mysql://tfx@127.0.0.1:%d/airflow\' % db_port)\n\n    # Set a couple of important environment variables. See\n    # https://airflow.apache.org/howto/set-config.html for details.\n    os.environ[\'AIRFLOW__CORE__DAGS_FOLDER\'] = os.path.join(\n        self._airflow_home, \'dags\')\n    os.environ[\'AIRFLOW__CORE__BASE_LOG_FOLDER\'] = os.path.join(\n        self._airflow_home, \'logs\')\n    # Do not load examples to make this a bit faster.\n    os.environ[\'AIRFLOW__CORE__LOAD_EXAMPLES\'] = \'False\'\n    # Following environment variables make scheduler process dags faster.\n    os.environ[\'AIRFLOW__SCHEDULER__JOB_HEARTBEAT_SEC\'] = \'1\'\n    os.environ[\'AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC\'] = \'1\'\n    os.environ[\'AIRFLOW__SCHEDULER__RUN_DURATION\'] = \'-1\'\n    os.environ[\'AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL\'] = \'1\'\n    os.environ[\'AIRFLOW__SCHEDULER__PRINT_STATS_INTERVAL\'] = \'30\'\n\n    # Following fields are specific to the chicago_taxi_simple example.\n    self._dag_id = \'chicago_taxi_simple\'\n    self._run_id = \'manual_run_id_1\'\n    # This execution date must be after the start_date in chicago_taxi_simple\n    # but before current execution date.\n    self._execution_date = \'2019-02-01T01:01:01\'\n    self._all_tasks = [\n        \'CsvExampleGen\',\n        \'Evaluator\',\n        \'ExampleValidator\',\n        \'Pusher\',\n        \'SchemaGen\',\n        \'StatisticsGen\',\n        \'Trainer\',\n        \'Transform\',\n    ]\n    # Copy dag file and data.\n    chicago_taxi_pipeline_dir = os.path.dirname(__file__)\n    simple_pipeline_file = os.path.join(chicago_taxi_pipeline_dir,\n                                        \'taxi_pipeline_simple.py\')\n\n    io_utils.copy_file(\n        simple_pipeline_file,\n        os.path.join(self._airflow_home, \'dags\', \'taxi_pipeline_simple.py\'))\n\n    data_dir = os.path.join(chicago_taxi_pipeline_dir, \'data\', \'simple\')\n    content = tf.io.gfile.listdir(data_dir)\n    assert content, \'content in {} is empty\'.format(data_dir)\n    target_data_dir = os.path.join(self._airflow_home, \'taxi\', \'data\', \'simple\')\n    io_utils.copy_dir(data_dir, target_data_dir)\n    assert tf.io.gfile.isdir(target_data_dir)\n    content = tf.io.gfile.listdir(target_data_dir)\n    assert content, \'content in {} is {}\'.format(target_data_dir, content)\n    io_utils.copy_file(\n        os.path.join(chicago_taxi_pipeline_dir, \'taxi_utils.py\'),\n        os.path.join(self._airflow_home, \'taxi\', \'taxi_utils.py\'))\n\n    # Initialize database.\n    subprocess.run([\'airflow\', \'initdb\'], check=True)\n    subprocess.run([\'airflow\', \'unpause\', self._dag_id], check=True)\n\n  def testSimplePipeline(self):\n    subprocess.run([\n        \'airflow\',\n        \'trigger_dag\',\n        self._dag_id,\n        \'-r\',\n        self._run_id,\n        \'-e\',\n        self._execution_date,\n    ],\n                   check=True)\n    absl.logging.info(\'Dag triggered: %s\', self._dag_id)\n    # We will use subprocess to start the DAG instead of webserver, so only\n    # need to start a scheduler on the background.\n    # Airflow scheduler should be launched after triggering the dag to mitigate\n    # a possible race condition between trigger_dag and scheduler.\n    with AirflowSubprocess([\'scheduler\']):\n      pending_tasks = set(self._all_tasks)\n      attempts = int(\n          _MAX_TASK_STATE_CHANGE_SEC / _TASK_POLLING_INTERVAL_SEC) + 1\n      while True:\n        if not pending_tasks:\n          absl.logging.info(\'No pending task left anymore\')\n          return\n        for _ in range(attempts):\n          absl.logging.debug(\'Polling task state\')\n          still_pending = self._CheckPendingTasks(pending_tasks)\n          if len(still_pending) != len(pending_tasks):\n            pending_tasks = still_pending\n            break\n          absl.logging.info(\'Polling task state after %d secs\',\n                            _TASK_POLLING_INTERVAL_SEC)\n          time.sleep(_TASK_POLLING_INTERVAL_SEC)\n        else:\n          self.fail(\'No pending tasks in %s finished within %d secs\' %\n                    (pending_tasks, _MAX_TASK_STATE_CHANGE_SEC))\n\n  def tearDown(self):\n    super(AirflowEndToEndTest, self).tearDown()\n    if self._old_airflow_home:\n      os.environ[\'AIRFLOW_HOME\'] = self._old_airflow_home\n    if self._old_home:\n      os.environ[\'HOME\'] = self._old_home\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_simple_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_simple.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom airflow import models\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_simple\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig\n\n\nclass TaxiPipelineSimpleTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineSimpleTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n  def testTaxiPipelineCheckDagConstruction(self):\n    airflow_config = {\n        \'schedule_interval\': None,\n        \'start_date\': datetime.datetime(2019, 1, 1),\n    }\n    logical_pipeline = taxi_pipeline_simple._create_pipeline(\n        pipeline_name=\'Test\',\n        pipeline_root=self._test_dir,\n        data_root=self._test_dir,\n        module_file=self._test_dir,\n        serving_model_dir=self._test_dir,\n        metadata_path=self._test_dir,\n        direct_num_workers=1)\n    self.assertEqual(9, len(logical_pipeline.components))\n    pipeline = AirflowDagRunner(\n        AirflowPipelineConfig(airflow_config)).run(logical_pipeline)\n    self.assertIsInstance(pipeline, models.DAG)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_warmstart.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_artifacts_resolver\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_warmstart\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Get the latest model so that we can warm start from the model.\n  latest_model_resolver = ResolverNode(\n      instance_name=\'latest_model_resolver\',\n      resolver_class=latest_artifacts_resolver.LatestArtifactsResolver,\n      latest_model=Channel(type=Model))\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      base_model=latest_model_resolver.outputs[\'latest_model\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          latest_model_resolver, trainer, model_resolver, evaluator, pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_warmstart.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_warmstart_e2e_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_warmstart.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_warmstart\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineWarmstartEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineWarmstartEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'beam_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\', \'simple\')\n    self._module_file = os.path.join(os.path.dirname(__file__), \'taxi_utils.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecuted(self, component: Text, execution_count: int) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(execution_count, len(execution))\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    self.assertExecuted(component, 1)\n\n  def assertExecutedTwice(self, component: Text) -> None:\n    self.assertExecuted(component, 2)\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testTaxiPipelineWarmstart(self):\n    BeamDagRunner().run(\n        taxi_pipeline_warmstart._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(10, execution_count)\n\n    self.assertPipelineExecution()\n\n    # Run pipeline again.\n    BeamDagRunner().run(\n        taxi_pipeline_warmstart._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    with metadata.Metadata(metadata_config) as m:\n      # 10 more executions.\n      self.assertEqual(20, len(m.store.get_executions()))\n\n    # Two trainer outputs.\n    self.assertExecutedTwice(\'Trainer\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_with_inference.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example pipeline for training and offline inference.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import BulkInferrer\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.proto import example_gen_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_with_inference\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_training_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n_inference_data_root = os.path.join(_taxi_root, \'data\', \'unlabelled\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text,\n                     training_data_root: Text, inference_data_root: Text,\n                     module_file: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  training_examples = external_input(training_data_root)\n\n  # Brings training data into the pipeline or otherwise joins/converts\n  # training data.\n  training_example_gen = CsvExampleGen(\n      input_base=training_examples, instance_name=\'training_example_gen\')\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(\n      input_data=training_example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=training_example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=training_example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  inference_examples = external_input(inference_data_root)\n\n  # Brings inference data into the pipeline.\n  inference_example_gen = CsvExampleGen(\n      input_base=inference_examples,\n      output_config=example_gen_pb2.Output(\n          split_config=example_gen_pb2.SplitConfig(\n              splits=[example_gen_pb2.SplitConfig.Split(\n                  name=\'unlabelled\', hash_buckets=100)])),\n      instance_name=\'inference_example_gen\')\n\n  # Performs offline batch inference over inference examples.\n  bulk_inferrer = BulkInferrer(\n      examples=inference_example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      # Empty data_spec.example_splits will result in using all splits.\n      data_spec=bulk_inferrer_pb2.DataSpec(),\n      model_spec=bulk_inferrer_pb2.ModelSpec())\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          training_example_gen, inference_example_gen, statistics_gen,\n          schema_gen, example_validator, transform, trainer, model_resolver,\n          evaluator, bulk_inferrer\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_with_inference.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          training_data_root=_training_data_root,\n          inference_data_root=_inference_data_root,\n          module_file=_module_file,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_pipeline_with_inference_test.py,1,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_pipeline_with_inference.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_with_inference\n\n\nclass TaxiPipelineWithInferenceTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineWithInferenceTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n  def testTaxiPipelineCheckDagConstruction(self):\n    logical_pipeline = taxi_pipeline_with_inference._create_pipeline(\n        pipeline_name=\'Test\',\n        pipeline_root=self._test_dir,\n        data_root=self._test_dir,\n        module_file=self._test_dir,\n        serving_model_dir=self._test_dir,\n        metadata_path=self._test_dir,\n        direct_num_workers=1)\n    self.assertEqual(9, len(logical_pipeline.components))\n'"
tfx/examples/chicago_taxi_pipeline/taxi_utils.py,30,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nFor a TFX pipeline to successfully run, a preprocessing_fn and a\ntrainer_fn function needs to be provided. This file contains both.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform.tf_metadata import schema_utils\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(\n      filenames,\n      compression_type=\'GZIP\')\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.sparse.to_dense(\n          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n          default_value),\n      axis=1)\n\n\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n\n\ndef _build_estimator(config, hidden_units=None, warm_start_from=None):\n  """"""Build an estimator for predicting the tipping behavior of taxi riders.\n\n  Args:\n    config: tf.estimator.RunConfig defining the runtime environment for the\n      estimator (including model_dir).\n    hidden_units: [int], the layer sizes of the DNN (input layer first)\n    warm_start_from: Optional directory to warm start from.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  return tf.estimator.DNNLinearCombinedClassifier(\n      config=config,\n      linear_feature_columns=categorical_columns,\n      dnn_feature_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n      warm_start_from=warm_start_from)\n\n\ndef _example_serving_receiver_fn(tf_transform_output, schema):\n  """"""Build the serving in inputs.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    Tensorflow graph which parses examples, applying tf-transform to them.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  transformed_features = tf_transform_output.transform_raw_features(\n      serving_input_receiver.features)\n\n  return tf.estimator.export.ServingInputReceiver(\n      transformed_features, serving_input_receiver.receiver_tensors)\n\n\ndef _eval_input_receiver_fn(tf_transform_output, schema):\n  """"""Build everything needed for the tf-model-analysis to run the model.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Tensorflow graph which parses raw untransformed features, applies the\n        tf-transform preprocessing operators.\n      - Set of raw, untransformed features.\n      - Label against which predictions will be compared.\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  serialized_tf_example = tf.compat.v1.placeholder(\n      dtype=tf.string, shape=[None], name=\'input_example_tensor\')\n\n  # Add a parse_example operator to the tensorflow graph, which will parse\n  # raw, untransformed, tf examples.\n  features = tf.io.parse_example(\n      serialized=serialized_tf_example, features=raw_feature_spec)\n\n  # Now that we have our raw examples, process them through the tf-transform\n  # function computed during the preprocessing step.\n  transformed_features = tf_transform_output.transform_raw_features(\n      features)\n\n  # The key name MUST be \'examples\'.\n  receiver_tensors = {\'examples\': serialized_tf_example}\n\n  # NOTE: Model is driven by transformed features (since training works on the\n  # materialized output of TFT, but slicing will happen on raw features.\n  features.update(transformed_features)\n\n  return tfma.export.EvalInputReceiver(\n      features=features,\n      receiver_tensors=receiver_tensors,\n      labels=transformed_features[_transformed_name(_LABEL_KEY)])\n\n\ndef _input_fn(file_pattern: List[Text],\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_transformed_name(_LABEL_KEY))\n\n  return dataset\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  # Number of nodes in the first layer of the DNN\n  first_dnn_layer_size = 100\n  num_dnn_layers = 4\n  dnn_decay_factor = 0.7\n\n  train_batch_size = 40\n  eval_batch_size = 40\n\n  tf_transform_output = tft.TFTransformOutput(trainer_fn_args.transform_output)\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      tf_transform_output,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      tf_transform_output,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n      train_input_fn,\n      max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  exporter = tf.estimator.FinalExporter(\'chicago-taxi\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'chicago-taxi-eval\')\n\n  # Keep multiple checkpoint files for distributed training, note that\n  # keep_max_checkpoint should be greater or equal to the number of replicas to\n  # avoid race condition.\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=5)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n  warm_start_from = trainer_fn_args.base_model\n\n  estimator = _build_estimator(\n      # Construct layers sizes with exponetial decay\n      hidden_units=[\n          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n          for i in range(num_dnn_layers)\n      ],\n      config=run_config,\n      warm_start_from=warm_start_from)\n\n  # Create an input receiver for TFMA processing\n  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': receiver_fn\n  }\n'"
tfx/examples/chicago_taxi_pipeline/taxi_utils_native_keras.py,36,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nThe utilities in this file are used to build a model with native Keras.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'big_tipper\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(\n      filenames,\n      compression_type=\'GZIP\')\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  if isinstance(x, tf.sparse.SparseTensor):\n    default_value = \'\' if x.dtype == tf.string else 0\n    dense_tensor = tf.sparse.to_dense(\n        tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n        default_value)\n  else:\n    dense_tensor = x\n\n  return tf.squeeze(dense_tensor, axis=1)\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that parses a serialized tf.Example and applies TFT.""""""\n\n  model.tft_layer = tf_transform_output.transform_features_layer()\n\n  @tf.function\n  def serve_tf_examples_fn(serialized_tf_examples):\n    """"""Returns the output to be used in the serving signature.""""""\n    feature_spec = tf_transform_output.raw_feature_spec()\n    feature_spec.pop(_LABEL_KEY)\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    transformed_features = model.tft_layer(parsed_features)\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(_transformed_name(_LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\ndef _input_fn(file_pattern: List[Text],\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_transformed_name(_LABEL_KEY))\n\n  return dataset\n\n\ndef _build_keras_model(hidden_units: List[int] = None) -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying taxi data.\n\n  Args:\n    hidden_units: [int], the layer sizes of the DNN (input layer first).\n\n  Returns:\n    A keras Model.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  indicator_column = [\n      tf.feature_column.indicator_column(categorical_column)\n      for categorical_column in categorical_columns\n  ]\n\n  model = _wide_and_deep_classifier(\n      # TODO(b/139668410) replace with premade wide_and_deep keras model\n      wide_columns=indicator_column,\n      deep_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n  return model\n\n\ndef _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units):\n  """"""Build a simple keras wide and deep model.\n\n  Args:\n    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n      part of the model.\n    deep_columns: Feature columns for deep part of the model.\n    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n\n  Returns:\n    A Wide and Deep Keras model\n  """"""\n  # Following values are hard coded for simplicity in this example,\n  # However prefarably they should be passsed in as hparams.\n\n  # Keras needs the feature definitions at compile time.\n  # TODO(b/139081439): Automate generation of input layers from FeatureColumn.\n  input_layers = {\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n      for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  }\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_VOCAB_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_BUCKET_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_CATEGORICAL_FEATURE_KEYS)\n  })\n\n  # TODO(b/144500510): SparseFeatures for feature columns + Keras.\n  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n  for numnodes in dnn_hidden_units:\n    deep = tf.keras.layers.Dense(numnodes)(deep)\n  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n\n  output = tf.keras.layers.Dense(\n      1, activation=\'sigmoid\')(\n          tf.keras.layers.concatenate([deep, wide]))\n  output = tf.squeeze(output, -1)\n\n  model = tf.keras.Model(input_layers, output)\n  model.compile(\n      loss=\'binary_crossentropy\',\n      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n      metrics=[tf.keras.metrics.BinaryAccuracy()])\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]),\n        _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # TODO(b/157064428): Support label transformation for Keras.\n  # Do not apply label transformation as it will result in wrong evaluation.\n  outputs[_transformed_name(_LABEL_KEY)] = inputs[_LABEL_KEY]\n\n  return outputs\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  # Number of nodes in the first layer of the DNN\n  first_dnn_layer_size = 100\n  num_dnn_layers = 4\n  dnn_decay_factor = 0.7\n\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 40)\n  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 40)\n\n  mirrored_strategy = tf.distribute.MirroredStrategy()\n  with mirrored_strategy.scope():\n    model = _build_keras_model(\n        # Construct layers sizes with exponetial decay\n        hidden_units=[\n            max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n            for i in range(num_dnn_layers)\n        ])\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps)\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(model,\n                                    tf_transform_output).get_concrete_function(\n                                        tf.TensorSpec(\n                                            shape=[None],\n                                            dtype=tf.string,\n                                            name=\'examples\')),\n  }\n  model.save(fn_args.serving_model_dir, save_format=\'tf\', signatures=signatures)\n'"
tfx/examples/chicago_taxi_pipeline/taxi_utils_test.py,12,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.chicago_taxi_pipeline.taxi_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport types\n\nimport apache_beam as beam\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform import beam as tft_beam\nfrom tensorflow_transform.tf_metadata import dataset_metadata\nfrom tensorflow_transform.tf_metadata import dataset_schema\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer import executor as trainer_executor\nfrom tfx.examples.chicago_taxi_pipeline import taxi_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\n\n\nclass TaxiUtilsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiUtilsTest, self).setUp()\n    self._testdata_path = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))),\n        \'components/testdata\')\n\n  def testUtils(self):\n    key = \'fare\'\n    xfm_key = taxi_utils._transformed_name(key)\n    self.assertEqual(xfm_key, \'fare_xf\')\n\n  def testPreprocessingFn(self):\n    schema_file = os.path.join(self._testdata_path, \'schema_gen/schema.pbtxt\')\n    schema = io_utils.parse_pbtxt_file(schema_file, schema_pb2.Schema())\n    feature_spec = taxi_utils._get_raw_feature_spec(schema)\n    working_dir = self.get_temp_dir()\n    transform_graph_path = os.path.join(working_dir, \'transform_graph\')\n    transformed_examples_path = os.path.join(\n        working_dir, \'transformed_examples\')\n\n    # Run very simplified version of executor logic.\n    # TODO(kestert): Replace with tft_unit.assertAnalyzeAndTransformResults.\n    # Generate legacy `DatasetMetadata` object.  Future version of Transform\n    # will accept the `Schema` proto directly.\n    legacy_metadata = dataset_metadata.DatasetMetadata(\n        dataset_schema.from_feature_spec(feature_spec))\n    decoder = tft.coders.ExampleProtoCoder(legacy_metadata.schema)\n    with beam.Pipeline() as p:\n      with tft_beam.Context(temp_dir=os.path.join(working_dir, \'tmp\')):\n        examples = (\n            p\n            | \'ReadTrainData\' >> beam.io.ReadFromTFRecord(\n                os.path.join(self._testdata_path, \'csv_example_gen/train/*\'),\n                coder=beam.coders.BytesCoder(),\n                # TODO(b/114938612): Eventually remove this override.\n                validate=False)\n            | \'DecodeTrainData\' >> beam.Map(decoder.decode))\n        (transformed_examples, transformed_metadata), transform_fn = (\n            (examples, legacy_metadata)\n            | \'AnalyzeAndTransform\' >> tft_beam.AnalyzeAndTransformDataset(\n                taxi_utils.preprocessing_fn))\n\n        # WriteTransformFn writes transform_fn and metadata to subdirectories\n        # tensorflow_transform.SAVED_MODEL_DIR and\n        # tensorflow_transform.TRANSFORMED_METADATA_DIR respectively.\n        # pylint: disable=expression-not-assigned\n        (transform_fn\n         |\n         \'WriteTransformFn\' >> tft_beam.WriteTransformFn(transform_graph_path))\n\n        encoder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\n        (transformed_examples\n         | \'EncodeTrainData\' >> beam.Map(encoder.encode)\n         | \'WriteTrainData\' >> beam.io.WriteToTFRecord(\n             os.path.join(transformed_examples_path,\n                          \'train/transformed_examples.gz\'),\n             coder=beam.coders.BytesCoder()))\n        # pylint: enable=expression-not-assigned\n\n    # Verify the output matches golden output.\n    # NOTE: we don\'t verify that transformed examples match golden output.\n    expected_transformed_schema = io_utils.parse_pbtxt_file(\n        os.path.join(\n            self._testdata_path,\n            \'transform/transform_graph/transformed_metadata/schema.pbtxt\'),\n        schema_pb2.Schema())\n    transformed_schema = io_utils.parse_pbtxt_file(\n        os.path.join(transform_graph_path, \'transformed_metadata/schema.pbtxt\'),\n        schema_pb2.Schema())\n    # Clear annotations so we only have to test main schema.\n    transformed_schema.ClearField(\'annotation\')\n    for feature in transformed_schema.feature:\n      feature.ClearField(\'annotation\')\n    self.assertEqual(transformed_schema, expected_transformed_schema)\n\n  def testTrainerFn(self):\n    temp_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    schema_file = os.path.join(self._testdata_path, \'schema_gen/schema.pbtxt\')\n    output_dir = os.path.join(temp_dir, \'output_dir\')\n    trainer_fn_args = trainer_executor.TrainerFnArgs(\n        train_files=os.path.join(self._testdata_path,\n                                 \'transform/transformed_examples/train/*.gz\'),\n        transform_output=os.path.join(self._testdata_path,\n                                      \'transform/transform_graph\'),\n        output_dir=output_dir,\n        serving_model_dir=os.path.join(temp_dir, \'serving_model_dir\'),\n        eval_files=os.path.join(self._testdata_path,\n                                \'transform/transformed_examples/eval/*.gz\'),\n        schema_file=schema_file,\n        train_steps=1,\n        eval_steps=1,\n        verbosity=\'INFO\',\n        base_model=None)\n    schema = io_utils.parse_pbtxt_file(schema_file, schema_pb2.Schema())\n    training_spec = taxi_utils.trainer_fn(trainer_fn_args, schema)\n\n    estimator = training_spec[\'estimator\']\n    train_spec = training_spec[\'train_spec\']\n    eval_spec = training_spec[\'eval_spec\']\n    eval_input_receiver_fn = training_spec[\'eval_input_receiver_fn\']\n\n    self.assertIsInstance(estimator,\n                          tf.estimator.DNNLinearCombinedClassifier)\n    self.assertIsInstance(train_spec, tf.estimator.TrainSpec)\n    self.assertIsInstance(eval_spec, tf.estimator.EvalSpec)\n    self.assertIsInstance(eval_input_receiver_fn, types.FunctionType)\n\n    # Test keep_max_checkpoint in RunConfig\n    self.assertGreater(estimator._config.keep_checkpoint_max, 1)\n\n    # Train for one step, then eval for one step.\n    eval_result, exports = tf.estimator.train_and_evaluate(\n        estimator, train_spec, eval_spec)\n    self.assertGreater(eval_result[\'loss\'], 0.0)\n    self.assertEqual(len(exports), 1)\n    self.assertGreaterEqual(len(tf.io.gfile.listdir(exports[0])), 1)\n\n    # Export the eval saved model.\n    eval_savedmodel_path = tfma.export.export_eval_savedmodel(\n        estimator=estimator,\n        export_dir_base=path_utils.eval_model_dir(output_dir),\n        eval_input_receiver_fn=eval_input_receiver_fn)\n    self.assertGreaterEqual(len(tf.io.gfile.listdir(eval_savedmodel_path)), 1)\n\n    # Test exported serving graph.\n    with tf.compat.v1.Session() as sess:\n      metagraph_def = tf.compat.v1.saved_model.loader.load(\n          sess, [tf.saved_model.SERVING], exports[0])\n      self.assertIsInstance(metagraph_def, tf.compat.v1.MetaGraphDef)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/iris/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/iris/iris_pipeline_beam.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Iris flowers example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'iris\'\n\n# This example assumes that Iris flowers data is stored in ~/iris/data and the\n# utility function is in ~/iris. Feel free to customize as needed.\n_iris_root = os.path.join(os.environ[\'HOME\'], \'iris\')\n_data_root = os.path.join(_iris_root, \'data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_iris_root, \'iris_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_iris_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the flowers\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the Iris flowers pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      # GenericExecutor uses `run_fn`, while default estimator based executor\n      # uses `trainer_fn` instead.\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=2000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute an evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \'sparse_categorical_accuracy\':\n                      tfma.config.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          trainer,\n          model_resolver,\n          evaluator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python iris_pipeline_beam.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/iris/iris_pipeline_beam_e2e_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.iris.iris_pipeline_beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.iris import iris_pipeline_beam\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass IrisPipelineBeamEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(IrisPipelineBeamEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'beam_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\')\n    self._module_file = os.path.join(os.path.dirname(__file__), \'iris_utils.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n\n  def testIrisPipelineBeam(self):\n    BeamDagRunner().run(\n        iris_pipeline_beam._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(8, execution_count)  # 7 components + 1 resolver\n\n    self.assertPipelineExecution()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/iris/iris_pipeline_native_keras.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Iris flowers example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components import Tuner\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'iris_native_keras\'\n\n# This example assumes that Iris flowers data is stored in ~/iris/data and the\n# utility function is in ~/iris. Feel free to customize as needed.\n_iris_root = os.path.join(os.environ[\'HOME\'], \'iris\')\n_data_root = os.path.join(_iris_root, \'data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_iris_root, \'iris_utils_native_keras.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_iris_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the flowers\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text, enable_tuning: bool,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the Iris flowers pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Tunes the hyperparameters for model training based on user-provided Python\n  # function. Note that once the hyperparameters are tuned, you can drop the\n  # Tuner component from pipeline and feed Trainer with tuned hyperparameters.\n  if enable_tuning:\n    tuner = Tuner(\n        module_file=module_file,\n        examples=transform.outputs[\'transformed_examples\'],\n        transform_graph=transform.outputs[\'transform_graph\'],\n        train_args=trainer_pb2.TrainArgs(num_steps=20),\n        eval_args=trainer_pb2.EvalArgs(num_steps=5))\n\n  # Uses user-provided Python function that trains a model.\n  trainer = Trainer(\n      module_file=module_file,\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=transform.outputs[\'transformed_examples\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      schema=schema_gen.outputs[\'schema\'],\n      # If Tuner is in the pipeline, Trainer can take Tuner\'s output\n      # best_hyperparameters artifact as input and utilize it in the user module\n      # code.\n      #\n      # If there isn\'t Tuner in the pipeline, either use ImporterNode to import\n      # a previous Tuner\'s output to feed to Trainer, or directly use the tuned\n      # hyperparameters in user module code and set hyperparameters to None\n      # here.\n      #\n      # Example of ImporterNode,\n      #   hparams_importer = ImporterNode(\n      #     instance_name=\'import_hparams\',\n      #     source_uri=\'path/to/best_hyperparameters.txt\',\n      #     artifact_type=HyperParameters)\n      #   ...\n      #   hyperparameters = hparams_importer.outputs[\'result\'],\n      hyperparameters=(tuner.outputs[\'best_hyperparameters\']\n                       if enable_tuning else None),\n      train_args=trainer_pb2.TrainArgs(num_steps=100),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute an evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'variety\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'SparseCategoricalAccuracy\',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': 0.6}),\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={\'value\': -1e-10})))\n          ])\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  components = [\n      example_gen,\n      statistics_gen,\n      schema_gen,\n      example_validator,\n      transform,\n      trainer,\n      model_resolver,\n      evaluator,\n      pusher,\n  ]\n  if enable_tuning:\n    components.append(tuner)\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=components,\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python iris_pipeline_native_keras.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          enable_tuning=True,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/iris/iris_pipeline_native_keras_e2e_test.py,10,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.iris.iris_pipeline_native_keras.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.iris import iris_pipeline_native_keras\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass IrisPipelineNativeKerasEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(IrisPipelineNativeKerasEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'keras_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\')\n    self._module_file = os.path.join(\n        os.path.dirname(__file__), \'iris_utils_native_keras.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self, has_tuner: bool) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n    if has_tuner:\n      self.assertExecutedOnce(\'Tuner\')\n\n  def testIrisPipelineNativeKeras(self):\n    pipeline = iris_pipeline_native_keras._create_pipeline(\n        pipeline_name=self._pipeline_name,\n        data_root=self._data_root,\n        module_file=self._module_file,\n        serving_model_dir=self._serving_model_dir,\n        pipeline_root=self._pipeline_root,\n        metadata_path=self._metadata_path,\n        enable_tuning=False,\n        direct_num_workers=1)\n\n    BeamDagRunner().run(pipeline)\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    expected_execution_count = 9  # 8 components + 1 resolver\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(expected_execution_count, execution_count)\n\n    self.assertPipelineExecution(False)\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(pipeline)\n\n    # All executions but Evaluator and Pusher are cached.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      self.assertEqual(expected_execution_count * 2,\n                       len(m.store.get_executions()))\n\n    # Runs pipeline the third time.\n    BeamDagRunner().run(pipeline)\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      self.assertEqual(expected_execution_count * 3,\n                       len(m.store.get_executions()))\n\n  def testIrisPipelineNativeKerasWithTuner(self):\n    BeamDagRunner().run(\n        iris_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            enable_tuning=True,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    expected_execution_count = 10  # 9 components + 1 resolver\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(expected_execution_count, execution_count)\n\n    self.assertPipelineExecution(True)\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_v2_behavior()\n  tf.test.main()\n'"
tfx/examples/iris/iris_pipeline_native_keras_infraval.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Iris flowers example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import InfraValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'iris_native_keras_infraval\'\n\n# This example assumes that Iris flowers data is stored in ~/iris/data and the\n# utility function is in ~/iris. Feel free to customize as needed.\n_iris_root = os.path.join(os.environ[\'HOME\'], \'iris\')\n_data_root = os.path.join(_iris_root, \'data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_iris_root, \'iris_utils_native_keras.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_iris_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the flowers\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the Iris flowers pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that trains a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=transform.outputs[\'transformed_examples\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      schema=schema_gen.outputs[\'schema\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=2000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute an evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'variety\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'SparseCategoricalAccuracy\',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': 0.6}),\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={\'value\': -1e-10})))\n          ])\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Performs infra validation of a candidate model to prevent unservable model\n  # from being pushed. This config will launch a model server of the latest\n  # TensorFlow Serving image in a local docker engine.\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=example_gen.outputs[\'examples\'],\n      serving_spec=infra_validator_pb2.ServingSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n              tags=[\'latest\']),\n          local_docker=infra_validator_pb2.LocalDockerConfig()),\n      request_spec=infra_validator_pb2.RequestSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec())\n  )\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      infra_blessing=infra_validator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          model_resolver,\n          evaluator,\n          infra_validator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python iris_pipeline_native_keras.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/iris/iris_pipeline_native_keras_infraval_e2e_test.py,10,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.iris.iris_pipeline_native_keras_infraval.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.iris import iris_pipeline_native_keras_infraval\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass IrisPipelineNativeKerasInfravalEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(IrisPipelineNativeKerasInfravalEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'keras_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\')\n    self._module_file = os.path.join(\n        os.path.dirname(__file__), \'iris_utils_native_keras.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertInfraValidatorPassed(self) -> None:\n    blessing_path = os.path.join(self._pipeline_root, \'InfraValidator\',\n                                 \'blessing\')\n    executions = tf.io.gfile.listdir(blessing_path)\n    self.assertGreaterEqual(len(executions), 1)\n    for exec_id in executions:\n      blessed = os.path.join(blessing_path, exec_id, \'INFRA_BLESSED\')\n      self.assertTrue(tf.io.gfile.exists(blessed))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'Evaluator\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'InfraValidator\')\n    self.assertExecutedOnce(\'Pusher\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testIrisPipelineNativeKeras(self):\n    BeamDagRunner().run(\n        iris_pipeline_native_keras_infraval._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    expected_execution_count = 10  # 9 components + 1 resolver\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(expected_execution_count, execution_count)\n\n    self.assertPipelineExecution()\n    self.assertInfraValidatorPassed()\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(\n        iris_pipeline_native_keras_infraval._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # All executions but Evaluator and Pusher are cached.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is increased by 3 caused by Evaluator and Pusher.\n      self.assertEqual(artifact_count + 3, len(m.store.get_artifacts()))\n      artifact_count = len(m.store.get_artifacts())\n      self.assertEqual(expected_execution_count * 2,\n                       len(m.store.get_executions()))\n\n    # Runs pipeline the third time.\n    BeamDagRunner().run(\n        iris_pipeline_native_keras_infraval._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            serving_model_dir=self._serving_model_dir,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n      self.assertEqual(expected_execution_count * 3,\n                       len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_v2_behavior()\n  tf.test.main()\n'"
tfx/examples/iris/iris_utils.py,12,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include Iris pipeline functions and necessary utils.\n\nThe utilities in this file are used to build a model with Keras Layers, but\nuses model_to_estimator for Trainer component adaption.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport absl\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_model_analysis as tfma\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer import executor\nfrom tfx.utils import io_utils\n\n_FEATURE_KEYS = [\'sepal_length\', \'sepal_width\', \'petal_length\', \'petal_width\']\n_LABEL_KEY = \'variety\'\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _serving_input_receiver_fn(schema):\n  """"""Build the serving inputs.\n\n  Args:\n    schema: the schema of the input data.\n\n  Returns:\n    serving_input_receiver_fn for serving this model, since no transformation is\n    required in this case it does not include a tf-transform graph.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  return raw_input_fn()\n\n\ndef _eval_input_receiver_fn(schema):\n  """"""Build the evalution inputs for the tf-model-analysis to run the model.\n\n  Args:\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Features (dict of Tensors) to be passed to the model.\n      - Raw features as serialized tf.Examples.\n      - Labels\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  labels = serving_input_receiver.features.pop(_LABEL_KEY)\n  return tfma.export.EvalInputReceiver(\n      features=serving_input_receiver.features,\n      labels=labels,\n      receiver_tensors=serving_input_receiver.receiver_tensors)\n\n\ndef _input_fn(filenames, schema, batch_size=200):\n  """"""Input function for training and evaluation.\n\n  Args:\n    filenames: [str] list of CSV files to read data from.\n    schema: Schema of the input data.\n    batch_size: int First dimension size of the Tensors returned by input_fn\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n\n  feature_spec = _get_raw_feature_spec(schema)\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      filenames, batch_size, feature_spec, reader=_gzip_reader_fn)\n\n  # We pop the label because we do not want to use it as a feature while we\'re\n  # training.\n  return dataset.map(lambda features: (features, features.pop(_LABEL_KEY)))\n\n\ndef _keras_model_builder():\n  """"""Creates a DNN Keras model  for classifying iris data.\n\n  Returns:\n    A keras Model.\n  """"""\n  # The model below is built with Functional API, please refer to\n  # https://www.tensorflow.org/guide/keras/overview for all API options.\n  inputs = [tf.keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n  d = keras.layers.concatenate(inputs)\n  for _ in range(3):\n    d = keras.layers.Dense(8, activation=\'relu\')(d)\n  outputs = keras.layers.Dense(3, activation=\'softmax\')(d)\n\n  model = keras.Model(inputs=inputs, outputs=outputs)\n  model.compile(\n      optimizer=keras.optimizers.Adam(lr=0.0005),\n      loss=\'sparse_categorical_crossentropy\',\n      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n\n  train_batch_size = 20\n  eval_batch_size = 10\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      schema,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      schema,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(\n      train_input_fn, max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _serving_input_receiver_fn(schema)\n\n  exporter = tf.estimator.FinalExporter(\'iris\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'iris-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=1)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n\n  estimator = tf.keras.estimator.model_to_estimator(\n      keras_model=_keras_model_builder(), config=run_config)\n\n  # Create an input receiver for TFMA processing\n  eval_receiver_fn = lambda: _eval_input_receiver_fn(schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': eval_receiver_fn\n  }\n\n\n# TFX generic trainer will call this function instead of train_fn.\ndef run_fn(fn_args: executor.TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  schema = io_utils.parse_pbtxt_file(fn_args.schema_file, schema_pb2.Schema())\n\n  training_spec = trainer_fn(fn_args, schema)\n\n  # Train the model\n  absl.logging.info(\'Training model.\')\n  tf.estimator.train_and_evaluate(training_spec[\'estimator\'],\n                                  training_spec[\'train_spec\'],\n                                  training_spec[\'eval_spec\'])\n  absl.logging.info(\'Training complete.  Model written to %s\',\n                    fn_args.serving_model_dir)\n\n  # Export an eval savedmodel for TFMA\n  # NOTE: When trained in distributed training cluster, eval_savedmodel must be\n  # exported only by the chief worker (check TF_CONFIG).\n  absl.logging.info(\'Exporting eval_savedmodel for TFMA.\')\n  tfma.export.export_eval_savedmodel(\n      estimator=training_spec[\'estimator\'],\n      export_dir_base=fn_args.eval_model_dir,\n      eval_input_receiver_fn=training_spec[\'eval_input_receiver_fn\'])\n\n  absl.logging.info(\'Exported eval_savedmodel to %s.\', fn_args.eval_model_dir)\n'"
tfx/examples/iris/iris_utils_native_keras.py,13,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include Iris pipeline functions and necessary utils.\n\nThe utilities in this file are used to build a model with native Keras.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport kerastuner\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_transform as tft\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\nfrom tfx.components.trainer.fn_args_utils import FnArgs\nfrom tfx.components.tuner.component import TunerFnResult\n\n_FEATURE_KEYS = [\'sepal_length\', \'sepal_width\', \'petal_length\', \'petal_width\']\n_LABEL_KEY = \'variety\'\n\n# Iris dataset has 150 records, and is divided to train and eval splits in 2:1\n# ratio.\n_TRAIN_DATA_SIZE = 100\n_EVAL_DATA_SIZE = 50\n_TRAIN_BATCH_SIZE = 20\n_EVAL_BATCH_SIZE = 10\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that parses a serialized tf.Example.""""""\n\n  model.tft_layer = tf_transform_output.transform_features_layer()\n\n  @tf.function\n  def serve_tf_examples_fn(serialized_tf_examples):\n    """"""Returns the output to be used in the serving signature.""""""\n    feature_spec = tf_transform_output.raw_feature_spec()\n    feature_spec.pop(_LABEL_KEY)\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    transformed_features = model.tft_layer(parsed_features)\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(_transformed_name(_LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\ndef _input_fn(file_pattern: List[Text],\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_transformed_name(_LABEL_KEY))\n\n  return dataset\n\n\ndef _get_hyperparameters() -> kerastuner.HyperParameters:\n  """"""Returns hyperparameters for building Keras model.""""""\n  hp = kerastuner.HyperParameters()\n  # Defines search space.\n  hp.Choice(\'learning_rate\', [1e-2, 1e-3], default=1e-2)\n  hp.Int(\'num_layers\', 1, 3, default=2)\n  return hp\n\n\ndef _build_keras_model(hparams: kerastuner.HyperParameters) -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying iris data.\n\n  Args:\n    hparams: Holds HyperParameters for tuning.\n\n  Returns:\n    A Keras Model.\n  """"""\n  # The model below is built with Functional API, please refer to\n  # https://www.tensorflow.org/guide/keras/overview for all API options.\n  inputs = [\n      keras.layers.Input(shape=(1,), name=_transformed_name(f))\n      for f in _FEATURE_KEYS\n  ]\n  d = keras.layers.concatenate(inputs)\n  for _ in range(int(hparams.get(\'num_layers\'))):\n    d = keras.layers.Dense(8, activation=\'relu\')(d)\n  outputs = keras.layers.Dense(3, activation=\'softmax\')(d)\n\n  model = keras.Model(inputs=inputs, outputs=outputs)\n  model.compile(\n      optimizer=keras.optimizers.Adam(hparams.get(\'learning_rate\')),\n      loss=\'sparse_categorical_crossentropy\',\n      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n\n  for key in _FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(inputs[key])\n  # TODO(b/157064428): Support label transformation for Keras.\n  # Do not apply label transformation as it will result in wrong evaluation.\n  outputs[_transformed_name(_LABEL_KEY)] = inputs[_LABEL_KEY]\n\n  return outputs\n\n\n# TFX Tuner will call this function.\ndef tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n  """"""Build the tuner using the KerasTuner API.\n\n  Args:\n    fn_args: Holds args as name/value pairs.\n      - working_dir: working dir for tuning.\n      - train_files: List of file paths containing training tf.Example data.\n      - eval_files: List of file paths containing eval tf.Example data.\n      - train_steps: number of train steps.\n      - eval_steps: number of eval steps.\n      - schema_path: optional schema of the input data.\n      - transform_graph_path: optional transform graph produced by TFT.\n\n  Returns:\n    A namedtuple contains the following:\n      - tuner: A BaseTuner that will be used for tuning.\n      - fit_kwargs: Args to pass to tuner\'s run_trial function for fitting the\n                    model , e.g., the training and validation dataset. Required\n                    args depend on the above tuner\'s implementation.\n  """"""\n  # RandomSearch is a subclass of kerastuner.Tuner which inherits from\n  # BaseTuner.\n  tuner = kerastuner.RandomSearch(\n      _build_keras_model,\n      max_trials=6,\n      hyperparameters=_get_hyperparameters(),\n      allow_new_entries=False,\n      objective=kerastuner.Objective(\'val_sparse_categorical_accuracy\', \'max\'),\n      directory=fn_args.working_dir,\n      project_name=\'iris_tuning\')\n\n  transform_graph = tft.TFTransformOutput(fn_args.transform_graph_path)\n  train_dataset = _input_fn(fn_args.train_files, transform_graph)\n  eval_dataset = _input_fn(fn_args.eval_files, transform_graph)\n\n  return TunerFnResult(\n      tuner=tuner,\n      fit_kwargs={\n          \'x\': train_dataset,\n          \'validation_data\': eval_dataset,\n          \'steps_per_epoch\': fn_args.train_steps,\n          \'validation_steps\': fn_args.eval_steps\n      })\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = _input_fn(fn_args.train_files, tf_transform_output,\n                            batch_size=_TRAIN_BATCH_SIZE)\n  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output,\n                           batch_size=_EVAL_BATCH_SIZE)\n\n  if fn_args.hyperparameters:\n    hparams = kerastuner.HyperParameters.from_config(fn_args.hyperparameters)\n  else:\n    # This is a shown case when hyperparameters is decided and Tuner is removed\n    # from the pipeline. User can also inline the hyperparameters directly in\n    # _build_keras_model.\n    hparams = _get_hyperparameters()\n  absl.logging.info(\'HyperParameters for training: %s\' % hparams.get_config())\n\n  mirrored_strategy = tf.distribute.MirroredStrategy()\n  with mirrored_strategy.scope():\n    model = _build_keras_model(hparams)\n\n  steps_per_epoch = _TRAIN_DATA_SIZE / _TRAIN_BATCH_SIZE\n\n  model.fit(\n      train_dataset,\n      epochs=int(fn_args.train_steps / steps_per_epoch),\n      steps_per_epoch=steps_per_epoch,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps)\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(model,\n                                    tf_transform_output).get_concrete_function(\n                                        tf.TensorSpec(\n                                            shape=[None],\n                                            dtype=tf.string,\n                                            name=\'examples\')),\n  }\n  model.save(fn_args.serving_model_dir, save_format=\'tf\', signatures=signatures)\n'"
tfx/examples/mnist/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/mnist/mnist_pipeline_native_keras.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""MNIST handwritten digit classification example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ImportExampleGen\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'mnist_native_keras\'\n\n# This example assumes that MNIST data is stored in ~/mnist/data and the utility\n# function is in ~/mnist. Feel free to customize as needed.\n_mnist_root = os.path.join(os.environ[\'HOME\'], \'mnist\')\n_data_root = os.path.join(_mnist_root, \'data\')\n# Python module files to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_mnist_root, \'mnist_utils_native_keras.py\')\n_module_file_lite = os.path.join(\n    _mnist_root, \'mnist_utils_native_keras_lite.py\')\n\n# Path which can be listened to by the model server. Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_mnist_root, \'serving_model\', _pipeline_name)\n_serving_model_dir_lite = os.path.join(\n    _mnist_root, \'serving_model_lite\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the images,\n# example code, and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, module_file_lite: Text,\n                     serving_model_dir: Text, serving_model_dir_lite: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the handwritten digit classification example using TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline.\n  example_gen = ImportExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  def _create_trainer(module_file, instance_name):\n    return Trainer(\n        module_file=module_file,\n        custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n        examples=transform.outputs[\'transformed_examples\'],\n        transform_graph=transform.outputs[\'transform_graph\'],\n        schema=schema_gen.outputs[\'schema\'],\n        train_args=trainer_pb2.TrainArgs(num_steps=5000),\n        eval_args=trainer_pb2.EvalArgs(num_steps=100),\n        instance_name=instance_name)\n\n  # Uses user-provided Python function that trains a Keras model.\n  trainer = _create_trainer(module_file, \'mnist\')\n\n  # Trains the same model as the one above, but converts it into a TFLite one.\n  trainer_lite = _create_trainer(module_file_lite, \'mnist_lite\')\n\n  # TODO(b/150949276): Add resolver back once it supports two trainers.\n\n  # Uses TFMA to compute an evaluation statistics over features of a model and\n  # performs quality validation of a candidate model.\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'image_class\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'SparseCategoricalAccuracy\',\n                  threshold=tfma.config.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': 0.8})))\n          ])\n      ])\n\n  eval_config_lite = tfma.EvalConfig()\n  eval_config_lite.CopyFrom(eval_config)\n  # Informs the evaluator that the model is a TFLite model.\n  eval_config_lite.model_specs[0].model_type = \'tf_lite\'\n\n  # Uses TFMA to compute the evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      eval_config=eval_config,\n      instance_name=\'mnist\')\n\n  # Uses TFMA to compute the evaluation statistics over features of a TFLite\n  # model.\n  evaluator_lite = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer_lite.outputs[\'model\'],\n      eval_config=eval_config_lite,\n      instance_name=\'mnist_lite\')\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)),\n      instance_name=\'mnist\')\n\n  # Checks whether the TFLite model passed the validation steps and pushes the\n  # model to a file destination if check passed.\n  pusher_lite = Pusher(\n      model=trainer_lite.outputs[\'model\'],\n      model_blessing=evaluator_lite.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir_lite)),\n      instance_name=\'mnist_lite\')\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          transform,\n          trainer,\n          trainer_lite,\n          evaluator,\n          evaluator_lite,\n          pusher,\n          pusher_lite,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers],\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python mnist_pipeline_native_keras.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          module_file_lite=_module_file_lite,\n          serving_model_dir=_serving_model_dir,\n          serving_model_dir_lite=_serving_model_dir_lite,\n          metadata_path=_metadata_path,\n          # 0 means auto-detect based on the number of CPUs available during\n          # execution time.\n          direct_num_workers=0))\n'"
tfx/examples/mnist/mnist_pipeline_native_keras_e2e_test.py,9,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.mnist.mnist_pipeline_native_keras.""""""\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport tensorflow as tf\n\nfrom tfx.examples.mnist import mnist_pipeline_native_keras\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass MNISTPipelineNativeKerasEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(MNISTPipelineNativeKerasEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'keras_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'data\')\n    self._module_file = os.path.join(\n        os.path.dirname(__file__), \'mnist_utils_native_keras.py\')\n    self._module_file_lite = os.path.join(\n        os.path.dirname(__file__), \'mnist_utils_native_keras_lite.py\')\n    self._serving_model_dir = os.path.join(self._test_dir, \'serving_model\')\n    self._serving_model_dir_lite = os.path.join(\n        self._test_dir, \'serving_model_lite\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertLen(execution, 1)\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'ImportExampleGen\')\n    self.assertExecutedOnce(\'Evaluator.mnist\')\n    self.assertExecutedOnce(\'Evaluator.mnist_lite\')\n    self.assertExecutedOnce(\'ExampleValidator\')\n    self.assertExecutedOnce(\'Pusher.mnist\')\n    self.assertExecutedOnce(\'Pusher.mnist_lite\')\n    self.assertExecutedOnce(\'SchemaGen\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n    self.assertExecutedOnce(\'Trainer.mnist\')\n    self.assertExecutedOnce(\'Trainer.mnist_lite\')\n    self.assertExecutedOnce(\'Transform\')\n\n  def testMNISTPipelineNativeKeras(self):\n    if not tf.executing_eagerly():\n      self.skipTest(\'The test requires TF2.\')\n    BeamDagRunner().run(\n        mnist_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            module_file_lite=self._module_file_lite,\n            serving_model_dir=self._serving_model_dir,\n            serving_model_dir_lite=self._serving_model_dir_lite,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir))\n    self.assertTrue(tf.io.gfile.exists(self._serving_model_dir_lite))\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    expected_execution_count = 11\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n      self.assertEqual(execution_count, expected_execution_count)\n\n    self.assertPipelineExecution()\n\n    # Runs pipeline the second time.\n    BeamDagRunner().run(\n        mnist_pipeline_native_keras._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            module_file=self._module_file,\n            module_file_lite=self._module_file_lite,\n            serving_model_dir=self._serving_model_dir,\n            serving_model_dir_lite=self._serving_model_dir_lite,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path,\n            direct_num_workers=1))\n\n    # Asserts cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertLen(m.store.get_artifacts(), artifact_count)\n      self.assertLen(m.store.get_executions(), expected_execution_count * 2)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/mnist/mnist_utils_native_keras.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file includes MNIST utils for Keras model.\n\nThe utilities in this file are used to build a model with native Keras.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\nfrom tfx.examples.mnist import mnist_utils_native_keras_base as base\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that parses a serialized tf.Example.""""""\n\n  @tf.function\n  def serve_tf_examples_fn(serialized_tf_examples):\n    """"""Returns the output to be used in the serving signature.""""""\n    feature_spec = tf_transform_output.raw_feature_spec()\n    feature_spec.pop(base.LABEL_KEY)\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    transformed_features = tf_transform_output.transform_raw_features(\n        parsed_features)\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(base.transformed_name(base.LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  return base.preprocessing_fn(inputs)\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = base.input_fn(fn_args.train_files, tf_transform_output, 40)\n  eval_dataset = base.input_fn(fn_args.eval_files, tf_transform_output, 40)\n\n  mirrored_strategy = tf.distribute.MirroredStrategy()\n  with mirrored_strategy.scope():\n    model = base.build_keras_model()\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps)\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(\n              model, tf_transform_output).get_concrete_function(\n                  tf.TensorSpec(shape=[None], dtype=tf.string, name=\'examples\'))\n  }\n  model.save(fn_args.serving_model_dir, save_format=\'tf\', signatures=signatures)\n'"
tfx/examples/mnist/mnist_utils_native_keras_base.py,13,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base Python source file for MNIST utils.\n\nThis file is used by both mnist_utils_native_keras and\nmnist_util_native_keras_lite to build Keras and TFLite models, respectively.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\n# MNIST dataset consists of an image of the handwritten digits,\n# and it\'s label which is the class indicating digits 0 through 9.\nIMAGE_KEY = \'image_floats\'\nLABEL_KEY = \'image_class\'\n\n\ndef transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef input_fn(file_pattern: List[Text],\n             tf_transform_output: tft.TFTransformOutput,\n             batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=transformed_name(LABEL_KEY))\n\n  return dataset\n\n\ndef build_keras_model() -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying MNIST data.\n\n  Returns:\n    A Keras Model.\n  """"""\n  # The model below is built with Sequential API, please refer to\n  # https://www.tensorflow.org/guide/keras/overview for all API options.\n  model = tf.keras.Sequential()\n  model.add(\n      tf.keras.layers.InputLayer(\n          input_shape=(784,), name=transformed_name(IMAGE_KEY)))\n  model.add(tf.keras.layers.Dense(64, activation=\'relu\'))\n  model.add(tf.keras.layers.Dropout(0.2))\n  model.add(tf.keras.layers.Dense(64, activation=\'relu\'))\n  model.add(tf.keras.layers.Dropout(0.2))\n  model.add(tf.keras.layers.Dense(10, activation=\'softmax\'))\n  model.compile(\n      loss=\'sparse_categorical_crossentropy\',\n      optimizer=tf.keras.optimizers.RMSprop(lr=0.0015),\n      metrics=[\'sparse_categorical_accuracy\'])\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n\n  # The input float values for the image encoding are in the range [-0.5, 0.5].\n  # So scale_by_min_max is a identity operation, since the range is preserved.\n  outputs[transformed_name(IMAGE_KEY)] = (\n      tft.scale_by_min_max(inputs[IMAGE_KEY], -0.5, 0.5))\n  # TODO(b/157064428): Support label transformation for Keras.\n  # Do not apply label transformation as it will result in wrong evaluation.\n  outputs[transformed_name(LABEL_KEY)] = inputs[LABEL_KEY]\n\n  return outputs\n'"
tfx/examples/mnist/mnist_utils_native_keras_lite.py,6,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file includes MNIST utils for TFLite model.\n\nThe utilities in this file are used to build a TFLite model.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\nfrom tfx.components.trainer.rewriting import converters\nfrom tfx.components.trainer.rewriting import rewriter\nfrom tfx.components.trainer.rewriting import rewriter_factory\nfrom tfx.examples.mnist import mnist_utils_native_keras_base as base\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that feeds the input tensor into the model.""""""\n\n  @tf.function\n  def serve_tf_examples_fn(image_tensor):\n    """"""Returns the output to be used in the serving signature.""""""\n    transformed_features = tf_transform_output.transform_raw_features(\n        {base.IMAGE_KEY: image_tensor})\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(base.transformed_name(base.LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  return base.preprocessing_fn(inputs)\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = base.input_fn(fn_args.train_files, tf_transform_output, 40)\n  eval_dataset = base.input_fn(fn_args.eval_files, tf_transform_output, 40)\n\n  mirrored_strategy = tf.distribute.MirroredStrategy()\n  with mirrored_strategy.scope():\n    model = base.build_keras_model()\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps)\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(\n              model, tf_transform_output).get_concrete_function(\n                  tf.TensorSpec(\n                      shape=[None, 784],\n                      dtype=tf.float32,\n                      name=\'image_floats\'))\n  }\n  temp_saving_model_dir = os.path.join(fn_args.serving_model_dir, \'temp\')\n  model.save(temp_saving_model_dir, save_format=\'tf\', signatures=signatures)\n\n  tfrw = rewriter_factory.create_rewriter(\n      rewriter_factory.TFLITE_REWRITER, name=\'tflite_rewriter\',\n      enable_experimental_new_converter=True)\n  converters.rewrite_saved_model(temp_saving_model_dir,\n                                 fn_args.serving_model_dir,\n                                 tfrw,\n                                 rewriter.ModelType.TFLITE_MODEL)\n\n  tf.io.gfile.rmtree(temp_saving_model_dir)\n'"
tfx/experimental/templates/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi_template_beam_e2e_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E test using Beam orchestrator for taxi template.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\nimport subprocess\nimport sys\n\nfrom absl import logging\nfrom click import testing as click_testing\nimport tensorflow as tf\n\nfrom tfx.tools.cli.cli_main import cli_group\nfrom tfx.utils import io_utils\n\n\nclass TaxiTemplateBeamEndToEndTest(tf.test.TestCase):\n  """"""This test covers step 1~6 of the accompanying document[1] for taxi template.\n\n  TODO(b/148500754) Add a test using KFP.\n  [1]https://github.com/tensorflow/tfx/blob/master/docs/tutorials/tfx/template.ipynb\n  """"""\n\n  def setUp(self):\n    super(TaxiTemplateBeamEndToEndTest, self).setUp()\n\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    # TODO(b/150100590) Delete this block after Python >=3.7\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n\n    self._temp_dir = self.create_tempdir().full_path\n\n    self._pipeline_name = \'TAXI_TEMPLATE_E2E_TEST\'\n    self._project_dir = os.path.join(self._temp_dir, \'src\')\n    self._old_cwd = os.getcwd()\n    os.mkdir(self._project_dir)\n    os.chdir(self._project_dir)\n\n    # Initialize CLI runner.\n    self._cli_runner = click_testing.CliRunner()\n\n  def tearDown(self):\n    super(TaxiTemplateBeamEndToEndTest, self).tearDown()\n    os.chdir(self._old_cwd)\n\n  def _runCli(self, args):\n    logging.info(\'Running cli: %s\', args)\n    result = self._cli_runner.invoke(cli_group, args)\n    logging.info(\'%s\', result.output)\n    if result.exit_code != 0:\n      logging.error(\'Exit code from cli: %d, exception:%s\', result.exit_code,\n                    result.exception)\n      logging.error(\'Traceback: %s\', result.exc_info)\n\n    return result\n\n  def _addAllComponents(self):\n    """"""Change \'pipeline.py\' file to put all components into the pipeline.""""""\n    pipeline_definition_file = os.path.join(self._project_dir, \'pipeline\',\n                                            \'pipeline.py\')\n    with open(pipeline_definition_file) as fp:\n      content = fp.read()\n    # At the initial state, these are commented out. Uncomment them.\n    content = content.replace(\'# components.append(\', \'components.append(\')\n    io_utils.write_string_file(pipeline_definition_file, content)\n    return pipeline_definition_file\n\n  def _getAllUnitTests(self):\n    for root, _, files in os.walk(self._project_dir):\n      base_dir = os.path.relpath(root, self._project_dir)\n      if base_dir == \'.\':  # project_dir == root\n        base_module = \'\'\n      else:\n        base_module = base_dir.replace(os.path.sep, \'.\') + \'.\'\n\n      for filename in files:\n        if filename.endswith(\'_test.py\'):\n          yield base_module + filename[:-3]\n\n  def _copyTemplate(self):\n    result = self._runCli([\n        \'template\',\n        \'copy\',\n        \'--pipeline_name\',\n        self._pipeline_name,\n        \'--destination_path\',\n        self._project_dir,\n        \'--model\',\n        \'taxi\',\n    ])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\'Copying taxi pipeline template\', result.output)\n\n  def testGeneratedUnitTests(self):\n    self._copyTemplate()\n    for m in self._getAllUnitTests():\n      logging.info(\'Running unit test ""%s""\', m)\n      # A failed googletest will raise a CalledProcessError.\n      _ = subprocess.check_output([sys.executable, \'-m\', m])\n\n  def testBeamPipeline(self):\n    self._copyTemplate()\n    os.environ[\'BEAM_HOME\'] = os.path.join(self._temp_dir, \'beam\')\n\n    # Create a pipeline with only one component.\n    result = self._runCli([\n        \'pipeline\',\n        \'create\',\n        \'--engine\',\n        \'beam\',\n        \'--pipeline_path\',\n        \'beam_dag_runner.py\',\n    ])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\n        \'Pipeline ""{}"" created successfully.\'.format(self._pipeline_name),\n        result.output)\n\n    # Run the pipeline.\n    result = self._runCli([\n        \'run\',\n        \'create\',\n        \'--engine\',\n        \'beam\',\n        \'--pipeline_name\',\n        self._pipeline_name,\n    ])\n    self.assertEqual(0, result.exit_code)\n\n    # Update the pipeline to include all components.\n    updated_pipeline_file = self._addAllComponents()\n    logging.info(\'Updated %s to add all components to the pipeline.\',\n                 updated_pipeline_file)\n    result = self._runCli([\n        \'pipeline\',\n        \'update\',\n        \'--engine\',\n        \'beam\',\n        \'--pipeline_path\',\n        \'beam_dag_runner.py\',\n    ])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\n        \'Pipeline ""{}"" updated successfully.\'.format(self._pipeline_name),\n        result.output)\n\n    # Run the updated pipeline.\n    result = self._runCli([\n        \'run\',\n        \'create\',\n        \'--engine\',\n        \'beam\',\n        \'--pipeline_name\',\n        self._pipeline_name,\n    ])\n    self.assertEqual(0, result.exit_code)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/extensions/google_cloud_ai_platform/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/extensions/google_cloud_ai_platform/cmle_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Deprecated definition of runner to start TFX training jobs on CMLE.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.extensions.google_cloud_ai_platform import runner\n\nstart_cmle_training = deprecation.deprecated_alias(\n    deprecated_name=\'cmle_runner.start_cmle_training\',\n    name=\'runner.start_aip_training\',\n    func_or_class=runner.start_aip_training)\ndeploy_model_for_cmle_serving = deprecation.deprecated_alias(\n    deprecated_name=\'cmle_runner.deploy_model_for_cmle_serving\',\n    name=\'runner.deploy_model_for_aip_prediction\',\n    func_or_class=runner.deploy_model_for_aip_prediction)\n'"
tfx/extensions/google_cloud_ai_platform/runner.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Helper class to start TFX training jobs on AI Platform.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport json\nimport sys\nimport time\nfrom typing import Any, Dict, List, Optional, Text\n\nimport absl\nfrom googleapiclient import discovery\nfrom googleapiclient import errors\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx import version\nfrom tfx.types import artifact_utils\nfrom tfx.utils import telemetry_utils\n\n_POLLING_INTERVAL_IN_SECONDS = 30\n\n# TODO(b/139934802) Ensure mirroring of released TFX containers in Docker Hub\n# and gcr.io/tfx-oss-public/ registries.\n_TFX_IMAGE = \'gcr.io/tfx-oss-public/tfx:{}\'.format(version.__version__)\n\n_TF_COMPATIBILITY_OVERRIDE = {\n    # Generally, runtimeVersion should be same as <major>.<minor> of currently\n    # installed tensorflow version, with certain compatibility hacks since\n    # some TensorFlow runtime versions are not explicitly supported by\n    # CAIP pusher. See:\n    # https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list\n    \'2.0\': \'1.15\',\n    # TODO(b/157039850) Remove this once CAIP model support TF 2.2 runtime.\n    \'2.2\': \'2.1\',\n    \'2.3\': \'2.1\',\n    \'2.4\': \'2.1\'\n}\n\n\ndef _get_tf_runtime_version(tf_version: Text) -> Text:\n  """"""Returns the tensorflow runtime version used in Cloud AI Platform.\n\n  This is only used for prediction service.\n\n  Args:\n    tf_version: version string returned from `tf.__version__`.\n\n  Returns: same major.minor version of installed tensorflow, except when\n    overriden by _TF_COMPATIBILITY_OVERRIDE.\n  """"""\n  tf_version = \'.\'.join(tf_version.split(\'.\')[0:2])\n  return _TF_COMPATIBILITY_OVERRIDE.get(tf_version) or tf_version\n\n\ndef _get_caip_python_version(caip_tf_runtime_version: Text) -> Text:\n  """"""Returns supported python version on Cloud AI Platform.\n\n  See\n  https://cloud.google.com/ml-engine/docs/tensorflow/versioning#set-python-version-training\n\n  Args:\n    caip_tf_runtime_version: version string returned from\n      _get_tf_runtime_version().\n\n  Returns:\n    \'2.7\' for PY2. \'3.5\' or \'3.7\' for PY3 depending on caip_tf_runtime_version.\n  """"""\n  if sys.version_info.major == 2:\n    return \'2.7\'\n  (major, minor) = caip_tf_runtime_version.split(\'.\')[0:2]\n  if (int(major), int(minor)) >= (1, 15):\n    return \'3.7\'\n  return \'3.5\'\n\n\ndef start_aip_training(input_dict: Dict[Text, List[types.Artifact]],\n                       output_dict: Dict[Text, List[types.Artifact]],\n                       exec_properties: Dict[Text,\n                                             Any], executor_class_path: Text,\n                       training_inputs: Dict[Text,\n                                             Any], job_id: Optional[Text]):\n  """"""Start a trainer job on AI Platform (AIP).\n\n  This is done by forwarding the inputs/outputs/exec_properties to the\n  tfx.scripts.run_executor module on a AI Platform training job interpreter.\n\n  Args:\n    input_dict: Passthrough input dict for tfx.components.Trainer.executor.\n    output_dict: Passthrough input dict for tfx.components.Trainer.executor.\n    exec_properties: Passthrough input dict for tfx.components.Trainer.executor.\n    executor_class_path: class path for TFX core default trainer.\n    training_inputs: Training input argument for AI Platform training job.\n      \'pythonModule\', \'pythonVersion\' and \'runtimeVersion\' will be inferred. For\n      the full set of parameters, refer to\n      https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput\n    job_id: Job ID for AI Platform Training job. If not supplied,\n      system-determined unique ID is given. Refer to\n    https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#resource-job\n\n  Returns:\n    None\n  Raises:\n    RuntimeError: if the Google Cloud AI Platform training job failed.\n  """"""\n  training_inputs = training_inputs.copy()\n\n  json_inputs = artifact_utils.jsonify_artifact_dict(input_dict)\n  absl.logging.info(\'json_inputs=\\\'{}\\\'.\'.format(json_inputs))\n  json_outputs = artifact_utils.jsonify_artifact_dict(output_dict)\n  absl.logging.info(\'json_outputs=\\\'{}\\\'.\'.format(json_outputs))\n  json_exec_properties = json.dumps(exec_properties, sort_keys=True)\n  absl.logging.info(\'json_exec_properties=\\\'{}\\\'.\'.format(json_exec_properties))\n\n  # Configure AI Platform training job\n  api_client = discovery.build(\'ml\', \'v1\')\n\n  # We use custom containers to launch training on AI Platform, which invokes\n  # the specified image using the container\'s entrypoint. The default\n  # entrypoint for TFX containers is to call scripts/run_executor.py. The\n  # arguments below are passed to this run_executor entry to run the executor\n  # specified in `executor_class_path`.\n  job_args = [\n      \'--executor_class_path\', executor_class_path, \'--inputs\', json_inputs,\n      \'--outputs\', json_outputs, \'--exec-properties\', json_exec_properties\n  ]\n\n  if not training_inputs.get(\'masterConfig\'):\n    training_inputs[\'masterConfig\'] = {\n        \'imageUri\': _TFX_IMAGE,\n    }\n\n  training_inputs[\'args\'] = job_args\n\n  # Pop project_id so AIP doesn\'t complain about an unexpected parameter.\n  # It\'s been a stowaway in aip_args and has finally reached its destination.\n  project = training_inputs.pop(\'project\')\n  project_id = \'projects/{}\'.format(project)\n  with telemetry_utils.scoped_labels(\n      {telemetry_utils.LABEL_TFX_EXECUTOR: executor_class_path}):\n    job_labels = telemetry_utils.get_labels_dict()\n\n  # \'tfx_YYYYmmddHHMMSS\' is the default job ID if not explicitly specified.\n  job_id = job_id or \'tfx_{}\'.format(\n      datetime.datetime.now().strftime(\'%Y%m%d%H%M%S\'))\n  job_spec = {\n      \'jobId\': job_id,\n      \'trainingInput\': training_inputs,\n      \'labels\': job_labels,\n  }\n\n  # Submit job to AIP Training\n  absl.logging.info(\n      \'Submitting job=\\\'{}\\\', project=\\\'{}\\\' to AI Platform.\'.format(\n          job_id, project))\n  request = api_client.projects().jobs().create(\n      body=job_spec, parent=project_id)\n  request.execute()\n\n  # Wait for AIP Training job to finish\n  job_name = \'{}/jobs/{}\'.format(project_id, job_id)\n  request = api_client.projects().jobs().get(name=job_name)\n  response = request.execute()\n  while response[\'state\'] not in (\'SUCCEEDED\', \'FAILED\'):\n    time.sleep(_POLLING_INTERVAL_IN_SECONDS)\n    response = request.execute()\n\n  if response[\'state\'] == \'FAILED\':\n    err_msg = \'Job \\\'{}\\\' did not succeed.  Detailed response {}.\'.format(\n        job_name, response)\n    absl.logging.error(err_msg)\n    raise RuntimeError(err_msg)\n\n  # AIP training complete\n  absl.logging.info(\'Job \\\'{}\\\' successful.\'.format(job_name))\n\n\ndef deploy_model_for_aip_prediction(\n    serving_path: Text,\n    model_version: Text,\n    ai_platform_serving_args: Dict[Text, Any],\n    executor_class_path: Text,\n):\n  """"""Deploys a model for serving with AI Platform.\n\n  Args:\n    serving_path: The path to the model. Must be a GCS URI.\n    model_version: Version of the model being deployed. Must be different from\n      what is currently being served.\n    ai_platform_serving_args: Dictionary containing arguments for pushing to AI\n      Platform. For the full set of parameters supported, refer to\n      https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions#Version\n    executor_class_path: class path for TFX core default trainer.\n\n  Raises:\n    RuntimeError: if an error is encountered when trying to push.\n  """"""\n  absl.logging.info(\n      \'Deploying to model with version {} to AI Platform for serving: {}\'\n      .format(model_version, ai_platform_serving_args))\n\n  model_name = ai_platform_serving_args[\'model_name\']\n  project_id = ai_platform_serving_args[\'project_id\']\n  regions = ai_platform_serving_args.get(\'regions\', [])\n  default_runtime_version = _get_tf_runtime_version(tf.__version__)\n  runtime_version = ai_platform_serving_args.get(\'runtime_version\',\n                                                 default_runtime_version)\n  python_version = _get_caip_python_version(runtime_version)\n\n  api = discovery.build(\'ml\', \'v1\')\n  body = {\'name\': model_name, \'regions\': regions}\n  parent = \'projects/{}\'.format(project_id)\n  try:\n    api.projects().models().create(body=body, parent=parent).execute()\n  except errors.HttpError as e:\n    # If the error is to create an already existing model, it\'s ok to ignore.\n    # TODO(b/135211463): Remove the disable once the pytype bug is fixed.\n    if e.resp.status == 409:  # pytype: disable=attribute-error\n      absl.logging.warn(\'Model {} already exists\'.format(model_name))\n    else:\n      raise RuntimeError(\'AI Platform Push failed: {}\'.format(e))\n  with telemetry_utils.scoped_labels(\n      {telemetry_utils.LABEL_TFX_EXECUTOR: executor_class_path}):\n    job_labels = telemetry_utils.get_labels_dict()\n  body = {\n      \'name\': model_version,\n      \'deployment_uri\': serving_path,\n      \'runtime_version\': runtime_version,\n      \'python_version\': python_version,\n      \'labels\': job_labels,\n  }\n\n  # Push to AIP, and record the operation name so we can poll for its state.\n  model_name = \'projects/{}/models/{}\'.format(project_id, model_name)\n  response = api.projects().models().versions().create(\n      body=body, parent=model_name).execute()\n  op_name = response[\'name\']\n\n  deploy_status_resc = api.projects().operations().get(name=op_name)\n  while not deploy_status_resc.execute().get(\'done\'):\n    time.sleep(_POLLING_INTERVAL_IN_SECONDS)\n    absl.logging.info(\'Model still being deployed...\')\n\n  deploy_status = deploy_status_resc.execute()\n\n  if deploy_status.get(\'error\'):\n    # The operation completed with an error.\n    raise RuntimeError(\n        \'Failed to deploy model to AI Platform for serving: {}\'.format(\n            deploy_status[\'error\']))\n\n  # Set the new version as default.\n  # By API specification, if Long-Running-Operation is done and there is\n  # no error, \'response\' is guaranteed to exist.\n  api.projects().models().versions().setDefault(\n      name=\'{}/versions/{}\'.format(model_name, deploy_status[\'response\']\n                                   [\'name\'])).execute()\n\n  absl.logging.info(\n      \'Successfully deployed model {} with version {}, serving from {}\'.format(\n          model_name, model_version, serving_path))\n'"
tfx/extensions/google_cloud_ai_platform/runner_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.extensions.google_cloud_ai_platform.runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport os\nimport sys\nfrom typing import Any, Dict, Text\n\n# Standard Imports\n\nimport mock\nimport tensorflow as tf\n\nfrom tfx import version\nfrom tfx.extensions.google_cloud_ai_platform import runner\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor\nfrom tfx.utils import json_utils\nfrom tfx.utils import telemetry_utils\n\n\nclass RunnerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(RunnerTest, self).setUp()\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._project_id = \'12345\'\n    self._mock_api_client = mock.Mock()\n    self._inputs = {}\n    self._outputs = {}\n    self._training_inputs = {\n        \'project\': self._project_id,\n    }\n    self._job_id = \'my_jobid\'\n    # Dict format of exec_properties. custom_config needs to be serialized\n    # before being passed into start_aip_training function.\n    self._exec_properties = {\n        \'custom_config\': {\n            executor.TRAINING_ARGS_KEY: self._training_inputs,\n        },\n    }\n    self._model_name = \'model_name\'\n    self._ai_platform_serving_args = {\n        \'model_name\': self._model_name,\n        \'project_id\': self._project_id,\n    }\n    self._executor_class_path = \'my.executor.Executor\'\n\n  def _setUpTrainingMocks(self):\n    self._mock_create = mock.Mock()\n    self._mock_api_client.projects().jobs().create = self._mock_create\n    self._mock_get = mock.Mock()\n    self._mock_api_client.projects().jobs().get.return_value = self._mock_get\n    self._mock_get.execute.return_value = {\n        \'state\': \'SUCCEEDED\',\n    }\n\n  def _serialize_custom_config_under_test(self) -> Dict[Text, Any]:\n    """"""Converts self._exec_properties[\'custom_config\'] to string.""""""\n    result = copy.deepcopy(self._exec_properties)\n    result[\'custom_config\'] = json_utils.dumps(result[\'custom_config\'])\n    return result\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testStartAIPTraining(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpTrainingMocks()\n\n    class_path = \'foo.bar.class\'\n\n    runner.start_aip_training(self._inputs, self._outputs,\n                              self._serialize_custom_config_under_test(),\n                              class_path,\n                              self._training_inputs, None)\n\n    self._mock_create.assert_called_with(\n        body=mock.ANY, parent=\'projects/{}\'.format(self._project_id))\n    (_, kwargs) = self._mock_create.call_args\n    body = kwargs[\'body\']\n\n    default_image = \'gcr.io/tfx-oss-public/tfx:{}\'.format(version.__version__)\n    self.assertDictContainsSubset(\n        {\n            \'masterConfig\': {\n                \'imageUri\': default_image,\n            },\n            \'args\': [\n                \'--executor_class_path\', class_path, \'--inputs\', \'{}\',\n                \'--outputs\', \'{}\', \'--exec-properties\', \'{""custom_config"": \'\n                \'""{\\\\""ai_platform_training_args\\\\"": {\\\\""project\\\\"": \\\\""12345\\\\""\'\n                \'}}""}\'\n            ],\n        }, body[\'trainingInput\'])\n    self.assertStartsWith(body[\'jobId\'], \'tfx_\')\n    self._mock_get.execute.assert_called_with()\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testStartAIPTrainingWithUserContainer(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpTrainingMocks()\n\n    class_path = \'foo.bar.class\'\n\n    self._training_inputs[\'masterConfig\'] = {\'imageUri\': \'my-custom-image\'}\n    self._exec_properties[\'custom_config\'][executor.JOB_ID_KEY] = self._job_id\n    runner.start_aip_training(self._inputs, self._outputs,\n                              self._serialize_custom_config_under_test(),\n                              class_path,\n                              self._training_inputs, self._job_id)\n\n    self._mock_create.assert_called_with(\n        body=mock.ANY, parent=\'projects/{}\'.format(self._project_id))\n    (_, kwargs) = self._mock_create.call_args\n    body = kwargs[\'body\']\n    self.assertDictContainsSubset(\n        {\n            \'masterConfig\': {\n                \'imageUri\': \'my-custom-image\',\n            },\n            \'args\': [\n                \'--executor_class_path\', class_path, \'--inputs\', \'{}\',\n                \'--outputs\', \'{}\', \'--exec-properties\', \'{""custom_config"": \'\n                \'""{\\\\""ai_platform_training_args\\\\"": \'\n                \'{\\\\""masterConfig\\\\"": {\\\\""imageUri\\\\"": \\\\""my-custom-image\\\\""}, \'\n                \'\\\\""project\\\\"": \\\\""12345\\\\""}, \'\n                \'\\\\""ai_platform_training_job_id\\\\"": \\\\""my_jobid\\\\""}""}\'\n            ],\n        }, body[\'trainingInput\'])\n    self.assertEqual(body[\'jobId\'], \'my_jobid\')\n    self._mock_get.execute.assert_called_with()\n\n  def _setUpPredictionMocks(self):\n    self._serving_path = os.path.join(self._output_data_dir, \'serving_path\')\n    self._model_version = \'model_version\'\n\n    self._mock_models_create = mock.Mock()\n    self._mock_api_client.projects().models().create = self._mock_models_create\n\n    self._mock_versions_create = mock.Mock()\n    self._mock_versions_create.return_value.execute.return_value = {\n        \'name\': \'versions_create_op_name\'\n    }\n\n    self._mock_api_client.projects().models().versions(\n    ).create = self._mock_versions_create\n    self._mock_get = mock.Mock()\n    self._mock_api_client.projects().operations().get = self._mock_get\n\n    self._mock_set_default = mock.Mock()\n    self._mock_api_client.projects().models().versions(\n    ).setDefault = self._mock_set_default\n\n    self._mock_set_default_execute = mock.Mock()\n    self._mock_api_client.projects().models().versions().setDefault(\n    ).execute = self._mock_set_default_execute\n\n    self._mock_get.return_value.execute.return_value = {\n        \'done\': True,\n        \'response\': {\n            \'name\': self._model_version,\n        },\n    }\n\n  def _assertDeployModelMockCalls(self,\n                                  expected_models_create_body=None,\n                                  expected_versions_create_body=None,\n                                  expect_set_default=True):\n    if not expected_models_create_body:\n      expected_models_create_body = {\n          \'name\':\n              self._model_name,\n          \'regions\':\n              [],\n      }\n\n    if not expected_versions_create_body:\n      with telemetry_utils.scoped_labels(\n          {telemetry_utils.LABEL_TFX_EXECUTOR: self._executor_class_path}):\n        labels = telemetry_utils.get_labels_dict()\n\n      expected_versions_create_body = {\n          \'name\':\n              self._model_version,\n          \'deployment_uri\':\n              self._serving_path,\n          \'runtime_version\':\n              runner._get_tf_runtime_version(tf.__version__),\n          \'python_version\':\n              runner._get_caip_python_version(\n                  runner._get_tf_runtime_version(tf.__version__)),\n          \'labels\': labels\n      }\n\n    self._mock_models_create.assert_called_with(\n        body=mock.ANY,\n        parent=\'projects/{}\'.format(self._project_id),\n    )\n    (_, models_create_kwargs) = self._mock_models_create.call_args\n    self.assertDictEqual(expected_models_create_body,\n                         models_create_kwargs[\'body\'])\n\n    self._mock_versions_create.assert_called_with(\n        body=mock.ANY,\n        parent=\'projects/{}/models/{}\'.format(self._project_id,\n                                              self._model_name))\n    (_, versions_create_kwargs) = self._mock_versions_create.call_args\n\n    self.assertDictEqual(expected_versions_create_body,\n                         versions_create_kwargs[\'body\'])\n\n    if not expect_set_default:\n      return\n\n    self._mock_set_default.assert_called_with(\n        name=\'projects/{}/models/{}/versions/{}\'.format(\n            self._project_id, self._model_name, self._model_version))\n    self._mock_set_default_execute.assert_called_with()\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testDeployModelForAIPPrediction(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpPredictionMocks()\n\n    runner.deploy_model_for_aip_prediction(self._serving_path,\n                                           self._model_version,\n                                           self._ai_platform_serving_args,\n                                           self._executor_class_path)\n\n    expected_models_create_body = {\n        \'name\': self._model_name,\n        \'regions\': []\n    }\n    self._assertDeployModelMockCalls(\n        expected_models_create_body=expected_models_create_body)\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testDeployModelForAIPPredictionError(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpPredictionMocks()\n\n    self._mock_get.return_value.execute.return_value = {\n        \'done\': True,\n        \'error\': {\n            \'code\': 999,\n            \'message\': \'it was an error.\'\n        },\n    }\n\n    with self.assertRaises(RuntimeError):\n      runner.deploy_model_for_aip_prediction(self._serving_path,\n                                             self._model_version,\n                                             self._ai_platform_serving_args,\n                                             self._executor_class_path)\n\n    expected_models_create_body = {\n        \'name\': self._model_name,\n        \'regions\': []\n    }\n    self._assertDeployModelMockCalls(\n        expected_models_create_body=expected_models_create_body,\n        expect_set_default=False)\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testDeployModelForAIPPredictionWithCustomRegion(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpPredictionMocks()\n\n    self._ai_platform_serving_args[\'regions\'] = [\'custom-region\']\n    runner.deploy_model_for_aip_prediction(self._serving_path,\n                                           self._model_version,\n                                           self._ai_platform_serving_args,\n                                           self._executor_class_path)\n\n    expected_models_create_body = {\n        \'name\': self._model_name,\n        \'regions\': [\'custom-region\'],\n    }\n    self._assertDeployModelMockCalls(\n        expected_models_create_body=expected_models_create_body)\n\n  @mock.patch(\n      \'tfx.extensions.google_cloud_ai_platform.runner.discovery\'\n  )\n  def testDeployModelForAIPPredictionWithCustomRuntime(self, mock_discovery):\n    mock_discovery.build.return_value = self._mock_api_client\n    self._setUpPredictionMocks()\n\n    self._ai_platform_serving_args[\'runtime_version\'] = \'1.23.45\'\n    runner.deploy_model_for_aip_prediction(self._serving_path,\n                                           self._model_version,\n                                           self._ai_platform_serving_args,\n                                           self._executor_class_path)\n\n    with telemetry_utils.scoped_labels(\n        {telemetry_utils.LABEL_TFX_EXECUTOR: self._executor_class_path}):\n      labels = telemetry_utils.get_labels_dict()\n\n    expected_versions_create_body = {\n        \'name\': self._model_version,\n        \'deployment_uri\': self._serving_path,\n        \'runtime_version\': \'1.23.45\',\n        \'python_version\': runner._get_caip_python_version(\'1.23.45\'),\n        \'labels\': labels,\n    }\n    self._assertDeployModelMockCalls(\n        expected_versions_create_body=expected_versions_create_body)\n\n  def testGetTensorflowRuntime(self):\n    self.assertEqual(\'1.14\', runner._get_tf_runtime_version(\'1.14\'))\n    self.assertEqual(\'1.15\', runner._get_tf_runtime_version(\'1.15.0\'))\n    self.assertEqual(\'1.15\', runner._get_tf_runtime_version(\'1.15.1\'))\n    self.assertEqual(\'1.15\', runner._get_tf_runtime_version(\'2.0.0\'))\n    self.assertEqual(\'1.15\', runner._get_tf_runtime_version(\'2.0.1\'))\n    self.assertEqual(\'2.1\', runner._get_tf_runtime_version(\'2.1.0\'))\n    # TODO(b/157039850) Remove this once CAIP model support TF 2.2 runtime.\n    self.assertEqual(\'2.1\', runner._get_tf_runtime_version(\'2.2.0\'))\n\n  def testGetCaipPythonVersion(self):\n    if sys.version_info.major == 2:\n      self.assertEqual(\'2.7\', runner._get_caip_python_version(\'1.14\'))\n      self.assertEqual(\'2.7\', runner._get_caip_python_version(\'1.15\'))\n    else:  # 3.x\n      self.assertEqual(\'3.5\', runner._get_caip_python_version(\'1.14\'))\n      self.assertEqual(\'3.7\', runner._get_caip_python_version(\'1.15\'))\n      self.assertEqual(\'3.7\', runner._get_caip_python_version(\'2.1\'))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/extensions/google_cloud_big_query_ml/__init__.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/airflow/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/airflow/airflow_component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition for Airflow component for TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport functools\nfrom typing import Any, Dict, List, Text, Type\n\nfrom airflow import models\nfrom airflow.operators import python_operator\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.utils import telemetry_utils\n\n\ndef _airflow_component_launcher(\n    component: base_node.BaseNode, component_launcher_class: Type[\n        base_component_launcher.BaseComponentLauncher],\n    pipeline_info: data_types.PipelineInfo, driver_args: data_types.DriverArgs,\n    metadata_connection_config: metadata_store_pb2.ConnectionConfig,\n    beam_pipeline_args: List[Text], additional_pipeline_args: Dict[Text, Any],\n    component_config: base_component_config.BaseComponentConfig,\n    **kwargs) -> None:\n  """"""Helper function to launch TFX component execution.\n\n  This helper function will be called with Airflow env objects which contains\n  run_id that we need to pass into TFX ComponentLauncher.\n\n  Args:\n    component: TFX BaseComponent instance. This instance holds all inputs and\n      outputs placeholders as well as component properties.\n    component_launcher_class: the class of the launcher to launch the component.\n    pipeline_info: a data_types.PipelineInfo instance that holds pipeline\n      properties\n    driver_args: component specific args for driver.\n    metadata_connection_config: configuration for how to connect to metadata.\n    beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n    additional_pipeline_args: a dict of additional pipeline args.\n    component_config: component config to launch the component.\n    **kwargs: Context arguments that will be passed in by Airflow, including:\n      - ti: TaskInstance object from which we can get run_id of the running\n        pipeline.\n      For more details, please refer to the code:\n      https://github.com/apache/airflow/blob/master/airflow/operators/python_operator.py\n  """"""\n  # Populate run id from Airflow task instance.\n  pipeline_info.run_id = kwargs[\'ti\'].get_dagrun().run_id\n  launcher = component_launcher_class.create(\n      component=component,\n      pipeline_info=pipeline_info,\n      driver_args=driver_args,\n      metadata_connection=metadata.Metadata(metadata_connection_config),\n      beam_pipeline_args=beam_pipeline_args,\n      additional_pipeline_args=additional_pipeline_args,\n      component_config=component_config)\n  with telemetry_utils.scoped_labels(\n      {telemetry_utils.LABEL_TFX_RUNNER: \'airflow\'}):\n    launcher.launch()\n\n\nclass AirflowComponent(python_operator.PythonOperator):\n  """"""Airflow-specific TFX Component.\n\n  This class wrap a component run into its own PythonOperator in Airflow.\n  """"""\n\n  def __init__(self, parent_dag: models.DAG, component: base_node.BaseNode,\n               component_launcher_class: Type[\n                   base_component_launcher.BaseComponentLauncher],\n               pipeline_info: data_types.PipelineInfo, enable_cache: bool,\n               metadata_connection_config: metadata_store_pb2.ConnectionConfig,\n               beam_pipeline_args: List[Text],\n               additional_pipeline_args: Dict[Text, Any],\n               component_config: base_component_config.BaseComponentConfig):\n    """"""Constructs an Airflow implementation of TFX component.\n\n    Args:\n      parent_dag: An AirflowPipeline instance as the pipeline DAG.\n      component: An instance of base_node.BaseNode that holds all\n        properties of a logical component.\n      component_launcher_class: the class of the launcher to launch the\n        component.\n      pipeline_info: An instance of data_types.PipelineInfo that holds pipeline\n        properties.\n      enable_cache: Whether or not cache is enabled for this component run.\n      metadata_connection_config: A config proto for metadata connection.\n      beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n      additional_pipeline_args: Additional pipeline args.\n      component_config: component config to launch the component.\n    """"""\n    # Prepare parameters to create TFX worker.\n    driver_args = data_types.DriverArgs(enable_cache=enable_cache)\n\n    super(AirflowComponent, self).__init__(\n        task_id=component.id,\n        provide_context=True,\n        python_callable=functools.partial(\n            _airflow_component_launcher,\n            component=component,\n            component_launcher_class=component_launcher_class,\n            pipeline_info=pipeline_info,\n            driver_args=driver_args,\n            metadata_connection_config=metadata_connection_config,\n            beam_pipeline_args=beam_pipeline_args,\n            additional_pipeline_args=additional_pipeline_args,\n            component_config=component_config),\n        dag=parent_dag)\n'"
tfx/orchestration/airflow/airflow_component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.airflow.airflow_component.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport datetime\nimport os\nfrom airflow import models\nimport mock\n\nimport tensorflow as tf\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.airflow import airflow_component\nfrom tfx.types import component_spec\n\n\nclass _ArtifactTypeA(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeA\'\n\n\nclass _ArtifactTypeB(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeB\'\n\n\nclass _FakeComponentSpec(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'input\': component_spec.ChannelParameter(type=_ArtifactTypeA),\n  }\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeB)}\n\n\nclass _FakeComponent(base_component.BaseComponent):\n\n  SPEC_CLASS = types.ComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n  def __init__(self, spec: types.ComponentSpec):\n    super(_FakeComponent, self).__init__(spec=spec)\n\n\nclass AirflowComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(AirflowComponentTest, self).setUp()\n    self._component = _FakeComponent(\n        _FakeComponentSpec(\n            input=types.Channel(type=_ArtifactTypeA),\n            output=types.Channel(type=_ArtifactTypeB)))\n    self._pipeline_info = data_types.PipelineInfo(\'name\', \'root\')\n    self._driver_args = data_types.DriverArgs(True)\n    self._metadata_connection_config = metadata.sqlite_metadata_connection_config(\n        os.path.join(\n            os.environ.get(\'TEST_TMP_DIR\', self.get_temp_dir()), \'metadata\'))\n    self._parent_dag = models.DAG(\n        dag_id=self._pipeline_info.pipeline_name,\n        start_date=datetime.datetime(2018, 1, 1),\n        schedule_interval=None)\n\n  def testAirflowAdaptor(self):\n    fake_dagrun = collections.namedtuple(\'fake_dagrun\', [\'run_id\'])\n    mock_ti = mock.Mock()\n    mock_ti.get_dagrun.return_value = fake_dagrun(\'run_id\')\n    mock_component_launcher = mock.Mock()\n    mock_component_launcher_class = mock.Mock()\n    mock_component_launcher_class.create.return_value = mock_component_launcher\n    airflow_component._airflow_component_launcher(\n        component=self._component,\n        component_launcher_class=mock_component_launcher_class,\n        pipeline_info=self._pipeline_info,\n        driver_args=self._driver_args,\n        metadata_connection_config=self._metadata_connection_config,\n        beam_pipeline_args=[],\n        additional_pipeline_args={},\n        component_config=None,\n        ti=mock_ti)\n    mock_component_launcher_class.create.assert_called_once()\n    arg_list = mock_component_launcher_class.create.call_args_list\n    self.assertEqual(arg_list[0][1][\'pipeline_info\'].run_id, \'run_id\')\n    mock_component_launcher.launch.assert_called_once()\n\n  @mock.patch(\'functools.partial\')\n  def testAirflowComponent(self, mock_functools_partial):\n    mock_component_launcher_class = mock.Mock()\n    airflow_component.AirflowComponent(\n        parent_dag=self._parent_dag,\n        component=self._component,\n        component_launcher_class=mock_component_launcher_class,\n        pipeline_info=self._pipeline_info,\n        enable_cache=True,\n        metadata_connection_config=self._metadata_connection_config,\n        beam_pipeline_args=[],\n        additional_pipeline_args={},\n        component_config=None)\n    mock_functools_partial.assert_called_once_with(\n        airflow_component._airflow_component_launcher,\n        component=self._component,\n        component_launcher_class=mock_component_launcher_class,\n        pipeline_info=self._pipeline_info,\n        driver_args=mock.ANY,\n        metadata_connection_config=self._metadata_connection_config,\n        beam_pipeline_args=[],\n        additional_pipeline_args={},\n        component_config=None)\n    arg_list = mock_functools_partial.call_args_list\n    self.assertTrue(arg_list[0][1][\'driver_args\'].enable_cache)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/airflow/airflow_dag_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition of Airflow TFX runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nfrom typing import Any, Dict, Optional, Text, Union\n\nimport absl\nfrom airflow import models\n\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration import tfx_runner\nfrom tfx.orchestration.airflow import airflow_component\nfrom tfx.orchestration.config import config_utils\nfrom tfx.orchestration.config import pipeline_config\n\n\nclass AirflowPipelineConfig(pipeline_config.PipelineConfig):\n  """"""Pipeline config for AirflowDagRunner.""""""\n\n  def __init__(self, airflow_dag_config: Dict[Text, Any] = None, **kwargs):\n    """"""Creates an instance of AirflowPipelineConfig.\n\n    Args:\n      airflow_dag_config: Configs of Airflow DAG model. See\n        https://airflow.apache.org/_api/airflow/models/dag/index.html#airflow.models.dag.DAG\n          for the full spec.\n      **kwargs: keyword args for PipelineConfig.\n    """"""\n\n    super(AirflowPipelineConfig, self).__init__(**kwargs)\n    self.airflow_dag_config = airflow_dag_config or {}\n\n\nclass AirflowDagRunner(tfx_runner.TfxRunner):\n  """"""Tfx runner on Airflow.""""""\n\n  def __init__(self,\n               config: Optional[Union[Dict[Text, Any],\n                                      AirflowPipelineConfig]] = None):\n    """"""Creates an instance of AirflowDagRunner.\n\n    Args:\n      config: Optional Airflow pipeline config for customizing the launching of\n        each component.\n    """"""\n    if config and not isinstance(config, AirflowPipelineConfig):\n      absl.logging.warning(\n          \'Pass config as a dict type is going to deprecated in 0.1.16. Use AirflowPipelineConfig type instead.\',\n          PendingDeprecationWarning)\n      config = AirflowPipelineConfig(airflow_dag_config=config)\n    super(AirflowDagRunner, self).__init__(config)\n\n  def run(self, tfx_pipeline: pipeline.Pipeline):\n    """"""Deploys given logical pipeline on Airflow.\n\n    Args:\n      tfx_pipeline: Logical pipeline containing pipeline args and components.\n\n    Returns:\n      An Airflow DAG.\n    """"""\n\n    # Merge airflow-specific configs with pipeline args\n    airflow_dag = models.DAG(\n        dag_id=tfx_pipeline.pipeline_info.pipeline_name,\n        **self._config.airflow_dag_config)\n    if \'tmp_dir\' not in tfx_pipeline.additional_pipeline_args:\n      tmp_dir = os.path.join(tfx_pipeline.pipeline_info.pipeline_root, \'.temp\',\n                             \'\')\n      tfx_pipeline.additional_pipeline_args[\'tmp_dir\'] = tmp_dir\n\n    component_impl_map = {}\n    for tfx_component in tfx_pipeline.components:\n\n      (component_launcher_class,\n       component_config) = config_utils.find_component_launch_info(\n           self._config, tfx_component)\n      current_airflow_component = airflow_component.AirflowComponent(\n          airflow_dag,\n          component=tfx_component,\n          component_launcher_class=component_launcher_class,\n          pipeline_info=tfx_pipeline.pipeline_info,\n          enable_cache=tfx_pipeline.enable_cache,\n          metadata_connection_config=tfx_pipeline.metadata_connection_config,\n          beam_pipeline_args=tfx_pipeline.beam_pipeline_args,\n          additional_pipeline_args=tfx_pipeline.additional_pipeline_args,\n          component_config=component_config)\n      component_impl_map[tfx_component] = current_airflow_component\n      for upstream_node in tfx_component.upstream_nodes:\n        assert upstream_node in component_impl_map, (\'Components is not in \'\n                                                     \'topological order\')\n        current_airflow_component.set_upstream(\n            component_impl_map[upstream_node])\n\n    return airflow_dag\n'"
tfx/orchestration/airflow/airflow_dag_runner_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.airflow.airflow_dag_runner.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport mock\nimport tensorflow as tf\n\n# TODO(b/158143615): importing airflow after kerastuner causes issue.\nfrom tfx.orchestration.airflow import airflow_dag_runner  # pylint: disable=g-bad-import-order\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import pipeline\nfrom tfx.types import component_spec\n\n\nclass _ArtifactTypeA(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeA\'\n\n\nclass _ArtifactTypeB(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeB\'\n\n\nclass _ArtifactTypeC(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeC\'\n\n\nclass _ArtifactTypeD(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeD\'\n\n\nclass _ArtifactTypeE(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeE\'\n\n\nclass _FakeComponentSpecA(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {}\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeA)}\n\n\nclass _FakeComponentSpecB(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\'a\': component_spec.ChannelParameter(type=_ArtifactTypeA)}\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeB)}\n\n\nclass _FakeComponentSpecC(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'a\': component_spec.ChannelParameter(type=_ArtifactTypeA),\n      \'b\': component_spec.ChannelParameter(type=_ArtifactTypeB)\n  }\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeC)}\n\n\nclass _FakeComponentSpecD(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'b\': component_spec.ChannelParameter(type=_ArtifactTypeB),\n      \'c\': component_spec.ChannelParameter(type=_ArtifactTypeC),\n  }\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeD)}\n\n\nclass _FakeComponentSpecE(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'a\': component_spec.ChannelParameter(type=_ArtifactTypeA),\n      \'b\': component_spec.ChannelParameter(type=_ArtifactTypeB),\n      \'d\': component_spec.ChannelParameter(type=_ArtifactTypeD),\n  }\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_ArtifactTypeE)}\n\n\nclass _FakeComponent(base_component.BaseComponent):\n\n  SPEC_CLASS = types.ComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n  def __init__(self, spec: types.ComponentSpec):\n    instance_name = spec.__class__.__name__.replace(\n        \'_FakeComponentSpec\', \'\')\n    super(_FakeComponent, self).__init__(\n        spec=spec, instance_name=instance_name)\n\n\nclass AirflowDagRunnerTest(tf.test.TestCase):\n\n  @mock.patch(\n      \'tfx.orchestration.airflow.airflow_component.AirflowComponent\'\n  )\n  @mock.patch(\'airflow.models.DAG\')\n  def testAirflowDagRunner(self, mock_airflow_dag_class,\n                           mock_airflow_component_class):\n    mock_airflow_dag_class.return_value = \'DAG\'\n    mock_airflow_component_a = mock.Mock()\n    mock_airflow_component_b = mock.Mock()\n    mock_airflow_component_c = mock.Mock()\n    mock_airflow_component_d = mock.Mock()\n    mock_airflow_component_e = mock.Mock()\n    mock_airflow_component_class.side_effect = [\n        mock_airflow_component_a, mock_airflow_component_b,\n        mock_airflow_component_c, mock_airflow_component_d,\n        mock_airflow_component_e\n    ]\n\n    airflow_config = {\n        \'schedule_interval\': \'* * * * *\',\n        \'start_date\': datetime.datetime(2019, 1, 1)\n    }\n    component_a = _FakeComponent(\n        _FakeComponentSpecA(output=types.Channel(type=_ArtifactTypeA)))\n    component_b = _FakeComponent(\n        _FakeComponentSpecB(\n            a=component_a.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeB)))\n    component_c = _FakeComponent(\n        _FakeComponentSpecC(\n            a=component_a.outputs[\'output\'],\n            b=component_b.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeC)))\n    component_d = _FakeComponent(\n        _FakeComponentSpecD(\n            b=component_b.outputs[\'output\'],\n            c=component_c.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeD)))\n    component_e = _FakeComponent(\n        _FakeComponentSpecE(\n            a=component_a.outputs[\'output\'],\n            b=component_b.outputs[\'output\'],\n            d=component_d.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeE)))\n\n    test_pipeline = pipeline.Pipeline(\n        pipeline_name=\'x\',\n        pipeline_root=\'y\',\n        metadata_connection_config=None,\n        components=[\n            component_d, component_c, component_a, component_b, component_e\n        ])\n    runner = airflow_dag_runner.AirflowDagRunner(\n        airflow_dag_runner.AirflowPipelineConfig(\n            airflow_dag_config=airflow_config))\n    runner.run(test_pipeline)\n\n    mock_airflow_component_a.set_upstream.assert_not_called()\n    mock_airflow_component_b.set_upstream.assert_has_calls(\n        [mock.call(mock_airflow_component_a)])\n    mock_airflow_component_c.set_upstream.assert_has_calls([\n        mock.call(mock_airflow_component_a),\n        mock.call(mock_airflow_component_b)\n    ],\n                                                           any_order=True)\n    mock_airflow_component_d.set_upstream.assert_has_calls([\n        mock.call(mock_airflow_component_b),\n        mock.call(mock_airflow_component_c)\n    ],\n                                                           any_order=True)\n    mock_airflow_component_e.set_upstream.assert_has_calls([\n        mock.call(mock_airflow_component_a),\n        mock.call(mock_airflow_component_b),\n        mock.call(mock_airflow_component_d)\n    ],\n                                                           any_order=True)\n\n  def testAirflowDagRunnerInitBackwardCompatible(self):\n    airflow_config = {\n        \'schedule_interval\': \'* * * * *\',\n        \'start_date\': datetime.datetime(2019, 1, 1)\n    }\n\n    runner = airflow_dag_runner.AirflowDagRunner(airflow_config)\n\n    self.assertEqual(airflow_config, runner._config.airflow_dag_config)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/airflow/airflow_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Deprecated definition of Airflow TFX runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.orchestration.airflow import airflow_dag_runner\n\nAirflowDAGRunner = deprecation.deprecated_alias(  # pylint: disable=invalid-name\n    deprecated_name=\'airflow_runner.AirflowDAGRunner\',\n    name=\'airflow_dag_runner.AirflowDagRunner\',\n    func_or_class=airflow_dag_runner.AirflowDagRunner)\n'"
tfx/orchestration/airflow/test_utils.py,0,"b'# Lint as: python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common utility for testing airflow-based orchestrator.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport subprocess\nimport time\n\nfrom typing import Text\nfrom absl import logging\nimport docker\n\n_MYSQL_POLLING_INTERVAL_SEC = 2\n_MYSQL_POLLING_MAX_ATTEMPTS = 60\n_MYSQL_PORT = \'3306/tcp\'\n\n\ndef create_mysql_container(container_name: Text) -> int:\n  """"""Create a mysql docker container and returns port to it.\n\n  A created mysql will have \'airflow\' database and \'tfx\' user without password.\n\n  Args:\n      container_name: A name of the new container.\n\n  Returns:\n      The new port number.\n\n  Raises:\n      RuntimeError: When mysql couldn\'t respond in pre-defined time limit or\n                    failed to run initialization sqls.\n  """"""\n\n  client = docker.from_env()\n  container = client.containers.run(\n      \'mysql:5.7\',\n      name=container_name,\n      environment=[\'MYSQL_ROOT_PASSWORD=root\'],\n      ports={_MYSQL_PORT: None},\n      detach=True)\n  container.reload()  # required to get auto-assigned ports\n  port = int(container.ports[_MYSQL_PORT][0][\'HostPort\'])\n\n  for _ in range(_MYSQL_POLLING_MAX_ATTEMPTS):\n    logging.info(\'Waiting for mysqld container...\')\n    time.sleep(_MYSQL_POLLING_INTERVAL_SEC)\n    # MySQL availability should be checked with a network access to distinguish\n    # a temporary server with a real mysql. See\n    # https://github.com/docker-library/mysql/blob/bc6e37a2bed792b1c4fc6ab1ec3ce316e6a5f061/5.7/docker-entrypoint.sh#L360-L362\n    check_available = subprocess.run(  # pylint: disable=subprocess-run-check\n        [\n            \'mysql\',\n            \'-uroot\',\n            \'-proot\',\n            \'-h\',\n            \'127.0.0.1\',\n            \'-P\',\n            str(port),\n            \'-e\',\n            \'SELECT 1;\',\n        ],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE)\n    if check_available.returncode == 0:\n      break\n  else:\n    logging.error(\'Logs from mysql container:\\n%s\', container.logs())\n    raise RuntimeError(\n        \'MySql could not started in %d seconds\' %\n        (_MYSQL_POLLING_INTERVAL_SEC * _MYSQL_POLLING_MAX_ATTEMPTS))\n\n  create_db_sql = """"""\n      CREATE USER \'tfx\'@\'%\' IDENTIFIED BY \'\';\n      GRANT ALL ON *.* TO \'tfx\'@\'%\' WITH GRANT OPTION;\n      FLUSH PRIVILEGES;\n      SET GLOBAL explicit_defaults_for_timestamp = 1;\n      CREATE DATABASE airflow;\n  """"""\n  exit_code, output_bytes = container.exec_run(\'mysql -uroot -proot -e ""%s""\' %\n                                               create_db_sql)\n  if exit_code != 0:\n    output = output_bytes.decode(\'utf-8\')\n    logging.error(\'Failed to run sql for initialization:\\n%s\', output)\n    raise RuntimeError(\'Failed to run initialization SQLs: {}\'.format(output))\n\n  return port\n\n\ndef delete_mysql_container(container_name: Text):\n  """"""Delete a mysql docker container with name.\n\n  Args:\n      container_name: A name of the new container.\n  """"""\n  client = docker.from_env()\n  container = client.containers.get(container_name)\n  container.remove(force=True)\n'"
tfx/orchestration/beam/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/beam/beam_dag_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Definition of Beam TFX runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom typing import Any, Iterable, List, Optional, Text, Type\n\nimport absl\nimport apache_beam as beam\n\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration import tfx_runner\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.config import config_utils\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.orchestration.launcher import docker_component_launcher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.utils import telemetry_utils\n\n\n# TODO(jyzhao): confirm it\'s re-executable, add test case.\n@beam.typehints.with_input_types(Any)\n@beam.typehints.with_output_types(Any)\nclass _ComponentAsDoFn(beam.DoFn):\n  """"""Wrap component as beam DoFn.""""""\n\n  def __init__(self, component: base_node.BaseNode,\n               component_launcher_class: Type[\n                   base_component_launcher.BaseComponentLauncher],\n               component_config: base_component_config.BaseComponentConfig,\n               tfx_pipeline: pipeline.Pipeline):\n    """"""Initialize the _ComponentAsDoFn.\n\n    Args:\n      component: Component that to be executed.\n      component_launcher_class: The class of the launcher to launch the\n        component.\n      component_config: component config to launch the component.\n      tfx_pipeline: Logical pipeline that contains pipeline related information.\n    """"""\n    driver_args = data_types.DriverArgs(enable_cache=tfx_pipeline.enable_cache)\n    metadata_connection = metadata.Metadata(\n        tfx_pipeline.metadata_connection_config)\n    self._component_launcher = component_launcher_class.create(\n        component=component,\n        pipeline_info=tfx_pipeline.pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=tfx_pipeline.beam_pipeline_args,\n        additional_pipeline_args=tfx_pipeline.additional_pipeline_args,\n        component_config=component_config)\n    self._component_id = component.id\n\n  def process(self, element: Any, *signals: Iterable[Any]) -> None:\n    """"""Executes component based on signals.\n\n    Args:\n      element: a signal element to trigger the component.\n      *signals: side input signals indicate completeness of upstream components.\n    """"""\n    for signal in signals:\n      assert not list(signal), \'Signal PCollection should be empty.\'\n    self._run_component()\n\n  def _run_component(self) -> None:\n    absl.logging.info(\'Component %s is running.\', self._component_id)\n    self._component_launcher.launch()\n    absl.logging.info(\'Component %s is finished.\', self._component_id)\n\n\nclass BeamDagRunner(tfx_runner.TfxRunner):\n  """"""Tfx runner on Beam.""""""\n\n  def __init__(self,\n               beam_orchestrator_args: Optional[List[Text]] = None,\n               config: Optional[pipeline_config.PipelineConfig] = None):\n    """"""Initializes BeamDagRunner as a TFX orchestrator.\n\n    Args:\n      beam_orchestrator_args: beam args for the beam orchestrator. Note that\n        this is different from the beam_pipeline_args within\n        additional_pipeline_args, which is for beam pipelines in components.\n      config: Optional pipeline config for customizing the launching of each\n        component. Defaults to pipeline config that supports\n        InProcessComponentLauncher and DockerComponentLauncher.\n    """"""\n    if config is None:\n      config = pipeline_config.PipelineConfig(\n          supported_launcher_classes=[\n              in_process_component_launcher.InProcessComponentLauncher,\n              docker_component_launcher.DockerComponentLauncher,\n          ],\n      )\n    super(BeamDagRunner, self).__init__(config)\n    self._beam_orchestrator_args = beam_orchestrator_args\n\n  def run(self, tfx_pipeline: pipeline.Pipeline) -> None:\n    """"""Deploys given logical pipeline on Beam.\n\n    Args:\n      tfx_pipeline: Logical pipeline containing pipeline args and components.\n    """"""\n    # For CLI, while creating or updating pipeline, pipeline_args are extracted\n    # and hence we avoid deploying the pipeline.\n    if \'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\' in os.environ:\n      return\n\n    tfx_pipeline.pipeline_info.run_id = datetime.datetime.now().isoformat()\n\n    with telemetry_utils.scoped_labels(\n        {telemetry_utils.LABEL_TFX_RUNNER: \'beam\'}):\n      with beam.Pipeline(argv=self._beam_orchestrator_args) as p:\n        # Uses for triggering the component DoFns.\n        root = p | \'CreateRoot\' >> beam.Create([None])\n\n        # Stores mapping of component to its signal.\n        signal_map = {}\n        # pipeline.components are in topological order.\n        for component in tfx_pipeline.components:\n          component_id = component.id\n\n          # Signals from upstream components.\n          signals_to_wait = []\n          if component.upstream_nodes:\n            for upstream_node in component.upstream_nodes:\n              assert upstream_node in signal_map, (\'Components is not in \'\n                                                   \'topological order\')\n              signals_to_wait.append(signal_map[upstream_node])\n          absl.logging.info(\'Component %s depends on %s.\', component_id,\n                            [s.producer.full_label for s in signals_to_wait])\n\n          (component_launcher_class,\n           component_config) = config_utils.find_component_launch_info(\n               self._config, component)\n\n          # Each signal is an empty PCollection. AsIter ensures component will\n          # be triggered after upstream components are finished.\n          signal_map[component] = (\n              root\n              | \'Run[%s]\' % component_id >> beam.ParDo(\n                  _ComponentAsDoFn(component, component_launcher_class,\n                                   component_config, tfx_pipeline),\n                  *[beam.pvalue.AsIter(s) for s in signals_to_wait]))\n          absl.logging.info(\'Component %s is scheduled.\', component_id)\n'"
tfx/orchestration/beam/beam_dag_runner_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.beam.beam_dag_runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam import beam_dag_runner\nfrom tfx.types.component_spec import ChannelParameter\n\n_executed_components = []\n\n\nclass _ArtifactTypeA(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeA\'\n\n\nclass _ArtifactTypeB(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeB\'\n\n\nclass _ArtifactTypeC(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeC\'\n\n\nclass _ArtifactTypeD(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeD\'\n\n\nclass _ArtifactTypeE(types.Artifact):\n  TYPE_NAME = \'ArtifactTypeE\'\n\n\nclass _FakeComponentAsDoFn(beam_dag_runner._ComponentAsDoFn):\n\n  def _run_component(self):\n    _executed_components.append(self._component_id)\n\n\n# We define fake component spec classes below for testing. Note that we can\'t\n# programmatically generate component using anonymous classes for testing\n# because of a limitation in the ""dill"" pickler component used by Apache Beam.\n# An alternative we considered but rejected here was to write a function that\n# returns anonymous classes within that function\'s closure (as is done in\n# tfx/orchestration/pipeline_test.py), but that strategy does not work here\n# as these anonymous classes cannot be used with Beam, since they cannot be\n# pickled with the ""dill"" library.\nclass _FakeComponentSpecA(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {}\n  OUTPUTS = {\'output\': ChannelParameter(type=_ArtifactTypeA)}\n\n\nclass _FakeComponentSpecB(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\'a\': ChannelParameter(type=_ArtifactTypeA)}\n  OUTPUTS = {\'output\': ChannelParameter(type=_ArtifactTypeB)}\n\n\nclass _FakeComponentSpecC(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\'a\': ChannelParameter(type=_ArtifactTypeA)}\n  OUTPUTS = {\'output\': ChannelParameter(type=_ArtifactTypeC)}\n\n\nclass _FakeComponentSpecD(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'b\': ChannelParameter(type=_ArtifactTypeB),\n      \'c\': ChannelParameter(type=_ArtifactTypeC),\n  }\n  OUTPUTS = {\'output\': ChannelParameter(type=_ArtifactTypeD)}\n\n\nclass _FakeComponentSpecE(types.ComponentSpec):\n  PARAMETERS = {}\n  INPUTS = {\n      \'a\': ChannelParameter(type=_ArtifactTypeA),\n      \'b\': ChannelParameter(type=_ArtifactTypeB),\n      \'d\': ChannelParameter(type=_ArtifactTypeD),\n  }\n  OUTPUTS = {\'output\': ChannelParameter(type=_ArtifactTypeE)}\n\n\nclass _FakeComponent(base_component.BaseComponent):\n\n  SPEC_CLASS = types.ComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)\n\n  def __init__(self, spec: types.ComponentSpec):\n    instance_name = spec.__class__.__name__.replace(\n        \'_FakeComponentSpec\', \'\').lower()\n    super(_FakeComponent, self).__init__(spec=spec, instance_name=instance_name)\n\n\nclass BeamDagRunnerTest(tf.test.TestCase):\n\n  @mock.patch.multiple(\n      beam_dag_runner,\n      _ComponentAsDoFn=_FakeComponentAsDoFn,\n  )\n  def testRun(self):\n    component_a = _FakeComponent(\n        _FakeComponentSpecA(output=types.Channel(type=_ArtifactTypeA)))\n    component_b = _FakeComponent(\n        _FakeComponentSpecB(\n            a=component_a.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeB)))\n    component_c = _FakeComponent(\n        _FakeComponentSpecC(\n            a=component_a.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeC)))\n    component_c.add_upstream_node(component_b)\n    component_d = _FakeComponent(\n        _FakeComponentSpecD(\n            b=component_b.outputs[\'output\'],\n            c=component_c.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeD)))\n    component_e = _FakeComponent(\n        _FakeComponentSpecE(\n            a=component_a.outputs[\'output\'],\n            b=component_b.outputs[\'output\'],\n            d=component_d.outputs[\'output\'],\n            output=types.Channel(type=_ArtifactTypeE)))\n\n    test_pipeline = pipeline.Pipeline(\n        pipeline_name=\'x\',\n        pipeline_root=\'y\',\n        metadata_connection_config=metadata_store_pb2.ConnectionConfig(),\n        components=[\n            component_d, component_c, component_a, component_b, component_e\n        ])\n\n    beam_dag_runner.BeamDagRunner().run(test_pipeline)\n    self.assertEqual(_executed_components, [\n        \'_FakeComponent.a\', \'_FakeComponent.b\', \'_FakeComponent.c\',\n        \'_FakeComponent.d\', \'_FakeComponent.e\'\n    ])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/config/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/config/base_component_config.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for TFX component configs.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom six import with_metaclass\n\nfrom tfx.utils import json_utils\n\n\nclass BaseComponentConfig(with_metaclass(abc.ABCMeta, json_utils.Jsonable)):\n  """"""Base class for TFX component configs.""""""\n  pass\n'"
tfx/orchestration/config/config_utils.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utilities for handling common config operations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Tuple, Type\n\nfrom tfx.components.base import base_component\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.launcher import base_component_launcher\n\n\ndef find_component_launch_info(\n    p_config: pipeline_config.PipelineConfig,\n    component: base_component.BaseComponent,\n) -> Tuple[Type[base_component_launcher.BaseComponentLauncher],\n           Optional[base_component_config.BaseComponentConfig]]:\n  """"""Find a launcher and component config to launch the component.\n\n  The default lookup logic goes through the `supported_launcher_classes`\n  in sequence for each config from the `default_component_configs`. User can\n  override a single component setting by `component_config_overrides`. The\n  method returns the first component config and launcher which together can\n  launch the executor_spec of the component.\n  Subclass may customize the logic by overriding the method.\n\n  Args:\n    p_config: the pipeline config.\n    component: the component to launch.\n\n  Returns:\n    The found tuple of component launcher class and the compatible component\n    config.\n\n  Raises:\n    RuntimeError: if no supported launcher is found.\n  """"""\n  if component.id in p_config.component_config_overrides:\n    component_configs = [p_config.component_config_overrides[component.id]]\n  else:\n    # Add None to the end of the list to find launcher with no component\n    # config\n    component_configs = p_config.default_component_configs + [None]\n\n  for component_config in component_configs:\n    for component_launcher_class in p_config.supported_launcher_classes:\n      if component_launcher_class.can_launch(component.executor_spec,\n                                             component_config):\n        return (component_launcher_class, component_config)\n  raise RuntimeError(\'No launcher info can be found for component ""%s"".\' %\n                     component.component_id)\n'"
tfx/orchestration/config/config_utils_test.py,2,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.config.config_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration.config import config_utils\nfrom tfx.orchestration.config import docker_component_config\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.launcher import docker_component_launcher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.orchestration.launcher import test_utils\nfrom tfx.types import channel_utils\n\n\nclass ConfigUtilsTest(tf.test.TestCase):\n\n  def testFindComponentLaunchInfoReturnDefaultLaunchInfo(self):\n    input_artifact = test_utils._InputArtifact()\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]))\n    p_config = pipeline_config.PipelineConfig()\n\n    (launcher_class,\n     c_config) = config_utils.find_component_launch_info(p_config, component)\n\n    self.assertEqual(in_process_component_launcher.InProcessComponentLauncher,\n                     launcher_class)\n    self.assertIsNone(c_config)\n\n  def testFindComponentLaunchInfoReturnConfigOverride(self):\n    input_artifact = test_utils._InputArtifact()\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]),\n        custom_executor_spec=executor_spec.ExecutorContainerSpec(\n            image=\'gcr://test\', args=[\'{{input_dict[""input""][0].uri}}\']))\n    default_config = docker_component_config.DockerComponentConfig()\n    override_config = docker_component_config.DockerComponentConfig(name=\'test\')\n    p_config = pipeline_config.PipelineConfig(\n        supported_launcher_classes=[\n            docker_component_launcher.DockerComponentLauncher\n        ],\n        default_component_configs=[default_config],\n        component_config_overrides={\n            \'_FakeComponent.FakeComponent\': override_config\n        })\n\n    (launcher_class,\n     c_config) = config_utils.find_component_launch_info(p_config, component)\n\n    self.assertEqual(docker_component_launcher.DockerComponentLauncher,\n                     launcher_class)\n    self.assertEqual(override_config, c_config)\n\n  def testFindComponentLaunchInfoFailWithNoLauncherClassFound(self):\n    input_artifact = test_utils._InputArtifact()\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]))\n    p_config = pipeline_config.PipelineConfig(supported_launcher_classes=[\n        docker_component_launcher.DockerComponentLauncher\n    ])\n\n    with self.assertRaises(RuntimeError):\n      # DockerComponentLauncher cannot launch class executor.\n      config_utils.find_component_launch_info(p_config, component)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/config/docker_component_config.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Component config for docker run.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, List, Text, Union\n\nfrom tfx.orchestration.config import base_component_config\n\n\nclass DockerComponentConfig(base_component_config.BaseComponentConfig):\n  """"""Component config which holds docker run args.\n\n  Attributes:\n    docker_server_url: URL to the Docker server. For example,\n      `unix:///var/run/docker.sock` or `tcp://127.0.0.1:1234`. Uses environment\n        viarable to initialize the docker client if this parameter is not set.\n        Default: `None`.\n    environment: Environment variables to set inside the container, as a\n      dictionary or a list of strings in the format [""SOMEVARIABLE=xxx""].\n    name: The name for this container.\n    privileged: Give extended privileges to this container. Default: `False`.\n    remove: Remove the container when it has finished running. Default: `False`.\n    user: Username or UID to run commands as inside the container.\n    volumes: A dictionary to configure volumes mounted inside the container. The\n      key is either the host path or a volume name, and the value is a\n      dictionary with the keys: {bind: mode}.\n      For example:\n      `{\'/home/user1\': {\'bind\': \'/mnt/vol2\', \'mode\': \'rw\'},\n       \'/var/www\': {\'bind\': \'/mnt/vol1\', \'mode\': \'ro\'}}`\n    additional_run_args: Additional run args to pass to\n      `docker.client.containers.run`. See\n      https://docker-py.readthedocs.io/en/stable/containers.html#docker.models.containers.ContainerCollection.run.\n  """"""\n\n  def __init__(self,\n               docker_server_url: Text = None,\n               environment: Union[Dict[Text, Text], List[Text]] = None,\n               name: Text = None,\n               privileged: bool = False,\n               user: Union[Text, int] = None,\n               volumes: Union[Dict[Text, Dict[Text, Text]], List[Text]] = None,\n               **kwargs):\n    self.docker_server_url = docker_server_url\n    self.environment = environment\n    self.name = name\n    self.privileged = privileged\n    self.user = user\n    self.volumes = volumes\n    self.additional_run_args = kwargs\n\n  def to_run_args(self):\n    if self.additional_run_args:\n      args = self.additional_run_args.copy()\n    else:\n      args = {}\n    args.update(privileged=self.privileged)\n    if self.environment:\n      args.update(environment=self.environment)\n    if self.name:\n      args.update(name=self.name)\n    if self.user:\n      args.update(user=self.user)\n    if self.volumes:\n      args.update(volumes=self.volumes)\n    return args\n'"
tfx/orchestration/config/docker_component_config_test.py,2,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.config.docker_component_config.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.orchestration.config import docker_component_config\n\n\nclass DockerComponentConfigTest(tf.test.TestCase):\n\n  def testToRunArgs(self):\n    docker_config = docker_component_config.DockerComponentConfig(\n        docker_server_url=\'http://mock.docker.server\',\n        environment={\'name\': \'value\'},\n        privileged=True,\n        volumes=[\'/local/etc:/local/etc\'],\n        ports={\'2222/tcp\': 3333})\n\n    run_args = docker_config.to_run_args()\n\n    self.assertEqual(\'http://mock.docker.server\',\n                     docker_config.docker_server_url)\n    self.assertDictEqual({\'name\': \'value\'}, run_args[\'environment\'])\n    self.assertTrue(run_args[\'privileged\'])\n    self.assertListEqual([\'/local/etc:/local/etc\'], run_args[\'volumes\'])\n    self.assertDictEqual({\'2222/tcp\': 3333}, run_args[\'ports\'])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/config/kubernetes_component_config.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Component config for Kubernets Pod execution.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Text, Union\n\nfrom kubernetes import client\n\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.launcher import container_common\n\n\nclass KubernetesComponentConfig(base_component_config.BaseComponentConfig):\n  """"""Component config which holds Kubernetes Pod execution args.\n\n  Attributes:\n    pod: the spec for a Pod. It can either be an instance of client.V1Pod or a\n      dict of a Pod spec. The spec details are:\n      https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1Pod.md\n  """"""\n\n  def __init__(self, pod: Union[client.V1Pod, Dict[Text, Any]]):\n    if not pod:\n      raise ValueError(\'pod must have a value.\')\n    self.pod = container_common.to_swagger_dict(pod)\n'"
tfx/orchestration/config/pipeline_config.py,0,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Settings for controlling how to run a pipeline.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, List, Text, Type\n\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.orchestration.launcher import in_process_component_launcher\n\n\nclass PipelineConfig(object):\n  """"""Config class which controls how to run a pipeline.\n\n  Attributes\n    supported_launcher_classes: A list of component launcher classes that are\n      supported by the current pipeline. List sequence determines the order in\n      which launchers are chosen for each component being run.\n    default_component_configs: A list of default component configs which will\n      be used as default component config to run each component in the pipeline.\n      List sequence determines the order in which config are chosen for each\n      component being run.\n    component_config_overrides: component configs for customizing the launching\n      of each component. The key is the component ID.\n  """"""\n\n  # TODO(hongyes): figure out the best practice to put the\n  # SUPPORTED_LAUNCHER_CLASSES.\n  def __init__(self,\n               supported_launcher_classes: List[Type[\n                   base_component_launcher.BaseComponentLauncher]] = None,\n               default_component_configs: List[\n                   base_component_config.BaseComponentConfig] = None,\n               component_config_overrides: Dict[\n                   Text, base_component_config.BaseComponentConfig] = None):\n    self.supported_launcher_classes = supported_launcher_classes or [\n        in_process_component_launcher.InProcessComponentLauncher\n    ]\n    self.default_component_configs = default_component_configs or []\n    self.component_config_overrides = component_config_overrides or {}\n    self._validate_configs()\n\n  def _validate_configs(self):\n    """"""Validate the config settings.""""""\n    if len(self.supported_launcher_classes) > len(\n        set(self.supported_launcher_classes)):\n      raise ValueError(\n          \'supported_launcher_classes must not have duplicate types\')\n    default_component_config_classes = [\n        type(config) for config in self.default_component_configs\n    ]\n    if len(default_component_config_classes) > len(\n        set(default_component_config_classes)):\n      raise ValueError(\n          \'default_component_configs must not have configs with the same type\')\n'"
tfx/orchestration/config/pipeline_config_test.py,2,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.config.pipeline_config.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.orchestration.config import docker_component_config\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.launcher import in_process_component_launcher\n\n\nclass PipelineConfigTest(tf.test.TestCase):\n\n  def testInitSucceed(self):\n    # Init with default parameters\n    pipeline_config.PipelineConfig()\n    # Init with custom parameters\n    pipeline_config.PipelineConfig(\n        supported_launcher_classes=[\n            in_process_component_launcher.InProcessComponentLauncher\n        ],\n        default_component_configs=[\n            docker_component_config.DockerComponentConfig()\n        ],\n        component_config_overrides={\n            \'comp-1\', docker_component_config.DockerComponentConfig()\n        })\n\n  def testInitFailWithDupLauncherClasses(self):\n    with self.assertRaises(ValueError):\n      pipeline_config.PipelineConfig(supported_launcher_classes=[\n          in_process_component_launcher.InProcessComponentLauncher,\n          in_process_component_launcher.InProcessComponentLauncher,\n      ])\n\n  def testInitFailWithDupDefaultComponentConfigClasses(self):\n    with self.assertRaises(ValueError):\n      pipeline_config.PipelineConfig(default_component_configs=[\n          docker_component_config.DockerComponentConfig(),\n          docker_component_config.DockerComponentConfig(),\n      ])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/experimental/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/kubeflow/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/kubeflow/base_component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Kubeflow Pipelines based implementation of TFX components.\n\nThese components are lightweight wrappers around the KFP DSL\'s ContainerOp,\nand ensure that the container gets called with the right set of input\narguments. It also ensures that each component exports named output\nattributes that are consistent with those provided by the native TFX\ncomponents, thus ensuring that both types of pipeline definitions are\ncompatible.\nNote: This requires Kubeflow Pipelines SDK to be installed.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nfrom typing import Dict, Optional, Set, Text, Type\n\nimport absl\nfrom kfp import dsl\nfrom kubernetes import client as k8s_client\n\nfrom google.protobuf import json_format\nfrom tfx.components.base import base_node as tfx_base_node\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.kubeflow import node_wrapper\nfrom tfx.orchestration.kubeflow import utils\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.utils import json_utils\n\n_COMMAND = [\n    \'python\', \'/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py\'\n]\n\n_WORKFLOW_ID_KEY = \'WORKFLOW_ID\'\n\n\n# TODO(hongyes): renaming the name to KubeflowComponent.\nclass BaseComponent(object):\n  """"""Base component for all Kubeflow pipelines TFX components.\n\n  Returns a wrapper around a KFP DSL ContainerOp class, and adds named output\n  attributes that match the output names for the corresponding native TFX\n  components.\n  """"""\n\n  def __init__(\n      self,\n      component: tfx_base_node.BaseNode,\n      component_launcher_class: Type[\n          base_component_launcher.BaseComponentLauncher],\n      depends_on: Set[dsl.ContainerOp],\n      pipeline: tfx_pipeline.Pipeline,\n      pipeline_name: Text,\n      pipeline_root: dsl.PipelineParam,\n      tfx_image: Text,\n      kubeflow_metadata_config: Optional[kubeflow_pb2.KubeflowMetadataConfig],\n      component_config: base_component_config.BaseComponentConfig,\n      pod_labels_to_attach: Optional[Dict[Text, Text]] = None):\n    """"""Creates a new Kubeflow-based component.\n\n    This class essentially wraps a dsl.ContainerOp construct in Kubeflow\n    Pipelines.\n\n    Args:\n      component: The logical TFX component to wrap.\n      component_launcher_class: the class of the launcher to launch the\n        component.\n      depends_on: The set of upstream KFP ContainerOp components that this\n        component will depend on.\n      pipeline: The logical TFX pipeline to which this component belongs.\n      pipeline_name: The name of the TFX pipeline.\n      pipeline_root: The pipeline root specified, as a dsl.PipelineParam\n      tfx_image: The container image to use for this component.\n      kubeflow_metadata_config: Configuration settings for connecting to the\n        MLMD store in a Kubeflow cluster.\n      component_config: Component config to launch the component.\n      pod_labels_to_attach: Optional dict of pod labels to attach to the\n        GKE pod.\n    """"""\n    component_launcher_class_path = \'.\'.join([\n        component_launcher_class.__module__, component_launcher_class.__name__\n    ])\n\n    serialized_component = utils.replace_placeholder(\n        json_utils.dumps(node_wrapper.NodeWrapper(component)))\n\n    arguments = [\n        \'--pipeline_name\',\n        pipeline_name,\n        \'--pipeline_root\',\n        pipeline_root,\n        \'--kubeflow_metadata_config\',\n        json_format.MessageToJson(\n            message=kubeflow_metadata_config, preserving_proto_field_name=True),\n        \'--beam_pipeline_args\',\n        json.dumps(pipeline.beam_pipeline_args),\n        \'--additional_pipeline_args\',\n        json.dumps(pipeline.additional_pipeline_args),\n        \'--component_launcher_class_path\',\n        component_launcher_class_path,\n        \'--serialized_component\',\n        serialized_component,\n        \'--component_config\',\n        json_utils.dumps(component_config),\n    ]\n\n    if pipeline.enable_cache:\n      arguments.append(\'--enable_cache\')\n\n    self.container_op = dsl.ContainerOp(\n        name=component.id.replace(\'.\', \'_\'),\n        command=_COMMAND,\n        image=tfx_image,\n        arguments=arguments,\n        output_artifact_paths={\n            \'mlpipeline-ui-metadata\': \'/mlpipeline-ui-metadata.json\',\n        },\n    )\n\n    absl.logging.info(\'Adding upstream dependencies for component {}\'.format(\n        self.container_op.name))\n    for op in depends_on:\n      absl.logging.info(\'   ->  Component: {}\'.format(op.name))\n      self.container_op.after(op)\n\n    # TODO(b/140172100): Document the use of additional_pipeline_args.\n    if _WORKFLOW_ID_KEY in pipeline.additional_pipeline_args:\n      # Allow overriding pipeline\'s run_id externally, primarily for testing.\n      self.container_op.container.add_env_variable(\n          k8s_client.V1EnvVar(\n              name=_WORKFLOW_ID_KEY,\n              value=pipeline.additional_pipeline_args[_WORKFLOW_ID_KEY]))\n    else:\n      # Add the Argo workflow ID to the container\'s environment variable so it\n      # can be used to uniquely place pipeline outputs under the pipeline_root.\n      field_path = ""metadata.labels[\'workflows.argoproj.io/workflow\']""\n      self.container_op.container.add_env_variable(\n          k8s_client.V1EnvVar(\n              name=_WORKFLOW_ID_KEY,\n              value_from=k8s_client.V1EnvVarSource(\n                  field_ref=k8s_client.V1ObjectFieldSelector(\n                      field_path=field_path))))\n\n    if pod_labels_to_attach:\n      for k, v in pod_labels_to_attach.items():\n        self.container_op.add_pod_label(k, v)\n'"
tfx/orchestration/kubeflow/base_component_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.kubeflow.base_component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport absl\nfrom kfp import dsl\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.example_gen.csv_example_gen import component as csv_example_gen_component\nfrom tfx.components.statistics_gen import component as statistics_gen_component\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration.kubeflow import base_component\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass BaseComponentTest(tf.test.TestCase):\n  maxDiff = None  # pylint: disable=invalid-name\n  _test_pipeline_name = \'test_pipeline\'\n\n  def setUp(self):\n    super(BaseComponentTest, self).setUp()\n    examples = standard_artifacts.ExternalArtifact()\n    example_gen = csv_example_gen_component.CsvExampleGen(\n        input=channel_utils.as_channel([examples]))\n    statistics_gen = statistics_gen_component.StatisticsGen(\n        examples=example_gen.outputs[\'examples\'], instance_name=\'foo\')\n\n    pipeline = tfx_pipeline.Pipeline(\n        pipeline_name=self._test_pipeline_name,\n        pipeline_root=\'test_pipeline_root\',\n        metadata_connection_config=metadata_store_pb2.ConnectionConfig(),\n        components=[example_gen, statistics_gen],\n    )\n\n    test_pipeline_root = dsl.PipelineParam(name=\'pipeline-root-param\')\n\n    self._metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n    self._metadata_config.mysql_db_service_host.environment_variable = \'MYSQL_SERVICE_HOST\'\n    with dsl.Pipeline(\'test_pipeline\'):\n      self.component = base_component.BaseComponent(\n          component=statistics_gen,\n          component_launcher_class=in_process_component_launcher\n          .InProcessComponentLauncher,\n          depends_on=set(),\n          pipeline=pipeline,\n          pipeline_name=self._test_pipeline_name,\n          pipeline_root=test_pipeline_root,\n          tfx_image=\'container_image\',\n          kubeflow_metadata_config=self._metadata_config,\n          component_config=None,\n      )\n    self.tfx_component = statistics_gen\n\n  def testContainerOpArguments(self):\n    # TODO(hongyes): make the whole args list in one golden file to keep\n    # source of truth in same file.\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    with open(os.path.join(source_data_dir,\n                           \'component.json\')) as component_json_file:\n      formatted_component_json = json.dumps(\n          json.load(component_json_file), sort_keys=True)\n\n    expected_args = [\n        \'--pipeline_name\',\n        \'test_pipeline\',\n        \'--pipeline_root\',\n        \'{{pipelineparam:op=;name=pipeline-root-param}}\',\n        \'--kubeflow_metadata_config\',\n        \'{\\n\'\n        \'  ""mysql_db_service_host"": {\\n\'\n        \'    ""environment_variable"": ""MYSQL_SERVICE_HOST""\\n\'\n        \'  }\\n\'\n        \'}\',\n        \'--beam_pipeline_args\',\n        \'[]\',\n        \'--additional_pipeline_args\',\n        \'{}\',\n        \'--component_launcher_class_path\',\n        \'tfx.orchestration.launcher.in_process_component_launcher.InProcessComponentLauncher\',\n        \'--serialized_component\',\n        formatted_component_json,\n        \'--component_config\',\n        \'null\',\n    ]\n    try:\n      self.assertEqual(\n          self.component.container_op.arguments[:len(expected_args)],\n          expected_args)\n    except AssertionError:\n      # Print out full arguments for debugging.\n      absl.logging.error(\'==== BEGIN CONTAINER OP ARGUMENT DUMP ====\')\n      absl.logging.error(\n          json.dumps(self.component.container_op.arguments, indent=2))\n      absl.logging.error(\'==== END CONTAINER OP ARGUMENT DUMP ====\')\n      raise\n\n  def testContainerOpName(self):\n    self.assertEqual(\'StatisticsGen.foo\', self.tfx_component.id)\n    self.assertEqual(\'StatisticsGen_foo\', self.component.container_op.name)\n\n\nclass BaseComponentWithPipelineParamTest(tf.test.TestCase):\n  """"""Test the usage of RuntimeParameter.""""""\n  maxDiff = None  # pylint: disable=invalid-name\n  _test_pipeline_name = \'test_pipeline\'\n\n  def setUp(self):\n    super(BaseComponentWithPipelineParamTest, self).setUp()\n\n    test_pipeline_root = dsl.PipelineParam(name=\'pipeline-root-param\')\n    example_gen_buckets = data_types.RuntimeParameter(\n        name=\'example-gen-buckets\', ptype=int, default=10)\n\n    examples = standard_artifacts.ExternalArtifact()\n    example_gen = csv_example_gen_component.CsvExampleGen(\n        input=channel_utils.as_channel([examples]),\n        output_config={\n            \'split_config\': {\n                \'splits\': [{\n                    \'name\': \'examples\',\n                    \'hash_buckets\': example_gen_buckets\n                }]\n            }\n        })\n    statistics_gen = statistics_gen_component.StatisticsGen(\n        examples=example_gen.outputs[\'examples\'], instance_name=\'foo\')\n\n    pipeline = tfx_pipeline.Pipeline(\n        pipeline_name=self._test_pipeline_name,\n        pipeline_root=\'test_pipeline_root\',\n        metadata_connection_config=metadata_store_pb2.ConnectionConfig(),\n        components=[example_gen, statistics_gen],\n    )\n\n    self._metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n    self._metadata_config.mysql_db_service_host.environment_variable = \'MYSQL_SERVICE_HOST\'\n    with dsl.Pipeline(\'test_pipeline\'):\n      self.example_gen = base_component.BaseComponent(\n          component=example_gen,\n          component_launcher_class=in_process_component_launcher\n          .InProcessComponentLauncher,\n          depends_on=set(),\n          pipeline=pipeline,\n          pipeline_name=self._test_pipeline_name,\n          pipeline_root=test_pipeline_root,\n          tfx_image=\'container_image\',\n          kubeflow_metadata_config=self._metadata_config,\n          component_config=None)\n      self.statistics_gen = base_component.BaseComponent(\n          component=statistics_gen,\n          component_launcher_class=in_process_component_launcher\n          .InProcessComponentLauncher,\n          depends_on=set(),\n          pipeline=pipeline,\n          pipeline_name=self._test_pipeline_name,\n          pipeline_root=test_pipeline_root,\n          tfx_image=\'container_image\',\n          kubeflow_metadata_config=self._metadata_config,\n          component_config=None,\n      )\n\n    self.tfx_example_gen = example_gen\n    self.tfx_statistics_gen = statistics_gen\n\n  def testContainerOpArguments(self):\n    # TODO(hongyes): make the whole args list in one golden file to keep\n    # source of truth in same file.\n    source_data_dir = os.path.join(os.path.dirname(__file__), \'testdata\')\n    with open(os.path.join(source_data_dir,\n                           \'statistics_gen.json\')) as component_json_file:\n      formatted_statistics_gen = json.dumps(\n          json.load(component_json_file), sort_keys=True)\n    with open(os.path.join(source_data_dir,\n                           \'example_gen.json\')) as component_json_file:\n      formatted_example_gen = json.dumps(\n          json.load(component_json_file), sort_keys=True)\n\n    statistics_gen_expected_args = [\n        \'--pipeline_name\',\n        \'test_pipeline\',\n        \'--pipeline_root\',\n        \'{{pipelineparam:op=;name=pipeline-root-param}}\',\n        \'--kubeflow_metadata_config\',\n        \'{\\n\'\n        \'  ""mysql_db_service_host"": {\\n\'\n        \'    ""environment_variable"": ""MYSQL_SERVICE_HOST""\\n\'\n        \'  }\\n\'\n        \'}\',\n        \'--beam_pipeline_args\',\n        \'[]\',\n        \'--additional_pipeline_args\',\n        \'{}\',\n        \'--component_launcher_class_path\',\n        \'tfx.orchestration.launcher.in_process_component_launcher.InProcessComponentLauncher\',\n        \'--serialized_component\',\n        formatted_statistics_gen,\n        \'--component_config\',\n        \'null\',\n    ]\n    example_gen_expected_args = [\n        \'--pipeline_name\',\n        \'test_pipeline\',\n        \'--pipeline_root\',\n        \'{{pipelineparam:op=;name=pipeline-root-param}}\',\n        \'--kubeflow_metadata_config\',\n        \'{\\n\'\n        \'  ""mysql_db_service_host"": {\\n\'\n        \'    ""environment_variable"": ""MYSQL_SERVICE_HOST""\\n\'\n        \'  }\\n\'\n        \'}\',\n        \'--beam_pipeline_args\',\n        \'[]\',\n        \'--additional_pipeline_args\',\n        \'{}\',\n        \'--component_launcher_class_path\',\n        \'tfx.orchestration.launcher.in_process_component_launcher.InProcessComponentLauncher\',\n        \'--serialized_component\',\n        formatted_example_gen,\n        \'--component_config\',\n        \'null\',\n    ]\n    try:\n      self.assertEqual(\n          self.statistics_gen.container_op\n          .arguments[:len(statistics_gen_expected_args)],\n          statistics_gen_expected_args)\n      self.assertEqual(\n          self.example_gen.container_op.arguments[:len(example_gen_expected_args\n                                                      )],\n          example_gen_expected_args)\n    except AssertionError:\n      # Print out full arguments for debugging.\n      absl.logging.error(\n          \'==== BEGIN STATISTICSGEN CONTAINER OP ARGUMENT DUMP ====\')\n      absl.logging.error(\n          json.dumps(self.statistics_gen.container_op.arguments, indent=2))\n      absl.logging.error(\n          \'==== END STATISTICSGEN CONTAINER OP ARGUMENT DUMP ====\')\n      absl.logging.error(\n          \'==== BEGIN EXAMPLEGEN CONTAINER OP ARGUMENT DUMP ====\')\n      absl.logging.error(\n          json.dumps(self.example_gen.container_op.arguments, indent=2))\n      absl.logging.error(\'==== END EXAMPLEGEN CONTAINER OP ARGUMENT DUMP ====\')\n      raise\n\n  def testContainerOpName(self):\n    self.assertEqual(\'StatisticsGen.foo\', self.tfx_statistics_gen.id)\n    self.assertEqual(\'StatisticsGen_foo\', self.statistics_gen.container_op.name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/container_entrypoint.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Main entrypoint for containers with Kubeflow TFX component executors.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport json\nimport logging\nimport os\nimport sys\nimport textwrap\nfrom typing import Dict, List, Text, Union\n\nimport absl\n\nfrom google.protobuf import json_format\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration.kubeflow import kubeflow_metadata_adapter\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.types import artifact\nfrom tfx.types import channel\nfrom tfx.utils import import_utils\nfrom tfx.utils import json_utils\nfrom tfx.utils import telemetry_utils\n\n\ndef _get_config_value(config_value: kubeflow_pb2.ConfigValue) -> Text:\n  value_from = config_value.WhichOneof(\'value_from\')\n\n  if value_from is None:\n    raise ValueError(\'No value set in config value: {}\'.format(config_value))\n\n  if value_from == \'value\':\n    return config_value.value\n\n  return os.getenv(config_value.environment_variable)\n\n\ndef _get_metadata_connection_config(\n    kubeflow_metadata_config: kubeflow_pb2.KubeflowMetadataConfig\n) -> Union[metadata_store_pb2.ConnectionConfig,\n           metadata_store_pb2.MetadataStoreClientConfig]:\n  """"""Constructs a metadata connection config.\n\n  Args:\n    kubeflow_metadata_config: Configuration parameters to use for constructing a\n      valid metadata connection config in a Kubeflow cluster.\n\n  Returns:\n    A Union of metadata_store_pb2.ConnectionConfig and\n    metadata_store_pb2.MetadataStoreClientConfig object.\n  """"""\n  config_type = kubeflow_metadata_config.WhichOneof(\'connection_config\')\n\n  if config_type is None:\n    absl.logging.warning(\n        \'Providing mysql configuration through KubeflowMetadataConfig will be \'\n        \'deprecated soon. Use one of KubeflowGrpcMetadataConfig or\'\n        \'KubeflowMySqlMetadataConfig instead\')\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.mysql.host = _get_config_value(\n        kubeflow_metadata_config.mysql_db_service_host)\n    connection_config.mysql.port = int(\n        _get_config_value(kubeflow_metadata_config.mysql_db_service_port))\n    connection_config.mysql.database = _get_config_value(\n        kubeflow_metadata_config.mysql_db_name)\n    connection_config.mysql.user = _get_config_value(\n        kubeflow_metadata_config.mysql_db_user)\n    connection_config.mysql.password = _get_config_value(\n        kubeflow_metadata_config.mysql_db_password)\n    return connection_config\n\n  assert config_type == \'grpc_config\', (\'expected oneof grpc_config\')\n\n  return _get_grpc_metadata_connection_config(\n      kubeflow_metadata_config.grpc_config)\n\n\ndef _get_grpc_metadata_connection_config(\n    kubeflow_metadata_config: kubeflow_pb2.KubeflowGrpcMetadataConfig\n) -> metadata_store_pb2.MetadataStoreClientConfig:\n  """"""Constructs a metadata grpc connection config.\n\n  Args:\n    kubeflow_metadata_config: Configuration parameters to use for constructing a\n      valid metadata connection config in a Kubeflow cluster.\n\n  Returns:\n    A metadata_store_pb2.MetadataStoreClientConfig object.\n  """"""\n  connection_config = metadata_store_pb2.MetadataStoreClientConfig()\n  connection_config.host = _get_config_value(\n      kubeflow_metadata_config.grpc_service_host)\n  connection_config.port = int(\n      _get_config_value(kubeflow_metadata_config.grpc_service_port))\n\n  return connection_config\n\n\ndef _sanitize_underscore(name: Text) -> Text:\n  """"""Sanitize the underscore in pythonic name for markdown visualization.""""""\n  if name:\n    return str(name).replace(\'_\', \'\\\\_\')\n  else:\n    return None\n\n\ndef _render_channel_as_mdstr(input_channel: channel.Channel) -> Text:\n  """"""Render a Channel as markdown string with the following format.\n\n  **Type**: input_channel.type_name\n  **Artifact: artifact1**\n  **Properties**:\n  **key1**: value1\n  **key2**: value2\n  ......\n\n  Args:\n    input_channel: the channel to be rendered.\n\n  Returns:\n    a md-formatted string representation of the channel.\n  """"""\n\n  md_str = \'**Type**: {}\\n\\n\'.format(\n      _sanitize_underscore(input_channel.type_name))\n  rendered_artifacts = []\n  # List all artifacts in the channel.\n  for single_artifact in input_channel.get():\n    rendered_artifacts.append(_render_artifact_as_mdstr(single_artifact))\n\n  return md_str + \'\\n\\n\'.join(rendered_artifacts)\n\n\n# TODO(b/147097443): clean up and consolidate rendering code.\ndef _render_artifact_as_mdstr(single_artifact: artifact.Artifact) -> Text:\n  """"""Render an artifact as markdown string with the following format.\n\n  **Artifact: artifact1**\n  **Properties**:\n  **key1**: value1\n  **key2**: value2\n  ......\n\n  Args:\n    single_artifact: the artifact to be rendered.\n\n  Returns:\n    a md-formatted string representation of the artifact.\n  """"""\n  span_str = \'None\'\n  split_names_str = \'None\'\n  if single_artifact.PROPERTIES:\n    if \'span\' in single_artifact.PROPERTIES:\n      span_str = str(single_artifact.span)\n    if \'split_names\' in single_artifact.PROPERTIES:\n      split_names_str = str(single_artifact.split_names)\n  return textwrap.dedent(""""""\\\n      **Artifact: {name}**\n\n      **Properties**:\n\n      **uri**: {uri}\n\n      **id**: {id}\n\n      **span**: {span}\n\n      **type_id**: {type_id}\n\n      **type_name**: {type_name}\n\n      **state**: {state}\n\n      **split_names**: {split_names}\n\n      **producer_component**: {producer_component}\n\n      """""".format(\n          name=_sanitize_underscore(single_artifact.name) or \'None\',\n          uri=_sanitize_underscore(single_artifact.uri) or \'None\',\n          id=str(single_artifact.id),\n          span=_sanitize_underscore(span_str),\n          type_id=str(single_artifact.type_id),\n          type_name=_sanitize_underscore(single_artifact.type_name),\n          state=_sanitize_underscore(single_artifact.state) or \'None\',\n          split_names=_sanitize_underscore(split_names_str),\n          producer_component=_sanitize_underscore(\n              single_artifact.producer_component) or \'None\'))\n\n\ndef _dump_ui_metadata(component: base_node.BaseNode,\n                      execution_info: data_types.ExecutionInfo) -> None:\n  """"""Dump KFP UI metadata json file for visualization purpose.\n\n  For general components we just render a simple Markdown file for\n    exec_properties/inputs/outputs.\n\n  Args:\n    component: associated TFX component.\n    execution_info: runtime execution info for this component, including\n      materialized inputs/outputs/execution properties and id.\n  """"""\n  exec_properties_list = [\n      \'**{}**: {}\'.format(\n          _sanitize_underscore(name), _sanitize_underscore(exec_property))\n      for name, exec_property in execution_info.exec_properties.items()\n  ]\n  src_str_exec_properties = \'# Execution properties:\\n{}\'.format(\n      \'\\n\\n\'.join(exec_properties_list) or \'No execution property.\')\n\n  def _dump_populated_artifacts(\n      name_to_channel: Dict[Text, channel.Channel],\n      name_to_artifacts: Dict[Text, List[artifact.Artifact]]) -> List[Text]:\n    """"""Dump artifacts markdown string.\n\n    Args:\n      name_to_channel: maps from channel name to channel object.\n      name_to_artifacts: maps from channel name to list of populated artifacts.\n\n    Returns:\n      A list of dumped markdown string, each of which represents a channel.\n    """"""\n    rendered_list = []\n    for name, chnl in name_to_channel.items():\n      # Need to look for materialized artifacts in the execution decision.\n      rendered_artifacts = \'\'.join([\n          _render_artifact_as_mdstr(single_artifact)\n          for single_artifact in name_to_artifacts.get(name, [])\n      ])\n      rendered_list.append(\n          \'## {name}\\n\\n**Type**: {channel_type}\\n\\n{artifacts}\'.format(\n              name=_sanitize_underscore(name),\n              channel_type=_sanitize_underscore(chnl.type_name),\n              artifacts=rendered_artifacts))\n\n    return rendered_list\n\n  src_str_inputs = \'# Inputs:\\n{}\'.format(\'\'.join(\n      _dump_populated_artifacts(\n          name_to_channel=component.inputs.get_all(),\n          name_to_artifacts=execution_info.input_dict)) or \'No input.\')\n\n  src_str_outputs = \'# Outputs:\\n{}\'.format(\'\'.join(\n      _dump_populated_artifacts(\n          name_to_channel=component.outputs.get_all(),\n          name_to_artifacts=execution_info.output_dict)) or \'No output.\')\n\n  outputs = [{\n      \'storage\':\n          \'inline\',\n      \'source\':\n          \'{exec_properties}\\n\\n{inputs}\\n\\n{outputs}\'.format(\n              exec_properties=src_str_exec_properties,\n              inputs=src_str_inputs,\n              outputs=src_str_outputs),\n      \'type\':\n          \'markdown\',\n  }]\n  # Add Tensorboard view for Trainer.\n  # TODO(b/142804764): Visualization based on component type seems a bit of\n  # arbitrary and fragile. We need a better way to improve this. See also\n  # b/146594754\n  if component.type == \'tfx.components.trainer.component.Trainer\':\n    output_model = execution_info.output_dict[\'model\'][0]\n\n    # Add Tensorboard view.\n    tensorboard_output = {\'type\': \'tensorboard\', \'source\': output_model.uri}\n    outputs.append(tensorboard_output)\n\n  metadata = {\'outputs\': outputs}\n\n  with open(\'/mlpipeline-ui-metadata.json\', \'w\') as f:\n    json.dump(metadata, f)\n\n\ndef main():\n  # Log to the container\'s stdout so Kubeflow Pipelines UI can display logs to\n  # the user.\n  logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n  logging.getLogger().setLevel(logging.INFO)\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\'--pipeline_name\', type=str, required=True)\n  parser.add_argument(\'--pipeline_root\', type=str, required=True)\n  parser.add_argument(\'--kubeflow_metadata_config\', type=str, required=True)\n  parser.add_argument(\'--beam_pipeline_args\', type=str, required=True)\n  parser.add_argument(\'--additional_pipeline_args\', type=str, required=True)\n  parser.add_argument(\n      \'--component_launcher_class_path\', type=str, required=True)\n  parser.add_argument(\'--enable_cache\', action=\'store_true\')\n  parser.add_argument(\'--serialized_component\', type=str, required=True)\n  parser.add_argument(\'--component_config\', type=str, required=True)\n\n  args = parser.parse_args()\n\n  component = json_utils.loads(args.serialized_component)\n  component_config = json_utils.loads(args.component_config)\n  component_launcher_class = import_utils.import_class_by_path(\n      args.component_launcher_class_path)\n  if not issubclass(component_launcher_class,\n                    base_component_launcher.BaseComponentLauncher):\n    raise TypeError(\n        \'component_launcher_class ""%s"" is not subclass of base_component_launcher.BaseComponentLauncher\'\n        % component_launcher_class)\n\n  kubeflow_metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n  json_format.Parse(args.kubeflow_metadata_config, kubeflow_metadata_config)\n  metadata_connection = kubeflow_metadata_adapter.KubeflowMetadataAdapter(\n      _get_metadata_connection_config(kubeflow_metadata_config))\n  driver_args = data_types.DriverArgs(enable_cache=args.enable_cache)\n\n  beam_pipeline_args = json.loads(args.beam_pipeline_args)\n\n  additional_pipeline_args = json.loads(args.additional_pipeline_args)\n\n  launcher = component_launcher_class.create(\n      component=component,\n      pipeline_info=data_types.PipelineInfo(\n          pipeline_name=args.pipeline_name,\n          pipeline_root=args.pipeline_root,\n          run_id=os.environ[\'WORKFLOW_ID\']),\n      driver_args=driver_args,\n      metadata_connection=metadata_connection,\n      beam_pipeline_args=beam_pipeline_args,\n      additional_pipeline_args=additional_pipeline_args,\n      component_config=component_config)\n\n  # Attach necessary labels to distinguish different runner and DSL.\n  # TODO(zhitaoli): Pass this from KFP runner side when the same container\n  # entrypoint can be used by a different runner.\n  with telemetry_utils.scoped_labels({\n      telemetry_utils.LABEL_TFX_RUNNER: \'kfp\',\n  }):\n    execution_info = launcher.launch()\n\n  # Dump the UI metadata.\n  _dump_ui_metadata(component, execution_info)\n\n\nif __name__ == \'__main__\':\n  main()\n'"
tfx/orchestration/kubeflow/container_entrypoint_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.kubeflow.container_entrypoint.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.orchestration.kubeflow import container_entrypoint\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\n\n\nclass MLMDConfigTest(tf.test.TestCase):\n\n  def _set_required_env_vars(self, env_vars):\n    for k, v in env_vars.items():\n      os.environ[k] = v\n\n  def testDeprecatedMysqlMetadataConnectionConfig(self):\n    self._set_required_env_vars({\n        \'mysql_host\': \'mysql\',\n        \'mysql_port\': \'3306\',\n        \'mysql_database\': \'metadb\',\n        \'mysql_user_name\': \'root\',\n        \'mysql_user_password\': \'test\'\n    })\n\n    metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n    metadata_config.mysql_db_service_host.environment_variable = \'mysql_host\'\n    metadata_config.mysql_db_service_port.environment_variable = \'mysql_port\'\n    metadata_config.mysql_db_name.environment_variable = \'mysql_database\'\n    metadata_config.mysql_db_user.environment_variable = \'mysql_user_name\'\n    metadata_config.mysql_db_password.environment_variable = \'mysql_user_password\'\n\n    ml_metadata_config = container_entrypoint._get_metadata_connection_config(\n        metadata_config)\n    self.assertIsInstance(ml_metadata_config,\n                          metadata_store_pb2.ConnectionConfig)\n    self.assertEqual(ml_metadata_config.mysql.host, \'mysql\')\n    self.assertEqual(ml_metadata_config.mysql.port, 3306)\n    self.assertEqual(ml_metadata_config.mysql.database, \'metadb\')\n    self.assertEqual(ml_metadata_config.mysql.user, \'root\')\n    self.assertEqual(ml_metadata_config.mysql.password, \'test\')\n\n  def testGrpcMetadataConnectionConfig(self):\n    self._set_required_env_vars({\n        \'METADATA_GRPC_SERVICE_HOST\': \'metadata-grpc\',\n        \'METADATA_GRPC_SERVICE_PORT\': \'8080\',\n    })\n\n    grpc_config = kubeflow_pb2.KubeflowGrpcMetadataConfig()\n    grpc_config.grpc_service_host.environment_variable = \'METADATA_GRPC_SERVICE_HOST\'\n    grpc_config.grpc_service_port.environment_variable = \'METADATA_GRPC_SERVICE_PORT\'\n    metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n    metadata_config.grpc_config.CopyFrom(grpc_config)\n\n    ml_metadata_config = container_entrypoint._get_metadata_connection_config(\n        metadata_config)\n    self.assertIsInstance(ml_metadata_config,\n                          metadata_store_pb2.MetadataStoreClientConfig)\n    self.assertEqual(ml_metadata_config.host, \'metadata-grpc\')\n    self.assertEqual(ml_metadata_config.port, 8080)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/kubeflow_dag_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX runner for Kubeflow.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nfrom typing import Callable, Dict, List, Optional, Text, Type\n\nfrom kfp import compiler\nfrom kfp import dsl\nfrom kfp import gcp\nfrom kubernetes import client as k8s_client\n\nfrom tfx import version\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration import tfx_runner\nfrom tfx.orchestration.config import config_utils\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.kubeflow import base_component\nfrom tfx.orchestration.kubeflow import utils\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.orchestration.launcher import kubernetes_component_launcher\nfrom tfx.utils import json_utils\nfrom tfx.utils import telemetry_utils\n\n# OpFunc represents the type of a function that takes as input a\n# dsl.ContainerOp and returns the same object. Common operations such as adding\n# k8s secrets, mounting volumes, specifying the use of TPUs and so on can be\n# specified as an OpFunc.\n# See example usage here:\n# https://github.com/kubeflow/pipelines/blob/master/sdk/python/kfp/gcp.py\nOpFunc = Callable[[dsl.ContainerOp], dsl.ContainerOp]\n\n# Default secret name for GCP credentials. This secret is installed as part of\n# a typical Kubeflow installation when the component is GKE.\n_KUBEFLOW_GCP_SECRET_NAME = \'user-gcp-sa\'\n\n# Default TFX container image to use in KubeflowDagRunner.\n_KUBEFLOW_TFX_IMAGE = \'tensorflow/tfx:%s\' % (version.__version__)\n\n\ndef _mount_config_map_op(config_map_name: Text) -> OpFunc:\n  """"""Mounts all key-value pairs found in the named Kubernetes ConfigMap.\n\n  All key-value pairs in the ConfigMap are mounted as environment variables.\n\n  Args:\n    config_map_name: The name of the ConfigMap resource.\n\n  Returns:\n    An OpFunc for mounting the ConfigMap.\n  """"""\n\n  def mount_config_map(container_op: dsl.ContainerOp):\n    config_map_ref = k8s_client.V1ConfigMapEnvSource(\n        name=config_map_name, optional=True)\n    container_op.container.add_env_from(\n        k8s_client.V1EnvFromSource(config_map_ref=config_map_ref))\n\n  return mount_config_map\n\n\ndef _mount_secret_op(secret_name: Text) -> OpFunc:\n  """"""Mounts all key-value pairs found in the named Kubernetes Secret.\n\n  All key-value pairs in the Secret are mounted as environment variables.\n\n  Args:\n    secret_name: The name of the Secret resource.\n\n  Returns:\n    An OpFunc for mounting the Secret.\n  """"""\n\n  def mount_secret(container_op: dsl.ContainerOp):\n    secret_ref = k8s_client.V1ConfigMapEnvSource(\n        name=secret_name, optional=True)\n\n    container_op.container.add_env_from(\n        k8s_client.V1EnvFromSource(secret_ref=secret_ref))\n\n  return mount_secret\n\n\ndef get_default_pipeline_operator_funcs(\n    use_gcp_sa: bool = False) -> List[OpFunc]:\n  """"""Returns a default list of pipeline operator functions.\n\n  Args:\n    use_gcp_sa: If true, mount a GCP service account secret to each pod, with\n      the name _KUBEFLOW_GCP_SECRET_NAME.\n\n  Returns:\n    A list of functions with type OpFunc.\n  """"""\n  # Enables authentication for GCP services if needed.\n  gcp_secret_op = gcp.use_gcp_secret(_KUBEFLOW_GCP_SECRET_NAME)\n\n  # Mounts configmap containing Metadata gRPC server configuration.\n  mount_config_map_op = _mount_config_map_op(\'metadata-grpc-configmap\')\n  if use_gcp_sa:\n    return [gcp_secret_op, mount_config_map_op]\n  else:\n    return [mount_config_map_op]\n\n\ndef get_default_kubeflow_metadata_config(\n) -> kubeflow_pb2.KubeflowMetadataConfig:\n  """"""Returns the default metadata connection config for Kubeflow.\n\n  Returns:\n    A config proto that will be serialized as JSON and passed to the running\n    container so the TFX component driver is able to communicate with MLMD in\n    a Kubeflow cluster.\n  """"""\n  # The default metadata configuration for a Kubeflow Pipelines cluster is\n  # codified as a Kubernetes ConfigMap\n  # https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/base/metadata/metadata-grpc-configmap.yaml\n\n  config = kubeflow_pb2.KubeflowMetadataConfig()\n  # The environment variable to use to obtain the Metadata gRPC service host in\n  # the cluster that is backing Kubeflow Metadata. Note that the key in the\n  # config map and therefore environment variable used, are lower-cased.\n  config.grpc_config.grpc_service_host.environment_variable = \'METADATA_GRPC_SERVICE_HOST\'\n  # The environment variable to use to obtain the Metadata grpc service port in\n  # the cluster that is backing Kubeflow Metadata.\n  config.grpc_config.grpc_service_port.environment_variable = \'METADATA_GRPC_SERVICE_PORT\'\n\n  return config\n\n\ndef get_default_pod_labels() -> Dict[Text, Text]:\n  """"""Returns the default pod label dict for Kubeflow.""""""\n  # KFP default transformers add pod env:\n  # https://github.com/kubeflow/pipelines/blob/0.1.32/sdk/python/kfp/compiler/_default_transformers.py\n  result = {\n      \'add-pod-env\': \'true\',\n      telemetry_utils.LABEL_KFP_SDK_ENV: \'tfx\'\n  }\n  return result\n\n\nclass KubeflowDagRunnerConfig(pipeline_config.PipelineConfig):\n  """"""Runtime configuration parameters specific to execution on Kubeflow.""""""\n\n  def __init__(\n      self,\n      pipeline_operator_funcs: Optional[List[OpFunc]] = None,\n      tfx_image: Optional[Text] = None,\n      kubeflow_metadata_config: Optional[\n          kubeflow_pb2.KubeflowMetadataConfig] = None,\n      # TODO(b/143883035): Figure out the best practice to put the\n      # SUPPORTED_LAUNCHER_CLASSES\n      supported_launcher_classes: List[Type[\n          base_component_launcher.BaseComponentLauncher]] = None,\n      **kwargs):\n    """"""Creates a KubeflowDagRunnerConfig object.\n\n    The user can use pipeline_operator_funcs to apply modifications to\n    ContainerOps used in the pipeline. For example, to ensure the pipeline\n    steps mount a GCP secret, and a Persistent Volume, one can create config\n    object like so:\n\n      from kfp import gcp, onprem\n      mount_secret_op = gcp.use_secret(\'my-secret-name)\n      mount_volume_op = onprem.mount_pvc(\n        ""my-persistent-volume-claim"",\n        ""my-volume-name"",\n        ""/mnt/volume-mount-path"")\n\n      config = KubeflowDagRunnerConfig(\n        pipeline_operator_funcs=[mount_secret_op, mount_volume_op]\n      )\n\n    Args:\n      pipeline_operator_funcs: A list of ContainerOp modifying functions that\n        will be applied to every container step in the pipeline.\n      tfx_image: The TFX container image to use in the pipeline.\n      kubeflow_metadata_config: Runtime configuration to use to connect to\n        Kubeflow metadata.\n      supported_launcher_classes: A list of component launcher classes that are\n        supported by the current pipeline. List sequence determines the order in\n        which launchers are chosen for each component being run.\n      **kwargs: keyword args for PipelineConfig.\n    """"""\n    supported_launcher_classes = supported_launcher_classes or [\n        in_process_component_launcher.InProcessComponentLauncher,\n        kubernetes_component_launcher.KubernetesComponentLauncher,\n    ]\n    super(KubeflowDagRunnerConfig, self).__init__(\n        supported_launcher_classes=supported_launcher_classes, **kwargs)\n    self.pipeline_operator_funcs = (\n        pipeline_operator_funcs or get_default_pipeline_operator_funcs())\n    self.tfx_image = tfx_image or _KUBEFLOW_TFX_IMAGE\n    self.kubeflow_metadata_config = (\n        kubeflow_metadata_config or get_default_kubeflow_metadata_config())\n\n\nclass KubeflowDagRunner(tfx_runner.TfxRunner):\n  """"""Kubeflow Pipelines runner.\n\n  Constructs a pipeline definition YAML file based on the TFX logical pipeline.\n  """"""\n\n  def __init__(\n      self,\n      output_dir: Optional[Text] = None,\n      output_filename: Optional[Text] = None,\n      config: Optional[KubeflowDagRunnerConfig] = None,\n      pod_labels_to_attach: Optional[Dict[Text, Text]] = None\n  ):\n    """"""Initializes KubeflowDagRunner for compiling a Kubeflow Pipeline.\n\n    Args:\n      output_dir: An optional output directory into which to output the pipeline\n        definition files. Defaults to the current working directory.\n      output_filename: An optional output file name for the pipeline definition\n        file. Defaults to pipeline_name.tar.gz when compiling a TFX pipeline.\n        Currently supports .tar.gz, .tgz, .zip, .yaml, .yml formats. See\n        https://github.com/kubeflow/pipelines/blob/181de66cf9fa87bcd0fe9291926790c400140783/sdk/python/kfp/compiler/compiler.py#L851\n          for format restriction.\n      config: An optional KubeflowDagRunnerConfig object to specify runtime\n        configuration when running the pipeline under Kubeflow.\n      pod_labels_to_attach: Optional set of pod labels to attach to GKE pod\n        spinned up for this pipeline. Default to the 3 labels:\n        1. add-pod-env: true,\n        2. pipeline SDK type,\n        3. pipeline unique ID,\n        where 2 and 3 are instrumentation of usage tracking.\n    """"""\n    if config and not isinstance(config, KubeflowDagRunnerConfig):\n      raise TypeError(\'config must be type of KubeflowDagRunnerConfig.\')\n    super(KubeflowDagRunner, self).__init__(config or KubeflowDagRunnerConfig())\n    self._output_dir = output_dir or os.getcwd()\n    self._output_filename = output_filename\n    self._compiler = compiler.Compiler()\n    self._params = []  # List of dsl.PipelineParam used in this pipeline.\n    self._deduped_parameter_names = set()  # Set of unique param names used.\n    if pod_labels_to_attach is None:\n      self._pod_labels_to_attach = get_default_pod_labels()\n    else:\n      self._pod_labels_to_attach = pod_labels_to_attach\n\n  def _parse_parameter_from_component(\n      self, component: base_component.BaseComponent) -> None:\n    """"""Extract embedded RuntimeParameter placeholders from a component.\n\n    Extract embedded RuntimeParameter placeholders from a component, then append\n    the corresponding dsl.PipelineParam to KubeflowDagRunner.\n\n    Args:\n      component: a TFX component.\n    """"""\n\n    serialized_component = json_utils.dumps(component)\n    placeholders = re.findall(data_types.RUNTIME_PARAMETER_PATTERN,\n                              serialized_component)\n    for placeholder in placeholders:\n      placeholder = placeholder.replace(\'\\\\\', \'\')  # Clean escapes.\n      placeholder = utils.fix_brackets(placeholder)  # Fix brackets if needed.\n      parameter = json_utils.loads(placeholder)\n      # Escape pipeline root because it will be added later.\n      if parameter.name == tfx_pipeline.ROOT_PARAMETER.name:\n        continue\n      if parameter.name not in self._deduped_parameter_names:\n        self._deduped_parameter_names.add(parameter.name)\n        dsl_parameter = dsl.PipelineParam(\n            name=parameter.name, value=parameter.default)\n        self._params.append(dsl_parameter)\n\n  def _parse_parameter_from_pipeline(self,\n                                     pipeline: tfx_pipeline.Pipeline) -> None:\n    """"""Extract all the RuntimeParameter placeholders from the pipeline.""""""\n\n    for component in pipeline.components:\n      self._parse_parameter_from_component(component)\n\n  def _construct_pipeline_graph(self, pipeline: tfx_pipeline.Pipeline,\n                                pipeline_root: dsl.PipelineParam):\n    """"""Constructs a Kubeflow Pipeline graph.\n\n    Args:\n      pipeline: The logical TFX pipeline to base the construction on.\n      pipeline_root: dsl.PipelineParam representing the pipeline root.\n    """"""\n    component_to_kfp_op = {}\n\n    # Assumption: There is a partial ordering of components in the list, i.e.,\n    # if component A depends on component B and C, then A appears after B and C\n    # in the list.\n    for component in pipeline.components:\n      # Keep track of the set of upstream dsl.ContainerOps for this component.\n      depends_on = set()\n\n      for upstream_component in component.upstream_nodes:\n        depends_on.add(component_to_kfp_op[upstream_component])\n\n      (component_launcher_class,\n       component_config) = config_utils.find_component_launch_info(\n           self._config, component)\n\n      kfp_component = base_component.BaseComponent(\n          component=component,\n          component_launcher_class=component_launcher_class,\n          depends_on=depends_on,\n          pipeline=pipeline,\n          pipeline_name=pipeline.pipeline_info.pipeline_name,\n          pipeline_root=pipeline_root,\n          tfx_image=self._config.tfx_image,\n          kubeflow_metadata_config=self._config.kubeflow_metadata_config,\n          component_config=component_config,\n          pod_labels_to_attach=self._pod_labels_to_attach)\n\n      for operator in self._config.pipeline_operator_funcs:\n        kfp_component.container_op.apply(operator)\n\n      component_to_kfp_op[component] = kfp_component.container_op\n\n  def run(self, pipeline: tfx_pipeline.Pipeline):\n    """"""Compiles and outputs a Kubeflow Pipeline YAML definition file.\n\n    Args:\n      pipeline: The logical TFX pipeline to use when building the Kubeflow\n        pipeline.\n    """"""\n    pipeline_root = tfx_pipeline.ROOT_PARAMETER\n    # KFP DSL representation of pipeline root parameter.\n    dsl_pipeline_root = dsl.PipelineParam(\n        name=pipeline_root.name, value=pipeline.pipeline_info.pipeline_root)\n    self._params.append(dsl_pipeline_root)\n\n    def _construct_pipeline():\n      """"""Constructs a Kubeflow pipeline.\n\n      Creates Kubeflow ContainerOps for each TFX component encountered in the\n      logical pipeline definition.\n      """"""\n      self._construct_pipeline_graph(pipeline, dsl_pipeline_root)\n\n    # Need to run this first to get self._params populated. Then KFP compiler\n    # can correctly match default value with PipelineParam.\n    self._parse_parameter_from_pipeline(pipeline)\n\n    file_name = self._output_filename or pipeline.pipeline_info.pipeline_name + \'.tar.gz\'\n    # Create workflow spec and write out to package.\n    self._compiler._create_and_write_workflow(  # pylint: disable=protected-access\n        pipeline_func=_construct_pipeline,\n        pipeline_name=pipeline.pipeline_info.pipeline_name,\n        params_list=self._params,\n        package_path=os.path.join(self._output_dir, file_name))\n'"
tfx/orchestration/kubeflow/kubeflow_dag_runner_test.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.kubeflow.kubeflow_dag_runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport shutil\nimport tarfile\nimport tempfile\nfrom typing import Text\nfrom kfp import onprem\nimport tensorflow as tf\nimport yaml\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.example_gen.big_query_example_gen import component as big_query_example_gen_component\nfrom tfx.components.statistics_gen import component as statistics_gen_component\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.utils import telemetry_utils\n\n\n# 2-step pipeline under test.\ndef _two_step_pipeline() -> tfx_pipeline.Pipeline:\n  table_name = data_types.RuntimeParameter(\n      name=\'table-name\', ptype=Text, default=\'default-table\')\n  example_gen = big_query_example_gen_component.BigQueryExampleGen(\n      query=\'SELECT * FROM %s\' % str(table_name))\n  statistics_gen = statistics_gen_component.StatisticsGen(\n      examples=example_gen.outputs[\'examples\'])\n  return tfx_pipeline.Pipeline(\n      pipeline_name=\'two_step_pipeline\',\n      pipeline_root=\'pipeline_root\',\n      metadata_connection_config=metadata_store_pb2.ConnectionConfig(),\n      components=[example_gen, statistics_gen],\n  )\n\n\nclass KubeflowDagRunnerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(KubeflowDagRunnerTest, self).setUp()\n    self.test_dir = tempfile.mkdtemp()\n    os.chdir(self.test_dir)\n\n  def tearDown(self):\n    super(KubeflowDagRunnerTest, self).tearDown()\n    shutil.rmtree(self.test_dir)\n\n  def testTwoStepPipeline(self):\n    """"""Sanity-checks the construction and dependencies for a 2-step pipeline.""""""\n    kubeflow_dag_runner.KubeflowDagRunner().run(_two_step_pipeline())\n    file_path = os.path.join(self.test_dir, \'two_step_pipeline.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n    with tarfile.TarFile.open(file_path).extractfile(\n        \'pipeline.yaml\') as pipeline_file:\n      self.assertIsNotNone(pipeline_file)\n      pipeline = yaml.safe_load(pipeline_file)\n\n      containers = [\n          c for c in pipeline[\'spec\'][\'templates\'] if \'container\' in c\n      ]\n      self.assertEqual(2, len(containers))\n\n      big_query_container = [\n          c for c in containers if c[\'name\'] == \'bigqueryexamplegen\'\n      ]\n      self.assertEqual(1, len(big_query_container))\n      self.assertEqual([\n          \'python\',\n          \'/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py\'\n      ], big_query_container[0][\'container\'][\'command\'])\n\n      statistics_gen_container = [\n          c for c in containers if c[\'name\'] == \'statisticsgen\'\n      ]\n      self.assertEqual(1, len(statistics_gen_container))\n\n      # Ensure the pod labels are correctly appended.\n      metadata = [\n          c[\'metadata\'] for c in pipeline[\'spec\'][\'templates\'] if \'dag\' not in c\n      ]\n      for m in metadata:\n        self.assertEqual(\'tfx\', m[\'labels\'][telemetry_utils.LABEL_KFP_SDK_ENV])\n\n      # Ensure dependencies between components are captured.\n      dag = [c for c in pipeline[\'spec\'][\'templates\'] if \'dag\' in c]\n      self.assertEqual(1, len(dag))\n\n      self.assertEqual(\n          {\n              \'tasks\': [{\n                  \'name\': \'bigqueryexamplegen\',\n                  \'template\': \'bigqueryexamplegen\',\n                  \'arguments\': {\n                      \'parameters\': [{\n                          \'name\': \'pipeline-root\',\n                          \'value\': \'{{inputs.parameters.pipeline-root}}\'\n                      }, {\n                          \'name\': \'table-name\',\n                          \'value\': \'{{inputs.parameters.table-name}}\'\n                      }]\n                  }\n              }, {\n                  \'name\': \'statisticsgen\',\n                  \'template\': \'statisticsgen\',\n                  \'arguments\': {\n                      \'parameters\': [{\n                          \'name\': \'pipeline-root\',\n                          \'value\': \'{{inputs.parameters.pipeline-root}}\'\n                      }]\n                  },\n                  \'dependencies\': [\'bigqueryexamplegen\'],\n              }]\n          }, dag[0][\'dag\'])\n\n  def testDefaultPipelineOperatorFuncs(self):\n    kubeflow_dag_runner.KubeflowDagRunner().run(_two_step_pipeline())\n    file_path = os.path.join(self.test_dir, \'two_step_pipeline.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n    with tarfile.TarFile.open(file_path).extractfile(\n        \'pipeline.yaml\') as pipeline_file:\n      self.assertIsNotNone(pipeline_file)\n      pipeline = yaml.safe_load(pipeline_file)\n\n      containers = [\n          c for c in pipeline[\'spec\'][\'templates\'] if \'container\' in c\n      ]\n      self.assertEqual(2, len(containers))\n\n  def testMountGcpServiceAccount(self):\n    kubeflow_dag_runner.KubeflowDagRunner(\n        config=kubeflow_dag_runner.KubeflowDagRunnerConfig(\n            pipeline_operator_funcs=kubeflow_dag_runner\n            .get_default_pipeline_operator_funcs(use_gcp_sa=True))).run(\n                _two_step_pipeline())\n    file_path = os.path.join(self.test_dir, \'two_step_pipeline.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n    with tarfile.TarFile.open(file_path).extractfile(\n        \'pipeline.yaml\') as pipeline_file:\n      self.assertIsNotNone(pipeline_file)\n      pipeline = yaml.safe_load(pipeline_file)\n\n      containers = [\n          c for c in pipeline[\'spec\'][\'templates\'] if \'container\' in c\n      ]\n      self.assertEqual(2, len(containers))\n\n      # Check that each container has default GCP credentials.\n\n      container_0 = containers[0]\n      env = [\n          env for env in container_0[\'container\'][\'env\']\n          if env[\'name\'] == \'GOOGLE_APPLICATION_CREDENTIALS\'\n      ]\n      self.assertEqual(1, len(env))\n      self.assertEqual(\'/secret/gcp-credentials/user-gcp-sa.json\',\n                       env[0][\'value\'])\n\n      container_1 = containers[0]\n      env = [\n          env for env in container_1[\'container\'][\'env\']\n          if env[\'name\'] == \'GOOGLE_APPLICATION_CREDENTIALS\'\n      ]\n      self.assertEqual(1, len(env))\n      self.assertEqual(\'/secret/gcp-credentials/user-gcp-sa.json\',\n                       env[0][\'value\'])\n\n  def testVolumeMountingPipelineOperatorFuncs(self):\n    mount_volume_op = onprem.mount_pvc(\'my-persistent-volume-claim\',\n                                       \'my-volume-name\',\n                                       \'/mnt/volume-mount-path\')\n    config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n        pipeline_operator_funcs=[mount_volume_op])\n\n    kubeflow_dag_runner.KubeflowDagRunner(config=config).run(\n        _two_step_pipeline())\n    file_path = os.path.join(self.test_dir, \'two_step_pipeline.tar.gz\')\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n    with tarfile.TarFile.open(file_path).extractfile(\n        \'pipeline.yaml\') as pipeline_file:\n      self.assertIsNotNone(pipeline_file)\n      pipeline = yaml.safe_load(pipeline_file)\n\n      container_templates = [\n          c for c in pipeline[\'spec\'][\'templates\'] if \'container\' in c\n      ]\n      self.assertEqual(2, len(container_templates))\n\n      volumes = [{\n          \'name\': \'my-volume-name\',\n          \'persistentVolumeClaim\': {\n              \'claimName\': \'my-persistent-volume-claim\'\n          }\n      }]\n\n      # Check that the PVC is specified for kfp<=0.1.31.1.\n      if \'volumes\' in pipeline[\'spec\']:\n        self.assertEqual(volumes, pipeline[\'spec\'][\'volumes\'])\n\n      for template in container_templates:\n        # Check that each container has the volume mounted.\n        self.assertEqual([{\n            \'name\': \'my-volume-name\',\n            \'mountPath\': \'/mnt/volume-mount-path\'\n        }], template[\'container\'][\'volumeMounts\'])\n\n        # Check that each template has the PVC specified for kfp>=0.1.31.2.\n        if \'volumes\' in template:\n          self.assertEqual(volumes, template[\'volumes\'])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/kubeflow_e2e_test.py,5,"b'# Lint as: python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""End to end tests for Kubeflow-based orchestrator.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\nimport time\nfrom typing import List, Text\n\nfrom absl import logging\nfrom grpc import insecure_channel\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom ml_metadata.proto import metadata_store_service_pb2\nfrom ml_metadata.proto import metadata_store_service_pb2_grpc\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import test_utils\nfrom tfx.orchestration.kubeflow import test_utils as kubeflow_test_utils\nfrom tfx.orchestration.test_pipelines import download_grep_print_pipeline\nfrom tfx.types import standard_artifacts\n\n# TODO(jxzheng): Change this hard-coded port forwarding address to a dynamic\n# one, perhaps with incrementing-retry logic, in order to guarantee different\n# tests not to step on each other.\n\n# The port-forwarding address used by Kubeflow E2E test.\n_KFP_E2E_TEST_FORWARDING_PORT = \'8081\'\n\n\nclass KubeflowEndToEndTest(kubeflow_test_utils.BaseKubeflowTest):\n\n  @classmethod\n  def setUpClass(cls):\n    # Initializes the port-forward process to talk MLMD.\n    super().setUpClass()\n    cls._port_forwarding_process = cls._setup_mlmd_port_forward()\n\n  @classmethod\n  def tearDownClass(cls):\n    super(KubeflowEndToEndTest, cls).tearDownClass()\n\n    # Delete container image used in tests.\n    logging.info(\'Killing the GRPC port-forwarding process.\')\n    cls._port_forwarding_process.kill()\n\n  @classmethod\n  def _get_grpc_port(cls) -> Text:\n    """"""Get the port number used by MLMD gRPC server.""""""\n    get_grpc_port_command = [\n        \'kubectl\', \'-n\', \'kubeflow\', \'get\', \'configmap\',\n        \'metadata-grpc-configmap\', \'-o\',\n        \'jsonpath={.data.METADATA_GRPC_SERVICE_PORT}\'\n    ]\n\n    grpc_port = subprocess.check_output(get_grpc_port_command)\n    return grpc_port.decode(\'utf-8\')\n\n  @classmethod\n  def _setup_mlmd_port_forward(cls) -> subprocess.Popen:\n    """"""Uses port forward to talk to MLMD gRPC server.""""""\n    grpc_port = cls._get_grpc_port()\n    grpc_forward_command = [\n        \'kubectl\', \'port-forward\', \'deployment/metadata-deployment\', \'-n\',\n        \'kubeflow\', (\'%s:%s\' % (_KFP_E2E_TEST_FORWARDING_PORT, grpc_port))\n    ]\n    # Begin port forwarding.\n    proc = subprocess.Popen(grpc_forward_command)\n    try:\n      # Wait while port forward to pod is being established\n      poll_grpc_port_command = [\n          \'lsof\', \'-i\', \':%s\' % _KFP_E2E_TEST_FORWARDING_PORT\n      ]\n      result = subprocess.run(poll_grpc_port_command)  # pylint: disable=subprocess-run-check\n      max_attempts = 30\n      for _ in range(max_attempts):\n        if result.returncode == 0:\n          break\n        logging.info(\'Waiting while gRPC port-forward is being established...\')\n        time.sleep(5)\n        result = subprocess.run(poll_grpc_port_command)  # pylint: disable=subprocess-run-check\n    except:\n      # Kill the process in case unexpected error occurred.\n      proc.kill()\n      raise\n\n    if result.returncode != 0:\n      raise RuntimeError(\n          \'Failed to establish gRPC port-forward to cluster after %s retries. \'\n          \'See error message: %s\' % (max_attempts, result.stderr))\n\n    # Establish MLMD gRPC channel.\n    forwarding_channel = insecure_channel(\'localhost:%s\' % (int(grpc_port) + 1))\n    cls._stub = metadata_store_service_pb2_grpc.MetadataStoreServiceStub(\n        forwarding_channel)\n\n    return proc\n\n  def _get_artifacts_with_type(\n      self, type_name: Text) -> List[metadata_store_pb2.Artifact]:\n    """"""Helper function returns artifacts with given type.""""""\n    request = metadata_store_service_pb2.GetArtifactsByTypeRequest(\n        type_name=type_name)\n    return self._stub.GetArtifactsByType(request).artifacts\n\n  def _get_artifacts_with_type_and_pipeline(\n      self, type_name: Text,\n      pipeline_name: Text) -> List[metadata_store_pb2.Artifact]:\n    """"""Helper function returns artifacts of specified pipeline and type.""""""\n    request = metadata_store_service_pb2.GetArtifactsByTypeRequest(\n        type_name=type_name)\n    all_artifacts = self._stub.GetArtifactsByType(request).artifacts\n    return [\n        artifact for artifact in all_artifacts\n        if artifact.custom_properties[\'pipeline_name\'].string_value ==\n        pipeline_name\n    ]\n\n  def _get_value_of_string_artifact(\n      self, string_artifact: metadata_store_pb2.Artifact) -> Text:\n    """"""Helper function returns the actual value of a ValueArtifact.""""""\n    file_path = os.path.join(string_artifact.uri,\n                             standard_artifacts.String.VALUE_FILE)\n    # Assert there is a file exists.\n    if (not tf.io.gfile.exists(file_path)) or tf.io.gfile.isdir(file_path):\n      raise RuntimeError(\n          \'Given path does not exist or is not a valid file: %s\' % file_path)\n    serialized_value = tf.io.gfile.GFile(file_path, \'rb\').read()\n    return standard_artifacts.String().decode(serialized_value)\n\n  def _get_executions_by_pipeline_name(\n      self, pipeline_name: Text) -> List[metadata_store_pb2.Execution]:\n    """"""Helper function returns executions under a given pipeline name.""""""\n    # step 1: get context id by context name\n    request = metadata_store_service_pb2.GetContextByTypeAndNameRequest(\n        type_name=\'pipeline\', context_name=pipeline_name)\n    context_id = self._stub.GetContextByTypeAndName(request).context.id\n    # step 2: get executions by context id\n    request = metadata_store_service_pb2.GetExecutionsByContextRequest(\n        context_id=context_id)\n    return self._stub.GetExecutionsByContext(request).executions\n\n  def _get_executions_by_pipeline_name_and_state(\n      self, pipeline_name: Text,\n      state: Text) -> List[metadata_store_pb2.Execution]:\n    """"""Helper function returns executions for a given state.""""""\n    executions = self._get_executions_by_pipeline_name(pipeline_name)\n    result = []\n    for e in executions:\n      if e.properties[\'state\'].string_value == state:\n        result.append(e)\n\n    return result\n\n  def _assert_infra_validator_passed(self, pipeline_name: Text):\n    artifacts = self._get_artifacts_with_type_and_pipeline(\n        type_name=\'InfraBlessing\', pipeline_name=pipeline_name)\n    self.assertGreaterEqual(len(artifacts), 1)\n    for artifact in artifacts:\n      blessed = os.path.join(artifact.uri, \'INFRA_BLESSED\')\n      self.assertTrue(\n          tf.io.gfile.exists(blessed),\n          \'Expected InfraBlessing results cannot be found under path %s for \'\n          \'artifact %s\' % (blessed, artifact))\n\n  def testSimpleEnd2EndPipeline(self):\n    """"""End-to-End test for simple pipeline.""""""\n    pipeline_name = \'kubeflow-e2e-test-{}\'.format(test_utils.random_id())\n    components = kubeflow_test_utils.create_e2e_components(\n        self._pipeline_root(pipeline_name),\n        self._data_root,\n        self._transform_module,\n        self._trainer_module,\n    )\n    pipeline = self._create_pipeline(pipeline_name, components)\n\n    self._compile_and_run_pipeline(pipeline)\n    self._assert_infra_validator_passed(pipeline_name)\n\n  def testPrimitiveEnd2EndPipeline(self):\n    """"""End-to-End test for primitive artifacts passing.""""""\n    pipeline_name = \'kubeflow-primitive-e2e-test-{}\'.format(\n        test_utils.random_id())\n    components = kubeflow_test_utils.create_primitive_type_components(\n        pipeline_name)\n    # Test that the pipeline can be executed successfully.\n    pipeline = self._create_pipeline(pipeline_name, components)\n    self._compile_and_run_pipeline(\n        pipeline=pipeline, workflow_name=pipeline_name + \'-run-1\')\n    # Test if the correct value has been passed.\n    str_artifacts = self._get_artifacts_with_type_and_pipeline(\n        type_name=\'String\', pipeline_name=pipeline_name)\n    # There should be exactly one string artifact.\n    self.assertEqual(1, len(str_artifacts))\n    self.assertEqual(\n        self._get_value_of_string_artifact(str_artifacts[0]),\n        \'hello %s\\n\' % pipeline_name)\n    # Test caching.\n    self._compile_and_run_pipeline(\n        pipeline=pipeline, workflow_name=pipeline_name + \'-run-2\')\n    cached_execution = self._get_executions_by_pipeline_name_and_state(\n        pipeline_name=pipeline_name, state=metadata.EXECUTION_STATE_CACHED)\n    self.assertEqual(2, len(cached_execution))\n\n  def testCreateContainerComponentEnd2EndPipeline(self):\n    """"""End-to-End test for container components.""""""\n    pipeline_name = \'kubeflow-container-e2e-test-{}\'.format(\n        test_utils.random_id())\n    text_url = (\n        \'https://storage.googleapis.com/ml-pipeline-playground/hamlet.txt\')\n    pattern = \'art thou\'\n    component_instances = download_grep_print_pipeline.create_pipeline_component_instances(\n        text_url=text_url,\n        pattern=pattern,\n    )\n    # Test that the pipeline can be executed successfully.\n    pipeline = self._create_pipeline(pipeline_name, component_instances)\n    self._compile_and_run_pipeline(\n        pipeline=pipeline, workflow_name=pipeline_name)\n    # Test if the correct value has been passed.\n    artifacts = self._get_artifacts_with_type_and_pipeline(\n        type_name=\'ExternalArtifact\', pipeline_name=pipeline_name)\n    # There should be exactly two artifacts.\n    self.assertEqual(len(artifacts), 2)\n    for artifact in artifacts:\n      # TODO(b/150515270) Remove the \'/data\' suffix when b/150515270 is fixed.\n      artifact_value = tf.io.gfile.GFile(artifact.uri + \'/data\', \'r\').read()\n      self.assertGreater(len(artifact_value), 100)\n\n\nif __name__ == \'__main__\':\n  logging.set_verbosity(logging.INFO)\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/kubeflow_gcp_integration_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Integration tests for Kubeflow-based orchestrator and GCP backend.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\n\nimport absl\nimport tensorflow as tf\n\nfrom tfx.components.base import executor_spec\nfrom tfx.components.common_nodes.importer_node import ImporterNode\nfrom tfx.components.evaluator.component import Evaluator\nfrom tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\nfrom tfx.components.pusher.component import Pusher\nfrom tfx.components.statistics_gen.component import StatisticsGen\nfrom tfx.components.trainer.component import Trainer\nfrom tfx.components.transform.component import Transform\nfrom tfx.extensions.google_cloud_ai_platform.pusher import executor as ai_platform_pusher_executor\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor as ai_platform_trainer_executor\nfrom tfx.orchestration import test_utils\nfrom tfx.orchestration.kubeflow import kubeflow_test_utils\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import dsl_utils\nfrom tfx.utils import path_utils\n\n\nclass KubeflowGCPIntegrationTest(kubeflow_test_utils.BaseKubeflowTest):\n\n  def _delete_ai_platform_model(self, model_name):\n    """"""Delete pushed model in AI Platform.""""""\n    # In order to delete model, all versions in the model must be deleted first.\n    versions_command = [\n        \'gcloud\', \'ai-platform\', \'versions\', \'list\',\n        \'--model=%s\' % model_name\n    ]\n    versions = subprocess.run(versions_command, stdout=subprocess.PIPE)\n\n    if versions.returncode == 0:\n      absl.logging.info(\'Model %s has versions %s\' %\n                        (model_name, versions.stdout))\n\n      # First line of the output is the header: [NAME] [DEPLOYMENT_URI] [STATE]\n      # By specification of test case, the latest version is the default model,\n      # which needs to be deleted last.\n      for version in versions.stdout.decode(\'utf-8\').strip(\'\\n\').split(\n          \'\\n\')[1:]:\n        version = version.split()[0]\n        absl.logging.info(\'Deleting version %s of model %s\' %\n                          (version, model_name))\n        version_delete_command = [\n            \'gcloud\', \'--quiet\', \'ai-platform\', \'versions\', \'delete\', version,\n            \'--model=%s\' % model_name\n        ]\n        subprocess.run(version_delete_command, check=True)\n\n    absl.logging.info(\'Deleting model %s\' % model_name)\n    subprocess.run(\n        [\'gcloud\', \'--quiet\', \'ai-platform\', \'models\', \'delete\', model_name],\n        check=True)\n\n  def setUp(self):\n    super(KubeflowGCPIntegrationTest, self).setUp()\n\n    # Example artifacts for testing.\n    self.raw_examples_importer = ImporterNode(\n        instance_name=\'raw_examples\',\n        source_uri=os.path.join(self._testdata_root, \'csv_example_gen\'),\n        artifact_type=standard_artifacts.Examples,\n        reimport=True,\n        properties={\'split_names\': \'[""train"", ""eval""]\'})\n\n    # Transformed Example artifacts for testing.\n    self.transformed_examples_importer = ImporterNode(\n        instance_name=\'transformed_examples\',\n        source_uri=os.path.join(self._testdata_root, \'transform\',\n                                \'transformed_examples\'),\n        artifact_type=standard_artifacts.Examples,\n        reimport=True,\n        properties={\'split_names\': \'[""train"", ""eval""]\'})\n\n    # Schema artifact for testing.\n    self.schema_importer = ImporterNode(\n        instance_name=\'schema\',\n        source_uri=os.path.join(self._testdata_root, \'schema_gen\'),\n        artifact_type=standard_artifacts.Schema,\n        reimport=True)\n\n    # TransformGraph artifact for testing.\n    self.transform_graph_importer = ImporterNode(\n        instance_name=\'transform_graph\',\n        source_uri=os.path.join(self._testdata_root, \'transform\',\n                                \'transform_graph\'),\n        artifact_type=standard_artifacts.TransformGraph,\n        reimport=True)\n\n    # Model artifact for testing.\n    self.model_1_importer = ImporterNode(\n        instance_name=\'model_1\',\n        source_uri=os.path.join(self._testdata_root, \'trainer\', \'previous\'),\n        artifact_type=standard_artifacts.Model,\n        reimport=True)\n\n    self.model_2_importer = ImporterNode(\n        instance_name=\'model_2\',\n        source_uri=os.path.join(self._testdata_root, \'trainer\', \'current\'),\n        artifact_type=standard_artifacts.Model,\n        reimport=True)\n\n    # ModelBlessing artifact for testing.\n    self.model_blessing_importer = ImporterNode(\n        instance_name=\'model_blessing\',\n        source_uri=os.path.join(self._testdata_root, \'model_validator\',\n                                \'blessed\'),\n        artifact_type=standard_artifacts.ModelBlessing,\n        reimport=True,\n        custom_properties={\'blessed\': 1})\n\n  def testCsvExampleGenOnDataflowRunner(self):\n    """"""CsvExampleGen-only test pipeline on DataflowRunner invocation.""""""\n    pipeline_name = \'kubeflow-csv-example-gen-dataflow-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_dataflow_pipeline(pipeline_name, [\n        CsvExampleGen(input=dsl_utils.csv_input(self._data_root)),\n    ])\n    self._compile_and_run_pipeline(pipeline)\n\n  def testStatisticsGenOnDataflowRunner(self):\n    """"""StatisticsGen-only test pipeline on DataflowRunner.""""""\n    pipeline_name = \'kubeflow-statistics-gen-dataflow-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_dataflow_pipeline(pipeline_name, [\n        self.raw_examples_importer,\n        StatisticsGen(examples=self.raw_examples_importer.outputs[\'result\'])\n    ])\n    self._compile_and_run_pipeline(pipeline)\n\n  def testTransformOnDataflowRunner(self):\n    """"""Transform-only test pipeline on DataflowRunner.""""""\n    pipeline_name = \'kubeflow-transform-dataflow-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_dataflow_pipeline(pipeline_name, [\n        self.raw_examples_importer, self.schema_importer,\n        Transform(\n            examples=self.raw_examples_importer.outputs[\'result\'],\n            schema=self.schema_importer.outputs[\'result\'],\n            module_file=self._transform_module)\n    ])\n    self._compile_and_run_pipeline(pipeline)\n\n  def testEvaluatorOnDataflowRunner(self):\n    """"""Evaluator-only test pipeline on DataflowRunner.""""""\n    pipeline_name = \'kubeflow-evaluator-dataflow-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_dataflow_pipeline(pipeline_name, [\n        self.raw_examples_importer, self.model_1_importer,\n        Evaluator(\n            examples=self.raw_examples_importer.outputs[\'result\'],\n            model=self.model_1_importer.outputs[\'result\'],\n            feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n                evaluator_pb2.SingleSlicingSpec(\n                    column_for_slicing=[\'trip_start_hour\'])\n            ]))\n    ])\n    self._compile_and_run_pipeline(pipeline)\n\n  def getCaipTrainingArgs(self, pipeline_name):\n    """"""Training args for Google CAIP Training.""""""\n    return {\n        \'project\': self._GCP_PROJECT_ID,\n        \'region\': self._GCP_REGION,\n        \'jobDir\': os.path.join(self._pipeline_root(pipeline_name), \'tmp\'),\n        \'masterConfig\': {\n            \'imageUri\': self._CONTAINER_IMAGE,\n        },\n    }\n\n  def getCaipTrainingArgsForDistributed(self, pipeline_name):\n    """"""Training args to test that distributed training is behaves properly.""""""\n    args = self.getCaipTrainingArgs(pipeline_name)\n    args.update({\n        \'scaleTier\': \'CUSTOM\',\n        \'masterType\': \'large_model\',\n        \'parameterServerType\': \'standard\',\n        \'parameterServerCount\': 1,\n        \'workerType\': \'standard\',\n        \'workerCount\': 2,\n    })\n    return args\n\n  def assertNumberOfTrainerOutputIsOne(self, pipeline_name):\n    """"""Make sure the number of trainer executions and output models.""""""\n    # There must be only one execution of Trainer.\n    trainer_output_base_dir = os.path.join(\n        self._pipeline_root(pipeline_name), \'Trainer\', \'model\')\n    trainer_outputs = tf.io.gfile.listdir(trainer_output_base_dir)\n    self.assertEqual(1, len(trainer_outputs))\n\n    # There must be only one saved models each for serving and eval.\n    model_uri = os.path.join(trainer_output_base_dir, trainer_outputs[0])\n    self.assertEqual(\n        1, len(tf.io.gfile.listdir(path_utils.eval_model_dir(model_uri))))\n    self.assertEqual(\n        1,\n        len(\n            tf.io.gfile.listdir(\n                os.path.join(\n                    path_utils.serving_model_dir(model_uri), \'export\',\n                    \'chicago-taxi\'))))\n\n  def testAIPlatformTrainerPipeline(self):\n    """"""Trainer-only test pipeline on AI Platform Training.""""""\n    pipeline_name = \'kubeflow-aip-trainer-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_pipeline(pipeline_name, [\n        self.schema_importer, self.transformed_examples_importer,\n        self.transform_graph_importer,\n        Trainer(\n            custom_executor_spec=executor_spec.ExecutorClassSpec(\n                ai_platform_trainer_executor.Executor),\n            module_file=self._trainer_module,\n            transformed_examples=self.transformed_examples_importer\n            .outputs[\'result\'],\n            schema=self.schema_importer.outputs[\'result\'],\n            transform_graph=self.transform_graph_importer.outputs[\'result\'],\n            train_args=trainer_pb2.TrainArgs(num_steps=10),\n            eval_args=trainer_pb2.EvalArgs(num_steps=5),\n            custom_config={\n                ai_platform_trainer_executor.TRAINING_ARGS_KEY:\n                    self.getCaipTrainingArgsForDistributed(pipeline_name)\n            })\n    ])\n    self._compile_and_run_pipeline(pipeline)\n    self.assertNumberOfTrainerOutputIsOne(pipeline_name)\n\n  def testAIPlatformGenericTrainerPipeline(self):\n    """"""Trainer-only pipeline on AI Platform Training with GenericTrainer.""""""\n    pipeline_name = \'kubeflow-aip-generic-trainer-test-{}\'.format(\n        test_utils.random_id())\n    pipeline = self._create_pipeline(pipeline_name, [\n        self.schema_importer,\n        self.transformed_examples_importer,\n        self.transform_graph_importer,\n        Trainer(\n            custom_executor_spec=executor_spec.ExecutorClassSpec(\n                ai_platform_trainer_executor.GenericExecutor),\n            module_file=self._trainer_module,\n            transformed_examples=self.transformed_examples_importer\n            .outputs[\'result\'],\n            schema=self.schema_importer.outputs[\'result\'],\n            transform_graph=self.transform_graph_importer.outputs[\'result\'],\n            train_args=trainer_pb2.TrainArgs(num_steps=10),\n            eval_args=trainer_pb2.EvalArgs(num_steps=5),\n            custom_config={\n                ai_platform_trainer_executor.TRAINING_ARGS_KEY:\n                    self.getCaipTrainingArgs(pipeline_name)\n            })\n    ])\n    self._compile_and_run_pipeline(pipeline)\n    self.assertNumberOfTrainerOutputIsOne(pipeline_name)\n  # TODO(b/150661783): Add tests using distributed training with a generic\n  #  trainer.\n  # TODO(b/150576271): Add Trainer tests using Keras models.\n\n  # TODO(muchida): Identify more model types to ensure models trained in TF 2\n  # works with CAIP prediction service.\n  def testAIPlatformPusherPipeline(self):\n    """"""Pusher-only test pipeline to AI Platform Prediction.""""""\n    pipeline_name_base = \'kubeflow-aip-pusher-test-{}\'.format(\n        test_utils.random_id())\n    # AI Platform does not accept \'-\' in the model name.\n    model_name = (\'%s_model\' % pipeline_name_base).replace(\'-\', \'_\')\n    self.addCleanup(self._delete_ai_platform_model, model_name)\n\n    def _pusher(model_importer, model_blessing_importer):\n      return Pusher(\n          custom_executor_spec=executor_spec.ExecutorClassSpec(\n              ai_platform_pusher_executor.Executor),\n          model=model_importer.outputs[\'result\'],\n          model_blessing=model_blessing_importer.outputs[\'result\'],\n          custom_config={\n              ai_platform_pusher_executor.SERVING_ARGS_KEY: {\n                  \'model_name\': model_name,\n                  \'project_id\': self._GCP_PROJECT_ID,\n              }\n          },\n      )\n\n    # Test creation of multiple versions under the same model_name.\n    pipeline_name_1 = \'%s-1\' % pipeline_name_base\n    pipeline_1 = self._create_pipeline(pipeline_name_1, [\n        self.model_1_importer,\n        self.model_blessing_importer,\n        _pusher(self.model_1_importer, self.model_blessing_importer),\n    ])\n    self._compile_and_run_pipeline(pipeline_1)\n\n    pipeline_name_2 = \'%s-2\' % pipeline_name_base\n    pipeline_2 = self._create_pipeline(pipeline_name_2, [\n        self.model_2_importer,\n        self.model_blessing_importer,\n        _pusher(self.model_2_importer, self.model_blessing_importer),\n    ])\n    self._compile_and_run_pipeline(pipeline_2)\n\n\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/kubeflow_gcp_perf_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Integration tests for TFX-on-KFP and GCP services.""""""\n\n# TODO(b/149535307): Remove __future__ imports\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nimport subprocess\nimport time\nfrom typing import Text\n\nfrom absl import logging\nimport kfp\nfrom kfp_server_api import rest\nimport tensorflow as tf\n\nfrom tfx.examples.chicago_taxi_pipeline import taxi_pipeline_kubeflow_gcp\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration import test_utils\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.orchestration.kubeflow import test_utils as kubeflow_test_utils\n\n\nclass KubeflowGcpPerfTest(kubeflow_test_utils.BaseKubeflowTest):\n\n  # The endpoint of the KFP instance.\n  # This test fixture assumes an established KFP instance authenticated via\n  # inverse proxy.\n  _KFP_ENDPOINT = os.environ[\'KFP_E2E_ENDPOINT\']\n\n  # The namespace where KFP is deployed.\n  _KFP_NAMESPACE = \'kubeflow\'\n\n  # Timeout for a single pipeline run. Set to 6 hours.\n  # TODO(b/158009615): Tune this timeout to align with our observation.\n  # Note: the Chicago Taxi dataset is a dataset growing with time. The 6 hour\n  # timeout here was calibrated according to our empirical study in\n  # b/150222976. This might need to be adjusted occasionally.\n  _TIME_OUT = datetime.timedelta(hours=6)\n\n  # KFP client polling interval, in seconds\n  _POLLING_INTERVAL = 60\n\n  # TODO(b/156784019): temporary workaround.\n  # Number of retries when `get_run` returns remote error.\n  _N_RETRIES = 5\n\n  # The base container image name to use when building the image used in tests.\n  _BASE_CONTAINER_IMAGE = os.environ[\'KFP_E2E_BASE_CONTAINER_IMAGE\']\n\n  # The project id to use to run tests.\n  _GCP_PROJECT_ID = os.environ[\'KFP_E2E_GCP_PROJECT_ID\']\n\n  # The GCP region in which the end-to-end test is run.\n  _GCP_REGION = os.environ[\'KFP_E2E_GCP_REGION\']\n\n  # The GCP zone in which the cluster is created.\n  _GCP_ZONE = os.environ[\'KFP_E2E_GCP_ZONE\']\n\n  # The GCP bucket to use to write output artifacts.\n  _BUCKET_NAME = os.environ[\'KFP_E2E_BUCKET_NAME\']\n\n  # The GCP GKE cluster name where the KFP deployment is installed.\n  _CLUSTER_NAME = os.environ[\'KFP_E2E_CLUSTER_NAME\']\n\n  # Various execution status of a KFP pipeline.\n  _KFP_RUNNING_STATUS = \'running\'\n  _KFP_SUCCESS_STATUS = \'succeeded\'\n  _KFP_FAIL_STATUS = \'failed\'\n  _KFP_SKIPPED_STATUS = \'skipped\'\n  _KFP_ERROR_STATUS = \'error\'\n\n  _KFP_FINAL_STATUS = frozenset((_KFP_SUCCESS_STATUS, _KFP_FAIL_STATUS,\n                                 _KFP_SKIPPED_STATUS, _KFP_ERROR_STATUS))\n\n  # The location of test user module file.\n  # It is retrieved from inside the container subject to testing.\n  _MODULE_FILE = \'/tfx-src/tfx/examples/chicago_taxi_pipeline/taxi_utils.py\'\n\n  # Parameterize worker type/count for easily ramping up the pipeline scale.\n  _WORKER_COUNT = data_types.RuntimeParameter(\n      name=\'worker_count\',\n      default=2,\n      ptype=int,\n  )\n\n  _WORKER_TYPE = data_types.RuntimeParameter(\n      name=\'worker_type\',\n      default=\'standard\',\n      ptype=str,\n  )\n\n  # Parameterize parameter server count for easily ramping up the scale.\n  _PARAMETER_SERVER_COUNT = data_types.RuntimeParameter(\n      name=\'parameter_server_count\',\n      default=1,\n      ptype=int,\n  )\n\n  _AI_PLATFORM_SERVING_ARGS = {\n      \'model_name\': \'chicago_taxi\',\n      \'project_id\': _GCP_PROJECT_ID,\n      \'regions\': [_GCP_REGION],\n  }\n\n  # TODO(b/151114974): Remove `disk_size_gb` flag after default is increased.\n  # TODO(b/151116587): Remove `shuffle_mode` flag after default is changed.\n  _BEAM_PIPELINE_ARGS = [\n      \'--runner=DataflowRunner\',\n      \'--project=\' + _GCP_PROJECT_ID,\n      \'--temp_location=gs://\' + os.path.join(_BUCKET_NAME, \'dataflow\', \'tmp\'),\n      \'--region=\' + _GCP_REGION,\n\n      # In order not to consume in-use global IP addresses by Dataflow workers,\n      # configure workers to not use public IPs. If workers needs access to\n      # public Internet, CloudNAT needs to be configured for the VPC in which\n      # Dataflow runs.\n      \'--no_use_public_ips\'\n\n      # Temporary overrides of defaults.\n      \'--disk_size_gb=50\',\n      \'--experiments=shuffle_mode=auto\',\n  ]\n\n  @classmethod\n  def tearDownClass(cls):\n    super(kubeflow_test_utils.BaseKubeflowTest, cls).tearDownClass()\n    # Delete the cluster created in the test.\n    delete_cluster_command = [\n        \'gcloud\', \'container\', \'clusters\', \'delete\', cls._CLUSTER_NAME,\n        \'--region=%s\' % cls._GCP_ZONE, \'--quiet\'\n    ]\n    logging.info(\n        subprocess.check_output(delete_cluster_command).decode(\'utf-8\'))\n\n  def _get_workflow_name(self, pipeline_name: Text) -> Text:\n    """"""Gets the Argo workflow name using pipeline name.""""""\n    get_workflow_name_command = (\n        \'argo --namespace %s list | grep -o ""%s[^ ]*""\' %\n        (self._KFP_NAMESPACE, pipeline_name))\n    # Need to explicitly decode because the test fixture is running on\n    # Python 3.5. Also need to remove the new line at the end of the string.\n    return subprocess.check_output(\n        get_workflow_name_command, shell=True).decode(\'utf-8\')[:-1]\n\n  def _get_workflow_log(self, pipeline_name: Text) -> Text:\n    """"""Gets the workflow log for all the pods using pipeline name.""""""\n    get_workflow_log_command = [\n        \'argo\', \'--namespace\', self._KFP_NAMESPACE, \'logs\', \'-w\',\n        self._get_workflow_name(pipeline_name)\n    ]\n    # Need to explicitly decode because the test fixture is running on\n    # Python 3.5.\n    return subprocess.check_output(get_workflow_log_command).decode(\'utf-8\')\n\n  def _poll_kfp_with_retry(self, host: Text, run_id: Text, retry_limit: int,\n                           timeout: datetime.timedelta,\n                           polling_interval: int) -> Text:\n    """"""Gets the pipeline execution status by polling KFP at the specified host.\n\n    Args:\n      host: address of the KFP deployment.\n      run_id: id of the execution of the pipeline.\n      retry_limit: number of retries that will be performed before raise an\n        error.\n      timeout: timeout of this long-running operation, in timedelta.\n      polling_interval: interval between two consecutive polls, in seconds.\n\n    Returns:\n      The final status of the execution. Possible value can be found at\n      https://github.com/kubeflow/pipelines/blob/master/backend/api/run.proto#L254\n\n    Raises:\n      RuntimeError: if polling failed for retry_limit times consecutively.\n    """"""\n\n    start_time = datetime.datetime.now()\n    retry_count = 0\n    while True:\n      # TODO(jxzheng): workaround for 1hr timeout limit in kfp.Client().\n      # This should be changed after\n      # https://github.com/kubeflow/pipelines/issues/3630 is fixed.\n      # Currently gcloud authentication token has a 1-hour expiration by default\n      # but kfp.Client() does not have a refreshing mechanism in place. This\n      # causes failure when attempting to get running status for a long pipeline\n      # execution (> 1 hour).\n      # Instead of implementing a whole authentication refreshing mechanism\n      # here, we chose re-creating kfp.Client() frequently to make sure the\n      # authentication does not expire. This is based on the fact that\n      # kfp.Client() is very light-weight.\n      # See more details at\n      # https://github.com/kubeflow/pipelines/issues/3630\n      client = kfp.Client(host=host)\n      # TODO(b/156784019): workaround the known issue at b/156784019 and\n      # https://github.com/kubeflow/pipelines/issues/3669\n      # by wait-and-retry when ApiException is hit.\n      try:\n        get_run_response = client._run_api.get_run(run_id=run_id)\n      except rest.ApiException as api_err:\n        # If get_run failed with ApiException, wait _POLLING_INTERVAL and retry.\n        if retry_count < retry_limit:\n          retry_count += 1\n          logging.info(\'API error %s was hit. Retrying: %s / %s.\', api_err,\n                       retry_count, retry_limit)\n          time.sleep(self._POLLING_INTERVAL)\n          continue\n\n        raise RuntimeError(\'Still hit remote error after %s retries: %s\' %\n                           (retry_limit, api_err))\n      else:\n        # If get_run succeeded, reset retry_count.\n        retry_count = 0\n\n      if (get_run_response and get_run_response.run and\n          get_run_response.run.status and\n          get_run_response.run.status.lower() in self._KFP_FINAL_STATUS):\n        # Return because final status is reached.\n        return get_run_response.run.status\n\n      if datetime.datetime.now() - start_time > timeout:\n        # Timeout.\n        raise RuntimeError(\'Waiting for run timeout at %s\' %\n                           datetime.datetime.now().strftime(\'%H:%M:%S\'))\n\n      logging.info(\'Waiting for the job to complete...\')\n      time.sleep(self._POLLING_INTERVAL)\n\n  def _assert_successful_run_completion(self, host: Text, run_id: Text,\n                                        pipeline_name: Text,\n                                        timeout: datetime.timedelta):\n    """"""Waits and asserts a successful KFP pipeline execution.\n\n    Args:\n      host: the endpoint of the KFP deployment.\n      run_id: the run ID of the execution, can be obtained from the respoonse\n        when submitting the pipeline.\n      pipeline_name: the name of the pipeline under test.\n      timeout: maximal waiting time for this execution, in timedelta.\n\n    Raises:\n      RuntimeError: when timeout exceeds after waiting for specified duration.\n    """"""\n\n    status = self._poll_kfp_with_retry(\n        host=host,\n        run_id=run_id,\n        retry_limit=self._N_RETRIES,\n        timeout=timeout,\n        polling_interval=self._POLLING_INTERVAL)\n\n    workflow_log = self._get_workflow_log(pipeline_name)\n\n    self.assertEqual(\n        status.lower(), self._KFP_SUCCESS_STATUS,\n        \'Pipeline %s failed to complete successfully: %s\' %\n        (pipeline_name, workflow_log))\n\n  def _compile_and_run_pipeline(self, pipeline: tfx_pipeline.Pipeline,\n                                **kwargs):\n    """"""Compiles and runs a KFP pipeline.\n\n    In this method, provided TFX pipeline will be submitted via kfp.Client()\n    instead of from Argo.\n\n    Args:\n      pipeline: The logical pipeline to run.\n      **kwargs: Key-value pairs of runtime paramters passed to the pipeline\n        execution.\n    """"""\n    client = kfp.Client(host=self._KFP_ENDPOINT)\n\n    pipeline_name = pipeline.pipeline_info.pipeline_name\n    config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n        kubeflow_metadata_config=self._get_kubeflow_metadata_config(),\n        tfx_image=self._CONTAINER_IMAGE)\n    kubeflow_dag_runner.KubeflowDagRunner(config=config).run(pipeline)\n\n    file_path = os.path.join(self._test_dir, \'{}.tar.gz\'.format(pipeline_name))\n    self.assertTrue(tf.io.gfile.exists(file_path))\n\n    run_result = client.create_run_from_pipeline_package(\n        pipeline_file=file_path, arguments=kwargs)\n    run_id = run_result.run_id\n\n    self._assert_successful_run_completion(\n        host=self._KFP_ENDPOINT,\n        run_id=run_id,\n        pipeline_name=pipeline_name,\n        timeout=self._TIME_OUT)\n\n  def testFullTaxiGcpPipeline(self):\n    pipeline_name = \'gcp-perf-test-full-e2e-test-{}\'.format(\n        test_utils.random_id())\n\n    # Custom CAIP training job using a testing image.\n    ai_platform_training_args = {\n        \'project\': self._GCP_PROJECT_ID,\n        \'region\': self._GCP_REGION,\n        \'scaleTier\': \'CUSTOM\',\n        \'masterType\': \'large_model\',\n        \'masterConfig\': {\n            \'imageUri\': self._CONTAINER_IMAGE\n        },\n        \'workerType\': self._WORKER_TYPE,\n        \'parameterServerType\': \'standard\',\n        \'workerCount\': self._WORKER_COUNT,\n        \'parameterServerCount\': self._PARAMETER_SERVER_COUNT\n    }\n\n    pipeline = taxi_pipeline_kubeflow_gcp.create_pipeline(\n        pipeline_name=pipeline_name,\n        pipeline_root=self._pipeline_root(pipeline_name),\n        module_file=self._MODULE_FILE,\n        ai_platform_training_args=ai_platform_training_args,\n        ai_platform_serving_args=self._AI_PLATFORM_SERVING_ARGS,\n        beam_pipeline_args=self._BEAM_PIPELINE_ARGS)\n    self._compile_and_run_pipeline(\n        pipeline=pipeline,\n        query_sample_rate=1,\n        # (1M * batch_size=200) / 200M records ~ 1 epoch\n        train_steps=1000000,\n        eval_steps=10000,\n        worker_count=20,\n        parameter_server_count=3,\n    )\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/kubeflow_metadata_adapter.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A Metadata adapter class used to add Kubeflow-specific context.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, Text\nimport absl\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\n\n_KFP_POD_NAME_ENV_KEY = \'KFP_POD_NAME\'\n_KFP_POD_NAME_PROPERTY_KEY = \'kfp_pod_name\'\n\n\nclass KubeflowMetadataAdapter(metadata.Metadata):\n  """"""A Metadata adapter class for pipelines run using KFP.\n\n  This is used to add properties to artifacts and executions, such as the Argo\n  pod IDs.\n  """"""\n\n  def _is_eligible_previous_execution(\n      self, current_execution: metadata_store_pb2.Execution,\n      target_execution: metadata_store_pb2.Execution) -> bool:\n    current_execution.properties[_KFP_POD_NAME_PROPERTY_KEY].string_value = \'\'\n    target_execution.properties[_KFP_POD_NAME_PROPERTY_KEY].string_value = \'\'\n    return super(KubeflowMetadataAdapter,\n                 self)._is_eligible_previous_execution(current_execution,\n                                                       target_execution)\n\n  def _prepare_execution(\n      self,\n      state: Text,\n      exec_properties: Dict[Text, Any],\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> metadata_store_pb2.Execution:\n    if os.environ[_KFP_POD_NAME_ENV_KEY]:\n      kfp_pod_name = os.environ[_KFP_POD_NAME_ENV_KEY]\n      absl.logging.info(\'Adding KFP pod name %s to execution\' % kfp_pod_name)\n      exec_properties[_KFP_POD_NAME_PROPERTY_KEY] = kfp_pod_name\n    return super(KubeflowMetadataAdapter,\n                 self)._prepare_execution(state, exec_properties, pipeline_info,\n                                          component_info)\n'"
tfx/orchestration/kubeflow/kubeflow_metadata_adapter_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.kubeflow.kubeflow_metadata_adapter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration.kubeflow import kubeflow_metadata_adapter\n\n\nclass KubeflowMetadataAdapterTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(KubeflowMetadataAdapterTest, self).setUp()\n    self._connection_config = metadata_store_pb2.ConnectionConfig()\n    self._connection_config.sqlite.SetInParent()\n    self._pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'fake_pipeline_name\',\n        pipeline_root=\'/fake_pipeline_root\',\n        run_id=\'fake_run_id\')\n    self._pipeline_info2 = data_types.PipelineInfo(\n        pipeline_name=\'fake_pipeline_name\',\n        pipeline_root=\'/fake_pipeline_root\',\n        run_id=\'fake_run_id2\')\n    self._component_info = data_types.ComponentInfo(\n        component_type=\'fake.component.type\',\n        component_id=\'fake_component_id\',\n        pipeline_info=self._pipeline_info)\n    self._component_info2 = data_types.ComponentInfo(\n        component_type=\'fake.component.type\',\n        component_id=\'fake_component_id\',\n        pipeline_info=self._pipeline_info2)\n\n  def testPrepareExecution(self):\n    with kubeflow_metadata_adapter.KubeflowMetadataAdapter(\n        connection_config=self._connection_config) as m:\n      contexts = m.register_pipeline_contexts_if_not_exists(self._pipeline_info)\n      exec_properties = {\'arg_one\': 1}\n      os.environ[\'KFP_POD_NAME\'] = \'fake_pod_name\'\n      m.register_execution(\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts)\n      [execution] = m.store.get_executions_by_context(contexts[0].id)\n      # Skip verifying time sensitive fields.\n      execution.ClearField(\'create_time_since_epoch\')\n      execution.ClearField(\'last_update_time_since_epoch\')\n      self.assertProtoEquals(\n          """"""\n        id: 1\n        type_id: 3\n        properties {\n          key: ""state""\n          value {\n            string_value: ""new""\n          }\n        }\n        properties {\n          key: ""pipeline_name""\n          value {\n            string_value: ""fake_pipeline_name""\n          }\n        }\n        properties {\n          key: ""pipeline_root""\n          value {\n            string_value: ""/fake_pipeline_root""\n          }\n        }\n        properties {\n          key: ""run_id""\n          value {\n            string_value: ""fake_run_id""\n          }\n        }\n        properties {\n          key: ""component_id""\n          value {\n            string_value: ""fake_component_id""\n          }\n        }\n        properties {\n          key: ""arg_one""\n          value {\n            string_value: ""1""\n          }\n        }\n        properties {\n          key: ""kfp_pod_name""\n          value {\n            string_value: ""fake_pod_name""\n          }\n        }"""""", execution)\n\n  def testIsEligiblePreviousExecution(self):\n    with kubeflow_metadata_adapter.KubeflowMetadataAdapter(\n        connection_config=self._connection_config) as m:\n      contexts_one = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info)\n      contexts_two = m.register_pipeline_contexts_if_not_exists(\n          self._pipeline_info2)\n      exec_properties = {\'arg_one\': 1}\n      os.environ[\'KFP_POD_NAME\'] = \'fake_pod_name1\'\n      m.register_execution(\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info,\n          contexts=contexts_one)\n      os.environ[\'KFP_POD_NAME\'] = \'fake_pod_name2\'\n      m.register_execution(\n          exec_properties=exec_properties,\n          pipeline_info=self._pipeline_info2,\n          component_info=self._component_info2,\n          contexts=contexts_two)\n      [execution1,\n       execution2] = m.store.get_executions_by_context(contexts_one[0].id)\n      self.assertTrue(m._is_eligible_previous_execution(execution1, execution2))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/node_wrapper.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A wrapper to pass a node without its type information.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Text\n\nfrom tfx.components.base import base_node\nfrom tfx.types import node_common\n\n\nclass NodeWrapper(base_node.BaseNode):\n  """"""Wrapper of a node.\n\n  The wrapper is needed for container entrypoint to deserialize a component\n  wihtout knowning it\'s original python class. This enables users\n  to use container base component without re-compiling the tfx base image every\n  time they change the component and spec definitions.\n  """"""\n\n  def __init__(self, node: base_node.BaseNode):\n    self.executor_spec = node.executor_spec\n    self.driver_class = node.driver_class\n    self._type = node.type\n    self._id = node.id\n    self._inputs = node.inputs\n    self._outputs = node.outputs\n    self._exec_properties = node.exec_properties\n\n  @property\n  def type(self) -> Text:\n    return self._type\n\n  @property\n  def id(self) -> Text:\n    return self._id\n\n  @property\n  def inputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return self._inputs\n\n  @property\n  def outputs(self) -> node_common._PropertyDictWrapper:  # pylint: disable=protected-access\n    return self._outputs\n\n  @property\n  def exec_properties(self) -> Dict[Text, Any]:\n    return self._exec_properties\n'"
tfx/orchestration/kubeflow/runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Deprecated definition of Kubeflow TFX runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\n\nKubeflowRunner = deprecation.deprecated_alias(  # pylint: disable=invalid-name\n    deprecated_name=\'runner.KubeflowRunner\',\n    name=\'kubeflow_dag_runner.KubeflowDagRunner\',\n    func_or_class=kubeflow_dag_runner.KubeflowDagRunner)\nKubeflowRunnerConfig = deprecation.deprecated_alias(  # pylint: disable=invalid-name\n    deprecated_name=\'runner.KubeflowRunnerConfig\',\n    name=\'kubeflow_dag_runner.KubeflowDagRunnerConfig\',\n    func_or_class=kubeflow_dag_runner.KubeflowDagRunnerConfig)\n'"
tfx/orchestration/kubeflow/test_utils.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common utility for testing Kubeflow-based orchestrator.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport re\nimport shutil\nimport subprocess\nimport tarfile\nimport tempfile\nimport time\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import InfraValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.base.base_component import BaseComponent\nfrom tfx.dsl.experimental import latest_artifacts_resolver\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration import test_utils\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.orchestration.kubeflow.proto import kubeflow_pb2\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types import channel_utils\nfrom tfx.types import component_spec\nfrom tfx.types import standard_artifacts\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.utils import dsl_utils\n\n\n# Custom component definitions for testing purpose.\nclass _HelloWorldSpec(component_spec.ComponentSpec):\n  INPUTS = {}\n  OUTPUTS = {\n      \'greeting\':\n          component_spec.ChannelParameter(type=standard_artifacts.String)\n  }\n  PARAMETERS = {\n      \'word\': component_spec.ExecutionParameter(type=str),\n  }\n\n\nclass _ByeWorldSpec(component_spec.ComponentSpec):\n  INPUTS = {\n      \'hearing\':\n          component_spec.ChannelParameter(type=standard_artifacts.String)\n  }\n  OUTPUTS = {}\n  PARAMETERS = {}\n\n\nclass HelloWorldComponent(BaseComponent):\n  """"""Producer component.""""""\n\n  SPEC_CLASS = _HelloWorldSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorContainerSpec(\n      # TODO(b/143965964): move the image to private repo if the test is flaky\n      # due to docker hub.\n      image=\'google/cloud-sdk:latest\',\n      command=[\'sh\', \'-c\'],\n      # TODO(b/147242148): Remove /value after decision is made regarding uri\n      # structure.\n      args=[\n          \'echo ""hello {{exec_properties.word}}"" | gsutil cp - {{output_dict[""greeting""][0].uri}}/value\'\n      ])\n\n  def __init__(self, word, greeting=None):\n    if not greeting:\n      artifact = standard_artifacts.String()\n      greeting = channel_utils.as_channel([artifact])\n    super(HelloWorldComponent,\n          self).__init__(_HelloWorldSpec(word=word, greeting=greeting))\n\n\nclass ByeWorldComponent(BaseComponent):\n  """"""Consumer component.""""""\n\n  SPEC_CLASS = _ByeWorldSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorContainerSpec(\n      image=\'bash:latest\',\n      command=[\'echo\'],\n      args=[\'received {{input_dict[""hearing""][0].value}}\'])\n\n  def __init__(self, hearing):\n    super(ByeWorldComponent, self).__init__(_ByeWorldSpec(hearing=hearing))\n\n\ndef create_primitive_type_components(\n    pipeline_name: Text) -> List[BaseComponent]:\n  """"""Creates components for testing primitive type artifact passing.\n\n  Args:\n    pipeline_name: Name of this pipeline.\n\n  Returns:\n    A list of TFX custom container components.\n  """"""\n  hello_world = HelloWorldComponent(word=pipeline_name)\n  bye_world = ByeWorldComponent(hearing=hello_world.outputs[\'greeting\'])\n\n  return [hello_world, bye_world]\n\n\ndef create_e2e_components(\n    pipeline_root: Text,\n    csv_input_location: Text,\n    transform_module: Text,\n    trainer_module: Text,\n) -> List[BaseComponent]:\n  """"""Creates components for a simple Chicago Taxi TFX pipeline for testing.\n\n  Args:\n    pipeline_root: The root of the pipeline output.\n    csv_input_location: The location of the input data directory.\n    transform_module: The location of the transform module file.\n    trainer_module: The location of the trainer module file.\n\n  Returns:\n    A list of TFX components that constitutes an end-to-end test pipeline.\n  """"""\n  examples = dsl_utils.csv_input(csv_input_location)\n\n  example_gen = CsvExampleGen(input=examples)\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=transform_module)\n  latest_model_resolver = ResolverNode(\n      instance_name=\'latest_model_resolver\',\n      resolver_class=latest_artifacts_resolver.LatestArtifactsResolver,\n      latest_model=Channel(type=Model))\n  trainer = Trainer(\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      base_model=latest_model_resolver.outputs[\'latest_model\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5),\n      module_file=trainer_module,\n  )\n  # Set the TFMA config for Model Evaluation and Validation.\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\'eval\')],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              metrics=[tfma.MetricConfig(class_name=\'ExampleCount\')],\n              thresholds={\n                  \'accuracy\':\n                      tfma.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\'value\': 0.5}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\'value\': -1e-10}))\n              })\n      ],\n      slicing_specs=[\n          tfma.SlicingSpec(),\n          tfma.SlicingSpec(feature_keys=[\'trip_start_hour\'])\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      eval_config=eval_config)\n\n  infra_validator = InfraValidator(\n      model=trainer.outputs[\'model\'],\n      examples=example_gen.outputs[\'examples\'],\n      serving_spec=infra_validator_pb2.ServingSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n              tags=[\'latest\']),\n          kubernetes=infra_validator_pb2.KubernetesConfig()),\n      request_spec=infra_validator_pb2.RequestSpec(\n          tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec())\n  )\n\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=evaluator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=os.path.join(pipeline_root, \'model_serving\'))))\n\n  return [\n      example_gen,\n      statistics_gen,\n      schema_gen,\n      example_validator,\n      transform,\n      latest_model_resolver,\n      trainer,\n      evaluator,\n      infra_validator,\n      pusher,\n  ]\n\n\nclass BaseKubeflowTest(tf.test.TestCase):\n  """"""Base class that defines testing harness for pipeline on KubeflowRunner.""""""\n\n  _POLLING_INTERVAL_IN_SECONDS = 10\n\n  # The following environment variables need to be set prior to calling the test\n  # in this file. All variables are required and do not have a default.\n\n  # The base container image name to use when building the image used in tests.\n  _BASE_CONTAINER_IMAGE = os.environ[\'KFP_E2E_BASE_CONTAINER_IMAGE\']\n\n  # The src path to use to build docker image\n  _REPO_BASE = os.environ[\'KFP_E2E_SRC\']\n\n  # The project id to use to run tests.\n  _GCP_PROJECT_ID = os.environ[\'KFP_E2E_GCP_PROJECT_ID\']\n\n  # The GCP region in which the end-to-end test is run.\n  _GCP_REGION = os.environ[\'KFP_E2E_GCP_REGION\']\n\n  # The GCP bucket to use to write output artifacts.\n  _BUCKET_NAME = os.environ[\'KFP_E2E_BUCKET_NAME\']\n\n  # The location of test data. The input files are copied to a test-local\n  # location for each invocation, and cleaned up at the end of test.\n  _TEST_DATA_ROOT = os.environ[\'KFP_E2E_TEST_DATA_ROOT\']\n\n  # The location of test user module\n  # It is retrieved from inside the container subject to testing.\n  _MODULE_ROOT = \'/tfx-src/tfx/components/testdata/module_file\'\n\n  _CONTAINER_IMAGE = \'{}:{}\'.format(_BASE_CONTAINER_IMAGE,\n                                    test_utils.random_id())\n\n  @classmethod\n  def setUpClass(cls):\n    super(BaseKubeflowTest, cls).setUpClass()\n\n    # Create a container image for use by test pipelines.\n    test_utils.build_and_push_docker_image(cls._CONTAINER_IMAGE, cls._REPO_BASE)\n\n  @classmethod\n  def tearDownClass(cls):\n    super(BaseKubeflowTest, cls).tearDownClass()\n\n    # Delete container image used in tests.\n    absl.logging.info(\'Deleting image %s\', cls._CONTAINER_IMAGE)\n    subprocess.run(\n        [\'gcloud\', \'container\', \'images\', \'delete\', cls._CONTAINER_IMAGE],\n        check=True)\n\n  @classmethod\n  def _get_mysql_pod_name(cls):\n    """"""Returns MySQL pod name in the cluster.""""""\n    pod_name = subprocess.check_output([\n        \'kubectl\',\n        \'-n\',\n        \'kubeflow\',\n        \'get\',\n        \'pods\',\n        \'-l\',\n        \'app=mysql\',\n        \'--no-headers\',\n        \'-o\',\n        \'custom-columns=:metadata.name\',\n    ]).decode(\'utf-8\').strip(\'\\n\')\n    absl.logging.info(\'MySQL pod name is: {}\'.format(pod_name))\n    return pod_name\n\n  @classmethod\n  def _get_mlmd_db_name(cls, pipeline_name: Text):\n    # MySQL DB names must not contain \'-\' while k8s names must not contain \'_\'.\n    # So we replace the dashes here for the DB name.\n    valid_mysql_name = pipeline_name.replace(\'-\', \'_\')\n    # MySQL database name cannot exceed 64 characters.\n    return \'mlmd_{}\'.format(valid_mysql_name[-59:])\n\n  def setUp(self):\n    super(BaseKubeflowTest, self).setUp()\n    self._old_cwd = os.getcwd()\n    self._test_dir = tempfile.mkdtemp()\n    os.chdir(self._test_dir)\n\n    self._test_output_dir = \'gs://{}/test_output\'.format(self._BUCKET_NAME)\n\n    test_id = test_utils.random_id()\n\n    self._testdata_root = \'gs://{}/test_data/{}\'.format(self._BUCKET_NAME,\n                                                        test_id)\n    subprocess.run(\n        [\'gsutil\', \'cp\', \'-r\', self._TEST_DATA_ROOT, self._testdata_root],\n        check=True,\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL,\n    )\n\n    self._data_root = os.path.join(self._testdata_root, \'external\', \'csv\')\n    self._transform_module = os.path.join(self._MODULE_ROOT,\n                                          \'transform_module.py\')\n    self._trainer_module = os.path.join(self._MODULE_ROOT, \'trainer_module.py\')\n\n    self.addCleanup(self._delete_test_dir, test_id)\n\n  def tearDown(self):\n    super(BaseKubeflowTest, self).tearDown()\n    os.chdir(self._old_cwd)\n    shutil.rmtree(self._test_dir)\n\n  def _delete_test_dir(self, test_id: Text):\n    """"""Deletes files for this test including the module file and data files.\n\n    Args:\n      test_id: Randomly generated id of the test.\n    """"""\n    test_utils.delete_gcs_files(self._GCP_PROJECT_ID, self._BUCKET_NAME,\n                                \'test_data/{}\'.format(test_id))\n\n  def _delete_workflow(self, workflow_name: Text):\n    """"""Deletes the specified Argo workflow.""""""\n    absl.logging.info(\'Deleting workflow {}\'.format(workflow_name))\n    subprocess.run([\'argo\', \'--namespace\', \'kubeflow\', \'delete\', workflow_name],\n                   check=True)\n\n  def _run_workflow(self,\n                    workflow_file: Text,\n                    workflow_name: Text,\n                    parameter: Dict[Text, Text] = None):\n    """"""Runs the specified workflow with Argo.\n\n    Blocks until the workflow has run (successfully or not) to completion.\n\n    Args:\n      workflow_file: YAML file with Argo workflow spec for the pipeline.\n      workflow_name: Name to use for the workflow.\n      parameter: mapping from pipeline parameter name to its runtime value.\n    """"""\n\n    # TODO(ajaygopinathan): Consider using KFP cli instead.\n    def _format_parameter(parameter: Dict[Text, Any]) -> List[Text]:\n      """"""Format the pipeline parameter section of argo workflow.""""""\n      if parameter:\n        result = []\n        for k, v in parameter.items():\n          result.append(\'-p\')\n          result.append(\'%s=%s\' % (k, v))\n        return result\n      else:\n        return []\n\n    run_command = [\n        \'argo\',\n        \'submit\',\n        \'--name\',\n        workflow_name,\n        \'--namespace\',\n        \'kubeflow\',\n        \'--serviceaccount\',\n        \'pipeline-runner\',\n        workflow_file,\n    ]\n    run_command += _format_parameter(parameter)\n    absl.logging.info(\'Launching workflow {} with parameter {}\'.format(\n        workflow_name, _format_parameter(parameter)))\n    with test_utils.Timer(\'RunningPipelineToCompletion\'):\n      subprocess.run(run_command, check=True)\n      # Wait in the loop while pipeline is running.\n      status = \'Running\'\n      while status == \'Running\':\n        time.sleep(self._POLLING_INTERVAL_IN_SECONDS)\n        status = self._get_argo_pipeline_status(workflow_name)\n\n  def _delete_pipeline_output(self, pipeline_name: Text):\n    """"""Deletes output produced by the named pipeline.\n\n    Args:\n      pipeline_name: The name of the pipeline.\n    """"""\n    test_utils.delete_gcs_files(self._GCP_PROJECT_ID, self._BUCKET_NAME,\n                                \'test_output/{}\'.format(pipeline_name))\n\n  def _delete_pipeline_metadata(self, pipeline_name: Text):\n    """"""Drops the database containing metadata produced by the pipeline.\n\n    Args:\n      pipeline_name: The name of the pipeline owning the database.\n    """"""\n    pod_name = self._get_mysql_pod_name()\n    db_name = self._get_mlmd_db_name(pipeline_name)\n\n    command = [\n        \'kubectl\',\n        \'-n\',\n        \'kubeflow\',\n        \'exec\',\n        \'-it\',\n        pod_name,\n        \'--\',\n        \'mysql\',\n        \'--user\',\n        \'root\',\n        \'--execute\',\n        \'drop database if exists {};\'.format(db_name),\n    ]\n    absl.logging.info(\'Dropping MLMD DB with name: {}\'.format(db_name))\n\n    with test_utils.Timer(\'DeletingMLMDDatabase\'):\n      subprocess.run(command, check=True)\n\n  def _pipeline_root(self, pipeline_name: Text):\n    return os.path.join(self._test_output_dir, pipeline_name)\n\n  def _create_pipeline(self, pipeline_name: Text,\n                       components: List[BaseComponent]):\n    """"""Creates a pipeline given name and list of components.""""""\n    return tfx_pipeline.Pipeline(\n        pipeline_name=pipeline_name,\n        pipeline_root=self._pipeline_root(pipeline_name),\n        components=components,\n        enable_cache=True,\n    )\n\n  def _create_dataflow_pipeline(self, pipeline_name: Text,\n                                components: List[BaseComponent]):\n    """"""Creates a pipeline with Beam DataflowRunner.""""""\n    pipeline = self._create_pipeline(pipeline_name, components)\n    pipeline.beam_pipeline_args = [\n        \'--runner=DataflowRunner\',\n        \'--project=\' + self._GCP_PROJECT_ID,\n        \'--temp_location=\' +\n        os.path.join(self._pipeline_root(pipeline_name), \'tmp\'),\n        \'--region=\' + self._GCP_REGION,\n    ]\n    return pipeline\n\n  def _get_kubeflow_metadata_config(\n      self) -> kubeflow_pb2.KubeflowMetadataConfig:\n    config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n    return config\n\n  def _get_argo_pipeline_status(self, workflow_name: Text) -> Text:\n    """"""Get Pipeline status.\n\n    Args:\n      workflow_name: The name of the workflow.\n\n    Returns:\n      Simple status string which is returned from `argo get` command.\n    """"""\n    get_workflow_command = [\n        \'argo\', \'--namespace\', \'kubeflow\', \'get\', workflow_name\n    ]\n    output = subprocess.check_output(get_workflow_command).decode(\'utf-8\')\n    absl.logging.info(\'Argo output ----\\n%s\', output)\n    match = re.search(r\'^Status:\\s+(.+)$\', output, flags=re.MULTILINE)\n    self.assertIsNotNone(match)\n    return match.group(1)\n\n  def _compile_and_run_pipeline(self,\n                                pipeline: tfx_pipeline.Pipeline,\n                                workflow_name: Text = None,\n                                parameters: Dict[Text, Any] = None):\n    """"""Compiles and runs a KFP pipeline.\n\n    Args:\n      pipeline: The logical pipeline to run.\n      workflow_name: The argo workflow name, default to pipeline name.\n      parameters: Value of runtime paramters of the pipeline.\n    """"""\n    pipeline_name = pipeline.pipeline_info.pipeline_name\n    config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n        kubeflow_metadata_config=self._get_kubeflow_metadata_config(),\n        tfx_image=self._CONTAINER_IMAGE)\n    kubeflow_dag_runner.KubeflowDagRunner(config=config).run(pipeline)\n\n    file_path = os.path.join(self._test_dir, \'{}.tar.gz\'.format(pipeline_name))\n    self.assertTrue(tf.io.gfile.exists(file_path))\n    tarfile.TarFile.open(file_path).extract(\'pipeline.yaml\')\n    pipeline_file = os.path.join(self._test_dir, \'pipeline.yaml\')\n    self.assertIsNotNone(pipeline_file)\n\n    workflow_name = workflow_name or pipeline_name\n    # Ensure cleanup regardless of whether pipeline succeeds or fails.\n    self.addCleanup(self._delete_workflow, workflow_name)\n    self.addCleanup(self._delete_pipeline_metadata, pipeline_name)\n    self.addCleanup(self._delete_pipeline_output, pipeline_name)\n\n    # Run the pipeline to completion.\n    self._run_workflow(pipeline_file, workflow_name, parameters)\n\n    # Obtain workflow logs.\n    get_logs_command = [\n        \'argo\', \'--namespace\', \'kubeflow\', \'logs\', \'-w\', workflow_name\n    ]\n    logs_output = subprocess.check_output(get_logs_command).decode(\'utf-8\')\n\n    # Check if pipeline completed successfully.\n    status = self._get_argo_pipeline_status(workflow_name)\n    self.assertEqual(\n        \'Succeeded\', status, \'Pipeline {} failed to complete successfully: {}\'\n        \'\\nFailed workflow logs:\\n{}\'.format(pipeline_name, status,\n                                             logs_output))\n'"
tfx/orchestration/kubeflow/utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common utility for Kubeflow-based orchestrator.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nfrom typing import Text\n# utils.py should not be used in container_entrypoint.py because of its\n# dependency on KFP.\nfrom kfp import dsl\n\nfrom tfx.orchestration import data_types\nfrom tfx.utils import json_utils\n\n\ndef replace_placeholder(serialized_component: Text) -> Text:\n  """"""Replaces the RuntimeParameter placeholders with kfp.dsl.PipelineParam.""""""\n  placeholders = re.findall(data_types.RUNTIME_PARAMETER_PATTERN,\n                            serialized_component)\n\n  for placeholder in placeholders:\n    # We need to keep the level of escaping of original RuntimeParameter\n    # placeholder. This can be done by probing the pair of quotes around\n    # literal \'RuntimeParameter\'.\n    placeholder = fix_brackets(placeholder)\n    cleaned_placeholder = placeholder.replace(\'\\\\\', \'\')  # Clean escapes.\n    parameter = json_utils.loads(cleaned_placeholder)\n    dsl_parameter_str = str(dsl.PipelineParam(name=parameter.name))\n\n    serialized_component = serialized_component.replace(placeholder,\n                                                        dsl_parameter_str)\n\n  return serialized_component\n\n\ndef fix_brackets(placeholder: Text) -> Text:\n  """"""Fix the imbalanced brackets in placeholder.\n\n  When ptype is not null, regex matching might grab a placeholder with }\n  missing. This function fix the missing bracket.\n\n  Args:\n    placeholder: string placeholder of RuntimeParameter\n\n  Returns:\n    Placeholder with re-balanced brackets.\n\n  Raises:\n    RuntimeError: if left brackets are less than right brackets.\n  """"""\n  lcount = placeholder.count(\'{\')\n  rcount = placeholder.count(\'}\')\n  if lcount < rcount:\n    raise RuntimeError(\n        \'Unexpected redundant left brackets found in {}\'.format(placeholder))\n  else:\n    patch = \'\'.join([\'}\'] * (lcount - rcount))\n    return placeholder + patch\n'"
tfx/orchestration/launcher/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/launcher/base_component_launcher.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""For component execution, includes driver, executor and publisher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Any, Dict, List, Optional, Text\n\nimport absl\nfrom six import with_metaclass\n\nfrom tfx import types\nfrom tfx.components.base import base_node\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.config import base_component_config\n\n\nclass BaseComponentLauncher(with_metaclass(abc.ABCMeta, object)):\n  """"""Responsible for launching driver, executor and publisher of component.""""""\n\n  def __init__(\n      self,\n      component: base_node.BaseNode,\n      pipeline_info: data_types.PipelineInfo,\n      driver_args: data_types.DriverArgs,\n      metadata_connection: metadata.Metadata,\n      beam_pipeline_args: List[Text],\n      additional_pipeline_args: Dict[Text, Any],\n      component_config: Optional[\n          base_component_config.BaseComponentConfig] = None,\n  ):\n    """"""Initialize a BaseComponentLauncher.\n\n    Args:\n      component: The Tfx node to launch.\n      pipeline_info: An instance of data_types.PipelineInfo that holds pipeline\n        properties.\n      driver_args: An instance of data_types.DriverArgs that holds component\n        specific driver args.\n      metadata_connection: ML metadata connection. The connection is expected to\n        not be opened when given to this object.\n      beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n      additional_pipeline_args: Additional pipeline args.\n      component_config: Optional component specific config to instrument\n        launcher on how to launch a component.\n\n    Raises:\n      ValueError: when component and component_config are not launchable by the\n      launcher.\n    """"""\n    self._pipeline_info = pipeline_info\n    self._component_info = data_types.ComponentInfo(\n        component_type=component.type,\n        component_id=component.id,\n        pipeline_info=self._pipeline_info)\n    self._driver_args = driver_args\n\n    self._driver_class = component.driver_class\n    self._component_executor_spec = component.executor_spec\n\n    self._input_dict = component.inputs.get_all()\n    self._output_dict = component.outputs.get_all()\n    self._exec_properties = component.exec_properties\n\n    self._metadata_connection = metadata_connection\n    self._beam_pipeline_args = beam_pipeline_args\n\n    self._additional_pipeline_args = additional_pipeline_args\n    self._component_config = component_config\n\n    if not self.can_launch(self._component_executor_spec,\n                           self._component_config):\n      raise ValueError(\n          \'component.executor_spec with type ""%s"" and component config with\'\n          \' type ""%s"" are not launchable by ""%s"".\' % (\n              type(self._component_executor_spec).__name__,\n              type(self._component_config).__name__,\n              type(self).__name__,\n          ))\n\n  @classmethod\n  def create(\n      cls,\n      component: base_node.BaseNode,\n      pipeline_info: data_types.PipelineInfo,\n      driver_args: data_types.DriverArgs,\n      metadata_connection: metadata.Metadata,\n      beam_pipeline_args: List[Text],\n      additional_pipeline_args: Dict[Text, Any],\n      component_config: Optional[\n          base_component_config.BaseComponentConfig] = None,\n  ) -> \'BaseComponentLauncher\':\n    """"""Initialize a ComponentLauncher directly from a BaseComponent instance.\n\n    This class method is the contract between `TfxRunner` and\n    `BaseComponentLauncher` to support launcher polymorphism. Sublcass of this\n    class must make sure it can be initialized by the method.\n\n    Args:\n      component: The component to launch.\n      pipeline_info: An instance of data_types.PipelineInfo that holds pipeline\n        properties.\n      driver_args: An instance of data_types.DriverArgs that holds component\n        specific driver args.\n      metadata_connection: ML metadata connection. The connection is expected to\n        not be opened when given to this object.\n      beam_pipeline_args: Beam pipeline args for beam jobs within executor.\n      additional_pipeline_args: Additional pipeline args.\n      component_config: Optional component specific config to instrument\n        launcher on how to launch a component.\n\n    Returns:\n      A new instance of component launcher.\n    """"""\n    return cls(\n        component=component,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=beam_pipeline_args,\n        additional_pipeline_args=additional_pipeline_args,\n        component_config=component_config)\n\n  @classmethod\n  @abc.abstractmethod\n  def can_launch(\n      cls, component_executor_spec: executor_spec.ExecutorSpec,\n      component_config: base_component_config.BaseComponentConfig) -> bool:\n    """"""Checks if the launcher can launch the executor spec with an optional component config.""""""\n    raise NotImplementedError\n\n  def _run_driver(\n      self, input_dict: Dict[Text,\n                             types.Channel], output_dict: Dict[Text,\n                                                               types.Channel],\n      exec_properties: Dict[Text, Any]) -> data_types.ExecutionDecision:\n    """"""Prepare inputs, outputs and execution properties for actual execution.""""""\n\n    with self._metadata_connection as m:\n      driver = self._driver_class(metadata_handler=m)\n\n      execution_decision = driver.pre_execution(\n          input_dict=input_dict,\n          output_dict=output_dict,\n          exec_properties=exec_properties,\n          driver_args=self._driver_args,\n          pipeline_info=self._pipeline_info,\n          component_info=self._component_info)\n\n      return execution_decision\n\n  @abc.abstractmethod\n  # TODO(jyzhao): consider returning an execution result.\n  def _run_executor(self, execution_id: int,\n                    input_dict: Dict[Text, List[types.Artifact]],\n                    output_dict: Dict[Text, List[types.Artifact]],\n                    exec_properties: Dict[Text, Any]) -> None:\n    """"""Execute underlying component implementation.""""""\n    raise NotImplementedError\n\n  def _run_publisher(self, output_dict: Dict[Text,\n                                             List[types.Artifact]]) -> None:\n    """"""Publish execution result to ml metadata.""""""\n\n    with self._metadata_connection as m:\n      p = publisher.Publisher(metadata_handler=m)\n      p.publish_execution(\n          component_info=self._component_info, output_artifacts=output_dict)\n\n  def launch(self) -> data_types.ExecutionInfo:\n    """"""Execute the component, includes driver, executor and publisher.\n\n    Returns:\n      The execution decision of the launch.\n    """"""\n    absl.logging.info(\'Running driver for %s\',\n                      self._component_info.component_id)\n    execution_decision = self._run_driver(self._input_dict, self._output_dict,\n                                          self._exec_properties)\n\n    if not execution_decision.use_cached_results:\n      absl.logging.info(\'Running executor for %s\',\n                        self._component_info.component_id)\n      self._run_executor(execution_decision.execution_id,\n                         execution_decision.input_dict,\n                         execution_decision.output_dict,\n                         execution_decision.exec_properties)\n\n    absl.logging.info(\'Running publisher for %s\',\n                      self._component_info.component_id)\n    self._run_publisher(output_dict=execution_decision.output_dict)\n\n    return data_types.ExecutionInfo(\n        input_dict=execution_decision.input_dict,\n        output_dict=execution_decision.output_dict,\n        exec_properties=execution_decision.exec_properties,\n        execution_id=execution_decision.execution_id)\n'"
tfx/orchestration/launcher/base_component_launcher_test.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.component_launcher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport mock\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.orchestration.launcher import test_utils\nfrom tfx.types import channel_utils\n\n\nclass ComponentRunnerTest(tf.test.TestCase):\n\n  @mock.patch.object(publisher, \'Publisher\')\n  def testRun(self, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n\n    test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.sqlite.SetInParent()\n    metadata_connection = metadata.Metadata(connection_config)\n\n    pipeline_root = os.path.join(test_dir, \'Test\')\n    input_path = os.path.join(test_dir, \'input\')\n    tf.io.gfile.makedirs(os.path.dirname(input_path))\n    file_io.write_string_to_file(input_path, \'test\')\n\n    input_artifact = test_utils._InputArtifact()\n    input_artifact.uri = input_path\n\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]))\n\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'Test\', pipeline_root=pipeline_root, run_id=\'123\')\n\n    driver_args = data_types.DriverArgs(enable_cache=True)\n\n    # We use InProcessComponentLauncher to test BaseComponentLauncher logics.\n    launcher = in_process_component_launcher.InProcessComponentLauncher.create(\n        component=component,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=[],\n        additional_pipeline_args={})\n    self.assertEqual(\n        launcher._component_info.component_type, \'.\'.join([\n            test_utils._FakeComponent.__module__,\n            test_utils._FakeComponent.__name__\n        ]))\n    launcher.launch()\n\n    output_path = component.outputs[\'output\'].get()[0].uri\n    self.assertTrue(tf.io.gfile.exists(output_path))\n    contents = file_io.read_file_to_string(output_path)\n    self.assertEqual(\'test\', contents)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/launcher/container_common.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common code shared by container based launchers.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text, Union\n\nimport jinja2\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental import executor_specs\nfrom tfx.dsl.component.experimental import placeholders\n\n\ndef resolve_container_template(\n    container_spec_tmpl: Union[executor_spec.ExecutorContainerSpec,\n                               executor_specs.TemplatedExecutorContainerSpec],\n    input_dict: Dict[Text, List[types.Artifact]],\n    output_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any]) -> executor_spec.ExecutorContainerSpec:\n  """"""Resolves Jinja2 template languages from an executor container spec.\n\n  Args:\n    container_spec_tmpl: the container spec template to be resolved.\n    input_dict: Dictionary of input artifacts consumed by this component.\n    output_dict: Dictionary of output artifacts produced by this component.\n    exec_properties: Dictionary of execution properties.\n\n  Returns:\n    A resolved container spec.\n  """"""\n  context = {\n      \'input_dict\': input_dict,\n      \'output_dict\': output_dict,\n      \'exec_properties\': exec_properties,\n  }\n  if isinstance(container_spec_tmpl,\n                executor_specs.TemplatedExecutorContainerSpec):\n    return executor_spec.ExecutorContainerSpec(\n        image=container_spec_tmpl.image,\n        command=resolve_container_command_line(\n            container_spec=container_spec_tmpl,\n            input_dict=input_dict,\n            output_dict=output_dict,\n            exec_properties=exec_properties,\n        ),\n    )\n  return executor_spec.ExecutorContainerSpec(\n      image=_render_text(container_spec_tmpl.image, context),\n      command=_render_items(container_spec_tmpl.command, context),\n      args=_render_items(container_spec_tmpl.args, context))\n\n\ndef _render_items(items: List[Text], context: Dict[Text, Any]) -> List[Text]:\n  if not items:\n    return items\n\n  return [_render_text(item, context) for item in items]\n\n\ndef _render_text(text: Text, context: Dict[Text, Any]) -> Text:\n  return jinja2.Template(text).render(context)\n\n\ndef resolve_container_command_line(\n    container_spec: executor_specs.TemplatedExecutorContainerSpec,\n    input_dict: Dict[Text, List[types.Artifact]],\n    output_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any],\n) -> List[Text]:\n  """"""Resolves placeholders in the command line of a container.\n\n  Args:\n    container_spec: ContainerSpec to resolve\n    input_dict: Dictionary of input artifacts consumed by this component.\n    output_dict: Dictionary of output artifacts produced by this component.\n    exec_properties: Dictionary of execution properties.\n\n  Returns:\n    Resolved command line.\n  """"""\n\n  def expand_command_line_arg(\n      cmd_arg: executor_specs.CommandlineArgumentType,\n  ) -> Text:\n    """"""Resolves a single argument.""""""\n    if isinstance(cmd_arg, str):\n      return cmd_arg\n    elif isinstance(cmd_arg, placeholders.InputValuePlaceholder):\n      return exec_properties[cmd_arg.input_name]\n    elif isinstance(cmd_arg, placeholders.InputUriPlaceholder):\n      return input_dict[cmd_arg.input_name][0].uri\n    elif isinstance(cmd_arg, placeholders.OutputUriPlaceholder):\n      return output_dict[cmd_arg.output_name][0].uri\n    else:\n      raise TypeError(\n          (\'Unsupported type of command-line arguments: ""{}"".\'\n           \' Supported types are {}.\')\n          .format(type(cmd_arg), str(executor_specs.CommandlineArgumentType)))\n\n  resolved_command_line = []\n  for cmd_arg in (container_spec.command or []):\n    resolved_cmd_arg = expand_command_line_arg(cmd_arg)\n    if not isinstance(resolved_cmd_arg, (str, Text)):\n      raise TypeError(\n          \'Resolved argument ""{}"" (type=""{}"") is not a string.\'.format(\n              resolved_cmd_arg, type(resolved_cmd_arg)))\n    resolved_command_line.append(resolved_cmd_arg)\n\n  return resolved_command_line\n\n\ndef to_swagger_dict(config: Any) -> Any:\n  """"""Converts a config object to a swagger API dict.\n\n  This utility method recursively converts swagger code generated configs into\n  a valid swagger dictionary. This method is trying to workaround a bug\n  (https://github.com/swagger-api/swagger-codegen/issues/8948)\n  from swagger generated code\n\n  Args:\n    config: The config object. It can be one of List, Dict or a Swagger code\n      generated object, which has a `attribute_map` attribute.\n\n  Returns:\n    The original object with all Swagger generated object replaced with\n    dictionary object.\n  """"""\n  if isinstance(config, list):\n    return [to_swagger_dict(x) for x in config]\n  if hasattr(config, \'attribute_map\'):\n    return {\n        swagger_name: to_swagger_dict(getattr(config, key))\n        for (key, swagger_name) in config.attribute_map.items()\n        if getattr(config, key)\n    }\n  if isinstance(config, dict):\n    return {key: to_swagger_dict(value) for key, value in config.items()}\n  return config\n'"
tfx/orchestration/launcher/container_common_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.launcher.container_common.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom kubernetes import client\nimport tensorflow as tf\n\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration.launcher import container_common\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import standard_artifacts\n\n\nclass ContainerUtilsTest(tf.test.TestCase):\n\n  def testResolveContainerTemplate(self):\n    container_spec = executor_spec.ExecutorContainerSpec(\n        image=\'gcr.io/my/trainer:{{exec_properties.version}}\',\n        command=[\'{{exec_properties.model}}_trainer\'],\n        args=[\n            \'--steps\',\n            \'{{exec_properties.train_args.num_steps}}\',\n            \'--examples\',\n            \'{{input_dict[""examples""]|join("","",attribute=""uri"")}}\',\n            \'--model-path\',\n            \'{{output_dict[""model""][0].uri}}\',\n        ])\n    examples_artifact_1 = standard_artifacts.Examples()\n    examples_artifact_1.uri = \'gcs://examples/1\'\n    examples_artifact_2 = standard_artifacts.Examples()\n    examples_artifact_2.uri = \'gcs://examples/2\'\n    model = standard_artifacts.Model()\n    model.uri = \'gcs://model\'\n    input_dict = {\'examples\': [examples_artifact_1, examples_artifact_2]}\n    output_dict = {\'model\': [model]}\n    exec_properties = {\n        \'version\': \'v1\',\n        \'model\': \'cnn\',\n        \'train_args\': trainer_pb2.TrainArgs(num_steps=10000),\n    }\n\n    actual_spec = container_common.resolve_container_template(\n        container_spec, input_dict, output_dict, exec_properties)\n\n    self.assertEqual(\'gcr.io/my/trainer:v1\', actual_spec.image)\n    self.assertListEqual([\'cnn_trainer\'], actual_spec.command)\n    self.assertListEqual([\n        \'--steps\',\n        \'10000\',\n        \'--examples\',\n        \'gcs://examples/1,gcs://examples/2\',\n        \'--model-path\',\n        \'gcs://model\',\n    ], actual_spec.args)\n\n  def testToSwaggerDict(self):\n    pod = client.V1Pod(\n        metadata=client.V1ObjectMeta(owner_references=[\n            client.V1OwnerReference(\n                api_version=\'argoproj.io/v1alpha1\',\n                kind=\'Workflow\',\n                name=\'wf-1\',\n                uid=\'wf-uid-1\')\n        ]),\n        spec=client.V1PodSpec(containers=[], service_account=\'sa-1\'))\n\n    pod_dict = container_common.to_swagger_dict(pod)\n\n    self.assertDictEqual(\n        {\n            \'metadata\': {\n                \'ownerReferences\': [{\n                    \'apiVersion\': \'argoproj.io/v1alpha1\',\n                    \'kind\': \'Workflow\',\n                    \'name\': \'wf-1\',\n                    \'uid\': \'wf-uid-1\'\n                }]\n            },\n            \'spec\': {\n                \'serviceAccount\': \'sa-1\'\n            }\n        }, pod_dict)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/launcher/docker_component_launcher.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Docker component launcher which launches a container in docker environment .""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text, cast\n\nimport absl\nimport docker\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental import executor_specs\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.config import docker_component_config\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.orchestration.launcher import container_common\n\n\nclass DockerComponentLauncher(base_component_launcher.BaseComponentLauncher):\n  """"""Responsible for launching a container executor.""""""\n\n  @classmethod\n  def can_launch(\n      cls, component_executor_spec: executor_spec.ExecutorSpec,\n      component_config: base_component_config.BaseComponentConfig) -> bool:\n    """"""Checks if the launcher can launch the executor spec.""""""\n    if component_config and not isinstance(\n        component_config, docker_component_config.DockerComponentConfig):\n      return False\n\n    return isinstance(component_executor_spec,\n                      (executor_spec.ExecutorContainerSpec,\n                       executor_specs.TemplatedExecutorContainerSpec))\n\n  def _run_executor(self, execution_id: int,\n                    input_dict: Dict[Text, List[types.Artifact]],\n                    output_dict: Dict[Text, List[types.Artifact]],\n                    exec_properties: Dict[Text, Any]) -> None:\n    """"""Execute underlying component implementation.""""""\n\n    executor_container_spec = cast(executor_spec.ExecutorContainerSpec,\n                                   self._component_executor_spec)\n    if self._component_config:\n      docker_config = cast(docker_component_config.DockerComponentConfig,\n                           self._component_config)\n    else:\n      docker_config = docker_component_config.DockerComponentConfig()\n\n    # Replace container spec with jinja2 template.\n    executor_container_spec = container_common.resolve_container_template(\n        executor_container_spec, input_dict, output_dict, exec_properties)\n\n    absl.logging.info(\'Container spec: %s\' % vars(executor_container_spec))\n    absl.logging.info(\'Docker config: %s\' % vars(docker_config))\n\n    # Call client.containers.run and wait for completion.\n    # ExecutorContainerSpec follows k8s container spec which has different\n    # names to Docker\'s container spec. It\'s intended to set command to docker\'s\n    # entrypoint and args to docker\'s command.\n    if docker_config.docker_server_url:\n      client = docker.DockerClient(base_url=docker_config.docker_server_url)\n    else:\n      client = docker.from_env()\n\n    run_args = docker_config.to_run_args()\n    container = client.containers.run(\n        image=executor_container_spec.image,\n        entrypoint=executor_container_spec.command,\n        command=executor_container_spec.args,\n        detach=True,\n        **run_args)\n\n    # Streaming logs\n    for log in container.logs(stream=True):\n      absl.logging.info(\'Docker: \' + log.decode(\'utf-8\'))\n    exit_code = container.wait()[\'StatusCode\']\n    if exit_code != 0:\n      raise RuntimeError(\n          \'Container exited with error code ""{}""\'.format(exit_code))\n    # TODO(b/141192583): Report data to publisher\n    # - report container digest\n    # - report replaced command line entrypoints\n    # - report docker run args\n'"
tfx/orchestration/launcher/docker_component_launcher_e2e_test.py,2,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.orchestration.launcher.docker_component_launcher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam import beam_dag_runner\nfrom tfx.orchestration.config import docker_component_config\nfrom tfx.orchestration.config import pipeline_config\nfrom tfx.orchestration.launcher import docker_component_launcher\nfrom tfx.types import component_spec\n\n\nclass _HelloWorldSpec(component_spec.ComponentSpec):\n  INPUTS = {}\n  OUTPUTS = {}\n  PARAMETERS = {\n      \'name\': component_spec.ExecutionParameter(type=str),\n  }\n\n\nclass _HelloWorldComponent(base_component.BaseComponent):\n\n  SPEC_CLASS = _HelloWorldSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorContainerSpec(\n      # TODO(b/143965964): move the image to private repo if the test is flaky\n      # due to docker hub.\n      image=\'alpine:latest\',\n      command=[\'echo\'],\n      args=[\'hello {{exec_properties.name}}\'])\n\n  def __init__(self, name):\n    super(_HelloWorldComponent, self).__init__(_HelloWorldSpec(name=name))\n\n\n# TODO(hongyes): Add more complicated samples to pass inputs/outputs between\n# containers.\ndef _create_pipeline(\n    pipeline_name,\n    pipeline_root,\n    metadata_path,\n    name,\n):\n  hello_world = _HelloWorldComponent(name=name)\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[hello_world],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      additional_pipeline_args={},\n  )\n\n\nclass DockerComponentLauncherE2eTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(DockerComponentLauncherE2eTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'docker_e2e_test\'\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def testDockerComponentLauncherInBeam(self):\n\n    beam_dag_runner.BeamDagRunner(\n        config=pipeline_config.PipelineConfig(\n            supported_launcher_classes=[\n                docker_component_launcher.DockerComponentLauncher\n            ],\n            default_component_configs=[\n                docker_component_config.DockerComponentConfig()\n            ])).run(\n                _create_pipeline(\n                    pipeline_name=self._pipeline_name,\n                    pipeline_root=self._pipeline_root,\n                    metadata_path=self._metadata_path,\n                    name=\'docker_e2e_test_in_beam\'))\n\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      self.assertEqual(1, len(m.store.get_executions()))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/launcher/docker_component_launcher_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.launcher.docker_component_launcher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport docker\nimport mock\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.config import docker_component_config\nfrom tfx.orchestration.launcher import docker_component_launcher\nfrom tfx.orchestration.launcher import test_utils\nfrom tfx.types import channel_utils\n\n\n# TODO(hongyes): add e2e testing to cover docker launcher in beam/airflow.\nclass DockerComponentLauncherTest(tf.test.TestCase):\n\n  def testCanLaunch(self):\n    self.assertTrue(\n        docker_component_launcher.DockerComponentLauncher.can_launch(\n            executor_spec.ExecutorContainerSpec(image=\'test\'),\n            component_config=None))\n    self.assertFalse(\n        docker_component_launcher.DockerComponentLauncher.can_launch(\n            executor_spec.ExecutorClassSpec(base_executor.BaseExecutor),\n            component_config=None))\n\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(docker, \'from_env\', autospec=True)\n  def testLaunchSucceedsWithoutConfig(self, mock_docker_client, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    mock_run = mock_docker_client.return_value.containers.run\n    mock_run.return_value.logs.return_value = []\n    mock_run.return_value.wait.return_value = {\'StatusCode\': 0}\n    context = self._create_launcher_context()\n\n    context[\'launcher\'].launch()\n\n    mock_run.assert_called_once()\n    _, mock_kwargs = mock_run.call_args\n    self.assertEqual(\'gcr://test\', mock_kwargs[\'image\'])\n    self.assertListEqual([context[\'input_artifact\'].uri],\n                         mock_kwargs[\'command\'])\n\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(docker, \'DockerClient\', autospec=True)\n  def testLaunchSucceedsWithConfig(self, mock_docker_client, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    mock_run = mock_docker_client.return_value.containers.run\n    mock_run.return_value.logs.return_value = []\n    mock_run.return_value.wait.return_value = {\'StatusCode\': 0}\n    docker_config = docker_component_config.DockerComponentConfig(\n        docker_server_url=\'http://mock.docker.server\',\n        environment={\'name\': \'value\'},\n        privileged=True,\n        volumes=[\'/local/etc:/local/etc\'],\n        ports={\'2222/tcp\': 3333})\n    context = self._create_launcher_context(docker_config)\n\n    context[\'launcher\'].launch()\n\n    mock_run.assert_called_once()\n    _, mock_kwargs = mock_run.call_args\n    self.assertEqual(\'gcr://test\', mock_kwargs[\'image\'])\n    self.assertListEqual([context[\'input_artifact\'].uri],\n                         mock_kwargs[\'command\'])\n    mock_docker_client.assert_called_with(base_url=\'http://mock.docker.server\')\n    self.assertDictEqual({\'name\': \'value\'}, mock_kwargs[\'environment\'])\n    self.assertTrue(mock_kwargs[\'privileged\'])\n    self.assertListEqual([\'/local/etc:/local/etc\'], mock_kwargs[\'volumes\'])\n    self.assertDictEqual({\'2222/tcp\': 3333}, mock_kwargs[\'ports\'])\n\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(docker, \'from_env\', autospec=True)\n  def testLaunchWithErrorCode(self, mock_docker_client, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    mock_run = mock_docker_client.return_value.containers.run\n    mock_run.return_value.logs.return_value = []\n    mock_run.return_value.wait.return_value = {\'StatusCode\': 1}\n    launcher = self._create_launcher_context()[\'launcher\']\n\n    with self.assertRaises(RuntimeError):\n      launcher.launch()\n\n  def _create_launcher_context(self, component_config=None):\n    test_dir = self.get_temp_dir()\n\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.sqlite.SetInParent()\n    metadata_connection = metadata.Metadata(connection_config)\n\n    pipeline_root = os.path.join(test_dir, \'Test\')\n\n    input_artifact = test_utils._InputArtifact()\n    input_artifact.uri = os.path.join(test_dir, \'input\')\n\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]),\n        custom_executor_spec=executor_spec.ExecutorContainerSpec(\n            image=\'gcr://test\', args=[\'{{input_dict[""input""][0].uri}}\']))\n\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'Test\', pipeline_root=pipeline_root, run_id=\'123\')\n\n    driver_args = data_types.DriverArgs(enable_cache=True)\n\n    launcher = docker_component_launcher.DockerComponentLauncher.create(\n        component=component,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=[],\n        additional_pipeline_args={},\n        component_config=component_config)\n\n    return {\'launcher\': launcher, \'input_artifact\': input_artifact}\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/launcher/in_process_component_launcher.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""In process component launcher which launches python executors in process.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom typing import Any, Dict, List, Text, cast\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.launcher import base_component_launcher\n\n\nclass InProcessComponentLauncher(base_component_launcher.BaseComponentLauncher):\n  """"""Responsible for launching a python executor.\n\n  The executor will be launched in the same process of the rest of the\n  component, i.e. its driver and publisher.\n  """"""\n\n  @classmethod\n  def can_launch(\n      cls, component_executor_spec: executor_spec.ExecutorSpec,\n      component_config: base_component_config.BaseComponentConfig) -> bool:\n    """"""Checks if the launcher can launch the executor spec.""""""\n    if component_config:\n      return False\n\n    return isinstance(component_executor_spec, executor_spec.ExecutorClassSpec)\n\n  def _run_executor(self, execution_id: int,\n                    input_dict: Dict[Text, List[types.Artifact]],\n                    output_dict: Dict[Text, List[types.Artifact]],\n                    exec_properties: Dict[Text, Any]) -> None:\n    """"""Execute underlying component implementation.""""""\n    executor_context = base_executor.BaseExecutor.Context(\n        beam_pipeline_args=self._beam_pipeline_args,\n        tmp_dir=os.path.join(self._pipeline_info.pipeline_root, \'.temp\', \'\'),\n        unique_id=str(execution_id))\n\n    executor_class_spec = cast(executor_spec.ExecutorClassSpec,\n                               self._component_executor_spec)\n\n    # Type hint of component will cause not-instantiable error as\n    # component.executor is Type[BaseExecutor] which has an abstract function.\n    executor = executor_class_spec.executor_class(\n        executor_context)  # type: ignore\n\n    executor.Do(input_dict, output_dict, exec_properties)\n'"
tfx/orchestration/launcher/kubernetes_component_launcher.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Docker component launcher which launches a container in docker environment .""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport re\nimport time\nfrom typing import Any, Callable, Dict, List, Optional, Text, cast\n\nfrom absl import logging\nfrom kubernetes import client\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental import executor_specs\nfrom tfx.orchestration.config import base_component_config\nfrom tfx.orchestration.config import kubernetes_component_config\nfrom tfx.orchestration.launcher import base_component_launcher\nfrom tfx.orchestration.launcher import container_common\nfrom tfx.utils import kube_utils\n\n\ndef _pod_is_not_pending(resp: client.V1Pod):\n  return resp.status.phase != kube_utils.PodPhase.PENDING.value\n\n\ndef _pod_is_done(resp: client.V1Pod):\n  return kube_utils.PodPhase(resp.status.phase).is_done\n\n\ndef _sanitize_pod_name(pod_name: Text) -> Text:\n  pod_name = re.sub(r\'[^a-z0-9-]\', \'-\', pod_name.lower())\n  pod_name = re.sub(r\'^[-]+\', \'\', pod_name)\n  return re.sub(r\'[-]+\', \'-\', pod_name)\n\n\nclass KubernetesComponentLauncher(base_component_launcher.BaseComponentLauncher\n                                 ):\n  """"""Responsible for launching a container executor on Kubernetes.""""""\n\n  # TODO(hongyes): add container spec into exec_properties for driver to check.\n  @classmethod\n  def can_launch(\n      cls,\n      component_executor_spec: executor_spec.ExecutorSpec,\n      component_config: base_component_config.BaseComponentConfig = None\n  ) -> bool:\n    """"""Checks if the launcher can launch the executor spec.""""""\n    if component_config and not isinstance(\n        component_config,\n        kubernetes_component_config.KubernetesComponentConfig):\n      return False\n\n    return isinstance(component_executor_spec,\n                      (executor_spec.ExecutorContainerSpec,\n                       executor_specs.TemplatedExecutorContainerSpec))\n\n  def _run_executor(self, execution_id: int,\n                    input_dict: Dict[Text, List[types.Artifact]],\n                    output_dict: Dict[Text, List[types.Artifact]],\n                    exec_properties: Dict[Text, Any]) -> None:\n    """"""Execute underlying component implementation.\n\n    Runs executor container in a Kubernetes Pod and wait until it goes into\n    `Succeeded` or `Failed` state.\n\n    Args:\n      execution_id: The ID of the execution.\n      input_dict: Input dict from input key to a list of Artifacts. These are\n        often outputs of another component in the pipeline and passed to the\n        component by the orchestration system.\n      output_dict: Output dict from output key to a list of Artifacts. These are\n        often consumed by a dependent component.\n      exec_properties: A dict of execution properties. These are inputs to\n        pipeline with primitive types (int, string, float) and fully\n        materialized when a pipeline is constructed. No dependency to other\n        component or later injection from orchestration systems is necessary or\n        possible on these values.\n\n    Raises:\n      RuntimeError: when the pod is in `Failed` state or unexpected failure from\n      Kubernetes API.\n\n    """"""\n\n    container_spec = cast(executor_spec.ExecutorContainerSpec,\n                          self._component_executor_spec)\n\n    # Replace container spec with jinja2 template.\n    container_spec = container_common.resolve_container_template(\n        container_spec, input_dict, output_dict, exec_properties)\n    pod_name = self._build_pod_name(execution_id)\n    # TODO(hongyes): replace the default value from component config.\n    try:\n      namespace = kube_utils.get_kfp_namespace()\n    except RuntimeError:\n      namespace = \'kubeflow\'\n\n    pod_manifest = self._build_pod_manifest(pod_name, container_spec)\n    core_api = kube_utils.make_core_v1_api()\n\n    if kube_utils.is_inside_kfp():\n      launcher_pod = kube_utils.get_current_kfp_pod(core_api)\n      pod_manifest[\'spec\'][\'serviceAccount\'] = launcher_pod.spec.service_account\n      pod_manifest[\'spec\'][\n          \'serviceAccountName\'] = launcher_pod.spec.service_account_name\n      pod_manifest[\'metadata\'][\n          \'ownerReferences\'] = container_common.to_swagger_dict(\n              launcher_pod.metadata.owner_references)\n\n    logging.info(\'Looking for pod ""%s:%s"".\', namespace, pod_name)\n    resp = self._get_pod(core_api, pod_name, namespace)\n    if not resp:\n      logging.info(\'Pod ""%s:%s"" does not exist. Creating it...\',\n                   namespace, pod_name)\n      logging.info(\'Pod manifest: %s\', pod_manifest)\n      try:\n        resp = core_api.create_namespaced_pod(\n            namespace=namespace, body=pod_manifest)\n      except client.rest.ApiException as e:\n        raise RuntimeError(\n            \'Failed to created container executor pod!\\nReason: %s\\nBody: %s\' %\n            (e.reason, e.body))\n\n    logging.info(\'Waiting for pod ""%s:%s"" to start.\', namespace, pod_name)\n    self._wait_pod(\n        core_api,\n        pod_name,\n        namespace,\n        exit_condition_lambda=_pod_is_not_pending,\n        condition_description=\'non-pending status\')\n\n    logging.info(\'Start log streaming for pod ""%s:%s"".\', namespace, pod_name)\n    try:\n      logs = core_api.read_namespaced_pod_log(\n          name=pod_name,\n          namespace=namespace,\n          container=kube_utils.ARGO_MAIN_CONTAINER_NAME,\n          follow=True,\n          _preload_content=False).stream()\n    except client.rest.ApiException as e:\n      raise RuntimeError(\n          \'Failed to stream the logs from the pod!\\nReason: %s\\nBody: %s\' %\n          (e.reason, e.body))\n\n    for log in logs:\n      logging.info(log.decode().rstrip(\'\\n\'))\n\n    resp = self._wait_pod(\n        core_api,\n        pod_name,\n        namespace,\n        exit_condition_lambda=_pod_is_done,\n        condition_description=\'done state\')\n\n    if resp.status.phase == kube_utils.PodPhase.FAILED.value:\n      raise RuntimeError(\'Pod ""%s:%s"" failed with status ""%s"".\' %\n                         (namespace, pod_name, resp.status))\n\n    logging.info(\'Pod ""%s:%s"" is done.\', namespace, pod_name)\n\n  def _build_pod_manifest(\n      self, pod_name: Text,\n      container_spec: executor_spec.ExecutorContainerSpec) -> Dict[Text, Any]:\n    """"""Build a pod spec.\n\n    The function builds a pod spec by patching executor container spec into\n    the pod spec from component config.\n\n    Args:\n      pod_name: The name of the pod.\n      container_spec: The resolved executor container spec.\n\n    Returns:\n      The pod manifest in dictionary format.\n    """"""\n    if self._component_config:\n      kubernetes_config = cast(\n          kubernetes_component_config.KubernetesComponentConfig,\n          self._component_config)\n      pod_manifest = container_common.to_swagger_dict(kubernetes_config.pod)\n    else:\n      pod_manifest = {}\n\n    pod_manifest.update({\n        \'apiVersion\': \'v1\',\n        \'kind\': \'Pod\',\n    })\n    # TODO(hongyes): figure out a better way to figure out type hints for nested\n    # dict.\n    metadata = pod_manifest.setdefault(\'metadata\', {})  # type: Dict[Text, Any]\n    metadata.update({\'name\': pod_name})\n    spec = pod_manifest.setdefault(\'spec\', {})  # type: Dict[Text, Any]\n    spec.update({\'restartPolicy\': \'Never\'})\n    containers = spec.setdefault(\'containers\',\n                                 [])  # type: List[Dict[Text, Any]]\n    container = None  # type: Optional[Dict[Text, Any]]\n    for c in containers:\n      if c[\'name\'] == kube_utils.ARGO_MAIN_CONTAINER_NAME:\n        container = c\n        break\n    if not container:\n      container = {\'name\': kube_utils.ARGO_MAIN_CONTAINER_NAME}\n      containers.append(container)\n    container.update({\n        \'image\': container_spec.image,\n        \'command\': container_spec.command,\n        \'args\': container_spec.args,\n    })\n    return pod_manifest\n\n  def _get_pod(self, core_api: client.CoreV1Api, pod_name: Text,\n               namespace: Text) -> Optional[client.V1Pod]:\n    """"""Get a pod from Kubernetes metadata API.\n\n    Args:\n      core_api: Client of Core V1 API of Kubernetes API.\n      pod_name: The name of the POD.\n      namespace: The namespace of the POD.\n\n    Returns:\n      The found POD object. None if it\'s not found.\n\n    Raises:\n      RuntimeError: When it sees unexpected errors from Kubernetes API.\n    """"""\n    try:\n      return core_api.read_namespaced_pod(name=pod_name, namespace=namespace)\n    except client.rest.ApiException as e:\n      if e.status != 404:\n        raise RuntimeError(\'Unknown error! \\nReason: %s\\nBody: %s\' %\n                           (e.reason, e.body))\n      return None\n\n  def _wait_pod(self,\n                core_api: client.CoreV1Api,\n                pod_name: Text,\n                namespace: Text,\n                exit_condition_lambda: Callable[[client.V1Pod], bool],\n                condition_description: Text,\n                timeout_sec: int = 300) -> client.V1Pod:\n    """"""Wait for a POD to meet an exit condition.\n\n    Args:\n      core_api: Client of Core V1 API of Kubernetes API.\n      pod_name: The name of the POD.\n      namespace: The namespace of the POD.\n      exit_condition_lambda: A lambda which will be called intervally to wait\n        for a POD to exit. The function returns True to exit.\n      condition_description: The description of the exit condition which will be\n        set in the error message if the wait times out.\n      timeout_sec: The seconds for the function to wait. Defaults to 300s.\n\n    Returns:\n      The POD object which meets the exit condition.\n\n    Raises:\n      RuntimeError: when the function times out.\n    """"""\n    start_time = datetime.datetime.utcnow()\n    while True:\n      resp = self._get_pod(core_api, pod_name, namespace)\n      logging.info(resp.status.phase)\n      if exit_condition_lambda(resp):\n        return resp\n      elapse_time = datetime.datetime.utcnow() - start_time\n      if elapse_time.seconds >= timeout_sec:\n        raise RuntimeError(\n            \'Pod ""%s:%s"" does not reach ""%s"" within %s seconds.\' %\n            (namespace, pod_name, condition_description, timeout_sec))\n      # TODO(hongyes): add exponential backoff here.\n      time.sleep(1)\n\n  def _build_pod_name(self, execution_id: int) -> Text:\n    if self._pipeline_info.run_id:\n      pipeline_name = (\n          self._pipeline_info.pipeline_name[:50] + \'-\' +\n          self._pipeline_info.run_id[:50])\n    else:\n      pipeline_name = self._pipeline_info.pipeline_name[:100]\n\n    pod_name = \'%s-%s-%s\' % (\n        pipeline_name, self._component_info.component_id[:50], execution_id)\n    return _sanitize_pod_name(pod_name)\n'"
tfx/orchestration/launcher/kubernetes_component_launcher_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.launcher.kubernetes_component_launcher.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom kubernetes import client\nfrom kubernetes import config\nimport mock\nimport tensorflow as tf\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.config import kubernetes_component_config\nfrom tfx.orchestration.launcher import kubernetes_component_launcher\nfrom tfx.orchestration.launcher import test_utils\nfrom tfx.types import channel_utils\nfrom tfx.utils import kube_utils\n\n\nclass KubernetesComponentLauncherTest(tf.test.TestCase):\n\n  def testCanLaunch(self):\n    self.assertTrue(\n        kubernetes_component_launcher.KubernetesComponentLauncher.can_launch(\n            executor_spec.ExecutorContainerSpec(image=\'test\')))\n    self.assertFalse(\n        kubernetes_component_launcher.KubernetesComponentLauncher.can_launch(\n            executor_spec.ExecutorClassSpec(base_executor.BaseExecutor)))\n\n  @mock.patch.dict(os.environ, {\n      kube_utils.KFP_NAMESPACE: \'ns-1\',\n      kube_utils.KFP_POD_NAME: \'pod-1\'\n  })\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(config, \'load_incluster_config\', autospec=True)\n  @mock.patch.object(client, \'CoreV1Api\', autospec=True)\n  def testLaunch_loadInClusterSucceed(self, mock_core_api_cls,\n                                      mock_incluster_config, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    core_api = mock_core_api_cls.return_value\n    core_api.read_namespaced_pod.side_effect = [\n        self._mock_launcher_pod(),\n        client.rest.ApiException(status=404),  # Mock no existing pod state.\n        self._mock_executor_pod(\n            \'Pending\'),  # Mock pending state after creation.\n        self._mock_executor_pod(\'Running\'),  # Mock running state after pending.\n        self._mock_executor_pod(\'Succeeded\'),  # Mock Succeeded state.\n    ]\n    # Mock successful pod creation.\n    core_api.create_namespaced_pod.return_value = client.V1Pod()\n    core_api.read_namespaced_pod_log.return_value.stream.return_value = [\n        b\'log-1\'\n    ]\n    context = self._create_launcher_context()\n\n    context[\'launcher\'].launch()\n\n    self.assertEqual(5, core_api.read_namespaced_pod.call_count)\n    core_api.create_namespaced_pod.assert_called_once()\n    core_api.read_namespaced_pod_log.assert_called_once()\n    _, mock_kwargs = core_api.create_namespaced_pod.call_args\n    self.assertEqual(\'ns-1\', mock_kwargs[\'namespace\'])\n    pod_manifest = mock_kwargs[\'body\']\n    self.assertDictEqual(\n        {\n            \'apiVersion\': \'v1\',\n            \'kind\': \'Pod\',\n            \'metadata\': {\n                \'name\':\n                    \'test-123-fakecomponent-fakecomponent-123\',\n                \'ownerReferences\': [{\n                    \'apiVersion\': \'argoproj.io/v1alpha1\',\n                    \'kind\': \'Workflow\',\n                    \'name\': \'wf-1\',\n                    \'uid\': \'wf-uid-1\'\n                }]\n            },\n            \'spec\': {\n                \'restartPolicy\': \'Never\',\n                \'containers\': [{\n                    \'name\': \'main\',\n                    \'image\': \'gcr://test\',\n                    \'command\': None,\n                    \'args\': [context[\'input_artifact\'].uri],\n                }],\n                \'serviceAccount\': \'sa-1\',\n                \'serviceAccountName\': None\n            }\n        }, pod_manifest)\n\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(config, \'load_incluster_config\', autospec=True)\n  @mock.patch.object(config, \'load_kube_config\', autospec=True)\n  @mock.patch.object(client, \'CoreV1Api\', autospec=True)\n  def testLaunch_loadKubeConfigSucceed(self, mock_core_api_cls,\n                                       mock_kube_config, mock_incluster_config,\n                                       mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    mock_incluster_config.side_effect = config.config_exception.ConfigException(\n    )\n    core_api = mock_core_api_cls.return_value\n    core_api.read_namespaced_pod.side_effect = [\n        client.rest.ApiException(status=404),  # Mock no existing pod state.\n        self._mock_executor_pod(\n            \'Pending\'),  # Mock pending state after creation.\n        self._mock_executor_pod(\'Running\'),  # Mock running state after pending.\n        self._mock_executor_pod(\'Succeeded\'),  # Mock Succeeded state.\n    ]\n    # Mock successful pod creation.\n    core_api.create_namespaced_pod.return_value = client.V1Pod()\n    core_api.read_namespaced_pod_log.return_value.stream.return_value = [\n        b\'log-1\'\n    ]\n    context = self._create_launcher_context()\n\n    context[\'launcher\'].launch()\n\n    self.assertEqual(4, core_api.read_namespaced_pod.call_count)\n    core_api.create_namespaced_pod.assert_called_once()\n    core_api.read_namespaced_pod_log.assert_called_once()\n    _, mock_kwargs = core_api.create_namespaced_pod.call_args\n    self.assertEqual(\'kubeflow\', mock_kwargs[\'namespace\'])\n    pod_manifest = mock_kwargs[\'body\']\n    self.assertDictEqual(\n        {\n            \'apiVersion\': \'v1\',\n            \'kind\': \'Pod\',\n            \'metadata\': {\n                \'name\': \'test-123-fakecomponent-fakecomponent-123\',\n            },\n            \'spec\': {\n                \'restartPolicy\':\n                    \'Never\',\n                \'containers\': [{\n                    \'name\': \'main\',\n                    \'image\': \'gcr://test\',\n                    \'command\': None,\n                    \'args\': [context[\'input_artifact\'].uri],\n                }],\n            }\n        }, pod_manifest)\n\n  @mock.patch.dict(os.environ, {\n      \'KFP_NAMESPACE\': \'ns-1\',\n      \'KFP_POD_NAME\': \'pod-1\'\n  })\n  @mock.patch.object(publisher, \'Publisher\', autospec=True)\n  @mock.patch.object(config, \'load_incluster_config\', autospec=True)\n  @mock.patch.object(client, \'CoreV1Api\', autospec=True)\n  def testLaunch_withComponentConfig(self, mock_core_api_cls,\n                                     mock_incluster_config, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n    core_api = mock_core_api_cls.return_value\n    core_api.read_namespaced_pod.side_effect = [\n        self._mock_launcher_pod(),\n        client.rest.ApiException(status=404),  # Mock no existing pod state.\n        self._mock_executor_pod(\n            \'Pending\'),  # Mock pending state after creation.\n        self._mock_executor_pod(\'Running\'),  # Mock running state after pending.\n        self._mock_executor_pod(\'Succeeded\'),  # Mock Succeeded state.\n    ]\n    # Mock successful pod creation.\n    core_api.create_namespaced_pod.return_value = client.V1Pod()\n    core_api.read_namespaced_pod_log.return_value.stream.return_value = [\n        b\'log-1\'\n    ]\n    component_config = kubernetes_component_config.KubernetesComponentConfig(\n        client.V1Pod(\n            spec=client.V1PodSpec(containers=[\n                client.V1Container(\n                    name=\'main\', resources={\'limits\': {\n                        \'memory\': \'200mi\'\n                    }})\n            ])))\n    context = self._create_launcher_context(component_config)\n\n    context[\'launcher\'].launch()\n\n    self.assertEqual(5, core_api.read_namespaced_pod.call_count)\n    core_api.create_namespaced_pod.assert_called_once()\n    core_api.read_namespaced_pod_log.assert_called_once()\n    _, mock_kwargs = core_api.create_namespaced_pod.call_args\n    self.assertEqual(\'ns-1\', mock_kwargs[\'namespace\'])\n    pod_manifest = mock_kwargs[\'body\']\n    print(pod_manifest)\n    self.assertDictEqual(\n        {\n            \'apiVersion\': \'v1\',\n            \'kind\': \'Pod\',\n            \'metadata\': {\n                \'name\':\n                    \'test-123-fakecomponent-fakecomponent-123\',\n                \'ownerReferences\': [{\n                    \'apiVersion\': \'argoproj.io/v1alpha1\',\n                    \'kind\': \'Workflow\',\n                    \'name\': \'wf-1\',\n                    \'uid\': \'wf-uid-1\'\n                }]\n            },\n            \'spec\': {\n                \'restartPolicy\': \'Never\',\n                \'containers\': [{\n                    \'name\': \'main\',\n                    \'image\': \'gcr://test\',\n                    \'command\': None,\n                    \'args\': [context[\'input_artifact\'].uri],\n                    \'resources\': {\n                        \'limits\': {\n                            \'memory\': \'200mi\'\n                        }\n                    }\n                }],\n                \'serviceAccount\': \'sa-1\',\n                \'serviceAccountName\': None\n            }\n        }, pod_manifest)\n\n  def _create_launcher_context(self, component_config=None):\n    test_dir = self.get_temp_dir()\n\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.sqlite.SetInParent()\n    metadata_connection = metadata.Metadata(connection_config)\n\n    pipeline_root = os.path.join(test_dir, \'Test\')\n\n    input_artifact = test_utils._InputArtifact()\n    input_artifact.uri = os.path.join(test_dir, \'input\')\n\n    component = test_utils._FakeComponent(\n        name=\'FakeComponent\',\n        input_channel=channel_utils.as_channel([input_artifact]),\n        custom_executor_spec=executor_spec.ExecutorContainerSpec(\n            image=\'gcr://test\', args=[\'{{input_dict[""input""][0].uri}}\']))\n\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'Test\', pipeline_root=pipeline_root, run_id=\'123\')\n\n    driver_args = data_types.DriverArgs(enable_cache=True)\n\n    launcher = kubernetes_component_launcher.KubernetesComponentLauncher.create(\n        component=component,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=[],\n        additional_pipeline_args={},\n        component_config=component_config)\n\n    return {\'launcher\': launcher, \'input_artifact\': input_artifact}\n\n  def _mock_launcher_pod(self):\n    return client.V1Pod(\n        metadata=client.V1ObjectMeta(owner_references=[\n            client.V1OwnerReference(\n                api_version=\'argoproj.io/v1alpha1\',\n                kind=\'Workflow\',\n                name=\'wf-1\',\n                uid=\'wf-uid-1\')\n        ]),\n        spec=client.V1PodSpec(containers=[], service_account=\'sa-1\'))\n\n  def _mock_executor_pod(self, phase):\n    return client.V1Pod(status=client.V1PodStatus(phase=phase))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/launcher/test_utils.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common code shared by test code.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Optional, Text\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_driver\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration import data_types\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import component_spec\n\n\nclass _InputArtifact(types.Artifact):\n  TYPE_NAME = \'InputArtifact\'\n\n\nclass _OutputArtifact(types.Artifact):\n  TYPE_NAME = \'OutputArtifact\'\n\n\nclass _FakeDriver(base_driver.BaseDriver):\n  """"""Fake driver for testing purpose only.""""""\n\n  def pre_execution(\n      self,\n      input_dict: Dict[Text, types.Channel],\n      output_dict: Dict[Text, types.Channel],\n      exec_properties: Dict[Text, Any],\n      driver_args: data_types.DriverArgs,\n      pipeline_info: data_types.PipelineInfo,\n      component_info: data_types.ComponentInfo,\n  ) -> data_types.ExecutionDecision:\n    input_artifacts = channel_utils.unwrap_channel_dict(input_dict)\n    output_artifacts = channel_utils.unwrap_channel_dict(output_dict)\n\n    # Generating missing output artifact URIs\n    for name, artifacts in output_artifacts.items():\n      for idx, artifact in enumerate(artifacts):\n        if not artifact.uri:\n          suffix = str(idx + 1) if idx > 0 else \'\'\n          artifact.uri = os.path.join(\n              pipeline_info.pipeline_root, \'artifacts\', name + suffix, \'data\',\n          )\n          tf.io.gfile.makedirs(os.path.dirname(artifact.uri))\n\n    return data_types.ExecutionDecision(input_artifacts, output_artifacts,\n                                        exec_properties, 123, False)\n\n\nclass _FakeExecutor(base_executor.BaseExecutor):\n  """"""Fake executor for testing purpose only.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    input_path = artifact_utils.get_single_uri(input_dict[\'input\'])\n    output_path = artifact_utils.get_single_uri(output_dict[\'output\'])\n    tf.io.gfile.copy(input_path, output_path)\n\n\nclass _FakeComponentSpec(types.ComponentSpec):\n  """"""Fake component spec for testing purpose only.""""""\n  PARAMETERS = {}\n  INPUTS = {\'input\': component_spec.ChannelParameter(type=_InputArtifact)}\n  OUTPUTS = {\'output\': component_spec.ChannelParameter(type=_OutputArtifact)}\n\n\nclass _FakeComponent(base_component.BaseComponent):\n  """"""Fake component for testing purpose only.""""""\n  SPEC_CLASS = _FakeComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(_FakeExecutor)\n  DRIVER_CLASS = _FakeDriver\n\n  def __init__(self,\n               name: Text,\n               input_channel: types.Channel,\n               output_channel: Optional[types.Channel] = None,\n               custom_executor_spec: executor_spec.ExecutorSpec = None):\n    output_channel = output_channel or types.Channel(\n        type=_OutputArtifact, artifacts=[_OutputArtifact()])\n    spec = _FakeComponentSpec(input=input_channel, output=output_channel)\n    super(_FakeComponent, self).__init__(\n        spec=spec,\n        instance_name=name,\n        custom_executor_spec=custom_executor_spec)\n'"
tfx/orchestration/test_pipelines/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/test_pipelines/download_grep_print_pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Container-based pipeline sample.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nfrom tfx.dsl.component.experimental import container_component\nfrom tfx.dsl.component.experimental import placeholders\nfrom tfx.types import standard_artifacts\n\n\ndownloader_component = container_component.create_container_component(\n    name=\'DownloadFromHttp\',\n    outputs={\n        \'data\': standard_artifacts.ExternalArtifact,\n    },\n    parameters={\n        \'url\': str,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          url=""$0""\n          output_data_uri=""$1""/data  # TODO(b/150515270) Remove when fixed.\n          output_data_path=$(mktemp)\n\n          # Running the main code\n          wget ""$0"" -O ""$output_data_path"" || curl ""$0"" > ""$output_data_path""\n\n          # Getting data out of the container\n          gsutil cp ""$output_data_path"" ""$output_data_uri""\n        \'\'\',\n        placeholders.InputValuePlaceholder(\'url\'),\n        placeholders.OutputUriPlaceholder(\'data\'),\n    ],\n)\n\n\ngrep_component = container_component.create_container_component(\n    name=\'FilterWithGrep\',\n    inputs={\n        \'text\': standard_artifacts.ExternalArtifact,\n    },\n    outputs={\n        \'filtered_text\': standard_artifacts.ExternalArtifact,\n    },\n    parameters={\n        \'pattern\': str,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          pattern=""$0""\n          text_uri=""$1""/data  # TODO(b/150515270) Remove when fixed.\n          text_path=$(mktemp)\n          filtered_text_uri=""$2""/data  # TODO(b/150515270) Remove when fixed.\n          filtered_text_path=$(mktemp)\n\n          # Getting data into the container\n          gsutil cp ""$text_uri"" ""$text_path""\n\n          # Running the main code\n          grep ""$pattern"" ""$text_path"" >""$filtered_text_path""\n\n          # Getting data out of the container\n          gsutil cp ""$filtered_text_path"" ""$filtered_text_uri""\n        \'\'\',\n        placeholders.InputValuePlaceholder(\'pattern\'),\n        placeholders.InputUriPlaceholder(\'text\'),\n        placeholders.OutputUriPlaceholder(\'filtered_text\'),\n    ],\n)\n\n\nprint_component = container_component.create_container_component(\n    name=\'Print\',\n    inputs={\n        \'text\': standard_artifacts.ExternalArtifact,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          text_uri=""$0""/data  # TODO(b/150515270) Remove when fixed.\n          text_path=$(mktemp)\n\n          # Getting data into the container\n          gsutil cp ""$text_uri"" ""$text_path""\n\n          # Running the main code\n          cat ""$text_path""\n        \'\'\',\n        placeholders.InputUriPlaceholder(\'text\'),\n    ],\n)\n\n\ndef create_pipeline_component_instances(text_url: Text, pattern: Text):\n  """"""Creates tasks for the download_grep_print pipeline.""""""\n\n  downloader_task = downloader_component(url=text_url)\n  grep_task = grep_component(\n      text=downloader_task.outputs[\'data\'],\n      pattern=pattern,\n  )\n  print_task = print_component(\n      text=grep_task.outputs[\'filtered_text\'],\n  )\n\n  component_instances = [\n      downloader_task,\n      grep_task,\n      print_task,\n  ]\n\n  return component_instances\n'"
tfx/proto/orchestration/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/cli_context.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Context for @cli_group.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport click\n\n\nclass Context(object):\n  """"""Context shared between all command groups.\n\n  Attributes :\n    flags_dict: A dictionary containing the flags of a command.\n  """"""\n\n  def __init__(self):\n    self.flags_dict = {}\n\npass_context = click.make_pass_decorator(Context, ensure=True)\n'"
tfx/tools/cli/cli_main.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Main script to invoke CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport click\nfrom tfx.tools.cli.commands.pipeline import pipeline_group\nfrom tfx.tools.cli.commands.run import run_group\nfrom tfx.tools.cli.commands.template import template_group\n\n\n@click.group(\'cli\')\ndef cli_group():\n  click.echo(\'CLI\')\n\n\ncli_group.add_command(pipeline_group)\ncli_group.add_command(run_group)\ncli_group.add_command(template_group)\n\nif __name__ == \'__main__\':\n  cli_group()\n'"
tfx/tools/cli/cli_main_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.cli_main.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\n\nfrom click import testing as click_testing\nimport tensorflow as tf\nfrom tfx.tools.cli.cli_main import cli_group\n\n\nclass CliTest(tf.test.TestCase):\n\n  def setUp(self):\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    super(CliTest, self).setUp()\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n    self.runner = click_testing.CliRunner()\n\n  def testCliPipeline(self):\n    result = self.runner.invoke(cli_group, [\'pipeline\'])\n    self.assertIn(\'CLI\', result.output)\n\n  def testCliRun(self):\n    result = self.runner.invoke(cli_group, [\'run\'])\n    self.assertIn(\'CLI\', result.output)\n\n  def testCliTemplate(self):\n    result = self.runner.invoke(cli_group, [\'template\'])\n    self.assertIn(\'CLI\', result.output)\n\n  def testCliInvalidCommand(self):\n    result = self.runner.invoke(cli_group, [\'pipelin\'])\n    self.assertNotEqual(0, result.exit_code)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/labels.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common Flags.""""""\n\nENGINE_FLAG = \'engine\'\nPIPELINE_DSL_PATH = \'pipeline_dsl_path\'\nPIPELINE_NAME = \'pipeline_name\'\nTFX_JSON_EXPORT_PIPELINE_ARGS_PATH = \'TFX_JSON_EXPORT_PIPELINE_ARGS_PATH\'\nAIRFLOW_PACKAGE_NAME = \'apache-airflow\'\nKUBEFLOW_PACKAGE_NAME = \'kfp\'\nRUN_ID = \'run_id\'\nAIRFLOW_ENGINE = \'airflow\'\nBEAM_ENGINE = \'beam\'\nKUBEFLOW_ENGINE = \'kubeflow\'\n# Path to root directory of the pipeline.\nPIPELINE_ROOT = \'pipeline_root\'\n# List of components in the pipeline.\nPIPELINE_COMPONENTS = \'pipeline_components\'\n\n# Kubeflow specific labels.\n# Path to the output workflow file for Kubeflow pipelines.\nPIPELINE_PACKAGE_PATH = \'pipeline_package_path\'\n# Target container image path.\nTARGET_IMAGE = \'build_target_image\'\n# Base container image path.\nBASE_IMAGE = \'build_base_image\'\n# Skaffold command\nSKAFFOLD_CMD = \'skaffold_cmd\'\n# Client ID for IAP protected endpoint.\nIAP_CLIENT_ID = \'iap_client_id\'\n# Endpoint of the KFP API service to connect.\nENDPOINT = \'endpoint\'\n# Kubernetes namespace to connect to the KFP API.\nNAMESPACE = \'namespace\'\n# Pipeline id generated when pipeline is uploaded to KFP server.\nPIPELINE_ID = \'pipeline_id\'\n# Pipeline version id generated when pipeline is created or updated.\nPIPELINE_VERSION_ID = \'pipeline_version_id\'\n# Experiment id generated when a new experiment is created on KFP server.\nEXPERIMENT_ID = \'experiment_id\'\n# Environment variable for the default Kubeflow TFX image.\nKUBEFLOW_TFX_IMAGE_ENV = \'KUBEFLOW_TFX_IMAGE\'\n\n# Template specific labels.\n# Destination directory path to copy files\nDESTINATION_PATH = \'destination_path\'\n# Model kind of the copying template\nMODEL = \'model\'\n'"
tfx/types/experimental/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Subpackage for experimental TFX pipeline types.""""""\n'"
tfx/types/experimental/simple_artifacts.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A set of simple Artifact types for use with AI Platform Pipelines.\n\nExperimental: the artifact definitions here are expected to change.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tfx.types import artifact\n\n\nclass Dataset(artifact.Artifact):\n  TYPE_NAME = \'Dataset\'\n\n\nclass File(artifact.Artifact):\n  TYPE_NAME = \'File\'\n\n\nclass Statistics(artifact.Artifact):\n  TYPE_NAME = \'Statistics\'\n\n\nclass Model(artifact.Artifact):\n  TYPE_NAME = \'Model\'\n\n\nclass Metrics(artifact.Artifact):\n  TYPE_NAME = \'Metrics\'\n\n\nclass Schema(artifact.Artifact):\n  TYPE_NAME = \'Schema\'\n'"
tfx/utils/model_paths/__init__.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/utils/model_paths/tf_serving_flavor.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module for constructing and parsing tensorflow-serving-flavored model path.\n\nIn TensorFlow Serving, the model should be stored with the directory structure\n`{model_base_path}/{model_name}/{version}` to be correctly recognized by the\nmodel server. We call this a *TFS-flavored model path*.\n\nExample:\n\n```\n/foo/bar/        # A `model_base_path`\n  my_model/      # A `model_name`\n    1582072718/  # An integer `version`\n      (Your exported SavedModel)\n```\n\nIf you\'re using TensorFlow estimator API, the exporter uses this directory\nstructure to organize the model, where `model_name` is the name of the exporter.\n\nTensorFlow Serving also requires the version segment to be an integer (mostly\na unix timestamp) to track the latest model easily.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Optional, Text, Tuple\n\n\ndef make_model_path(model_base_path: Text, model_name: Text,\n                    version: int) -> Text:\n  """"""Make a TFS-flavored model path.\n\n  Args:\n    model_base_path: A base path containing the directory of model_name.\n    model_name: A name of the model.\n    version: An integer version of the model.\n\n  Returns:\n    `{model_base_path}/{model_name}/{version}`.\n  """"""\n  return os.path.join(model_base_path, model_name, str(version))\n\n\ndef parse_model_path(\n    model_path: Text,\n    expected_model_name: Optional[Text] = None) -> Tuple[Text, Text, int]:\n  """"""Parse model_path into parts of TFS flavor.\n\n  Args:\n    model_path: A TFS-flavored model path.\n    expected_model_name: Expected model_name as defined from the module\n        docstring. If model_name does not match, parsing will be failed.\n\n  Raises:\n    ValueError: If model path is invalid (not TFS-flavored).\n\n  Returns:\n    Tuple of (model_base_path, model_name, version)\n  """"""\n  rest, version = os.path.split(model_path)\n  if not rest:\n    raise ValueError(\'model_path is too short ({})\'.format(model_path))\n  if not version.isdigit():\n    raise ValueError(\'No version segment ({})\'.format(model_path))\n  version = int(version)\n\n  model_base_path, model_name = os.path.split(rest)\n  if expected_model_name is not None and model_name != expected_model_name:\n    raise ValueError(\'model_name does not match (expected={}, actual={})\'\n                     .format(expected_model_name, model_path))\n\n  return model_base_path, model_name, version\n\n\ndef parse_model_base_path(model_path: Text) -> Text:\n  """"""Parse model_base_path from the TFS-flavored model path.\n\n  Args:\n    model_path: A TFS-flavored model path.\n\n  Raises:\n    ValueError: If model path is invalid (not TFS-flavored).\n\n  Returns:\n    model_base_path as defined from the module docstring.\n  """"""\n  return parse_model_path(model_path)[0]\n'"
tfx/utils/model_paths/tf_serving_flavor_test.py,2,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.utils.model_paths.tf_serving_flavor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx.utils.model_paths import tf_serving_flavor as tfs_flavor\n\n\nclass TFServingFlavorTest(tf.test.TestCase):\n\n  def testRoundTrip(self):\n    self.assertEqual(\n        tfs_flavor.parse_model_path(\n            tfs_flavor.make_model_path(\'/foo/bar\', \'my-model\', 123)),\n        (\'/foo/bar\', \'my-model\', 123))\n\n    self.assertEqual(\n        tfs_flavor.make_model_path(\n            *tfs_flavor.parse_model_path(\'/foo/bar/my-model/123\')),\n        \'/foo/bar/my-model/123\')\n\n  def testMakeModelPath(self):\n    self.assertEqual(\n        tfs_flavor.make_model_path(\n            model_base_path=\'/foo/bar\',\n            model_name=\'my-model\',\n            version=123),\n        \'/foo/bar/my-model/123\')\n\n    self.assertEqual(\n        tfs_flavor.make_model_path(\n            model_base_path=\'s3://bucket-name/foo/bar\',\n            model_name=\'my-model\',\n            version=123),\n        \'s3://bucket-name/foo/bar/my-model/123\')\n\n    self.assertEqual(\n        tfs_flavor.make_model_path(\n            model_base_path=\'gs://bucket-name/foo/bar\',\n            model_name=\'my-model\',\n            version=123),\n        \'gs://bucket-name/foo/bar/my-model/123\')\n\n  def testParseModelPath(self):\n    self.assertEqual(\n        tfs_flavor.parse_model_path(\'/foo/bar/my-model/123\',),\n        (\'/foo/bar\', \'my-model\', 123))\n\n    self.assertEqual(\n        tfs_flavor.parse_model_path(\'s3://bucket-name/foo/bar/my-model/123\'),\n        (\'s3://bucket-name/foo/bar\', \'my-model\', 123))\n\n    self.assertEqual(\n        tfs_flavor.parse_model_path(\'gs://bucket-name/foo/bar/my-model/123\'),\n        (\'gs://bucket-name/foo/bar\', \'my-model\', 123))\n\n  def testParseModelPath_Fail(self):\n    with self.assertRaises(ValueError):\n      tfs_flavor.parse_model_path(\'too-short\')\n\n    with self.assertRaises(ValueError):\n      tfs_flavor.parse_model_path(\'/foo/bar/my-model/not-an-int-version\')\n\n    with self.assertRaises(ValueError):\n      tfs_flavor.parse_model_path(\'/foo/bar/other-model/123\',\n                                  expected_model_name=\'my-model\')\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/utils/testdata/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/utils/testdata/test_fn.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test module containing test function.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\ndef test_fn(inputs):\n  """"""test function to sum all inputs.""""""\n  return sum(inputs)\n\n\nclass TestClass(object):\n  """"""a class to test import_utils.""""""\n  pass\n'"
tfx/benchmarks/datasets/chicago_taxi/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/benchmarks/datasets/chicago_taxi/dataset.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport shutil\nimport tempfile\n\nfrom absl import logging\nimport apache_beam as beam\n\nfrom tfx_bsl.coders import csv_decoder\n\nfrom tfx import components\nfrom tfx.benchmarks import benchmark_dataset\nfrom tfx.components.example_gen.csv_example_gen import executor as csv_exgen\nfrom tfx.examples.chicago_taxi_pipeline import taxi_utils\n\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils.dsl_utils import external_input\n\n\nclass ChicagoTaxiDataset(benchmark_dataset.BenchmarkDataset):\n  """"""Chicago taxi dataset.""""""\n\n  def dataset_path(self):\n    return self.datasets_dir(""chicago_taxi/data/taxi_1M.tfrecords.gz"")\n\n  def tf_metadata_schema_path(self):\n    return self.datasets_dir(\n        ""../../examples/chicago_taxi_pipeline/data/user_provided_schema/""\n        ""schema.pbtxt"")\n\n  def trained_saved_model_path(self):\n    return self.datasets_dir(""chicago_taxi/model/trained_saved_model"")\n\n  def tft_saved_model_path(self):\n    return self.datasets_dir(""chicago_taxi/model/tft_saved_model"")\n\n  def tfma_saved_model_path(self):\n    return self.datasets_dir(""chicago_taxi/model/tfma_saved_model"")\n\n  def tft_preprocessing_fn(self):\n    return taxi_utils.preprocessing_fn\n\n  def num_examples(self, limit=None):\n    result = 1000000\n    if limit:\n      result = min(result, limit)\n    return result\n\n  def convert_csv_to_tf_examples(self, csv_path, tfrecords_output_path):\n    """"""Runs a Beam pipeline to convert the CSV file into a TFRecords file.\n\n    This is needed because the conversion is orders of magnitude more\n    time-consuming than the functions we want to benchmark, so instead of\n    doing the conversion each time, we do it once to generate a converted\n    dataset and use that for the benchmark instead.\n\n    Args:\n      csv_path: Path to CSV file containing examples.\n      tfrecords_output_path: Path to output TFRecords file containing parsed\n        examples.\n    """"""\n    # Copied from CSV example gen.\n    fp = open(csv_path, ""r"")\n    column_names = next(fp).strip().split("","")\n    fp.close()\n\n    with beam.Pipeline() as p:\n      parsed_csv_lines = (\n          p\n          | ""ReadFromText"" >> beam.io.ReadFromText(\n              file_pattern=csv_path, skip_header_lines=1)\n          |\n          ""ParseCSVLine"" >> beam.ParDo(csv_decoder.ParseCSVLine(delimiter="","")))\n      # TODO(b/155997704) clean this up once tfx_bsl makes a release.\n      if getattr(csv_decoder, ""PARSE_CSV_LINE_YIELDS_RAW_RECORDS"", False):\n        # parsed_csv_lines is the following tuple (parsed_lines, raw_records)\n        # we only want the parsed_lines.\n        parsed_csv_lines |= ""ExtractParsedCSVLines"" >> beam.Keys()\n\n      column_infos = beam.pvalue.AsSingleton(\n          parsed_csv_lines\n          | ""InferColumnTypes"" >> beam.CombineGlobally(\n              csv_decoder.ColumnTypeInferrer(\n                  column_names, skip_blank_lines=True)))\n      _ = (\n          parsed_csv_lines\n          | ""ToTFExample"" >> beam.ParDo(\n              csv_exgen._ParsedCsvToTfExample(),  # pylint: disable=protected-access\n              column_infos)\n          | ""Serialize"" >> beam.Map(lambda x: x.SerializeToString())\n          | ""WriteToTFRecord"" >> beam.io.tfrecordio.WriteToTFRecord(\n              file_path_prefix=tfrecords_output_path,\n              shard_name_template="""",\n              compression_type=beam.io.filesystem.CompressionTypes.GZIP))\n\n  def generate_raw_dataset(self, args):\n    logging.warn(\n        ""Not actually regenerating the raw dataset.\\n""\n        ""To regenerate the raw CSV dataset, see the TFX Chicago Taxi example ""\n        ""for details as to how to do so. ""\n        ""tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_gcp.py ""\n        ""has the BigQuery query used to generate the dataset.\\n""\n        ""After regenerating the raw CSV dataset, you should also regenerate ""\n        ""the derived TFRecords dataset. You can do so by passing ""\n        ""--generate_dataset_args=/path/to/csv_dataset.csv to ""\n        ""regenerate_datasets.py."")\n\n    if args:\n      logging.info(""Converting CSV at %s to TFRecords"", args)\n      self.convert_csv_to_tf_examples(args, self.dataset_path())\n      logging.info(""TFRecords written to %s"", self.dataset_path())\n\n  def generate_models(self, args):\n    # Modified version of Chicago Taxi Example pipeline\n    # tfx/examples/chicago_taxi_pipeline/taxi_pipeline_beam.py\n\n    root = tempfile.mkdtemp()\n    pipeline_root = os.path.join(root, ""pipeline"")\n    metadata_path = os.path.join(root, ""metadata/metadata.db"")\n    module_file = os.path.join(\n        os.path.dirname(__file__),\n        ""../../../examples/chicago_taxi_pipeline/taxi_utils.py"")\n\n    examples = external_input(os.path.dirname(self.dataset_path()))\n    example_gen = components.ImportExampleGen(input=examples)\n    statistics_gen = components.StatisticsGen(\n        examples=example_gen.outputs[""examples""])\n    schema_gen = components.SchemaGen(\n        statistics=statistics_gen.outputs[""statistics""],\n        infer_feature_shape=False)\n    transform = components.Transform(\n        examples=example_gen.outputs[""examples""],\n        schema=schema_gen.outputs[""schema""],\n        module_file=module_file)\n    trainer = components.Trainer(\n        module_file=module_file,\n        transformed_examples=transform.outputs[""transformed_examples""],\n        schema=schema_gen.outputs[""schema""],\n        transform_graph=transform.outputs[""transform_graph""],\n        train_args=trainer_pb2.TrainArgs(num_steps=100),\n        eval_args=trainer_pb2.EvalArgs(num_steps=50))\n    p = pipeline.Pipeline(\n        pipeline_name=""chicago_taxi_beam"",\n        pipeline_root=pipeline_root,\n        components=[\n            example_gen, statistics_gen, schema_gen, transform, trainer\n        ],\n        enable_cache=True,\n        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n            metadata_path))\n    BeamDagRunner().run(p)\n\n    def join_unique_subdir(path):\n      dirs = os.listdir(path)\n      if len(dirs) != 1:\n        raise ValueError(\n            ""expecting there to be only one subdirectory in %s, but ""\n            ""subdirectories were: %s"" % (path, dirs))\n      return os.path.join(path, dirs[0])\n\n    trainer_output_dir = join_unique_subdir(\n        os.path.join(pipeline_root, ""Trainer/model""))\n    eval_model_dir = join_unique_subdir(\n        os.path.join(trainer_output_dir, ""eval_model_dir""))\n    serving_model_dir = join_unique_subdir(\n        os.path.join(trainer_output_dir,\n                     ""serving_model_dir/export/chicago-taxi""))\n\n    shutil.rmtree(self.trained_saved_model_path(), ignore_errors=True)\n    shutil.rmtree(self.tfma_saved_model_path(), ignore_errors=True)\n    shutil.copytree(serving_model_dir, self.trained_saved_model_path())\n    shutil.copytree(eval_model_dir, self.tfma_saved_model_path())\n\n\ndef get_dataset(base_dir=None):\n  return ChicagoTaxiDataset(base_dir)\n'"
tfx/components/example_gen/big_query_example_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_gen/big_query_example_gen/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX BigQueryExampleGen component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import component\nfrom tfx.components.example_gen import utils\nfrom tfx.components.example_gen.big_query_example_gen import executor\nfrom tfx.proto import example_gen_pb2\n\n\nclass BigQueryExampleGen(component._QueryBasedExampleGen):  # pylint: disable=protected-access\n  """"""Official TFX BigQueryExampleGen component.\n\n  The BigQuery examplegen component takes a query, and generates train\n  and eval examples for downsteam components.\n  """"""\n\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               query: Optional[Text] = None,\n               input_config: Optional[example_gen_pb2.Input] = None,\n               output_config: Optional[example_gen_pb2.Output] = None,\n               example_artifacts: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Constructs a BigQueryExampleGen component.\n\n    Args:\n      query: BigQuery sql string, query result will be treated as a single\n        split, can be overwritten by input_config.\n      input_config: An example_gen_pb2.Input instance with Split.pattern as\n        BigQuery sql string. If set, it overwrites the \'query\' arg, and allows\n        different queries per split. If any field is provided as a\n        RuntimeParameter, input_config should be constructed as a dict with the\n        same field names as Input proto message.\n      output_config: An example_gen_pb2.Output instance, providing output\n        configuration. If unset, default splits will be \'train\' and \'eval\' with\n        size 2:1. If any field is provided as a RuntimeParameter,\n        input_config should be constructed as a dict with the same field names\n        as Output proto message.\n      example_artifacts: Optional channel of \'ExamplesPath\' for output train and\n        eval examples.\n      instance_name: Optional unique instance name. Necessary if multiple\n        BigQueryExampleGen components are declared in the same pipeline.\n\n    Raises:\n      RuntimeError: Only one of query and input_config should be set.\n    """"""\n    if bool(query) == bool(input_config):\n      raise RuntimeError(\'Exactly one of query and input_config should be set.\')\n    input_config = input_config or utils.make_default_input_config(query)\n    super(BigQueryExampleGen, self).__init__(\n        input_config=input_config,\n        output_config=output_config,\n        example_artifacts=example_artifacts,\n        instance_name=instance_name)\n'"
tfx/components/example_gen/big_query_example_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.big_query_example_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.example_gen.big_query_example_gen import component\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    big_query_example_gen = component.BigQueryExampleGen(query=\'query\')\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     big_query_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = big_query_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithOutputConfig(self):\n    big_query_example_gen = component.BigQueryExampleGen(\n        query=\'query\',\n        output_config=example_gen_pb2.Output(\n            split_config=example_gen_pb2.SplitConfig(splits=[\n                example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n                example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1),\n                example_gen_pb2.SplitConfig.Split(name=\'test\', hash_buckets=1)\n            ])))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     big_query_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = big_query_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithInputConfig(self):\n    big_query_example_gen = component.BigQueryExampleGen(\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'train\', pattern=\'query1\'),\n            example_gen_pb2.Input.Split(name=\'eval\', pattern=\'query2\'),\n            example_gen_pb2.Input.Split(name=\'test\', pattern=\'query3\')\n        ]))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     big_query_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = big_query_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/big_query_example_gen/executor.py,11,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX BigQueryExampleGen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Optional, Text\n\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom google.cloud import bigquery\nfrom tfx import types\nfrom tfx.components.example_gen import base_example_gen_executor\n\n# TODO(b/155637606): Move Big query example gen to GCP extensions.\n\n\nclass _BigQueryConverter(object):\n  """"""Help class for bigquery result row to tf example conversion.""""""\n\n  def __init__(self, query: Text):\n    client = bigquery.Client()\n    # Dummy query to get the type information for each field.\n    query_job = client.query(\'SELECT * FROM ({}) LIMIT 0\'.format(query))\n    results = query_job.result()\n    self._type_map = {}\n    for field in results.schema:\n      self._type_map[field.name] = field.field_type\n\n  def RowToExample(self, instance: Dict[Text, Any]) -> tf.train.Example:\n    """"""Convert bigquery result row to tf example.""""""\n    feature = {}\n    for key, value in instance.items():\n      data_type = self._type_map[key]\n\n      if value is None:\n        feature[key] = tf.train.Feature()\n        continue\n\n      value_list = value if isinstance(value, list) else [value]\n      if data_type in (\'INTEGER\', \'BOOLEAN\'):\n        feature[key] = tf.train.Feature(\n            int64_list=tf.train.Int64List(value=value_list))\n      elif data_type == \'FLOAT\':\n        feature[key] = tf.train.Feature(\n            float_list=tf.train.FloatList(value=value_list))\n      elif data_type == \'STRING\':\n        feature[key] = tf.train.Feature(\n            bytes_list=tf.train.BytesList(\n                value=[tf.compat.as_bytes(elem) for elem in value_list]))\n      else:\n        # TODO(jyzhao): support more types.\n        raise RuntimeError(\n            \'BigQuery column type {} is not supported.\'.format(data_type))\n\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\n\n# Create this instead of inline in _BigQueryToExample for test mocking purpose.\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(beam.typehints.Dict[Text, Any])\ndef _ReadFromBigQueryImpl(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    query: Text,\n    project: Optional[Text],\n    use_bigquery_source: bool = False) -> beam.pvalue.PCollection:\n  """"""Read from BigQuery.\n\n  Args:\n    pipeline: beam pipeline.\n    query: a BigQuery sql string.\n    project: The ID of the project running this job.\n    use_bigquery_source: Whether to use BigQuerySource instead of experimental\n      `ReadFromBigQuery` PTransform.\n\n  Returns:\n    PCollection of dict.\n  """"""\n  # TODO(b/155441037): Consolidate to ReadFromBigQuery once its performance\n  # on dataflow runner is on par with BigQuerySource.\n  if use_bigquery_source:\n    return (pipeline\n            | \'ReadFromBigQuerySource\' >> beam.io.Read(\n                beam.io.BigQuerySource(query=query, use_standard_sql=True)))\n  # TODO(b/155441037): Change this to top level import after Beam version is\n  # upgraded to 2.22.\n  try:\n    from apache_beam.io.gcp.bigquery import ReadFromBigQuery  # pylint: disable=import-outside-toplevel,g-import-not-at-top\n  except ImportError:\n    from apache_beam.io.gcp.bigquery import _ReadFromBigQuery as ReadFromBigQuery  # pylint: disable=import-outside-toplevel,g-import-not-at-top\n  return (pipeline\n          | \'ReadFromBigQuery\' >> ReadFromBigQuery(\n              query=query, use_standard_sql=True, project=project))\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _BigQueryToExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],  # pylint: disable=unused-argument\n    exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read from BigQuery and transform to TF examples.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, a BigQuery sql string.\n\n  Returns:\n    PCollection of TF examples.\n  """"""\n  converter = _BigQueryConverter(split_pattern)\n\n  # TODO(b/155441037): Clean up the usage of `runner` flag\n  # once ReadFromBigQuery performance on dataflow runner is on par\n  # with BigQuerySource, and clean up `project` once beam is upgraded to 2.22.\n  beam_pipeline_args = exec_properties[\'_beam_pipeline_args\']\n  pipeline_options = beam.options.pipeline_options.PipelineOptions(\n      beam_pipeline_args)\n  project = pipeline_options.get_all_options().get(\'project\')\n  use_dataflow_runner = pipeline_options.get_all_options().get(\'runner\') in [\n      \'dataflow\', \'DataflowRunner\'\n  ]\n\n  return (pipeline\n          | \'QueryTable\' >> _ReadFromBigQueryImpl(  # pylint: disable=no-value-for-parameter\n              query=split_pattern,\n              project=project,\n              use_bigquery_source=use_dataflow_runner)\n          | \'ToTFExample\' >> beam.Map(converter.RowToExample))\n\n\nclass Executor(base_example_gen_executor.BaseExampleGenExecutor):\n  """"""Generic TFX BigQueryExampleGen executor.""""""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for BigQuery to TF examples.""""""\n    return _BigQueryToExample\n'"
tfx/components/example_gen/big_query_example_gen/executor_test.py,22,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.big_query_example_gen.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport mock\nimport tensorflow as tf\nfrom google.cloud import bigquery\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen.big_query_example_gen import executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n_test_project = \'test-project\'\n\n\n@beam.ptransform_fn\ndef _MockReadFromBigQuery(pipeline, query, project, use_bigquery_source):  # pylint: disable=invalid-name, unused-argument\n  mock_query_results = []\n  for i in range(10000):\n    mock_query_result = {\n        \'i\': None if random.randrange(10) == 0 else i,\n        \'f\': None if random.randrange(10) == 0 else float(i),\n        \'s\': None if random.randrange(10) == 0 else str(i)\n    }\n    mock_query_results.append(mock_query_result)\n  return pipeline | beam.Create(mock_query_results)\n\n\n@beam.ptransform_fn\ndef _MockReadFromBigQuery2(pipeline, query, project, use_bigquery_source):  # pylint: disable=invalid-name, unused-argument\n  mock_query_results = [{\n      \'i\': 1,\n      \'i2\': [2, 3],\n      \'b\': True,\n      \'f\': 2.0,\n      \'f2\': [2.7, 3.8],\n      \'s\': \'abc\',\n      \'s2\': [\'abc\', \'def\']\n  }]\n  return pipeline | beam.Create(mock_query_results)\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    # Mock BigQuery result schema.\n    self._schema = [\n        bigquery.SchemaField(\'i\', \'INTEGER\', mode=\'REQUIRED\'),\n        bigquery.SchemaField(\'i2\', \'INTEGER\', mode=\'REPEATED\'),\n        bigquery.SchemaField(\'b\', \'BOOLEAN\', mode=\'REQUIRED\'),\n        bigquery.SchemaField(\'f\', \'FLOAT\', mode=\'REQUIRED\'),\n        bigquery.SchemaField(\'f2\', \'FLOAT\', mode=\'REPEATED\'),\n        bigquery.SchemaField(\'s\', \'STRING\', mode=\'REQUIRED\'),\n        bigquery.SchemaField(\'s2\', \'STRING\', mode=\'REPEATED\'),\n    ]\n    super(ExecutorTest, self).setUp()\n\n  @mock.patch.multiple(\n      executor,\n      _ReadFromBigQueryImpl=_MockReadFromBigQuery2,  # pylint: disable=invalid-name, unused-argument\n  )\n  @mock.patch.object(bigquery, \'Client\')\n  def testBigQueryToExample(self, mock_client):\n    # Mock query result schema for _BigQueryConverter.\n    mock_client.return_value.query.return_value.result.return_value.schema = self._schema\n\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline | \'ToTFExample\' >> executor._BigQueryToExample(\n              input_dict={},\n              exec_properties={\n                  \'_beam_pipeline_args\': [\'--project=\' + _test_project],\n              },\n              split_pattern=\'SELECT i, i2, b, f, f2, s, s2 FROM `fake`\'))\n\n      feature = {}\n      feature[\'i\'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[1]))\n      feature[\'i2\'] = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[2, 3]))\n      feature[\'b\'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[1]))\n      feature[\'f\'] = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[2.0]))\n      feature[\'f2\'] = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[2.7, 3.8]))\n      feature[\'s\'] = tf.train.Feature(\n          bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(\'abc\')]))\n      feature[\'s2\'] = tf.train.Feature(\n          bytes_list=tf.train.BytesList(\n              value=[tf.compat.as_bytes(\'abc\'),\n                     tf.compat.as_bytes(\'def\')]))\n      example_proto = tf.train.Example(\n          features=tf.train.Features(feature=feature))\n      util.assert_that(examples, util.equal_to([example_proto]))\n\n  @mock.patch.multiple(\n      executor,\n      _ReadFromBigQueryImpl=_MockReadFromBigQuery,  # pylint: disable=invalid-name, unused-argument\n  )\n  @mock.patch.object(bigquery, \'Client\')\n  def testDo(self, mock_client):\n    # Mock query result schema for _BigQueryConverter.\n    mock_client.return_value.query.return_value.result.return_value.schema = self._schema\n\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exe properties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'bq\', pattern=\'SELECT i, b, f, s FROM `fake`\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])),\n                preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    big_query_example_gen = executor.Executor()\n    big_query_example_gen.Do({}, output_dict, exec_properties)\n\n    # Check BigQuery example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/csv_example_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_gen/csv_example_gen/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX CsvExampleGen component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import component\nfrom tfx.components.example_gen.csv_example_gen import executor\nfrom tfx.proto import example_gen_pb2\n\n\nclass CsvExampleGen(component.FileBasedExampleGen):  # pylint: disable=protected-access\n  """"""Official TFX CsvExampleGen component.\n\n  The csv examplegen component takes csv data, and generates train\n  and eval examples for downsteam components.\n  """"""\n\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      input: types.Channel = None,  # pylint: disable=redefined-builtin\n      input_config: Optional[Union[example_gen_pb2.Input, Dict[Text,\n                                                               Any]]] = None,\n      output_config: Optional[Union[example_gen_pb2.Output, Dict[Text,\n                                                                 Any]]] = None,\n      example_artifacts: Optional[types.Channel] = None,\n      input_base: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct a CsvExampleGen component.\n\n    Args:\n      input: A Channel of type `standard_artifacts.ExternalArtifact`, which\n        includes one artifact whose uri is an external directory containing csv\n        files (required).\n      input_config: An example_gen_pb2.Input instance, providing input\n        configuration. If unset, the files under input_base will be treated as a\n        single split. If any field is provided as a RuntimeParameter,\n        input_config should be constructed as a dict with the same field names\n        as Input proto message.\n      output_config: An example_gen_pb2.Output instance, providing output\n        configuration. If unset, default splits will be \'train\' and \'eval\' with\n        size 2:1. If any field is provided as a RuntimeParameter,\n        output_config should be constructed as a dict with the same field names\n        as Output proto message.\n      example_artifacts: Optional channel of \'ExamplesPath\' for output train and\n        eval examples.\n      input_base: Backwards compatibility alias for the \'input\' argument.\n      instance_name: Optional unique instance name. Necessary if multiple\n        CsvExampleGen components are declared in the same pipeline.\n    """"""\n    super(CsvExampleGen, self).__init__(\n        input=input,\n        input_config=input_config,\n        output_config=output_config,\n        example_artifacts=example_artifacts,\n        input_base=input_base,\n        instance_name=instance_name)\n'"
tfx/components/example_gen/csv_example_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.csv_example_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.example_gen.csv_example_gen import component\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    csv_example_gen = component.CsvExampleGen(\n        input=channel_utils.as_channel([input_base]))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     csv_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = csv_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/csv_example_gen/executor.py,13,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX CSV example gen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, Iterable, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\nfrom tfx_bsl.coders import csv_decoder\n\nfrom tfx import types\nfrom tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n\n@beam.typehints.with_input_types(List[csv_decoder.CSVCell],\n                                 List[csv_decoder.ColumnInfo])\n@beam.typehints.with_output_types(tf.train.Example)\nclass _ParsedCsvToTfExample(beam.DoFn):\n  """"""A beam.DoFn to convert a parsed CSV line to a tf.Example.""""""\n\n  def __init__(self):\n    self._column_handlers = None\n\n  def _process_column_infos(self, column_infos: List[csv_decoder.ColumnInfo]):\n    column_handlers = []\n    for column_info in column_infos:\n      # pylint: disable=g-long-lambda\n      if column_info.type == csv_decoder.ColumnType.INT:\n        handler_fn = lambda csv_cell: tf.train.Feature(\n            int64_list=tf.train.Int64List(value=[int(csv_cell)]))\n      elif column_info.type == csv_decoder.ColumnType.FLOAT:\n        handler_fn = lambda csv_cell: tf.train.Feature(\n            float_list=tf.train.FloatList(value=[float(csv_cell)]))\n      elif column_info.type == csv_decoder.ColumnType.STRING:\n        handler_fn = lambda csv_cell: tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[csv_cell]))\n      else:\n        handler_fn = None\n      column_handlers.append((column_info.name, handler_fn))\n\n    self._column_handlers = column_handlers\n\n  def process(\n      self, csv_cells: List[csv_decoder.CSVCell],\n      column_infos: List[csv_decoder.ColumnInfo]) -> Iterable[tf.train.Example]:\n    if not self._column_handlers:\n      self._process_column_infos(column_infos)\n\n    # skip blank lines.\n    if not csv_cells:\n      return\n\n    if len(csv_cells) != len(self._column_handlers):\n      raise ValueError(\'Invalid CSV line: {}\'.format(csv_cells))\n\n    feature = {}\n    for csv_cell, (column_name, handler_fn) in zip(csv_cells,\n                                                   self._column_handlers):\n      if not csv_cell:\n        feature[column_name] = tf.train.Feature()\n        continue\n      if not handler_fn:\n        raise ValueError(\n            \'Internal error: failed to infer type of column {} while it\'\n            \'had at least some values {}\'.format(column_name, csv_cell))\n      feature[column_name] = handler_fn(csv_cell)\n    yield tf.train.Example(features=tf.train.Features(feature=feature))\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _CsvToExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read CSV files and transform to TF examples.\n\n  Note that each input split will be transformed by this function separately.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n      - input_base: input dir that contains csv data. csv files must have header\n        line.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, glob relative file pattern\n      that maps to input files with root directory given by input_base.\n\n  Returns:\n    PCollection of TF examples.\n\n  Raises:\n    RuntimeError: if split is empty or csv headers are not equal.\n  """"""\n  input_base_uri = artifact_utils.get_single_uri(input_dict[INPUT_KEY])\n  csv_pattern = os.path.join(input_base_uri, split_pattern)\n  absl.logging.info(\n      \'Processing input csv data {} to TFExample.\'.format(csv_pattern))\n\n  csv_files = tf.io.gfile.glob(csv_pattern)\n  if not csv_files:\n    raise RuntimeError(\n        \'Split pattern {} does not match any files.\'.format(csv_pattern))\n\n  column_names = io_utils.load_csv_column_names(csv_files[0])\n  for csv_file in csv_files[1:]:\n    if io_utils.load_csv_column_names(csv_file) != column_names:\n      raise RuntimeError(\n          \'Files in same split {} have different header.\'.format(csv_pattern))\n\n  parsed_csv_lines = (\n      pipeline\n      | \'ReadFromText\' >> beam.io.ReadFromText(\n          file_pattern=csv_pattern, skip_header_lines=1)\n      | \'ParseCSVLine\' >> beam.ParDo(csv_decoder.ParseCSVLine(delimiter=\',\')))\n  # TODO(b/155997704) clean this up once tfx_bsl makes a release.\n  if getattr(csv_decoder, \'PARSE_CSV_LINE_YIELDS_RAW_RECORDS\', False):\n    # parsed_csv_lines is the following tuple (parsed_lines, raw_records)\n    # we only want the parsed_lines.\n    parsed_csv_lines |= \'ExtractParsedCSVLines\' >> beam.Keys()\n  column_infos = beam.pvalue.AsSingleton(\n      parsed_csv_lines\n      | \'InferColumnTypes\' >> beam.CombineGlobally(\n          csv_decoder.ColumnTypeInferrer(column_names, skip_blank_lines=True)))\n\n  return (parsed_csv_lines\n          | \'ToTFExample\' >> beam.ParDo(_ParsedCsvToTfExample(), column_infos))\n\n\nclass Executor(BaseExampleGenExecutor):\n  """"""Generic TFX CSV example gen executor.""""""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for CSV to TF examples.""""""\n    return _CsvToExample\n'"
tfx/components/example_gen/csv_example_gen/executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.csv_example_gen.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.csv_example_gen import executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n\n    # Create input dict.\n    input_base = standard_artifacts.ExternalArtifact()\n    input_base.uri = os.path.join(input_data_dir, \'external\')\n    self._input_dict = {INPUT_KEY: [input_base]}\n    super(ExecutorTest, self).setUp()\n\n  def testCsvToExample(self):\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline\n          | \'ToTFExample\' >> executor._CsvToExample(\n              input_dict=self._input_dict,\n              exec_properties={},\n              split_pattern=\'csv/*\'))\n\n      def check_result(got):\n        # We use Python assertion here to avoid Beam serialization error in\n        # pickling tf.test.TestCase.\n        assert (15000 == len(got)), \'Unexpected example count\'\n        assert (18 == len(got[0].features.feature)), \'Example not match\'\n\n      util.assert_that(examples, check_result)\n\n  def testDo(self):\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(name=\'csv\', pattern=\'csv/*\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])),\n                preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    csv_example_gen = executor.Executor()\n    csv_example_gen.Do(self._input_dict, output_dict, exec_properties)\n\n    # Check CSV example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/custom_executors/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_gen/custom_executors/avro_component_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for using avro_executor with example_gen component.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport mock\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen.component import FileBasedExampleGen\nfrom tfx.components.example_gen.custom_executors import avro_executor\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.proto import example_gen_pb2\nfrom tfx.utils.dsl_utils import external_input\n\n\nclass ExampleGenComponentWithAvroExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExampleGenComponentWithAvroExecutorTest, self).setUp()\n    # Create input_base.\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n    self.avro_dir_path = os.path.join(input_data_dir, \'external\')\n\n    # Create input_config.\n    self.input_config = example_gen_pb2.Input(splits=[\n        example_gen_pb2.Input.Split(name=\'avro\', pattern=\'avro/*.avro\'),\n    ])\n\n    # Create output_config.\n    self.output_config = example_gen_pb2.Output(\n        split_config=example_gen_pb2.SplitConfig(splits=[\n            example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n            example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1)\n        ]))\n\n  @mock.patch.object(publisher, \'Publisher\')\n  def testRun(self, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n\n    example_gen = FileBasedExampleGen(\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            avro_executor.Executor),\n        input=external_input(self.avro_dir_path),\n        input_config=self.input_config,\n        output_config=self.output_config,\n        instance_name=\'AvroExampleGen\')\n\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    pipeline_root = os.path.join(output_data_dir, \'Test\')\n    tf.io.gfile.makedirs(pipeline_root)\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'Test\', pipeline_root=pipeline_root, run_id=\'123\')\n\n    driver_args = data_types.DriverArgs(enable_cache=True)\n\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.sqlite.SetInParent()\n    metadata_connection = metadata.Metadata(connection_config)\n\n    launcher = in_process_component_launcher.InProcessComponentLauncher.create(\n        component=example_gen,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=[],\n        additional_pipeline_args={})\n    self.assertEqual(\n        launcher._component_info.component_type,\n        \'.\'.join([FileBasedExampleGen.__module__,\n                  FileBasedExampleGen.__name__]))\n\n    launcher.launch()\n    mock_publisher.return_value.publish_execution.assert_called_once()\n\n    # Get output paths.\n    examples = example_gen.outputs[\'examples\'].get()[0]\n\n    # Check Avro example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/custom_executors/avro_executor.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Avro based TFX example gen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.utils import dict_to_example\nfrom tfx.types import artifact_utils\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _AvroToExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read Avro files and transform to TF examples.\n\n  Note that each input split will be transformed by this function separately.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n      - input_base: input dir that contains Avro data.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, glob relative file pattern\n      that maps to input files with root directory given by input_base.\n\n  Returns:\n    PCollection of TF examples.\n  """"""\n  input_base_uri = artifact_utils.get_single_uri(input_dict[INPUT_KEY])\n  avro_pattern = os.path.join(input_base_uri, split_pattern)\n  absl.logging.info(\n      \'Processing input avro data {} to TFExample.\'.format(avro_pattern))\n\n  return (pipeline\n          | \'ReadFromAvro\' >> beam.io.ReadFromAvro(avro_pattern)\n          | \'ToTFExample\' >> beam.Map(dict_to_example))\n\n\nclass Executor(BaseExampleGenExecutor):\n  """"""TFX example gen executor for processing avro format.\n\n  Data type conversion:\n    integer types will be converted to tf.train.Feature with tf.train.Int64List.\n    float types will be converted to tf.train.Feature with tf.train.FloatList.\n    string types will be converted to tf.train.Feature with tf.train.BytesList\n      and utf-8 encoding.\n\n    Note that,\n      Single value will be converted to a list of that single value.\n      Missing value will be converted to empty tf.train.Feature().\n\n    For details, check the dict_to_example function in example_gen.utils.\n\n\n  Example usage:\n\n    from tfx.components.example_gen.component import\n    FileBasedExampleGen\n    from tfx.components.example_gen.custom_executors import\n    avro_executor\n    from tfx.utils.dsl_utils import external_input\n\n    example_gen = FileBasedExampleGen(\n        input=external_input(avro_dir_path),\n        executor_class=avro_executor.Executor)\n  """"""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for avro to TF examples.""""""\n    return _AvroToExample\n'"
tfx/components/example_gen/custom_executors/avro_executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.custom_executos.avro_executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.custom_executors import avro_executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n\n    # Create input dict.\n    input_base = standard_artifacts.ExternalArtifact()\n    input_base.uri = os.path.join(input_data_dir, \'external\')\n    self._input_dict = {INPUT_KEY: [input_base]}\n\n  def testAvroToExample(self):\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline\n          | \'ToTFExample\' >> avro_executor._AvroToExample(\n              input_dict=self._input_dict,\n              exec_properties={},\n              split_pattern=\'avro/*.avro\'))\n\n      def check_result(got):\n        # We use Python assertion here to avoid Beam serialization error in\n        # pickling tf.test.TestCase.\n        assert (10000 == len(got)), \'Unexpected example count\'\n        assert (18 == len(got[0].features.feature)), \'Example not match\'\n\n      util.assert_that(examples, check_result)\n\n  def testDo(self):\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'avro\', pattern=\'avro/*.avro\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])),\n                preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    avro_example_gen = avro_executor.Executor()\n    avro_example_gen.Do(self._input_dict, output_dict, exec_properties)\n\n    # Check Avro example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/custom_executors/parquet_component_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for using parquet_executor with example_gen component.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport mock\nimport tensorflow as tf\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen.component import FileBasedExampleGen\nfrom tfx.components.example_gen.custom_executors import parquet_executor\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import publisher\nfrom tfx.orchestration.launcher import in_process_component_launcher\nfrom tfx.proto import example_gen_pb2\nfrom tfx.utils.dsl_utils import external_input\n\n\nclass ExampleGenComponentWithParquetExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExampleGenComponentWithParquetExecutorTest, self).setUp()\n    # Create input_base.\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n    self.parquet_dir_path = os.path.join(input_data_dir, \'external\')\n\n    # Create input_config.\n    self.input_config = example_gen_pb2.Input(splits=[\n        example_gen_pb2.Input.Split(name=\'parquet\',\n                                    pattern=\'parquet/*.parquet\'),\n    ])\n\n    # Create output_config.\n    self.output_config = example_gen_pb2.Output(\n        split_config=example_gen_pb2.SplitConfig(splits=[\n            example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n            example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1)\n        ]))\n\n  @mock.patch.object(publisher, \'Publisher\')\n  def testRun(self, mock_publisher):\n    mock_publisher.return_value.publish_execution.return_value = {}\n\n    example_gen = FileBasedExampleGen(\n        custom_executor_spec=executor_spec.ExecutorClassSpec(\n            parquet_executor.Executor),\n        input=external_input(self.parquet_dir_path),\n        input_config=self.input_config,\n        output_config=self.output_config,\n        instance_name=\'ParquetExampleGen\')\n\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    pipeline_root = os.path.join(output_data_dir, \'Test\')\n    tf.io.gfile.makedirs(pipeline_root)\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=\'Test\', pipeline_root=pipeline_root, run_id=\'123\')\n\n    driver_args = data_types.DriverArgs(enable_cache=True)\n\n    connection_config = metadata_store_pb2.ConnectionConfig()\n    connection_config.sqlite.SetInParent()\n    metadata_connection = metadata.Metadata(connection_config)\n\n    launcher = in_process_component_launcher.InProcessComponentLauncher.create(\n        component=example_gen,\n        pipeline_info=pipeline_info,\n        driver_args=driver_args,\n        metadata_connection=metadata_connection,\n        beam_pipeline_args=[],\n        additional_pipeline_args={})\n    self.assertEqual(\n        launcher._component_info.component_type,\n        \'.\'.join([FileBasedExampleGen.__module__,\n                  FileBasedExampleGen.__name__]))\n\n    launcher.launch()\n    mock_publisher.return_value.publish_execution.assert_called_once()\n\n    # Get output paths.\n    examples = example_gen.outputs[\'examples\'].get()[0]\n\n    # Check parquet example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/custom_executors/parquet_executor.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Parquet based TFX example gen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.utils import dict_to_example\nfrom tfx.types import artifact_utils\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _ParquetToExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read Parquet files and transform to TF examples.\n\n  Note that each input split will be transformed by this function separately.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n      - input_base: input dir that contains Parquet data.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, glob relative file pattern\n      that maps to input files with root directory given by input_base.\n\n  Returns:\n    PCollection of TF examples.\n  """"""\n  input_base_uri = artifact_utils.get_single_uri(input_dict[INPUT_KEY])\n  parquet_pattern = os.path.join(input_base_uri, split_pattern)\n  absl.logging.info(\n      \'Processing input parquet data {} to TFExample.\'.format(parquet_pattern))\n\n  return (pipeline\n          # TODO(jyzhao): support per column read by input_config.\n          | \'ReadFromParquet\' >> beam.io.ReadFromParquet(parquet_pattern)\n          | \'ToTFExample\' >> beam.Map(dict_to_example))\n\n\nclass Executor(BaseExampleGenExecutor):\n  """"""TFX example gen executor for processing parquet format.\n\n  Data type conversion:\n    integer types will be converted to tf.train.Feature with tf.train.Int64List.\n    float types will be converted to tf.train.Feature with tf.train.FloatList.\n    string types will be converted to tf.train.Feature with tf.train.BytesList\n      and utf-8 encoding.\n\n    Note that,\n      Single value will be converted to a list of that single value.\n      Missing value will be converted to empty tf.train.Feature().\n      Parquet data might lose precision, e.g., int96.\n\n    For details, check the dict_to_example function in example_gen.utils.\n\n\n  Example usage:\n\n    from tfx.components.example_gen.component import\n    FileBasedExampleGen\n    from tfx.components.example_gen.custom_executors import\n    parquet_executor\n    from tfx.utils.dsl_utils import external_input\n\n    example_gen = FileBasedExampleGen(\n        input=external_input(parquet_dir_path),\n        executor_class=parquet_executor.Executor)\n  """"""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for parquet to TF examples.""""""\n    return _ParquetToExample\n'"
tfx/components/example_gen/custom_executors/parquet_executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.custom_executors.parquet_executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.custom_executors import parquet_executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n\n    # Create input dict.\n    input_base = standard_artifacts.ExternalArtifact()\n    input_base.uri = os.path.join(input_data_dir, \'external\')\n    self._input_dict = {INPUT_KEY: [input_base]}\n    super(ExecutorTest, self).setUp()\n\n  def testParquetToExample(self):\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline\n          | \'ToTFExample\' >> parquet_executor._ParquetToExample(\n              input_dict=self._input_dict,\n              exec_properties={},\n              split_pattern=\'parquet/*\'))\n\n      def check_result(got):\n        # We use Python assertion here to avoid Beam serialization error in\n        # pickling tf.test.TestCase.\n        assert (10000 == len(got)), \'Unexpected example count\'\n        assert (18 == len(got[0].features.feature)), \'Example not match\'\n\n      util.assert_that(examples, check_result)\n\n  def testDo(self):\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'parquet\', pattern=\'parquet/*\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])),\n                preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    parquet_example_gen = parquet_executor.Executor()\n    parquet_example_gen.Do(self._input_dict, output_dict, exec_properties)\n\n    # Check Parquet example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/import_example_gen/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/example_gen/import_example_gen/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX ImportExampleGen component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, Optional, Text, Union\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import component\nfrom tfx.components.example_gen.import_example_gen import executor\nfrom tfx.proto import example_gen_pb2\n\n\nclass ImportExampleGen(component.FileBasedExampleGen):  # pylint: disable=protected-access\n  """"""Official TFX ImportExampleGen component.\n\n  The ImportExampleGen component takes TFRecord files with TF Example data\n  format, and generates train and eval examples for downsteam components.\n  This component provides consistent and configurable partition, and it also\n  shuffle the dataset for ML best practice.\n  """"""\n\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(\n      self,\n      input: types.Channel = None,  # pylint: disable=redefined-builtin\n      input_config: Optional[Union[example_gen_pb2.Input, Dict[Text,\n                                                               Any]]] = None,\n      output_config: Optional[Union[example_gen_pb2.Output, Dict[Text,\n                                                                 Any]]] = None,\n      example_artifacts: Optional[types.Channel] = None,\n      input_base: Optional[types.Channel] = None,\n      instance_name: Optional[Text] = None):\n    """"""Construct an ImportExampleGen component.\n\n    Args:\n      input: A Channel of type `standard_artifacts.ExternalArtifact`, which\n        includes one artifact whose uri is an external directory containing\n        TFRecord files (required).\n      input_config: An example_gen_pb2.Input instance, providing input\n        configuration. If unset, the files under input_base will be treated as a\n        single split. If any field is provided as a RuntimeParameter,\n        input_config should be constructed as a dict with the same field names\n        as Input proto message.\n      output_config: An example_gen_pb2.Output instance, providing output\n        configuration. If unset, default splits will be \'train\' and \'eval\' with\n        size 2:1. If any field is provided as a RuntimeParameter,\n        output_config should be constructed as a dict with the same field names\n        as Output proto message.\n      example_artifacts: Optional channel of \'ExamplesPath\' for output train and\n        eval examples.\n      input_base: Backwards compatibility alias for the \'input\' argument.\n      instance_name: Optional unique instance name. Necessary if multiple\n        ImportExampleGen components are declared in the same pipeline.\n    """"""\n    super(ImportExampleGen, self).__init__(\n        input=input,\n        input_config=input_config,\n        output_config=output_config,\n        example_artifacts=example_artifacts,\n        input_base=input_base,\n        instance_name=instance_name)\n'"
tfx/components/example_gen/import_example_gen/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.import_example_gen.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.components.example_gen.import_example_gen import component\nfrom tfx.types import artifact_utils\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def testConstruct(self):\n    input_base = standard_artifacts.ExternalArtifact()\n    import_example_gen = component.ImportExampleGen(\n        input=channel_utils.as_channel([input_base]))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     import_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = import_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/example_gen/import_example_gen/executor.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX ImportExampleGen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport absl\nimport apache_beam as beam\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.types import artifact_utils\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _ImportExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],\n    exec_properties: Dict[Text, Any],  # pylint: disable=unused-argument\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read TFRecord files to PCollection of TF examples.\n\n  Note that each input split will be transformed by this function separately.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n      - input_base: input dir that contains tf example data.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, glob relative file pattern\n      that maps to input files with root directory given by input_base.\n\n  Returns:\n    PCollection of TF examples.\n  """"""\n  input_base_uri = artifact_utils.get_single_uri(input_dict[INPUT_KEY])\n  input_split_pattern = os.path.join(input_base_uri, split_pattern)\n  absl.logging.info(\n      \'Reading input TFExample data {}.\'.format(input_split_pattern))\n\n  # TODO(jyzhao): profile input examples.\n  return (pipeline\n          # TODO(jyzhao): support multiple input format.\n          | \'ReadFromTFRecord\' >>\n          beam.io.ReadFromTFRecord(file_pattern=input_split_pattern)\n          # TODO(jyzhao): consider move serialization out of base example gen.\n          | \'ToTFExample\' >> beam.Map(tf.train.Example.FromString))\n\n\nclass Executor(BaseExampleGenExecutor):\n  """"""Generic TFX import example gen executor.""""""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for importing TF examples.""""""\n    return _ImportExample\n'"
tfx/components/example_gen/import_example_gen/executor_test.py,7,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.example_gen.import_example_gen.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport tensorflow as tf\nfrom google.protobuf import json_format\nfrom tfx.components.example_gen.base_example_gen_executor import INPUT_KEY\nfrom tfx.components.example_gen.import_example_gen import executor\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    input_data_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \'testdata\')\n\n    # Create input dict.\n    input_base = standard_artifacts.ExternalArtifact()\n    input_base.uri = os.path.join(input_data_dir, \'external\')\n    self._input_dict = {INPUT_KEY: [input_base]}\n\n  def testImportExample(self):\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline\n          | \'ToTFExample\' >> executor._ImportExample(\n              input_dict=self._input_dict,\n              exec_properties={},\n              split_pattern=\'tfrecord/*\'))\n\n      def check_result(got):\n        # We use Python assertion here to avoid Beam serialization error in\n        # pickling tf.test.TestCase.\n        assert (15000 == len(got)), \'Unexpected example count\'\n        assert (18 == len(got[0].features.feature)), \'Example not match\'\n\n      util.assert_that(examples, check_result)\n\n  def testDo(self):\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exec proterties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'tfrecord\', pattern=\'tfrecord/*\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ])),\n                preserving_proto_field_name=True)\n    }\n\n    # Run executor.\n    import_example_gen = executor.Executor()\n    import_example_gen.Do(self._input_dict, output_dict, exec_properties)\n\n    # Check import_example_gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/model_server_clients/__init__.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Modules of all model server clients that correspond to serving binary.""""""\n'"
tfx/components/infra_validator/model_server_clients/base_client.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module for shared interface of every model server clients.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport time\n\nfrom absl import logging\nimport six\nfrom typing import List\n\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import types\n\n\nclass BaseModelServerClient(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Common interface for all model server clients.""""""\n\n  @abc.abstractmethod\n  def _GetServingStatus(self) -> types.ModelServingStatus:\n    """"""Check whether the model is available for query or not.\n\n    Returns:\n      A ModelServingStatus.\n    """"""\n    pass\n\n  def WaitUntilModelLoaded(self, deadline: float,\n                           polling_interval_sec: int) -> None:\n    """"""Wait until model is loaded and available.\n\n    Args:\n      deadline: A deadline time in UTC timestamp (in seconds).\n      polling_interval_sec: GetServingStatus() polling interval.\n\n    Raises:\n      DeadlineExceeded: When deadline exceeded before model is ready.\n      ValidationFailed: If validation failed explicitly.\n    """"""\n    while time.time() < deadline:\n      status = self._GetServingStatus()\n      if status == types.ModelServingStatus.NOT_READY:\n        logging.log_every_n_seconds(\n            level=logging.INFO,\n            n_seconds=10,\n            msg=\'Waiting for model to be loaded...\')\n        time.sleep(polling_interval_sec)\n        continue\n      elif status == types.ModelServingStatus.UNAVAILABLE:\n        raise error_types.ValidationFailed(\n            \'Model server failed to load the model.\')\n      else:\n        logging.info(\'Model is successfully loaded.\')\n        return\n\n    raise error_types.DeadlineExceeded(\n        \'Deadline exceeded while waiting the model to be loaded.\')\n\n  @abc.abstractmethod\n  def _SendRequest(self, request: types.Request) -> None:\n    """"""Send a request to the model server.\n\n    Args:\n      request: A request proto.\n    """"""\n    pass\n\n  def SendRequests(self, requests: List[types.Request]) -> None:\n    """"""Send requests to the model server.\n\n    Args:\n      requests: A list of request protos.\n\n    Raises:\n      ValidationFailed: If error occurred while sending requests.\n    """"""\n    for r in requests:\n      try:\n        self._SendRequest(r)\n      except Exception as original_error:  # pylint: disable=broad-except\n        six.raise_from(\n            error_types.ValidationFailed(\n                \'Model server failed to respond to the request {}\'.format(r)),\n            original_error)\n'"
tfx/components/infra_validator/model_server_clients/tensorflow_serving_client.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module for TensorFlowServingClient.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\nimport grpc\nfrom typing import Text\n\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import get_model_status_pb2\nfrom tensorflow_serving.apis import model_pb2\nfrom tensorflow_serving.apis import model_service_pb2_grpc\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import prediction_service_pb2_grpc\nfrom tensorflow_serving.apis import regression_pb2\nfrom tfx.components.infra_validator import types\nfrom tfx.components.infra_validator.model_server_clients import base_client\n\nState = get_model_status_pb2.ModelVersionStatus.State\n\n\nclass TensorFlowServingClient(base_client.BaseModelServerClient):\n  """"""A model server client for TensorFlow Serving.\n\n  It uses gRPC client to talk to TensorFlow Serving server.\n  """"""\n\n  def __init__(self, endpoint: Text, model_name: Text):\n    # Note that the channel instance is automatically closed (unsubscribed) on\n    # deletion, so we don\'t have to manually close this on __del__.\n    self._channel = grpc.insecure_channel(endpoint)\n    self._model_name = model_name\n    self._model_service = model_service_pb2_grpc.ModelServiceStub(self._channel)\n    self._prediction_service = prediction_service_pb2_grpc.PredictionServiceStub(self._channel)  # pylint: disable=line-too-long\n\n  def _GetModelStatus(self) -> get_model_status_pb2.GetModelStatusResponse:\n    """"""Call GetModelStatus() from model service.\n\n    https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto\n\n    Returns:\n      GetModelStatusResponse from GetModelStatus().\n    """"""\n    request = get_model_status_pb2.GetModelStatusRequest(\n        model_spec=model_pb2.ModelSpec(name=self._model_name))\n    return self._model_service.GetModelStatus(request)\n\n  def _GetServingStatus(self) -> types.ModelServingStatus:\n    """"""Check whether the model is available for query or not.\n\n    In TensorFlow Serving, model is READY if and only if the state from\n    _GetModelStatus() is AVAILABLE. If returned state is END, it will never\n    become READY therefore returns UNAVAILABLE. Otherwise it will return\n    NOT_READY.\n\n    Returns:\n      A ModelState.\n    """"""\n    try:\n      resp = self._GetModelStatus()\n    except grpc.RpcError as e:\n      logging.info(\'Error while obtaining model status:\\n%s\', e)\n      return types.ModelServingStatus.NOT_READY\n\n    # When no versions available. (empty list)\n    if not resp.model_version_status:\n      return types.ModelServingStatus.NOT_READY\n\n    # Wait until all serving model versions are in AVAILABLE state.\n    # In TensorFlow Serving, model state lifecycle is\n    #     START -> LOADING -> AVAILABLE -> UNLOADING -> END\n    # if loaded successfully or\n    #     START -> LOADING -> END\n    # if loaded unsuccessfully. The model is available iff state is AVAILABLE.\n    # The model is unavailable for goods iff state is END.\n    # https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/get_model_status.proto\n    if all(mvs.state == State.AVAILABLE\n           for mvs in resp.model_version_status):\n      return types.ModelServingStatus.READY\n    if any(mvs.state == State.END\n           for mvs in resp.model_version_status):\n      return types.ModelServingStatus.UNAVAILABLE\n    return types.ModelServingStatus.NOT_READY\n\n  def _SendRequest(self, request: types.Request) -> None:\n    if isinstance(request, classification_pb2.ClassificationRequest):\n      self._prediction_service.Classify(request)\n    elif isinstance(request, regression_pb2.RegressionRequest):\n      self._prediction_service.Regress(request)\n    elif isinstance(request, predict_pb2.PredictRequest):\n      self._prediction_service.Predict(request)\n    else:\n      raise NotImplementedError(\'Unsupported request type {}\'.format(\n          type(request).__name__))\n'"
tfx/components/infra_validator/model_server_clients/tensorflow_serving_client_test.py,2,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.infra_validator.model_server_clients.tensorflow_serving_client.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport grpc\nimport mock\nimport tensorflow as tf\nfrom typing import Any, Dict, Text\n\nfrom google.protobuf import json_format\nfrom tensorflow_serving.apis import classification_pb2\nfrom tensorflow_serving.apis import get_model_status_pb2\nfrom tensorflow_serving.apis import regression_pb2\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import types\nfrom tfx.components.infra_validator.model_server_clients import tensorflow_serving_client\n\n\ndef _make_response(\n    payload: Dict[Text, Any]) -> get_model_status_pb2.GetModelStatusResponse:\n  result = get_model_status_pb2.GetModelStatusResponse()\n  json_format.ParseDict(payload, result)\n  return result\n\n\nclass TensorflowServingClientTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TensorflowServingClientTest, self).setUp()\n    self.model_stub_patcher = mock.patch(\'tensorflow_serving.apis.model_service_pb2_grpc.ModelServiceStub\')  # pylint: disable=line-too-long\n    self.model_stub_cls = self.model_stub_patcher.start()\n    self.model_stub = self.model_stub_cls.return_value\n    self.prediction_stub_patcher = mock.patch(\'tensorflow_serving.apis.prediction_service_pb2_grpc.PredictionServiceStub\')  # pylint: disable=line-too-long\n    self.prediction_stub_cls = self.prediction_stub_patcher.start()\n    self.prediction_stub = self.prediction_stub_cls.return_value\n\n  def tearDown(self):\n    super(TensorflowServingClientTest, self).tearDown()\n    self.model_stub_patcher.stop()\n    self.prediction_stub_patcher.stop()\n\n  def testGetModelState_ReturnsReady_IfAllAvailable(self):\n    # Prepare stub and client.\n    self.model_stub.GetModelStatus.return_value = _make_response({\n        \'model_version_status\': [\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'AVAILABLE\'}\n        ]\n    })\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call.\n    result = client._GetServingStatus()\n\n    # Check result.\n    self.assertEqual(result, types.ModelServingStatus.READY)\n\n  def testGetModelState_ReturnsNotReady_IfAnyStateNotAvailable(self):\n    # Prepare stub and client.\n    self.model_stub.GetModelStatus.return_value = _make_response({\n        \'model_version_status\': [\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'LOADING\'}\n        ]\n    })\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call.\n    result = client._GetServingStatus()\n\n    # Check result.\n    self.assertEqual(result, types.ModelServingStatus.NOT_READY)\n\n  def testGetModelState_ReturnsUnavailable_IfAnyStateEnded(self):\n    # Prepare stub and client.\n    self.model_stub.GetModelStatus.return_value = _make_response({\n        \'model_version_status\': [\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'AVAILABLE\'},\n            {\'state\': \'END\'}\n        ]\n    })\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call.\n    result = client._GetServingStatus()\n\n    # Check result.\n    self.assertEqual(result, types.ModelServingStatus.UNAVAILABLE)\n\n  def testGetModelState_ReturnsNotReady_IfEmptyState(self):\n    # Prepare stub and client.\n    self.model_stub.GetModelStatus.return_value = _make_response({\n        \'model_version_status\': []  # Empty\n    })\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Calls\n    result = client._GetServingStatus()\n\n    # Check result.\n    self.assertEqual(result, types.ModelServingStatus.NOT_READY)\n\n  def testGetModelState_ReturnsNotReady_IfServerUnavailable(self):\n    # Prepare stub and client.\n    self.model_stub.GetModelStatus.side_effect = grpc.RpcError\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call.\n    result = client._GetServingStatus()\n\n    # Check result.\n    self.assertEqual(result, types.ModelServingStatus.NOT_READY)\n\n  def testIssueRequests_NoErrorIfSucceeded(self):\n    # Prepare requests and client.\n    r1 = classification_pb2.ClassificationRequest()\n    r2 = classification_pb2.ClassificationRequest()\n    r3 = regression_pb2.RegressionRequest()\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call.\n    client.SendRequests([r1, r2, r3])\n\n    # Check calls\n    self.prediction_stub.Classify.assert_called_with(r1)\n    self.prediction_stub.Classify.assert_called_with(r2)\n    self.prediction_stub.Regress.assert_called_with(r3)\n\n  def testIssueRequests_RaiseValueErrorOnUnrecognizedRequestType(self):\n    # Prepare requests and client.\n    not_a_request = \'i am a request\'\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n\n    # Call\n    with self.assertRaises(error_types.ValidationFailed):\n      client.SendRequests([not_a_request])\n\n  def testIssueRequests_RaiseRpcErrorIfRpcFailed(self):\n    # Prepare client and a side effect.\n    request = classification_pb2.ClassificationRequest()\n    client = tensorflow_serving_client.TensorFlowServingClient(\n        \'localhost:1234\', \'a_model_name\')\n    self.prediction_stub.Classify.side_effect = grpc.RpcError\n\n    # Call.\n    with self.assertRaises(error_types.ValidationFailed):\n      client.SendRequests([request])\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/model_server_runners/__init__.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/infra_validator/model_server_runners/base_runner.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module for shared interface of every model server runners.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\n\nimport six\nfrom typing import Text\n\n\nclass BaseModelServerRunner(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Shared interface of all model server runners.\n\n  Model server runner is responsible for managing the model server job and\n  relevant resources in the serving platform. For example, model server runner\n  for kubernetes will launch a Pod of model server with required resources\n  allocated, and tear down all the kubernetes resources once infra validation\n  is done. Note that model server runner does *not* interact with model server\n  app.\n\n  Model server job have 5 states: Initial, Scheduled, Running, Aborted, and End.\n  Each state transition is depicted in the diagram below.\n\n  ```\n             +-----------+\n             |  Initial  |\n             +-----+-----+\n                   | Start()\n             +-----v-----+\n          +--+ Scheduled |\n          |  +-----+-----+\n          |        | WaitUntilRunning()\n          |  +-----v-----+\n          +--+  Running  |\n          |  +-----+-----+\n          |        |\n    +-----v-----+  |\n    |  Aborted  +--+ Stop()\n    +-----------+  |\n                   |\n             +-----v-----+\n             |    End    |\n             +-----------+\n  ```\n\n  At any step, the job can be aborted in the serving platform. Model server\n  runner will NOT recover a job from failure (even if it can) and regard the\n  abortion as a validation failure.\n\n  All the infra validation logic (waiting for model loaded, sending requests,\n  measuring metrics, etc.) will happen when model server job has reached Running\n  state. This is not a scope of model server runner work.\n\n  Depending on the serving platform, some of the states might be the same. For\n  example, in a GCP cloud AI prediction service we have a global model server\n  instance running, which makes Scheduled state and Running state\n  indistinguishable. In such case, `WaitUntilRunning()` action will be a no-op.\n  """"""\n\n  @abc.abstractmethod\n  def __repr__(self) -> Text:\n    pass\n\n  @abc.abstractmethod\n  def GetEndpoint(self) -> Text:\n    """"""Get an endpoint to the model server to connect to.\n\n    Endpoint will be available after the model server job has reached the\n    Running state.\n\n    Raises:\n      AssertionError: if runner hasn\'t reached the Running state.\n    """"""\n\n  @abc.abstractmethod\n  def Start(self) -> None:\n    """"""Start the model server in non-blocking manner.\n\n    `Start()` will transition the job state from Initial to Scheduled. Serving\n    platform will turn the job into Running state in the future.\n\n    In `Start()`, model server runner should prepare the resources model server\n    requires including config files, environment variables, volumes, proper\n    authentication, computing resource allocation, etc.. Cleanup for the\n    resources does not happen automatically, and you should call `Stop()` to do\n    that if you have ever called `Start()`.\n\n    It is not allowed to run `Start()` twice. If you need to restart the job,\n    you should create another model server runner instance.\n    """"""\n\n  @abc.abstractmethod\n  def WaitUntilRunning(self, deadline: float) -> None:\n    """"""Wait until model server job is running.\n\n    When this method is returned without error, the model server job is in the\n    Running state where you can perform all the infra validation logic. It does\n    not guarantee that model server job would remain in the Running state\n    forever, (e.g. preemption could happen in some serving platform) and any\n    kind of infra validation logic failure can be caused from model server job\n    not being in the Running state. Still, it is a validation failure and we\n    blame model for this.\n\n    Args:\n      deadline: A deadline time in UTC timestamp (in seconds).\n    Returns:\n      Whether the model is available or not.\n    """"""\n\n  @abc.abstractmethod\n  def Stop(self) -> None:\n    """"""Stop the model server in blocking manner.\n\n    Model server job would be gracefully stopped once infra validation logic is\n    done. Here is the place you need to cleanup every resources you\'ve created\n    in the `Start()`. It is recommended not to raise error during the `Stop()`\n    as it will usually be called in the `finally` block.\n\n    `Stop()` is guaranteed to be called if `Start()` is ever called, unless the\n    process dies unexpectedly due to external factors (e.g. SIGKILL). `Stop()`\n    can be called even when `Start()` was not completed. `Stop()` should not\n    assume the completion of `Start()`.\n\n    `Stop()` is also called when graceful shutdown for the *executor* (not\n    model server) is requested. `Stop()` method should be finished within the\n    graceful shutdown period, and it is perfectly fine to add a retry logic\n    inside `Stop()` until the deadline is met.\n    """"""\n'"
tfx/components/infra_validator/model_server_runners/kubernetes_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Model server runner for kubernetes runtime.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nimport sys\nimport time\nfrom typing import Optional, Text\n\nfrom absl import logging\nfrom apache_beam.utils import retry\nfrom kubernetes import client as k8s_client\nfrom kubernetes.client import rest\nimport six\n\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.components.infra_validator.model_server_runners import base_runner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.utils import kube_utils\n\n_DEFAULT_POLLING_INTERVAL_SEC = 5\n_DEFAULT_ACTIVE_DEADLINE_SEC = int(datetime.timedelta(hours=24).total_seconds())\n\n_NUM_RETRIES = 4  # Total 5 attempts\n# Total delay is smaller than 2 + 4 + 8 + 16 = 30 seconds which is the default\n# kubernetes graceful shutdown period.\n_INITIAL_BACKOFF_DELAY_SEC = 2.0\n\n# Alias enums.\n_PodPhase = kube_utils.PodPhase\n_RestartPolicy = kube_utils.RestartPolicy\n_AccessMode = kube_utils.PersistentVolumeAccessMode\n\n# Kubernetes resource metadata values\n_APP_KEY = \'app\'\n_MODEL_SERVER_POD_NAME_PREFIX = \'tfx-infraval-modelserver-\'\n_MODEL_SERVER_APP_LABEL = \'tfx-infraval-modelserver\'\n_MODEL_SERVER_CONTAINER_NAME = \'model-server\'\n_MODEL_SERVER_MODEL_VOLUME_NAME = \'model-volume\'\n\n\n# TODO(b/149534564): Use pathlib.\ndef _is_subdirectory(maybe_parent: Text, maybe_child: Text) -> bool:\n  paren = os.path.realpath(maybe_parent).split(os.path.sep)\n  child = os.path.realpath(maybe_child).split(os.path.sep)\n  return len(paren) <= len(child) and all(a == b for a, b in zip(paren, child))\n\n\ndef _get_container_or_error(\n    pod: k8s_client.V1Pod, container_name: Text) -> k8s_client.V1Container:\n  for container in pod.spec.containers:\n    if container.name == container_name:\n      return container\n  raise ValueError(\n      \'Unable to find {} container from the pod (found {}).\'.format(\n          container_name, [c.name for c in pod.spec.containers]))\n\n\ndef _api_exception_retry_filter(exception: Exception):\n  return isinstance(exception, rest.ApiException)\n\n\nclass KubernetesRunner(base_runner.BaseModelServerRunner):\n  """"""A model server runner that launches model server in kubernetes cluster.""""""\n\n  def __init__(\n      self,\n      model_path: Text,\n      serving_binary: serving_bins.ServingBinary,\n      serving_spec: infra_validator_pb2.ServingSpec):\n    """"""Create a kubernetes model server runner.\n\n    Args:\n      model_path: An IV-flavored model path. (See model_path_utils.py)\n      serving_binary: A ServingBinary to run.\n      serving_spec: A ServingSpec instance.\n    """"""\n    assert serving_spec.WhichOneof(\'serving_platform\') == \'kubernetes\', (\n        \'ServingSpec configuration mismatch.\')\n    self._config = serving_spec.kubernetes\n\n    self._model_path = model_path\n    self._serving_binary = serving_binary\n    self._serving_spec = serving_spec\n    self._k8s_core_api = kube_utils.make_core_v1_api()\n    if not kube_utils.is_inside_kfp():\n      raise NotImplementedError(\n          \'KubernetesRunner should be running inside KFP.\')\n    self._executor_pod = kube_utils.get_current_kfp_pod(self._k8s_core_api)\n    self._executor_container = _get_container_or_error(\n        self._executor_pod,\n        container_name=kube_utils.ARGO_MAIN_CONTAINER_NAME)\n    self._namespace = kube_utils.get_kfp_namespace()\n    self._label_dict = {\n        _APP_KEY: _MODEL_SERVER_APP_LABEL,\n    }\n    # Pod name would be populated once creation request sent.\n    self._pod_name = None\n    # Endpoint would be populated once the Pod is running.\n    self._endpoint = None\n\n  def __repr__(self):\n    return \'KubernetesRunner(image: {image}, pod_name: {pod_name})\'.format(\n        image=self._serving_binary.image,\n        pod_name=self._pod_name)\n\n  def GetEndpoint(self) -> Text:\n    assert self._endpoint is not None, (\n        \'self._endpoint is not ready. You should call Start() and \'\n        \'WaitUntilRunning() first.\')\n    return self._endpoint\n\n  def Start(self) -> None:\n    assert not self._pod_name, (\n        \'You cannot start model server multiple times.\')\n\n    # We\'re creating a Pod rather than a Deployment as we\'re relying on\n    # executor\'s retry mechanism for failure recovery, and the death of the Pod\n    # should be regarded as a validation failure.\n    pod = self._k8s_core_api.create_namespaced_pod(\n        namespace=self._namespace,\n        body=self._BuildPodManifest())\n    self._pod_name = pod.metadata.name\n    logging.info(\'Created Pod:\\n%s\', pod)\n\n  def WaitUntilRunning(self, deadline: float) -> None:\n    assert self._pod_name, (\n        \'Pod has not been created yet. You should call Start() first.\')\n\n    while time.time() < deadline:\n      try:\n        pod = self._k8s_core_api.read_namespaced_pod(\n            name=self._pod_name,\n            namespace=self._namespace)\n      except rest.ApiException as e:\n        logging.info(\'Continue polling after getting ApiException(%s)\', e)\n        time.sleep(_DEFAULT_POLLING_INTERVAL_SEC)\n        continue\n      # Pod phase is one of Pending, Running, Succeeded, Failed, or Unknown.\n      # Succeeded and Failed indicates the pod lifecycle has reached its end,\n      # while we expect the job to be running and hanging. Phase is Unknown if\n      # the state of the pod could not be obtained, thus we can wait until we\n      # confirm the phase.\n      pod_phase = _PodPhase(pod.status.phase)\n      if pod_phase == _PodPhase.RUNNING and pod.status.pod_ip:\n        self._endpoint = \'{}:{}\'.format(pod.status.pod_ip,\n                                        self._serving_binary.container_port)\n        return\n      if pod_phase.is_done:\n        raise error_types.JobAborted(\n            \'Job has been aborted. (phase={})\'.format(pod_phase))\n      logging.info(\'Waiting for the pod to be running. (phase=%s)\', pod_phase)\n      time.sleep(_DEFAULT_POLLING_INTERVAL_SEC)\n\n    raise error_types.DeadlineExceeded(\n        \'Deadline exceeded while waiting for pod to be running.\')\n\n  def Stop(self) -> None:\n    try:\n      self._DeleteModelServerPod()\n    except:  # pylint: disable=broad-except, bare-except\n      logging.warning(\'Error occurred while deleting the Pod. Please run the \'\n                      \'following command to manually clean it up:\\n\\n\'\n                      \'kubectl delete pod --namespace %s %s\',\n                      self._namespace, self._pod_name, exc_info=True)\n\n  @retry.with_exponential_backoff(\n      num_retries=_NUM_RETRIES,\n      initial_delay_secs=_INITIAL_BACKOFF_DELAY_SEC,\n      logger=logging.warning,\n      retry_filter=_api_exception_retry_filter)\n  def _DeleteModelServerPod(self):\n    try:\n      logging.info(\'Deleting Pod (name=%s)\', self._pod_name)\n      self._k8s_core_api.delete_namespaced_pod(\n          name=self._pod_name,\n          namespace=self._namespace)\n    except rest.ApiException as e:\n      if e.status == 404:  # Pod is already deleted.\n        logging.info(\'Pod (name=%s) does not exist.\', self._pod_name)\n        return\n      else:\n        six.reraise(*sys.exc_info())\n\n  def _BuildPodManifest(self) -> k8s_client.V1Pod:\n    if isinstance(self._serving_binary, serving_bins.TensorFlowServing):\n      env_vars_dict = self._serving_binary.MakeEnvVars(\n          model_path=self._model_path)\n      env_vars = [k8s_client.V1EnvVar(name=key, value=value)\n                  for key, value in env_vars_dict.items()]\n    else:\n      raise NotImplementedError(\'Unsupported serving binary {}\'.format(\n          type(self._serving_binary).__name__))\n\n    service_account_name = (self._config.service_account_name or\n                            self._executor_pod.spec.service_account_name)\n    active_deadline_seconds = (self._config.active_deadline_seconds or\n                               _DEFAULT_ACTIVE_DEADLINE_SEC)\n    if active_deadline_seconds < 0:\n      raise ValueError(\'active_deadline_seconds should be > 0. Got {}\'\n                       .format(active_deadline_seconds))\n\n    result = k8s_client.V1Pod(\n        metadata=k8s_client.V1ObjectMeta(\n            generate_name=_MODEL_SERVER_POD_NAME_PREFIX,\n            labels=self._label_dict,\n            # Resources with ownerReferences are automatically deleted once all\n            # its owners are deleted.\n            owner_references=[\n                k8s_client.V1OwnerReference(\n                    api_version=self._executor_pod.api_version,\n                    kind=self._executor_pod.kind,\n                    name=self._executor_pod.metadata.name,\n                    uid=self._executor_pod.metadata.uid,\n                ),\n            ],\n        ),\n        spec=k8s_client.V1PodSpec(\n            containers=[\n                k8s_client.V1Container(\n                    name=_MODEL_SERVER_CONTAINER_NAME,\n                    image=self._serving_binary.image,\n                    env=env_vars,\n                    volume_mounts=[],\n                ),\n            ],\n            service_account_name=service_account_name,\n            # No retry in case model server container failed. Retry will happen\n            # at the outermost loop (executor.py).\n            restart_policy=_RestartPolicy.NEVER.value,\n            # This is a hard deadline for the model server container to ensure\n            # the Pod is properly cleaned up even with an unexpected termination\n            # of an infra validator. After the deadline, container will be\n            # removed but Pod resource won\'t. This makes the Pod log visible\n            # after the termination.\n            active_deadline_seconds=active_deadline_seconds,\n            volumes=[],\n            # TODO(b/152002076): Add TTL controller once it graduates Beta.\n            # ttl_seconds_after_finished=,\n        )\n    )\n\n    self._SetupModelVolumeIfNeeded(result)\n\n    return result\n\n  def _FindVolumeMountForPath(self, path) -> Optional[k8s_client.V1VolumeMount]:\n    if not os.path.exists(path):\n      return None\n    for mount in self._executor_container.volume_mounts:\n      if _is_subdirectory(mount.mount_path, self._model_path):\n        return mount\n    return None\n\n  def _SetupModelVolumeIfNeeded(self, pod_manifest: k8s_client.V1Pod):\n    mount = self._FindVolumeMountForPath(self._model_path)\n    if not mount:\n      return\n    [volume] = [v for v in self._executor_pod.spec.volumes\n                if v.name == mount.name]\n    if volume.persistent_volume_claim is None:\n      raise NotImplementedError(\'Only PersistentVolumeClaim is allowed.\')\n    claim_name = volume.persistent_volume_claim.claim_name\n    pvc = self._k8s_core_api.read_namespaced_persistent_volume_claim(\n        name=claim_name,\n        namespace=self._namespace)\n\n    # PersistentVolumeClaim for pipeline root SHOULD have ReadWriteMany access\n    # mode. Although it is allowed to mount ReadWriteOnce volume if Pods share\n    # the Node, there\'s no guarantee the model server Pod will be launched in\n    # the same Node.\n    if all(access_mode != _AccessMode.READ_WRITE_MANY.value\n           for access_mode in pvc.spec.access_modes):\n      raise RuntimeError(\'Access mode should be ReadWriteMany.\')\n\n    logging.info(\'PersistentVolumeClaim %s will be mounted to %s.\',\n                 pvc, mount.mount_path)\n\n    pod_manifest.spec.volumes.append(\n        k8s_client.V1Volume(\n            name=_MODEL_SERVER_MODEL_VOLUME_NAME,\n            persistent_volume_claim=k8s_client\n            .V1PersistentVolumeClaimVolumeSource(\n                claim_name=claim_name,\n                read_only=True)))\n    container_manifest = _get_container_or_error(\n        pod_manifest, container_name=_MODEL_SERVER_CONTAINER_NAME)\n    container_manifest.volume_mounts.append(\n        k8s_client.V1VolumeMount(\n            name=_MODEL_SERVER_MODEL_VOLUME_NAME,\n            mount_path=mount.mount_path,\n            read_only=True,\n        )\n    )\n'"
tfx/components/infra_validator/model_server_runners/kubernetes_runner_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.infra_validator.model_server_runners.kubernetes_runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Any, Dict, Text\n\nfrom kubernetes import client as k8s_client\nfrom kubernetes.client import rest\nimport mock\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.components.infra_validator.model_server_runners import kubernetes_runner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import kube_utils\nfrom tfx.utils import path_utils\n\n\ndef _create_serving_spec(payload: Dict[Text, Any]):\n  result = infra_validator_pb2.ServingSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\nclass KubernetesRunnerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(KubernetesRunnerTest, self).setUp()\n    self.addCleanup(mock.patch.stopall)\n\n    self._base_dir = os.path.join(\n        os.path.dirname(  # components/\n            os.path.dirname(  # infra_validator/\n                os.path.dirname(__file__))),  # model_server_runners/\n        \'testdata\'\n    )\n    self._model = standard_artifacts.Model()\n    self._model.uri = os.path.join(self._base_dir, \'trainer\', \'current\')\n    self._model_name = \'chicago-taxi\'\n\n    # Prepare mocks\n    self._mock_sleep = mock.patch(\'time.sleep\').start()\n    self._mock_core_v1_api = mock.patch.object(\n        kube_utils, \'make_core_v1_api\').start().return_value\n\n  def _CreateKubernetesRunner(self, k8s_config_dict=None):\n    self._serving_spec = infra_validator_pb2.ServingSpec()\n    json_format.ParseDict({\n        \'tensorflow_serving\': {\n            \'tags\': [\'1.15.0\']},\n        \'kubernetes\': k8s_config_dict or {},\n        \'model_name\': self._model_name,\n    }, self._serving_spec)\n    serving_binary = serving_bins.parse_serving_binaries(self._serving_spec)[0]\n\n    return kubernetes_runner.KubernetesRunner(\n        model_path=path_utils.serving_model_path(self._model.uri),\n        serving_binary=serving_binary,\n        serving_spec=self._serving_spec)\n\n  def _AssumeInsideKfp(\n      self,\n      namespace=\'my-namespace\',\n      pod_name=\'my-pod-name\',\n      pod_uid=\'my-pod-uid\',\n      pod_service_account_name=\'my-service-account-name\',\n      with_pvc=False):\n    pod = k8s_client.V1Pod(\n        api_version=\'v1\',\n        kind=\'Pod\',\n        metadata=k8s_client.V1ObjectMeta(\n            name=pod_name,\n            uid=pod_uid,\n        ),\n        spec=k8s_client.V1PodSpec(\n            containers=[\n                k8s_client.V1Container(\n                    name=\'main\',\n                    volume_mounts=[]),\n            ],\n            volumes=[]))\n\n    if with_pvc:\n      pod.spec.volumes.append(\n          k8s_client.V1Volume(\n              name=\'my-volume\',\n              persistent_volume_claim=k8s_client\n              .V1PersistentVolumeClaimVolumeSource(\n                  claim_name=\'my-pvc\')))\n      pod.spec.containers[0].volume_mounts.append(\n          k8s_client.V1VolumeMount(\n              name=\'my-volume\',\n              mount_path=self._base_dir))\n\n    mock.patch.object(kube_utils, \'is_inside_kfp\', return_value=True).start()\n    pod.spec.service_account_name = pod_service_account_name\n    mock.patch.object(kube_utils, \'get_current_kfp_pod\',\n                      return_value=pod).start()\n    mock.patch.object(kube_utils, \'get_kfp_namespace\',\n                      return_value=namespace).start()\n    if with_pvc:\n      (self._mock_core_v1_api.read_namespaced_persistent_volume_claim\n       .return_value) = k8s_client.V1PersistentVolumeClaim(\n           metadata=k8s_client.V1ObjectMeta(\n               name=\'my-pvc\'),\n           spec=k8s_client.V1PersistentVolumeClaimSpec(\n               access_modes=[\'ReadWriteMany\']))\n\n  def _AssumeOutsideKfp(self):\n    mock.patch.object(kube_utils, \'is_inside_kfp\', return_value=False).start()\n\n  def testStart_InsideKfp(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp(namespace=\'vanilla-latte\')\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    runner.Start()\n\n    # Check states.\n    self._mock_core_v1_api.create_namespaced_pod.assert_called()\n    _, kwargs = self._mock_core_v1_api.create_namespaced_pod.call_args\n    self.assertEqual(kwargs[\'namespace\'], \'vanilla-latte\')\n    self.assertTrue(runner._pod_name)\n\n  def testBuildPodManifest_InsideKfp(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp(\n        namespace=\'strawberry-latte\',\n        pod_name=\'green-tea-latte\',\n        pod_uid=\'chocolate-latte\',\n        pod_service_account_name=\'vanilla-latte\')\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    pod_manifest = runner._BuildPodManifest()\n\n    # Check result.\n    self.assertEqual(\n        pod_manifest.metadata.generate_name, \'tfx-infraval-modelserver-\')\n    self.assertEqual(pod_manifest.metadata.labels, {\n        \'app\': \'tfx-infraval-modelserver\'\n    })\n    owner_ref = pod_manifest.metadata.owner_references[0]\n    self.assertEqual(owner_ref.name, \'green-tea-latte\')\n    self.assertEqual(owner_ref.uid, \'chocolate-latte\')\n    self.assertEqual(pod_manifest.spec.service_account_name, \'vanilla-latte\')\n    self.assertEqual(pod_manifest.spec.restart_policy, \'Never\')\n    container = pod_manifest.spec.containers[0]\n    self.assertEqual(container.name, \'model-server\')\n    self.assertEqual(container.image, \'tensorflow/serving:1.15.0\')\n    container_envs = {env.name for env in container.env}\n    self.assertIn(\'MODEL_NAME\', container_envs)\n    self.assertIn(\'MODEL_BASE_PATH\', container_envs)\n\n  def testBuildPodManifest_InsideKfp_WithPvc(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp(with_pvc=True)\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    pod_manifest = runner._BuildPodManifest()\n\n    # Check Volume.\n    volume = pod_manifest.spec.volumes[0]\n    self.assertEqual(volume.name, \'model-volume\')\n    self.assertEqual(volume.persistent_volume_claim.claim_name, \'my-pvc\')\n\n    # Check VolumeMount.\n    container = pod_manifest.spec.containers[0]\n    volume_mount = container.volume_mounts[0]\n    self.assertEqual(volume_mount.name, \'model-volume\')\n    self.assertEqual(volume_mount.mount_path, self._base_dir)\n\n  def testBuildPodManifest_InsideKfp_OverrideConfig(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner(k8s_config_dict={\n        \'service_account_name\': \'chocolate-latte\',\n        \'active_deadline_seconds\': 123,\n    })\n\n    # Act.\n    pod_manifest = runner._BuildPodManifest()\n\n    # Check result.\n    self.assertEqual(pod_manifest.spec.service_account_name, \'chocolate-latte\')\n    self.assertEqual(pod_manifest.spec.active_deadline_seconds, 123)\n\n  def testStart_FailsIfOutsideKfp(self):\n    # Prepare mocks and variables.\n    self._AssumeOutsideKfp()\n\n    # Act.\n    with self.assertRaises(NotImplementedError):\n      self._CreateKubernetesRunner()\n\n  def testStart_FailsIfStartedTwice(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    runner.Start()\n    with self.assertRaises(AssertionError):\n      runner.Start()\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning(self, mock_time):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n    mock_time.side_effect = list(range(20))\n    pending_pod = mock.Mock()\n    pending_pod.status.phase = \'Pending\'\n    running_pod = mock.Mock()\n    running_pod.status.phase = \'Running\'\n    self._mock_core_v1_api.read_namespaced_pod.side_effect = [\n        rest.ApiException(\'meh\'),  # Error is tolerable.\n        pending_pod,\n        pending_pod,\n        running_pod\n    ]\n\n    # Act.\n    runner.Start()\n    try:\n      runner.WaitUntilRunning(deadline=10)\n    except Exception as e:  # pylint: disable=broad-except\n      self.fail(e)\n\n    # Check calls.\n    self.assertEqual(self._mock_core_v1_api.read_namespaced_pod.call_count, 4)\n\n  def testWaitUntilRunning_FailsIfNotStarted(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    with self.assertRaises(AssertionError):\n      runner.WaitUntilRunning(deadline=10)\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning_FailsIfJobAborted(self, mock_time):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n    mock_time.side_effect = list(range(20))\n    terminated_pod = mock.Mock()\n    terminated_pod.status.phase = \'Succeeded\'\n    self._mock_core_v1_api.read_namespaced_pod.return_value = terminated_pod\n\n    # Act.\n    runner.Start()\n    with self.assertRaises(error_types.JobAborted):\n      runner.WaitUntilRunning(deadline=10)\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning_FailsIfDeadlineExceeded(self, mock_time):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n    mock_time.side_effect = list(range(20))\n    pending_pod = mock.Mock()\n    pending_pod.status.phase = \'Pending\'\n    self._mock_core_v1_api.read_namespaced_pod.return_value = pending_pod\n\n    # Act.\n    runner.Start()\n    with self.assertRaises(error_types.DeadlineExceeded):\n      runner.WaitUntilRunning(deadline=10)\n\n  def testStop(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n\n    # Act.\n    try:\n      runner.Start()\n      runner.Stop()\n    except Exception as e:  # pylint: disable=broad-except\n      self.fail(e)\n\n    # Check calls.\n    self._mock_core_v1_api.delete_namespaced_pod.assert_called_once()\n\n  def testStop_RetryIfApiException(self):\n    # Prepare mocks and variables.\n    self._AssumeInsideKfp()\n    runner = self._CreateKubernetesRunner()\n    self._mock_core_v1_api.delete_namespaced_pod.side_effect = rest.ApiException\n\n    # Act.\n    try:\n      runner.Start()\n      runner.Stop()\n    except Exception as e:  # pylint: disable=broad-except\n      self.fail(e)\n\n    # Check calls.\n    self.assertEqual(self._mock_sleep.call_count, 4)\n    self.assertEqual(self._mock_core_v1_api.delete_namespaced_pod.call_count, 5)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/infra_validator/model_server_runners/local_docker_runner.py,0,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Module for LocalDockerModelServerRunner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport time\n\nfrom absl import logging\nimport docker\nfrom docker import errors as docker_errors\nfrom typing import Any, Dict, Text\n\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.components.infra_validator.model_server_runners import base_runner\nfrom tfx.proto import infra_validator_pb2\n\n_POLLING_INTERVAL_SEC = 1\n\n\ndef _make_docker_client(config: infra_validator_pb2.LocalDockerConfig):\n  params = {}\n  if config.client_timeout_seconds:\n    params[\'timeout\'] = config.client_timeout_seconds\n  if config.client_base_url:\n    params[\'base_url\'] = config.client_base_url\n  if config.client_api_version:\n    params[\'version\'] = config.client_api_version\n  return docker.DockerClient(**params)\n\n\ndef _find_host_port(ports: Dict[Text, Any], container_port: int) -> Text:\n  """"""Find host port from container port mappings.\n\n  `ports` is a nested dictionary of the following structure:\n\n  {\'8500/tcp\': [{\'HostIp\': \'0.0.0.0\', \'HostPort\': \'32769\'}],\n   \'8501/tcp\': [{\'HostIp\': \'0.0.0.0\', \'HostPort\': \'32768\'}]}\n\n  Args:\n    ports: Dictionary of docker container port mapping.\n    container_port: Corresponding container port you\'re looking for.\n\n  Returns:\n    A found host port.\n\n  Raises:\n    ValueError: No corresponding host port was found.\n  """"""\n  mappings = ports.get(\'{}/tcp\'.format(container_port))\n  if mappings:\n    return mappings[0].get(\'HostPort\')\n  else:\n    raise ValueError(\n        \'No HostPort found for ContainerPort={} (all port mappings: {})\'\n        .format(container_port, ports))\n\n\nclass LocalDockerRunner(base_runner.BaseModelServerRunner):\n  """"""A model server runner that runs in a local docker runtime.\n\n  You need to pre-install docker in the machine that is running InfraValidator\n  component. For that reason, it is recommended to use this runner only for\n  testing purpose.\n  """"""\n\n  def __init__(self,\n               model_path: Text,\n               serving_binary: serving_bins.ServingBinary,\n               serving_spec: infra_validator_pb2.ServingSpec):\n    """"""Make a local docker runner.\n\n    Args:\n      model_path: An IV-flavored model path. (See model_path_utils.py)\n      serving_binary: A ServingBinary to run.\n      serving_spec: A ServingSpec instance.\n    """"""\n    self._model_path = model_path\n    self._serving_binary = serving_binary\n    self._serving_spec = serving_spec\n    self._docker = _make_docker_client(serving_spec.local_docker)\n    self._container = None\n    self._endpoint = None\n\n  def __repr__(self):\n    return \'LocalDockerRunner(image: {image})\'.format(\n        image=self._serving_binary.image)\n\n  def GetEndpoint(self):\n    assert self._endpoint is not None, (\n        \'Endpoint is not yet created. You should call Start() first.\')\n    return self._endpoint\n\n  def Start(self):\n    assert self._container is None, (\n        \'You cannot start model server multiple times.\')\n\n    if isinstance(self._serving_binary, serving_bins.TensorFlowServing):\n      is_local = os.path.isdir(self._model_path)\n      run_params = self._serving_binary.MakeDockerRunParams(\n          model_path=self._model_path,\n          needs_mount=is_local)\n    else:\n      raise NotImplementedError(\'Unsupported serving binary {}\'.format(\n          type(self._serving_binary).__name__))\n\n    logging.info(\'Running container with parameter %s\', run_params)\n    self._container = self._docker.containers.run(**run_params)\n\n  def WaitUntilRunning(self, deadline):\n    assert self._container is not None, \'container has not been started.\'\n\n    while time.time() < deadline:\n      try:\n        # Reload container attributes from server. This is the only right way to\n        # retrieve the latest container status from docker engine.\n        self._container.reload()\n        status = self._container.status\n      except docker_errors.NotFound:\n        # If the job has been aborted and container has specified auto_removal\n        # to True, we might get a NotFound error during container.reload().\n        raise error_types.JobAborted(\n            \'Container not found. Possibly removed after the job has been \'\n            \'aborted.\')\n      # The container is just created and not yet in the running status.\n      if status == \'created\':\n        time.sleep(_POLLING_INTERVAL_SEC)\n        continue\n      # The container is running :)\n      if status == \'running\':\n        host_port = _find_host_port(self._container.ports,\n                                    self._serving_binary.container_port)\n        self._endpoint = \'localhost:{}\'.format(host_port)\n        return\n      # Docker status is one of {\'created\', \'restarting\', \'running\', \'removing\',\n      # \'paused\', \'exited\', or \'dead\'}. Status other than \'created\' and\n      # \'running\' indicates the job has been aborted.\n      raise error_types.JobAborted(\n          \'Job has been aborted (container status={})\'.format(status))\n\n    raise error_types.DeadlineExceeded(\n        \'Deadline exceeded while waiting for the container to be running.\')\n\n  def Stop(self):\n    if self._container:\n      logging.info(\'Stopping container.\')\n      self._container.stop()\n    self._docker.close()\n'"
tfx/components/infra_validator/model_server_runners/local_docker_runner_test.py,2,"b'# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.infra_validator.model_server_runners.local_docker_runner.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom docker import errors as docker_errors\nimport mock\nimport tensorflow as tf\nfrom typing import Any, Dict, Text\n\nfrom google.protobuf import json_format\nfrom tfx.components.infra_validator import error_types\nfrom tfx.components.infra_validator import serving_bins\nfrom tfx.components.infra_validator.model_server_runners import local_docker_runner\nfrom tfx.proto import infra_validator_pb2\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import path_utils\n\n\ndef _create_serving_spec(payload: Dict[Text, Any]):\n  result = infra_validator_pb2.ServingSpec()\n  json_format.ParseDict(payload, result)\n  return result\n\n\nclass LocalDockerRunnerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(LocalDockerRunnerTest, self).setUp()\n\n    base_dir = os.path.join(\n        os.path.dirname(  # components/\n            os.path.dirname(  # infra_validator/\n                os.path.dirname(__file__))),  # model_server_runners/\n        \'testdata\'\n    )\n    self._model = standard_artifacts.Model()\n    self._model.uri = os.path.join(base_dir, \'trainer\', \'current\')\n    self._model_name = \'chicago-taxi\'\n    self._model_path = path_utils.serving_model_path(self._model.uri)\n\n    # Mock docker.DockerClient\n    patcher = mock.patch(\'docker.DockerClient\')\n    self._docker_client = patcher.start().return_value\n    self.addCleanup(patcher.stop)\n\n    self._serving_spec = _create_serving_spec({\n        \'tensorflow_serving\': {\n            \'tags\': [\'1.15.0\']},\n        \'local_docker\': {},\n        \'model_name\': self._model_name,\n    })\n    self._serving_binary = serving_bins.parse_serving_binaries(\n        self._serving_spec)[0]\n    patcher = mock.patch.object(self._serving_binary, \'MakeClient\')\n    self._model_server_client = patcher.start().return_value\n    self.addCleanup(patcher.stop)\n\n  def _CreateLocalDockerRunner(self):\n    return local_docker_runner.LocalDockerRunner(\n        model_path=self._model_path,\n        serving_binary=self._serving_binary,\n        serving_spec=self._serving_spec)\n\n  def testStart(self):\n    # Prepare mocks and variables.\n    runner = self._CreateLocalDockerRunner()\n\n    # Act.\n    runner.Start()\n\n    # Check calls.\n    self._docker_client.containers.run.assert_called()\n    _, run_kwargs = self._docker_client.containers.run.call_args\n    self.assertDictContainsSubset(dict(\n        image=\'tensorflow/serving:1.15.0\',\n        environment={\n            \'MODEL_NAME\': \'chicago-taxi\',\n            \'MODEL_BASE_PATH\': \'/model\'\n        },\n        publish_all_ports=True,\n        auto_remove=True,\n        detach=True\n    ), run_kwargs)\n\n  def testStartMultipleTimesFail(self):\n    # Prepare mocks and variables.\n    runner = self._CreateLocalDockerRunner()\n\n    # Act.\n    runner.Start()\n    with self.assertRaises(AssertionError) as err:\n      runner.Start()\n\n    # Check errors.\n    self.assertEqual(\n        str(err.exception), \'You cannot start model server multiple times.\')\n\n  @mock.patch(\'time.time\')\n  def testGetEndpoint_AfterWaitUntilRunning(self, mock_time):\n    # Prepare mocks and variables.\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(10))\n    container = self._docker_client.containers.run.return_value\n    container.status = \'running\'\n    container.ports = {\n        \'8500/tcp\': [{\'HostIp\': \'0.0.0.0\', \'HostPort\': \'1234\'}],  # gRPC port.\n        \'8501/tcp\': [{\'HostIp\': \'0.0.0.0\', \'HostPort\': \'5678\'}]   # REST port.\n    }\n\n    # Act.\n    runner.Start()\n    runner.WaitUntilRunning(deadline=10)\n    endpoint = runner.GetEndpoint()\n\n    # Check result.\n    self.assertEqual(endpoint, \'localhost:1234\')\n\n  def testGetEndpoint_FailWithoutStartingFirst(self):\n    # Prepare mocks and variables.\n    runner = self._CreateLocalDockerRunner()\n\n    # Act.\n    with self.assertRaises(AssertionError):\n      runner.GetEndpoint()\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning(self, mock_time):\n    # Prepare mocks and variables.\n    container = self._docker_client.containers.run.return_value\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(10))\n\n    # Setup state.\n    runner.Start()\n    container.status = \'running\'\n\n    # Act.\n    try:\n      runner.WaitUntilRunning(deadline=10)\n    except Exception as e:  # pylint: disable=broad-except\n      self.fail(e)\n\n    # Check states.\n    container.reload.assert_called()\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning_FailWithoutStartingFirst(self, mock_time):\n    # Prepare runner.\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(10))\n\n    # Act.\n    with self.assertRaises(AssertionError) as err:\n      runner.WaitUntilRunning(deadline=10)\n\n    # Check errors.\n    self.assertEqual(str(err.exception), \'container has not been started.\')\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning_FailWhenBadContainerStatus(self, mock_time):\n    # Prepare mocks and variables.\n    container = self._docker_client.containers.run.return_value\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(10))\n\n    # Setup state.\n    runner.Start()\n    container.status = \'dead\'  # Bad status.\n\n    # Act.\n    with self.assertRaises(error_types.JobAborted):\n      runner.WaitUntilRunning(deadline=10)\n\n  @mock.patch(\'time.time\')\n  @mock.patch(\'time.sleep\')\n  def testWaitUntilRunning_FailIfNotRunningUntilDeadline(\n      self, mock_sleep, mock_time):\n    # Prepare mocks and variables.\n    container = self._docker_client.containers.run.return_value\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(20))\n\n    # Setup state.\n    runner.Start()\n    container.status = \'created\'\n\n    # Act.\n    with self.assertRaises(error_types.DeadlineExceeded):\n      runner.WaitUntilRunning(deadline=10)\n\n    # Check result.\n    mock_sleep.assert_called()\n\n  @mock.patch(\'time.time\')\n  def testWaitUntilRunning_FailIfContainerNotFound(self, mock_time):\n    # Prepare mocks and variables.\n    container = self._docker_client.containers.run.return_value\n    container.reload.side_effect = docker_errors.NotFound(\'message required.\')\n    runner = self._CreateLocalDockerRunner()\n    mock_time.side_effect = list(range(20))\n\n    # Setup state.\n    runner.Start()\n\n    # Act.\n    with self.assertRaises(error_types.JobAborted):\n      runner.WaitUntilRunning(deadline=10)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/testdata/module_file/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/testdata/module_file/trainer_module.py,21,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nFor a TFX pipeline to successfully run, a preprocessing_fn and a\n_build_estimator function needs to be provided.  This file contains both.\n\nThis file is equivalent to examples/chicago_taxi/trainer/model.py and\nexamples/chicago_taxi/preprocess.py.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer import executor\nfrom tfx.utils import io_utils\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _build_estimator(config, hidden_units=None, warm_start_from=None):\n  """"""Build an estimator for predicting the tipping behavior of taxi riders.\n\n  Args:\n    config: tf.estimator.RunConfig defining the runtime environment for the\n      estimator (including model_dir).\n    hidden_units: [int], the layer sizes of the DNN (input layer first)\n    warm_start_from: Optional directory to warm start from.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  return tf.estimator.DNNLinearCombinedClassifier(\n      config=config,\n      linear_feature_columns=categorical_columns,\n      dnn_feature_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n      warm_start_from=warm_start_from)\n\n\ndef _example_serving_receiver_fn(tf_transform_output, schema):\n  """"""Build the serving in inputs.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    Tensorflow graph which parses examples, applying tf-transform to them.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  transformed_features = tf_transform_output.transform_raw_features(\n      serving_input_receiver.features)\n\n  return tf.estimator.export.ServingInputReceiver(\n      transformed_features, serving_input_receiver.receiver_tensors)\n\n\ndef _eval_input_receiver_fn(tf_transform_output, schema):\n  """"""Build everything needed for the tf-model-analysis to run the model.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Tensorflow graph which parses raw untransformed features, applies the\n        tf-transform preprocessing operators.\n      - Set of raw, untransformed features.\n      - Label against which predictions will be compared.\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  serialized_tf_example = tf.compat.v1.placeholder(\n      dtype=tf.string, shape=[None], name=\'input_example_tensor\')\n\n  # Add a parse_example operator to the tensorflow graph, which will parse\n  # raw, untransformed, tf examples.\n  features = tf.io.parse_example(\n      serialized=serialized_tf_example, features=raw_feature_spec)\n\n  # Now that we have our raw examples, process them through the tf-transform\n  # function computed during the preprocessing step.\n  transformed_features = tf_transform_output.transform_raw_features(\n      features)\n\n  # The key name MUST be \'examples\'.\n  receiver_tensors = {\'examples\': serialized_tf_example}\n\n  # NOTE: Model is driven by transformed features (since training works on the\n  # materialized output of TFT, but slicing will happen on raw features.\n  features.update(transformed_features)\n\n  return tfma.export.EvalInputReceiver(\n      features=features,\n      receiver_tensors=receiver_tensors,\n      labels=transformed_features[_transformed_name(_LABEL_KEY)])\n\n\ndef _input_fn(filenames, tf_transform_output, batch_size=200):\n  """"""Generates features and labels for training or evaluation.\n\n  Args:\n    filenames: [str] list of CSV files to read data from.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: int First dimension size of the Tensors returned by input_fn\n\n  Returns:\n    A (features, indices) tuple where features is a dictionary of\n      Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn)\n\n  transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n      dataset).get_next()\n  # We pop the label because we do not want to use it as a feature while we\'re\n  # training.\n  return transformed_features, transformed_features.pop(\n      _transformed_name(_LABEL_KEY))\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  if trainer_fn_args.hyperparameters:\n    hp = trainer_fn_args.hyperparameters\n    first_dnn_layer_size = hp.get(\'first_dnn_layer_size\')\n    num_dnn_layers = hp.get(\'num_dnn_layers\')\n    dnn_decay_factor = hp.get(\'dnn_decay_factor\')\n  else:\n    # Number of nodes in the first layer of the DNN\n    first_dnn_layer_size = 100\n    num_dnn_layers = 4\n    dnn_decay_factor = 0.7\n\n  train_batch_size = 40\n  eval_batch_size = 40\n\n  tf_transform_output = tft.TFTransformOutput(trainer_fn_args.transform_output)\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      tf_transform_output,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      tf_transform_output,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n      train_input_fn,\n      max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  exporter = tf.estimator.FinalExporter(\'chicago-taxi\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'chicago-taxi-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999,\n      # keep_checkpoint_max must be more than the number of worker replicas\n      # nodes if training distributed, in order to avoid race condition.\n      keep_checkpoint_max=5)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n  warm_start_from = trainer_fn_args.base_model\n\n  estimator = _build_estimator(\n      # Construct layers sizes with exponetial decay\n      hidden_units=[\n          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n          for i in range(num_dnn_layers)\n      ],\n      config=run_config,\n      warm_start_from=warm_start_from)\n\n  # Create an input receiver for TFMA processing\n  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': receiver_fn\n  }\n\n\n# TFX generic trainer will call this function\ndef run_fn(fn_args: executor.TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  schema = io_utils.parse_pbtxt_file(fn_args.schema_file, schema_pb2.Schema())\n\n  training_spec = trainer_fn(fn_args, schema)\n\n  # Train the model\n  absl.logging.info(\'Training model.\')\n  tf.estimator.train_and_evaluate(training_spec[\'estimator\'],\n                                  training_spec[\'train_spec\'],\n                                  training_spec[\'eval_spec\'])\n  absl.logging.info(\'Training complete.  Model written to %s\',\n                    fn_args.serving_model_dir)\n\n  # Export an eval savedmodel for TFMA\n  # NOTE: When trained in distributed training cluster, eval_savedmodel must be\n  # exported only by the chief worker.\n  absl.logging.info(\'Exporting eval_savedmodel for TFMA.\')\n  tfma.export.export_eval_savedmodel(\n      estimator=training_spec[\'estimator\'],\n      export_dir_base=fn_args.eval_model_dir,\n      eval_input_receiver_fn=training_spec[\'eval_input_receiver_fn\'])\n\n  absl.logging.info(\'Exported eval_savedmodel to %s.\', fn_args.eval_model_dir)\n'"
tfx/components/testdata/module_file/transform_module.py,14,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nFor a TFX pipeline to successfully run, a preprocessing_fn and a\n_build_estimator function needs to be provided.  This file contains both.\n\nThis file is equivalent to examples/chicago_taxi/trainer/model.py and\nexamples/chicago_taxi/preprocess.py.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.sparse.to_dense(\n          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n          default_value),\n      axis=1)\n\n\n@tf.function\ndef _identity(x):\n  """"""Make sure everything still works when there is a tf.function used.""""""\n  return x\n\n\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(_identity(inputs[key])))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]),\n        _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n'"
tfx/components/testdata/module_file/tuner_module.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include Iris pipeline functions and necessary utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text, Union\n\nimport absl\nimport kerastuner\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer.fn_args_utils import FnArgs\nfrom tfx.components.tuner.component import TunerFnResult\nfrom tfx.utils import io_utils\n\n_FEATURE_KEYS = [\'sepal_length\', \'sepal_width\', \'petal_length\', \'petal_width\']\n_LABEL_KEY = \'variety\'\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _input_fn(file_pattern: Union[Text, List[Text]],\n              schema: schema_pb2.Schema,\n              batch_size: int = 20) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: string or list of strings, contains pattern(s) of input\n      tfrecord files.\n    schema: Schema of the input data.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch.\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  feature_spec = schema_utils.schema_as_feature_spec(schema).feature_spec\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_LABEL_KEY)\n\n  return dataset\n\n\ndef _build_keras_model(hparams: kerastuner.HyperParameters) -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying iris data.\n\n  Args:\n    hparams: Holds HyperParameters for tuning.\n\n  Returns:\n    A Keras Model.\n  """"""\n  # The model below is built with Functional API, please refer to\n  # https://www.tensorflow.org/guide/keras/overview for all API options.\n  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n  d = keras.layers.concatenate(inputs)\n  for _ in range(int(hparams.get(\'num_layers\'))):\n    d = keras.layers.Dense(8, activation=\'relu\')(d)\n  outputs = keras.layers.Dense(3, activation=\'softmax\')(d)\n\n  model = keras.Model(inputs=inputs, outputs=outputs)\n  model.compile(\n      optimizer=keras.optimizers.Adam(hparams.get(\'learning_rate\')),\n      loss=\'sparse_categorical_crossentropy\',\n      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# This will be called by TFX Tuner.\ndef tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n  """"""Build the tuner using the KerasTuner API.\n\n  Args:\n    fn_args: Holds args as name/value pairs.\n      - working_dir: working dir for tuning.\n      - train_files: List of file paths containing training tf.Example data.\n      - eval_files: List of file paths containing eval tf.Example data.\n      - train_steps: number of train steps.\n      - eval_steps: number of eval steps.\n      - schema_path: optional schema of the input data.\n      - transform_graph_path: optional transform graph produced by TFT.\n\n  Returns:\n    A namedtuple contains the following:\n      - tuner: A BaseTuner that will be used for tuning.\n      - fit_kwargs: Args to pass to tuner\'s run_trial function for fitting the\n                    model , e.g., the training and validation dataset. Required\n                    args depend on the above tuner\'s implementation.\n  """"""\n  hp = kerastuner.HyperParameters()\n  # Defines search space.\n  hp.Choice(\'learning_rate\', [1e-1, 1e-3])\n  hp.Int(\'num_layers\', 1, 5)\n\n  # RandomSearch is a subclass of Keras model Tuner.\n  tuner = kerastuner.RandomSearch(\n      _build_keras_model,\n      max_trials=5,\n      hyperparameters=hp,\n      allow_new_entries=False,\n      objective=\'val_sparse_categorical_accuracy\',\n      directory=fn_args.working_dir,\n      project_name=\'test\')\n\n  schema = schema_pb2.Schema()\n  io_utils.parse_pbtxt_file(fn_args.schema_path, schema)\n  train_dataset = _input_fn(fn_args.train_files, schema)\n  eval_dataset = _input_fn(fn_args.eval_files, schema)\n\n  return TunerFnResult(\n      tuner=tuner,\n      fit_kwargs={\n          \'x\': train_dataset,\n          \'validation_data\': eval_dataset,\n          \'steps_per_epoch\': fn_args.train_steps,\n          \'validation_steps\': fn_args.eval_steps\n      })\n'"
tfx/components/trainer/rewriting/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/components/trainer/rewriting/converters.py,7,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Converters rewrite models using the provided rewriters.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport time\n\nfrom typing import Text\n\nimport tensorflow as tf\nfrom tfx.components.trainer.rewriting import rewriter\n\n\ndef _invoke_rewriter(src: Text, dst: Text, rewriter_inst: rewriter.BaseRewriter,\n                     src_model_type: rewriter.ModelType,\n                     dst_model_type: rewriter.ModelType):\n  """"""Converts the provided model by invoking the specified rewriters.\n\n  Args:\n    src: Path to the source model.\n    dst: Path where the destination model is to be written.\n    rewriter_inst: instance of the rewriter to invoke.\n    src_model_type: the `rewriter.ModelType` of the source model.\n    dst_model_type: the `rewriter.ModelType` of the destination model.\n\n  Raises:\n    ValueError: if the source path is the same as the destination path.\n  """"""\n\n  if src == dst:\n    raise ValueError(\'Source path and destination path cannot match.\')\n\n  original_model = rewriter.ModelDescription(src_model_type, src)\n  rewritten_model = rewriter.ModelDescription(dst_model_type, dst)\n\n  rewriter_inst.perform_rewrite(original_model, rewritten_model)\n\n\nclass RewritingExporter(tf.estimator.Exporter):\n  """"""This class invokes the base exporter and a series of rewriters.""""""\n\n  def __init__(self, base_exporter: tf.estimator.Exporter,\n               rewriter_inst: rewriter.BaseRewriter):\n    """"""Initializes the rewriting exporter.\n\n    Args:\n      base_exporter: The exporter of the original model.\n      rewriter_inst: The rewriter instance to invoke. Must inherit from\n        `rewriter.BaseRewriter`.\n    """"""\n    self._base_exporter = base_exporter\n    self._rewriter_inst = rewriter_inst\n\n  @property\n  def name(self):\n    """"""Name of the exporter.""""""\n    return self._base_exporter.name\n\n  def export(self, estimator, export_path, checkpoint_path, eval_result,\n             is_the_final_export):\n    """"""Exports the given `Estimator` to a specific format.\n\n    Performs the export as defined by the base_exporter and invokes all of the\n    specified rewriters.\n\n    Args:\n      estimator: the `Estimator` to export.\n      export_path: A string containing a directory where to write the export.\n      checkpoint_path: The checkpoint path to export.\n      eval_result: The output of `Estimator.evaluate` on this checkpoint.\n      is_the_final_export: This boolean is True when this is an export in the\n        end of training.  It is False for the intermediate exports during the\n        training. When passing `Exporter` to `tf.estimator.train_and_evaluate`\n        `is_the_final_export` is always False if `TrainSpec.max_steps` is\n        `None`.\n\n    Returns:\n      The string path to the base exported directory or `None` if export is\n        skipped.\n\n    Raises:\n      RuntimeError: Unable to create a temporary rewrite directory.\n    """"""\n    base_path = self._base_exporter.export(estimator, export_path,\n                                           checkpoint_path, eval_result,\n                                           is_the_final_export)\n    if not base_path:\n      return None\n\n    tmp_rewrite_folder = \'tmp-rewrite-\' + str(int(time.time()))\n    tmp_rewrite_path = os.path.join(export_path, tmp_rewrite_folder)\n    if tf.io.gfile.exists(tmp_rewrite_path):\n      raise RuntimeError(\'Unable to create a unique temporary rewrite path.\')\n    tf.io.gfile.makedirs(tmp_rewrite_path)\n\n    _invoke_rewriter(base_path, tmp_rewrite_path, self._rewriter_inst,\n                     rewriter.ModelType.SAVED_MODEL,\n                     rewriter.ModelType.ANY_MODEL)\n\n    tf.io.gfile.rmtree(base_path)\n    tf.io.gfile.rename(tmp_rewrite_path, base_path)\n    return base_path\n\n\ndef rewrite_saved_model(\n    src: Text,\n    dst: Text,\n    rewriter_inst: rewriter.BaseRewriter,\n    dst_model_type: rewriter.ModelType = rewriter.ModelType.SAVED_MODEL):\n  """"""Rewrites the provided SavedModel.\n\n  Args:\n    src: location of the saved_model to rewrite.\n    dst: location of the rewritten saved_model.\n    rewriter_inst: the rewriter instance to invoke. Must inherit from\n      `rewriter.BaseRewriter`.\n    dst_model_type: the `rewriter.ModelType` of the destination model.\n  """"""\n  _invoke_rewriter(src, dst, rewriter_inst, rewriter.ModelType.SAVED_MODEL,\n                   dst_model_type)\n'"
tfx/components/trainer/rewriting/converters_test.py,22,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for third_party.tfx.components.trainer.rewriting.converters.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nfrom absl.testing.absltest import mock\n\nimport tensorflow as tf\n\nfrom tfx.components.trainer.rewriting import converters\nfrom tfx.components.trainer.rewriting import rewriter\n\nBASE_EXPORT_SUBDIR = \'export_1\'\nORIGINAL_SAVED_MODEL = \'saved_model.pbtxt\'\nORIGINAL_VOCAB = \'vocab\'\nREWRITTEN_SAVED_MODEL = \'rewritten_model.pbtxt\'\nREWRITTEN_VOCAB = \'rewritten_vocab\'\n\n\ndef _export_fn(estimator, export_path, checkpoint_path, eval_result,\n               is_the_final_export):\n  del estimator, checkpoint_path, eval_result, is_the_final_export\n  path = os.path.join(export_path, BASE_EXPORT_SUBDIR)\n  tf.io.gfile.makedirs(path)\n  with tf.io.gfile.GFile(os.path.join(path, ORIGINAL_SAVED_MODEL), \'w\') as f:\n    f.write(str(ORIGINAL_SAVED_MODEL))\n\n  assets_path = os.path.join(path, tf.saved_model.ASSETS_DIRECTORY)\n  tf.io.gfile.makedirs(assets_path)\n  with tf.io.gfile.GFile(os.path.join(assets_path, ORIGINAL_VOCAB), \'w\') as f:\n    f.write(str(ORIGINAL_VOCAB))\n\n  return path\n\n\nclass RewritingExporterTest(tf.test.TestCase):\n\n  class _TestRewriter(rewriter.BaseRewriter):\n\n    def __init__(self, rewrite_raises_error):\n      """"""Initializes the MyRewriter class.\n\n      Args:\n        rewrite_raises_error: Boolean specifying whether to raise a ValueError.\n      """"""\n      self._rewrite_raises_error = rewrite_raises_error\n      self.rewrite_called = False\n\n    @property\n    def name(self):\n      return \'test_rewriter\'\n\n    def _pre_rewrite_validate(self, original_model):\n      pass\n\n    def _rewrite(self, original_model, rewritten_model):\n      self.rewrite_called = True\n      assert tf.io.gfile.exists(\n          os.path.join(original_model.path, ORIGINAL_SAVED_MODEL))\n      assert tf.io.gfile.exists(\n          os.path.join(original_model.path, tf.saved_model.ASSETS_DIRECTORY,\n                       ORIGINAL_VOCAB))\n      with tf.io.gfile.GFile(\n          os.path.join(rewritten_model.path, REWRITTEN_SAVED_MODEL), \'w\') as f:\n        f.write(str(REWRITTEN_SAVED_MODEL))\n      assets_path = os.path.join(rewritten_model.path,\n                                 tf.saved_model.ASSETS_DIRECTORY)\n      tf.io.gfile.makedirs(assets_path)\n      with tf.io.gfile.GFile(os.path.join(assets_path, REWRITTEN_VOCAB),\n                             \'w\') as f:\n        f.write(str(REWRITTEN_VOCAB))\n      if self._rewrite_raises_error:\n        raise ValueError(\'rewrite-error\')\n\n    def _post_rewrite_validate(self, rewritten_model):\n      pass\n\n  def setUp(self):\n    super(RewritingExporterTest, self).setUp()\n    self._estimator = \'estimator\'\n    self._export_path = tempfile.mkdtemp()\n    self._checkpoint_path = \'checkpoint_path\'\n    self._eval_result = \'eval_result\'\n    self._is_the_final_export = True\n    self._base_exporter = tf.estimator.FinalExporter(\n        name=\'base_exporter\', serving_input_receiver_fn=lambda: None)\n\n  @mock.patch.object(tf.estimator.FinalExporter, \'export\')\n  def testRewritingExporterSucceeds(self, base_exporter_mock):\n\n    base_exporter_mock.side_effect = _export_fn\n\n    tr = self._TestRewriter(False)\n    r_e = converters.RewritingExporter(self._base_exporter, tr)\n    final_path = r_e.export(self._estimator, self._export_path,\n                            self._checkpoint_path, self._eval_result,\n                            self._is_the_final_export)\n    self.assertEqual(final_path,\n                     os.path.join(self._export_path, BASE_EXPORT_SUBDIR))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(final_path, REWRITTEN_SAVED_MODEL)))\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(final_path, tf.saved_model.ASSETS_DIRECTORY,\n                         REWRITTEN_VOCAB)))\n\n    base_exporter_mock.assert_called_once_with(self._estimator,\n                                               self._export_path,\n                                               self._checkpoint_path,\n                                               self._eval_result,\n                                               self._is_the_final_export)\n\n  @mock.patch.object(tf.estimator.FinalExporter, \'export\')\n  def testRewritingHandlesNoBaseExport(self, base_exporter_mock):\n\n    base_exporter_mock.return_value = None\n\n    tr = self._TestRewriter(False)\n    r_e = converters.RewritingExporter(self._base_exporter, tr)\n    final_path = r_e.export(self._estimator, self._export_path,\n                            self._checkpoint_path, self._eval_result,\n                            self._is_the_final_export)\n    self.assertEqual(final_path, None)\n    self.assertFalse(tr.rewrite_called)\n\n    base_exporter_mock.assert_called_once_with(self._estimator,\n                                               self._export_path,\n                                               self._checkpoint_path,\n                                               self._eval_result,\n                                               self._is_the_final_export)\n\n  @mock.patch.object(tf.estimator.FinalExporter, \'export\')\n  def testRewritingExporterHandlesError(self, base_exporter_mock):\n\n    base_exporter_mock.side_effect = _export_fn\n\n    tr = self._TestRewriter(True)\n    r_e = converters.RewritingExporter(self._base_exporter, tr)\n    with self.assertRaisesRegex(ValueError, \'.*rewrite-error\'):\n      r_e.export(self._estimator, self._export_path, self._checkpoint_path,\n                 self._eval_result, self._is_the_final_export)\n    base_exporter_mock.assert_called_once_with(self._estimator,\n                                               self._export_path,\n                                               self._checkpoint_path,\n                                               self._eval_result,\n                                               self._is_the_final_export)\n    self.assertTrue(tr.rewrite_called)\n\n\nclass RewriteSavedModelTest(tf.test.TestCase):\n\n  @mock.patch.object(converters, \'_invoke_rewriter\')\n  def testRewritingExporterSucceeds(self, invoke_rewriter_mock):\n    src = \'/my/src\'\n    dst = \'/my/dst\'\n    rewriter_inst = \'r1\'\n    converters.rewrite_saved_model(src, dst, rewriter_inst)\n    invoke_rewriter_mock.assert_called_once_with(src, dst, rewriter_inst,\n                                                 rewriter.ModelType.SAVED_MODEL,\n                                                 rewriter.ModelType.SAVED_MODEL)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/trainer/rewriting/rewriter.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class that TFX rewriters inherit and invocation utilities.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport collections\nimport enum\n\nfrom typing import Text\n\nimport six\n\nModelDescription = collections.namedtuple(\'ModelDescription\',\n                                          [\'model_type\', \'path\'])\n\n\nclass ModelType(enum.Enum):\n  """"""Types of models used or created by the rewriter.""""""\n  ANY_MODEL = 1\n  SAVED_MODEL = 2\n  TFLITE_MODEL = 3\n  TFJS_MODEL = 4\n\n\nclass BaseRewriter(six.with_metaclass(abc.ABCMeta, object)):\n  """"""Base class from which all rewriters should inherit.""""""\n\n  @abc.abstractproperty\n  def name(self) -> Text:\n    """"""Name of the rewriter.\n\n    Should not be `None` nor empty.\n    """"""\n    pass\n\n  @abc.abstractmethod\n  def _pre_rewrite_validate(self, original_model: ModelDescription):\n    """"""Perform pre-rewrite validation to check the model has expected structure.\n\n    Args:\n      original_model: A `ModelDescription` object describing the original model.\n\n    Raises:\n      ValueError: If the original model does not have the expected structure.\n    """"""\n    pass\n\n  @abc.abstractmethod\n  def _rewrite(self, original_model: ModelDescription,\n               rewritten_model: ModelDescription):\n    """"""Perform the rewrite.\n\n    Args:\n      original_model: A `ModelDescription` object describing the original model.\n      rewritten_model: A `ModelDescription` object describing the location and\n        type of the rewritten output.\n\n    Raises:\n      ValueError: If the original model was not successfully rewritten.\n    """"""\n    pass\n\n  @abc.abstractmethod\n  def _post_rewrite_validate(self, rewritten_model: ModelDescription):\n    """"""Perform post-rewrite validation.\n\n    Args:\n      rewritten_model: A `ModelDescription` object describing the location and\n        type of the rewritten output.\n\n    Raises:\n      ValueError: If the rewritten model is not valid.\n    """"""\n    pass\n\n  def perform_rewrite(self, original_model: ModelDescription,\n                      rewritten_model: ModelDescription):\n    """"""Invoke all validations and perform the rewrite.\n\n    Args:\n      original_model: A `base_rewriter.ModelDescription` object describing the\n        original model.\n      rewritten_model: A `base_rewriter.ModelDescription` object describing the\n        location and type of the rewritten model.\n\n    Raises:\n      ValueError: if the model was not successfully rewritten.\n    """"""\n    try:\n      self._pre_rewrite_validate(original_model)\n    except ValueError as v:\n      raise ValueError(\'{} failed to perform pre-rewrite validation. Original \'\n                       \'model: {}. Error: {}\'.format(self.name,\n                                                     str(original_model),\n                                                     str(v)))\n\n    try:\n      self._rewrite(original_model, rewritten_model)\n    except ValueError as v:\n      raise ValueError(\n          \'{} failed to rewrite model. Original model: {}. Error {}\'.format(\n              self.name, str(original_model), str(v)))\n\n    try:\n      self._post_rewrite_validate(rewritten_model)\n    except ValueError as v:\n      raise ValueError(\n          \'{} failed to validate rewritten model. Rewritten model: {}. Error {}\'\n          .format(self.name, str(rewritten_model), str(v)))\n'"
tfx/components/trainer/rewriting/rewriter_factory.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Factory for instantiating rewriters.\n\nNOTE: For your rewriter to be instanitated, please include it as an import and\na constant for ease of invoking the new rewriter.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nfrom tfx.components.trainer.rewriting import rewriter\nfrom tfx.components.trainer.rewriting import tfjs_rewriter  # pylint: disable=unused-import\nfrom tfx.components.trainer.rewriting import tflite_rewriter  # pylint: disable=unused-import\n\nTFLITE_REWRITER = ""TFLiteRewriter""\nTFJS_REWRITER = ""TFJSRewriter""\n\n\ndef create_rewriter(rewriter_type: Text, *args,\n                    **kwargs) -> rewriter.BaseRewriter:\n  """"""Instantiates a new rewriter with the given type and constructor arguments.\n\n  Args:\n    rewriter_type: The rewriter subclass to instantiate (can be all lowercase).\n    *args: Positional initialization arguments to pass to the rewriter.\n    **kwargs: Keyward initialization arguments to pass to the rewriter.\n\n  Returns:\n    The instantiated rewriter.\n  Raises:\n    ValueError: If unable to instantiate the rewriter.\n  """"""\n  for c in rewriter.BaseRewriter.__subclasses__():\n    if (c.__name__.lower()) == rewriter_type.lower():\n      return c(*args, **kwargs)\n  raise ValueError(""Failed to find rewriter: {}"".format(rewriter_type))\n'"
tfx/components/trainer/rewriting/rewriter_factory_test.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for third_party.tfx.components.trainer.rewriting.rewriter_factory.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nfrom tfx.components.trainer.rewriting import rewriter_factory\n\n\nclass RewriterFactoryTest(parameterized.TestCase):\n\n  @parameterized.named_parameters((\'TFJS\', rewriter_factory.TFJS_REWRITER),\n                                  (\'TFLite\', rewriter_factory.TFLITE_REWRITER))\n  def testRewriterFactorySuccessfullyCreatedRewriter(self, rewriter_name):\n    tfrw = rewriter_factory.create_rewriter(rewriter_name, name=\'my_rewriter\')\n    self.assertTrue(tfrw)\n    self.assertEqual(tfrw.name, \'my_rewriter\')\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
tfx/components/trainer/rewriting/rewriter_test.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for third_party.components.trainer.rewriting.rewriter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import absltest\nfrom tfx.components.trainer.rewriting import rewriter\n\n\nclass PerformRewriteTest(absltest.TestCase):\n\n  class MyRewriter(rewriter.BaseRewriter):\n\n    def __init__(self, pre_rewrite_validate_raises_error, rewrite_raises_error,\n                 post_rewrite_validate_raises_error, expected_original_model,\n                 expected_rewritten_model):\n      """"""Initializes the MyRewriter class.\n\n      Args:\n        pre_rewrite_validate_raises_error: Boolean specifying if\n          pre_rewrite_validate raises ValueError.\n        rewrite_raises_error: Boolean specifying if rewrite raises ValueError.\n        post_rewrite_validate_raises_error: Boolean specifying if\n          post_rewrite_validate raises ValueError.\n        expected_original_model: A `rewriter.ModelDescription` specifying\n          the expected original model.\n        expected_rewritten_model: A `rewriter.ModelDescription` specifying\n          the expected rewritten model.\n      """"""\n      self._pre_rewrite_validate_raises_error = (\n          pre_rewrite_validate_raises_error)\n      self._rewrite_raises_error = rewrite_raises_error\n      self._post_rewrite_validate_raises_error = (\n          post_rewrite_validate_raises_error)\n      self._expected_original_model = expected_original_model\n      self._expected_rewritten_model = expected_rewritten_model\n\n      self.pre_rewrite_validate_called = False\n      self.rewrite_called = False\n      self.post_rewrite_validate_called = False\n\n    @property\n    def name(self):\n      return \'my_rewriter\'\n\n    def _pre_rewrite_validate(self, original_model):\n      assert original_model == self._expected_original_model\n      self.pre_rewrite_validate_called = True\n      if self._pre_rewrite_validate_raises_error:\n        raise ValueError(\'pre-rewrite-validate-error\')\n\n    def _rewrite(self, original_model, rewritten_model):\n      assert original_model == self._expected_original_model\n      assert rewritten_model == self._expected_rewritten_model\n      self.rewrite_called = True\n      if self._rewrite_raises_error:\n        raise ValueError(\'rewrite-error\')\n\n    def _post_rewrite_validate(self, rewritten_model):\n      assert rewritten_model == self._expected_rewritten_model\n      self.post_rewrite_validate_called = True\n      if self._post_rewrite_validate_raises_error:\n        raise ValueError(\'post-rewrite-validate-error\')\n\n  def setUp(self):\n    super(PerformRewriteTest, self).setUp()\n    src_model_path = \'/path/to/src/model\'\n    dst_model_path = \'/path/to/dst/model\'\n    self._source_model = rewriter.ModelDescription(\n        rewriter.ModelType.SAVED_MODEL, src_model_path)\n\n    self._dest_model = rewriter.ModelDescription(\n        rewriter.ModelType.SAVED_MODEL, dst_model_path)\n\n  def testPerformRewriteCallsAllValidationsAndRewrites(self):\n    rw = self.MyRewriter(False, False, False, self._source_model,\n                         self._dest_model)\n    rw.perform_rewrite(self._source_model, self._dest_model)\n    self.assertTrue(rw.pre_rewrite_validate_called)\n    self.assertTrue(rw.rewrite_called)\n    self.assertTrue(rw.post_rewrite_validate_called)\n\n  def testPerformRewriteStopsOnFailedPreRewriteValidation(self):\n    rw = self.MyRewriter(True, False, False, self._source_model,\n                         self._dest_model)\n    with self.assertRaisesRegex(ValueError, \'.*pre-rewrite-validate-error\'):\n      rw.perform_rewrite(self._source_model, self._dest_model)\n    self.assertTrue(rw.pre_rewrite_validate_called)\n    self.assertFalse(rw.rewrite_called)\n    self.assertFalse(rw.post_rewrite_validate_called)\n\n  def testPeformRewriteStopsOnFailedRewrite(self):\n    rw = self.MyRewriter(False, True, False, self._source_model,\n                         self._dest_model)\n    with self.assertRaisesRegex(ValueError, \'.*rewrite-error\'):\n      rw.perform_rewrite(self._source_model, self._dest_model)\n    self.assertTrue(rw.pre_rewrite_validate_called)\n    self.assertTrue(rw.rewrite_called)\n    self.assertFalse(rw.post_rewrite_validate_called)\n\n  def testPerformRewriteStopsOnFailedPostRewriteValidation(self):\n    rw = self.MyRewriter(False, False, True, self._source_model,\n                         self._dest_model)\n    with self.assertRaisesRegex(ValueError, \'.*post-rewrite-validate-error\'):\n      rw.perform_rewrite(self._source_model, self._dest_model)\n    self.assertTrue(rw.pre_rewrite_validate_called)\n    self.assertTrue(rw.rewrite_called)\n    self.assertTrue(rw.post_rewrite_validate_called)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
tfx/components/trainer/rewriting/tfjs_rewriter.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Rewriter that invokes the TFJS converter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport six\n\nfrom tensorflowjs.converters import converter\n\nfrom tfx.components.trainer.rewriting import rewriter\n\nCONVERTER_SAVED_MODEL_INPUT_FLAG = \'--input_format=tf_saved_model\'\nCONVERTER_SERVING_TAG_FLAG = \'--saved_model_tags=serve\'\nCONVERTER_DEFAULT_SIGNATURE_FLAG = \'--signature_name=serving_default\'\n\n\ndef _convert_tfjs_model(saved_model_path: Text, destination_path: Text):\n  converter.convert([\n      CONVERTER_SAVED_MODEL_INPUT_FLAG, CONVERTER_SERVING_TAG_FLAG,\n      CONVERTER_DEFAULT_SIGNATURE_FLAG,\n      saved_model_path, destination_path\n  ])\n\n\nclass TFJSRewriter(rewriter.BaseRewriter):\n  """"""Performs TFJS conversion.""""""\n\n  def __init__(self, name: Text):\n    """"""Create an instance of the TFJSRewriter.\n\n    Args:\n      name: The name to use when identifying the rewriter.\n    """"""\n    self._name = name\n\n  @property\n  def name(self) -> Text:\n    """"""The user-specified name of the rewriter.""""""\n    return self._name\n\n  def _pre_rewrite_validate(self, original_model: rewriter.ModelDescription):\n    """"""Performs pre-rewrite checks to see if the model can be rewritten.\n\n    Args:\n      original_model: A `ModelDescription` object describing the model to be\n        rewritten.\n\n    Raises:\n      ValueError: If the original model does not have the expected structure.\n    """"""\n    if original_model.model_type != rewriter.ModelType.SAVED_MODEL:\n      raise ValueError(\'TFJSRewriter can only convert SavedModels.\')\n\n  def _rewrite(self, original_model: rewriter.ModelDescription,\n               rewritten_model: rewriter.ModelDescription):\n    """"""Rewrites the provided model.\n\n    Args:\n      original_model: A `ModelDescription` specifying the original model to be\n        rewritten.\n      rewritten_model: A `ModelDescription` specifying the format and location\n        of the rewritten model.\n\n    Raises:\n      ValueError: If the model could not be sucessfully rewritten.\n    """"""\n    if rewritten_model.model_type not in [\n        rewriter.ModelType.TFJS_MODEL, rewriter.ModelType.ANY_MODEL\n    ]:\n      raise ValueError(\'TFJSConverter can only convert to the TFJS format.\')\n\n    _convert_tfjs_model(\n        six.ensure_text(original_model.path),\n        six.ensure_text(rewritten_model.path))\n\n  def _post_rewrite_validate(self, rewritten_model: rewriter.ModelDescription):\n    """"""Performs post-rewrite checks to see if the rewritten model is valid.\n\n    Args:\n      rewritten_model: A `ModelDescription` specifying the format and location\n        of the rewritten model.\n\n    Raises:\n      ValueError: If the rewritten model is not valid.\n    """"""\n    # TODO(dzats): Implement post-rewrite validation.\n    pass\n'"
tfx/components/trainer/rewriting/tfjs_rewriter_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for third_party.tfx.components.trainer.rewriting.tfjs_rewriter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\n\nimport tensorflow as tf\n\nfrom tfx.components.trainer.rewriting import rewriter\nfrom tfx.components.trainer.rewriting import tfjs_rewriter\n\n\nclass TFJSRewriterTest(tf.test.TestCase):\n\n  @mock.patch(\'tfx.components.trainer.rewriting.\'\n              \'tfjs_rewriter._convert_tfjs_model\')\n  def testInvokeTFJSRewriter(self, converter):\n    src_model_path = \'/path/to/src/model\'\n    dst_model_path = \'/path/to/dst/model\'\n\n    src_model = rewriter.ModelDescription(rewriter.ModelType.SAVED_MODEL,\n                                          src_model_path)\n    dst_model = rewriter.ModelDescription(rewriter.ModelType.TFJS_MODEL,\n                                          dst_model_path)\n\n    tfrw = tfjs_rewriter.TFJSRewriter(name=\'myrw\')\n    tfrw.perform_rewrite(src_model, dst_model)\n\n    converter.assert_called_once_with(src_model_path, dst_model_path)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/components/trainer/rewriting/tflite_rewriter.py,18,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Rewriter that invokes the TFLite converter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport time\n\nfrom typing import Text\n\nimport six\nimport tensorflow as tf\n\nfrom tfx.components.trainer.rewriting import rewriter\nfrom tfx.utils import io_utils\n\nEXTRA_ASSETS_DIRECTORY = \'assets.extra\'\n\n\ndef _create_tflite_converter(\n    saved_model_path: Text, enable_experimental_new_converter: bool,\n    enable_quantization: bool) -> tf.lite.TFLiteConverter:\n  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n  converter.experimental_new_converter = enable_experimental_new_converter\n  if enable_quantization:\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n  return converter\n\n\ndef _create_tflite_compatible_saved_model(src: Text, dst: Text):\n  io_utils.copy_dir(src, dst)\n  assets_path = os.path.join(dst, tf.saved_model.ASSETS_DIRECTORY)\n  if tf.io.gfile.exists(assets_path):\n    tf.io.gfile.rmtree(assets_path)\n  assets_extra_path = os.path.join(dst, EXTRA_ASSETS_DIRECTORY)\n  if tf.io.gfile.exists(assets_extra_path):\n    tf.io.gfile.rmtree(assets_extra_path)\n\n\nclass TFLiteRewriter(rewriter.BaseRewriter):\n  """"""Performs TFLite conversion.""""""\n\n  def __init__(self,\n               name: Text,\n               filename: Text = \'tflite\',\n               enable_experimental_new_converter: bool = False,\n               copy_assets: bool = True,\n               copy_assets_extra: bool = True,\n               enable_quantization: bool = False):\n    """"""Create an instance of the TFLiteRewriter.\n\n    Args:\n      name: The name to use when identifying the rewriter.\n      filename: The name of the file to use for the tflite model.\n      enable_experimental_new_converter: Whether to use the MLIR converter.\n      copy_assets: Boolean whether to copy the assets directory to the rewritten\n        model directory.\n      copy_assets_extra: Boolean whether to copy the assets.extra directory to\n        the rewritten model directory.\n      enable_quantization: Boolean whether to enable default TFLite\n        quantization.\n    """"""\n    # TODO(b/152636072): Add support for representative_dataset.\n    self._name = name\n    self._filename = six.ensure_text(filename)\n    self._enable_experimental_new_converter = enable_experimental_new_converter\n    self._copy_assets = copy_assets\n    self._copy_assets_extra = copy_assets_extra\n    self._enable_quantization = enable_quantization\n\n  @property\n  def name(self) -> Text:\n    """"""The user-specified name of the rewriter.""""""\n    return self._name\n\n  def _pre_rewrite_validate(self, original_model: rewriter.ModelDescription):\n    """"""Performs pre-rewrite checks to see if the model can be rewritten.\n\n    Args:\n      original_model: A `ModelDescription` object describing the model to be\n        rewritten.\n\n    Raises:\n      ValueError: If the original model does not have the expected structure.\n    """"""\n    if original_model.model_type != rewriter.ModelType.SAVED_MODEL:\n      raise ValueError(\'TFLiteRewriter can only convert SavedModels.\')\n\n  def _rewrite(self, original_model: rewriter.ModelDescription,\n               rewritten_model: rewriter.ModelDescription):\n    """"""Rewrites the provided model.\n\n    Args:\n      original_model: A `ModelDescription` specifying the original model to be\n        rewritten.\n      rewritten_model: A `ModelDescription` specifying the format and location\n        of the rewritten model.\n\n    Raises:\n      ValueError: If the model could not be sucessfully rewritten.\n    """"""\n    if rewritten_model.model_type not in [\n        rewriter.ModelType.TFLITE_MODEL, rewriter.ModelType.ANY_MODEL\n    ]:\n      raise ValueError(\'TFLiteConverter can only convert to the TFLite format.\')\n\n    # TODO(dzats): We create a temporary directory with a SavedModel that does\n    # not contain an assets or assets.extra directory. Remove this when the\n    # TFLite converter can convert models having these directories.\n    tmp_model_dir = os.path.join(\n        six.ensure_text(rewritten_model.path),\n        \'tmp-rewrite-\' + str(int(time.time())))\n    if tf.io.gfile.exists(tmp_model_dir):\n      raise ValueError(\'TFLiteConverter is unable to create a unique path \'\n                       \'for the temp rewriting directory.\')\n\n    tf.io.gfile.makedirs(tmp_model_dir)\n    _create_tflite_compatible_saved_model(\n        six.ensure_text(original_model.path), tmp_model_dir)\n\n    converter = _create_tflite_converter(\n        saved_model_path=tmp_model_dir,\n        enable_experimental_new_converter=self\n        ._enable_experimental_new_converter,\n        enable_quantization=self._enable_quantization)\n    tflite_model = converter.convert()\n\n    output_path = os.path.join(\n        six.ensure_text(rewritten_model.path), self._filename)\n    with tf.io.gfile.GFile(six.ensure_text(output_path), \'wb\') as f:\n      f.write(six.ensure_binary(tflite_model))\n    tf.io.gfile.rmtree(tmp_model_dir)\n\n    copy_pairs = []\n    if self._copy_assets:\n      src = os.path.join(\n          six.ensure_text(original_model.path), tf.saved_model.ASSETS_DIRECTORY)\n      dst = os.path.join(\n          six.ensure_text(rewritten_model.path),\n          tf.saved_model.ASSETS_DIRECTORY)\n      if tf.io.gfile.isdir(src):\n        tf.io.gfile.mkdir(dst)\n        copy_pairs.append((src, dst))\n    if self._copy_assets_extra:\n      src = os.path.join(\n          six.ensure_text(original_model.path), EXTRA_ASSETS_DIRECTORY)\n      dst = os.path.join(\n          six.ensure_text(rewritten_model.path), EXTRA_ASSETS_DIRECTORY)\n      if tf.io.gfile.isdir(src):\n        tf.io.gfile.mkdir(dst)\n        copy_pairs.append((src, dst))\n    for src, dst in copy_pairs:\n      io_utils.copy_dir(src, dst)\n\n  def _post_rewrite_validate(self, rewritten_model: rewriter.ModelDescription):\n    """"""Performs post-rewrite checks to see if the rewritten model is valid.\n\n    Args:\n      rewritten_model: A `ModelDescription` specifying the format and location\n        of the rewritten model.\n\n    Raises:\n      ValueError: If the rewritten model is not valid.\n    """"""\n    # TODO(dzats): Implement post-rewrite validation.\n    pass\n'"
tfx/components/trainer/rewriting/tflite_rewriter_test.py,18,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for third_party.tfx.components.trainer.rewriting.tflite_rewriter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tempfile\n\nimport mock\nimport six\n\nimport tensorflow as tf\n\nfrom tfx.components.trainer.rewriting import rewriter\nfrom tfx.components.trainer.rewriting import tflite_rewriter\n\nEXTRA_ASSETS_DIRECTORY = \'assets.extra\'\n\n\nclass TFLiteRewriterTest(tf.test.TestCase):\n\n  class ConverterMock(object):\n\n    def convert(self):\n      return \'model\'\n\n  @mock.patch(\'tfx.components.trainer.rewriting.\'\n              \'tflite_rewriter._create_tflite_converter\')\n  def testInvokeTFLiteRewriterNoAssetsSucceeds(self, converter):\n    m = self.ConverterMock()\n    converter.return_value = m\n\n    src_model_path = tempfile.mkdtemp()\n    dst_model_path = tempfile.mkdtemp()\n\n    saved_model_path = os.path.join(src_model_path,\n                                    tf.saved_model.SAVED_MODEL_FILENAME_PBTXT)\n    with tf.io.gfile.GFile(saved_model_path, \'wb\') as f:\n      f.write(six.ensure_binary(\'saved_model\'))\n\n    src_model = rewriter.ModelDescription(rewriter.ModelType.SAVED_MODEL,\n                                          src_model_path)\n    dst_model = rewriter.ModelDescription(rewriter.ModelType.TFLITE_MODEL,\n                                          dst_model_path)\n\n    tfrw = tflite_rewriter.TFLiteRewriter(\n        name=\'myrw\',\n        filename=\'fname\',\n        enable_experimental_new_converter=True)\n    tfrw.perform_rewrite(src_model, dst_model)\n\n    converter.assert_called_once_with(\n        saved_model_path=mock.ANY,\n        enable_experimental_new_converter=True,\n        enable_quantization=False)\n    expected_model = os.path.join(dst_model_path, \'fname\')\n    self.assertTrue(tf.io.gfile.exists(expected_model))\n    with tf.io.gfile.GFile(expected_model, \'rb\') as f:\n      self.assertEqual(six.ensure_text(f.readline()), \'model\')\n\n  @mock.patch(\'tfx.components.trainer.rewriting\'\n              \'.tflite_rewriter._create_tflite_converter\')\n  def testInvokeTFLiteRewriterWithAssetsSucceeds(self, converter):\n    m = self.ConverterMock()\n    converter.return_value = m\n\n    src_model_path = tempfile.mkdtemp()\n    dst_model_path = tempfile.mkdtemp()\n\n    saved_model_path = os.path.join(src_model_path,\n                                    tf.saved_model.SAVED_MODEL_FILENAME_PBTXT)\n    with tf.io.gfile.GFile(saved_model_path, \'wb\') as f:\n      f.write(six.ensure_binary(\'saved_model\'))\n\n    assets_dir = os.path.join(src_model_path, tf.saved_model.ASSETS_DIRECTORY)\n    tf.io.gfile.mkdir(assets_dir)\n    assets_file_path = os.path.join(assets_dir, \'assets_file\')\n    with tf.io.gfile.GFile(assets_file_path, \'wb\') as f:\n      f.write(six.ensure_binary(\'assets_file\'))\n\n    assets_extra_dir = os.path.join(src_model_path, EXTRA_ASSETS_DIRECTORY)\n    tf.io.gfile.mkdir(assets_extra_dir)\n    assets_extra_file_path = os.path.join(assets_extra_dir, \'assets_extra_file\')\n    with tf.io.gfile.GFile(assets_extra_file_path, \'wb\') as f:\n      f.write(six.ensure_binary(\'assets_extra_file\'))\n\n    src_model = rewriter.ModelDescription(rewriter.ModelType.SAVED_MODEL,\n                                          src_model_path)\n    dst_model = rewriter.ModelDescription(rewriter.ModelType.TFLITE_MODEL,\n                                          dst_model_path)\n\n    tfrw = tflite_rewriter.TFLiteRewriter(\n        name=\'myrw\',\n        filename=\'fname\',\n        enable_experimental_new_converter=True,\n        enable_quantization=True)\n    tfrw.perform_rewrite(src_model, dst_model)\n\n    converter.assert_called_once_with(\n        saved_model_path=mock.ANY,\n        enable_experimental_new_converter=True,\n        enable_quantization=True)\n    expected_model = os.path.join(dst_model_path, \'fname\')\n    self.assertTrue(tf.io.gfile.exists(expected_model))\n    with tf.io.gfile.GFile(expected_model, \'rb\') as f:\n      self.assertEqual(six.ensure_text(f.readline()), \'model\')\n\n    expected_assets_file = os.path.join(dst_model_path,\n                                        tf.saved_model.ASSETS_DIRECTORY,\n                                        \'assets_file\')\n    with tf.io.gfile.GFile(expected_assets_file, \'rb\') as f:\n      self.assertEqual(six.ensure_text(f.readline()), \'assets_file\')\n\n    expected_assets_extra_file = os.path.join(dst_model_path,\n                                              EXTRA_ASSETS_DIRECTORY,\n                                              \'assets_extra_file\')\n    with tf.io.gfile.GFile(expected_assets_extra_file, \'rb\') as f:\n      self.assertEqual(six.ensure_text(f.readline()), \'assets_extra_file\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/component/experimental/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/dsl/component/experimental/annotations.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Python function component type annotations.\n\nExperimental. No backwards compatibility guarantees.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport inspect\nfrom typing import Text, Type, Union\nfrom six import with_metaclass\n\nfrom tfx.types import artifact\n\n\nclass _ArtifactGenericMeta(type):\n  """"""Metaclass for _ArtifactGeneric, to enable class indexing.""""""\n\n  def __getitem__(cls: Type[\'_ArtifactGeneric\'],\n                  params: Type[artifact.Artifact]):\n    """"""Metaclass method allowing indexing class (`_ArtifactGeneric[T]`).""""""\n    return cls._generic_getitem(params)  # pytype: disable=attribute-error\n\n\nclass _ArtifactGeneric(with_metaclass(_ArtifactGenericMeta, object)):\n  """"""A generic that takes a Type[tfx.types.Artifact] as its single argument.""""""\n\n  def __init__(  # pylint: disable=invalid-name\n      self,\n      artifact_type: Type[artifact.Artifact],\n      _init_via_getitem=False):\n    if not _init_via_getitem:\n      class_name = self.__class__.__name__\n      raise ValueError(\n          (\'%s should be instantiated via the syntax `%s[T]`, where T is a \'\n           \'subclass of tfx.types.Artifact.\') % (class_name, class_name))\n    self.type = artifact_type\n\n  @classmethod\n  def _generic_getitem(cls, params):\n    """"""Return the result of `_ArtifactGeneric[T]` for a given type T.""""""\n    # Check that the given parameter is a concrete (i.e. non-abstract) subclass\n    # of `tfx.types.Artifact`.\n    if (inspect.isclass(params) and issubclass(params, artifact.Artifact) and\n        params.TYPE_NAME):\n      return cls(params, _init_via_getitem=True)\n    else:\n      class_name = cls.__name__\n      raise ValueError(\n          (\'Generic type `%s[T]` expects the single parameter T to be a \'\n           \'concrete subclass of `tfx.types.Artifact` (got %r instead).\') %\n          (class_name, params))\n\n  def __repr__(self):\n    return \'%s[%s]\' % (self.__class__.__name__, self.type)\n\n\nclass _PrimitiveTypeGenericMeta(type):\n  """"""Metaclass for _PrimitiveTypeGeneric, to enable primitive type indexing.""""""\n\n  def __getitem__(cls: Type[Union[int, float, Text, bytes]],\n                  params: Type[artifact.Artifact]):\n    """"""Metaclass method allowing indexing class (`_PrimitiveTypeGeneric[T]`).""""""\n    return cls._generic_getitem(params)  # pytype: disable=attribute-error\n\n\nclass _PrimitiveTypeGeneric(with_metaclass(_PrimitiveTypeGenericMeta, object)):\n  """"""A generic that takes a primitive type as its single argument.""""""\n\n  def __init__(  # pylint: disable=invalid-name\n      self,\n      artifact_type: Type[Union[int, float, Text, bytes]],\n      _init_via_getitem=False):\n    if not _init_via_getitem:\n      class_name = self.__class__.__name__\n      raise ValueError(\n          (\'%s should be instantiated via the syntax `%s[T]`, where T is \'\n           \'`int`, `float`, `str` or `bytes`.\') % (class_name, class_name))\n    self.type = artifact_type\n\n  @classmethod\n  def _generic_getitem(cls, params):\n    """"""Return the result of `_PrimitiveTypeGeneric[T]` for a given type T.""""""\n    # Check that the given parameter is a primitive type.\n    if inspect.isclass(params) and params in (int, float, Text, bytes):\n      return cls(params, _init_via_getitem=True)\n    else:\n      class_name = cls.__name__\n      raise ValueError(\n          (\'Generic type `%s[T]` expects the single parameter T to be \'\n           \'`int`, `float`, `str` or `bytes` (got %r instead).\') %\n          (class_name, params))\n\n  def __repr__(self):\n    return \'%s[%s]\' % (self.__class__.__name__, self.type)\n\n# Typehint annotations for component authoring.\n\n\nclass InputArtifact(_ArtifactGeneric):\n  """"""Input artifact object type annotation.""""""\n  pass\n\n\nclass OutputArtifact(_ArtifactGeneric):\n  """"""Output artifact object type annotation.""""""\n  pass\n\n\nclass Parameter(_PrimitiveTypeGeneric):\n  """"""Component parameter type annotation.""""""\n  pass\n\n\n# TODO(ccy): potentially make this compatible `typing.TypedDict` in\n# Python 3.8, to allow for component return value type checking.\nclass OutputDict(object):\n  """"""Decorator declaring component executor function outputs.""""""\n\n  def __init__(self, **kwargs):\n    self.kwargs = kwargs\n'"
tfx/dsl/component/experimental/annotations_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.annotations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom typing import Text\n\n# Standard Imports\n\nimport tensorflow as tf\n\nfrom tfx.dsl.component.experimental import annotations\nfrom tfx.types import artifact\nfrom tfx.types import standard_artifacts\n\n\nclass AnnotationsTest(tf.test.TestCase):\n\n  def testArtifactGenericAnnotation(self):\n    # Error: type hint whose parameter is not an Artifact subclass.\n    with self.assertRaisesRegexp(ValueError,\n                                 \'expects .* a concrete subclass of\'):\n      _ = annotations._ArtifactGeneric[int]\n\n    # Error: type hint with abstract Artifact subclass.\n    with self.assertRaisesRegexp(ValueError,\n                                 \'expects .* a concrete subclass of\'):\n      _ = annotations._ArtifactGeneric[artifact.Artifact]\n\n    # Error: type hint with abstract Artifact subclass.\n    with self.assertRaisesRegexp(ValueError,\n                                 \'expects .* a concrete subclass of\'):\n      _ = annotations._ArtifactGeneric[artifact.ValueArtifact]\n\n    # OK.\n    _ = annotations._ArtifactGeneric[standard_artifacts.Examples]\n\n  def testArtifactAnnotationUsage(self):\n    _ = annotations.InputArtifact[standard_artifacts.Examples]\n    _ = annotations.OutputArtifact[standard_artifacts.Examples]\n\n  def testPrimitiveTypeGenericAnnotation(self):\n    # Error: type hint whose parameter is not a primitive type\n    with self.assertRaisesRegexp(ValueError,\n                                 \'T to be `int`, `float`, `str` or `bytes`\'):\n      _ = annotations._PrimitiveTypeGeneric[artifact.Artifact]\n    with self.assertRaisesRegexp(ValueError,\n                                 \'T to be `int`, `float`, `str` or `bytes`\'):\n      _ = annotations._PrimitiveTypeGeneric[object]\n    with self.assertRaisesRegexp(ValueError,\n                                 \'T to be `int`, `float`, `str` or `bytes`\'):\n      _ = annotations._PrimitiveTypeGeneric[123]\n    with self.assertRaisesRegexp(ValueError,\n                                 \'T to be `int`, `float`, `str` or `bytes`\'):\n      _ = annotations._PrimitiveTypeGeneric[\'string\']\n\n    # OK.\n    _ = annotations._PrimitiveTypeGeneric[int]\n    _ = annotations._PrimitiveTypeGeneric[float]\n    _ = annotations._PrimitiveTypeGeneric[Text]\n    _ = annotations._PrimitiveTypeGeneric[bytes]\n\n  def testParameterUsage(self):\n    _ = annotations.Parameter[int]\n    _ = annotations.Parameter[float]\n    _ = annotations.Parameter[Text]\n    _ = annotations.Parameter[bytes]\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/component/experimental/container_component.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Functions for creating container components.""""""\n\n# TODO(b/149535307): Remove __future__ imports\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Callable, List, Dict, Text\n\nfrom tfx.components.base import base_component\nfrom tfx.dsl.component.experimental import executor_specs\nfrom tfx.types import channel_utils\nfrom tfx.types import component_spec\n\n\ndef create_container_component(\n    name: Text,\n    image: Text,\n    command: List[executor_specs.CommandlineArgumentType],\n    inputs: Dict[Text, Any] = None,\n    outputs: Dict[Text, Any] = None,\n    parameters: Dict[Text, Any] = None,\n) -> Callable[..., base_component.BaseComponent]:\n  """"""Creates a container-based component.\n\n  Args:\n    name: The name of the component\n    image: Container image name.\n    command: Container entrypoint command-line. Not executed within a shell.\n      The command-line can use placeholder objects that will be replaced at\n      the compilation time. The placeholder objects can be imported from\n      tfx.dsl.component.experimental.placeholders.\n      Note that Jinja templates are not supported.\n\n    inputs: The list of component inputs\n    outputs: The list of component outputs\n    parameters: The list of component parameters\n\n  Returns:\n    Component that can be instantiated and user inside pipeline.\n\n  Example:\n\n    component = create_container_component(\n        name=\'TrainModel\',\n        inputs={\n            \'training_data\': Dataset,\n        },\n        outputs={\n            \'model\': Model,\n        },\n        parameters={\n            \'num_training_steps\': int,\n        },\n        image=\'gcr.io/my-project/my-trainer\',\n        command=[\n            \'python3\', \'my_trainer\',\n            \'--training_data_uri\', InputUriPlaceholder(\'training_data\'),\n            \'--model_uri\', OutputUriPlaceholder(\'model\'),\n            \'--num_training-steps\', InputValuePlaceholder(\'num_training_steps\'),\n        ]\n    )\n  """"""\n  if not name:\n    raise ValueError(\'Component name cannot be empty.\')\n\n  if inputs is None:\n    inputs = {}\n  if outputs is None:\n    outputs = {}\n  if parameters is None:\n    parameters = {}\n\n  input_channel_parameters = {}\n  output_channel_parameters = {}\n  output_channels = {}\n  execution_parameters = {}\n\n  for input_name, channel_type in inputs.items():\n    # TODO(b/155804245) Sanitize the names so that they\'re valid python names\n    input_channel_parameters[input_name] = (\n        component_spec.ChannelParameter(\n            type=channel_type,\n        ))\n\n  for output_name, channel_type in outputs.items():\n    # TODO(b/155804245) Sanitize the names so that they\'re valid python names\n    output_channel_parameters[output_name] = (\n        component_spec.ChannelParameter(type=channel_type))\n    artifact = channel_type()\n    channel = channel_utils.as_channel([artifact])\n    output_channels[output_name] = channel\n\n  for param_name, parameter_type in parameters.items():\n    # TODO(b/155804245) Sanitize the names so that they\'re valid python names\n\n    execution_parameters[param_name] = (\n        component_spec.ExecutionParameter(type=parameter_type))\n\n  tfx_component_spec_class = type(\n      name + \'Spec\',\n      (component_spec.ComponentSpec,),\n      dict(\n          PARAMETERS=execution_parameters,\n          INPUTS=input_channel_parameters,\n          OUTPUTS=output_channel_parameters,\n      ),\n  )\n\n  def tfx_component_class_init(self, **kwargs):\n    instance_name = kwargs.pop(\'instance_name\', None)\n    arguments = {}\n    arguments.update(output_channels)\n    arguments.update(kwargs)\n\n    base_component.BaseComponent.__init__(\n        self,\n        spec=self.__class__.SPEC_CLASS(**arguments),\n        instance_name=instance_name,\n    )\n\n  tfx_component_class = type(\n      name,\n      (base_component.BaseComponent,),\n      dict(\n          SPEC_CLASS=tfx_component_spec_class,\n          EXECUTOR_SPEC=executor_specs.TemplatedExecutorContainerSpec(\n              image=image,\n              command=command,\n          ),\n          __init__=tfx_component_class_init,\n      ),\n  )\n  return tfx_component_class\n'"
tfx/dsl/component/experimental/decorators.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Decorators for defining components via Python functions.\n\nExperimental: no backwards compatibility guarantees.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\nimport types\nfrom typing import Any, Callable, Dict, List, Text\n\n# Standard Imports\n\nimport six\n\nfrom tfx import types as tfx_types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental import function_parser\nfrom tfx.types import channel_utils\nfrom tfx.types import component_spec\n\n\nclass _SimpleComponent(base_component.BaseComponent):\n  """"""Component whose constructor generates spec instance from arguments.""""""\n\n  def __init__(self, *unused_args, **kwargs):\n    if unused_args:\n      raise ValueError((\'%s expects arguments to be passed as keyword \'\n                        \'arguments\') % (self.__class__.__name__,))\n    spec_kwargs = {}\n    unseen_args = set(kwargs.keys())\n    for key, channel_parameter in self.SPEC_CLASS.INPUTS.items():\n      if key not in kwargs and not channel_parameter.optional:\n        raise ValueError(\'%s expects input %r to be a Channel of type %s.\' %\n                         (self.__class__.__name__, key, channel_parameter.type))\n      if key in kwargs:\n        spec_kwargs[key] = kwargs[key]\n        unseen_args.remove(key)\n    for key, parameter in self.SPEC_CLASS.PARAMETERS.items():\n      if key not in kwargs and not parameter.optional:\n        raise ValueError(\'%s expects parameter %r of type %s.\' %\n                         (self.__class__.__name__, key, parameter.type))\n      if key in kwargs:\n        spec_kwargs[key] = kwargs[key]\n        unseen_args.remove(key)\n    instance_name = kwargs.get(\'instance_name\', None)\n    unseen_args.discard(\'instance_name\')\n    if unseen_args:\n      raise ValueError(\n          \'Unknown arguments to %r: %s.\' %\n          (self.__class__.__name__, \', \'.join(sorted(unseen_args))))\n    for key, channel_parameter in self.SPEC_CLASS.OUTPUTS.items():\n      spec_kwargs[key] = channel_utils.as_channel([channel_parameter.type()])\n    spec = self.SPEC_CLASS(**spec_kwargs)\n    super(_SimpleComponent, self).__init__(spec, instance_name=instance_name)\n\n\nclass _FunctionExecutor(base_executor.BaseExecutor):\n  """"""Base class for function-based executors.""""""\n\n  # Properties that should be overridden by subclass. Defaults are provided to\n  # allow pytype to properly type check these properties.\n\n  # Describes the format of each argument passed to the component function, as\n  # a dictionary from name to a `function_parser.ArgFormats` enum value.\n  _ARG_FORMATS = {}\n  # Map from names of optional arguments to their default argument values.\n  _ARG_DEFAULTS = {}\n  # User-defined component function. Should be wrapped in staticmethod() to\n  # avoid being interpreted as a bound method (i.e. one taking `self` as its\n  # first argument.\n  _FUNCTION = staticmethod(lambda: None)\n  # Set of output names that are primitive type values returned from the user\n  # function.\n  _RETURNED_VALUES = set()\n\n  def Do(self, input_dict: Dict[Text, List[tfx_types.Artifact]],\n         output_dict: Dict[Text, List[tfx_types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    function_args = {}\n    for name, arg_format in self._ARG_FORMATS.items():\n      if arg_format == function_parser.ArgFormats.INPUT_ARTIFACT:\n        input_list = input_dict.get(name, [])\n        if len(input_list) == 1:\n          function_args[name] = input_list[0]\n        elif not input_list and name in self._ARG_DEFAULTS:\n          # Do not pass the missing optional input.\n          pass\n        else:\n          raise ValueError((\n              \'Expected input %r to %s to be a singleton ValueArtifact channel \'\n              \'(got %s instead).\') % (name, self, input_list))\n      elif arg_format == function_parser.ArgFormats.OUTPUT_ARTIFACT:\n        output_list = output_dict.get(name, [])\n        if len(output_list) == 1:\n          function_args[name] = output_list[0]\n        else:\n          raise ValueError((\n              \'Expected output %r to %s to be a singleton ValueArtifact channel \'\n              \'(got %s instead).\') % (name, self, output_list))\n      elif arg_format == function_parser.ArgFormats.ARTIFACT_VALUE:\n        input_list = input_dict.get(name, [])\n        if len(input_list) == 1:\n          function_args[name] = input_list[0].value\n        elif not input_list and name in self._ARG_DEFAULTS:\n          # Do not pass the missing optional input.\n          pass\n        else:\n          raise ValueError((\n              \'Expected input %r to %s to be a singleton ValueArtifact channel \'\n              \'(got %s instead).\') % (name, self, input_list))\n      elif arg_format == function_parser.ArgFormats.PARAMETER:\n        if name in exec_properties:\n          function_args[name] = exec_properties[name]\n        elif name in self._ARG_DEFAULTS:\n          # Do not pass the missing optional input.\n          pass\n        else:\n          raise ValueError((\n              \'Expected non-optional parameter %r of %s to be provided, but no \'\n              \'value was passed.\') % (name, self))\n      else:\n        raise ValueError(\'Unknown argument format: %r\' % (arg_format,))\n\n    # Call function and check returned values.\n    outputs = self._FUNCTION(**function_args)\n    outputs = outputs or {}\n    if not isinstance(outputs, dict):\n      raise ValueError(\n          (\'Expected component executor function %s to return a dict of \'\n           \'outputs (got %r instead).\') % (self._FUNCTION, outputs))\n\n    # Assign returned ValueArtifact values.\n    for name in self._RETURNED_VALUES:\n      if name not in outputs:\n        raise ValueError(\n            \'Did not receive expected output %r as return value from \'\n            \'component executor function %s.\' % (name, self._FUNCTION))\n      try:\n        output_dict[name][0].value = outputs[name]\n      except TypeError:\n        raise TypeError(\n            (\'Return value %r for output %r is incompatible with output type \'\n             \'%r.\') % (outputs[name], name, output_dict[name][0].__class__))\n\n\ndef component(func: types.FunctionType) -> Callable[..., Any]:\n  """"""Decorator: creates a component from a typehint-annotated Python function.\n\n  This decorator creates a component based on typehint annotations specified for\n  the arguments and return value for a Python function. Specifically, function\n  arguments can be annotated with the following types and associated semantics:\n\n  * `Parameter[T]` where `T` is `int`, `float`, `str`, or `bytes`: indicates\n    that a primitive type execution parameter, whose value is known at pipeline\n    construction time, will be passed for this argument. These parameters will\n    be recorded in ML Metadata as part of the component\'s execution record. Can\n    be an optional argument.\n  * `int`, `float`, `str`, `bytes`: indicates that a primitive type value will\n    be passed for this argument. This value is tracked as an `Integer`, `Float`\n    `String` or `Bytes` artifact (see `tfx.types.standard_artifacts`) whose\n    value is read and passed into the given Python component function. Can be\n    an optional argument.\n  * `InputArtifact[ArtifactType]`: indicates that an input artifact object of\n    type `ArtifactType` (deriving from `tfx.types.Artifact`) will be passed for\n    this argument. This artifact is intended to be consumed as an input by this\n    component (possibly reading from the path specified by its `.uri`). Can be\n    an optional argument by specifying a default value of `None`.\n  * `OutputArtifact[ArtifactType]`: indicates that an output artifact object of\n    type `ArtifactType` (deriving from `tfx.types.Artifact`) will be passed for\n    this argument. This artifact is intended to be emitted as an output by this\n    component (and written to the path specified by its `.uri`). Cannot be an\n    optional argument.\n\n  The return value typehint should be either empty or `None`, in the case of a\n  component function that has no return values, or an instance of\n  `OutputDict(key_1=type_1, ...)`, where each key maps to a given type (each\n  type is a primitive value type, i.e. `int`, `float`, `str` or `bytes`), to\n  indicate that the return value is a dictionary with specified keys and value\n  types.\n\n  Note that output artifacts should not be included in the return value\n  typehint; they should be included as `OutputArtifact` annotations in the\n  function inputs, as described above.\n\n  The function to which this decorator is applied must be at the top level of\n  its Python module (it may not be defined within nested classes or function\n  closures).\n\n  This is example usage of component definition using this decorator:\n\n      from tfx.components.base.annotations import OutputDict\n      from tfx.components.base.annotations import\n      InputArtifact\n      from tfx.components.base.annotations import\n      OutputArtifact\n      from tfx.components.base.annotations import\n      Parameter\n      from tfx.components.base.decorators import component\n      from tfx.types.standard_artifacts import Examples\n      from tfx.types.standard_artifacts import Model\n\n      @component\n      def MyTrainerComponent(\n          training_data: InputArtifact[Examples],\n          model: OutputArtifact[Model],\n          dropout_hyperparameter: float,\n          num_iterations: Parameter[int] = 10\n          ) -> OutputDict(loss=float, accuracy=float):\n        \'\'\'My simple trainer component.\'\'\'\n\n        records = read_examples(training_data.uri)\n        model_obj = train_model(records, num_iterations, dropout_hyperparameter)\n        model_obj.write_to(model.uri)\n\n        return {\n          \'loss\': model_obj.loss,\n          \'accuracy\': model_obj.accuracy\n        }\n\n      # Example usage in a pipeline graph definition:\n      # ...\n      trainer = MyTrainerComponent(\n          examples=example_gen.outputs[\'examples\'],\n          dropout_hyperparameter=other_component.outputs[\'dropout\'],\n          num_iterations=1000)\n      pusher = Pusher(model=trainer.outputs[\'model\'])\n      # ...\n\n  Experimental: no backwards compatibility guarantees.\n\n  Args:\n    func: Typehint-annotated component executor function.\n\n  Returns:\n    `base_component.BaseComponent` subclass for the given component executor\n    function.\n\n  Raises:\n    EnvironmentError: if the current Python interpreter is not Python 3.\n  """"""\n  if six.PY2:\n    raise EnvironmentError(\'`@component` is only supported in Python 3.\')\n\n  # Defining a component within a nested class or function closure causes\n  # problems because in this case, the generated component classes can\'t be\n  # referenced via their qualified module path.\n  #\n  # See https://www.python.org/dev/peps/pep-3155/ for details about the special\n  # \'<locals>\' namespace marker.\n  if \'<locals>\' in func.__qualname__.split(\'.\'):\n    raise ValueError(\n        \'The @component decorator can only be applied to a function defined \'\n        \'at the module level. It cannot be used to construct a component for a \'\n        \'function defined in a nested class or function closure.\')\n\n  inputs, outputs, parameters, arg_formats, arg_defaults, returned_values = (\n      function_parser.parse_typehint_component_function(func))\n\n  spec_inputs = {}\n  spec_outputs = {}\n  spec_parameters = {}\n  for key, artifact_type in inputs.items():\n    spec_inputs[key] = component_spec.ChannelParameter(\n        type=artifact_type, optional=(key in arg_defaults))\n  for key, artifact_type in outputs.items():\n    assert key not in arg_defaults, \'Optional outputs are not supported.\'\n    spec_outputs[key] = component_spec.ChannelParameter(type=artifact_type)\n  for key, primitive_type in parameters.items():\n    spec_parameters[key] = component_spec.ExecutionParameter(\n        type=primitive_type, optional=(key in arg_defaults))\n  component_spec_class = type(\n      \'%s_Spec\' % func.__name__, (tfx_types.ComponentSpec,), {\n          \'INPUTS\': spec_inputs,\n          \'OUTPUTS\': spec_outputs,\n          \'PARAMETERS\': spec_parameters,\n      })\n\n  executor_class = type(\n      \'%s_Executor\' % func.__name__,\n      (_FunctionExecutor,),\n      {\n          \'_ARG_FORMATS\': arg_formats,\n          \'_ARG_DEFAULTS\': arg_defaults,\n          # The function needs to be marked with `staticmethod` so that later\n          # references of `self._FUNCTION` do not result in a bound method (i.e.\n          # one with `self` as its first parameter).\n          \'_FUNCTION\': staticmethod(func),\n          \'_RETURNED_VALUES\': returned_values,\n          \'__module__\': func.__module__,\n      })\n\n  # Expose the generated executor class in the same module as the decorated\n  # function. This is needed so that the executor class can be accessed at the\n  # proper module path. One place this is needed is in the Dill pickler used by\n  # Apache Beam serialization.\n  module = sys.modules[func.__module__]\n  setattr(module, \'%s_Executor\' % func.__name__, executor_class)\n\n  executor_spec_instance = executor_spec.ExecutorClassSpec(\n      executor_class=executor_class)\n\n  return type(\n      func.__name__, (_SimpleComponent,), {\n          \'SPEC_CLASS\': component_spec_class,\n          \'EXECUTOR_SPEC\': executor_spec_instance,\n          \'__module__\': func.__module__,\n      })\n'"
tfx/dsl/component/experimental/decorators_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.decorators.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Optional, Text\nimport unittest\n\n# Standard Imports\n\nimport six\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental.annotations import InputArtifact\nfrom tfx.dsl.component.experimental.annotations import OutputArtifact\nfrom tfx.dsl.component.experimental.annotations import OutputDict\nfrom tfx.dsl.component.experimental.annotations import Parameter\nfrom tfx.dsl.component.experimental.decorators import _SimpleComponent\nfrom tfx.dsl.component.experimental.decorators import component\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam import beam_dag_runner\nfrom tfx.types import component_spec\nfrom tfx.types import standard_artifacts\n\n\nclass _InputArtifact(types.Artifact):\n  TYPE_NAME = \'_InputArtifact\'\n\n\nclass _OutputArtifact(types.Artifact):\n  TYPE_NAME = \'_OutputArtifact\'\n\n\nclass _BasicComponentSpec(component_spec.ComponentSpec):\n\n  PARAMETERS = {\n      \'folds\': component_spec.ExecutionParameter(type=int),\n  }\n  INPUTS = {\n      \'input\': component_spec.ChannelParameter(type=_InputArtifact),\n  }\n  OUTPUTS = {\n      \'output\': component_spec.ChannelParameter(type=_OutputArtifact),\n  }\n\n\nif not six.PY2:\n  # Currently, function components must be defined at the module level (not in\n  # nested class or function scope). We define the test components here.\n\n  @component\n  def _injector_1(\n      foo: Parameter[int], bar: Parameter[Text]) -> OutputDict(\n          a=int, b=int, c=Text, d=bytes):\n    assert foo == 9\n    assert bar == \'secret\'\n    return {\'a\': 10, \'b\': 22, \'c\': \'unicode\', \'d\': b\'bytes\'}\n\n  @component\n  def _simple_component(a: int, b: int, c: Text, d: bytes) -> OutputDict(\n      e=float, f=float):\n    del c, d\n    return {\'e\': float(a + b), \'f\': float(a * b)}\n\n  @component\n  def _verify(e: float, f: float):\n    assert (e, f) == (32.0, 220.0), (e, f)\n\n  @component\n  def _injector_2(\n      examples: OutputArtifact[standard_artifacts.Examples]\n  ) -> OutputDict(\n      a=int, b=float, c=Text, d=bytes, e=Text):\n    tf.io.gfile.makedirs(examples.uri)\n    return {\'a\': 1, \'b\': 2.0, \'c\': \'3\', \'d\': b\'4\', \'e\': \'passed\'}\n\n  @component\n  def _optionalarg_component(\n      foo: Parameter[int],\n      bar: Parameter[Text],\n      examples: InputArtifact[standard_artifacts.Examples],\n      a: int,\n      b: float,\n      c: Text,\n      d: bytes,\n      e1: Text = \'default\',\n      e2: Optional[Text] = \'default\',\n      f: bytes = b\'default\',\n      g: Parameter[float] = 1000.0,\n      h: Parameter[Text] = \'2000\',\n      optional_examples_1: InputArtifact[standard_artifacts.Examples] = None,\n      optional_examples_2: InputArtifact[standard_artifacts.Examples] = None):\n    # Test non-optional parameters.\n    assert foo == 9\n    assert bar == \'secret\'\n    assert isinstance(examples, standard_artifacts.Examples)\n    # Test non-optional `int`, `float`, `Text` and `bytes` input values.\n    assert a == 1\n    assert b == 2.0\n    assert c == \'3\'\n    assert d == b\'4\'\n    # Test passed optional arguments (with and without the `Optional` typehint\n    # specifier).\n    assert e1 == \'passed\'\n    assert e2 == \'passed\'\n    # Test that non-passed optional argument becomes the argument default.\n    assert f == b\'default\'\n    # Test passed optional parameter.\n    assert g == 999.0\n    # Test non-passed optional parameter.\n    assert h == \'2000\'\n    # Test passed optional input artifact.\n    assert optional_examples_1 and optional_examples_1.uri\n    # Test non-passed optional input artifact.\n    assert optional_examples_2 is None\n\n\n@unittest.skipIf(six.PY2, \'Not compatible with Python 2.\')\nclass ComponentDecoratorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ComponentDecoratorTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._metadata_path = os.path.join(self._test_dir, \'metadata.db\')\n\n  def testSimpleComponent(self):\n\n    class _MySimpleComponent(_SimpleComponent):\n      SPEC_CLASS = _BasicComponentSpec\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(\n          base_executor.BaseExecutor)\n\n    input_channel = types.Channel(type=_InputArtifact)\n    instance = _MySimpleComponent(input=input_channel, folds=10,\n                                  instance_name=\'my_instance\')\n    self.assertIs(instance.inputs[\'input\'], input_channel)\n    self.assertEqual(instance.outputs[\'output\'].type, _OutputArtifact)\n    self.assertEqual(instance._instance_name, \'my_instance\')\n\n  def testDefinitionInClosureFails(self):\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The @component decorator can only be applied to a function defined at \'\n        \'the module level\'):\n\n      @component\n      def my_component():  # pylint: disable=unused-variable\n        return None\n\n  def testNonKwargFails(self):\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'expects arguments to be passed as keyword arguments\'):\n      _injector_1(9, \'secret\')\n\n  def testBeamExecutionSuccess(self):\n    """"""Test execution with return values; success case.""""""\n    instance_1 = _injector_1(foo=9, bar=\'secret\')\n    instance_2 = _simple_component(\n        a=instance_1.outputs[\'a\'],\n        b=instance_1.outputs[\'b\'],\n        c=instance_1.outputs[\'c\'],\n        d=instance_1.outputs[\'d\'])\n    instance_3 = _verify(e=instance_2.outputs[\'e\'], f=instance_2.outputs[\'f\'])  # pylint: disable=assignment-from-no-return\n\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    test_pipeline = pipeline.Pipeline(\n        pipeline_name=\'test_pipeline_1\',\n        pipeline_root=self._test_dir,\n        metadata_connection_config=metadata_config,\n        components=[instance_1, instance_2, instance_3])\n\n    beam_dag_runner.BeamDagRunner().run(test_pipeline)\n\n  def testBeamExecutionFailure(self):\n    """"""Test execution with return values; failure case.""""""\n    instance_1 = _injector_1(foo=9, bar=\'secret\')\n    instance_2 = _simple_component(\n        a=instance_1.outputs[\'a\'],\n        b=instance_1.outputs[\'b\'],\n        c=instance_1.outputs[\'c\'],\n        d=instance_1.outputs[\'d\'])\n    # Swapped \'e\' and \'f\'.\n    instance_3 = _verify(e=instance_2.outputs[\'f\'], f=instance_2.outputs[\'e\'])  # pylint: disable=assignment-from-no-return\n\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    test_pipeline = pipeline.Pipeline(\n        pipeline_name=\'test_pipeline_1\',\n        pipeline_root=self._test_dir,\n        metadata_connection_config=metadata_config,\n        components=[instance_1, instance_2, instance_3])\n\n    with self.assertRaisesRegexp(RuntimeError,\n                                 r\'AssertionError: \\(220.0, 32.0\\)\'):\n      beam_dag_runner.BeamDagRunner().run(test_pipeline)\n\n  def testBeamExecutionOptionalInputsAndParameters(self):\n    """"""Test execution with optional inputs and parameters.""""""\n    instance_1 = _injector_2()  # pylint: disable=no-value-for-parameter\n    self.assertEqual(1, len(instance_1.outputs[\'examples\'].get()))\n    instance_2 = _optionalarg_component(  # pylint: disable=assignment-from-no-return\n        foo=9,\n        bar=\'secret\',\n        examples=instance_1.outputs[\'examples\'],\n        a=instance_1.outputs[\'a\'],\n        b=instance_1.outputs[\'b\'],\n        c=instance_1.outputs[\'c\'],\n        d=instance_1.outputs[\'d\'],\n        e1=instance_1.outputs[\'e\'],\n        e2=instance_1.outputs[\'e\'],\n        g=999.0,\n        optional_examples_1=instance_1.outputs[\'examples\'])\n\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    test_pipeline = pipeline.Pipeline(\n        pipeline_name=\'test_pipeline_1\',\n        pipeline_root=self._test_dir,\n        metadata_connection_config=metadata_config,\n        components=[instance_1, instance_2])\n\n    beam_dag_runner.BeamDagRunner().run(test_pipeline)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/component/experimental/executor_specs.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Executor specifications for components.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text, Union\n\nfrom tfx.components.base import executor_spec\nfrom tfx.dsl.component.experimental import placeholders\n\n\nCommandlineArgumentType = Union[\n    Text,\n    placeholders.InputValuePlaceholder,\n    placeholders.InputUriPlaceholder,\n    placeholders.OutputUriPlaceholder,\n]\n\n\nclass TemplatedExecutorContainerSpec(executor_spec.ExecutorSpec):\n  """"""Experimental: Describes a command-line program inside a container.\n\n  This class is similar to ExecutorContainerSpec, but uses structured\n  placeholders instead of jinja templates for constructing container commands\n  based on input and output artifact metadata. See placeholders.py for a list of\n  supported placeholders.\n  The spec includes the container image name and the command line\n  (entrypoint plus arguments) for a program inside the container.\n\n  Example:\n\n  class MyTrainer(base_component.BaseComponent)\n    class MyTrainerSpec(types.ComponentSpec):\n      INPUTS = {\n          \'training_data\':\n              component_spec.ChannelParameter(type=standard_artifacts.Dataset),\n      }\n      OUTPUTS = {\n          \'model\':\n              component_spec.ChannelParameter(type=standard_artifacts.Model),\n      }\n      PARAMETERS = {\n          \'num_training_steps\': component_spec.ExecutionParameter(type=int),\n      }\n\n    SPEC_CLASS = MyTrainerSpec\n    EXECUTOR_SPEC = executor_specs.TemplatedExecutorContainerSpec(\n        image=\'gcr.io/my-project/my-trainer\',\n        command=[\n            \'python3\', \'my_trainer\',\n            \'--training_data_uri\', InputUriPlaceholder(\'training_data\'),\n            \'--model_uri\', OutputUriPlaceholder(\'model\'),\n            \'--num_training-steps\', InputValuePlaceholder(\'num_training_steps\'),\n        ]\n    )\n\n  Attributes:\n    image: Container image name.\n    command: Container entrypoint command-line. Not executed within a shell.\n      The command-line can use placeholder objects that will be replaced at\n      the compilation time. Note: Jinja templates are not supported.\n  """"""\n\n  # The ""command"" parameter holds the name of the program and its arguments.\n  # The ""command"" parameter is required to enable instrumentation.\n  # The command-line is often split into command+args, but here ""args"" would be\n  # redundant since all items can just be added to ""command"".\n\n  def __init__(\n      self,\n      image: Text,\n      command: List[CommandlineArgumentType],\n  ):\n    self.image = image\n    self.command = command\n    super(TemplatedExecutorContainerSpec, self).__init__()\n'"
tfx/dsl/component/experimental/function_parser.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Component executor function parser.\n\nInternal use only. No backwards compatibility guarantees.\n""""""\n\n# TODO(ccy): Remove pytype ""disable=attribute-error"" and ""disable=module-attr""\n# overrides after Python 2 support is removed from TFX.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport enum\nimport inspect\nimport types\nfrom typing import Any, Dict, Optional, Set, Text, Tuple, Type, Union\n\nfrom tfx.dsl.component.experimental import annotations\nfrom tfx.types import artifact\nfrom tfx.types import standard_artifacts\n\n\nclass ArgFormats(enum.Enum):\n  INPUT_ARTIFACT = 1\n  OUTPUT_ARTIFACT = 2\n  ARTIFACT_VALUE = 3\n  PARAMETER = 4\n\n\n_PRIMITIVE_TO_ARTIFACT = {\n    int: standard_artifacts.Integer,\n    float: standard_artifacts.Float,\n    Text: standard_artifacts.String,\n    bytes: standard_artifacts.Bytes,\n}\n\n\n# Map from `Optional[T]` to `T` for primitive types. This map is a simple way\n# to extract the value of `T` from its optional typehint, since the internal\n# fields of the typehint vary depending on the Python version.\n_OPTIONAL_PRIMITIVE_MAP = dict((Optional[t], t) for t in _PRIMITIVE_TO_ARTIFACT)\n\n\ndef _validate_signature(\n    func: types.FunctionType,\n    argspec: inspect.FullArgSpec,  # pytype: disable=module-attr\n    typehints: Dict[Text, Any],\n    subject_message: Text) -> None:\n  """"""Validates signature of a typehint-annotated component executor function.""""""\n  args, varargs, keywords = argspec.args, argspec.varargs, argspec.varkw\n  if varargs or keywords:\n    raise ValueError(\'%s does not support *args or **kwargs arguments.\' %\n                     subject_message)\n\n  # Validate argument type hints.\n  for arg in args:\n    if isinstance(arg, list):\n      # Note: this feature was removed in Python 3:\n      # https://www.python.org/dev/peps/pep-3113/.\n      raise ValueError(\'%s does not support nested input arguments.\' %\n                       subject_message)\n    if arg not in typehints:\n      raise ValueError(\'%s must have all arguments annotated with typehints.\' %\n                       subject_message)\n\n  # Validate return type hints.\n  if isinstance(typehints.get(\'return\', None), annotations.OutputDict):\n    for arg, arg_typehint in typehints[\'return\'].kwargs.items():\n      if (isinstance(arg_typehint, annotations.OutputArtifact) or\n          (inspect.isclass(arg_typehint) and\n           issubclass(arg_typehint, artifact.Artifact))):\n        raise ValueError(\n            (\'Output artifacts for the component executor function %r should \'\n             \'be declared as function parameters annotated with type hint \'\n             \'`tfx.types.annotations.OutputArtifact[T]` where T is a \'\n             \'subclass of `tfx.types.Artifact`. They should not be declared \'\n             \'as part of the return value `OutputDict` type hint.\') % func)\n  elif \'return\' not in typehints or typehints[\'return\'] in (None, type(None)):\n    pass\n  else:\n    raise ValueError(\n        (\'%s must have either an OutputDict instance or `None` as its return \'\n         \'value typehint.\') % subject_message)\n\n\ndef _parse_signature(\n    func: types.FunctionType,\n    argspec: inspect.FullArgSpec,  # pytype: disable=module-attr\n    typehints: Dict[Text, Any]\n) -> Tuple[Dict[Text, Type[artifact.Artifact]], Dict[\n    Text, Type[artifact.Artifact]], Dict[Text, Type[Union[\n        int, float, Text, bytes]]], Dict[Text, Any], Dict[Text, ArgFormats],\n           Set[Text]]:\n  """"""Parses signature of a typehint-annotated component executor function.\n\n  Args:\n    func: A component executor function to be parsed.\n    argspec: A `inspect.FullArgSpec` instance describing the component executor\n      function. Usually obtained from `inspect.getfullargspec(func)`.\n    typehints: A dictionary mapping function argument names to type hints.\n      Usually obtained from `func.__annotations__`.\n\n  Returns:\n    inputs: A dictionary mapping each input name to its artifact type (as a\n      subclass of `tfx.types.Artifact`).\n    outputs: A dictionary mapping each output name to its artifact type (as a\n      subclass of `tfx.types.Artifact`).\n    parameters: A dictionary mapping each parameter name to its primitive type\n      (one of `int`, `float`, `Text` and `bytes`).\n    arg_formats: Dictionary representing the input arguments of the given\n      component executor function. Each entry\'s key is the argument\'s string\n      name; each entry\'s value is the format of the argument to be passed into\n      the function (given by a value of the `ArgFormats` enum).\n    arg_defaults: Dictionary mapping names of optional arguments to default\n      values.\n    returned_outputs: A set of output names that are declared as ValueArtifact\n      returned outputs.\n  """"""\n  # Extract optional arguments as dict from name to its declared optional value.\n  arg_defaults = {}\n  if argspec.defaults:\n    arg_defaults = dict(\n        zip(argspec.args[-len(argspec.defaults):], argspec.defaults))\n\n  # Parse function arguments.\n  inputs = {}\n  outputs = {}\n  parameters = {}\n  arg_formats = {}\n  returned_outputs = set()\n  for arg in argspec.args:\n    arg_typehint = typehints[arg]\n    # If the typehint is `Optional[T]` for a primitive type `T`, unwrap it.\n    if arg_typehint in _OPTIONAL_PRIMITIVE_MAP:\n      arg_typehint = _OPTIONAL_PRIMITIVE_MAP[arg_typehint]\n    if isinstance(arg_typehint, annotations.InputArtifact):\n      if arg_defaults.get(arg, None) is not None:\n        raise ValueError(\n            (\'If an input artifact is declared as an optional argument, \'\n             \'its default value must be `None` (got default value %r for \'\n             \'input argument %r of %r instead).\') %\n            (arg_defaults[arg], arg, func))\n      arg_formats[arg] = ArgFormats.INPUT_ARTIFACT\n      inputs[arg] = arg_typehint.type\n    elif isinstance(arg_typehint, annotations.OutputArtifact):\n      if arg in arg_defaults:\n        raise ValueError(\n            (\'Output artifact of component function cannot be declared as \'\n             \'optional (error for argument %r of %r).\') % (arg, func))\n      arg_formats[arg] = ArgFormats.OUTPUT_ARTIFACT\n      outputs[arg] = arg_typehint.type\n    elif isinstance(arg_typehint, annotations.Parameter):\n      if arg in arg_defaults:\n        if not (arg_defaults[arg] is None or\n                isinstance(arg_defaults[arg], arg_typehint.type)):\n          raise ValueError((\n              \'The default value for optional parameter %r on function %r must \'\n              \'be an instance of its declared type %r or `None` (got %r \'\n              \'instead)\') % (arg, func, arg_typehint.type, arg_defaults[arg]))\n      arg_formats[arg] = ArgFormats.PARAMETER\n      parameters[arg] = arg_typehint.type\n    elif arg_typehint in _PRIMITIVE_TO_ARTIFACT:\n      if arg in arg_defaults:\n        if not (arg_defaults[arg] is None or\n                isinstance(arg_defaults[arg], arg_typehint)):\n          raise ValueError(\n              (\'The default value for optional input value %r on function %r \'\n               \'must be an instance of its declared type %r or `None` (got %r \'\n               \'instead)\') % (arg, func, arg_typehint, arg_defaults[arg]))\n      arg_formats[arg] = ArgFormats.ARTIFACT_VALUE\n      inputs[arg] = _PRIMITIVE_TO_ARTIFACT[arg_typehint]\n    elif (inspect.isclass(arg_typehint) and\n          issubclass(arg_typehint, artifact.Artifact)):\n      raise ValueError((\n          \'Invalid type hint annotation for argument %r on function %r. \'\n          \'Argument with an artifact class typehint annotation should indicate \'\n          \'whether it is used as an input or output artifact by using the \'\n          \'`InputArtifact[ArtifactType]` or `OutputArtifact[ArtifactType]` \'\n          \'typehint annotations.\') % (arg, func))\n    else:\n      raise ValueError(\n          \'Unknown type hint annotation for argument %r on function %r\' %\n          (arg, func))\n\n  if \'return\' in typehints and typehints[\'return\'] not in (None, type(None)):\n    for arg, arg_typehint in typehints[\'return\'].kwargs.items():\n      if arg_typehint in _PRIMITIVE_TO_ARTIFACT:\n        outputs[arg] = _PRIMITIVE_TO_ARTIFACT[arg_typehint]\n        returned_outputs.add(arg)\n      else:\n        raise ValueError(\n            (\'Unknown type hint annotation %r for returned output %r on \'\n             \'function %r\') % (arg_typehint, arg, func))\n\n  return (inputs, outputs, parameters, arg_formats, arg_defaults,\n          returned_outputs)\n\n\ndef parse_typehint_component_function(\n    func: types.FunctionType\n) -> Tuple[Dict[Text, Type[artifact.Artifact]], Dict[\n    Text, Type[artifact.Artifact]], Dict[Text, Type[Union[\n        int, float, Text, bytes]]], Dict[Text, Any], Dict[Text, ArgFormats],\n           Set[Text]]:\n  """"""Parses the given component executor function.\n\n  This method parses a typehinted-annotated Python function that is intended to\n  be used as a component and returns the information needed about the interface\n  (inputs / outputs / returned output values) about that components, as well as\n  a list of argument names and formats for determining the parameters that\n  should be passed when calling `func(*args)`.\n\n  Args:\n    func: A component executor function to be parsed.\n\n  Returns:\n    inputs: A dictionary mapping each input name to its artifact type (as a\n      subclass of `tfx.types.Artifact`).\n    outputs: A dictionary mapping each output name to its artifact type (as a\n      subclass of `tfx.types.Artifact`).\n    parameters: A dictionary mapping each parameter name to its primitive type\n      (one of `int`, `float`, `Text` and `bytes`).\n    arg_formats: Dictionary representing the input arguments of the given\n      component executor function. Each entry\'s key is the argument\'s string\n      name; each entry\'s value is the format of the argument to be passed into\n      the function (given by a value of the `ArgFormats` enum).\n    arg_defaults: Dictionary mapping names of optional arguments to default\n      values.\n    returned_outputs: A set of output names that are declared as ValueArtifact\n      returned outputs.\n  """"""\n  # Check input argument type.\n  if not isinstance(func, types.FunctionType):\n    raise ValueError(\n        \'Expected a typehint-annotated Python function (got %r instead).\' %\n        (func,))\n\n  # Inspect the component executor function.\n  typehints = func.__annotations__  # pytype: disable=attribute-error\n  argspec = inspect.getfullargspec(func)  # pytype: disable=module-attr\n  subject_message = \'Component declared as a typehint-annotated function\'\n  _validate_signature(func, argspec, typehints, subject_message)\n\n  # Parse the function and return its details.\n  inputs, outputs, parameters, arg_formats, arg_defaults, returned_outputs = (\n      _parse_signature(func, argspec, typehints))\n\n  return (inputs, outputs, parameters, arg_formats, arg_defaults,\n          returned_outputs)\n'"
tfx/dsl/component/experimental/function_parser_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.base.function_parser.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Dict, Optional, Text\nimport unittest\n\n# Standard Imports\n\nimport six\nimport tensorflow as tf\n\nfrom tfx.dsl.component.experimental.annotations import InputArtifact\nfrom tfx.dsl.component.experimental.annotations import OutputArtifact\nfrom tfx.dsl.component.experimental.annotations import OutputDict\nfrom tfx.dsl.component.experimental.annotations import Parameter\nfrom tfx.dsl.component.experimental.function_parser import ArgFormats\nfrom tfx.dsl.component.experimental.function_parser import parse_typehint_component_function\nfrom tfx.types import standard_artifacts\n\n\n@unittest.skipIf(six.PY2, \'Not compatible with Python 2.\')\nclass FunctionParserTest(tf.test.TestCase):\n\n  def testSimpleFunctionParse(self):\n\n    def func_a(a: int, b: int, unused_c: Text, unused_d: bytes,\n               unused_e: Parameter[float]) -> OutputDict(c=float):\n      return {\'c\': float(a + b)}\n\n    inputs, outputs, parameters, arg_formats, arg_defaults, returned_values = (\n        parse_typehint_component_function(func_a))\n    self.assertDictEqual(\n        inputs, {\n            \'a\': standard_artifacts.Integer,\n            \'b\': standard_artifacts.Integer,\n            \'unused_c\': standard_artifacts.String,\n            \'unused_d\': standard_artifacts.Bytes,\n        })\n    self.assertDictEqual(outputs, {\n        \'c\': standard_artifacts.Float,\n    })\n    self.assertDictEqual(parameters, {\n        \'unused_e\': float,\n    })\n    self.assertDictEqual(\n        arg_formats, {\n            \'a\': ArgFormats.ARTIFACT_VALUE,\n            \'b\': ArgFormats.ARTIFACT_VALUE,\n            \'unused_c\': ArgFormats.ARTIFACT_VALUE,\n            \'unused_d\': ArgFormats.ARTIFACT_VALUE,\n            \'unused_e\': ArgFormats.PARAMETER,\n        })\n    self.assertDictEqual(arg_defaults, {})\n    self.assertEqual(returned_values, set([\'c\']))\n\n  def testArtifactFunctionParse(self):\n\n    def func_a(\n        examples: InputArtifact[standard_artifacts.Examples],\n        model: OutputArtifact[standard_artifacts.Model],\n        schema: InputArtifact[standard_artifacts.Schema],\n        statistics: OutputArtifact[standard_artifacts.ExampleStatistics],\n        num_steps: Parameter[int]\n    ) -> OutputDict(\n        precision=float, recall=float, message=Text, serialized_value=bytes):\n      del examples, model, schema, statistics, num_steps\n      return {\n          \'precision\': 0.9,\n          \'recall\': 0.8,\n          \'message\': \'foo\',\n          \'serialized_value\': b\'bar\'\n      }\n\n    inputs, outputs, parameters, arg_formats, arg_defaults, returned_values = (\n        parse_typehint_component_function(func_a))\n    self.assertDictEqual(\n        inputs, {\n            \'examples\': standard_artifacts.Examples,\n            \'schema\': standard_artifacts.Schema,\n        })\n    self.assertDictEqual(\n        outputs, {\n            \'model\': standard_artifacts.Model,\n            \'statistics\': standard_artifacts.ExampleStatistics,\n            \'precision\': standard_artifacts.Float,\n            \'recall\': standard_artifacts.Float,\n            \'message\': standard_artifacts.String,\n            \'serialized_value\': standard_artifacts.Bytes,\n        })\n    self.assertDictEqual(parameters, {\n        \'num_steps\': int,\n    })\n    self.assertDictEqual(\n        arg_formats, {\n            \'examples\': ArgFormats.INPUT_ARTIFACT,\n            \'model\': ArgFormats.OUTPUT_ARTIFACT,\n            \'schema\': ArgFormats.INPUT_ARTIFACT,\n            \'statistics\': ArgFormats.OUTPUT_ARTIFACT,\n            \'num_steps\': ArgFormats.PARAMETER,\n        })\n    self.assertDictEqual(arg_defaults, {})\n    self.assertEqual(\n        returned_values,\n        set([\'precision\', \'recall\', \'message\', \'serialized_value\']))\n\n  def testEmptyReturnValue(self):\n    # No output typehint.\n    def func_a(examples: InputArtifact[standard_artifacts.Examples],\n               model: OutputArtifact[standard_artifacts.Model], a: int,\n               b: float, c: Parameter[int], d: Parameter[Text],\n               e: Parameter[bytes]):\n      del examples, model, a, b, c, d, e\n\n    # `None` output typehint.\n    def func_b(examples: InputArtifact[standard_artifacts.Examples],\n               model: OutputArtifact[standard_artifacts.Model], a: int,\n               b: float, c: Parameter[int], d: Parameter[Text],\n               e: Parameter[bytes]) -> None:\n      del examples, model, a, b, c, d, e\n\n    # Both functions should be parsed in the same way.\n    for func in [func_a, func_b]:\n      (inputs, outputs, parameters, arg_formats, arg_defaults,\n       returned_values) = parse_typehint_component_function(func)\n      self.assertDictEqual(\n          inputs, {\n              \'examples\': standard_artifacts.Examples,\n              \'a\': standard_artifacts.Integer,\n              \'b\': standard_artifacts.Float,\n          })\n      self.assertDictEqual(outputs, {\n          \'model\': standard_artifacts.Model,\n      })\n      self.assertDictEqual(parameters, {\n          \'c\': int,\n          \'d\': Text,\n          \'e\': bytes,\n      })\n      self.assertDictEqual(\n          arg_formats, {\n              \'examples\': ArgFormats.INPUT_ARTIFACT,\n              \'model\': ArgFormats.OUTPUT_ARTIFACT,\n              \'a\': ArgFormats.ARTIFACT_VALUE,\n              \'b\': ArgFormats.ARTIFACT_VALUE,\n              \'c\': ArgFormats.PARAMETER,\n              \'d\': ArgFormats.PARAMETER,\n              \'e\': ArgFormats.PARAMETER,\n          })\n      self.assertDictEqual(arg_defaults, {})\n      self.assertEqual(returned_values, set([]))\n\n  def testOptionalArguments(self):\n    # Various optional argument schemes.\n    def func_a(a: float,\n               b: int,\n               c: Parameter[Text],\n               d: int = 123,\n               e: Optional[int] = 345,\n               f: Text = \'abc\',\n               g: bytes = b\'xyz\',\n               h: Parameter[Text] = \'default\',\n               i: Parameter[int] = 999,\n               examples: InputArtifact[standard_artifacts.Examples] = None):\n      del a, b, c, d, e, f, g, h, i, examples\n\n    inputs, outputs, parameters, arg_formats, arg_defaults, returned_values = (\n        parse_typehint_component_function(func_a))\n    self.assertDictEqual(\n        inputs,\n        {\n            \'a\': standard_artifacts.Float,\n            \'b\': standard_artifacts.Integer,\n            # \'c\' is missing here as it is a parameter.\n            \'d\': standard_artifacts.Integer,\n            \'e\': standard_artifacts.Integer,\n            \'f\': standard_artifacts.String,\n            \'g\': standard_artifacts.Bytes,\n            # \'h\' is missing here as it is a parameter.\n            # \'i\' is missing here as it is a parameter.\n            \'examples\': standard_artifacts.Examples,\n        })\n    self.assertDictEqual(outputs, {})\n    self.assertDictEqual(parameters, {\n        \'c\': Text,\n        \'h\': Text,\n        \'i\': int,\n    })\n    self.assertDictEqual(\n        arg_formats, {\n            \'a\': ArgFormats.ARTIFACT_VALUE,\n            \'b\': ArgFormats.ARTIFACT_VALUE,\n            \'c\': ArgFormats.PARAMETER,\n            \'d\': ArgFormats.ARTIFACT_VALUE,\n            \'e\': ArgFormats.ARTIFACT_VALUE,\n            \'f\': ArgFormats.ARTIFACT_VALUE,\n            \'g\': ArgFormats.ARTIFACT_VALUE,\n            \'h\': ArgFormats.PARAMETER,\n            \'i\': ArgFormats.PARAMETER,\n            \'examples\': ArgFormats.INPUT_ARTIFACT,\n        })\n    self.assertDictEqual(\n        arg_defaults, {\n            \'d\': 123,\n            \'e\': 345,\n            \'f\': \'abc\',\n            \'g\': b\'xyz\',\n            \'h\': \'default\',\n            \'i\': 999,\n            \'examples\': None,\n        })\n    self.assertEqual(returned_values, set([]))\n\n  def testFunctionParseErrors(self):\n    # Non-function arguments.\n    with self.assertRaisesRegexp(\n        ValueError, \'Expected a typehint-annotated Python function\'):\n      parse_typehint_component_function(object())\n    with self.assertRaisesRegexp(\n        ValueError, \'Expected a typehint-annotated Python function\'):\n      parse_typehint_component_function(\'foo\')\n\n    # Unannotated lambda.\n    with self.assertRaisesRegexp(\n        ValueError, \'must have all arguments annotated with typehints\'):\n      parse_typehint_component_function(lambda x: True)\n\n    # Function with *args and **kwargs.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'must have either an OutputDict instance or `None` as its return\'):\n\n      def func_a(a: int, b: int) -> object:\n        del a, b\n        return object()\n\n      parse_typehint_component_function(func_a)\n\n    # Function with *args and **kwargs.\n    with self.assertRaisesRegexp(\n        ValueError, r\'does not support \\*args or \\*\\*kwargs arguments\'):\n\n      def func_b(a: int, b: int, *unused_args) -> OutputDict(c=float):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_b)\n    with self.assertRaisesRegexp(\n        ValueError, r\'does not support \\*args or \\*\\*kwargs arguments\'):\n\n      def func_c(a: int, b: int, **unused_kwargs) -> OutputDict(c=float):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_c)\n\n    # Not all arguments annotated with typehints.\n    with self.assertRaisesRegexp(\n        ValueError, \'must have all arguments annotated with typehint\'):\n\n      def func_d(a: int, b) -> OutputDict(c=float):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_d)\n\n    # Artifact type used in annotation without `InputArtifact[ArtifactType]` or\n    # `OutputArtifact[ArtifactType]` wrapper.\n    with self.assertRaisesRegexp(\n        ValueError, \'Invalid type hint annotation.*\'\n        \'should indicate whether it is used as an input or output artifact\'):\n\n      def func_e(a: int,\n                 unused_b: standard_artifacts.Examples) -> OutputDict(c=float):\n        return {\'c\': float(a)}\n\n      parse_typehint_component_function(func_e)\n\n    # Invalid input typehint.\n    with self.assertRaisesRegexp(ValueError, \'Unknown type hint annotation\'):\n\n      def func_f(a: int, b: Dict[int, int]) -> OutputDict(c=float):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_f)\n\n    # Invalid output typehint.\n    with self.assertRaisesRegexp(ValueError, \'Unknown type hint annotation\'):\n\n      def func_g(a: int, b: int) -> OutputDict(c=\'whatever\'):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_g)\n\n    # Output artifact in the wrong place.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'Output artifacts .* should be declared as function parameters\'):\n\n      def func_h(a: int, b: int) -> OutputDict(c=standard_artifacts.Examples):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_h)\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'Output artifacts .* should be declared as function parameters\'):\n\n      def func_i(\n          a: int,\n          b: int) -> OutputDict(c=OutputArtifact[standard_artifacts.Examples]):\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_i)\n\n    # Input artifact declared optional with non-`None` default value.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'If an input artifact is declared as an optional argument, its default \'\n        \'value must be `None`\'):\n\n      def func_j(\n          a: int,\n          b: int,\n          examples: InputArtifact[standard_artifacts.Examples] = 123\n      ) -> OutputDict(c=float):\n        del examples\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_j)\n\n    # Output artifact declared optional.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'Output artifact of component function cannot be declared as optional\'):\n\n      def func_k(\n          a: int,\n          b: int,\n          model: OutputArtifact[standard_artifacts.Model] = None\n      ) -> OutputDict(c=float):\n        del model\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_k)\n\n    # Optional parameter\'s default value does not match declared type.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The default value for optional input value .* on function .* must be \'\n        \'an instance of its declared type .* or `None`\'):\n\n      def func_l(a: int,\n                 b: int,\n                 num_iterations: int = \'abc\') -> OutputDict(c=float):\n        del num_iterations\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_l)\n\n    # Optional parameter\'s default value does not match declared type.\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'The default value for optional parameter .* on function .* must be an \'\n        \'instance of its declared type .* or `None`\'):\n\n      def func_m(a: int,\n                 b: int,\n                 num_iterations: Parameter[int] = \'abc\') -> OutputDict(c=float):\n        del num_iterations\n        return {\'c\': float(a + b)}\n\n      parse_typehint_component_function(func_m)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/dsl/component/experimental/placeholders.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Command-line placeholders for use in container component definitions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nfrom tfx.utils import json_utils\n\n\nclass InputValuePlaceholder(json_utils.Jsonable):\n  """"""Represents a placeholder for the value of the input argument.\n\n  Represents a placeholder that will be replaced at runtime with the string\n  value of the input argument of an execution property.\n  """"""\n\n  def __init__(self, input_name: Text):\n    self.input_name = input_name\n\n\nclass InputUriPlaceholder(json_utils.Jsonable):\n  """"""Represents a placeholder for the URI of the input artifact argument.\n\n  Represents a placeholder that will be replaced at runtime with the URI\n  of the input artifact argument data.\n  """"""\n\n  def __init__(self, input_name: Text):\n    self.input_name = input_name\n\n\nclass OutputUriPlaceholder(json_utils.Jsonable):\n  """"""Represents a placeholder for the URI of the output artifact argument.\n\n  Represents a placeholder that will be replaced at runtime with the URI\n  for the output artifact data.\n  """"""\n\n  def __init__(self, output_name: Text):\n    self.output_name = output_name\n'"
tfx/examples/airflow_workshop/notebooks/tfx_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utils to query a TFX pipeline\'s ml-metadata store in a notebook.""""""\n\nimport os\nimport time\n\nimport papermill as pm\nimport tensorflow_data_validation as tfdv\nimport tensorflow_model_analysis as tfma\nimport utils\n\nfrom ml_metadata.metadata_store import metadata_store\nfrom ml_metadata.proto import metadata_store_pb2\n\n\nclass TFXArtifactTypes(object):\n  """"""Constants for different TFX artifact type names.""""""\n  EXAMPLES = \'Examples\'\n  SCHEMA = \'Schema\'\n  EXAMPLE_STATS = \'ExampleStatistics\'\n  EXAMPLE_VALIDATION = \'ExampleAnomalies\'\n  TRANSFORMED_EXAMPLES = \'TransformGraph\'\n  MODEL = \'Model\'\n  MODEL_EVAL = \'ModelEvaluation\'\n\n\nclass TFXExecutionTypes(object):\n  """"""Constants for different TFX execution type names.""""""\n  EXAMPLE_GEN = \'tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\'\n  STATISTICS_GEN = \'tfx.components.statistics_gen.component.StatisticsGen\'\n  SCHEMA_GEN = \'tfx.components.schema_gen.component.SchemaGen\'\n  EXAMPLE_VALIDATION = \'tfx.components.example_validator.component.ExampleValidator\'\n  TRANSFORM = \'tfx.components.transform.component.Transform\'\n  TRAINER = \'tfx.components.trainer.component.Trainer\'\n  EVALUATOR = \'tfx.components.evaluator.component.Evaluator\'\n\n\nclass TFXReadonlyMetadataStore(utils.ReadonlyMetadataStore):\n  """"""A TFX ml-metadata store that provides read-only methods for notebooks.""""""\n\n  @staticmethod\n  def from_sqlite_db(filename_uri):\n    """"""Returns a `TFXReadonlyMetadataStore` based off a SQLITE db uri.\n\n    Args:\n      filename_uri: A `str` indicating the path to the SQLITE db.\n\n    Returns:\n      A `TFXReadonlyMetadataStore` based off a SQLITE db uri.\n    """"""\n    c = metadata_store_pb2.ConnectionConfig()\n    c.sqlite.filename_uri = filename_uri\n    return TFXReadonlyMetadataStore(metadata_store.MetadataStore(c))\n\n  def display_tfma_analysis(self, model_id, slicing_column=None):\n    """"""Displays TFMA metrics for `model_id` sliced by `slicing_column`.\n\n    Args:\n      model_id: A `int` indicating the id of a `TFXArtifactTypes.MODEL` artifact\n      slicing_column: (Optional) A `str` indicating the slicing column for the\n        TFMA metrics.\n\n    Returns:\n      A SlicingMetricsViewer object if in Jupyter notebook; None if in Colab.\n    """"""\n    tfma_artifact = self.get_dest_artifact_of_type(model_id,\n                                                   TFXArtifactTypes.MODEL_EVAL)\n    if tfma_artifact:\n      return tfma.view.render_slicing_metrics(\n          tfma.load_eval_result(tfma_artifact.uri),\n          slicing_column=slicing_column)\n\n  def compare_tfma_analysis(self, model_id, other_model_id):\n    """"""Compares TFMA metrics for `model_id` and `other_model_id`.\n\n    Args:\n      model_id: A `int` indicating the id of a `TFXArtifactTypes.MODEL` artifact\n      other_model_id: A `int` indicating the id of another\n        `TFXArtifactTypes.MODEL` artifact.\n\n    Returns:\n      A TimeSeriesViewer object if in Jupyter notebook; None if in Colab.\n    """"""\n    tfma_artifact, other_tfma_artifact = (self.get_dest_artifact_of_type(\n        model_id, TFXArtifactTypes.MODEL_EVAL),\n                                          self.get_dest_artifact_of_type(\n                                              other_model_id,\n                                              TFXArtifactTypes.MODEL_EVAL))\n    if tfma_artifact and other_tfma_artifact:\n      eval_results = tfma.make_eval_results([\n          tfma.load_eval_result(tfma_artifact.uri),\n          tfma.load_eval_result(other_tfma_artifact.uri)\n      ], tfma.constants.MODEL_CENTRIC_MODE)\n      return tfma.view.render_time_series(eval_results,\n                                          tfma.slicer.slicer.SingleSliceSpec())\n\n  def display_stats_for_examples(self, examples_id, split=\'train\'):\n    """"""Displays stats for `examples_id`.\n\n    Args:\n      examples_id: A `int` indicating the id of a `TFXArtifactTypes.EXAMPLES`\n        artifact.\n      split: A `string` specifying the split name, by default \'train\' is used.\n    """"""\n    stats_artifact = self.get_dest_artifact_of_type(\n        examples_id, TFXArtifactTypes.EXAMPLE_STATS)\n    if stats_artifact:\n      tfdv.visualize_statistics(\n          tfdv.load_statistics(\n              os.path.join(stats_artifact.uri, split, \'stats_tfrecord\')))\n\n  def compare_stats_for_examples(self,\n                                 examples_id,\n                                 other_examples_id,\n                                 name=\'\',\n                                 other_name=\'\'):\n    """"""Compares stats for `examples_id` and `other_examples_id`.\n\n    Args:\n      examples_id: A `int` indicating the id of one `TFXArtifactTypes.EXAMPLES`\n        artifact.\n      other_examples_id: A `int` indicating the id of another\n        `TFXArtifactTypes.EXAMPLES` artifact.\n      name: (Optional) A `str` indicating the label to use for stats of\n        `examples_id`.\n      other_name: (Optional) A `str` indicating the label to use for stats of\n        `other_examples_id`.\n    """"""\n    stats_artifact, other_stats_artifact = (self.get_dest_artifact_of_type(\n        examples_id, TFXArtifactTypes.EXAMPLE_STATS),\n                                            self.get_dest_artifact_of_type(\n                                                other_examples_id,\n                                                TFXArtifactTypes.EXAMPLE_STATS))\n    if stats_artifact and other_stats_artifact:\n      tfdv.visualize_statistics(\n          tfdv.load_statistics(stats_artifact.uri),\n          rhs_statistics=tfdv.load_statistics(other_stats_artifact.uri),\n          lhs_name=name,\n          rhs_name=other_name)\n\n  def display_examples_stats_for_model(self, model_id):\n    """"""Displays stats for examples used to train `model_id`.""""""\n    examples_artifact = self.get_source_artifact_of_type(\n        model_id, TFXArtifactTypes.EXAMPLES)\n    if examples_artifact:\n      self.display_stats_for_examples(examples_artifact.id)\n\n  def compare_examples_stats_for_models(self, model_id, other_model_id):\n    """"""Compares stats for examples to train `model_id` & `other_model_id`.""""""\n    examples_artifact, other_examples_artifact = (\n        self.get_source_artifact_of_type(model_id, TFXArtifactTypes.EXAMPLES),\n        self.get_source_artifact_of_type(other_model_id,\n                                         TFXArtifactTypes.EXAMPLES))\n    if examples_artifact and other_examples_artifact:\n      self.compare_stats_for_examples(\n          examples_artifact.id,\n          other_examples_artifact.id,\n          name=\'model_\' + str(model_id),\n          other_name=\'model_\' + str(other_model_id))\n\n  def display_tensorboard(self, model_id, *other_model_ids):\n    """"""Returns a Tensorboard link for `model_id` and `other_model_ids`.\n\n    Args:\n      model_id: A `int` indicating the id of a `TFXArtifactTypes.MODEL`\n        artifact.\n      *other_model_ids: (Optional) A list of `int` indicating the ids of other\n        `TFXArtifactTypes.MODEL` artifacts to also include in the Tensorboard\n        invocation for comparison.\n    """"""\n    model_ids = [model_id] + list(other_model_ids)\n    model_artifacts = self.metadata_store.get_artifacts_by_id(model_ids)\n    model_ids_str = \'-\'.join([str(m) for m in model_ids])\n    log_file = os.path.join(\n        os.environ[\'HOME\'],\n        \'tensorboard_model_{}_log.txt\'.format(model_ids_str),\n    )\n    output_notebook_path = os.path.join(\n        os.environ[\'HOME\'],\n        \'spawn_tensorboard_{}_output.ipynb\'.format(model_ids_str),\n    )\n    tensorboard_logdir = \',\'.join(\n        [\'model_{}:{}\'.format(m.id, m.uri) for m in model_artifacts])\n    pm.execute_notebook(\n        \'spawn_tensorboard.ipynb\',\n        output_notebook_path,\n        parameters=dict(tb_logdir=tensorboard_logdir, tb_run_log=log_file),\n        progress_bar=False)\n    time.sleep(5)  # Give it some time for log_filename to be flushed.\n    with open(log_file) as f:\n      for l in f:\n        if \'TensorBoard\' in l:\n          # ""TensorBoard 1.12.2 at http://... (Press CTRL+C to quit)""\n          return l.split(\' \')[3]\n'"
tfx/examples/airflow_workshop/notebooks/utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Utils to query ml-metadata store in a notebook.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\n\nfrom IPython.display import display_html\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport pandas as pd\n\nfrom ml_metadata.proto import metadata_store_pb2\n\n\ndef _is_output_event(event):\n  """"""Checks if event is an Output event.""""""\n  return event.type == metadata_store_pb2.Event.OUTPUT\n\n\ndef _is_input_event(event):\n  """"""Checks if event is an Input event.""""""\n  return event.type in [metadata_store_pb2.Event.DECLARED_INPUT,\n                        metadata_store_pb2.Event.INPUT]\n\n\ndef _get_value_str(p):\n  """"""Returns a string representation of a `metadata_store_pb2.Value` object.""""""\n  if p.int_value:\n    return str(p.int_value)\n  if p.string_value:\n    return p.string_value\n  if p.double_value:\n    return str(p.double_value)\n  return \'\'\n\n\nclass _LineageGraphHelper(object):\n  """"""A helper class to compute and plot lineage of ml-metadata artifacts.""""""\n\n  def __init__(self, store):\n    """"""Initializes the _LineageGraphBuilder with given metadata store.\n\n    Args:\n      store: An instance of `metadata_store.MetadataStore`.\n    """"""\n    self.metadata_store = store\n\n  def _get_upstream_execution_ids(self, artifact_id):\n    """"""Returns a tuple of most recent execution id and whether it is cached run.\n\n    Args:\n      artifact_id: The artifact used to retrieve the upstream executions.\n    """"""\n    events = self.metadata_store.get_events_by_artifact_ids([artifact_id])\n    # skip other executions from caching.\n    execution_ids = [e.execution_id for e in events if _is_output_event(e)]\n    num_parents = len(execution_ids)\n    return [] if num_parents < 1 else [(max(execution_ids), num_parents > 1)]\n\n  def _get_upstream_artifact_ids(self, execution_id):\n    """"""Returns a list of artifact_ids that were inputs for `execution_id`.""""""\n    events = self.metadata_store.get_events_by_execution_ids([execution_id])\n    return [e.artifact_id for e in events if _is_input_event(e)]\n\n  def _add_node_attribute(self, g, node_id, depth, is_artifact):\n    """"""Adds the attributes of given artifact or execution to the graph `g`.""""""\n    # if it is not an artifact, use negative gnode id\n    gnode_id = node_id if is_artifact else -1 * node_id\n    g.add_node(gnode_id, depth=depth, is_artifact=is_artifact)\n    node_label = \'\'\n    if is_artifact:\n      [a] = self.metadata_store.get_artifacts_by_id([node_id])\n      [t] = self.metadata_store.get_artifact_types_by_id([a.type_id])\n      node_label += t.name\n    else:\n      [e] = self.metadata_store.get_executions_by_id([node_id])\n      [t] = self.metadata_store.get_execution_types_by_id([e.type_id])\n      node_label += t.name\n    g.nodes[gnode_id][\'_label_\'] = node_label\n\n  def _add_parents(self, g, node_id, is_artifact, depth, max_depth=None):\n    """"""Adds the parent artifacts/executions for `node_id` to the graph `g`.""""""\n    # if it is not an artifact, use negative gnode id\n    gnode_id = node_id if is_artifact else -1 * node_id\n    self._add_node_attribute(g, node_id, depth, is_artifact)\n    if gnode_id in g and g.in_edges(gnode_id):\n      return\n    if max_depth is not None and depth > max_depth:\n      return\n    if is_artifact:\n      for (e_id, is_cached) in self._get_upstream_execution_ids(node_id):\n        g.add_edge(e_id * -1, node_id, is_cached=is_cached)\n        self._add_parents(g, e_id, not is_artifact, depth + 1, max_depth)\n    else:\n      for a_id in self._get_upstream_artifact_ids(node_id):\n        g.add_edge(a_id, node_id * -1, is_cached=False)\n        self._add_parents(g, a_id, not is_artifact, depth + 1, max_depth)\n\n  def get_artifact_lineage(self, artifact_id, max_depth=None):\n    """"""Returns a `nx.DiGraph` representing the lineage of given `artifact_id`.\n\n    Args:\n      artifact_id: An `int` indicating the id of an Artifact.\n      max_depth: (Optional): An `int` indicating how far back the lineage\n          should be computed for `artifact_id`. By default the entire lineage\n          is computed.\n\n    Returns:\n      A `nx.DiGraph` for the lineage of given `artifact_id`.\n      Nodes with positive ids indicate an Artifact.\n      Nodes with negative ids indicate an Execution.\n    """"""\n    g = nx.DiGraph(query_artifact_id=artifact_id)\n    if max_depth is None or max_depth > 0:\n      self._add_parents(g, artifact_id, True, 1, max_depth)\n    return g\n\n  def plot_artifact_lineage(self, g):\n    """"""Plots a `nx.DiGraph` object.\n\n    This method uses networkx and matplotlib to plot the graph.\n    The nodes are places from left to right w.r.t. its depth.\n    Nodes at the same depths are placed vertically.\n    Artifact is shown in green, and Execution is shown in red.\n    Nodes are positioned in a bipartite graph layout.\n\n    Args:\n      g: A `nx.DiGraph` object.\n    """"""\n    # make a copy of the graph; add auxiliary nodes\n    dag = g.copy(as_view=False)\n    label_anchor_id = 10000\n    for node_id in g.nodes:\n      if node_id > 0:\n        dag.add_node(label_anchor_id + node_id)\n      else:\n        dag.add_node(node_id - label_anchor_id)\n\n    # assign node color and label\n    node_color = \'\'\n    node_labels = {}\n    for node_id in dag.nodes:\n      if node_id > 0 and node_id < label_anchor_id:\n        node_color += \'c\'\n        node_labels[node_id] = abs(node_id)\n      elif node_id > 0 and node_id >= label_anchor_id:\n        # artifact label\n        node_color += \'w\'\n        type_name = dag.nodes[node_id - label_anchor_id][\'_label_\']\n        type_segments = re.split(\'([A-Z][a-z]+)\', type_name)\n        node_txt = (\'\\n\').join([s for s in type_segments if s])\n        node_labels[node_id] = node_txt\n      elif node_id < 0 and node_id > -1 * label_anchor_id:\n        node_color += \'m\'\n        node_labels[node_id] = abs(node_id)\n      else:\n        # execution label\n        node_color += \'w\'\n        type_name = dag.nodes[node_id + label_anchor_id][\'_label_\']\n        node_txt = type_name.split(\'.\')[-1]\n        node_labels[node_id] = node_txt\n    pos = {}\n    a_nodes = []\n    e_nodes = []\n    for node_id in dag.nodes:\n      if node_id > 0 and node_id < label_anchor_id:\n        a_nodes.append(node_id)\n      elif node_id < 0 and node_id > -1 * label_anchor_id:\n        e_nodes.append(node_id)\n\n    # assign edge color\n    edge_color = []\n    for (_, _, labels) in dag.edges(data=True):\n      edge_color.append(\'y\' if labels[\'is_cached\'] else \'k\')\n\n    a_nodes.sort(key=abs)\n    e_nodes.sort(key=abs)\n    a_node_y = 0\n    e_node_y = 0.035\n    a_offset = -0.5 if len(a_nodes) % 2 == 0 else 0\n    e_offset = -0.5 if len(e_nodes) % 2 == 0 else 0\n    a_node_x_min = -1 * len(a_nodes)/2 + a_offset\n    e_node_x_min = -1 * len(e_nodes)/2 + e_offset\n    a_node_x = a_node_x_min\n    e_node_x = e_node_x_min\n    node_step = 1\n    for a_id in a_nodes:\n      pos[a_id] = [a_node_x, a_node_y]\n      pos[a_id + label_anchor_id] = [a_node_x, a_node_y - 0.01]\n      a_node_x += node_step\n    for e_id in e_nodes:\n      pos[e_id] = [e_node_x, e_node_y]\n      pos[e_id - label_anchor_id] = [e_node_x, e_node_y + 0.01]\n      e_node_x += node_step\n\n    nx.draw(dag, pos=pos,\n            node_size=500, node_color=node_color,\n            labels=node_labels, node_shape=\'o\', font_size=8.3, label=\'abc\',\n            width=0.5, edge_color=edge_color)\n\n    a_bbox_props = dict(boxstyle=\'square,pad=0.3\', fc=\'c\', ec=\'b\', lw=0)\n    plt.annotate(\'  Artifacts  \',\n                 xycoords=\'axes fraction\', xy=(0.85, 0.575),\n                 textcoords=\'axes fraction\', xytext=(0.85, 0.575),\n                 bbox=a_bbox_props, alpha=0.6)\n    e_bbox_props = dict(boxstyle=\'square,pad=0.3\', fc=\'m\', ec=\'b\', lw=0)\n    plt.annotate(\'Executions\',\n                 xycoords=\'axes fraction\', xy=(0.85, 0.5),\n                 textcoords=\'axes fraction\', xytext=(0.85, 0.5),\n                 bbox=e_bbox_props, alpha=0.6)\n    plt.annotate(\'  Cached    \',\n                 xycoords=\'axes fraction\', xy=(0.85, 0.425),\n                 textcoords=\'axes fraction\', xytext=(0.85, 0.425),\n                 alpha=0.6)\n    plt.annotate(\'\', xycoords=\'axes fraction\', xy=(0.975, 0.405),\n                 textcoords=\'axes fraction\', xytext=(0.845, 0.405),\n                 arrowprops=dict(edgecolor=\'y\', arrowstyle=\'->\', alpha=0.6))\n\n    x_lim_left = min(a_node_x_min, e_node_x_min) - 0.5\n    x_lim_right = min(1 - 0.05 * len(a_nodes), max(a_node_x, e_node_x))\n\n    x_lim_left = max(-2 - 1.5/len(a_nodes),\n                     min(a_node_x_min, e_node_x_min) - 1.0)\n    x_lim_right = max(a_node_x, e_node_x) + 0.1\n    plt.xlim(x_lim_left, x_lim_right)\n\n    plt.show()\n\n\nclass ReadonlyMetadataStore(object):\n  """"""An ml-metadata store that provides read-only methods for notebooks.""""""\n\n  def __init__(self, store):\n    """"""Initializes a ReadonlyMetadataStore with given store.\n\n    Args:\n      store: An instance of `metadata_store.MetadataStore`.\n    """"""\n    self.metadata_store = store\n    self._lineage_graph_helper = _LineageGraphHelper(store)\n\n  def get_df_from_single_artifact_or_execution(self, obj):\n    """"""Returns a `pd.DataFrame` based on an artifact/execution properties.\n\n    Args:\n      obj: An instance of `metadata_store_pb2.Artifact` or\n           `metadata_store_pb2.Execution`.\n\n    Returns:\n      A `pd.DataFrame` to display the properties of an artifact/execution.\n    """"""\n    data = {}\n    if isinstance(obj, metadata_store_pb2.Artifact):\n      data[\'URI\'] = obj.uri\n    for p in obj.properties:\n      data[p.upper()] = _get_value_str(obj.properties[p])\n    for p in obj.custom_properties:\n      data[p.upper()] = _get_value_str(obj.custom_properties[p])\n    return pd.DataFrame.from_dict(\n        data=data, orient=\'index\', columns=[\'\']).fillna(\'-\')\n\n  def get_df_from_artifacts_or_executions(self, objects):\n    """"""Returns a `pd.DataFrame` of given artifacts\'/executions\' properties.""""""\n    data = {}\n    for obj in objects:\n      col_map = {}\n      if isinstance(obj, metadata_store_pb2.Artifact):\n        col_map[\'URI\'] = obj.uri\n      for p in obj.properties:\n        col_map[p.upper()] = _get_value_str(obj.properties[p])\n      for p in obj.custom_properties:\n        col_map[p.upper()] = _get_value_str(obj.custom_properties[p])\n      data[obj.id] = col_map\n    df = pd.DataFrame.from_dict(data=data, orient=\'index\').fillna(\'-\')\n    df.index.name = \'ID\'\n    return df\n\n  def get_artifact_df(self, artifact_id):\n    """"""Returns a `pd.DataFrame` for an artifact with `artifact_id`.\n\n    Args:\n      artifact_id: An `int` indicating the id of an artifact in the store.\n\n    Returns:\n      A `pd.DataFrame` to display the properties of the artifact corresponding\n      to `artifact_id` or None if no such artifact exists in the store.\n    """"""\n    artifacts = self.metadata_store.get_artifacts_by_id([artifact_id])\n    return (\n        self.get_df_from_single_artifact_or_execution(artifacts[0])\n        if artifacts else None\n    )\n\n  def get_execution_df(self, execution_id):\n    """"""Returns a `pd.DataFrame` for an execution with `execution_id`.\n\n    Args:\n      execution_id: An `int` indicating the id of an execution in the store.\n\n    Returns:\n      A `pd.DataFrame` to display the properties of the execution corresponding\n      to `execution_id` or None if no such execution exists in the store.\n    """"""\n    executions = self.metadata_store.get_executions_by_id([execution_id])\n    return (\n        self.get_df_from_single_artifact_or_execution(executions[0])\n        if executions else None\n    )\n\n  def get_artifacts_of_type_df(self, type_name):\n    """"""Returns a `pd.DataFrame` for all artifacts of given `type_name`.\n\n    Args:\n      type_name: A `str` indicating the name of an artifact type in the store.\n\n    Returns:\n      A `pd.DataFrame` to display the properties of all artifacts with given\n      type in the store.\n    """"""\n    return self.get_df_from_artifacts_or_executions(\n        self.metadata_store.get_artifacts_by_type(type_name))\n\n  def get_executions_of_type_df(self, type_name):\n    """"""Returns a `pd.DataFrame` for all executions of given `type_name`.\n\n    Args:\n      type_name: A `str` indicating the name of an execution type in the store.\n\n    Returns:\n      A `pd.DataFrame` to display the properties of all executions with given\n      type in the store.\n    """"""\n    return self.get_df_from_artifacts_or_executions(\n        self.metadata_store.get_executions_by_type(type_name))\n\n  def get_source_artifact_of_type(self, artifact_id, source_type_name):\n    """"""Returns the source artifact of `source_type_name` for `artifact_id`.\n\n    This method recursively traverses the events and associated executions that\n    led to generating `artifact_id` to find an artifact of type\n    `source_type_name` that was an input for these events.\n\n    Args:\n      artifact_id: A `int` indicating the id of an artifact.\n      source_type_name: A `str` indicating the type of an artifact that is\n          a direct or indirect input for generating `artifact_id`.\n\n    Returns:\n      A `metadata_store_pb2.Artifact` of type `source_type_name` that is a\n      direct/indirect input for generating `artifact_id` or `None` if no such\n      artifact exists.\n    """"""\n    a_events = self.metadata_store.get_events_by_artifact_ids([artifact_id])\n    for a_event in a_events:\n      if _is_input_event(a_event):\n        continue\n      [execution] = self.metadata_store.get_executions_by_id(\n          [a_event.execution_id])\n      e_events = self.metadata_store.get_events_by_execution_ids([execution.id])\n      for e_event in e_events:\n        if _is_output_event(e_event):\n          continue\n        [artifact] = self.metadata_store.get_artifacts_by_id(\n            [e_event.artifact_id])\n        [artifact_type] = self.metadata_store.get_artifact_types_by_id(\n            [artifact.type_id])\n        if artifact_type.name == source_type_name:\n          return artifact\n        input_artifact = self.get_source_artifact_of_type(\n            artifact.id, source_type_name)\n        if input_artifact:\n          return input_artifact\n\n  def get_dest_artifact_of_type(self, artifact_id, dest_type_name):\n    """"""Returns the destination artifact of `dest_type_name` from `artifact_id`.\n\n    This method recursively traverses the events and associated executions that\n    consumed `artifact_id` to find an artifact of type `dest_type_name` that was\n    an output for these events.\n\n    Args:\n      artifact_id: A `int` indicating the id of an artifact.\n      dest_type_name: A `str` indicating the type of an artifact that is\n          a output of an event that directly/indirectly consumed `artifact_id`.\n\n    Returns:\n      A `metadata_store_pb2.Artifact` of type `dest_type_name` that is a\n      direct/indirect output from `artifact_id` or `None` if no such artifact\n      exists.\n    """"""\n    a_events = self.metadata_store.get_events_by_artifact_ids([artifact_id])\n    for a_event in a_events:\n      if _is_output_event(a_event):\n        continue\n      [execution] = self.metadata_store.get_executions_by_id(\n          [a_event.execution_id])\n      e_events = self.metadata_store.get_events_by_execution_ids(\n          [execution.id])\n      for e_event in e_events:\n        if _is_input_event(e_event):\n          continue\n        [artifact] = self.metadata_store.get_artifacts_by_id(\n            [e_event.artifact_id])\n        [artifact_type] = self.metadata_store.get_artifact_types_by_id(\n            [artifact.type_id])\n        if artifact_type.name == dest_type_name:\n          return artifact\n        dest_artifact = self.get_dest_artifact_of_type(\n            artifact.id, dest_type_name)\n        if dest_artifact:\n          return dest_artifact\n\n  def get_execution_for_output_artifact(self, artifact_id, type_name):\n    """"""Returns the execution of `type_name` that generated `artifact_id`.\n\n    Args:\n      artifact_id: A `int` indicating the id of an artifact.\n      type_name: A `str` indicating the type of an Execution that generated\n        `artifact_id`.\n\n    Returns:\n      A `metadata_store_pb2.Execution` of type `type_name` that generated\n      `artifact_id` or `None` if no such execution exists.\n    """"""\n    a_events = self.metadata_store.get_events_by_artifact_ids([artifact_id])\n    for a_event in a_events:\n      if _is_input_event(a_event):\n        continue\n      [execution] = self.metadata_store.get_executions_by_id(\n          [a_event.execution_id])\n      [execution_type] = self.metadata_store.get_execution_types_by_id(\n          [execution.type_id])\n      if execution_type.name == type_name:\n        return execution\n\n  def display_artifact_and_execution_properties(self, artifact_id,\n                                                execution_type_name):\n    """"""Displays properties of artifact and the execution that generated it.\n\n    Args:\n      artifact_id: A `int` indicating the id of an artifact.\n      execution_type_name: A `str` indicating the type of an execution that\n          generated `artifact_id`.\n    """"""\n    execution = self.get_execution_for_output_artifact(\n        artifact_id, execution_type_name)\n    if not execution:\n      return\n    execution_id = execution.id\n\n    # Get data frames to visualize the artifact and execution properties.\n    artifact_df, execution_df = (\n        self.get_artifact_df(artifact_id), self.get_execution_df(execution_id)\n    )\n\n    # Style the data frames to set captions.\n    artifact_df_styler = artifact_df.style.set_caption(\n        \'Properties for Artifact {}\'.format(artifact_id))\n    execution_df_styler = execution_df.style.set_caption(\n        \'Properties for Execution {} that generated Artifact {}\'.format(\n            execution_id, artifact_id))\n\n    # Display the HTML.\n    # pylint: disable=protected-access\n    display_html(\n        artifact_df_styler._repr_html_() + execution_df_styler._repr_html_(),\n        raw=True)\n    # pylint: enable=protected-access\n\n  def compare_artifact_pair_and_execution_properties(\n      self, artifact_id, other_artifact_id, execution_type_name):\n    """"""Displays properties of 2 artifacts and executions that generated them.\n\n    Args:\n      artifact_id: A `int` indicating the id of one artifact.\n      other_artifact_id: A `int` indicating the id of another artifact.\n      execution_type_name: A `str` indicating the type of executions that\n          generated `artifact_id` and `other_artifact_id`.\n    """"""\n    # Get data frame to visualize properties of the 2 artifacts.\n    df = self.get_df_from_artifacts_or_executions(\n        self.metadata_store.get_artifacts_by_id(\n            [artifact_id, other_artifact_id]))\n    artifacts_df_styler = df.style.set_caption(\n        \'Properties for Artifacts {}, {}\'.format(\n            artifact_id, other_artifact_id))\n\n    # Compare properties of the executions that generated these artifacts.\n    execution = self.get_execution_for_output_artifact(\n        artifact_id, execution_type_name)\n    other_execution = self.get_execution_for_output_artifact(\n        other_artifact_id, execution_type_name)\n    if not execution or not other_execution:\n      return\n    executions_df = self.get_df_from_artifacts_or_executions([\n        execution, other_execution])\n    executions_df_styler = executions_df.style.set_caption(\n        \'Properties for Executions that generated Artifacts {}, {}\'.format(\n            artifact_id, other_artifact_id))\n\n    # Display the HTML.\n    # pylint: disable=protected-access\n    display_html(\n        artifacts_df_styler._repr_html_() + executions_df_styler._repr_html_(),\n        raw=True)\n    # pylint: enable=protected-access\n\n  def plot_artifact_lineage(self, artifact_id, max_depth=None):\n    """"""Computes and plots the lineage graph for `artifact_id` upto `max_depth`.\n\n    Args:\n      artifact_id: An `int` indicating the id of an Artifact.\n      max_depth: (Optional): An `int` indicating how far back the lineage\n          should be computed for `artifact_id`. By default the entire lineage\n          is computed.\n    """"""\n    self._lineage_graph_helper.plot_artifact_lineage(\n        self._lineage_graph_helper.get_artifact_lineage(\n            artifact_id, max_depth=max_depth))\n'"
tfx/examples/bigquery_ml/testdata/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/chicago_taxi_pipeline/serving/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/chicago_taxi_pipeline/serving/chicago_taxi_client.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A client for the chicago_taxi demo.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport base64\nimport json\nimport os\nimport subprocess\nimport tempfile\n\nimport requests\n\nfrom tensorflow_transform import coders as tft_coders\nfrom tensorflow_transform.tf_metadata import dataset_schema\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom google.protobuf import text_format\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow.python.platform import app  # pylint: disable=g-direct-tensorflow-import\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.utils import io_utils\n\n_LOCAL_INFERENCE_TIMEOUT_SECONDS = 5.0\n\n_LABEL_KEY = \'tips\'\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _make_proto_coder(schema):\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_schema = dataset_schema.from_feature_spec(raw_feature_spec)\n  return tft_coders.ExampleProtoCoder(raw_schema)\n\n\ndef _make_csv_coder(schema, column_names):\n  """"""Return a coder for tf.transform to read csv files.""""""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  parsing_schema = dataset_schema.from_feature_spec(raw_feature_spec)\n  return tft_coders.CsvCoder(column_names, parsing_schema)\n\n\ndef _read_schema(path):\n  """"""Reads a schema from the provided location.\n\n  Args:\n    path: The location of the file holding a serialized Schema proto.\n\n  Returns:\n    An instance of Schema or None if the input argument is None\n  """"""\n  result = schema_pb2.Schema()\n  contents = file_io.read_file_to_string(path)\n  text_format.Parse(contents, result)\n  return result\n\n\ndef _do_local_inference(host, port, serialized_examples):\n  """"""Performs inference on a model hosted by the host:port server.""""""\n\n  json_examples = []\n  for serialized_example in serialized_examples:\n    # The encoding follows the guidelines in:\n    # https://www.tensorflow.org/tfx/serving/api_rest\n    example_bytes = base64.b64encode(serialized_example).decode(\'utf-8\')\n    predict_request = \'{ ""b64"": ""%s"" }\' % example_bytes\n    json_examples.append(predict_request)\n\n  json_request = \'{ ""instances"": [\' + \',\'.join(map(str, json_examples)) + \']}\'\n\n  server_url = \'http://\' + host + \':\' + port + \'/v1/models/chicago_taxi:predict\'\n  response = requests.post(\n      server_url, data=json_request, timeout=_LOCAL_INFERENCE_TIMEOUT_SECONDS)\n  response.raise_for_status()\n  prediction = response.json()\n  print(json.dumps(prediction, indent=4))\n\n\ndef _do_aiplatform_inference(model, version, serialized_examples):\n  """"""Performs inference on the model:version in AI Platform.""""""\n  working_dir = tempfile.mkdtemp()\n  instances_file = os.path.join(working_dir, \'test.json\')\n  json_examples = []\n  for serialized_example in serialized_examples:\n    # The encoding follows the example in:\n    # https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/tpu/invoke_model.py\n    json_examples.append(\'{ ""inputs"": { ""b64"": ""%s"" } }\' %\n                         base64.b64encode(serialized_example).decode(\'utf-8\'))\n  file_io.write_string_to_file(instances_file, \'\\n\'.join(json_examples))\n  gcloud_command = [\n      \'gcloud\', \'ai-platform\', \'predict\', \'--model\', model, \'--version\',\n      version, \'--json-instances\', instances_file\n  ]\n  print(subprocess.check_output(gcloud_command))\n\n\ndef _do_inference(model_handle, examples_file, num_examples, schema):\n  """"""Sends requests to the model and prints the results.\n\n  Args:\n    model_handle: handle to the model. This can be either\n     ""aiplatform:model:version"" or ""host:port""\n    examples_file: path to csv file containing examples, with the first line\n      assumed to have the column headers\n    num_examples: number of requests to send to the server\n    schema: a Schema describing the input data\n\n  Returns:\n    Response from model server\n  """"""\n  filtered_features = [\n      feature for feature in schema.feature if feature.name != _LABEL_KEY\n  ]\n  del schema.feature[:]\n  schema.feature.extend(filtered_features)\n\n  column_names = io_utils.load_csv_column_names(examples_file)\n  csv_coder = _make_csv_coder(schema, column_names)\n  proto_coder = _make_proto_coder(schema)\n\n  input_file = open(examples_file, \'r\')\n  input_file.readline()  # skip header line\n\n  serialized_examples = []\n  for _ in range(num_examples):\n    one_line = input_file.readline()\n    if not one_line:\n      print(\'End of example file reached\')\n      break\n    one_example = csv_coder.decode(one_line)\n\n    serialized_example = proto_coder.encode(one_example)\n    serialized_examples.append(serialized_example)\n\n  parsed_model_handle = model_handle.split(\':\')\n  if parsed_model_handle[0] == \'aiplatform\':\n    _do_aiplatform_inference(\n        model=parsed_model_handle[1],\n        version=parsed_model_handle[2],\n        serialized_examples=serialized_examples)\n  else:\n    _do_local_inference(\n        host=parsed_model_handle[0],\n        port=parsed_model_handle[1],\n        serialized_examples=serialized_examples)\n\n\ndef main(_):\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      \'--num_examples\',\n      help=(\'Number of examples to send to the server.\'),\n      default=1,\n      type=int)\n\n  parser.add_argument(\n      \'--server\',\n      help=(\'Prediction service host:port or aiplatform:model:version\'),\n      required=True)\n\n  parser.add_argument(\n      \'--examples_file\',\n      help=(\'Path to csv file containing examples.\'),\n      required=True)\n\n  parser.add_argument(\n      \'--schema_file\', help=\'File holding the schema for the input data\')\n  known_args, _ = parser.parse_known_args()\n  _do_inference(known_args.server, known_args.examples_file,\n                known_args.num_examples, _read_schema(known_args.schema_file))\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
tfx/examples/custom_components/container_components/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/container_components/download_grep_print_pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Container-based pipeline sample.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nfrom tfx.dsl.component.experimental import container_component\nfrom tfx.dsl.component.experimental import placeholders\nfrom tfx.types import standard_artifacts\n\n\ndownloader_component = container_component.create_container_component(\n    name=\'DownloadFromHttp\',\n    outputs={\n        \'data\': standard_artifacts.ExternalArtifact,\n    },\n    parameters={\n        \'url\': str,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          url=""$0""\n          output_data_uri=""$1""/data  # TODO(b/150515270) Remove when fixed.\n          output_data_path=$(mktemp)\n\n          # Running the main code\n          wget ""$0"" -O ""$output_data_path"" || curl ""$0"" > ""$output_data_path""\n\n          # Getting data out of the container\n          gsutil cp ""$output_data_path"" ""$output_data_uri""\n        \'\'\',\n        placeholders.InputValuePlaceholder(\'url\'),\n        placeholders.OutputUriPlaceholder(\'data\'),\n    ],\n)\n\n\ngrep_component = container_component.create_container_component(\n    name=\'FilterWithGrep\',\n    inputs={\n        \'text\': standard_artifacts.ExternalArtifact,\n    },\n    outputs={\n        \'filtered_text\': standard_artifacts.ExternalArtifact,\n    },\n    parameters={\n        \'pattern\': str,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          pattern=""$0""\n          text_uri=""$1""/data  # TODO(b/150515270) Remove when fixed.\n          text_path=$(mktemp)\n          filtered_text_uri=""$2""/data  # TODO(b/150515270) Remove when fixed.\n          filtered_text_path=$(mktemp)\n\n          # Getting data into the container\n          gsutil cp ""$text_uri"" ""$text_path""\n\n          # Running the main code\n          grep ""$pattern"" ""$text_path"" >""$filtered_text_path""\n\n          # Getting data out of the container\n          gsutil cp ""$filtered_text_path"" ""$filtered_text_uri""\n        \'\'\',\n        placeholders.InputValuePlaceholder(\'pattern\'),\n        placeholders.InputUriPlaceholder(\'text\'),\n        placeholders.OutputUriPlaceholder(\'filtered_text\'),\n    ],\n)\n\n\nprint_component = container_component.create_container_component(\n    name=\'Print\',\n    inputs={\n        \'text\': standard_artifacts.ExternalArtifact,\n    },\n    # The component code uses gsutil to upload the data to GCS, so the\n    # container image needs to have gsutil installed and configured.\n    # Fixing b/150670779 by merging cl/294536017 will lift this limitation.\n    image=\'google/cloud-sdk:278.0.0\',\n    command=[\n        \'sh\', \'-exc\',\n        \'\'\'\n          text_uri=""$0""/data  # TODO(b/150515270) Remove when fixed.\n          text_path=$(mktemp)\n\n          # Getting data into the container\n          gsutil cp ""$text_uri"" ""$text_path""\n\n          # Running the main code\n          cat ""$text_path""\n        \'\'\',\n        placeholders.InputUriPlaceholder(\'text\'),\n    ],\n)\n\n\ndef create_pipeline_component_instances(text_url: Text, pattern: Text):\n  """"""Creates tasks for the download_grep_print pipeline.""""""\n\n  downloader_task = downloader_component(url=text_url)\n  grep_task = grep_component(\n      text=downloader_task.outputs[\'data\'],\n      pattern=pattern,\n  )\n  print_task = print_component(\n      text=grep_task.outputs[\'filtered_text\'],\n  )\n\n  component_instances = [\n      downloader_task,\n      grep_task,\n      print_task,\n  ]\n\n  return component_instances\n'"
tfx/examples/custom_components/container_components/download_grep_print_pipeline_on_beam_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Container-based pipeline sample.""""""\n\nimport os\n\nimport absl\nimport tensorflow as tf\n\nfrom tfx.examples.custom_components.container_components import download_grep_print_pipeline\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline as pipeline_module\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\ndef create_pipeline():\n  """"""Creates the pipeline object.""""""\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  text_url = \'https://raw.githubusercontent.com/karpathy/char-rnn/370cbcd/data/tinyshakespeare/input.txt\'\n  pattern = \'art thou\'\n  component_instances = download_grep_print_pipeline.create_pipeline_component_instances(\n      text_url=text_url,\n      pattern=pattern,\n  )\n\n  pipeline_name = \'download-grep-print-pipelin\'\n\n  tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx_root\')\n  pipeline_root = os.path.join(tfx_root, \'pipelines\', pipeline_name)\n  # Sqlite ML-metadata db path.\n  metadata_path = os.path.join(tfx_root, \'metadata\', pipeline_name,\n                               \'metadata.db\')\n\n  pipeline = pipeline_module.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=component_instances,\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n  )\n  return pipeline\n\n\ndef run_pipeline_on_beam():\n  """"""Runs the pipelineon Beam.""""""\n  pipeline = create_pipeline()\n  BeamDagRunner().run(pipeline)\n\n\nclass PipelineTest(tf.test.TestCase):\n\n  def test_create_pipeline(self):\n    pipeline = create_pipeline()\n    self.assertIsNotNone(pipeline)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/hello_world/setup.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package Setup script for HelloComponent.""""""\n\nfrom __future__ import print_function\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\n# Get version from version module.\nwith open(\'hello_component/version.py\') as fp:\n  globals_dict = {}\n  exec(fp.read(), globals_dict)  # pylint: disable=exec-used\n__version__ = globals_dict[\'__version__\']\n\n# Get the long description from the README file.\nwith open(\'README.md\') as fp:\n  _LONG_DESCRIPTION = fp.read()\n\nsetup(\n    name=\'tfx_hello_component\',\n    version=__version__,\n    author=\'Google LLC\',\n    author_email=\'tensorflow-extended-dev@googlegroups.com\',\n    license=\'Apache 2.0\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3 :: Only\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development\',\n        \'Topic :: Software Development :: Libraries\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n    ],\n    namespace_packages=[],\n    install_requires=[\'tfx>=0.22.0,<0.23.0.dev\'],\n    python_requires=\'>=3.5,<4\',\n    packages=find_packages(),\n    include_package_data=True,\n    description=\'Hello World TFX component\',\n    long_description=_LONG_DESCRIPTION,\n    long_description_content_type=\'text/markdown\',\n    keywords=\'tfx hello world\',\n    requires=[])\n'"
tfx/examples/custom_components/presto_example_gen/setup.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package Setup script for presto based example gen component.""""""\n\nfrom __future__ import print_function\n\nfrom distutils import spawn\nimport os\nimport subprocess\nimport sys\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n# Find the Protocol Compiler.\nif \'PROTOC\' in os.environ and os.path.exists(os.environ[\'PROTOC\']):\n  protoc = os.environ[\'PROTOC\']\nelif os.path.exists(\'../src/protoc\'):\n  protoc = \'../src/protoc\'\nelif os.path.exists(\'../src/protoc.exe\'):\n  protoc = \'../src/protoc.exe\'\nelif os.path.exists(\'../vsprojects/Debug/protoc.exe\'):\n  protoc = \'../vsprojects/Debug/protoc.exe\'\nelif os.path.exists(\'../vsprojects/Release/protoc.exe\'):\n  protoc = \'../vsprojects/Release/protoc.exe\'\nelse:\n  protoc = spawn.find_executable(\'protoc\')\n\n\ndef generate_proto():\n  """"""Invokes the Protocol Compiler to generate a _pb2.py.""""""\n  source = \'proto/presto_config.proto\'\n\n  if protoc is None:\n    sys.stderr.write(\n        \'protoc is not installed nor found in ../src.  Please compile it \'\n        \'or install the binary package.\\n\')\n    sys.exit(-1)\n\n  protoc_command = [protoc, \'-I.\', \'--python_out=.\', source]\n  if subprocess.call(protoc_command) != 0:\n    sys.exit(-1)\n\n\ngenerate_proto()\n\n# Get version from version module.\nwith open(\'presto_component/version.py\') as fp:\n  globals_dict = {}\n  exec(fp.read(), globals_dict)  # pylint: disable=exec-used\n__version__ = globals_dict[\'__version__\']\n\n# Get the long description from the README file.\nwith open(\'README.md\') as fp:\n  _LONG_DESCRIPTION = fp.read()\n\nsetup(\n    name=\'tfx_presto_example_gen\',\n    version=__version__,\n    author=\'Google LLC\',\n    author_email=\'tensorflow-extended-dev@googlegroups.com\',\n    license=\'Apache 2.0\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3 :: Only\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development\',\n        \'Topic :: Software Development :: Libraries\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n    ],\n    namespace_packages=[],\n    install_requires=[\n        \'presto-python-client>=0.7,<0.8\',\n        \'tfx>=0.22.0,<=0.23.0.dev\',\n    ],\n    python_requires=\'>=3.5,<4\',\n    packages=find_packages(),\n    include_package_data=True,\n    description=\'Customized TFX component for data ingestion from Presto\',\n    long_description=_LONG_DESCRIPTION,\n    long_description_content_type=\'text/markdown\',\n    keywords=\'tfx presto\',\n    requires=[])\n'"
tfx/examples/custom_components/slack/setup.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package Setup script for slack custom component.""""""\n\nfrom __future__ import print_function\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\ndef _make_required_install_packages():\n  # Make sure to sync the versions of common dependencies (absl-py, numpy,\n  # six, and protobuf) with TF.\n  return [\n      \'slackclient>=2.0.0,<2.0.1\',\n      \'tfx>=0.22.0,<=0.23.0.dev\',\n      \'websocket-client>=0.56,<0.60\',\n  ]\n\n\n# Get version from version module.\nwith open(\'slack_component/version.py\') as fp:\n  globals_dict = {}\n  exec(fp.read(), globals_dict)  # pylint: disable=exec-used\n__version__ = globals_dict[\'__version__\']\n\n# Get the long description from the README file.\nwith open(\'README.md\') as fp:\n  _LONG_DESCRIPTION = fp.read()\n\nsetup(\n    name=\'tfx_slack_component\',\n    version=__version__,\n    author=\'Google LLC\',\n    author_email=\'tensorflow-extended-dev@googlegroups.com\',\n    license=\'Apache 2.0\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3 :: Only\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development\',\n        \'Topic :: Software Development :: Libraries\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n    ],\n    namespace_packages=[],\n    install_requires=_make_required_install_packages(),\n    python_requires=\'>=3.6,<4\',\n    packages=find_packages(),\n    include_package_data=True,\n    description=\'Customized TFX component for Slack integration\',\n    long_description=_LONG_DESCRIPTION,\n    long_description_content_type=\'text/markdown\',\n    keywords=\'tfx slack\',\n    requires=[])\n'"
tfx/examples/custom_components/tuner/setup.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Package Setup script for tuner component.""""""\n\nfrom __future__ import print_function\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\ndef _make_required_install_packages():\n  # Make sure to sync the versions of common dependencies (absl-py, numpy,\n  # six, and protobuf) with TF.\n  return [\n      \'tfx>=0.22.0,<=0.23.0.dev\',\n      \'keras-tuner>=1.0,<2.0\',\n  ]\n\n# Get version from version module.\nwith open(\'version.py\') as fp:\n  globals_dict = {}\n  exec(fp.read(), globals_dict)  # pylint: disable=exec-used\n__version__ = globals_dict[\'__version__\']\n\n# Get the long description from the README file.\nwith open(\'README.md\') as fp:\n  _LONG_DESCRIPTION = fp.read()\n\nsetup(\n    name=\'tfx_tuner\',\n    version=__version__,\n    author=\'Google LLC\',\n    author_email=\'tensorflow-extended-dev@googlegroups.com\',\n    license=\'Apache 2.0\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3 :: Only\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development\',\n        \'Topic :: Software Development :: Libraries\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n    ],\n    namespace_packages=[],\n    install_requires=_make_required_install_packages(),\n    python_requires=\'>=3.5,<4\',\n    packages=find_packages(),\n    include_package_data=True,\n    description=\'TFX Tuner\',\n    long_description=_LONG_DESCRIPTION,\n    long_description_content_type=\'text/markdown\',\n    keywords=\'tfx tuner\',\n    requires=[])\n'"
tfx/examples/custom_components/tuner/version.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Contains the version string of Tuner for TFX.""""""\n\n# Note that setup.py uses this version.\n__version__ = \'0.1\'\n'"
tfx/experimental/templates/taxi/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi/beam_dag_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Define BeamDagRunner to run the pipeline using Apache Beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import logging\n\nfrom tfx.experimental.templates.taxi.pipeline import configs\nfrom tfx.experimental.templates.taxi.pipeline import pipeline\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import trainer_pb2\n\n\n# TFX pipeline produces many output files and metadata. All output data will be\n# stored under this OUTPUT_DIR.\n# NOTE: It is recommended to have a separated OUTPUT_DIR which is *outside* of\n#       the source code structure. Please change OUTPUT_DIR to other location\n#       where we can store outputs of the pipeline.\nOUTPUT_DIR = \'.\'\n\n# TFX produces two types of outputs, files and metadata.\n# - Files will be created under PIPELINE_ROOT directory.\n# - Metadata will be written to SQLite database in METADATA_PATH.\nPIPELINE_ROOT = os.path.join(OUTPUT_DIR, \'tfx_pipeline_output\',\n                             configs.PIPELINE_NAME)\nMETADATA_PATH = os.path.join(OUTPUT_DIR, \'tfx_metadata\', configs.PIPELINE_NAME,\n                             \'metadata.db\')\n\n# The last component of the pipeline, ""Pusher"" will produce serving model under\n# SERVING_MODEL_DIR.\nSERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT, \'serving_model\')\n\n# Specifies data file directory. DATA_PATH should be a directory containing CSV\n# files for CsvExampleGen in this example. By default, data files are in the\n# `data` directory.\n# NOTE: If you upload data files to GCS(which is recommended if you use\n#       Kubeflow), you can use a path starting ""gs://YOUR_BUCKET_NAME/path"" for\n#       DATA_PATH. For example,\n#       DATA_PATH = \'gs://bucket/chicago_taxi_trips/csv/\'.\nDATA_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \'data\')\n\n\ndef run():\n  """"""Define a beam pipeline.""""""\n\n  BeamDagRunner().run(\n      pipeline.create_pipeline(\n          pipeline_name=configs.PIPELINE_NAME,\n          pipeline_root=PIPELINE_ROOT,\n          data_path=DATA_PATH,\n          # TODO(step 7): (Optional) Uncomment here to use BigQueryExampleGen.\n          # query=configs.BIG_QUERY_QUERY,\n          preprocessing_fn=configs.PREPROCESSING_FN,\n          run_fn=configs.RUN_FN,\n          train_args=trainer_pb2.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),\n          eval_args=trainer_pb2.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),\n          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,\n          serving_model_dir=SERVING_MODEL_DIR,\n          # TODO(step 7): (Optional) Uncomment here to use provide GCP related\n          #               config for BigQuery with Beam DirectRunner.\n          # beam_pipeline_args=configs.\n          # BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,\n          metadata_connection_config=metadata.sqlite_metadata_connection_config(\n              METADATA_PATH)))\n\n\nif __name__ == \'__main__\':\n  logging.set_verbosity(logging.INFO)\n  run()\n'"
tfx/experimental/templates/taxi/kubeflow_dag_runner.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Define KubeflowDagRunner to run the pipeline using Kubeflow.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import logging\n\nfrom tfx.experimental.templates.taxi.pipeline import configs\nfrom tfx.experimental.templates.taxi.pipeline import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils import telemetry_utils\n\n# TFX pipeline produces many output files and metadata. All output data will be\n# stored under this OUTPUT_DIR.\nOUTPUT_DIR = os.path.join(\'gs://\', configs.GCS_BUCKET_NAME)\n\n# TFX produces two types of outputs, files and metadata.\n# - Files will be created under PIPELINE_ROOT directory.\nPIPELINE_ROOT = os.path.join(OUTPUT_DIR, \'tfx_pipeline_output\',\n                             configs.PIPELINE_NAME)\n\n# The last component of the pipeline, ""Pusher"" will produce serving model under\n# SERVING_MODEL_DIR.\nSERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT, \'serving_model\')\n\n# Specifies data file directory. DATA_PATH should be a directory containing CSV\n# files for CsvExampleGen in this example. By default, data files are in the\n# `data` directory.\n# NOTE: If you upload data files to GCS(which is recommended if you use\n#       Kubeflow), you can use a path starting ""gs://YOUR_BUCKET_NAME/path"" for\n#       DATA_PATH. For example,\n#       DATA_PATH = \'gs://bucket/chicago_taxi_trips/csv/\'\nDATA_PATH = \'data\'\n\n\ndef run():\n  """"""Define a kubeflow pipeline.""""""\n\n  # Metadata config. The defaults works work with the installation of\n  # KF Pipelines using Kubeflow. If installing KF Pipelines using the\n  # lightweight deployment option, you may need to override the defaults.\n  # If you use Kubeflow, metadata will be written to MySQL database inside\n  # Kubeflow cluster.\n  metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  # TODO(b/157598477) Find a better way to pass parameters from CLI handler to\n  # pipeline DSL file, instead of using environment vars.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=metadata_config, tfx_image=tfx_image)\n  pod_labels = kubeflow_dag_runner.get_default_pod_labels().update(\n      {telemetry_utils.LABEL_KFP_SDK_ENV: \'tfx-template\'})\n  kubeflow_dag_runner.KubeflowDagRunner(\n      config=runner_config, pod_labels_to_attach=pod_labels\n  ).run(\n      pipeline.create_pipeline(\n          pipeline_name=configs.PIPELINE_NAME,\n          pipeline_root=PIPELINE_ROOT,\n          data_path=DATA_PATH,\n          # TODO(step 7): (Optional) Uncomment below to use BigQueryExampleGen.\n          # query=configs.BIG_QUERY_QUERY,\n          preprocessing_fn=configs.PREPROCESSING_FN,\n          run_fn=configs.RUN_FN,\n          train_args=trainer_pb2.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),\n          eval_args=trainer_pb2.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),\n          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,\n          serving_model_dir=SERVING_MODEL_DIR,\n          # TODO(step 7): (Optional) Uncomment below to use provide GCP related\n          #               config for BigQuery with Beam DirectRunner.\n          # beam_pipeline_args=configs\n          # .BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,\n          # TODO(step 8): (Optional) Uncomment below to use Dataflow.\n          # beam_pipeline_args=configs.DATAFLOW_BEAM_PIPELINE_ARGS,\n          # TODO(step 9): (Optional) Uncomment below to use Cloud AI Platform.\n          # ai_platform_training_args=configs.GCP_AI_PLATFORM_TRAINING_ARGS,\n          # TODO(step 9): (Optional) Uncomment below to use Cloud AI Platform.\n          # ai_platform_serving_args=configs.GCP_AI_PLATFORM_SERVING_ARGS,\n      ))\n\n\nif __name__ == \'__main__\':\n  logging.set_verbosity(logging.INFO)\n  run()\n'"
tfx/extensions/google_cloud_ai_platform/pusher/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/extensions/google_cloud_ai_platform/pusher/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Custom executor to push TFX model to AI Platform.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\nfrom typing import Any, Dict, List, Text\n\nfrom tfx import types\nfrom tfx.components.pusher import executor as tfx_pusher_executor\nfrom tfx.extensions.google_cloud_ai_platform import runner\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import json_utils\nfrom tfx.utils import path_utils\n\n# Google Cloud AI Platform\'s ModelVersion resource path format.\n# https://cloud.google.com/ai-platform/prediction/docs/reference/rest/v1/projects.models.versions/get\n_CAIP_MODEL_VERSION_PATH_FORMAT = (\n    \'projects/{project_id}/models/{model}/versions/{version}\')\n\n# Keys to the items in custom_config passed as a part of exec_properties.\nSERVING_ARGS_KEY = \'ai_platform_serving_args\'\n# Keys for custom_config.\n_CUSTOM_CONFIG_KEY = \'custom_config\'\n\n\nclass Executor(tfx_pusher_executor.Executor):\n  """"""Deploy a model to Google Cloud AI Platform serving.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]):\n    """"""Overrides the tfx_pusher_executor.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - model_export: exported model from trainer.\n        - model_blessing: model blessing path from evaluator.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - model_push: A list of \'ModelPushPath\' artifact of size one. It will\n          include the model in this push execution if the model was pushed.\n      exec_properties: Mostly a passthrough input dict for\n        tfx.components.Pusher.executor.  custom_config.ai_platform_serving_args\n        is consumed by this class.  For the full set of parameters supported by\n        Google Cloud AI Platform, refer to\n        https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models#creating_a_model_version.\n\n    Raises:\n      ValueError:\n        If ai_platform_serving_args is not in exec_properties.custom_config.\n        If Serving model path does not start with gs://.\n      RuntimeError: if the Google Cloud AI Platform training job failed.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n    model_push = artifact_utils.get_single_instance(\n        output_dict[tfx_pusher_executor.PUSHED_MODEL_KEY])\n    if not self.CheckBlessing(input_dict):\n      self._MarkNotPushed(model_push)\n      return\n\n    model_export = artifact_utils.get_single_instance(\n        input_dict[tfx_pusher_executor.MODEL_KEY])\n\n    custom_config = json_utils.loads(\n        exec_properties.get(_CUSTOM_CONFIG_KEY, \'null\'))\n    if custom_config is not None and not isinstance(custom_config, Dict):\n      raise ValueError(\'custom_config in execution properties needs to be a \'\n                       \'dict.\')\n\n    ai_platform_serving_args = custom_config.get(SERVING_ARGS_KEY)\n    if not ai_platform_serving_args:\n      raise ValueError(\n          \'\\\'ai_platform_serving_args\\\' is missing in \\\'custom_config\\\'\')\n    # Deploy the model.\n    io_utils.copy_dir(\n        src=path_utils.serving_model_path(model_export.uri), dst=model_push.uri)\n    model_path = model_push.uri\n    # TODO(jjong): Introduce Versioning.\n    # Note that we\'re adding ""v"" prefix as Cloud AI Prediction only allows the\n    # version name that starts with letters, and contains letters, digits,\n    # underscore only.\n    model_version = \'v{}\'.format(int(time.time()))\n    executor_class_path = \'%s.%s\' % (self.__class__.__module__,\n                                     self.__class__.__name__)\n    runner.deploy_model_for_aip_prediction(\n        model_path,\n        model_version,\n        ai_platform_serving_args,\n        executor_class_path,\n    )\n\n    self._MarkPushed(\n        model_push,\n        pushed_destination=_CAIP_MODEL_VERSION_PATH_FORMAT.format(\n            project_id=ai_platform_serving_args[\'project_id\'],\n            model=ai_platform_serving_args[\'model_name\'],\n            version=model_version),\n        pushed_version=model_version)\n'"
tfx/extensions/google_cloud_ai_platform/pusher/executor_test.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.extensions.google_cloud_ai_platform.pusher.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport os\nfrom typing import Any, Dict, Text\n# Standard Imports\nimport mock\nimport tensorflow as tf\n\nfrom tfx.components.pusher import executor as tfx_pusher_executor\nfrom tfx.extensions.google_cloud_ai_platform.pusher import executor\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import json_utils\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(\n            os.path.dirname(os.path.dirname(os.path.dirname(__file__)))),\n        \'components\', \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(self._output_data_dir)\n    self._model_export = standard_artifacts.Model()\n    self._model_export.uri = os.path.join(self._source_data_dir,\n                                          \'trainer/current\')\n    self._model_blessing = standard_artifacts.ModelBlessing()\n    self._input_dict = {\n        tfx_pusher_executor.MODEL_KEY: [self._model_export],\n        tfx_pusher_executor.MODEL_BLESSING_KEY: [self._model_blessing],\n    }\n\n    self._model_push = standard_artifacts.PushedModel()\n    self._model_push.uri = os.path.join(self._output_data_dir, \'model_push\')\n    tf.io.gfile.makedirs(self._model_push.uri)\n    self._output_dict = {\n        tfx_pusher_executor.PUSHED_MODEL_KEY: [self._model_push],\n    }\n    # Dict format of exec_properties. custom_config needs to be serialized\n    # before being passed into Do function.\n    self._exec_properties = {\n        \'custom_config\': {\n            executor.SERVING_ARGS_KEY: {\n                \'model_name\': \'model_name\',\n                \'project_id\': \'project_id\'\n            },\n        },\n        \'push_destination\': None,\n    }\n    self._executor = executor.Executor()\n\n  def _serialize_custom_config_under_test(self) -> Dict[Text, Any]:\n    """"""Converts self._exec_properties[\'custom_config\'] to string.""""""\n    result = copy.deepcopy(self._exec_properties)\n    result[\'custom_config\'] = json_utils.dumps(result[\'custom_config\'])\n    return result\n\n  def assertDirectoryEmpty(self, path):\n    self.assertEqual(len(tf.io.gfile.listdir(path)), 0)\n\n  def assertDirectoryNotEmpty(self, path):\n    self.assertGreater(len(tf.io.gfile.listdir(path)), 0)\n\n  def assertPushed(self):\n    self.assertDirectoryNotEmpty(self._model_push.uri)\n    self.assertEqual(1, self._model_push.get_int_custom_property(\'pushed\'))\n\n  def assertNotPushed(self):\n    self.assertDirectoryEmpty(self._model_push.uri)\n    self.assertEqual(0, self._model_push.get_int_custom_property(\'pushed\'))\n\n  @mock.patch.object(executor, \'runner\', autospec=True)\n  def testDoBlessed(self, mock_runner):\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 1)\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._serialize_custom_config_under_test())\n    executor_class_path = \'%s.%s\' % (self._executor.__class__.__module__,\n                                     self._executor.__class__.__name__)\n    mock_runner.deploy_model_for_aip_prediction.assert_called_once_with(\n        self._model_push.uri,\n        mock.ANY,\n        mock.ANY,\n        executor_class_path,\n    )\n    self.assertPushed()\n    version = self._model_push.get_string_custom_property(\'pushed_version\')\n    self.assertEqual(\n        self._model_push.get_string_custom_property(\'pushed_destination\'),\n        \'projects/project_id/models/model_name/versions/{}\'.format(version))\n\n  @mock.patch.object(executor, \'runner\', autospec=True)\n  def testDoNotBlessed(self, mock_runner):\n    self._model_blessing.uri = os.path.join(self._source_data_dir,\n                                            \'model_validator/not_blessed\')\n    self._model_blessing.set_int_custom_property(\'blessed\', 0)\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._serialize_custom_config_under_test())\n    self.assertNotPushed()\n    mock_runner.deploy_model_for_aip_prediction.assert_not_called()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/extensions/google_cloud_ai_platform/trainer/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/extensions/google_cloud_ai_platform/trainer/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Helper class to start TFX training jobs on AI Platform.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Any, Dict, List, Text\n\nimport absl\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.trainer import executor as tfx_trainer_executor\nfrom tfx.extensions.google_cloud_ai_platform import runner\nfrom tfx.utils import json_utils\n\n# Keys to the items in custom_config passed as a part of exec_properties.\nTRAINING_ARGS_KEY = \'ai_platform_training_args\'\nJOB_ID_KEY = \'ai_platform_training_job_id\'\n_CUSTOM_CONFIG_KEY = \'custom_config\'\n\n\nclass GenericExecutor(base_executor.BaseExecutor):\n  """"""Start a trainer job on Google Cloud AI Platform using a generic Trainer.""""""\n\n  def _GetExecutorClass(self):\n    return tfx_trainer_executor.GenericExecutor\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]):\n    """"""Starts a trainer job on Google Cloud AI Platform.\n\n    Args:\n      input_dict: Passthrough input dict for tfx.components.Trainer.executor.\n      output_dict: Passthrough input dict for tfx.components.Trainer.executor.\n      exec_properties: Mostly a passthrough input dict for\n        tfx.components.Trainer.executor. custom_config.ai_platform_training_args\n        and custom_config.ai_platform_training_job_id are consumed by this\n        class.  For the full set of parameters supported by Google Cloud AI\n        Platform, refer to\n        https://cloud.google.com/ml-engine/docs/tensorflow/training-jobs#configuring_the_job\n\n    Returns:\n      None\n    Raises:\n      ValueError: if ai_platform_training_args is not in\n      exec_properties.custom_config.\n      RuntimeError: if the Google Cloud AI Platform training job failed.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    custom_config = json_utils.loads(\n        exec_properties.get(_CUSTOM_CONFIG_KEY, \'null\'))\n    if custom_config is not None and not isinstance(custom_config, Dict):\n      raise ValueError(\'custom_config in execution properties needs to be a \'\n                       \'dict.\')\n\n    training_inputs = custom_config.get(TRAINING_ARGS_KEY)\n    if training_inputs is None:\n      err_msg = \'\\\'%s\\\' not found in custom_config.\' % TRAINING_ARGS_KEY\n      absl.logging.error(err_msg)\n      raise ValueError(err_msg)\n\n    job_id = custom_config.get(JOB_ID_KEY)\n\n    executor_class = self._GetExecutorClass()\n    executor_class_path = \'%s.%s\' % (executor_class.__module__,\n                                     executor_class.__name__)\n    # Note: exec_properties[\'custom_config\'] here is a dict.\n    return runner.start_aip_training(input_dict, output_dict, exec_properties,\n                                     executor_class_path, training_inputs,\n                                     job_id)\n\n\nclass Executor(GenericExecutor):\n  """"""Start a trainer job on Google Cloud AI Platform using a default Trainer.""""""\n\n  def _GetExecutorClass(self):\n    return tfx_trainer_executor.Executor\n'"
tfx/extensions/google_cloud_ai_platform/trainer/executor_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.extensions.google_cloud_ai_platform.trainer.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport os\nfrom typing import Any, Dict, Text\n\n# Standard Imports\n\nimport mock\nimport tensorflow as tf\n\nfrom tfx.components.trainer import executor as tfx_trainer_executor\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor as ai_platform_trainer_executor\nfrom tfx.utils import json_utils\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._job_dir = os.path.join(self._output_data_dir, \'jobDir\')\n    self._project_id = \'12345\'\n    self._inputs = {}\n    self._outputs = {}\n    # Dict format of exec_properties. custom_config needs to be serialized\n    # before being passed into Do function.\n    self._exec_properties = {\n        \'custom_config\': {\n            ai_platform_trainer_executor.TRAINING_ARGS_KEY: {\n                \'project\': self._project_id,\n                \'jobDir\': self._job_dir,\n            },\n        },\n    }\n    self._executor_class_path = \'%s.%s\' % (\n        tfx_trainer_executor.Executor.__module__,\n        tfx_trainer_executor.Executor.__name__)\n    self._generic_executor_class_path = \'%s.%s\' % (\n        tfx_trainer_executor.GenericExecutor.__module__,\n        tfx_trainer_executor.GenericExecutor.__name__)\n\n    self.addCleanup(mock.patch.stopall)\n    self.mock_runner = mock.patch(\n        \'tfx.extensions.google_cloud_ai_platform.trainer.executor.runner\'\n    ).start()\n\n  def _serialize_custom_config_under_test(self) -> Dict[Text, Any]:\n    """"""Converts self._exec_properties[\'custom_config\'] to string.""""""\n    result = copy.deepcopy(self._exec_properties)\n    result[\'custom_config\'] = json_utils.dumps(result[\'custom_config\'])\n    return result\n\n  def testDo(self):\n    executor = ai_platform_trainer_executor.Executor()\n    executor.Do(self._inputs, self._outputs,\n                self._serialize_custom_config_under_test())\n    self.mock_runner.start_aip_training.assert_called_with(\n        self._inputs, self._outputs, self._serialize_custom_config_under_test(),\n        self._executor_class_path, {\n            \'project\': self._project_id,\n            \'jobDir\': self._job_dir,\n        }, None)\n\n  def testDoWithJobIdOverride(self):\n    executor = ai_platform_trainer_executor.Executor()\n    job_id = \'overridden_job_id\'\n    self._exec_properties[\'custom_config\'][\n        ai_platform_trainer_executor.JOB_ID_KEY] = job_id\n    executor.Do(self._inputs, self._outputs,\n                self._serialize_custom_config_under_test())\n    self.mock_runner.start_aip_training.assert_called_with(\n        self._inputs, self._outputs, self._serialize_custom_config_under_test(),\n        self._executor_class_path, {\n            \'project\': self._project_id,\n            \'jobDir\': self._job_dir,\n        }, job_id)\n\n  def testDoWithGenericExecutorClass(self):\n    executor = ai_platform_trainer_executor.GenericExecutor()\n    executor.Do(self._inputs, self._outputs,\n                self._serialize_custom_config_under_test())\n    self.mock_runner.start_aip_training.assert_called_with(\n        self._inputs, self._outputs, self._serialize_custom_config_under_test(),\n        self._generic_executor_class_path, {\n            \'project\': self._project_id,\n            \'jobDir\': self._job_dir,\n        }, None)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/extensions/google_cloud_big_query_ml/pusher/__init__.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/extensions/google_cloud_big_query_ml/pusher/executor.py,0,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Custom executor to push TFX model to Big Query.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\nfrom typing import Any, Dict, List, Text\nfrom google.cloud import bigquery\n\nfrom tfx import types\nfrom tfx.components.pusher import executor as tfx_pusher_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import json_utils\nfrom tfx.utils import path_utils\nfrom tfx.utils import telemetry_utils\n\n_POLLING_INTERVAL_IN_SECONDS = 30\n\n_GCS_PREFIX = \'gs://\'\n\n# Keys to the items in custom_config passed as a part of exec_properties.\nSERVING_ARGS_KEY = \'bigquery_serving_args\'\n\n# BigQueryML serving argument keys\n_PROJECT_ID_KEY = \'project_id\'\n_BQ_DATASET_ID_KEY = \'bq_dataset_id\'\n_MODEL_NAME_KEY = \'model_name\'\n\n# Keys for custom_config.\n_CUSTOM_CONFIG_KEY = \'custom_config\'\n\n# Model name should be enclosed within backticks.\n# model_path should ends with asterisk glob (/*).\n_BQML_CREATE_OR_REPLACE_MODEL_QUERY_TEMPLATE = """"""\nCREATE OR REPLACE MODEL `{model_uri}`\nOPTIONS (model_type=\'tensorflow\',\n         model_path=\'{model_path}/*\')\n""""""\n\n\nclass Executor(tfx_pusher_executor.Executor):\n  """"""Deploy a model to BigQuery ML for serving.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]):\n    """"""Overrides the tfx_pusher_executor.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - model_export: exported model from trainer.\n        - model_blessing: model blessing path from evaluator.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - model_push: A list of \'ModelPushPath\' artifact of size one. It will\n          include the model in this push execution if the model was pushed.\n      exec_properties: Mostly a passthrough input dict for\n        tfx.components.Pusher.executor.  custom_config.bigquery_serving_args is\n        consumed by this class.  For the full set of parameters supported by\n        Big Query ML, refer to https://cloud.google.com/bigquery-ml/\n\n    Returns:\n      None\n    Raises:\n      ValueError:\n        If bigquery_serving_args is not in exec_properties.custom_config.\n        If pipeline_root is not \'gs://...\'\n      RuntimeError: if the Big Query job failed.\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n    model_push = artifact_utils.get_single_instance(\n        output_dict[tfx_pusher_executor.PUSHED_MODEL_KEY])\n    if not self.CheckBlessing(input_dict):\n      self._MarkNotPushed(model_push)\n      return\n\n    model_export = artifact_utils.get_single_instance(\n        input_dict[tfx_pusher_executor.MODEL_KEY])\n    model_export_uri = model_export.uri\n\n    custom_config = json_utils.loads(\n        exec_properties.get(_CUSTOM_CONFIG_KEY, \'null\'))\n    if custom_config is not None and not isinstance(custom_config, Dict):\n      raise ValueError(\'custom_config in execution properties needs to be a \'\n                       \'dict.\')\n\n    bigquery_serving_args = custom_config.get(SERVING_ARGS_KEY)\n    # if configuration is missing error out\n    if bigquery_serving_args is None:\n      raise ValueError(\'Big Query ML configuration was not provided\')\n\n    bq_model_uri = \'.\'.join([\n        bigquery_serving_args[_PROJECT_ID_KEY],\n        bigquery_serving_args[_BQ_DATASET_ID_KEY],\n        bigquery_serving_args[_MODEL_NAME_KEY],\n    ])\n\n    # Deploy the model.\n    io_utils.copy_dir(\n        src=path_utils.serving_model_path(model_export_uri), dst=model_push.uri)\n    model_path = model_push.uri\n    if not model_path.startswith(_GCS_PREFIX):\n      raise ValueError(\'pipeline_root must be gs:// for BigQuery ML Pusher.\')\n\n    logging.info(\'Deploying the model to BigQuery ML for serving: %s from %s\',\n                 bigquery_serving_args, model_path)\n\n    query = _BQML_CREATE_OR_REPLACE_MODEL_QUERY_TEMPLATE.format(\n        model_uri=bq_model_uri, model_path=model_path)\n\n    # TODO(zhitaoli): Refactor the executor_class_path creation into a common\n    # utility function.\n    executor_class_path = \'%s.%s\' % (self.__class__.__module__,\n                                     self.__class__.__name__)\n    with telemetry_utils.scoped_labels(\n        {telemetry_utils.LABEL_TFX_EXECUTOR: executor_class_path}):\n      default_query_job_config = bigquery.job.QueryJobConfig(\n          labels=telemetry_utils.get_labels_dict())\n    client = bigquery.Client(default_query_job_config=default_query_job_config)\n\n    try:\n      query_job = client.query(query)\n      query_job.result()  # Waits for the query to finish\n    except Exception as e:\n      raise RuntimeError(\'BigQuery ML Push failed: {}\'.format(e))\n\n    logging.info(\'Successfully deployed model %s serving from %s\', bq_model_uri,\n                 model_path)\n\n    # Setting the push_destination to bigquery uri\n    self._MarkPushed(model_push, pushed_destination=bq_model_uri)\n'"
tfx/extensions/google_cloud_big_query_ml/pusher/executor_test.py,3,"b'# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.extensions.google_cloud_bigquery_ml.pusher.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport os\nimport mock\nimport tensorflow as tf\nfrom typing import Any, Dict, Text\n\nfrom google.cloud import bigquery\n\nfrom tfx.extensions.google_cloud_big_query_ml.pusher.executor import Executor\nfrom tfx.types import standard_artifacts\nfrom tfx.utils import io_utils\nfrom tfx.utils import json_utils\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._source_data_dir = os.path.join(\n        os.path.dirname(\n            os.path.dirname(os.path.dirname(os.path.dirname(__file__)))),\n        \'components\', \'testdata\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(self._output_data_dir)\n    self._model_export = standard_artifacts.Model()\n    self._model_export.uri = os.path.join(self._source_data_dir,\n                                          \'trainer/current\')\n    self._model_blessing = standard_artifacts.ModelBlessing()\n    self._input_dict = {\n        \'model\': [self._model_export],\n        \'model_blessing\': [self._model_blessing],\n    }\n\n    self._model_push = standard_artifacts.PushedModel()\n    self._model_push.uri = \'gs://bucket/test_model_path\'\n    self._output_dict = {\n        \'pushed_model\': [self._model_push],\n    }\n    self._exec_properties = {\n        \'custom_config\': {\n            \'bigquery_serving_args\': {\n                \'model_name\': \'model_name\',\n                \'project_id\': \'project_id\',\n                \'bq_dataset_id\': \'bq_dataset_id\',\n            },\n        },\n        \'push_destination\': None,\n    }\n    self._executor = Executor()\n\n    # Setting up Mock for external services\n    self.addCleanup(mock.patch.stopall)\n    self.mock_bq = mock.patch.object(bigquery, \'Client\', autospec=True).start()\n    self.mock_check_blessing = mock.patch.object(\n        Executor, \'CheckBlessing\', autospec=True).start()\n    self.mock_copy_dir = mock.patch.object(\n        io_utils, \'copy_dir\', autospec=True).start()\n\n  def _serialize_custom_config_under_test(self) -> Dict[Text, Any]:\n    """"""Converts self._exec_properties[\'custom_config\'] to string.""""""\n    result = copy.deepcopy(self._exec_properties)\n    result[\'custom_config\'] = json_utils.dumps(result[\'custom_config\'])\n    return result\n\n  def assertPushed(self):\n    self.mock_copy_dir.assert_called_with(\n        src=mock.ANY, dst=self._model_push.uri)\n    self.assertEqual(1, self._model_push.get_int_custom_property(\'pushed\'))\n\n  def assertNotPushed(self):\n    self.assertEqual(0, self._model_push.get_int_custom_property(\'pushed\'))\n\n  def testPipelineRoot(self):\n    self._model_push.uri = \'/none_gcs_pipeline_root\'\n    with self.assertRaises(ValueError):\n      self._executor.Do(self._input_dict, self._output_dict,\n                        self._serialize_custom_config_under_test())\n\n  def testBigQueryServingArgs(self):\n    temp_exec_properties = {\n        \'custom_config\': json_utils.dumps({}),\n        \'push_destination\': None,\n    }\n    with self.assertRaises(ValueError):\n      self._executor.Do(self._input_dict, self._output_dict,\n                        temp_exec_properties)\n\n  def testDoBlessed(self):\n    self.mock_check_blessing.return_value = True\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._serialize_custom_config_under_test())\n    self.mock_bq.assert_called_once()\n    self.assertPushed()\n\n  def testDoNotBlessed(self):\n    self.mock_check_blessing.return_value = False\n    self._executor.Do(self._input_dict, self._output_dict,\n                      self._serialize_custom_config_under_test())\n    self.mock_bq.assert_not_called()\n    self.assertNotPushed()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/experimental/interactive/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/experimental/interactive/execution_result.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX IPython formatter integration.\n\nNote: these APIs are **experimental** and major changes to interface and\nfunctionality are expected.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Standard Imports\n\nfrom tfx.components.base import base_node\n\n\nclass ExecutionResult(object):\n  """"""Execution result from a component launch.""""""\n\n  def __init__(self, component: base_node.BaseNode, execution_id: int):\n    self.component = component\n    self.execution_id = execution_id\n\n  def __repr__(self):\n    outputs_parts = []\n    for name, chan in self.component.outputs.items():\n      repr_string = \'%s: %s\' % (name, repr(chan))\n      for line in repr_string.split(\'\\n\'):\n        outputs_parts.append(line)\n    outputs_str = \'\\n\'.join(\'        %s\' % line for line in outputs_parts)\n    return (\'ExecutionResult(\\n    component_id: %s\'\n            \'\\n    execution_id: %s\'\n            \'\\n    outputs:\\n%s\'\n            \')\') % (self.component.id,\n                    self.execution_id,\n                    outputs_str)\n'"
tfx/orchestration/experimental/interactive/interactive_context.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX interactive context for iterative development.\n\nSee `examples/chicago_taxi_pipeline/taxi_pipeline_interactive.ipynb` for an\nexample of how to run TFX in a Jupyter notebook for iterative development.\n\nNote: these APIs are **experimental** and major changes to interface and\nfunctionality are expected.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport cgi\nimport datetime\nimport functools\nimport os\nimport tempfile\nfrom typing import List, Optional, Text\n\nimport absl\nimport jinja2\nimport nbformat\nfrom six.moves import builtins\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx import types\nfrom tfx.components.base import base_node\nfrom tfx.orchestration import data_types\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.experimental.interactive import execution_result\nfrom tfx.orchestration.experimental.interactive import notebook_formatters\nfrom tfx.orchestration.experimental.interactive import standard_visualizations\nfrom tfx.orchestration.experimental.interactive import visualizations\nfrom tfx.orchestration.launcher import in_process_component_launcher\n\n_SKIP_FOR_EXPORT_MAGIC = \'%%skip_for_export\'\n_MAGIC_PREFIX = \'%\'\n_CMD_LINE_PREFIX = \'!\'\n_EXPORT_TEMPLATES_DIR = \'export_templates\'\n\n\ndef requires_ipython(fn):\n  """"""Decorator for methods that can only be run in IPython.""""""\n\n  @functools.wraps(fn)\n  def run_if_ipython(*args, **kwargs):\n    """"""Invokes `fn` if called from IPython, otherwise just emits a warning.""""""\n    if getattr(builtins, \'__IPYTHON__\', None):\n      # __IPYTHON__ variable is set by IPython, see\n      # https://ipython.org/ipython-doc/rel-0.10.2/html/interactive/reference.html#embedding-ipython.\n      return fn(*args, **kwargs)\n    else:\n      absl.logging.warning(\n          \'Method ""%s"" is a no-op when invoked outside of IPython.\',\n          fn.__name__)\n\n  return run_if_ipython\n\n\nclass InteractiveContext(object):\n  """"""TFX interactive context for interactive TFX notebook development.\n\n  Note: these APIs are **experimental** and major changes to interface and\n  functionality are expected.\n  """"""\n\n  _DEFAULT_SQLITE_FILENAME = \'metadata.sqlite\'\n\n  def __init__(\n      self,\n      pipeline_name: Text = None,\n      pipeline_root: Text = None,\n      metadata_connection_config: metadata_store_pb2.ConnectionConfig = None):\n    """"""Initialize an InteractiveContext.\n\n    Args:\n      pipeline_name: Optional name of the pipeline for ML Metadata tracking\n        purposes. If not specified, a name will be generated for you.\n      pipeline_root: Optional path to the root of the pipeline\'s outputs. If not\n        specified, an ephemeral temporary directory will be created and used.\n      metadata_connection_config: Optional metadata_store_pb2.ConnectionConfig\n        instance used to configure connection to a ML Metadata connection. If\n        not specified, an ephemeral SQLite MLMD connection contained in the\n        pipeline_root directory with file name ""metadata.sqlite"" will be used.\n    """"""\n\n    if not pipeline_name:\n      pipeline_name = (\'interactive-%s\' %\n                       datetime.datetime.now().isoformat().replace(\':\', \'_\'))\n    if not pipeline_root:\n      pipeline_root = tempfile.mkdtemp(prefix=\'tfx-%s-\' % pipeline_name)\n      absl.logging.warning(\n          \'InteractiveContext pipeline_root argument not provided: using \'\n          \'temporary directory %s as root for pipeline outputs.\', pipeline_root)\n    if not metadata_connection_config:\n      # TODO(ccy): consider reconciling similar logic here with other instances\n      # in tfx/orchestration/...\n      metadata_sqlite_path = os.path.join(pipeline_root,\n                                          self._DEFAULT_SQLITE_FILENAME)\n      metadata_connection_config = metadata.sqlite_metadata_connection_config(\n          metadata_sqlite_path)\n      absl.logging.warning(\n          \'InteractiveContext metadata_connection_config not provided: using \'\n          \'SQLite ML Metadata database at %s.\', metadata_sqlite_path)\n    self.pipeline_name = pipeline_name\n    self.pipeline_root = pipeline_root\n    self.metadata_connection_config = metadata_connection_config\n\n    # Register IPython formatters.\n    notebook_formatters.register_formatters()\n\n    # Register artifact visualizations.\n    standard_visualizations.register_standard_visualizations()\n\n  @requires_ipython\n  def run(\n      self,\n      component: base_node.BaseNode,\n      enable_cache: bool = True,\n      beam_pipeline_args: Optional[List[Text]] = None\n  ) -> execution_result.ExecutionResult:\n    """"""Run a given TFX component in the interactive context.\n\n    Args:\n      component: Component instance to be run.\n      enable_cache: whether caching logic should be enabled in the driver.\n      beam_pipeline_args: Optional Beam pipeline args for beam jobs within\n        executor. Executor will use beam DirectRunner as Default.\n\n    Returns:\n      execution_result.ExecutionResult object.\n    """"""\n    run_id = datetime.datetime.now().isoformat()\n    pipeline_info = data_types.PipelineInfo(\n        pipeline_name=self.pipeline_name,\n        pipeline_root=self.pipeline_root,\n        run_id=run_id)\n    driver_args = data_types.DriverArgs(\n        enable_cache=enable_cache, interactive_resolution=True)\n    metadata_connection = metadata.Metadata(self.metadata_connection_config)\n    beam_pipeline_args = beam_pipeline_args or []\n    additional_pipeline_args = {}\n    for name, output in component.outputs.items():\n      for artifact in output.get():\n        artifact.pipeline_name = self.pipeline_name\n        artifact.producer_component = component.id\n        artifact.name = name\n    # TODO(hongyes): figure out how to resolve launcher class in the interactive\n    # context.\n    launcher = in_process_component_launcher.InProcessComponentLauncher.create(\n        component, pipeline_info, driver_args, metadata_connection,\n        beam_pipeline_args, additional_pipeline_args)\n    execution_id = launcher.launch().execution_id\n\n    return execution_result.ExecutionResult(\n        component=component, execution_id=execution_id)\n\n  @requires_ipython\n  def export_to_pipeline(self, notebook_filepath: Text, export_filepath: Text,\n                         runner_type: Text):\n    """"""Exports a notebook to a .py file as a runnable pipeline.\n\n    Args:\n      notebook_filepath: String path of the notebook file, e.g.\n        \'/path/to/notebook.ipynb\'.\n      export_filepath: String path for the exported pipeline python file, e.g.\n        \'/path/to/exported_pipeline.py\'.\n      runner_type: String indicating type of runner, e.g. \'beam\', \'airflow\'.\n    """"""\n    if runner_type not in [\'beam\', \'airflow\']:\n      raise ValueError(\'Invalid runner_type: %s\' % runner_type)\n\n    absl.logging.info(\'Exporting contents of %s to %s with %s runner.\',\n                      notebook_filepath, export_filepath, runner_type)\n\n    with open(notebook_filepath) as notebook_f,\\\n        open(export_filepath, \'w\') as export_f:\n      notebook = nbformat.read(notebook_f, nbformat.NO_CONVERT)\n      cells = notebook[\'cells\']\n      code_cells = (cell for cell in cells if cell[\'cell_type\'] == \'code\')\n      sources = []\n      num_skipped_cells = 0\n      for code_cell in code_cells:\n        cell_source = code_cell[\'source\']\n        if cell_source.lstrip().startswith(_SKIP_FOR_EXPORT_MAGIC):\n          num_skipped_cells += 1\n          continue\n\n        # Filter out all line/cell magics using `%` prefix and command line\n        # invocations (e.g. !pip install ...).\n        # Note: This will not work for magics invoked without the prefix when\n        # %automagic is set.\n        sources.append((\'\\n\'.join(\n            line for line in cell_source.split(\'\\n\')\n            if not (line.lstrip().startswith(_MAGIC_PREFIX) or\n                    line.lstrip().startswith(_CMD_LINE_PREFIX)))))\n\n      jinja_env = jinja2.Environment(\n          loader=jinja2.PackageLoader(\n              __name__, package_path=_EXPORT_TEMPLATES_DIR))\n      template_name = \'export_%s.tmpl\' % runner_type\n      # TODO(b/142326292): Consider parameterizing the other variables names\n      # present in the export templates.\n      rendered_template = jinja_env.get_template(template_name).render({\n          \'notebook_content\': \'\\n\\n\'.join(sources),\n      })\n      export_f.write(rendered_template)\n      absl.logging.info(\'%d cell(s) marked with ""%s"", skipped.\',\n                        num_skipped_cells, _SKIP_FOR_EXPORT_MAGIC)\n\n  @requires_ipython\n  def show(self, item: object) -> None:\n    """"""Show the given object in an IPython notebook display.""""""\n    from IPython.core.display import display  # pylint: disable=g-import-not-at-top\n    from IPython.core.display import HTML  # pylint: disable=g-import-not-at-top\n    if isinstance(item, types.Channel):\n      channel = item\n      artifacts = channel.get()\n      for artifact in artifacts:\n        artifact_heading = \'Artifact at %s\' % cgi.escape(artifact.uri)  # pylint: disable=deprecated-method\n        display(HTML(\'<b>%s</b><br/><br/>\' % artifact_heading))\n        visualization = visualizations.get_registry().get_visualization(\n            artifact.type_name)\n        if visualization:\n          visualization.display(artifact)\n    else:\n      display(item)\n'"
tfx/orchestration/experimental/interactive/interactive_context_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.experimental.interactive.interactive_context.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport shutil\nimport tempfile\nimport textwrap\nfrom typing import Any, Dict, List, Text\n\nimport jinja2\nimport mock\nimport nbformat\nfrom six.moves import builtins\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import base_executor\nfrom tfx.components.base import executor_spec\nfrom tfx.orchestration.experimental.interactive import interactive_context\nfrom tfx.orchestration.experimental.interactive import standard_visualizations\nfrom tfx.types import component_spec\nfrom tfx.types import standard_artifacts\n\n\nclass InteractiveContextTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(InteractiveContextTest, self).setUp()\n\n    builtins.__dict__[\'__IPYTHON__\'] = True\n    self._tmpdir = None\n\n  def tearDown(self):\n    if self._tmpdir:\n      shutil.rmtree(self._tmpdir, ignore_errors=True)\n    super(InteractiveContextTest, self).tearDown()\n\n  def _setupTestNotebook(self, notebook_name=\'test_notebook.ipynb\'):\n    notebook = nbformat.v4.new_notebook(\n        cells=[\n            nbformat.v4.new_markdown_cell(source=\'A markdown cell.\'),\n            nbformat.v4.new_code_cell(source=\'foo = 1\'),\n            nbformat.v4.new_markdown_cell(source=\'Another markdown cell.\'),\n            nbformat.v4.new_code_cell(source=textwrap.dedent(\'\'\'\\\n                %%skip_for_export\n                !pip install something\n                !ls\n                x = 1\n                y = 2\n                print(\'this cell should not be exported\')\'\'\')),\n            nbformat.v4.new_code_cell(source=textwrap.dedent(\'\'\'\\\n                def bar():\n                  %some_line_magic print(\'this line should not be exported\')\n                  a = ""hello""\n                  b = ""world""\n                  return a + b\'\'\')),\n            nbformat.v4.new_code_cell(source=textwrap.dedent(\'\'\'\\\n                def baz():\n                  c = ""nyan""\n                  d = ""cat""\n                  return c + d\'\'\')),\n        ]\n    )\n    self._tmpdir = tempfile.mkdtemp()\n    self._exportdir = tempfile.mkdtemp()\n    self._notebook_fp = os.path.join(self._tmpdir, notebook_name)\n    nbformat.write(notebook, self._notebook_fp)\n\n  def testRequiresIPythonExecutes(self):\n    self.foo_called = False\n    def foo():\n      self.foo_called = True\n\n    interactive_context.requires_ipython(foo)()\n    self.assertTrue(self.foo_called)\n\n  def testRequiresIPythonNoOp(self):\n    del builtins.__dict__[\'__IPYTHON__\']\n\n    self.foo_called = False\n    def foo():\n      self.foo_called = True\n    interactive_context.requires_ipython(foo)()\n    self.assertFalse(self.foo_called)\n\n  def testBasicRun(self):\n\n    class _FakeComponentSpec(types.ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {}\n      OUTPUTS = {}\n\n    class _FakeExecutor(base_executor.BaseExecutor):\n      CALLED = False\n\n      def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n             output_dict: Dict[Text, List[types.Artifact]],\n             exec_properties: Dict[Text, Any]) -> None:\n        _FakeExecutor.CALLED = True\n\n    class _FakeComponent(base_component.BaseComponent):\n      SPEC_CLASS = _FakeComponentSpec\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(_FakeExecutor)\n\n      def __init__(self, spec: types.ComponentSpec):\n        super(_FakeComponent, self).__init__(spec=spec)\n\n    c = interactive_context.InteractiveContext()\n    component = _FakeComponent(_FakeComponentSpec())\n    c.run(component)\n    self.assertTrue(_FakeExecutor.CALLED)\n\n  def testRunMethodRequiresIPython(self):\n    del builtins.__dict__[\'__IPYTHON__\']\n\n    c = interactive_context.InteractiveContext()\n    self.assertIsNone(c.run(None))\n\n  def testUnresolvedChannel(self):\n\n    class _FakeComponentSpec(types.ComponentSpec):\n      PARAMETERS = {}\n      INPUTS = {\n          \'input\':\n              component_spec.ChannelParameter(type=standard_artifacts.Examples)\n      }\n      OUTPUTS = {}\n\n    class _FakeExecutor(base_executor.BaseExecutor):\n      CALLED = False\n\n      def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n             output_dict: Dict[Text, List[types.Artifact]],\n             exec_properties: Dict[Text, Any]) -> None:\n        _FakeExecutor.CALLED = True\n\n    class _FakeComponent(base_component.BaseComponent):\n      SPEC_CLASS = _FakeComponentSpec\n      EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(_FakeExecutor)\n\n      def __init__(self, spec: types.ComponentSpec):\n        super(_FakeComponent, self).__init__(spec=spec)\n\n    c = interactive_context.InteractiveContext()\n    foo = types.Channel(\n        type=standard_artifacts.Examples,\n        artifacts=[standard_artifacts.Examples()])\n    component = _FakeComponent(_FakeComponentSpec(input=foo))\n    with self.assertRaisesRegexp(ValueError, \'Unresolved input channel\'):\n      c.run(component)\n\n  @mock.patch.object(jinja2.Environment, \'get_template\',\n                     return_value=jinja2.Template(\'{{ notebook_content }}\'))\n  def testExportToPipeline(self, mock_get_template):\n    self._setupTestNotebook()\n\n    c = interactive_context.InteractiveContext()\n    export_filepath = os.path.join(self._exportdir, \'exported_pipeline.py\')\n    c.export_to_pipeline(notebook_filepath=self._notebook_fp,\n                         export_filepath=export_filepath,\n                         runner_type=\'beam\')\n\n    with open(export_filepath, \'r\') as exported_pipeline:\n      code = exported_pipeline.read()\n      self.assertEqual(code, textwrap.dedent(\'\'\'\\\n          foo = 1\n\n          def bar():\n            a = ""hello""\n            b = ""world""\n            return a + b\n\n          def baz():\n            c = ""nyan""\n            d = ""cat""\n            return c + d\'\'\'))\n\n  def testExportToPipelineRaisesErrorInvalidRunnerType(self):\n    self._setupTestNotebook()\n\n    c = interactive_context.InteractiveContext()\n    export_filepath = os.path.join(self._exportdir, \'exported_pipeline.py\')\n    with self.assertRaisesRegexp(ValueError, \'runner_type\'):\n      c.export_to_pipeline(notebook_filepath=self._notebook_fp,\n                           export_filepath=export_filepath,\n                           runner_type=\'foobar\')\n\n  @mock.patch(\n      \'tfx.orchestration.experimental.interactive.\'\n      \'standard_visualizations.ExampleAnomaliesVisualization.display\')\n  def testShow(self, *unused_mocks):\n    context = interactive_context.InteractiveContext()\n    mock_object = mock.MagicMock()\n    standard_visualizations.ExampleAnomaliesVisualization.display = mock_object\n    mock_object.assert_not_called()\n    artifact = standard_artifacts.ExampleAnomalies()\n    context.show(\n        types.Channel(\n            type=standard_artifacts.ExampleAnomalies, artifacts=[artifact]))\n    mock_object.assert_called_with(artifact)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/experimental/interactive/notebook_formatters.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX IPython notebook formatter integration.\n\nNote: these APIs are **experimental** and major changes to interface and\nfunctionality are expected.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport cgi\nfrom typing import Callable, List, Optional, Text, Tuple, Type, Union\n\n# Standard Imports\n\nfrom six.moves import builtins\n\nfrom tfx.components.base.base_component import BaseComponent\nfrom tfx.orchestration.experimental.interactive.execution_result import ExecutionResult\nfrom tfx.types.artifact import Artifact\nfrom tfx.types.channel import Channel\nfrom tfx.types.node_common import _PropertyDictWrapper\n\nSTATIC_HTML_CONTENTS = u""""""<style>\n.tfx-object.expanded {\n  padding: 4px 8px 4px 8px;\n  background: white;\n  border: 1px solid #bbbbbb;\n  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n}\n.tfx-object, .tfx-object * {\n  font-size: 11pt;\n}\n.tfx-object > .title {\n  cursor: pointer;\n}\n.tfx-object .expansion-marker {\n  color: #999999;\n}\n.tfx-object.expanded > .title > .expansion-marker:before {\n  content: \'\\u25bc\';\n}\n.tfx-object.collapsed > .title > .expansion-marker:before {\n  content: \'\\u25b6\';\n}\n.tfx-object .class-name {\n  font-weight: bold;\n}\n.tfx-object .deemphasize {\n  opacity: 0.5;\n}\n.tfx-object.collapsed > table.attr-table {\n  display: none;\n}\n.tfx-object.expanded > table.attr-table {\n  display: block;\n}\n.tfx-object table.attr-table {\n  border: 2px solid white;\n  margin-top: 5px;\n}\n.tfx-object table.attr-table td.attr-name {\n  vertical-align: top;\n  font-weight: bold;\n}\n.tfx-object table.attr-table td.attrvalue {\n  text-align: left;\n}\n</style>\n<script>\nfunction toggleTfxObject(element) {\n  var objElement = element.parentElement;\n  if (objElement.classList.contains(\'collapsed\')) {\n    objElement.classList.remove(\'collapsed\');\n    objElement.classList.add(\'expanded\');\n  } else {\n    objElement.classList.add(\'collapsed\');\n    objElement.classList.remove(\'expanded\');\n  }\n}\n</script>\n""""""\n\n\nclass NotebookFormatter(object):\n  """"""Formats a TFX component in the context of an interactive notebook.""""""\n\n  _DEFAULT_TITLE_FORMAT = (\'<span class=""class-name"">%s</span>\',\n                           [\'__class__.__name__\'])\n\n  def __init__(self,\n               cls: Type[object],\n               attributes: List[Text] = None,\n               title_format: Tuple[Text, List[Union[Text, Callable]]] = None,  # pylint: disable=g-bare-generic\n               _show_artifact_attributes: Optional[bool] = False):\n    """"""Constructs a NotebookFormatter.\n\n    Args:\n      cls: The TFX class to be formated by this NotebookFormatter instance.\n      attributes: A list of string attributes that are to be displayed by this\n        formatter. Can be a nested field specifier with nested attribute names\n        separated by ""."" (e.g. to get `obj.a.b`, specify the attribute string\n        ""a.b"").\n      title_format: A 2-tuple consisting of (1) a format string and (2) a list\n        of either string attribute names (possible of nested field specifiers as\n        in ""attributes"" above) or callback callable objects taking as input the\n        object to be formatted and returning the value for that position of the\n        format string. If not specified, the default title format will be used.\n      _show_artifact_attributes: For a formatter of an Artifact object, show\n        the Artifact type-specific properties for each artifact.\n    """"""\n    self.cls = cls\n    self.attributes = attributes or []\n    self.title_format = title_format or NotebookFormatter._DEFAULT_TITLE_FORMAT\n    self._show_artifact_attributes = _show_artifact_attributes\n\n  def _extended_getattr(self, obj: object, property_name: Text) -> object:\n    """"""Get a possibly nested attribute of a given object.""""""\n    if callable(property_name):\n      return property_name(obj)\n    parts = property_name.split(\'.\')\n    current = obj\n    for part in parts:\n      current = getattr(current, part)\n    return current\n\n  def render(self,\n             obj: object,\n             expanded: bool = True,\n             seen_elements: Optional[set] = None) -> Text:  # pylint: disable=g-bare-generic\n    """"""Render a given object as an HTML string.\n\n    Args:\n      obj: The object to be rendered.\n      expanded: Whether the object is to be expanded by default.\n      seen_elements: Optionally, a set of seen elements to not re-render to\n        prevent a rendering cycle.\n\n    Returns:\n      Formatted HTML string representing the object, for notebook display.\n    """"""\n    seen_elements = seen_elements or set()\n    if id(obj) in seen_elements:\n      return \'(recursion in rendering object)\'\n    seen_elements.add(id(obj))\n    if not isinstance(obj, self.cls):\n      raise ValueError(\'Expected object of type %s but got %s.\' %\n                       (self.cls, obj))\n    seen_elements.remove(id(obj))\n    return STATIC_HTML_CONTENTS + (\n        \'<div class=""tfx-object%s"">\'\n        \'<div class = ""title"" onclick=""toggleTfxObject(this)"">\'\n        \'<span class=""expansion-marker""></span>\'\n        \'%s<span class=""deemphasize""> at 0x%x</span></div>%s\'\n        \'</div>\') % (\' expanded\' if expanded else \' collapsed\',\n                     self.render_title(obj), id(obj),\n                     self.render_attributes(obj, seen_elements))\n\n  def render_title(self, obj: object) -> Text:\n    """"""Render the title section of an object.""""""\n    title_format = self.title_format\n    values = []\n    for property_name in title_format[1]:\n      values.append(self._extended_getattr(obj, property_name))\n    return title_format[0] % tuple(values)\n\n  def render_value(self,\n                   value: object,\n                   seen_elements: set) -> object:  # pylint: disable=g-bare-generic\n    """"""Render the value section of an object.""""""\n    if isinstance(value, _PropertyDictWrapper):\n      value = value.get_all()\n    formatted_value = cgi.escape(Text(value))  # pylint: disable=deprecated-method\n    if isinstance(value, dict):\n      formatted_value = self.render_dict(value, seen_elements)\n    if isinstance(value, list):\n      formatted_value = self.render_list(value, seen_elements)\n    if value.__class__ != abc.ABCMeta:\n      # abc.ABCMeta.mro() does not work.\n      for cls in value.__class__.mro():\n        if cls in FORMATTER_REGISTRY:\n          formatted_value = FORMATTER_REGISTRY[cls].render(\n              value, expanded=False, seen_elements=seen_elements)\n          break\n    return formatted_value\n\n  def render_attributes(self,\n                        obj: object,\n                        seen_elements: set) -> Text:  # pylint: disable=g-bare-generic\n    """"""Render the attributes section of an object.""""""\n    if self._show_artifact_attributes and isinstance(obj, Artifact):\n      artifact_attributes = sorted((obj.PROPERTIES or {}).keys())\n      attributes = self.attributes + artifact_attributes\n    else:\n      attributes = self.attributes\n    attr_trs = []\n    for property_name in attributes:\n      value = self._extended_getattr(obj, property_name)\n      value = self.render_value(value, seen_elements)\n      attr_trs.append(\n          (\'<tr><td class=""attr-name"">.%s</td>\'\n           \'<td class = ""attrvalue"">%s</td></tr>\') % (property_name, value))\n    return \'<table class=""attr-table"">%s</table>\' % \'\'.join(attr_trs)\n\n  def render_dict(self,\n                  obj: dict,  # pylint: disable=g-bare-generic\n                  seen_elements: set) -> Text:  # pylint: disable=g-bare-generic\n    """"""Render a dictionary table.""""""\n    if not obj:\n      return \'{}\'\n    attr_trs = []\n    for key, value in obj.items():\n      value = self.render_value(value, seen_elements)\n      attr_trs.append(\n          (\'<tr><td class=""attr-name"">[%r]</td>\'\n           \'<td class = ""attrvalue"">%s</td></tr>\') % (cgi.escape(Text(key)),  # pylint: disable=deprecated-method\n                                                      value))\n    return \'<table class=""attr-table"">%s</table>\' % \'\'.join(attr_trs)\n\n  def render_list(self,\n                  obj: list,  # pylint: disable=g-bare-generic\n                  seen_elements: set) -> Text:  # pylint: disable=g-bare-generic\n    """"""Render a list table.""""""\n    if not obj:\n      return \'[]\'\n    attr_trs = []\n    for i, value in enumerate(obj):\n      value = self.render_value(value, seen_elements)\n      attr_trs.append((\'<tr><td class=""attr-name"">[%d]</td>\'\n                       \'<td class = ""attrvalue"">%s</td></tr>\') % (i, value))\n    return \'<table class=""attr-table"">%s</table>\' % \'\'.join(attr_trs)\n\n\ndef _create_formatters(formatters_spec):\n  result = {}\n  for cls, kwargs in formatters_spec.items():\n    formatter = NotebookFormatter(cls, **kwargs)\n    result[cls] = formatter\n  return result\n\n\nFORMATTER_REGISTRY = _create_formatters({\n    Artifact: {\n        \'attributes\': [\'type\', \'uri\'],\n        \'_show_artifact_attributes\': True,\n        \'title_format\': ((\'<span class=""class-name"">Artifact</span> of type \'\n                          \'<span class=""class-name"">%r</span> (uri: %s)\'),\n                         [\'type_name\', \'uri\']),\n    },\n    BaseComponent: {\n        \'attributes\': [\'inputs\', \'outputs\', \'exec_properties\']\n    },\n    Channel: {\n        \'attributes\': [\'type_name\', \'_artifacts\'],\n        \'title_format\': (\n            (\'<span class=""class-name"">Channel</span> of type \'\n             \'<span class=""class-name"">%r</span> (%d artifact%s)\'),\n            [\n                \'type_name\',\n                lambda o: len(o._artifacts),  # pylint: disable=protected-access\n                lambda o: \'\' if len(o._artifacts) == 1 else \'s\'  # pylint: disable=protected-access\n            ]),\n    },\n    ExecutionResult: {\n        \'attributes\': [\n            \'execution_id\', \'component\', \'component.inputs\', \'component.outputs\'\n        ]\n    },\n})\n\n\ndef register_formatters():\n  """"""Register HTML notebook formatters for TFX classes.\n\n  This method registers HTML formatters for TFX classes for display in\n  IPython / Jupyter / Colab notebooks. No action will be performed if called\n  outside a notebook environment.\n  """"""\n  if getattr(builtins, \'__IPYTHON__\', None):\n    # Skip registration if (1) IPython is not installed or (2) if IPython is\n    # installed but we are not running in the notebook context (in this case,\n    # get_ipython() returns None).\n    try:\n      ipython = __import__(\'IPython.core.getipython\').get_ipython()\n      if not ipython:\n        return\n    except ImportError:\n      return\n    html_formatter = ipython.display_formatter.formatters[\'text/html\']\n    for cls, formatter in FORMATTER_REGISTRY.items():\n      html_formatter.for_type(cls, formatter.render)\n'"
tfx/orchestration/experimental/interactive/notebook_formatters_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.experimental.interactive.notebook_formatters.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\n\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.orchestration.experimental.interactive import notebook_formatters\nfrom tfx.types import standard_artifacts\n\n\nclass NotebookFormattersTest(tf.test.TestCase):\n\n  def _format(self, obj):\n    for cls in obj.__class__.mro():\n      if cls in notebook_formatters.FORMATTER_REGISTRY:\n        formatter = notebook_formatters.FORMATTER_REGISTRY[cls]\n        return formatter.render(obj)\n\n  def testBasicFormatter(self):\n    # Basic artifact.\n    examples = standard_artifacts.Examples()\n    examples.uri = \'/tmp/123\'\n    self.assertIsNotNone(\n        re.search(\'Artifact.*of type.*Examples.*/tmp/123\',\n                  self._format(examples)))\n\n    # Channel containing artifact.\n    channel = types.Channel(\n        type=standard_artifacts.Examples,\n        artifacts=[examples])\n    self.assertIsNotNone(\n        re.search((\'.*Channel.*of type.*Examples\'\n                   \'(.|\\n)*Artifact.*of type.*Examples\'),\n                  self._format(channel)))\n\n  def testFormatterTypeCheck(self):\n    formatter = notebook_formatters.FORMATTER_REGISTRY[types.Artifact]\n    with self.assertRaisesRegexp(\n        ValueError,\n        \'Expected object of type .*Artifact.* but got .*object object\'):\n      formatter.render(object())\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/experimental/interactive/standard_visualizations.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX notebook visualizations for standard TFX artifacts.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\n# Standard Imports\n\nimport tensorflow_data_validation as tfdv\nimport tensorflow_model_analysis as tfma\n\nfrom tfx import types\nfrom tfx.orchestration.experimental.interactive import visualizations\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExampleAnomaliesVisualization(visualizations.ArtifactVisualization):\n  """"""Visualization for standard_artifacts.ExampleAnomalies.""""""\n\n  ARTIFACT_TYPE = standard_artifacts.ExampleAnomalies\n\n  def display(self, artifact: types.Artifact):\n    anomalies_path = os.path.join(artifact.uri, \'anomalies.pbtxt\')\n    anomalies = tfdv.load_anomalies_text(anomalies_path)\n    tfdv.display_anomalies(anomalies)\n\n\nclass ExampleStatisticsVisualization(visualizations.ArtifactVisualization):\n  """"""Visualization for standard_artifacts.Statistics.""""""\n\n  ARTIFACT_TYPE = standard_artifacts.ExampleStatistics\n\n  def display(self, artifact: types.Artifact):\n    from IPython.core.display import display  # pylint: disable=g-import-not-at-top\n    from IPython.core.display import HTML  # pylint: disable=g-import-not-at-top\n    for split in artifact_utils.decode_split_names(artifact.split_names):\n      display(HTML(\'<div><b>%r split:</b></div><br/><br/>\' % split))\n      stats_path = os.path.join(artifact.uri, split, \'stats_tfrecord\')\n      stats = tfdv.load_statistics(stats_path)\n      tfdv.visualize_statistics(stats)\n\n\nclass ModelEvaluationVisualization(visualizations.ArtifactVisualization):\n  """"""Visualization for standard_artifacts.ModelEvaluation.""""""\n\n  ARTIFACT_TYPE = standard_artifacts.ModelEvaluation\n\n  def display(self, artifact: types.Artifact):\n    tfma_result = tfma.load_eval_result(artifact.uri)\n    # TODO(ccy): add comment instructing user to use the TFMA library directly\n    # in order to render non-default slicing metric views.\n    tfma.view.render_slicing_metrics(tfma_result)\n\n\nclass SchemaVisualization(visualizations.ArtifactVisualization):\n  """"""Visualization for standard_artifacts.Schema.""""""\n\n  ARTIFACT_TYPE = standard_artifacts.Schema\n\n  def display(self, artifact: types.Artifact):\n    schema_path = os.path.join(artifact.uri, \'schema.pbtxt\')\n    schema = tfdv.load_schema_text(schema_path)\n    tfdv.display_schema(schema)\n\n\nSTANDARD_VISUALIZATIONS = frozenset([\n    ExampleAnomaliesVisualization,\n    ExampleStatisticsVisualization,\n    ModelEvaluationVisualization,\n    SchemaVisualization,\n])\n\n\ndef register_standard_visualizations():\n  for visualization in STANDARD_VISUALIZATIONS:\n    visualizations.get_registry().register(visualization)\n'"
tfx/orchestration/experimental/interactive/visualizations.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX notebook visualizations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom typing import Text, Type\n\n# Standard Imports\n\nfrom six import with_metaclass\n\nfrom tfx import types\nfrom tfx.utils import abc_utils\n\n\nclass ArtifactVisualization(with_metaclass(abc.ABCMeta)):\n  """"""Visualization for a certain type of Artifact.""""""\n\n  # Artifact type (of type `Type[types.Artifact]`) to which the visualization\n  # applies.\n  ARTIFACT_TYPE = abc_utils.abstract_property()\n\n  @abc.abstractmethod\n  def display(self, artifact: types.Artifact) -> Text:\n    """"""Returns HTML string rendering artifact, in a notebook environment.""""""\n    raise NotImplementedError()\n\n\nclass ArtifactVisualizationRegistry(object):\n  """"""Registry of artifact visualizations.""""""\n\n  def __init__(self):\n    self.visualizations = {}\n\n  def register(self, visualization_class: Type[ArtifactVisualization]):\n    artifact_type = visualization_class.ARTIFACT_TYPE\n    if not (issubclass(artifact_type, types.Artifact) and\n            artifact_type.TYPE_NAME is not None):\n      raise TypeError(\n          \'Visualization class must provide subclass of types.Artifact in its \'\n          \'ARTIFACT_TYPE attribute. This subclass must have non-None TYPE_NAME \'\n          \'attribute.\')\n    self.visualizations[artifact_type.TYPE_NAME] = visualization_class()  # pytype: disable=not-instantiable\n\n  def get_visualization(self, artifact_type_name):\n    return self.visualizations.get(artifact_type_name, None)\n\n\n_REGISTRY = ArtifactVisualizationRegistry()\n\n\ndef get_registry():\n  return _REGISTRY\n'"
tfx/orchestration/experimental/interactive/visualizations_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.orchestration.experimental.interactive.visualizations.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\n\nfrom six.moves import builtins\nimport tensorflow as tf\n\nfrom tfx.orchestration.experimental.interactive import visualizations\nfrom tfx.types import standard_artifacts\n\n\nclass VisualizationsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(VisualizationsTest, self).setUp()\n    builtins.__dict__[\'__IPYTHON__\'] = True\n\n  def tearDown(self):\n    del builtins.__dict__[\'__IPYTHON__\']\n    super(VisualizationsTest, self).tearDown()\n\n  @mock.patch(\n      \'tfx.orchestration.experimental.interactive.\'\n      \'visualizations.get_registry\')\n  def testVisualizationRegistrationAndUsage(self, *unused_mocks):\n    registry = visualizations.ArtifactVisualizationRegistry()\n    visualizations.get_registry = mock.MagicMock(return_value=registry)\n    mock_object = mock.MagicMock()\n\n    class MyVisualization(visualizations.ArtifactVisualization):\n\n      # Arbitrary artifact type class.\n      ARTIFACT_TYPE = standard_artifacts.Examples\n\n      def display(self, unused_artifact):\n        mock_object(\'foo\')\n\n    visualizations.get_registry().register(MyVisualization)\n    self.assertIs(\n        MyVisualization,\n        visualizations.get_registry().get_visualization(\n            standard_artifacts.Examples.TYPE_NAME).__class__)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/orchestration/kubeflow/proto/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Init module for TFX.""""""\n\n# Import version string.\nfrom tfx.version import __version__\n'"
tfx/tools/cli/commands/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/commands/pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Commands for pipeline group.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport click\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.cli_context import Context\nfrom tfx.tools.cli.cli_context import pass_context\nfrom tfx.tools.cli.handler import handler_factory\n\n\n@click.group(\'pipeline\')\ndef pipeline_group() -> None:\n  pass\n\n\n# TODO(b/132286477): Add support for requirements file.\n@pipeline_group.command(\'create\', help=\'Create a pipeline\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_path\',\n    \'--pipeline-path\',\n    required=True,\n    type=str,\n    help=\'Path to Python DSL.\')\n@click.option(\n    \'--package_path\',\n    \'--package-path\',\n    default=None,\n    type=str,\n    help=\'Path to the pipeline output workflow file. When unset, it will try to find the workflow file, ""<pipeline_name>.tar.gz"" in the current directory.\'\n)\n@click.option(\n    \'--build_target_image\',\n    \'--build-target-image\',\n    default=None,\n    type=str,\n    help=\'Target container image path. The target image will be built by this \'\n    \'command to include local python codes to the TFX default image. By default, \'\n    \'it uses docker daemon to build an image which will install the local \'\n    \'python setup file onto TFX default image. You can place a setup.py file \'\n    \'to control the python code to install the dependent packages. You can also \'\n    \'customize the Skaffold building options by placing a build.yaml in the \'\n    \'local directory. In addition, you can place a Dockerfile file to customize\'\n    \'the docker building script.\'\n)\n@click.option(\n    \'--build_base_image\',\n    \'--build-base-image\',\n    default=None,\n    type=str,\n    help=\'Container image path to be used as the base image. If not specified, \'\n    \'target image will be build based on the released TFX image.\'\n)\n@click.option(\n    \'--skaffold_cmd\',\n    \'--skaffold-cmd\',\n    default=None,\n    type=str,\n    help=\'Skaffold program command.\')\n@click.option(\n    \'--endpoint\',\n    default=None,\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=None,\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef create_pipeline(ctx: Context, engine: Text, pipeline_path: Text,\n                    package_path: Text, build_target_image: Text,\n                    build_base_image: Text,\n                    skaffold_cmd: Text, endpoint: Text, iap_client_id: Text,\n                    namespace: Text) -> None:\n  """"""Command definition to create a pipeline.""""""\n  # TODO(b/142358865): Add support for container building for Airflow and Beam\n  # runners when they support container executors.\n  click.echo(\'Creating pipeline\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_DSL_PATH] = pipeline_path\n  ctx.flags_dict[labels.PIPELINE_PACKAGE_PATH] = package_path\n  ctx.flags_dict[labels.TARGET_IMAGE] = build_target_image\n  ctx.flags_dict[labels.BASE_IMAGE] = build_base_image\n  ctx.flags_dict[labels.SKAFFOLD_CMD] = skaffold_cmd\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).create_pipeline()\n\n\n@pipeline_group.command(\'update\', help=\'Update an existing pipeline.\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_path\',\n    \'--pipeline-path\',\n    required=True,\n    type=str,\n    help=\'Path to Python DSL file\')\n@click.option(\n    \'--package_path\',\n    \'--package-path\',\n    type=str,\n    default=None,\n    help=\'Path to the pipeline output workflow file. When unset, it will try to find the workflow file, ""<pipeline_name>.tar.gz"" in the current directory.\'\n)\n@click.option(\n    \'--skaffold_cmd\',\n    \'--skaffold-cmd\',\n    default=None,\n    type=str,\n    help=\'Skaffold program command.\')\n@click.option(\n    \'--endpoint\',\n    default=None,\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=None,\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef update_pipeline(ctx: Context, engine: Text, pipeline_path: Text,\n                    package_path: Text, skaffold_cmd: Text,\n                    endpoint: Text, iap_client_id: Text,\n                    namespace: Text) -> None:\n  """"""Command definition to update a pipeline.""""""\n  click.echo(\'Updating pipeline\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_DSL_PATH] = pipeline_path\n  ctx.flags_dict[labels.PIPELINE_PACKAGE_PATH] = package_path\n  ctx.flags_dict[labels.SKAFFOLD_CMD] = skaffold_cmd\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).update_pipeline()\n\n\n@pipeline_group.command(\'delete\', help=\'Delete a pipeline\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\n@click.option(\n    \'--endpoint\',\n    default=None,\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=None,\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef delete_pipeline(ctx: Context, engine: Text, pipeline_name: Text,\n                    endpoint: Text, iap_client_id: Text,\n                    namespace: Text) -> None:\n  """"""Command definition to delete a pipeline.""""""\n  click.echo(\'Deleting pipeline\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).delete_pipeline()\n\n\n@pipeline_group.command(\'list\', help=\'List all the pipelines\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'orchestrator for pipelines\')\n@click.option(\n    \'--endpoint\',\n    default=None,\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=None,\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef list_pipelines(ctx: Context, engine: Text, endpoint: Text,\n                   iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to list pipelines.""""""\n  click.echo(\'Listing all pipelines\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).list_pipelines()\n\n\n@pipeline_group.command(\'compile\', help=\'Compile a pipeline\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_path\',\n    \'--pipeline-path\',\n    required=True,\n    type=str,\n    help=\'Path to Python DSL.\')\n@click.option(\n    \'--package_path\',\n    \'--package-path\',\n    default=None,\n    type=str,\n    help=\'Path to the pipeline output workflow file. When unset, it will try to find the workflow file, ""<pipeline_name>.tar.gz"" in the current directory.\'\n)\ndef compile_pipeline(ctx: Context, engine: Text, pipeline_path: Text,\n                     package_path: Text) -> None:\n  """"""Command definition to compile a pipeline.""""""\n  click.echo(\'Compiling pipeline\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_DSL_PATH] = pipeline_path\n  ctx.flags_dict[labels.PIPELINE_PACKAGE_PATH] = package_path\n  handler_factory.create_handler(ctx.flags_dict).compile_pipeline()\n\n\n@pipeline_group.command(\'schema\', help=\'Obtain latest database schema.\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\ndef get_schema(ctx: Context, engine: Text, pipeline_name: Text) -> None:\n  """"""Command definition to infer latest schema.""""""\n  click.echo(\'Getting latest schema.\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  handler_factory.create_handler(ctx.flags_dict).get_schema()\n'"
tfx/tools/cli/commands/pipeline_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.cmd.pipeline_commands.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\nimport sys\n\nfrom click import testing as click_testing\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli.commands.pipeline import pipeline_group\n\n\nclass PipelineTest(tf.test.TestCase):\n\n  def setUp(self):\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    super(PipelineTest, self).setUp()\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n    self.runner = click_testing.CliRunner()\n    sys.modules[\'handler_factory\'] = mock.Mock()\n\n  def testPipelineCreateAuto(self):\n    result = self.runner.invoke(pipeline_group,\n                                [\'create\', \'--pipeline_path\', \'chicago.py\'])\n    self.assertIn(\'Creating pipeline\', result.output)\n    result = self.runner.invoke(pipeline_group,\n                                [\'create\', \'--pipeline-path\', \'chicago.py\'])\n    self.assertIn(\'Creating pipeline\', result.output)\n\n  def testPipelineUpdate(self):\n    result = self.runner.invoke(pipeline_group, [\n        \'update\', \'--pipeline_path\', \'chicago.py\', \'--engine\', \'kubeflow\',\n        \'--package_path\', \'chicago.tar.gz\', \'--iap_client_id\', \'fake_id\',\n        \'--namespace\', \'kubeflow\', \'--endpoint\', \'endpoint_url\'\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n    result = self.runner.invoke(pipeline_group, [\n        \'update\', \'--pipeline-path\', \'chicago.py\', \'--engine\', \'kubeflow\',\n        \'--package-path\', \'chicago.tar.gz\', \'--iap-client-id\', \'fake_id\',\n        \'--namespace\', \'kubeflow\', \'--endpoint\', \'endpoint_url\'\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n\n  def testPipelineDelete(self):\n    result = self.runner.invoke(\n        pipeline_group,\n        [\'delete\', \'--pipeline_name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Deleting pipeline\', result.output)\n    result = self.runner.invoke(\n        pipeline_group,\n        [\'delete\', \'--pipeline-name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Deleting pipeline\', result.output)\n\n  def testPipelineList(self):\n    result = self.runner.invoke(pipeline_group, [\'list\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Listing all pipelines\', result.output)\n\n  def testPipelineCompile(self):\n    result = self.runner.invoke(pipeline_group, [\n        \'compile\', \'--pipeline_path\', \'chicago.py\', \'--engine\', \'kubeflow\',\n        \'--package_path\', \'chicago.tar.gz\'\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    result = self.runner.invoke(pipeline_group, [\n        \'compile\', \'--pipeline-path\', \'chicago.py\', \'--engine\', \'kubeflow\',\n        \'--package-path\', \'chicago.tar.gz\'\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n\n  def testPipelineInvalidFlag(self):\n    result = self.runner.invoke(pipeline_group,\n                                [\'create\', \'--pipeline_name\', \'chicago.py\'])\n    self.assertIn(\'no such option\', result.output)\n    self.assertNotEqual(0, result.exit_code)\n\n  def testPipelineInvalidFlagType(self):\n    result = self.runner.invoke(pipeline_group,\n                                [\'update\', \'--pipeline_name\', 1])\n    self.assertNotEqual(0, result.exit_code)\n\n  def testPipelineMissingFlag(self):\n    result = self.runner.invoke(pipeline_group, [\'update\'])\n    self.assertIn(\'Missing option\', result.output)\n    self.assertNotEqual(0, result.exit_code)\n\n  def testPipelineInvalidCommand(self):\n    result = self.runner.invoke(pipeline_group, [\'rerun\'])\n    self.assertIn(\'No such command\', result.output)\n    self.assertNotEqual(0, result.exit_code)\n\n  def testPipelineEmptyFlagValue(self):\n    result = self.runner.invoke(pipeline_group, [\'create\', \'--pipeline_path\'])\n    self.assertIn(\'option requires an argument\', result.output)\n    self.assertNotEqual(0, result.exit_code)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/commands/run.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Commands for run group.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport click\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.cli_context import Context\nfrom tfx.tools.cli.cli_context import pass_context\nfrom tfx.tools.cli.handler import handler_factory\n\n\n@click.group(\'run\')\ndef run_group() -> None:\n  pass\n\n\n@run_group.command(\'create\', help=\'Create a new run for a pipeline\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\n@click.option(\n    \'--endpoint\',\n    default=\'\',\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=\'\',\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef create_run(ctx: Context, engine: Text, pipeline_name: Text, endpoint: Text,\n               iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to create a pipeline run.""""""\n  click.echo(\'Creating a run for pipeline: \' + pipeline_name)\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).create_run()\n\n\n@run_group.command(\'terminate\', help=\'Stop a run\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--run_id\',\n    \'--run-id\',\n    required=True,\n    type=str,\n    help=\'Unique ID for the run.)\')\n@click.option(\n    \'--endpoint\',\n    default=\'\',\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=\'\',\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef terminate_run(ctx: Context, engine: Text, run_id: Text, endpoint: Text,\n                  iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to stop a run.""""""\n  click.echo(\'Terminating run.\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.RUN_ID] = run_id\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).terminate_run()\n\n\n@run_group.command(\'list\', help=\'List all the runs of a pipeline\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\n@click.option(\n    \'--endpoint\',\n    default=\'\',\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=\'\',\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef list_runs(ctx: Context, engine: Text, pipeline_name: Text, endpoint: Text,\n              iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to list all runs of a pipeline.""""""\n  click.echo(\'Listing all runs of pipeline: \' + pipeline_name)\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).list_runs()\n\n\n@run_group.command(\'status\', help=\'Get the status of a run.\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\n@click.option(\n    \'--run_id\',\n    \'--run-id\',\n    required=True,\n    type=str,\n    help=\'Unique ID for the run.\')\n@click.option(\n    \'--endpoint\',\n    default=\'\',\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=\'\',\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef get_run(ctx: Context, engine: Text, pipeline_name: Text, run_id: Text,\n            endpoint: Text, iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to stop a run.""""""\n  click.echo(\'Retrieving run status.\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.RUN_ID] = run_id\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).get_run()\n\n\n@run_group.command(\'delete\', help=\'Delete a run\')\n@pass_context\n@click.option(\n    \'--engine\', default=\'auto\', type=str, help=\'Orchestrator for pipelines\')\n@click.option(\n    \'--run_id\',\n    \'--run-id\',\n    required=True,\n    type=str,\n    help=\'Unique ID for the run.\')\n@click.option(\n    \'--endpoint\',\n    default=\'\',\n    type=str,\n    help=\'Endpoint of the KFP API service to connect.\')\n@click.option(\n    \'--iap_client_id\',\n    \'--iap-client-id\',\n    default=\'\',\n    type=str,\n    help=\'Client ID for IAP protected endpoint.\')\n@click.option(\n    \'-n\',\n    \'--namespace\',\n    default=\'kubeflow\',\n    type=str,\n    help=\'Kubernetes namespace to connect to the KFP API.\')\ndef delete_run(ctx: Context, engine: Text, run_id: Text, endpoint: Text,\n               iap_client_id: Text, namespace: Text) -> None:\n  """"""Command definition to delete a run.""""""\n  click.echo(\'Deleting run.\')\n  ctx.flags_dict[labels.ENGINE_FLAG] = engine\n  ctx.flags_dict[labels.RUN_ID] = run_id\n  ctx.flags_dict[labels.ENDPOINT] = endpoint\n  ctx.flags_dict[labels.IAP_CLIENT_ID] = iap_client_id\n  ctx.flags_dict[labels.NAMESPACE] = namespace\n  handler_factory.create_handler(ctx.flags_dict).delete_run()\n'"
tfx/tools/cli/commands/run_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.commands.run.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\nimport sys\n\nfrom click import testing as click_testing\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli.commands.run import run_group\n\n\nclass RunTest(tf.test.TestCase):\n\n  def setUp(self):\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    super(RunTest, self).setUp()\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n    self.runner = click_testing.CliRunner()\n    sys.modules[\'handler_factory\'] = mock.Mock()\n\n  def testRunCreateAirflow(self):\n    result = self.runner.invoke(\n        run_group,\n        [\'create\', \'--pipeline_name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Creating a run for pipeline\', result.output)\n    result = self.runner.invoke(\n        run_group,\n        [\'create\', \'--pipeline-name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Creating a run for pipeline\', result.output)\n\n  def testRunCreateKubeflow(self):\n    result = self.runner.invoke(run_group, [\n        \'create\', \'--pipeline_name\', \'chicago\', \'--engine\', \'kubeflow\',\n        \'--iap_client_id\', \'fake_id\', \'--namespace\', \'kubeflow\', \'--endpoint\',\n        \'endpoint_url\'\n    ])\n    self.assertIn(\'Creating a run for pipeline\', result.output)\n    result = self.runner.invoke(run_group, [\n        \'create\', \'--pipeline-name\', \'chicago\', \'--engine\', \'kubeflow\',\n        \'--iap-client-id\', \'fake_id\', \'--namespace\', \'kubeflow\', \'--endpoint\',\n        \'endpoint_url\'\n    ])\n    self.assertIn(\'Creating a run for pipeline\', result.output)\n\n  def testRunList(self):\n    result = self.runner.invoke(\n        run_group,\n        [\'list\', \'--pipeline_name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Listing all runs of pipeline\', result.output)\n    result = self.runner.invoke(\n        run_group,\n        [\'list\', \'--pipeline-name\', \'chicago\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Listing all runs of pipeline\', result.output)\n\n  def testRunStatusAirflow(self):\n    result = self.runner.invoke(run_group, [\n        \'status\', \'--pipeline_name\', \'chicago_taxi_pipeline\', \'--run_id\',\n        \'airflow_run_id\', \'--engine\', \'airflow\'\n    ])\n    self.assertIn(\'Retrieving run status\', result.output)\n    result = self.runner.invoke(run_group, [\n        \'status\', \'--pipeline-name\', \'chicago_taxi_pipeline\', \'--run-id\',\n        \'airflow_run_id\', \'--engine\', \'airflow\'\n    ])\n    self.assertIn(\'Retrieving run status\', result.output)\n\n  def testRunStatusKubeflow(self):\n    result = self.runner.invoke(run_group, [\n        \'status\', \'--pipeline_name\', \'chicago_taxi_pipeline\', \'--run_id\',\n        \'kubeflow_run_id\', \'--engine\', \'kubeflow\', \'--iap_client_id\', \'fake_id\',\n        \'--namespace\', \'kubeflow\', \'--endpoint\', \'endpoint_url\'\n    ])\n    self.assertIn(\'Retrieving run status\', result.output)\n    result = self.runner.invoke(run_group, [\n        \'status\', \'--pipeline-name\', \'chicago_taxi_pipeline\', \'--run-id\',\n        \'kubeflow_run_id\', \'--engine\', \'kubeflow\', \'--iap-client-id\', \'fake_id\',\n        \'--namespace\', \'kubeflow\', \'--endpoint\', \'endpoint_url\'\n    ])\n    self.assertIn(\'Retrieving run status\', result.output)\n\n  def testRunTerminate(self):\n    result = self.runner.invoke(\n        run_group,\n        [\'terminate\', \'--run_id\', \'airflow_run_id\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Terminating run.\', result.output)\n    result = self.runner.invoke(\n        run_group,\n        [\'terminate\', \'--run-id\', \'airflow_run_id\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Terminating run.\', result.output)\n\n  def testRunDelete(self):\n    result = self.runner.invoke(run_group, [\n        \'delete\', \'--run_id\', \'kubeflow_run_id\', \'--engine\', \'kubeflow\',\n        \'--iap_client_id\', \'fake_id\', \'--namespace\', \'kubeflow\', \'--endpoint\',\n        \'endpoint_url\'\n    ])\n    self.assertIn(\'Deleting run\', result.output)\n    result = self.runner.invoke(run_group, [\n        \'delete\', \'--run-id\', \'kubeflow_run_id\', \'--engine\', \'kubeflow\',\n        \'--iap-client-id\', \'fake_id\', \'--namespace\', \'kubeflow\', \'--endpoint\',\n        \'endpoint_url\'\n    ])\n    self.assertIn(\'Deleting run\', result.output)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/commands/template.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Commands for copy_template.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport click\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.cli_context import Context\nfrom tfx.tools.cli.cli_context import pass_context\nfrom tfx.tools.cli.handler import template_handler\n\n\n@click.group(\n    \'template\',\n    help=\'[Experimental] Helps creating a new TFX pipeline scaffold.\')\ndef template_group() -> None:\n  pass\n\n\n@template_group.command(\'list\', help=\'[Experimental] List available templates\')\ndef list_templates() -> None:\n  click.echo(\'Available templates:\')\n  for model in template_handler.list_template():\n    click.echo(\'- {}\'.format(model))\n\n\n@template_group.command(\n    \'copy\', help=\'[Experimental] Copy a template to destination directory\')\n@pass_context\n@click.option(\n    \'--pipeline_name\',\n    \'--pipeline-name\',\n    required=True,\n    type=str,\n    help=\'Name of the pipeline\')\n@click.option(\n    \'--destination_path\',\n    \'--destination-path\',\n    required=True,\n    type=str,\n    help=\'Destination directory path to copy the pipeline template\')\n@click.option(\n    \'--model\',\n    required=True,\n    type=str,\n    help=\'Name of the template to copy. Currently, `taxi` is the only template provided.\'\n)\ndef copy(ctx: Context, pipeline_name: Text, destination_path: Text,\n         model: Text) -> None:\n  """"""Command definition to copy template to specified directory.""""""\n  click.echo(\'Copying {} pipeline template\'.format(model))\n  ctx.flags_dict[labels.PIPELINE_NAME] = pipeline_name\n  ctx.flags_dict[labels.DESTINATION_PATH] = destination_path\n  ctx.flags_dict[labels.MODEL] = model\n  template_handler.copy_template(ctx.flags_dict)\n'"
tfx/tools/cli/commands/template_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.commands.copy_template.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\n\nfrom absl import logging\nfrom click import testing as click_testing\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli.commands.template import template_group\nfrom tfx.tools.cli.handler import template_handler\n\n\nclass TemplateTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TemplateTest, self).setUp()\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n      logging.info(\'Changing locale to %s to ensure UTF-8 environment.\',\n                   os.environ[\'LANG\'])\n    self.runner = click_testing.CliRunner()\n    self.addCleanup(mock.patch.stopall)\n    mock.patch.object(template_handler, \'list_template\').start()\n    mock.patch.object(template_handler, \'copy_template\').start()\n\n  def testListSuccess(self):\n    result = self.runner.invoke(template_group, [\'list\'])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\'Available templates\', result.output)\n\n  def testMissingPipelineName(self):\n    result = self.runner.invoke(\n        template_group, [\'copy\', \'--model\', \'m\', \'--destination_path\', \'/path\'])\n    self.assertNotEqual(0, result.exit_code)\n    self.assertIn(\'pipeline_name\', result.output)\n\n  def testMissingDestinationPath(self):\n    result = self.runner.invoke(\n        template_group, [\'copy\', \'--pipeline_name\', \'p\', \'--model\', \'m\'])\n    self.assertNotEqual(0, result.exit_code)\n    self.assertIn(\'destination_path\', result.output)\n\n  def testMissingModel(self):\n    result = self.runner.invoke(\n        template_group,\n        [\'copy\', \'--pipeline_name\', \'p\', \'--destination_path\', \'/path\'])\n    self.assertNotEqual(0, result.exit_code)\n    self.assertIn(\'model\', result.output)\n\n  def testCopySuccess(self):\n    result = self.runner.invoke(template_group, [\n        \'copy\', \'--pipeline_name\', \'p\', \'--destination_path\', \'/path\',\n        \'--model\', \'m\'\n    ])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\'Copying\', result.output)\n    result = self.runner.invoke(template_group, [\n        \'copy\', \'--pipeline-name\', \'p\', \'--destination-path\', \'/path\',\n        \'--model\', \'m\'\n    ])\n    self.assertEqual(0, result.exit_code)\n    self.assertIn(\'Copying\', result.output)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/container_builder/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/container_builder/builder.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""ContainerBuilder builds the container image.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Optional, Text\n\nimport click\n\nfrom tfx.tools.cli.container_builder import buildspec\nfrom tfx.tools.cli.container_builder import labels\nfrom tfx.tools.cli.container_builder.dockerfile import Dockerfile\nfrom tfx.tools.cli.container_builder.skaffold_cli import SkaffoldCli\n\n\n# TODO(b/142357382): add e2e tests.\nclass ContainerBuilder(object):\n  """"""Build containers.\n\n  ContainerBuilder prepares the build files and run Skaffold to build the\n  containers.\n\n  Attributes:\n    _buildspec: BuildSpec instance.\n    _skaffold_cmd: Skaffold command.\n  """"""\n\n  def __init__(self,\n               target_image: Optional[Text] = None,\n               base_image: Optional[Text] = None,\n               skaffold_cmd: Optional[Text] = None,\n               buildspec_filename: Optional[Text] = None,\n               dockerfile_name: Optional[Text] = None,\n               setup_py_filename: Optional[Text] = None):\n    """"""Initialization.\n\n    Args:\n      target_image: the target image path to be built.\n      base_image: the image path to use as the base image.\n      skaffold_cmd: skaffold command.\n      buildspec_filename: the buildspec file path that is accessible to the\n        current execution environment. It could be either absolute path or\n        relative path.\n      dockerfile_name: the dockerfile name, which is stored in the workspace\n        directory. The workspace directory is specified in the build spec and\n        the default workspace directory is \'.\'.\n      setup_py_filename: the setup.py file name, which is used to build a\n        python package for the workspace directory. If not specified, the\n        whole directory is copied and PYTHONPATH is configured.\n    """"""\n    base_image = base_image or labels.BASE_IMAGE\n    self._skaffold_cmd = skaffold_cmd or labels.SKAFFOLD_COMMAND\n    buildspec_filename = buildspec_filename or labels.BUILD_SPEC_FILENAME\n    dockerfile_name = dockerfile_name or labels.DOCKERFILE_NAME\n    setup_py_filename = setup_py_filename or labels.SETUP_PY_FILENAME\n\n    if os.path.exists(buildspec_filename):\n      self._buildspec = buildspec.BuildSpec(filename=buildspec_filename)\n      if target_image is not None:\n        click.echo(\n            \'Target image %s is not used. If the build spec is \'\n            \'provided, update the target image in the build spec \'\n            \'file %s.\' % (target_image, buildspec_filename))\n    else:\n      self._buildspec = buildspec.BuildSpec.load_default(\n          filename=buildspec_filename,\n          target_image=target_image,\n          dockerfile_name=dockerfile_name)\n\n    Dockerfile(\n        filename=os.path.join(self._buildspec.build_context, dockerfile_name),\n        setup_py_filename=setup_py_filename,\n        base_image=base_image)\n\n  def build(self):\n    """"""Build the container and return the built image path with SHA.""""""\n    click.echo(\'Use skaffold to build the container image.\')\n    skaffold_cli = SkaffoldCli(cmd=self._skaffold_cmd)\n    image_sha = skaffold_cli.build(buildspec_filename=self._buildspec.filename)\n    target_image = self._buildspec.target_image\n    return target_image + \'@\' + image_sha\n'"
tfx/tools/cli/container_builder/buildspec.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""BuildSpec helper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Optional, Text\n\nimport click\nimport yaml\n\nfrom tfx.tools.cli.container_builder import labels\n\n\nclass BuildSpec(object):\n  """"""Build specification.\n\n  BuildSpec generates a default build spec if it does not exist.\n\n  Attributes:\n    filename: build spec filename.\n    build_context: build working directory.\n    target_image: target image with no tag.\n    _buildspec: in-memory representation of the build spec.\n  """"""\n\n  def __init__(self,\n               filename: Text = labels.BUILD_SPEC_FILENAME):\n    self._filename = filename\n    if not os.path.exists(self._filename):\n      raise ValueError(\'BuildSpec:: build spec file %s does not exist.\' %\n                       filename)\n    self._read_existing_build_spec()\n\n  @staticmethod\n  def load_default(filename: Text = labels.BUILD_SPEC_FILENAME,\n                   target_image: Optional[Text] = None,\n                   build_context: Optional[Text] = None,\n                   dockerfile_name: Optional[Text] = None):\n    """"""Generate a default build spec yaml.\n\n    Args:\n      filename: build spec filename.\n      target_image: target image path. If it contains the tag, the build spec\n        will also include it; If it does not, the build spec will tag it as\n        \'lastest\'.\n      build_context: local build context path.\n      dockerfile_name: dockerfile filename in the build_context.\n\n    Returns:\n      BuildSpec instance.\n    """"""\n    if os.path.exists(filename):\n      raise ValueError(\'BuildSpec: build spec file %s already exists.\' %\n                       filename)\n    if target_image is None:\n      raise ValueError(\'BuildSpec: target_image is not given.\')\n\n    target_image_fields = target_image.split(\':\')\n    if len(target_image_fields) > 2:\n      raise ValueError(\'BuildSpec: target_image is in illegal form.\')\n    target_image_with_no_tag = target_image_fields[0]\n    target_image_tag = \'latest\' if len(\n        target_image_fields) <= 1 else target_image_fields[1]\n\n    build_context = build_context or labels.BUILD_CONTEXT\n    dockerfile_name = dockerfile_name or labels.DOCKERFILE_NAME\n\n    build_spec = {\n        \'apiVersion\': labels.SKAFFOLD_API_VERSION,\n        \'kind\': \'Config\',\n        \'build\': {\n            \'tagPolicy\': {\n                \'envTemplate\': {\n                    \'template\': \'{{.IMAGE_NAME}}:\' + target_image_tag\n                }\n            },\n            \'artifacts\': [{\n                \'image\': target_image_with_no_tag,\n                \'context\': build_context,\n                \'docker\': {\n                    \'dockerfile\': dockerfile_name\n                }\n            }]\n        }\n    }\n    with open(filename, \'w\') as f:\n      yaml.dump(build_spec, f)\n    return BuildSpec(filename)\n\n  def _read_existing_build_spec(self):\n    """"""Read existing build spec yaml.""""""\n    with open(self.filename, \'r\') as f:\n      click.echo(\'Reading build spec from %s\' % self.filename)\n      self._buildspec = yaml.safe_load(f)\n      if len(self._buildspec[\'build\'][\'artifacts\']) != 1:\n        raise RuntimeError(\'The build spec contains multiple artifacts however\'\n                           \'only one is supported.\')\n      self._build_context = self._buildspec[\'build\'][\'artifacts\'][0][\'context\']\n      self._target_image = self._buildspec[\'build\'][\'artifacts\'][0][\'image\']\n\n  @property\n  def filename(self):\n    return self._filename\n\n  @property\n  def build_context(self):\n    return self._build_context\n\n  @property\n  def target_image(self):\n    return self._target_image\n'"
tfx/tools/cli/container_builder/buildspec_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.builder.buildspec.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\nimport yaml\n\nfrom tfx.tools.cli.container_builder import buildspec\nfrom tfx.tools.cli.container_builder import labels\n\n\nclass BuildSpecTest(tf.test.TestCase):\n\n  def test_generate_clean(self):\n    test_buildspec_name = \'test_buildspec\'\n    default_buildspec_path = os.path.join(\n        os.path.dirname(__file__), \'testdata\', test_buildspec_name)\n    output_path = os.path.join(self.create_tempdir().full_path, \'generated\')\n\n    build_spec = buildspec.BuildSpec.load_default(\n        filename=output_path,\n        target_image=\'gcr.io/test:dev\',\n        dockerfile_name=labels.DOCKERFILE_NAME)\n    with open(default_buildspec_path, \'r\') as f:\n      golden_buildspec = yaml.safe_load(f)\n    with open(build_spec.filename, \'r\') as f:\n      generated_buildspec = yaml.safe_load(f)\n\n    self.assertEqual(generated_buildspec, golden_buildspec)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/container_builder/dockerfile.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Dockerfile helper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport click\n\nfrom tfx.tools.cli.container_builder import labels\n\n_DEFAULT_DOCKERFILE_CONTENT_WITH_SETUP_PY = \'\'\'FROM %s\nWORKDIR /pipeline\nCOPY ./ ./\nRUN python3 %s install\'\'\'\n\n_DEFAULT_DOCKERFILE_CONTENT_WITHOUT_SETUP_PY = \'\'\'FROM %s\nWORKDIR /pipeline\nCOPY ./ ./\nENV PYTHONPATH=""/pipeline:${PYTHONPATH}""\'\'\'\n\n\nclass Dockerfile(object):\n  """"""Dockerfile class.\n\n  Dockerfile generates a default dockerfile if it does not exist.\n\n  Attributes:\n    filename: dockerfile filename.\n    setup_py_filename: setup.py filename that defines the pipeline PIP package.\n  """"""\n\n  def __init__(self,\n               filename: Text = labels.DOCKERFILE_NAME,\n               setup_py_filename: Text = labels.SETUP_PY_FILENAME,\n               base_image: Text = labels.BASE_IMAGE):\n    self.filename = filename\n    if os.path.exists(self.filename):\n      return\n    if os.path.exists(setup_py_filename):\n      click.echo(\'Generating Dockerfile with python package installation \'\n                 \'based on %s.\' % setup_py_filename)\n      self._generate_default(_DEFAULT_DOCKERFILE_CONTENT_WITH_SETUP_PY %\n                             (base_image, setup_py_filename))\n      return\n\n    click.echo(\'No local %s, copying the directory and \'\n               \'configuring the PYTHONPATH.\' % setup_py_filename)\n    self._generate_default(_DEFAULT_DOCKERFILE_CONTENT_WITHOUT_SETUP_PY %\n                           base_image)\n\n  def _generate_default(self, contents):\n    """"""Generate a dockerfile with the contents.""""""\n    with open(self.filename, \'w+\') as f:\n      f.write(contents)\n'"
tfx/tools/cli/container_builder/dockerfile_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.builder.dockerfile.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport filecmp\nimport os\nimport tempfile\nimport tensorflow as tf\n\nfrom tfx import version\nfrom tfx.tools.cli.container_builder import dockerfile\nfrom tfx.tools.cli.container_builder import labels\n\n\n_test_dockerfile_content = \'\'\'FROM tensorflow/tfx:%s\nWORKDIR /pipeline\nCOPY ./ ./\nENV PYTHONPATH=""/pipeline:${PYTHONPATH}""\'\'\' % version.__version__\n\n\nclass DockerfileTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(DockerfileTest, self).setUp()\n    self._testdata_dir = os.path.join(\n        os.path.abspath(os.path.dirname(__file__)), \'testdata\')\n    # change to a temporary working dir such that\n    # there is no setup.py in the working dir.\n    self._old_working_dir = os.getcwd()\n    self._tmp_working_dir = tempfile.mkdtemp()\n    self._test_dockerfile = os.path.join(self._tmp_working_dir,\n                                         \'.test_dockerfile\')\n    with open(self._test_dockerfile, \'w\') as f:\n      f.writelines(_test_dockerfile_content)\n    os.chdir(self._tmp_working_dir)\n\n  def tearDown(self):\n    super(DockerfileTest, self).tearDown()\n    os.chdir(self._old_working_dir)\n\n  def testGenerate(self):\n    generated_dockerfile_path = labels.DOCKERFILE_NAME\n    dockerfile.Dockerfile(filename=generated_dockerfile_path)\n    self.assertTrue(\n        filecmp.cmp(self._test_dockerfile, generated_dockerfile_path))\n\n  def testGenerateWithBaseOverride(self):\n    generated_dockerfile_path = labels.DOCKERFILE_NAME\n    dockerfile.Dockerfile(\n        filename=generated_dockerfile_path,\n        base_image=\'my_customized_image:latest\')\n    self.assertTrue(\n        filecmp.cmp(\n            os.path.join(self._testdata_dir, \'test_dockerfile_with_base\'),\n            generated_dockerfile_path))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/container_builder/labels.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common variables.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tfx import version\n\n# Default values\nBASE_IMAGE = \'tensorflow/tfx:%s\' % version.__version__\nBUILD_SPEC_FILENAME = \'build.yaml\'\nBUILD_CONTEXT = \'.\'\nDOCKERFILE_NAME = \'Dockerfile\'\nSETUP_PY_FILENAME = \'setup.py\'\nSKAFFOLD_COMMAND = \'skaffold\'\nSKAFFOLD_API_VERSION = \'skaffold/v1beta13\'\n'"
tfx/tools/cli/container_builder/setup_gen.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python setup helper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# TODO(jxzheng): Generate setup.py\n'"
tfx/tools/cli/container_builder/skaffold_cli.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Skaffold Cli helper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport re\nimport subprocess\nfrom typing import Text\n\nimport click\n\nfrom tfx.tools.cli.container_builder import labels\n\n\nclass SkaffoldCli(object):\n  """"""Skaffold CLI.""""""\n\n  def __init__(self, cmd=labels.SKAFFOLD_COMMAND):\n    self._cmd = cmd or labels.SKAFFOLD_COMMAND\n    try:\n      subprocess.run([\'which\', self._cmd], check=True)\n    except subprocess.CalledProcessError:\n      click.echo(\'No executable %s\' % self._cmd)\n      click.echo(\'please refer to \'\n                 \'https://github.com/GoogleContainerTools/skaffold/releases \'\n                 \'for installation instructions.\')\n      raise RuntimeError\n\n  def build(self, buildspec_filename: Text = labels.BUILD_SPEC_FILENAME):\n    """"""Builds an image and return the image SHA.""""""\n    if not os.path.exists(buildspec_filename):\n      raise ValueError(\'Build spec: %s does not exist.\' % buildspec_filename)\n    output = subprocess.check_output([\n        self._cmd, \'build\', \'-q\', \'--output={{json .}}\', \'-f\',\n        buildspec_filename\n    ]).decode(\'utf-8\')\n    full_image_name_with_tag = json.loads(output)[\'builds\'][0][\'tag\']\n    m = re.search(r\'sha256:[0-9a-f]{64}\', full_image_name_with_tag)\n    if m is None:\n      raise RuntimeError(\'SkaffoldCli: built image SHA is not found.\')\n    return m.group(0)\n'"
tfx/tools/cli/container_builder/skaffold_cli_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.container_builder.skaffold_cli.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport subprocess\n\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli.container_builder import skaffold_cli\n\nSAMPLE_SKAFFOLD_OUTPUT = b\'{""builds"":[{""imageName"":""gcr.io/my-test/test"",""tag"":""gcr.io/my-test/test:latest@sha256:f5ee0ecb19eb5dc970f15290f2c47c10d23e303d381aebef91929c2df2ce5004""}]}\'\n\n\nclass SkaffoldCliTest(tf.test.TestCase):\n\n  @mock.patch.object(subprocess, \'run\')\n  @mock.patch.object(os.path, \'exists\')\n  @mock.patch.object(\n      subprocess, \'check_output\', return_value=SAMPLE_SKAFFOLD_OUTPUT)\n  def testSkaffoldBuild(self, mock_run, mock_exists, mock_check_output):\n    cli = skaffold_cli.SkaffoldCli()\n    sha256 = cli.build()\n    self.assertEqual(\n        sha256,\n        \'sha256:f5ee0ecb19eb5dc970f15290f2c47c10d23e303d381aebef91929c2df2ce5004\'\n    )\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/e2e/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/e2e/cli_airflow_e2e_test.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Airflow tests for CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\nimport subprocess\nimport sys\nimport time\n\nimport absl\nfrom click import testing as click_testing\nimport tensorflow as tf\nfrom tfx.orchestration.airflow import test_utils as airflow_test_utils\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.cli_main import cli_group\nfrom tfx.tools.cli.e2e import test_utils\nfrom tfx.utils import io_utils\n\n\nclass CliAirflowEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(CliAirflowEndToEndTest, self).setUp()\n\n    # List of packages installed.\n    self._pip_list = str(subprocess.check_output([\'pip\', \'freeze\', \'--local\']))\n\n    # Check if Apache Airflow is installed before running E2E tests.\n    if labels.AIRFLOW_PACKAGE_NAME not in self._pip_list:\n      sys.exit(\'Apache Airflow not installed.\')\n\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n\n    # Setup airflow_home in a temp directory\n    self._airflow_home = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName, \'airflow\')\n    self._old_airflow_home = os.environ.get(\'AIRFLOW_HOME\')\n    os.environ[\'AIRFLOW_HOME\'] = self._airflow_home\n    self._old_home = os.environ.get(\'HOME\')\n    os.environ[\'HOME\'] = self._airflow_home\n    absl.logging.info(\'Using %s as AIRFLOW_HOME and HOME in this e2e test\',\n                      self._airflow_home)\n\n    # Testdata path.\n    self._testdata_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n    self._pipeline_name = \'chicago_taxi_simple\'\n    self._pipeline_path = os.path.join(self._testdata_dir,\n                                       \'test_pipeline_airflow_1.py\')\n\n    # Copy data.\n    chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(\n            os.path.dirname(\n                os.path.dirname(os.path.dirname(os.path.abspath(__file__))))),\n        \'examples\', \'chicago_taxi_pipeline\')\n    data_dir = os.path.join(chicago_taxi_pipeline_dir, \'data\', \'simple\')\n    content = tf.io.gfile.listdir(data_dir)\n    assert content, \'content in {} is empty\'.format(data_dir)\n    target_data_dir = os.path.join(self._airflow_home, \'taxi\', \'data\', \'simple\')\n    io_utils.copy_dir(data_dir, target_data_dir)\n    assert tf.io.gfile.isdir(target_data_dir)\n    content = tf.io.gfile.listdir(target_data_dir)\n    assert content, \'content in {} is {}\'.format(target_data_dir, content)\n    io_utils.copy_file(\n        os.path.join(chicago_taxi_pipeline_dir, \'taxi_utils.py\'),\n        os.path.join(self._airflow_home, \'taxi\', \'taxi_utils.py\'))\n\n    self._mysql_container_name = \'airflow_\' + test_utils.generate_random_id()\n    db_port = airflow_test_utils.create_mysql_container(\n        self._mysql_container_name)\n    self.addCleanup(airflow_test_utils.delete_mysql_container,\n                    self._mysql_container_name)\n    os.environ[\'AIRFLOW__CORE__SQL_ALCHEMY_CONN\'] = (\n        \'mysql://tfx@127.0.0.1:%d/airflow\' % db_port)\n    # Do not load examples to make this a bit faster.\n    os.environ[\'AIRFLOW__CORE__LOAD_EXAMPLES\'] = \'False\'\n\n    self._airflow_initdb()\n\n    # Initialize CLI runner.\n    self.runner = click_testing.CliRunner()\n\n  def tearDown(self):\n    super(CliAirflowEndToEndTest, self).tearDown()\n    if self._old_airflow_home:\n      os.environ[\'AIRFLOW_HOME\'] = self._old_airflow_home\n    if self._old_home:\n      os.environ[\'HOME\'] = self._old_home\n\n  def _airflow_initdb(self):\n    _ = subprocess.check_output([\'airflow\', \'initdb\'])\n\n  def _reload_airflow_dags(self):\n    # Created pipelines can be registered to the DB by airflow scheduler\n    # asynchronously. But we will rely on `initdb` which does same job\n    # synchronously for deterministic and fast test execution.\n    # (And it doesn\'t initialize db.)\n    self._airflow_initdb()\n\n  def _does_pipeline_args_file_exist(self, pipeline_name):\n    handler_pipeline_path = os.path.join(self._airflow_home, \'dags\',\n                                         pipeline_name)\n    return tf.io.gfile.exists(\n        os.path.join(handler_pipeline_path, \'pipeline_args.json\'))\n\n  def _valid_create_and_check(self, pipeline_path, pipeline_name):\n    # Create a pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        pipeline_path\n    ])\n\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(self._does_pipeline_args_file_exist(pipeline_name))\n    self.assertIn(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name),\n                  result.output)\n\n  def testPipelineCreateAutoDetect(self):\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'auto\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Creating pipeline\', result.output)\n    if labels.AIRFLOW_PACKAGE_NAME in self._pip_list and labels.KUBEFLOW_PACKAGE_NAME in self._pip_list:\n      self.assertIn(\n          \'Multiple orchestrators found. Choose one using --engine flag.\',\n          result.output)\n    else:\n      self.assertIn(\'Detected Airflow\', result.output)\n      self.assertTrue(\n          self._does_pipeline_args_file_exist(self._pipeline_name))\n      self.assertIn(\n          \'Pipeline ""{}"" created successfully.\'.format(self._pipeline_name),\n          result.output)\n\n  def testPipelineCreate(self):\n    # Create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Test pipeline create when pipeline already exists.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(\'Pipeline ""{}"" already exists.\'.format(self._pipeline_name),\n                    result.output)\n\n  def testPipelineUpdate(self):\n    # Try pipeline update when pipeline does not exist.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n    self.assertFalse(self._does_pipeline_args_file_exist(self._pipeline_name))\n\n    # Now update an existing pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\n        \'Pipeline ""{}"" updated successfully.\'.format(self._pipeline_name),\n        result.output)\n    self.assertTrue(self._does_pipeline_args_file_exist(self._pipeline_name))\n\n  def testPipelineCompile(self):\n    # Invalid DSL path\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_flink.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Invalid pipeline path: {}\'.format(pipeline_path),\n                  result.output)\n\n    # Wrong Runner.\n    pipeline_path = os.path.join(self._testdata_dir,\n                                 \'test_pipeline_kubeflow_1.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'airflow runner not found in dsl.\', result.output)\n\n    # Successful compilation.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'airflow\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Pipeline compiled successfully\', result.output)\n\n  def testPipelineDelete(self):\n    # Try deleting a non existent pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'airflow\', \'--pipeline_name\',\n        self._pipeline_name\n    ])\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n    self.assertFalse(self._does_pipeline_args_file_exist(self._pipeline_name))\n\n    # Create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Now delete the pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'airflow\', \'--pipeline_name\',\n        self._pipeline_name\n    ])\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertFalse(self._does_pipeline_args_file_exist(self._pipeline_name))\n    self.assertIn(\n        \'Pipeline ""{}"" deleted successfully.\'.format(self._pipeline_name),\n        result.output)\n\n  def testPipelineList(self):\n    # Prepare another pipeline file.\n    pipeline_name_v2 = \'chicago_taxi_simple_v2\'\n    pipeline_path_v2 = os.path.join(self.get_temp_dir(),\n                                    \'test_pipeline_airflow_v2.py\')\n    test_utils.copy_and_change_pipeline_name(self._pipeline_path,\n                                             pipeline_path_v2,\n                                             self._pipeline_name,\n                                             pipeline_name_v2)\n\n    # Try listing pipelines when there are none.\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'list\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Listing all pipelines\', result.output)\n\n    # Create pipelines.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n    self._valid_create_and_check(pipeline_path_v2, pipeline_name_v2)\n\n    # List pipelines.\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'list\', \'--engine\', \'airflow\'])\n    self.assertIn(\'Listing all pipelines\', result.output)\n    self.assertIn(self._pipeline_name, result.output)\n    self.assertIn(pipeline_name_v2, result.output)\n\n  def _valid_run_and_check(self, pipeline_name):\n    # Wait to fill up the DagBag.\n    response = \'\'\n    while pipeline_name not in response:\n      response = str(\n          subprocess.check_output([\'airflow\', \'list_dags\', \'--report\']))\n\n    self._reload_airflow_dags()\n\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'create\', \'--engine\', \'airflow\', \'--pipeline_name\', pipeline_name\n    ])\n\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(pipeline_name),\n                  result.output)\n    self.assertNotIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name),\n                     result.output)\n    self.assertIn(\'Run created for pipeline: {}\'.format(pipeline_name),\n                  result.output)\n\n    # NOTE: Because airflow scheduler was not launched, this run will not ""run"",\n    #       actually. This e2e test covers CLI side of the execution only.\n\n  def testRunCreate(self):\n    # Try running a non-existent pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'create\', \'--engine\', \'airflow\', \'--pipeline_name\',\n        self._pipeline_name\n    ])\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(self._pipeline_name),\n                  result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline.\n    self._valid_run_and_check(self._pipeline_name)\n\n  def testRunList(self):\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Check if pipeline runs exist.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'list\', \'--engine\', \'airflow\', \'--pipeline_name\',\n        self._pipeline_name\n    ])\n    self.assertIn(\n        \'Listing all runs of pipeline: {}\'.format(self._pipeline_name),\n        result.output)\n    self.assertIn(\'No pipeline runs for {}\'.format(self._pipeline_name),\n                  result.output)\n\n    # Run pipeline.\n    self._valid_run_and_check(self._pipeline_name)\n\n    time.sleep(1)  # Sleep to ensure two pipelines have different timestamps.\n    # Run pipeline again.\n    self._valid_run_and_check(self._pipeline_name)\n\n    # List pipeline runs.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'list\', \'--engine\', \'airflow\', \'--pipeline_name\',\n        self._pipeline_name\n    ])\n    self.assertIn(\n        \'Listing all runs of pipeline: {}\'.format(self._pipeline_name),\n        result.output)\n\n  def testUninstalledOrchestratorKubeflow(self):\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'list\', \'--engine\', \'kubeflow\'])\n    self.assertIn(\'Listing all pipelines\', result.output)\n    # When only Airflow is installed.\n    if labels.KUBEFLOW_PACKAGE_NAME not in self._pip_list:\n      self.assertIn(\'Kubeflow not found\', result.output)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/e2e/cli_beam_e2e_test.py,11,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Beam tests for CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\nimport tempfile\n\nfrom click import testing as click_testing\nimport tensorflow as tf\n\nfrom tfx.tools.cli.cli_main import cli_group\nfrom tfx.utils import io_utils\n\n\nclass CliBeamEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(CliBeamEndToEndTest, self).setUp()\n\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n\n    # Setup beam_home in a temp directory\n    self._home = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', tempfile.mkdtemp()),\n        self._testMethodName)\n    self._old_home = os.environ.get(\'HOME\')\n    os.environ[\'HOME\'] = self._home\n    self._old_beam_home = os.environ.get(\'BEAM_HOME\')\n    os.environ[\'BEAM_HOME\'] = os.path.join(self._home, \'beam\', \'\')\n    self._beam_home = os.environ[\'BEAM_HOME\']\n\n    # Testdata path.\n    self._testdata_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n\n    # Copy data.\n    chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(\n            os.path.dirname(\n                os.path.dirname(os.path.dirname(os.path.abspath(__file__))))),\n        \'examples\', \'chicago_taxi_pipeline\', \'\')\n    data_dir = os.path.join(chicago_taxi_pipeline_dir, \'data\', \'simple\')\n    content = tf.io.gfile.listdir(data_dir)\n    assert content, \'content in {} is empty\'.format(data_dir)\n    target_data_dir = os.path.join(self._home, \'taxi\', \'data\', \'simple\')\n    io_utils.copy_dir(data_dir, target_data_dir)\n    assert tf.io.gfile.isdir(target_data_dir)\n    content = tf.io.gfile.listdir(target_data_dir)\n    assert content, \'content in {} is {}\'.format(target_data_dir, content)\n    io_utils.copy_file(\n        os.path.join(chicago_taxi_pipeline_dir, \'taxi_utils.py\'),\n        os.path.join(self._home, \'taxi\', \'taxi_utils.py\'))\n\n    # Initialize CLI runner.\n    self.runner = click_testing.CliRunner()\n\n  def tearDown(self):\n    super(CliBeamEndToEndTest, self).tearDown()\n    if self._old_beam_home:\n      os.environ[\'BEAM_HOME\'] = self._old_beam_home\n    if self._old_home:\n      os.environ[\'HOME\'] = self._old_home\n\n  def _valid_create_and_check(self, pipeline_path, pipeline_name):\n    handler_pipeline_path = os.path.join(self._beam_home, pipeline_name)\n\n    # Create a pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'pipeline_args.json\')))\n    self.assertIn(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name),\n                  result.output)\n\n  def testPipelineCreate(self):\n    # Create a pipeline.\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_beam_1.py\')\n    pipeline_name = \'chicago_taxi_beam\'\n    self._valid_create_and_check(pipeline_path, pipeline_name)\n\n    # Test pipeline create when pipeline already exists.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(\'Pipeline ""{}"" already exists.\'.format(pipeline_name),\n                    result.output)\n\n  def testPipelineUpdate(self):\n    pipeline_name = \'chicago_taxi_beam\'\n    handler_pipeline_path = os.path.join(self._beam_home, pipeline_name)\n    pipeline_path_1 = os.path.join(self._testdata_dir,\n                                   \'test_pipeline_beam_1.py\')\n    # Try pipeline update when pipeline does not exist.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path_1\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name),\n                  result.output)\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n\n    # Now update an existing pipeline.\n    self._valid_create_and_check(pipeline_path_1, pipeline_name)\n    pipeline_path_2 = os.path.join(self._testdata_dir,\n                                   \'test_pipeline_beam_2.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path_2\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" updated successfully.\'.format(pipeline_name),\n                  result.output)\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'pipeline_args.json\')))\n\n  def testPipelineCompile(self):\n    # Invalid DSL path\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_flink.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Invalid pipeline path: {}\'.format(pipeline_path),\n                  result.output)\n\n    # Wrong Runner.\n    pipeline_path = os.path.join(self._testdata_dir,\n                                 \'test_pipeline_kubeflow_1.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'beam runner not found in dsl.\', result.output)\n\n    # Successful compilation.\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_beam_2.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Pipeline compiled successfully\', result.output)\n\n  def testPipelineDelete(self):\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_beam_1.py\')\n    pipeline_name = \'chicago_taxi_beam\'\n    handler_pipeline_path = os.path.join(self._beam_home, pipeline_name)\n\n    # Try deleting a non existent pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name),\n                  result.output)\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n\n    # Create a pipeline.\n    self._valid_create_and_check(pipeline_path, pipeline_name)\n\n    # Now delete the pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n    self.assertIn(\'Pipeline ""{}"" deleted successfully.\'.format(pipeline_name),\n                  result.output)\n\n  def testPipelineList(self):\n\n    # Try listing pipelines when there are none.\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'list\', \'--engine\', \'beam\'])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Listing all pipelines\', result.output)\n    self.assertIn(\'No pipelines to display.\', result.output)\n\n    # Create pipelines.\n    pipeline_name_1 = \'chicago_taxi_beam\'\n    pipeline_path_1 = os.path.join(self._testdata_dir,\n                                   \'test_pipeline_beam_1.py\')\n    self._valid_create_and_check(pipeline_path_1, pipeline_name_1)\n\n    pipeline_name_2 = \'chicago_taxi_beam_v2\'\n    pipeline_path_2 = os.path.join(self._testdata_dir,\n                                   \'test_pipeline_beam_3.py\')\n    self._valid_create_and_check(pipeline_path_2, pipeline_name_2)\n\n    # List pipelines.\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'list\', \'--engine\', \'beam\'])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Listing all pipelines\', result.output)\n    self.assertIn(pipeline_name_1, result.output)\n    self.assertIn(pipeline_name_2, result.output)\n\n  def testPipelineSchema(self):\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_beam_2.py\')\n    pipeline_name = \'chicago_taxi_beam\'\n\n    # Try getting schema without creating pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'schema\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Getting latest schema.\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name),\n                  result.output)\n\n    # Create a pipeline.\n    self._valid_create_and_check(pipeline_path, pipeline_name)\n\n    # Try getting schema without creating a pipeline run.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'schema\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Getting latest schema.\', result.output)\n    self.assertIn(\n        \'Create a run before inferring schema. If pipeline is already running, then wait for it to successfully finish.\',\n        result.output)\n\n    # Run pipeline.\n    self._valid_run_and_check(pipeline_name)\n\n    # Try inferring schema without SchemaGen component.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'schema\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Getting latest schema.\', result.output)\n    self.assertIn(\n        \'Either SchemaGen component does not exist or pipeline is still running. If pipeline is running, then wait for it to successfully finish.\',\n        result.output)\n\n    # Create a pipeline.\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_beam_3.py\')\n    pipeline_name = \'chicago_taxi_beam_v2\'\n    self._valid_create_and_check(pipeline_path, pipeline_name)\n\n    # Run pipeline\n    self._valid_run_and_check(pipeline_name)\n\n    # Infer Schema when pipeline runs for the first time.\n    schema_path = os.path.join(os.getcwd(), \'schema.pbtxt\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'schema\', \'--engine\', \'beam\', \'--pipeline_name\',\n        pipeline_name\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Getting latest schema.\', result.output)\n    self.assertTrue(tf.io.gfile.exists(schema_path))\n    self.assertIn(\'Path to schema: {}\'.format(schema_path), result.output)\n    self.assertIn(\n        \'*********SCHEMA FOR {}**********\'.format(pipeline_name.upper()),\n        result.output)\n\n  def _valid_run_and_check(self, pipeline_name):\n    result = self.runner.invoke(\n        cli_group,\n        [\'run\', \'create\', \'--engine\', \'beam\', \'--pipeline_name\', pipeline_name])\n    self.assertIn(\'CLI\', result.output)\n    self.assertNotIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name),\n                     result.output)\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(pipeline_name),\n                  result.output)\n\n  def testRunCreate(self):\n    # Create a pipeline first.\n    pipeline_name_1 = \'chicago_taxi_beam\'\n    pipeline_path_1 = os.path.join(self._testdata_dir,\n                                   \'test_pipeline_beam_2.py\')\n    self._valid_create_and_check(pipeline_path_1, pipeline_name_1)\n\n    # Now run a different pipeline\n    pipeline_name_2 = \'chicago_taxi_beam_v2\'\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'create\', \'--engine\', \'beam\', \'--pipeline_name\', pipeline_name_2\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(pipeline_name_2),\n                  result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name_2),\n                  result.output)\n\n    # Now run the pipeline\n    self._valid_run_and_check(pipeline_name_1)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/e2e/cli_common_e2e_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.tools.cli.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport locale\nimport os\n\nfrom click import testing as click_testing\nimport tensorflow as tf\n\nfrom tfx.tools.cli.cli_main import cli_group\n\n\nclass CliCommonEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(CliCommonEndToEndTest, self).setUp()\n\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n\n    self._home = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._original_home_value = os.environ.get(\'HOME\', \'\')\n    os.environ[\'HOME\'] = self._home\n    self._original_beam_home_value = os.environ.get(\'BEAM_HOME\', \'\')\n    os.environ[\'BEAM_HOME\'] = os.path.join(os.environ[\'HOME\'], \'beam\')\n    self._original_airflow_home_value = os.environ.get(\'AIRFLOW_HOME\', \'\')\n    os.environ[\'AIRFLOW_HOME\'] = os.path.join(os.environ[\'HOME\'], \'airflow\')\n    self._original_kubeflow_home_value = os.environ.get(\'KUBEFLOW_HOME\', \'\')\n    os.environ[\'KUBEFLOW_HOME\'] = os.path.join(os.environ[\'HOME\'], \'kubeflow\')\n\n    self.chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self.runner = click_testing.CliRunner()\n\n  def tearDown(self):\n    super(CliCommonEndToEndTest, self).tearDown()\n    os.environ[\'HOME\'] = self._original_home_value\n    os.environ[\'BEAM_HOME\'] = self._original_beam_home_value\n    os.environ[\'AIRFLOW_HOME\'] = self._original_airflow_home_value\n    os.environ[\'KUBEFLOW_HOME\'] = self._original_kubeflow_home_value\n\n  def testPipelineCreateUnsupportedEngine(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_beam_1.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'flink\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertIn(\'Engine flink is not supported.\', str(result.exception))\n\n  def testPipelineCreateIncorrectRunner(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_airflow_1.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'beam\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertIn(\'beam runner not found in dsl.\', result.output)\n\n  def testPipelineCreateInvalidPipelinePath(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'beam\',\n        \'--pipeline_path\', pipeline_path\n    ])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertIn(\'Invalid pipeline path: {}\'.format(pipeline_path),\n                  result.output)\n\n  def testMissingRequiredFlag(self):\n    pipeline_name_1 = \'chicago_taxi_simple\'\n\n    # Missing flag for pipeline create.\n    result = self.runner.invoke(cli_group,\n                                [\'pipeline\', \'create\', \'--engine\', \'beam\'])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Missing option\', result.output)\n    self.assertIn(\'--pipeline_path\', result.output)\n\n    # Missing flag for run create.\n    result = self.runner.invoke(cli_group,\n                                [\'run\', \'create\', \'--engine\', \'airflow\'])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Missing option\', result.output)\n    self.assertIn(\'--pipeline_name\', result.output)\n\n    # Missing flag for run status.\n    result = self.runner.invoke(\n        cli_group, [\'run\', \'status\', \'--pipeline_name\', pipeline_name_1])\n    self.assertIn(\'CLI\', result.output)\n    self.assertIn(\'Missing option\', result.output)\n    self.assertIn(\'--run_id\', result.output)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/e2e/cli_kubeflow_e2e_test.py,16,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Kubeflow tests for CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport codecs\nimport datetime\nimport json\nimport locale\nimport os\nimport random\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nfrom typing import Text, Tuple\n\nimport absl\nfrom click import testing as click_testing\nimport kfp\nimport kfp_server_api\nimport tensorflow as tf\n\nfrom google.cloud import storage\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.cli_main import cli_group\nfrom tfx.tools.cli.e2e import test_utils\n\n\nclass CliKubeflowEndToEndTest(tf.test.TestCase):\n\n  def _get_endpoint(self, config: Text) -> Text:\n    lines = config.decode(\'utf-8\').split(\'\\n\')\n    for line in lines:\n      if line.endswith(\'googleusercontent.com\'):\n        return line\n\n  def setUp(self):\n    super(CliKubeflowEndToEndTest, self).setUp()\n    random.seed(datetime.datetime.now())\n\n    # List of packages installed.\n    self._pip_list = str(subprocess.check_output([\'pip\', \'freeze\', \'--local\']))\n\n    # Check if Kubeflow is installed before running E2E tests.\n    if labels.KUBEFLOW_PACKAGE_NAME not in self._pip_list:\n      sys.exit(\'Kubeflow not installed.\')\n\n    # Change the encoding for Click since Python 3 is configured to use ASCII as\n    # encoding for the environment.\n    if codecs.lookup(locale.getpreferredencoding()).name == \'ascii\':\n      os.environ[\'LANG\'] = \'en_US.utf-8\'\n\n    # Initialize CLI runner.\n    self.runner = click_testing.CliRunner()\n\n    # Testdata path.\n    self._testdata_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n    self._testdata_dir_updated = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    tf.io.gfile.makedirs(self._testdata_dir_updated)\n\n    self._pipeline_name = (\'cli-kubeflow-e2e-test-\' +\n                           test_utils.generate_random_id())\n    absl.logging.info(\'Pipeline name is %s\' % self._pipeline_name)\n    self._pipeline_name_v2 = self._pipeline_name + \'_v2\'\n\n    orig_pipeline_path = os.path.join(self._testdata_dir,\n                                      \'test_pipeline_kubeflow_1.py\')\n    self._pipeline_path = os.path.join(self._testdata_dir_updated,\n                                       \'test_pipeline_kubeflow_1.py\')\n    self._pipeline_path_v2 = os.path.join(self._testdata_dir_updated,\n                                          \'test_pipeline_kubeflow_2.py\')\n\n    test_utils.copy_and_change_pipeline_name(orig_pipeline_path,\n                                             self._pipeline_path,\n                                             \'chicago_taxi_pipeline_kubeflow\',\n                                             self._pipeline_name)\n    self.assertTrue(tf.io.gfile.exists(self._pipeline_path))\n    test_utils.copy_and_change_pipeline_name(orig_pipeline_path,\n                                             self._pipeline_path_v2,\n                                             \'chicago_taxi_pipeline_kubeflow\',\n                                             self._pipeline_name_v2)\n    self.assertTrue(tf.io.gfile.exists(self._pipeline_path_v2))\n\n    # Endpoint URL\n    self._endpoint = self._get_endpoint(\n        subprocess.check_output(\n            \'kubectl describe configmap inverse-proxy-config -n kubeflow\'.split(\n                )))\n    absl.logging.info(\'ENDPOINT: \' + self._endpoint)\n\n    # Change home directories\n    self._olddir = os.getcwd()\n    self._old_kubeflow_home = os.environ.get(\'KUBEFLOW_HOME\')\n    os.environ[\'KUBEFLOW_HOME\'] = os.path.join(tempfile.mkdtemp(),\n                                               \'CLI_Kubeflow_Pipelines\')\n    self._kubeflow_home = os.environ[\'KUBEFLOW_HOME\']\n    tf.io.gfile.makedirs(self._kubeflow_home)\n    os.chdir(self._kubeflow_home)\n\n    self._handler_pipeline_path = os.path.join(self._kubeflow_home,\n                                               self._pipeline_name)\n    self._handler_pipeline_args_path = os.path.join(self._handler_pipeline_path,\n                                                    \'pipeline_args.json\')\n    self._pipeline_package_path = \'{}.tar.gz\'.format(self._pipeline_name)\n\n    try:\n      # Create a kfp client for cleanup after running commands.\n      self._client = kfp.Client(host=self._endpoint)\n    except kfp_server_api.rest.ApiException as err:\n      absl.logging.info(err)\n\n  def tearDown(self):\n    super(CliKubeflowEndToEndTest, self).tearDown()\n    self._cleanup_kfp_server()\n    if self._old_kubeflow_home:\n      os.environ[\'KUBEFLOW_HOME\'] = self._old_kubeflow_home\n    os.chdir(self._olddir)\n    shutil.rmtree(self._kubeflow_home)\n    absl.logging.info(\'Deleted all runs.\')\n\n  def _cleanup_kfp_server(self):\n    pipelines = tf.io.gfile.listdir(self._kubeflow_home)\n    for pipeline_name in pipelines:\n      if tf.io.gfile.isdir(pipeline_name):\n        self._delete_experiment(pipeline_name)\n        self._delete_pipeline(pipeline_name)\n        self._delete_pipeline_output(pipeline_name)\n        self._delete_pipeline_metadata(pipeline_name)\n\n  def _delete_pipeline(self, pipeline_name: Text):\n    pipeline_id, _ = self._get_pipeline_id_and_experiment_id(pipeline_name)\n    if self._client._pipelines_api.get_pipeline(pipeline_id):\n      self._client._pipelines_api.delete_pipeline(id=pipeline_id)\n      absl.logging.info(\'Deleted pipeline : {}\'.format(pipeline_name))\n\n  def _delete_experiment(self, pipeline_name: Text):\n    if self._client.get_experiment(experiment_name=pipeline_name):\n      experiment_id = self._client.get_experiment(\n          experiment_name=pipeline_name).id\n      self._delete_all_runs(experiment_id)\n      self._client._experiment_api.delete_experiment(experiment_id)\n      absl.logging.info(\'Deleted experiment : {}\'.format(pipeline_name))\n\n  def _get_pipeline_id_and_experiment_id(\n      self, pipeline_name: Text) -> Tuple[Text, Text]:\n    # Path to pipeline_args.json .\n    pipeline_args_path = os.path.join(self._kubeflow_home, pipeline_name,\n                                      \'pipeline_args.json\')\n    # Get pipeline_id and experiment_id from pipeline_args.json\n    with open(pipeline_args_path, \'r\') as f:\n      pipeline_args = json.load(f)\n    pipeline_id = pipeline_args[labels.PIPELINE_ID]\n    experiment_id = pipeline_args[labels.EXPERIMENT_ID]\n    return pipeline_id, experiment_id\n\n  def _delete_pipeline_output(self, pipeline_name: Text) -> None:\n    """"""Deletes output produced by the named pipeline.\n\n    Args:\n      pipeline_name: The name of the pipeline.\n    """"""\n    gcp_project_id = \'tfx-oss-testing\'\n    bucket_name = \'tfx-oss-testing-bucket\'\n    client = storage.Client(project=gcp_project_id)\n    bucket = client.get_bucket(bucket_name)\n    prefix = \'test_output/{}\'.format(pipeline_name)\n    absl.logging.info(\n        \'Deleting output under GCS bucket prefix: {}\'.format(prefix))\n    blobs = bucket.list_blobs(prefix=prefix)\n    bucket.delete_blobs(blobs)\n\n  def _get_mysql_pod_name(self) -> Text:\n    """"""Returns MySQL pod name in the cluster.""""""\n    pod_name = subprocess.check_output([\n        \'kubectl\',\n        \'-n\',\n        \'kubeflow\',\n        \'get\',\n        \'pods\',\n        \'-l\',\n        \'app=mysql\',\n        \'--no-headers\',\n        \'-o\',\n        \'custom-columns=:metadata.name\',\n    ]).decode(\'utf-8\').strip(\'\\n\')\n    absl.logging.info(\'MySQL pod name is: {}\'.format(pod_name))\n    return pod_name\n\n  def _delete_pipeline_metadata(self, pipeline_name: Text) -> None:\n    """"""Drops the database containing metadata produced by the pipeline.\n\n    Args:\n      pipeline_name: The name of the pipeline owning the database.\n    """"""\n    pod_name = self._get_mysql_pod_name()\n    valid_mysql_name = pipeline_name.replace(\'-\', \'_\')\n    # MySQL database name cannot exceed 64 characters.\n    db_name = \'mlmd_{}\'.format(valid_mysql_name[-59:])\n\n    command = [\n        \'kubectl\',\n        \'-n\',\n        \'kubeflow\',\n        \'exec\',\n        \'-it\',\n        pod_name,\n        \'--\',\n        \'mysql\',\n        \'--user\',\n        \'root\',\n        \'--execute\',\n        \'drop database if exists {};\'.format(db_name),\n    ]\n    absl.logging.info(\'Dropping MLMD DB with name: {}\'.format(db_name))\n    subprocess.run(command, check=True)\n\n  def _delete_all_runs(self, experiment_id: Text):\n    try:\n      # Get all runs related to the experiment_id.\n      response = self._client.list_runs(experiment_id=experiment_id)\n      if response and response.runs:\n        for run in response.runs:\n          self._client._run_api.delete_run(id=run.id)\n    except kfp_server_api.rest.ApiException as err:\n      absl.logging.info(err)\n\n  def _valid_create_and_check(self, pipeline_path: Text,\n                              pipeline_name: Text) -> None:\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        pipeline_path, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(tf.io.gfile.exists(self._pipeline_package_path))\n    self.assertTrue(tf.io.gfile.exists(self._handler_pipeline_args_path))\n    self.assertIn(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name),\n                  result.output)\n\n  def _run_pipeline_using_kfp_client(self, pipeline_name: Text):\n    try:\n      pipeline_id, experiment_id = self._get_pipeline_id_and_experiment_id(\n          pipeline_name)\n      run = self._client.run_pipeline(\n          experiment_id=experiment_id,\n          job_name=pipeline_name,\n          pipeline_id=pipeline_id)\n\n      return run\n\n    except kfp_server_api.rest.ApiException as err:\n      absl.logging.info(err)\n\n  def testPipelineCreate(self):\n    # Create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Test pipeline create when pipeline already exists.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        self._pipeline_path, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Creating pipeline\', result.output)\n    self.assertTrue(\'Pipeline ""{}"" already exists.\'.format(self._pipeline_name),\n                    result.output)\n\n  def testPipelineUpdate(self):\n    # Try pipeline update when pipeline does not exist.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        self._pipeline_path, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n    self.assertFalse(tf.io.gfile.exists(self._handler_pipeline_path))\n\n    # Now update an existing pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'update\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        self._pipeline_path, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Updating pipeline\', result.output)\n    self.assertIn(\n        \'Pipeline ""{}"" updated successfully.\'.format(self._pipeline_name),\n        result.output)\n    self.assertTrue(tf.io.gfile.exists(self._handler_pipeline_args_path))\n\n  def testPipelineCompile(self):\n    # Invalid DSL path\n    pipeline_path = os.path.join(self._testdata_dir, \'test_pipeline_flink.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Invalid pipeline path: {}\'.format(pipeline_path),\n                  result.output)\n\n    # Wrong Runner.\n    pipeline_path = os.path.join(self._testdata_dir,\n                                 \'test_pipeline_airflow_1.py\')\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'kubeflow runner not found in dsl.\', result.output)\n\n    # Successful compilation.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'compile\', \'--engine\', \'kubeflow\', \'--pipeline_path\',\n        self._pipeline_path\n    ])\n    self.assertIn(\'Compiling pipeline\', result.output)\n    self.assertIn(\'Pipeline compiled successfully\', result.output)\n\n  def testPipelineDelete(self):\n    # Try deleting a non existent pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n    self.assertFalse(tf.io.gfile.exists(self._handler_pipeline_path))\n\n    # Create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Now delete the pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'delete\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Deleting pipeline\', result.output)\n    self.assertFalse(tf.io.gfile.exists(self._handler_pipeline_path))\n    self.assertIn(\n        \'Pipeline {} deleted successfully.\'.format(self._pipeline_name),\n        result.output)\n\n  def testPipelineList(self):\n    # Create pipelines.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n    self._valid_create_and_check(self._pipeline_path_v2, self._pipeline_name_v2)\n\n    # List pipelines.\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'list\', \'--engine\', \'kubeflow\', \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Listing all pipelines\', result.output)\n    self.assertIn(self._pipeline_name, result.output)\n    self.assertIn(self._pipeline_name_v2, result.output)\n\n  def testPipelineCreateAutoDetect(self):\n    result = self.runner.invoke(cli_group, [\n        \'pipeline\', \'create\', \'--engine\', \'auto\', \'--pipeline_path\',\n        self._pipeline_path, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Creating pipeline\', result.output)\n    if labels.AIRFLOW_PACKAGE_NAME in self._pip_list and labels.KUBEFLOW_PACKAGE_NAME in self._pip_list:\n      self.assertIn(\n          \'Multiple orchestrators found. Choose one using --engine flag.\',\n          result.output)\n    else:\n      self.assertTrue(tf.io.gfile.exists(self._pipeline_package_path))\n      self.assertTrue(tf.io.gfile.exists(self._handler_pipeline_args_path))\n      self.assertIn(\n          \'Pipeline ""{}"" created successfully.\'.format(self._pipeline_name),\n          result.output)\n\n  def testRunCreate(self):\n    # Try running a non-existent pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'create\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(self._pipeline_name),\n                  result.output)\n    self.assertIn(\'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n                  result.output)\n\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'create\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint\n    ])\n\n    self.assertIn(\'Creating a run for pipeline: {}\'.format(self._pipeline_name),\n                  result.output)\n    self.assertNotIn(\n        \'Pipeline ""{}"" does not exist.\'.format(self._pipeline_name),\n        result.output)\n    self.assertIn(\'Run created for pipeline: {}\'.format(self._pipeline_name),\n                  result.output)\n\n  def testRunDelete(self):\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline using kfp client to get run_id.\n    run = self._run_pipeline_using_kfp_client(self._pipeline_name)\n\n    # Delete run.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'delete\', \'--engine\', \'kubeflow\', \'--endpoint\', self._endpoint,\n        \'--run_id\', run.id\n    ])\n    self.assertIn(\'Deleting run.\', result.output)\n    self.assertIn(\'Run deleted.\', result.output)\n\n  def testRunTerminate(self):\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline using kfp client to get run_id.\n    run = self._run_pipeline_using_kfp_client(self._pipeline_name)\n\n    # Delete run.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'terminate\', \'--engine\', \'kubeflow\', \'--endpoint\',\n        self._endpoint, \'--run_id\', run.id\n    ])\n    self.assertIn(\'Terminating run.\', result.output)\n    self.assertIn(\'Run terminated.\', result.output)\n\n  def testRunStatus(self):\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline using kfp client to get run_id.\n    run = self._run_pipeline_using_kfp_client(self._pipeline_name)\n\n    # Delete run.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'status\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint, \'--run_id\', run.id\n    ])\n    self.assertIn(\'Retrieving run status.\', result.output)\n    self.assertIn(str(run.id), result.output)\n    self.assertIn(self._pipeline_name, result.output)\n\n  def testRunList(self):\n    # Now create a pipeline.\n    self._valid_create_and_check(self._pipeline_path, self._pipeline_name)\n\n    # Run pipeline using kfp client to get run_id.\n    run_1 = self._run_pipeline_using_kfp_client(self._pipeline_name)\n    run_2 = self._run_pipeline_using_kfp_client(self._pipeline_name)\n\n    # List runs.\n    result = self.runner.invoke(cli_group, [\n        \'run\', \'list\', \'--engine\', \'kubeflow\', \'--pipeline_name\',\n        self._pipeline_name, \'--endpoint\', self._endpoint\n    ])\n    self.assertIn(\n        \'Listing all runs of pipeline: {}\'.format(self._pipeline_name),\n        result.output)\n    self.assertIn(str(run_1.id), result.output)\n    self.assertIn(str(run_2.id), result.output)\n    self.assertIn(self._pipeline_name, result.output)\n\n\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  tf.test.main()\n'"
tfx/tools/cli/e2e/test_utils.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common utility for testing CLI in Kubeflow.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport random\nimport string\n\nfrom typing import List, Text\n\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components.base.base_component import BaseComponent\nfrom tfx.utils import dsl_utils\n\n\ndef create_e2e_components(csv_input_location: Text,) -> List[BaseComponent]:\n  """"""Creates components for a simple Chicago Taxi TFX pipeline for testing.\n\n     Because we don\'t need to run whole pipeline, we will make a very short\n     toy pipeline.\n\n  Args:\n    csv_input_location: The location of the input data directory.\n\n  Returns:\n    A list of TFX components that constitutes an end-to-end test pipeline.\n  """"""\n  examples = dsl_utils.external_input(csv_input_location)\n\n  example_gen = CsvExampleGen(input=examples)\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  return [example_gen, statistics_gen, schema_gen]\n\n\ndef generate_random_id():\n  """"""Generate a random id string which has a timestamp prefix.""""""\n  return datetime.datetime.now().strftime(\'%s\') + \'\'.join([\n      random.choice(string.ascii_lowercase + string.digits) for _ in range(10)\n  ])\n\n\ndef copy_and_change_pipeline_name(orig_path: Text, new_path: Text,\n                                  origin_pipeline_name: Text,\n                                  new_pipeline_name: Text) -> None:\n  """"""Copy pipeline file to new path with pipeline name changed.""""""\n  contents = file_io.read_file_to_string(orig_path)\n  assert contents.count(\n      origin_pipeline_name) == 1, \'DSL file can only contain one pipeline name\'\n  contents = contents.replace(origin_pipeline_name, new_pipeline_name)\n  file_io.write_string_to_file(new_path, contents)\n'"
tfx/tools/cli/handler/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/tools/cli/handler/airflow_handler.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Handler for Airflow.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport subprocess\nimport sys\nfrom typing import Any, Dict, Text\n\nimport click\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import base_handler\nfrom tfx.utils import io_utils\n\n\nclass AirflowHandler(base_handler.BaseHandler):\n  """"""Helper methods for Airflow Handler.""""""\n\n  def __init__(self, flags_dict):\n    super(AirflowHandler, self).__init__(flags_dict)\n    self._handler_home_dir = os.path.join(self._handler_home_dir, \'dags\', \'\')\n\n  def create_pipeline(self, overwrite: bool = False) -> None:\n    """"""Creates pipeline in Airflow.\n\n    Args:\n      overwrite: Set as True to update pipeline.\n    """"""\n    # Compile pipeline to check if pipeline_args are extracted successfully.\n    pipeline_args = self.compile_pipeline()\n\n    pipeline_name = pipeline_args[labels.PIPELINE_NAME]\n\n    self._check_pipeline_existence(pipeline_name, required=overwrite)\n\n    self._save_pipeline(pipeline_args)\n\n    if overwrite:\n      click.echo(\'Pipeline ""{}"" updated successfully.\'.format(pipeline_name))\n    else:\n      click.echo(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name))\n\n  def update_pipeline(self) -> None:\n    """"""Updates pipeline in Airflow.""""""\n    # Set overwrite as True to update the pipeline.\n    self.create_pipeline(overwrite=True)\n\n  def list_pipelines(self) -> None:\n    """"""List all the pipelines in the environment.""""""\n    if not tf.io.gfile.exists(self._handler_home_dir):\n      click.echo(\'No pipelines to display.\')\n      return\n\n    pipelines_list = tf.io.gfile.listdir(self._handler_home_dir)\n\n    # Print every pipeline name in a new line.\n    click.echo(\'-\' * 30)\n    click.echo(\'\\n\'.join(pipelines_list))\n    click.echo(\'-\' * 30)\n\n  def delete_pipeline(self) -> None:\n    """"""Delete pipeline in Airflow.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Path to pipeline folder.\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name,\n                                         \'\')\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Delete pipeline folder.\n    io_utils.delete_dir(handler_pipeline_path)\n    click.echo(\'Pipeline ""{}"" deleted successfully.\'.format(pipeline_name))\n\n  def compile_pipeline(self) -> Dict[Text, Any]:\n    """"""Compiles pipeline in Airflow.\n\n    Returns:\n      A python dictionary with pipeline details extracted from DSL.\n    """"""\n    self._check_pipeline_dsl_path()\n    self._check_dsl_runner()\n    pipeline_args = self._extract_pipeline_args()\n    if not pipeline_args:\n      sys.exit(\'Unable to compile pipeline. Check your pipeline dsl.\')\n    click.echo(\'Pipeline compiled successfully.\')\n    return pipeline_args\n\n  def create_run(self) -> None:\n    """"""Trigger DAG in Airflow.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Unpause DAG.\n    self._subprocess_call([\'airflow\', \'unpause\', pipeline_name])\n\n    # Trigger DAG.\n    self._subprocess_call([\'airflow\', \'trigger_dag\', pipeline_name])\n\n    click.echo(\'Run created for pipeline: \' + pipeline_name)\n\n  def delete_run(self) -> None:\n    """"""Deletes a run in Airflow.""""""\n    click.echo(\'Not supported for Airflow.\')\n\n  def terminate_run(self) -> None:\n    """"""Stops a run in Airflow.""""""\n    click.echo(\'Not supported for Airflow.\')\n\n  def list_runs(self) -> None:\n    """"""Lists all runs of a pipeline in Airflow.""""""\n    # Check if pipeline exists.\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n    self._check_pipeline_existence(pipeline_name)\n\n    # Get status of all DAG runs.\n    dag_runs_list = str(\n        subprocess.check_output([\'airflow\', \'list_dag_runs\', pipeline_name]))\n\n    # No runs to display.\n    if \'No dag runs for {}\'.format(pipeline_name) in dag_runs_list:\n      sys.exit(\'No pipeline runs for {}\'.format(pipeline_name))\n\n    self._subprocess_call([\'airflow\', \'list_dag_runs\', pipeline_name])\n\n  def get_run(self) -> None:\n    """"""Checks run status in Airflow.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Get status of all DAG runs.\n    dag_runs_list = str(\n        subprocess.check_output([\'airflow\', \'list_dag_runs\', pipeline_name]))\n\n    lines = dag_runs_list.split(\'\\\\n\')\n    for line in lines:\n      # The tokens are id, run_id, state, execution_date, state_date\n      tokens = line.split(\'|\')\n      if self.flags_dict[labels.RUN_ID] in line:\n        click.echo(\'run_id :\' + tokens[1])\n        click.echo(\'state :\' + tokens[2])\n        break\n\n  def _save_pipeline(self, pipeline_args: Dict[Text, Any]) -> None:\n    """"""Creates/updates pipeline folder in the handler directory.\n\n    Args:\n      pipeline_args: Pipeline details obtained from DSL.\n    """"""\n    # Path to pipeline folder in Airflow.\n    handler_pipeline_path = os.path.join(self._handler_home_dir,\n                                         pipeline_args[labels.PIPELINE_NAME],\n                                         \'\')\n\n    # If updating pipeline, first delete pipeline directory.\n    if tf.io.gfile.exists(handler_pipeline_path):\n      io_utils.delete_dir(handler_pipeline_path)\n\n    # Dump pipeline_args to handler pipeline folder as json.\n    tf.io.gfile.makedirs(handler_pipeline_path)\n    with open(os.path.join(\n        handler_pipeline_path, \'pipeline_args.json\'), \'w\') as f:\n      json.dump(pipeline_args, f)\n\n    # Copy dsl to pipeline folder\n    pipeline_dsl_path = self.flags_dict[labels.PIPELINE_DSL_PATH]\n    io_utils.copy_file(\n        pipeline_dsl_path,\n        os.path.join(handler_pipeline_path,\n                     os.path.basename(pipeline_dsl_path)))\n'"
tfx/tools/cli/handler/airflow_handler_test.py,18,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.handler.airflow_handler.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport sys\nimport click\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import airflow_handler\nfrom tfx.utils import io_utils\n\n_testdata_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n\n\ndef _MockSubprocess(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a json file.\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_root = os.path.join(os.environ[\'HOME\'], \'tfx\', \'pipelines\')\n  pipeline_args = {\n      \'pipeline_name\': \'chicago_taxi_simple\',\n      \'pipeline_root\': pipeline_root\n  }\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n  return 0\n\n\ndef _MockSubprocess2(cmd, env=None):  # pylint: disable=invalid-name, unused-argument\n  click.echo(cmd)\n  return 0\n\n\ndef _MockSubprocess3(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a json file.\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_args = {}\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n  return 0\n\n\ndef _MockSubprocess4(cmd):  # pylint: disable=invalid-name, unused-argument\n  list_dags_output_path = os.path.join(_testdata_dir,\n                                       \'test_airflow_list_dags_output.txt\')\n  with open(list_dags_output_path, \'rb\') as f:\n    list_dags_output = f.read()\n  return list_dags_output\n\n\nclass AirflowHandlerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(AirflowHandlerTest, self).setUp()\n    self._tmp_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\',\n                                   self.get_temp_dir())\n    self._home = os.path.join(self._tmp_dir, self._testMethodName)\n    self._olddir = os.getcwd()\n    os.chdir(self._tmp_dir)\n    self._original_home_value = os.environ.get(\'HOME\', \'\')\n    os.environ[\'HOME\'] = self._home\n    self._original_airflow_home_value = os.environ.get(\'AIRFLOW_HOME\', \'\')\n    os.environ[\'AIRFLOW_HOME\'] = os.path.join(os.environ[\'HOME\'], \'airflow\')\n\n    # Flags for handler.\n    self.engine = \'airflow\'\n    self.pipeline_path = os.path.join(_testdata_dir,\n                                      \'test_pipeline_airflow_1.py\')\n    self.pipeline_root = os.path.join(self._home, \'tfx\', \'pipelines\')\n    self.pipeline_name = \'chicago_taxi_simple\'\n    self.run_id = \'manual__2019-07-19T19:56:02+00:00\'\n\n    # Pipeline args for mocking subprocess\n    self.pipeline_args = {\'pipeline_name\': \'chicago_taxi_simple\'}\n\n  def tearDown(self):\n    super(AirflowHandlerTest, self).tearDown()\n    os.environ[\'HOME\'] = self._original_home_value\n    os.environ[\'AIRFLOW_HOME\'] = self._original_airflow_home_value\n    os.chdir(self._olddir)\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testSavePipeline(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    pipeline_args = handler._extract_pipeline_args()\n    handler._save_pipeline(pipeline_args)\n    self.assertTrue(tf.io.gfile.exists(os.path.join(\n        handler._handler_home_dir,\n        self.pipeline_args[labels.PIPELINE_NAME])))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipeline(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'test_pipeline_airflow_1.py\')))\n    self.assertTrue(tf.io.gfile.exists(os.path.join(\n        handler_pipeline_path, \'pipeline_args.json\')))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipelineExistentPipeline(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n    # Run create_pipeline again to test.\n    with self.assertRaises(SystemExit) as err:\n      handler.create_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" already exists.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipeline(self):\n    # First create pipeline with test_pipeline.py\n    pipeline_path_1 = os.path.join(_testdata_dir, \'test_pipeline_airflow_1.py\')\n    flags_dict_1 = {labels.ENGINE_FLAG: self.engine,\n                    labels.PIPELINE_DSL_PATH: pipeline_path_1}\n    handler = airflow_handler.AirflowHandler(flags_dict_1)\n    handler.create_pipeline()\n\n    # Update test_pipeline and run update_pipeline\n    pipeline_path_2 = os.path.join(self._tmp_dir, \'test_pipeline_airflow_2.py\')\n    io_utils.copy_file(pipeline_path_1, pipeline_path_2)\n    flags_dict_2 = {labels.ENGINE_FLAG: self.engine,\n                    labels.PIPELINE_DSL_PATH: pipeline_path_2}\n    handler = airflow_handler.AirflowHandler(flags_dict_2)\n    handler.update_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'test_pipeline_airflow_2.py\')))\n    self.assertTrue(tf.io.gfile.exists(os.path.join(\n        handler_pipeline_path, \'pipeline_args.json\')))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipelineNoPipeline(self):\n    # Update pipeline without craeting one.\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.update_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipeline(self):\n    # First create a pipeline.\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    # Now delete the pipeline created aand check if pipeline folder is deleted.\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_NAME: self.pipeline_name}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.delete_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipelineNonExistentPipeline(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_NAME: self.pipeline_name}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.delete_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  def testListPipelinesNonEmpty(self):\n    # First create two pipelines in the dags folder.\n    handler_pipeline_path_1 = os.path.join(os.environ[\'AIRFLOW_HOME\'],\n                                           \'dags\',\n                                           \'pipeline_1\')\n    handler_pipeline_path_2 = os.path.join(os.environ[\'AIRFLOW_HOME\'],\n                                           \'dags\',\n                                           \'pipeline_2\')\n    tf.io.gfile.makedirs(handler_pipeline_path_1)\n    tf.io.gfile.makedirs(handler_pipeline_path_2)\n\n    # Now, list the pipelines\n    flags_dict = {labels.ENGINE_FLAG: self.engine}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_pipelines()\n    self.assertIn(\'pipeline_1\', captured.contents())\n    self.assertIn(\'pipeline_2\', captured.contents())\n\n  def testListPipelinesEmpty(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_pipelines()\n    self.assertIn(\'No pipelines to display.\', captured.contents())\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCompilePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.compile_pipeline()\n    self.assertIn(\'Pipeline compiled successfully\', captured.contents())\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess3)\n  def testCompilePipelineNoPipelineArgs(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.compile_pipeline()\n    self.assertEqual(\n        str(err.exception),\n        \'Unable to compile pipeline. Check your pipeline dsl.\')\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaNoPipelineRoot(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Create a run before inferring schema. If pipeline is already running, then wait for it to successfully finish.\'\n    )\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaNoSchemaGenOutput(self):\n    # First create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    tf.io.gfile.makedirs(self.pipeline_root)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Either SchemaGen component does not exist or pipeline is still running. If pipeline is running, then wait for it to successfully finish.\'\n    )\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaSuccessfulRun(self):\n    # First create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    # Create fake schema in pipeline root.\n    schema_path = os.path.join(self.pipeline_root, \'SchemaGen\', \'schema\', \'3\')\n    tf.io.gfile.makedirs(schema_path)\n    with open(os.path.join(schema_path, \'schema.pbtxt\'), \'w\') as f:\n      f.write(\'SCHEMA\')\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.get_schema()\n      curr_dir_path = os.path.join(os.getcwd(), \'schema.pbtxt\')\n      self.assertIn(\'Path to schema: {}\'.format(curr_dir_path),\n                    captured.contents())\n      self.assertIn(\n          \'*********SCHEMA FOR {}**********\'.format(self.pipeline_name.upper()),\n          captured.contents())\n      self.assertTrue(tf.io.gfile.exists(curr_dir_path))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess2)\n  def testCreateRun(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'AIRFLOW_HOME\'], \'dags\',\n        self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_NAME: self.pipeline_name}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.create_run()\n    self.assertIn(""[\'airflow\', \'unpause\', \'"" + self.pipeline_name + ""\']"",\n                  captured.contents())\n    self.assertIn(""[\'airflow\', \'trigger_dag\', \'"" + self.pipeline_name + ""\']"",\n                  captured.contents())\n\n  def testCreateRunNoPipeline(self):\n    # Run pipeline without creating one.\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_NAME: self.pipeline_name}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.create_run()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess2)\n  @mock.patch(\'subprocess.check_output\', _MockSubprocess2)\n  def testListRuns(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'AIRFLOW_HOME\'], \'dags\',\n        self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_runs()\n    self.assertIn(""[\'airflow\', \'list_dag_runs\', \'"" + self.pipeline_name + ""\']"",\n                  captured.contents())\n\n  def testListRunsWrongPipeline(self):\n    # Run pipeline without creating one.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: \'chicago_taxi\'\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.list_runs()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.check_output\', _MockSubprocess4)\n  def testGetRun(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'AIRFLOW_HOME\'], \'dags\',\n        self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.RUN_ID: self.run_id,\n        labels.PIPELINE_NAME: self.pipeline_name\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.get_run()\n    self.assertIn(\'run_id : \' + self.run_id, captured.contents())\n    self.assertIn(\'state : running\', captured.contents())\n\n  def testGetRunWrongPipeline(self):\n    # Run pipeline without creating one.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.RUN_ID: self.run_id,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_run()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess2)\n  def testDeleteRun(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'AIRFLOW_HOME\'], \'dags\',\n        self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.delete_run()\n    self.assertIn(\'Not supported for Airflow.\', captured.contents())\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess2)\n  def testTerminateRun(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'AIRFLOW_HOME\'], \'dags\',\n        self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = airflow_handler.AirflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.terminate_run()\n    self.assertIn(\'Not supported for Airflow.\', captured.contents())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/handler/base_handler.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base handler class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport json\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom typing import Any, Dict, List, Text\n\nimport click\nfrom six import with_metaclass\nimport tensorflow as tf\n\nfrom tfx.components.base import base_driver\nfrom tfx.tools.cli import labels\nfrom tfx.utils import io_utils\n\n\nclass BaseHandler(with_metaclass(abc.ABCMeta, object)):\n  """"""Base Handler for CLI.\n\n  Attributes:\n    flags_dict: A dictionary with flags provided in a command.\n  """"""\n\n  def __init__(self, flags_dict: Dict[Text, Any]):\n    self.flags_dict = flags_dict\n    self._handler_home_dir = self._get_handler_home()\n\n  @abc.abstractmethod\n  def create_pipeline(self) -> None:\n    """"""Creates pipeline for the handler.""""""\n    pass\n\n  @abc.abstractmethod\n  def update_pipeline(self) -> None:\n    """"""Updates pipeline for the handler.""""""\n    pass\n\n  @abc.abstractmethod\n  def list_pipelines(self) -> None:\n    """"""List all the pipelines in the environment.""""""\n    pass\n\n  @abc.abstractmethod\n  def delete_pipeline(self) -> None:\n    """"""Deletes pipeline for the handler.""""""\n    pass\n\n  @abc.abstractmethod\n  def compile_pipeline(self) -> None:\n    """"""Compiles pipeline for the handler.""""""\n    pass\n\n  @abc.abstractmethod\n  def create_run(self) -> None:\n    """"""Runs a pipeline for the handler.""""""\n    pass\n\n  @abc.abstractmethod\n  def delete_run(self) -> None:\n    """"""Deletes a run.""""""\n    pass\n\n  @abc.abstractmethod\n  def terminate_run(self) -> None:\n    """"""Stops a run.""""""\n    pass\n\n  @abc.abstractmethod\n  def list_runs(self) -> None:\n    """"""Lists all runs of a pipeline.""""""\n    pass\n\n  @abc.abstractmethod\n  def get_run(self) -> None:\n    """"""Checks run status.""""""\n    pass\n\n  def _check_pipeline_dsl_path(self) -> None:\n    """"""Check if pipeline dsl path exists.""""""\n    pipeline_dsl_path = self.flags_dict[labels.PIPELINE_DSL_PATH]\n    if not tf.io.gfile.exists(pipeline_dsl_path):\n      sys.exit(\'Invalid pipeline path: {}\'.format(pipeline_dsl_path))\n\n  def _check_dsl_runner(self) -> None:\n    """"""Check if runner in dsl is same as engine flag.""""""\n    engine_flag = self.flags_dict[labels.ENGINE_FLAG]\n    with open(self.flags_dict[labels.PIPELINE_DSL_PATH], \'r\') as f:\n      dsl_contents = f.read()\n      runner_names = {\n          labels.AIRFLOW_ENGINE: \'AirflowDagRunner\',\n          labels.KUBEFLOW_ENGINE: \'KubeflowDagRunner\',\n          labels.BEAM_ENGINE: \'BeamDagRunner\',\n      }\n      if runner_names[engine_flag] not in dsl_contents:\n        sys.exit(\'{} runner not found in dsl.\'.format(engine_flag))\n\n  def _extract_pipeline_args(self) -> Dict[Text, Any]:\n    """"""Get pipeline args from the DSL.\n\n    Returns:\n      Python dictionary with pipeline details extracted from DSL.\n    """"""\n    pipeline_dsl_path = self.flags_dict[labels.PIPELINE_DSL_PATH]\n    if os.path.isdir(pipeline_dsl_path):\n      sys.exit(\'Provide dsl file path.\')\n\n    # Create an environment for subprocess.\n    temp_env = os.environ.copy()\n\n    # Create temp file to store pipeline_args from pipeline dsl.\n    temp_file = tempfile.mkstemp(prefix=\'cli_tmp_\', suffix=\'_pipeline_args\')[1]\n\n    # Store temp_file path in temp_env.\n    temp_env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH] = temp_file\n\n    # Run dsl with mock environment to store pipeline args in temp_file.\n    self._subprocess_call([sys.executable, pipeline_dsl_path], env=temp_env)\n    if os.stat(temp_file).st_size != 0:\n      # Load pipeline_args from temp_file for TFX pipelines\n      with open(temp_file, \'r\') as f:\n        pipeline_args = json.load(f)\n    else:\n      # For non-TFX pipelines, extract pipeline name from the dsl filename.\n      pipeline_args = {\n          labels.PIPELINE_NAME:\n              os.path.basename(pipeline_dsl_path).split(\'.\')[0]\n      }\n\n    # Delete temp file\n    io_utils.delete_dir(temp_file)\n\n    return pipeline_args\n\n  def _get_handler_home(self) -> Text:\n    """"""Sets handler home.\n\n    Returns:\n      Path to handler home directory.\n    """"""\n    engine_flag = self.flags_dict[labels.ENGINE_FLAG]\n    handler_home_dir = engine_flag.upper() + \'_HOME\'\n    if handler_home_dir in os.environ:\n      return os.environ[handler_home_dir]\n    return os.path.join(os.environ[\'HOME\'], engine_flag, \'\')\n\n  def _subprocess_call(self,\n                       command: List[Text],\n                       env: Dict[Text, Any] = None) -> None:\n    return_code = subprocess.call(command, env=env)\n    if return_code != 0:\n      sys.exit(\'Error while running ""{}"" \'.format(\' \'.join(command)))\n\n  def _check_pipeline_existence(self,\n                                pipeline_name: Text,\n                                required: bool = True) -> None:\n    """"""Check if pipeline folder exists and if not, exit system.\n\n    Args:\n      pipeline_name: Name of the pipeline.\n      required: Set it as True if pipeline needs to exist else set it to False.\n    """"""\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name,\n                                         \'\')\n    # Check if pipeline folder exists.\n    exists = tf.io.gfile.exists(handler_pipeline_path)\n    if required and not exists:\n      sys.exit(\'Pipeline ""{}"" does not exist.\'.format(pipeline_name))\n    elif not required and exists:\n      sys.exit(\'Pipeline ""{}"" already exists.\'.format(pipeline_name))\n\n  def get_schema(self):\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Path to pipeline args.\n    pipeline_args_path = os.path.join(self._handler_home_dir,\n                                      self.flags_dict[labels.PIPELINE_NAME],\n                                      \'pipeline_args.json\')\n\n    # Get pipeline_root.\n    with open(pipeline_args_path, \'r\') as f:\n      pipeline_args = json.load(f)\n\n    # Check if pipeline root created. If not, it means that the user has not\n    # created a run yet or the pipeline is still running for the first time.\n    pipeline_root = pipeline_args[labels.PIPELINE_ROOT]\n    if not tf.io.gfile.exists(pipeline_root):\n      sys.exit(\n          \'Create a run before inferring schema. If pipeline is already running, then wait for it to successfully finish.\'\n      )\n\n    # If pipeline_root exists, then check if SchemaGen output exists.\n    components = tf.io.gfile.listdir(pipeline_root)\n    if \'SchemaGen\' not in components:\n      sys.exit(\n          \'Either SchemaGen component does not exist or pipeline is still running. If pipeline is running, then wait for it to successfully finish.\'\n      )\n\n    # Get the latest SchemaGen output.\n    component_output_dir = os.path.join(pipeline_root, \'SchemaGen\')\n    schema1_uri = base_driver._generate_output_uri(  # pylint: disable=protected-access\n        component_output_dir, \'schema\', 1)\n    schema_dir = os.path.join(os.path.dirname(schema1_uri), \'\')\n    schemagen_outputs = tf.io.gfile.listdir(schema_dir)\n    latest_schema_folder = max(schemagen_outputs, key=int)\n\n    # Copy schema to current dir.\n    latest_schema_uri = base_driver._generate_output_uri(  # pylint: disable=protected-access\n        component_output_dir, \'schema\', latest_schema_folder)\n    latest_schema_path = os.path.join(latest_schema_uri, \'schema.pbtxt\')\n    curr_dir_path = os.path.join(os.getcwd(), \'schema.pbtxt\')\n    io_utils.copy_file(latest_schema_path, curr_dir_path, overwrite=True)\n\n    # Print schema and path to schema\n    click.echo(\'Path to schema: {}\'.format(curr_dir_path))\n    click.echo(\'*********SCHEMA FOR {}**********\'.format(pipeline_name.upper()))\n    with open(curr_dir_path, \'r\') as f:\n      click.echo(f.read())\n'"
tfx/tools/cli/handler/base_handler_test.py,3,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.handler.base_handler.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport mock\n\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import base_handler\n\n\nclass FakeHandler(base_handler.BaseHandler):\n\n  def create_pipeline(self) -> None:\n    pass\n\n  def update_pipeline(self) -> None:\n    pass\n\n  def list_pipelines(self) -> None:\n    pass\n\n  def delete_pipeline(self) -> None:\n    pass\n\n  def compile_pipeline(self) -> None:\n    pass\n\n  def get_schema(self) -> None:\n    pass\n\n  def create_run(self) -> None:\n    pass\n\n  def delete_run(self) -> None:\n    pass\n\n  def terminate_run(self) -> None:\n    pass\n\n  def list_runs(self) -> None:\n    pass\n\n  def get_run(self) -> None:\n    pass\n\n\ndef _MockSubprocess(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a pickle file\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_args = {\'pipeline_name\': \'pipeline_test_name\'}\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n  return 0\n\n\nclass BaseHandlerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(BaseHandlerTest, self).setUp()\n    self.engine = \'airflow\'\n    self.chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n    self.pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                      \'test_pipeline_airflow_1.py\')\n\n  def testCheckPipelineDslPathInvalid(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: \'taxi_pipeline.py\'}\n    handler = FakeHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler._check_pipeline_dsl_path()\n    self.assertEqual(str(err.exception), \'Invalid pipeline path: {}\'\n                     .format(flags_dict[labels.PIPELINE_DSL_PATH]))\n\n  def testCheckDslRunner(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine,\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = FakeHandler(flags_dict)\n    handler._check_dsl_runner()\n\n  def testCheckDslRunner_WrongEngine(self):\n    flags_dict = {labels.ENGINE_FLAG: \'kubeflow\',\n                  labels.PIPELINE_DSL_PATH: self.pipeline_path}\n    handler = FakeHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler._check_dsl_runner()\n    self.assertEqual(str(err.exception),\n                     \'{} runner not found in dsl.\'\n                     .format(flags_dict[labels.ENGINE_FLAG]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testExtractPipelineArgs(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: \'engine\',\n        labels.PIPELINE_DSL_PATH: \'path_to_pipeline_dsl\'\n    }\n    handler = FakeHandler(flags_dict)\n    pipeline_args = handler._extract_pipeline_args()\n    self.assertEqual(pipeline_args, {\'pipeline_name\': \'pipeline_test_name\'})\n\n  def testGetHandlerHome(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: \'engine\',\n        labels.PIPELINE_DSL_PATH: \'path_to_pipeline_dsl\'\n    }\n    handler = FakeHandler(flags_dict)\n    self.assertEqual(\n        os.path.join(os.environ[\'HOME\'], \'engine\', \'\'),\n        handler._get_handler_home())\n\n  def testCheckDslRunnerAirflow(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_airflow_1.py\')\n    flags_dict = {\n        labels.ENGINE_FLAG: \'airflow\',\n        labels.PIPELINE_DSL_PATH: pipeline_path\n    }\n    handler = FakeHandler(flags_dict)\n    self.assertIsNone(handler._check_dsl_runner())\n\n  def testCheckDslRunnerKubeflow(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_kubeflow_1.py\')\n    flags_dict = {\n        labels.ENGINE_FLAG: \'kubeflow\',\n        labels.PIPELINE_DSL_PATH: pipeline_path\n    }\n    handler = FakeHandler(flags_dict)\n    self.assertIsNone(handler._check_dsl_runner())\n\n  def testCheckDslRunnerBeam(self):\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_beam_1.py\')\n    flags_dict = {\n        labels.ENGINE_FLAG: \'beam\',\n        labels.PIPELINE_DSL_PATH: pipeline_path\n    }\n    handler = FakeHandler(flags_dict)\n    self.assertIsNone(handler._check_dsl_runner())\n\n  def testCheckPipelinExistenceNotRequired(self):\n    flags_dict = {labels.ENGINE_FLAG: \'beam\', labels.PIPELINE_NAME: \'pipeline\'}\n    handler = FakeHandler(flags_dict)\n    tf.io.gfile.makedirs(\n        os.path.join(os.environ[\'HOME\'], \'beam\', \'pipeline\', \'\'))\n    with self.assertRaises(SystemExit) as err:\n      handler._check_pipeline_existence(\n          flags_dict[labels.PIPELINE_NAME], required=False)\n    self.assertTrue(\n        str(err.exception), \'Pipeline ""{}"" already exists.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  def testCheckPipelineExistenceRequired(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: \'beam\',\n        labels.PIPELINE_NAME: \'chicago_taxi_beam\'\n    }\n    handler = FakeHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler._check_pipeline_existence(flags_dict[labels.PIPELINE_NAME])\n    self.assertTrue(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/handler/beam_handler.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Handler for Beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport sys\nfrom typing import Any, Dict, Text\n\nimport click\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import base_handler\nfrom tfx.utils import io_utils\n\n\nclass BeamHandler(base_handler.BaseHandler):\n  """"""Helper methods for Beam Handler.""""""\n\n  def create_pipeline(self, overwrite: bool = False) -> None:\n    """"""Creates pipeline in Beam.\n\n    Args:\n      overwrite: set as true to update pipeline.\n    """"""\n    # Compile pipeline to check if pipeline_args are extracted successfully.\n    pipeline_args = self.compile_pipeline()\n\n    pipeline_name = pipeline_args[labels.PIPELINE_NAME]\n\n    self._check_pipeline_existence(pipeline_name, required=overwrite)\n\n    self._save_pipeline(pipeline_args)\n\n    if overwrite:\n      click.echo(\'Pipeline ""{}"" updated successfully.\'.format(pipeline_name))\n    else:\n      click.echo(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name))\n\n  def update_pipeline(self) -> None:\n    """"""Updates pipeline in Beam.""""""\n\n    # Set overwrite as True to update the pipeline.\n    self.create_pipeline(overwrite=True)\n\n  def list_pipelines(self) -> None:\n    """"""List all the pipelines in the environment.""""""\n    if not tf.io.gfile.exists(self._handler_home_dir):\n      click.echo(\'No pipelines to display.\')\n      return\n    pipelines_list = tf.io.gfile.listdir(self._handler_home_dir)\n\n    # Print every pipeline name in a new line.\n    click.echo(\'-\' * 30)\n    click.echo(\'\\n\'.join(pipelines_list))\n    click.echo(\'-\' * 30)\n\n  def delete_pipeline(self) -> None:\n    """"""Deletes pipeline in Beam.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Path to pipeline folder.\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name,\n                                         \'\')\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Delete pipeline folder.\n    io_utils.delete_dir(handler_pipeline_path)\n    click.echo(\'Pipeline ""{}"" deleted successfully.\'.format(pipeline_name))\n\n  def compile_pipeline(self) -> Dict[Text, Any]:\n    """"""Compiles pipeline in Beam.\n\n    Returns:\n      pipeline_args: python dictionary with pipeline details extracted from DSL.\n    """"""\n    self._check_pipeline_dsl_path()\n    self._check_dsl_runner()\n    pipeline_args = self._extract_pipeline_args()\n    if not pipeline_args:\n      sys.exit(\'Unable to compile pipeline. Check your pipeline dsl.\')\n    click.echo(\'Pipeline compiled successfully.\')\n    return pipeline_args\n\n  def create_run(self) -> None:\n    """"""Runs a pipeline in Beam.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Get dsl path from pipeline args.\n    pipeline_args_path = os.path.join(self._handler_home_dir, pipeline_name,\n                                      \'pipeline_args.json\')\n    with open(pipeline_args_path, \'r\') as f:\n      pipeline_args = json.load(f)\n\n    # Run pipeline dsl.\n    self._subprocess_call(\n        [sys.executable, str(pipeline_args[labels.PIPELINE_DSL_PATH])])\n\n  def delete_run(self) -> None:\n    """"""Deletes a run.""""""\n    click.echo(\'Not supported for Beam.\')\n\n  def terminate_run(self) -> None:\n    """"""Stops a run.""""""\n    click.echo(\'Not supported for Beam.\')\n\n  def list_runs(self) -> None:\n    """"""Lists all runs of a pipeline.""""""\n    click.echo(\'Not supported for Beam.\')\n\n  def get_run(self) -> None:\n    """"""Checks run status.""""""\n    click.echo(\'Not supported for Beam.\')\n\n  def _save_pipeline(self, pipeline_args: Dict[Text, Any]) -> None:\n    """"""Creates/updates pipeline folder in the handler directory.""""""\n    # Add pipeline dsl path to pipeline args.\n    pipeline_args[labels.PIPELINE_DSL_PATH] = self.flags_dict[\n        labels.PIPELINE_DSL_PATH]\n\n    # Path to pipeline folder in beam.\n    handler_pipeline_path = os.path.join(self._handler_home_dir,\n                                         pipeline_args[labels.PIPELINE_NAME],\n                                         \'\')\n\n    # If updating pipeline, first delete pipeline directory.\n    if tf.io.gfile.exists(handler_pipeline_path):\n      io_utils.delete_dir(handler_pipeline_path)\n\n    # Dump pipeline_args to handler pipeline folder as json.\n    tf.io.gfile.makedirs(handler_pipeline_path)\n    with open(os.path.join(handler_pipeline_path, \'pipeline_args.json\'),\n              \'w\') as f:\n      json.dump(pipeline_args, f)\n'"
tfx/tools/cli/handler/beam_handler_test.py,16,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.handler.beam_handler.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport sys\nimport click\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import beam_handler\n\n\ndef _MockSubprocess(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a json file\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_name = \'chicago_taxi_beam\'\n  pipeline_root = os.path.join(os.environ[\'HOME\'], \'tfx\', \'pipelines\',\n                               pipeline_name)\n  pipeline_args = {\n      \'pipeline_name\': pipeline_name,\n      \'pipeline_root\': pipeline_root\n  }\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n  return 0\n\n\ndef _MockSubprocess2(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a json file\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_args = {}\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n  return 0\n\n\ndef _MockSubprocess3(cmd, env):  # pylint: disable=unused-argument\n  click.echo(cmd)\n  return 0\n\n\nclass BeamHandlerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(BeamHandlerTest, self).setUp()\n    self.chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n    self._tmp_dir = os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\',\n                                   self.get_temp_dir())\n    self._home = os.path.join(self._tmp_dir, self._testMethodName)\n    self._olddir = os.getcwd()\n    os.chdir(self._tmp_dir)\n    self._original_home_value = os.environ.get(\'HOME\', \'\')\n    os.environ[\'HOME\'] = self._home\n    self._original_beam_home_value = os.environ.get(\'BEAM_HOME\', \'\')\n    os.environ[\'BEAM_HOME\'] = os.path.join(os.environ[\'HOME\'], \'beam\')\n    self._beam_home = os.environ[\'BEAM_HOME\']\n\n    # Flags for handler.\n    self.engine = \'beam\'\n    self.pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                      \'test_pipeline_beam_1.py\')\n    self.pipeline_name = \'chicago_taxi_beam\'\n    self.pipeline_root = os.path.join(self._home, \'tfx\', \'pipelines\',\n                                      self.pipeline_name)\n    self.run_id = \'dummyID\'\n\n    # Pipeline args for mocking subprocess\n    self.pipeline_args = {\n        \'pipeline_name\': \'chicago_taxi_beam\',\n        \'pipeline_dsl_path\': self.pipeline_path\n    }\n\n  def tearDown(self):\n    super(BeamHandlerTest, self).tearDown()\n    if self._home:\n      os.environ[\'HOME\'] = self._original_home_value\n    if self._beam_home:\n      os.environ[\'BEAM_HOME\'] = self._original_beam_home_value\n    os.chdir(self._olddir)\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testSavePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    pipeline_args = handler._extract_pipeline_args()\n    handler._save_pipeline(pipeline_args)\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler._handler_home_dir,\n                         self.pipeline_args[labels.PIPELINE_NAME])))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'pipeline_args.json\')))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipelineExistentPipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n    # Run create_pipeline again to test.\n    with self.assertRaises(SystemExit) as err:\n      handler.create_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" already exists.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipeline(self):\n    # First create pipeline with test_pipeline.py\n    pipeline_path_1 = os.path.join(self.chicago_taxi_pipeline_dir,\n                                   \'test_pipeline_beam_1.py\')\n    flags_dict_1 = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: pipeline_path_1\n    }\n    handler = beam_handler.BeamHandler(flags_dict_1)\n    handler.create_pipeline()\n\n    # Update test_pipeline and run update_pipeline\n    pipeline_path_2 = os.path.join(self.chicago_taxi_pipeline_dir,\n                                   \'test_pipeline_beam_2.py\')\n    flags_dict_2 = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: pipeline_path_2\n    }\n    handler = beam_handler.BeamHandler(flags_dict_2)\n    handler.update_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'pipeline_args.json\')))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipelineNoPipeline(self):\n    # Update pipeline without creating one.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.update_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCompilePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.compile_pipeline()\n    self.assertIn(\'Pipeline compiled successfully\', captured.contents())\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess2)\n  def testCompilePipelineNoPipelineArgs(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.compile_pipeline()\n    self.assertEqual(\n        str(err.exception),\n        \'Unable to compile pipeline. Check your pipeline dsl.\')\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipeline(self):\n    # First create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n\n    # Now delete the pipeline created aand check if pipeline folder is deleted.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.delete_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipelineNonExistentPipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.delete_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  def testListPipelinesNonEmpty(self):\n    # First create two pipelines in the dags folder.\n    handler_pipeline_path_1 = os.path.join(os.environ[\'BEAM_HOME\'],\n                                           \'pipeline_1\')\n    handler_pipeline_path_2 = os.path.join(os.environ[\'BEAM_HOME\'],\n                                           \'pipeline_2\')\n    tf.io.gfile.makedirs(handler_pipeline_path_1)\n    tf.io.gfile.makedirs(handler_pipeline_path_2)\n\n    # Now, list the pipelines\n    flags_dict = {labels.ENGINE_FLAG: self.engine}\n    handler = beam_handler.BeamHandler(flags_dict)\n\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_pipelines()\n    self.assertIn(\'pipeline_1\', captured.contents())\n    self.assertIn(\'pipeline_2\', captured.contents())\n\n  def testListPipelinesEmpty(self):\n    flags_dict = {labels.ENGINE_FLAG: self.engine}\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_pipelines()\n    self.assertIn(\'No pipelines to display.\', captured.contents())\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaNoPipelineRoot(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Create a run before inferring schema. If pipeline is already running, then wait for it to successfully finish.\'\n    )\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaNoSchemaGenOutput(self):\n    # First create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    tf.io.gfile.makedirs(self.pipeline_root)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Either SchemaGen component does not exist or pipeline is still running. If pipeline is running, then wait for it to successfully finish.\'\n    )\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testPipelineSchemaSuccessfulRun(self):\n    # First create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    # Create fake schema in pipeline root.\n    schema_path = os.path.join(self.pipeline_root, \'SchemaGen\', \'schema\', \'3\')\n    tf.io.gfile.makedirs(schema_path)\n    with open(os.path.join(schema_path, \'schema.pbtxt\'), \'w\') as f:\n      f.write(\'SCHEMA\')\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.get_schema()\n      curr_dir_path = os.path.join(os.getcwd(), \'schema.pbtxt\')\n      self.assertIn(\'Path to schema: {}\'.format(curr_dir_path),\n                    captured.contents())\n      self.assertIn(\n          \'*********SCHEMA FOR {}**********\'.format(self.pipeline_name.upper()),\n          captured.contents())\n      self.assertTrue(tf.io.gfile.exists(curr_dir_path))\n\n  @mock.patch(\'subprocess.call\', _MockSubprocess3)\n  def testCreateRun(self):\n    # Create a pipeline in dags folder.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'BEAM_HOME\'], self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n    with open(os.path.join(handler_pipeline_path, \'pipeline_args.json\'),\n              \'w\') as f:\n      json.dump(self.pipeline_args, f)\n\n    # Now run the pipeline\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.create_run()\n    self.assertIn(self.pipeline_path, captured.contents())\n\n  def testCreateRunNoPipeline(self):\n    # Run pipeline without creating one.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name\n    }\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.create_run()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  def testDeleteRun(self):\n    # Create a pipeline in beam home.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'BEAM_HOME\'], self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.delete_run()\n    self.assertIn(\'Not supported for Beam.\', captured.contents())\n\n  def testTerminateRun(self):\n    # Create a pipeline in beam home.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'BEAM_HOME\'], self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.terminate_run()\n    self.assertIn(\'Not supported for Beam.\', captured.contents())\n\n  def testListRuns(self):\n    # Create a pipeline in beam home.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'BEAM_HOME\'], self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_runs()\n    self.assertIn(\'Not supported for Beam.\', captured.contents())\n\n  def testGetRun(self):\n    # Create a pipeline in beam home.\n    handler_pipeline_path = os.path.join(\n        os.environ[\'BEAM_HOME\'], self.pipeline_args[labels.PIPELINE_NAME])\n    tf.io.gfile.makedirs(handler_pipeline_path)\n\n    # Now run the pipeline\n    flags_dict = {labels.ENGINE_FLAG: self.engine, labels.RUN_ID: self.run_id}\n    handler = beam_handler.BeamHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.get_run()\n    self.assertIn(\'Not supported for Beam.\', captured.contents())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/handler/handler_factory.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Helper functions to choose engine.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport subprocess\nimport sys\nfrom typing import Any, Dict, Text\n\nimport click\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import base_handler\n\n\ndef detect_handler(flags_dict: Dict[Text, Any]) -> base_handler.BaseHandler:\n  """"""Detect handler from the environment.\n\n  Details:\n    When the engine flag is set to \'auto\', this method first finds all the\n    packages in the local environment. The environment is first checked\n    for multiple orchestrators and if true the user must rerun the command with\n    required engine. If only one orchestrator is present, the engine is set to\n    that.\n\n  Args:\n    flags_dict: A dictionary containing the flags of a command.\n\n  Returns:\n    Corrosponding Handler object.\n  """"""\n  packages_list = str(subprocess.check_output([\'pip\', \'freeze\', \'--local\']))\n  if labels.AIRFLOW_PACKAGE_NAME in packages_list and labels.KUBEFLOW_PACKAGE_NAME in packages_list:\n    sys.exit(\'Multiple orchestrators found. Choose one using --engine flag.\')\n  if labels.AIRFLOW_PACKAGE_NAME in packages_list:\n    click.echo(\'Detected Airflow.\')\n    click.echo(\n        \'Use --engine flag if you intend to use a different orchestrator.\')\n    flags_dict[labels.ENGINE_FLAG] = \'airflow\'\n    from tfx.tools.cli.handler import airflow_handler  # pylint: disable=g-import-not-at-top\n    return airflow_handler.AirflowHandler(flags_dict)\n  elif labels.KUBEFLOW_PACKAGE_NAME in packages_list:\n    click.echo(\'Detected Kubeflow.\')\n    click.echo(\n        \'Use --engine flag if you intend to use a different orchestrator.\')\n    flags_dict[labels.ENGINE_FLAG] = \'kubeflow\'\n    from tfx.tools.cli.handler import kubeflow_handler  # pylint: disable=g-import-not-at-top\n    return kubeflow_handler.KubeflowHandler(flags_dict)\n  else:\n    click.echo(\'Detected Beam.\')\n    flags_dict[labels.ENGINE_FLAG] = \'beam\'\n    from tfx.tools.cli.handler import beam_handler  # pylint: disable=g-import-not-at-top\n    return beam_handler.BeamHandler(flags_dict)\n\n\ndef create_handler(flags_dict: Dict[Text, Any]) -> base_handler.BaseHandler:\n  """"""Retrieve handler from the environment using the --engine flag.\n\n  Args:\n    flags_dict: A dictionary containing the flags of a command.\n\n  Raises:\n    RuntimeError: When engine is not supported by TFX.\n\n  Returns:\n    Corresponding Handler object.\n  """"""\n  engine = flags_dict[labels.ENGINE_FLAG]\n  packages_list = str(subprocess.check_output([\'pip\', \'freeze\', \'--local\']))\n  if engine == \'airflow\':\n    if labels.AIRFLOW_PACKAGE_NAME not in packages_list:\n      sys.exit(\'Airflow not found.\')\n    from tfx.tools.cli.handler import airflow_handler  # pylint: disable=g-import-not-at-top\n    return airflow_handler.AirflowHandler(flags_dict)\n  elif engine == \'kubeflow\':\n    if labels.KUBEFLOW_PACKAGE_NAME not in packages_list:\n      sys.exit(\'Kubeflow not found.\')\n    from tfx.tools.cli.handler import kubeflow_handler  # pylint: disable=g-import-not-at-top\n    return kubeflow_handler.KubeflowHandler(flags_dict)\n  elif engine == \'beam\':\n    from tfx.tools.cli.handler import beam_handler  # pylint: disable=g-import-not-at-top\n    return beam_handler.BeamHandler(flags_dict)\n  elif engine == \'auto\':\n    return detect_handler(flags_dict)\n  else:\n    raise RuntimeError(\'Engine {} is not supported.\'.format(engine))\n'"
tfx/tools/cli/handler/handler_factory_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.cmd.helper.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport tempfile\n\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import airflow_handler\nfrom tfx.tools.cli.handler import beam_handler\nfrom tfx.tools.cli.handler import handler_factory\n\n\nclass _MockClientClass(object):\n\n  def __init__(self, host, client_id, namespace):\n    config = {\'host\': host, \'client_id\': client_id, \'namespace\': namespace}  # pylint: disable=invalid-name, unused-variable\n    self._output_dir = os.path.join(tempfile.gettempdir(), \'output_dir\')\n\n\nclass HandlerFactoryTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(HandlerFactoryTest, self).setUp()\n    self.flags_dict = {}\n    sys.modules[\'kfp\'] = mock.Mock()\n    sys.modules[\'kfp_server_api\'] = mock.Mock()\n\n  def _MockSubprocessAirflow(self):\n    return b\'absl-py==0.7.1\\nalembic==0.9.10\\napache-beam==2.12.0\\napache-airflow==1.10.3\\n\'\n\n  @mock.patch(\'subprocess.check_output\', _MockSubprocessAirflow)\n  def testCreateHandlerAirflow(self):\n    self.flags_dict[labels.ENGINE_FLAG] = \'airflow\'\n    self.assertIsInstance(\n        handler_factory.create_handler(self.flags_dict),\n        airflow_handler.AirflowHandler)\n\n  def _MockSubprocessKubeflow(self):\n    return b\'absl-py==0.7.1\\nadal==1.2.1\\nalembic==0.9.10\\napache-beam==2.12.0\\nkfp==0.1\\n\'\n\n  @mock.patch(\'subprocess.check_output\', _MockSubprocessKubeflow)\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  def testCreateHandlerKubeflow(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: \'kubeflow\',\n        labels.ENDPOINT: \'dummyEndpoint\',\n        labels.IAP_CLIENT_ID: \'dummyID\',\n        labels.NAMESPACE: \'kubeflow\',\n    }\n    from tfx.tools.cli.handler import kubeflow_handler  # pylint: disable=g-import-not-at-top\n    self.assertIsInstance(\n        handler_factory.create_handler(flags_dict),\n        kubeflow_handler.KubeflowHandler)\n\n  def testCreateHandlerBeam(self):\n    self.flags_dict[labels.ENGINE_FLAG] = \'beam\'\n    self.assertIsInstance(\n        handler_factory.create_handler(self.flags_dict),\n        beam_handler.BeamHandler)\n\n  def testCreateHandlerOther(self):\n    self.flags_dict[labels.ENGINE_FLAG] = \'flink\'\n    with self.assertRaises(Exception) as err:\n      handler_factory.create_handler(self.flags_dict)\n    self.assertEqual(\n        str(err.exception), \'Engine {} is not supported.\'.format(\n            self.flags_dict[labels.ENGINE_FLAG]))\n\n  def _MockSubprocessNoEngine(self):\n    return b\'absl-py==0.7.1\\nalembic==0.9.10\\napache-beam==2.12.0\\n\'\n\n  @mock.patch(\'subprocess.check_output\', _MockSubprocessNoEngine)\n  def testDetectHandlerMissing(self):\n    self.flags_dict[labels.ENGINE_FLAG] = \'auto\'\n    self.assertIsInstance(\n        handler_factory.detect_handler(self.flags_dict),\n        beam_handler.BeamHandler)\n\n  def _MockSubprocessMultipleEngines(self):\n    return b\'absl-py==0.7.1\\nadal==1.2.1\\nalembic==0.9.10\\napache-airflow==1.10.3\\napache-beam==2.12.0\\nkfp==0.1\\n\'\n\n  @mock.patch(\'subprocess.check_output\', _MockSubprocessMultipleEngines)\n  def testDetectHandlerMultiple(self):\n    self.flags_dict[labels.ENGINE_FLAG] = \'auto\'\n    with self.assertRaises(SystemExit) as cm:\n      handler_factory.detect_handler(self.flags_dict)\n    self.assertEqual(\n        str(cm.exception),\n        \'Multiple orchestrators found. Choose one using --engine flag.\'\n        )\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/handler/kubeflow_handler.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Handler for Kubeflow.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport subprocess\nimport sys\nimport time\nfrom typing import Any, Dict, Optional, Text\n\nimport click\nimport kfp\nfrom tabulate import tabulate\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.container_builder import builder\nfrom tfx.tools.cli.container_builder import labels as container_builder_labels\nfrom tfx.tools.cli.handler import base_handler\nfrom tfx.utils import io_utils\n\n\n# TODO(b/132286477): Change generated api methods to client methods after SDK is\n# updated.\nclass KubeflowHandler(base_handler.BaseHandler):\n  """"""Helper methods for Kubeflow Handler.""""""\n\n  def __init__(self, flags_dict: Dict[Text, Any]):\n    """"""Initialize Kubeflow handler.\n\n    Args:\n      flags_dict: A dictionary with flags provided in a command.\n    """"""\n    super(KubeflowHandler, self).__init__(flags_dict)\n    # TODO(b/132286477): Change to setup config instead of flags if needed.\n    if labels.NAMESPACE in self.flags_dict:\n      self._client = kfp.Client(\n          host=self.flags_dict[labels.ENDPOINT],\n          client_id=self.flags_dict[labels.IAP_CLIENT_ID],\n          namespace=self.flags_dict[labels.NAMESPACE])\n    else:\n      self._client = None\n\n  def create_pipeline(self, update: bool = False) -> None:\n    """"""Creates or updates a pipeline in Kubeflow.\n\n    Args:\n      update: set as true to update pipeline.\n    """"""\n    # Build pipeline container image.\n    try:\n      target_image = self.flags_dict.get(labels.TARGET_IMAGE)\n      skaffold_cmd = self.flags_dict.get(labels.SKAFFOLD_CMD)\n      if target_image is not None or os.path.exists(\n          container_builder_labels.BUILD_SPEC_FILENAME):\n        base_image = self.flags_dict.get(labels.BASE_IMAGE)\n        target_image = self._build_pipeline_image(target_image, base_image,\n                                                  skaffold_cmd)\n        os.environ[labels.KUBEFLOW_TFX_IMAGE_ENV] = target_image\n    except (ValueError, subprocess.CalledProcessError, RuntimeError):\n      click.echo(\'No container image is built.\')\n      raise\n    else:\n      click.echo(\'New container image is built. Target image is available in \'\n                 \'the build spec file.\')\n\n    # Compile pipeline to check if pipeline_args are extracted successfully.\n    pipeline_args = self.compile_pipeline()\n\n    pipeline_name = pipeline_args[labels.PIPELINE_NAME]\n\n    self._check_pipeline_existence(pipeline_name, required=update)\n\n    self._save_pipeline(pipeline_args, update=update)\n\n    if update:\n      click.echo(\'Pipeline ""{}"" updated successfully.\'.format(pipeline_name))\n    else:\n      click.echo(\'Pipeline ""{}"" created successfully.\'.format(pipeline_name))\n\n  def update_pipeline(self) -> None:\n    """"""Updates pipeline in Kubeflow.""""""\n    self.create_pipeline(update=True)\n\n  def list_pipelines(self) -> None:\n    """"""List all the pipelines in the environment.""""""\n    # TODO(jyzhao): use metadata context to get the pipeline info.\n    response = self._client.list_pipelines(page_size=100)\n\n    if response and response.pipelines:\n      click.echo(response.pipelines)\n    else:\n      click.echo(\'No pipelines to display.\')\n\n  def delete_pipeline(self) -> None:\n    """"""Delete pipeline in Kubeflow.""""""\n\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n    # Check if pipeline exists on server.\n    pipeline_id = self._get_pipeline_id(pipeline_name)\n    self._client._pipelines_api.get_pipeline(pipeline_id)  # pylint: disable=protected-access\n\n    # Delete pipeline for kfp server.\n    self._client._pipelines_api.delete_pipeline(id=pipeline_id)  # pylint: disable=protected-access\n\n    # Delete experiment from server.\n    experiment_id = self._get_experiment_id(pipeline_name)\n    self._client._experiment_api.delete_experiment(experiment_id)  # pylint: disable=protected-access\n\n    # Path to pipeline folder.\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name,\n                                         \'\')\n\n    # Delete pipeline for home directory.\n    io_utils.delete_dir(handler_pipeline_path)\n\n    click.echo(\'Pipeline \' + pipeline_name + \' deleted successfully.\')\n\n  def compile_pipeline(self) -> Dict[Text, Any]:\n    """"""Compiles pipeline in Kubeflow.\n\n    Returns:\n      pipeline_args: python dictionary with pipeline details extracted from DSL.\n    """"""\n    self._check_pipeline_dsl_path()\n    self._check_dsl_runner()\n    pipeline_args = self._extract_pipeline_args()\n    self._check_pipeline_package_path(pipeline_args[labels.PIPELINE_NAME])\n    if not pipeline_args:\n      sys.exit(\'Unable to compile pipeline. Check your pipeline dsl.\')\n    click.echo(\'Pipeline compiled successfully.\')\n    click.echo(\'Pipeline package path: {}\'.format(\n        self.flags_dict[labels.PIPELINE_PACKAGE_PATH]))\n    return pipeline_args\n\n  def create_run(self) -> None:\n    """"""Runs a pipeline in Kubeflow.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n    experiment_name = pipeline_name\n\n    pipeline_version_id = self._get_pipeline_version_id(pipeline_name)\n    experiment_id = self._get_experiment_id(pipeline_name)\n\n    # Run pipeline.\n    if pipeline_version_id is not None:\n      run = self._client.run_pipeline(\n          experiment_id=experiment_id,\n          job_name=experiment_name,\n          version_id=pipeline_version_id)\n    else:\n      # TODO(b/153599914): Delete support for version-less pipelines which were\n      #                    created with tfx <= 0.21.x\n      pipeline_id = self._get_pipeline_id(pipeline_name)\n      run = self._client.run_pipeline(\n          experiment_id=experiment_id,\n          job_name=experiment_name,\n          pipeline_id=pipeline_id)\n\n    click.echo(\'Run created for pipeline: \' + pipeline_name)\n    self._print_runs([run])\n\n  def delete_run(self) -> None:\n    """"""Deletes a run.""""""\n    self._client._run_api.delete_run(self.flags_dict[labels.RUN_ID])  # pylint: disable=protected-access\n\n    click.echo(\'Run deleted.\')\n\n  def terminate_run(self) -> None:\n    """"""Stops a run.""""""\n    self._client._run_api.terminate_run(self.flags_dict[labels.RUN_ID])  # pylint: disable=protected-access\n    click.echo(\'Run terminated.\')\n\n  def list_runs(self) -> None:\n    """"""Lists all runs of a pipeline.""""""\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    # Check if pipeline exists.\n    pipeline_id = self._get_pipeline_id(pipeline_name)\n    self._client._pipelines_api.get_pipeline(pipeline_id)  # pylint: disable=protected-access\n\n    # List runs.\n    # TODO(jyzhao): use metadata context to get the run info.\n    experiment_id = self._get_experiment_id(pipeline_name)\n    response = self._client.list_runs(experiment_id=experiment_id)\n\n    if response and response.runs:\n      self._print_runs(response.runs)\n    else:\n      click.echo(\'No runs found.\')\n\n  def get_run(self) -> None:\n    """"""Checks run status.""""""\n\n    run = self._client.get_run(self.flags_dict[labels.RUN_ID]).run\n    self._print_runs([run])\n\n  def _save_pipeline(self,\n                     pipeline_args: Dict[Text, Any],\n                     update: bool = False) -> None:\n    """"""Creates/updates pipeline folder in the handler directory.""""""\n    pipeline_name = pipeline_args[labels.PIPELINE_NAME]\n\n    # Path to pipeline folder.\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name)\n\n    pipeline_package_path = self.flags_dict[labels.PIPELINE_PACKAGE_PATH]\n\n    if update:\n      pipeline_id = self._get_pipeline_id(pipeline_name)\n      # A timestamp will be appended for the uniqueness of `version_name`.\n      version_name = \'{}_{}\'.format(pipeline_name,\n                                    time.strftime(\'%Y%m%d%H%M%S\'))\n      upload_response = self._client.pipeline_uploads.upload_pipeline_version(\n          uploadfile=pipeline_package_path,\n          name=version_name,\n          pipelineid=pipeline_id)\n      pipeline_version_id = upload_response.id\n\n      experiment_id = self._get_experiment_id(pipeline_name)\n    else:  # creating a new pipeline.\n      upload_response = self._client.upload_pipeline(\n          pipeline_package_path=pipeline_package_path,\n          pipeline_name=pipeline_name)\n      pipeline_id = upload_response.id\n      pipeline_version_id = upload_response.default_version.id\n\n      # Create experiment with pipeline name as experiment name.\n      experiment_name = pipeline_name\n      experiment_id = self._client.create_experiment(experiment_name).id\n\n    # Display the link to the pipeline detail page in KFP UI.\n    click.echo(upload_response)\n    click.echo(\'Please access the pipeline detail page at \'\n               \'{prefix}/#/pipelines/details/{pipeline_id}\'.format(\n                   prefix=self._client._get_url_prefix(),  # pylint: disable=protected-access\n                   pipeline_id=pipeline_id))\n\n    # Add pipeline details to pipeline_args.\n    pipeline_args[labels.PIPELINE_NAME] = pipeline_name\n    pipeline_args[labels.PIPELINE_ID] = pipeline_id\n    pipeline_args[labels.PIPELINE_VERSION_ID] = pipeline_version_id\n    pipeline_args[labels.PIPELINE_PACKAGE_PATH] = pipeline_package_path\n    pipeline_args[labels.EXPERIMENT_ID] = experiment_id\n\n    # Path to pipeline_args.json .\n    pipeline_args_path = os.path.join(handler_pipeline_path,\n                                      \'pipeline_args.json\')\n\n    # Copy pipeline_args to pipeline folder.\n    tf.io.gfile.makedirs(handler_pipeline_path)\n    with open(pipeline_args_path, \'w\') as f:\n      json.dump(pipeline_args, f)\n\n  def _check_pipeline_package_path(self, pipeline_name: Text) -> None:\n\n    # When unset, search for the workflow file in the current dir.\n    if not self.flags_dict[labels.PIPELINE_PACKAGE_PATH]:\n      self.flags_dict[labels.PIPELINE_PACKAGE_PATH] = os.path.join(\n          os.getcwd(), \'{}.tar.gz\'.format(pipeline_name))\n\n    pipeline_package_path = self.flags_dict[labels.PIPELINE_PACKAGE_PATH]\n    if not tf.io.gfile.exists(pipeline_package_path):\n      sys.exit(\n          \'Pipeline package not found at {}. When --package_path is unset, it will try to find the workflow file, ""<pipeline_name>.tar.gz"" in the current directory.\'\n          .format(pipeline_package_path))\n\n  def _build_pipeline_image(self,\n                            target_image: Optional[Text] = None,\n                            base_image: Optional[Text] = None,\n                            skaffold_cmd: Optional[Text] = None) -> None:\n    return builder.ContainerBuilder(\n        target_image=target_image,\n        base_image=base_image,\n        skaffold_cmd=skaffold_cmd).build()\n\n  def _get_pipeline_args(self, pipeline_name: Text,\n                         arg_name: Text) -> Optional[Text]:\n    # Path to pipeline folder.\n    handler_pipeline_path = os.path.join(self._handler_home_dir, pipeline_name)\n\n    # Check if pipeline exists.\n    self._check_pipeline_existence(pipeline_name)\n\n    # Path to pipeline_args.json .\n    pipeline_args_path = os.path.join(handler_pipeline_path,\n                                      \'pipeline_args.json\')\n    # Get pipeline_id/experiment_id from pipeline_args.json\n    with open(pipeline_args_path, \'r\') as f:\n      pipeline_args = json.load(f)\n    return pipeline_args.get(arg_name)\n\n  def _get_pipeline_id(self, pipeline_name: Text) -> Text:\n    pipeline_id = self._get_pipeline_args(pipeline_name, labels.PIPELINE_ID)\n    if pipeline_id is None:\n      raise ValueError(\n          \'Cannot find pipeline id for pipeline {}.\'.format(pipeline_name))\n    return pipeline_id\n\n  # NOTE: _get_pipeline_version_id is Optional for backward-compatibility.\n  def _get_pipeline_version_id(self, pipeline_name: Text) -> Optional[Text]:\n    return self._get_pipeline_args(pipeline_name, labels.PIPELINE_VERSION_ID)\n\n  def _get_experiment_id(self, pipeline_name: Text) -> Text:\n    experiment_id = self._get_pipeline_args(pipeline_name, labels.EXPERIMENT_ID)\n    if experiment_id is None:\n      raise ValueError(\n          \'Cannot find experiment id for pipeline {}.\'.format(pipeline_name))\n    return experiment_id\n\n  def _print_runs(self, runs):\n    """"""Prints runs in a tabular format with headers mentioned below.""""""\n    headers = [\'pipeline_name\', \'run_id\', \'status\', \'created_at\', \'link\']\n    pipeline_name = self.flags_dict[labels.PIPELINE_NAME]\n\n    def _get_run_details(run_id):\n      """"""Return the link to the run detail page.""""""\n      return \'{prefix}/#/runs/details/{run_id}\'.format(\n          prefix=self._client._get_url_prefix(), run_id=run_id)  # pylint: disable=protected-access\n\n    data = [\n        [  # pylint: disable=g-complex-comprehension\n            pipeline_name, run.id, run.status,\n            run.created_at.isoformat(),\n            _get_run_details(run.id)\n        ] for run in runs\n    ]\n    click.echo(tabulate(data, headers=headers, tablefmt=\'grid\'))\n'"
tfx/tools/cli/handler/kubeflow_handler_test.py,10,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.handler.kubeflow_handler.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport json\nimport os\nimport sys\nimport tarfile\nimport unittest\nimport mock\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import kubeflow_handler\n\n\ndef _MockSubprocess(cmd, env):  # pylint: disable=invalid-name, unused-argument\n  # Store pipeline_args in a pickle file\n  pipeline_args_path = env[labels.TFX_JSON_EXPORT_PIPELINE_ARGS_PATH]\n  pipeline_root = os.path.join(os.environ[\'HOME\'], \'tfx\', \'pipelines\')\n  pipeline_args = {\n      \'pipeline_name\': \'chicago_taxi_pipeline_kubeflow\',\n      \'pipeline_root\': pipeline_root\n  }\n  with open(pipeline_args_path, \'w\') as f:\n    json.dump(pipeline_args, f)\n\n  chicago_taxi_pipeline_dir = os.path.join(\n      os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n  pipeline_path = os.path.join(chicago_taxi_pipeline_dir,\n                               \'test_pipeline_kubeflow_1.py\')\n  # Store pipeline package\n  output_filename = os.path.join(chicago_taxi_pipeline_dir,\n                                 \'chicago_taxi_pipeline_kubeflow.tar.gz\')\n  with tarfile.open(output_filename, \'w:gz\') as tar:\n    tar.add(pipeline_path)\n  return 0\n\n\nclass _MockDefaultVersion(object):\n\n  def __init__(self, _id):\n    self.id = _id\n\n\nclass _MockUploadResponse(object):\n  """"""Mock upload response object.""""""\n\n  def __init__(self, config):\n    self.host = config[\'host\']\n    self.client_id = config[\'client_id\']\n    self.namespace = config[\'namespace\']\n    self.id = config[\'id\']\n    self.name = config[\'name\']\n    self.default_version = _MockDefaultVersion(config[\'pipeline_version_id\'])\n\n\nclass _MockClientClass(object):\n\n  def __init__(self, host, client_id, namespace):\n\n    self.config = {\n        \'host\': host,\n        \'client_id\': client_id,\n        \'namespace\': namespace,\n        \'id\': \'fake_pipeline_id\',\n        \'pipeline_version_id\': \'fake_pipeline_version_id\',\n        \'name\': \'fake_pipeline_name\'\n    }  # pylint: disable=invalid-name, unused-variable\n    self._pipelines_api = _MockPipelineApi()\n    self._experiment_api = _MockExperimentApi()\n    self._run_api = _MockRunApi()\n    self.pipeline_uploads = _MockPipielineUploadApi(\n        self.config[\'pipeline_version_id\'])\n\n  def upload_pipeline(self, pipeline_package_path, pipeline_name):  # pylint: disable=invalid-name, unused-argument\n    return _MockUploadResponse(self.config)\n\n  def create_experiment(self, name):\n    return self._experiment_api.create_experiment(name)\n\n  def get_experiment(self, experiment_id=None, experiment_name=None):  # pylint: disable=unused-argument\n    return self._experiment_api.get_experiment(experiment_id)\n\n  def run_pipeline(self,\n                   experiment_id,\n                   job_name,\n                   pipeline_id=None,\n                   version_id=None):\n    del experiment_id, job_name, pipeline_id, version_id\n    return self._pipelines_api.run_pipeline()\n\n  def list_pipelines(self):\n    return self._pipelines_api.list_pipelines()\n\n  def list_runs(self, experiment_id):\n    return self._run_api.list_runs(experiment_id)\n\n  def get_run(self, run_id):\n    return self._run_api.get_run(run_id)\n\n  def _get_url_prefix(self):\n    return \'http://\' + self.config[\'host\']\n\n\nclass _MockPipelineApi(object):\n\n  def delete_pipeline(self, id):  # pylint: disable=redefined-builtin, invalid-name\n    pass\n\n  def get_pipeline(self, id):  # pylint: disable=redefined-builtin, invalid-name\n    return id\n\n  def list_pipelines(self):\n    pass\n\n  def run_pipeline(self):\n    return _MockRunResponse(\'run_id\', \'Running\', datetime.datetime.now())\n\n\nclass _MockPipielineUploadApi(object):\n\n  def __init__(self, _id):\n    self.id = _id\n\n  def upload_pipeline_version(self, uploadfile, name, pipelineid):\n    del uploadfile, name, pipelineid\n    return _MockDefaultVersion(self.id)\n\n\nclass _MockExperimentResponse(object):\n\n  def __init__(self, experiment_name, experiment_id):  # pylint: disable=redefined-builtin\n    self.name = experiment_name\n    self.id = experiment_id\n\n\nclass _MockExperimentApi(object):\n\n  def create_experiment(self, name):\n    return _MockExperimentResponse(name, \'fake_id\')\n\n  def get_experiment(self, id):  # pylint: disable=redefined-builtin\n    return _MockExperimentResponse(\'fake_name\', id)\n\n  def delete_experiment(self, id):  # pylint: disable=redefined-builtin, invalid-name\n    pass\n\n\nclass _MockRunResponse(object):\n\n  def __init__(self, run_id, status, created_at):\n    self.id = run_id\n    self.status = status\n    self.created_at = created_at\n\n\nclass _Runs(object):\n\n  def __init__(self, runs):\n    self.runs = runs\n\n\nclass _MockRunApi(object):\n\n  def delete_run(self, run_id):\n    pass\n\n  def terminate_run(self, run_id):\n    pass\n\n  def get_run(self, run_id):\n    return _MockRunResponse(run_id, \'Running\', datetime.datetime.now())\n\n  def list_runs(self, experiment_id):  # pylint: disable=unused-argument\n    run_1 = _MockRunResponse(\'1\', \'Success\', datetime.datetime.now())\n    run_2 = _MockRunResponse(\'2\', \'Failed\', datetime.datetime.now())\n    return _Runs([run_1, run_2])\n\n\ndef _check_kfp_environment() -> bool:\n  required_environments = [\n      \'KFP_E2E_BASE_CONTAINER_IMAGE\', \'KFP_E2E_SRC\', \'KFP_E2E_GCP_PROJECT_ID\',\n      \'KFP_E2E_GCP_REGION\', \'KFP_E2E_BUCKET_NAME\', \'KFP_E2E_TEST_DATA_ROOT\'\n  ]\n  for name in required_environments:\n    if os.environ.get(name) is None:\n      return False\n  return True\n\n\n@unittest.skipUnless(_check_kfp_environment(),\n                     \'Required environment variables not set\')\nclass KubeflowHandlerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(KubeflowHandlerTest, self).setUp()\n    self._home = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n    self._original_home_value = os.environ.get(\'HOME\', \'\')\n    os.environ[\'HOME\'] = self._home\n    self._original_kubeflow_home_value = os.environ.get(\'KUBEFLOW_HOME\', \'\')\n    os.environ[\'KUBEFLOW_HOME\'] = os.path.join(os.environ[\'HOME\'], \'kubeflow\')\n\n    # Flags for handler.\n    self.engine = \'kubeflow\'\n    self.chicago_taxi_pipeline_dir = os.path.join(\n        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \'testdata\')\n    self.pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                      \'test_pipeline_kubeflow_1.py\')\n    self.pipeline_name = \'chicago_taxi_pipeline_kubeflow\'\n    self.pipeline_package_path = os.path.join(\n        os.getcwd(), \'chicago_taxi_pipeline_kubeflow.tar.gz\')\n    self.pipeline_root = os.path.join(self._home, \'tfx\', \'pipelines\')\n\n    # Kubeflow client params.\n    self.endpoint = \'dummyEndpoint\'\n    self.namespace = \'kubeflow\'\n    self.iap_client_id = \'dummyID\'\n\n    # Pipeline args for mocking subprocess.\n    self.pipeline_args = {\'pipeline_name\': \'chicago_taxi_pipeline_kubeflow\'}\n\n  def tearDown(self):\n    super(KubeflowHandlerTest, self).tearDown()\n    os.environ[\'HOME\'] = self._original_home_value\n    os.environ[\'KUBEFLOW_HOME\'] = self._original_kubeflow_home_value\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  def testCheckPipelinePackagePathDefaultPath(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: None\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    pipeline_args = handler._extract_pipeline_args()\n    handler._check_pipeline_package_path(pipeline_args[labels.PIPELINE_NAME])\n    self.assertEqual(\n        handler.flags_dict[labels.PIPELINE_PACKAGE_PATH],\n        os.path.join(os.getcwd(),\n                     \'{}.tar.gz\'.format(pipeline_args[labels.PIPELINE_NAME])))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  def testCheckPipelinePackagePathWrongPath(self):\n    flags_dict = {\n        labels.ENGINE_FLAG:\n            self.engine,\n        labels.PIPELINE_DSL_PATH:\n            self.pipeline_path,\n        labels.ENDPOINT:\n            self.endpoint,\n        labels.IAP_CLIENT_ID:\n            self.iap_client_id,\n        labels.NAMESPACE:\n            self.namespace,\n        labels.PIPELINE_PACKAGE_PATH:\n            os.path.join(self.chicago_taxi_pipeline_dir,\n                         \'{}.tar.gz\'.format(self.pipeline_name))\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    pipeline_args = handler._extract_pipeline_args()\n    with self.assertRaises(SystemExit) as err:\n      handler._check_pipeline_package_path(pipeline_args[labels.PIPELINE_NAME])\n    self.assertEqual(\n        str(err.exception),\n        \'Pipeline package not found at {}. When --package_path is unset, it will try to find the workflow file, ""<pipeline_name>.tar.gz"" in the current directory.\'\n        .format(flags_dict[labels.PIPELINE_PACKAGE_PATH]))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testSavePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler._save_pipeline(self.pipeline_args)\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertTrue(os.path.join(handler_pipeline_path, \'pipeline_args.json\'))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n    handler.create_pipeline()\n    self.assertTrue(tf.io.gfile.exists(handler_pipeline_path))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreatePipelineExistentPipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n    # Run create_pipeline again to test.\n    with self.assertRaises(SystemExit) as err:\n      handler.create_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" already exists.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipeline(self):\n    # First create pipeline with test_pipeline.py\n    pipeline_path = os.path.join(self.chicago_taxi_pipeline_dir,\n                                 \'test_pipeline_kubeflow_1.py\')\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME])\n    self.assertTrue(tf.io.gfile.exists(handler_pipeline_path))\n\n    # Update test_pipeline and run update_pipeline\n    handler.update_pipeline()\n    self.assertTrue(\n        tf.io.gfile.exists(\n            os.path.join(handler_pipeline_path, \'pipeline_args.json\')))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testUpdatePipelineNoPipeline(self):\n    # Update pipeline without creating one.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.update_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            self.pipeline_args[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCompilePipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.compile_pipeline()\n    self.assertIn(\'Pipeline compiled successfully\', captured.contents())\n    self.assertIn(\'Pipeline package path\', captured.contents())\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipeline(self):\n    # Create pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    # Delete pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.delete_pipeline()\n    handler_pipeline_path = os.path.join(\n        handler._handler_home_dir, self.pipeline_args[labels.PIPELINE_NAME], \'\')\n    self.assertFalse(tf.io.gfile.exists(handler_pipeline_path))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testDeletePipelineNonExistentPipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.delete_pipeline()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testGetSchema(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n    }\n\n    # No pipeline root\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Create a run before inferring schema. If pipeline is already running, then wait for it to successfully finish.\'\n    )\n\n    # No SchemaGen output.\n    tf.io.gfile.makedirs(self.pipeline_root)\n    with self.assertRaises(SystemExit) as err:\n      handler.get_schema()\n    self.assertEqual(\n        str(err.exception),\n        \'Either SchemaGen component does not exist or pipeline is still running. If pipeline is running, then wait for it to successfully finish.\'\n    )\n\n    # Successful pipeline run.\n    # Create fake schema in pipeline root.\n    schema_path = os.path.join(self.pipeline_root, \'SchemaGen\', \'schema\', \'3\')\n    tf.io.gfile.makedirs(schema_path)\n    with open(os.path.join(schema_path, \'schema.pbtxt\'), \'w\') as f:\n      f.write(\'SCHEMA\')\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.get_schema()\n      curr_dir_path = os.path.join(os.getcwd(), \'schema.pbtxt\')\n      self.assertIn(\'Path to schema: {}\'.format(curr_dir_path),\n                    captured.contents())\n      self.assertIn(\n          \'*********SCHEMA FOR {}**********\'.format(self.pipeline_name.upper()),\n          captured.contents())\n      self.assertTrue(tf.io.gfile.exists(curr_dir_path))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testCreateRun(self):\n    # Create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    # Run pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.create_run()\n    self.assertIn(\'Run created for pipeline: \', captured.contents())\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  def testCreateRunNoPipeline(self):\n    # Run pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.create_run()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  @mock.patch(\'subprocess.call\', _MockSubprocess)\n  def testListRuns(self):\n    # Create a pipeline.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_DSL_PATH: self.pipeline_path,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n        labels.PIPELINE_PACKAGE_PATH: self.pipeline_package_path\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    handler.create_pipeline()\n\n    # List pipelines.\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.captureWritesToStream(sys.stdout) as captured:\n      handler.list_runs()\n    self.assertIn(\'pipeline_name\', captured.contents())\n\n  @mock.patch(\'kfp.Client\', _MockClientClass)\n  def testListRunsNoPipeline(self):\n    flags_dict = {\n        labels.ENGINE_FLAG: self.engine,\n        labels.PIPELINE_NAME: self.pipeline_name,\n        labels.ENDPOINT: self.endpoint,\n        labels.IAP_CLIENT_ID: self.iap_client_id,\n        labels.NAMESPACE: self.namespace,\n    }\n    handler = kubeflow_handler.KubeflowHandler(flags_dict)\n    with self.assertRaises(SystemExit) as err:\n      handler.list_runs()\n    self.assertEqual(\n        str(err.exception), \'Pipeline ""{}"" does not exist.\'.format(\n            flags_dict[labels.PIPELINE_NAME]))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/handler/template_handler.py,1,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Handler for Template related operations.\n\nHandles operations for templates in tfx/experimental/templates/ directory.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport os\nimport re\nfrom typing import Text, Dict, Any, List, Pattern\nimport click\n\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.utils import io_utils\n\n_PLACEHOLDER_PIPELINE_NAME = re.compile(\'{{PIPELINE_NAME}}\')\n_PIPELINE_NAME_ESCAPE_CHAR = [\'\\\\\', \'\\\'\', \'""\', \'/\']\n_IMPORT_FROM_PACKAGE = re.compile(\n    r\'from tfx\\.experimental\\.templates\\.[^\\.]+\\.\')\n_IMPORT_FROM_LOCAL_DIR = \'from \'\n_INTERNAL_TODO_PREFIX = re.compile(r\'\\s*# TODO\\((?:b/\\d+|[a-z]+)\\):.*\')\n\n_TemplateFilePath = collections.namedtuple(\'_TemplateFilePath\', [\'src\', \'dst\'])\n_ADDITIONAL_FILE_PATHS = {\n    \'taxi\': [  # template name\n        _TemplateFilePath(\n            \'examples/chicago_taxi_pipeline/data/big_tipper_label/data.csv\',\n            \'data/data.csv\'),\n    ],\n}\n\n\ndef _tfx_src_dir() -> Text:\n  """"""Get tfx directory in the source tree.\n\n    We should find tfx\n    from tfx/tools/cli/handler/template_handler.py.\n  Returns:\n    Path to the directory containing tfx sources.\n  """"""\n  return os.path.dirname(  # tfx/\n      os.path.dirname(  # tools/\n          os.path.dirname(  # cli/\n              os.path.dirname(os.path.abspath(__file__)))))  # handler/\n\n\ndef _templates_src_dir() -> Text:\n  """"""Get template directory in the source tree.\n\n    We should find tfx/experimental/templates\n    from tfx/tools/cli/handler/template_handler.py.\n  Returns:\n    Path to the directory containing template sources.\n  """"""\n  return os.path.join(_tfx_src_dir(), \'experimental\', \'templates\')\n\n\ndef list_template() -> List[Text]:\n  """"""List available templates by inspecting template source directory.\n\n  Returns:\n    List of template names which is same as directory name.\n  """"""\n  templates_dir = _templates_src_dir()\n  names = []\n  for f in os.listdir(templates_dir):\n    if f.startswith(\'_\'):\n      continue\n    if not os.path.isdir(os.path.join(templates_dir, f)):\n      continue\n    names.append(f)\n  return names\n\n\ndef _copy_and_replace_placeholder_dir(\n    src: Text, dst: Text, replace_dict: Dict[Pattern[Text], Text]) -> None:\n  """"""Copy a directory to destination path and replace the placeholders.""""""\n  if not os.path.isdir(dst):\n    if os.path.exists(dst):\n      raise RuntimeError(\n          \'Cannot copy template directory {}. Already a file exists.\'.format(\n              src))\n    tf.io.gfile.makedirs(dst)\n  for f in os.listdir(src):\n    src_path = os.path.join(src, f)\n    dst_path = os.path.join(dst, f)\n    if os.path.isdir(src_path):\n      if f.startswith(\'_\'):  # Excludes __pycache__ and other private folders.\n        continue\n      _copy_and_replace_placeholder_dir(src_path, dst_path, replace_dict)\n    else:  # a file.\n      if f.endswith(\'.pyc\'):  # Excludes .pyc\n        continue\n      _copy_and_replace_placeholder_file(src_path, dst_path, replace_dict)\n\n\ndef _copy_and_replace_placeholder_file(\n    src: Text, dst: Text, replace_dict: Dict[Pattern[Text], Text]) -> None:\n  """"""Copy a file to destination path and replace the placeholders.""""""\n  click.echo(\'{} -> {}\'.format(os.path.basename(src), dst))\n  with open(src) as fp:\n    contents = fp.read()\n  for orig_regex, new in replace_dict.items():\n    contents = orig_regex.sub(new, contents)\n  with open(dst, \'w\') as fp:\n    fp.write(contents)\n\n\ndef _sanitize_pipeline_name(name: Text) -> Text:\n  """"""Escape special characters to make a valid directory name.""""""\n  for escape_char in _PIPELINE_NAME_ESCAPE_CHAR:\n    name = name.replace(escape_char, \'\\\\\' + escape_char)\n  return name\n\n\ndef copy_template(flags_dict: Dict[Text, Any]) -> None:\n  """"""Copy template flags_dict[""model""] to flags_dict[""dest_dir""].\n\n  Copies all *.py and README files in specified template, and replace\n  the content of the files.\n\n  Args:\n    flags_dict: Should have pipeline_name, model and dest_dir.\n  """"""\n  pipeline_name = _sanitize_pipeline_name(flags_dict[labels.PIPELINE_NAME])\n  template_dir = os.path.join(_templates_src_dir(), flags_dict[labels.MODEL])\n  destination_dir = flags_dict[labels.DESTINATION_PATH]\n  if not os.path.isdir(template_dir):\n    raise ValueError(\'Model {} does not exist.\'.format(\n        flags_dict[labels.MODEL]))\n\n  replace_dict = {\n      _IMPORT_FROM_PACKAGE: _IMPORT_FROM_LOCAL_DIR,\n      _PLACEHOLDER_PIPELINE_NAME: pipeline_name,\n      _INTERNAL_TODO_PREFIX: \'\',\n  }\n  _copy_and_replace_placeholder_dir(template_dir,\n                                    destination_dir,\n                                    replace_dict)\n  for additional_file in _ADDITIONAL_FILE_PATHS[flags_dict[labels.MODEL]]:\n    src_path = os.path.join(_tfx_src_dir(), additional_file.src)\n    dst_path = os.path.join(destination_dir, additional_file.dst)\n    io_utils.copy_file(src_path, dst_path)\n'"
tfx/tools/cli/handler/template_handler_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.tools.cli.handler.template_handler.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport tensorflow as tf\n\nfrom tfx.tools.cli import labels\nfrom tfx.tools.cli.handler import template_handler\n\n\nclass TemplateHandlerTest(tf.test.TestCase):\n\n  _PLACEHOLDER_TEST_DATA_BEFORE = """"""\n  from %s import mmm\n  # TODO(b/1): This will disappear.\n  # TODO(step 4): User instruction.\n  # TODO(zzzzzzz): This will disappear, too.\n  pipeline_name = \'{{PIPELINE_NAME}}\'\n  """""" % (\'tfx.experimental.templates.taxi.parent\',)\n\n  _PLACEHOLDER_TEST_DATA_AFTER = """"""\n  from parent import mmm\n  # TODO(step 4): User instruction.\n  pipeline_name = \'dummy\'\n  """"""\n\n  def testList(self):\n    templates = template_handler.list_template()\n    self.assertNotEqual(templates, [])\n    self.assertIn(\'taxi\', templates)\n\n  def testCopy(self):\n    test_dir = self.create_tempdir().full_path\n    pipeline_name = \'my_pipeline\'\n    flags = {\n        labels.MODEL: \'taxi\',\n        labels.DESTINATION_PATH: test_dir,\n        labels.PIPELINE_NAME: pipeline_name\n    }\n    template_handler.copy_template(flags)\n    copied_files = os.listdir(test_dir)\n    self.assertNotEqual(copied_files, [])\n    self.assertContainsSubset([\'__init__.py\', \'beam_dag_runner.py\'],\n                              copied_files)\n    self.assertTrue(\n        os.path.exists(os.path.join(test_dir, \'data\', \'data.csv\')))\n\n    with open(os.path.join(test_dir, \'pipeline\', \'configs.py\')) as fp:\n      configs_py_content = fp.read()\n    self.assertIn(pipeline_name, configs_py_content)\n    self.assertNotIn(\'# TODO(b/\', configs_py_content)\n\n  def testEscapePipelineName(self):\n    # pylint: disable=protected-access\n    self.assertEqual(\'x\', template_handler._sanitize_pipeline_name(\'x\'))\n    self.assertEqual(\'\\\\\\\\x\\\\\\\'\\\\""\',\n                     template_handler._sanitize_pipeline_name(\'\\\\x\\\'""\'))\n    self.assertEqual(\'a\\\\/b\', template_handler._sanitize_pipeline_name(\'a/b\'))\n    # pylint: enable=protected-access\n\n  def testReplacePlaceHolder(self):\n    pipeline_name = \'dummy\'\n    src = self.create_tempfile()\n    dst = self.create_tempfile()\n    # pylint: disable=protected-access\n    replace_dict = {\n        template_handler._IMPORT_FROM_PACKAGE:\n            template_handler._IMPORT_FROM_LOCAL_DIR,\n        template_handler._PLACEHOLDER_PIPELINE_NAME:\n            pipeline_name,\n        template_handler._INTERNAL_TODO_PREFIX:\n            \'\',\n    }\n    src.write_text(self._PLACEHOLDER_TEST_DATA_BEFORE)\n    template_handler._copy_and_replace_placeholder_file(src.full_path,\n                                                        dst.full_path,\n                                                        replace_dict)\n    # pylint: enable=protected-access\n    self.assertEqual(dst.read_text(), self._PLACEHOLDER_TEST_DATA_AFTER)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/tools/cli/testdata/test_pipeline_airflow_1.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Pipeline for testing CLI.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig\nfrom tfx.tools.cli.e2e import test_utils\n\n\n_pipeline_name = \'chicago_taxi_simple\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data/simple\')\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\')\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n_log_root = os.path.join(_tfx_root, \'logs\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\ndef _create_pipeline():\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  return pipeline.Pipeline(\n      pipeline_name=_pipeline_name,\n      pipeline_root=_pipeline_root,\n      components=test_utils.create_e2e_components(_data_root),\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          _metadata_path),\n  )\n\n\n# Airflow checks \'DAG\' keyword for finding the dag.\nairflow_pipeline = AirflowDagRunner(AirflowPipelineConfig(_airflow_config)).run(\n    _create_pipeline())\n'"
tfx/tools/cli/testdata/test_pipeline_beam_1.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX on Beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\n\nfrom tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\nfrom tfx.components.schema_gen.component import SchemaGen\nfrom tfx.components.statistics_gen.component import StatisticsGen\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_beam\'\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  infer_schema = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[example_gen, statistics_gen, infer_schema],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      additional_pipeline_args={},\n  )\n\n\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          metadata_path=_metadata_path))\n'"
tfx/tools/cli/testdata/test_pipeline_beam_2.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX on Beam.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\n\nfrom tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.utils.dsl_utils import external_input\n\n\n_pipeline_name = \'chicago_taxi_beam\'\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[example_gen],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      additional_pipeline_args={},\n  )\n\n\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          metadata_path=_metadata_path))\n'"
tfx/tools/cli/testdata/test_pipeline_beam_3.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\n\nfrom tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\nfrom tfx.components.example_validator.component import ExampleValidator\nfrom tfx.components.schema_gen.component import SchemaGen\nfrom tfx.components.statistics_gen.component import StatisticsGen\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'chicago_taxi_beam_v2\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data\', \'simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  infer_schema = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n\n  # Performs anomaly detection based on statistics and data schema.\n  validate_stats = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=infer_schema.outputs[\'schema\'])\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[example_gen, statistics_gen, infer_schema, validate_stats],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      additional_pipeline_args={},\n  )\n\n\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          metadata_path=_metadata_path))\n'"
tfx/tools/cli/testdata/test_pipeline_kubeflow_1.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Test pipeline for Kubeflow.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.orchestration import pipeline as tfx_pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.tools.cli.e2e import test_utils\n\n# The base container image name to use when building the image used in tests.\n_BASE_CONTAINER_IMAGE = os.environ[\'KFP_E2E_BASE_CONTAINER_IMAGE\']\n\n# The GCP bucket to use to write output artifacts.\n_BUCKET_NAME = os.environ[\'KFP_E2E_BUCKET_NAME\']\n\n# The location of test data. The input files are copied to a test-local\n# location for each invocation, and cleaned up at the end of test.\n_TESTDATA_ROOT = os.environ[\'KFP_E2E_TEST_DATA_ROOT\']\n\n\ndef _get_test_output_dir():\n  return \'gs://{}/test_output\'.format(_BUCKET_NAME)\n\n\ndef _get_csv_input_location():\n  return os.path.join(_TESTDATA_ROOT, \'external\', \'csv\')\n\n\n# Name of the pipeline\n_PIPELINE_NAME = \'chicago_taxi_pipeline_kubeflow\'\n\n\ndef _create_pipeline():\n  pipeline_name = _PIPELINE_NAME\n  pipeline_root = os.path.join(_get_test_output_dir(), pipeline_name)\n  components = test_utils.create_e2e_components(_get_csv_input_location())\n  return tfx_pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      metadata_connection_config=metadata_store_pb2.ConnectionConfig(),\n      components=components[:2],  # Run two components only to reduce overhead.\n      log_root=\'/var/tmp/tfx/logs\',\n      additional_pipeline_args={\n          \'WORKFLOW_ID\': pipeline_name,\n      },\n  )\n\n\nrunner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n    kubeflow_metadata_config=kubeflow_dag_runner\n    .get_default_kubeflow_metadata_config(),\n    tfx_image=_BASE_CONTAINER_IMAGE)\n_ = kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n    _create_pipeline())\n'"
tfx/components/testdata/external/avro/generate_avro_file.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generate avro file from Chicago taxi csv data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text\n\nimport fastavro\nimport pandas as pd\n\n\ndef get_schema():\n  """"""Returns schema for Chicago taxi dataset.""""""\n  name_to_types = {\n      \'company\': \'string\',\n      \'dropoff_census_tract\': \'float\',\n      \'dropoff_community_area\': \'float\',\n      \'dropoff_latitude\': \'float\',\n      \'dropoff_longitude\': \'float\',\n      \'fare\': \'float\',\n      \'payment_type\': \'string\',\n      \'pickup_census_tract\': \'float\',\n      \'pickup_community_area\': \'int\',\n      \'pickup_latitude\': \'float\',\n      \'pickup_longitude\': \'float\',\n      \'tips\': \'float\',\n      \'trip_miles\': \'float\',\n      \'trip_seconds\': \'float\',\n      \'trip_start_day\': \'int\',\n      \'trip_start_hour\': \'int\',\n      \'trip_start_month\': \'int\',\n      \'trip_start_timestamp\': \'int\'\n  }\n\n  # Allow every column to accept null types\n  fields = [{\'name\': name, \'type\': [col_type, \'null\']}\n            for name, col_type in name_to_types.items()]\n\n  return {\'name\': \'Chicago Taxi dataset\', \'type\': \'record\', \'fields\': fields}\n\n\ndef generate_avro(src_file: Text, output_file: Text):\n  """"""Generates avro file based on src file.\n\n  Args:\n    src_file: path to Chicago taxi dataset.\n    output_file: output path for avro file.\n  """"""\n  df = pd.read_csv(src_file)\n  # Replaces NaN\'s with None\'s for avroWriter to interpret null values\n  df = df.where((pd.notnull(df)), None)\n\n  records = df.to_dict(orient=\'records\')\n\n  parsed_schema = fastavro.parse_schema(get_schema())\n  with open(output_file, \'wb\') as f:\n    fastavro.writer(f, parsed_schema, records)\n\n\nif __name__ == \'__main__\':\n  generate_avro(\'../csv/data.csv\', \'data2.avro\')\n'"
tfx/examples/airflow_workshop/setup/dags/taxi_pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# pylint: disable=line-too-long\n# pylint: disable=unused-import\n# pylint: disable=unused-argument\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom typing import Text\n\n\nfrom tfx.components import CsvExampleGen\n\n# from tfx.components import StatisticsGen # Step 3\n# from tfx.components import SchemaGen # Step 3\n# from tfx.components import ExampleValidator # Step 3\n\n# from tfx.components import Transform # Step 4\n\n\n# from tfx.components import Trainer # Step 5\n# from tfx.proto import trainer_pb2 # Step 5\n# import tensorflow_model_analysis as tfma # Step 5\n\n# from tfx.components import Evaluator # Step 6\n# from tfx.components import ResolverNode # Step 6\n# from tfx.dsl.experimental import latest_blessed_model_resolver # Step 6\n\n# from tfx.components import Pusher # Step 7\n# from tfx.proto import pusher_pb2 # Step 7\n\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'taxi\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'airflow\')\n_data_root = os.path.join(_taxi_root, \'data\', \'taxi_data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'dags\', \'taxi_utils_solution.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(_taxi_root, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  # statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\']) # Step 3\n\n  # Generates schema based on statistics files.\n  # infer_schema = SchemaGen( # Step 3\n  #     statistics=statistics_gen.outputs[\'statistics\'], # Step 3\n  #     infer_feature_shape=False) # Step 3\n\n  # Performs anomaly detection based on statistics and data schema.\n  # validate_stats = ExampleValidator( # Step 3\n  #     statistics=statistics_gen.outputs[\'statistics\'], # Step 3\n  #     schema=infer_schema.outputs[\'schema\']) # Step 3\n\n  # Performs transformations and feature engineering in training and serving.\n  # transform = Transform( # Step 4\n  #     examples=example_gen.outputs[\'examples\'], # Step 4\n  #     schema=infer_schema.outputs[\'schema\'], # Step 4\n  #     module_file=module_file) # Step 4\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  # trainer = Trainer( # Step 5\n  #     module_file=module_file, # Step 5\n  #     custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor), # Step 5\n  #     examples=transform.outputs[\'transformed_examples\'], # Step 5\n  #     transform_graph=transform.outputs[\'transform_graph\'], # Step 5\n  #     schema=infer_schema.outputs[\'schema\'], # Step 5\n  #     train_args=trainer_pb2.TrainArgs(num_steps=10000), # Step 5\n  #     eval_args=trainer_pb2.EvalArgs(num_steps=5000)) # Step 5\n\n  # Get the latest blessed model for model validation.\n  # model_resolver = ResolverNode( # Step 6\n  #     instance_name=\'latest_blessed_model_resolver\', # Step 6\n  #     resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver, # Step 6\n  #     model=Channel(type=Model), # Step 6\n  #     model_blessing=Channel(type=ModelBlessing)) # Step 6\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  # eval_config = tfma.EvalConfig( # Step 6\n  #     model_specs=[tfma.ModelSpec(label_key=\'tips\')], # Step 6\n  #     slicing_specs=[tfma.SlicingSpec()], # Step 6\n  #     metrics_specs=[ # Step 6\n  #         tfma.MetricsSpec(metrics=[ # Step 6\n  #             tfma.MetricConfig( # Step 6\n  #                 class_name=\'BinaryAccuracy\', # Step 6\n  #                 threshold=tfma.MetricThreshold( # Step 6\n  #                     value_threshold=tfma.GenericValueThreshold( # Step 6\n  #                         lower_bound={\'value\': 0.6}), # Step 6\n  #                     change_threshold=tfma.GenericChangeThreshold( # Step 6\n  #                         direction=tfma.MetricDirection.HIGHER_IS_BETTER, # Step 6\n  #                         absolute={\'value\': -1e-10}))) # Step 6\n  #         ]) # Step 6\n  #     ]) # Step 6\n\n  # model_analyzer = Evaluator( # Step 6\n  #     examples=example_gen.outputs[\'examples\'], # Step 6\n  #     model=trainer.outputs[\'model\'], # Step 6\n  #     baseline_model=model_resolver.outputs[\'model\'], # Step 6\n  #     # Change threshold will be ignored if there is no baseline (first run). # Step 6\n  #     eval_config=eval_config) # Step 6\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  # pusher = Pusher( # Step 7\n  #     model=trainer.outputs[\'model\'], # Step 7\n  #     model_blessing=model_analyzer.outputs[\'blessing\'], # Step 7\n  #     push_destination=pusher_pb2.PushDestination( # Step 7\n  #         filesystem=pusher_pb2.PushDestination.Filesystem( # Step 7\n  #             base_directory=serving_model_dir))) # Step 7\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          # statistics_gen, # Step 3\n          # infer_schema, # Step 3\n          # validate_stats, # Step 3\n          # transform, # Step 4\n          # trainer, # Step 5\n          # model_resolver, # Step 6\n          # model_analyzer, # Step 6\n          # pusher, # Step 7\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# \'DAG\' below need to be kept for Airflow to detect dag.\nDAG = AirflowDagRunner(AirflowPipelineConfig(_airflow_config)).run(\n    _create_pipeline(\n        pipeline_name=_pipeline_name,\n        pipeline_root=_pipeline_root,\n        data_root=_data_root,\n        module_file=_module_file,\n        serving_model_dir=_serving_model_dir,\n        metadata_path=_metadata_path,\n        # 0 means auto-detect based on on the number of CPUs available during\n        # execution time.\n        direct_num_workers=0))\n'"
tfx/examples/airflow_workshop/setup/dags/taxi_pipeline_solution.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\nfrom typing import Text\n\nimport tensorflow_model_analysis as tfma\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer.executor import GenericExecutor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner\nfrom tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'taxi_solution\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'airflow\')\n_data_root = os.path.join(_taxi_root, \'data\', \'taxi_data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'dags\', \'taxi_utils_solution.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(_taxi_root, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\n# TODO(b/137289334): rename this as simple after DAG visualization is done.\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text,\n                     direct_num_workers: int) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  infer_schema = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=False)\n\n  # Performs anomaly detection based on statistics and data schema.\n  validate_stats = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=infer_schema.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=infer_schema.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=transform.outputs[\'transformed_examples\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      schema=infer_schema.outputs[\'schema\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'tips\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'BinaryAccuracy\',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': 0.6}),\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={\'value\': -1e-10})))\n          ])\n      ])\n\n  model_analyzer = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_analyzer.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          infer_schema,\n          validate_stats,\n          transform,\n          trainer,\n          model_resolver,\n          model_analyzer,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n      # TODO(b/142684737): The multi-processing API might change.\n      beam_pipeline_args=[\'--direct_num_workers=%d\' % direct_num_workers])\n\n\n# \'DAG\' below need to be kept for Airflow to detect dag.\nDAG = AirflowDagRunner(AirflowPipelineConfig(_airflow_config)).run(\n    _create_pipeline(\n        pipeline_name=_pipeline_name,\n        pipeline_root=_pipeline_root,\n        data_root=_data_root,\n        module_file=_module_file,\n        serving_model_dir=_serving_model_dir,\n        metadata_path=_metadata_path,\n        # 0 means auto-detect based on on the number of CPUs available during\n        # execution time.\n        direct_num_workers=0))\n'"
tfx/examples/airflow_workshop/setup/dags/taxi_utils.py,40,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# pylint: disable=line-too-long\n# pylint: disable=unused-argument\n# pylint: disable=unused-import\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nThe utilities in this file are used to build a model with native Keras.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport tensorflow as tf\n# import tensorflow_transform as tft # Step 4\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n# START Step 4 -----------------------------------------------------------\n# def _transformed_name(key):\n#   return key + \'_xf\'\n#\n#\n# def _transformed_names(keys):\n#   return [_transformed_name(key) for key in keys]\n#\n#\n# def _gzip_reader_fn(filenames):\n#   """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n#   return tf.data.TFRecordDataset(\n#       filenames,\n#       compression_type=\'GZIP\')\n#\n#\n# def _fill_in_missing(x):\n#   """"""Replace missing values in a SparseTensor.\n#\n#   Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n#\n#   Args:\n#     x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n#       in the second dimension.\n#\n#   Returns:\n#     A rank 1 tensor where missing values of `x` have been filled in.\n#   """"""\n#   default_value = \'\' if x.dtype == tf.string else 0\n#   return tf.squeeze(\n#       tf.sparse.to_dense(\n#           tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n#           default_value),\n#       axis=1)\n#\n#\n#   # TFX Transform will call this function.\n# def preprocessing_fn(inputs):\n#   """"""tf.transform\'s callback function for preprocessing inputs.\n#\n#   Args:\n#     inputs: map from feature keys to raw not-yet-transformed features.\n#\n#   Returns:\n#     Map from string feature key to transformed feature operations.\n#   """"""\n#   outputs = {}\n#   for key in _DENSE_FLOAT_FEATURE_KEYS:\n#     # Preserve this feature as a dense float, setting nan\'s to the mean.\n#     outputs[_transformed_name(key)] = tft.scale_to_z_score(\n#         _fill_in_missing(inputs[key]))\n#\n#   for key in _VOCAB_FEATURE_KEYS:\n#     # Build a vocabulary for this feature.\n#     outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n#         _fill_in_missing(inputs[key]),\n#         top_k=_VOCAB_SIZE,\n#         num_oov_buckets=_OOV_SIZE)\n#\n#   for key in _BUCKET_FEATURE_KEYS:\n#     outputs[_transformed_name(key)] = tft.bucketize(\n#         _fill_in_missing(inputs[key]),\n#         _FEATURE_BUCKET_COUNT)\n#\n#   for key in _CATEGORICAL_FEATURE_KEYS:\n#     outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n#\n#   # Was this passenger a big tipper?\n#   taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n#   tips = _fill_in_missing(inputs[_LABEL_KEY])\n#   outputs[_transformed_name(_LABEL_KEY)] = tf.where(\n#       tf.math.is_nan(taxi_fare),\n#       tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n#       # Test if the tip was > 20% of the fare.\n#       tf.cast(\n#           tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))),\n#                      tf.int64))\n#\n#   return outputs\n# END Step 4 -------------------------------------------------------------\n\n# START Step 5 -----------------------------------------------------------\n# def _get_serve_tf_examples_fn(model, tf_transform_output):\n#   """"""Returns a function that parses a serialized tf.Example and applies TFT""""""\n#\n#   model.tft_layer = tf_transform_output.transform_features_layer()\n#\n#   @tf.function\n#   def serve_tf_examples_fn(serialized_tf_examples):\n#     """"""Returns the output to be used in the serving signature.""""""\n#     feature_spec = tf_transform_output.raw_feature_spec()\n#     feature_spec.pop(_LABEL_KEY)\n#     parsed_features = tf.io.parse_example(serialized_tf_examples,\n#                                           feature_spec)\n#\n#     transformed_features = model.tft_layer(parsed_features)\n#\n#     return model(transformed_features)\n#\n#   return serve_tf_examples_fn\n#\n#\n# def _input_fn(file_pattern: List[Text],\n#               tf_transform_output: tft.TFTransformOutput,\n#               batch_size: int = 200) -> tf.data.Dataset:\n#   """"""Generates features and label for tuning/training.\n#\n#   Args:\n#     file_pattern: List of paths or patterns of input tfrecord files.\n#     tf_transform_output: A TFTransformOutput.\n#     batch_size: representing the number of consecutive elements of returned\n#       dataset to combine in a single batch\n#\n#   Returns:\n#     A dataset that contains (features, indices) tuple where features is a\n#       dictionary of Tensors, and indices is a single Tensor of label indices.\n#   """"""\n#   transformed_feature_spec = (\n#       tf_transform_output.transformed_feature_spec().copy())\n#\n#   dataset = tf.data.experimental.make_batched_features_dataset(\n#       file_pattern=file_pattern,\n#       batch_size=batch_size,\n#       features=transformed_feature_spec,\n#       reader=_gzip_reader_fn,\n#       label_key=_transformed_name(_LABEL_KEY))\n#\n#   return dataset\n#\n#\n# def _build_keras_model(hidden_units: List[int] = None) -> tf.keras.Model:\n#   """"""Creates a DNN Keras model for classifying taxi data.\n#\n#   Args:\n#     hidden_units: [int], the layer sizes of the DNN (input layer first).\n#\n#   Returns:\n#     A keras Model.\n#   """"""\n#   real_valued_columns = [\n#       tf.feature_column.numeric_column(key, shape=())\n#       for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n#   ]\n#   categorical_columns = [\n#       tf.feature_column.categorical_column_with_identity(\n#           key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n#       for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n#   ]\n#   categorical_columns += [\n#       tf.feature_column.categorical_column_with_identity(\n#           key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n#       for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n#   ]\n#   categorical_columns += [\n#       tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n#           key,\n#           num_buckets=num_buckets,\n#           default_value=0) for key, num_buckets in zip(\n#               _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n#               _MAX_CATEGORICAL_FEATURE_VALUES)\n#   ]\n#   indicator_column = [\n#       tf.feature_column.indicator_column(categorical_column)\n#       for categorical_column in categorical_columns\n#   ]\n#\n#   model = _wide_and_deep_classifier(\n#       # TODO(b/139668410) replace with premade wide_and_deep keras model\n#       wide_columns=indicator_column,\n#       deep_columns=real_valued_columns,\n#       dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n#   return model\n#\n#\n# def _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units):\n#   """"""Build a simple keras wide and deep model.\n#\n#   Args:\n#     wide_columns: Feature columns wrapped in indicator_column for wide\n#       (linear) part of the model.\n#     deep_columns: Feature columns for deep part of the model.\n#     dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n#\n#   Returns:\n#     A Wide and Deep Keras model\n#   """"""\n#   # Following values are hard coded for simplicity in this example,\n#   # However prefarably they should be passsed in as hparams.\n#\n#   # Keras needs the feature definitions at compile time.\n#   # TODO(b/139081439): Automate generation of input layers from FeatureColumn.\n#   input_layers = {\n#       colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n#       for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n#   }\n#   input_layers.update({\n#       colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n#       for colname in _transformed_names(_VOCAB_FEATURE_KEYS)\n#   })\n#   input_layers.update({\n#       colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n#       for colname in _transformed_names(_BUCKET_FEATURE_KEYS)\n#   })\n#   input_layers.update({\n#       colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n#       for colname in _transformed_names(_CATEGORICAL_FEATURE_KEYS)\n#   })\n#\n#   # TODO(b/144500510): SparseFeatures for feature columns + Keras.\n#   deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n#   for numnodes in dnn_hidden_units:\n#     deep = tf.keras.layers.Dense(numnodes)(deep)\n#   wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n#\n#   output = tf.keras.layers.Dense(\n#       1, activation=\'sigmoid\')(\n#           tf.keras.layers.concatenate([deep, wide]))\n#\n#   model = tf.keras.Model(input_layers, output)\n#   model.compile(\n#       loss=\'binary_crossentropy\',\n#       optimizer=tf.keras.optimizers.Adam(lr=0.001),\n#       metrics=[tf.keras.metrics.BinaryAccuracy()])\n#   model.summary(print_fn=absl.logging.info)\n#   return model\n#\n#\n# # TFX Trainer will call this function.\n# def run_fn(fn_args: TrainerFnArgs):\n#   """"""Train the model based on given args.\n#\n#   Args:\n#     fn_args: Holds args used to train the model as name/value pairs.\n#   """"""\n#   # Number of nodes in the first layer of the DNN\n#   first_dnn_layer_size = 100\n#   num_dnn_layers = 4\n#   dnn_decay_factor = 0.7\n#\n#   tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n#\n#   train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 40)\n#   eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 40)\n#\n#   # If no GPUs are found, CPU is used.\n#   mirrored_strategy = tf.distribute.MirroredStrategy()\n#   with mirrored_strategy.scope():\n#     model = _build_keras_model(\n#         # Construct layers sizes with exponetial decay\n#         hidden_units=[\n#             max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n#             for i in range(num_dnn_layers)\n#         ])\n#\n#   model.fit(\n#       train_dataset,\n#       steps_per_epoch=fn_args.train_steps,\n#       validation_data=eval_dataset,\n#       validation_steps=fn_args.eval_steps)\n#\n#   signatures = {\n#       \'serving_default\':\n#           _get_serve_tf_examples_fn(model,\n#                                     tf_transform_output).get_concrete_function(\n#                                         tf.TensorSpec(\n#                                             shape=[None],\n#                                             dtype=tf.string,\n#                                             name=\'examples\')),\n#   }\n#   model.save(fn_args.serving_model_dir, save_format=\'tf\',\n#              signatures=signatures)\n# END Step 5 -------------------------------------------------------------\n'"
tfx/examples/airflow_workshop/setup/dags/taxi_utils_solution.py,38,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# pylint: disable=line-too-long\n# pylint: disable=unused-argument\n# pylint: disable=unused-import\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nThe utilities in this file are used to build a model with native Keras.\nThis module file will be used in Transform and generic Trainer.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.components.trainer.executor import TrainerFnArgs\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(\n      filenames,\n      compression_type=\'GZIP\')\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.sparse.to_dense(\n          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n          default_value),\n      axis=1)\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that parses a serialized tf.Example and applies TFT.""""""\n\n  model.tft_layer = tf_transform_output.transform_features_layer()\n\n  @tf.function\n  def serve_tf_examples_fn(serialized_tf_examples):\n    """"""Returns the output to be used in the serving signature.""""""\n    feature_spec = tf_transform_output.raw_feature_spec()\n    feature_spec.pop(_LABEL_KEY)\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    transformed_features = model.tft_layer(parsed_features)\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(_transformed_name(_LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\ndef _input_fn(file_pattern: List[Text],\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_transformed_name(_LABEL_KEY))\n\n  return dataset\n\n\ndef _build_keras_model(hidden_units: List[int] = None) -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying taxi data.\n\n  Args:\n    hidden_units: [int], the layer sizes of the DNN (input layer first).\n\n  Returns:\n    A keras Model.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  indicator_column = [\n      tf.feature_column.indicator_column(categorical_column)\n      for categorical_column in categorical_columns\n  ]\n\n  model = _wide_and_deep_classifier(\n      # TODO(b/139668410) replace with premade wide_and_deep keras model\n      wide_columns=indicator_column,\n      deep_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n  return model\n\n\ndef _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units):\n  """"""Build a simple keras wide and deep model.\n\n  Args:\n    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n      part of the model.\n    deep_columns: Feature columns for deep part of the model.\n    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n\n  Returns:\n    A Wide and Deep Keras model\n  """"""\n  # Following values are hard coded for simplicity in this example,\n  # However prefarably they should be passsed in as hparams.\n\n  # Keras needs the feature definitions at compile time.\n  # TODO(b/139081439): Automate generation of input layers from FeatureColumn.\n  input_layers = {\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n      for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  }\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_VOCAB_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_BUCKET_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in _transformed_names(_CATEGORICAL_FEATURE_KEYS)\n  })\n\n  # TODO(b/144500510): SparseFeatures for feature columns + Keras.\n  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n  for numnodes in dnn_hidden_units:\n    deep = tf.keras.layers.Dense(numnodes)(deep)\n  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n\n  output = tf.keras.layers.Dense(\n      1, activation=\'sigmoid\')(\n          tf.keras.layers.concatenate([deep, wide]))\n\n  model = tf.keras.Model(input_layers, output)\n  model.compile(\n      loss=\'binary_crossentropy\',\n      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n      metrics=[tf.keras.metrics.BinaryAccuracy()])\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX Transform will call this function.\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]),\n        _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_transformed_name(_LABEL_KEY)] = tf.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: TrainerFnArgs):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  # Number of nodes in the first layer of the DNN\n  first_dnn_layer_size = 100\n  num_dnn_layers = 4\n  dnn_decay_factor = 0.7\n\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 40)\n  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 40)\n\n  model = _build_keras_model(\n      # Construct layers sizes with exponetial decay\n      hidden_units=[\n          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n          for i in range(num_dnn_layers)\n      ])\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps)\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(model,\n                                    tf_transform_output).get_concrete_function(\n                                        tf.TensorSpec(\n                                            shape=[None],\n                                            dtype=tf.string,\n                                            name=\'examples\')),\n  }\n  model.save(fn_args.serving_model_dir, save_format=\'tf\', signatures=signatures)\n'"
tfx/examples/custom_components/hello_world/example/taxi_pipeline_hello.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nfrom hello_component import component\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import StatisticsGen\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'taxi_hello_pipeline\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(os.path.dirname(__file__), \'data\', \'simple\')\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(_taxi_root, \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input_base=examples)\n\n  hello = component.HelloComponent(\n      input_data=example_gen.outputs[\'examples\'], name=u\'HelloWorld\')\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=hello.outputs[\'output_data\'])\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[example_gen, hello, statistics_gen],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path))\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_hello.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          metadata_path=_metadata_path))\n'"
tfx/examples/custom_components/hello_world/example/taxi_pipeline_hello_e2e_test.py,6,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""E2E Tests for tfx.examples.custom_components_hello_world.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport taxi_pipeline_hello\nimport tensorflow as tf\n\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n\n\nclass TaxiPipelineHelloEndToEndTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TaxiPipelineHelloEndToEndTest, self).setUp()\n    self._test_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._pipeline_name = \'hello_test\'\n    self._data_root = os.path.join(os.path.dirname(__file__), \'..\', \'data\')\n    self._pipeline_root = os.path.join(self._test_dir, \'tfx\', \'pipelines\',\n                                       self._pipeline_name)\n    self._metadata_path = os.path.join(self._test_dir, \'tfx\', \'metadata\',\n                                       self._pipeline_name, \'metadata.db\')\n\n  def assertExecutedOnce(self, component: Text) -> None:\n    """"""Check the component is executed exactly once.""""""\n    component_path = os.path.join(self._pipeline_root, component)\n    self.assertTrue(tf.io.gfile.exists(component_path))\n    outputs = tf.io.gfile.listdir(component_path)\n    for output in outputs:\n      execution = tf.io.gfile.listdir(os.path.join(component_path, output))\n      self.assertEqual(1, len(execution))\n\n  def assertPipelineExecution(self) -> None:\n    self.assertExecutedOnce(\'CsvExampleGen\')\n    self.assertExecutedOnce(\'HelloComponent\')\n    self.assertExecutedOnce(\'StatisticsGen\')\n\n  def testTaxiPipelineHello(self):\n    BeamDagRunner().run(\n        taxi_pipeline_hello._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path))\n\n    self.assertTrue(tf.io.gfile.exists(self._metadata_path))\n    metadata_config = metadata.sqlite_metadata_connection_config(\n        self._metadata_path)\n    with metadata.Metadata(metadata_config) as m:\n      artifact_count = len(m.store.get_artifacts())\n      execution_count = len(m.store.get_executions())\n      self.assertGreaterEqual(artifact_count, execution_count)\n\n    self.assertPipelineExecution()\n\n    # Run pipeline again.\n    BeamDagRunner().run(\n        taxi_pipeline_hello._create_pipeline(\n            pipeline_name=self._pipeline_name,\n            data_root=self._data_root,\n            pipeline_root=self._pipeline_root,\n            metadata_path=self._metadata_path))\n\n    # Assert cache execution.\n    with metadata.Metadata(metadata_config) as m:\n      # Artifact count is unchanged.\n      self.assertEqual(artifact_count, len(m.store.get_artifacts()))\n\n    self.assertPipelineExecution()\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/hello_world/hello_component/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/hello_world/hello_component/component.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example of a Hello World TFX custom component.\n\nThis custom component simply reads tf.Examples from input and passes through as\noutput.  This is meant to serve as a kind of starting point example for creating\ncustom components.\n\nThis component along with other custom component related code will only serve as\nan example and will not be supported by TFX team.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\nfrom hello_component import executor\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ExecutionParameter\n\n\nclass HelloComponentSpec(types.ComponentSpec):\n  """"""ComponentSpec for Custom TFX Hello World Component.""""""\n\n  PARAMETERS = {\n      # These are parameters that will be passed in the call to\n      # create an instance of this component.\n      \'name\': ExecutionParameter(type=Text),\n  }\n  INPUTS = {\n      # This will be a dictionary with input artifacts, including URIs\n      \'input_data\': ChannelParameter(type=standard_artifacts.Examples),\n  }\n  OUTPUTS = {\n      # This will be a dictionary which this component will populate\n      \'output_data\': ChannelParameter(type=standard_artifacts.Examples),\n  }\n\n\nclass HelloComponent(base_component.BaseComponent):\n  """"""Custom TFX Hello World Component.\n\n  This custom component class consists of only a constructor.\n  """"""\n\n  SPEC_CLASS = HelloComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               input_data: types.Channel = None,\n               output_data: types.Channel = None,\n               name: Optional[Text] = None):\n    """"""Construct a HelloComponent.\n\n    Args:\n      input_data: A Channel of type `standard_artifacts.Examples`. This will\n        often contain two splits: \'train\', and \'eval\'.\n      output_data: A Channel of type `standard_artifacts.Examples`. This will\n        usually contain the same splits as input_data.\n      name: Optional unique name. Necessary if multiple Hello components are\n        declared in the same pipeline.\n    """"""\n    # output_data will contain a list of Channels for each split of the data,\n    # by default a \'train\' split and an \'eval\' split. Since HelloComponent\n    # passes the input data through to output, the splits in output_data will\n    # be the same as the splits in input_data, which were generated by the\n    # upstream component.\n    if not output_data:\n      examples_artifact = standard_artifacts.Examples()\n      examples_artifact.split_names = input_data.get()[0].split_names\n      output_data = channel_utils.as_channel([examples_artifact])\n\n    spec = HelloComponentSpec(input_data=input_data,\n                              output_data=output_data, name=name)\n    super(HelloComponent, self).__init__(spec=spec)\n'"
tfx/examples/custom_components/hello_world/hello_component/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for HelloComponent.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nfrom hello_component import component\nimport tensorflow as tf\nfrom tfx.types import artifact\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass HelloComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(HelloComponentTest, self).setUp()\n    self.name = \'HelloWorld\'\n\n  def testConstruct(self):\n    input_data = standard_artifacts.Examples()\n    input_data.split_names = json.dumps(artifact.DEFAULT_EXAMPLE_SPLITS)\n    output_data = standard_artifacts.Examples()\n    output_data.split_names = json.dumps(artifact.DEFAULT_EXAMPLE_SPLITS)\n    this_component = component.HelloComponent(\n        input_data=channel_utils.as_channel([input_data]),\n        output_data=channel_utils.as_channel([output_data]),\n        name=u\'Testing123\')\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     this_component.outputs[\'output_data\'].type_name)\n    artifact_collection = this_component.outputs[\'output_data\'].get()\n    for artifacts in artifact_collection:\n      split_list = json.loads(artifacts.split_names)\n      self.assertEqual(artifact.DEFAULT_EXAMPLE_SPLITS.sort(),\n                       split_list.sort())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/hello_world/hello_component/executor.py,1,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example of a Hello World TFX custom component.\n\nThis custom component simply passes examples through. This is meant to serve as\na kind of starting point example for creating custom components.\n\nThis component along with other custom component related code will only serve as\nan example and will not be supported by TFX team.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, List, Text\n\nimport tensorflow as tf\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Executor for HelloComponent.""""""\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Copy the input_data to the output_data.\n\n    For this example that is all that the Executor does.  For a different\n    custom component, this is where the real functionality of the component\n    would be included.\n\n    This component both reads and writes Examples, but a different component\n    might read and write artifacts of other types.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - input_data: A list of type `standard_artifacts.Examples` which will\n          often contain two splits, \'train\' and \'eval\'.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - output_data: A list of type `standard_artifacts.Examples` which will\n          usually contain the same splits as input_data.\n      exec_properties: A dict of execution properties, including:\n        - name: Optional unique name. Necessary iff multiple Hello components\n          are declared in the same pipeline.\n\n    Returns:\n      None\n\n    Raises:\n      OSError and its subclasses\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    split_to_instance = {}\n    for artifact in input_dict[\'input_data\']:\n      for split in json.loads(artifact.split_names):\n        uri = os.path.join(artifact.uri, split)\n        split_to_instance[split] = uri\n\n    for split, instance in split_to_instance.items():\n      input_dir = instance\n      output_dir = artifact_utils.get_split_uri(\n          output_dict[\'output_data\'], split)\n      for filename in tf.io.gfile.listdir(input_dir):\n        input_uri = os.path.join(input_dir, filename)\n        output_uri = os.path.join(output_dir, filename)\n        io_utils.copy_file(src=input_uri, dst=output_uri, overwrite=True)\n'"
tfx/examples/custom_components/hello_world/hello_component/version.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Contains the version string of custom HelloComponent for TFX.""""""\n\n# Note that setup.py uses this version.\n__version__ = \'0.1\'\n'"
tfx/examples/custom_components/presto_example_gen/example/taxi_pipeline_presto.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Chicago taxi example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\n\nimport absl\nfrom presto_component.component import PrestoExampleGen\nfrom proto import presto_config_pb2\n\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ModelValidator\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\n\n_pipeline_name = \'chicago_taxi_presto\'\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n# Presto configuration that corresponds with tutorial in README.md\n_presto_config = presto_config_pb2.PrestoConnConfig(\n    host=\'localhost\', port=8080, user=\'user\', catalog=\'hive\', schema=\'default\')\n# The query that extracts the Chicago taxi data examples from Presto, following\n# setup as described in the README.md\n_query = \'SELECT * FROM chicago_taxi_trips_parquet\'\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_taxi_root, \'taxi_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text,\n                     module_file: Text,\n                     presto_config: presto_config_pb2.PrestoConnConfig,\n                     query: Text, serving_model_dir: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  # Brings data into the pipeline or otherwise joins/converts training data\n  example_gen = PrestoExampleGen(presto_config, query=query)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=module_file,\n      transformed_examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n          evaluator_pb2.SingleSlicingSpec(\n              column_for_slicing=[\'trip_start_hour\'])\n      ]))\n\n  # Performs quality validation of a candidate model (compared to a baseline).\n  model_validator = ModelValidator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_validator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, evaluator, model_validator, pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python taxi_pipeline_presto.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          presto_config=_presto_config,\n          query=_query,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path))\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX PrestoExampleGen component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nfrom presto_component import executor\nfrom proto import presto_config_pb2\n\nfrom tfx import types\nfrom tfx.components.base import executor_spec\nfrom tfx.components.example_gen import component\nfrom tfx.components.example_gen import utils\nfrom tfx.proto import example_gen_pb2\n\n\nclass PrestoExampleGen(component._QueryBasedExampleGen):  # pylint: disable=protected-access\n  """"""Official TFX PrestoExampleGen component.\n\n  The Presto examplegen component takes a query, connection client\n  configuration, and generates train and eval examples for downsteam components.\n  """"""\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               conn_config: presto_config_pb2.PrestoConnConfig,\n               query: Optional[Text] = None,\n               input_config: Optional[example_gen_pb2.Input] = None,\n               output_config: Optional[example_gen_pb2.Output] = None,\n               example_artifacts: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Constructs a PrestoExampleGen component.\n\n    Args:\n      conn_config: Parameters for Presto connection client.\n      query: Presto sql string, query result will be treated as a single split,\n        can be overwritten by input_config.\n      input_config: An example_gen_pb2.Input instance with Split.pattern as\n        Presto sql string. If set, it overwrites the \'query\' arg, and allows\n        different queries per split.\n      output_config: An example_gen_pb2.Output instance, providing output\n        configuration. If unset, default splits will be \'train\' and \'eval\' with\n        size 2:1.\n      example_artifacts: Optional channel of \'ExamplesPath\' for output train and\n        eval examples.\n      instance_name: Optional unique instance name. Necessary if multiple\n        PrestoExampleGen components are declared in the same pipeline.\n\n    Raises:\n      RuntimeError: Only one of query and input_config should be set. Or\n      required host field in connection_config should be set.\n    """"""\n    if bool(query) == bool(input_config):\n      raise RuntimeError(\'Exactly one of query and input_config should be set.\')\n    if not bool(conn_config.host):\n      raise RuntimeError(\n          \'Required host field in connection config should be set.\')\n\n    input_config = input_config or utils.make_default_input_config(query)\n\n    packed_custom_config = example_gen_pb2.CustomConfig()\n    packed_custom_config.custom_config.Pack(conn_config)\n\n    output_config = output_config or utils.make_default_output_config(\n        input_config)\n\n    super(PrestoExampleGen, self).__init__(\n        input_config=input_config,\n        output_config=output_config,\n        custom_config=packed_custom_config,\n        example_artifacts=example_artifacts,\n        instance_name=instance_name)\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for presto_component.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom presto_component import component\nfrom proto import presto_config_pb2\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ComponentTest, self).setUp()\n    self.conn_config = presto_config_pb2.PrestoConnConfig(\n        host=\'localhost\', port=8080)\n\n  def _extract_conn_config(self, custom_config):\n    unpacked_custom_config = example_gen_pb2.CustomConfig()\n    json_format.Parse(custom_config, unpacked_custom_config)\n\n    conn_config = presto_config_pb2.PrestoConnConfig()\n    unpacked_custom_config.custom_config.Unpack(conn_config)\n    return conn_config\n\n  def testConstruct(self):\n    presto_example_gen = component.PrestoExampleGen(\n        self.conn_config, query=\'query\')\n    self.assertEqual(\n        self.conn_config,\n        self._extract_conn_config(\n            presto_example_gen.exec_properties[\'custom_config\']))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     presto_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = presto_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithOutputConfig(self):\n    presto_example_gen = component.PrestoExampleGen(\n        self.conn_config,\n        query=\'query\',\n        output_config=example_gen_pb2.Output(\n            split_config=example_gen_pb2.SplitConfig(splits=[\n                example_gen_pb2.SplitConfig.Split(name=\'train\', hash_buckets=2),\n                example_gen_pb2.SplitConfig.Split(name=\'eval\', hash_buckets=1),\n                example_gen_pb2.SplitConfig.Split(name=\'test\', hash_buckets=1)\n            ])))\n    self.assertEqual(\n        self.conn_config,\n        self._extract_conn_config(\n            presto_example_gen.exec_properties[\'custom_config\']))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     presto_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = presto_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testConstructWithInputConfig(self):\n    presto_example_gen = component.PrestoExampleGen(\n        self.conn_config,\n        input_config=example_gen_pb2.Input(splits=[\n            example_gen_pb2.Input.Split(name=\'train\', pattern=\'query1\'),\n            example_gen_pb2.Input.Split(name=\'eval\', pattern=\'query2\'),\n            example_gen_pb2.Input.Split(name=\'test\', pattern=\'query3\')\n        ]))\n    self.assertEqual(\n        self.conn_config,\n        self._extract_conn_config(\n            presto_example_gen.exec_properties[\'custom_config\']))\n    self.assertEqual(standard_artifacts.Examples.TYPE_NAME,\n                     presto_example_gen.outputs[\'examples\'].type_name)\n    artifact_collection = presto_example_gen.outputs[\'examples\'].get()\n    self.assertEqual(1, len(artifact_collection))\n    self.assertEqual([\'train\', \'eval\', \'test\'],\n                     artifact_utils.decode_split_names(\n                         artifact_collection[0].split_names))\n\n  def testBadConstruction(self):\n    empty_config = presto_config_pb2.PrestoConnConfig()\n    self.assertRaises(\n        RuntimeError,\n        component.PrestoExampleGen,\n        conn_config=empty_config,\n        query=\'\')\n\n    port_only_config = presto_config_pb2.PrestoConnConfig(port=8080)\n    self.assertRaises(\n        RuntimeError,\n        component.PrestoExampleGen,\n        conn_config=port_only_config,\n        query=\'\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/executor.py,12,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX PrestoExampleGen executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nfrom typing import Any, Dict, Iterable, List, Text, Tuple\n\nimport apache_beam as beam\nimport prestodb\nfrom proto import presto_config_pb2\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx import types\nfrom tfx.components.example_gen import base_example_gen_executor\nfrom tfx.proto import example_gen_pb2\n\n\n@beam.typehints.with_input_types(Text)\n@beam.typehints.with_output_types(beam.typehints.Iterable[Tuple[Text, Text,\n                                                                Any]])\nclass _ReadPrestoDoFn(beam.DoFn):\n  """"""Beam DoFn class that reads from Presto.\n\n  Attributes:\n    cursor: A prestodb.dbapi.Cursor object that reads records from Presto table.\n  """"""\n\n  def __init__(self, client: prestodb.dbapi.Connection):\n    self.cursor = client.cursor()\n\n  def process(self, query: Text) -> Iterable[Tuple[Text, Text, Any]]:\n    """"""Yields rows from query results.\n\n    Args:\n      query: A SQL query used to return results from Presto table.\n\n    Yields:\n      One row from the query result, represented by a list of tuples. Each tuple\n      contains information on column name, column data type, data.\n    """"""\n    self.cursor.execute(query)\n    rows = self.cursor.fetchall()\n    if rows:\n      cols = []\n      col_types = []\n      # Returns a list of (column_name, column_type, None, ...)\n      # https://github.com/prestodb/presto-python-client/blob/master/prestodb/dbapi.py#L199\n      for metadata in self.cursor.description:\n        cols.append(metadata[0])\n        col_types.append(metadata[1])\n\n      for r in rows:\n        yield zip(cols, col_types, r)\n\n  def teardown(self):\n    if self.cursor:\n      self.cursor.close()\n\n\ndef _deserialize_conn_config(\n    conn_config: presto_config_pb2.PrestoConnConfig\n) -> prestodb.dbapi.Connection:\n  """"""Deserializes Presto connection config to Presto client.\n\n  Args:\n    conn_config: Protobuf-encoded connection config for Presto client.\n\n  Returns:\n    A prestodb.dbapi.Connection instance initialized with user-supplied\n    parameters.\n  """"""\n  params = {\'host\': conn_config.host}  # Required field\n  # Only deserialize rest of parameters if set by user\n  if conn_config.HasField(\'port\'):\n    params[\'port\'] = conn_config.port\n  if conn_config.HasField(\'user\'):\n    params[\'user\'] = conn_config.user\n  if conn_config.HasField(\'source\'):\n    params[\'source\'] = conn_config.source\n  if conn_config.HasField(\'catalog\'):\n    params[\'catalog\'] = conn_config.catalog\n  if conn_config.HasField(\'schema\'):\n    params[\'schema\'] = conn_config.schema\n  if conn_config.HasField(\'http_scheme\'):\n    params[\'http_scheme\'] = conn_config.http_scheme\n  if conn_config.WhichOneof(\'opt_auth\'):\n    params[\'auth\'] = _deserialize_auth_config(conn_config)\n  if conn_config.HasField(\'max_attempts\'):\n    params[\'max_attempts\'] = conn_config.max_attempts\n  if conn_config.HasField(\'request_timeout\'):\n    params[\'request_timeout\'] = conn_config.request_timeout\n\n  return prestodb.dbapi.connect(**params)\n\n\ndef _deserialize_auth_config(\n    conn_config: presto_config_pb2.PrestoConnConfig\n) -> prestodb.auth.Authentication:\n  """"""Extracts from conn config the deserialized Presto Authentication class.\n\n  Args:\n    conn_config: Protobuf-encoded connection config for Presto client.\n\n  Returns:\n    A prestodb.auth.Authentication instance initialized with user-supplied\n    parameters.\n\n  Raises:\n    RuntimeError: if authentication type is not currently supported.\n  """"""\n  if conn_config.HasField(\'basic_auth\'):\n    return prestodb.auth.BasicAuthentication(conn_config.basic_auth.username,\n                                             conn_config.basic_auth.password)\n    # TODO(b/140266796): Support KerberosAuth.\n  else:\n    raise RuntimeError(\'Authentication type not supported.\')\n\n\ndef _row_to_example(\n    instance: Iterable[Tuple[Text, Text, Any]]) -> tf.train.Example:\n  """"""Convert presto result row to tf example.""""""\n  feature = {}\n  for key, data_type, value in instance:\n    if value is None:\n      feature[key] = tf.train.Feature()\n    elif data_type in {\'tinyint\', \'smallint\', \'integer\', \'bigint\'}:\n      feature[key] = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[value]))\n    elif data_type in {\'real\', \'double\', \'decimal\'}:\n      feature[key] = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[value]))\n    elif data_type in {\'varchar\', \'char\'}:\n      feature[key] = tf.train.Feature(\n          bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(value)]))\n    elif data_type in {\'timestamp\'}:\n      value = int(datetime.datetime.fromisoformat(value).timestamp())\n      feature[key] = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[value]))\n    else:\n      # TODO(b/140266796): support more types\n      # https://prestodb.github.io/docs/current/language/types\n      raise RuntimeError(\n          \'Presto column type {} is not supported.\'.format(data_type))\n  return tf.train.Example(features=tf.train.Features(feature=feature))\n\n\n@beam.ptransform_fn\n@beam.typehints.with_input_types(beam.Pipeline)\n@beam.typehints.with_output_types(tf.train.Example)\ndef _PrestoToExample(  # pylint: disable=invalid-name\n    pipeline: beam.Pipeline,\n    input_dict: Dict[Text, List[types.Artifact]],  # pylint: disable=unused-argument\n    exec_properties: Dict[Text, Any],\n    split_pattern: Text) -> beam.pvalue.PCollection:\n  """"""Read from Presto and transform to TF examples.\n\n  Args:\n    pipeline: beam pipeline.\n    input_dict: Input dict from input key to a list of Artifacts.\n    exec_properties: A dict of execution properties.\n    split_pattern: Split.pattern in Input config, a Presto sql string.\n\n  Returns:\n    PCollection of TF examples.\n  """"""\n  conn_config = example_gen_pb2.CustomConfig()\n  json_format.Parse(exec_properties[\'custom_config\'], conn_config)\n  presto_config = presto_config_pb2.PrestoConnConfig()\n  conn_config.custom_config.Unpack(presto_config)\n\n  client = _deserialize_conn_config(presto_config)\n  return (pipeline\n          | \'Query\' >> beam.Create([split_pattern])\n          | \'QueryTable\' >> beam.ParDo(_ReadPrestoDoFn(client))\n          | \'ToTFExample\' >> beam.Map(_row_to_example))\n\n\nclass Executor(base_example_gen_executor.BaseExampleGenExecutor):\n  """"""Generic TFX PrestoExampleGen executor.""""""\n\n  def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n    """"""Returns PTransform for Presto to TF examples.""""""\n    return _PrestoToExample\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/executor_test.py,13,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for presto_component.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\n\nimport apache_beam as beam\nfrom apache_beam.testing import util\nimport mock\nfrom presto_component import executor\nimport prestodb\nfrom proto import presto_config_pb2\nimport tensorflow as tf\n\nfrom google.protobuf import json_format\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass _MockReadPrestoDoFn(beam.DoFn):\n\n  def __init__(self, client):\n    pass\n\n  def process(self, query):\n    for i in range(10000):\n      yield {(\'i\', \'integer\', None if random.randrange(10) == 0 else i),\n             (\'f\', \'double\', None if random.randrange(10) == 0 else float(i)),\n             (\'s\', \'varchar\', None if random.randrange(10) == 0 else str(i))}\n\n\nclass _MockReadPrestoDoFn2(beam.DoFn):\n\n  def __init__(self, client):\n    pass\n\n  def process(self, query):\n    yield {(\'i\', \'integer\', 1), (\'f\', \'double\', 2.0), (\'s\', \'varchar\', \'abc\')}\n\n\ndef _mock_deserialize_conn_config(input_config):  # pylint: disable=invalid-name, unused-argument\n  return prestodb.dbapi.connect(\'localhost\')\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def testDeserializeConnConfig(self):\n    conn_config = presto_config_pb2.PrestoConnConfig(\n        host=\'presto.localhost\', max_attempts=10)\n\n    deseralized_conn = executor._deserialize_conn_config(conn_config)\n    truth_conn = prestodb.dbapi.connect(\'presto.localhost\', max_attempts=10)\n    self.assertEqual(truth_conn.host, deseralized_conn.host)\n    self.assertEqual(truth_conn.port,\n                     deseralized_conn.port)  # test for default port value\n    self.assertEqual(truth_conn.auth,\n                     deseralized_conn.auth)  # test for default auth value\n    self.assertEqual(truth_conn.max_attempts, deseralized_conn.max_attempts)\n\n  @mock.patch.multiple(\n      executor,\n      _ReadPrestoDoFn=_MockReadPrestoDoFn2,\n      _deserialize_conn_config=_mock_deserialize_conn_config,\n  )\n  def testPrestoToExample(self):\n    with beam.Pipeline() as pipeline:\n      examples = (\n          pipeline | \'ToTFExample\' >> executor._PrestoToExample(\n              input_dict={},\n              exec_properties={\n                  \'input_config\':\n                      json_format.MessageToJson(\n                          example_gen_pb2.Input(),\n                          preserving_proto_field_name=True),\n                  \'custom_config\':\n                      json_format.MessageToJson(\n                          example_gen_pb2.CustomConfig(),\n                          preserving_proto_field_name=True)\n              },\n              split_pattern=\'SELECT i, f, s FROM `fake`\'))\n\n      feature = {}\n      feature[\'i\'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[1]))\n      feature[\'f\'] = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[2.0]))\n      feature[\'s\'] = tf.train.Feature(\n          bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(\'abc\')]))\n      example_proto = tf.train.Example(\n          features=tf.train.Features(feature=feature))\n      util.assert_that(examples, util.equal_to([example_proto]))\n\n  @mock.patch.multiple(\n      executor,\n      _ReadPrestoDoFn=_MockReadPrestoDoFn,\n      _deserialize_conn_config=_mock_deserialize_conn_config,\n  )\n  def testDo(self):\n    output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    # Create output dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = output_data_dir\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    output_dict = {\'examples\': [examples]}\n\n    # Create exe properties.\n    exec_properties = {\n        \'input_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Input(splits=[\n                    example_gen_pb2.Input.Split(\n                        name=\'bq\', pattern=\'SELECT i, f, s FROM `fake`\'),\n                ]),\n                preserving_proto_field_name=True),\n        \'custom_config\':\n            json_format.MessageToJson(example_gen_pb2.CustomConfig()),\n        \'output_config\':\n            json_format.MessageToJson(\n                example_gen_pb2.Output(\n                    split_config=example_gen_pb2.SplitConfig(splits=[\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'train\', hash_buckets=2),\n                        example_gen_pb2.SplitConfig.Split(\n                            name=\'eval\', hash_buckets=1)\n                    ]))),\n    }\n\n    # Run executor.\n    presto_example_gen = executor.Executor()\n    presto_example_gen.Do({}, output_dict, exec_properties)\n\n    # Check Presto example gen outputs.\n    train_output_file = os.path.join(examples.uri, \'train\',\n                                     \'data_tfrecord-00000-of-00001.gz\')\n    eval_output_file = os.path.join(examples.uri, \'eval\',\n                                    \'data_tfrecord-00000-of-00001.gz\')\n    self.assertTrue(tf.io.gfile.exists(train_output_file))\n    self.assertTrue(tf.io.gfile.exists(eval_output_file))\n    self.assertGreater(\n        tf.io.gfile.GFile(train_output_file).size(),\n        tf.io.gfile.GFile(eval_output_file).size())\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/presto_example_gen/presto_component/version.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Contains the version string of custom PrestoExampleGen for TFX.""""""\n\n# Note that setup.py uses this version.\n__version__ = \'0.1\'\n'"
tfx/examples/custom_components/presto_example_gen/proto/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/slack/example/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/slack/example/taxi_pipeline_slack.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example pipeline to demonstrate custom TFX component.\n\nThis example consists of standard TFX components as well as a custom TFX\ncomponent requesting for manual review through Slack.\n\nThis example along with the custom `SlackComponent` will only serve as an\nexample and will not be supported by TFX team.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\n\nfrom slack_component.component import SlackComponent\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ModelValidator\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_runner import BeamRunner\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils.dsl_utils import csv_input\n\n# This example assumes that the taxi data is stored in ~/taxi/data and the\n# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n_taxi_root = os.path.join(os.environ[\'HOME\'], \'taxi\')\n_data_root = os.path.join(_taxi_root, \'data/simple\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_taxi_module_file = os.path.join(_taxi_root, \'taxi_utils_slack.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model/taxi_slack\')\n# Slack channel to push the model notifications to.\n_slack_channel_id = \'my-channel-id\'\n# Slack token to set up connection.\n_slack_token = os.environ[\'SLACK_BOT_TOKEN\']\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_name = \'chicago_taxi_slack\'\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n_metadata_db_root = os.path.join(_tfx_root, \'metadata\', _pipeline_name)\n_log_root = os.path.join(_tfx_root, \'logs\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\ndef _create_pipeline():\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = csv_input(_data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=_taxi_module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      module_file=_taxi_module_file,\n      examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n          evaluator_pb2.SingleSlicingSpec(\n              column_for_slicing=[\'trip_start_hour\'])\n      ]))\n\n  # Performs quality validation of a candidate model (compared to a baseline).\n  model_validator = ModelValidator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # This custom component serves as a bridge between pipeline and human model\n  # reviewers to enable review-and-push workflow in model development cycle. It\n  # utilizes Slack API to send message to user-defined Slack channel with model\n  # URI info and wait for go / no-go decision from the same Slack channel:\n  #   * To approve the model, users need to reply the thread sent out by the bot\n  #     started by SlackComponent with \'lgtm\' or \'approve\'.\n  #   * To reject the model, users need to reply the thread sent out by the bot\n  #     started by SlackComponent with \'decline\' or \'reject\'.\n  slack_validator = SlackComponent(\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_validator.outputs[\'blessing\'],\n      slack_token=_slack_token,\n      slack_channel_id=_slack_channel_id,\n      timeout_sec=3600,\n  )\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=slack_validator.outputs[\'slack_blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=_serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=_pipeline_name,\n      pipeline_root=_pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, evaluator, model_validator, slack_validator, pusher\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          _metadata_db_root),\n  )\n\n\nif __name__ == \'__main__\':\n  BeamRunner().run(_create_pipeline())\n'"
tfx/examples/custom_components/slack/example/taxi_pipeline_slack_kubeflow.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example pipeline to demonstrate custom TFX component.\n\nThis example consists of standard TFX components as well as a custom TFX\ncomponent requesting for manual review through Slack.\n\nThis example along with the custom `SlackComponent` will only serve as an\nexample and will not be supported by TFX team.\n\nThis example runs in Kubeflow with Google Cloud services..\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\n\nfrom slack_component.component import SlackComponent\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ModelValidator\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.kubeflow import kubeflow_dag_runner\nfrom tfx.proto import evaluator_pb2\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils.dsl_utils import csv_input\n\n# This example assumes that the taxi data is stored in _input_bucket/data/simple\n# and the taxi utility function is in example/taxi_utils_slack.py.\n# Feel free to customize this as needed.\n_input_bucket = \'gs://my-bucket\'\n_output_bucket = \'gs://my-bucket\'\n_taxi_root = __file__\n_data_root = os.path.join(_input_bucket, \'data\', \'simple\')\n\n\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_taxi_trainer_func = \'example.taxi_utils_slack.trainer_fn\'\n_taxi_transformer_func = \'example.taxi_utils_slack.preprocessing_fn\'\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_taxi_root, \'serving_model/taxi_slack\')\n# Slack channel to push the model notifications to.\n_slack_channel_id = \'my-channel-id\'\n# Slack token to set up connection.\n_slack_token = os.environ[\'SLACK_BOT_TOKEN\']\n\n# Directory and data locations.  This example assumes all of the chicago taxi\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'/tfx\')\n_pipeline_name = \'chicago_taxi_slack_kubeflow\'\n_pipeline_root = os.path.join(_input_bucket, _pipeline_name)\n_log_root = os.path.join(_tfx_root, \'logs\')\n\n# Airflow-specific configs; these will be passed directly to airflow\n_airflow_config = {\n    \'schedule_interval\': None,\n    \'start_date\': datetime.datetime(2019, 1, 1),\n}\n\n\ndef _create_pipeline():\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n  examples = csv_input(_data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(statistics=statistics_gen.outputs[\'statistics\'])\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      preprocessing_fn=_taxi_transformer_func)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer = Trainer(\n      trainer_fn=_taxi_trainer_func,\n      examples=transform.outputs[\'transformed_examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      transform_graph=transform.outputs[\'transform_graph\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n          evaluator_pb2.SingleSlicingSpec(\n              column_for_slicing=[\'trip_start_hour\'])\n      ]))\n\n  # Performs quality validation of a candidate model (compared to a baseline).\n  model_validator = ModelValidator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # This custom component serves as a bridge between pipeline and human model\n  # reviewers to enable review-and-push workflow in model development cycle. It\n  # utilizes Slack API to send message to user-defined Slack channel with model\n  # URI info and wait for go / no-go decision from the same Slack channel:\n  #   * To approve the model, users need to reply the thread sent out by the bot\n  #     started by SlackComponent with \'lgtm\' or \'approve\'.\n  #   * To reject the model, users need to reply the thread sent out by the bot\n  #     started by SlackComponent with \'decline\' or \'reject\'.\n  slack_validator = SlackComponent(\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_validator.outputs[\'blessing\'],\n      slack_token=_slack_token,\n      slack_channel_id=_slack_channel_id,\n      timeout_sec=3600,\n  )\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=slack_validator.outputs[\'slack_blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=_serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=_pipeline_name,\n      pipeline_root=_pipeline_root,\n      components=[\n          example_gen, statistics_gen, schema_gen, example_validator, transform,\n          trainer, evaluator, model_validator, slack_validator, pusher\n      ],\n      enable_cache=True,\n  )\n\n\nif __name__ == \'__main__\':\n  # Metadata config. The defaults works work with the installation of\n  # KF Pipelines using Kubeflow. If installing KF Pipelines using the\n  # lightweight deployment option, you may need to override the defaults.\n  metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n\n  # This pipeline automatically injects the Kubeflow TFX image if the\n  # environment variable \'KUBEFLOW_TFX_IMAGE\' is defined. Currently, the tfx\n  # cli tool exports the environment variable to pass to the pipelines.\n  tfx_image = os.environ.get(\'KUBEFLOW_TFX_IMAGE\', None)\n\n  runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n      kubeflow_metadata_config=metadata_config,\n      # Specify custom docker image to use.\n      tfx_image=tfx_image\n  )\n\n  kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n      _create_pipeline())\n'"
tfx/examples/custom_components/slack/example/taxi_utils_slack.py,30,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include taxi pipeline functions and necesasry utils.\n\nFor a TFX pipeline to successfully run, a preprocessing_fn and a\n_build_estimator function needs to be provided.  This file contains both.\n\nThis file is equivalent to examples/chicago_taxi/trainer/model.py and\nexamples/chicago_taxi/preprocess.py.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform.beam.tft_beam_io import transform_fn_io\nfrom tensorflow_transform.saved import saved_transform_io\nfrom tensorflow_transform.tf_metadata import metadata_io\nfrom tensorflow_transform.tf_metadata import schema_utils\n\n# Categorical features are assumed to each have a maximum value in the dataset.\n_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n\n_CATEGORICAL_FEATURE_KEYS = [\n    \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\',\n    \'pickup_census_tract\', \'dropoff_census_tract\', \'pickup_community_area\',\n    \'dropoff_community_area\'\n]\n\n_DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n\n# Number of buckets used by tf.transform for encoding each feature.\n_FEATURE_BUCKET_COUNT = 10\n\n_BUCKET_FEATURE_KEYS = [\n    \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n    \'dropoff_longitude\'\n]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n_VOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n_OOV_SIZE = 10\n\n_VOCAB_FEATURE_KEYS = [\n    \'payment_type\',\n    \'company\',\n]\n\n# Keys\n_LABEL_KEY = \'tips\'\n_FARE_KEY = \'fare\'\n\n\ndef _transformed_name(key):\n  return key + \'_xf\'\n\n\ndef _transformed_names(keys):\n  return [_transformed_name(key) for key in keys]\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn():\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.compat.v1.TFRecordReader(\n      options=tf.io.TFRecordOptions(\n          compression_type=tf.compat.v1.python_io.TFRecordCompressionType.GZIP))\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.compat.v1.sparse_to_dense(x.indices, [x.dense_shape[0], 1], x.values,\n                                   default_value),\n      axis=1)\n\n\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in _DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in _VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=_VOCAB_SIZE,\n        num_oov_buckets=_OOV_SIZE)\n\n  for key in _BUCKET_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n\n  for key in _CATEGORICAL_FEATURE_KEYS:\n    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n\n\ndef _build_estimator(config, hidden_units=None, warm_start_from=None):\n  """"""Build an estimator for predicting the tipping behavior of taxi riders.\n\n  Args:\n    config: tf.contrib.learn.RunConfig defining the runtime environment for the\n      estimator (including model_dir).\n    hidden_units: [int], the layer sizes of the DNN (input layer first)\n    warm_start_from: Optional directory to warm start from.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(\n          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n              _MAX_CATEGORICAL_FEATURE_VALUES)\n  ]\n  return tf.estimator.DNNLinearCombinedClassifier(\n      config=config,\n      linear_feature_columns=categorical_columns,\n      dnn_feature_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n      warm_start_from=warm_start_from)\n\n\ndef _example_serving_receiver_fn(transform_output, schema):\n  """"""Build the serving in inputs.\n\n  Args:\n    transform_output: directory in which the tf-transform model was written\n      during the preprocessing step.\n    schema: the schema of the input data.\n\n  Returns:\n    Tensorflow graph which parses examples, applying tf-transform to them.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  _, transformed_features = (\n      saved_transform_io.partially_apply_saved_transform(\n          os.path.join(transform_output, transform_fn_io.TRANSFORM_FN_DIR),\n          serving_input_receiver.features))\n\n  return tf.estimator.export.ServingInputReceiver(\n      transformed_features, serving_input_receiver.receiver_tensors)\n\n\ndef _eval_input_receiver_fn(transform_output, schema):\n  """"""Build everything needed for the tf-model-analysis to run the model.\n\n  Args:\n    transform_output: directory in which the tf-transform model was written\n      during the preprocessing step.\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Tensorflow graph which parses raw untransformed features, applies the\n        tf-transform preprocessing operators.\n      - Set of raw, untransformed features.\n      - Label against which predictions will be compared.\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  serialized_tf_example = tf.compat.v1.placeholder(\n      dtype=tf.string, shape=[None], name=\'input_example_tensor\')\n\n  # Add a parse_example operator to the tensorflow graph, which will parse\n  # raw, untransformed, tf examples.\n  features = tf.io.parse_example(\n      serialized=serialized_tf_example, features=raw_feature_spec)\n\n  # Now that we have our raw examples, process them through the tf-transform\n  # function computed during the preprocessing step.\n  _, transformed_features = (\n      saved_transform_io.partially_apply_saved_transform(\n          os.path.join(transform_output, transform_fn_io.TRANSFORM_FN_DIR),\n          features))\n\n  # The key name MUST be \'examples\'.\n  receiver_tensors = {\'examples\': serialized_tf_example}\n\n  # NOTE: Model is driven by transformed features (since training works on the\n  # materialized output of TFT, but slicing will happen on raw features.\n  features.update(transformed_features)\n\n  return tfma.export.EvalInputReceiver(\n      features=features,\n      receiver_tensors=receiver_tensors,\n      labels=transformed_features[_transformed_name(_LABEL_KEY)])\n\n\ndef _input_fn(filenames, transform_output, batch_size=200):\n  """"""Generates features and labels for training or evaluation.\n\n  Args:\n    filenames: [str] list of CSV files to read data from.\n    transform_output: directory in which the tf-transform model was written\n      during the preprocessing step.\n    batch_size: int First dimension size of the Tensors returned by input_fn\n\n  Returns:\n    A (features, indices) tuple where features is a dictionary of\n      Tensors, and indices is a single Tensor of label indices.\n  """"""\n  metadata_dir = os.path.join(transform_output,\n                              transform_fn_io.TRANSFORMED_METADATA_DIR)\n  transformed_metadata = metadata_io.read_metadata(metadata_dir)\n  transformed_feature_spec = transformed_metadata.schema.as_feature_spec()\n\n  transformed_features = tf.contrib.learn.io.read_batch_features(\n      filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn)\n\n  # We pop the label because we do not want to use it as a feature while we\'re\n  # training.\n  return transformed_features, transformed_features.pop(\n      _transformed_name(_LABEL_KEY))\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  # Number of nodes in the first layer of the DNN\n  first_dnn_layer_size = 100\n  num_dnn_layers = 4\n  dnn_decay_factor = 0.7\n\n  train_batch_size = 40\n  eval_batch_size = 40\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      trainer_fn_args.transform_output,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      trainer_fn_args.transform_output,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n      train_input_fn,\n      max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.transform_output, schema)\n\n  exporter = tf.estimator.FinalExporter(\'chicago-taxi\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'chicago-taxi-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=1)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n\n  estimator = _build_estimator(\n      # Construct layers sizes with exponetial decay\n      hidden_units=[\n          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n          for i in range(num_dnn_layers)\n      ],\n      config=run_config,\n      warm_start_from=trainer_fn_args.base_model)\n\n  # Create an input receiver for TFMA processing\n  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.transform_output, schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': receiver_fn\n  }\n'"
tfx/examples/custom_components/slack/slack_component/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/examples/custom_components/slack/slack_component/component.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example of a TFX custom component integrating with slack.\n\nThis component along with other custom component related code will only serve as\nan example and will not be supported by TFX team.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text\n\nfrom slack_component import executor\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ExecutionParameter\n\n\nclass SlackComponentSpec(types.ComponentSpec):\n  """"""ComponentSpec for Custom TFX Slack Component.""""""\n\n  PARAMETERS = {\n      \'slack_token\': ExecutionParameter(type=Text),\n      \'slack_channel_id\': ExecutionParameter(type=Text),\n      \'timeout_sec\': ExecutionParameter(type=int),\n  }\n  INPUTS = {\n      \'model\': ChannelParameter(type=standard_artifacts.Model),\n      \'model_blessing\': ChannelParameter(type=standard_artifacts.ModelBlessing),\n  }\n  OUTPUTS = {\n      \'slack_blessing\': ChannelParameter(type=standard_artifacts.ModelBlessing),\n  }\n\n\nclass SlackComponent(base_component.BaseComponent):\n  """"""Custom TFX Slack Component.\n\n  This custom component serves as a bridge between TFX pipeline and human model\n  reviewers to enable review-and-push workflow in model development cycle. It\n  utilizes Slack API to send message to user-defined Slack channel with model\n  URI info and wait for go / no-go decision from the same Slack channel:\n    * To approve the model, a user need to reply the thread sent out by the bot\n      started by SlackComponent with \'lgtm\' or \'approve\'.\n    * To reject the model, a user need to reply the thread sent out by the bot\n      started by SlackComponent with \'decline\' or \'reject\'.\n\n  If the model is approved, an artifact will be created in ML metadata. It will\n  be materialized as a file named \'BLESSED\' in the directory specified by the\n  URI of \'slack_blessing\' artifact.\n  If the model is rejected, an artifact will be created in ML metadata. It will\n  be materialized as a file named \'NOT_BLESSED\' in the directory specified by\n  the URI of \'slack_blessing\' channel.\n  If no message indicating approve or reject was is received within given within\n  timeout_sec, component will error out. This ensures that model will not be\n  pushed and the validation is still retry-able.\n\n  The output artifact might contain the following custom properties:\n    - blessed: integer value indicating whether the model is blessed\n    - slack_decision_maker: the user id that made the decision.\n    - slack_decision_message: the message of the decision\n    - slack_decision_channel: the slack channel the decision is made on\n    - slack_decision_thread: the slack thread the decision is made on\n  """"""\n\n  SPEC_CLASS = SlackComponentSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               model: types.Channel,\n               model_blessing: types.Channel,\n               slack_token: Text,\n               slack_channel_id: Text,\n               timeout_sec: int,\n               slack_blessing: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct a SlackComponent.\n\n    Args:\n      model: A Channel of type `standard_artifacts.Model`, usually produced by\n        a Trainer component.\n      model_blessing: A Channel of type `standard_artifacts.ModelBlessing`,\n        usually produced by a ModelValidator component.\n      slack_token: A token used for setting up connection with Slack server.\n      slack_channel_id: Slack channel id to communicate on.\n      timeout_sec: Seconds to wait for response before default to reject.\n      slack_blessing: Optional output channel of type\n        `standard_artifacts.ModelBlessing` with result of blessing; will be\n        created for you if not specified.\n      instance_name: Optional unique instance name. Necessary if multiple Pusher\n        components are declared in the same pipeline.\n    """"""\n    slack_blessing = slack_blessing or types.Channel(\n        type=standard_artifacts.ModelBlessing,\n        artifacts=[standard_artifacts.ModelBlessing()])\n    spec = SlackComponentSpec(\n        slack_token=slack_token,\n        slack_channel_id=slack_channel_id,\n        timeout_sec=timeout_sec,\n        model=model,\n        model_blessing=model_blessing,\n        slack_blessing=slack_blessing)\n    super(SlackComponent, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/examples/custom_components/slack/slack_component/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for slack component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom slack_component import component\nimport tensorflow as tf\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ComponentTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ComponentTest, self).setUp()\n    self._model_export = channel_utils.as_channel([standard_artifacts.Model()])\n    self._model_blessing = channel_utils.as_channel(\n        [standard_artifacts.ModelBlessing()])\n\n  def testConstruct(self):\n    slack_component = component.SlackComponent(\n        model=self._model_export,\n        model_blessing=self._model_blessing,\n        slack_token=\'token\',\n        slack_channel_id=\'slack_channel_id\',\n        timeout_sec=3600)\n    self.assertEqual(standard_artifacts.ModelBlessing.TYPE_NAME,\n                     slack_component.outputs[\'slack_blessing\'].type_name)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/slack/slack_component/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Example of a TFX custom executor integrating with slack.\n\nThis executor along with other custom component related code will only serve as\nan example and will not be supported by TFX team.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport signal\nfrom typing import Any, Dict, List, NamedTuple, Text\n\nimport absl\nfrom slackclient import SlackClient\n\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.components.util import model_utils\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\n\n# Case-insensitive text messages that are accepted as signal for approving a\n# model.\n_APPROVE_TEXT = [\'lgtm\', \'approve\']\n# Case-insensitive text messages that are accepted as signal for rejecting a\n# model.\n_DECLINE_TEXT = [\'decline\', \'reject\']\n# Template for notifying model review\n_NOTIFY_MODEL_REVIEW_TEMPLATE = """"""\nPlease review the model in the following URI: {}""""""\n# Template for notifying valid model review reply\n_NOTIFY_CORRECT_REPLY_TEMPLATE = """"""\nUnrecognized text: ""{{}}"", please use one of the following to approve:\n{}\nor one of the following to reject:\n{}"""""".format(_APPROVE_TEXT, _DECLINE_TEXT)\n\n\nclass Timeout(object):\n  """"""Helper class for handle function timeout.""""""\n\n  def __init__(self, seconds):\n    self.seconds = seconds\n\n  def handle_timeout(self, unused_signum, unused_frame):\n    msg = \'Did not get model evaluation result in %d seconds\' % self.seconds\n    absl.logging.warning(msg)\n    raise TimeoutError(msg)  # pylint: disable=undefined-variable\n\n  def __enter__(self):\n    signal.signal(signal.SIGALRM, self.handle_timeout)\n    signal.alarm(self.seconds)\n\n  def __exit__(self, unused_type, unused_value, unused_traceback):\n    signal.alarm(0)\n\n\n# NamedTuple for slack response.\n_SlackResponse = NamedTuple(\n    \'_SlackResponse\',\n    [\n        # Whether the model is approved.\n        (\'approved\', bool),\n        # The user that made the decision.\n        (\'user_id\', Text),\n        # The decision message.\n        (\'message\', Text),\n        # The slack channel that the decision is made on.\n        (\'slack_channel_id\', Text),\n        # The slack thread that the decision is made on.\n        (\'thread_ts\', Text)\n    ])\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""Executor for Slack component.""""""\n\n  def _is_valid_message(self, payload: Dict[Text, Any],\n                        expected_slack_channel_id: Text,\n                        expected_thread_timestamp: int):\n    """"""Evaluates whether a payload is valid.\n\n    A payload is considered valid iff:\n      a. it is from the expected slack channel\n      b. it is from the expected slack thread\n      c. it contains message info\n\n    Args:\n      payload: the payload to be evaluated\n      expected_slack_channel_id: the id of the expected slack channel\n      expected_thread_timestamp: the timestamp of the expected slack thread\n\n    Returns:\n\n    """"""\n    return (payload.get(\'type\') == \'message\' and\n            payload.get(\'channel\') == expected_slack_channel_id and\n            payload.get(\'text\') and\n            payload.get(\'thread_ts\') == expected_thread_timestamp)\n\n  def _fetch_slack_blessing(self, slack_token: Text, slack_channel_id: Text,\n                            model_uri: Text) -> _SlackResponse:\n    """"""Send message via Slack channel and wait for response.\n\n    Args:\n      slack_token: The user-defined function to obtain token to send and receive\n        messages.\n      slack_channel_id: The id of the Slack channel to send and receive\n        messages.\n      model_uri: The URI of the model waiting for human review.\n\n    Returns:\n      A _SlackResponse instance.\n\n    Raises:\n      ConnectionError:\n        When connection to slack server cannot be established.\n\n    """"""\n    sc = SlackClient(slack_token)\n    msg = _NOTIFY_MODEL_REVIEW_TEMPLATE.format(model_uri)\n    ts = 0\n    if not sc.rtm_connect():\n      msg = \'Cannot connect to slack server with given token\'\n      absl.logging.error(msg)\n      raise ConnectionError(msg)  # pylint: disable=undefined-variable\n\n    sc.rtm_send_message(slack_channel_id, message=msg)\n\n    while sc.server.connected:\n      payload_list = sc.rtm_read()\n      if not payload_list:\n        continue\n\n      for payload in payload_list:\n        if payload.get(\'ok\') and payload.get(\'reply_to\') == 0 and not ts:\n          ts = payload[\'ts\']\n          continue\n        if not self._is_valid_message(payload, slack_channel_id, ts):\n          continue\n        if payload.get(\'text\').lower() in _APPROVE_TEXT:\n          absl.logging.info(\'User %s approves the model located at %s\',\n                            payload.get(\'user\'), model_uri)\n          return _SlackResponse(True, payload.get(\'user\'), payload.get(\'text\'),\n                                slack_channel_id, str(ts))\n        elif payload.get(\'text\').lower() in _DECLINE_TEXT:\n          absl.logging.info(\'User %s declines the model located at %s\',\n                            payload.get(\'user\'), model_uri)\n          return _SlackResponse(False, payload.get(\'user\'), payload.get(\'text\'),\n                                slack_channel_id, str(ts))\n        else:\n          unrecognized_text = payload.get(\'text\')\n          absl.logging.info(\'Unrecognized response: %s\', unrecognized_text)\n          sc.rtm_send_message(\n              slack_channel_id,\n              message=_NOTIFY_CORRECT_REPLY_TEMPLATE.format(unrecognized_text),\n              thread=ts)\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    """"""Get human review result on a model through Slack channel.\n\n    Args:\n      input_dict: Input dict from input key to a list of artifacts, including:\n        - model_export: exported model from trainer.\n        - model_blessing: model blessing path from evaluator.\n      output_dict: Output dict from key to a list of artifacts, including:\n        - slack_blessing: model blessing result.\n      exec_properties: A dict of execution properties, including:\n        - slack_token: Token used to setup connection with slack server.\n        - slack_channel_id: The id of the Slack channel to send and receive\n          messages.\n        - timeout_sec: How long do we wait for response, in seconds.\n\n    Returns:\n      None\n\n    Raises:\n      TimeoutError:\n        When there is no decision made within timeout_sec.\n      ConnectionError:\n        When connection to slack server cannot be established.\n\n    """"""\n    self._log_startup(input_dict, output_dict, exec_properties)\n\n    # Fetch execution properties from exec_properties dict.\n    slack_token = exec_properties[\'slack_token\']\n    slack_channel_id = exec_properties[\'slack_channel_id\']\n    timeout_sec = exec_properties[\'timeout_sec\']\n\n    # Fetch input URIs from input_dict.\n    model_export_uri = artifact_utils.get_single_uri(input_dict[\'model\'])\n    model_blessing = artifact_utils.get_single_instance(\n        input_dict[\'model_blessing\'])\n\n    # Fetch output artifact from output_dict.\n    slack_blessing = artifact_utils.get_single_instance(\n        output_dict[\'slack_blessing\'])\n\n    # We only consider a model as blessed if both of the following conditions\n    # are met:\n    # - The model is blessed by evaluator. This is determined by looking\n    #   for file named \'BLESSED\' from the output from Evaluator.\n    # - The model is blessed by a human reviewer. This logic is in\n    #   _fetch_slack_blessing().\n    slack_response = None\n    with Timeout(timeout_sec):\n      if model_utils.is_model_blessed(model_blessing):\n        slack_response = self._fetch_slack_blessing(slack_token,\n                                                    slack_channel_id,\n                                                    model_export_uri)\n\n    # If model is blessed, write an empty file named \'BLESSED\' in the assigned\n    # output path. Otherwise, write an empty file named \'NOT_BLESSED\' instead.\n    if slack_response and slack_response.approved:\n      io_utils.write_string_file(\n          os.path.join(slack_blessing.uri, \'BLESSED\'), \'\')\n      slack_blessing.set_int_custom_property(\'blessed\', 1)\n    else:\n      io_utils.write_string_file(\n          os.path.join(slack_blessing.uri, \'NOT_BLESSED\'), \'\')\n      slack_blessing.set_int_custom_property(\'blessed\', 0)\n    if slack_response:\n      slack_blessing.set_string_custom_property(\'slack_decision_maker\',\n                                                slack_response.user_id)\n      slack_blessing.set_string_custom_property(\'slack_decision_message\',\n                                                slack_response.message)\n      slack_blessing.set_string_custom_property(\'slack_decision_channel\',\n                                                slack_response.slack_channel_id)\n      slack_blessing.set_string_custom_property(\'slack_decision_thread\',\n                                                slack_response.thread_ts)\n    absl.logging.info(\'Blessing result written to %s.\', slack_blessing.uri)\n'"
tfx/examples/custom_components/slack/slack_component/version.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Contains the version string of custom SlackComponent for TFX.""""""\n\n# Note that setup.py uses this version.\n__version__ = \'0.1\'\n'"
tfx/examples/custom_components/tuner/example/iris_pipeline_tuner.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Iris flowers tuner example using TFX.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom typing import Text\nimport absl\n\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import ModelValidator\nfrom tfx.components import Pusher\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.examples.custom_components.tuner.tuner_component.component import Tuner\nfrom tfx.orchestration import metadata\nfrom tfx.orchestration import pipeline\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.utils.dsl_utils import external_input\n\n_pipeline_name = \'iris_tuner\'\n\n# This example assumes that Iris flowers data is stored in ~/iris/data and the\n# utility function is in ~/iris. Feel free to customize as needed.\n_iris_root = os.path.join(os.environ[\'HOME\'], \'iris\')\n_data_root = os.path.join(_iris_root, \'data\')\n# Python module file to inject customized logic into the TFX components. The\n# Transform and Trainer both require user-defined functions to run successfully.\n_module_file = os.path.join(_iris_root, \'iris_utils.py\')\n# Path which can be listened to by the model server.  Pusher will output the\n# trained model here.\n_serving_model_dir = os.path.join(_iris_root, \'serving_model\', _pipeline_name)\n\n# Directory and data locations.  This example assumes all of the flowers\n# example code and metadata library is relative to $HOME, but you can store\n# these files anywhere on your local filesystem.\n_tfx_root = os.path.join(os.environ[\'HOME\'], \'tfx\')\n_pipeline_root = os.path.join(_tfx_root, \'pipelines\', _pipeline_name)\n# Sqlite ML-metadata db path.\n_metadata_path = os.path.join(_tfx_root, \'metadata\', _pipeline_name,\n                              \'metadata.db\')\n\n\ndef _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n                     module_file: Text, serving_model_dir: Text,\n                     metadata_path: Text) -> pipeline.Pipeline:\n  """"""Implements the Iris flowers pipeline with TFX.""""""\n  examples = external_input(data_root)\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=examples)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'], infer_feature_shape=True)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n\n  # Hyperparameter tuning based on the tuner_fn in module_file.\n  tuner = Tuner(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      module_file=module_file)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  # TODO(jyzhao): example for importing a hyperparameters file generated not in\n  #               currently run, e.g., by previous pipeline run with Tuner.\n  # TODO(jyzhao): consider supporting warmstart from tuner\'s model for trainer.\n  trainer = Trainer(\n      module_file=module_file,\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      hyperparameters=tuner.outputs[\'best_hyperparameters\'],\n      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n\n  # Uses TFMA to compute a evaluation statistics over features of a model.\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # Performs quality validation of a candidate model (compared to a baseline).\n  model_validator = ModelValidator(\n      examples=example_gen.outputs[\'examples\'], model=trainer.outputs[\'model\'])\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher = Pusher(\n      model=trainer.outputs[\'model\'],\n      model_blessing=model_validator.outputs[\'blessing\'],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          schema_gen,\n          example_validator,\n          tuner,\n          trainer,\n          evaluator,\n          model_validator,\n          pusher,\n      ],\n      enable_cache=True,\n      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n          metadata_path),\n  )\n\n\n# To run this pipeline from the python CLI:\n#   $python iris_pipeline_tuner.py\nif __name__ == \'__main__\':\n  absl.logging.set_verbosity(absl.logging.INFO)\n  BeamDagRunner().run(\n      _create_pipeline(\n          pipeline_name=_pipeline_name,\n          pipeline_root=_pipeline_root,\n          data_root=_data_root,\n          module_file=_module_file,\n          serving_model_dir=_serving_model_dir,\n          metadata_path=_metadata_path))\n'"
tfx/examples/custom_components/tuner/example/iris_utils.py,14,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Python source file include Iris pipeline functions and necesasry utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import List, Text\n\nimport absl\nimport kerastuner\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_model_analysis as tfma\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.examples.custom_components.tuner.tuner_component import component\n\n_FEATURE_KEYS = [\'sepal_length\', \'sepal_width\', \'petal_length\', \'petal_width\']\n_LABEL_KEY = \'variety\'\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _serving_input_receiver_fn(schema):\n  """"""Build the serving inputs.\n\n  Args:\n    schema: the schema of the input data.\n\n  Returns:\n    serving_input_receiver_fn for serving this model, since no transformation is\n    required in this case it does not include a tf-transform graph.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(_LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  return raw_input_fn()\n\n\ndef _eval_input_receiver_fn(schema):\n  """"""Build the evalution inputs for the tf-model-analysis to run the model.\n\n  Args:\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Features (dict of Tensors) to be passed to the model.\n      - Raw features as serialized tf.Examples.\n      - Labels\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  labels = serving_input_receiver.features.pop(_LABEL_KEY)\n  return tfma.export.EvalInputReceiver(\n      features=serving_input_receiver.features,\n      labels=labels,\n      receiver_tensors=serving_input_receiver.receiver_tensors)\n\n\ndef _input_fn(file_pattern: List[Text],\n              schema: schema_pb2.Schema,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    schema: Schema of the input data.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  feature_spec = _get_raw_feature_spec(schema)\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=_LABEL_KEY)\n\n  return dataset\n\n\ndef _build_keras_model(hparams: kerastuner.HyperParameters) -> tf.keras.Model:\n  """"""Creates a DNN Keras model for classifying iris data.\n\n  Args:\n    hparams: Holds HyperParameters for tuning.\n\n  Returns:\n    A Keras Model.\n  """"""\n  absl.logging.info(\'HyperParameters config: %s\' % hparams.get_config())\n  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n  d = keras.layers.concatenate(inputs)\n  for _ in range(hparams.get(\'num_layers\')):  # pytype: disable=wrong-arg-types\n    d = keras.layers.Dense(8, activation=\'relu\')(d)\n  output = keras.layers.Dense(3, activation=\'softmax\')(d)\n  model = keras.Model(inputs=inputs, outputs=output)\n  model.compile(\n      optimizer=keras.optimizers.Adam(hparams.get(\'learning_rate\')),\n      loss=\'sparse_categorical_crossentropy\',\n      metrics=[keras.metrics.SparseCategoricalAccuracy(name=\'accuracy\')])\n  model.summary(print_fn=absl.logging.info)\n  return model\n\n\n# TFX will call this function\ndef trainer_fn(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  train_batch_size = 40\n  eval_batch_size = 40\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      schema,\n      batch_size=train_batch_size)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      schema,\n      batch_size=eval_batch_size)\n\n  train_spec = tf.estimator.TrainSpec(\n      train_input_fn, max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _serving_input_receiver_fn(schema)\n\n  exporter = tf.estimator.FinalExporter(\'iris\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'iris-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=1)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n\n  # TODO(jyzhao): change to native keras when supported.\n  estimator = tf.keras.estimator.model_to_estimator(\n      keras_model=_build_keras_model(\n          kerastuner.HyperParameters.from_config(\n              trainer_fn_args.hyperparameters)),\n      config=run_config)\n\n  # Create an input receiver for TFMA processing\n  eval_receiver_fn = lambda: _eval_input_receiver_fn(schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': eval_receiver_fn\n  }\n\n\n# TFX will call this function\ndef tuner_fn(working_dir: Text, train_data_pattern: Text,\n             eval_data_pattern: Text,\n             schema: schema_pb2.Schema) -> component.TunerFnResult:\n  """"""Build the tuner using the Keras Tuner API.\n\n  Args:\n    working_dir: working dir for KerasTuner.\n    train_data_pattern: file pattern of training tfrecord data.\n    eval_data_pattern: file pattern of eval tfrecord data.\n    schema: Schema of the input data.\n\n  Returns:\n    A namedtuple contains the following:\n      - tuner: A KerasTuner that will be used for tuning.\n      - train_dataset: A tf.data.Dataset of training data.\n      - eval_dataset: A tf.data.Dataset of eval data.\n  """"""\n  hparams = kerastuner.HyperParameters()\n  hparams.Choice(\'learning_rate\', [1e-1, 1e-3])\n  hparams.Int(\'num_layers\', 1, 5)\n\n  # TODO(jyzhao): support params, e.g., max_trials in user input config.\n  tuner = kerastuner.RandomSearch(\n      _build_keras_model,\n      max_trials=5,\n      hyperparameters=hparams,\n      allow_new_entries=False,\n      objective=\'val_accuracy\',\n      directory=working_dir,\n      project_name=\'iris\')\n\n  return component.TunerFnResult(\n      tuner=tuner,\n      train_dataset=_input_fn([train_data_pattern], schema, 10),\n      eval_dataset=_input_fn([eval_data_pattern], schema, 10))\n'"
tfx/examples/custom_components/tuner/tuner_component/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# TODO(b/156633036): remove Tuner from custom_components.\n'"
tfx/examples/custom_components/tuner/tuner_component/component.py,4,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX Tuner component definition.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text, NamedTuple\nimport kerastuner\nimport tensorflow as tf\n\nfrom tfx import types\nfrom tfx.components.base import base_component\nfrom tfx.components.base import executor_spec\nfrom tfx.examples.custom_components.tuner.tuner_component import executor\nfrom tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter\nfrom tfx.types.component_spec import ComponentSpec\nfrom tfx.types.component_spec import ExecutionParameter\n\nTunerFnResult = NamedTuple(\'TunerFnResult\', [(\'tuner\', kerastuner.Tuner),\n                                             (\'train_dataset\', tf.data.Dataset),\n                                             (\'eval_dataset\', tf.data.Dataset)])\n\n\n# TODO(jyzhao): move to tfx/types/standard_component_specs.py.\nclass TunerSpec(ComponentSpec):\n  """"""ComponentSpec for TFX Tuner Component.""""""\n\n  PARAMETERS = {\n      \'module_file\': ExecutionParameter(type=(str, Text), optional=True),\n      \'tuner_fn\': ExecutionParameter(type=(str, Text), optional=True),\n  }\n  INPUTS = {\n      \'examples\': ChannelParameter(type=standard_artifacts.Examples),\n      \'schema\': ChannelParameter(type=standard_artifacts.Schema),\n  }\n  OUTPUTS = {\n      \'model_export_path\':\n          ChannelParameter(type=standard_artifacts.Model),\n      \'best_hyperparameters\':\n          ChannelParameter(type=standard_artifacts.HyperParameters),\n  }\n  # TODO(b/139281215): these input / output names will be renamed in the future.\n  # These compatibility aliases are provided for forwards compatibility.\n  _OUTPUT_COMPATIBILITY_ALIASES = {\n      \'model\': \'model_export_path\',\n  }\n\n\nclass Tuner(base_component.BaseComponent):\n  """"""A TFX component for model hyperparameter tuning.""""""\n\n  SPEC_CLASS = TunerSpec\n  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n  def __init__(self,\n               examples: types.Channel = None,\n               schema: types.Channel = None,\n               module_file: Optional[Text] = None,\n               tuner_fn: Optional[Text] = None,\n               model: Optional[types.Channel] = None,\n               best_hyperparameters: Optional[types.Channel] = None,\n               instance_name: Optional[Text] = None):\n    """"""Construct a Tuner component.\n\n    Args:\n      examples: A Channel of type `standard_artifacts.Examples`, serving as the\n        source of examples that are used in tuning (required). Transformed\n        examples are not yet supported.\n      schema:  A Channel of type `standard_artifacts.Schema`, serving as the\n        schema of training and eval data.\n      module_file: A path to python module file containing UDF KerasTuner\n        definition. Exactly one of \'module_file\' or \'tuner_fn\' must be supplied.\n        The module_file must implement a function named `tuner_fn` at its top\n        level. The function takes working dir path, train data path, eval data\n        path and tensorflow_metadata.proto.v0.schema_pb2.Schema and generates a\n        namedtuple TunerFnResult which contains:\n        - \'tuner\': A KerasTuner that will be used for tuning.\n        - \'train_dataset\': A tf.data.Dataset of training data.\n        - \'eval_dataset\': A tf.data.Dataset of eval data.\n      tuner_fn:  A python path to UDF model definition function. See\n        \'module_file\' for the required signature of the UDF. Exactly one of\n        \'module_file\' or \'tuner_fn\' must be supplied.\n      model: Optional Channel of type `standard_artifacts.Model` for result of\n        best model.\n      best_hyperparameters: Optional Channel of type\n        `standard_artifacts.HyperParameters` for result of the best hparams.\n      instance_name: Optional unique instance name. Necessary if multiple Tuner\n        components are declared in the same pipeline.\n    """"""\n    if bool(module_file) == bool(tuner_fn):\n      raise ValueError(\n          ""Exactly one of \'module_file\' or \'tuner_fn\' must be supplied"")\n\n    model = model or types.Channel(\n        type=standard_artifacts.Model, artifacts=[standard_artifacts.Model()])\n    best_hyperparameters = best_hyperparameters or types.Channel(\n        type=standard_artifacts.HyperParameters,\n        artifacts=[standard_artifacts.HyperParameters()])\n    spec = TunerSpec(\n        examples=examples,\n        schema=schema,\n        module_file=module_file,\n        tuner_fn=tuner_fn,\n        model_export_path=model,\n        best_hyperparameters=best_hyperparameters)\n    super(Tuner, self).__init__(spec=spec, instance_name=instance_name)\n'"
tfx/examples/custom_components/tuner/tuner_component/component_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.examples.custom_components.tuner.tuner_component.component.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tfx.examples.custom_components.tuner.tuner_component import component\nfrom tfx.types import channel_utils\nfrom tfx.types import standard_artifacts\n\n\nclass TunerTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(TunerTest, self).setUp()\n\n    self.examples = channel_utils.as_channel([standard_artifacts.Examples()])\n    self.schema = channel_utils.as_channel([standard_artifacts.Schema()])\n\n  def _verify_output(self, tuner):\n    self.assertEqual(standard_artifacts.Model.TYPE_NAME,\n                     tuner.outputs[\'model\'].type_name)\n    self.assertEqual(standard_artifacts.HyperParameters.TYPE_NAME,\n                     tuner.outputs[\'best_hyperparameters\'].type_name)\n\n  def testConstructWithModuleFile(self):\n    tuner = component.Tuner(\n        examples=self.examples,\n        schema=self.schema,\n        module_file=\'/path/to/module/file\')\n    self._verify_output(tuner)\n\n  def testConstructWithTunerFn(self):\n    tuner = component.Tuner(\n        examples=self.examples, schema=self.schema, tuner_fn=\'path.to.tuner_fn\')\n    self._verify_output(tuner)\n\n  def testConstructDuplicateUserModule(self):\n    with self.assertRaises(ValueError):\n      _ = component.Tuner(\n          examples=self.examples,\n          schema=self.schema,\n          module_file=\'/path/to/module/file\',\n          tuner_fn=\'path.to.tuner_fn\')\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/examples/custom_components/tuner/tuner_component/executor.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Generic TFX tuner executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom typing import Any, Dict, List, Text\nimport absl\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx import types\nfrom tfx.components.base import base_executor\nfrom tfx.types import artifact_utils\nfrom tfx.utils import import_utils\nfrom tfx.utils import io_utils\n\n# Default file name for generated best hyperparameters file.\n_DEFAULT_FILE_NAME = \'best_hyperparameters.txt\'\n\n\nclass Executor(base_executor.BaseExecutor):\n  """"""TFX Tuner component executor.""""""\n\n  def _GetTunerFn(self, exec_properties: Dict[Text, Any]) -> Any:\n    """"""Loads and returns user-defined tuner_fn.""""""\n\n    has_module_file = bool(exec_properties.get(\'module_file\'))\n    has_tuner_fn = bool(exec_properties.get(\'tuner_fn\'))\n\n    if has_module_file == has_tuner_fn:\n      raise ValueError(\n          ""Neither or both of \'module_file\' \'tuner_fn\' have been supplied in ""\n          ""\'exec_properties\'."")\n\n    if has_module_file:\n      return import_utils.import_func_from_source(\n          exec_properties[\'module_file\'], \'tuner_fn\')\n\n    tuner_fn_path_split = exec_properties[\'tuner_fn\'].split(\'.\')\n    return import_utils.import_func_from_module(\n        \'.\'.join(tuner_fn_path_split[0:-1]), tuner_fn_path_split[-1])\n\n  def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n         output_dict: Dict[Text, List[types.Artifact]],\n         exec_properties: Dict[Text, Any]) -> None:\n    # KerasTuner generates tuning state (e.g., oracle, trials) to working dir.\n    working_dir = self._get_tmp_dir()\n\n    train_path = artifact_utils.get_split_uri(input_dict[\'examples\'], \'train\')\n    eval_path = artifact_utils.get_split_uri(input_dict[\'examples\'], \'eval\')\n    schema_file = io_utils.get_only_uri_in_dir(\n        artifact_utils.get_single_uri(input_dict[\'schema\']))\n    schema = io_utils.parse_pbtxt_file(schema_file, schema_pb2.Schema())\n\n    tuner_fn = self._GetTunerFn(exec_properties)\n    tuner_spec = tuner_fn(working_dir, io_utils.all_files_pattern(train_path),\n                          io_utils.all_files_pattern(eval_path), schema)\n    tuner = tuner_spec.tuner\n\n    tuner.search_space_summary()\n    # TODO(jyzhao): assert v2 behavior as KerasTuner doesn\'t work in v1.\n    # TODO(jyzhao): make steps configurable or move search() to module file.\n    tuner.search(\n        tuner_spec.train_dataset,\n        steps_per_epoch=1000,\n        validation_steps=500,\n        validation_data=tuner_spec.eval_dataset)\n    tuner.results_summary()\n\n    best_hparams = tuner.oracle.get_best_trials(\n        1)[0].hyperparameters.get_config()\n    best_hparams_path = os.path.join(\n        artifact_utils.get_single_uri(output_dict[\'best_hyperparameters\']),\n        _DEFAULT_FILE_NAME)\n    io_utils.write_string_file(best_hparams_path, json.dumps(best_hparams))\n    absl.logging.info(\'Best HParams is written to %s.\' % best_hparams_path)\n\n    # TODO(jyzhao): export best tuning model.\n'"
tfx/examples/custom_components/tuner/tuner_component/executor_test.py,5,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for tfx.components.trainer.executor.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nfrom kerastuner import HyperParameters\nimport tensorflow as tf\n\nfrom tensorflow.python.lib.io import file_io  # pylint: disable=g-direct-tensorflow-import\nfrom tfx.examples.custom_components.tuner.example import iris_utils as module\nfrom tfx.examples.custom_components.tuner.tuner_component import executor\nfrom tfx.types import artifact_utils\nfrom tfx.types import standard_artifacts\n\n\nclass ExecutorTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ExecutorTest, self).setUp()\n    self._testdata_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'testdata\')\n    self._module_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)), \'example\')\n    self._output_data_dir = os.path.join(\n        os.environ.get(\'TEST_UNDECLARED_OUTPUTS_DIR\', self.get_temp_dir()),\n        self._testMethodName)\n\n    self._context = executor.Executor.Context(\n        tmp_dir=self._output_data_dir, unique_id=\'1\')\n\n    # Create input dict.\n    examples = standard_artifacts.Examples()\n    examples.uri = os.path.join(self._testdata_dir, \'data\')\n    examples.split_names = artifact_utils.encode_split_names([\'train\', \'eval\'])\n    schema = standard_artifacts.Schema()\n    schema.uri = os.path.join(self._testdata_dir, \'schema\')\n\n    self._input_dict = {\n        \'examples\': [examples],\n        \'schema\': [schema],\n    }\n\n    # Create output dict.\n    model = standard_artifacts.Model()\n    model.uri = os.path.join(self._output_data_dir, \'model\')\n    self._best_hparams = standard_artifacts.Model()\n    self._best_hparams.uri = os.path.join(self._output_data_dir, \'best_hparams\')\n\n    self._output_dict = {\n        \'model\': [model],\n        \'best_hyperparameters\': [self._best_hparams],\n    }\n\n  def _verify_output(self):\n    # Test best hparams.\n    best_hparams_path = os.path.join(self._best_hparams.uri,\n                                     \'best_hyperparameters.txt\')\n    self.assertTrue(tf.io.gfile.exists(best_hparams_path))\n    best_hparams_config = json.loads(\n        file_io.read_file_to_string(best_hparams_path))\n    best_hparams = HyperParameters.from_config(best_hparams_config)\n    self.assertIn(best_hparams.get(\'learning_rate\'), (1e-1, 1e-3))\n    self.assertBetween(best_hparams.get(\'num_layers\'), 1, 5)\n\n  def testDoWithModuleFile(self):\n    # Create exec properties.\n    exec_properties = {\n        \'module_file\': os.path.join(self._module_dir, \'iris_utils.py\')\n    }\n\n    # Run tuner.\n    tuner = executor.Executor(self._context)\n    tuner.Do(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=exec_properties)\n\n    self._verify_output()\n\n  def testDoWithTunerFn(self):\n    # Create exec properties.\n    exec_properties = {\n        \'tuner_fn\':\n            \'%s.%s\' % (module.tuner_fn.__module__, module.tuner_fn.__name__)\n    }\n\n    # Run tuner.\n    tuner = executor.Executor(self._context)\n    tuner.Do(\n        input_dict=self._input_dict,\n        output_dict=self._output_dict,\n        exec_properties=exec_properties)\n\n    self._verify_output()\n\n\nif __name__ == \'__main__\':\n  # TODO(jyzhao): v1 doesn\'t work for dataset and tuner.\n  if hasattr(tf, \'enable_v2_behavior\'):\n    tf.enable_v2_behavior()\n  elif hasattr(tf, \'enable_eager_behavior\'):\n    tf.enable_eager_behavior()\n  tf.test.main()\n'"
tfx/experimental/templates/taxi/models/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi/models/features.py,3,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX taxi model features.\n\nDefine constants here that are common across all models\nincluding features names, label and size of vocabulary.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Text, List\n\n# At least one feature is needed.\n\n# Name of features which have continuous float values. These features will be\n# used as their own values.\nDENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\']\n\n# Name of features which have continuous float values. These features will be\n# bucketized using `tft.bucketize`, and will be used as categorical features.\nBUCKET_FEATURE_KEYS = [\'pickup_latitude\']\n# Number of buckets used by tf.transform for encoding each feature. The length\n# of this list should be the same with BUCKET_FEATURE_KEYS.\nBUCKET_FEATURE_BUCKET_COUNT = [10]\n\n# Name of features which have categorical values which are mapped to integers.\n# These features will be used as categorical features.\nCATEGORICAL_FEATURE_KEYS = [\'trip_start_hour\']\n# Number of buckets to use integer numbers as categorical features. The length\n# of this list should be the same with CATEGORICAL_FEATURE_KEYS.\nCATEGORICAL_FEATURE_MAX_VALUES = [24]\n\n# Name of features which have string values and are mapped to integers.\nVOCAB_FEATURE_KEYS = []\n\n# Uncomment below to add more features to the model\n# DENSE_FLOAT_FEATURE_KEYS = [\'trip_miles\', \'fare\', \'trip_seconds\']\n#\n# BUCKET_FEATURE_KEYS = [\n#     \'pickup_latitude\', \'pickup_longitude\', \'dropoff_latitude\',\n#     \'dropoff_longitude\'\n# ]\n# # Number of buckets used by tf.transform for encoding each feature.\n# BUCKET_FEATURE_BUCKET_COUNT = [10, 10, 10, 10]\n#\n# CATEGORICAL_FEATURE_KEYS = [\n#     \'trip_start_hour\', \'trip_start_day\', \'trip_start_month\'\n# ]\n# # Number of buckets to use integer numbers as categorical features.\n# CATEGORICAL_FEATURE_MAX_VALUES = [24, 31, 12]\n#\n#\n# VOCAB_FEATURE_KEYS = [\n#     \'payment_type\',\n#     \'company\',\n# ]\n\n# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\nVOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\nOOV_SIZE = 10\n\n# Keys\nLABEL_KEY = \'big_tipper\'\n\n\ndef transformed_name(key: Text) -> Text:\n  """"""Generate the name of the transformed feature from original name.""""""\n  return key + \'_xf\'\n\n\ndef vocabulary_name(key: Text) -> Text:\n  """"""Generate the name of the vocabulary feature from original name.""""""\n  return key + \'_vocab\'\n\n\ndef transformed_names(keys: List[Text]) -> List[Text]:\n  """"""Transform multiple feature names at once.""""""\n  return [transformed_name(key) for key in keys]\n'"
tfx/experimental/templates/taxi/models/features_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx.experimental.templates.taxi.models import features\n\n\nclass FeaturesTest(tf.test.TestCase):\n\n  def testNumberOfBucketFeatureBucketCount(self):\n    self.assertEqual(\n        len(features.BUCKET_FEATURE_KEYS),\n        len(features.BUCKET_FEATURE_BUCKET_COUNT))\n    self.assertEqual(\n        len(features.CATEGORICAL_FEATURE_KEYS),\n        len(features.CATEGORICAL_FEATURE_MAX_VALUES))\n\n  def testTransformedNames(self):\n    names = [""f1"", ""cf""]\n    self.assertEqual([""f1_xf"", ""cf_xf""], features.transformed_names(names))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
tfx/experimental/templates/taxi/models/preprocessing.py,6,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX taxi preprocessing.\n\nThis file defines a template for TFX Transform component.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.experimental.templates.taxi.models import features\n\n\ndef _fill_in_missing(x):\n  """"""Replace missing values in a SparseTensor.\n\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """"""\n  if isinstance(x, tf.sparse.SparseTensor):\n    default_value = \'\' if x.dtype == tf.string else 0\n    dense_tensor = tf.sparse.to_dense(\n        tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n        default_value)\n  else:\n    dense_tensor = x\n\n  return tf.squeeze(dense_tensor, axis=1)\n\n\ndef preprocessing_fn(inputs):\n  """"""tf.transform\'s callback function for preprocessing inputs.\n\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """"""\n  outputs = {}\n  for key in features.DENSE_FLOAT_FEATURE_KEYS:\n    # Preserve this feature as a dense float, setting nan\'s to the mean.\n    outputs[features.transformed_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]))\n\n  for key in features.VOCAB_FEATURE_KEYS:\n    # Build a vocabulary for this feature.\n    outputs[features.transformed_name(key)] = tft.compute_and_apply_vocabulary(\n        _fill_in_missing(inputs[key]),\n        top_k=features.VOCAB_SIZE,\n        num_oov_buckets=features.OOV_SIZE)\n\n  for key, num_buckets in zip(features.BUCKET_FEATURE_KEYS,\n                              features.BUCKET_FEATURE_BUCKET_COUNT):\n    outputs[features.transformed_name(key)] = tft.bucketize(\n        _fill_in_missing(inputs[key]),\n        num_buckets)\n\n  for key in features.CATEGORICAL_FEATURE_KEYS:\n    outputs[features.transformed_name(key)] = _fill_in_missing(inputs[key])\n\n  # TODO(b/157064428): Support label transformation for Keras.\n  # Do not apply label transformation as it will result in wrong evaluation.\n  outputs[features.transformed_name(\n      features.LABEL_KEY)] = inputs[features.LABEL_KEY]\n\n  return outputs\n'"
tfx/experimental/templates/taxi/models/preprocessing_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx.experimental.templates.taxi.models import preprocessing\n\n\nclass PreprocessingTest(tf.test.TestCase):\n\n  def testPreprocessingFn(self):\n    self.assertTrue(callable(preprocessing.preprocessing_fn))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/experimental/templates/taxi/pipeline/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi/pipeline/configs.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX taxi template configurations.\n\nThis file defines environments for a TFX taxi pipeline.\n""""""\n\nimport os  # pylint: disable=unused-import\n\n# TODO(b/149347293): Move more TFX CLI flags into python configuration.\n\n# Pipeline name will be used to identify this pipeline.\nPIPELINE_NAME = \'{{PIPELINE_NAME}}\'\n\n# GCP related configs.\n\n# Following code will retrieve your GCP project. You can choose which project\n# to use by setting GOOGLE_CLOUD_PROJECT environment variable.\ntry:\n  import google.auth  # pylint: disable=g-import-not-at-top\n  try:\n    _, GOOGLE_CLOUD_PROJECT = google.auth.default()\n  except google.auth.exceptions.DefaultCredentialsError:\n    GOOGLE_CLOUD_PROJECT = \'\'\nexcept ImportError:\n  GOOGLE_CLOUD_PROJECT = \'\'\n\n# Specify your GCS bucket name here. You have to use GCS to store output files\n# when running a pipeline with Kubeflow Pipeline on GCP or when running a job\n# using Dataflow. Default is \'<gcp_project_name>-kubeflowpipelines-default\'.\n# This bucket is created automatically when you deploy KFP from marketplace.\nGCS_BUCKET_NAME = GOOGLE_CLOUD_PROJECT + \'-kubeflowpipelines-default\'\n\n# TODO(step 8,step 9): (Optional) Set your region to use GCP services including\n#                      BigQuery, Dataflow and Cloud AI Platform.\n# GOOGLE_CLOUD_REGION = \'\'  # ex) \'us-central1\'\n\nPREPROCESSING_FN = \'models.preprocessing.preprocessing_fn\'\nRUN_FN = \'models.keras.model.run_fn\'\n# NOTE: Uncomment below to use an estimator based model.\n# RUN_FN = \'models.estimator.model.run_fn\'\n\nTRAIN_NUM_STEPS = 100\nEVAL_NUM_STEPS = 100\n\n# Change this value according to your use cases.\nEVAL_ACCURACY_THRESHOLD = 0.6\n\n# Beam args to use BigQueryExampleGen with Beam DirectRunner.\n# TODO(step 7): (Optional) Uncomment here to provide GCP related configs for\n#               BigQuery.\n# BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS = [\n#    \'--project=\' + GOOGLE_CLOUD_PROJECT,\n#    \'--temp_location=\' + os.path.join(\'gs://\', GCS_BUCKET_NAME, \'tmp\'),\n#    ]\n\n# The rate at which to sample rows from the Chicago Taxi dataset using BigQuery.\n# The full taxi dataset is > 120M record.  In the interest of resource\n# savings and time, we\'ve set the default for this example to be much smaller.\n# Feel free to crank it up and process the full dataset!\n_query_sample_rate = 0.0001  # Generate a 0.01% random sample.\n\n# The query that extracts the examples from BigQuery.  The Chicago Taxi dataset\n# used for this example is a public dataset available on Google AI Platform.\n# https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips\n# TODO(step 7): (Optional) Uncomment here to use BigQuery.\n# BIG_QUERY_QUERY = """"""\n#         SELECT\n#           pickup_community_area,\n#           fare,\n#           EXTRACT(MONTH FROM trip_start_timestamp) AS trip_start_month,\n#           EXTRACT(HOUR FROM trip_start_timestamp) AS trip_start_hour,\n#           EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS trip_start_day,\n#           UNIX_SECONDS(trip_start_timestamp) AS trip_start_timestamp,\n#           pickup_latitude,\n#           pickup_longitude,\n#           dropoff_latitude,\n#           dropoff_longitude,\n#           trip_miles,\n#           pickup_census_tract,\n#           dropoff_census_tract,\n#           payment_type,\n#           company,\n#           trip_seconds,\n#           dropoff_community_area,\n#           tips,\n#           IF(tips > fare * 0.2, 1, 0) AS big_tipper\n#         FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n#         WHERE (ABS(FARM_FINGERPRINT(unique_key)) / 0x7FFFFFFFFFFFFFFF)\n#           < {query_sample_rate}"""""".format(\n#    query_sample_rate=_query_sample_rate)\n\n# Beam args to run data processing on DataflowRunner.\n#\n# TODO(b/151114974): Remove `disk_size_gb` flag after default is increased.\n# TODO(b/151116587): Remove `shuffle_mode` flag after default is changed.\n# TODO(b/156874687): Remove `machine_type` after IP addresses are no longer a\n#                    scaling bottleneck.\n# TODO(step 8): (Optional) Uncomment below to use Dataflow.\n# DATAFLOW_BEAM_PIPELINE_ARGS = [\n#    \'--project=\' + GOOGLE_CLOUD_PROJECT,\n#    \'--runner=DataflowRunner\',\n#    \'--temp_location=\' + os.path.join(\'gs://\', GCS_BUCKET_NAME, \'tmp\'),\n#    \'--region=\' + GOOGLE_CLOUD_REGION,\n#\n#    # Temporary overrides of defaults.\n#    \'--disk_size_gb=50\',\n#    \'--experiments=shuffle_mode=auto\',\n#    \'--machine_type=n1-standard-8\',\n#    ]\n\n# A dict which contains the training job parameters to be passed to Google\n# Cloud AI Platform. For the full set of parameters supported by Google Cloud AI\n# Platform, refer to\n# https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#Job\n# TODO(step 9): (Optional) Uncomment below to use AI Platform training.\n# GCP_AI_PLATFORM_TRAINING_ARGS = {\n#     \'project\': GOOGLE_CLOUD_PROJECT,\n#     \'region\': GOOGLE_CLOUD_REGION,\n#     # Starting from TFX 0.14, training on AI Platform uses custom containers:\n#     # https://cloud.google.com/ml-engine/docs/containers-overview\n#     # You can specify a custom container here. If not specified, TFX will use\n#     # a public container image matching the installed version of TFX.\n#     # TODO(step 9): (Optional) Set your container name below.\n#     \'masterConfig\': {\n#       \'imageUri\': \'gcr.io/\' + GOOGLE_CLOUD_PROJECT + \'/tfx-pipeline\'\n#     },\n#     # Note that if you do specify a custom container, ensure the entrypoint\n#     # calls into TFX\'s run_executor script (tfx/scripts/run_executor.py)\n# }\n\n# A dict which contains the serving job parameters to be passed to Google\n# Cloud AI Platform. For the full set of parameters supported by Google Cloud AI\n# Platform, refer to\n# https://cloud.google.com/ml-engine/reference/rest/v1/projects.models\n# TODO(step 9): (Optional) Uncomment below to use AI Platform serving.\n# GCP_AI_PLATFORM_SERVING_ARGS = {\n#     \'model_name\': PIPELINE_NAME,\n#     \'project_id\': GOOGLE_CLOUD_PROJECT,\n#     # The region to use when serving the model. See available regions here:\n#     # https://cloud.google.com/ml-engine/docs/regions\n#     # Note that serving currently only supports a single region:\n#     # https://cloud.google.com/ml-engine/reference/rest/v1/projects.models#Model  # pylint: disable=line-too-long\n#     \'regions\': [GOOGLE_CLOUD_REGION],\n# }\n'"
tfx/experimental/templates/taxi/pipeline/pipeline.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX taxi template pipeline definition.\n\nThis file defines TFX pipeline and various components in the pipeline.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom typing import Optional, Text, List, Dict, Any\nimport tensorflow_model_analysis as tfma\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.components import BigQueryExampleGen  # pylint: disable=unused-import\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import Evaluator\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Pusher\nfrom tfx.components import ResolverNode\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Trainer\nfrom tfx.components import Transform\nfrom tfx.components.base import executor_spec\nfrom tfx.components.trainer import executor as trainer_executor\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\nfrom tfx.extensions.google_cloud_ai_platform.pusher import executor as ai_platform_pusher_executor\nfrom tfx.extensions.google_cloud_ai_platform.trainer import executor as ai_platform_trainer_executor\nfrom tfx.orchestration import pipeline\nfrom tfx.proto import pusher_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.utils.dsl_utils import external_input\n\n\ndef create_pipeline(\n    pipeline_name: Text,\n    pipeline_root: Text,\n    data_path: Text,\n    # TODO(step 7): (Optional) Uncomment here to use BigQuery as a data source.\n    # query: Text,\n    preprocessing_fn: Text,\n    run_fn: Text,\n    train_args: trainer_pb2.TrainArgs,\n    eval_args: trainer_pb2.EvalArgs,\n    eval_accuracy_threshold: float,\n    serving_model_dir: Text,\n    metadata_connection_config: Optional[\n        metadata_store_pb2.ConnectionConfig] = None,\n    beam_pipeline_args: Optional[List[Text]] = None,\n    ai_platform_training_args: Optional[Dict[Text, Text]] = None,\n    ai_platform_serving_args: Optional[Dict[Text, Any]] = None,\n) -> pipeline.Pipeline:\n  """"""Implements the chicago taxi pipeline with TFX.""""""\n\n  components = []\n\n  # Brings data into the pipeline or otherwise joins/converts training data.\n  example_gen = CsvExampleGen(input=external_input(data_path))\n  # TODO(step 7): (Optional) Uncomment here to use BigQuery as a data source.\n  # example_gen = BigQueryExampleGen(query=query)\n  components.append(example_gen)\n\n  # Computes statistics over data for visualization and example validation.\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\'examples\'])\n  # TODO(step 5): Uncomment here to add StatisticsGen to the pipeline.\n  # components.append(statistics_gen)\n\n  # Generates schema based on statistics files.\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\'statistics\'],\n      infer_feature_shape=True)\n  # TODO(step 5): Uncomment here to add SchemaGen to the pipeline.\n  # components.append(schema_gen)\n\n  # Performs anomaly detection based on statistics and data schema.\n  example_validator = ExampleValidator(  # pylint: disable=unused-variable\n      statistics=statistics_gen.outputs[\'statistics\'],\n      schema=schema_gen.outputs[\'schema\'])\n  # TODO(step 5): Uncomment here to add ExampleValidator to the pipeline.\n  # components.append(example_validator)\n\n  # Performs transformations and feature engineering in training and serving.\n  transform = Transform(\n      examples=example_gen.outputs[\'examples\'],\n      schema=schema_gen.outputs[\'schema\'],\n      preprocessing_fn=preprocessing_fn)\n  # TODO(step 6): Uncomment here to add Transform to the pipeline.\n  # components.append(transform)\n\n  # Uses user-provided Python function that implements a model using TF-Learn.\n  trainer_args = {\n      \'run_fn\': run_fn,\n      \'transformed_examples\': transform.outputs[\'transformed_examples\'],\n      \'schema\': schema_gen.outputs[\'schema\'],\n      \'transform_graph\': transform.outputs[\'transform_graph\'],\n      \'train_args\': train_args,\n      \'eval_args\': eval_args,\n      \'custom_executor_spec\':\n          executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n  }\n  if ai_platform_training_args is not None:\n    trainer_args.update({\n        \'custom_executor_spec\':\n            executor_spec.ExecutorClassSpec(\n                ai_platform_trainer_executor.GenericExecutor\n            ),\n        \'custom_config\': {\n            ai_platform_trainer_executor.TRAINING_ARGS_KEY:\n                ai_platform_training_args,\n        }\n    })\n  trainer = Trainer(**trainer_args)\n  # TODO(step 6): Uncomment here to add Trainer to the pipeline.\n  # components.append(trainer)\n\n  # Get the latest blessed model for model validation.\n  model_resolver = ResolverNode(\n      instance_name=\'latest_blessed_model_resolver\',\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n      model=Channel(type=Model),\n      model_blessing=Channel(type=ModelBlessing))\n  # TODO(step 6): Uncomment here to add ResolverNode to the pipeline.\n  # components.append(model_resolver)\n\n  # Uses TFMA to compute a evaluation statistics over features of a model and\n  # perform quality validation of a candidate model (compared to a baseline).\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(label_key=\'big_tipper\')],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(metrics=[\n              tfma.MetricConfig(\n                  class_name=\'BinaryAccuracy\',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={\'value\': eval_accuracy_threshold}),\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={\'value\': -1e-10})))\n          ])\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\'examples\'],\n      model=trainer.outputs[\'model\'],\n      baseline_model=model_resolver.outputs[\'model\'],\n      # Change threshold will be ignored if there is no baseline (first run).\n      eval_config=eval_config)\n  # TODO(step 6): Uncomment here to add Evaluator to the pipeline.\n  # components.append(evaluator)\n\n  # Checks whether the model passed the validation steps and pushes the model\n  # to a file destination if check passed.\n  pusher_args = {\n      \'model\':\n          trainer.outputs[\'model\'],\n      \'model_blessing\':\n          evaluator.outputs[\'blessing\'],\n      \'push_destination\':\n          pusher_pb2.PushDestination(\n              filesystem=pusher_pb2.PushDestination.Filesystem(\n                  base_directory=serving_model_dir)),\n  }\n  if ai_platform_serving_args is not None:\n    pusher_args.update({\n        \'custom_executor_spec\':\n            executor_spec.ExecutorClassSpec(ai_platform_pusher_executor.Executor\n                                           ),\n        \'custom_config\': {\n            ai_platform_pusher_executor.SERVING_ARGS_KEY:\n                ai_platform_serving_args\n        },\n    })\n  pusher = Pusher(**pusher_args)  # pylint: disable=unused-variable\n  # TODO(step 6): Uncomment here to add Pusher to the pipeline.\n  # components.append(pusher)\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=components,\n      # TODO(step 8): Change this value to control caching of execution results.\n      enable_cache=True,\n      metadata_connection_config=metadata_connection_config,\n      beam_pipeline_args=beam_pipeline_args,\n  )\n'"
tfx/orchestration/experimental/interactive/export_templates/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/experimental/interactive/notebook_extensions/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/orchestration/experimental/interactive/notebook_extensions/skip.py,0,"b'# Lint as: python2, python3\n# Copyright 2019 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Custom magic for marking cells to be skipped during pipeline export.""""""\n\nfrom __future__ import print_function\n\nfrom IPython.core.magic import cell_magic\nfrom IPython.core.magic import Magics\nfrom IPython.core.magic import magics_class\n\n\n@magics_class\nclass SkipMagics(Magics):\n\n  @cell_magic\n  def skip_for_export(self, line, cell):\n    # Execute the cell normally for now. During export to pipeline, this cell\n    # will be skipped.\n    self.shell.run_cell(cell)\n    print(\'This cell will be skipped during export to pipeline.\')\n\n\ndef load_ipython_extension(ipython):\n  ipython.register_magics(SkipMagics)\n'"
tfx/experimental/templates/taxi/models/estimator/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi/models/estimator/constants.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Constants of the taxi model.\n\nThese values can be tweaked to affect model training performance.\n""""""\n\nHIDDEN_UNITS = [16, 8]\n\nTRAIN_BATCH_SIZE = 40\nEVAL_BATCH_SIZE = 40\n'"
tfx/experimental/templates/taxi/models/estimator/model.py,20,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX template taxi model.\n\nA tf.estimator.DNNLinearCombinedClassifier which uses features\ndefined in features.py and network parameters defined in constants.py.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import logging\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\nimport tensorflow_transform as tft\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.experimental.templates.taxi.models import features\nfrom tfx.experimental.templates.taxi.models.estimator import constants\nfrom tfx.utils import io_utils\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\n# Tf.Transform considers these features as ""raw""\ndef _get_raw_feature_spec(schema):\n  return schema_utils.schema_as_feature_spec(schema).feature_spec\n\n\ndef _build_estimator(config, hidden_units=None, warm_start_from=None):\n  """"""Build an estimator for predicting the tipping behavior of taxi riders.\n\n  Args:\n    config: tf.estimator.RunConfig defining the runtime environment for the\n      estimator (including model_dir).\n    hidden_units: [int], the layer sizes of the DNN (input layer first)\n    warm_start_from: Optional directory to warm start from.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in features.transformed_names(features.DENSE_FLOAT_FEATURE_KEYS)\n  ]\n\n  categorical_columns = []\n  for key in features.transformed_names(features.VOCAB_FEATURE_KEYS):\n    categorical_columns.append(\n        tf.feature_column.categorical_column_with_identity(\n            key,\n            num_buckets=features.VOCAB_SIZE + features.OOV_SIZE,\n            default_value=0))\n\n  for key, num_buckets in zip(\n      features.transformed_names(features.BUCKET_FEATURE_KEYS),\n      features.BUCKET_FEATURE_BUCKET_COUNT):\n    categorical_columns.append(\n        tf.feature_column.categorical_column_with_identity(\n            key, num_buckets=num_buckets, default_value=0))\n\n  for key, num_buckets in zip(\n      features.transformed_names(features.CATEGORICAL_FEATURE_KEYS),\n      features.CATEGORICAL_FEATURE_MAX_VALUES):\n    categorical_columns.append(\n        tf.feature_column.categorical_column_with_identity(\n            key, num_buckets=num_buckets, default_value=0))\n\n  return tf.estimator.DNNLinearCombinedClassifier(\n      config=config,\n      linear_feature_columns=categorical_columns,\n      dnn_feature_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units or [100, 70, 50, 25],\n      warm_start_from=warm_start_from)\n\n\ndef _example_serving_receiver_fn(tf_transform_output, schema):\n  """"""Build the serving in inputs.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    Tensorflow graph which parses examples, applying tf-transform to them.\n  """"""\n  raw_feature_spec = _get_raw_feature_spec(schema)\n  raw_feature_spec.pop(features.LABEL_KEY)\n\n  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n      raw_feature_spec, default_batch_size=None)\n  serving_input_receiver = raw_input_fn()\n\n  transformed_features = tf_transform_output.transform_raw_features(\n      serving_input_receiver.features)\n\n  return tf.estimator.export.ServingInputReceiver(\n      transformed_features, serving_input_receiver.receiver_tensors)\n\n\ndef _eval_input_receiver_fn(tf_transform_output, schema):\n  """"""Build everything needed for the tf-model-analysis to run the model.\n\n  Args:\n    tf_transform_output: A TFTransformOutput.\n    schema: the schema of the input data.\n\n  Returns:\n    EvalInputReceiver function, which contains:\n      - Tensorflow graph which parses raw untransformed features, applies the\n        tf-transform preprocessing operators.\n      - Set of raw, untransformed features.\n      - Label against which predictions will be compared.\n  """"""\n  # Notice that the inputs are raw features, not transformed features here.\n  raw_feature_spec = _get_raw_feature_spec(schema)\n\n  serialized_tf_example = tf.compat.v1.placeholder(\n      dtype=tf.string, shape=[None], name=\'input_example_tensor\')\n\n  # Add a parse_example operator to the tensorflow graph, which will parse\n  # raw, untransformed, tf examples.\n  raw_features = tf.io.parse_example(\n      serialized=serialized_tf_example, features=raw_feature_spec)\n\n  # Now that we have our raw examples, process them through the tf-transform\n  # function computed during the preprocessing step.\n  transformed_features = tf_transform_output.transform_raw_features(\n      raw_features)\n\n  # The key name MUST be \'examples\'.\n  receiver_tensors = {\'examples\': serialized_tf_example}\n\n  # NOTE: Model is driven by transformed features (since training works on the\n  # materialized output of TFT, but slicing will happen on raw features.\n  raw_features.update(transformed_features)\n\n  return tfma.export.EvalInputReceiver(\n      features=raw_features,\n      receiver_tensors=receiver_tensors,\n      labels=transformed_features[features.transformed_name(\n          features.LABEL_KEY)])\n\n\ndef _input_fn(filenames, tf_transform_output, batch_size=200):\n  """"""Generates features and labels for training or evaluation.\n\n  Args:\n    filenames: [str] list of CSV files to read data from.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: int First dimension size of the Tensors returned by input_fn\n\n  Returns:\n    A (features, indices) tuple where features is a dictionary of\n      Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn)\n\n  transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n      dataset).get_next()\n  # We pop the label because we do not want to use it as a feature while we\'re\n  # training.\n  return transformed_features, transformed_features.pop(\n      features.transformed_name(features.LABEL_KEY))\n\n\ndef _create_train_and_eval_spec(trainer_fn_args, schema):\n  """"""Build the estimator using the high level API.\n\n  Args:\n    trainer_fn_args: Holds args used to train the model as name/value pairs.\n    schema: Holds the schema of the training examples.\n\n  Returns:\n    A dict of the following:\n      - estimator: The estimator that will be used for training and eval.\n      - train_spec: Spec for training.\n      - eval_spec: Spec for eval.\n      - eval_input_receiver_fn: Input function for eval.\n  """"""\n\n  tf_transform_output = tft.TFTransformOutput(trainer_fn_args.transform_output)\n\n  train_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.train_files,\n      tf_transform_output,\n      batch_size=constants.TRAIN_BATCH_SIZE)\n\n  eval_input_fn = lambda: _input_fn(  # pylint: disable=g-long-lambda\n      trainer_fn_args.eval_files,\n      tf_transform_output,\n      batch_size=constants.EVAL_BATCH_SIZE)\n\n  train_spec = tf.estimator.TrainSpec(  # pylint: disable=g-long-lambda\n      train_input_fn,\n      max_steps=trainer_fn_args.train_steps)\n\n  serving_receiver_fn = lambda: _example_serving_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  exporter = tf.estimator.FinalExporter(\'chicago-taxi\', serving_receiver_fn)\n  eval_spec = tf.estimator.EvalSpec(\n      eval_input_fn,\n      steps=trainer_fn_args.eval_steps,\n      exporters=[exporter],\n      name=\'chicago-taxi-eval\')\n\n  run_config = tf.estimator.RunConfig(\n      save_checkpoints_steps=999, keep_checkpoint_max=1)\n\n  run_config = run_config.replace(model_dir=trainer_fn_args.serving_model_dir)\n\n  estimator = _build_estimator(\n      hidden_units=constants.HIDDEN_UNITS, config=run_config)\n\n  # Create an input receiver for TFMA processing\n  receiver_fn = lambda: _eval_input_receiver_fn(  # pylint: disable=g-long-lambda\n      tf_transform_output, schema)\n\n  return {\n      \'estimator\': estimator,\n      \'train_spec\': train_spec,\n      \'eval_spec\': eval_spec,\n      \'eval_input_receiver_fn\': receiver_fn\n  }\n\n\n# TFX will call this function\ndef run_fn(fn_args):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n  schema = io_utils.parse_pbtxt_file(fn_args.schema_file, schema_pb2.Schema())\n\n  train_and_eval_spec = _create_train_and_eval_spec(fn_args, schema)\n\n  # Train the model\n  logging.info(\'Training model.\')\n  tf.estimator.train_and_evaluate(train_and_eval_spec[\'estimator\'],\n                                  train_and_eval_spec[\'train_spec\'],\n                                  train_and_eval_spec[\'eval_spec\'])\n  logging.info(\'Training complete.  Model written to %s\',\n               fn_args.serving_model_dir)\n\n  # Export an eval savedmodel for TFMA\n  # NOTE: When trained in distributed training cluster, eval_savedmodel must be\n  # exported only by the chief worker.\n  logging.info(\'Exporting eval_savedmodel for TFMA.\')\n  tfma.export.export_eval_savedmodel(\n      estimator=train_and_eval_spec[\'estimator\'],\n      export_dir_base=fn_args.eval_model_dir,\n      eval_input_receiver_fn=train_and_eval_spec[\'eval_input_receiver_fn\'])\n\n  logging.info(\'Exported eval_savedmodel to %s.\', fn_args.eval_model_dir)\n'"
tfx/experimental/templates/taxi/models/estimator/model_test.py,5,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tfx.components.trainer import executor as trainer_executor\nfrom tfx.experimental.templates.taxi.models.estimator import model\n\n\nclass ModelTest(tf.test.TestCase):\n\n  def testTrainerFn(self):\n    trainer_fn_args = trainer_executor.TrainerFnArgs(\n        train_files=\'/path/to/train.file\',\n        transform_output=\'/path/to/transform_output\',\n        serving_model_dir=\'/path/to/model_dir\',\n        eval_files=\'/path/to/eval.file\',\n        schema_file=\'/path/to/schema_file\',\n        train_steps=1000,\n        eval_steps=100,\n    )\n    schema = schema_pb2.Schema()\n    result = model._create_train_and_eval_spec(trainer_fn_args, schema)   # pylint: disable=protected-access\n    self.assertIsInstance(result[\'estimator\'], tf.estimator.Estimator)\n    self.assertIsInstance(result[\'train_spec\'], tf.estimator.TrainSpec)\n    self.assertIsInstance(result[\'eval_spec\'], tf.estimator.EvalSpec)\n    self.assertTrue(callable(result[\'eval_input_receiver_fn\']))\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
tfx/experimental/templates/taxi/models/keras/__init__.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
tfx/experimental/templates/taxi/models/keras/constants.py,0,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Constants for the taxi model.\n\nThese values can be tweaked to affect model training performance.\n""""""\n\nHIDDEN_UNITS = [16, 8]\nLEARNING_RATE = 0.001\n\nTRAIN_BATCH_SIZE = 40\nEVAL_BATCH_SIZE = 40\n'"
tfx/experimental/templates/taxi/models/keras/model.py,27,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TFX template taxi model.\n\nA DNN keras model which uses features defined in features.py and network\nparameters defined in constants.py.\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nfrom absl import logging\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx.experimental.templates.taxi.models import features\nfrom tfx.experimental.templates.taxi.models.keras import constants\n\n\ndef _gzip_reader_fn(filenames):\n  """"""Small utility returning a record reader that can read gzip\'ed files.""""""\n  return tf.data.TFRecordDataset(filenames, compression_type=\'GZIP\')\n\n\ndef _get_serve_tf_examples_fn(model, tf_transform_output):\n  """"""Returns a function that parses a serialized tf.Example and applies TFT.""""""\n\n  model.tft_layer = tf_transform_output.transform_features_layer()\n\n  @tf.function\n  def serve_tf_examples_fn(serialized_tf_examples):\n    """"""Returns the output to be used in the serving signature.""""""\n    feature_spec = tf_transform_output.raw_feature_spec()\n    feature_spec.pop(features.LABEL_KEY)\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    transformed_features = model.tft_layer(parsed_features)\n    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n    transformed_features.pop(\n        features.transformed_name(features.LABEL_KEY), None)\n\n    return model(transformed_features)\n\n  return serve_tf_examples_fn\n\n\ndef _input_fn(file_pattern, tf_transform_output, batch_size=200):\n  """"""Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: input tfrecord file pattern.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """"""\n  transformed_feature_spec = (\n      tf_transform_output.transformed_feature_spec().copy())\n\n  dataset = tf.data.experimental.make_batched_features_dataset(\n      file_pattern=file_pattern,\n      batch_size=batch_size,\n      features=transformed_feature_spec,\n      reader=_gzip_reader_fn,\n      label_key=features.transformed_name(features.LABEL_KEY))\n\n  return dataset\n\n\ndef _build_keras_model(hidden_units, learning_rate):\n  """"""Creates a DNN Keras model for classifying taxi data.\n\n  Args:\n    hidden_units: [int], the layer sizes of the DNN (input layer first).\n    learning_rate: [float], learning rate of the Adam optimizer.\n\n  Returns:\n    A keras Model.\n  """"""\n  real_valued_columns = [\n      tf.feature_column.numeric_column(key, shape=())\n      for key in features.transformed_names(features.DENSE_FLOAT_FEATURE_KEYS)\n  ]\n  categorical_columns = [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=features.VOCAB_SIZE + features.OOV_SIZE,\n          default_value=0)\n      for key in features.transformed_names(features.VOCAB_FEATURE_KEYS)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              features.transformed_names(features.BUCKET_FEATURE_KEYS),\n              features.BUCKET_FEATURE_BUCKET_COUNT)\n  ]\n  categorical_columns += [\n      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n          key,\n          num_buckets=num_buckets,\n          default_value=0) for key, num_buckets in zip(\n              features.transformed_names(features.CATEGORICAL_FEATURE_KEYS),\n              features.CATEGORICAL_FEATURE_MAX_VALUES)\n  ]\n  indicator_column = [\n      tf.feature_column.indicator_column(categorical_column)\n      for categorical_column in categorical_columns\n  ]\n\n  model = _wide_and_deep_classifier(\n      # TODO(b/140320729) Replace with premade wide_and_deep keras model\n      wide_columns=indicator_column,\n      deep_columns=real_valued_columns,\n      dnn_hidden_units=hidden_units,\n      learning_rate=learning_rate)\n  return model\n\n\ndef _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units,\n                              learning_rate):\n  """"""Build a simple keras wide and deep model.\n\n  Args:\n    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n      part of the model.\n    deep_columns: Feature columns for deep part of the model.\n    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n    learning_rate: [float], learning rate of the Adam optimizer.\n\n  Returns:\n    A Wide and Deep Keras model\n  """"""\n  # Keras needs the feature definitions at compile time.\n  # TODO(b/139081439): Automate generation of input layers from FeatureColumn.\n  input_layers = {\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n      for colname in features.transformed_names(\n          features.DENSE_FLOAT_FEATURE_KEYS)\n  }\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in features.transformed_names(features.VOCAB_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\')\n      for colname in features.transformed_names(features.BUCKET_FEATURE_KEYS)\n  })\n  input_layers.update({\n      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=\'int32\') for\n      colname in features.transformed_names(features.CATEGORICAL_FEATURE_KEYS)\n  })\n\n  # TODO(b/144500510): SparseFeatures for feature columns + Keras.\n  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n  for numnodes in dnn_hidden_units:\n    deep = tf.keras.layers.Dense(numnodes)(deep)\n  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n\n  output = tf.keras.layers.Dense(\n      1, activation=\'sigmoid\')(\n          tf.keras.layers.concatenate([deep, wide]))\n  output = tf.squeeze(output, -1)\n\n  model = tf.keras.Model(input_layers, output)\n  model.compile(\n      loss=\'binary_crossentropy\',\n      optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n      metrics=[tf.keras.metrics.BinaryAccuracy()])\n  model.summary(print_fn=logging.info)\n  return model\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args):\n  """"""Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """"""\n\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = _input_fn(fn_args.train_files, tf_transform_output,\n                            constants.TRAIN_BATCH_SIZE)\n  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output,\n                           constants.EVAL_BATCH_SIZE)\n\n  mirrored_strategy = tf.distribute.MirroredStrategy()\n  with mirrored_strategy.scope():\n    model = _build_keras_model(\n        hidden_units=constants.HIDDEN_UNITS,\n        learning_rate=constants.LEARNING_RATE)\n  # This log path might change in the future.\n  log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \'logs\')\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n      log_dir=log_dir, update_freq=\'batch\')\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps,\n      callbacks=[tensorboard_callback])\n\n  signatures = {\n      \'serving_default\':\n          _get_serve_tf_examples_fn(model,\n                                    tf_transform_output).get_concrete_function(\n                                        tf.TensorSpec(\n                                            shape=[None],\n                                            dtype=tf.string,\n                                            name=\'examples\')),\n  }\n  model.save(fn_args.serving_model_dir, save_format=\'tf\', signatures=signatures)\n'"
tfx/experimental/templates/taxi/models/keras/model_test.py,2,"b'# Lint as: python2, python3\n# Copyright 2020 Google LLC. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tfx.experimental.templates.taxi.models.keras import model\n\n\nclass ModelTest(tf.test.TestCase):\n\n  def testBuildKerasModel(self):\n    built_model = model._build_keras_model(\n        hidden_units=[1, 1], learning_rate=0.1)  # pylint: disable=protected-access\n    self.assertEqual(len(built_model.layers), 10)\n\n    built_model = model._build_keras_model(hidden_units=[1], learning_rate=0.1)  # pylint: disable=protected-access\n    self.assertEqual(len(built_model.layers), 9)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
