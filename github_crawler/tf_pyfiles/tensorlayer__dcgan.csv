file_path,api_count,code
data.py,10,"b'import os\nimport numpy as np\nimport tensorflow as tf\nimport tensorlayer as tl\n## enable debug logging\ntl.logging.set_verbosity(tl.logging.DEBUG)\n\nclass FLAGS(object):\n    def __init__(self):\n        self.n_epoch = 25 # ""Epoch to train [25]""\n        self.z_dim = 100 # ""Num of noise value]""\n        self.lr = 0.0002 # ""Learning rate of for adam [0.0002]"")\n        self.beta1 = 0.5 # ""Momentum term of adam [0.5]"")\n        self.batch_size = 64 # ""The number of batch images [64]"")\n        self.output_size = 64 # ""The size of the output images to produce [64]"")\n        self.sample_size = 64 # ""The number of sample images [64]"")\n        self.c_dim = 3 # ""Number of image channels. [3]"")\n        self.save_every_epoch = 1 # ""The interval of saveing checkpoints."")\n        # self.dataset = ""celebA"" # ""The name of dataset [celebA, mnist, lsun]"")\n        self.checkpoint_dir = ""checkpoint"" # ""Directory name to save the checkpoints [checkpoint]"")\n        self.sample_dir = ""samples"" # ""Directory name to save the image samples [samples]"")\n        assert np.sqrt(self.sample_size) % 1 == 0., \'Flag `sample_size` needs to be a perfect square\'\nflags = FLAGS()\n\ntl.files.exists_or_mkdir(flags.checkpoint_dir) # save model\ntl.files.exists_or_mkdir(flags.sample_dir) # save generated image\n\ndef get_celebA(output_size, n_epoch, batch_size):\n    # dataset API and augmentation\n    images_path = tl.files.load_file_list(path=\'data\', regx=\'.*.jpg\', keep_prefix=True, printable=False)\n    def generator_train():\n        for image_path in images_path:\n            yield image_path.encode(\'utf-8\')\n    def _map_fn(image_path):\n        image = tf.io.read_file(image_path)\n        image = tf.image.decode_jpeg(image, channels=3)  # get RGB with 0~1\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        # image = tf.image.crop_central(image, [FLAGS.output_size, FLAGS.output_size, FLAGS.c_dim])\n        # image = tf.image.resize_images(image, FLAGS.output_size])\n        image = image[45:173, 25:153, :] # central crop\n        image = tf.image.resize([image], (output_size, output_size))[0]\n        # image = tf.image.crop_and_resize(image, boxes=[[]], crop_size=[64, 64])\n        # image = tf.image.resize_image_with_crop_or_pad(image, FLAGS.output_size, FLAGS.output_size) # central crop\n        image = tf.image.random_flip_left_right(image)\n        image = image * 2 - 1\n        return image\n    train_ds = tf.data.Dataset.from_generator(generator_train, output_types=tf.string)\n    ds = train_ds.shuffle(buffer_size=4096)\n    # ds = ds.shard(num_shards=hvd.size(), index=hvd.rank())\n    # ds = ds.repeat(n_epoch)\n    ds = ds.map(_map_fn, num_parallel_calls=4)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=2)\n    return ds, images_path\n    # for batch_images in train_ds:\n    #     print(batch_images.shape)\n    # value = ds.make_one_shot_iterator().get_next()\n'"
model.py,13,"b""import tensorflow as tf\nimport tensorlayer as tl\nfrom tensorlayer.layers import Input, Dense, DeConv2d, Reshape, BatchNorm2d, Conv2d, Flatten\n\ndef get_generator(shape, gf_dim=64): # Dimension of gen filters in first conv layer. [64]\n    image_size = 64\n    s16 = image_size // 16\n    # w_init = tf.glorot_normal_initializer()\n    w_init = tf.random_normal_initializer(stddev=0.02)\n    gamma_init = tf.random_normal_initializer(1., 0.02)\n\n    ni = Input(shape)\n    nn = Dense(n_units=(gf_dim * 8 * s16 * s16), W_init=w_init, b_init=None)(ni)\n    nn = Reshape(shape=[-1, s16, s16, gf_dim*8])(nn)\n    nn = BatchNorm2d(decay=0.9, act=tf.nn.relu, gamma_init=gamma_init, name=None)(nn)\n    nn = DeConv2d(gf_dim * 4, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d( decay=0.9, act=tf.nn.relu, gamma_init=gamma_init)(nn)\n    nn = DeConv2d(gf_dim * 2, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d(decay=0.9, act=tf.nn.relu, gamma_init=gamma_init)(nn)\n    nn = DeConv2d(gf_dim, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d(decay=0.9, act=tf.nn.relu, gamma_init=gamma_init)(nn)\n    nn = DeConv2d(3, (5, 5), (2, 2), act=tf.nn.tanh, W_init=w_init)(nn)\n\n    return tl.models.Model(inputs=ni, outputs=nn, name='generator')\n\ndef get_discriminator(shape, df_dim=64): # Dimension of discrim filters in first conv layer. [64]\n    # w_init = tf.glorot_normal_initializer()\n    w_init = tf.random_normal_initializer(stddev=0.02)\n    gamma_init = tf.random_normal_initializer(1., 0.02)\n    lrelu = lambda x : tf.nn.leaky_relu(x, 0.2)\n\n    ni = Input(shape)\n    nn = Conv2d(df_dim, (5, 5), (2, 2), act=lrelu, W_init=w_init)(ni)\n    nn = Conv2d(df_dim*2, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d(decay=0.9, act=lrelu, gamma_init=gamma_init)(nn)\n    nn = Conv2d(df_dim*4, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d(decay=0.9, act=lrelu, gamma_init=gamma_init)(nn)\n    nn = Conv2d(df_dim*8, (5, 5), (2, 2), W_init=w_init, b_init=None)(nn)\n    nn = BatchNorm2d(decay=0.9, act=lrelu, gamma_init=gamma_init)(nn)\n    nn = Flatten()(nn)\n    nn = Dense(n_units=1, act=tf.identity, W_init=w_init)(nn)\n\n    return tl.models.Model(inputs=ni, outputs=nn, name='discriminator')\n"""
train.py,7,"b'import os, time, multiprocessing\nimport numpy as np\nimport tensorflow as tf\nimport tensorlayer as tl\nfrom glob import glob\nfrom data import get_celebA, flags\nfrom model import get_generator, get_discriminator\n\nnum_tiles = int(np.sqrt(flags.sample_size))\n\ndef train():\n    images, images_path = get_celebA(flags.output_size, flags.n_epoch, flags.batch_size)\n    G = get_generator([None, flags.z_dim])\n    D = get_discriminator([None, flags.output_size, flags.output_size, flags.c_dim])\n\n    G.train()\n    D.train()\n\n    d_optimizer = tf.optimizers.Adam(flags.lr, beta_1=flags.beta1)\n    g_optimizer = tf.optimizers.Adam(flags.lr, beta_1=flags.beta1)\n\n    n_step_epoch = int(len(images_path) // flags.batch_size)\n    \n    # Z = tf.distributions.Normal(0., 1.)\n    for epoch in range(flags.n_epoch):\n        for step, batch_images in enumerate(images):\n            if batch_images.shape[0] != flags.batch_size: # if the remaining data in this epoch < batch_size\n                break\n            step_time = time.time()\n            with tf.GradientTape(persistent=True) as tape:\n                # z = Z.sample([flags.batch_size, flags.z_dim]) \n                z = np.random.normal(loc=0.0, scale=1.0, size=[flags.batch_size, flags.z_dim]).astype(np.float32)\n                d_logits = D(G(z))\n                d2_logits = D(batch_images)\n                # discriminator: real images are labelled as 1\n                d_loss_real = tl.cost.sigmoid_cross_entropy(d2_logits, tf.ones_like(d2_logits), name=\'dreal\')\n                # discriminator: images from generator (fake) are labelled as 0\n                d_loss_fake = tl.cost.sigmoid_cross_entropy(d_logits, tf.zeros_like(d_logits), name=\'dfake\')\n                # combined loss for updating discriminator\n                d_loss = d_loss_real + d_loss_fake\n                # generator: try to fool discriminator to output 1\n                g_loss = tl.cost.sigmoid_cross_entropy(d_logits, tf.ones_like(d_logits), name=\'gfake\')\n\n            grad = tape.gradient(g_loss, G.trainable_weights)\n            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n            grad = tape.gradient(d_loss, D.trainable_weights)\n            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n            del tape\n\n            print(""Epoch: [{}/{}] [{}/{}] took: {:.3f}, d_loss: {:.5f}, g_loss: {:.5f}"".format(epoch, \\\n                  flags.n_epoch, step, n_step_epoch, time.time()-step_time, d_loss, g_loss))\n        \n        if np.mod(epoch, flags.save_every_epoch) == 0:\n            G.save_weights(\'{}/G.npz\'.format(flags.checkpoint_dir), format=\'npz\')\n            D.save_weights(\'{}/D.npz\'.format(flags.checkpoint_dir), format=\'npz\')\n            G.eval()\n            result = G(z)\n            G.train()\n            tl.visualize.save_images(result.numpy(), [num_tiles, num_tiles], \'{}/train_{:02d}.png\'.format(flags.sample_dir, epoch))\n\nif __name__ == \'__main__\':\n    train()\n'"
