file_path,api_count,code
config.py,0,"b'from easydict import EasyDict as edict\nimport json\n\nconfig = edict()\nconfig.TRAIN = edict()\n\n## Adam\nconfig.TRAIN.batch_size = 8 # [16] use 8 if your GPU memory is small, and use [2, 4] in tl.vis.save_images / use 16 for faster training\nconfig.TRAIN.lr_init = 1e-4\nconfig.TRAIN.beta1 = 0.9\n\n## initialize G\nconfig.TRAIN.n_epoch_init = 100\n    # config.TRAIN.lr_decay_init = 0.1\n    # config.TRAIN.decay_every_init = int(config.TRAIN.n_epoch_init / 2)\n\n## adversarial learning (SRGAN)\nconfig.TRAIN.n_epoch = 2000\nconfig.TRAIN.lr_decay = 0.1\nconfig.TRAIN.decay_every = int(config.TRAIN.n_epoch / 2)\n\n## train set location\nconfig.TRAIN.hr_img_path = \'DIV2K/DIV2K_train_HR/\'\nconfig.TRAIN.lr_img_path = \'DIV2K/DIV2K_train_LR_bicubic/X4/\'\n\nconfig.VALID = edict()\n## test set location\nconfig.VALID.hr_img_path = \'DIV2K/DIV2K_valid_HR/\'\nconfig.VALID.lr_img_path = \'DIV2K/DIV2K_valid_LR_bicubic/X4/\'\n\ndef log_config(filename, cfg):\n    with open(filename, \'w\') as f:\n        f.write(""================================================\\n"")\n        f.write(json.dumps(cfg, indent=4))\n        f.write(""\\n================================================\\n"")\n'"
model.py,74,"b'#! /usr/bin/python\n# -*- coding: utf8 -*-\n\nimport tensorflow as tf\nimport tensorlayer as tl\nfrom tensorlayer.layers import (Input, Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Dense)\nfrom tensorlayer.models import Model\n\ndef get_G(input_shape):\n    w_init = tf.random_normal_initializer(stddev=0.02)\n    g_init = tf.random_normal_initializer(1., 0.02)\n\n    nin = Input(input_shape)\n    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding=\'SAME\', W_init=w_init)(nin)\n    temp = n\n\n    # B residual blocks\n    for i in range(16):\n        nn = Conv2d(64, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n        nn = Conv2d(64, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(nn)\n        nn = BatchNorm2d(gamma_init=g_init)(nn)\n        nn = Elementwise(tf.add)([n, nn])\n        n = nn\n\n    n = Conv2d(64, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(gamma_init=g_init)(n)\n    n = Elementwise(tf.add)([n, temp])\n    # B residual blacks end\n\n    n = Conv2d(256, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init)(n)\n    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n\n    n = Conv2d(256, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init)(n)\n    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n\n    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding=\'SAME\', W_init=w_init)(n)\n    G = Model(inputs=nin, outputs=nn, name=""generator"")\n    return G\n\ndef get_D(input_shape):\n    w_init = tf.random_normal_initializer(stddev=0.02)\n    gamma_init = tf.random_normal_initializer(1., 0.02)\n    df_dim = 64\n    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n\n    nin = Input(input_shape)\n    n = Conv2d(df_dim, (4, 4), (2, 2), act=lrelu, padding=\'SAME\', W_init=w_init)(nin)\n\n    n = Conv2d(df_dim * 2, (4, 4), (2, 2), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 4, (4, 4), (2, 2), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 8, (4, 4), (2, 2), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 16, (4, 4), (2, 2), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 32, (4, 4), (2, 2), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 16, (1, 1), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 8, (1, 1), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    nn = BatchNorm2d(gamma_init=gamma_init)(n)\n\n    n = Conv2d(df_dim * 2, (1, 1), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(nn)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 2, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n    n = Conv2d(df_dim * 8, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=None)(n)\n    n = BatchNorm2d(gamma_init=gamma_init)(n)\n    n = Elementwise(combine_fn=tf.add, act=lrelu)([n, nn])\n\n    n = Flatten()(n)\n    no = Dense(n_units=1, W_init=w_init)(n)\n    D = Model(inputs=nin, outputs=no, name=""discriminator"")\n    return D\n\n# def get_G2(input_shape):\n#     w_init = tf.random_normal_initializer(stddev=0.02)\n#     g_init = tf.random_normal_initializer(1., 0.02)\n#\n#     n = InputLayer(t_image, name=\'in\')\n#     n = Conv2d(n, 64, (3, 3), (1, 1), act=tf.nn.relu, padding=\'SAME\', W_init=w_init, name=\'n64s1/c\')\n#     temp = n\n#\n#     # B residual blocks\n#     for i in range(16):\n#         nn = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n64s1/c1/%s\' % i)\n#         nn = BatchNormLayer(nn, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name=\'n64s1/b1/%s\' % i)\n#         nn = Conv2d(nn, 64, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n64s1/c2/%s\' % i)\n#         nn = BatchNormLayer(nn, is_train=is_train, gamma_init=g_init, name=\'n64s1/b2/%s\' % i)\n#         nn = ElementwiseLayer([n, nn], tf.add, name=\'b_residual_add/%s\' % i)\n#         n = nn\n#\n#     n = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n64s1/c/m\')\n#     n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n64s1/b/m\')\n#     n = ElementwiseLayer([n, temp], tf.add, name=\'add3\')\n#     # B residual blacks end\n#\n#     # n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init, name=\'n256s1/1\')\n#     # n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name=\'pixelshufflerx2/1\')\n#     #\n#     # n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding=\'SAME\', W_init=w_init, name=\'n256s1/2\')\n#     # n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name=\'pixelshufflerx2/2\')\n#\n#     ## 0, 1, 2, 3 BILINEAR NEAREST BICUBIC AREA\n#     n = UpSampling2dLayer(n, size=[size[1] * 2, size[2] * 2], is_scale=False, method=1, align_corners=False, name=\'up1/upsample2d\')\n#     n = Conv2d(n, 64, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'up1/conv2d\')  # <-- may need to increase n_filter\n#     n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name=\'up1/batch_norm\')\n#\n#     n = UpSampling2dLayer(n, size=[size[1] * 4, size[2] * 4], is_scale=False, method=1, align_corners=False, name=\'up2/upsample2d\')\n#     n = Conv2d(n, 32, (3, 3), (1, 1), padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'up2/conv2d\')  # <-- may need to increase n_filter\n#     n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name=\'up2/batch_norm\')\n#\n#     n = Conv2d(n, 3, (1, 1), (1, 1), act=tf.nn.tanh, padding=\'SAME\', W_init=w_init, name=\'out\')\n#     return n\n\n\n# def SRGAN_d2(t_image, is_train=False, reuse=False):\n#     """""" Discriminator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n#     feature maps (n) and stride (s) feature maps (n) and stride (s)\n#     """"""\n#     w_init = tf.random_normal_initializer(stddev=0.02)\n#     b_init = None\n#     g_init = tf.random_normal_initializer(1., 0.02)\n#     lrelu = lambda x: tl.act.lrelu(x, 0.2)\n#     with tf.variable_scope(""SRGAN_d"", reuse=reuse) as vs:\n#         # tl.layers.set_name_reuse(reuse) # remove for TL 1.8.0+\n#         n = InputLayer(t_image, name=\'in\')\n#         n = Conv2d(n, 64, (3, 3), (1, 1), act=lrelu, padding=\'SAME\', W_init=w_init, name=\'n64s1/c\')\n#\n#         n = Conv2d(n, 64, (3, 3), (2, 2), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n64s2/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n64s2/b\')\n#\n#         n = Conv2d(n, 128, (3, 3), (1, 1), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n128s1/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n128s1/b\')\n#\n#         n = Conv2d(n, 128, (3, 3), (2, 2), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n128s2/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n128s2/b\')\n#\n#         n = Conv2d(n, 256, (3, 3), (1, 1), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n256s1/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n256s1/b\')\n#\n#         n = Conv2d(n, 256, (3, 3), (2, 2), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n256s2/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n256s2/b\')\n#\n#         n = Conv2d(n, 512, (3, 3), (1, 1), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n512s1/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n512s1/b\')\n#\n#         n = Conv2d(n, 512, (3, 3), (2, 2), act=lrelu, padding=\'SAME\', W_init=w_init, b_init=b_init, name=\'n512s2/c\')\n#         n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name=\'n512s2/b\')\n#\n#         n = FlattenLayer(n, name=\'f\')\n#         n = DenseLayer(n, n_units=1024, act=lrelu, name=\'d1024\')\n#         n = DenseLayer(n, n_units=1, name=\'out\')\n#\n#         logits = n.outputs\n#         n.outputs = tf.nn.sigmoid(n.outputs)\n#\n#         return n, logits\n\n\n# def Vgg19_simple_api(rgb, reuse):\n#     """"""\n#     Build the VGG 19 Model\n#\n#     Parameters\n#     -----------\n#     rgb : rgb image placeholder [batch, height, width, 3] values scaled [0, 1]\n#     """"""\n#     VGG_MEAN = [103.939, 116.779, 123.68]\n#     with tf.variable_scope(""VGG19"", reuse=reuse) as vs:\n#         start_time = time.time()\n#         print(""build model started"")\n#         rgb_scaled = rgb * 255.0\n#         # Convert RGB to BGR\n#         if tf.__version__ <= \'0.11\':\n#             red, green, blue = tf.split(3, 3, rgb_scaled)\n#         else:  # TF 1.0\n#             # print(rgb_scaled)\n#             red, green, blue = tf.split(rgb_scaled, 3, 3)\n#         assert red.get_shape().as_list()[1:] == [224, 224, 1]\n#         assert green.get_shape().as_list()[1:] == [224, 224, 1]\n#         assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n#         if tf.__version__ <= \'0.11\':\n#             bgr = tf.concat(3, [\n#                 blue - VGG_MEAN[0],\n#                 green - VGG_MEAN[1],\n#                 red - VGG_MEAN[2],\n#             ])\n#         else:\n#             bgr = tf.concat(\n#                 [\n#                     blue - VGG_MEAN[0],\n#                     green - VGG_MEAN[1],\n#                     red - VGG_MEAN[2],\n#                 ], axis=3)\n#         assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n#         """""" input layer """"""\n#         net_in = InputLayer(bgr, name=\'input\')\n#         """""" conv1 """"""\n#         network = Conv2d(net_in, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv1_1\')\n#         network = Conv2d(network, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv1_2\')\n#         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding=\'SAME\', name=\'pool1\')\n#         """""" conv2 """"""\n#         network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv2_1\')\n#         network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv2_2\')\n#         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding=\'SAME\', name=\'pool2\')\n#         """""" conv3 """"""\n#         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv3_1\')\n#         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv3_2\')\n#         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv3_3\')\n#         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv3_4\')\n#         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding=\'SAME\', name=\'pool3\')\n#         """""" conv4 """"""\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv4_1\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv4_2\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv4_3\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv4_4\')\n#         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding=\'SAME\', name=\'pool4\')  # (batch_size, 14, 14, 512)\n#         conv = network\n#         """""" conv5 """"""\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv5_1\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv5_2\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv5_3\')\n#         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding=\'SAME\', name=\'conv5_4\')\n#         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding=\'SAME\', name=\'pool5\')  # (batch_size, 7, 7, 512)\n#         """""" fc 6~8 """"""\n#         network = FlattenLayer(network, name=\'flatten\')\n#         network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name=\'fc6\')\n#         network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name=\'fc7\')\n#         network = DenseLayer(network, n_units=1000, act=tf.identity, name=\'fc8\')\n#         print(""build model finished: %fs"" % (time.time() - start_time))\n#         return network, conv\n\n\n# def vgg16_cnn_emb(t_image, reuse=False):\n#     """""" t_image = 244x244 [0~255] """"""\n#     with tf.variable_scope(""vgg16_cnn"", reuse=reuse) as vs:\n#         tl.layers.set_name_reuse(reuse)\n#\n#         mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name=\'img_mean\')\n#         net_in = InputLayer(t_image - mean, name=\'vgg_input_im\')\n#         """""" conv1 """"""\n#         network = tl.layers.Conv2dLayer(net_in,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 3, 64],  # 64 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv1_1\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 64, 64],  # 64 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv1_2\')\n#         network = tl.layers.PoolLayer(network,\n#                         ksize=[1, 2, 2, 1],\n#                         strides=[1, 2, 2, 1],\n#                         padding=\'SAME\',\n#                         pool = tf.nn.max_pool,\n#                         name =\'vgg_pool1\')\n#         """""" conv2 """"""\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 64, 128],  # 128 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv2_1\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 128, 128],  # 128 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv2_2\')\n#         network = tl.layers.PoolLayer(network,\n#                         ksize=[1, 2, 2, 1],\n#                         strides=[1, 2, 2, 1],\n#                         padding=\'SAME\',\n#                         pool = tf.nn.max_pool,\n#                         name =\'vgg_pool2\')\n#         """""" conv3 """"""\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 128, 256],  # 256 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv3_1\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 256, 256],  # 256 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv3_2\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 256, 256],  # 256 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv3_3\')\n#         network = tl.layers.PoolLayer(network,\n#                         ksize=[1, 2, 2, 1],\n#                         strides=[1, 2, 2, 1],\n#                         padding=\'SAME\',\n#                         pool = tf.nn.max_pool,\n#                         name =\'vgg_pool3\')\n#         """""" conv4 """"""\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 256, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv4_1\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 512, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv4_2\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 512, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv4_3\')\n#\n#         network = tl.layers.PoolLayer(network,\n#                         ksize=[1, 2, 2, 1],\n#                         strides=[1, 2, 2, 1],\n#                         padding=\'SAME\',\n#                         pool = tf.nn.max_pool,\n#                         name =\'vgg_pool4\')\n#         conv4 = network\n#\n#         """""" conv5 """"""\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 512, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv5_1\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 512, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv5_2\')\n#         network = tl.layers.Conv2dLayer(network,\n#                         act = tf.nn.relu,\n#                         shape = [3, 3, 512, 512],  # 512 features for each 3x3 patch\n#                         strides = [1, 1, 1, 1],\n#                         padding=\'SAME\',\n#                         name =\'vgg_conv5_3\')\n#         network = tl.layers.PoolLayer(network,\n#                         ksize=[1, 2, 2, 1],\n#                         strides=[1, 2, 2, 1],\n#                         padding=\'SAME\',\n#                         pool = tf.nn.max_pool,\n#                         name =\'vgg_pool5\')\n#\n#         network = FlattenLayer(network, name=\'vgg_flatten\')\n#\n#         # # network = DropoutLayer(network, keep=0.6, is_fix=True, is_train=is_train, name=\'vgg_out/drop1\')\n#         # new_network = tl.layers.DenseLayer(network, n_units=4096,\n#         #                     act = tf.nn.relu,\n#         #                     name = \'vgg_out/dense\')\n#         #\n#         # # new_network = DropoutLayer(new_network, keep=0.8, is_fix=True, is_train=is_train, name=\'vgg_out/drop2\')\n#         # new_network = DenseLayer(new_network, z_dim, #num_lstm_units,\n#         #             b_init=None, name=\'vgg_out/out\')\n#         return conv4, network\n'"
train.py,13,"b'#! /usr/bin/python\n# -*- coding: utf8 -*-\n\nimport os\nimport time\nimport random\nimport numpy as np\nimport scipy, multiprocessing\nimport tensorflow as tf\nimport tensorlayer as tl\nfrom model import get_G, get_D\nfrom config import config\n\n###====================== HYPER-PARAMETERS ===========================###\n## Adam\nbatch_size = config.TRAIN.batch_size  # use 8 if your GPU memory is small, and change [4, 4] in tl.vis.save_images to [2, 4]\nlr_init = config.TRAIN.lr_init\nbeta1 = config.TRAIN.beta1\n## initialize G\nn_epoch_init = config.TRAIN.n_epoch_init\n## adversarial learning (SRGAN)\nn_epoch = config.TRAIN.n_epoch\nlr_decay = config.TRAIN.lr_decay\ndecay_every = config.TRAIN.decay_every\nshuffle_buffer_size = 128\n\n# ni = int(np.sqrt(batch_size))\n\n# create folders to save result images and trained models\nsave_dir = ""samples""\ntl.files.exists_or_mkdir(save_dir)\ncheckpoint_dir = ""models""\ntl.files.exists_or_mkdir(checkpoint_dir)\n\ndef get_train_data():\n    # load dataset\n    train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx=\'.*.png\', printable=False))#[0:20]\n        # train_lr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.lr_img_path, regx=\'.*.png\', printable=False))\n        # valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx=\'.*.png\', printable=False))\n        # valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx=\'.*.png\', printable=False))\n\n    ## If your machine have enough memory, please pre-load the entire train set.\n    train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)\n        # for im in train_hr_imgs:\n        #     print(im.shape)\n        # valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n        # for im in valid_lr_imgs:\n        #     print(im.shape)\n        # valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n        # for im in valid_hr_imgs:\n        #     print(im.shape)\n        \n    # dataset API and augmentation\n    def generator_train():\n        for img in train_hr_imgs:\n            yield img\n    def _map_fn_train(img):\n        hr_patch = tf.image.random_crop(img, [384, 384, 3])\n        hr_patch = hr_patch / (255. / 2.)\n        hr_patch = hr_patch - 1.\n        hr_patch = tf.image.random_flip_left_right(hr_patch)\n        lr_patch = tf.image.resize(hr_patch, size=[96, 96])\n        return lr_patch, hr_patch\n    train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n    train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n        # train_ds = train_ds.repeat(n_epoch_init + n_epoch)\n    train_ds = train_ds.shuffle(shuffle_buffer_size)\n    train_ds = train_ds.prefetch(buffer_size=2)\n    train_ds = train_ds.batch(batch_size)\n        # value = train_ds.make_one_shot_iterator().get_next()\n    return train_ds\n\ndef train():\n    G = get_G((batch_size, 96, 96, 3))\n    D = get_D((batch_size, 384, 384, 3))\n    VGG = tl.models.vgg19(pretrained=True, end_with=\'pool4\', mode=\'static\')\n\n    lr_v = tf.Variable(lr_init)\n    g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n    g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n    d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n\n    G.train()\n    D.train()\n    VGG.train()\n\n    train_ds = get_train_data()\n\n    ## initialize learning (G)\n    n_step_epoch = round(n_epoch_init // batch_size)\n    for epoch in range(n_epoch_init):\n        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n                break\n            step_time = time.time()\n            with tf.GradientTape() as tape:\n                fake_hr_patchs = G(lr_patchs)\n                mse_loss = tl.cost.mean_squared_error(fake_hr_patchs, hr_patchs, is_mean=True)\n            grad = tape.gradient(mse_loss, G.trainable_weights)\n            g_optimizer_init.apply_gradients(zip(grad, G.trainable_weights))\n            print(""Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mse: {:.3f} "".format(\n                epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss))\n        if (epoch != 0) and (epoch % 10 == 0):\n            tl.vis.save_images(fake_hr_patchs.numpy(), [2, 4], os.path.join(save_dir, \'train_g_init_{}.png\'.format(epoch)))\n\n    ## adversarial learning (G, D)\n    n_step_epoch = round(n_epoch // batch_size)\n    for epoch in range(n_epoch):\n        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n                break\n            step_time = time.time()\n            with tf.GradientTape(persistent=True) as tape:\n                fake_patchs = G(lr_patchs)\n                logits_fake = D(fake_patchs)\n                logits_real = D(hr_patchs)\n                feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1]\n                feature_real = VGG((hr_patchs+1)/2.)\n                d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n                d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n                d_loss = d_loss1 + d_loss2\n                g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n                mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n                vgg_loss = 2e-6 * tl.cost.mean_squared_error(feature_fake, feature_real, is_mean=True)\n                g_loss = mse_loss + vgg_loss + g_gan_loss\n            grad = tape.gradient(g_loss, G.trainable_weights)\n            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n            grad = tape.gradient(d_loss, D.trainable_weights)\n            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n            print(""Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f}"".format(\n                epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss))\n\n        # update the learning rate\n        if epoch != 0 and (epoch % decay_every == 0):\n            new_lr_decay = lr_decay**(epoch // decay_every)\n            lr_v.assign(lr_init * new_lr_decay)\n            log = "" ** new learning rate: %f (for GAN)"" % (lr_init * new_lr_decay)\n            print(log)\n\n        if (epoch != 0) and (epoch % 10 == 0):\n            tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, \'train_g_{}.png\'.format(epoch)))\n            G.save_weights(os.path.join(checkpoint_dir, \'g.h5\'))\n            D.save_weights(os.path.join(checkpoint_dir, \'d.h5\'))\n\ndef evaluate():\n    ###====================== PRE-LOAD DATA ===========================###\n    # train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx=\'.*.png\', printable=False))\n    # train_lr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.lr_img_path, regx=\'.*.png\', printable=False))\n    valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx=\'.*.png\', printable=False))\n    valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx=\'.*.png\', printable=False))\n\n    ## if your machine have enough memory, please pre-load the whole train set.\n    # train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)\n    # for im in train_hr_imgs:\n    #     print(im.shape)\n    valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n    # for im in valid_lr_imgs:\n    #     print(im.shape)\n    valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n    # for im in valid_hr_imgs:\n    #     print(im.shape)\n\n    ###========================== DEFINE MODEL ============================###\n    imid = 64  # 0: \xe4\xbc\x81\xe9\xb9\x85  81: \xe8\x9d\xb4\xe8\x9d\xb6 53: \xe9\xb8\x9f  64: \xe5\x8f\xa4\xe5\xa0\xa1\n    valid_lr_img = valid_lr_imgs[imid]\n    valid_hr_img = valid_hr_imgs[imid]\n    # valid_lr_img = get_imgs_fn(\'test.png\', \'data2017/\')  # if you want to test your own image\n    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to \xef\xbc\xbb\xef\xbc\x8d1, 1]\n    # print(valid_lr_img.min(), valid_lr_img.max())\n\n    G = get_G([1, None, None, 3])\n    G.load_weights(os.path.join(checkpoint_dir, \'g.h5\'))\n    G.eval()\n\n    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n\n    out = G(valid_lr_img).numpy()\n\n    print(""LR size: %s /  generated HR size: %s"" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n    print(""[*] save images"")\n    tl.vis.save_image(out[0], os.path.join(save_dir, \'valid_gen.png\'))\n    tl.vis.save_image(valid_lr_img[0], os.path.join(save_dir, \'valid_lr.png\'))\n    tl.vis.save_image(valid_hr_img, os.path.join(save_dir, \'valid_hr.png\'))\n\n    out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp=\'bicubic\', mode=None)\n    tl.vis.save_image(out_bicu, os.path.join(save_dir, \'valid_bicubic.png\'))\n\n\nif __name__ == \'__main__\':\n    import argparse\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--mode\', type=str, default=\'srgan\', help=\'srgan, evaluate\')\n\n    args = parser.parse_args()\n\n    tl.global_flag[\'mode\'] = args.mode\n\n    if tl.global_flag[\'mode\'] == \'srgan\':\n        train()\n    elif tl.global_flag[\'mode\'] == \'evaluate\':\n        evaluate()\n    else:\n        raise Exception(""Unknow --mode"")\n'"
