file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\nimport sys\nfrom setuptools import setup, find_packages\nfrom setuptools.command.test import test as TestCommand\n\n# explicitly config\ntest_args = [\n    \'--cov-report=term\',\n    \'--cov-report=html\',\n    \'--cov=tflearn\',\n    \'tests\'\n]\n\n\nclass PyTest(TestCommand):\n    user_options = [(\'pytest-args=\', \'a\', ""Arguments to pass to py.test"")]\n\n    def initialize_options(self):\n        TestCommand.initialize_options(self)\n        self.pytest_args = test_args\n\n    def run_tests(self):\n        # import here, cause outside the eggs aren\'t loaded\n        import pytest\n        errno = pytest.main(self.pytest_args)\n        sys.exit(errno)\n\n\nsetup(name=\'tflearn\',\n      version=\'0.3.2\',\n      description=\'Deep Learning Library featuring a higher-level API for \'\n                  \'TensorFlow\',\n      author=\'TFLearn contributors\',\n      author_email=\'aymeric.damien@gmail.com\',\n      url=\'https://github.com/tflearn/tflearn\',\n      download_url=\'https://github.com/tflearn/tflearn/tarball/0.3.2\',\n      license=\'MIT\',\n      packages=find_packages(exclude=[\'tests*\']),\n      install_requires=[\n          \'numpy\',\n          \'six\',\n          \'Pillow\'\n      ],\n      test_suite=\'tests\',\n      cmdclass={\'test\': PyTest},\n      classifiers=[\n          \'Programming Language :: Python\',\n          \'Operating System :: OS Independent\',\n          \'Intended Audience :: Developers\',\n          \'Intended Audience :: Science/Research\',\n          \'Topic :: Scientific/Engineering :: Artificial Intelligence\'\n      ],\n      keywords=[\n          \'TFLearn\',\n          \'TensorFlow\',\n          \'Deep Learning\',\n          \'Machine Learning\',\n          \'Neural Networks\',\n          \'AI\'\n      ]\n      )\n'"
docs/autodoc.py,0,"b'from __future__ import division, print_function, absolute_import\n\nimport inspect\nimport os\nimport os.path\nfrom inspect import getmembers, isfunction\nimport re\nimport ast\n\nimport tflearn\nfrom tflearn import activations\nfrom tflearn import callbacks\nfrom tflearn import collections\nimport tflearn.config\nfrom tflearn import initializations\nfrom tflearn import metrics\nfrom tflearn import objectives\nfrom tflearn import optimizers\nfrom tflearn import data_utils\nfrom tflearn import regularizers\nfrom tflearn import summaries\nfrom tflearn import utils\nfrom tflearn import variables\nfrom tflearn import data_flow\nfrom tflearn import data_preprocessing\nfrom tflearn import data_augmentation\nfrom tflearn.layers import conv\nfrom tflearn.layers import core\nfrom tflearn.layers import embedding_ops\nfrom tflearn.layers import estimator\nfrom tflearn.layers import merge_ops\nfrom tflearn.layers import normalization\nfrom tflearn.layers import recurrent\nfrom tflearn.models import dnn, generator\nfrom tflearn.helpers import evaluator\nfrom tflearn.helpers import regularizer\nfrom tflearn.helpers import summarizer\nfrom tflearn.helpers import trainer\n\nROOT = \'http://tflearn.org/\'\n\nMODULES = [(activations, \'tflearn.activations\'),\n           (callbacks, \'tflearn.callbacks\'),\n           (collections, \'tflearn.collections\'),\n           (tflearn.config, \'tflearn.config\'),\n           (initializations, \'tflearn.initializations\'),\n           (metrics, \'tflearn.metrics\'),\n           (objectives, \'tflearn.objectives\'),\n           (optimizers, \'tflearn.optimizers\'),\n           (data_utils, \'tflearn.data_utils\'),\n           (regularizers, \'tflearn.regularizers\'),\n           (summaries, \'tflearn.summaries\'),\n           (variables, \'tflearn.variables\'),\n           (utils, \'tflearn.utils\'),\n           (data_flow, \'tflearn.data_flow\'),\n           (data_preprocessing, \'tflearn.data_preprocessing\'),\n           (data_augmentation, \'tflearn.data_augmentation\'),\n           (conv, \'tflearn.layers.conv\'),\n           (core, \'tflearn.layers.core\'),\n           (embedding_ops, \'tflearn.layers.embedding_ops\'),\n           (estimator, \'tflearn.layers.estimator\'),\n           (merge_ops, \'tflearn.layers.merge_ops\'),\n           (normalization, \'tflearn.layers.normalization\'),\n           (recurrent, \'tflearn.layers.recurrent\'),\n           (dnn, \'tflearn.models.dnn\'),\n           (generator, \'tflearn.models.generator\'),\n           (evaluator, \'tflearn.helpers.evaluator\'),\n           (regularizer, \'tflearn.helpers.regularizer\'),\n           (summarizer, \'tflearn.helpers.summarizer\'),\n           (trainer, \'tflearn.helpers.trainer\')]\n\nKEYWORDS = [\'Input\', \'Output\', \'Examples\', \'Arguments\', \'Attributes\',\n            \'Returns\', \'Raises\', \'References\', \'Links\', \'Yields\']\n\nSKIP = [\'get_from_module\', \'leakyrelu\', \'RNNCell\', \'resize_image\']\n\n\ndef top_level_functions(body):\n    return (f for f in body if isinstance(f, ast.FunctionDef))\n\n\ndef top_level_classes(body):\n    return (f for f in body if isinstance(f, ast.ClassDef))\n\n\ndef parse_ast(filename):\n    with open(filename, ""rt"") as file:\n        return ast.parse(file.read(), filename=filename)\n\n\ndef format_func_doc(docstring, header):\n\n    rev_docstring = \'\'\n\n    if docstring:\n        # Erase 2nd lines\n        docstring = docstring.replace(\'\\n\' + \'    \' * 3, \'\')\n        docstring = docstring.replace(\'    \' * 2, \'\')\n        name = docstring.split(\'\\n\')[0]\n        docstring = docstring[len(name):]\n        if name[-1] == \'.\':\n            name = name[:-1]\n        docstring = \'\\n\\n\' + header_style(header) + docstring\n        docstring = ""# "" + name + docstring\n\n        # format arguments\n        for o in [\'Arguments\', \'Attributes\']:\n            if docstring.find(o + \':\') > -1:\n                args = docstring[docstring.find(o + \':\'):].split(\'\\n\\n\')[0]\n                args = args.replace(\'    \', \' - \')\n                args = re.sub(r\' - ([A-Za-z0-9_]+):\', r\' - **\\1**:\', args)\n                if rev_docstring == \'\':\n                    rev_docstring = docstring[:docstring.find(o + \':\')] + args\n                else:\n                    rev_docstring += \'\\n\\n\' + args\n\n        for o in [\'Returns\', \'References\', \'Links\']:\n            if docstring.find(o + \':\') > -1:\n                desc = docstring[docstring.find(o + \':\'):].split(\'\\n\\n\')[0]\n                desc = desc.replace(\'\\n-\', \'\\n\\n-\')\n                desc = desc.replace(\'    \', \'\')\n                if rev_docstring == \'\':\n                    rev_docstring = docstring[:docstring.find(o + \':\')] + desc\n                else:\n                    rev_docstring += \'\\n\\n\' + desc\n\n        rev_docstring = rev_docstring.replace(\'    \', \'\')\n        rev_docstring = rev_docstring.replace(\']\\n(http\', \'](http\')\n        for keyword in KEYWORDS:\n            rev_docstring = rev_docstring.replace(keyword + \':\', \'<h3>\'\n                                                  + keyword + \'</h3>\\n\\n\')\n    else:\n        rev_docstring = """"\n    return rev_docstring\n\n\ndef format_method_doc(docstring, header):\n\n    rev_docstring = \'\'\n\n    if docstring:\n        docstring = docstring.replace(\'\\n\' + \'    \' * 4, \'\')\n        docstring = docstring.replace(\'\\n\' + \'    \' * 3, \'\')\n        docstring = docstring.replace(\'    \' * 2, \'\')\n        name = docstring.split(\'\\n\')[0]\n        docstring = docstring[len(name):]\n        if name[-1] == \'.\':\n            name = name[:-1]\n        docstring = \'\\n\\n\' + method_header_style(header) + docstring\n        #docstring = ""\\n\\n <h3>"" + name + ""</h3>"" + docstring\n\n        # format arguments\n        for o in [\'Arguments\', \'Attributes\']:\n            if docstring.find(o + \':\') > -1:\n                args = docstring[docstring.find(o + \':\'):].split(\'\\n\\n\')[0]\n                args = args.replace(\'    \', \' - \')\n                args = re.sub(r\' - ([A-Za-z0-9_]+):\', r\' - **\\1**:\', args)\n                if rev_docstring == \'\':\n                    rev_docstring = docstring[:docstring.find(o + \':\')] + args\n                else:\n                    rev_docstring += \'\\n\\n\' + args\n\n        for o in [\'Returns\', \'References\', \'Links\']:\n            if docstring.find(o + \':\') > -1:\n                desc = docstring[docstring.find(o + \':\'):].split(\'\\n\\n\')[0]\n                desc = desc.replace(\'\\n-\', \'\\n\\n-\')\n                desc = desc.replace(\'    \', \'\')\n                if rev_docstring == \'\':\n                    rev_docstring = docstring[:docstring.find(o + \':\')] + desc\n                else:\n                    rev_docstring += \'\\n\\n\' + desc\n\n        rev_docstring = rev_docstring.replace(\'    \', \'\')\n        rev_docstring = rev_docstring.replace(\']\\n(http\', \'](http\')\n        for keyword in KEYWORDS:\n            rev_docstring = rev_docstring.replace(keyword + \':\', \'<h5>\'\n                                                  + keyword + \'</h5>\\n\\n\')\n    else:\n        rev_docstring = """"\n    return rev_docstring\n\n\ndef classesinmodule(module):\n    classes = []\n    tree = parse_ast(os.path.abspath(module.__file__).replace(\'.pyc\', \'.py\'))\n    for c in top_level_classes(tree.body):\n        classes.append(eval(module.__name__ + \'.\' + c.name))\n    return classes\n\n\ndef functionsinmodule(module):\n    fn = []\n    tree = parse_ast(os.path.abspath(module.__file__).replace(\'.pyc\', \'.py\'))\n    for c in top_level_functions(tree.body):\n        fn.append(eval(module.__name__ + \'.\' + c.name))\n    return fn\n\n\ndef enlarge_span(str):\n    return \'<span style=""font-size:115%"">\' + str + \'</span>\'\n\n\ndef header_style(header):\n    name = header.split(\'(\')[0]\n    bold_name = \'<span style=""color:black;""><b>\' + name + \'</b></span>\'\n    header = header.replace(\'self, \', \'\').replace(\'(\', \' (\').replace(\' \', \'  \')\n    header = header.replace(name, bold_name)\n    # return \'<span style=""display: inline-block;margin: 6px 0;font-size: \' \\\n    #        \'90%;line-height: 140%;background: #e7f2fa;color: #2980B9;\' \\\n    #        \'border-top: solid 3px #6ab0de;padding: 6px;position: relative;\' \\\n    #        \'font-weight:600"">\' + header + \'</span>\'\n    return \'<span class=""extra_h1"">\' + header + \'</span>\'\n\n\ndef method_header_style(header):\n    name = header.split(\'(\')[0]\n    bold_name = \'<span style=""color:black""><b>\' + name + \'</b></span>\'\n    header = header.replace(\'self, \', \'\').replace(\'(\', \' (\').replace(\' \', \'  \')\n    header = header.replace(name, bold_name)\n    return \'<span class=""extra_h2"">\' + header + \'</span>\'\n\n\n\nprint(\'Starting...\')\nclasses_and_functions = set()\n\n\ndef get_func_doc(name, func):\n    doc_source = \'\'\n    if name in SKIP:\n        return  \'\'\n    if name[0] == \'_\':\n        return \'\'\n    if func in classes_and_functions:\n        return \'\'\n    classes_and_functions.add(func)\n    header = name + inspect.formatargspec(*inspect.getargspec(func))\n    docstring = format_func_doc(inspect.getdoc(func), module_name + \'.\' +\n                                header)\n\n    if docstring != \'\':\n        doc_source += docstring\n        doc_source += \'\\n\\n ---------- \\n\\n\'\n\n    return doc_source\n\n\ndef get_method_doc(name, func):\n    doc_source = \'\'\n    if name in SKIP:\n        return  \'\'\n    if name[0] == \'_\':\n        return \'\'\n    if func in classes_and_functions:\n        return \'\'\n    classes_and_functions.add(func)\n    header = name + inspect.formatargspec(*inspect.getargspec(func))\n    docstring = format_method_doc(inspect.getdoc(func), header)\n\n    if docstring != \'\':\n        doc_source += \'\\n\\n <span class=""hr_large""></span> \\n\\n\'\n        doc_source += docstring\n\n    return doc_source\n\n\ndef get_class_doc(c):\n    doc_source = \'\'\n    if c.__name__ in SKIP:\n        return \'\'\n    if c.__name__[0] == \'_\':\n        return \'\'\n    if c in classes_and_functions:\n        return \'\'\n    classes_and_functions.add(c)\n    header = c.__name__ + inspect.formatargspec(*inspect.getargspec(\n        c.__init__))\n    docstring = format_func_doc(inspect.getdoc(c), module_name + \'.\' +\n                                header)\n\n    method_doc = \'\'\n    if docstring != \'\':\n        methods = inspect.getmembers(c, predicate=inspect.ismethod)\n        if len(methods) > 0:\n            method_doc += \'\\n\\n<h2>Methods</h2>\'\n        for name, func in methods:\n            method_doc += get_method_doc(name, func)\n        if method_doc == \'\\n\\n<h2>Methods</h2>\':\n            method_doc = \'\'\n        doc_source += docstring + method_doc\n        doc_source += \'\\n\\n --------- \\n\\n\'\n\n    return doc_source\n\nfor module, module_name in MODULES:\n\n    # Handle Classes\n    md_source = """"\n    for c in classesinmodule(module):\n        md_source += get_class_doc(c)\n\n    # Handle Functions\n    for func in functionsinmodule(module):\n        md_source += get_func_doc(func.__name__, func)\n\n    # save module page.\n    # Either insert content into existing page,\n    # or create page otherwise\n    path = \'templates/\' + module_name.replace(\'.\', \'/\')[8:] + \'.md\'\n    if False: #os.path.exists(path):\n        template = open(path).read()\n        assert \'{{autogenerated}}\' in template, (\'Template found for \' + path +\n                                                 \' but missing {{autogenerated}} tag.\')\n        md_source = template.replace(\'{{autogenerated}}\', md_source)\n        print(\'...inserting autogenerated content into template:\', path)\n    else:\n        print(\'...creating new page with autogenerated content:\', path)\n    subdir = os.path.dirname(path)\n    if not os.path.exists(subdir):\n        os.makedirs(subdir)\n    open(path, \'w\').write(md_source)\n'"
tests/__init__.py,0,b''
tests/test.py,8,"b'\'\'\'\n    This file contains test cases for tflearn\n\'\'\'\n\nimport tensorflow as tf\nimport tflearn\nimport unittest\n\nclass TestActivations(unittest.TestCase):\n    \'\'\'\n        This class contains test cases for the functions in tflearn/activations.py\n    \'\'\'\n    PLACES = 4 # Number of places to match when testing floating point values\n\n    def test_linear(self):\n        f = tflearn.linear\n\n        # Case 1\n        x = tf.placeholder(tf.float32, shape=())\n        self.assertEqual(f(x), x)\n\n        # Case 2\n        x = tf.placeholder(tf.int64, shape=())\n        self.assertEqual(f(x), x)\n\n    def test_tanh(self):\n        f = tflearn.tanh\n        x = tf.placeholder(tf.float32, shape=())\n        \n        with tf.Session() as sess:\n            # Case 1\n            self.assertEqual(sess.run(f(x), feed_dict={x:0}), 0)\n\n            # Case 2\n            self.assertAlmostEqual(sess.run(f(x), feed_dict={x:0.5}),\n                0.4621, places=TestActivations.PLACES)\n\n            # Case 3\n            self.assertAlmostEqual(sess.run(f(x), feed_dict={x:-0.25}),\n                -0.2449, places=TestActivations.PLACES)\n\n    def test_leaky_relu(self):\n        f = lambda x: tflearn.leaky_relu(x, alpha=0.2)\n        x = tf.placeholder(tf.float32, shape=())\n\n        with tf.Session() as sess:\n            # Case 1\n            self.assertEqual(sess.run(f(x), feed_dict={x:0}), 0)\n\n            # Case 2\n            self.assertAlmostEqual(sess.run(f(x), feed_dict={x:1}),\n                1, places=TestActivations.PLACES)\n\n            # Case 3\n            self.assertAlmostEqual(sess.run(f(x), feed_dict={x:-1}),\n                -0.2, places=TestActivations.PLACES)\n\n            # Case 4\n            self.assertAlmostEqual(sess.run(f(x), feed_dict={x:-5}),\n                -1, places=TestActivations.PLACES)\n\n    def test_apply_activation(self):\n        lrelu_02 = lambda x: tflearn.leaky_relu(x, alpha=0.2)\n        x = tf.constant(-0.25, tf.float32)\n\n        with tf.Session() as sess:\n            # Case 1: \'linear\'\n            self.assertEqual(\n                sess.run(tflearn.activation(x, \'linear\')),\n                -0.25)\n\n            # Case 2: \'relu\'\n            self.assertEqual(\n                sess.run(tflearn.activation(x, \'relu\')),\n                0)\n\n            # Case 3: \'leaky_relu\'\n            self.assertAlmostEqual(\n                sess.run(tflearn.activation(x, \'leaky_relu\')),\n                -0.025, places=TestActivations.PLACES)\n\n            # Case 4: \'tanh\'\n            self.assertAlmostEqual(\n                sess.run(tflearn.activation(x, \'tanh\')),\n                -0.2449, places=TestActivations.PLACES)\n\n            # Case 5: lrelu_02 (callable)\n            self.assertAlmostEqual(\n                sess.run(tflearn.activation(x, lrelu_02)),\n                -0.05, places=TestActivations.PLACES)\n\nif __name__ == ""__main__"":\n    unittest.main()'"
tests/test_helpers.py,11,"b'import tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nclass TestHelpers(unittest.TestCase):\n    """"""\n    Testing helper functions from tflearn/helpers\n    """"""\n\n    def test_variable(self):\n        # Bulk Tests\n        with tf.Graph().as_default():\n            W = tflearn.variable(name=\'W1\', shape=[784, 256],\n                     initializer=\'uniform_scaling\',\n                     regularizer=\'L2\')\n            W = tflearn.variable(name=\'W2\', shape=[784, 256],\n                     initializer=\'uniform_scaling\',\n                     regularizer=\'L2\')\n\n    def test_regularizer(self):\n        # Bulk Tests\n        with tf.Graph().as_default():\n            x = tf.placeholder(""float"", [None, 4])\n            W = tf.Variable(tf.random_normal([4, 4]))\n            x = tf.nn.tanh(tf.matmul(x, W))\n            tflearn.add_weights_regularizer(W, \'L2\', weight_decay=0.001)\n\n    def test_summarizer(self):\n        # Bulk Tests\n        with tf.Graph().as_default():\n            x = tf.placeholder(""float"", [None, 4])\n            W = tf.Variable(tf.random_normal([4, 4]))\n            x = tf.nn.tanh(tf.matmul(x, W))\n            tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, x)\n            import tflearn.helpers.summarizer as s\n            s.summarize_variables([W])\n            s.summarize_activations(tf.get_collection(tf.GraphKeys.ACTIVATIONS))\n            s.summarize(x, \'histogram\', ""test_summary"")\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_inputs.py,4,"b'\'\'\'\n    This file contains test cases for tflearn\n\'\'\'\n\nimport tensorflow as tf\nimport tflearn\nimport unittest\n\nclass TestInputs(unittest.TestCase):\n    \'\'\'\n        This class contains test cases for serval input types\n    \'\'\'\n    INPUT_DATA_1 = [ [ 1 ], [ 2 ], [ 3 ], [ 4 ], [ 5 ] ]\n    INPUT_DATA_2 = [ [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ] ]\n    TARGET = [ [ 14 ], [ 18 ], [ 22 ], [ 26 ], [ 30 ] ]   # (input1 + input2) * 2\n\n    def test_list_inputs(self):\n        """"""Test input a list\n        """"""\n        with tf.Graph().as_default():\n            model, inputs, target = self.build_simple_model()\n            model.fit([ inpData for _, _, inpData in inputs ], target, batch_size = 1)\n\n    def test_dict_inputs(self):\n        """"""Test input a dict with layer name\n        """"""\n        with tf.Graph().as_default():\n            model, inputs, target = self.build_simple_model()\n            model.fit({ name: inpData for name, _, inpData in inputs }, target, batch_size = 1)\n\n    def test_dict_withtensor_inputs(self):\n        """"""Test input a dict with placeholder\n        """"""\n        with tf.Graph().as_default():\n            model, inputs, target = self.build_simple_model()\n            model.fit({ placeholder: inpData for _, placeholder, inpData in inputs }, target, batch_size = 1)\n\n    def build_simple_model(self):\n        """"""Build a simple model for test\n        Returns:\n            DNN, [ (input layer name, input placeholder, input data) ], Target data\n        """"""\n        inputPlaceholder1, inputPlaceholder2 = \\\n            tf.placeholder(tf.float32, (1, 1), name = ""input1""), tf.placeholder(tf.float32, (1, 1), name = ""input2"")\n        input1 = tflearn.input_data(placeholder = inputPlaceholder1)\n        input2 = tflearn.input_data(placeholder = inputPlaceholder2)\n        network = tflearn.merge([ input1, input2 ], ""sum"")\n        network = tflearn.reshape(network, (1, 1))\n        network = tflearn.fully_connected(network, 1)\n        network = tflearn.regression(network)\n        return (\n            tflearn.DNN(network),\n            [ (""input1:0"", inputPlaceholder1, self.INPUT_DATA_1), (""input2:0"", inputPlaceholder2, self.INPUT_DATA_2) ],\n            self.TARGET,\n        )\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_layers.py,10,"b'import tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nclass TestLayers(unittest.TestCase):\n    """"""\n    Testing layers from tflearn/layers\n    """"""\n\n    def test_core_layers(self):\n\n        X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n        Y_nand = [[1.], [1.], [1.], [0.]]\n        Y_or = [[0.], [1.], [1.], [1.]]\n\n        # Graph definition\n        with tf.Graph().as_default():\n            # Building a network with 2 optimizers\n            g = tflearn.input_data(shape=[None, 2])\n\n            # Nand operator definition\n            g_nand = tflearn.fully_connected(g, 32, activation=\'linear\')\n            g_nand = tflearn.fully_connected(g_nand, 32, activation=\'linear\')\n            g_nand = tflearn.fully_connected(g_nand, 1, activation=\'sigmoid\')\n            g_nand = tflearn.regression(g_nand, optimizer=\'sgd\',\n                                        learning_rate=2.,\n                                        loss=\'binary_crossentropy\')\n            # Or operator definition\n            g_or = tflearn.fully_connected(g, 32, activation=\'linear\')\n            g_or = tflearn.fully_connected(g_or, 32, activation=\'linear\')\n            g_or = tflearn.fully_connected(g_or, 1, activation=\'sigmoid\')\n            g_or = tflearn.regression(g_or, optimizer=\'sgd\',\n                                      learning_rate=2.,\n                                      loss=\'binary_crossentropy\')\n            # XOR merging Nand and Or operators\n            g_xor = tflearn.merge([g_nand, g_or], mode=\'elemwise_mul\')\n\n            # Training\n            m = tflearn.DNN(g_xor)\n            m.fit(X, [Y_nand, Y_or], n_epoch=400, snapshot_epoch=False)\n\n            # Testing\n            self.assertLess(m.predict([[0., 0.]])[0][0], 0.01)\n            self.assertGreater(m.predict([[0., 1.]])[0][0], 0.9)\n            self.assertGreater(m.predict([[1., 0.]])[0][0], 0.9)\n            self.assertLess(m.predict([[1., 1.]])[0][0], 0.01)\n\n        # Bulk Tests\n        with tf.Graph().as_default():\n            net = tflearn.input_data(shape=[None, 2])\n            net = tflearn.flatten(net)\n            net = tflearn.reshape(net, new_shape=[-1])\n            net = tflearn.activation(net, \'relu\')\n            net = tflearn.dropout(net, 0.5)\n            net = tflearn.single_unit(net)\n\n    def test_conv_layers(self):\n\n        X = [[0., 0., 0., 0.], [1., 1., 1., 1.], [0., 0., 1., 0.], [1., 1., 1., 0.]]\n        Y = [[1., 0.], [0., 1.], [1., 0.], [0., 1.]]\n\n        with tf.Graph().as_default():\n            g = tflearn.input_data(shape=[None, 4])\n            g = tflearn.reshape(g, new_shape=[-1, 2, 2, 1])\n            g = tflearn.conv_2d(g, 4, 2, activation=\'relu\')\n            g = tflearn.max_pool_2d(g, 2)\n            g = tflearn.fully_connected(g, 2, activation=\'softmax\')\n            g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=1.)\n\n            m = tflearn.DNN(g)\n            m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n            # TODO: Fix test\n            #self.assertGreater(m.predict([[1., 0., 0., 0.]])[0][0], 0.5)\n\n        # Bulk Tests\n        with tf.Graph().as_default():\n            g = tflearn.input_data(shape=[None, 4])\n            g = tflearn.reshape(g, new_shape=[-1, 2, 2, 1])\n            g = tflearn.conv_2d(g, 4, 2)\n            g = tflearn.conv_2d(g, 4, 1)\n            g = tflearn.conv_2d_transpose(g, 4, 2, [2, 2])\n            g = tflearn.max_pool_2d(g, 2)\n\n    def test_recurrent_layers(self):\n\n        X = [[1, 3, 5, 7], [2, 4, 8, 10], [1, 5, 9, 11], [2, 6, 8, 0]]\n        Y = [[0., 1.], [1., 0.], [0., 1.], [1., 0.]]\n\n        with tf.Graph().as_default():\n            g = tflearn.input_data(shape=[None, 4])\n            g = tflearn.embedding(g, input_dim=12, output_dim=4)\n            g = tflearn.lstm(g, 6)\n            g = tflearn.fully_connected(g, 2, activation=\'softmax\')\n            g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=1.)\n\n            m = tflearn.DNN(g)\n            m.fit(X, Y, n_epoch=300, snapshot_epoch=False)\n            self.assertGreater(m.predict([[5, 9, 11, 1]])[0][1], 0.9)\n\n    def test_regression_placeholder(self):\n        \'\'\'\n        Check that regression does not duplicate placeholders\n        \'\'\'\n\n        with tf.Graph().as_default():\n\n            g = tflearn.input_data(shape=[None, 2])\n            g_nand = tflearn.fully_connected(g, 1, activation=\'linear\')\n            with tf.name_scope(""Y""):\n                Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=""Y"")\n            tflearn.regression(g_nand, optimizer=\'sgd\',\n                               placeholder=Y_in,\n                               learning_rate=2.,\n                               loss=\'binary_crossentropy\', \n                               op_name=""regression1"",\n                               name=""Y"")\n            # for this test, just use the same default trainable_vars\n            # in practice, this should be different for the two regressions\n            tflearn.regression(g_nand, optimizer=\'adam\',\n                               placeholder=Y_in,\n                               learning_rate=2.,\n                               loss=\'binary_crossentropy\', \n                               op_name=""regression2"",\n                               name=""Y"")\n\n            self.assertEqual(len(tf.get_collection(tf.GraphKeys.TARGETS)), 1)\n\n    def test_feed_dict_no_None(self):\n\n        X = [[0., 0., 0., 0.], [1., 1., 1., 1.], [0., 0., 1., 0.], [1., 1., 1., 0.]]\n        Y = [[1., 0.], [0., 1.], [1., 0.], [0., 1.]]\n\n        with tf.Graph().as_default():\n            g = tflearn.input_data(shape=[None, 4], name=""X_in"")\n            g = tflearn.reshape(g, new_shape=[-1, 2, 2, 1])\n            g = tflearn.conv_2d(g, 4, 2)\n            g = tflearn.conv_2d(g, 4, 1)\n            g = tflearn.max_pool_2d(g, 2)\n            g = tflearn.fully_connected(g, 2, activation=\'softmax\')\n            g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=1.)\n\n            m = tflearn.DNN(g)\n\n            def do_fit():\n                m.fit({""X_in"": X, \'non_existent\': X}, Y, n_epoch=30, snapshot_epoch=False)\n            self.assertRaisesRegexp(Exception, ""Feed dict asks for variable named \'non_existent\' but no such variable is known to exist"", do_fit)\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_metrics.py,9,"b'import tflearn\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\n\nclass TestMetrics(unittest.TestCase):\n    """"""\n    Testing metric functions from tflearn/metrics\n    """"""\n\n    def test_binary_accuracy(self):\n        with tf.Graph().as_default():\n            input_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n            y_true = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n            ba = tflearn.metrics.accuracy()\n            ba.build(input_data, y_true)\n            acc_op = ba.tensor\n    \n            X = np.array([1,-1,1,1,-1,-1]).reshape([-1, 1])\n            Y = np.array([1,0,1,0,0,1]).reshape([-1, 1])\n            with tf.Session() as sess:\n                binary_accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n                print (""binary_accuracy = %s"" % binary_accuracy)\n            self.assertEqual(acc_op.m_name, ""binary_acc"")\n            self.assertLess(abs(binary_accuracy-4.0/6), 0.0001)\n\n    def test_categorical_accuracy(self):\n        with tf.Graph().as_default():\n            input_data = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n            y_true = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n            ba = tflearn.metrics.accuracy()\n            ba.build(input_data, y_true)\n            acc_op = ba.tensor\n    \n            X = np.array([1,-1, -1, 1, 0.5, 0]).reshape([-1, 2])\n            Y = np.array([1, 0,  0, 1, 0,   1]).reshape([-1, 2])\n            with tf.Session() as sess:\n                accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n                print (""categorical accuracy = %s"" % accuracy)\n            self.assertEqual(acc_op.m_name, ""acc"")\n            self.assertLess(abs(accuracy - 2.0/3), 0.0001)\n\n            X = np.array([1,-1, -1, 1, 0.5, 0]).reshape([-1, 2])\n            Y = np.array([1, 0,  0, 1, 1,   0]).reshape([-1, 2])\n            with tf.Session() as sess:\n                accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n                print (""categorical accuracy = %s"" % accuracy)\n            self.assertEqual(accuracy, 1.0)\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_models.py,4,"b'import tensorflow as tf\nimport numpy as np\nimport tflearn\nimport unittest\nimport os\n\nclass TestModels(unittest.TestCase):\n    """"""\n    Testing DNN model from tflearn/models/dnn.py\n    """"""\n\n    def test_dnn(self):\n\n        with tf.Graph().as_default():\n            X = [3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1]\n            Y = [1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3]\n            input = tflearn.input_data(shape=[None])\n            linear = tflearn.single_unit(input)\n            regression = tflearn.regression(linear, optimizer=\'sgd\', loss=\'mean_square\',\n                                            metric=\'R2\', learning_rate=0.01)\n            m = tflearn.DNN(regression)\n            # Testing fit and predict\n            m.fit(X, Y, n_epoch=1000, show_metric=True, snapshot_epoch=False)\n            res = m.predict([3.2])[0]\n            self.assertGreater(res, 1.3, ""DNN test (linear regression) failed! with score: "" + str(res) + "" expected > 1.3"")\n            self.assertLess(res, 1.8, ""DNN test (linear regression) failed! with score: "" + str(res) + "" expected < 1.8"")\n\n            # Testing save method\n            m.save(""test_dnn.tflearn"")\n            self.assertTrue(os.path.exists(""test_dnn.tflearn.index""))\n\n        with tf.Graph().as_default():\n            input = tflearn.input_data(shape=[None])\n            linear = tflearn.single_unit(input)\n            regression = tflearn.regression(linear, optimizer=\'sgd\', loss=\'mean_square\',\n                                            metric=\'R2\', learning_rate=0.01)\n            m = tflearn.DNN(regression)\n\n            # Testing load method\n            m.load(""test_dnn.tflearn"")\n            res = m.predict([3.2])[0]\n            self.assertGreater(res, 1.3, ""DNN test (linear regression) failed after loading model! score: "" + str(res) + "" expected > 1.3"")\n            self.assertLess(res, 1.8, ""DNN test (linear regression) failed after loading model! score: "" + str(res) + "" expected < 1.8"")\n\n    def test_sequencegenerator(self):\n\n        with tf.Graph().as_default():\n            text = ""123456789101234567891012345678910123456789101234567891012345678910""\n            maxlen = 5\n\n            X, Y, char_idx = \\\n                tflearn.data_utils.string_to_semi_redundant_sequences(text, seq_maxlen=maxlen, redun_step=3)\n\n            g = tflearn.input_data(shape=[None, maxlen, len(char_idx)])\n            g = tflearn.lstm(g, 32)\n            g = tflearn.dropout(g, 0.5)\n            g = tflearn.fully_connected(g, len(char_idx), activation=\'softmax\')\n            g = tflearn.regression(g, optimizer=\'adam\', loss=\'categorical_crossentropy\',\n                                   learning_rate=0.1)\n\n            m = tflearn.SequenceGenerator(g, dictionary=char_idx,\n                                          seq_maxlen=maxlen,\n                                          clip_gradients=5.0)\n            m.fit(X, Y, validation_set=0.1, n_epoch=100, snapshot_epoch=False)\n            res = m.generate(10, temperature=.5, seq_seed=""12345"")\n            #self.assertEqual(res, ""123456789101234"", ""SequenceGenerator test failed! Generated sequence: "" + res + "" expected \'123456789101234\'"")\n\n            # Testing save method\n            m.save(""test_seqgen.tflearn"")\n            self.assertTrue(os.path.exists(""test_seqgen.tflearn.index""))\n\n            # Testing load method\n            m.load(""test_seqgen.tflearn"")\n            res = m.generate(10, temperature=.5, seq_seed=""12345"")\n            # TODO: Fix test\n            #self.assertEqual(res, ""123456789101234"", ""SequenceGenerator test failed after loading model! Generated sequence: "" + res + "" expected \'123456789101234\'"")\n\n    def test_sequencegenerator_words(self):\n\n        with tf.Graph().as_default():\n            text = [""hello"",""world""]*100\n            word_idx = {""hello"": 0, ""world"": 1}\n            maxlen = 2\n\n            vec = [x for x in map(word_idx.get, text) if x is not None]\n\n            sequences = []\n            next_words = []\n            for i in range(0, len(vec) - maxlen, 3):\n                sequences.append(vec[i: i + maxlen])\n                next_words.append(vec[i + maxlen])\n\n            X = np.zeros((len(sequences), maxlen, len(word_idx)), dtype=np.bool)\n            Y = np.zeros((len(sequences), len(word_idx)), dtype=np.bool)\n            for i, seq in enumerate(sequences):\n                for t, idx in enumerate(seq):\n                    X[i, t, idx] = True\n                    Y[i, next_words[i]] = True\n\n            g = tflearn.input_data(shape=[None, maxlen, len(word_idx)])\n            g = tflearn.lstm(g, 32)\n            g = tflearn.dropout(g, 0.5)\n            g = tflearn.fully_connected(g, len(word_idx), activation=\'softmax\')\n            g = tflearn.regression(g, optimizer=\'adam\', loss=\'categorical_crossentropy\',\n                                   learning_rate=0.1)\n\n            m = tflearn.SequenceGenerator(g, dictionary=word_idx,\n                                          seq_maxlen=maxlen,\n                                          clip_gradients=5.0)\n            m.fit(X, Y, validation_set=0.1, n_epoch=100, snapshot_epoch=False)\n            res = m.generate(4, temperature=.5, seq_seed=[""hello"",""world""])\n            res_str = "" "".join(res[-2:])\n            self.assertEqual(res_str, ""hello world"", ""SequenceGenerator (word level) test failed! Generated sequence: "" + res_str + "" expected \'hello world\'"")\n\n            # Testing save method\n            m.save(""test_seqgen_word.tflearn"")\n            self.assertTrue(os.path.exists(""test_seqgen_word.tflearn.index""))\n\n            # Testing load method\n            m.load(""test_seqgen_word.tflearn"")\n            res = m.generate(4, temperature=.5, seq_seed=[""hello"",""world""])\n            res_str = "" "".join(res[-2:])\n            self.assertEqual(res_str, ""hello world"", ""Reloaded SequenceGenerator (word level) test failed! Generated sequence: "" + res_str + "" expected \'hello world\'"")\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_models_loading_scope.py,4,"b'import tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nclass TestModelsLoadingScope(unittest.TestCase):\n    """"""\n    Testing loading scope, using DNN\n    """"""\n\n    def test_dnn_loading_scope(self):\n\n        with tf.Graph().as_default():\n            X = [3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1]\n            Y = [1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3]\n            input = tflearn.input_data(shape=[None])\n            linear = tflearn.single_unit(input)\n            regression = tflearn.regression(linear, optimizer=\'sgd\', loss=\'mean_square\',\n                                            metric=\'R2\', learning_rate=0.01)\n            m = tflearn.DNN(regression)\n            # Testing fit and predict\n            m.fit(X, Y, n_epoch=1000, show_metric=True, snapshot_epoch=False)\n            res = m.predict([3.2])[0]\n            self.assertGreater(res, 1.3, ""DNN test (linear regression) failed! with score: "" + str(res) + "" expected > 1.3"")\n            self.assertLess(res, 1.8, ""DNN test (linear regression) failed! with score: "" + str(res) + "" expected < 1.8"")\n\n            # Testing save method\n            m.save(""test_dnn.tflearn"")\n            self.assertTrue(os.path.exists(""test_dnn.tflearn.index""))\n\n        # Testing loading, with change of variable scope (saved with no scope, now loading into scopeA)\n        with tf.Graph().as_default():\t# start with clear graph\n            with tf.variable_scope(""scopeA"") as scope:\n                input = tflearn.input_data(shape=[None])\n                linear = tflearn.single_unit(input)\n                regression = tflearn.regression(linear, optimizer=\'sgd\', loss=\'mean_square\',\n                                                metric=\'R2\', learning_rate=0.01)\n                m = tflearn.DNN(regression)\n                def try_load():\n                    m.load(""test_dnn.tflearn"")\n                self.assertRaises(tf.errors.NotFoundError, try_load)\t# fails, since names in file don\'t have ""scopeA""\n\n                m.load(""test_dnn.tflearn"", variable_name_map=(""scopeA/"", """"))\t# succeeds, because variable names are rewritten\n                res = m.predict([3.2])[0]\n                self.assertGreater(res, 1.3, ""DNN test (linear regression) failed after loading model! score: "" + str(res) + "" expected > 1.3"")\n                self.assertLess(res, 1.8, ""DNN test (linear regression) failed after loading model! score: "" + str(res) + "" expected < 1.8"")\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_objectives.py,4,"b'import tflearn\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\n\n\nclass TestObjectives(unittest.TestCase):\n    """"""\n    Testing objective functions from tflearn/objectives\n    """"""\n\n    def test_weak_cross_entropy_2d(self):\n        """"""\n        Test tflearn.objectives.weak_cross_entropy_2d\n        """"""\n        num_classes = 2\n        batch_size = 3\n        height, width = 5, 5\n        shape = (batch_size, height, width, num_classes)\n        y_pred = np.random.random(shape).astype(np.float32)\n        target = np.random.randint(0, num_classes, np.prod(shape[:-1]))\n        # convert to one-hot encoding\n        y_true = np.eye(num_classes)[target].reshape(shape)\n\n        with tf.Graph().as_default():\n            y_pred = tf.convert_to_tensor(y_pred)\n            y_true = tf.convert_to_tensor(y_true)\n\n            loss = tflearn.objectives.weak_cross_entropy_2d(y_pred, y_true)\n\n            with tf.Session() as sess:\n                res = sess.run(loss)\n\n        self.assertGreater(res, 0.)\n        self.assertLess(res, 1.)\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_validation_monitors.py,6,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\nclass TestValidationMonitors(unittest.TestCase):\n    """"""\n    Testing Validation Monitors\n    """"""\n\n    def test_vm1(self):\n\n        with tf.Graph().as_default():\n            # Data loading and preprocessing\n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:10, :, :, :]\n            Y = Y[:10, :]\n            \n            # Building convolutional network\n            network = input_data(shape=[None, 28, 28, 1], name=\'input\')\n            network = conv_2d(network, 32, 3, activation=\'relu\', regularizer=""L2"")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation=\'relu\', regularizer=""L2"")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation=\'tanh\')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation=\'tanh\')\n            network = dropout(network, 0.8)\n    \n            # construct two varaibles to add as additional ""valiation monitors""\n            # these varaibles are evaluated each time validation happens (eg at a snapshot)\n            # and the results are summarized and output to the tensorboard events file,\n            # together with the accuracy and loss plots.\n            #\n            # Here, we generate a dummy variable given by the sum over the current\n            # network tensor, and a constant variable.  In practice, the validation\n            # monitor may present useful information, like confusion matrix\n            # entries, or an AUC metric.\n            with tf.name_scope(\'CustomMonitor\'):\n                test_var = tf.reduce_sum(tf.cast(network, tf.float32), name=""test_var"")\n                test_const = tf.constant(32.0, name=""custom_constant"")\n    \n            print (""network=%s, test_var=%s"" % (network, test_var))\n            network = fully_connected(network, 10, activation=\'softmax\')\n            network = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                                 loss=\'categorical_crossentropy\', name=\'target\', validation_monitors=[test_var, test_const])\n            \n            # Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({\'input\': X}, {\'target\': Y}, n_epoch=1,\n                       validation_set=({\'input\': testX}, {\'target\': testY}),\n                       snapshot_step=10, show_metric=True, run_id=\'convnet_mnist\')\n            \n            # check for validation monitor variables\n            ats = tf.get_collection(""Adam_testing_summaries"")\n            print (""ats=%s"" % ats)\n            self.assertTrue(len(ats)==4)\t# should be four variables being summarized: [loss, test_var, test_const, accuracy]\n            \n            session = model.session\n            print (""session=%s"" % session)\n            trainer = model.trainer\n            print (""train_ops = %s"" % trainer.train_ops)\n            top = trainer.train_ops[0]\n            vmtset = top.validation_monitors_T\n            print (""validation_monitors_T = %s"" % vmtset)\n            with model.session.as_default():\n                ats_var_val = tflearn.variables.get_value(vmtset[0])\n                ats_const_val = tflearn.variables.get_value(vmtset[1])\n            print (""summary values: var=%s, const=%s"" % (ats_var_val, ats_const_val))\n            self.assertTrue(ats_const_val==32)\t# test to make sure the constant made it through\n    \n            # TBD: parse the recorded tensorboard events and ensure the validation monitor variables show up there\n    \nclass TestValidationBatch(unittest.TestCase):\n    """"""\n    Testing Validation Batch size specification\n    """"""\n\n    def test_vbs1(self):\n\n        with tf.Graph().as_default():\n            # Data loading and preprocessing\n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:20, :, :, :]\n            Y = Y[:20, :]\n            testX = testX[:10, :, :, :]\n            testY = testY[:10, :]\n            \n            # Building convolutional network\n            network = input_data(shape=[None, 28, 28, 1], name=\'input\')\n            network = conv_2d(network, 32, 3, activation=\'relu\', regularizer=""L2"")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation=\'relu\', regularizer=""L2"")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation=\'tanh\')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation=\'tanh\')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 10, activation=\'softmax\')\n            network = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                                 loss=\'categorical_crossentropy\', name=\'target\')\n            \n            # Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({\'input\': X}, {\'target\': Y}, n_epoch=1,\n                      batch_size=10,\n                      validation_set=({\'input\': testX}, {\'target\': testY}),\n                      validation_batch_size=5,\n                      snapshot_step=10, show_metric=True, run_id=\'convnet_mnist_vbs\')\n    \n            self.assertEqual(model.train_ops[0].validation_batch_size, 5)\n            self.assertEqual(model.train_ops[0].batch_size, 10)\n    \nif __name__ == ""__main__"":\n    unittest.main()\n'"
tflearn/__init__.py,0,"b'from __future__ import absolute_import\n\n# Config\nfrom . import config\nfrom .config import is_training, get_training_mode, init_graph\n\n# Import models\nfrom . import models\nfrom .models.dnn import DNN\nfrom .models.generator import SequenceGenerator\n\n# Helpers\nfrom . import helpers\nfrom .helpers.evaluator import Evaluator\nfrom .helpers.trainer import Trainer, TrainOp\nfrom .helpers.regularizer import add_weights_regularizer\nfrom .helpers.summarizer import summarize, summarize_activations, \\\n    summarize_gradients, summarize_variables, summarize_all\n\n# Predefined ops\nfrom .layers import normalization\nfrom . import metrics\nfrom . import activations\nfrom . import distances\nfrom . import regularizers\nfrom . import initializations\nfrom . import optimizers\nfrom . import summaries\nfrom . import optimizers\nfrom . import variables\nfrom . import collections # Add TFLearn collections to Tensorflow GraphKeys\n\n# Direct ops inclusion\nfrom .optimizers import SGD, AdaGrad, Adam, RMSProp, Momentum, Ftrl, AdaDelta, \\\n    ProximalAdaGrad, Nesterov\nfrom .activations import linear, tanh, sigmoid, softmax, softplus, softsign,\\\n    relu, relu6, leaky_relu, prelu, elu, crelu, selu\nfrom .variables import variable, get_all_trainable_variable, \\\n    get_all_variables, get_layer_variables_by_name, get_layer_variables_by_scope\nfrom .objectives import categorical_crossentropy, binary_crossentropy, \\\n    softmax_categorical_crossentropy, hinge_loss, mean_square, weighted_crossentropy\nfrom .metrics import Top_k, Accuracy, R2, top_k_op, accuracy_op, r2_op, Prediction_Counts\n\n# Direct layers inclusion\nfrom . import layers\nfrom .layers.conv import conv_2d, max_pool_2d, avg_pool_2d, conv_1d, \\\n    highway_conv_2d, highway_conv_1d, max_pool_1d, avg_pool_1d, \\\n    global_avg_pool, residual_block, residual_bottleneck, \\\n    conv_2d_transpose, upsample_2d, conv_3d, max_pool_3d, avg_pool_3d, \\\n    resnext_block, upscore_layer, deconv_2d, densenet_block\nfrom .layers.core import input_data, dropout, custom_layer, reshape, \\\n    flatten, activation, fully_connected, single_unit, highway, \\\n    one_hot_encoding, time_distributed, multi_target_data\nfrom .layers.normalization import batch_normalization, local_response_normalization\nfrom .layers.estimator import regression\nfrom .layers.recurrent import lstm, gru, simple_rnn, bidirectional_rnn, \\\n    BasicRNNCell, BasicLSTMCell, GRUCell\nfrom .layers.embedding_ops import embedding\nfrom .layers.merge_ops import merge, merge_outputs\n\n# Datasets\nfrom . import datasets\n\n# Utils\nfrom . import data_utils\nfrom . import utils\nfrom .utils import get_layer_by_name\n\n# Data Utils\nfrom .data_augmentation import DataAugmentation, ImageAugmentation, SequenceAugmentation\nfrom .data_preprocessing import DataPreprocessing, ImagePreprocessing, SequencePreprocessing\n\n# Init training mode\nconfig.init_training_mode()\n'"
tflearn/activations.py,18,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nimport numpy as np\nimport tflearn\nfrom . import initializations\nfrom . import variables as va\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    if hasattr(identifier, \'__call__\'):\n        return identifier\n    else:\n        return get_from_module(identifier, globals(), \'activation\')\n\n\n"""""" Activation Functions """"""\n\n\ndef linear(x):\n    """""" Linear.\n\n    f(x) = x\n\n    Arguments:\n        x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`.\n\n    Returns:\n        The incoming Tensor (without changes).\n    """"""\n    return x\n\n\ndef tanh(x):\n    """""" Tanh.\n\n    Computes hyperbolic tangent of `x` element-wise.\n\n    Arguments:\n        x: A Tensor with type `float`, `double`, `int32`, `complex64`, `int64`,\n            or `qint32`.\n\n    Returns:\n        A Tensor with the same type as `x` if `x.dtype != qint32` otherwise\n          the return type is `quint8`.\n    """"""\n    return tf.tanh(x)\n\n\ndef sigmoid(x):\n    """""" Sigmoid.\n\n    Computes sigmoid of `x` element-wise.\n    Specifically, `y = 1 / (1 + exp(-x))`.\n\n    Arguments:\n        x: A Tensor with type `float`, `double`, `int32`, `complex64`, `int64`,\n            or `qint32`.\n\n    Returns:\n        A Tensor with the same type as `x` if `x.dtype != qint32` otherwise\n        the return type is `quint8`.\n    """"""\n    return tf.nn.sigmoid(x)\n\n\ndef softmax(x):\n    """""" Softmax.\n\n    Computes softmax activations.\n\n    For each batch `i` and class `j` we have\n\n      softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))\n\n    Arguments:\n        x: A `Tensor`. Must be one of the following types: `float32`,\n            `float64`. 2-D with shape `[batch_size, num_classes]`.\n\n    Returns:\n        A `Tensor`. Has the same type as `x`. Same shape as `x`.\n    """"""\n    return tf.nn.softmax(x)\n\n\ndef softplus(x):\n    """""" Softplus.\n\n    Computes softplus: `log(exp(features) + 1)`.\n\n    Arguments:\n        x: A `Tensor`. Must be one of the following types: `float32`,\n            `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`.\n\n    Returns:\n        A `Tensor`. Has the same type as `x`.\n    """"""\n    return tf.nn.softplus(x)\n\n\ndef softsign(x):\n    """""" Softsign.\n\n    Computes softsign: `features / (abs(features) + 1)`.\n\n    Arguments:\n        x: A `Tensor`. Must be one of the following types: `float32`,\n            `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`.\n\n    Returns:\n        A `Tensor`. Has the same type as `x`.\n    """"""\n    return tf.nn.softsign(x)\n\n\ndef relu(x):\n    """""" ReLU.\n\n    Computes rectified linear: `max(features, 0)`.\n\n    Arguments:\n        x: A `Tensor`. Must be one of the following types: `float32`,\n            `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`.\n\n    Returns:\n        A `Tensor`. Has the same type as `x`.\n    """"""\n    return tf.nn.relu(x)\n\n\ndef relu6(x):\n    """""" ReLU6.\n\n    Computes Rectified Linear 6: `min(max(features, 0), 6)`.\n\n    Arguments:\n        x: A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`.\n\n    Returns:\n        A `Tensor` with the same type as `x`.\n    """"""\n    return tf.nn.relu6(x)\n\n\ndef leaky_relu(x, alpha=0.1, name=""LeakyReLU""):\n    """""" LeakyReLU.\n\n    Modified version of ReLU, introducing a nonzero gradient for negative\n    input.\n\n    Arguments:\n        x: A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`.\n        alpha: `float`. slope.\n        name: A name for this activation op (optional).\n\n    Returns:\n        A `Tensor` with the same type as `x`.\n\n    References:\n        Rectifier Nonlinearities Improve Neural Network Acoustic Models,\n        Maas et al. (2013).\n\n    Links:\n        [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf]\n        (http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n\n    """"""\n\n    with tf.name_scope(name) as scope:\n        m_x = tf.nn.relu(-x)\n        x = tf.nn.relu(x)\n        x -= alpha * m_x\n\n    x.scope = scope\n\n    return x\n\n# Shortcut\nleakyrelu = leaky_relu\n\n\ndef prelu(x, channel_shared=False, weights_init=\'zeros\', trainable=True,\n          restore=True, reuse=False, scope=None, name=""PReLU""):\n    """""" PReLU.\n\n    Parametric Rectified Linear Unit.\n\n    Arguments:\n        x: A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`.\n        channel_shared: `bool`. Single weight is shared by all channels\n        weights_init: `str`. Weights initialization. Default: zeros.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. Restore or not alphas.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        name: A name for this activation op (optional).\n\n    Attributes:\n        scope: `str`. This op scope.\n        alphas: `Variable`. PReLU alphas.\n\n    Returns:\n        A `Tensor` with the same type as `x`.\n\n    References:\n        Delving Deep into Rectifiers: Surpassing Human-Level Performance\n        on ImageNet Classification. He et al., 2014.\n\n    Links:\n        [http://arxiv.org/pdf/1502.01852v1.pdf]\n        (http://arxiv.org/pdf/1502.01852v1.pdf)\n\n    """"""\n    if channel_shared:\n        w_shape = (1,)\n    else:\n        w_shape = tflearn.utils.get_incoming_shape(x)[-1:]\n\n    with tf.variable_scope(scope, default_name=name, values=[x],\n                           reuse=reuse) as scope:\n        W_init = initializations.get(weights_init)()\n        alphas = va.variable(""alphas"", shape=w_shape, initializer=W_init,\n                             restore=restore, trainable=trainable)\n\n        x = tf.nn.relu(x) + tf.multiply(alphas, (x - tf.abs(x))) * 0.5\n\n    x.scope = scope\n    x.alphas = alphas\n\n    return x\n\n\ndef elu(x):\n    """""" ELU.\n\n    Exponential Linear Unit.\n\n    Arguments:\n        x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`\n\n    Returns:\n        A `tuple` of `tf.Tensor`. This layer inference, i.e. output Tensors\n        at training and testing time.\n\n    References:\n        Fast and Accurate Deep Network Learning by Exponential Linear Units,\n        Djork-Arn\xc3\xa9 Clevert, Thomas Unterthiner, Sepp Hochreiter. 2015.\n\n    Links:\n        [http://arxiv.org/abs/1511.07289](http://arxiv.org/abs/1511.07289)\n\n    """"""\n\n    return tf.nn.elu(x)\n\n\ndef crelu(x):\n    """""" CReLU\n\n    Computes Concatenated ReLU.\n\n    Concatenates a ReLU which selects only the positive part of the activation\n    with a ReLU which selects only the negative part of the activation. Note\n    that as a result this non-linearity doubles the depth of the activations.\n\n    Arguments:\n        x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`.\n\n    Returns:\n        A `Tensor` with the same type as `x`.\n\n    Links:\n        [https://arxiv.org/abs/1603.05201](https://arxiv.org/abs/1603.05201)\n\n    """"""\n\n    return tf.nn.crelu(x)\n\n\ndef selu(x):\n    """""" SELU.\n\n    Scaled Exponential Linear Unit.\n\n    Arguments\n        x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n            `int16`, or `int8`\n\n    References:\n        Self-Normalizing Neural Networks, Klambauer et al., 2017.\n\n    Links:\n        [https://arxiv.org/abs/1706.02515](https://arxiv.org/abs/1706.02515)\n\n    """"""\n    return tf.nn.selu(x)\n\n\ndef hard_sigmoid(x):\n    """"""Hard sigmoid activation function.\n    \n    Segment-wise linear approximation of sigmoid. Faster than sigmoid\n    \n    Arguments\n      x: Input tensor.\n      \n    Returns\n      Hard sigmoid activation:\n      \n      - `0` if `x < -2.5`\n      - `1` if `x > 2.5`\n      - `0.2 * x + 0.5` if `-2.5 <= x <= 2.5`.\n    \n    """"""\n    return tf.keras.backend.hard_sigmoid(x)\n\n\ndef gelu(x):\n    """"""Gaussian Error Linear Units (GELUs)\n    \n    GLUEs are nonconvex, nonmonotonic.\n    \n    Arguments\n      x: Input tensor.\n    \n    References:\n      Gaussian Error Linear Units (GELUs), Hendrycks et. al, 2018.\n      \n    Links: \n        [https://arxiv.org/pdf/1606.08415.pdf](https://arxiv.org/pdf/1606.08415.pdf)\n    """"""\n    \n    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n'"
tflearn/callbacks.py,0,"b'from __future__ import division, print_function, absolute_import\n\nimport time\nimport sys\n\n# Verify curses module for Windows and Notebooks Support\ntry:\n    from IPython.core.display import clear_output\nexcept:\n    pass\n\nCURSES_SUPPORTED = True\ntry:\n    import curses\nexcept Exception:\n    print(""curses is not supported on this machine (please install/reinstall curses for an optimal experience)"")\n    CURSES_SUPPORTED = False\n\n\nclass Callback(object):\n    """""" Callback base class. """"""\n    def __init__(self):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n        pass\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n\nclass ChainCallback(Callback):\n    def __init__(self, callbacks=[]):\n        self.callbacks = callbacks\n\n    def on_train_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_begin(training_state)\n\n    def on_epoch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_begin(training_state)\n\n    def on_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_batch_begin(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_sub_batch_begin(training_state)\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        for callback in self.callbacks:\n            callback.on_sub_batch_end(training_state, train_index)\n\n    def on_batch_end(self, training_state, snapshot=False):\n        for callback in self.callbacks:\n            callback.on_batch_end(training_state, snapshot)\n\n    def on_epoch_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_end(training_state)\n\n    def on_train_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_end(training_state)\n\n    def add(self, callback):\n        if not isinstance(callback, Callback):\n            raise Exception(str(callback) + "" is an invalid Callback object"")\n\n        self.callbacks.append(callback)\n\n\nclass TermLogger(Callback):\n    def __init__(self):\n        self.data = []\n        self.has_ipython = True\n        self.display_type = ""multi""\n        self.global_data_size = 0\n        self.global_val_data_size = 0\n        self.snapped = False\n\n        global CURSES_SUPPORTED\n        if CURSES_SUPPORTED:\n            try:\n                curses.setupterm()\n                sys.stdout.write(curses.tigetstr(\'civis\').decode())\n            except Exception:\n                CURSES_SUPPORTED = False\n        \n        try:\n            clear_output\n        except NameError:\n            self.has_ipython = False\n\n    def add(self, data_size, val_size=0, metric_name=None, name=None):\n        if not metric_name: metric_name = \'acc\'\n        self.data.append({\n            \'name\': name if name else ""Train op. "" + str(len(self.data)),\n            \'metric_name\': metric_name,\n            \'data_size\': data_size,\n            \'epoch\': 0,\n            \'step\': 0,\n            \'val_size\': val_size,\n            \'loss\': None,\n            \'acc\': None,\n            \'val_loss\': None,\n            \'val_acc\': None\n        })\n        self.global_data_size += data_size\n        self.global_val_data_size += val_size\n\n    def on_epoch_begin(self, training_state):\n        training_state.step_time = time.time()\n        training_state.step_time_total = 0.\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        training_state.step_time = time.time()\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        training_state.step_time_total += time.time() - training_state.step_time\n        if snapshot:\n            self.snapshot_termlogs(training_state)\n        else:\n            self.print_termlogs(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n\n        self.data[train_index][\'loss\'] = training_state.loss_value\n        self.data[train_index][\'acc\'] = training_state.acc_value\n        self.data[train_index][\'val_loss\'] = training_state.val_loss\n        self.data[train_index][\'val_acc\'] = training_state.val_acc\n        self.data[train_index][\'epoch\'] = training_state.epoch\n        self.data[train_index][\'step\'] = training_state.current_iter\n\n    def on_train_begin(self, training_state):\n        print(""---------------------------------"")\n        print(""Training samples: "" + str(self.global_data_size))\n        print(""Validation samples: "" + str(self.global_val_data_size))\n        print(""--"")\n        if len(self.data) == 1:\n            self.display_type = ""single""\n\n    def on_train_end(self, training_state):\n        # Reset caret to last position\n        to_be_printed = """"\n        if CURSES_SUPPORTED: #if not self.has_ipython #TODO:check bug here\n            for i in range(len(self.data) + 2):\n                to_be_printed += ""\\033[B""\n            if not self.snapped:\n                to_be_printed += ""--\\n""\n        sys.stdout.write(to_be_printed)\n        sys.stdout.flush()\n\n        # Set caret visible if possible\n        if CURSES_SUPPORTED:\n            sys.stdout.write(curses.tigetstr(\'cvvis\').decode())\n\n    def termlogs(self, step=0, global_loss=None, global_acc=None, step_time=None):\n\n        termlogs = ""Training Step: "" + str(step) + "" ""\n        if global_loss:\n            termlogs += "" | total loss: \\033[1m\\033[32m"" + \\\n                        ""%.5f"" % global_loss + ""\\033[0m\\033[0m""\n        if global_acc and not self.display_type == ""single"":\n            termlogs += "" - avg acc: %.4f"" % float(global_acc)\n        if step_time:\n            termlogs += "" | time: %.3fs"" % step_time\n        termlogs += ""\\n""\n        for i, data in enumerate(self.data):\n            print_loss = """"\n            print_acc = """"\n            print_val_loss = """"\n            print_val_acc = """"\n            if data[\'loss\'] is not None:\n                print_loss = "" | loss: "" + ""%.5f"" % data[\'loss\']\n            if data[\'acc\'] is not None:\n                print_acc = "" - "" + data[\'metric_name\'] + "": "" + \\\n                            ""%.4f"" % data[\'acc\']\n            if data[\'val_loss\'] is not None:\n                print_val_loss = "" | val_loss: "" + ""%.5f"" % data[\'val_loss\']\n            if data[\'val_acc\'] is not None:\n                print_val_acc = "" - val_"" + data[\'metric_name\'] + "": "" + ""%.4f"" % data[\'val_acc\']\n            # fix diplay, if step reached the whole epoch, display epoch - 1, as epoch has been updated\n            print_epoch = data[\'epoch\']\n            # Smoothing display, so we show display at step + 1 to show data_size/data_size at end\n            print_step = "" -- iter: "" + \\\n                         (""%0"" + str(len(str(data[\'data_size\']))) +\n                          ""d"") % data[\'step\'] + ""/"" + str(data[\'data_size\'])\n            if data[\'step\'] == 0:\n                print_epoch = data[\'epoch\']\n                # print_step = """"\n                print_step = "" -- iter: "" + (""%0"" + str(\n                    len(str(data[\'data_size\']))) + ""d"") % 0 \\\n                             + ""/"" + str(data[\'data_size\'])\n            termlogs += ""\\x1b[2K\\r| "" + data[\'name\'] + "" | epoch: "" + \\\n                        ""%03d"" % print_epoch + print_loss + print_acc + \\\n                        print_val_loss + print_val_acc + print_step + ""\\n""\n\n        return termlogs\n\n    def print_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        if self.has_ipython and not CURSES_SUPPORTED:\n            clear_output(wait=True)\n        else:\n            for i in range(len(self.data) + 1):\n                termlogs += ""\\033[A""\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n\n    def snapshot_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        termlogs += ""--\\n""\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n        self.snapped = True\n\n\nclass ModelSaver(Callback):\n    def __init__(self, save_func, snapshot_path, best_snapshot_path,\n                 best_val_accuracy, snapshot_step, snapshot_epoch):\n        self.save_func = save_func\n        self.snapshot_path = snapshot_path\n        self.snapshot_epoch = snapshot_epoch\n        self.best_snapshot_path = best_snapshot_path\n        self.best_val_accuracy = best_val_accuracy\n        self.snapshot_step = snapshot_step\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_epoch_end(self, training_state):\n        if self.snapshot_epoch:\n            self.save(training_state.step)\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        if snapshot & (self.snapshot_step is not None):\n            self.save(training_state.step)\n\n        if None not in (self.best_snapshot_path, self.best_val_accuracy, training_state.val_acc):\n            if training_state.val_acc > self.best_val_accuracy:\n                self.best_val_accuracy = training_state.val_acc\n                self.save_best(int(10000 * round(training_state.val_acc, 4)))\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n    def save(self, training_step=0):\n        if self.snapshot_path:\n            self.save_func(self.snapshot_path, training_step)\n\n    def save_best(self, val_accuracy):\n        if self.best_snapshot_path:\n            snapshot_path = self.best_snapshot_path + str(val_accuracy)\n            self.save_func(snapshot_path, use_val_saver=True)\n'"
tflearn/collections.py,11,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\n""""""\nFor handling networks and keep tracks of important parameters, TFLearn is\nusing Tensorflow collections.\n""""""\n#TODO: Chek if a layer without import tflearn doesn\'t have problem with those\n# Collection for network inputs. Used by `Trainer` class for retrieving all\n# data input placeholders.\ntf.GraphKeys.INPUTS = \'inputs\'\n\n# Collection for network targets. Used by `Trainer` class for retrieving all\n# targets (labels) placeholders.\ntf.GraphKeys.TARGETS = \'targets\'\n\n# Collection for network train ops. Used by `Trainer` class for retrieving all\n# optimization processes.\ntf.GraphKeys.TRAIN_OPS = \'trainops\'\n\n# Collection to retrieve layers variables. Variables are stored according to\n# the following pattern: /tf.GraphKeys.LAYER_VARIABLES/layer_name (so there\n# will have as many collections as layers with variables).\ntf.GraphKeys.LAYER_VARIABLES = \'layer_variables\'\n\n# Collection to store all returned tensors for every layer\ntf.GraphKeys.LAYER_TENSOR = \'layer_tensor\'\n\n# Collection to store all variables that will be restored\ntf.GraphKeys.EXCL_RESTORE_VARS = \'restore_variables\'\n\n# Collection to store the default graph configuration\ntf.GraphKeys.GRAPH_CONFIG = \'graph_config\'\n\n# Collection to store all input variable data preprocessing\ntf.GraphKeys.DATA_PREP = \'data_preprocessing\'\n\n# Collection to store all input variable data preprocessing\ntf.GraphKeys.DATA_AUG = \'data_augmentation\'\n\n# Collection to store all custom learning rate variable\ntf.GraphKeys.LR_VARIABLES = \'lr_variables\'\n'"
tflearn/config.py,20,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nfrom .variables import variable\n\n# -------------------\n# Basic Configuration\n# -------------------\n\n\ndef init_graph(seed=None, log_device=False, num_cores=0, gpu_memory_fraction=0,\n               soft_placement=True):\n    """""" init_graph.\n\n    Initialize a graph with specific parameters.\n\n    Arguments:\n        seed: `int`. Set the graph random seed.\n        log_device: `bool`. Log device placement or not.\n        num_cores: Number of CPU cores to be used. Default: All.\n        gpu_memory_fraction: A value between 0 and 1 that indicates what\n            fraction of the available GPU memory to pre-allocate for each\n            process. 1 means to pre-allocate all of the GPU memory,\n            0.5 means the process allocates ~50% of the available GPU\n            memory. Default: Use all GPU\'s available memory.\n        soft_placement: `bool`. Whether soft placement is allowed. If true,\n            an op will be placed on CPU if:\n                1. there\'s no GPU implementation for the OP\n                    or\n                2. no GPU devices are known or registered\n                    or\n                3. need to co-locate with reftype input(s) which are from CPU.\n    """"""\n    if seed: tf.set_random_seed(seed)\n    gs = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n    config = tf.ConfigProto(log_device_placement=log_device,\n                            inter_op_parallelism_threads=num_cores,\n                            intra_op_parallelism_threads=num_cores,\n                            gpu_options=gs,\n                            allow_soft_placement=soft_placement)\n    tf.add_to_collection(tf.GraphKeys.GRAPH_CONFIG, config)\n\n    return config\n\n\n# ------------------\n# Training Mode\n# ------------------\n""""""\nBecause some ops have different behavior at training and testing time (such\nas dropout, or batch normalization), TFLearn implements a boolean variable\n`is_training` to indicates the network if it is used for training or not.\nThis variable is stored in the tf.collection `is_training`, and is the\nunique element of it.\nThe two operations to update that variable (set it to True or False),\nare stored in another tf.collection `is_training_ops` with 2 elemens:\n[set_training_mode_op, set_predicting_mode_op]. So invoking the first element\nwill enable training mode, while the second one will enable predicting mode.\n""""""\n\n\ndef is_training(is_training=False,  session=None):\n    """""" is_training.\n\n    Set the graph training mode.\n\n    This is meant to be used to control ops that have different output at\n    training and testing time., such as dropout or batch normalization,\n\n    Examples:\n        ```\n        >> # Retrieve variable responsible for managing training mode\n        >> training_mode = tflearn.get_training_mode()\n        >> # Define a conditional op\n        >> my_conditional_op = tf.cond(training_mode, if_yes_op, if_no_op)\n        >> # Set training mode to True\n        >> tflearn.is_training(True)\n        >> session.run(my_conditional_op)\n        if_yes_op\n        >> # Set training mode to False\n        >> tflearn.is_training(False)\n        >> session.run(my_conditional_op)\n        if_no_op\n        ```\n\n    Returns:\n        A `bool`, True if training, False else.\n\n    """"""\n    if not session:\n        session = tf.get_default_session()\n    init_training_mode()\n    if is_training:\n        tf.get_collection(\'is_training_ops\')[0].eval(session=session)\n    else:\n        tf.get_collection(\'is_training_ops\')[1].eval(session=session)\n\n\ndef get_training_mode():\n    """""" get_training_mode.\n\n    Returns variable in-use to set training mode.\n\n    Returns:\n        A `Variable`, the training mode holder.\n\n    """"""\n    init_training_mode()\n    coll = tf.get_collection(\'is_training\')\n    return coll[0]\n\n\ndef init_training_mode():\n    """"""  init_training_mode.\n\n    Creates `is_training` variable and its ops if they haven\'t be created\n    yet. This op is required if you are using layers such as dropout or\n    batch normalization independently of TFLearn models (DNN or Trainer class).\n\n    """"""\n    # \'is_training\' collection stores the training mode variable\n    coll = tf.get_collection(\'is_training\')\n    if len(coll) == 0:\n        tr_var = variable(\n            ""is_training"", dtype=tf.bool, shape=[],\n            initializer=tf.constant_initializer(False),\n            trainable=False)\n        tf.add_to_collection(\'is_training\', tr_var)\n        # \'is_training_ops\' stores the ops to update training mode variable\n        a = tf.assign(tr_var, True)\n        b = tf.assign(tr_var, False)\n        tf.add_to_collection(\'is_training_ops\', a)\n        tf.add_to_collection(\'is_training_ops\', b)\n\n\n_FLOATX = tf.float32\n_EPSILON = 1e-10\n\n'"
tflearn/data_augmentation.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport random\nimport numpy as np\ntry:\n    import scipy.ndimage\nexcept Exception:\n    print(""Scipy not supported!"")\n\n\nclass DataAugmentation(object):\n    """""" Data Augmentation.\n\n    Base class for applying common real-time data augmentation.\n\n    This class is meant to be used as an argument of `input_data`. When training\n    a model, the defined augmentation methods will be applied at training\n    time only. Note that DataPreprocessing is similar to DataAugmentation,\n    but applies at both training time and testing time.\n\n    Arguments:\n        None\n\n    Parameters:\n        methods: `list of function`. The augmentation methods to apply.\n        args: A `list` of arguments list to use for these methods.\n\n    """"""\n\n    def __init__(self):\n        self.methods = []\n        self.args = []\n\n    def apply(self, batch):\n        for i, m in enumerate(self.methods):\n            if self.args[i]:\n                batch = m(batch, *self.args[i])\n            else:\n                batch = m(batch)\n        return batch\n\n\nclass ImageAugmentation(DataAugmentation):\n    """""" Image Augmentation.\n\n    Base class for applying real-time augmentation related to images.\n\n    This class is meant to be used as an argument of `input_data`. When training\n    a model, the defined augmentation methods will be applied at training\n    time only. Note that ImagePreprocessing is similar to ImageAugmentation,\n    but applies at both training time and testing time.\n\n    Arguments:\n        None.\n\n    Parameters:\n        methods: `list of function`. The augmentation methods to apply.\n        args: A `list` of arguments list to use for these methods.\n\n    """"""\n\n    def __init__(self):\n        super(ImageAugmentation, self).__init__()\n\n    # ----------------------------\n    #  Image Augmentation Methods\n    # ----------------------------\n\n    def add_random_crop(self, crop_shape, padding=None):\n        """""" add_random_crop.\n\n        Randomly crop a picture according to \'crop_shape\'. An optional padding\n        can be specified, for padding picture with 0s (To conserve original\n        image shape).\n\n        Examples:\n            ```python\n            # Example: pictures of 32x32\n            imgaug = tflearn.ImageAugmentation()\n            # Random crop of 24x24 into a 32x32 picture => output 24x24\n            imgaug.add_random_crop((24, 24))\n            # Random crop of 32x32 with image padding of 6 (to conserve original image shape) => output 32x32\n            imgaug.add_random_crop((32, 32), 6)\n            ```\n\n        Arguments:\n            crop_shape: `tuple` of `int`. The crop shape (height, width).\n            padding: `int`. If not None, the image is padded with \'padding\' 0s.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._random_crop)\n        self.args.append([crop_shape, padding])\n\n    def add_random_flip_leftright(self):\n        """""" add_random_flip_leftright.\n\n        Randomly flip an image (left to right).\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._random_flip_leftright)\n        self.args.append(None)\n\n    def add_random_flip_updown(self):\n        """""" add_random_flip_leftright.\n\n        Randomly flip an image (upside down).\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._random_flip_updown)\n        self.args.append(None)\n\n    def add_random_90degrees_rotation(self, rotations=[0, 1, 2, 3]):\n        """""" add_random_90degrees_rotation\n\n        Randomly perform 90 degrees rotations.\n\n        Arguments:\n            rotations: `list`. Allowed 90 degrees rotations.\n\n        Return:\n             Nothing.\n\n        """"""\n        self.methods.append(self._random_90degrees_rotation)\n        self.args.append([rotations])\n\n    def add_random_rotation(self, max_angle=20.):\n        """""" add_random_rotation.\n\n        Randomly rotate an image by a random angle (-max_angle, max_angle).\n\n        Arguments:\n            max_angle: `float`. The maximum rotation angle.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._random_rotation)\n        self.args.append([max_angle])\n\n    def add_random_blur(self, sigma_max=5.):\n        """""" add_random_blur.\n\n        Randomly blur an image by applying a gaussian filter with a random\n        sigma (0., sigma_max).\n\n        Arguments:\n            sigma: `float` or list of `float`. Standard deviation for Gaussian\n                kernel. The standard deviations of the Gaussian filter are\n                given for each axis as a sequence, or as a single number,\n                in which case it is equal for all axes.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._random_blur)\n        self.args.append([sigma_max])\n\n    # --------------------------\n    #  Augmentation Computation\n    # --------------------------\n\n    def _random_crop(self, batch, crop_shape, padding=None):\n        oshape = np.shape(batch[0])\n        if padding:\n            oshape = (oshape[0] + 2*padding, oshape[1] + 2*padding)\n        new_batch = []\n        npad = ((padding, padding), (padding, padding), (0, 0))\n        for i in range(len(batch)):\n            new_batch.append(batch[i])\n            if padding:\n                new_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n                                          mode=\'constant\', constant_values=0)\n            nh = random.randint(0, oshape[0] - crop_shape[0])\n            nw = random.randint(0, oshape[1] - crop_shape[1])\n            new_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n                                        nw:nw + crop_shape[1]]\n        return new_batch\n\n    def _random_flip_leftright(self, batch):\n        for i in range(len(batch)):\n            if bool(random.getrandbits(1)):\n                batch[i] = np.fliplr(batch[i])\n        return batch\n\n    def _random_flip_updown(self, batch):\n        for i in range(len(batch)):\n            if bool(random.getrandbits(1)):\n                batch[i] = np.flipud(batch[i])\n        return batch\n\n    def _random_90degrees_rotation(self, batch, rotations=[0, 1, 2, 3]):\n        for i in range(len(batch)):\n            num_rotations = random.choice(rotations)\n            batch[i] = np.rot90(batch[i], num_rotations)\n\n        return batch\n\n    def _random_rotation(self, batch, max_angle):\n        for i in range(len(batch)):\n            if bool(random.getrandbits(1)):\n                # Random angle\n                angle = random.uniform(-max_angle, max_angle)\n                batch[i] = scipy.ndimage.interpolation.rotate(batch[i], angle,\n                                                              reshape=False)\n        return batch\n\n    def _random_blur(self, batch, sigma_max):\n        for i in range(len(batch)):\n            if bool(random.getrandbits(1)):\n                # Random sigma\n                sigma = random.uniform(0., sigma_max)\n                batch[i] = \\\n                    scipy.ndimage.filters.gaussian_filter(batch[i], sigma)\n        return batch\n\n\nclass SequenceAugmentation(DataAugmentation):\n\n    def __init__(self):\n        raise NotImplementedError\n\n    def random_reverse(self):\n        raise NotImplementedError\n'"
tflearn/data_flow.py,10,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport threading\ntry:\n    # Python 2\n    import Queue as queue\nexcept Exception:\n    # Python 3\n    import queue\n\nimport tensorflow as tf\nfrom . import utils\n\n\nclass DataFlow(object):\n    """""" Data Flow.\n\n    Base class for using real time pre-processing and controlling data flow.\n    Supports pipelining for faster computation.\n\n    Arguments:\n        coord: `Coordinator`. A Tensorflow coordinator.\n        num_threads: `int`. Total number of simultaneous threads to process data.\n        max_queue: `int`. Maximum number of data stored in a queue.\n        shuffle: `bool`. If True, data will be shuffle.\n        continuous: `bool`. If True, when an epoch is over, same data will be\n            feeded again.\n        ensure_data_order: `bool`. Ensure that data order is keeped when using\n            \'next\' to retrieve data (Processing will be slower).\n        dprep_dict: dict. Optional data pre-processing parameter for performing\n            real time data pre-processing. Keys must be placeholders and values\n            `DataPreprocessing` subclass object.\n        daug_dict: dict. Optional data augmentation parameter for performing\n            real time data augmentation. Keys must be placeholders and values\n            `DataAugmentation` subclass object.\n\n    """"""\n\n    def __init__(self, coord, num_threads=8, max_queue=32, shuffle=False,\n                 continuous=False, ensure_data_order=False,\n                 dprep_dict=None, daug_dict=None):\n        self.coord = coord\n        self.num_threads = num_threads\n        self.max_queue = max_queue\n        self.shuffle = shuffle\n        self.continuous = continuous\n        if ensure_data_order:\n            self.num_threads = 1\n            self.max_queue = 1\n        self.dprep_dict = dprep_dict\n        self.daug_dict = daug_dict\n        self.interrupted = False\n\n\nclass FeedDictFlow(DataFlow):\n\n    """""" FeedDictFlow.\n\n    Generate a stream of batches from a dataset. It uses two queues, one for\n    generating batch of data ids, and the other one to load data and apply pre\n    processing. If continuous is `True`, data flow will never ends until `stop`\n    is invoked, or `coord` interrupt threads.\n\n    Arguments:\n        feed_dict: `dict`. A TensorFlow formatted feed dict (with placeholders\n            as keys and data as values).\n        coord: `Coordinator`. A Tensorflow coordinator.\n        num_threads: `int`. Total number of simultaneous threads to process data.\n        max_queue: `int`. Maximum number of data stored in a queue.\n        shuffle: `bool`. If True, data will be shuffle.\n        continuous: `bool`. If True, when an epoch is over, same data will be\n            feeded again.\n        ensure_data_order: `bool`. Ensure that data order is keeped when using\n            \'next\' to retrieve data (Processing will be slower).\n        dprep_dict: dict. Optional data pre-processing parameter for performing\n            real time data pre-processing. Keys must be placeholders and values\n            `DataPreprocessing` subclass object.\n        daug_dict: dict. Optional data augmentation parameter for performing\n            real time data augmentation. Keys must be placeholders and values\n            `DataAugmentation` subclass object.\n        index_array: `list`. An optional list of index to be used instead of\n            using the whole dataset indexes (Useful for validation split).\n\n    """"""\n\n    def __init__(self, feed_dict, coord, batch_size=128, num_threads=8,\n                 max_queue=32, shuffle=False, continuous=False,\n                 ensure_data_order=False, dprep_dict=None, daug_dict=None,\n                 index_array=None):\n        super(FeedDictFlow, self).__init__(coord, num_threads, max_queue,\n                                           shuffle, continuous,\n                                           ensure_data_order,\n                                           dprep_dict,\n                                           daug_dict)\n        self.feed_dict = feed_dict\n        self.batch_size = batch_size\n        self.n_samples = len(utils.get_dict_first_element(feed_dict))\n\n        # Queue holding batch ids\n        self.batch_ids_queue = queue.Queue(self.max_queue)\n        # Queue holding data ready feed dicts\n        self.feed_dict_queue = queue.Queue(self.max_queue)\n\n        # Create samples index array\n        self.index_array = np.arange(self.n_samples)\n        if index_array is not None:\n            self.index_array = index_array\n            self.n_samples = len(index_array)\n\n        # Create batches\n        self.batches = self.make_batches()\n        self.reset_batches()\n\n        # Data Recording\n        self.data_status = DataFlowStatus(self.batch_size, self.n_samples)\n\n    def next(self, timeout=None):\n        """""" next.\n\n        Get the next feed dict.\n\n        Returns:\n            A TensorFlow feed dict, or \'False\' if it has no more data.\n\n        """"""\n        self.data_status.update()\n        return self.feed_dict_queue.get(timeout=timeout)\n\n    def start(self, reset_status=True):\n        """""" start.\n\n        Arguments:\n            reset_status: `bool`. If True, `DataStatus` will be reset.\n\n        Returns:\n\n        """"""\n        # Start to process data and fill queues\n        self.clear_queues()\n        self.interrupted = False\n        # Reset Data Status\n        if reset_status:\n            self.data_status.reset()\n        # Only a single thread needed for batches ids\n        bi_threads = [threading.Thread(target=self.fill_batch_ids_queue)]\n        # Multiple threads available for feed batch pre-processing\n        fd_threads = [threading.Thread(target=self.fill_feed_dict_queue)\n                      for i in range(self.num_threads)]\n        self.threads = bi_threads + fd_threads\n        for t in self.threads:\n            t.daemon = True\n            t.start()\n\n    def stop(self):\n        """""" stop.\n\n        Stop the queue from creating more feed_dict.\n\n        """"""\n        # Send stop signal to processing queue\n        for i in range(self.num_threads):\n            self.batch_ids_queue.put(False)\n        # Launch a Thread to wait for processing scripts to finish\n        t = threading.Thread(target=self.wait_for_threads)\n        t.daemon = True\n        t.start()\n\n    def reset(self):\n        """""" reset.\n\n        Reset batch index.\n        """"""\n        self.batch_index = -1\n\n    def interrupt(self):\n        # Send interruption signal to processing queue\n        self.interrupted = True\n        self.clear_queues()\n\n    def fill_feed_dict_queue(self):\n        while not self.coord.should_stop() and not self.interrupted:\n            batch_ids = self.batch_ids_queue.get()\n            if batch_ids is False:\n                break\n            data = self.retrieve_data(batch_ids)\n            # Apply augmentation according to daug dict\n            if self.daug_dict:\n                for k in self.daug_dict:\n                    data[k] = self.daug_dict[k].apply(data[k])\n            # Apply preprocessing according to dprep dict\n            if self.dprep_dict:\n                for k in self.dprep_dict:\n                    data[k] = self.dprep_dict[k].apply(data[k])\n            #all prepped, put the data into the queue\n            self.feed_dict_queue.put(data)\n\n    def fill_batch_ids_queue(self):\n        while not self.coord.should_stop() and not self.interrupted:\n            ids = self.next_batch_ids()\n            if ids is False:\n                break\n            self.batch_ids_queue.put(ids)\n\n    def next_batch_ids(self):\n\n        self.batch_index += 1\n        if self.batch_index == len(self.batches):\n            if not self.continuous:\n                self.stop()\n                return False\n            self.reset_batches()\n\n        batch_start, batch_end = self.batches[self.batch_index]\n        return self.index_array[batch_start:batch_end]\n\n    def retrieve_data(self, batch_ids):\n        feed_batch = {}\n        for key in self.feed_dict:\n            feed_batch[key] = \\\n                    utils.slice_array(self.feed_dict[key], batch_ids)\n        return feed_batch\n\n    def reset_batches(self):\n        if self.shuffle:\n            self.shuffle_samples()\n            # Generate new batches\n            self.batches = self.make_batches()\n        self.batch_index = -1\n\n    def make_batches(self):\n        return utils.make_batches(self.n_samples, self.batch_size)\n\n    def shuffle_samples(self):\n        np.random.shuffle(self.index_array)\n\n    def wait_for_threads(self):\n        # Wait for threads to finish computation (max 120s)\n        self.coord.join(self.threads)\n        # Send end signal to indicate no more data in feed queue\n        self.feed_dict_queue.put(False)\n\n    def clear_queues(self):\n        """""" clear_queues.\n\n        Clear queues.\n\n        """"""\n        while not self.feed_dict_queue.empty():\n            self.feed_dict_queue.get()\n        while not self.batch_ids_queue.empty():\n            self.batch_ids_queue.get()\n\n\nclass TFRecordsFlow(DataFlow):\n\n    def __init__(self, coord):\n        super(TFRecordsFlow, self).__init__(coord)\n        raise NotImplementedError\n\n\nclass DataFlowStatus(object):\n    """""" Data Flow Status\n\n    Simple class for recording how many data have been processed.\n\n    """"""\n\n    def __init__(self, batch_size, n_samples):\n        self.step = 0\n        self.epoch = 0\n        self.current_iter = 0\n        self.batch_size = batch_size\n        self.n_samples = n_samples\n\n    def update(self):\n        self.step += 1\n        self.current_iter = min(self.step * self.batch_size, self.n_samples)\n\n        if self.current_iter == self.n_samples:\n            self.epoch += 1\n            self.step = 0\n\n    def reset(self):\n        self.step = 0\n        self.epoch = 0\n\n\nclass ArrayFlow(object):\n    """""" ArrayFlow.\n\n    Convert array samples to tensors and store them in a queue.\n\n    Arguments:\n        X: `array`. The features data array.\n        Y: `array`. The targets data array.\n        multi_inputs: `bool`. Set to True if X has multiple input sources (i.e.\n            X is a list of arrays).\n        batch_size: `int`. The batch size.\n        shuffle: `bool`. If True, data will be shuffled.\n\n    Returns:\n        The `X` and `Y` data tensors or a list(`X`) and `Y` data tensors if\n        multi_inputs is True.\n\n    """"""\n    def __init__(self, X, Y, multi_inputs=False, batch_size=32, shuffle=True,\n                 capacity=None):\n        # Handle multiple inputs\n        if not multi_inputs:\n            X = [X]\n        if not capacity:\n            capacity =batch_size * 8\n        X = [np.array(x) for x in X]\n        self.X = X\n        self.Xlen = len(X[0])\n        Y = np.array(Y)\n        self.Y = Y\n        # Create X placeholders\n        self.tensorX = [tf.placeholder(\n                dtype=tf.float32,\n                shape=[None] + list(utils.get_incoming_shape(x)[1:]))\n            for x in X]\n        # Create Y placeholders\n        self.tensorY = tf.placeholder(\n            dtype=tf.float32,\n            shape=[None] + list(utils.get_incoming_shape(Y)[1:]))\n        # FIFO Queue for feeding data\n        self.queue = tf.FIFOQueue(\n            dtypes=[x.dtype for x in self.tensorX] + [self.tensorY.dtype],\n            capacity=capacity)\n        self.enqueue_op = self.queue.enqueue(self.tensorX + [self.tensorY])\n        self.batch_size = batch_size\n        self.multi_inputs = multi_inputs\n        self.shuffle = shuffle\n\n    def iterate(self, X, Y, batch_size):\n        while True:\n            # Shuffle array if specified\n            if self.shuffle:\n                idxs = np.arange(0, len(X[0]))\n                np.random.shuffle(idxs)\n                X = [x[idxs] for x in X]\n                Y = Y[idxs]\n            # Split array by batch\n            for batch_idx in range(0, self.Xlen, batch_size):\n                batchX = [x[batch_idx:batch_idx + batch_size] for x in X]\n                batchY = Y[batch_idx:batch_idx + batch_size]\n                yield batchX, batchY\n\n    def get(self):\n        # get data from the queue\n        dequeue = self.queue.dequeue()\n        if self.multi_inputs:\n            return dequeue[:-1], dequeue[-1]\n        else:\n            return dequeue[0], dequeue[1]\n\n    def launch_threads(self, session, num_threads=1):\n        threads = []\n        for i in range(num_threads):\n            t = threading.Thread(target=self.thread_main, args=(session,))\n            t.daemon = True\n            t.start()\n            threads.append(t)\n        return threads\n\n    def thread_main(self, sess):\n        for dataX, dataY in self.iterate(self.X, self.Y, self.batch_size):\n            feed_dict = {self.tensorY: dataY}\n            for i, x in enumerate(self.tensorX):\n                feed_dict[x] = dataX[i]\n            sess.run(self.enqueue_op, feed_dict=feed_dict)\n\n\ndef generate_data_tensor(X, Y, batch_size, shuffle=True, num_threads=1,\n                         capacity=None):\n    #TODO: Add a way with no batch?\n    #TODO: Set threads to #CPUs fo machine\n    cr = None\n    if capacity is None:\n        capacity = batch_size * num_threads * 4\n\n    if isinstance(X, tf.Tensor) and isinstance(Y, tf.Tensor):\n        # Optional Image and Label Batching\n        if shuffle:\n            X, Y = tf.train.shuffle_batch([X, Y], batch_size=batch_size,\n                                          min_after_dequeue=batch_size,\n                                          capacity=capacity,\n                                          num_threads=num_threads)\n        else:\n            X, Y = tf.train.batch([X, Y], batch_size=batch_size,\n                                  capacity=capacity,\n                                  num_threads=num_threads)\n\n    # Array Input\n    elif X is not None and Y is not None:\n        X_shape = list(np.shape(X))\n        Y_shape = list(np.shape(Y))\n        # Create a queue using feed_dicts\n        cr = ArrayFlow(X, Y, batch_size=batch_size, shuffle=shuffle,\n                       capacity=capacity)\n        X, Y = cr.get()\n        # Assign a shape to tensors\n        X_reshape = [-1] + X_shape[1:] if len(X_shape[1:]) > 0 else [-1, 1]\n        Y_reshape = [-1] + Y_shape[1:] if len(Y_shape[1:]) > 0 else [-1, 1]\n        X = tf.reshape(X, X_reshape)\n        Y = tf.reshape(Y, Y_reshape)\n\n    return X, Y, cr\n'"
tflearn/data_preprocessing.py,6,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport pickle\nimport tensorflow as tf\n\n_EPSILON = 1e-8\n\n\nclass DataPreprocessing(object):\n    """""" Data Preprocessing.\n\n    Base class for applying common real-time data preprocessing.\n\n    This class is meant to be used as an argument of `input_data`. When training\n    a model, the defined pre-processing methods will be applied at both\n    training and testing time. Note that DataAugmentation is similar to\n    DataPreprocessing, but only applies at training time.\n\n    Arguments:\n        None.\n\n    Parameters:\n        methods: `list of function`. Augmentation methods to apply.\n        args: A `list` of arguments to use for these methods.\n\n    """"""\n\n    def __init__(self, name=""DataPreprocessing""):\n        self.methods = []\n        self.args = []\n        self.session = None\n        # Data Persistence\n        with tf.name_scope(name) as scope:\n            self.scope = scope\n        self.global_mean = self.PersistentParameter(scope, name=""mean"")\n        self.global_std = self.PersistentParameter(scope, name=""std"")\n        self.global_pc = self.PersistentParameter(scope, name=""pc"")\n\n    def apply(self, batch):\n        for i, m in enumerate(self.methods):\n            if self.args[i]:\n                batch = m(batch, *self.args[i])\n            else:\n                batch = m(batch)\n        return batch\n\n    def restore_params(self, session):\n        self.global_mean.is_restored(session)\n        self.global_std.is_restored(session)\n        self.global_pc.is_restored(session)\n\n    def initialize(self, dataset, session, limit=None):\n        """""" Initialize preprocessing methods that pre-requires\n        calculation over entire dataset. """"""\n        if self.global_mean.is_required:\n            # If a value is already provided, it has priority\n            if self.global_mean.value is not None:\n                self.global_mean.assign(self.global_mean.value, session)\n            # Otherwise, if it has not been restored, compute it\n            if not self.global_mean.is_restored(session):\n                print(""---------------------------------"")\n                print(""Preprocessing... Calculating mean over all dataset ""\n                      ""(this may take long)..."")\n                self._compute_global_mean(dataset, session, limit)\n                print(""Mean: "" + str(self.global_mean.value) + "" (To avoid ""\n                      ""repetitive computation, add it to argument \'mean\' of ""\n                      ""`add_featurewise_zero_center`)"")\n        if self.global_std.is_required:\n            # If a value is already provided, it has priority\n            if self.global_std.value is not None:\n                self.global_std.assign(self.global_std.value, session)\n            # Otherwise, if it has not been restored, compute it\n            if not self.global_std.is_restored(session):\n                print(""---------------------------------"")\n                print(""Preprocessing... Calculating std over all dataset ""\n                      ""(this may take long)..."")\n                self._compute_global_std(dataset, session, limit)\n                print(""STD: "" + str(self.global_std.value) + "" (To avoid ""\n                      ""repetitive computation, add it to argument \'std\' of ""\n                      ""`add_featurewise_stdnorm`)"")\n        if self.global_pc.is_required:\n            # If a value is already provided, it has priority\n            if self.global_pc.value is not None:\n                self.global_pc.assign(self.global_pc.value, session)\n            # Otherwise, if it has not been restored, compute it\n            if not self.global_pc.is_restored(session):\n                print(""---------------------------------"")\n                print(""Preprocessing... PCA over all dataset ""\n                      ""(this may take long)..."")\n                self._compute_global_pc(dataset, session, limit)\n                with open(\'PC.pkl\', \'wb\') as f:\n                    pickle.dump(self.global_pc.value, f)\n                print(""PC saved to \'PC.pkl\' (To avoid repetitive computation, ""\n                      ""load this pickle file and assign its value to \'pc\' ""\n                      ""argument of `add_zca_whitening`)"")\n\n    # -----------------------\n    #  Preprocessing Methods\n    # -----------------------\n\n    def add_custom_preprocessing(self, func):\n        """""" add_custom_preprocessing.\n\n        Apply any custom pre-processing function to the .\n\n        Arguments:\n            func: a `Function` that take a numpy array as input and returns\n                a numpy array.\n\n        Returns:\n            Nothing.\n        """"""\n        self.methods.append(func)\n        self.args.append(None)\n\n    def add_samplewise_zero_center(self):\n        """""" add_samplewise_zero_center.\n\n        Zero center each sample by subtracting it by its mean.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._samplewise_zero_center)\n        self.args.append(None)\n\n    def add_samplewise_stdnorm(self):\n        """""" add_samplewise_stdnorm.\n\n        Scale each sample with its standard deviation.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._samplewise_stdnorm)\n        self.args.append(None)\n\n    def add_featurewise_zero_center(self, mean=None):\n        """""" add_samplewise_zero_center.\n\n        Zero center every sample with specified mean. If not specified,\n        the mean is evaluated over all samples.\n\n        Arguments:\n            mean: `float` (optional). Provides a custom mean. If none\n                provided, it will be automatically caluclated based on\n                the training dataset. Default: None.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.global_mean.is_required = True\n        self.global_mean.value = mean\n        self.methods.append(self._featurewise_zero_center)\n        self.args.append(None)\n\n    def add_featurewise_stdnorm(self, std=None):\n        """""" add_featurewise_stdnorm.\n\n        Scale each sample by the specified standard deviation. If no std\n        specified, std is evaluated over all samples data.\n\n        Arguments:\n            std: `float` (optional). Provides a custom standard derivation.\n                If none provided, it will be automatically caluclated based on\n                the training dataset. Default: None.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.global_std.is_required = True\n        self.global_std.value = std\n        self.methods.append(self._featurewise_stdnorm)\n        self.args.append(None)\n\n    def add_zca_whitening(self, pc=None):\n        """""" add_zca_whitening.\n\n        Apply ZCA Whitening to data.\n\n        Arguments:\n            pc: `array` (optional). Use the provided pre-computed principal\n                component instead of computing it.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.global_pc.is_required = True\n        self.global_pc.value = pc\n        self.methods.append(self._zca_whitening)\n        self.args.append(None)\n\n    # ---------------------------\n    #  Preprocessing Calculation\n    # ---------------------------\n\n    def _samplewise_zero_center(self, batch):\n        for i in range(len(batch)):\n            batch[i] -= np.mean(batch[i], axis=0)\n        return batch\n\n    def _samplewise_stdnorm(self, batch):\n        for i in range(len(batch)):\n            batch[i] /= (np.std(batch[i], axis=0) + _EPSILON)\n        return batch\n\n    def _featurewise_zero_center(self, batch):\n        for i in range(len(batch)):\n            batch[i] -= self.global_mean.value\n        return batch\n\n    def _featurewise_stdnorm(self, batch):\n        for i in range(len(batch)):\n            batch[i] /= (self.global_std.value + _EPSILON)\n        return batch\n\n    def _zca_whitening(self, batch):\n        for i in range(len(batch)):\n            flat = np.reshape(batch[i], batch[i].size)\n            white = np.dot(flat, self.global_pc.value)\n            s1, s2, s3 = batch[i].shape[0], batch[i].shape[1], batch[i].shape[2]\n            batch[i] = np.reshape(white, (s1, s2, s3))\n        return batch\n\n    # ---------------------------------------\n    #  Calulation with Persistent Parameters\n    # ---------------------------------------\n\n    def _compute_global_mean(self, dataset, session, limit=None):\n        """""" Compute mean of a dataset. A limit can be specified for faster\n        computation, considering only \'limit\' first elements. """"""\n        _dataset = dataset\n        mean = 0.\n        if isinstance(limit, int):\n            _dataset = _dataset[:limit]\n        if isinstance(_dataset, np.ndarray):\n            mean = np.mean(_dataset)\n        else:\n            # Iterate in case of non numpy data\n            for i in range(len(dataset)):\n                mean += np.mean(dataset[i]) / len(dataset)\n        self.global_mean.assign(mean, session)\n        return mean\n\n    def _compute_global_std(self, dataset, session, limit=None):\n        """""" Compute std of a dataset. A limit can be specified for faster\n        computation, considering only \'limit\' first elements. """"""\n        _dataset = dataset\n        std = 0.\n        if isinstance(limit, int):\n            _dataset = _dataset[:limit]\n        if isinstance(_dataset, np.ndarray):\n            std = np.std(_dataset)\n        else:\n            for i in range(len(dataset)):\n                std += np.std(dataset[i]) / len(dataset)\n        self.global_std.assign(std, session)\n        return std\n\n    def _compute_global_pc(self, dataset, session, limit=None):\n        """""" Compute the Principal Component. """"""\n        _dataset = dataset\n        if isinstance(limit, int):\n            _dataset = _dataset[:limit]\n        d = _dataset\n        s0, s1, s2, s3 = d.shape[0], d.shape[1], d.shape[2], d.shape[3]\n        flat = np.reshape(d, (s0, s1 * s2 * s3))\n        sigma = np.dot(flat.T, flat) / flat.shape[1]\n        U, S, V = np.linalg.svd(sigma)\n        pc = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + _EPSILON))), U.T)\n        self.global_pc.assign(pc, session)\n        return pc\n\n    # -----------------------\n    #  Persistent Parameters\n    # -----------------------\n\n    class PersistentParameter:\n        """""" Create a persistent variable that will be stored into the Graph.\n        """"""\n        def __init__(self, scope, name):\n            self.is_required = False\n            with tf.name_scope(scope):\n                with tf.device(\'/cpu:0\'):\n                    # One variable contains the value\n                    self.var = tf.Variable(0., trainable=False, name=name,\n                                           validate_shape=False)\n                    # Another one check if it has been restored or not\n                    self.var_r = tf.Variable(False, trainable=False,\n                                             name=name+""_r"")\n            # RAM saved vars for faster access\n            self.restored = False\n            self.value = None\n\n        def is_restored(self, session):\n            if self.var_r.eval(session=session):\n                self.value = self.var.eval(session=session)\n                return True\n            else:\n                return False\n\n        def assign(self, value, session):\n            session.run(tf.assign(self.var, value, validate_shape=False))\n            self.value = value\n            session.run(self.var_r.assign(True))\n            self.restored = True\n\n\nclass ImagePreprocessing(DataPreprocessing):\n    """""" Image Preprocessing.\n\n    Base class for applying real-time image related pre-processing.\n\n    This class is meant to be used as an argument of `input_data`. When training\n    a model, the defined pre-processing methods will be applied at both\n    training and testing time. Note that ImageAugmentation is similar to\n    ImagePreprocessing, but only applies at training time.\n\n    """"""\n\n    def __init__(self):\n        super(ImagePreprocessing, self).__init__()\n        self.global_mean_pc = False\n        self.global_std_pc = False\n\n    # -----------------------\n    #  Preprocessing Methods\n    # -----------------------\n\n    def add_image_normalization(self):\n        """""" add_image_normalization.\n\n        Normalize a picture pixel to 0-1 float (instead of 0-255 int).\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._normalize_image)\n        self.args.append(None)\n\n    def add_crop_center(self, shape):\n        """""" add_crop_center.\n\n        Crop the center of an image.\n\n        Arguments:\n            shape: `tuple` of `int`. The croping shape (height, width).\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._crop_center)\n        self.args.append([shape])\n\n    def resize(self, height, width):\n        raise NotImplementedError\n\n    def blur(self):\n        raise NotImplementedError\n\n    # -----------------------\n    #  Preprocessing Methods\n    # -----------------------\n\n    def _normalize_image(self, batch):\n        return np.array(batch) / 255.\n\n    def _crop_center(self, batch, shape):\n        oshape = np.shape(batch[0])\n        nh = int((oshape[0] - shape[0]) * 0.5)\n        nw = int((oshape[1] - shape[1]) * 0.5)\n        new_batch = []\n        for i in range(len(batch)):\n            new_batch.append(batch[i][nh: nh + shape[0], nw: nw + shape[1]])\n        return new_batch\n\n    # ----------------------------------------------\n    #  Preprocessing Methods (Overwritten from Base)\n    # ----------------------------------------------\n\n    def add_samplewise_zero_center(self, per_channel=False):\n        """""" add_samplewise_zero_center.\n\n        Zero center each sample by subtracting it by its mean.\n\n        Arguments:\n            per_channel: `bool`. If True, apply per channel mean.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._samplewise_zero_center)\n        self.args.append([per_channel])\n\n    def add_samplewise_stdnorm(self, per_channel=False):\n        """""" add_samplewise_stdnorm.\n\n        Scale each sample with its standard deviation.\n\n        Arguments:\n            per_channel: `bool`. If True, apply per channel std.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.methods.append(self._samplewise_stdnorm)\n        self.args.append([per_channel])\n\n    def add_featurewise_zero_center(self, mean=None, per_channel=False):\n        """""" add_samplewise_zero_center.\n\n        Zero center every sample with specified mean. If not specified,\n        the mean is evaluated over all samples.\n\n        Arguments:\n            mean: `float` (optional). Provides a custom mean. If none\n                provided, it will be automatically caluclated based on\n                the training dataset. Default: None.\n            per_channel: `bool`. If True, compute mean per color channel.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.global_mean.is_required = True\n        self.global_mean.value = mean\n        if per_channel:\n            self.global_mean_pc = True\n        self.methods.append(self._featurewise_zero_center)\n        self.args.append(None)\n\n    def add_featurewise_stdnorm(self, std=None, per_channel=False):\n        """""" add_featurewise_stdnorm.\n\n        Scale each sample by the specified standard deviation. If no std\n        specified, std is evaluated over all samples data.\n\n        Arguments:\n            std: `float` (optional). Provides a custom standard derivation.\n                If none provided, it will be automatically caluclated based on\n                the training dataset. Default: None.\n            per_channel: `bool`. If True, compute std per color channel.\n\n        Returns:\n            Nothing.\n\n        """"""\n        self.global_std.is_required = True\n        self.global_std.value = std\n        if per_channel:\n            self.global_std_pc = True\n        self.methods.append(self._featurewise_stdnorm)\n        self.args.append(None)\n\n    # --------------------------------------------------\n    #  Preprocessing Calculation (Overwritten from Base)\n    # --------------------------------------------------\n\n    def _samplewise_zero_center(self, batch, per_channel=False):\n        for i in range(len(batch)):\n            if not per_channel:\n                batch[i] -= np.mean(batch[i])\n            else:\n                batch[i] -= np.mean(batch[i], axis=(0, 1, 2), keepdims=True)\n        return batch\n\n    def _samplewise_stdnorm(self, batch, per_channel=False):\n        for i in range(len(batch)):\n            if not per_channel:\n                batch[i] /= (np.std(batch[i]) + _EPSILON)\n            else:\n                batch[i] /= (np.std(batch[i], axis=(0, 1, 2),\n                                    keepdims=True) + _EPSILON)\n        return batch\n\n    # --------------------------------------------------------------\n    #  Calulation with Persistent Parameters (Overwritten from Base)\n    # --------------------------------------------------------------\n\n    def _compute_global_mean(self, dataset, session, limit=None):\n        """""" Compute mean of a dataset. A limit can be specified for faster\n        computation, considering only \'limit\' first elements. """"""\n        _dataset = dataset\n        mean = 0.\n        if isinstance(limit, int):\n            _dataset = _dataset[:limit]\n        if isinstance(_dataset, np.ndarray) and not self.global_mean_pc:\n            mean = np.mean(_dataset)\n        else:\n            # Iterate in case of non numpy data\n            for i in range(len(dataset)):\n                if not self.global_mean_pc:\n                    mean += np.mean(dataset[i]) / len(dataset)\n                else:\n                    mean += (np.mean(dataset[i], axis=(0, 1),\n                             keepdims=True) / len(dataset))[0][0]\n        self.global_mean.assign(mean, session)\n        return mean\n\n    def _compute_global_std(self, dataset, session, limit=None):\n        """""" Compute std of a dataset. A limit can be specified for faster\n        computation, considering only \'limit\' first elements. """"""\n        _dataset = dataset\n        std = 0.\n        if isinstance(limit, int):\n            _dataset = _dataset[:limit]\n        if isinstance(_dataset, np.ndarray) and not self.global_std_pc:\n            std = np.std(_dataset)\n        else:\n            for i in range(len(dataset)):\n                if not self.global_std_pc:\n                    std += np.std(dataset[i]) / len(dataset)\n                else:\n                    std += (np.std(dataset[i], axis=(0, 1),\n                             keepdims=True) / len(dataset))[0][0]\n        self.global_std.assign(std, session)\n        return std\n\n\nclass SequencePreprocessing(DataPreprocessing):\n\n    def __init__(self):\n        super(SequencePreprocessing, self).__init__()\n\n    def sequence_padding(self):\n        raise NotImplementedError\n'"
tflearn/data_utils.py,3,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport os\nimport random\nimport numpy as np\nfrom PIL import Image\nimport pickle\nimport csv\nimport warnings\nimport tensorflow as tf\ntry: #py3\n    from urllib.parse import urlparse\n    from urllib import request\nexcept: #py2\n    from urlparse import urlparse\n    from six.moves.urllib import request\nfrom io import BytesIO\n\n""""""\nPreprocessing provides some useful functions to preprocess data before\ntraining, such as pictures dataset building, sequence padding, etc...\n\nNote: Those preprocessing functions are only meant to be directly applied to\ndata, they are not meant to be use with Tensors or Layers.\n""""""\n\n_EPSILON = 1e-8\n\n\n# =======================\n# TARGETS (LABELS) UTILS\n# =======================\n\n\ndef to_categorical(y, nb_classes=None):\n    """""" to_categorical.\n\n    Convert class vector (integers from 0 to nb_classes)\n    to binary class matrix, for use with categorical_crossentropy.\n\n    Arguments:\n        y: `array`. Class vector to convert.\n        nb_classes: `int`. The total number of classes.\n    """"""\n    if nb_classes:\n        y = np.asarray(y, dtype=\'int32\')\n        if len(y.shape) > 2:\n            print(""Warning: data array ndim > 2"")\n        if len(y.shape) > 1:\n            y = y.reshape(-1)\n        Y = np.zeros((len(y), nb_classes))\n        Y[np.arange(len(y)), y] = 1.\n        return Y\n    else:\n        y = np.array(y)\n        return (y[:, None] == np.unique(y)).astype(np.float32)\n\n\n# =====================\n#    SEQUENCES UTILS\n# =====================\n\n\ndef pad_sequences(sequences, maxlen=None, dtype=\'int32\', padding=\'post\',\n                  truncating=\'post\', value=0.):\n    """""" pad_sequences.\n\n    Pad each sequence to the same length: the length of the longest sequence.\n    If maxlen is provided, any sequence longer than maxlen is truncated to\n    maxlen. Truncation happens off either the beginning or the end (default)\n    of the sequence. Supports pre-padding and post-padding (default).\n\n    Arguments:\n        sequences: list of lists where each element is a sequence.\n        maxlen: int, maximum length.\n        dtype: type to cast the resulting sequence.\n        padding: \'pre\' or \'post\', pad either before or after each sequence.\n        truncating: \'pre\' or \'post\', remove values from sequences larger than\n            maxlen either in the beginning or in the end of the sequence\n        value: float, value to pad the sequences to the desired value.\n\n    Returns:\n        x: `numpy array` with dimensions (number_of_sequences, maxlen)\n\n    Credits: From Keras `pad_sequences` function.\n    """"""\n    lengths = [len(s) for s in sequences]\n\n    nb_samples = len(sequences)\n    if maxlen is None:\n        maxlen = np.max(lengths)\n\n    x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)\n    for idx, s in enumerate(sequences):\n        if len(s) == 0:\n            continue  # empty list was found\n        if truncating == \'pre\':\n            trunc = s[-maxlen:]\n        elif truncating == \'post\':\n            trunc = s[:maxlen]\n        else:\n            raise ValueError(""Truncating type \'%s\' not understood"" % truncating)\n\n        if padding == \'post\':\n            x[idx, :len(trunc)] = trunc\n        elif padding == \'pre\':\n            x[idx, -len(trunc):] = trunc\n        else:\n            raise ValueError(""Padding type \'%s\' not understood"" % padding)\n    return x\n\n\ndef string_to_semi_redundant_sequences(string, seq_maxlen=25, redun_step=3, char_idx=None):\n    """""" string_to_semi_redundant_sequences.\n\n    Vectorize a string and returns parsed sequences and targets, along with\n    the associated dictionary.\n\n    Arguments:\n        string: `str`. Lower-case text from input text file.\n        seq_maxlen: `int`. Maximum length of a sequence. Default: 25.\n        redun_step: `int`. Redundancy step. Default: 3.\n        char_idx: \'dict\'. A dictionary to convert chars to positions. Will be automatically generated if None\n\n    Returns:\n        A tuple: (inputs, targets, dictionary)\n    """"""\n\n    print(""Vectorizing text..."")\n\n    if char_idx is None:\n      char_idx = chars_to_dictionary(string)\n\n    len_chars = len(char_idx)\n\n    sequences = []\n    next_chars = []\n    for i in range(0, len(string) - seq_maxlen, redun_step):\n        sequences.append(string[i: i + seq_maxlen])\n        next_chars.append(string[i + seq_maxlen])\n\n    X = np.zeros((len(sequences), seq_maxlen, len_chars), dtype=np.bool)\n    Y = np.zeros((len(sequences), len_chars), dtype=np.bool)\n    for i, seq in enumerate(sequences):\n        for t, char in enumerate(seq):\n            X[i, t, char_idx[char]] = 1\n        Y[i, char_idx[next_chars[i]]] = 1\n\n    print(""Text total length: {:,}"".format(len(string)))\n    print(""Distinct chars   : {:,}"".format(len_chars))\n    print(""Total sequences  : {:,}"".format(len(sequences)))\n\n    return X, Y, char_idx\n\n\ndef textfile_to_semi_redundant_sequences(path, seq_maxlen=25, redun_step=3,\n                                         to_lower_case=False, pre_defined_char_idx=None):\n    """""" Vectorize Text file """"""\n    text = open(path).read()\n    if to_lower_case:\n        text = text.lower()\n    return string_to_semi_redundant_sequences(text, seq_maxlen, redun_step, pre_defined_char_idx)\n\n\ndef chars_to_dictionary(string):\n    """""" Creates a dictionary char:integer for each unique character """"""\n    chars = set(string)\n    # sorted tries to keep a consistent dictionary, if you run a second time for the same char set\n    char_idx = {c: i for i, c in enumerate(sorted(chars))}\n    return char_idx\n\n\ndef random_sequence_from_string(string, seq_maxlen):\n    rand_index = random.randint(0, len(string) - seq_maxlen - 1)\n    return string[rand_index: rand_index + seq_maxlen]\n\n\ndef random_sequence_from_textfile(path, seq_maxlen):\n    text = open(path).read()\n    return random_sequence_from_string(text, seq_maxlen)\n\n\nclass VocabularyProcessor(object):\n    """""" Vocabulary Processor.\n\n    Maps documents to sequences of word ids.\n\n    Arguments:\n        max_document_length: Maximum length of documents.\n            if documents are longer, they will be trimmed, if shorter - padded.\n        min_frequency: Minimum frequency of words in the vocabulary.\n        vocabulary: CategoricalVocabulary object.\n\n    Attributes:\n        vocabulary_: CategoricalVocabulary object.\n\n    """"""\n\n    def __init__(self,\n                 max_document_length,\n                 min_frequency=0,\n                 vocabulary=None,\n                 tokenizer_fn=None):\n        from tensorflow.contrib.learn.python.learn.preprocessing.text import \\\n            VocabularyProcessor as _VocabularyProcessor\n        self.__dict__[\'_vocabulary_processor\'] = _VocabularyProcessor(\n            max_document_length,\n            min_frequency,\n            vocabulary,\n            tokenizer_fn)\n\n    def __getattr__(self, key):\n        return getattr(self._vocabulary_processor, key)\n\n    def __setattr__(self, key, value):\n        setattr(self._vocabulary_processor, key, value)\n\n    def fit(self, raw_documents, unused_y=None):\n        """""" fit.\n\n        Learn a vocabulary dictionary of all tokens in the raw documents.\n\n        Arguments:\n            raw_documents: An iterable which yield either str or unicode.\n            unused_y: to match fit format signature of estimators.\n\n        Returns:\n            self\n        """"""\n        return self._vocabulary_processor.fit(raw_documents, unused_y)\n\n    def fit_transform(self, raw_documents, unused_y=None):\n        """""" fit_transform.\n\n        Learn the vocabulary dictionary and return indices of words.\n\n        Arguments:\n            raw_documents: An iterable which yield either str or unicode.\n            unused_y: to match fit_transform signature of estimators.\n\n        Returns:\n            X: iterable, [n_samples, max_document_length] Word-id matrix.\n        """"""\n        return self._vocabulary_processor.fit_transform(raw_documents,\n                                                              unused_y)\n\n    def transform(self, raw_documents):\n        """""" transform.\n\n        Transform documents to word-id matrix.\n\n        Convert words to ids with vocabulary fitted with fit or the one\n        provided in the constructor.\n\n        Arguments:\n            raw_documents: An iterable which yield either str or unicode.\n\n        Yields:\n            X: iterable, [n_samples, max_document_length] Word-id matrix.\n        """"""\n        return self._vocabulary_processor.transform(raw_documents)\n\n    def reverse(self, documents):\n        """""" reverse.\n\n        Reverses output of vocabulary mapping to words.\n\n        Arguments:\n            documents: iterable, list of class ids.\n\n        Returns:\n            Iterator over mapped in words documents.\n        """"""\n        return self._vocabulary_processor.reverse(documents)\n\n    def save(self, filename):\n        """""" save.\n\n        Saves vocabulary processor into given file.\n\n        Arguments:\n            filename: Path to output file.\n        """"""\n        return self._vocabulary_processor.save(filename)\n\n    @classmethod\n    def restore(cls, filename):\n        """""" restore.\n\n        Restores vocabulary processor from given file.\n\n        Arguments:\n            filename: Path to file to load from.\n\n        Returns:\n            VocabularyProcessor object.\n        """"""\n        return self._vocabulary_processor.restore(filename)\n\n\n# ===================\n#    IMAGES UTILS\n# ===================\n\ndef build_hdf5_image_dataset(target_path, image_shape, output_path=\'dataset.h5\',\n                             mode=\'file\', categorical_labels=True,\n                             normalize=True, grayscale=False,\n                             files_extension=None, chunks=False, image_base_path=\'\', float_labels=False):\n    """""" Build HDF5 Image Dataset.\n\n    Build an HDF5 dataset by providing either a root folder or a plain text\n    file with images path and class id.\n\n    \'folder\' mode: Root folder should be arranged as follow:\n    ```\n    ROOT_FOLDER -> SUBFOLDER_0 (CLASS 0) -> CLASS0_IMG1.jpg\n                                         -> CLASS0_IMG2.jpg\n                                         -> ...\n                -> SUBFOLDER_1 (CLASS 1) -> CLASS1_IMG1.jpg\n                                         -> ...\n                -> ...\n    ```\n    Note that if sub-folders are not integers from 0 to n_classes, an id will\n    be assigned to each sub-folder following alphabetical order.\n\n    \'file\' mode: Plain text file should be formatted as follow:\n    ```\n    /path/to/img1 class_id\n    /path/to/img2 class_id\n    /path/to/img3 class_id\n    ```\n\n    Examples:\n        ```\n        # Load path/class_id image file:\n        dataset_file = \'my_dataset.txt\'\n\n        # Build a HDF5 dataset (only required once)\n        from tflearn.data_utils import build_hdf5_image_dataset\n        build_hdf5_image_dataset(dataset_file, image_shape=(128, 128),\n                                 mode=\'file\', output_path=\'dataset.h5\',\n                                 categorical_labels=True, normalize=True)\n\n        # Load HDF5 dataset\n        import h5py\n        h5f = h5py.File(\'dataset.h5\', \'r\')\n        X = h5f[\'X\']\n        Y = h5f[\'Y\']\n\n        # Build neural network and train\n        network = ...\n        model = DNN(network, ...)\n        model.fit(X, Y)\n        ```\n\n    Arguments:\n        target_path: `str`. Path of root folder or images plain text file.\n        image_shape: `tuple (height, width)`. The images shape. Images that\n            doesn\'t match that shape will be resized.\n        output_path: `str`. The output path for the hdf5 dataset. Default:\n            \'dataset.h5\'\n        mode: `str` in [\'file\', \'folder\']. The data source mode. \'folder\'\n            accepts a root folder with each of his sub-folder representing a\n            class containing the images to classify.\n            \'file\' accepts a single plain text file that contains every\n            image path with their class id.\n            Default: \'folder\'.\n        categorical_labels: `bool`. If True, labels are converted to binary\n            vectors.\n        normalize: `bool`. If True, normalize all pictures by dividing\n            every image array by 255.\n        grayscale: `bool`. If true, images are converted to grayscale.\n        files_extension: `list of str`. A list of allowed image file\n            extension, for example [\'.jpg\', \'.jpeg\', \'.png\']. If None,\n            all files are allowed.\n        chunks: `bool` Whether to chunks the dataset or not. You should use\n            chunking only when you really need it. See HDF5 documentation.\n            If chunks is \'True\' a sensitive default will be computed.\n        image_base_path: `str`. Base path for the images listed in the file mode.\n        float_labels: `bool`. Read float labels instead of integers in file mode.\n\n    """"""\n    import h5py\n\n    assert image_shape, ""Image shape must be defined.""\n    assert image_shape[0] and image_shape[1], \\\n        ""Image shape error. It must be a tuple of int: (\'width\', \'height\').""\n    assert mode in [\'folder\', \'file\'], ""`mode` arg must be \'folder\' or \'file\'""\n\n    if mode == \'folder\':\n        images, labels = directory_to_samples(target_path,\n                                              flags=files_extension)\n    else:\n        with open(target_path, \'r\') as f:\n            images, labels = [], []\n            for l in f.readlines():\n                l = l.strip(\'\\n\').split()\n                l[0] = image_base_path + l[0]\n                images.append(l[0])\n                if float_labels:\n                    labels.append(float(l[1]))\n                else:\n                    labels.append(int(l[1]))\n\n    n_classes = np.max(labels) + 1\n\n    d_imgshape = (len(images), image_shape[1], image_shape[0], 3) \\\n        if not grayscale else (len(images), image_shape[1], image_shape[0])\n    d_labelshape = (len(images), n_classes) \\\n        if categorical_labels else (len(images), )\n    x_chunks = None\n    y_chunks = None\n    if chunks is True:\n        x_chunks = (1,)+ d_imgshape[1:]\n        if len(d_labelshape) > 1:\n            y_chunks = (1,) + d_labelshape[1:]\n    dataset = h5py.File(output_path, \'w\')\n    dataset.create_dataset(\'X\', d_imgshape, chunks=x_chunks)\n    dataset.create_dataset(\'Y\', d_labelshape, chunks=y_chunks)\n\n    for i in range(len(images)):\n        img = load_image(images[i])\n        width, height = img.size\n        if width != image_shape[0] or height != image_shape[1]:\n            img = resize_image(img, image_shape[0], image_shape[1])\n        if grayscale:\n            img = convert_color(img, \'L\')\n        elif img.mode == \'L\' or img.mode == \'RGBA\':\n            img = convert_color(img, \'RGB\')\n\n        img = pil_to_nparray(img)\n        if normalize:\n            img /= 255.\n        dataset[\'X\'][i] = img\n        if categorical_labels:\n            dataset[\'Y\'][i] = to_categorical([labels[i]], n_classes)[0]\n        else:\n            dataset[\'Y\'][i] = labels[i]\n\n\ndef get_img_channel(image_path):\n    """"""\n    Load a image and return the channel of the image\n    :param image_path:\n    :return: the channel of the image\n    """"""\n    img = load_image(image_path)\n    img = pil_to_nparray(img)\n    try:\n        channel = img.shape[2]\n    except:\n        channel = 1\n    return channel\n\n\ndef image_preloader(target_path, image_shape, mode=\'file\', normalize=True,\n                    grayscale=False, categorical_labels=True,\n                    files_extension=None, filter_channel=False, image_base_path=\'\', float_labels=False):\n    """""" Image PreLoader.\n\n    Create a python array (`Preloader`) that loads images on the fly (from\n    disk or url). There is two ways to provide image samples \'folder\' or\n    \'file\', see the specifications below.\n\n    \'folder\' mode: Load images from disk, given a root folder. This folder\n    should be arranged as follow:\n    ```\n    ROOT_FOLDER -> SUBFOLDER_0 (CLASS 0) -> CLASS0_IMG1.jpg\n                                         -> CLASS0_IMG2.jpg\n                                         -> ...\n                -> SUBFOLDER_1 (CLASS 1) -> CLASS1_IMG1.jpg\n                                         -> ...\n                -> ...\n    ```\n    Note that if sub-folders are not integers from 0 to n_classes, an id will\n    be assigned to each sub-folder following alphabetical order.\n\n    \'file\' mode: A plain text file listing every image path and class id.\n    This file should be formatted as follow:\n    ```\n    /path/to/img1 class_id\n    /path/to/img2 class_id\n    /path/to/img3 class_id\n    ```\n\n    Note that load images on the fly and convert is time inefficient,\n    so you can instead use `build_hdf5_image_dataset` to build a HDF5 dataset\n    that enable fast retrieval (this function takes similar arguments).\n\n    Examples:\n        ```\n        # Load path/class_id image file:\n        dataset_file = \'my_dataset.txt\'\n\n        # Build the preloader array, resize images to 128x128\n        from tflearn.data_utils import image_preloader\n        X, Y = image_preloader(dataset_file, image_shape=(128, 128),\n                               mode=\'file\', categorical_labels=True,\n                               normalize=True)\n\n        # Build neural network and train\n        network = ...\n        model = DNN(network, ...)\n        model.fit(X, Y)\n        ```\n\n    Arguments:\n        target_path: `str`. Path of root folder or images plain text file.\n        image_shape: `tuple (height, width)`. The images shape. Images that\n            doesn\'t match that shape will be resized.\n        mode: `str` in [\'file\', \'folder\']. The data source mode. \'folder\'\n            accepts a root folder with each of his sub-folder representing a\n            class containing the images to classify.\n            \'file\' accepts a single plain text file that contains every\n            image path with their class id.\n            Default: \'folder\'.\n        categorical_labels: `bool`. If True, labels are converted to binary\n            vectors.\n        normalize: `bool`. If True, normalize all pictures by dividing\n            every image array by 255.\n        grayscale: `bool`. If true, images are converted to grayscale.\n        files_extension: `list of str`. A list of allowed image file\n            extension, for example [\'.jpg\', \'.jpeg\', \'.png\']. If None,\n            all files are allowed.\n        filter_channel: `bool`. If true, images which the channel is not 3 should\n            be filter.\n        image_base_path: `str`. Base path for the images listed in the file mode.\n        float_labels: `bool`. Read float labels instead of integers in file mode.\n\n    Returns:\n        (X, Y): with X the images array and Y the labels array.\n\n    """"""\n    assert mode in [\'folder\', \'file\']\n    if mode == \'folder\':\n        images, labels = directory_to_samples(target_path,\n                                              flags=files_extension, filter_channel=filter_channel)\n    else:\n        with open(target_path, \'r\') as f:\n            images, labels = [], []\n            for l in f.readlines():\n                l = l.strip(\'\\n\').split()\n                l[0] = image_base_path + l[0]\n                if not files_extension or any(flag in l[0] for flag in files_extension):\n                    if filter_channel:\n                        if get_img_channel(l[0]) != 3:\n                            continue\n                    images.append(l[0])\n                    if float_labels:\n                        labels.append(float(l[1]))\n                    else:\n                        labels.append(int(l[1]))\n\n    n_classes = np.max(labels) + 1\n    X = ImagePreloader(images, image_shape, normalize, grayscale)\n    Y = LabelPreloader(labels, n_classes, categorical_labels)\n\n    return X, Y\n\n\ndef load_image(in_image):\n    """""" Load an image, returns PIL.Image. """"""\n    # if the path appears to be an URL\n    if urlparse(in_image).scheme in (\'http\', \'https\',):\n        # set up the byte stream\n        img_stream = BytesIO(request.urlopen(in_image).read())\n        # and read in as PIL image\n        img = Image.open(img_stream)\n    else:\n        # else use it as local file path\n        img = Image.open(in_image)\n    return img\n\n\ndef resize_image(in_image, new_width, new_height, out_image=None,\n                 resize_mode=Image.ANTIALIAS):\n    """""" Resize an image.\n\n    Arguments:\n        in_image: `PIL.Image`. The image to resize.\n        new_width: `int`. The image new width.\n        new_height: `int`. The image new height.\n        out_image: `str`. If specified, save the image to the given path.\n        resize_mode: `PIL.Image.mode`. The resizing mode.\n\n    Returns:\n        `PIL.Image`. The resize image.\n\n    """"""\n    img = in_image.resize((new_width, new_height), resize_mode)\n    if out_image:\n        img.save(out_image)\n    return img\n\n\ndef convert_color(in_image, mode):\n    """""" Convert image color with provided `mode`. """"""\n    return in_image.convert(mode)\n\n\ndef pil_to_nparray(pil_image):\n    """""" Convert a PIL.Image to numpy array. """"""\n    pil_image.load()\n    return np.asarray(pil_image, dtype=""float32"")\n\n\ndef image_dirs_to_samples(directory, resize=None, convert_gray=None,\n                          filetypes=None):\n    print(""Starting to parse images..."")\n    if filetypes:\n        if filetypes not in [list, tuple]: filetypes = list(filetypes)\n    samples, targets = directory_to_samples(directory, flags=filetypes)\n    for i, s in enumerate(samples):\n        samples[i] = load_image(s)\n        if resize:\n            samples[i] = resize_image(samples[i], resize[0], resize[1])\n        if convert_gray:\n            samples[i] = convert_color(samples[i], \'L\')\n        samples[i] = pil_to_nparray(samples[i])\n        samples[i] /= 255.\n    print(""Parsing Done!"")\n    return samples, targets\n\n\ndef build_image_dataset_from_dir(directory,\n                                 dataset_file=""my_tflearn_dataset.pkl"",\n                                 resize=None, convert_gray=None,\n                                 filetypes=None, shuffle_data=False,\n                                 categorical_Y=False):\n    try:\n        X, Y = pickle.load(open(dataset_file, \'rb\'))\n    except Exception:\n        X, Y = image_dirs_to_samples(directory, resize, convert_gray, filetypes)\n        if categorical_Y:\n            Y = to_categorical(Y, np.max(Y) + 1) # First class is \'0\'\n        if shuffle_data:\n            X, Y = shuffle(X, Y)\n        pickle.dump((X, Y), open(dataset_file, \'wb\'))\n    return X, Y\n\n\ndef random_flip_leftright(x):\n    if bool(random.getrandbits(1)):\n        return np.fliplr(x)\n    else:\n        return x\n\n\ndef random_flip_updown(x):\n    if bool(random.getrandbits(1)):\n        return np.flipud(x)\n    else:\n        return x\n\n\n# ==================\n#     DATA UTILS\n# ==================\n\n\ndef shuffle(*arrs):\n    """""" shuffle.\n\n    Shuffle given arrays at unison, along first axis.\n\n    Arguments:\n        *arrs: Each array to shuffle at unison.\n\n    Returns:\n        Tuple of shuffled arrays.\n\n    """"""\n    arrs = list(arrs)\n    for i, arr in enumerate(arrs):\n        assert len(arrs[0]) == len(arrs[i])\n        arrs[i] = np.array(arr)\n    p = np.random.permutation(len(arrs[0]))\n    return tuple(arr[p] for arr in arrs)\n\n\ndef samplewise_zero_center(X):\n    """""" samplewise_zero_center.\n\n    Zero center each sample by subtracting it by its mean.\n\n    Arguments:\n        X: `array`. The batch of samples to center.\n\n    Returns:\n        A numpy array with same shape as input.\n\n    """"""\n    for i in range(len(X)):\n        X[i] -= np.mean(X[i], axis=1, keepdims=True)\n    return X\n\n\ndef samplewise_std_normalization(X):\n    """""" samplewise_std_normalization.\n\n    Scale each sample with its standard deviation.\n\n    Arguments:\n        X: `array`. The batch of samples to scale.\n\n    Returns:\n        A numpy array with same shape as input.\n\n    """"""\n    for i in range(len(X)):\n        X[i] /= (np.std(X[i], axis=1, keepdims=True) + _EPSILON)\n    return X\n\n\ndef featurewise_zero_center(X, mean=None):\n    """""" featurewise_zero_center.\n\n    Zero center every sample with specified mean. If not specified, the mean\n    is evaluated over all samples.\n\n    Arguments:\n        X: `array`. The batch of samples to center.\n        mean: `float`. The mean to use for zero centering. If not specified, it\n            will be evaluated on provided data.\n\n    Returns:\n        A numpy array with same shape as input. Or a tuple (array, mean) if no\n        mean value was specified.\n\n    """"""\n    if mean is None:\n        mean = np.mean(X, axis=0)\n        return X - mean, mean\n    else:\n        return X - mean\n\n\ndef featurewise_std_normalization(X, std=None):\n    """""" featurewise_std_normalization.\n\n    Scale each sample by the specified standard deviation. If no std\n    specified, std is evaluated over all samples data.\n\n    Arguments:\n        X: `array`. The batch of samples to scale.\n        std: `float`. The std to use for scaling data. If not specified, it\n            will be evaluated over the provided data.\n\n    Returns:\n        A numpy array with same shape as input. Or a tuple (array, std) if no\n        std value was specified.\n\n    """"""\n    if std is None:\n        std = np.std(X, axis=0)\n        return X / std, std\n    else:\n        return X / std\n\n\ndef directory_to_samples(directory, flags=None, filter_channel=False):\n    """""" Read a directory, and list all subdirectories files as class sample """"""\n    samples = []\n    targets = []\n    label = 0\n    try: # Python 2\n        classes = sorted(os.walk(directory).next()[1])\n    except Exception: # Python 3\n        classes = sorted(os.walk(directory).__next__()[1])\n    for c in classes:\n        c_dir = os.path.join(directory, c)\n        try: # Python 2\n            walk = os.walk(c_dir).next()\n        except Exception: # Python 3\n            walk = os.walk(c_dir).__next__()\n        for sample in walk[2]:\n            if not flags or any(flag in sample for flag in flags):\n                if filter_channel:\n                    if get_img_channel(os.path.join(c_dir, sample)) != 3:\n                        continue\n                samples.append(os.path.join(c_dir, sample))\n                targets.append(label)\n        label += 1\n    return samples, targets\n\n\n# ==================\n#    OTHERS\n# ==================\n\ndef load_csv(filepath, target_column=-1, columns_to_ignore=None,\n             has_header=True, categorical_labels=False, n_classes=None):\n    """""" load_csv.\n\n    Load data from a CSV file. By default the labels are considered to be the\n    last column, but it can be changed by filling \'target_column\' parameter.\n\n    Arguments:\n        filepath: `str`. The csv file path.\n        target_column: The id of the column representing the labels.\n            Default: -1 (The last column).\n        columns_to_ignore: `list of int`. A list of columns index to ignore.\n        has_header: `bool`. Whether the csv file has a header or not.\n        categorical_labels: `bool`. If True, labels are returned as binary\n            vectors (to be used with \'categorical_crossentropy\').\n        n_classes: `int`. Total number of class (needed if\n            categorical_labels is True).\n\n    Returns:\n        A tuple (data, target).\n\n    """"""\n\n    from tensorflow.python.platform import gfile\n    with gfile.Open(filepath) as csv_file:\n        data_file = csv.reader(csv_file)\n        if not columns_to_ignore:\n            columns_to_ignore = []\n        if has_header:\n            header = next(data_file)\n        data, target = [], []\n        # Fix column to ignore ids after removing target_column\n        for i, c in enumerate(columns_to_ignore):\n            if c > target_column:\n                columns_to_ignore[i] -= 1\n        for i, d in enumerate(data_file):\n            target.append(d.pop(target_column))\n            data.append([_d for j, _d in enumerate(d) if j not in columns_to_ignore])\n        if categorical_labels:\n            assert isinstance(n_classes, int), ""n_classes not specified!""\n            target = to_categorical(target, n_classes)\n        return data, target\n\n\nclass Preloader(object):\n    def __init__(self, array, function):\n        self.array = array\n        self.function = function\n\n    def __getitem__(self, id):\n        if type(id) in [list, np.ndarray]:\n            return [self.function(self.array[i]) for i in id]\n        elif isinstance(id, slice):\n            return [self.function(arr) for arr in self.array[id]]\n        else:\n            return self.function(self.array[id])\n\n    def __len__(self):\n        return len(self.array)\n\n\nclass ImagePreloader(Preloader):\n    def __init__(self, array, image_shape, normalize=True, grayscale=False):\n        fn = lambda x: self.preload(x, image_shape, normalize, grayscale)\n        super(ImagePreloader, self).__init__(array, fn)\n\n    def preload(self, path, image_shape, normalize=True, grayscale=False):\n        img = load_image(path)\n        width, height = img.size\n        if width != image_shape[0] or height != image_shape[1]:\n            img = resize_image(img, image_shape[0], image_shape[1])\n        if grayscale:\n            img = convert_color(img, \'L\')\n        img = pil_to_nparray(img)\n        if grayscale:\n            img = np.reshape(img, img.shape + (1,))\n        if normalize:\n            img /= 255.\n        return img\n\n\nclass LabelPreloader(Preloader):\n    def __init__(self, array, n_class=None, categorical_label=True):\n        fn = lambda x: self.preload(x, n_class, categorical_label)\n        super(LabelPreloader, self).__init__(array, fn)\n\n    def preload(self, label, n_class, categorical_label):\n        if categorical_label:\n            #TODO: inspect assert bug\n            #assert isinstance(n_class, int)\n            return to_categorical([label], n_class)[0]\n        else:\n            return label\n\n\ndef is_array(X):\n    return type(X) in [np.array, np.ndarray, list]\n\n\ndef get_num_features(X):\n    if isinstance(X, tf.Tensor):\n        return X.get_shape().as_list()[-1]\n    elif is_array(X):\n        return list(np.shape(X))[-1]\n    else:\n        raise ValueError(""Unknown data type."")\n\n\ndef get_num_classes(Y):\n    if is_array(Y):\n        # Assume max integer is number of classes\n        return np.max(Y) + 1\n    elif isinstance(Y, tf.Tensor):\n        return ValueError(""Cannot automatically retrieve number of classes ""\n                          ""from a Tensor. Please fill \'num_classes\' argument."")\n    else:\n        raise ValueError(""Unknown data type."")\n\n\ndef get_num_sample(X):\n    if is_array(X):\n        return np.shape(X)[0]\n    elif isinstance(X, tf.Tensor):\n        return X.get_shape()[0]\n    else:\n        raise ValueError(""Unknown data type."")\n\n\n# ==================\n#   STATS UTILS\n# ==================\n\ndef get_max(X):\n    return np.max(X)\n\n\ndef get_mean(X):\n    return np.mean(X)\n\n\ndef get_std(X):\n    return np.std(X)\n'"
tflearn/distances.py,2,"b'"""""" Distance Ops """"""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    if hasattr(identifier, \'__call__\'):\n        return identifier\n    else:\n        return get_from_module(identifier, globals(), \'distances\')\n\n\ndef euclidean(a, b):\n    return tf.sqrt(tf.reduce_sum(tf.square(a - b),\n                                 reduction_indices=0))\n\n\ndef cosine(a, b):\n    return 1 - tf.matmul(a, b)\n'"
tflearn/initializations.py,17,"b'from __future__ import division, print_function, absolute_import\n\nimport math\nimport tensorflow as tf\n\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    if hasattr(identifier, \'__call__\'):\n        return identifier\n    else:\n        return get_from_module(identifier, globals(), \'initializations\')\n\n\ndef zeros(shape=None, dtype=tf.float32, seed=None):\n    """""" Zeros.\n\n    Initialize a tensor with all elements set to zero.\n\n    Arguments:\n        shape: List of `int`. A shape to initialize a Tensor (optional).\n        dtype: The tensor data type.\n\n    Returns:\n        The Initializer, or an initialized `Tensor` if a shape is specified.\n\n    """"""\n    if shape:\n        return tf.zeros(shape, dtype=dtype)\n    else:\n        return tf.constant_initializer(0.)\n\n\ndef uniform(shape=None, minval=0, maxval=None, dtype=tf.float32, seed=None):\n    """""" Uniform.\n\n    Initialization with random values from a uniform distribution.\n\n    The generated values follow a uniform distribution in the range\n    `[minval, maxval)`. The lower bound `minval` is included in the range,\n    while the upper bound `maxval` is excluded.\n\n    For floats, the default range is `[0, 1)`.  For ints, at least `maxval`\n    must be specified explicitly.\n\n    In the integer case, the random integers are slightly biased unless\n    `maxval - minval` is an exact power of two.  The bias is small for values of\n    `maxval - minval` significantly smaller than the range of the output (either\n    `2**32` or `2**64`).\n\n    Arguments:\n        shape: List of `int`. A shape to initialize a Tensor (optional).\n        dtype: The tensor data type. Only float are supported.\n        seed: `int`. Used to create a random seed for the distribution.\n\n    Returns:\n        The Initializer, or an initialized `Tensor` if shape is specified.\n\n    """"""\n    if shape:\n        return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                                 seed=seed, dtype=dtype)\n    else:\n        return tf.random_uniform_initializer(minval=minval, maxval=maxval,\n                                             seed=seed, dtype=dtype)\n\n\ndef uniform_scaling(shape=None, factor=1.0, dtype=tf.float32, seed=None):\n    """""" Uniform Scaling.\n\n    Initialization with random values from uniform distribution without scaling\n    variance.\n\n    When initializing a deep network, it is in principle advantageous to keep\n    the scale of the input variance constant, so it does not explode or diminish\n    by reaching the final layer. If the input is `x` and the operation `x * W`,\n    and we want to initialize `W` uniformly at random, we need to pick `W` from\n\n      [-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]\n\n    to keep the scale intact, where `dim = W.shape[0]` (the size of the input).\n    A similar calculation for convolutional networks gives an analogous result\n    with `dim` equal to the product of the first 3 dimensions.  When\n    nonlinearities are present, we need to multiply this by a constant `factor`.\n    See [Sussillo et al., 2014](https://arxiv.org/abs/1412.6558)\n    ([pdf](http://arxiv.org/pdf/1412.6558.pdf)) for deeper motivation, experiments\n    and the calculation of constants. In section 2.3 there, the constants were\n    numerically computed: for a linear layer it\'s 1.0, relu: ~1.43, tanh: ~1.15.\n\n    Arguments:\n        shape: List of `int`. A shape to initialize a Tensor (optional).\n        factor: `float`. A multiplicative factor by which the values will be\n            scaled.\n        dtype: The tensor data type. Only float are supported.\n        seed: `int`. Used to create a random seed for the distribution.\n\n    Returns:\n        The Initializer, or an initialized `Tensor` if shape is specified.\n\n    """"""\n    if shape:\n        input_size = 1.0\n        for dim in shape[:-1]:\n          input_size *= float(dim)\n        max_val = math.sqrt(3 / input_size) * factor\n        return tf.random_ops.random_uniform(shape, -max_val, max_val,\n                                            dtype, seed=seed)\n    else:\n        return tf.uniform_unit_scaling_initializer(seed=seed, dtype=dtype)\n\n\ndef normal(shape=None, mean=0.0, stddev=0.02, dtype=tf.float32, seed=None):\n    """""" Normal.\n\n    Initialization with random values from a normal distribution.\n\n    Arguments:\n        shape: List of `int`. A shape to initialize a Tensor (optional).\n        mean: Same as `dtype`. The mean of the truncated normal distribution.\n        stddev: Same as `dtype`. The standard deviation of the truncated\n            normal distribution.\n        dtype: The tensor data type.\n        seed: `int`. Used to create a random seed for the distribution.\n\n    Returns:\n        The Initializer, or an initialized `Tensor` if shape is specified.\n\n    """"""\n    if shape:\n        return tf.random_normal(shape, mean=mean, stddev=stddev, seed=seed,\n                                dtype=dtype)\n    else:\n        return tf.random_normal_initializer(mean=mean, stddev=stddev,\n                                            seed=seed, dtype=dtype)\n\n\ndef truncated_normal(shape=None, mean=0.0, stddev=0.02, dtype=tf.float32,\n                     seed=None):\n    """""" Truncated Normal.\n\n    Initialization with random values from a normal truncated distribution.\n\n    The generated values follow a normal distribution with specified mean and\n    standard deviation, except that values whose magnitude is more than 2 standard\n    deviations from the mean are dropped and re-picked.\n\n    Arguments:\n        shape: List of `int`. A shape to initialize a Tensor (optional).\n        mean: Same as `dtype`. The mean of the truncated normal distribution.\n        stddev: Same as `dtype`. The standard deviation of the truncated\n            normal distribution.\n        dtype: The tensor data type.\n        seed: `int`. Used to create a random seed for the distribution.\n\n    Returns:\n        The Initializer, or an initialized `Tensor` if shape is specified.\n\n    """"""\n    if shape:\n        return tf.truncated_normal(shape=shape, mean=mean, stddev=stddev,\n                                   seed=seed, dtype=dtype)\n    else:\n        return tf.truncated_normal_initializer(mean=mean, stddev=stddev,\n                                               seed=seed, dtype=dtype)\n\n\ndef xavier(uniform=True, seed=None, dtype=tf.float32):\n    """""" Xavier.\n\n    Returns an initializer performing ""Xavier"" initialization for weights.\n\n    This initializer is designed to keep the scale of the gradients roughly the\n    same in all layers. In uniform distribution this ends up being the range:\n    `x = sqrt(6. / (in + out)); [-x, x]` and for normal distribution a standard\n    deviation of `sqrt(3. / (in + out))` is used.\n\n    Arguments:\n        uniform: Whether to use uniform or normal distributed random\n            initialization.\n        seed: A Python integer. Used to create random seeds. See\n            `set_random_seed` for behavior.\n        dtype: The data type. Only floating point types are supported.\n\n    Returns:\n        An initializer for a weight matrix.\n\n    References:\n        Understanding the difficulty of training deep feedforward neural\n        networks. International conference on artificial intelligence and\n        statistics. Xavier Glorot and Yoshua Bengio (2010).\n\n    Links:\n        [http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf]\n        (http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n    """"""\n    try:\n        from tensorflow.contrib.layers.python.layers.initializers import \\\n            xavier_initializer\n    except ImportError:\n        raise NotImplementedError(""\'xavier_initializer\' not supported, ""\n                                  ""please update TensorFlow."")\n    return xavier_initializer(uniform=uniform, seed=seed, dtype=dtype)\n\n\ndef variance_scaling(factor=2.0, mode=\'FAN_IN\', uniform=False, seed=None,\n                     dtype=tf.float32):\n    """""" Variance Scaling.\n\n    Returns an initializer that generates tensors without scaling variance.\n\n    When initializing a deep network, it is in principle advantageous to keep\n    the scale of the input variance constant, so it does not explode or diminish\n    by reaching the final layer. This initializer use the following formula:\n\n    ```\n    if mode=\'FAN_IN\': # Count only number of input connections.\n      n = fan_in\n    elif mode=\'FAN_OUT\': # Count only number of output connections.\n      n = fan_out\n    elif mode=\'FAN_AVG\': # Average number of inputs and output connections.\n      n = (fan_in + fan_out)/2.0\n\n      truncated_normal(shape, 0.0, stddev=sqrt(factor / n))\n    ```\n\n    To get http://arxiv.org/pdf/1502.01852v1.pdf use (Default):\n    - factor=2.0 mode=\'FAN_IN\' uniform=False\n\n    To get http://arxiv.org/abs/1408.5093 use:\n    - factor=1.0 mode=\'FAN_IN\' uniform=True\n\n    To get http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf use:\n    - factor=1.0 mode=\'FAN_AVG\' uniform=True.\n\n    To get xavier_initializer use either:\n    - factor=1.0 mode=\'FAN_AVG\' uniform=True.\n    - factor=1.0 mode=\'FAN_AVG\' uniform=False.\n\n    Arguments:\n        factor: Float.  A multiplicative factor.\n        mode: String.  \'FAN_IN\', \'FAN_OUT\', \'FAN_AVG\'.\n        uniform: Whether to use uniform or normal distributed random\n            initialization.\n        seed: A Python integer. Used to create random seeds. See\n            `set_random_seed` for behavior.\n        dtype: The data type. Only floating point types are supported.\n\n    Returns:\n        An initializer that generates tensors with unit variance.\n\n    Raises:\n        ValueError: if `dtype` is not a floating point type.\n        TypeError: if `mode` is not in [\'FAN_IN\', \'FAN_OUT\', \'FAN_AVG\'].\n    """"""\n    try:\n        from tensorflow.contrib.layers.python.layers.initializers import \\\n            variance_scaling_initializer\n    except ImportError:\n        raise NotImplementedError(""\'variance_scaling_initializer\' not ""\n                                  ""supported, please update TensorFlow."")\n    return variance_scaling_initializer(factor=factor, mode=mode,\n                                        uniform=uniform, seed=seed,\n                                        dtype=dtype)\n'"
tflearn/metrics.py,28,"b'from __future__ import division, print_function, absolute_import\n\nfrom .utils import get_from_module\nimport tensorflow as tf\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), \'metrics\')\n\n""""""\nMetric classes are meant to be used with TFLearn models (such as DNN). For\ndirect operations to be used with Tensorflow, see below (accuracy_op, ...).\n""""""\n\n# --------------\n# Metric classes\n# --------------\n\n\nclass Metric(object):\n    """""" Base Metric Class.\n\n    Metric class is meant to be used by TFLearn models class. It can be\n    first initialized with desired parameters, and a model class will\n    build it later using the given network output and targets.\n\n    Attributes:\n        tensor: `Tensor`. The metric tensor.\n\n    """"""\n    def __init__(self, name=None):\n        self.name = name\n        self.tensor = None\n        self.built = False\n\n    def build(self, predictions, targets, inputs):\n        """""" build.\n\n        Build metric method, with common arguments to all Metrics.\n\n        Arguments:\n            prediction: `Tensor`. The network to perform prediction.\n            targets: `Tensor`. The targets (labels).\n            inputs: `Tensor`. The input data.\n\n        """"""\n        raise NotImplementedError\n\n    def get_tensor(self):\n        """""" get_tensor.\n\n        Get the metric tensor.\n\n        Returns:\n            The metric `Tensor`.\n\n        """"""\n        if not self.built:\n            raise Exception(""Metric class Tensor hasn\'t be built. \'build\' ""\n                            ""method must be invoked before using \'get_tensor\'."")\n        return self.tensor\n\n\nclass Accuracy(Metric):\n    """""" Accuracy.\n\n    Computes the model accuracy.  The target predictions are assumed\n    to be logits.  \n\n    If the predictions tensor is 1D (ie shape [?], or [?, 1]), then the \n    labels are assumed to be binary (cast as float32), and accuracy is\n    computed based on the average number of equal binary outcomes,\n    thresholding predictions on logits > 0.  \n\n    Otherwise, accuracy is computed based on categorical outcomes,\n    and assumes the inputs (both the model predictions and the labels)\n    are one-hot encoded.  tf.argmax is used to obtain categorical\n    predictions, for equality comparison.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        acc = Accuracy()\n        regression = regression(net, metric=acc)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    """"""\n\n    def __init__(self, name=None):\n        super(Accuracy, self).__init__(name)\n\n    def build(self, predictions, targets, inputs=None):\n        """""" Build accuracy, comparing predictions and targets. """"""\n        self.built = True\n        pshape = predictions.get_shape()\n        if len(pshape)==1 or (len(pshape)==2 and int(pshape[1])==1):\n            self.name = self.name or ""binary_acc""   # clearly indicate binary accuracy being used\n            self.tensor = binary_accuracy_op(predictions, targets)\n        else:\n            self.name = self.name or ""acc""   \t    # traditional categorical accuracy\n            self.tensor = accuracy_op(predictions, targets)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\naccuracy = Accuracy\n\nclass Top_k(Metric):\n    """""" Top-k.\n\n    Computes Top-k mean accuracy (whether the targets are in the top \'K\'\n    predictions).\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        top5 = Top_k(k=5)\n        regression = regression(net, metric=top5)\n        ```\n\n    Arguments:\n        k: `int`. Number of top elements to look at for computing precision.\n        name: The name to display.\n\n    """"""\n\n    def __init__(self, k=1, name=None):\n        super(Top_k, self).__init__(name)\n        self.name = ""top"" + str(k) if not name else name\n        self.k = k\n\n    def build(self, predictions, targets, inputs=None):\n        """""" Build top-k accuracy, comparing top-k predictions and targets. """"""\n        self.built = True\n        self.tensor = top_k_op(predictions, targets, self.k)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\ntop_k = Top_k\n\n\nclass R2(Metric):\n    """""" Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        r2 = R2()\n        regression = regression(net, metric=r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    """"""\n\n    def __init__(self, name=None):\n        super(R2, self).__init__(name)\n        self.name = ""R2"" if not name else name\n\n    def build(self, predictions, targets, inputs=None):\n        """""" Build standard error tensor. """"""\n        self.built = True\n        self.tensor = r2_op(predictions, targets)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\n\nclass WeightedR2(Metric):\n    """""" Weighted Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        weighted_r2 = WeightedR2()\n        regression = regression(net, metric=weighted_r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    """"""\n\n    def __init__(self, name=None):\n        super(WeightedR2, self).__init__(name)\n        self.name = ""R2"" if not name else name\n\n    def build(self, predictions, targets, inputs):\n        """""" Build standard error tensor. """"""\n        self.built = True\n        self.tensor = weighted_r2_op(predictions, targets, inputs)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\n\nclass Prediction_Counts(Metric):\n    """""" Prints the count of each category of prediction that is present in the predictions.\n    Can be useful to see, for example, to see if the model only gives one type of predictions,\n    or if the predictions given are in the expected proportions """"""\n\n    def __init__(self, inner_metric, name=None):\n        super(Prediction_Counts, self).__init__(name)\n        self.inner_metric = inner_metric\n\n    def build(self, predictions, targets, inputs=None):\n        """""" Prints the number of each kind of prediction """"""\n        self.built = True\n        pshape = predictions.get_shape()\n        self.inner_metric.build(predictions, targets, inputs)\n\n        with tf.name_scope(self.name):\n            if len(pshape) == 1 or (len(pshape) == 2 and int(pshape[1]) == 1):\n                self.name = self.name or ""binary_prediction_counts""\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions))\n                self.tensor = tf.Print(self.inner_metric, [y, count], name=self.inner_metric.name)\n            else:\n                self.name = self.name or ""categorical_prediction_counts""\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions, dimension=1))\n                self.tensor = tf.Print(self.inner_metric.tensor, [y, count], name=self.inner_metric.name)\n\nprediction_counts = Prediction_Counts\n\n\n# ----------\n# Metric ops\n# ----------\n\n\ndef accuracy_op(predictions, targets):\n    """""" accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictiosn are targets\n    are both one-hot encoded.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        acc_op = accuracy_op(y_pred, y_true)\n\n        # Calculate accuracy by feeding data X and labels Y\n        accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    """"""\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(""mean_accuracy \'input\' argument only accepts type ""\n                         ""Tensor, \'"" + str(type(input)) + ""\' given."")\n\n    with tf.name_scope(\'Accuracy\'):\n        correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(targets, 1))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef binary_accuracy_op(predictions, targets):\n    """""" binary_accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictions are logits, and\n    targets are binary encoded (and represented as int32).\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        acc_op = binary_accuracy_op(y_pred, y_true)\n\n        # Calculate accuracy by feeding data X and labels Y\n        binary_accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor` of `float` type.\n        targets: `Tensor` of `float` type.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    """"""\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(""mean_accuracy \'input\' argument only accepts type ""\n                         ""Tensor, \'"" + str(type(input)) + ""\' given."")\n\n    with tf.name_scope(\'BinaryAccuracy\'):\n        predictions = tf.cast(tf.greater(predictions, 0), tf.float32)\n        correct_pred = tf.equal(predictions, tf.cast(targets, tf.float32))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef top_k_op(predictions, targets, k=1):\n    """""" top_k_op.\n\n    An op that calculates top-k mean accuracy.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        top3_op = top_k_op(y_pred, y_true, 3)\n\n        # Calculate Top-3 accuracy by feeding data X and labels Y\n        top3_accuracy = sess.run(top3_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        k: `int`. Number of top elements to look at for computing precision.\n\n    Returns:\n        `Float`. The top-k mean accuracy.\n\n    """"""\n    with tf.name_scope(\'Top_\' + str(k)):\n        targets = tf.cast(targets, tf.int32)\n        correct_pred = tf.nn.in_top_k(predictions, tf.argmax(targets, 1), k)\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef r2_op(predictions, targets):\n    """""" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = r2_op(y_pred, y_true)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    """"""\n    with tf.name_scope(\'StandardError\'):\n        a = tf.reduce_sum(tf.square(tf.subtract(targets, predictions)))\n        b = tf.reduce_sum(tf.square(tf.subtract(targets, tf.reduce_mean(targets))))\n        return tf.subtract(1.0, tf.divide(a, b))\n\n\ndef weighted_r2_op(predictions, targets, inputs):\n    """""" weighted_r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = weighted_r2_op(y_pred, y_true, input_data)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        inputs: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    """"""\n    with tf.name_scope(\'WeightedStandardError\'):\n        if hasattr(inputs, \'__len__\'):\n            inputs = tf.add_n(inputs)\n        if inputs.get_shape().as_list() != targets.get_shape().as_list():\n            raise Exception(""Weighted R2 metric requires Inputs and Targets to ""\n                            ""have same shape."")\n        a = tf.reduce_sum(tf.square(predictions - inputs))\n        b = tf.reduce_sum(tf.square(targets - inputs))\n        return tf.divide(a, b)\n'"
tflearn/objectives.py,37,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nfrom .config import _EPSILON, _FLOATX\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), \'objective\')\n\n\ndef softmax_categorical_crossentropy(y_pred, y_true):\n    """""" Softmax Categorical Crossentropy.\n\n    Computes softmax cross entropy between y_pred (logits) and\n    y_true (labels).\n\n    Measures the probability error in discrete classification tasks in which\n    the classes are mutually exclusive (each entry is in exactly one class).\n    For example, each CIFAR-10 image is labeled with one and only one label:\n    an image can be a dog or a truck, but not both.\n\n    **WARNING:** This op expects unscaled logits, since it performs a `softmax`\n    on `y_pred` internally for efficiency.  Do not call this op with the\n    output of `softmax`, as it will produce incorrect results.\n\n    `y_pred` and `y_true` must have the same shape `[batch_size, num_classes]`\n    and the same dtype (either `float32` or `float64`). It is also required\n    that `y_true` (labels) are binary arrays (For example, class 2 out of a\n    total of 5 different classes, will be define as [0., 1., 0., 0., 0.])\n\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n\n    """"""\n    with tf.name_scope(""SoftmaxCrossentropy""):\n        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n            logits=y_pred, labels=y_true))\n\n\ndef categorical_crossentropy(y_pred, y_true):\n    """""" Categorical Crossentropy.\n\n    Computes cross entropy between y_pred (logits) and y_true (labels).\n\n    Measures the probability error in discrete classification tasks in which\n    the classes are mutually exclusive (each entry is in exactly one class).\n    For example, each CIFAR-10 image is labeled with one and only one label:\n    an image can be a dog or a truck, but not both.\n\n    `y_pred` and `y_true` must have the same shape `[batch_size, num_classes]`\n    and the same dtype (either `float32` or `float64`). It is also required\n    that `y_true` (labels) are binary arrays (For example, class 2 out of a\n    total of 5 different classes, will be define as [0., 1., 0., 0., 0.])\n\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n\n    """"""\n    with tf.name_scope(""Crossentropy""):\n        y_pred /= tf.reduce_sum(y_pred,\n                                reduction_indices=len(y_pred.get_shape())-1,\n                                keepdims=True)\n        # manual computation of crossentropy\n        y_pred = tf.clip_by_value(y_pred, tf.cast(_EPSILON, dtype=_FLOATX),\n                                  tf.cast(1.-_EPSILON, dtype=_FLOATX))\n        cross_entropy = - tf.reduce_sum(y_true * tf.log(y_pred),\n                               reduction_indices=len(y_pred.get_shape())-1)\n        return tf.reduce_mean(cross_entropy)\n\n\ndef binary_crossentropy(y_pred, y_true):\n    """""" Binary Crossentropy.\n\n    Computes sigmoid cross entropy between y_pred (logits) and y_true\n    (labels).\n\n    Measures the probability error in discrete classification tasks in which\n    each class is independent and not mutually exclusive. For instance,\n    one could perform multilabel classification where a picture can contain\n    both an elephant and a dog at the same time.\n\n    For brevity, let `x = logits`, `z = targets`.  The logistic loss is\n\n      x - x * z + log(1 + exp(-x))\n\n    To ensure stability and avoid overflow, the implementation uses\n\n      max(x, 0) - x * z + log(1 + exp(-abs(x)))\n\n    `y_pred` and `y_true` must have the same type and shape.\n\n    Arguments:\n        y_pred: `Tensor` of `float` type. Predicted values.\n        y_true: `Tensor` of `float` type. Targets (labels).\n\n    """"""\n    with tf.name_scope(""BinaryCrossentropy""):\n        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n            logits=y_pred, labels=y_true))\n\n\ndef weighted_crossentropy(y_pred, y_true, weight=1.):\n    """""" Weighted Crossentropy.\n\n    Computes weighted sigmoid cross entropy between y_pred (logits) and y_true\n    (labels).\n\n    Computes a weighted cross entropy.\n\n    This is like sigmoid_cross_entropy_with_logits() except that pos_weight,\n    allows one to trade off recall and precision by up- or down-weighting the\n    cost of a positive error relative to a negative error.\n\n    The usual cross-entropy cost is defined as:\n\n    `targets * -log(sigmoid(logits)) + (1 - targets) * -log(1 - sigmoid(logits))`\n\n    The argument pos_weight is used as a multiplier for the positive targets:\n\n    `targets * -log(sigmoid(logits)) * pos_weight + (1 - targets) * -log(1 - sigmoid(logits))`\n\n    For brevity, let x = logits, z = targets, q = pos_weight. The loss is:\n\n    ```\n      qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n    = qz * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n    = qz * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n    = qz * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n    = (1 - z) * x + (qz +  1 - z) * log(1 + exp(-x))\n    = (1 - z) * x + (1 + (q - 1) * z) * log(1 + exp(-x))\n    ```\n\n    Setting l = (1 + (q - 1) * z), to ensure stability and avoid overflow,\n    the implementation uses\n\n    `(1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0))`\n\n    logits and targets must have the same type and shape.\n\n    Arguments:\n        y_pred: `Tensor` of `float` type. Predicted values.\n        y_true: `Tensor` of `float` type. Targets (labels).\n        weight: A coefficient to use on the positive examples.\n\n    """"""\n    with tf.name_scope(""WeightedCrossentropy""):\n        return tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n            targets=y_true, logits=y_pred, pos_weight=weight))\n\n\ndef mean_square(y_pred, y_true):\n    """""" Mean Square Loss.\n\n    Arguments:\n        y_pred: `Tensor` of `float` type. Predicted values.\n        y_true: `Tensor` of `float` type. Targets (labels).\n\n    """"""\n    with tf.name_scope(""MeanSquare""):\n        return tf.reduce_mean(tf.square(y_pred - y_true))\n\n\ndef hinge_loss(y_pred, y_true):\n    """""" Hinge Loss.\n\n    Arguments:\n        y_pred: `Tensor` of `float` type. Predicted values.\n        y_true: `Tensor` of `float` type. Targets (labels).\n\n    """"""\n    with tf.name_scope(""HingeLoss""):\n        return tf.reduce_mean(tf.maximum(1. - y_true * y_pred, 0.))\n\n\ndef roc_auc_score(y_pred, y_true):\n    """""" ROC AUC Score.\n\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n\n    Measures overall performance for a full range of threshold levels.\n\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n\n    """"""\n    with tf.name_scope(""RocAucScore""):\n\n        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n\n        pos = tf.expand_dims(pos, 0)\n        neg = tf.expand_dims(neg, 1)\n\n        # original paper suggests performance is robust to exact parameter choice\n        gamma = 0.2\n        p     = 3\n\n        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n\n        masked = tf.boolean_mask(difference, difference < 0.0)\n\n        return tf.reduce_sum(tf.pow(-masked, p))\n\n\ndef weak_cross_entropy_2d(y_pred, y_true, num_classes=None, epsilon=0.0001,\n                          head=None):\n    """""" Weak Crossentropy 2d.\n\n    Calculate the semantic segmentation using weak softmax cross entropy loss.\n\n    Given the prediction `y_pred` shaped as 2d image and the corresponding\n    y_true, this calculated the widely used semantic segmentation loss.\n    Using `tf.nn.softmax_cross_entropy_with_logits` is currently not supported.\n    See https://github.com/tensorflow/tensorflow/issues/2327#issuecomment-224491229\n\n    Arguments:\n        y_pred: `tensor, float` - [batch_size, width, height, num_classes].\n        y_true: `Labels tensor, int32` - [batch_size, width, height, num_classes].\n            The ground truth of your data.\n        num_classes: `int`. Number of classes.\n        epsilon: `float`. Small number to add to `y_pred`.\n        head: `numpy array` - [num_classes]. Weighting the loss of each class.\n\n    Returns:\n        Loss tensor of type float.\n    """"""\n    if num_classes is None:\n        num_classes = y_true.get_shape().as_list()[-1]\n        # This only works if shape of y_true is defined\n        assert (num_classes is not None)\n\n    with tf.name_scope(""weakCrossEntropy2d""):\n        y_pred = tf.reshape(y_pred, (-1, num_classes))\n        y_pred = y_pred + tf.constant(epsilon, dtype=y_pred.dtype)\n        y_true = tf.to_float(tf.reshape(y_true, (-1, num_classes)))\n\n        softmax = tf.nn.softmax(y_pred)\n\n        if head is not None:\n            cross_entropy = -tf.reduce_sum(tf.multiply(y_true * tf.log(softmax),\n                                                  head), reduction_indices=[1])\n        else:\n            cross_entropy = -tf.reduce_sum(y_true * tf.log(softmax),\n                                           reduction_indices=[1])\n\n        cross_entropy_mean = tf.reduce_mean(cross_entropy,\n                                            name=""xentropy_mean"")\n\n    return cross_entropy_mean\n\ndef contrastive_loss(y_pred, y_true, margin = 1.0):\n    """""" Contrastive Loss.\n    \n        Computes the constrative loss between y_pred (logits) and\n        y_true (labels).\n\n        http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf\n        Sumit Chopra, Raia Hadsell and Yann LeCun (2005).\n        Learning a Similarity Metric Discriminatively, with Application to Face Verification.\n\n        Arguments:\n            y_pred: `Tensor`. Predicted values.\n            y_true: `Tensor`. Targets (labels).\n            margin: . A self-set parameters that indicate the distance between the expected different identity features. Defaults 1.\n    """"""\n\n    with tf.name_scope(""ContrastiveLoss""):\n        dis1 = y_true * tf.square(y_pred)\n        dis2 = (1 - y_true) * tf.square(tf.maximum((margin - y_pred), 0))\n        return tf.reduce_sum(dis1 +dis2) / 2.\n'"
tflearn/optimizers.py,25,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), \'optimizer\')\n\n\nclass Optimizer(object):\n    """""" Base Optimizer class.\n\n    A basic class to create optimizers to be used with TFLearn estimators.\n    First, The Optimizer class is initialized with given parameters,\n    but no Tensor is created. In a second step, invoking `get_tensor` method\n    will actually build the Tensorflow `Optimizer` Tensor, and return it.\n\n    This way, a user can easily specifies an optimizer with non default\n    parameters and learning rate decay, while TFLearn estimators will\n    build the optimizer and a step tensor by itself.\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. The optimizer name.\n\n    Attributes:\n        tensor: `Optimizer`. The optimizer tensor.\n        has_decay: `bool`. True if optimizer has a learning rate decay.\n\n    """"""\n\n    def __init__(self, learning_rate, use_locking, name):\n        self.learning_rate = learning_rate\n        self.use_locking = use_locking\n        self.name = name\n        self.tensor = None\n        self.has_decay = False\n        self.built = False\n\n    def build(self, step_tensor=None):\n        """""" build optimizer tensor.\n\n        This method creates the optimizer with specified parameters. It must\n        be implemented for every `Optimizer`.\n\n        Arguments:\n            step_tensor: `tf.Tensor`. A variable holding the training step.\n                Only necessary when optimizer has a learning rate decay.\n\n        """"""\n        raise NotImplementedError\n\n    def get_tensor(self):\n        """""" get_tensor.\n\n        A method to retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        """"""\n        if not self.built:\n            self.build()\n        return self.tensor\n\n    def __call__(self):\n        """""" __call__\n\n        A shortcut for `get_tensor`. Retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        """"""\n        return self.get_tensor()\n\n\nclass SGD(Optimizer):\n    """""" Stochastic Gradient Descent.\n\n    SGD Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        sgd = SGD(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=sgd)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        sgd = SGD(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""GradientDescent"".\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, lr_decay=0., decay_step=100,\n                 staircase=False, use_locking=False, name=""SGD""):\n        super(SGD, self).__init__(learning_rate, use_locking, name)\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(""Learning rate decay but no step_tensor ""\n                                ""provided."")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.GradientDescentOptimizer(\n            learning_rate=self.learning_rate,\n            use_locking=self.use_locking,\n            name=self.name)\n\n# Shortcut\nsgd = SGD\n\n\nclass RMSProp(Optimizer):\n    """""" RMSprop.\n\n    Maintain a moving (discounted) average of the square of gradients.\n    Divide gradient by the root of this average.\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        rmsprop = RMSProp(learning_rate=0.1, decay=0.999)\n        regression = regression(net, optimizer=rmsprop)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999).get_tensor()\n        # or\n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999)()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        decay: `float`. Discounting factor for the history/coming gradient.\n        momentum: `float`. Momentum.\n        epsilon: `float`. Small value to avoid zero denominator.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""RMSProp"".\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, decay=0.9, momentum=0.0,\n                 epsilon=1e-10, use_locking=False, name=""RMSProp""):\n        super(RMSProp, self).__init__(learning_rate, use_locking, name)\n        self.decay = decay\n        self.momentum = momentum\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.RMSPropOptimizer(\n            learning_rate=self.learning_rate, decay=self.decay,\n            momentum=self.momentum, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nrmsprop = RMSProp\n\n\nclass Adam(Optimizer):\n    """""" Adam.\n\n    The default value of 1e-8 for epsilon might not be a good default in\n    general. For example, when training an Inception network on ImageNet a\n    current good choice is 1.0 or 0.1.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        adam = Adam(learning_rate=0.001, beta1=0.99)\n        regression = regression(net, optimizer=adam)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adam = Adam(learning_rate=0.01).get_tensor()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        beta1: `float`. The exponential decay rate for the 1st moment\n            estimates.\n        beta2: `float`. The exponential decay rate for the 2nd moment\n            estimates.\n        epsilon: `float`. A small constant for numerical stability.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""Adam"".\n\n    References:\n        Adam: A Method for Stochastic Optimization. Diederik Kingma,\n        Jimmy Ba. ICLR 2015.\n\n    Links:\n        [Paper](http://arxiv.org/pdf/1412.6980v8.pdf)\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,\n                 epsilon=1e-8, use_locking=False, name=""Adam""):\n        super(Adam, self).__init__(learning_rate, use_locking, name)\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdamOptimizer(\n            learning_rate=self.learning_rate, beta1=self.beta1,\n            beta2=self.beta2, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadam = Adam\n\n\nclass Momentum(Optimizer):\n    """""" Momentum.\n\n    Momentum Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        momentum = Momentum(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=momentum)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Momentum(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""Momentum"".\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=""Momentum""):\n        super(Momentum, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(""Learning rate decay but no step_tensor ""\n                                ""provided."")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name)\n\nmomentum = Momentum\n\n\nclass AdaGrad(Optimizer):\n    """""" AdaGrad.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        adagrad = AdaGrad(learning_rate=0.01, initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = AdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""AdaGrad"".\n\n    References:\n        Adaptive Subgradient Methods for Online Learning and Stochastic\n        Optimization. J. Duchi, E. Hazan & Y. Singer. Journal of Machine\n        Learning Research 12 (2011) 2121-2159.\n\n    Links:\n        [Paper](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=""AdaGrad""):\n        super(AdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nadagrad = AdaGrad\n\n\nclass Ftrl(Optimizer):\n    """""" Ftrl Proximal.\n\n    The Ftrl-proximal algorithm, abbreviated for Follow-the-regularized-leader,\n    is described in the paper below.\n\n    It can give a good performance vs. sparsity tradeoff.\n\n    Ftrl-proximal uses its own global base learning rate and can behave like\n    Adagrad with `learning_rate_power=-0.5`, or like gradient descent with\n    `learning_rate_power=0.0`.\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        ftrl = Ftrl(learning_rate=0.01, learning_rate_power=-0.1)\n        regression = regression(net, optimizer=ftrl)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        ftrl = Ftrl(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        learning_rate_power: `float`. Must be less or equal to zero.\n        initial_accumulator_value: `float`. The starting value for accumulators.\n            Only positive values are allowed.\n        l1_regularization_strength: `float`. Must be less or equal to zero.\n        l2_regularization_strength: `float`. Must be less or equal to zero.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""Ftrl"".\n\n    Links:\n        [Ad Click Prediction: a View from the Trenches](https://www.eecs.tufts.\n        edu/~dsculley/papers/ad-click-prediction.pdf)\n\n    """"""\n\n    def __init__(self, learning_rate=3.0, learning_rate_power=-0.5,\n                 initial_accumulator_value=0.1, l1_regularization_strength=0.0,\n                 l2_regularization_strength=0.0, use_locking=False,\n                 name=""Ftrl""):\n        super(Ftrl, self).__init__(learning_rate, use_locking, name)\n        self.learning_rate_power = learning_rate_power\n        self.initial_accumulator_value = initial_accumulator_value\n        self.l1_regularization_strength = l1_regularization_strength\n        self.l2_regularization_strength = l2_regularization_strength\n\n    def build(self, step_tensor=None):\n        self.built = True\n        with tf.device(\'/cpu:0\'):\n            self.tensor = tf.train.FtrlOptimizer(\n                self.learning_rate,\n                learning_rate_power=self.learning_rate_power,\n                initial_accumulator_value=self.initial_accumulator_value,\n                l1_regularization_strength=self.l1_regularization_strength,\n                l2_regularization_strength=self.l2_regularization_strength,\n                use_locking=self.use_locking, name=self.name)\n\nftrl = Ftrl\n\n\nclass AdaDelta(Optimizer):\n    """""" AdaDelta.\n\n    Construct a new Adadelta optimizer.\n\n    Arguments:\n        learning_rate: A `Tensor` or a floating point value. The learning rate.\n        rho: A `Tensor` or a floating point value. The decay rate.\n        epsilon: A `Tensor` or a floating point value.  A constant epsilon used\n            to better conditioning the grad update.\n        use_locking: If `True` use locks for update operations.\n        name: Optional name prefix for the operations created when applying\n            gradients.  Defaults to ""Adadelta"".\n\n    References:\n        ADADELTA: An Adaptive Learning Rate Method, Matthew D. Zeiler, 2012.\n\n    Links:\n        [http://arxiv.org/abs/1212.5701](http://arxiv.org/abs/1212.5701)\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, rho=0.1, epsilon=1e-08,\n                 use_locking=False, name=""AdaDelta""):\n        super(AdaDelta, self).__init__(learning_rate, use_locking, name)\n        self.rho = rho\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdadeltaOptimizer(\n            self.learning_rate,\n            rho=self.rho, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadadelta = AdaDelta\n\n\nclass ProximalAdaGrad(Optimizer):\n    """""" ProximalAdaGrad.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        proxi_adagrad = ProximalAdaGrad(learning_rate=0.01,\n                                        l2_regularization_strength=0.01,\n                                        initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=proxi_adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = ProximalAdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""AdaGrad"".\n\n    References:\n        Efficient Learning using Forward-Backward Splitting. J. Duchi, Yoram\n        Singer, 2009.\n\n    Links:\n        [Paper](http://papers.nips.cc/paper/3793-efficient-learning-using-forward-backward-splitting.pdf)\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=""AdaGrad""):\n        super(ProximalAdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nproximaladagrad = ProximalAdaGrad\n\n\nclass Nesterov(Optimizer):\n    """""" Nesterov.\n\n    The main difference between classical momentum and nesterov is:\n    In classical momentum you first correct your velocity and \n    then make a big step according to that velocity (and then repeat), \n    but in Nesterov momentum you first making a step into velocity \n    direction and then make a correction to a velocity vector based on\n    new location (then repeat).\n    See [Sutskever et. al., 2013](\n            http://jmlr.org/proceedings/papers/v28/sutskever13.pdf)\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        nesterov = Nesterov(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=nesterov)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Neserov(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to ""Momentum"".\n\n    """"""\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=""Nesterov""):\n        super(Nesterov, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(""Learning rate decay but no step_tensor ""\n                                ""provided."")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name,use_nesterov=True)\n\nnesterov = Nesterov\n'"
tflearn/regularizers.py,2,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    if hasattr(identifier, \'__call__\'):\n        return identifier\n    else:\n        return get_from_module(identifier, globals(), \'regularizer\')\n\n\ndef L2(tensor, wd=0.001):\n    """""" L2.\n\n    Computes half the L2 norm of a tensor without the `sqrt`:\n\n      output = sum(t ** 2) / 2 * wd\n\n    Arguments:\n        tensor: `Tensor`. The tensor to apply regularization.\n        wd: `float`. The decay.\n\n    Returns:\n        The regularization `Tensor`.\n\n    """"""\n    return tf.multiply(tf.nn.l2_loss(tensor), wd, name=\'L2-Loss\')\n\n\ndef L1(tensor, wd=0.001):\n    """""" L1.\n\n    Computes the L1 norm of a tensor:\n\n      output = sum(|t|) * wd\n\n    Arguments:\n        tensor: `Tensor`. The tensor to apply regularization.\n        wd: `float`. The decay.\n\n    Returns:\n        The regularization `Tensor`.\n\n    """"""\n    return tf.multiply(tf.reduce_sum(tf.abs(tensor)), wd, name=\'L1-Loss\')\n'"
tflearn/summaries.py,14,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom tensorflow.core.framework import summary_pb2\n\nfrom .utils import format_scope_name\n\n\ndef monitor_activation(tensor):\n    tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, tensor)\n\n\ndef get_summary(stype, tag, value=None, collection_key=None,\n                break_if_exists=False):\n    """""" get_summary.\n\n    Create or retrieve a summary. It keep tracks of all graph summaries\n    through summary_tags collection. If a summary tags already exists,\n    it will return that summary tensor or raise an error (according to\n    \'break_if_exists\').\n\n    Arguments:\n        stype: `str`. Summary type: \'histogram\', \'scalar\' or \'image\'.\n        tag: `str`. The summary tag (name).\n        value: `Tensor`. The summary initialization value. Default: None.\n        collection_key: `str`. If specified, the created summary will be\n            added to that collection (optional).\n        break_if_exists: `bool`. If True, if a summary with same tag already\n            exists, it will raise an exception (instead of returning that\n            existing summary).\n\n    Returns:\n        The summary `Tensor`.\n\n    """"""\n    summ = next((item for item in tf.get_collection(""summary_tags"") if\n                 item[""tag""] == tag), None)\n\n    if not summ:\n        if value is None:\n            raise Exception(""Summary doesn\'t exist, a value must be ""\n                            ""specified to initialize it."")\n        if stype == ""histogram"":\n            summ = tf.summary.histogram(tag, value)\n        elif stype == ""scalar"":\n            summ = tf.summary.scalar(tag, value)\n        elif stype == ""image"":\n            pass  # TODO: create summary\n        else:\n            raise ValueError(""Unknow summary type: \'"" + str(stype) + ""\'"")\n        tf.add_to_collection(""summary_tags"", {""tag"": tag, ""tensor"": summ})\n        if collection_key:\n            tf.add_to_collection(collection_key, summ)\n    elif break_if_exists:\n        raise ValueError(""Error: Summary tag already exists! (to ignore this ""\n                         ""error, set add_summary() parameter \'break_if_exists\'""\n                         "" to False)"")\n    else:\n        summ = summ[""tensor""]\n\n    return summ\n\n\ndef add_activations_summary(activation_ops, name_prefix="""", name_suffix="""",\n                            collection_key=None):\n    """""" add_activations_summary.\n\n    Add histogram summary for given activations.\n\n    Arguments:\n        activation_ops: A list of `Tensor`. The activations to summarize.\n        name_prefix: `str`. A prefix to add to summary scope.\n        name_suffix: `str`. A suffix to add to summary scope.\n        collection_key: `str`. A collection to store the summaries.\n\n    Returns:\n        The list of created activation summaries.\n    """"""\n\n    summ = []\n    for ao in activation_ops:\n        ao_name = ao.op.name\n        summ_name = format_scope_name(ao_name, name_prefix,\n                                      ""Activations/"" + name_suffix)\n        summ_exists = summary_exists(summ_name)\n        if summ_exists is not None:\n            tf.add_to_collection(collection_key, summ_exists)\n        else:\n            get_summary(""histogram"", summ_name, ao, collection_key)\n\n        summ_name = format_scope_name(ao_name, name_prefix,\n                                      ""Sparsity/"" + name_suffix)\n        summ_exists = summary_exists(summ_name)\n        if summ_exists is not None:\n            tf.add_to_collection(collection_key, summ_exists)\n            summ.append(summ_exists)\n        else:\n            summ.append(get_summary(""scalar"", summ_name,\n                                    tf.nn.zero_fraction(ao), collection_key))\n    return summ\n\n\ndef add_gradients_summary(grads, name_prefix="""", name_suffix="""",\n                          collection_key=None):\n    """""" add_gradients_summary.\n\n    Add histogram summary for given gradients.\n\n    Arguments:\n        grads: A list of `Tensor`. The gradients to summarize.\n        name_prefix: `str`. A prefix to add to summary scope.\n        name_suffix: `str`. A suffix to add to summary scope.\n        collection_key: `str`. A collection to store the summaries.\n\n    Returns:\n        The list of created gradient summaries.\n\n    """"""\n\n    # Add histograms for gradients.\n    summ = []\n    for grad, var in grads:\n        if grad is not None:\n            summ_name = format_scope_name(var.op.name, name_prefix,\n                                          ""Gradients/"" + name_suffix)\n            summ_exists = summary_exists(summ_name)\n            if summ_exists is not None:\n                tf.add_to_collection(collection_key, summ_exists)\n                summ.append(summ_exists)\n            else:\n                summ.append(get_summary(""histogram"", summ_name, grad,\n                                        collection_key))\n    return summ\n\n\ndef add_trainable_vars_summary(variables, name_prefix="""", name_suffix="""",\n                               collection_key=None):\n    """""" add_trainable_vars_summary.\n\n    Add histogram summary for given variables weights.\n\n    Arguments:\n        variables: A list of `Variable`. The variables to summarize.\n        name_prefix: `str`. A prefix to add to summary scope.\n        name_suffix: `str`. A suffix to add to summary scope.\n        collection_key: `str`. A collection to store the summaries.\n\n    Returns:\n        The list of created weights summaries.\n\n    """"""\n\n    # Add histograms for trainable variables.\n    summ = []\n    for var in variables:\n        summ_name = format_scope_name(var.op.name, name_prefix, name_suffix)\n        summ_exists = summary_exists(summ_name)\n        if summ_exists is not None:\n            tf.add_to_collection(collection_key, summ_exists)\n            summ.append(summ_exists)\n        else:\n            summ.append(get_summary(""histogram"", summ_name, var, collection_key))\n    return summ\n\n\ndef get_value_from_summary_string(tag, summary_str):\n    """""" get_value_from_summary_string.\n\n    Retrieve a summary value from a summary string.\n\n    Arguments:\n        tag: `str`. The summary tag (name).\n        summary_str: `str`. The summary string to look in.\n\n    Returns:\n        A `float`. The retrieved value.\n\n    Raises:\n        `Exception` if tag not found.\n\n    """"""\n\n    # Compatibility hotfix for the seq2seq example\n    if tag == u\'acc:0/\':\n        tag = u\'acc_0/\'\n\n    # Fix for TF 0.12\n    if tag[-1] == \'/\':\n        tag = tag[:-1]\n    summ = summary_pb2.Summary()\n    summ.ParseFromString(summary_str)\n\n    for row in summ.value:\n        if row.tag.endswith(tag):\n            return float(row.simple_value)\n\n    raise ValueError(""Tag: "" + tag + "" cannot be found in summaries list."")\n\n\ndef add_loss_summaries(total_loss, loss, regul_losses_collection_key,\n                       name_prefix="""", summaries_collection_key=None,\n                       exp_moving_avg=0.9, ema_num_updates=None):\n    """""" add_loss_summaries.\n\n    Add scalar summaries (raw and averages) for given losses.\n\n    Generates moving average for all losses and associated summaries for\n    visualizing the performance of the network.\n\n    Arguments:\n        total_loss: `Tensor`. The total loss (Regression loss +\n            regularization losses).\n        loss: `Tensor`. Regression loss.\n        name_prefix: `str`. A prefix to add to the summary name.\n        regul_losses_collection_key: `str`. A collection name to retrieve\n            regularization losses.\n        exp_moving_avg: `float`. Exponential moving average.\n        ema_num_updates: `int`. Step to be used with exp moving avg.\n\n    Returns:\n        loss_averages_op: op for generating moving averages of losses.\n    """"""\n    # Compute the moving average of all individual losses and the total loss.\n    loss_averages = tf.train.ExponentialMovingAverage(exp_moving_avg,\n                                                      ema_num_updates,\n                                                      name=\'moving_avg\')\n    other_losses = tf.get_collection(regul_losses_collection_key)\n\n    # Attach a scalar summmary to all individual losses and the total loss;\n    # do the same for the averaged version of the losses.\n    # Name each loss as \'(raw)\' and name the moving average version of the loss\n    # as the original loss name.\n\n    # Only add total loss, if it has more than one loss...\n    if len(other_losses) > 0 and total_loss is not None:\n        loss_averages_op = loss_averages.apply(\n            [total_loss] + [loss] + other_losses)\n        summ_name = ""Loss_var_loss/"" + name_prefix\n        get_summary(""scalar"", summ_name, loss_averages.average(total_loss),\n                    summaries_collection_key)\n        get_summary(""scalar"", summ_name + \'raw\', total_loss,\n                    summaries_collection_key)\n    elif total_loss is not None:\n        loss_averages_op = loss_averages.apply([loss] + other_losses)\n    else:\n        loss_averages_op = loss_averages.apply([loss])\n\n    # For tflearn wrapper visibility\n    summ_name = ""Loss/"" + name_prefix\n    get_summary(""scalar"", summ_name, loss_averages.average(loss),\n                summaries_collection_key)\n    get_summary(""scalar"", summ_name + \'raw\', loss, summaries_collection_key)\n\n    for wdl in other_losses:\n        # No prefix, we store every variable into their own scope\n        summ_name = wdl.op.name\n        get_summary(""scalar"", summ_name, loss_averages.average(wdl),\n                    summaries_collection_key)\n        get_summary(""scalar"", summ_name + \'raw\', wdl,\n                    summaries_collection_key)\n\n    return loss_averages_op\n\n\ndef summary_exists(tag):\n    """""" summary_exists.\n\n    Check if a summary exists.\n\n    Arguments:\n        tag: `str`. The summary name.\n\n    Returns:\n        A `bool`. Whether the summary exists or not.\n\n    """"""\n    return next(\n        (item[\'tensor\'] for item in tf.get_collection(""summary_tags"") if\n         item[""tag""] == tag), None)\n'"
tflearn/utils.py,27,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport six\nimport string\nimport random\ntry:\n    import h5py\n    H5PY_SUPPORTED = True\nexcept Exception as e:\n    print(""hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)"")\n    H5PY_SUPPORTED = False\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import pywrap_tensorflow\n\nimport tflearn.variables as vs\n\n\ndef get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):\n    if isinstance(identifier, six.string_types):\n        res = module_params.get(identifier)\n        if not res:\n            res = module_params.get(identifier.lower())\n            if not res:\n                raise Exception(\'Invalid \' + str(module_name) + \': \' + str(identifier))\n        if instantiate and not kwargs:\n            return res()\n        elif instantiate and kwargs:\n            return res(**kwargs)\n        else:\n            return res\n    return identifier\n\n\n# ------------------\n#  Ops utils\n# ------------------\n\ndef get_layer_by_name(name_or_scope):\n    """""" get_layer.\n\n    Retrieve the output tensor of a layer with the given name or scope.\n\n    Arguments:\n        name_or_scope: `str`. The name (or scope) given to the layer to\n            retrieve.\n\n    Returns:\n        A Tensor.\n\n    """"""\n    # Track output tensor.\n    c = tf.get_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name_or_scope)\n    if len(c) == 0:\n        raise Exception(""No layer found for this name."")\n    if len(c) > 1:\n        return c\n    return c[0]\n\n\ndef get_incoming_shape(incoming):\n    """""" Returns the incoming data shape """"""\n    if isinstance(incoming, tf.Tensor):\n        return incoming.get_shape().as_list()\n    elif type(incoming) in [np.array, np.ndarray, list, tuple]:\n        return np.shape(incoming)\n    else:\n        raise Exception(""Invalid incoming layer."")\n\n\ndef get_tensor_parents_placeholders(tensor):\n    """""" Get all placeholders that is depending the given tensor. """"""\n    placeholders_list = []\n    if tensor.op.type == \'Placeholder\':\n        placeholders_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.inputs:\n            if not \'read:0\' in t.name:\n                placeholders_list += get_tensor_parents_placeholders(t)\n    return list(set(placeholders_list))\n\n\ndef get_tensor_parents(tensor):\n    """""" Get all calculation and data parent tensors (Not read). """"""\n    parents_list = []\n    parents_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.inputs:\n            if not \'read:0\' in t.name:\n                parents_list += get_tensor_parents(t)\n    return parents_list\n\n\ndef get_all_tensor_parents(tensor):\n    """""" Get all parents tensors. """"""\n    parents_list = []\n    parents_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.inputs:\n            parents_list += get_tensor_parents(t)\n    return list(set(parents_list))\n\n\ndef get_tensor_children_placeholders(tensor):\n    """""" Get all placeholders that is depending the given tensor. """"""\n    placeholders_list = []\n    if tensor.op.type == \'Placeholder\':\n        placeholders_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.outputs:\n            if not \'read:0\' in t.name:\n                placeholders_list += get_tensor_children_placeholders(t)\n    return list(set(placeholders_list))\n\n\ndef get_tensor_children(tensor):\n    """""" Get all calculation and data parent tensors (Not read). """"""\n    children_list = []\n    children_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.outputs:\n            if not \'read:0\' in t.name:\n                children_list += get_tensor_children(t)\n    return list(set(children_list))\n\n\ndef get_all_tensor_children(tensor):\n    """""" Get all parents tensors. """"""\n    children_list = []\n    children_list.append(tensor)\n    if tensor.op:\n        for t in tensor.op.outputs:\n            children_list += get_all_tensor_children(t)\n    return list(set(children_list))\n\n\n# ---------------\n#   Tensor Utils\n# ---------------\n\ndef read_tensor_in_checkpoint(tensor_name, checkpoint_path):\n    try:\n        reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n        return reader.get_tensor(tensor_name)\n    except Exception as e:  # pylint: disable=broad-except\n        print(str(e))\n        if ""corrupted compressed block contents"" in str(e):\n            print(""It\'s likely that your checkpoint file has been compressed ""\n                  ""with SNAPPY."")\n\n\n# ------------------\n#  Other utils\n# ------------------\n\n\ndef to_list(data):\n    if data is None: return None\n    if type(data) in [tuple, list]:\n        return data\n    return [data]\n\n\ndef standarize_data(data):\n    if data is None: return None\n    if type(data) in [tuple, list]:\n        return [np.asarray(x) for x in data]\n    if type(data) is dict:\n        return data\n    return [np.asarray(data)]\n\n\ndef standarize_dict(d):\n    for key in d:\n        if isinstance(d[key], list):\n            d[key] = np.asarray(d[key])\n\n\ndef del_duplicated(l):\n    res = []\n    for e in l:\n        if e not in res:\n            res.append(e)\n    return res\n    #return list(np.unique(np.array(l)))\n\n\ndef make_batches(samples_size, batch_size):\n    nb_batch = int(np.ceil(samples_size/float(batch_size)))\n    return [(i*batch_size, min(samples_size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n\n\ndef slice_array(X, start=None, stop=None):\n    if type(X) == list:\n        if hasattr(start, \'__len__\'):\n            return [x[start] for x in X]\n        else:\n            return [x[start:stop] for x in X]\n    if H5PY_SUPPORTED:\n        if type(X) == h5py.Dataset:\n            return [X[i] for i in start]\n    if hasattr(start, \'__len__\'):\n        return X[start]\n    else:\n        return X[start:stop]\n\n\ndef get_dict_first_element(input_dict):\n    for key in input_dict:\n        return input_dict[key]\n\n\ndef get_tensor_with_parent_name(tensor):\n    """""" Get a tensor name with its parent tensor\'s name as prefix. """"""\n    tensor_name = tensor.name\n    if tensor.op.inputs[0].name is not None:\n        return tensor.op.inputs[0].name + ""_"" + tensor_name\n    return tensor_name\n\n\ndef format_scope_name(scope_name, prefix, suffix):\n    """""" Add a predix and a suffix to a scope name. """"""\n    if prefix is not """":\n        if not prefix[-1] == ""/"":\n            prefix += ""/""\n    if suffix is not """":\n        if not suffix[0] == ""/"":\n            suffix = ""/"" + suffix\n    return prefix + scope_name + suffix\n\n\ndef check_scope_path(scope_name):\n    scope_name = scope_name.replace(""//"", ""/"")\n    return scope_name\n\n\ndef feed_dict_builder(X, Y, net_inputs, net_targets):\n    """""" Format provided data to a dictionary format compatible with\n    Tensorflow data feeding. It match all X and Y data provided with\n    net_inputs and net_targets provided placeholders. In case of inputs\n    data list, matching is made respectively.\n\n    Examples:\n        ```python\n        # Building feed dictionary\n        >> feed_dict = feed_dict_builder(X, Y, input1, output1)\n        >> {input1: X, output1: Y}\n        >> feed_dict = feed_dict_builder({input1: X}, Y, input1, output1)\n        >> {input1: X, output1: Y}\n        >> feed_dict = feed_dict_builder([X1, X2], Y, [in1, in2], out1)\n        >> {in1: X1, in2: X2, output1: Y}\n        # For validation split:\n        >> val_feed_dict = feed_dict_builder(0.1, 0.1, input1, output1)\n        >> {input1: 0.1, output1: 0.1}\n        ```\n\n    Arguments:\n        X: `array` or `dict`. The input data.\n        Y: `array`, `dict` or `float`. The targets (labels).\n        net_inputs: `list`. The network data inputs `Placeholders`.\n        net_targets: `list`. The network targets `Placeholders`.\n\n    Returns:\n        `dict`. A Tensorflow-ready dictionary to feed data.\n\n    Raises:\n        Exception if X and net_inputs or Y and net_targets list length doesn\'t\n        match.\n    """"""\n\n    feed_dict = {}\n\n    if not (is_none(X) or is_none(net_inputs)):\n        # If input data are not a dict, we match them by creation order\n        if not isinstance(X, dict):\n            # If validation split, copy that value to the whole placeholders\n            if isinstance(X, float):\n                X = [X for _i in net_inputs]\n            elif len(net_inputs) > 1:\n                try:  # TODO: Fix brodcast issue if different\n                    if np.ndim(X) < 2:\n                        raise ValueError(""Multiple inputs but only one data ""\n                                         ""feeded. Please verify number of ""\n                                         ""inputs and data provided match."")\n                    elif len(X) != len(net_inputs):\n                        raise Exception(str(len(X)) + "" inputs feeded, "" +\n                                        ""but expected: "" + str(len(net_inputs)) +\n                                        "". If you are using notebooks, please ""\n                                        ""make sure that you didn\'t run graph ""\n                                        ""construction cell multiple time, ""\n                                        ""or try to enclose your graph within ""\n                                        ""`with tf.Graph().as_default():` or ""\n                                        ""use `tf.reset_default_graph()`"")\n                except Exception:\n                    pass\n            else:\n                X = [X]\n            for i, x in enumerate(X):\n                feed_dict[net_inputs[i]] = x\n        else:\n            # If a dict is provided\n            for key, val in X.items():\n                # Copy to feed_dict if dict already fits {placeholder: data} template\n                if isinstance(key, tf.Tensor):\n                    feed_dict[key] = val\n                else:  # Else retrieve placeholder with its name\n                    var = vs.get_inputs_placeholder_by_name(key)\n                    if var is None:\n                        raise Exception(""Feed dict asks for variable named \'%s\' but no ""\n                                        ""such variable is known to exist"" % key)\n                    feed_dict[var] = val\n\n    if not (is_none(Y) or is_none(net_targets)):\n        if not isinstance(Y, dict):\n            # Verify network has targets\n            if len(net_targets) == 0:\n                return feed_dict\n            # If validation split, copy that value to every target placeholder.\n            if isinstance(Y, float):\n                Y = [Y for _t in net_targets]\n            elif len(net_targets) > 1:\n                try:  # TODO: Fix brodcast issue if different\n                    if np.ndim(Y) < 2:\n                        raise ValueError(""Multiple outputs but only one data ""\n                                         ""feeded. Please verify number of outputs ""\n                                         ""and data provided match."")\n                    elif len(Y) != len(net_targets):\n                        raise Exception(str(len(Y)) + "" outputs feeded, ""\n                                                      ""but expected: "" + str(len(net_targets)))\n                except Exception:\n                    # skip verif\n                    pass\n            else:\n                Y = [Y]\n            for i, y in enumerate(Y):\n                feed_dict[net_targets[i]] = y\n        else:\n            # If a dict is provided\n            for key, val in Y.items():\n                # Copy to feed_dict if dict already fits {placeholder: data} template\n                if isinstance(key, tf.Tensor):\n                    feed_dict[key] = val\n                else:  # Else retrieve placeholder with its name\n                    var = vs.get_targets_placeholder_by_name(key)\n                    if var is None:\n                        raise Exception(""Feed dict asks for variable named \'%s\' but no ""\n                                        ""such variable is known to exist"" % key)\n                    feed_dict[var] = val\n\n    return feed_dict\n\n\ndef is_none(val):\n    # Check if a value is None or not, required because `np.array is None` is\n    # ambiguous and raise Exception.\n    if type(val) is np.array:\n        return False\n    else:\n        return val is None\n\n\ndef id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    return \'\'.join(random.choice(chars) for _ in range(size))\n\n\ndef check_dir_name(dir_path):\n    if isinstance(dir_path, str):\n        if len(dir_path) > 0:\n            if dir_path[-1] != ""/"":\n                dir_path += ""/""\n        return dir_path\n    else:\n        raise ValueError(""Incorrect string format for directory path."")\n\n\ndef check_restore_tensor(tensor_to_check, exclvars):\n    for exclvar in exclvars:\n        if isinstance(exclvar, str):\n            if exclvar.split(\':\')[0] in tensor_to_check.name:\n                return False\n        elif exclvar.name.split(\':\')[0] in tensor_to_check.name:\n                return False\n    return True\n\n# ----------------------------\n# Parameter formatting helpers\n# ----------------------------\n\n\n# Auto format kernel\ndef autoformat_kernel_2d(strides):\n    if isinstance(strides, int):\n        return [1, strides, strides, 1]\n    elif isinstance(strides, (tuple, list, tf.TensorShape)):\n        if len(strides) == 2:\n            return [1, strides[0], strides[1], 1]\n        elif len(strides) == 4:\n            return [strides[0], strides[1], strides[2], strides[3]]\n        else:\n            raise Exception(""strides length error: "" + str(len(strides))\n                            + "", only a length of 2 or 4 is supported."")\n    else:\n        raise Exception(""strides format error: "" + str(type(strides)))\n\n\n# Auto format filter size\n# Output shape: (rows, cols, input_depth, out_depth)\ndef autoformat_filter_conv2d(fsize, in_depth, out_depth):\n    if isinstance(fsize,int):\n        return [fsize, fsize, in_depth, out_depth]\n    elif isinstance(fsize, (tuple, list, tf.TensorShape)):\n        if len(fsize) == 2:\n            return [fsize[0], fsize[1], in_depth, out_depth]\n        else:\n            raise Exception(""filter length error: "" + str(len(fsize))\n                            + "", only a length of 2 is supported."")\n    else:\n        raise Exception(""filter format error: "" + str(type(fsize)))\n\n\n# Auto format padding\ndef autoformat_padding(padding):\n    if padding in [\'same\', \'SAME\', \'valid\', \'VALID\']:\n        return str.upper(padding)\n    else:\n        raise Exception(""Unknown padding! Accepted values: \'same\', \'valid\'."")\n\n\n# Auto format filter size\n# Output shape: (rows, cols, input_depth, out_depth)\ndef autoformat_filter_conv3d(fsize, in_depth, out_depth):\n    if isinstance(fsize, int):\n        return [fsize, fsize, fsize, in_depth, out_depth]\n    elif isinstance(fsize, (tuple, list, tf.TensorShape)):\n        if len(fsize) == 3:\n            return [fsize[0], fsize[1],fsize[2], in_depth, out_depth]\n        else:\n            raise Exception(""filter length error: "" + str(len(fsize))\n                            + "", only a length of 3 is supported."")\n    else:\n        raise Exception(""filter format error: "" + str(type(fsize)))\n\n\n# Auto format stride for 3d convolution\ndef autoformat_stride_3d(strides):\n    if isinstance(strides, int):\n        return [1, strides, strides, strides, 1]\n    elif isinstance(strides, (tuple, list, tf.TensorShape)):\n        if len(strides) == 3:\n            return [1, strides[0], strides[1],strides[2], 1]\n        elif len(strides) == 5:\n            assert strides[0] == strides[4] == 1, ""Must have strides[0] = strides[4] = 1""\n            return [strides[0], strides[1], strides[2], strides[3], strides[4]]\n        else:\n            raise Exception(""strides length error: "" + str(len(strides))\n                            + "", only a length of 3 or 5 is supported."")\n    else:\n        raise Exception(""strides format error: "" + str(type(strides)))\n\n\n# Auto format kernel for 3d convolution\ndef autoformat_kernel_3d(kernel):\n    if isinstance(kernel, int):\n        return [1, kernel, kernel, kernel, 1]\n    elif isinstance(kernel, (tuple, list, tf.TensorShape)):\n        if len(kernel) == 3:\n            return [1, kernel[0], kernel[1], kernel[2], 1]\n        elif len(kernel) == 5:\n            assert kernel[0] == kernel[4] == 1, ""Must have kernel_size[0] = kernel_size[4] = 1""\n            return [kernel[0], kernel[1], kernel[2], kernel[3], kernel[4]]\n        else:\n            raise Exception(""kernel length error: "" + str(len(kernel))\n                            + "", only a length of 3 or 5 is supported."")\n    else:\n        raise Exception(""kernel format error: "" + str(type(kernel)))\n\n\ndef repeat(inputs, repetitions, layer, *args, **kwargs):\n    outputs = inputs\n    for i in range(repetitions):\n        outputs = layer(outputs, *args, **kwargs)\n    return outputs\n\n\ndef fix_saver(collection_lists=None):\n    # Workaround to prevent serialization warning by removing objects\n    if collection_lists is None:\n        try:\n            # Try latest api\n            l = tf.get_collection_ref(""summary_tags"")\n            l4 = tf.get_collection_ref(tf.GraphKeys.GRAPH_CONFIG)\n        except Exception:\n            l = tf.get_collection(""summary_tags"")\n            l4 = tf.get_collection(tf.GraphKeys.GRAPH_CONFIG)\n        l_stags = list(l)\n        l4_stags = list(l4)\n        del l[:]\n        del l4[:]\n\n        try:\n            # Try latest api\n            l1 = tf.get_collection_ref(tf.GraphKeys.DATA_PREP)\n            l2 = tf.get_collection_ref(tf.GraphKeys.DATA_AUG)\n        except Exception:\n            l1 = tf.get_collection(tf.GraphKeys.DATA_PREP)\n            l2 = tf.get_collection(tf.GraphKeys.DATA_AUG)\n        l1_dtags = list(l1)\n        l2_dtags = list(l2)\n        del l1[:]\n        del l2[:]\n\n        try: # Do not save exclude variables\n            l3 = tf.get_collection_ref(tf.GraphKeys.EXCL_RESTORE_VARS)\n        except Exception:\n            l3 = tf.get_collection(tf.GraphKeys.EXCL_RESTORE_VARS)\n        l3_tags = list(l3)\n        del l3[:]\n        return [l_stags, l1_dtags, l2_dtags, l3_tags, l4_stags]\n    else:\n        # 0.7+ workaround, restore values\n        for t in collection_lists[0]:\n            tf.add_to_collection(""summary_tags"", t)\n        for t in collection_lists[4]:\n            tf.add_to_collection(tf.GraphKeys.GRAPH_CONFIG, t)\n        for t in collection_lists[1]:\n            tf.add_to_collection(tf.GraphKeys.DATA_PREP, t)\n        for t in collection_lists[2]:\n            tf.add_to_collection(tf.GraphKeys.DATA_AUG, t)\n        for t in collection_lists[3]:\n            tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS, t)\n\n\ndef validate_func(x, allow_none=True):\n    if not (allow_none and x is None) and hasattr(x, \'__call__\'):\n        raise ValueError(""\'%s\' must be a function."" % x.__name__)\n\n\ndef validate_dim(x, max_dim=None, min_dim=None, var_name=\'var\'):\n    # Calculate dimension\n    if isinstance(x, tf.Tensor):\n        dim = len(x.get_shape().as_list())\n    elif type(x) in [np.ndarray, np.array, list]:\n        dim = np.ndim(x)\n    else:\n        #TODO: check hdf5, panda\n        return\n    # Verify dimension conditions\n    if max_dim == min_dim:\n        if dim != max_dim:\n            raise ValueError(""%s must be %s-D."" % (var_name, max_dim))\n    else:\n        if min_dim and dim < min_dim:\n            raise ValueError(\n                ""%s must be at least %s-D."" % (var_name, min_dim))\n        elif max_dim and dim > max_dim:\n            raise ValueError(\n                ""%s must be %s-D or less."" % (var_name, max_dim))\n\n\ndef prepare_X(X, target_ndim, max_dim=None, min_dim=None, debug_msg=""Data""):\n\n    # Validate the dimension\n    validate_dim(X, max_dim, min_dim)\n\n    X_ndim = np.ndim(X)\n    # Reshape to the desired dimension\n    if X_ndim < target_ndim:\n        for i in range(target_ndim - X_ndim):\n            try:\n                X = np.expand_dims(X, axis=0)\n            except Exception:\n                raise Exception(debug_msg + "" shape mismatch (too few dimensions)."")\n    elif X_ndim > target_ndim:\n        for i in range(X_ndim - target_ndim):\n            try:\n                X = np.reshape(X, newshape=np.shape(X)[:-1])\n            except Exception:\n                raise Exception(debug_msg +  "" shape mismatch (too many dimensions)."")\n    return X, X_ndim\n\n'"
tflearn/variables.py,15,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport tflearn\n\nfrom tflearn.vendor.arg_scope import add_arg_scope as contrib_add_arg_scope\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import variable_scope\n\n\n@contrib_add_arg_scope\ndef variable(name, shape=None, dtype=tf.float32, initializer=None,\n             regularizer=None, trainable=True, collections=None,\n             caching_device=None, validate_shape=True, device=None,\n             restore=True):\n    """""" variable.\n\n    Instantiate a new variable.\n\n    Arguments:\n        name: `str`. A name for this variable.\n        shape: list of `int`. The variable shape (optional).\n        dtype: `type`. The variable data type.\n        initializer: `str` or `Tensor`. The variable initialization. (See\n            tflearn.initializations for references).\n        regularizer: `str` or `Tensor`. The variable regularizer. (See\n            tflearn.losses for references).\n        trainable: `bool`. If True, this variable weights will be trained.\n        collections: `str`. A collection to add the new variable to (optional).\n        caching_device: `str`. Optional device string or function describing\n            where the Variable should be cached for reading.  Defaults to the\n            Variable\'s device.\n        validate_shape: `bool`. Validate or not shape when restoring.\n        device: `str`. Optional device ID to store the variable.\n        restore: `bool`. Restore or not this variable when loading a\n            pre-trained model (Only compatible with tflearn pre-built\n            training functions).\n\n    Returns:\n        A Variable.\n\n    """"""\n\n    if isinstance(initializer, str):\n        initializer = tflearn.initializations.get(initializer)()\n    # Remove shape param if initializer is a Tensor\n    if not callable(initializer) and isinstance(initializer, tf.Tensor):\n        shape = None\n\n    if isinstance(regularizer, str):\n        regularizer = tflearn.regularizers.get(regularizer)\n\n    collections = set(collections or [])\n    collections |= set([ops.GraphKeys.GLOBAL_VARIABLES,\n                        ops.GraphKeys.MODEL_VARIABLES])\n\n    with ops.device(device or \'\'):\n        var = variable_scope.get_variable(name, shape=shape, dtype=dtype,\n                                           initializer=initializer,\n                                           regularizer=regularizer,\n                                           trainable=trainable,\n                                           collections=collections,\n                                           caching_device=caching_device,\n                                           validate_shape=validate_shape)\n\n    if not restore:\n        tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS, var)\n\n    return var\n\n\ndef get_all_variables():\n    """""" get_all_variables.\n\n    Get all Graph variables.\n\n    Returns:\n        A list of Variables.\n\n    """"""\n    try:\n        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n    except Exception:\n        return tf.get_collection(tf.GraphKeys.VARIABLES)\n\n\ndef get_all_trainable_variable():\n    """""" get_all_variables.\n\n    Get all Graph trainable variables.\n\n    Returns:\n        A list of Variables.\n\n    """"""\n    return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n\n\ndef get_layer_variables_by_name(name):\n    """""" get_layer_variables_by_name.\n\n    Retrieve a layer\'s variables, given its name.\n\n    Arguments:\n        name: `str`. The layer name.\n\n    Returns:\n        A list of Variables.\n\n    """"""\n    return tf.get_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name)\n\n# Shortcut\nget_layer_variables = get_layer_variables_by_name\n\n\ndef get_layer_variables_by_scope(scope_name):\n    ret = []\n    for v in tf.get_collection(tf.GraphKeys.MODEL_VARIABLES):\n        if scope_name + \'/\' in v.name:\n            ret.append(v)\n    return ret\n\n\ndef get_value(var, session=None):\n    """""" get_value.\n\n    Get a variable\'s value. If no session provided, use default one.\n\n    Arguments:\n        var: `Variable`. The variable to get value from.\n        session: `Session`. The session to run the op. Default: the default\n            session.\n\n    Returns:\n        The variable\'s value.\n\n    """"""\n    if not session:\n        session = tf.get_default_session()\n    return var.eval(session)\n\n\ndef set_value(var, value, session=None):\n    """""" set_value.\n\n    Set a variable\'s value. If no session provided, use default one.\n\n    Arguments:\n        var: `Variable`. The variable to assign a value.\n        value: The value to assign. Must be compatible with variable dtype.\n        session: `Session`. The session to perform the assignation.\n            Default: the default session.\n\n    """"""\n    op = tf.assign(var, value=value)\n    if not session:\n        session = tf.get_default_session()\n    return op.eval(session=session)\n\n\ndef get_inputs_placeholder_by_name(name):\n    vars = tf.get_collection(tf.GraphKeys.INPUTS)\n    tflearn_name = name + \'/X:0\'\n    if len(vars) == 0:\n        raise Exception(""The collection `tf.GraphKeys.INPUTS` is empty! ""\n                        ""Cannot retrieve placeholder. In case placeholder was ""\n                        ""defined outside TFLearn `input_data` layer, please ""\n                        ""add it to that collection."")\n    for e in vars:\n        if e.name == tflearn_name:\n            return e\n    # Search again, in case defined outside TFLearn wrappers.\n    for e in vars:\n        if e.name == name:\n            return e\n\n    return None\n\n\ndef get_targets_placeholder_by_name(name):\n    vars = tf.get_collection(tf.GraphKeys.TARGETS)\n    tflearn_name = name + \'/Y:0\'\n    if len(vars) == 0:\n        raise Exception(""The collection `tf.GraphKeys.INPUTS` is empty! ""\n                        ""Cannot retrieve placeholder. In case placeholder was ""\n                        ""defined outside TFLearn `input_data` layer, please ""\n                        ""add it to that collection."")\n    for e in vars:\n        if e.name == tflearn_name:\n            return e\n    # Search again, in case defined outside TFLearn wrappers.\n    for e in vars:\n        if e.name == name+\':0\':\n            return e\n\n    return None\n'"
examples/basics/dask.py,0,"b""# Moved to 'use_dask.py'\n# https://github.com/tflearn/tflearn/blob/master/examples/basics/use_dask.py\n"""
examples/basics/finetuning.py,0,"b'# -*- coding: utf-8 -*-\n"""""" Finetuning Example. Using weights from model trained in\nconvnet_cifar10.py to retrain network for a new task (your own dataset).\nAll weights are restored except last layer (softmax) that will be retrained\nto match the new task (finetuning).\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.estimator import regression\n\n# Data loading\n# Note: You input here any dataset you would like to finetune\nX, Y = your_dataset()\nnum_classes = 10\n\n# Redefinition of convnet_cifar10 network\nnetwork = input_data(shape=[None, 32, 32, 3])\nnetwork = conv_2d(network, 32, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = dropout(network, 0.75)\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 512, activation=\'relu\')\nnetwork = dropout(network, 0.5)\n# Finetuning Softmax layer (Setting restore=False to not restore its weights)\nsoftmax = fully_connected(network, num_classes, activation=\'softmax\', restore=False)\nregression = regression(softmax, optimizer=\'adam\',\n                        loss=\'categorical_crossentropy\',\n                        learning_rate=0.001)\n\nmodel = tflearn.DNN(regression, checkpoint_path=\'model_finetuning\',\n                    max_checkpoints=3, tensorboard_verbose=0)\n# Load pre-existing model, restoring all weights, except softmax layer ones\nmodel.load(\'cifar10_cnn\')\n\n# Start finetuning\nmodel.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n          show_metric=True, batch_size=64, snapshot_step=200,\n          snapshot_epoch=False, run_id=\'model_finetuning\')\n\nmodel.save(\'model_finetuning\')\n'"
examples/basics/kmeans.py,0,"b'"""""" K-Means Example """"""\n\nfrom __future__ import division, print_function, absolute_import\n\nfrom tflearn.estimators import KMeans\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=False)\n\n# K-Means training\nm = KMeans(n_clusters=10, distance=\'squared_euclidean\')\nm.fit(X, display_step=10)\n\n# Testing\nprint(""Clusters center coordinates:"")\nprint(m.cluster_centers_vars)\n\nprint(""X[0] nearest cluster:"")\nprint(m.labels_[0])\n\nprint(""Predicting testX[0] nearest cluster:"")\nprint(m.predict(testX[0]))\n\nprint(""Transforming testX[0] to a cluster-distance space:"")\nprint(m.transform(testX[0]))\n'"
examples/basics/linear_regression.py,0,"b'"""""" Linear Regression Example """"""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport tflearn\n\n# Regression data\nX = [3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1]\nY = [1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3]\n\n# Linear Regression graph\ninput_ = tflearn.input_data(shape=[None])\nlinear = tflearn.single_unit(input_)\nregression = tflearn.regression(linear, optimizer=\'sgd\', loss=\'mean_square\',\n                                metric=\'R2\', learning_rate=0.01)\nm = tflearn.DNN(regression)\nm.fit(X, Y, n_epoch=1000, show_metric=True, snapshot_epoch=False)\n\nprint(""\\nRegression result:"")\nprint(""Y = "" + str(m.get_weights(linear.W)) +\n      ""*X + "" + str(m.get_weights(linear.b)))\n\nprint(""\\nTest prediction for x = 3.2, 3.3, 3.4:"")\nprint(m.predict([3.2, 3.3, 3.4]))\n# should output (close, not exact) y = [1.5315033197402954, 1.5585315227508545, 1.5855598449707031]\n'"
examples/basics/logical.py,4,"b'# -*- coding: utf-8 -*-\n""""""\nSimple Example to train logical operators\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\nimport tflearn\n\n# Logical NOT operator\nX = [[0.], [1.]]\nY = [[1.], [0.]]\n\n# Graph definition\nwith tf.Graph().as_default():\n    g = tflearn.input_data(shape=[None, 1])\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 1, activation=\'sigmoid\')\n    g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=2.,\n                           loss=\'mean_square\')\n\n    # Model training\n    m = tflearn.DNN(g)\n    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n\n    # Test model\n    print(""Testing NOT operator"")\n    print(""NOT 0:"", m.predict([[0.]]))\n    print(""NOT 1:"", m.predict([[1.]]))\n\n# Logical OR operator\nX = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\nY = [[0.], [1.], [1.], [1.]]\n\n# Graph definition\nwith tf.Graph().as_default():\n    g = tflearn.input_data(shape=[None, 2])\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 1, activation=\'sigmoid\')\n    g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=2.,\n                           loss=\'mean_square\')\n\n    # Model training\n    m = tflearn.DNN(g)\n    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n\n    # Test model\n    print(""Testing OR operator"")\n    print(""0 or 0:"", m.predict([[0., 0.]]))\n    print(""0 or 1:"", m.predict([[0., 1.]]))\n    print(""1 or 0:"", m.predict([[1., 0.]]))\n    print(""1 or 1:"", m.predict([[1., 1.]]))\n\n# Logical AND operator\nX = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\nY = [[0.], [0.], [0.], [1.]]\n\n# Graph definition\nwith tf.Graph().as_default():\n    g = tflearn.input_data(shape=[None, 2])\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 128, activation=\'linear\')\n    g = tflearn.fully_connected(g, 1, activation=\'sigmoid\')\n    g = tflearn.regression(g, optimizer=\'sgd\', learning_rate=2.,\n                           loss=\'mean_square\')\n\n    # Model training\n    m = tflearn.DNN(g)\n    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n\n    # Test model\n    print(""Testing AND operator"")\n    print(""0 and 0:"", m.predict([[0., 0.]]))\n    print(""0 and 1:"", m.predict([[0., 1.]]))\n    print(""1 and 0:"", m.predict([[1., 0.]]))\n    print(""1 and 1:"", m.predict([[1., 1.]]))\n\n\'\'\'\nGoing further: Graph combination with multiple optimizers\nCreate a XOR operator using product of NAND and OR operators\n\'\'\'\n# Data\nX = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\nY_nand = [[1.], [1.], [1.], [0.]]\nY_or = [[0.], [1.], [1.], [1.]]\n\n# Graph definition\nwith tf.Graph().as_default():\n    # Building a network with 2 optimizers\n    g = tflearn.input_data(shape=[None, 2])\n    # Nand operator definition\n    g_nand = tflearn.fully_connected(g, 32, activation=\'linear\')\n    g_nand = tflearn.fully_connected(g_nand, 32, activation=\'linear\')\n    g_nand = tflearn.fully_connected(g_nand, 1, activation=\'sigmoid\')\n    g_nand = tflearn.regression(g_nand, optimizer=\'sgd\',\n                                learning_rate=2.,\n                                loss=\'binary_crossentropy\')\n    # Or operator definition\n    g_or = tflearn.fully_connected(g, 32, activation=\'linear\')\n    g_or = tflearn.fully_connected(g_or, 32, activation=\'linear\')\n    g_or = tflearn.fully_connected(g_or, 1, activation=\'sigmoid\')\n    g_or = tflearn.regression(g_or, optimizer=\'sgd\',\n                              learning_rate=2.,\n                              loss=\'binary_crossentropy\')\n    # XOR merging Nand and Or operators\n    g_xor = tflearn.merge([g_nand, g_or], mode=\'elemwise_mul\')\n\n    # Training\n    m = tflearn.DNN(g_xor)\n    m.fit(X, [Y_nand, Y_or], n_epoch=400, snapshot_epoch=False)\n\n    # Testing\n    print(""Testing XOR operator"")\n    print(""0 xor 0:"", m.predict([[0., 0.]]))\n    print(""0 xor 1:"", m.predict([[0., 1.]]))\n    print(""1 xor 0:"", m.predict([[1., 0.]]))\n    print(""1 xor 1:"", m.predict([[1., 1.]]))\n'"
examples/basics/multiple_regression.py,0,"b'"""""" Multiple Regression/Multi target Regression Example\n\nThe input features have 10 dimensions, and target features are 2 dimension.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport tflearn\nimport numpy as np\n\n# Regression data- 10 training instances\n#10 input features per instance.\nX=np.random.rand(10,10).tolist()\n#2 output features per instance\nY=np.random.rand(10,2).tolist()\n\n# Multiple Regression graph, 10-d input layer\ninput_ = tflearn.input_data(shape=[None,10])\n#10-d fully connected layer\nr1 = tflearn.fully_connected(input_,10)\n#2-d fully connected layer for output\nr1 = tflearn.fully_connected(r1,2)\nr1 = tflearn.regression(r1, optimizer=\'sgd\', loss=\'mean_square\',\n                                        metric=\'R2\', learning_rate=0.01)\n\nm = tflearn.DNN(r1)\nm.fit(X,Y, n_epoch=100, show_metric=True, snapshot_epoch=False)\n\n#Predict for 1 instance\ntestinstance=np.random.rand(1,10).tolist()\nprint(""\\nInput features:  "",testinstance)\nprint(""\\n Predicted output: "")\nprint(m.predict(testinstance))\n'"
examples/basics/random_forest.py,0,"b'"""""" Random Forest example. """"""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.estimators import RandomForestClassifier\n\n# Data loading and pre-processing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=False)\n\nm = RandomForestClassifier(n_estimators=100, max_nodes=1000)\nm.fit(X, Y, batch_size=10000, display_step=10)\n\nprint(""Compute the accuracy on train set:"")\nprint(m.evaluate(X, Y, tflearn.accuracy_op))\n\nprint(""Compute the accuracy on test set:"")\nprint(m.evaluate(testX, testY, tflearn.accuracy_op))\n\nprint(""Digits for test images id 0 to 5:"")\nprint(m.predict(testX[:5]))\nprint(""True digits:"")\nprint(testY[:5])\n'"
examples/basics/use_dask.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nExample on how to use Dask with TFLearn. Dask is a simple task scheduling\nsystem that uses directed acyclic graphs (DAGs) of tasks to break up large\ncomputations into many small ones. It can handle large dataset that could\nnot fit totally in ram memory. Note that this example just give a quick\ncompatibility demonstration. In practice, there is no so much need to use\nDask for small dataset such as CIFAR-10.\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import *\nfrom tflearn.layers.conv import *\nfrom tflearn.data_utils import *\nfrom tflearn.layers.estimator import *\n\n# Load CIFAR-10 Dataset\nfrom tflearn.datasets import cifar10\n(X, Y), (X_test, Y_test) = cifar10.load_data()\nY = to_categorical(Y)\nY_test = to_categorical(Y_test)\n\n# Create DASK array using numpy arrays\n# (Note that it can work with HDF5 Dataset too)\nimport dask.array as da\nX = da.from_array(np.asarray(X), chunks=(1000, 1000, 1000, 1000))\nY = da.from_array(np.asarray(Y), chunks=(1000, 1000, 1000, 1000))\nX_test = da.from_array(np.asarray(X_test), chunks=(1000, 1000, 1000, 1000))\nY_test = da.from_array(np.asarray(Y_test), chunks=(1000, 1000, 1000, 1000))\n\n# Build network\nnetwork = input_data(shape=[None, 32, 32, 3])\nnetwork = conv_2d(network, 32, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = dropout(network, 0.75)\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 512, activation=\'relu\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 10, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# Training\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=50, shuffle=True, validation_set=(X_test, Y_test),\n          show_metric=True, batch_size=96, run_id=\'cifar10_cnn\')\n'"
examples/basics/use_hdf5.py,1,"b'# -*- coding: utf-8 -*-\n""""""\nExample on how to use HDF5 dataset with TFLearn. HDF5 is a data model,\nlibrary, and file format for storing and managing data. It can handle large\ndataset that could not fit totally in ram memory. Note that this example\njust give a quick compatibility demonstration. In practice, there is no so\nreal need to use HDF5 for small dataset such as CIFAR-10.\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import *\nfrom tflearn.layers.conv import *\nfrom tflearn.data_utils import *\nfrom tflearn.layers.normalization import *\nfrom tflearn.layers.estimator import regression\n\n# CIFAR-10 Dataset\nfrom tflearn.datasets import cifar10\n(X, Y), (X_test, Y_test) = cifar10.load_data()\nY = to_categorical(Y)\nY_test = to_categorical(Y_test)\n\n# Create a hdf5 dataset from CIFAR-10 numpy array\nimport h5py\nh5f = h5py.File(\'data.h5\', \'w\')\nh5f.create_dataset(\'cifar10_X\', data=X)\nh5f.create_dataset(\'cifar10_Y\', data=Y)\nh5f.create_dataset(\'cifar10_X_test\', data=X_test)\nh5f.create_dataset(\'cifar10_Y_test\', data=Y_test)\nh5f.close()\n\n# Load hdf5 dataset\nh5f = h5py.File(\'data.h5\', \'r\')\nX = h5f[\'cifar10_X\']\nY = h5f[\'cifar10_Y\']\nX_test = h5f[\'cifar10_X_test\']\nY_test = h5f[\'cifar10_Y_test\']\n\n# Build network\nnetwork = input_data(shape=[None, 32, 32, 3], dtype=tf.float32)\nnetwork = conv_2d(network, 32, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = fully_connected(network, 512, activation=\'relu\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 10, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# Training\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=50, shuffle=True, validation_set=(X_test, Y_test),\n          show_metric=True, batch_size=96, run_id=\'cifar10_cnn\')\n\nh5f.close()\n'"
examples/basics/weights_loading_scope.py,15,"b'\'\'\'\nDemonstrate that weights saved with models in one scope, can be loaded \ninto models being used in a different scope.\n\nThis allows multiple models to be run, and combined models to load\nweights from separately trained models.\n\'\'\'\n\nfrom __future__ import division, print_function, absolute_import\n\nimport re\nimport tflearn\nimport tensorflow as tf\nimport tflearn.datasets.mnist as mnist\n\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\n#-----------------------------------------------------------------------------\n\nclass Model1(object):\n    \'\'\'\n    convnet MNIST\n    \'\'\'\n    def __init__(self):\n        network = tflearn.input_data(shape=[None, 784], name=""input"")\n        network = self.make_core_network(network)\n        network = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                             loss=\'categorical_crossentropy\', name=\'target\')\n        \n        model = tflearn.DNN(network, tensorboard_verbose=0)\n        self.model = model\n\n    @staticmethod\n    def make_core_network(network):\n        network = tflearn.reshape(network, [-1, 28, 28, 1], name=""reshape"")\n        network = conv_2d(network, 32, 3, activation=\'relu\', regularizer=""L2"")\n        network = max_pool_2d(network, 2)\n        network = local_response_normalization(network)\n        network = conv_2d(network, 64, 3, activation=\'relu\', regularizer=""L2"")\n        network = max_pool_2d(network, 2)\n        network = local_response_normalization(network)\n        network = fully_connected(network, 128, activation=\'tanh\')\n        network = dropout(network, 0.8)\n        network = fully_connected(network, 256, activation=\'tanh\')\n        network = dropout(network, 0.8)\n        network = fully_connected(network, 10, activation=\'softmax\')\n        return network\n\n    def train(self, X, Y, testX, testY, n_epoch=1, snapshot_step=1000):\n        # Training\n        self.model.fit({\'input\': X}, {\'target\': Y}, n_epoch=n_epoch,\n                       validation_set=({\'input\': testX}, {\'target\': testY}),\n                       snapshot_step=snapshot_step,\n                       show_metric=True, run_id=\'convnet_mnist\')\n        \nclass Model2(object):\n    \'\'\'\n    dnn MNIST\n    \'\'\'\n    def __init__(self):\n        # Building deep neural network\n        network = tflearn.input_data(shape=[None, 784], name=""input"")\n        network = self.make_core_network(network)\n\n        # Regression using SGD with learning rate decay and Top-3 accuracy\n        sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=1000)\n        top_k = tflearn.metrics.Top_k(3)\n\n        network = tflearn.regression(network, optimizer=sgd, metric=top_k,\n                                 loss=\'categorical_crossentropy\', name=""target"")\n        model = tflearn.DNN(network, tensorboard_verbose=0)\n        self.model = model\n\n    @staticmethod\n    def make_core_network(network):\n        dense1 = tflearn.fully_connected(network, 64, activation=\'tanh\',\n                                         regularizer=\'L2\', weight_decay=0.001, name=""dense1"")\n        dropout1 = tflearn.dropout(dense1, 0.8)\n        dense2 = tflearn.fully_connected(dropout1, 64, activation=\'tanh\',\n                                         regularizer=\'L2\', weight_decay=0.001, name=""dense2"")\n        dropout2 = tflearn.dropout(dense2, 0.8)\n        softmax = tflearn.fully_connected(dropout2, 10, activation=\'softmax\', name=""softmax"")\n        return softmax\n\n    def train(self, X, Y, testX, testY, n_epoch=1, snapshot_step=1000):\n        # Training\n        self.model.fit(X, Y, n_epoch=n_epoch, validation_set=(testX, testY),\n                       snapshot_step=snapshot_step,\n                       show_metric=True, run_id=""dense_model"")\n        \nclass Model12(object):\n    \'\'\'\n    Combination of two networks\n    \'\'\'\n    def __init__(self):\n        inputs = tflearn.input_data(shape=[None, 784], name=""input"")\n\n        with tf.variable_scope(""scope1"") as scope:\n            net_conv = Model1.make_core_network(inputs)\t# shape (?, 10)\n        with tf.variable_scope(""scope2"") as scope:\n            net_dnn = Model2.make_core_network(inputs)\t# shape (?, 10)\n\n        network = tf.concat([net_conv, net_dnn], 1, name=""concat"")\t# shape (?, 20)\n        network = tflearn.fully_connected(network, 10, activation=""softmax"")\n        network = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                             loss=\'categorical_crossentropy\', name=\'target\')\n\n        self.model = tflearn.DNN(network, tensorboard_verbose=0)\n\n    def load_from_two(self, m1fn, m2fn):\n        self.model.load(m1fn, scope_for_restore=""scope1"", weights_only=True)\n        self.model.load(m2fn, scope_for_restore=""scope2"", weights_only=True, create_new_session=False)\n\n    def train(self, X, Y, testX, testY, n_epoch=1, snapshot_step=1000):\n        # Training\n        self.model.fit(X, Y, n_epoch=n_epoch, validation_set=(testX, testY),\n                       snapshot_step=snapshot_step,\n                       show_metric=True, run_id=""model12"")\n\n#-----------------------------------------------------------------------------\n\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\ndef prepare_model1_weights_file():\n    tf.reset_default_graph()\n    m1 = Model1()\n    m1.train(X, Y, testX, testY, 2)\n    m1.model.save(""model1.tfl"")\n\ndef prepare_model1_weights_file_in_scopeQ():\n    tf.reset_default_graph()\n    with tf.variable_scope(""scopeQ"") as scope:\n        m1 = Model1()\n    m1.model.fit({""scopeQ/input"": X}, {""scopeQ/target"": Y}, n_epoch=1, validation_set=0.1, show_metric=True, run_id=""model1_scopeQ"")\n    m1.model.save(""model1_scopeQ.tfl"")\n\ndef prepare_model2_weights_file():\n    tf.reset_default_graph()\n    m2 = Model2()\n    m2.train(X, Y, testX, testY, 1)\n    m2.model.save(""model2.tfl"")\n\ndef demonstrate_loading_weights_into_different_scope():\n    print(""=""*60 + "" Demonstrate loading weights saved in scopeQ, into variables now in scopeA"")\n    tf.reset_default_graph()\n    with tf.variable_scope(""scopeA"") as scope:\n        m1a = Model1()\n        print (""="" * 60 + "" Trying to load model1 weights from scopeQ into scopeA"")\n        m1a.model.load(""model1_scopeQ.tfl"", variable_name_map=(""scopeA"", ""scopeQ""), verbose=True)\n\ndef demonstrate_loading_weights_into_different_scope_using_custom_function():\n    print(""=""*60 + "" Demonstrate loading weights saved in scopeQ, into variables now in scopeA, using custom map function"")\n    tf.reset_default_graph()\n    def vname_map(ename):\t# variables were saved in scopeA, but we want to load into scopeQ\n        name_in_file = ename.replace(""scopeA"", ""scopeQ"")\n        print (""%s -> %s"" % (ename, name_in_file))\n        return name_in_file\n    with tf.variable_scope(""scopeA"") as scope:\n        m1a = Model1()\n        print (""="" * 60 + "" Trying to load model1 weights from scopeQ into scopeA"")\n        m1a.model.load(""model1_scopeQ.tfl"", variable_name_map=vname_map, verbose=True)\n\ndef demonstrate_loading_two_instances_of_model1():\n    print(""=""*60 + "" Demonstrate loading weights from model1 into two instances of model1 in scopeA and scopeB"")\n    tf.reset_default_graph()\n    with tf.variable_scope(""scopeA"") as scope:\n        m1a = Model1()\n        print (""-"" * 40 + "" Trying to load model1 weights: should fail"")\n        try:\n            m1a.model.load(""model1.tfl"", weights_only=True)\n        except Exception as err:\n            print (""Loading failed, with error as expected, because variables are in scopeA"")\n            print (""error: %s"" % str(err))\n        print (""-"" * 40)\n\n        print (""="" * 60 + "" Trying to load model1 weights: should succeed"")\n        m1a.model.load(""model1.tfl"", scope_for_restore=""scopeA"", verbose=True, weights_only=True)\n\n    with tf.variable_scope(""scopeB"") as scope:\n        m1b = Model1()\n        m1b.model.load(""model1.tfl"", scope_for_restore=""scopeB"", verbose=True, weights_only=True)\n    print (""=""*60 + "" Successfully restored weights to two instances of model1, in different scopes"")\n            \ndef demonstrate_combined_model1_and_model2_network():\n    print(""=""*60 + "" Demonstrate loading weights from model1 and model2 into new mashup network model12"")\n    print (""-""*40 + "" Creating mashup of model1 and model2 networks"")\n    tf.reset_default_graph()\n    m12 = Model12()\n    print (""-""*60 + "" Loading model1 and model2 weights into mashup"")\n    m12.load_from_two(""model1.tfl"", ""model2.tfl"")\n    print (""-""*60 + "" Training mashup"")\n    m12.train(X, Y, testX, testY, 1)\n    print (""-""*60 + "" Saving mashup weights"")\n    m12.model.save(""model12.tfl"")\n    print (""-""*60 + "" Done"")\n\nprint(""=""*77)\nprepare_model1_weights_file()\nprepare_model2_weights_file()\nprepare_model1_weights_file_in_scopeQ()\nprint(""-""*77)\nprint(""-""*77)\n\ndemonstrate_loading_weights_into_different_scope()\ndemonstrate_loading_weights_into_different_scope_using_custom_function()\ndemonstrate_loading_two_instances_of_model1()\ndemonstrate_combined_model1_and_model2_network()\n\nprint(""=""*77)\n'"
examples/basics/weights_persistence.py,0,"b'"""""" An example showing how to save/restore models and retrieve weights. """"""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport tflearn\n\nimport tflearn.datasets.mnist as mnist\n\n# MNIST Data\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\n# Model\ninput_layer = tflearn.input_data(shape=[None, 784], name=\'input\')\ndense1 = tflearn.fully_connected(input_layer, 128, name=\'dense1\')\ndense2 = tflearn.fully_connected(dense1, 256, name=\'dense2\')\nsoftmax = tflearn.fully_connected(dense2, 10, activation=\'softmax\')\nregression = tflearn.regression(softmax, optimizer=\'adam\',\n                                learning_rate=0.001,\n                                loss=\'categorical_crossentropy\')\n\n# Define classifier, with model checkpoint (autosave)\nmodel = tflearn.DNN(regression, checkpoint_path=\'model.tfl.ckpt\')\n\n# Train model, with model checkpoint every epoch and every 200 training steps.\nmodel.fit(X, Y, n_epoch=1,\n          validation_set=(testX, testY),\n          show_metric=True,\n          snapshot_epoch=True, # Snapshot (save & evaluate) model every epoch.\n          snapshot_step=500, # Snapshot (save & evalaute) model every 500 steps.\n          run_id=\'model_and_weights\')\n\n\n# ---------------------\n# Save and load a model\n# ---------------------\n\n# Manually save model\nmodel.save(""model.tfl"")\n\n# Load a model\nmodel.load(""model.tfl"")\n\n# Or Load a model from auto-generated checkpoint\n# >> model.load(""model.tfl.ckpt-500"")\n\n# Resume training\nmodel.fit(X, Y, n_epoch=1,\n          validation_set=(testX, testY),\n          show_metric=True,\n          snapshot_epoch=True,\n          run_id=\'model_and_weights\')\n\n\n# ------------------\n# Retrieving weights\n# ------------------\n\n# Retrieve a layer weights, by layer name:\ndense1_vars = tflearn.variables.get_layer_variables_by_name(\'dense1\')\n# Get a variable\'s value, using model `get_weights` method:\nprint(""Dense1 layer weights:"")\nprint(model.get_weights(dense1_vars[0]))\n# Or using generic tflearn function:\nprint(""Dense1 layer biases:"")\nwith model.session.as_default():\n    print(tflearn.variables.get_value(dense1_vars[1]))\n\n# It is also possible to retrieve a layer weights through its attributes `W`\n# and `b` (if available).\n# Get variable\'s value, using model `get_weights` method:\nprint(""Dense2 layer weights:"")\nprint(model.get_weights(dense2.W))\n# Or using generic tflearn function:\nprint(""Dense2 layer biases:"")\nwith model.session.as_default():\n    print(tflearn.variables.get_value(dense2.b))\n'"
examples/extending_tensorflow/builtin_ops.py,12,"b'from __future__ import division, print_function, absolute_import\n\n""""""\nThis tutorial will introduce how to combine TFLearn built-in ops with any\nTensorflow graph.\n""""""\n\nimport tensorflow as tf\nimport tflearn\n\n# ----------------------------------\n# Using TFLearn built-in ops example\n# ----------------------------------\n\n# Using MNIST Dataset\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n# User defined placeholders\nwith tf.Graph().as_default():\n\n    # Model variables\n    X = tf.placeholder(""float"", [None, 784])\n    Y = tf.placeholder(""float"", [None, 10])\n\n    W1 = tf.Variable(tf.random_normal([784, 256]))\n    W2 = tf.Variable(tf.random_normal([256, 256]))\n    W3 = tf.Variable(tf.random_normal([256, 10]))\n    b1 = tf.Variable(tf.random_normal([256]))\n    b2 = tf.Variable(tf.random_normal([256]))\n    b3 = tf.Variable(tf.random_normal([10]))\n\n    # Multilayer perceptron\n    def dnn(x):\n        # Using TFLearn PReLU activations ops\n        x = tflearn.prelu(tf.add(tf.matmul(x, W1), b1))\n        tflearn.summaries.monitor_activation(x) # Monitor activation\n        x = tflearn.prelu(tf.add(tf.matmul(x, W2), b2))\n        tflearn.summaries.monitor_activation(x) # Monitor activation\n        x = tf.nn.softmax(tf.add(tf.matmul(x, W3), b3))\n        return x\n\n    net = dnn(X)\n\n    # Using objective ops from TFLearn to compute crossentropy\n    loss = tflearn.categorical_crossentropy(net, Y)\n\n    # Using metric ops from TFLearn to compute accuracy\n    acc = tflearn.metrics.accuracy_op(net, Y)\n\n    # Using TFLearn SGD Optimizer class\n    optimizer = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=200)\n    # Because of lr decay, it is required to first build the Optimizer with\n    # the step tensor that will monitor training step.\n    # (Note: When using TFLearn estimators wrapper, build is self managed,\n    # so only using above `Optimizer` class as `DNN` optimizer arg is enough).\n    step = tflearn.variable(""step"", initializer=\'zeros\', shape=[])\n    optimizer.build(step_tensor=step)\n    optim_tensor = optimizer.get_tensor()\n\n    # Using TFLearn Trainer\n    # Define a training op (op for backprop, only need 1 in this model)\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optim_tensor,\n                              metric=acc, batch_size=128,\n                              step_tensor=step)\n\n    # Create Trainer, providing all training ops. Tensorboard logs stored\n    # in /tmp/tflearn_logs/. It is possible to change verbose level for more\n    # details logs about gradients, variables etc...\n    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=0)\n    # Training for 10 epochs.\n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True)\n'"
examples/extending_tensorflow/layers.py,8,"b'""""""\nThis tutorial will introduce how to combine TFLearn and Tensorflow, using\nTFLearn trainer with regular Tensorflow graph.\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tflearn\n\n# --------------------------------------\n# High-Level API: Using TFLearn wrappers\n# --------------------------------------\n\n# Using MNIST Dataset\nimport tflearn.datasets.mnist as mnist\nmnist_data = mnist.read_data_sets(one_hot=True)\n\n# User defined placeholders\nwith tf.Graph().as_default():\n    # Placeholders for data and labels\n    X = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n    Y = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n\n    net = tf.reshape(X, [-1, 28, 28, 1])\n\n    # Using TFLearn wrappers for network building\n    net = tflearn.conv_2d(net, 32, 3, activation=\'relu\')\n    net = tflearn.max_pool_2d(net, 2)\n    net = tflearn.local_response_normalization(net)\n    net = tflearn.dropout(net, 0.8)\n    net = tflearn.conv_2d(net, 64, 3, activation=\'relu\')\n    net = tflearn.max_pool_2d(net, 2)\n    net = tflearn.local_response_normalization(net)\n    net = tflearn.dropout(net, 0.8)\n    net = tflearn.fully_connected(net, 128, activation=\'tanh\')\n    net = tflearn.dropout(net, 0.8)\n    net = tflearn.fully_connected(net, 256, activation=\'tanh\')\n    net = tflearn.dropout(net, 0.8)\n    net = tflearn.fully_connected(net, 10, activation=\'linear\')\n\n    # Defining other ops using Tensorflow\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=net, labels=Y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n\n    # Initializing the variables\n    init = tf.global_variables_initializer()\n\n    # Launch the graph\n    with tf.Session() as sess:\n        sess.run(init)\n\n        batch_size = 128\n        for epoch in range(2):  # 2 epochs\n            avg_cost = 0.\n            total_batch = int(mnist_data.train.num_examples / batch_size)\n            for i in range(total_batch):\n                batch_xs, batch_ys = mnist_data.train.next_batch(batch_size)\n                sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys})\n                cost = sess.run(loss, feed_dict={X: batch_xs, Y: batch_ys})\n                avg_cost += cost / total_batch\n                if i % 20 == 0:\n                    print(""Epoch:"", \'%03d\' % (epoch + 1), ""Step:"", \'%03d\' % i,\n                          ""Loss:"", str(cost))\n'"
examples/extending_tensorflow/summaries.py,27,"b'""""""\nThis example introduces the use of TFLearn functions to easily summarize\nvariables into tensorboard.\n\nTFLearn can summarize:\n- Loss / Accuracy: The model loss and accuracy over training steps.\n- Activations: Histogram of operation output values.(Requires to add each\n    activation to monitor into tf.Graphkeys.ACTIVATIONS collection).\n- Gradients: Histogram of trainable variables gradient.\n- Weights: Histogram of trainable variables weights.\n- Weight Decay: Decay of trainable variables with regularizer. (Requires\n    to add each decay into tf.Graphkeys.REGULARIZATION_LOSSES collection)\n- Sparsity: Sparsity of trainable variables.\n\nIt is useful to also be able to periodically monitor various variables\nduring training, e.g. confusion matrix entries or AUC metrics. This\ncan be done using ""validation_monitors"", an argument to regression or\nTrainOp; this argument takes a list of Tensor variables, and passes\nthem to the trainer, where they are evaluated each time a validation\nstep happens. The evaluation results are then summarized, and saved\nfor tensorboard visualization.\n\nSummaries are monitored according to the following verbose levels:\n- 0: Loss & Metric (Best speed).\n- 1: Loss, Metric & Gradients.\n- 2: Loss, Metric, Gradients & Weights.\n- 3: Loss, Metric, Gradients, Weights, Activations & Sparsity (Best\n     Visualization).\n\nNote: If you are using TFLearn layers, summaries are automatically handled,\nso you do not need to manually add them.\n\n""""""\n\nimport tensorflow as tf\nimport tflearn\n\n# Loading MNIST dataset\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n# Define a dnn using Tensorflow\nwith tf.Graph().as_default():\n\n    # Model variables\n    X = tf.placeholder(""float"", [None, 784])\n    Y = tf.placeholder(""float"", [None, 10])\n\n    # Multilayer perceptron, with `tanh` functions activation monitor\n    def dnn(x):\n        with tf.name_scope(\'Layer1\'):\n            W1 = tf.Variable(tf.random_normal([784, 256]), name=""W1"")\n            b1 = tf.Variable(tf.random_normal([256]), name=""b1"")\n            x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n            # Add this `tanh` op to activations collection or monitoring\n            tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, x)\n            # Add weights regularizer (Regul. summary automatically added)\n            tflearn.add_weights_regularizer(W1, \'L2\', weight_decay=0.001)\n\n        with tf.name_scope(\'Layer2\'):\n            W2 = tf.Variable(tf.random_normal([256, 256]), name=""W2"")\n            b2 = tf.Variable(tf.random_normal([256]), name=""b2"")\n            x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n            # Add this `tanh` op to activations collection or monitoring\n            tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, x)\n            # Add weights regularizer (Regul. summary automatically added)\n            tflearn.add_weights_regularizer(W2, \'L2\', weight_decay=0.001)\n\n        with tf.name_scope(\'Layer3\'):\n            W3 = tf.Variable(tf.random_normal([256, 10]), name=""W3"")\n            b3 = tf.Variable(tf.random_normal([10]), name=""b3"")\n            x = tf.add(tf.matmul(x, W3), b3)\n\n        return x\n\n    net = dnn(X)\n        \n    with tf.name_scope(\'Summaries\'):\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net,labels=Y))\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n        accuracy = tf.reduce_mean(\n            tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n            name=""acc"")\n\n    # construct two varaibles to add as additional ""valiation monitors""\n    # these varaibles are evaluated each time validation happens (eg at a snapshot)\n    # and the results are summarized and output to the tensorboard events file,\n    # together with the accuracy and loss plots.\n    #\n    # Here, we generate a dummy variable given by the sum over the current\n    # network tensor, and a constant variable.  In practice, the validation\n    # monitor may present useful information, like confusion matrix\n    # entries, or an AUC metric.\n    with tf.name_scope(\'CustomMonitor\'):\n        test_var = tf.reduce_sum(tf.cast(net, tf.float32), name=""test_var"")\n        test_const = tf.constant(32.0, name=""custom_constant"")\n        # Define a train op\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n                            validation_monitors=[test_var, test_const],\n                            metric=accuracy, batch_size=128)\n\n    # Tensorboard logs stored in /tmp/tflearn_logs/. Using verbose level 2.\n    trainer = tflearn.Trainer(train_ops=trainop,\n                              tensorboard_dir=\'/tmp/tflearn_logs/\',\n                              tensorboard_verbose=2)\n    # Training for 10 epochs.\n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True, run_id=\'Summaries_example\')\n\n    # Run the following command to start tensorboard:\n    # >> tensorboard /tmp/tflearn_logs/\n    # Navigate with your web browser to http://0.0.0.0:6006/\n'"
examples/extending_tensorflow/trainer.py,16,"b'""""""\nThis tutorial will introduce how to combine TFLearn and Tensorflow, using\nTFLearn wrappers regular Tensorflow expressions.\n""""""\n\nimport tensorflow as tf\nimport tflearn\n\n# ----------------------------\n# Utils: Using TFLearn Trainer\n# ----------------------------\n\n# Loading MNIST complete dataset\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n# Define a dnn using Tensorflow\nwith tf.Graph().as_default():\n\n    # Model variables\n    X = tf.placeholder(""float"", [None, 784])\n    Y = tf.placeholder(""float"", [None, 10])\n\n    W1 = tf.Variable(tf.random_normal([784, 256]))\n    W2 = tf.Variable(tf.random_normal([256, 256]))\n    W3 = tf.Variable(tf.random_normal([256, 10]))\n    b1 = tf.Variable(tf.random_normal([256]))\n    b2 = tf.Variable(tf.random_normal([256]))\n    b3 = tf.Variable(tf.random_normal([10]))\n\n    # Multilayer perceptron\n    def dnn(x):\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n        x = tf.add(tf.matmul(x, W3), b3)\n        return x\n\n    net = dnn(X)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n    accuracy = tf.reduce_mean(\n        tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n        name=\'acc\')\n\n    # Using TFLearn Trainer\n    # Define a training op (op for backprop, only need 1 in this model)\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n                              metric=accuracy, batch_size=128)\n\n    # Create Trainer, providing all training ops. Tensorboard logs stored\n    # in /tmp/tflearn_logs/. It is possible to change verbose level for more\n    # details logs about gradients, variables etc...\n    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=0)\n    # Training for 10 epochs.\n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True)\n'"
examples/extending_tensorflow/variables.py,14,"b'""""""\nThis example introduces the use of TFLearn variables to easily implement\nTensorflow variables with custom initialization and regularization.\n\nNote: If you are using TFLearn layers, inititalization and regularization\nare directly defined at the layer definition level and applied to inner\nvariables.\n""""""\n\nimport tensorflow as tf\nimport tflearn\nimport tflearn.variables as va\n\n# Loading MNIST dataset\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n# Define a dnn using Tensorflow\nwith tf.Graph().as_default():\n\n    # Model variables\n    X = tf.placeholder(""float"", [None, 784])\n    Y = tf.placeholder(""float"", [None, 10])\n\n    # Multilayer perceptron\n    def dnn(x):\n        with tf.variable_scope(\'Layer1\'):\n            # Creating variable using TFLearn\n            W1 = va.variable(name=\'W\', shape=[784, 256],\n                             initializer=\'uniform_scaling\',\n                             regularizer=\'L2\')\n            b1 = va.variable(name=\'b\', shape=[256])\n            x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n\n        with tf.variable_scope(\'Layer2\'):\n            W2 = va.variable(name=\'W\', shape=[256, 256],\n                             initializer=\'uniform_scaling\',\n                             regularizer=\'L2\')\n            b2 = va.variable(name=\'b\', shape=[256])\n            x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n\n        with tf.variable_scope(\'Layer3\'):\n            W3 = va.variable(name=\'W\', shape=[256, 10],\n                             initializer=\'uniform_scaling\')\n            b3 = va.variable(name=\'b\', shape=[10])\n            x = tf.add(tf.matmul(x, W3), b3)\n\n        return x\n\n    net = dnn(X)\n    loss = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n    accuracy = tf.reduce_mean(\n        tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n        name=\'acc\')\n\n    # Define a train op\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n                              metric=accuracy, batch_size=128)\n\n    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=3,\n                              tensorboard_dir=\'/tmp/tflearn_logs/\')\n    # Training for 10 epochs.\n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True, run_id=\'Variables_example\')\n'"
examples/images/VGG19.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Very Deep Convolutional Networks for Large-Scale Visual Recognition.\nApplying VGG 19-layers convolutional network to Imagenet classification task.\nReferences:\n    Very Deep Convolutional Networks for Large-Scale Image Recognition.\n    K. Simonyan, A. Zisserman. arXiv technical report, 2014.\nLinks:\n    http://arxiv.org/pdf/1409.1556\n""""""\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.estimator import regression\n\n\n# Building \'VGG Network\'\ninput_layer = input_data(shape=[None, 224, 224, 3])\n\nblock1_conv1 = conv_2d(input_layer, 64, 3, activation=\'relu\', name=\'block1_conv1\')\nblock1_conv2 = conv_2d(block1_conv1, 64, 3, activation=\'relu\', name=\'block1_conv2\')\nblock1_pool = max_pool_2d(block1_conv2, 2, strides=2, name = \'block1_pool\')\n\nblock2_conv1 = conv_2d(block1_pool, 128, 3, activation=\'relu\', name=\'block2_conv1\')\nblock2_conv2 = conv_2d(block2_conv1, 128, 3, activation=\'relu\', name=\'block2_conv2\')\nblock2_pool = max_pool_2d(block2_conv2, 2, strides=2, name = \'block2_pool\')\n\nblock3_conv1 = conv_2d(block2_pool, 256, 3, activation=\'relu\', name=\'block3_conv1\')\nblock3_conv2 = conv_2d(block3_conv1, 256, 3, activation=\'relu\', name=\'block3_conv2\')\nblock3_conv3 = conv_2d(block3_conv2, 256, 3, activation=\'relu\', name=\'block3_conv3\')\nblock3_conv4 = conv_2d(block3_conv3, 256, 3, activation=\'relu\', name=\'block3_conv4\')\nblock3_pool = max_pool_2d(block3_conv4, 2, strides=2, name = \'block3_pool\')\n\nblock4_conv1 = conv_2d(block3_pool, 512, 3, activation=\'relu\', name=\'block4_conv1\')\nblock4_conv2 = conv_2d(block4_conv1, 512, 3, activation=\'relu\', name=\'block4_conv2\')\nblock4_conv3 = conv_2d(block4_conv2, 512, 3, activation=\'relu\', name=\'block4_conv3\')\nblock4_conv4 = conv_2d(block4_conv3, 512, 3, activation=\'relu\', name=\'block4_conv4\')\nblock4_pool = max_pool_2d(block4_conv4, 2, strides=2, name = \'block4_pool\')\n\nblock5_conv1 = conv_2d(block4_pool, 512, 3, activation=\'relu\', name=\'block5_conv1\')\nblock5_conv2 = conv_2d(block5_conv1, 512, 3, activation=\'relu\', name=\'block5_conv2\')\nblock5_conv3 = conv_2d(block5_conv2, 512, 3, activation=\'relu\', name=\'block5_conv3\')\nblock5_conv4 = conv_2d(block5_conv3, 512, 3, activation=\'relu\', name=\'block5_conv4\')\nblock4_pool = max_pool_2d(block5_conv4, 2, strides=2, name = \'block4_pool\')\nflatten_layer = tflearn.layers.core.flatten (block4_pool, name=\'Flatten\')\n\n\nfc1 = fully_connected(flatten_layer, 4096, activation=\'relu\')\ndp1 = dropout(fc1, 0.5)\nfc2 = fully_connected(dp1, 4096, activation=\'relu\')\ndp2 = dropout(fc2, 0.5)\n\nnetwork = fully_connected(dp2, 1000, activation=\'rmsprop\')\n\nregression = tflearn.regression(network, optimizer=\'adam\',\n                            loss=\'categorical_crossentropy\',\n                            learning_rate=0.001)\n\nmodel = tflearn.DNN(regression, checkpoint_path=\'vgg19\',\n                    tensorboard_dir=""./logs"")\n\n'"
examples/images/alexnet.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" AlexNet.\n\nApplying \'Alexnet\' to Oxford\'s 17 Category Flower Dataset classification task.\n\nReferences:\n    - Alex Krizhevsky, Ilya Sutskever & Geoffrey E. Hinton. ImageNet\n    Classification with Deep Convolutional Neural Networks. NIPS, 2012.\n    - 17 Category Flower Dataset. Maria-Elena Nilsback and Andrew Zisserman.\n\nLinks:\n    - [AlexNet Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n    - [Flower Dataset (17)](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/)\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\nimport tflearn.datasets.oxflower17 as oxflower17\nX, Y = oxflower17.load_data(one_hot=True, resize_pics=(227, 227))\n\n# Building \'AlexNet\'\nnetwork = input_data(shape=[None, 227, 227, 3])\nnetwork = conv_2d(network, 96, 11, strides=4, activation=\'relu\')\nnetwork = max_pool_2d(network, 3, strides=2)\nnetwork = local_response_normalization(network)\nnetwork = conv_2d(network, 256, 5, activation=\'relu\')\nnetwork = max_pool_2d(network, 3, strides=2)\nnetwork = local_response_normalization(network)\nnetwork = conv_2d(network, 384, 3, activation=\'relu\')\nnetwork = conv_2d(network, 384, 3, activation=\'relu\')\nnetwork = conv_2d(network, 256, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 3, strides=2)\nnetwork = local_response_normalization(network)\nnetwork = fully_connected(network, 4096, activation=\'tanh\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 4096, activation=\'tanh\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 17, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'momentum\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# Training\nmodel = tflearn.DNN(network, checkpoint_path=\'model_alexnet\',\n                    max_checkpoints=1, tensorboard_verbose=2)\nmodel.fit(X, Y, n_epoch=1000, validation_set=0.1, shuffle=True,\n          show_metric=True, batch_size=64, snapshot_step=200,\n          snapshot_epoch=False, run_id=\'alexnet_oxflowers17\')\n'"
examples/images/autoencoder.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Auto Encoder Example.\n\nUsing an auto encoder on MNIST handwritten digits.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\n# Building the encoder\nencoder = tflearn.input_data(shape=[None, 784])\nencoder = tflearn.fully_connected(encoder, 256)\nencoder = tflearn.fully_connected(encoder, 64)\n\n# Building the decoder\ndecoder = tflearn.fully_connected(encoder, 256)\ndecoder = tflearn.fully_connected(decoder, 784, activation=\'sigmoid\')\n\n# Regression, with mean square error\nnet = tflearn.regression(decoder, optimizer=\'adam\', learning_rate=0.001,\n                         loss=\'mean_square\', metric=None)\n\n# Training the auto encoder\nmodel = tflearn.DNN(net, tensorboard_verbose=0)\nmodel.fit(X, X, n_epoch=20, validation_set=(testX, testX),\n          run_id=""auto_encoder"", batch_size=256)\n\n# Encoding X[0] for test\nprint(""\\nTest encoding of X[0]:"")\n# New model, re-using the same session, for weights sharing\nencoding_model = tflearn.DNN(encoder, session=model.session)\nprint(encoding_model.predict([X[0]]))\n\n# Testing the image reconstruction on new data (test set)\nprint(""\\nVisualizing results after being encoded and decoded:"")\ntestX = tflearn.data_utils.shuffle(testX)[0]\n# Applying encode and decode over test set\nencode_decode = model.predict(testX)\n# Compare original images with their reconstructions\nf, a = plt.subplots(2, 10, figsize=(10, 2))\nfor i in range(10):\n    temp = [[ii, ii, ii] for ii in list(testX[i])]\n    a[0][i].imshow(np.reshape(temp, (28, 28, 3)))\n    temp = [[ii, ii, ii] for ii in list(encode_decode[i])]\n    a[1][i].imshow(np.reshape(temp, (28, 28, 3)))\nf.show()\nplt.draw()\nplt.waitforbuttonpress()\n'"
examples/images/convnet_cifar10.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Convolutional network applied to CIFAR-10 dataset classification task.\n\nReferences:\n    Learning Multiple Layers of Features from Tiny Images, A. Krizhevsky, 2009.\n\nLinks:\n    [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.data_utils import shuffle, to_categorical\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.estimator import regression\nfrom tflearn.data_preprocessing import ImagePreprocessing\nfrom tflearn.data_augmentation import ImageAugmentation\n\n# Data loading and preprocessing\nfrom tflearn.datasets import cifar10\n(X, Y), (X_test, Y_test) = cifar10.load_data()\nX, Y = shuffle(X, Y)\nY = to_categorical(Y)\nY_test = to_categorical(Y_test)\n\n# Real-time data preprocessing\nimg_prep = ImagePreprocessing()\nimg_prep.add_featurewise_zero_center()\nimg_prep.add_featurewise_stdnorm()\n\n# Real-time data augmentation\nimg_aug = ImageAugmentation()\nimg_aug.add_random_flip_leftright()\nimg_aug.add_random_rotation(max_angle=25.)\n\n# Convolutional network building\nnetwork = input_data(shape=[None, 32, 32, 3],\n                     data_preprocessing=img_prep,\n                     data_augmentation=img_aug)\nnetwork = conv_2d(network, 32, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2)\nnetwork = fully_connected(network, 512, activation=\'relu\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 10, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# Train using classifier\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=50, shuffle=True, validation_set=(X_test, Y_test),\n          show_metric=True, batch_size=96, run_id=\'cifar10_cnn\')\n'"
examples/images/convnet_highway_mnist.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Convolutional Neural Network for MNIST dataset classification task.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import highway_conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization, batch_normalization\nfrom tflearn.layers.estimator import regression\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\nX = X.reshape([-1, 28, 28, 1])\ntestX = testX.reshape([-1, 28, 28, 1])\n\n# Building convolutional network\nnetwork = input_data(shape=[None, 28, 28, 1], name=\'input\')\n#highway convolutions with pooling and dropout\nfor i in range(3):\n    for j in [3, 2, 1]: \n        network = highway_conv_2d(network, 16, j, activation=\'elu\')\n    network = max_pool_2d(network, 2)\n    network = batch_normalization(network)\n    \nnetwork = fully_connected(network, 128, activation=\'elu\')\nnetwork = fully_connected(network, 256, activation=\'elu\')\nnetwork = fully_connected(network, 10, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                     loss=\'categorical_crossentropy\', name=\'target\')\n\n# Training\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=20, validation_set=(testX, testY),\n          show_metric=True, run_id=\'convnet_highway_mnist\')\n'"
examples/images/convnet_mnist.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Convolutional Neural Network for MNIST dataset classification task.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\nX = X.reshape([-1, 28, 28, 1])\ntestX = testX.reshape([-1, 28, 28, 1])\n\n# Building convolutional network\nnetwork = input_data(shape=[None, 28, 28, 1], name=\'input\')\nnetwork = conv_2d(network, 32, 3, activation=\'relu\', regularizer=""L2"")\nnetwork = max_pool_2d(network, 2)\nnetwork = local_response_normalization(network)\nnetwork = conv_2d(network, 64, 3, activation=\'relu\', regularizer=""L2"")\nnetwork = max_pool_2d(network, 2)\nnetwork = local_response_normalization(network)\nnetwork = fully_connected(network, 128, activation=\'tanh\')\nnetwork = dropout(network, 0.8)\nnetwork = fully_connected(network, 256, activation=\'tanh\')\nnetwork = dropout(network, 0.8)\nnetwork = fully_connected(network, 10, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\', learning_rate=0.01,\n                     loss=\'categorical_crossentropy\', name=\'target\')\n\n# Training\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit({\'input\': X}, {\'target\': Y}, n_epoch=20,\n           validation_set=({\'input\': testX}, {\'target\': testY}),\n           snapshot_step=100, show_metric=True, run_id=\'convnet_mnist\')\n'"
examples/images/dcgan.py,6,"b'# -*- coding: utf-8 -*-\n"""""" DCGAN Example\n\nUse a deep convolutional generative adversarial network (DCGAN) to generate\ndigit images from a noise distribution.\n\nReferences:\n    - Unsupervised representation learning with deep convolutional generative\n    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n\nLinks:\n    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\nX = np.reshape(X, newshape=[-1, 28, 28, 1])\n\nz_dim = 200 # Noise data points\ntotal_samples = len(X)\n\n\n# Generator\ndef generator(x, reuse=False):\n    with tf.variable_scope(\'Generator\', reuse=reuse):\n        x = tflearn.fully_connected(x, n_units=7 * 7 * 128)\n        x = tflearn.batch_normalization(x)\n        x = tf.nn.tanh(x)\n        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 64, 5, activation=\'tanh\')\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 1, 5, activation=\'sigmoid\')\n        return x\n\n\n# Discriminator\ndef discriminator(x, reuse=False):\n    with tf.variable_scope(\'Discriminator\', reuse=reuse):\n        x = tflearn.conv_2d(x, 64, 5, activation=\'tanh\')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.conv_2d(x, 128, 5, activation=\'tanh\')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.fully_connected(x, 1024, activation=\'tanh\')\n        x = tflearn.fully_connected(x, 2)\n        x = tf.nn.softmax(x)\n        return x\n\n\n# Input Data\ngen_input = tflearn.input_data(shape=[None, z_dim], name=\'input_gen_noise\')\ninput_disc_noise = tflearn.input_data(shape=[None, z_dim], name=\'input_disc_noise\')\ninput_disc_real = tflearn.input_data(shape=[None, 28, 28, 1], name=\'input_disc_real\')\n\n# Build Discriminator\ndisc_fake = discriminator(generator(input_disc_noise))\ndisc_real = discriminator(input_disc_real, reuse=True)\ndisc_net = tf.concat([disc_fake, disc_real], axis=0)\n# Build Stacked Generator/Discriminator\ngen_net = generator(gen_input, reuse=True)\nstacked_gan_net = discriminator(gen_net, reuse=True)\n\n# Build Training Ops for both Generator and Discriminator.\n# Each network optimization should only update its own variable, thus we need\n# to retrieve each network variables (with get_layer_variables_by_scope).\ndisc_vars = tflearn.get_layer_variables_by_scope(\'Discriminator\')\n# We need 2 target placeholders, for both the real and fake image target.\ndisc_target = tflearn.multi_target_data([\'target_disc_fake\', \'target_disc_real\'],\n                                        shape=[None, 2])\ndisc_model = tflearn.regression(disc_net, optimizer=\'adam\',\n                                placeholder=disc_target,\n                                loss=\'categorical_crossentropy\',\n                                trainable_vars=disc_vars,\n                                batch_size=64, name=\'target_disc\',\n                                op_name=\'DISC\')\n\ngen_vars = tflearn.get_layer_variables_by_scope(\'Generator\')\ngan_model = tflearn.regression(stacked_gan_net, optimizer=\'adam\',\n                               loss=\'categorical_crossentropy\',\n                               trainable_vars=gen_vars,\n                               batch_size=64, name=\'target_gen\',\n                               op_name=\'GEN\')\n\n# Define GAN model, that output the generated images.\ngan = tflearn.DNN(gan_model)\n\n# Training\n# Prepare input data to feed to the discriminator\ndisc_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator (0: fake image, 1: real image)\ny_disc_fake = np.zeros(shape=[total_samples])\ny_disc_real = np.ones(shape=[total_samples])\ny_disc_fake = tflearn.data_utils.to_categorical(y_disc_fake, 2)\ny_disc_real = tflearn.data_utils.to_categorical(y_disc_real, 2)\n\n# Prepare input data to feed to the stacked generator/discriminator\ngen_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator\n# Generator tries to fool the discriminator, thus target is 1 (e.g. real images)\ny_gen = np.ones(shape=[total_samples])\ny_gen = tflearn.data_utils.to_categorical(y_gen, 2)\n\n# Start training, feed both noise and real images.\ngan.fit(X_inputs={\'input_gen_noise\': gen_noise,\n                  \'input_disc_noise\': disc_noise,\n                  \'input_disc_real\': X},\n        Y_targets={\'target_gen\': y_gen,\n                   \'target_disc_fake\': y_disc_fake,\n                   \'target_disc_real\': y_disc_real},\n        n_epoch=10)\n\n# Create another model from the generator graph to generate some samples\n# for testing (re-using same session to re-use the weights learnt).\ngen = tflearn.DNN(gen_net, session=gan.session)\n\nf, a = plt.subplots(4, 10, figsize=(10, 4))\nfor i in range(10):\n    # Noise input.\n    z = np.random.uniform(-1., 1., size=[4, z_dim])\n    g = np.array(gen.predict({\'input_gen_noise\': z}))\n    for j in range(4):\n        # Generate image from noise. Extend to 3 channels for matplot figure.\n        img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                         newshape=(28, 28, 3))\n        a[j][i].imshow(img)\n\nf.show()\nplt.draw()\nplt.waitforbuttonpress()\n'"
examples/images/densenet.py,0,"b'# -*- coding: utf-8 -*-\n"""""" Densely Connected Convolutional Networks.\n\nApplying a \'DenseNet\' to CIFAR-10 Dataset classification task.\n\nReferences:\n    - G. Huang, Z. Liu, K. Q. Weinberger, L. van der Maaten. Densely Connected \n        Convolutional Networks, 2016.\n\nLinks:\n    - [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n    - [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\n\n# Growth Rate (12, 16, 32, ...)\nk = 12\n\n# Depth (40, 100, ...)\nL = 40\nnb_layers = int((L - 4) / 3)\n\n# Data loading\nfrom tflearn.datasets import cifar10\n(X, Y), (testX, testY) = cifar10.load_data()\nY = tflearn.data_utils.to_categorical(Y)\ntestY = tflearn.data_utils.to_categorical(testY)\n\n# Real-time data preprocessing\nimg_prep = tflearn.ImagePreprocessing()\nimg_prep.add_featurewise_zero_center(per_channel=True)\n\n# Real-time data augmentation\nimg_aug = tflearn.ImageAugmentation()\nimg_aug.add_random_flip_leftright()\nimg_aug.add_random_crop([32, 32], padding=4)\n\n# Building Residual Network\nnet = tflearn.input_data(shape=[None, 32, 32, 3],\n                         data_preprocessing=img_prep,\n                         data_augmentation=img_aug)\nnet = tflearn.conv_2d(net, 16, 3, regularizer=\'L2\', weight_decay=0.0001)\nnet = tflearn.densenet_block(net, nb_layers, k)\nnet = tflearn.densenet_block(net, nb_layers, k)\nnet = tflearn.densenet_block(net, nb_layers, k)\nnet = tflearn.global_avg_pool(net)\n\n# Regression\nnet = tflearn.fully_connected(net, 10, activation=\'softmax\')\nopt = tflearn.Nesterov(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\nnet = tflearn.regression(net, optimizer=opt,\n                         loss=\'categorical_crossentropy\')\n# Training\nmodel = tflearn.DNN(net, checkpoint_path=\'model_densenet_cifar10\',\n                    max_checkpoints=10, tensorboard_verbose=0,\n                    clip_gradients=0.)\n\nmodel.fit(X, Y, n_epoch=200, validation_set=(testX, testY),\n          snapshot_epoch=False, snapshot_step=500,\n          show_metric=True, batch_size=128, shuffle=True,\n          run_id=\'densenet_cifar10\')\n'"
examples/images/dnn.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Deep Neural Network for MNIST dataset classification task.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\n# Building deep neural network\ninput_layer = tflearn.input_data(shape=[None, 784])\ndense1 = tflearn.fully_connected(input_layer, 64, activation=\'tanh\',\n                                 regularizer=\'L2\', weight_decay=0.001)\ndropout1 = tflearn.dropout(dense1, 0.8)\ndense2 = tflearn.fully_connected(dropout1, 64, activation=\'tanh\',\n                                 regularizer=\'L2\', weight_decay=0.001)\ndropout2 = tflearn.dropout(dense2, 0.8)\nsoftmax = tflearn.fully_connected(dropout2, 10, activation=\'softmax\')\n\n# Regression using SGD with learning rate decay and Top-3 accuracy\nsgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=1000)\ntop_k = tflearn.metrics.Top_k(3)\nnet = tflearn.regression(softmax, optimizer=sgd, metric=top_k,\n                         loss=\'categorical_crossentropy\')\n\n# Training\nmodel = tflearn.DNN(net, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=20, validation_set=(testX, testY),\n          show_metric=True, run_id=""dense_model"")\n'"
examples/images/gan.py,4,"b'# -*- coding: utf-8 -*-\n"""""" GAN Example\n\nUse a generative adversarial network (GAN) to generate digit images from a\nnoise distribution.\n\nReferences:\n    - Generative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza,\n    B Xu, D Warde-Farley, S Ozair, Y. Bengio. Advances in neural information\n    processing systems, 2672-2680.\n\nLinks:\n    - [GAN Paper](https://arxiv.org/pdf/1406.2661.pdf).\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\n\nimage_dim = 784 # 28*28 pixels\nz_dim = 200 # Noise data points\ntotal_samples = len(X)\n\n\n# Generator\ndef generator(x, reuse=False):\n    with tf.variable_scope(\'Generator\', reuse=reuse):\n        x = tflearn.fully_connected(x, 256, activation=\'relu\')\n        x = tflearn.fully_connected(x, image_dim, activation=\'sigmoid\')\n        return x\n\n\n# Discriminator\ndef discriminator(x, reuse=False):\n    with tf.variable_scope(\'Discriminator\', reuse=reuse):\n        x = tflearn.fully_connected(x, 256, activation=\'relu\')\n        x = tflearn.fully_connected(x, 1, activation=\'sigmoid\')\n        return x\n\n# Build Networks\ngen_input = tflearn.input_data(shape=[None, z_dim], name=\'input_noise\')\ndisc_input = tflearn.input_data(shape=[None, 784], name=\'disc_input\')\n\ngen_sample = generator(gen_input)\ndisc_real = discriminator(disc_input)\ndisc_fake = discriminator(gen_sample, reuse=True)\n\n# Define Loss\ndisc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\ngen_loss = -tf.reduce_mean(tf.log(disc_fake))\n\n# Build Training Ops for both Generator and Discriminator.\n# Each network optimization should only update its own variable, thus we need\n# to retrieve each network variables (with get_layer_variables_by_scope) and set\n# \'placeholder=None\' because we do not need to feed any target.\ngen_vars = tflearn.get_layer_variables_by_scope(\'Generator\')\ngen_model = tflearn.regression(gen_sample, placeholder=None, optimizer=\'adam\',\n                               loss=gen_loss, trainable_vars=gen_vars,\n                               batch_size=64, name=\'target_gen\', op_name=\'GEN\')\ndisc_vars = tflearn.get_layer_variables_by_scope(\'Discriminator\')\ndisc_model = tflearn.regression(disc_real, placeholder=None, optimizer=\'adam\',\n                                loss=disc_loss, trainable_vars=disc_vars,\n                                batch_size=64, name=\'target_disc\', op_name=\'DISC\')\n# Define GAN model, that output the generated images.\ngan = tflearn.DNN(gen_model)\n\n# Training\n# Generate noise to feed to the generator\nz = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Start training, feed both noise and real images.\ngan.fit(X_inputs={gen_input: z, disc_input: X},\n        Y_targets=None,\n        n_epoch=100)\n\n# Generate images from noise, using the generator network.\nf, a = plt.subplots(2, 10, figsize=(10, 4))\nfor i in range(10):\n    for j in range(2):\n        # Noise input.\n        z = np.random.uniform(-1., 1., size=[1, z_dim])\n        # Generate image from noise. Extend to 3 channels for matplot figure.\n        temp = [[ii, ii, ii] for ii in list(gan.predict([z])[0])]\n        a[j][i].imshow(np.reshape(temp, (28, 28, 3)))\nf.show()\nplt.draw()\nplt.waitforbuttonpress()\n'"
examples/images/googlenet.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" GoogLeNet.\nApplying \'GoogLeNet\' to Oxford\'s 17 Category Flower Dataset classification task.\nReferences:\n    - Szegedy, Christian, et al.\n    Going deeper with convolutions.\n    - 17 Category Flower Dataset. Maria-Elena Nilsback and Andrew Zisserman.\nLinks:\n    - [GoogLeNet Paper](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n    - [Flower Dataset (17)](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/)\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.merge_ops import merge\nfrom tflearn.layers.estimator import regression\n\nimport tflearn.datasets.oxflower17 as oxflower17\nX, Y = oxflower17.load_data(one_hot=True, resize_pics=(227, 227))\n\nnetwork = input_data(shape=[None, 227, 227, 3])\nconv1_7_7 = conv_2d(network, 64, 7, strides=2, activation=\'relu\', name=\'conv1_7_7_s2\')\npool1_3_3 = max_pool_2d(conv1_7_7, 3, strides=2)\npool1_3_3 = local_response_normalization(pool1_3_3)\nconv2_3_3_reduce = conv_2d(pool1_3_3, 64, 1, activation=\'relu\', name=\'conv2_3_3_reduce\')\nconv2_3_3 = conv_2d(conv2_3_3_reduce, 192, 3, activation=\'relu\', name=\'conv2_3_3\')\nconv2_3_3 = local_response_normalization(conv2_3_3)\npool2_3_3 = max_pool_2d(conv2_3_3, kernel_size=3, strides=2, name=\'pool2_3_3_s2\')\n\n# 3a\ninception_3a_1_1 = conv_2d(pool2_3_3, 64, 1, activation=\'relu\', name=\'inception_3a_1_1\')\ninception_3a_3_3_reduce = conv_2d(pool2_3_3, 96, 1, activation=\'relu\', name=\'inception_3a_3_3_reduce\')\ninception_3a_3_3 = conv_2d(inception_3a_3_3_reduce, 128, filter_size=3,  activation=\'relu\', name=\'inception_3a_3_3\')\ninception_3a_5_5_reduce = conv_2d(pool2_3_3, 16, filter_size=1, activation=\'relu\', name=\'inception_3a_5_5_reduce\')\ninception_3a_5_5 = conv_2d(inception_3a_5_5_reduce, 32, filter_size=5, activation=\'relu\', name=\'inception_3a_5_5\')\ninception_3a_pool = max_pool_2d(pool2_3_3, kernel_size=3, strides=1, name=\'inception_3a_pool\')\ninception_3a_pool_1_1 = conv_2d(inception_3a_pool, 32, filter_size=1, activation=\'relu\', name=\'inception_3a_pool_1_1\')\ninception_3a_output = merge([inception_3a_1_1, inception_3a_3_3, inception_3a_5_5, inception_3a_pool_1_1], mode=\'concat\', axis=3)\n\n# 3b\ninception_3b_1_1 = conv_2d(inception_3a_output, 128, filter_size=1, activation=\'relu\', name=\'inception_3b_1_1\')\ninception_3b_3_3_reduce = conv_2d(inception_3a_output, 128, filter_size=1, activation=\'relu\', name=\'inception_3b_3_3_reduce\')\ninception_3b_3_3 = conv_2d(inception_3b_3_3_reduce, 192, filter_size=3, activation=\'relu\', name=\'inception_3b_3_3\')\ninception_3b_5_5_reduce = conv_2d(inception_3a_output, 32, filter_size=1, activation=\'relu\', name=\'inception_3b_5_5_reduce\')\ninception_3b_5_5 = conv_2d(inception_3b_5_5_reduce, 96, filter_size=5,  name=\'inception_3b_5_5\')\ninception_3b_pool = max_pool_2d(inception_3a_output, kernel_size=3, strides=1,  name=\'inception_3b_pool\')\ninception_3b_pool_1_1 = conv_2d(inception_3b_pool, 64, filter_size=1, activation=\'relu\', name=\'inception_3b_pool_1_1\')\ninception_3b_output = merge([inception_3b_1_1, inception_3b_3_3, inception_3b_5_5, inception_3b_pool_1_1], mode=\'concat\', axis=3, name=\'inception_3b_output\')\npool3_3_3 = max_pool_2d(inception_3b_output, kernel_size=3, strides=2, name=\'pool3_3_3\')\n\n# 4a\ninception_4a_1_1 = conv_2d(pool3_3_3, 192, filter_size=1, activation=\'relu\', name=\'inception_4a_1_1\')\ninception_4a_3_3_reduce = conv_2d(pool3_3_3, 96, filter_size=1, activation=\'relu\', name=\'inception_4a_3_3_reduce\')\ninception_4a_3_3 = conv_2d(inception_4a_3_3_reduce, 208, filter_size=3,  activation=\'relu\', name=\'inception_4a_3_3\')\ninception_4a_5_5_reduce = conv_2d(pool3_3_3, 16, filter_size=1, activation=\'relu\', name=\'inception_4a_5_5_reduce\')\ninception_4a_5_5 = conv_2d(inception_4a_5_5_reduce, 48, filter_size=5,  activation=\'relu\', name=\'inception_4a_5_5\')\ninception_4a_pool = max_pool_2d(pool3_3_3, kernel_size=3, strides=1,  name=\'inception_4a_pool\')\ninception_4a_pool_1_1 = conv_2d(inception_4a_pool, 64, filter_size=1, activation=\'relu\', name=\'inception_4a_pool_1_1\')\ninception_4a_output = merge([inception_4a_1_1, inception_4a_3_3, inception_4a_5_5, inception_4a_pool_1_1], mode=\'concat\', axis=3, name=\'inception_4a_output\')\n\n# 4b\ninception_4b_1_1 = conv_2d(inception_4a_output, 160, filter_size=1, activation=\'relu\', name=\'inception_4a_1_1\')\ninception_4b_3_3_reduce = conv_2d(inception_4a_output, 112, filter_size=1, activation=\'relu\', name=\'inception_4b_3_3_reduce\')\ninception_4b_3_3 = conv_2d(inception_4b_3_3_reduce, 224, filter_size=3, activation=\'relu\', name=\'inception_4b_3_3\')\ninception_4b_5_5_reduce = conv_2d(inception_4a_output, 24, filter_size=1, activation=\'relu\', name=\'inception_4b_5_5_reduce\')\ninception_4b_5_5 = conv_2d(inception_4b_5_5_reduce, 64, filter_size=5,  activation=\'relu\', name=\'inception_4b_5_5\')\ninception_4b_pool = max_pool_2d(inception_4a_output, kernel_size=3, strides=1,  name=\'inception_4b_pool\')\ninception_4b_pool_1_1 = conv_2d(inception_4b_pool, 64, filter_size=1, activation=\'relu\', name=\'inception_4b_pool_1_1\')\ninception_4b_output = merge([inception_4b_1_1, inception_4b_3_3, inception_4b_5_5, inception_4b_pool_1_1], mode=\'concat\', axis=3, name=\'inception_4b_output\')\n\n# 4c\ninception_4c_1_1 = conv_2d(inception_4b_output, 128, filter_size=1, activation=\'relu\', name=\'inception_4c_1_1\')\ninception_4c_3_3_reduce = conv_2d(inception_4b_output, 128, filter_size=1, activation=\'relu\', name=\'inception_4c_3_3_reduce\')\ninception_4c_3_3 = conv_2d(inception_4c_3_3_reduce, 256,  filter_size=3, activation=\'relu\', name=\'inception_4c_3_3\')\ninception_4c_5_5_reduce = conv_2d(inception_4b_output, 24, filter_size=1, activation=\'relu\', name=\'inception_4c_5_5_reduce\')\ninception_4c_5_5 = conv_2d(inception_4c_5_5_reduce, 64,  filter_size=5, activation=\'relu\', name=\'inception_4c_5_5\')\ninception_4c_pool = max_pool_2d(inception_4b_output, kernel_size=3, strides=1)\ninception_4c_pool_1_1 = conv_2d(inception_4c_pool, 64, filter_size=1, activation=\'relu\', name=\'inception_4c_pool_1_1\')\ninception_4c_output = merge([inception_4c_1_1, inception_4c_3_3, inception_4c_5_5, inception_4c_pool_1_1], mode=\'concat\', axis=3, name=\'inception_4c_output\')\n\n# 4d\ninception_4d_1_1 = conv_2d(inception_4c_output, 112, filter_size=1, activation=\'relu\', name=\'inception_4d_1_1\')\ninception_4d_3_3_reduce = conv_2d(inception_4c_output, 144, filter_size=1, activation=\'relu\', name=\'inception_4d_3_3_reduce\')\ninception_4d_3_3 = conv_2d(inception_4d_3_3_reduce, 288, filter_size=3, activation=\'relu\', name=\'inception_4d_3_3\')\ninception_4d_5_5_reduce = conv_2d(inception_4c_output, 32, filter_size=1, activation=\'relu\', name=\'inception_4d_5_5_reduce\')\ninception_4d_5_5 = conv_2d(inception_4d_5_5_reduce, 64, filter_size=5,  activation=\'relu\', name=\'inception_4d_5_5\')\ninception_4d_pool = max_pool_2d(inception_4c_output, kernel_size=3, strides=1,  name=\'inception_4d_pool\')\ninception_4d_pool_1_1 = conv_2d(inception_4d_pool, 64, filter_size=1, activation=\'relu\', name=\'inception_4d_pool_1_1\')\ninception_4d_output = merge([inception_4d_1_1, inception_4d_3_3, inception_4d_5_5, inception_4d_pool_1_1], mode=\'concat\', axis=3, name=\'inception_4d_output\')\n\n# 4e\ninception_4e_1_1 = conv_2d(inception_4d_output, 256, filter_size=1, activation=\'relu\', name=\'inception_4e_1_1\')\ninception_4e_3_3_reduce = conv_2d(inception_4d_output, 160, filter_size=1, activation=\'relu\', name=\'inception_4e_3_3_reduce\')\ninception_4e_3_3 = conv_2d(inception_4e_3_3_reduce, 320, filter_size=3, activation=\'relu\', name=\'inception_4e_3_3\')\ninception_4e_5_5_reduce = conv_2d(inception_4d_output, 32, filter_size=1, activation=\'relu\', name=\'inception_4e_5_5_reduce\')\ninception_4e_5_5 = conv_2d(inception_4e_5_5_reduce, 128,  filter_size=5, activation=\'relu\', name=\'inception_4e_5_5\')\ninception_4e_pool = max_pool_2d(inception_4d_output, kernel_size=3, strides=1,  name=\'inception_4e_pool\')\ninception_4e_pool_1_1 = conv_2d(inception_4e_pool, 128, filter_size=1, activation=\'relu\', name=\'inception_4e_pool_1_1\')\ninception_4e_output = merge([inception_4e_1_1, inception_4e_3_3, inception_4e_5_5, inception_4e_pool_1_1], axis=3, mode=\'concat\')\npool4_3_3 = max_pool_2d(inception_4e_output, kernel_size=3, strides=2, name=\'pool_3_3\')\n\n# 5a\ninception_5a_1_1 = conv_2d(pool4_3_3, 256, filter_size=1, activation=\'relu\', name=\'inception_5a_1_1\')\ninception_5a_3_3_reduce = conv_2d(pool4_3_3, 160, filter_size=1, activation=\'relu\', name=\'inception_5a_3_3_reduce\')\ninception_5a_3_3 = conv_2d(inception_5a_3_3_reduce, 320, filter_size=3, activation=\'relu\', name=\'inception_5a_3_3\')\ninception_5a_5_5_reduce = conv_2d(pool4_3_3, 32, filter_size=1, activation=\'relu\', name=\'inception_5a_5_5_reduce\')\ninception_5a_5_5 = conv_2d(inception_5a_5_5_reduce, 128, filter_size=5,  activation=\'relu\', name=\'inception_5a_5_5\')\ninception_5a_pool = max_pool_2d(pool4_3_3, kernel_size=3, strides=1,  name=\'inception_5a_pool\')\ninception_5a_pool_1_1 = conv_2d(inception_5a_pool, 128, filter_size=1, activation=\'relu\', name=\'inception_5a_pool_1_1\')\ninception_5a_output = merge([inception_5a_1_1, inception_5a_3_3, inception_5a_5_5, inception_5a_pool_1_1], axis=3, mode=\'concat\')\n\n# 5b\ninception_5b_1_1 = conv_2d(inception_5a_output, 384, filter_size=1, activation=\'relu\', name=\'inception_5b_1_1\')\ninception_5b_3_3_reduce = conv_2d(inception_5a_output, 192, filter_size=1, activation=\'relu\', name=\'inception_5b_3_3_reduce\')\ninception_5b_3_3 = conv_2d(inception_5b_3_3_reduce, 384,  filter_size=3, activation=\'relu\', name=\'inception_5b_3_3\')\ninception_5b_5_5_reduce = conv_2d(inception_5a_output, 48, filter_size=1, activation=\'relu\', name=\'inception_5b_5_5_reduce\')\ninception_5b_5_5 = conv_2d(inception_5b_5_5_reduce, 128, filter_size=5, activation=\'relu\', name=\'inception_5b_5_5\')\ninception_5b_pool = max_pool_2d(inception_5a_output, kernel_size=3, strides=1,  name=\'inception_5b_pool\')\ninception_5b_pool_1_1 = conv_2d(inception_5b_pool, 128, filter_size=1, activation=\'relu\', name=\'inception_5b_pool_1_1\')\ninception_5b_output = merge([inception_5b_1_1, inception_5b_3_3, inception_5b_5_5, inception_5b_pool_1_1], axis=3, mode=\'concat\')\npool5_7_7 = avg_pool_2d(inception_5b_output, kernel_size=7, strides=1)\npool5_7_7 = dropout(pool5_7_7, 0.4)\n\n# fc\nloss = fully_connected(pool5_7_7, 17, activation=\'softmax\')\nnetwork = regression(loss, optimizer=\'momentum\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# to train\nmodel = tflearn.DNN(network, checkpoint_path=\'model_googlenet\',\n                    max_checkpoints=1, tensorboard_verbose=2)\n\nmodel.fit(X, Y, n_epoch=1000, validation_set=0.1, shuffle=True,\n          show_metric=True, batch_size=64, snapshot_step=200,\n          snapshot_epoch=False, run_id=\'googlenet_oxflowers17\')\n\n'"
examples/images/highway_dnn.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Deep Neural Network for MNIST dataset classification task using \na highway network\n\nReferences:\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n    [https://arxiv.org/abs/1505.00387](https://arxiv.org/abs/1505.00387)\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\n# Building deep neural network\ninput_layer = tflearn.input_data(shape=[None, 784])\ndense1 = tflearn.fully_connected(input_layer, 64, activation=\'elu\',\n                                 regularizer=\'L2\', weight_decay=0.001)\n                 \n                 \n#install a deep network of highway layers\nhighway = dense1                              \nfor i in range(10):\n    highway = tflearn.highway(highway, 64, activation=\'elu\',\n                              regularizer=\'L2\', weight_decay=0.001, transform_dropout=0.8)\n                              \n                              \nsoftmax = tflearn.fully_connected(highway, 10, activation=\'softmax\')\n\n# Regression using SGD with learning rate decay and Top-3 accuracy\nsgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=1000)\ntop_k = tflearn.metrics.Top_k(3)\nnet = tflearn.regression(softmax, optimizer=sgd, metric=top_k,\n                         loss=\'categorical_crossentropy\')\n\n# Training\nmodel = tflearn.DNN(net, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=20, validation_set=(testX, testY),\n          show_metric=True, run_id=""highway_dense_model"")\n'"
examples/images/inception_resnet_v2.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" inception_resnet_v2.\n\nApplying \'inception_resnet_v2\' to Oxford\'s 17 Category Flower Dataset classification task.\n\nReferences:\n    Inception-v4, Inception-ResNet and the Impact of Residual Connections\n    on Learning\n  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi.\n\nLinks:\n    http://arxiv.org/abs/1602.07261\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport tflearn\nimport tflearn.activations as activations\n# Data loading and preprocessing\nimport tflearn.datasets.oxflower17 as oxflower17\nfrom tflearn.activations import relu\nfrom tflearn.data_utils import shuffle, to_categorical\nfrom tflearn.layers.conv import avg_pool_2d, conv_2d, max_pool_2d\nfrom tflearn.layers.core import dropout, flatten, fully_connected, input_data\nfrom tflearn.layers.merge_ops import merge\nfrom tflearn.layers.normalization import batch_normalization\nfrom tflearn.utils import repeat\n\n\ndef block35(net, scale=1.0, activation=""relu""):\n    tower_conv = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    tower_conv1_0 = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None,name=\'Conv2d_0a_1x1\')))\n    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 32, 3, bias=False, activation=None,name=\'Conv2d_0b_3x3\')))\n    tower_conv2_0 = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None, name=\'Conv2d_0a_1x1\')))\n    tower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2_0, 48,3, bias=False, activation=None, name=\'Conv2d_0b_3x3\')))\n    tower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 64,3, bias=False, activation=None, name=\'Conv2d_0c_3x3\')))\n    tower_mixed = merge([tower_conv, tower_conv1_1, tower_conv2_2], mode=\'concat\', axis=3)\n    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    net += scale * tower_out\n    if activation:\n        if isinstance(activation, str):\n            net = activations.get(activation)(net)\n        elif hasattr(activation, \'__call__\'):\n            net = activation(net)\n        else:\n            raise ValueError(""Invalid Activation."")\n    return net\n\ndef block17(net, scale=1.0, activation=""relu""):\n    tower_conv = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    tower_conv_1_0 = relu(batch_normalization(conv_2d(net, 128, 1, bias=False, activation=None, name=\'Conv2d_0a_1x1\')))\n    tower_conv_1_1 = relu(batch_normalization(conv_2d(tower_conv_1_0, 160,[1,7], bias=False, activation=None,name=\'Conv2d_0b_1x7\')))\n    tower_conv_1_2 = relu(batch_normalization(conv_2d(tower_conv_1_1, 192, [7,1], bias=False, activation=None,name=\'Conv2d_0c_7x1\')))\n    tower_mixed = merge([tower_conv,tower_conv_1_2], mode=\'concat\', axis=3)\n    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    net += scale * tower_out\n    if activation:\n        if isinstance(activation, str):\n            net = activations.get(activation)(net)\n        elif hasattr(activation, \'__call__\'):\n            net = activation(net)\n        else:\n            raise ValueError(""Invalid Activation."")\n    return net\n\n\ndef block8(net, scale=1.0, activation=""relu""):\n    tower_conv = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    tower_conv1_0 = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name=\'Conv2d_0a_1x1\')))\n    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 224, [1,3], bias=False, activation=None, name=\'Conv2d_0b_1x3\')))\n    tower_conv1_2 = relu(batch_normalization(conv_2d(tower_conv1_1, 256, [3,1], bias=False, name=\'Conv2d_0c_3x1\')))\n    tower_mixed = merge([tower_conv,tower_conv1_2], mode=\'concat\', axis=3)\n    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name=\'Conv2d_1x1\')))\n    net += scale * tower_out\n    if activation:\n        if isinstance(activation, str):\n            net = activations.get(activation)(net)\n        elif hasattr(activation, \'__call__\'):\n            net = activation(net)\n        else:\n            raise ValueError(""Invalid Activation."")\n    return net\n\nX, Y = oxflower17.load_data(one_hot=True, resize_pics=(299, 299))\n\nnum_classes = 17\ndropout_keep_prob = 0.8\n\nnetwork = input_data(shape=[None, 299, 299, 3])\nconv1a_3_3 = relu(batch_normalization(conv_2d(network, 32, 3, strides=2, bias=False, padding=\'VALID\',activation=None,name=\'Conv2d_1a_3x3\')))\nconv2a_3_3 = relu(batch_normalization(conv_2d(conv1a_3_3, 32, 3, bias=False, padding=\'VALID\',activation=None, name=\'Conv2d_2a_3x3\')))\nconv2b_3_3 = relu(batch_normalization(conv_2d(conv2a_3_3, 64, 3, bias=False, activation=None, name=\'Conv2d_2b_3x3\')))\nmaxpool3a_3_3 = max_pool_2d(conv2b_3_3, 3, strides=2, padding=\'VALID\', name=\'MaxPool_3a_3x3\')\nconv3b_1_1 = relu(batch_normalization(conv_2d(maxpool3a_3_3, 80, 1, bias=False, padding=\'VALID\',activation=None, name=\'Conv2d_3b_1x1\')))\nconv4a_3_3 = relu(batch_normalization(conv_2d(conv3b_1_1, 192, 3, bias=False, padding=\'VALID\',activation=None, name=\'Conv2d_4a_3x3\')))\nmaxpool5a_3_3 = max_pool_2d(conv4a_3_3, 3, strides=2, padding=\'VALID\', name=\'MaxPool_5a_3x3\')\n\ntower_conv = relu(batch_normalization(conv_2d(maxpool5a_3_3, 96, 1, bias=False, activation=None, name=\'Conv2d_5b_b0_1x1\')))\n\ntower_conv1_0 = relu(batch_normalization(conv_2d(maxpool5a_3_3, 48, 1, bias=False, activation=None, name=\'Conv2d_5b_b1_0a_1x1\')))\ntower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 64, 5, bias=False, activation=None, name=\'Conv2d_5b_b1_0b_5x5\')))\n\ntower_conv2_0 = relu(batch_normalization(conv_2d(maxpool5a_3_3, 64, 1, bias=False, activation=None, name=\'Conv2d_5b_b2_0a_1x1\')))\ntower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2_0, 96, 3, bias=False, activation=None, name=\'Conv2d_5b_b2_0b_3x3\')))\ntower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 96, 3, bias=False, activation=None,name=\'Conv2d_5b_b2_0c_3x3\')))\n\ntower_pool3_0 = avg_pool_2d(maxpool5a_3_3, 3, strides=1, padding=\'same\', name=\'AvgPool_5b_b3_0a_3x3\')\ntower_conv3_1 = relu(batch_normalization(conv_2d(tower_pool3_0, 64, 1, bias=False, activation=None,name=\'Conv2d_5b_b3_0b_1x1\')))\n\ntower_5b_out = merge([tower_conv, tower_conv1_1, tower_conv2_2, tower_conv3_1], mode=\'concat\', axis=3)\n\nnet = repeat(tower_5b_out, 10, block35, scale=0.17)\n\ntower_conv = relu(batch_normalization(conv_2d(net, 384, 3, bias=False, strides=2,activation=None, padding=\'VALID\', name=\'Conv2d_6a_b0_0a_3x3\')))\ntower_conv1_0 = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, activation=None, name=\'Conv2d_6a_b1_0a_1x1\')))\ntower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 256, 3, bias=False, activation=None, name=\'Conv2d_6a_b1_0b_3x3\')))\ntower_conv1_2 = relu(batch_normalization(conv_2d(tower_conv1_1, 384, 3, bias=False, strides=2, padding=\'VALID\', activation=None,name=\'Conv2d_6a_b1_0c_3x3\')))\ntower_pool = max_pool_2d(net, 3, strides=2, padding=\'VALID\',name=\'MaxPool_1a_3x3\')\nnet = merge([tower_conv, tower_conv1_2, tower_pool], mode=\'concat\', axis=3)\nnet = repeat(net, 20, block17, scale=0.1)\n\ntower_conv = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, activation=None, name=\'Conv2d_0a_1x1\')))\ntower_conv0_1 = relu(batch_normalization(conv_2d(tower_conv, 384, 3, bias=False, strides=2, padding=\'VALID\', activation=None,name=\'Conv2d_0a_1x1\')))\n\ntower_conv1 = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, padding=\'VALID\', activation=None,name=\'Conv2d_0a_1x1\')))\ntower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1,288,3, bias=False, strides=2, padding=\'VALID\',activation=None, name=\'COnv2d_1a_3x3\')))\n\ntower_conv2 = relu(batch_normalization(conv_2d(net, 256,1, bias=False, activation=None,name=\'Conv2d_0a_1x1\')))\ntower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2, 288,3, bias=False, name=\'Conv2d_0b_3x3\',activation=None)))\ntower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 320, 3, bias=False, strides=2, padding=\'VALID\',activation=None, name=\'Conv2d_1a_3x3\')))\n\ntower_pool = max_pool_2d(net, 3, strides=2, padding=\'VALID\', name=\'MaxPool_1a_3x3\')\nnet = merge([tower_conv0_1, tower_conv1_1,tower_conv2_2, tower_pool], mode=\'concat\', axis=3)\n\nnet = repeat(net, 9, block8, scale=0.2)\nnet = block8(net, activation=None)\n\nnet = relu(batch_normalization(conv_2d(net, 1536, 1, bias=False, activation=None, name=\'Conv2d_7b_1x1\')))\nnet = avg_pool_2d(net, net.get_shape().as_list()[1:3],strides=2, padding=\'VALID\', name=\'AvgPool_1a_8x8\')\nnet = flatten(net)\nnet = dropout(net, dropout_keep_prob)\nloss = fully_connected(net, num_classes,activation=\'softmax\')\n\n\nnetwork = tflearn.regression(loss, optimizer=\'RMSprop\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.0001)\nmodel = tflearn.DNN(network, checkpoint_path=\'inception_resnet_v2\',\n                    max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=""./tflearn_logs/"")\nmodel.fit(X, Y, n_epoch=1000, validation_set=0.1, shuffle=True,\n          show_metric=True, batch_size=32, snapshot_step=2000,\n          snapshot_epoch=False, run_id=\'inception_resnet_v2_17flowers\')\n'"
examples/images/network_in_network.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Network In Network.\n\nApplying \'Network In Network\' to CIFAR-10 classification task.\n\nReferences:\n    Network In Network. Min Li, Qiang Chen & Shuicheng Yan, 2014.\n\nLinks:\n    http://arxiv.org/pdf/1312.4400v3.pdf\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.data_utils import shuffle, to_categorical\nfrom tflearn.layers.core import input_data, dropout, flatten\nfrom tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2d\nfrom tflearn.layers.estimator import regression\n\n# Data loading and preprocessing\nfrom tflearn.datasets import cifar10\n(X, Y), (X_test, Y_test) = cifar10.load_data()\nX, Y = shuffle(X, Y)\nY = to_categorical(Y)\nY_test = to_categorical(Y_test)\n\n# Building \'Network In Network\'\nnetwork = input_data(shape=[None, 32, 32, 3])\nnetwork = conv_2d(network, 192, 5, activation=\'relu\')\nnetwork = conv_2d(network, 160, 1, activation=\'relu\')\nnetwork = conv_2d(network, 96, 1, activation=\'relu\')\nnetwork = max_pool_2d(network, 3, strides=2)\nnetwork = dropout(network, 0.5)\nnetwork = conv_2d(network, 192, 5, activation=\'relu\')\nnetwork = conv_2d(network, 192, 1, activation=\'relu\')\nnetwork = conv_2d(network, 192, 1, activation=\'relu\')\nnetwork = avg_pool_2d(network, 3, strides=2)\nnetwork = dropout(network, 0.5)\nnetwork = conv_2d(network, 192, 3, activation=\'relu\')\nnetwork = conv_2d(network, 192, 1, activation=\'relu\')\nnetwork = conv_2d(network, 10, 1, activation=\'relu\')\nnetwork = avg_pool_2d(network, 8)\nnetwork = flatten(network)\nnetwork = regression(network, optimizer=\'adam\',\n                     loss=\'softmax_categorical_crossentropy\',\n                     learning_rate=0.001)\n\n# Training\nmodel = tflearn.DNN(network)\nmodel.fit(X, Y, n_epoch=50, shuffle=True, validation_set=(X_test, Y_test),\n          show_metric=True, batch_size=128, run_id=\'cifar10_net_in_net\')\n'"
examples/images/residual_network_cifar10.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Deep Residual Network.\n\nApplying a Deep Residual Network to CIFAR-10 Dataset classification task.\n\nReferences:\n    - K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image\n      Recognition, 2015.\n    - Learning Multiple Layers of Features from Tiny Images, A. Krizhevsky, 2009.\n\nLinks:\n    - [Deep Residual Network](http://arxiv.org/pdf/1512.03385.pdf)\n    - [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\n\n# Residual blocks\n# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18\nn = 5\n\n# Data loading\nfrom tflearn.datasets import cifar10\n(X, Y), (testX, testY) = cifar10.load_data()\nY = tflearn.data_utils.to_categorical(Y)\ntestY = tflearn.data_utils.to_categorical(testY)\n\n# Real-time data preprocessing\nimg_prep = tflearn.ImagePreprocessing()\nimg_prep.add_featurewise_zero_center(per_channel=True)\n\n# Real-time data augmentation\nimg_aug = tflearn.ImageAugmentation()\nimg_aug.add_random_flip_leftright()\nimg_aug.add_random_crop([32, 32], padding=4)\n\n# Building Residual Network\nnet = tflearn.input_data(shape=[None, 32, 32, 3],\n                         data_preprocessing=img_prep,\n                         data_augmentation=img_aug)\nnet = tflearn.conv_2d(net, 16, 3, regularizer=\'L2\', weight_decay=0.0001)\nnet = tflearn.residual_block(net, n, 16)\nnet = tflearn.residual_block(net, 1, 32, downsample=True)\nnet = tflearn.residual_block(net, n-1, 32)\nnet = tflearn.residual_block(net, 1, 64, downsample=True)\nnet = tflearn.residual_block(net, n-1, 64)\nnet = tflearn.batch_normalization(net)\nnet = tflearn.activation(net, \'relu\')\nnet = tflearn.global_avg_pool(net)\n# Regression\nnet = tflearn.fully_connected(net, 10, activation=\'softmax\')\nmom = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\nnet = tflearn.regression(net, optimizer=mom,\n                         loss=\'categorical_crossentropy\')\n# Training\nmodel = tflearn.DNN(net, checkpoint_path=\'model_resnet_cifar10\',\n                    max_checkpoints=10, tensorboard_verbose=0,\n                    clip_gradients=0.)\n\nmodel.fit(X, Y, n_epoch=200, validation_set=(testX, testY),\n          snapshot_epoch=False, snapshot_step=500,\n          show_metric=True, batch_size=128, shuffle=True,\n          run_id=\'resnet_cifar10\')\n'"
examples/images/residual_network_mnist.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Deep Residual Network.\n\nApplying a Deep Residual Network to MNIST Dataset classification task.\n\nReferences:\n    - K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image\n      Recognition, 2015.\n    - Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n      learning applied to document recognition."" Proceedings of the IEEE,\n      86(11):2278-2324, November 1998.\n\nLinks:\n    - [Deep Residual Network](http://arxiv.org/pdf/1512.03385.pdf)\n    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nimport tflearn.data_utils as du\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\nX = X.reshape([-1, 28, 28, 1])\ntestX = testX.reshape([-1, 28, 28, 1])\nX, mean = du.featurewise_zero_center(X)\ntestX = du.featurewise_zero_center(testX, mean)\n\n# Building Residual Network\nnet = tflearn.input_data(shape=[None, 28, 28, 1])\nnet = tflearn.conv_2d(net, 64, 3, activation=\'relu\', bias=False)\n# Residual blocks\nnet = tflearn.residual_bottleneck(net, 3, 16, 64)\nnet = tflearn.residual_bottleneck(net, 1, 32, 128, downsample=True)\nnet = tflearn.residual_bottleneck(net, 2, 32, 128)\nnet = tflearn.residual_bottleneck(net, 1, 64, 256, downsample=True)\nnet = tflearn.residual_bottleneck(net, 2, 64, 256)\nnet = tflearn.batch_normalization(net)\nnet = tflearn.activation(net, \'relu\')\nnet = tflearn.global_avg_pool(net)\n# Regression\nnet = tflearn.fully_connected(net, 10, activation=\'softmax\')\nnet = tflearn.regression(net, optimizer=\'momentum\',\n                         loss=\'categorical_crossentropy\',\n                         learning_rate=0.1)\n# Training\nmodel = tflearn.DNN(net, checkpoint_path=\'model_resnet_mnist\',\n                    max_checkpoints=10, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=100, validation_set=(testX, testY),\n          show_metric=True, batch_size=256, run_id=\'resnet_mnist\')\n'"
examples/images/resnext_cifar10.py,0,"b'# -*- coding: utf-8 -*-\n"""""" Aggregated Residual Transformations for Deep Neural Network.\n\nApplying a \'ResNeXT\' to CIFAR-10 Dataset classification task.\n\nReferences:\n    - S. Xie, R. Girshick, P. Dollar, Z. Tu and K. He. Aggregated Residual\n        Transformations for Deep Neural Networks, 2016.\n\nLinks:\n    - [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf)\n    - [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\n\n# Residual blocks\n# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18\nn = 5\n\n# Data loading\nfrom tflearn.datasets import cifar10\n(X, Y), (testX, testY) = cifar10.load_data()\nY = tflearn.data_utils.to_categorical(Y)\ntestY = tflearn.data_utils.to_categorical(testY)\n\n# Real-time data preprocessing\nimg_prep = tflearn.ImagePreprocessing()\nimg_prep.add_featurewise_zero_center(per_channel=True)\n\n# Real-time data augmentation\nimg_aug = tflearn.ImageAugmentation()\nimg_aug.add_random_flip_leftright()\nimg_aug.add_random_crop([32, 32], padding=4)\n\n# Building Residual Network\nnet = tflearn.input_data(shape=[None, 32, 32, 3],\n                         data_preprocessing=img_prep,\n                         data_augmentation=img_aug)\nnet = tflearn.conv_2d(net, 16, 3, regularizer=\'L2\', weight_decay=0.0001)\nnet = tflearn.resnext_block(net, n, 16, 32)\nnet = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\nnet = tflearn.resnext_block(net, n-1, 32, 32)\nnet = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\nnet = tflearn.resnext_block(net, n-1, 64, 32)\nnet = tflearn.batch_normalization(net)\nnet = tflearn.activation(net, \'relu\')\nnet = tflearn.global_avg_pool(net)\n# Regression\nnet = tflearn.fully_connected(net, 10, activation=\'softmax\')\nopt = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\nnet = tflearn.regression(net, optimizer=opt,\n                         loss=\'categorical_crossentropy\')\n# Training\nmodel = tflearn.DNN(net, checkpoint_path=\'model_resnext_cifar10\',\n                    max_checkpoints=10, tensorboard_verbose=0,\n                    clip_gradients=0.)\n\nmodel.fit(X, Y, n_epoch=200, validation_set=(testX, testY),\n          snapshot_epoch=False, snapshot_step=500,\n          show_metric=True, batch_size=128, shuffle=True,\n          run_id=\'resnext_cifar10\')\n'"
examples/images/rnn_pixels.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nMNIST Classification using RNN over images pixels. A picture is\nrepresentated as a sequence of pixels, coresponding to an image\'s\nwidth (timestep) and height (number of sequences).\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport tflearn\n\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\nX = np.reshape(X, (-1, 28, 28))\ntestX = np.reshape(testX, (-1, 28, 28))\n\nnet = tflearn.input_data(shape=[None, 28, 28])\nnet = tflearn.lstm(net, 128, return_seq=True)\nnet = tflearn.lstm(net, 128)\nnet = tflearn.fully_connected(net, 10, activation=\'softmax\')\nnet = tflearn.regression(net, optimizer=\'adam\',\n                         loss=\'categorical_crossentropy\', name=""output1"")\nmodel = tflearn.DNN(net, tensorboard_verbose=2)\nmodel.fit(X, Y, n_epoch=1, validation_set=0.1, show_metric=True,\n          snapshot_step=100)\n'"
examples/images/variational_autoencoder.py,8,"b'# -*- coding: utf-8 -*-\n\n"""""" Variational Auto-Encoder Example.\n\nUsing a variational auto-encoder to generate digits images from noise.\nMNIST handwritten digits are used as training examples.\n\nReferences:\n    - Auto-Encoding Variational Bayes The International Conference on Learning\n    Representations (ICLR), Banff, 2014. D.P. Kingma, M. Welling\n    - Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    - [VAE Paper] https://arxiv.org/abs/1312.6114\n    - [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport tensorflow as tf\n\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data(one_hot=True)\n\n# Params\noriginal_dim = 784 # MNIST images are 28x28 pixels\nhidden_dim = 256\nlatent_dim = 2\n\n# Building the encoder\nencoder = tflearn.input_data(shape=[None, 784], name=\'input_images\')\nencoder = tflearn.fully_connected(encoder, hidden_dim, activation=\'relu\')\nz_mean = tflearn.fully_connected(encoder, latent_dim)\nz_std = tflearn.fully_connected(encoder, latent_dim)\n\n# Sampler: Normal (gaussian) random distribution\neps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n                       name=\'epsilon\')\nz = z_mean + tf.exp(z_std / 2) * eps\n\n# Building the decoder (with scope to re-use these layers later)\ndecoder = tflearn.fully_connected(z, hidden_dim, activation=\'relu\',\n                                  scope=\'decoder_h\')\ndecoder = tflearn.fully_connected(decoder, original_dim, activation=\'sigmoid\',\n                                  scope=\'decoder_out\')\n\n# Define VAE Loss\ndef vae_loss(x_reconstructed, x_true):\n    # Reconstruction loss\n    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n    # KL Divergence loss\n    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n\nnet = tflearn.regression(decoder, optimizer=\'rmsprop\', learning_rate=0.001,\n                         loss=vae_loss, metric=None, name=\'target_images\')\n\n# We will need 2 models, one for training that will learn the latent\n# representation, and one that can take random normal noise as input and\n# use the decoder part of the network to generate an image\n\n# Train the VAE\ntraining_model = tflearn.DNN(net, tensorboard_verbose=0)\ntraining_model.fit({\'input_images\': X}, {\'target_images\': X}, n_epoch=100,\n                   validation_set=(testX, testX), batch_size=256, run_id=""vae"")\n\n# Build an image generator (re-using the decoding layers)\n# Input data is a normal (gaussian) random distribution (with dim = latent_dim)\ninput_noise = tflearn.input_data(shape=[None, latent_dim], name=\'input_noise\')\ndecoder = tflearn.fully_connected(input_noise, hidden_dim, activation=\'relu\',\n                                  scope=\'decoder_h\', reuse=True)\ndecoder = tflearn.fully_connected(decoder, original_dim, activation=\'sigmoid\',\n                                  scope=\'decoder_out\', reuse=True)\ngenerator_model = tflearn.DNN(decoder, session=training_model.session)\n\n# Building a manifold of generated digits\nn = 25 # Figure row size\nfigure = np.zeros((28 * n, 28 * n))\n# Random normal distributions to feed network with\nx_axis = norm.ppf(np.linspace(0., 1., n))\ny_axis = norm.ppf(np.linspace(0., 1., n))\n\nfor i, x in enumerate(x_axis):\n    for j, y in enumerate(y_axis):\n        samples = np.array([[x, y]])\n        x_reconstructed = generator_model.predict({\'input_noise\': samples})\n        digit = np.array(x_reconstructed[0]).reshape(28, 28)\n        figure[i * 28: (i + 1) * 28, j * 28: (j + 1) * 28] = digit\n\nplt.figure(figsize=(10, 10))\nplt.imshow(figure, cmap=\'Greys_r\')\nplt.show()\n'"
examples/images/vgg_network.py,0,"b'# -*- coding: utf-8 -*-\n\n"""""" Very Deep Convolutional Networks for Large-Scale Visual Recognition.\n\nApplying VGG 16-layers convolutional network to Oxford\'s 17 Category Flower\nDataset classification task.\n\nReferences:\n    Very Deep Convolutional Networks for Large-Scale Image Recognition.\n    K. Simonyan, A. Zisserman. arXiv technical report, 2014.\n\nLinks:\n    http://arxiv.org/pdf/1409.1556\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.estimator import regression\n\n# Data loading and preprocessing\nimport tflearn.datasets.oxflower17 as oxflower17\nX, Y = oxflower17.load_data(one_hot=True)\n\n# Building \'VGG Network\'\nnetwork = input_data(shape=[None, 224, 224, 3])\n\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = conv_2d(network, 64, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2, strides=2)\n\nnetwork = conv_2d(network, 128, 3, activation=\'relu\')\nnetwork = conv_2d(network, 128, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2, strides=2)\n\nnetwork = conv_2d(network, 256, 3, activation=\'relu\')\nnetwork = conv_2d(network, 256, 3, activation=\'relu\')\nnetwork = conv_2d(network, 256, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2, strides=2)\n\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2, strides=2)\n\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = conv_2d(network, 512, 3, activation=\'relu\')\nnetwork = max_pool_2d(network, 2, strides=2)\n\nnetwork = fully_connected(network, 4096, activation=\'relu\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 4096, activation=\'relu\')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 17, activation=\'softmax\')\n\nnetwork = regression(network, optimizer=\'rmsprop\',\n                     loss=\'categorical_crossentropy\',\n                     learning_rate=0.0001)\n\n# Training\nmodel = tflearn.DNN(network, checkpoint_path=\'model_vgg\',\n                    max_checkpoints=1, tensorboard_verbose=0)\nmodel.fit(X, Y, n_epoch=500, shuffle=True,\n          show_metric=True, batch_size=32, snapshot_step=500,\n          snapshot_epoch=False, run_id=\'vgg_oxflowers17\')\n'"
examples/images/vgg_network_finetuning.py,0,"b'# -*- coding: utf-8 -*-\n\'\'\'\nRetraining (Finetuning) Example with vgg.tflearn. Using weights from VGG model to retrain\nnetwork for a new task (your own dataset).All weights are restored except\nlast layer (softmax) that will be retrained to match the new task (finetuning).\n\'\'\'\nimport tflearn\nfrom tflearn.data_preprocessing import ImagePreprocessing\nimport os\n\n\ndef vgg16(input, num_class):\n\n    x = tflearn.conv_2d(input, 64, 3, activation=\'relu\', scope=\'conv1_1\')\n    x = tflearn.conv_2d(x, 64, 3, activation=\'relu\', scope=\'conv1_2\')\n    x = tflearn.max_pool_2d(x, 2, strides=2, name=\'maxpool1\')\n\n    x = tflearn.conv_2d(x, 128, 3, activation=\'relu\', scope=\'conv2_1\')\n    x = tflearn.conv_2d(x, 128, 3, activation=\'relu\', scope=\'conv2_2\')\n    x = tflearn.max_pool_2d(x, 2, strides=2, name=\'maxpool2\')\n\n    x = tflearn.conv_2d(x, 256, 3, activation=\'relu\', scope=\'conv3_1\')\n    x = tflearn.conv_2d(x, 256, 3, activation=\'relu\', scope=\'conv3_2\')\n    x = tflearn.conv_2d(x, 256, 3, activation=\'relu\', scope=\'conv3_3\')\n    x = tflearn.max_pool_2d(x, 2, strides=2, name=\'maxpool3\')\n\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv4_1\')\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv4_2\')\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv4_3\')\n    x = tflearn.max_pool_2d(x, 2, strides=2, name=\'maxpool4\')\n\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv5_1\')\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv5_2\')\n    x = tflearn.conv_2d(x, 512, 3, activation=\'relu\', scope=\'conv5_3\')\n    x = tflearn.max_pool_2d(x, 2, strides=2, name=\'maxpool5\')\n\n    x = tflearn.fully_connected(x, 4096, activation=\'relu\', scope=\'fc6\')\n    x = tflearn.dropout(x, 0.5, name=\'dropout1\')\n\n    x = tflearn.fully_connected(x, 4096, activation=\'relu\', scope=\'fc7\')\n    x = tflearn.dropout(x, 0.5, name=\'dropout2\')\n\n    x = tflearn.fully_connected(x, num_class, activation=\'softmax\', scope=\'fc8\',\n                                restore=False)\n\n    return x\n\n\ndata_dir = ""/path/to/your/data""\nmodel_path = ""/path/to/your/vgg_model""\n# the file gen by generated by gen_files_list.py\nfiles_list = ""/path/to/your/file/with/images""\n\nfrom tflearn.data_utils import image_preloader\n\nX, Y = image_preloader(files_list, image_shape=(224, 224), mode=\'file\',\n                       categorical_labels=True, normalize=False,\n                       files_extension=[\'.jpg\', \'.png\'], filter_channel=True)\n# or use the mode \'floder\'\n# X, Y = image_preloader(data_dir, image_shape=(224, 224), mode=\'folder\',\n#                        categorical_labels=True, normalize=True,\n#                        files_extension=[\'.jpg\', \'.png\'], filter_channel=True)\n\nnum_classes = 10 # num of your dataset\n\n# VGG preprocessing\nimg_prep = ImagePreprocessing()\nimg_prep.add_featurewise_zero_center(mean=[123.68, 116.779, 103.939],\n                                     per_channel=True)\n# VGG Network\nx = tflearn.input_data(shape=[None, 224, 224, 3], name=\'input\',\n                       data_preprocessing=img_prep)\nsoftmax = vgg16(x, num_classes)\nregression = tflearn.regression(softmax, optimizer=\'adam\',\n                                loss=\'categorical_crossentropy\',\n                                learning_rate=0.001, restore=False)\n\nmodel = tflearn.DNN(regression, checkpoint_path=\'vgg-finetuning\',\n                    max_checkpoints=3, tensorboard_verbose=2,\n                    tensorboard_dir=""./logs"")\n\nmodel_file = os.path.join(model_path, ""vgg16.tflearn"")\nmodel.load(model_file, weights_only=True)\n\n# Start finetuning\nmodel.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n          show_metric=True, batch_size=64, snapshot_epoch=False,\n          snapshot_step=200, run_id=\'vgg-finetuning\')\n\nmodel.save(\'your-task-model-retrained-by-vgg\')\n'"
examples/nlp/bidirectional_lstm.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nSimple example using LSTM recurrent neural network to classify IMDB\nsentiment dataset.\n\nReferences:\n    - Long Short Term Memory, Sepp Hochreiter & Jurgen Schmidhuber, Neural\n    Computation 9(8): 1735-1780, 1997.\n    - Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng,\n    and Christopher Potts. (2011). Learning Word Vectors for Sentiment\n    Analysis. The 49th Annual Meeting of the Association for Computational\n    Linguistics (ACL 2011).\n\nLinks:\n    - http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n    - http://ai.stanford.edu/~amaas/data/sentiment/\n\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.data_utils import to_categorical, pad_sequences\nfrom tflearn.datasets import imdb\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.embedding_ops import embedding\nfrom tflearn.layers.recurrent import bidirectional_rnn, BasicLSTMCell\nfrom tflearn.layers.estimator import regression\n\n# IMDB Dataset loading\ntrain, test, _ = imdb.load_data(path=\'imdb.pkl\', n_words=10000,\n                                valid_portion=0.1)\ntrainX, trainY = train\ntestX, testY = test\n\n# Data preprocessing\n# Sequence padding\ntrainX = pad_sequences(trainX, maxlen=200, value=0.)\ntestX = pad_sequences(testX, maxlen=200, value=0.)\n# Converting labels to binary vectors\ntrainY = to_categorical(trainY)\ntestY = to_categorical(testY)\n\n# Network building\nnet = input_data(shape=[None, 200])\nnet = embedding(net, input_dim=20000, output_dim=128)\nnet = bidirectional_rnn(net, BasicLSTMCell(128), BasicLSTMCell(128))\nnet = dropout(net, 0.5)\nnet = fully_connected(net, 2, activation=\'softmax\')\nnet = regression(net, optimizer=\'adam\', loss=\'categorical_crossentropy\')\n\n# Training\nmodel = tflearn.DNN(net, clip_gradients=0., tensorboard_verbose=2)\nmodel.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=64)\n'"
examples/nlp/cnn_sentence_classification.py,1,"b'# -*- coding: utf-8 -*-\n""""""\nSimple example using convolutional neural network to classify IMDB\nsentiment dataset.\n\nReferences:\n    - Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng,\n    and Christopher Potts. (2011). Learning Word Vectors for Sentiment\n    Analysis. The 49th Annual Meeting of the Association for Computational\n    Linguistics (ACL 2011).\n    - Kim Y. Convolutional Neural Networks for Sentence Classification[C]. \n    Empirical Methods in Natural Language Processing, 2014.\n\nLinks:\n    - http://ai.stanford.edu/~amaas/data/sentiment/\n    - http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_1d, global_max_pool\nfrom tflearn.layers.merge_ops import merge\nfrom tflearn.layers.estimator import regression\nfrom tflearn.data_utils import to_categorical, pad_sequences\nfrom tflearn.datasets import imdb\n\n# IMDB Dataset loading\ntrain, test, _ = imdb.load_data(path=\'imdb.pkl\', n_words=10000,\n                                valid_portion=0.1)\ntrainX, trainY = train\ntestX, testY = test\n\n# Data preprocessing\n# Sequence padding\ntrainX = pad_sequences(trainX, maxlen=100, value=0.)\ntestX = pad_sequences(testX, maxlen=100, value=0.)\n# Converting labels to binary vectors\ntrainY = to_categorical(trainY)\ntestY = to_categorical(testY)\n\n# Building convolutional network\nnetwork = input_data(shape=[None, 100], name=\'input\')\nnetwork = tflearn.embedding(network, input_dim=10000, output_dim=128)\nbranch1 = conv_1d(network, 128, 3, padding=\'valid\', activation=\'relu\', regularizer=""L2"")\nbranch2 = conv_1d(network, 128, 4, padding=\'valid\', activation=\'relu\', regularizer=""L2"")\nbranch3 = conv_1d(network, 128, 5, padding=\'valid\', activation=\'relu\', regularizer=""L2"")\nnetwork = merge([branch1, branch2, branch3], mode=\'concat\', axis=1)\nnetwork = tf.expand_dims(network, 2)\nnetwork = global_max_pool(network)\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 2, activation=\'softmax\')\nnetwork = regression(network, optimizer=\'adam\', learning_rate=0.001,\n                     loss=\'categorical_crossentropy\', name=\'target\')\n# Training\nmodel = tflearn.DNN(network, tensorboard_verbose=0)\nmodel.fit(trainX, trainY, n_epoch = 5, shuffle=True, validation_set=(testX, testY), show_metric=True, batch_size=32)\n'"
examples/nlp/dynamic_lstm.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nSimple example using a Dynamic RNN (LSTM) to classify IMDB sentiment dataset.\nDynamic computation are performed over sequences with variable length.\n\nReferences:\n    - Long Short Term Memory, Sepp Hochreiter & Jurgen Schmidhuber, Neural\n    Computation 9(8): 1735-1780, 1997.\n    - Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng,\n    and Christopher Potts. (2011). Learning Word Vectors for Sentiment\n    Analysis. The 49th Annual Meeting of the Association for Computational\n    Linguistics (ACL 2011).\n\nLinks:\n    - http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n    - http://ai.stanford.edu/~amaas/data/sentiment/\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.data_utils import to_categorical, pad_sequences\nfrom tflearn.datasets import imdb\n\n# IMDB Dataset loading\ntrain, test, _ = imdb.load_data(path=\'imdb.pkl\', n_words=10000,\n                                valid_portion=0.1)\ntrainX, trainY = train\ntestX, testY = test\n\n# Data preprocessing\n# NOTE: Padding is required for dimension consistency. This will pad sequences\n# with 0 at the end, until it reaches the max sequence length. 0 is used as a\n# masking value by dynamic RNNs in TFLearn; a sequence length will be\n# retrieved by counting non zero elements in a sequence. Then dynamic RNN step\n# computation is performed according to that length.\ntrainX = pad_sequences(trainX, maxlen=100, value=0.)\ntestX = pad_sequences(testX, maxlen=100, value=0.)\n# Converting labels to binary vectors\ntrainY = to_categorical(trainY)\ntestY = to_categorical(testY)\n\n# Network building\nnet = tflearn.input_data([None, 100])\n# Masking is not required for embedding, sequence length is computed prior to\n# the embedding op and assigned as \'seq_length\' attribute to the returned Tensor.\nnet = tflearn.embedding(net, input_dim=10000, output_dim=128)\nnet = tflearn.lstm(net, 128, dropout=0.8, dynamic=True)\nnet = tflearn.fully_connected(net, 2, activation=\'softmax\')\nnet = tflearn.regression(net, optimizer=\'adam\', learning_rate=0.001,\n                         loss=\'categorical_crossentropy\')\n\n# Training\nmodel = tflearn.DNN(net, tensorboard_verbose=0)\nmodel.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n          batch_size=32)\n'"
examples/nlp/lstm.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nSimple example using LSTM recurrent neural network to classify IMDB\nsentiment dataset.\n\nReferences:\n    - Long Short Term Memory, Sepp Hochreiter & Jurgen Schmidhuber, Neural\n    Computation 9(8): 1735-1780, 1997.\n    - Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng,\n    and Christopher Potts. (2011). Learning Word Vectors for Sentiment\n    Analysis. The 49th Annual Meeting of the Association for Computational\n    Linguistics (ACL 2011).\n\nLinks:\n    - http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n    - http://ai.stanford.edu/~amaas/data/sentiment/\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tflearn\nfrom tflearn.data_utils import to_categorical, pad_sequences\nfrom tflearn.datasets import imdb\n\n# IMDB Dataset loading\ntrain, test, _ = imdb.load_data(path=\'imdb.pkl\', n_words=10000,\n                                valid_portion=0.1)\ntrainX, trainY = train\ntestX, testY = test\n\n# Data preprocessing\n# Sequence padding\ntrainX = pad_sequences(trainX, maxlen=100, value=0.)\ntestX = pad_sequences(testX, maxlen=100, value=0.)\n# Converting labels to binary vectors\ntrainY = to_categorical(trainY)\ntestY = to_categorical(testY)\n\n# Network building\nnet = tflearn.input_data([None, 100])\nnet = tflearn.embedding(net, input_dim=10000, output_dim=128)\nnet = tflearn.lstm(net, 128, dropout=0.8)\nnet = tflearn.fully_connected(net, 2, activation=\'softmax\')\nnet = tflearn.regression(net, optimizer=\'adam\', learning_rate=0.001,\n                         loss=\'categorical_crossentropy\')\n\n# Training\nmodel = tflearn.DNN(net, tensorboard_verbose=0)\nmodel.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n          batch_size=32)\n'"
examples/nlp/lstm_generator_cityname.py,0,"b'from __future__ import absolute_import, division, print_function\n\nimport os\nfrom six import moves\nimport ssl\n\nimport tflearn\nfrom tflearn.data_utils import *\n\npath = ""US_Cities.txt""\nif not os.path.isfile(path):\n    context = ssl._create_unverified_context()\n    moves.urllib.request.urlretrieve(""https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/US_Cities.txt"", path, context=context)\n\nmaxlen = 20\n\nstring_utf8 = open(path, ""r"").read().decode(\'utf-8\')\nX, Y, char_idx = \\\n    string_to_semi_redundant_sequences(string_utf8, seq_maxlen=maxlen, redun_step=3)\n\ng = tflearn.input_data(shape=[None, maxlen, len(char_idx)])\ng = tflearn.lstm(g, 512, return_seq=True)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.lstm(g, 512)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.fully_connected(g, len(char_idx), activation=\'softmax\')\ng = tflearn.regression(g, optimizer=\'adam\', loss=\'categorical_crossentropy\',\n                       learning_rate=0.001)\n\nm = tflearn.SequenceGenerator(g, dictionary=char_idx,\n                              seq_maxlen=maxlen,\n                              clip_gradients=5.0,\n                              checkpoint_path=\'model_us_cities\')\n\nfor i in range(40):\n    seed = random_sequence_from_string(string_utf8, maxlen)\n    m.fit(X, Y, validation_set=0.1, batch_size=128,\n          n_epoch=1, run_id=\'us_cities\')\n    print(""-- TESTING..."")\n    print(""-- Test with temperature of 1.2 --"")\n    print(m.generate(30, temperature=1.2, seq_seed=seed).encode(\'utf-8\'))\n    print(""-- Test with temperature of 1.0 --"")\n    print(m.generate(30, temperature=1.0, seq_seed=seed).encode(\'utf-8\'))\n    print(""-- Test with temperature of 0.5 --"")\n    print(m.generate(30, temperature=0.5, seq_seed=seed).encode(\'utf-8\'))\n'"
examples/nlp/lstm_generator_shakespeare.py,0,"b'from __future__ import absolute_import, division, print_function\n\nimport os\nimport pickle\nfrom six.moves import urllib\n\nimport tflearn\nfrom tflearn.data_utils import *\n\npath = ""shakespeare_input.txt""\nchar_idx_file = \'char_idx.pickle\'\n\nif not os.path.isfile(path):\n    urllib.request.urlretrieve(""https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/shakespeare_input.txt"", path)\n\nmaxlen = 25\n\nchar_idx = None\nif os.path.isfile(char_idx_file):\n  print(\'Loading previous char_idx\')\n  char_idx = pickle.load(open(char_idx_file, \'rb\'))\n\nX, Y, char_idx = \\\n    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3,\n                                         pre_defined_char_idx=char_idx)\n\npickle.dump(char_idx, open(char_idx_file,\'wb\'))\n\ng = tflearn.input_data([None, maxlen, len(char_idx)])\ng = tflearn.lstm(g, 512, return_seq=True)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.lstm(g, 512, return_seq=True)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.lstm(g, 512)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.fully_connected(g, len(char_idx), activation=\'softmax\')\ng = tflearn.regression(g, optimizer=\'adam\', loss=\'categorical_crossentropy\',\n                       learning_rate=0.001)\n\nm = tflearn.SequenceGenerator(g, dictionary=char_idx,\n                              seq_maxlen=maxlen,\n                              clip_gradients=5.0,\n                              checkpoint_path=\'model_shakespeare\')\n\nfor i in range(50):\n    seed = random_sequence_from_textfile(path, maxlen)\n    m.fit(X, Y, validation_set=0.1, batch_size=128,\n          n_epoch=1, run_id=\'shakespeare\')\n    print(""-- TESTING..."")\n    print(""-- Test with temperature of 1.0 --"")\n    print(m.generate(600, temperature=1.0, seq_seed=seed))\n    print(""-- Test with temperature of 0.5 --"")\n    print(m.generate(600, temperature=0.5, seq_seed=seed))\n'"
examples/nlp/lstm_generator_textfile.py,0,"b'from __future__ import absolute_import, division, print_function\n\nimport os, sys, argparse\nimport urllib\n\nimport tflearn\nfrom tflearn.data_utils import *\n\nparser = argparse.ArgumentParser(description=\n    \'Pass a text file to generate LSTM output\')\n\nparser.add_argument(\'filename\')\nparser.add_argument(\'-t\',\'--temp\', help=\n    \'Defaults to displaying multiple temperature outputs which is suggested.\' +\n    \' If temp is specified, a value of 0.0 to 2.0 is recommended.\' +\n    \' Temperature is the novelty or\' +\n    \' riskiness of the generated output.  A value closer to 0 will result\' +\n    \' in output closer to the input, so higher is riskier.\', \n    required=False, nargs=1, type=float)\nparser.add_argument(\'-l\',\'--length\', help=\n    \'Optional length of text sequences to analyze.  Defaults to 25.\',\n    required=False, default=25, nargs=1, type=int)\n\nargs = vars(parser.parse_args())\n\npath = args[\'filename\']\nif args[\'temp\'] and args[\'temp\'][0] is not None:\n    temp = args[\'temp\'][0]\n    print(""Temperature set to"", temp)\n    if temp > 2 or temp < 0:\n        print(""Temperature out of suggested range.  Suggested temp range is 0.0-2.0"") \n    else:\n        print(""Will display multiple temperature outputs"")\n\nif args[\'length\'] is not 25: \n    maxlen = args[\'length\'][0] # default 25 is set in .add_argument above if not set by user\n    print(""Sequence max length set to "", maxlen)\nelse:\n    maxlen = args[\'length\']\nmodel_name=path.split(\'.\')[0]  # create model name from textfile input\n\nif not os.path.isfile(path):\n    print(""Couldn\'t find the text file. Are you sure the you passed is correct?"")\n\nX, Y, char_idx = \\\n    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3)\n\ng = tflearn.input_data([None, maxlen, len(char_idx)])\ng = tflearn.lstm(g, 512, return_seq=True)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.lstm(g, 512, return_seq=True)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.lstm(g, 512)\ng = tflearn.dropout(g, 0.5)\ng = tflearn.fully_connected(g, len(char_idx), activation=\'softmax\')\ng = tflearn.regression(g, optimizer=\'adam\', loss=\'categorical_crossentropy\',\n                       learning_rate=0.001)\n\nm = tflearn.SequenceGenerator(g, dictionary=char_idx,\n                              seq_maxlen=maxlen,\n                              clip_gradients=5.0,\n                              checkpoint_path=\'model_\'+ model_name)\n\nfor i in range(50):\n    seed = random_sequence_from_textfile(path, maxlen)\n    m.fit(X, Y, validation_set=0.1, batch_size=128,\n          n_epoch=1, run_id=model_name)\n    print(""-- TESTING..."")\n    if args[\'temp\'] is not None:\n        temp = args[\'temp\'][0]\n        print(""-- Test with temperature of %s --"" % temp)\n        print(m.generate(600, temperature=temp, seq_seed=seed))\n    else:\n        print(""-- Test with temperature of 1.0 --"")\n        print(m.generate(600, temperature=1.0, seq_seed=seed))\n        print(""-- Test with temperature of 0.5 --"")\n        print(m.generate(600, temperature=0.5, seq_seed=seed))\n'"
examples/nlp/seq2seq_example.py,28,"b'\'\'\'\nPedagogical example realization of seq2seq recurrent neural networks, using TensorFlow and TFLearn.\nMore info at https://github.com/ichuang/tflearn_seq2seq\n\'\'\'\n\nfrom __future__ import division, print_function\n\nimport os\nimport sys\nimport tflearn\nimport argparse\nimport json\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.contrib.legacy_seq2seq.python.ops import seq2seq\nfrom tensorflow.python.ops import rnn_cell\n\n#-----------------------------------------------------------------------------\n\nclass SequencePattern(object):\n\n    INPUT_SEQUENCE_LENGTH = 10\n    OUTPUT_SEQUENCE_LENGTH = 10\n    INPUT_MAX_INT = 9\n    OUTPUT_MAX_INT = 9\n    PATTERN_NAME = ""sorted""\n\n    def __init__(self, name=None, in_seq_len=None, out_seq_len=None):\n        if name is not None:\n            assert hasattr(self, ""%s_sequence"" % name)\n            self.PATTERN_NAME = name\n        if in_seq_len:\n            self.INPUT_SEQUENCE_LENGTH = in_seq_len\n        if out_seq_len:\n            self.OUTPUT_SEQUENCE_LENGTH = out_seq_len\n\n    def generate_output_sequence(self, x):\n        \'\'\'\n        For a given input sequence, generate the output sequence.  x is a 1D numpy array \n        of integers, with length INPUT_SEQUENCE_LENGTH.\n        \n        Returns a 1D numpy array of length OUTPUT_SEQUENCE_LENGTH\n        \n        This procedure defines the pattern which the seq2seq RNN will be trained to find.\n        \'\'\'\n        return getattr(self, ""%s_sequence"" % self.PATTERN_NAME)(x)\n\n    def maxmin_dup_sequence(self, x):\n        \'\'\'\n        Generate sequence with [max, min, rest of original entries]\n        \'\'\'\n        x = np.array(x)\n        y = [ x.max(), x.min()] +  list(x[2:])\n        return np.array(y)[:self.OUTPUT_SEQUENCE_LENGTH]\t# truncate at out seq len\n\n    def sorted_sequence(self, x):\n        \'\'\'\n        Generate sorted version of original sequence\n        \'\'\'\n        return np.array( sorted(x) )[:self.OUTPUT_SEQUENCE_LENGTH]\n\n    def reversed_sequence(self, x):\n        \'\'\'\n        Generate reversed version of original sequence\n        \'\'\'\n        return np.array( x[::-1] )[:self.OUTPUT_SEQUENCE_LENGTH]\n\n#-----------------------------------------------------------------------------\n\nclass TFLearnSeq2Seq(object):\n    \'\'\'\n    seq2seq recurrent neural network, implemented using TFLearn.\n    \'\'\'\n    AVAILABLE_MODELS = [""embedding_rnn"", ""embedding_attention""]\n    def __init__(self, sequence_pattern, seq2seq_model=None, verbose=None, name=None, data_dir=None):\n        \'\'\'\n        sequence_pattern_class = a SequencePattern class instance, which defines pattern parameters \n                                 (input, output lengths, name, generating function)\n        seq2seq_model = string specifying which seq2seq model to use, e.g. ""embedding_rnn""\n        \'\'\'\n        self.sequence_pattern = sequence_pattern\n        self.seq2seq_model = seq2seq_model or ""embedding_rnn""\n        assert self.seq2seq_model in self.AVAILABLE_MODELS\n        self.in_seq_len = self.sequence_pattern.INPUT_SEQUENCE_LENGTH\n        self.out_seq_len = self.sequence_pattern.OUTPUT_SEQUENCE_LENGTH\n        self.in_max_int = self.sequence_pattern.INPUT_MAX_INT\n        self.out_max_int = self.sequence_pattern.OUTPUT_MAX_INT\n        self.verbose = verbose or 0\n        self.n_input_symbols = self.in_max_int + 1\n        self.n_output_symbols = self.out_max_int + 2\t\t# extra one for GO symbol\n        self.model_instance = None\n        self.name = name\n        self.data_dir = data_dir\n\n    def generate_trainig_data(self, num_points):\n        \'\'\'\n        Generate training dataset.  Produce random (integer) sequences X, and corresponding\n        expected output sequences Y = generate_output_sequence(X).\n\n        Return xy_data, y_data (both of type uint32)\n\n        xy_data = numpy array of shape [num_points, in_seq_len + out_seq_len], with each point being X + Y\n        y_data  = numpy array of shape [num_points, out_seq_len]\n        \'\'\'\n        x_data = np.random.randint(0, self.in_max_int, size=(num_points, self.in_seq_len))\t\t# shape [num_points, in_seq_len]\n        x_data = x_data.astype(np.uint32)\t\t\t\t\t\t# ensure integer type\n\n        y_data = [ self.sequence_pattern.generate_output_sequence(x) for x in x_data ]\n        y_data = np.array(y_data)\n\n        xy_data = np.append(x_data, y_data, axis=1)\t\t# shape [num_points, 2*seq_len]\n        return xy_data, y_data\n\n    def sequence_loss(self, y_pred, y_true):\n        \'\'\'\n        Loss function for the seq2seq RNN.  Reshape predicted and true (label) tensors, generate dummy weights,\n        then use seq2seq.sequence_loss to actually compute the loss function.\n        \'\'\'\n        if self.verbose > 2: print (""my_sequence_loss y_pred=%s, y_true=%s"" % (y_pred, y_true))\n        logits = tf.unstack(y_pred, axis=1)\t\t# list of [-1, num_decoder_synbols] elements\n        targets = tf.unstack(y_true, axis=1)\t\t# y_true has shape [-1, self.out_seq_len]; unpack to list of self.out_seq_len [-1] elements\n        if self.verbose > 2:\n            print (""my_sequence_loss logits=%s"" % (logits,))\n            print (""my_sequence_loss targets=%s"" % (targets,))\n        weights = [tf.ones_like(yp, dtype=tf.float32) for yp in targets]\n        if self.verbose > 4: print (""my_sequence_loss weights=%s"" % (weights,))\n        sl = seq2seq.sequence_loss(logits, targets, weights)\n        if self.verbose > 2: print (""my_sequence_loss return = %s"" % sl)\n        return sl\n\n    def accuracy(self, y_pred, y_true, x_in):\t\t# y_pred is [-1, self.out_seq_len, num_decoder_symbols]; y_true is [-1, self.out_seq_len]\n        \'\'\'\n        Compute accuracy of the prediction, based on the true labels.  Use the average number of equal\n        values.\n        \'\'\'\n        pred_idx = tf.to_int32(tf.argmax(y_pred, 2))\t\t# [-1, self.out_seq_len]\n        if self.verbose > 2: print (""my_accuracy pred_idx = %s"" % pred_idx)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(pred_idx, y_true), tf.float32), name=\'acc\')\n        return accuracy\n    \n    def model(self, mode=""train"", num_layers=1, cell_size=32, cell_type=""BasicLSTMCell"", embedding_size=20, learning_rate=0.0001,\n              tensorboard_verbose=0, checkpoint_path=None):\n        \'\'\'\n        Build tensor specifying graph of operations for the seq2seq neural network model.\n\n        mode = string, either ""train"" or ""predict""\n        cell_type = attribute of rnn_cell specifying which RNN cell type to use\n        cell_size = size for the hidden layer in the RNN cell\n        num_layers = number of RNN cell layers to use\n\n        Return TFLearn model instance.  Use DNN model for this.\n        \'\'\'\n        assert mode in [""train"", ""predict""]\n\n        checkpoint_path = checkpoint_path or (""%s%ss2s_checkpoint.tfl"" % (self.data_dir or """", ""/"" if self.data_dir else """"))\n        GO_VALUE = self.out_max_int + 1\t\t# unique integer value used to trigger decoder outputs in the seq2seq RNN\n\n        network = tflearn.input_data(shape=[None, self.in_seq_len + self.out_seq_len], dtype=tf.int32, name=""XY"")\n        encoder_inputs = tf.slice(network, [0, 0], [-1, self.in_seq_len], name=""enc_in"")\t# get encoder inputs\n        encoder_inputs = tf.unstack(encoder_inputs, axis=1)\t\t\t\t\t# transform into list of self.in_seq_len elements, each [-1]\n\n        decoder_inputs = tf.slice(network, [0, self.in_seq_len], [-1, self.out_seq_len], name=""dec_in"")\t# get decoder inputs\n        decoder_inputs = tf.unstack(decoder_inputs, axis=1)\t\t\t\t\t# transform into list of self.out_seq_len elements, each [-1]\n\n        go_input = tf.multiply( tf.ones_like(decoder_inputs[0], dtype=tf.int32), GO_VALUE ) # insert ""GO"" symbol as the first decoder input; drop the last decoder input\n        decoder_inputs = [go_input] + decoder_inputs[: self.out_seq_len-1]\t\t\t\t# insert GO as first; drop last decoder input\n\n        feed_previous = not (mode==""train"")\n\n        if self.verbose > 3:\n            print (""feed_previous = %s"" % str(feed_previous))\n            print (""encoder inputs: %s"" % str(encoder_inputs))\n            print (""decoder inputs: %s"" % str(decoder_inputs))\n            print (""len decoder inputs: %s"" % len(decoder_inputs))\n\n        self.n_input_symbols = self.in_max_int + 1\t\t# default is integers from 0 to 9 \n        self.n_output_symbols = self.out_max_int + 2\t\t# extra ""GO"" symbol for decoder inputs\n\n        single_cell = getattr(rnn_cell, cell_type)(cell_size, state_is_tuple=True)\n        if num_layers==1:\n            cell = single_cell\n        else:\n            cell = rnn_cell.MultiRNNCell([single_cell] * num_layers)\n\n        if self.seq2seq_model==""embedding_rnn"":\n            model_outputs, states = seq2seq.embedding_rnn_seq2seq(encoder_inputs,\t# encoder_inputs: A list of 2D Tensors [batch_size, input_size].\n                                                                  decoder_inputs,\n                                                                  cell,\n                                                                  num_encoder_symbols=self.n_input_symbols,\n                                                                  num_decoder_symbols=self.n_output_symbols,\n                                                                  embedding_size=embedding_size,\n                                                                  feed_previous=feed_previous)\n        elif self.seq2seq_model==""embedding_attention"":\n            model_outputs, states = seq2seq.embedding_attention_seq2seq(encoder_inputs,\t# encoder_inputs: A list of 2D Tensors [batch_size, input_size].\n                                                                        decoder_inputs,\n                                                                        cell,\n                                                                        num_encoder_symbols=self.n_input_symbols,\n                                                                        num_decoder_symbols=self.n_output_symbols,\n                                                                        embedding_size=embedding_size,\n                                                                        num_heads=1,\n                                                                        initial_state_attention=False,\n                                                                        feed_previous=feed_previous)\n        else:\n            raise Exception(\'[TFLearnSeq2Seq] Unknown seq2seq model %s\' % self.seq2seq_model)\n            \n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + ""seq2seq_model"", model_outputs)\t# for TFLearn to know what to save and restore\n\n        # model_outputs: list of the same length as decoder_inputs of 2D Tensors with shape [batch_size x output_size] containing the generated outputs.\n        if self.verbose > 2: print (""model outputs: %s"" % model_outputs)\n        network = tf.stack(model_outputs, axis=1)\t\t# shape [-1, n_decoder_inputs (= self.out_seq_len), num_decoder_symbols]\n        if self.verbose > 2: print (""packed model outputs: %s"" % network)\n        \n        if self.verbose > 3:\n            all_vars = tf.get_collection(tf.GraphKeys.VARIABLES)\n            print (""all_vars = %s"" % all_vars)\n\n        with tf.name_scope(""TargetsData""):\t\t\t# placeholder for target variable (i.e. trainY input)\n            targetY = tf.placeholder(shape=[None, self.out_seq_len], dtype=tf.int32, name=""Y"")\n\n        network = tflearn.regression(network, \n                                     placeholder=targetY,\n                                     optimizer=\'adam\',\n                                     learning_rate=learning_rate,\n                                     loss=self.sequence_loss, \n                                     metric=self.accuracy,\n                                     name=""Y"")\n\n        model = tflearn.DNN(network, tensorboard_verbose=tensorboard_verbose, checkpoint_path=checkpoint_path)\n        return model\n\n    def train(self, num_epochs=20, num_points=100000, model=None, model_params=None, weights_input_fn=None, \n              validation_set=0.1, snapshot_step=5000, batch_size=128, weights_output_fn=None):\n        \'\'\'\n        Train model, with specified number of epochs, and dataset size.\n\n        Use specified model, or create one if not provided.  Load initial weights from file weights_input_fn, \n        if provided. validation_set specifies what to use for the validation.\n\n        Returns logits for prediction, as an numpy array of shape [out_seq_len, n_output_symbols].\n        \'\'\'\n        trainXY, trainY = self.generate_trainig_data(num_points)\n        print (""[TFLearnSeq2Seq] Training on %d point dataset (pattern \'%s\'), with %d epochs"" % (num_points, \n                                                                                               self.sequence_pattern.PATTERN_NAME,\n                                                                                               num_epochs))\n        if self.verbose > 1:\n            print (""  model parameters: %s"" % json.dumps(model_params, indent=4))\n        model_params = model_params or {}\n        model = model or self.setup_model(""train"", model_params, weights_input_fn)\n        \n        model.fit(trainXY, trainY, \n                  n_epoch=num_epochs, \n                  validation_set=validation_set, \n                  batch_size=batch_size,\n                  shuffle=True,\n                  show_metric=True,\n                  snapshot_step=snapshot_step,\n                  snapshot_epoch=False, \n                  run_id=""TFLearnSeq2Seq""\n             )\n        print (""Done!"")\n        if weights_output_fn is not None:\n            weights_output_fn = self.canonical_weights_fn(weights_output_fn)\n            model.save(weights_output_fn)\n            print (""Saved %s"" % weights_output_fn)\n            self.weights_output_fn = weights_output_fn\n        return model\n\n    def canonical_weights_fn(self, iteration_num=0):\n        \'\'\'\n        Construct canonical weights filename, based on model and pattern names.\n        \'\'\'\n        if not type(iteration_num)==int:\n            try:\n                iteration_num = int(iteration_num)\n            except Exception as err:\n                return iteration_num\n        model_name = self.name or ""basic""\n        wfn = ""ts2s__%s__%s_%s.tfl"" % (model_name, self.sequence_pattern.PATTERN_NAME, iteration_num)\n        if self.data_dir:\n            wfn = ""%s/%s"" % (self.data_dir, wfn)\n        self.weights_filename = wfn\n        return wfn\n\n    def setup_model(self, mode, model_params=None, weights_input_fn=None):\n        \'\'\'\n        Setup a model instance, using the specified mode and model parameters.\n        Load the weights from the specified file, if it exists.\n        If weights_input_fn is an integer, use that the model name, and\n        the pattern name, to construct a canonical filename.\n        \'\'\'\n        model_params = model_params or {}\n        model = self.model_instance or self.model(mode=mode, **model_params)\n        self.model_instance = model\n        if weights_input_fn:\n            if type(weights_input_fn)==int:\n                weights_input_fn = self.canonical_weights_fn(weights_input_fn)\n            if os.path.exists(weights_input_fn):\n                model.load(weights_input_fn)\n                print (""[TFLearnSeq2Seq] model weights loaded from %s"" % weights_input_fn)\n            else:\n                print (""[TFLearnSeq2Seq] MISSING model weights file %s"" % weights_input_fn)\n        return model\n\n    def predict(self, Xin, model=None, model_params=None, weights_input_fn=None):\n        \'\'\'\n        Make a prediction, using the seq2seq model, for the given input sequence Xin.\n        If model is not provided, create one (or use last created instance).\n\n        Return prediction, y\n\n        prediction = array of integers, giving output prediction.  Length = out_seq_len\n        y = array of shape [out_seq_len, out_max_int], giving logits for output prediction\n        \'\'\'\n        if not model:\n            model = self.model_instance or self.setup_model(""predict"", model_params, weights_input_fn)\n\n        if self.verbose: print (""Xin = %s"" % str(Xin))\n\n        X = np.array(Xin).astype(np.uint32)\n        assert len(X)==self.in_seq_len\n        if self.verbose:\n            print (""X Input shape=%s, data=%s"" % (X.shape, X))\n            print (""Expected output = %s"" % str(self.sequence_pattern.generate_output_sequence(X)))\n\n        Yin = [0]*self.out_seq_len\n\n        XY = np.append(X, np.array(Yin).astype(np.float32))\n        XY = XY.reshape([-1, self.in_seq_len + self.out_seq_len])\t\t# batch size 1\n        if self.verbose > 1: print (""XY Input shape=%s, data=%s"" % (XY.shape, XY))\n\n        res = model.predict(XY)\n        res = np.array(res)\n        if self.verbose > 1: print (""prediction shape = %s"" % str(res.shape))\n        y = res.reshape(self.out_seq_len, self.n_output_symbols)\n        prediction = np.argmax(y, axis=1)\n        if self.verbose:\n            print (""Predicted output sequence: %s"" % str(prediction))\n        return prediction, y\n\n#-----------------------------------------------------------------------------\n\nclass VAction(argparse.Action):\n    def __call__(self, parser, args, values, option_string=None):\n        curval = getattr(args, self.dest, 0) or 0\n        values=values.count(\'v\')+1\n        setattr(args, self.dest, values + curval)\n    \n#-----------------------------------------------------------------------------\n\ndef CommandLine(args=None, arglist=None):\n    \'\'\'\n    Main command line.  Accepts args, to allow for simple unit testing.\n    \'\'\'\n    help_text = """"""\nCommands:\n\ntrain - give size of training set to use, as argument\npredict - give input sequence as argument (or specify inputs via --from-file <filename>)\n\n""""""\n    parser = argparse.ArgumentParser(description=help_text, formatter_class=argparse.RawTextHelpFormatter)\n    \n    parser.add_argument(""cmd"", help=""command"")\n    parser.add_argument(""cmd_input"", nargs=\'*\', help=""input to command"")\n    parser.add_argument(\'-v\', ""--verbose"", nargs=0, help=""increase output verbosity (add more -v to increase versbosity)"", action=VAction, dest=\'verbose\')\n    parser.add_argument(""-m"", ""--model"", help=""seq2seq model name: either embedding_rnn (default) or embedding_attention"", default=None)\n    parser.add_argument(""-r"", ""--learning-rate"", type=float, help=""learning rate (default 0.0001)"", default=0.0001)\n    parser.add_argument(""-e"", ""--epochs"", type=int, help=""number of trainig epochs"", default=10)\n    parser.add_argument(""-i"", ""--input-weights"", type=str, help=""tflearn file with network weights to load"", default=None)\n    parser.add_argument(""-o"", ""--output-weights"", type=str, help=""new tflearn file where network weights are to be saved"", default=None)\n    parser.add_argument(""-p"", ""--pattern-name"", type=str, help=""name of pattern to use for sequence"", default=None)\n    parser.add_argument(""-n"", ""--name"", type=str, help=""name of model, used when generating default weights filenames"", default=None)\n    parser.add_argument(""--in-len"", type=int, help=""input sequence length (default 10)"", default=None)\n    parser.add_argument(""--out-len"", type=int, help=""output sequence length (default 10)"", default=None)\n    parser.add_argument(""--from-file"", type=str, help=""name of file to take input data sequences from (json format)"", default=None)\n    parser.add_argument(""--iter-num"", type=int, help=""training iteration number; specify instead of input- or output-weights to use generated filenames"", default=None)\n    parser.add_argument(""--data-dir"", help=""directory to use for storing checkpoints (also used when generating default weights filenames)"", default=None)\n    # model parameters\n    parser.add_argument(""-L"", ""--num-layers"", type=int, help=""number of RNN layers to use in the model (default 1)"", default=1)\n    parser.add_argument(""--cell-size"", type=int, help=""size of RNN cell to use (default 32)"", default=32)\n    parser.add_argument(""--cell-type"", type=str, help=""type of RNN cell to use (default BasicLSTMCell)"", default=""BasicLSTMCell"")\n    parser.add_argument(""--embedding-size"", type=int, help=""size of embedding to use (default 20)"", default=20)\n    parser.add_argument(""--tensorboard-verbose"", type=int, help=""tensorboard verbosity level (default 0)"", default=0)\n\n    if not args:\n        args = parser.parse_args(arglist)\n    \n    if args.iter_num is not None:\n        args.input_weights = args.iter_num\n        args.output_weights = args.iter_num + 1\n\n    model_params = dict(num_layers=args.num_layers,\n                        cell_size=args.cell_size,\n                        cell_type=args.cell_type,\n                        embedding_size=args.embedding_size,\n                        learning_rate=args.learning_rate,\n                        tensorboard_verbose=args.tensorboard_verbose,\n                    )\n\n    if args.cmd==""train"":\n        try:\n            num_points = int(args.cmd_input[0])\n        except:\n            raise Exception(""Please specify the number of datapoints to use for training, as the first argument"")\n        sp = SequencePattern(args.pattern_name, in_seq_len=args.in_len, out_seq_len=args.out_len)\n        ts2s = TFLearnSeq2Seq(sp, seq2seq_model=args.model, data_dir=args.data_dir, name=args.name, verbose=args.verbose)\n        ts2s.train(num_epochs=args.epochs, num_points=num_points, weights_output_fn=args.output_weights, \n                   weights_input_fn=args.input_weights, model_params=model_params)\n        return ts2s\n        \n    elif args.cmd==""predict"":\n        if args.from_file:\n            inputs = json.loads(args.from_file)\n        try:\n            input_x = map(int, args.cmd_input)\n            inputs = [input_x]\n        except:\n            raise Exception(""Please provide a space-delimited input sequence as the argument"")\n\n        sp = SequencePattern(args.pattern_name, in_seq_len=args.in_len, out_seq_len=args.out_len)\n        ts2s = TFLearnSeq2Seq(sp, seq2seq_model=args.model, data_dir=args.data_dir, name=args.name, verbose=args.verbose)\n        results = []\n        for x in inputs:\n            prediction, y = ts2s.predict(x, weights_input_fn=args.input_weights, model_params=model_params)\n            print(""==> For input %s, prediction=%s (expected=%s)"" % (x, prediction, sp.generate_output_sequence(x)))\n            results.append([prediction, y])\n        ts2s.prediction_results = results\n        return ts2s\n\n    else:\n        print(""Unknown command %s"" % args.cmd)\n\n#-----------------------------------------------------------------------------\n# unit tests\n\ndef test_sp1():\n    \'\'\'\n    Test two different SequencePattern instances\n    \'\'\'\n    sp = SequencePattern(""maxmin_dup"")\n    y = sp.generate_output_sequence(range(10))\n    assert all(y==np.array([9, 0, 2, 3, 4, 5, 6, 7, 8, 9]))    \n    sp = SequencePattern(""sorted"")\n    y = sp.generate_output_sequence([5,6,1,2,9])\n    assert all(y==np.array([1, 2, 5, 6, 9]))\n    sp = SequencePattern(""reversed"")\n    y = sp.generate_output_sequence(range(10))\n    assert all(y==np.array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]))\n\ndef test_sp2():\n    \'\'\'\n    Test two SequencePattern instance with lengths different from default\n    \'\'\'\n    sp = SequencePattern(""sorted"", in_seq_len=20, out_seq_len=5)\n    x = np.random.randint(0, 9, 20)\n    y = sp.generate_output_sequence(x)\n    assert len(y)==5\n    y_exp = sorted(x)[:5]\n    assert all(y==y_exp)\n\ndef test_train1():\n    \'\'\'\n    Test simple training of an embedding_rnn seq2seq model\n    \'\'\'\n    sp = SequencePattern()\n    ts2s = TFLearnSeq2Seq(sp)\n    ofn = ""test_%s"" % ts2s.canonical_weights_fn(0)\n    print (""using weights filename %s"" % ofn)\n    if os.path.exists(ofn):\n        os.unlink(ofn)\n    tf.reset_default_graph()\n    ts2s.train(num_epochs=1, num_points=10000, weights_output_fn=ofn)\n    assert os.path.exists(ofn)\n\ndef test_predict1():\n    \'\'\'\n    Test simple preductions using weights just produced (in test_train1)\n    \'\'\'\n    sp = SequencePattern()\n    ts2s = TFLearnSeq2Seq(sp, verbose=1)\n    wfn = ""test_%s"" % ts2s.canonical_weights_fn(0)\n    print (""using weights filename %s"" % wfn)\n    tf.reset_default_graph()\n    prediction, y = ts2s.predict(Xin=range(10), weights_input_fn=wfn)\n    assert len(prediction==10)\n\ndef test_train_predict2():\n    \'\'\'\n    Test that the embedding_attention model works, with saving and loading of weights\n    \'\'\'\n    import tempfile\n    sp = SequencePattern()\n    tempdir = tempfile.mkdtemp()\n    ts2s = TFLearnSeq2Seq(sp, seq2seq_model=""embedding_attention"", data_dir=tempdir, name=""attention"")\n    tf.reset_default_graph()\n    ts2s.train(num_epochs=1, num_points=1000, weights_output_fn=1, weights_input_fn=0)\n    assert os.path.exists(ts2s.weights_output_fn)\n\n    tf.reset_default_graph()\n    ts2s = TFLearnSeq2Seq(sp, seq2seq_model=""embedding_attention"", data_dir=""DATA"", name=""attention"", verbose=1)\n    prediction, y = ts2s.predict(Xin=range(10), weights_input_fn=1)\n    assert len(prediction==10)\n\n    os.system(""rm -rf %s"" % tempdir)\n\ndef test_train_predict3():\n    \'\'\'\n    Test that a model trained on sequencees of one length can be used for predictions on other sequence lengths\n    \'\'\'\n    import tempfile\n    sp = SequencePattern(""sorted"", in_seq_len=10, out_seq_len=10)\n    tempdir = tempfile.mkdtemp()\n    ts2s = TFLearnSeq2Seq(sp, seq2seq_model=""embedding_attention"", data_dir=tempdir, name=""attention"")\n    tf.reset_default_graph()\n    ts2s.train(num_epochs=1, num_points=1000, weights_output_fn=1, weights_input_fn=0)\n    assert os.path.exists(ts2s.weights_output_fn)\n\n    tf.reset_default_graph()\n    sp = SequencePattern(""sorted"", in_seq_len=20, out_seq_len=8)\n    tf.reset_default_graph()\n    ts2s = TFLearnSeq2Seq(sp, seq2seq_model=""embedding_attention"", data_dir=""DATA"", name=""attention"", verbose=1)\n    x = np.random.randint(0, 9, 20)\n    prediction, y = ts2s.predict(x, weights_input_fn=1)\n    assert len(prediction==8)\n\n    os.system(""rm -rf %s"" % tempdir)\n\ndef test_main1():\n    \'\'\'\n    Integration test - training\n    \'\'\'\n    import tempfile\n    tempdir = tempfile.mkdtemp()\n    arglist = ""--data-dir %s -e 2 --iter-num=1 -v -v --tensorboard-verbose=1 train 5000"" % tempdir\n    arglist = arglist.split(\' \')\n    tf.reset_default_graph()\n    ts2s = CommandLine(arglist=arglist)\n    assert os.path.exists(ts2s.weights_output_fn)\n    os.system(""rm -rf %s"" % tempdir)\n\ndef test_main2():\n    \'\'\'\n    Integration test - training then prediction\n    \'\'\'\n    import tempfile\n    tempdir = tempfile.mkdtemp()\n    arglist = ""--data-dir %s -e 2 --iter-num=1 -v -v --tensorboard-verbose=1 train 5000"" % tempdir\n    arglist = arglist.split(\' \')\n    tf.reset_default_graph()\n    ts2s = CommandLine(arglist=arglist)\n    wfn = ts2s.weights_output_fn\n    assert os.path.exists(wfn)\n\n    arglist = ""-i %s predict 1 2 3 4 5 6 7 8 9 0"" % wfn\n    arglist = arglist.split(\' \')\n    tf.reset_default_graph()\n    ts2s = CommandLine(arglist=arglist)\n    assert len(ts2s.prediction_results[0][0])==10\n\n    os.system(""rm -rf %s"" % tempdir)\n\ndef test_main3():\n    \'\'\'\n    Integration test - training then prediction: attention model\n    \'\'\'\n    import tempfile\n    wfn = ""tmp_weights.tfl""\n    if os.path.exists(wfn):\n        os.unlink(wfn)\n    arglist = ""-e 2 -o tmp_weights.tfl -v -v -v -v -m embedding_attention train 5000""\n    arglist = arglist.split(\' \')\n    tf.reset_default_graph()\n    ts2s = CommandLine(arglist=arglist)\n    assert os.path.exists(wfn)\n\n    arglist = ""-i tmp_weights.tfl -v -v -v -v -m embedding_attention predict 1 2 3 4 5 6 7 8 9 0"" \n    arglist = arglist.split(\' \')\n    tf.reset_default_graph()\n    ts2s = CommandLine(arglist=arglist)\n    assert len(ts2s.prediction_results[0][0])==10\n\n#-----------------------------------------------------------------------------\n\nif __name__==""__main__"":\n    CommandLine()\n'"
examples/others/recommender_wide_and_deep.py,34,"b'\'\'\'\nPedagogical example realization of wide & deep networks, using TensorFlow and TFLearn.\n\nThis is a re-implementation of http://arxiv.org/abs/1606.07792, using the combination\nof a wide linear model, and a deep feed-forward neural network, for binary classification  \nThis example realization is based on Tensorflow\'s TF.Learn tutorial \n(https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html),\nbut implemented in TFLearn.  Note that despite the closeness of names, TFLearn is distinct\nfrom TF.Learn (previously known as scikit flow).\n\nThis implementation explicitly presents the construction of layers in the deep part of the\nnetwork, and allows direct access to changing the layer architecture, and customization\nof methods used for regression and optimization.\n\nIn contrast, the TF.Learn tutorial offers more sophistication, but hides the layer\narchitecture behind a black box function, tf.contrib.learn.DNNLinearCombinedClassifier.\n\nSee https://github.com/ichuang/tflearn_wide_and_deep for more about this example.\n\'\'\'\n\nfrom __future__ import division, print_function\n\nimport os\nimport sys\nimport argparse\nimport tflearn\nimport tempfile\nimport urllib\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n#-----------------------------------------------------------------------------\n\nCOLUMNS = [""age"", ""workclass"", ""fnlwgt"", ""education"", ""education_num"",\n           ""marital_status"", ""occupation"", ""relationship"", ""race"", ""gender"",\n           ""capital_gain"", ""capital_loss"", ""hours_per_week"", ""native_country"",\n           ""income_bracket""]\nLABEL_COLUMN = ""label""\nCATEGORICAL_COLUMNS = {""workclass"": 10, ""education"": 17, ""marital_status"":8, \n                       ""occupation"": 16, ""relationship"": 7, ""race"": 6, \n                       ""gender"": 3, ""native_country"": 43, ""age_binned"": 14}\nCONTINUOUS_COLUMNS = [""age"", ""education_num"", ""capital_gain"", ""capital_loss"",\n                      ""hours_per_week""]\n\n#-----------------------------------------------------------------------------\n\nclass TFLearnWideAndDeep(object):\n    \'\'\'\n    Wide and deep model, implemented using TFLearn\n    \'\'\'\n    AVAILABLE_MODELS = [""wide"", ""deep"", ""wide+deep""]\n    def __init__(self, model_type=""wide+deep"", verbose=None, name=None, tensorboard_verbose=3, \n                 wide_learning_rate=0.001, deep_learning_rate=0.001, checkpoints_dir=None):\n        \'\'\'\n        model_type = `str`: wide or deep or wide+deep\n        verbose = `bool`\n        name = `str` used for run_id (defaults to model_type)\n        tensorboard_verbose = `int`: logging level for tensorboard (0, 1, 2, or 3)\n        wide_learning_rate = `float`: defaults to 0.001\n        deep_learning_rate = `float`: defaults to 0.001\n        checkpoints_dir = `str`: where checkpoint files will be stored (defaults to ""CHECKPOINTS"")\n        \'\'\'\n        self.model_type = model_type or ""wide+deep""\n        assert self.model_type in self.AVAILABLE_MODELS\n        self.verbose = verbose or 0\n        self.tensorboard_verbose = tensorboard_verbose\n        self.name = name or self.model_type\t# name is used for the run_id\n        self.data_columns = COLUMNS\n        self.continuous_columns = CONTINUOUS_COLUMNS\n        self.categorical_columns = CATEGORICAL_COLUMNS\t# dict with category_name: category_size\n        self.label_column = LABEL_COLUMN\n        self.checkpoints_dir = checkpoints_dir or ""CHECKPOINTS""\n        if not os.path.exists(self.checkpoints_dir):\n            os.mkdir(self.checkpoints_dir)\n            print(""Created checkpoints directory %s"" % self.checkpoints_dir)\n        self.build_model([wide_learning_rate, deep_learning_rate])\n\n    def load_data(self, train_dfn=""adult.data"", test_dfn=""adult.test""):\n        \'\'\'\n        Load data (use files offered in the Tensorflow wide_n_deep_tutorial)\n        \'\'\'\n        if not os.path.exists(train_dfn):\n            urllib.urlretrieve(""https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"", train_dfn)\n            print(""Training data is downloaded to %s"" % train_dfn)\n\n        if not os.path.exists(test_dfn):\n            urllib.urlretrieve(""https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test"", test_dfn)\n            print(""Test data is downloaded to %s"" % test_dfn)\n\n        self.train_data = pd.read_csv(train_dfn, names=COLUMNS, skipinitialspace=True)\n        self.test_data = pd.read_csv(test_dfn, names=COLUMNS, skipinitialspace=True, skiprows=1)\n\n        self.train_data[self.label_column] = (self.train_data[""income_bracket""].apply(lambda x: "">50K"" in x)).astype(int)\n        self.test_data[self.label_column] = (self.test_data[""income_bracket""].apply(lambda x: "">50K"" in x)).astype(int)\n\n\n    def build_model(self, learning_rate=[0.001, 0.01]):\n        \'\'\'\n        Model - wide and deep - built using tflearn\n        \'\'\'\n        n_cc = len(self.continuous_columns)\n        n_categories = 1\t\t\t# two categories: is_idv and is_not_idv\n        input_shape = [None, n_cc]\n        if self.verbose:\n            print (""=""*77 + "" Model %s (type=%s)"" % (self.name, self.model_type))\n            print (""  Input placeholder shape=%s"" % str(input_shape))\n        wide_inputs = tflearn.input_data(shape=input_shape, name=""wide_X"")\n        if not isinstance(learning_rate, list):\n            learning_rate = [learning_rate, learning_rate]\t# wide, deep\n        if self.verbose:\n            print (""  Learning rates (wide, deep)=%s"" % learning_rate)\n\n        with tf.name_scope(""Y""):\t\t\t# placeholder for target variable (i.e. trainY input)\n            Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=""Y"")\n\n        with tf.variable_scope(None, ""cb_unit"", [wide_inputs]) as scope:\n            central_bias = tflearn.variables.variable(\'central_bias\', shape=[1],\n                                                      initializer=tf.constant_initializer(np.random.randn()),\n                                                      trainable=True, restore=True)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/cb_unit\', central_bias)\n\n        if \'wide\' in self.model_type:\n            wide_network = self.wide_model(wide_inputs, n_cc)\n            network = wide_network\n            wide_network_with_bias = tf.add(wide_network, central_bias, name=""wide_with_bias"")\n\n        if \'deep\' in self.model_type:\n            deep_network = self.deep_model(wide_inputs, n_cc)\n            deep_network_with_bias = tf.add(deep_network, central_bias, name=""deep_with_bias"")\n            if \'wide\' in self.model_type:\n                network = tf.add(wide_network, deep_network)\n                if self.verbose:\n                    print (""Wide + deep model network %s"" % network)\n            else:\n                network = deep_network\n\n        network = tf.add(network, central_bias, name=""add_central_bias"")\n\n        # add validation monitor summaries giving confusion matrix entries\n        with tf.name_scope(\'Monitors\'):\n            predictions = tf.cast(tf.greater(network, 0), tf.int64)\n            print (""predictions=%s"" % predictions)\n            Ybool = tf.cast(Y_in, tf.bool)\n            print (""Ybool=%s"" % Ybool)\n            pos = tf.boolean_mask(predictions, Ybool)\n            neg = tf.boolean_mask(predictions, ~Ybool)\n            psize = tf.cast(tf.shape(pos)[0], tf.int64)\n            nsize = tf.cast(tf.shape(neg)[0], tf.int64)\n            true_positive = tf.reduce_sum(pos, name=""true_positive"")\n            false_negative = tf.subtract(psize, true_positive, name=""false_negative"")\n            false_positive = tf.reduce_sum(neg, name=""false_positive"")\n            true_negative = tf.subtract(nsize, false_positive, name=""true_negative"")\n            overall_accuracy = tf.truediv(tf.add(true_positive, true_negative), tf.add(nsize, psize), name=""overall_accuracy"")\n        vmset = [true_positive, true_negative, false_positive, false_negative, overall_accuracy]\n\n        trainable_vars = tf.trainable_variables()\n        tv_deep = [v for v in trainable_vars if v.name.startswith(\'deep_\')]\n        tv_wide = [v for v in trainable_vars if v.name.startswith(\'wide_\')]\n\n        if self.verbose:\n            print (""DEEP trainable_vars"")\n            for v in tv_deep:\n                print (""  Variable %s: %s"" % (v.name, v))\n            print (""WIDE trainable_vars"")\n            for v in tv_wide:\n                print (""  Variable %s: %s"" % (v.name, v))\n\n        if \'wide\' in self.model_type:\n            if not \'deep\' in self.model_type:\n                tv_wide.append(central_bias)\n            tflearn.regression(wide_network_with_bias, \n                               placeholder=Y_in,\n                               optimizer=\'sgd\', \n                               #loss=\'roc_auc_score\',\n                               loss=\'binary_crossentropy\',\n                               metric=""accuracy"",\n                               learning_rate=learning_rate[0],\n                               validation_monitors=vmset,\n                               trainable_vars=tv_wide,\n                               op_name=""wide_regression"",\n                               name=""Y"")\n\n        if \'deep\' in self.model_type:\n            if not \'wide\' in self.model_type:\n                tv_wide.append(central_bias)\n            tflearn.regression(deep_network_with_bias, \n                               placeholder=Y_in,\n                               optimizer=\'adam\', \n                               #loss=\'roc_auc_score\',\n                               loss=\'binary_crossentropy\',\n                               metric=""accuracy"",\n                               learning_rate=learning_rate[1],\n                               validation_monitors=vmset if not \'wide\' in self.model_type else None,\n                               trainable_vars=tv_deep,\n                               op_name=""deep_regression"",\n                               name=""Y"")\n\n        if self.model_type==\'wide+deep\':\t# learn central bias separately for wide+deep\n            tflearn.regression(network, \n                               placeholder=Y_in,\n                               optimizer=\'adam\', \n                               loss=\'binary_crossentropy\',\n                               metric=""accuracy"",\n                               learning_rate=learning_rate[0],\t# use wide learning rate\n                               trainable_vars=[central_bias],\n                               op_name=""central_bias_regression"",\n                               name=""Y"")\n\n        self.model = tflearn.DNN(network,\n                                 tensorboard_verbose=self.tensorboard_verbose,\n                                 max_checkpoints=5,\n                                 checkpoint_path=""%s/%s.tfl"" % (self.checkpoints_dir, self.name),\n        )\n\n        if self.verbose:\n            print (""Target variables:"")\n            for v in tf.get_collection(tf.GraphKeys.TARGETS):\n                print (""  variable %s: %s"" % (v.name, v))\n\n            print (""=""*77)\n\n\n    def deep_model(self, wide_inputs, n_inputs, n_nodes=[100, 50], use_dropout=False):\n        \'\'\'\n        Model - deep, i.e. two-layer fully connected network model\n        \'\'\'\n        cc_input_var = {}\n        cc_embed_var = {}\n        flat_vars = []\n        if self.verbose:\n            print (""--> deep model: %s categories, %d continuous"" % (len(self.categorical_columns), n_inputs))\n        for cc, cc_size in self.categorical_columns.items():\n            cc_input_var[cc] = tflearn.input_data(shape=[None, 1], name=""%s_in"" % cc,  dtype=tf.int32)\n            # embedding layers only work on CPU!  No GPU implementation in tensorflow, yet!\n            cc_embed_var[cc] = tflearn.layers.embedding_ops.embedding(cc_input_var[cc],    cc_size,  8, name=""deep_%s_embed"" % cc)\n            if self.verbose:\n                print (""    %s_embed = %s"" % (cc, cc_embed_var[cc]))\n            flat_vars.append(tf.squeeze(cc_embed_var[cc], squeeze_dims=[1], name=""%s_squeeze"" % cc))\n\n        network = tf.concat([wide_inputs] + flat_vars, 1, name=""deep_concat"")\n        for k in range(len(n_nodes)):\n            network = tflearn.fully_connected(network, n_nodes[k], activation=""relu"", name=""deep_fc%d"" % (k+1))\n            if use_dropout:\n                network = tflearn.dropout(network, 0.5, name=""deep_dropout%d"" % (k+1))\n        if self.verbose:\n            print (""Deep model network before output %s"" % network)\n        network = tflearn.fully_connected(network, 1, activation=""linear"", name=""deep_fc_output"", bias=False)\n        network = tf.reshape(network, [-1, 1])\t# so that accuracy is binary_accuracy\n        if self.verbose:\n            print (""Deep model network %s"" % network)\n        return network\n\n    def wide_model(self, inputs, n_inputs):\n        \'\'\'\n        Model - wide, i.e. normal linear model (for logistic regression)\n        \'\'\'\n        network = inputs\n        # use fully_connected (instad of single_unit) because fc works properly with batches, whereas single_unit is 1D only\n        network = tflearn.fully_connected(network, n_inputs, activation=""linear"", name=""wide_linear"", bias=False)\t# x*W (no bias)\n        network = tf.reduce_sum(network, 1, name=""reduce_sum"")\t# batched sum, to produce logits\n        network = tf.reshape(network, [-1, 1])\t# so that accuracy is binary_accuracy\n        if self.verbose:\n            print (""Wide model network %s"" % network)\n        return network\n\n    def prepare_input_data(self, input_data, name="""", category_map=None):\n        \'\'\'\n        Prepare input data dicts\n        \'\'\'\n        print (""-""*40 + "" Preparing %s"" % name)\n        X = input_data[self.continuous_columns].values.astype(np.float32)\n        Y = input_data[self.label_column].values.astype(np.float32)\n        Y = Y.reshape([-1, 1])\n        if self.verbose:\n            print (""  Y shape=%s, X shape=%s"" % (Y.shape, X.shape))\n\n        X_dict = {""wide_X"": X}\n\n        if \'deep\' in self.model_type:\n            # map categorical value strings to integers\n            td = input_data\n            if category_map is None:\n                category_map = {}\n                for cc in self.categorical_columns:\n                    if not cc in td.columns:\n                        continue\n                    cc_values = sorted(td[cc].unique())\n                    cc_max = 1+len(cc_values)\n                    cc_map = dict(zip(cc_values, range(1, cc_max)))\t# start from 1 to avoid 0:0 mapping (save 0 for missing)\n                    if self.verbose:\n                        print (""  category %s max=%s,  map=%s"" % (cc, cc_max, cc_map))\n                    category_map[cc] = cc_map\n                \n            td = td.replace(category_map)\n    \n            # bin ages (cuts off extreme values)\n            age_bins = [ 0, 12, 18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 80, 65535 ]\n            td[\'age_binned\'] = pd.cut(td[\'age\'], age_bins, labels=False)\n            td = td.replace({\'age_binned\': {np.nan: 0}})\n            print (""  %d age bins: age bins = %s"" % (len(age_bins), age_bins))\n\n            X_dict.update({ (""%s_in"" % cc): td[cc].values.astype(np.int32).reshape([-1, 1]) for cc in self.categorical_columns})\n\n        Y_dict = {""Y"": Y}\n        if self.verbose:\n            print (""-""*40)\n        return X_dict, Y_dict, category_map\n\n\n    def train(self, n_epoch=1000, snapshot_step=10, batch_size=None):\n\n        self.X_dict, self.Y_dict, category_map = self.prepare_input_data(self.train_data, ""train data"")\n        self.testX_dict, self.testY_dict, _ = self.prepare_input_data(self.test_data, ""test data"", category_map)\n        validation_batch_size = batch_size or self.testY_dict[\'Y\'].shape[0]\n        batch_size = batch_size or self.Y_dict[\'Y\'].shape[0]\n\n        print (""Input data shape = %s; output data shape=%s, batch_size=%s"" % (str(self.X_dict[\'wide_X\'].shape), \n                                                                               str(self.Y_dict[\'Y\'].shape), \n                                                                               batch_size))\n        print (""Test data shape = %s; output data shape=%s, validation_batch_size=%s"" % (str(self.testX_dict[\'wide_X\'].shape), \n                                                                                         str(self.testY_dict[\'Y\'].shape), \n                                                                                         validation_batch_size))\n        print (""=""*60 + ""  Training"")\n        self.model.fit(self.X_dict, \n                       self.Y_dict,\n                       n_epoch=n_epoch,\n                       validation_set=(self.testX_dict, self.testY_dict),\n                       snapshot_step=snapshot_step,\n                       batch_size=batch_size,\n                       validation_batch_size=validation_batch_size,\n                       show_metric=True, \n                       snapshot_epoch=False,\n                       shuffle=True,\n                       run_id=self.name,\n        )\n        \n    def evaluate(self):\n        logits = np.array(self.model.predict(self.testX_dict)).reshape([-1])\n        print (""=""*60 + ""  Evaluation"")\n        print (""  logits: %s, min=%s, max=%s"" % (logits.shape, logits.min(), logits.max()))\n        probs =  1.0 / (1.0 + np.exp(-logits))\n        y_pred = pd.Series((probs > 0.5).astype(np.int32))\n        Y = pd.Series(self.testY_dict[\'Y\'].astype(np.int32).reshape([-1]))\n        self.confusion_matrix = self.output_confusion_matrix(Y, y_pred)\n        print (""=""*60)\n\n    def output_confusion_matrix(self, y, y_pred):\n        assert y.size == y_pred.size\n        print(""Actual IDV"")\n        print(y.value_counts())\n        print(""Predicted IDV"")\n        print(y_pred.value_counts())\n        print()\n        print(""Confusion matrix:"")\n        cmat = pd.crosstab(y_pred, y, rownames=[\'predictions\'], colnames=[\'actual\'])\n        print(cmat)\n        sys.stdout.flush()\n        return cmat\n    \n#-----------------------------------------------------------------------------\n\ndef CommandLine(args=None):\n    \'\'\'\n    Main command line.  Accepts args, to allow for simple unit testing.\n    \'\'\'\n    flags = tf.app.flags\n    FLAGS = flags.FLAGS\n    if args:\n        FLAGS.__init__()\n        FLAGS.__dict__.update(args)\n\n    try:\n        flags.DEFINE_string(""model_type"", ""wide+deep"",""Valid model types: {\'wide\', \'deep\', \'wide+deep\'}."")\n        flags.DEFINE_string(""run_name"", None, ""name for this run (defaults to model type)"")\n        flags.DEFINE_string(""load_weights"", None, ""filename with initial weights to load"")\n        flags.DEFINE_string(""checkpoints_dir"", None, ""name of directory where checkpoints should be saved"")\n        flags.DEFINE_integer(""n_epoch"", 200, ""Number of training epoch steps"")\n        flags.DEFINE_integer(""snapshot_step"", 100, ""Step number when snapshot (and validation testing) is done"")\n        flags.DEFINE_float(""wide_learning_rate"", 0.001, ""learning rate for the wide part of the model"")\n        flags.DEFINE_float(""deep_learning_rate"", 0.001, ""learning rate for the deep part of the model"")\n        flags.DEFINE_boolean(""verbose"", False, ""Verbose output"")\n    except argparse.ArgumentError:\n        pass\t# so that CommandLine can be run more than once, for testing\n\n    twad = TFLearnWideAndDeep(model_type=FLAGS.model_type, verbose=FLAGS.verbose, \n                              name=FLAGS.run_name, wide_learning_rate=FLAGS.wide_learning_rate,\n                              deep_learning_rate=FLAGS.deep_learning_rate,\n                              checkpoints_dir=FLAGS.checkpoints_dir)\n    twad.load_data()\n    if FLAGS.load_weights:\n        print (""Loading initial weights from %s"" % FLAGS.load_weights)\n        twad.model.load(FLAGS.load_weights)\n    twad.train(n_epoch=FLAGS.n_epoch, snapshot_step=FLAGS.snapshot_step)\n    twad.evaluate()\n    return twad\n\n#-----------------------------------------------------------------------------\n# unit tests\n\ndef test_wide_and_deep():\n    import glob\n    tf.reset_default_graph()\n    cdir = ""test_checkpoints""\n    if os.path.exists(cdir):\n        os.system(""rm -rf %s"" % cdir)\n    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type=""wide+deep"", snapshot_step=5, \n                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))\n    cfiles = glob.glob(""%s/*.tfl-*"" % cdir)\n    print (""cfiles=%s"" % cfiles)\n    assert(len(cfiles))\n    cm = twad.confusion_matrix.values.astype(np.float32)\n    assert(cm[1][1])\n\ndef test_deep():\n    import glob\n    tf.reset_default_graph()\n    cdir = ""test_checkpoints""\n    if os.path.exists(cdir):\n        os.system(""rm -rf %s"" % cdir)\n    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type=""deep"", snapshot_step=5, \n                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))\n    cfiles = glob.glob(""%s/*.tfl-*"" % cdir)\n    print (""cfiles=%s"" % cfiles)\n    assert(len(cfiles))\n    cm = twad.confusion_matrix.values.astype(np.float32)\n    assert(cm[1][1])\n\ndef test_wide():\n    import glob\n    tf.reset_default_graph()\n    cdir = ""test_checkpoints""\n    if os.path.exists(cdir):\n        os.system(""rm -rf %s"" % cdir)\n    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type=""wide"", snapshot_step=5, \n                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))\n    cfiles = glob.glob(""%s/*.tfl-*"" % cdir)\n    print (""cfiles=%s"" % cfiles)\n    assert(len(cfiles))\n    cm = twad.confusion_matrix.values.astype(np.float32)\n    assert(cm[1][1])\n\n#-----------------------------------------------------------------------------\n\nif __name__==""__main__"":\n    CommandLine()\n    None\n'"
examples/reinforcement_learning/atari_1step_qlearning.py,24,"b'# -*- coding: utf-8 -*-\n""""""\nTeaching a machine to play an Atari game (Pacman by default) by implementing\na 1-step Q-learning with TFLearn, TensorFlow and OpenAI gym environment. The\nalgorithm is described in ""Asynchronous Methods for Deep Reinforcement Learning""\npaper. OpenAI\'s gym environment is used here for providing the Atari game\nenvironment for handling games logic and states. This example is originally\nadapted from Corey Lynch\'s repo (url below).\n\nRequirements:\n    - gym environment (pip install gym)\n    - gym Atari environment (pip install gym[atari])\n\nReferences:\n    - Asynchronous Methods for Deep Reinforcement Learning. Mnih et al, 2015.\n\nLinks:\n    - Paper: http://arxiv.org/pdf/1602.01783v1.pdf\n    - OpenAI\'s gym: https://gym.openai.com/\n    - Original Repo: https://github.com/coreylynch/async-rl\n\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport threading\nimport random\nimport numpy as np\nimport time\nfrom skimage.transform import resize\nfrom skimage.color import rgb2gray\nfrom collections import deque\n\nimport gym\nimport tensorflow as tf\nimport tflearn\n\n# Fix for TF 0.12\ntry:\n    writer_summary = tf.summary.FileWriter\n    merge_all_summaries = tf.summary.merge_all\n    histogram_summary = tf.summary.histogram\n    scalar_summary = tf.summary.scalar\nexcept Exception:\n    writer_summary = tf.train.SummaryWriter\n    merge_all_summaries = tf.merge_all_summaries\n    histogram_summary = tf.histogram_summary\n    scalar_summary = tf.scalar_summary\n\n# Change that value to test instead of train\ntesting = False\n# Model path (to load when testing)\ntest_model_path = \'/path/to/your/qlearning.tflearn.ckpt\'\n# Atari game to learn\n# You can also try: \'Breakout-v0\', \'Pong-v0\', \'SpaceInvaders-v0\', ...\ngame = \'MsPacman-v0\'\n# Learning threads\nn_threads = 8\n\n# =============================\n#   Training Parameters\n# =============================\n# Max training steps\nTMAX = 80000000\n# Current training step\nT = 0\n# Consecutive screen frames when performing training\naction_repeat = 4\n# Async gradient update frequency of each learning thread\nI_AsyncUpdate = 5\n# Timestep to reset the target network\nI_target = 40000\n# Learning rate\nlearning_rate = 0.001\n# Reward discount rate\ngamma = 0.99\n# Number of timesteps to anneal epsilon\nanneal_epsilon_timesteps = 400000\n\n# =============================\n#   Utils Parameters\n# =============================\n# Display or not gym evironment screens\nshow_training = True\n# Directory for storing tensorboard summaries\nsummary_dir = \'/tmp/tflearn_logs/\'\nsummary_interval = 100\ncheckpoint_path = \'qlearning.tflearn.ckpt\'\ncheckpoint_interval = 2000\n# Number of episodes to run gym evaluation\nnum_eval_episodes = 100\n\n\n# =============================\n#   TFLearn Deep Q Network\n# =============================\ndef build_dqn(num_actions, action_repeat):\n    """"""\n    Building a DQN.\n    """"""\n    inputs = tf.placeholder(tf.float32, [None, action_repeat, 84, 84])\n    # Inputs shape: [batch, channel, height, width] need to be changed into\n    # shape [batch, height, width, channel]\n    net = tf.transpose(inputs, [0, 2, 3, 1])\n    net = tflearn.conv_2d(net, 32, 8, strides=4, activation=\'relu\')\n    net = tflearn.conv_2d(net, 64, 4, strides=2, activation=\'relu\')\n    net = tflearn.fully_connected(net, 256, activation=\'relu\')\n    q_values = tflearn.fully_connected(net, num_actions)\n    return inputs, q_values\n\n\n# =============================\n#   ATARI Environment Wrapper\n# =============================\nclass AtariEnvironment(object):\n    """"""\n    Small wrapper for gym atari environments.\n    Responsible for preprocessing screens and holding on to a screen buffer\n    of size action_repeat from which environment state is constructed.\n    """"""\n    def __init__(self, gym_env, action_repeat):\n        self.env = gym_env\n        self.action_repeat = action_repeat\n\n        # Agent available actions, such as LEFT, RIGHT, NOOP, etc...\n        self.gym_actions = range(gym_env.action_space.n)\n        # Screen buffer of size action_repeat to be able to build\n        # state arrays of size [1, action_repeat, 84, 84]\n        self.state_buffer = deque()\n\n    def get_initial_state(self):\n        """"""\n        Resets the atari game, clears the state buffer.\n        """"""\n        # Clear the state buffer\n        self.state_buffer = deque()\n\n        x_t = self.env.reset()\n        x_t = self.get_preprocessed_frame(x_t)\n        s_t = np.stack([x_t for i in range(self.action_repeat)], axis=0)\n\n        for i in range(self.action_repeat-1):\n            self.state_buffer.append(x_t)\n        return s_t\n\n    def get_preprocessed_frame(self, observation):\n        """"""\n        0) Atari frames: 210 x 160\n        1) Get image grayscale\n        2) Rescale image 110 x 84\n        3) Crop center 84 x 84 (you can crop top/bottom according to the game)\n        """"""\n        return resize(rgb2gray(observation), (110, 84))[13:110 - 13, :]\n\n    def step(self, action_index):\n        """"""\n        Excecutes an action in the gym environment.\n        Builds current state (concatenation of action_repeat-1 previous\n        frames and current one). Pops oldest frame, adds current frame to\n        the state buffer. Returns current state.\n        """"""\n\n        x_t1, r_t, terminal, info = self.env.step(self.gym_actions[action_index])\n        x_t1 = self.get_preprocessed_frame(x_t1)\n\n        previous_frames = np.array(self.state_buffer)\n        s_t1 = np.empty((self.action_repeat, 84, 84))\n        s_t1[:self.action_repeat-1, :] = previous_frames\n        s_t1[self.action_repeat-1] = x_t1\n\n        # Pop the oldest frame, add the current frame to the queue\n        self.state_buffer.popleft()\n        self.state_buffer.append(x_t1)\n\n        return s_t1, r_t, terminal, info\n\n\n# =============================\n#   1-step Q-Learning\n# =============================\ndef sample_final_epsilon():\n    """"""\n    Sample a final epsilon value to anneal towards from a distribution.\n    These values are specified in section 5.1 of http://arxiv.org/pdf/1602.01783v1.pdf\n    """"""\n    final_epsilons = np.array([.1, .01, .5])\n    probabilities = np.array([0.4, 0.3, 0.3])\n    return np.random.choice(final_epsilons, 1, p=list(probabilities))[0]\n\n\ndef actor_learner_thread(thread_id, env, session, graph_ops, num_actions,\n                         summary_ops, saver):\n    """"""\n    Actor-learner thread implementing asynchronous one-step Q-learning, as specified\n    in algorithm 1 here: http://arxiv.org/pdf/1602.01783v1.pdf.\n    """"""\n    global TMAX, T\n\n    # Unpack graph ops\n    s = graph_ops[""s""]\n    q_values = graph_ops[""q_values""]\n    st = graph_ops[""st""]\n    target_q_values = graph_ops[""target_q_values""]\n    reset_target_network_params = graph_ops[""reset_target_network_params""]\n    a = graph_ops[""a""]\n    y = graph_ops[""y""]\n    grad_update = graph_ops[""grad_update""]\n\n    summary_placeholders, assign_ops, summary_op = summary_ops\n\n    # Wrap env with AtariEnvironment helper class\n    env = AtariEnvironment(gym_env=env,\n                           action_repeat=action_repeat)\n\n    # Initialize network gradients\n    s_batch = []\n    a_batch = []\n    y_batch = []\n\n    final_epsilon = sample_final_epsilon()\n    initial_epsilon = 1.0\n    epsilon = 1.0\n\n    print(""Thread "" + str(thread_id) + "" - Final epsilon: "" + str(final_epsilon))\n\n    time.sleep(3*thread_id)\n    t = 0\n    while T < TMAX:\n        # Get initial game observation\n        s_t = env.get_initial_state()\n        terminal = False\n\n        # Set up per-episode counters\n        ep_reward = 0\n        episode_ave_max_q = 0\n        ep_t = 0\n\n        while True:\n            # Forward the deep q network, get Q(s,a) values\n            readout_t = q_values.eval(session=session, feed_dict={s: [s_t]})\n\n            # Choose next action based on e-greedy policy\n            a_t = np.zeros([num_actions])\n            if random.random() <= epsilon:\n                action_index = random.randrange(num_actions)\n            else:\n                action_index = np.argmax(readout_t)\n            a_t[action_index] = 1\n\n            # Scale down epsilon\n            if epsilon > final_epsilon:\n                epsilon -= (initial_epsilon - final_epsilon) / anneal_epsilon_timesteps\n\n            # Gym excecutes action in game environment on behalf of actor-learner\n            s_t1, r_t, terminal, info = env.step(action_index)\n\n            # Accumulate gradients\n            readout_j1 = target_q_values.eval(session = session,\n                                              feed_dict = {st : [s_t1]})\n            clipped_r_t = np.clip(r_t, -1, 1)\n            if terminal:\n                y_batch.append(clipped_r_t)\n            else:\n                y_batch.append(clipped_r_t + gamma * np.max(readout_j1))\n\n            a_batch.append(a_t)\n            s_batch.append(s_t)\n\n            # Update the state and counters\n            s_t = s_t1\n            T += 1\n            t += 1\n\n            ep_t += 1\n            ep_reward += r_t\n            episode_ave_max_q += np.max(readout_t)\n\n            # Optionally update target network\n            if T % I_target == 0:\n                session.run(reset_target_network_params)\n\n            # Optionally update online network\n            if t % I_AsyncUpdate == 0 or terminal:\n                if s_batch:\n                    session.run(grad_update, feed_dict={y: y_batch,\n                                                        a: a_batch,\n                                                        s: s_batch})\n                # Clear gradients\n                s_batch = []\n                a_batch = []\n                y_batch = []\n\n            # Save model progress\n            if t % checkpoint_interval == 0:\n                saver.save(session, ""qlearning.ckpt"", global_step=t)\n\n            # Print end of episode stats\n            if terminal:\n                stats = [ep_reward, episode_ave_max_q/float(ep_t), epsilon]\n                for i in range(len(stats)):\n                    session.run(assign_ops[i],\n                                {summary_placeholders[i]: float(stats[i])})\n                print(""| Thread %.2i"" % int(thread_id), ""| Step"", t,\n                      ""| Reward: %.2i"" % int(ep_reward), "" Qmax: %.4f"" %\n                      (episode_ave_max_q/float(ep_t)),\n                      "" Epsilon: %.5f"" % epsilon, "" Epsilon progress: %.6f"" %\n                      (t/float(anneal_epsilon_timesteps)))\n                break\n\n\ndef build_graph(num_actions):\n    # Create shared deep q network\n    s, q_network = build_dqn(num_actions=num_actions,\n                             action_repeat=action_repeat)\n    network_params = tf.trainable_variables()\n    q_values = q_network\n\n    # Create shared target network\n    st, target_q_network = build_dqn(num_actions=num_actions,\n                                     action_repeat=action_repeat)\n    target_network_params = tf.trainable_variables()[len(network_params):]\n    target_q_values = target_q_network\n\n    # Op for periodically updating target network with online network weights\n    reset_target_network_params = \\\n        [target_network_params[i].assign(network_params[i])\n         for i in range(len(target_network_params))]\n\n    # Define cost and gradient update op\n    a = tf.placeholder(""float"", [None, num_actions])\n    y = tf.placeholder(""float"", [None])\n    action_q_values = tf.reduce_sum(tf.multiply(q_values, a), reduction_indices=1)\n    cost = tflearn.mean_square(action_q_values, y)\n    optimizer = tf.train.RMSPropOptimizer(learning_rate)\n    grad_update = optimizer.minimize(cost, var_list=network_params)\n\n    graph_ops = {""s"": s,\n                 ""q_values"": q_values,\n                 ""st"": st,\n                 ""target_q_values"": target_q_values,\n                 ""reset_target_network_params"": reset_target_network_params,\n                 ""a"": a,\n                 ""y"": y,\n                 ""grad_update"": grad_update}\n\n    return graph_ops\n\n\n# Set up some episode summary ops to visualize on tensorboard.\ndef build_summaries():\n    episode_reward = tf.Variable(0.)\n    scalar_summary(""Reward"", episode_reward)\n    episode_ave_max_q = tf.Variable(0.)\n    scalar_summary(""Qmax Value"", episode_ave_max_q)\n    logged_epsilon = tf.Variable(0.)\n    scalar_summary(""Epsilon"", logged_epsilon)\n    # Threads shouldn\'t modify the main graph, so we use placeholders\n    # to assign the value of every summary (instead of using assign method\n    # in every thread, that would keep creating new ops in the graph)\n    summary_vars = [episode_reward, episode_ave_max_q, logged_epsilon]\n    summary_placeholders = [tf.placeholder(""float"")\n                            for i in range(len(summary_vars))]\n    assign_ops = [summary_vars[i].assign(summary_placeholders[i])\n                  for i in range(len(summary_vars))]\n    summary_op = merge_all_summaries()\n    return summary_placeholders, assign_ops, summary_op\n\n\ndef get_num_actions():\n    """"""\n    Returns the number of possible actions for the given atari game\n    """"""\n    # Figure out number of actions from gym env\n    env = gym.make(game)\n    num_actions = env.action_space.n\n    return num_actions\n\n\ndef train(session, graph_ops, num_actions, saver):\n    """"""\n    Train a model.\n    """"""\n\n    # Set up game environments (one per thread)\n    envs = [gym.make(game) for i in range(n_threads)]\n\n    summary_ops = build_summaries()\n    summary_op = summary_ops[-1]\n\n    # Initialize variables\n    session.run(tf.initialize_all_variables())\n    writer = writer_summary(summary_dir + ""/qlearning"", session.graph)\n\n    # Initialize target network weights\n    session.run(graph_ops[""reset_target_network_params""])\n\n    # Start n_threads actor-learner training threads\n    actor_learner_threads = \\\n        [threading.Thread(target=actor_learner_thread,\n                          args=(thread_id, envs[thread_id], session,\n                                graph_ops, num_actions, summary_ops, saver))\n         for thread_id in range(n_threads)]\n    for t in actor_learner_threads:\n        t.start()\n        time.sleep(0.01)\n\n    # Show the agents training and write summary statistics\n    last_summary_time = 0\n    while True:\n        if show_training:\n            for env in envs:\n                env.render()\n        now = time.time()\n        if now - last_summary_time > summary_interval:\n            summary_str = session.run(summary_op)\n            writer.add_summary(summary_str, float(T))\n            last_summary_time = now\n    for t in actor_learner_threads:\n        t.join()\n\n\ndef evaluation(session, graph_ops, saver):\n    """"""\n    Evaluate a model.\n    """"""\n    saver.restore(session, test_model_path)\n    print(""Restored model weights from "", test_model_path)\n    monitor_env = gym.make(game)\n    monitor_env.monitor.start(""qlearning/eval"")\n\n    # Unpack graph ops\n    s = graph_ops[""s""]\n    q_values = graph_ops[""q_values""]\n\n    # Wrap env with AtariEnvironment helper class\n    env = AtariEnvironment(gym_env=monitor_env,\n                           action_repeat=action_repeat)\n\n    for i_episode in xrange(num_eval_episodes):\n        s_t = env.get_initial_state()\n        ep_reward = 0\n        terminal = False\n        while not terminal:\n            monitor_env.render()\n            readout_t = q_values.eval(session=session, feed_dict={s : [s_t]})\n            action_index = np.argmax(readout_t)\n            s_t1, r_t, terminal, info = env.step(action_index)\n            s_t = s_t1\n            ep_reward += r_t\n        print(ep_reward)\n    monitor_env.monitor.close()\n\n\ndef main(_):\n    with tf.Session() as session:\n        num_actions = get_num_actions()\n        graph_ops = build_graph(num_actions)\n        saver = tf.train.Saver(max_to_keep=5)\n\n        if testing:\n            evaluation(session, graph_ops, saver)\n        else:\n            train(session, graph_ops, num_actions, saver)\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
tflearn/datasets/__init__.py,0,b'from . import cifar10\nfrom . import imdb\nfrom . import mnist\nfrom . import oxflower17\nfrom . import titanic'
tflearn/datasets/cifar10.py,0,"b'"""""" CIFAR-10 Dataset\n\nCredits: A. Krizhevsky. https://www.cs.toronto.edu/~kriz/cifar.html.\n\n""""""\nfrom __future__ import absolute_import, print_function\n\nimport os\nimport sys\nfrom six.moves import urllib\nimport tarfile\n\nimport numpy as np\nimport pickle\n\nfrom ..data_utils import to_categorical\n\n\ndef load_data(dirname=""cifar-10-batches-py"", one_hot=False):\n    tarpath = maybe_download(""cifar-10-python.tar.gz"",\n                             ""http://www.cs.toronto.edu/~kriz/"",\n                             dirname)\n    X_train = []\n    Y_train = []\n\n    dirname = os.path.join(dirname, \'cifar-10-batches-py\')\n\n    for i in range(1, 6):\n        fpath = os.path.join(dirname, \'data_batch_\' + str(i))\n        data, labels = load_batch(fpath)\n        if i == 1:\n            X_train = data\n            Y_train = labels\n        else:\n            X_train = np.concatenate([X_train, data], axis=0)\n            Y_train = np.concatenate([Y_train, labels], axis=0)\n\n    fpath = os.path.join(dirname, \'test_batch\')\n    X_test, Y_test = load_batch(fpath)\n\n    X_train = np.dstack((X_train[:, :1024], X_train[:, 1024:2048],\n                         X_train[:, 2048:])) / 255.\n    X_train = np.reshape(X_train, [-1, 32, 32, 3])\n    X_test = np.dstack((X_test[:, :1024], X_test[:, 1024:2048],\n                        X_test[:, 2048:])) / 255.\n    X_test = np.reshape(X_test, [-1, 32, 32, 3])\n\n    if one_hot:\n        Y_train = to_categorical(Y_train, 10)\n        Y_test = to_categorical(Y_test, 10)\n\n    return (X_train, Y_train), (X_test, Y_test)\n\n\ndef load_batch(fpath):\n    with open(fpath, \'rb\') as f:\n        if sys.version_info > (3, 0):\n            # Python3\n            d = pickle.load(f, encoding=\'latin1\')\n        else:\n            # Python2\n            d = pickle.load(f)\n    data = d[""data""]\n    labels = d[""labels""]\n    return data, labels\n\n\ndef maybe_download(filename, source_url, work_directory):\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(""Downloading CIFAR 10, Please wait..."")\n        filepath, _ = urllib.request.urlretrieve(source_url + filename,\n                                                 filepath, reporthook)\n        statinfo = os.stat(filepath)\n        print((\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\'))\n        untar(filepath,work_directory)\n    return filepath\n\n\n# reporthook from stackoverflow #13881092\ndef reporthook(blocknum, blocksize, totalsize):\n    readsofar = blocknum * blocksize\n    if totalsize > 0:\n        percent = readsofar * 1e2 / totalsize\n        s = ""\\r%5.1f%% %*d / %d"" % (\n            percent, len(str(totalsize)), readsofar, totalsize)\n        sys.stderr.write(s)\n        if readsofar >= totalsize:  # near the end\n            sys.stderr.write(""\\n"")\n    else:  # total size is unknown\n        sys.stderr.write(""read %d\\n"" % (readsofar,))\n\n\ndef untar(fname,path=""""):\n    if (fname.endswith(""tar.gz"")):\n        tar = tarfile.open(fname)\n        tar.extractall(path=os.path.join(\n            path,\n            \'/\'.join(fname.split(\'/\')[:-1])\n        ))\n        tar.close()\n        if path is """":\n            print(""File Extracted in Current Directory"")\n        else:\n            print(""File Extracted in to "".join(path))\n    else:\n        print(""Not a tar.gz file: \'%s \'"" % sys.argv[0])\n\n'"
tflearn/datasets/cifar100.py,0,"b'"""""" CIFAR-100 Dataset\n\nCredits: A. Krizhevsky. https://www.cs.toronto.edu/~kriz/cifar.html.\n\n""""""\nfrom __future__ import absolute_import, print_function\n\nimport os\nimport sys\nfrom six.moves import urllib\nimport tarfile\n\nimport numpy as np\nimport pickle\n\nfrom ..data_utils import to_categorical\n\n\ndef load_data(dirname=""cifar-100-python"", one_hot=False):\n    tarpath = maybe_download(""cifar-100-python.tar.gz"",\n                             ""http://www.cs.toronto.edu/~kriz/"",\n                             dirname)\n    X_train = []\n    Y_train = []\n\n    for i in [""train""]:\n        fpath = os.path.join(dirname, i)\n        data, labels = load_batch(fpath)\n        if i == ""train"":\n            X_train = data\n            Y_train = labels\n        else:\n            X_train = np.concatenate([X_train, data], axis=0)\n            Y_train = np.concatenate([Y_train, labels], axis=0)\n\n    fpath = os.path.join(dirname, \'test\')\n    X_test, Y_test = load_batch(fpath)\n\n    X_train = np.dstack((X_train[:, :1024], X_train[:, 1024:2048],\n                         X_train[:, 2048:])) / 255.\n    X_train = np.reshape(X_train, [-1, 32, 32, 3])\n    X_test = np.dstack((X_test[:, :1024], X_test[:, 1024:2048],\n                        X_test[:, 2048:])) / 255.\n    X_test = np.reshape(X_test, [-1, 32, 32, 3])\n\n    if one_hot:\n        Y_train = to_categorical(Y_train, 100)\n        Y_test = to_categorical(Y_test, 100)\n\n    return (X_train, Y_train), (X_test, Y_test)\n\n\ndef load_batch(fpath):\n    with open(fpath, \'rb\') as f:\n        if sys.version_info > (3, 0):\n            # Python3\n            d = pickle.load(f, encoding=\'latin1\')\n        else:\n            # Python2\n            d = pickle.load(f)\n    data = d[""data""]\n    labels = d[""fine_labels""]\n    return data, labels\n\n\ndef maybe_download(filename, source_url, work_directory):\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(""Downloading CIFAR 100, Please wait..."")\n        filepath, _ = urllib.request.urlretrieve(source_url + filename,\n                                                 filepath)\n        statinfo = os.stat(filepath)\n        print((\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\'))\n        untar(filepath)\n    return filepath\n\n\ndef untar(fname):\n    if (fname.endswith(""tar.gz"")):\n        tar = tarfile.open(fname)\n        tar.extractall()\n        tar.close()\n        print(""File Extracted in Current Directory"")\n    else:\n        print(""Not a tar.gz file: \'%s \'"" % sys.argv[0])\n'"
tflearn/datasets/imdb.py,1,"b'"""""" IMDB Dataset\n\nCredits: LISA-lab, https://github.com/lisa-lab/\n""""""\nfrom __future__ import print_function\nimport six.moves.cPickle as pickle\n\nimport gzip\nimport os\n\nimport numpy\nimport tensorflow as tf\n\ndef prepare_data(seqs, labels, maxlen=None):\n    """"""Create the matrices from the datasets.\n    This pad each sequence to the same lenght: the lenght of the\n    longuest sequence or maxlen.\n    if maxlen is set, we will cut all sequence to this maximum\n    lenght.\n    This swap the axis!\n    """"""\n    # x: a list of sentences\n    lengths = [len(s) for s in seqs]\n\n    if maxlen is not None:\n        new_seqs = []\n        new_labels = []\n        new_lengths = []\n        for l, s, y in zip(lengths, seqs, labels):\n            if l < maxlen:\n                new_seqs.append(s)\n                new_labels.append(y)\n                new_lengths.append(l)\n        lengths = new_lengths\n        labels = new_labels\n        seqs = new_seqs\n\n        if len(lengths) < 1:\n            return None, None, None\n\n    n_samples = len(seqs)\n    maxlen = numpy.max(lengths)\n\n    x = numpy.zeros((maxlen, n_samples)).astype(\'int64\')\n    x_mask = numpy.zeros((maxlen, n_samples)).astype(tf.float32)\n    for idx, s in enumerate(seqs):\n        x[:lengths[idx], idx] = s\n        x_mask[:lengths[idx], idx] = 1.\n\n    return x, x_mask, labels\n\n\ndef get_dataset_file(dataset, default_dataset, origin):\n    \'\'\'Look for it as if it was a full path, if not, try local file,\n    if not try in the data directory.\n    Download dataset if it is not present\n    \'\'\'\n    data_dir, data_file = os.path.split(dataset)\n    if (not os.path.isfile(dataset)) and data_file == default_dataset:\n        from six.moves import urllib\n        print(\'Downloading data from %s\' % origin)\n        urllib.request.urlretrieve(origin, dataset)\n\n\n    return dataset\n\n\ndef load_data(path=""imdb.pkl"", n_words=100000, valid_portion=0.1,\n              maxlen=None,\n              sort_by_len=True):\n    \'\'\'Loads the dataset\n    :type path: String\n    :param path: The path to the dataset (here IMDB)\n    :type n_words: int\n    :param n_words: The number of word to keep in the vocabulary.\n        All extra words are set to unknow (1).\n    :type valid_portion: float\n    :param valid_portion: The proportion of the full train set used for\n        the validation set.\n    :type maxlen: None or positive int\n    :param maxlen: the max sequence length we use in the train/valid set.\n    :type sort_by_len: bool\n    :name sort_by_len: Sort by the sequence lenght for the train,\n        valid and test set. This allow faster execution as it cause\n        less padding per minibatch. Another mechanism must be used to\n        shuffle the train set at each epoch.\n    \'\'\'\n\n    #############\n    # LOAD DATA #\n    #############\n\n    # Load the dataset\n    path = get_dataset_file(\n        path, ""imdb.pkl"",\n        ""http://www.iro.umontreal.ca/~lisa/deep/data/imdb.pkl"")\n\n    if path.endswith("".gz""):\n        f = gzip.open(path, \'rb\')\n    else:\n        f = open(path, \'rb\')\n\n    train_set = pickle.load(f)\n    test_set = pickle.load(f)\n    f.close()\n    if maxlen:\n        new_train_set_x = []\n        new_train_set_y = []\n        for x, y in zip(train_set[0], train_set[1]):\n            if len(x) < maxlen:\n                new_train_set_x.append(x)\n                new_train_set_y.append(y)\n        train_set = (new_train_set_x, new_train_set_y)\n        del new_train_set_x, new_train_set_y\n\n    # split training set into validation set\n    train_set_x, train_set_y = train_set\n    n_samples = len(train_set_x)\n    sidx = numpy.random.permutation(n_samples)\n    n_train = int(numpy.round(n_samples * (1. - valid_portion)))\n    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n\n    train_set = (train_set_x, train_set_y)\n    valid_set = (valid_set_x, valid_set_y)\n\n    def remove_unk(x):\n        return [[1 if w >= n_words else w for w in sen] for sen in x]\n\n    test_set_x, test_set_y = test_set\n    valid_set_x, valid_set_y = valid_set\n    train_set_x, train_set_y = train_set\n\n    train_set_x = remove_unk(train_set_x)\n    valid_set_x = remove_unk(valid_set_x)\n    test_set_x = remove_unk(test_set_x)\n\n    def len_argsort(seq):\n        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n\n    if sort_by_len:\n        sorted_index = len_argsort(test_set_x)\n        test_set_x = [test_set_x[i] for i in sorted_index]\n        test_set_y = [test_set_y[i] for i in sorted_index]\n\n        sorted_index = len_argsort(valid_set_x)\n        valid_set_x = [valid_set_x[i] for i in sorted_index]\n        valid_set_y = [valid_set_y[i] for i in sorted_index]\n\n        sorted_index = len_argsort(train_set_x)\n        train_set_x = [train_set_x[i] for i in sorted_index]\n        train_set_y = [train_set_y[i] for i in sorted_index]\n\n    train = (train_set_x, train_set_y)\n    valid = (valid_set_x, valid_set_y)\n    test = (test_set_x, test_set_y)\n\n    return train, valid, test\n'"
tflearn/datasets/mnist.py,0,"b'""""""Functions for downloading and reading MNIST data.\n\nCredits: Y. LeCun. http://yann.lecun.com/exdb/mnist/.\n""""""\nfrom __future__ import print_function\nimport gzip\nimport os\nfrom six.moves import urllib\nimport numpy\n\nSOURCE_URL = \'http://yann.lecun.com/exdb/mnist/\'\n\n\ndef load_data(data_dir=""mnist/"", one_hot=False):\n    mnist = read_data_sets(data_dir, one_hot=one_hot)\n    return mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n\n\ndef maybe_download(filename, work_directory):\n    """"""Download the data from Yann\'s website, unless it\'s already here.""""""\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(\'Downloading MNIST...\')\n        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename,\n                                                 filepath)\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    return filepath\n\n\ndef _read32(bytestream):\n    try:\n        dt = numpy.dtype(numpy.uint32).newbyteorder(\'>\')\n        return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n    except Exception:\n        dt = numpy.dtype(numpy.uint32).newbyteorder(\'>\')\n        return numpy.frombuffer(bytestream.read(4), dtype=dt)\n\n\ndef extract_images(filename):\n    """"""Extract the images into a 4D uint8 numpy array [index, y, x, depth].""""""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        magic = _read32(bytestream)\n        if magic != 2051:\n            raise ValueError(\n                \'Invalid magic number %d in MNIST image file: %s\' %\n                (magic, filename))\n        num_images = _read32(bytestream)\n        rows = _read32(bytestream)\n        cols = _read32(bytestream)\n        buf = bytestream.read(rows * cols * num_images)\n        data = numpy.frombuffer(buf, dtype=numpy.uint8)\n        data = data.reshape(num_images, rows, cols, 1)\n        return data\n\n\ndef dense_to_one_hot(labels_dense, num_classes=10):\n    """"""Convert class labels from scalars to one-hot vectors.""""""\n    num_labels = labels_dense.shape[0]\n    index_offset = numpy.arange(num_labels) * num_classes\n    labels_one_hot = numpy.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n\ndef extract_labels(filename, one_hot=False):\n    """"""Extract the labels into a 1D uint8 numpy array [index].""""""\n    print(\'Extracting\', filename)\n    with gzip.open(filename) as bytestream:\n        magic = _read32(bytestream)\n        if magic != 2049:\n            raise ValueError(\n                \'Invalid magic number %d in MNIST label file: %s\' %\n                (magic, filename))\n        num_items = _read32(bytestream)\n        buf = bytestream.read(num_items)\n        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n        if one_hot:\n            return dense_to_one_hot(labels)\n        return labels\n\n\nclass DataSet(object):\n    def __init__(self, images, labels, fake_data=False):\n        if fake_data:\n            self._num_examples = 10000\n        else:\n            assert images.shape[0] == labels.shape[0], (\n                ""images.shape: %s labels.shape: %s"" % (images.shape,\n                                                       labels.shape))\n            self._num_examples = images.shape[0]\n            # Convert shape from [num examples, rows, columns, depth]\n            # to [num examples, rows*columns] (assuming depth == 1)\n            assert images.shape[3] == 1\n            images = images.reshape(images.shape[0],\n                                    images.shape[1] * images.shape[2])\n            # Convert from [0, 255] -> [0.0, 1.0].\n            images = images.astype(numpy.float32)\n            images = numpy.multiply(images, 1.0 / 255.0)\n        self._images = images\n        self._labels = labels\n        self._epochs_completed = 0\n        self._index_in_epoch = 0\n\n    @property\n    def images(self):\n        return self._images\n\n    @property\n    def labels(self):\n        return self._labels\n\n    @property\n    def num_examples(self):\n        return self._num_examples\n\n    @property\n    def epochs_completed(self):\n        return self._epochs_completed\n\n    def next_batch(self, batch_size, fake_data=False):\n        """"""Return the next `batch_size` examples from this data set.""""""\n        if fake_data:\n            fake_image = [1.0 for _ in range(784)]\n            fake_label = 0\n            return [fake_image for _ in range(batch_size)], [\n                fake_label for _ in range(batch_size)]\n        start = self._index_in_epoch\n        self._index_in_epoch += batch_size\n        if self._index_in_epoch > self._num_examples:\n            # Finished epoch\n            self._epochs_completed += 1\n            # Shuffle the data\n            perm = numpy.arange(self._num_examples)\n            numpy.random.shuffle(perm)\n            self._images = self._images[perm]\n            self._labels = self._labels[perm]\n            # Start next epoch\n            start = 0\n            self._index_in_epoch = batch_size\n            assert batch_size <= self._num_examples\n        end = self._index_in_epoch\n        return self._images[start:end], self._labels[start:end]\n\n\ndef read_data_sets(train_dir=""mnist/"", fake_data=False, one_hot=False):\n    class DataSets(object):\n        pass\n\n    data_sets = DataSets()\n    if fake_data:\n        data_sets.train = DataSet([], [], fake_data=True)\n        data_sets.validation = DataSet([], [], fake_data=True)\n        data_sets.test = DataSet([], [], fake_data=True)\n        return data_sets\n    TRAIN_IMAGES = \'train-images-idx3-ubyte.gz\'\n    TRAIN_LABELS = \'train-labels-idx1-ubyte.gz\'\n    TEST_IMAGES = \'t10k-images-idx3-ubyte.gz\'\n    TEST_LABELS = \'t10k-labels-idx1-ubyte.gz\'\n    VALIDATION_SIZE = 5000\n    local_file = maybe_download(TRAIN_IMAGES, train_dir)\n    train_images = extract_images(local_file)\n    local_file = maybe_download(TRAIN_LABELS, train_dir)\n    train_labels = extract_labels(local_file, one_hot=one_hot)\n    local_file = maybe_download(TEST_IMAGES, train_dir)\n    test_images = extract_images(local_file)\n    local_file = maybe_download(TEST_LABELS, train_dir)\n    test_labels = extract_labels(local_file, one_hot=one_hot)\n    validation_images = train_images[:VALIDATION_SIZE]\n    validation_labels = train_labels[:VALIDATION_SIZE]\n    train_images = train_images[VALIDATION_SIZE:]\n    train_labels = train_labels[VALIDATION_SIZE:]\n    data_sets.train = DataSet(train_images, train_labels)\n    data_sets.validation = DataSet(validation_images, validation_labels)\n    data_sets.test = DataSet(test_images, test_labels)\n    return data_sets\n'"
tflearn/datasets/oxflower17.py,0,"b'"""""" 17 Category Flower Dataset\n\nCredits: Maria-Elena Nilsback and Andrew Zisserman.\nhttp://www.robots.ox.ac.uk/~vgg/data/flowers/17/\n\n""""""\nfrom __future__ import absolute_import, print_function\n\nimport os\nimport sys\nfrom six.moves import urllib\nimport tarfile\n\nimport numpy as np\nimport pickle\n\nfrom ..data_utils import *\n\n\ndef load_data(dirname=""17flowers"", resize_pics=(224, 224), shuffle=True,\n    one_hot=False):\n    dataset_file = os.path.join(dirname, \'17flowers.pkl\')\n    if not os.path.exists(dataset_file):\n        tarpath = maybe_download(""17flowers.tgz"",\n                                 ""http://www.robots.ox.ac.uk/~vgg/data/flowers/17/"",\n                                 dirname)\n\n    X, Y = build_image_dataset_from_dir(os.path.join(dirname, \'jpg/\'),\n                                        dataset_file=dataset_file,\n                                        resize=resize_pics,\n                                        filetypes=[\'.jpg\', \'.jpeg\'],\n                                        convert_gray=False,\n                                        shuffle_data=shuffle,\n                                        categorical_Y=one_hot)\n\n    return X, Y\n\n\ndef maybe_download(filename, source_url, work_directory):\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(""Downloading Oxford 17 category Flower Dataset, Please ""\n              ""wait..."")\n        filepath, _ = urllib.request.urlretrieve(source_url + filename,\n                                                 filepath, reporthook)\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n\n        untar(filepath, work_directory)\n        build_class_directories(os.path.join(work_directory, \'jpg\'))\n    return filepath\n\n#reporthook from stackoverflow #13881092\ndef reporthook(blocknum, blocksize, totalsize):\n    readsofar = blocknum * blocksize\n    if totalsize > 0:\n        percent = readsofar * 1e2 / totalsize\n        s = ""\\r%5.1f%% %*d / %d"" % (\n            percent, len(str(totalsize)), readsofar, totalsize)\n        sys.stderr.write(s)\n        if readsofar >= totalsize: # near the end\n            sys.stderr.write(""\\n"")\n    else: # total size is unknown\n        sys.stderr.write(""read %d\\n"" % (readsofar,))\n\ndef build_class_directories(dir):\n    dir_id = 0\n    class_dir = os.path.join(dir, str(dir_id))\n    if not os.path.exists(class_dir):\n        os.mkdir(class_dir)\n    for i in range(1, 1361):\n        fname = ""image_"" + (""%.4i"" % i) + "".jpg""\n        os.rename(os.path.join(dir, fname), os.path.join(class_dir, fname))\n        if i % 80 == 0 and dir_id < 16:\n            dir_id += 1\n            class_dir = os.path.join(dir, str(dir_id))\n            os.mkdir(class_dir)\n\n\ndef untar(fname, extract_dir):\n    if fname.endswith(""tar.gz"") or fname.endswith(""tgz""):\n        tar = tarfile.open(fname)\n        tar.extractall(extract_dir)\n        tar.close()\n        print(""File Extracted"")\n    else:\n        print(""Not a tar.gz/tgz file: \'%s \'"" % sys.argv[0])\n'"
tflearn/datasets/svhn.py,0,"b'################################################\n# The Street View House Numbers (SVHN) Dataset #\n# http://ufldl.stanford.edu/housenumbers       #\n# Format 2: Cropped Digits                     #\n# Train set: 73257 32x32 RGB Digits            #\n# Test set:  26032 32x32 RGB Digits            #\n# Extra set: 531131 32x32 RGB Digits           #\n################################################\nfrom __future__ import print_function\nimport numpy as np\nimport scipy.io\nfrom six.moves import urllib\nimport os\n\nURL_BASE = \'http://ufldl.stanford.edu/housenumbers/\'\nTRAIN_FILE = \'train_32x32.mat\'\nTEST_FILE = \'test_32x32.mat\'\nEXTRA_FILE = \'extra_32x32.mat\'\nTRAIN_INSTANCES = 73257\nTEST_INSTANCES = 26032\nEXTRA_INSTANCES = 531131\n\ndef load_data(data_dir=""svhn/"", one_hot=True):\n\ttrain_filepath = maybe_download(TRAIN_FILE,data_dir)\n\ttest_filepath = maybe_download(TEST_FILE,data_dir)\n\ttrainX, trainY = read_data_from_file(train_filepath,TRAIN_INSTANCES) \n\ttestX, testY = read_data_from_file(test_filepath,TEST_INSTANCES)\n\treturn trainX, trainY, testX, testY\n\ndef load_extra_data(data_dir=""svhn/"", one_hot=True):\n\textra_filepath = maybe_download(EXTRA_FILE,data_dir)\n\textraX, extraY = read_data_from_file(extra_filepath,EXTRA_INSTANCES) \n\treturn extraX, extraY\n\ndef read_data_from_file(filepath,instances):\n\tprint(\'Reading SVHN Dataset...\')\n\tmat = scipy.io.loadmat(filepath)\n\tY = mat[\'y\'] ##Y.shape = (instances,1) \n\tX = mat[\'X\'] #X.shape = (32, 32, 3, instances) -> 32x32 RGB \n\tnX = np.zeros(instances*3*32*32).reshape(instances,32,32,3)\n\tfor n in range (instances):\n\t\tfor rgb in range(3):\n\t\t\tfor i in range(32):\n\t\t\t\tfor j in range(32):\n\t\t\t\t\tnX[n,i,j,rgb]=X[i,j,rgb,n] #output shape: (Nx32x32x3)\n\tnY = np.zeros(instances*10).reshape(instances,10)\n\tfor n in range(instances):\n\t\tnY[n] = label_to_one_hot_y(Y[n,0],10)\n\tprint(\'   ...dataset read!\')\n\treturn nX, nY\n\ndef label_to_one_hot_y(y,classes):\n\t#original .mat files has the \'y\' classes labeled from 1 up to 10\n\tY = np.zeros(classes)\n\tY[y-1] = 1 #classes labeled from 0 up to 9: one_hot vector y\n\treturn Y\n\ndef maybe_download(filename, work_directory):\n    """"""Download the data from Stanford\'s website, unless it\'s already here.""""""\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(\'Downloading SVHN Dataset...\')\n        filepath, _ = urllib.request.urlretrieve(URL_BASE + filename,filepath)\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    return filepath\n'"
tflearn/datasets/titanic.py,0,"b'from __future__ import print_function\nimport gzip\nimport os\nfrom six.moves import urllib\n\n\ndef download_dataset(filename=\'titanic_dataset.csv\', work_directory=\'./\'):\n    """"""Download the data, unless it\'s already here.""""""\n    url = \'http://tflearn.org/resources/titanic_dataset.csv\'\n    if not os.path.exists(work_directory):\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath):\n        print(\'Downloading Titanic dataset...\')\n        filepath, _ = urllib.request.urlretrieve(url, filepath)\n        statinfo = os.stat(filepath)\n        print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    return filepath\n\n\ndef load_dataset():\n    raise NotImplementedError\n'"
tflearn/estimators/__init__.py,0,"b'from .ensemble import RandomForestRegressor, RandomForestClassifier\nfrom .cluster import KMeans, MiniBatchKMeans\n'"
tflearn/estimators/base.py,7,"b'from __future__ import division, print_function, absolute_import\n\nimport os\nimport tensorflow as tf\nfrom tensorflow.python.ops import resources\n\nfrom ..utils import validate_func\n\n\nclass GraphBranch(object):\n    """""" A graph branch class used for building part of an Estimator graph.\n    """"""\n    def __init__(self, input_tensor=None, output_tensor=None, params=None):\n        self.input_tensor = input_tensor\n        self.output_tensor = output_tensor\n        self.params = params if params is not None else dict()\n        self._is_ready = False\n        if input_tensor is not None and output_tensor is not None:\n            self._is_ready = True\n\n    def build(self, input_tensor, output_tensor, params=None):\n        self.input_tensor = input_tensor\n        self.output_tensor = output_tensor\n        self.params = params if params is not None else dict()\n        self._is_ready = True\n\n    @property\n    def is_ready(self):\n        return self._is_ready\n\n    def get_params(self, x):\n        if x in self.params.keys():\n            return self.params[x]\n        else:\n            return None\n\n\nclass BaseEstimator(object):\n\n    """""" Estimators Graph is only build when fit/predict or evaluate is called.\n    """"""\n\n    def __init__(self, metric=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n\n        self.name = name\n\n        # Estimator Graph and Session\n        self.graph = tf.Graph() if graph is None else graph\n        with self.graph.as_default():\n            conf = tf.ConfigProto(allow_soft_placement=True)\n            self.session = tf.Session(config=conf) if session is None else session\n        if global_step is None:\n            with self.graph.as_default():\n                self.global_step = tf.train.get_or_create_global_step()\n\n        self.metric = validate_func(metric)\n\n        # Estimator Graph Branches\n        self._train = GraphBranch()\n        self._pred = GraphBranch()\n        self._transform = GraphBranch()\n        self._eval = GraphBranch()\n\n        # Tensor Utils\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n        self.log_dir = log_dir\n        self._is_initialized = False\n        self._to_be_restored = False\n\n        # Ops\n        self.train_op = None\n        self.loss_op = None\n\n    # -----------------\n    #  Initializations\n    # -----------------\n    def _init_graph(self):\n        # Initialize all weights\n        if not self._is_initialized:\n            self.saver = tf.train.Saver()\n            init_vars = tf.group(tf.global_variables_initializer(),\n                                 resources.initialize_resources(\n                                     resources.shared_resources()))\n            self.session.run(init_vars)\n            self._is_initialized = True\n        # Restore weights if needed\n        if self._to_be_restored:\n            self.saver = tf.train.Saver()\n            self.saver.restore(self.session, self._to_be_restored)\n            self._to_be_restored = False\n\n    def _init_estimator(self):\n        raise NotImplementedError\n\n    # ----------------------\n    #  Build Graph Branches\n    # ----------------------\n    def _build_fit(self, X, Y, batch_size, multi_inputs=False):\n        if not self._train._is_ready:\n            self._init_graph()\n        train_params = {\'X\': X, \'Y\': Y, \'batch_size\': batch_size,\n                        \'multi_inputs\': multi_inputs}\n        self._train.build(None, None, train_params)\n\n    def _build_pred(self, input_tensor, output_tensor):\n        self._pred.build(input_tensor, output_tensor)\n\n    def _build_transform(self, input_tensor, output_tensor):\n        self._transform.build(input_tensor, output_tensor)\n\n    def _build_eval(self, X, Y, metric, batch_size, multi_inputs=False):\n        eval_params = {\'X\': X, \'Y\': Y, \'batch_size\': batch_size,\n                       \'metric\': metric, \'multi_inputs\': multi_inputs}\n        self._eval.build(None, None, eval_params)\n\n    # ---------\n    #  Methods\n    # ---------\n    def fit(self, *args):\n        #TODO: Handle multiple fits\n        raise NotImplementedError\n\n    def predict(self, *args):\n        raise NotImplementedError\n\n    def evaluate(self, *args):\n        raise NotImplementedError\n\n    def load(self, *args):\n        raise NotImplementedError\n\n    def save(self, *args):\n        raise NotImplementedError\n\n\nclass SupervisedEstimator(BaseEstimator):\n\n    def __init__(self, metric=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n        super(SupervisedEstimator, self).__init__(\n            metric=metric, log_dir=log_dir, global_step=global_step,\n            session=session, graph=graph, name=name)\n\n    def fit(self, X, Y, *args):\n        pass\n'"
tflearn/helpers/__init__.py,0,"b'from __future__ import absolute_import\nfrom .evaluator import Evaluator\nfrom .trainer import Trainer, TrainOp\nfrom .regularizer import add_weights_regularizer\nfrom .summarizer import summarize, summarize_activations, \\\n    summarize_gradients, summarize_variables, summarize_all\n'"
tflearn/helpers/evaluator.py,7,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nimport tflearn\nfrom ..utils import to_list\nfrom .. import data_flow\nfrom .. import metrics\nfrom .trainer import evaluate_flow\n\n\nclass Evaluator(object):\n\n    """""" Evaluator.\n\n    A class used for performing predictions and evaluate a model performance.\n\n    Arguments:\n        tensors: list of `Tensor`. A list of tensors to perform predictions.\n        model: `str`. The model weights path (Optional).\n        session: `Session`. The session to run the prediction (Optional).\n\n    """"""\n\n    def __init__(self, tensors, model=None, session=None):\n        self.tensors = to_list(tensors)\n        self.graph = self.tensors[0].graph\n        self.model = model\n        self.dprep_collection = tf.get_collection(tf.GraphKeys.DATA_PREP)\n        self.inputs = tf.get_collection(tf.GraphKeys.INPUTS)\n\n        with self.graph.as_default():\n            self.session = tf.Session()\n            if session: self.session = session\n            self.saver = tf.train.Saver()\n            if model: self.saver.restore(self.session, model)\n\n    def predict(self, feed_dict):\n        """""" predict.\n\n        Run data through the provided network and return the result value.\n\n        Arguments:\n            feed_dict: `dict`. Feed data dictionary, with placeholders as\n                keys, and data as values.\n\n        Returns:\n            An `array`. In case of multiple tensors to predict, each tensor\'s\n            prediction result is concatenated.\n\n        """"""\n        with self.graph.as_default():\n            # Data Preprocessing\n            dprep_dict = dict()\n            for i in range(len(self.inputs)):\n                # Support for custom inputs not using dprep/daug\n                if len(self.dprep_collection) > i:\n                    if self.dprep_collection[i] is not None:\n                        dprep_dict[self.inputs[i]] = self.dprep_collection[i]\n            # Apply pre-processing\n            if len(dprep_dict) > 0:\n                for k in dprep_dict:\n                    feed_dict[k] = dprep_dict[k].apply(feed_dict[k])\n\n            # Prediction for each tensor\n            tflearn.is_training(False, self.session)\n            prediction = []\n            if len(self.tensors) == 1:\n                return self.session.run(self.tensors[0], feed_dict=feed_dict)\n            else:\n                for output in self.tensors:\n                    o_pred = self.session.run(output, feed_dict=feed_dict).tolist()\n                    for i, val in enumerate(o_pred): # Reshape pred per sample\n                        if len(self.tensors) > 1:\n                            if not len(prediction) > i: prediction.append([])\n                            prediction[i].append(val)\n                return prediction\n\n    def evaluate(self, feed_dict, ops, batch_size=128):\n        """""" Evaluate.\n\n        Evaluate a list of tensors over a whole dataset. Generally,\n        \'ops\' argument are average performance metrics (such as average mean,\n        top-3, etc...)\n\n        Arguments:\n            feed_dict: `dict`. The feed dictionary of data.\n            ops: list of `Tensors`. The tensors to evaluate.\n            batch_size: `int`. A batch size.\n\n        Returns:\n            The mean average result per tensor over all batches.\n\n        """"""\n        tflearn.is_training(False, self.session)\n        coord = tf.train.Coordinator()\n        inputs = tf.get_collection(tf.GraphKeys.INPUTS)\n        # Data Preprocessing\n        dprep_dict = {}\n        dprep_collection = tf.get_collection(tf.GraphKeys.DATA_PREP)\n        for i in range(len(inputs)):\n            # Support for custom inputs not using dprep/daug\n            if len(dprep_collection) > i:\n                if dprep_collection[i] is not None:\n                    dprep_dict[inputs[i]] = dprep_collection[i]\n        # Data Flow\n        df = data_flow.FeedDictFlow(feed_dict, coord,\n                                    batch_size=batch_size,\n                                    dprep_dict=dprep_dict,\n                                    daug_dict=None,\n                                    index_array=None,\n                                    num_threads=1)\n\n        return evaluate_flow(self.session, ops, df)\n'"
tflearn/helpers/generator.py,2,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nfrom ..utils import to_list\n\n\nclass SequenceGenerator(object):\n\n    def __init__(self, net_outputs, model=None, session=None):\n        self.net_outputs = to_list(net_outputs)\n        self.graph = net_outputs[0].graph\n        self.model = model\n\n        with self.graph.as_default():\n            self.session = tf.Session()\n            if session: self.session = session\n            self.saver = tf.train.Saver()\n            if model: self.saver.restore(self.session, model)\n\n    def predict(self, feed_dict):\n        with self.graph.as_default():\n            prediction = []\n            for output in self.net_outputs:\n                o_pred = self.session.run(output, feed_dict=feed_dict).tolist()\n                for i, val in enumerate(o_pred): # Reshape pred per sample\n                    if len(self.net_outputs) > 1:\n                        if not len(prediction) > i: prediction.append([])\n                        prediction[i].append(val)\n                    else:\n                        prediction.append(val)\n            return prediction\n\n    def generate(self):\n        raise NotImplementedError\n'"
tflearn/helpers/regularizer.py,4,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .. import regularizers\n\n\n""""""\nRegularizer contains some useful functions to help add regularization to\nweights and activations.\n""""""\n\n\ndef add_weights_regularizer(variable, loss=""L2"", weight_decay=0.001,\n                            add_to_collection=None):\n    """""" add_weights_regularizer.\n\n    Add a weights regularizer to the provided Tensor\n\n    Arguments:\n        variable: `Variable`. Tensor to add regularization.\n        loss: `str`. Regularization mode.\n        weight_decay: `float`. Decay to use for regularization.\n        add_to_collection: `str`. Add the regularization loss to the\n            specified collection. Default: tf.GraphKeys.REGULARIZATION_LOSSES.\n\n    Returns:\n        `tf.Tensor`. The weight regularizer.\n\n    """"""\n    if not add_to_collection:\n        add_to_collection = tf.GraphKeys.REGULARIZATION_LOSSES\n    if isinstance(loss, str):\n        regul = regularizers.get(loss)\n        weights_regularizer = regul(variable, weight_decay)\n    elif loss and callable(loss):\n        weights_regularizer = loss(variable)\n    else:\n        weights_regularizer = loss\n    if add_to_collection:\n        tf.add_to_collection(add_to_collection, weights_regularizer)\n    return weights_regularizer\n\n\ndef add_activation_regularizer(op, loss=""L2"", activ_decay=0.001,\n                               add_to_collection=None):\n    raise NotImplementedError\n'"
tflearn/helpers/summarizer.py,7,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .. import summaries\n\n# Fix for TF 0.12\ntry:\n    tf012 = True\n    merge_summary = tf.summary.merge\nexcept Exception:\n    tf012 = False\n    merge_summary = tf.merge_summary\n\n""""""\nSummarizer contains some useful functions to help summarize variables,\nactivations etc... in Tensorboard.\n""""""\n\n\ndef summarize_all(train_vars, grads, activations,\n                  summary_collection=""tflearn_summ""):\n    summarize_variables(train_vars, summary_collection)\n    summarize_gradients(grads, summary_collection)\n    return summarize_activations(activations, summary_collection)\n\n\ndef summarize_variables(train_vars=None, summary_collection=""tflearn_summ""):\n    """""" summarize_variables.\n\n    Arguemnts:\n        train_vars: list of `Variable`. The variable weights to monitor.\n        summary_collection: A collection to add this summary to and\n            also used for returning a merged summary over all its elements.\n            Default: \'tflearn_summ\'.\n\n    Returns:\n        `Tensor`. Merge of all summary in \'summary_collection\'\n\n    """"""\n    if not train_vars: train_vars = tf.trainable_variables()\n    summaries.add_trainable_vars_summary(train_vars, """", """", summary_collection)\n    return merge_summary(tf.get_collection(summary_collection))\n\n\ndef summarize_activations(activations, summary_collection=""tflearn_summ""):\n    """""" summarize_activations.\n\n    Arguemnts:\n        activations: list of `Tensor`. The activations to monitor.\n        summary_collection: A collection to add this summary to and\n            also used for returning a merged summary over all its elements.\n            Default: \'tflearn_summ\'.\n\n    Returns:\n        `Tensor`. Merge of all summary in \'summary_collection\'\n\n    """"""\n    summaries.add_activations_summary(activations, """", """", summary_collection)\n    return merge_summary(tf.get_collection(summary_collection))\n\n\ndef summarize_gradients(grads, summary_collection=""tflearn_summ""):\n    """""" summarize_gradients.\n\n    Arguemnts:\n        grads: list of `Tensor`. The gradients to monitor.\n        summary_collection: A collection to add this summary to and\n            also used for returning a merged summary over all its elements.\n            Default: \'tflearn_summ\'.\n\n    Returns:\n        `Tensor`. Merge of all summary in \'summary_collection\'\n\n    """"""\n    summaries.add_gradients_summary(grads, """", """", summary_collection)\n    return merge_summary(tf.get_collection(summary_collection))\n\n\ndef summarize(value, type, name, summary_collection=""tflearn_summ""):\n    """""" summarize.\n\n    A custom summarization op.\n\n    Arguemnts:\n        value: `Tensor`. The tensor value to monitor.\n        type: `str` among \'histogram\', \'scalar\'. The data monitoring type.\n        name: `str`. A name for this summary.\n        summary_collection: A collection to add this summary to and\n            also used for returning a merged summary over all its elements.\n            Default: \'tflearn_summ\'.\n\n    Returns:\n        `Tensor`. Merge of all summary in \'summary_collection\'.\n\n    """"""\n    if tf012:\n        name = name.replace(\':\', \'_\')\n    summaries.get_summary(type, name, value, summary_collection)\n    return merge_summary(tf.get_collection(summary_collection))\n'"
tflearn/helpers/trainer.py,71,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport re\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.training import optimizer as tf_optimizer\n\nimport tflearn\nfrom .. import callbacks as tf_callbacks\nfrom ..config import init_training_mode\nfrom ..utils import to_list, id_generator, check_dir_name, standarize_dict, \\\n    get_dict_first_element, make_batches, slice_array, check_scope_path, \\\n    check_restore_tensor\nfrom .. import data_flow\nfrom .. import variables\nfrom .. import utils\n\nfrom .summarizer import summaries, summarize, summarize_gradients, \\\n    summarize_variables, summarize_activations\n\n# Fix for TF 0.12\ntry:\n    writer_summary = tf.summary.FileWriter\n    merge_summary = tf.summary.merge\nexcept Exception:\n    writer_summary = tf.train.SummaryWriter\n    merge_summary = tf.merge_summary\n\n\nclass Trainer(object):\n    """""" Trainer.\n\n    Generic class to handle any TensorFlow graph training. It requires\n    the use of `TrainOp` to specify all optimization parameters.\n\n    Arguments:\n        train_ops: list of `TrainOp`. A list of a network training\n            operations for performing optimizations.\n        graph: `tf.Graph`. The TensorFlow graph to use. Default: default tf\n            graph.\n        clip_gradients: `float`. Clip gradient. Default: 5.0.\n        tensorboard_dir: `str`. Tensorboard log directory.\n            Default: ""/tmp/tflearn_logs/"".\n        tensorboard_verbose: `int`. Verbose level. It supports:\n            ```python\n            0 - Loss, Accuracy. (Best Speed)\n            1 - Loss, Accuracy, Gradients.\n            2 - Loss, Accuracy, Gradients, Weights.\n            3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity.\n                (Best Visualization)\n            ```\n        checkpoint_path: `str`. Path to store model checkpoints. If None,\n            no model checkpoint will be saved. Default: None.\n        best_checkpoint_path: `str`. Path to store the model when the validation rate reaches its\n            highest point of the current training session and also is above best_val_accuracy. Default: None.\n        max_checkpoints: `int` or None. Maximum amount of checkpoints. If\n            None, no limit. Default: None.\n        keep_checkpoint_every_n_hours: `float`. Number of hours between each\n            model checkpoints.\n        random_seed: `int`. Random seed, for test reproductivity.\n            Default: None.\n        session: `Session`. A session for running ops. If None, a new one will\n            be created. Note: When providing a session, variables must have been\n            initialized already, otherwise an error will be raised.\n        best_val_accuracy: `float` The minimum validation accuracy that needs to be\n            achieved before a model weight\'s are saved to the best_checkpoint_path. This\n            allows the user to skip early saves and also set a minimum save point when continuing\n            to train a reloaded model. Default: 0.0.\n\n    """"""\n\n    def __init__(self, train_ops, graph=None, clip_gradients=5.0,\n                 tensorboard_dir=""/tmp/tflearn_logs/"",\n                 tensorboard_verbose=0, checkpoint_path=None, best_checkpoint_path=None,\n                 max_checkpoints=None,\n                 keep_checkpoint_every_n_hours=10000.0, random_seed=None,\n                 session=None, best_val_accuracy=0.0):\n\n        self.graph = tf.get_default_graph()\n        self.summ_writer = None\n        if graph:\n            self.graph = graph\n\n        with self.graph.as_default():\n\n            init_training_mode()\n\n            train_ops = to_list(train_ops)\n            duplicate_identical_ops(train_ops)\n\n            if random_seed:\n                tf.set_random_seed(random_seed)\n            self.restored = False\n            self.tensorboard_dir = check_dir_name(tensorboard_dir)\n            self.training_state = TrainingState()\n\n            self.train_ops = to_list(train_ops)\n            self.validate_trainop_names()\n\n            self.global_step = tf.Variable(0., name=\'Global_Step\',\n                                           trainable=False)\n            self.incr_global_step = tf.assign(self.global_step,\n                                              tf.add(self.global_step, 1))\n            self.best_val_accuracy = best_val_accuracy\n            self.best_checkpoint_path = best_checkpoint_path\n\n            config = None\n            tflearn_conf = tf.get_collection(tf.GraphKeys.GRAPH_CONFIG)\n            if tflearn_conf:\n                config = tflearn_conf[0]\n\n            if not session:\n                self.session = tf.Session(config=config)\n            else:\n                self.session = session\n                self.restored = True\n\n            self.coord = tf.train.Coordinator()\n\n            for i, train_op in enumerate(self.train_ops):\n\n                # For display simplicity in Tensorboard, if only one optmizer,\n                # we don\'t display its name\n                if len(train_ops) == 1:\n                    train_op.scope_name = """"\n\n                train_op.initialize_training_ops(i, self.session,\n                                                 tensorboard_verbose,\n                                                 clip_gradients)\n\n            # Saver for saving a model\n            self.saver = tf.train.Saver(\n                max_to_keep=max_checkpoints,\n                keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours,\n                allow_empty=True)\n            # Saver for saving a best validation accuracy model\n            if self.best_checkpoint_path:\n                self.val_saver = tf.train.Saver(\n                    max_to_keep=1,\n                    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours,\n                    allow_empty=True)\n            # Saver for restoring a model (With exclude variable list)\n            all_vars = variables.get_all_variables()\n            excl_vars = tf.get_collection(tf.GraphKeys.EXCL_RESTORE_VARS)\n            to_restore = [item for item in all_vars\n                          if check_restore_tensor(item, excl_vars)]\n            self.restorer = tf.train.Saver(\n                var_list=to_restore,\n                max_to_keep=max_checkpoints,\n                keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours,\n                allow_empty=True)\n            # A second Saver, that only restore trainable variables\n            to_restore_trainvars = [item for item in tf.trainable_variables()\n                                    if check_restore_tensor(item, excl_vars)]\n            self.restorer_trainvars = tf.train.Saver(\n                var_list=to_restore_trainvars,\n                max_to_keep=max_checkpoints,\n                keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours,\n                allow_empty=True)\n\n            self.to_restore = to_restore\n            self.to_restore_trainvars = to_restore_trainvars\n            self.checkpoint_path = checkpoint_path\n\n            if not self.restored:\n                # TF 0.12 fix\n                try:\n                    init = tf.group(tf.global_variables_initializer(),\n                                    tf.local_variables_initializer())\n                    self.session.run(tf.variables_initializer(\n                        tf.get_collection_ref(\'is_training\')))\n                except Exception as e:\n                    init = tf.initialize_all_variables()\n                self.session.run(init)\n            # Fix for re-using sessions\n            #initialize_uninit_variables(self.session)\n\n    def fit(self, feed_dicts, n_epoch=10, val_feed_dicts=None, show_metric=False,\n            snapshot_step=None, snapshot_epoch=True, shuffle_all=None,\n            dprep_dict=None, daug_dict=None, excl_trainops=None, run_id=None,\n            callbacks=[]):\n        """""" fit.\n\n        Train network with feeded data dicts.\n\n        Examples:\n            ```python\n            # 1 Optimizer\n            trainer.fit(feed_dicts={input1: X, output1: Y},\n                        val_feed_dicts={input1: X, output1: Y})\n            trainer.fit(feed_dicts={input1: X1, input2: X2, output1: Y},\n                        val_feed_dicts=0.1) # 10% of data used for validation\n\n            # 2 Optimizers\n            trainer.fit(feed_dicts=[{in1: X1, out1:Y}, {in2: X2, out2:Y2}],\n                        val_feed_dicts=[{in1: X1, out1:Y}, {in2: X2, out2:Y2}])\n            ```\n\n        Arguments:\n            feed_dicts: `dict` or list of `dict`. The dictionary to feed\n                data to the network. It follows Tensorflow feed dict\n                specifications: \'{placeholder: data}\'. In case of multiple\n                optimizers, a list of dict is expected, that will\n                respectively feed optimizers.\n            n_epoch: `int`. Number of epoch to runs.\n            val_feed_dicts: `dict`, list of `dict`, `float` or list of\n                `float`. The data used for validation. Feed dict are\n                following the same specification as `feed_dicts` above. It\n                is also possible to provide a `float` for splitting training\n                data for validation (Note that this will shuffle data).\n            show_metric: `bool`. If True, accuracy will be calculated and\n                displayed at every step. Might give slower training.\n            snapshot_step: `int`. If not None, the network will be snapshot\n                every provided step (calculate validation loss/accuracy and\n                save model, if a `checkpoint_path` is specified in `Trainer`).\n            snapshot_epoch: `bool`. If True, snapshot the network at the end\n                of every epoch.\n            shuffle_all: `bool`. If True, shuffle all data batches (overrides\n                `TrainOp` shuffle parameter behavior).\n            dprep_dict: `dict` with `Placeholder` as key and\n                `DataPreprocessing` as value. Apply realtime data\n                preprocessing to the given placeholders (Applied at training\n                and testing time).\n            daug_dict: `dict` with `Placeholder` as key and\n                `DataAugmentation` as value. Apply realtime data\n                augmentation to the given placeholders (Only applied at\n                training time).\n            excl_trainops: `list` of `TrainOp`. A list of train ops to\n                exclude from training process.\n            run_id: `str`. A name for the current run. Used for Tensorboard\n                display. If no name provided, a random one will be generated.\n            callbacks: `Callback` or `list`. Custom callbacks to use in the\n                training life cycle\n        """"""\n\n        if not run_id:\n            run_id = id_generator(6)\n        print(""---------------------------------"")\n        print(""Run id: "" + run_id)\n        print(""Log directory: "" + self.tensorboard_dir)\n\n        original_train_ops = list(self.train_ops)\n        # Remove excluded train_ops\n        if excl_trainops:\n            self.train_ops = list(filter(lambda a: a not in excl_trainops, self.train_ops))\n\t    \n        # shuffle is an override for simplicty, it will overrides every\n        # training op batch shuffling\n        if isinstance(shuffle_all, bool):\n            for t in self.train_ops: t.shuffle = shuffle_all\n\n        with self.graph.as_default():\n\n            # TF 0.12 Fix\n            obj_lists = utils.fix_saver()\n            if self.summ_writer:\n                try:\n                    self.summ_writer.reopen()\n                except:\n                    self.summ_writer = writer_summary(\n                        self.tensorboard_dir + run_id, self.session.graph)\n            else:\n                try:\n                    self.summ_writer = writer_summary(\n                        self.tensorboard_dir + run_id, self.session.graph)\n                except Exception: # TF 0.7\n                    self.summ_writer = writer_summary(\n                        self.tensorboard_dir + run_id, self.session.graph_def)\n            utils.fix_saver(obj_lists)\n\n            feed_dicts = to_list(feed_dicts)\n            for d in feed_dicts: standarize_dict(d)\n            val_feed_dicts = to_list(val_feed_dicts)\n            if val_feed_dicts:\n                [standarize_dict(d) for d in val_feed_dicts if not\n                 isinstance(d, float)]\n\n            termlogger = tf_callbacks.TermLogger()\n            modelsaver = tf_callbacks.ModelSaver(self.save,\n                                              self.checkpoint_path,\n                                              self.best_checkpoint_path,\n                                              self.best_val_accuracy,\n                                              snapshot_step,\n                                              snapshot_epoch)\n\n            for i, train_op in enumerate(self.train_ops):\n                vd = val_feed_dicts[i] if val_feed_dicts else None\n                # Prepare all train_ops for fitting\n                train_op.initialize_fit(feed_dicts[i], vd, dprep_dict,\n                                        daug_dict, show_metric,\n                                        self.summ_writer, self.coord)\n\n                # Prepare TermLogger for training display\n                metric_term_name = None\n                if train_op.metric is not None:\n                    if hasattr(train_op.metric, \'m_name\'):\n                        metric_term_name = train_op.metric.m_name\n                    else:\n                        metric_term_name = train_op.metric.name.split(\':\')[0]\n                termlogger.add(train_op.n_train_samples,\n                               val_size=train_op.n_val_samples,\n                               metric_name=metric_term_name,\n                               name=train_op.name)\n\n            max_batches_len = np.max([t.n_batches for t in self.train_ops])\n\n            caller = tf_callbacks.ChainCallback(callbacks=[termlogger, modelsaver])\n\n            callbacks = to_list(callbacks)\n\n            if callbacks:\n                [caller.add(cb) for cb in callbacks]\n\n            caller.on_train_begin(self.training_state)\n            train_ops_count = len(self.train_ops)\n            snapshot = snapshot_epoch\n\n            try:\n                for epoch in range(n_epoch):\n\n                    self.training_state.increaseEpoch()\n\n                    caller.on_epoch_begin(self.training_state)\n\n                    # Global epoch are defined as loop over all data (whatever\n                    # which data input), so one epoch loop in a multi-inputs\n                    # model is equal to max(data_input) size.\n                    for batch_step in range(max_batches_len):\n\n                        self.training_state.increaseStep()\n                        self.training_state.resetGlobal()\n\n                        caller.on_batch_begin(self.training_state)\n\n                        for i, train_op in enumerate(self.train_ops):\n\n                            caller.on_sub_batch_begin(self.training_state)\n\n                            snapshot = train_op._train(self.training_state.step,\n                                                       (bool(self.best_checkpoint_path) | snapshot_epoch),\n                                                       snapshot_step,\n                                                       show_metric)\n\n                            # Update training state\n                            self.training_state.update(train_op, train_ops_count)\n\n                            # Optimizer batch end\n                            caller.on_sub_batch_end(self.training_state, i)\n\n                        # All optimizers batch end\n                        self.session.run(self.incr_global_step)\n                        caller.on_batch_end(self.training_state, snapshot)\n\n                    # Epoch end\n                    caller.on_epoch_end(self.training_state)\n\n            finally:\n                caller.on_train_end(self.training_state)\n                for t in self.train_ops:\n                    t.train_dflow.interrupt()\n                # Set back train_ops\n                self.train_ops = original_train_ops\n\n        self.summ_writer.close()\n\n    def fit_batch(self, feed_dicts, dprep_dict=None, daug_dict=None):\n        """""" fit_batch.\n\n        Train network with a single batch.\n\n        Arguments:\n            feed_dicts: `dict` or list of `dict`. The dictionary to feed\n                data to the network. It follows Tensorflow feed dict\n                specifications: \'{placeholder: data}\'. In case of multiple\n                optimizers, a list of dict is expected, that will\n                respectively feed optimizers.\n            dprep_dict: `dict` with `Placeholder` as key and\n                `DataPreprocessing` as value. Apply realtime data\n                preprocessing to the given placeholders (Applied at training\n                and testing time).\n            daug_dict: `dict` with `Placeholder` as key and\n                `DataAugmentation` as value. Apply realtime data\n                augmentation to the given placeholders (Only applied at\n                training time).\n        """"""\n        feed_dicts = to_list(feed_dicts)\n        for d in feed_dicts: standarize_dict(d)\n        val_loss = []\n        for train_op in self.train_ops:\n            if daug_dict:\n                for k in daug_dict:\n                    feed_dicts[k] = daug_dict.apply(feed_dicts[k])\n            if dprep_dict:\n                for k in dprep_dict:\n                    feed_dicts[k] = dprep_dict.apply(feed_dicts[k])\n        for d in feed_dicts:\n            val_loss.append(train_op._train_batch(d))\n        if len(val_loss) == 1: val_loss = val_loss[0]\n        return val_loss\n\n    def save(self, model_file, global_step=None, use_val_saver=False):\n        """""" save.\n\n        Save a Tensorflow model\n\n        Arguments:\n            model_file: `str`. Saving path of tensorflow model\n            global_step: `int`. The training step to append to the\n                model file name (optional).\n            use_val_saver: If True, the ""best validation accuracy"" model saver is used\n                instead of the regular training model saver.\n\n        """"""\n        # Temp workaround for tensorflow 0.7+ dict proto serialization issue\n        obj_lists = utils.fix_saver()\n        # TF 0.12 Fix\n        if not os.path.isabs(model_file):\n            model_file = os.path.abspath(os.path.join(os.getcwd(), model_file))\n        if use_val_saver:\n            self.val_saver.save(self.session, model_file, global_step=global_step)\n        else:\n            self.saver.save(self.session, model_file, global_step=global_step)\n        utils.fix_saver(obj_lists)\n\n    def restore(self, model_file, trainable_variable_only=False, variable_name_map=None, scope_for_restore=None,\n                create_new_session=True, verbose=False):\n        """""" restore.\n\n        Restore a Tensorflow model\n\n        Arguments:\n            model_file: path of tensorflow model to restore\n            trainable_variable_only: If True, only restore trainable variables.\n            variable_name_map: - a (pattern, repl) tuple providing a regular expression pattern\n                                 and replacement, which is applied to variable names, before\n                                 restoration from the model file\n                               - OR, a function map_func, used to perform the mapping, called as:\n                                 name_in_file = map_func(existing_var_op_name)\n                                 The function may return None to indicate a variable is not to be\n                                 restored.\n            scope_for_restore: string specifying the scope to limit to, when restoring variables.\n                               Also removes the scope name prefix from the var name to use when restoring.\n            create_new_session: Set to False if the current session is to be kept.  \n                                Set to True (the default) to create a new session, and re-init all variables.\n            verbose           : Set to True to see a printout of what variables are being restored,\n                                when using scope_for_restore or variable_name_map\n        \n        """"""\n        # TF 0.12 Fix\n        if not os.path.isabs(model_file):\n            model_file = os.path.abspath(os.path.join(os.getcwd(), model_file))\n\n        if create_new_session:\n            self.close_session()\n            config = None\n            tflearn_conf = tf.get_collection(tf.GraphKeys.GRAPH_CONFIG)\n            if tflearn_conf:\n                config = tflearn_conf[0]\n            self.session = tf.Session(config=config)\n            # TF 0.12 Fix\n            try:\n                self.session.run([tf.global_variables_initializer(),\n                                  tf.local_variables_initializer()])\n            except Exception:\n                self.session.run(tf.initialize_all_variables())\n\n        if scope_for_restore is not None:\t# allow variables to be restored into a different scope\n            sname = scope_for_restore\n            def vn_map_func(existing_name):\t\t# variable name map function which removes the scope name, e.g.\n                if not existing_name.startswith(sname):  # so that ""scope_name/var_name/... is retrieved from var_name/...\n                    return None\t\t\t# and variables outside of scope_name are not restored\n                name_in_file = re.sub(""^%s/"" % sname, """", existing_name)\n                if verbose:\n                    print (""[%s] Restoring %s <- %s"" % (sname, existing_name, name_in_file))\n                return name_in_file\n            variable_name_map = vn_map_func\n\n        if variable_name_map is not None:\t# general-purpose remapping of variable names (name in file vs existing name)\n            if type(variable_name_map)==tuple:\t# tuple interpreted as regular expression pattern substitution\n                (pattern, repl) = variable_name_map\n                def vn_map_func(existing_name):\n                    name_in_file = re.sub(pattern, repl, existing_name)\n                    if verbose:\n                        print (""Restoring %s <- %s"" % (existing_name, name_in_file))\n                    return name_in_file\n            else:\n                vn_map_func = variable_name_map\t# allow arbitrary user-provided mapping function\n            if trainable_variable_only:\t\t# restore either trainingable variables only, or all variables\n                to_restore = self.to_restore_trainvars\n            else:\n                to_restore = self.to_restore\n            renamed_to_restore = {vn_map_func(v.op.name): v for v in to_restore}\n            if None in renamed_to_restore:\n                renamed_to_restore.pop(None)\n            restorer = tf.train.Saver(var_list=renamed_to_restore)\n            restorer.restore(self.session, model_file)\n        elif not trainable_variable_only:\n            self.restorer.restore(self.session, model_file)\n        else:\n            self.restorer_trainvars.restore(self.session, model_file)\n        for o in self.train_ops:\n            o.session = self.session\n        self.restored = True\n\n        # Restore the training step\n        self.training_state.step = int(self.global_step.eval(self.session))\n\n    def close_session(self):\n        """""" Close session """"""\n        self.session.close()\n\n    def validate_trainop_names(self):\n        """""" Give names to all TrainOp, handle no names and duplicated names """"""\n        t_len = len(self.train_ops)\n        # Rename optimizers without name\n        for i in range(t_len):\n            if not self.train_ops[i].name:\n                self.train_ops[i].name = \'Optimizer\'\n                self.train_ops[i].scope_name = \'Optimizer\'\n        # Handle duplicate names\n        for i in range(t_len):\n            dupl = 0\n            for j in range(i+1, t_len):\n                if not self.train_ops[i].name:\n                    break\n                if self.train_ops[i].name == self.train_ops[j].name:\n                    if dupl == 0:\n                        self.train_ops[i].name += \'_\' + str(dupl)\n                        self.train_ops[i].scope_name = self.train_ops[i].name\n                    dupl += 1\n                    self.train_ops[j].name += \'_\' + str(dupl)\n                    self.train_ops[j].scope_name = self.train_ops[j].name\n\n\nclass TrainOp(object):\n    """""" TrainOp.\n\n    TrainOp represents a set of operation used for optimizing a network.\n\n    A TrainOp is meant to hold all training parameters of an optimizer.\n    `Trainer` class will then instantiate them all specifically considering all\n    optimizers of the network (set names, scopes... set optimization ops...).\n\n    Arguments:\n        loss: `Tensor`. Loss operation to evaluate network cost.\n            Optimizer will use this cost function to train network.\n        optimizer: `Optimizer`. Tensorflow Optimizer. The optimizer to\n            use to train network.\n        metric:  `Tensor`. The metric tensor to be used for evaluation.\n        batch_size: `int`. Batch size for data feeded to this optimizer.\n            Default: 64.\n        ema: `float`. Exponential moving averages.\n        trainable_vars: list of `tf.Variable`. List of trainable variables to\n            use for training. Default: all trainable variables.\n        shuffle: `bool`. Shuffle data.\n        step_tensor: `tf.Tensor`. A variable holding training step. If not\n            provided, it will be created. Early defining the step tensor\n            might be useful for network creation, such as for learning rate\n            decay.\n        validation_monitors: `list` of `Tensor` objects.  List of variables\n            to compute during validation, which are also used to produce\n            summaries for output to TensorBoard.  For example, this can be\n            used to periodically record a confusion matrix or AUC metric, \n            during training.  Each variable should have rank 1, i.e. \n            shape [None].\n        validation_batch_size: `int` or None. If `int`, specifies the batch\n            size to be used for the validation data feed; otherwise \n            defaults to being th esame as `batch_size`.\n        name: `str`. A name for this class (optional).\n        graph: `tf.Graph`. Tensorflow Graph to use for training. Default:\n            default tf graph.\n\n    """"""\n\n    def __init__(self, loss, optimizer, metric=None, batch_size=64, ema=0.,\n                 trainable_vars=None, shuffle=True, step_tensor=None,\n                 validation_monitors=None, validation_batch_size=None,\n                 name=None, graph=None):\n        self.graph = tf.get_default_graph()\n        if graph:\n            self.graph = graph\n\n        self.name = name\n        self.scope_name = name\n\n        # Ops\n        self.loss = loss\n        self.optimizer = optimizer\n        self.metric = metric\n        self.metric_summ_name = """"\n        if metric is not None:\n            self.metric_summ_name = metric.name.split(\'/\')[0]\n        if isinstance(validation_monitors, tf.Tensor):\n            validation_monitors = [validation_monitors]\n        self.validation_monitors = validation_monitors or []\n        self.grad = None\n        self.apply_grad = None\n        self.summ_op = None\n        self.val_summary_op = None\n\n        self.train_vars = trainable_vars\n        self.shuffle = shuffle\n\n        self.batch_size = batch_size\n        self.validation_batch_size = validation_batch_size or batch_size\n        self.n_batches = 0\n\n        self.ema = ema\n\n        self.feed_dict = None\n        self.val_feed_dict = None\n        self.loss_value = None\n        self.val_loss = None\n        self.acc_value = None\n        self.val_acc = None\n\n        if step_tensor is None:\n            with self.graph.as_default():\n                self.training_steps = tf.Variable(0., name=""Training_step"",\n                                                  trainable=False)\n        else:\n            self.training_steps = step_tensor\n\n        # Building\n        if not isinstance(self.loss, tf.Tensor):\n            raise ValueError(""Unknown Loss type"")\n\n        if not isinstance(self.optimizer, tf_optimizer.Optimizer):\n            raise ValueError(""Unknown Optimizer"")\n\n        if self.train_vars is None:\n            self.train_vars = tf.trainable_variables()\n        else:\n            self.train_var = to_list(self.train_vars)\n\n        self.train = None\n\n    def initialize_training_ops(self, i, session, tensorboard_verbose,\n                                clip_gradients):\n        """""" initialize_training_ops.\n\n        Initialize all ops used for training. Because a network can have\n        multiple optimizers, an id \'i\' is allocated to differentiate them.\n        This is meant to be used by `Trainer` when initializing all train ops.\n\n        Arguments:\n            i: `int`. This optimizer training process ID.\n            session: `tf.Session`. The session used to train the network.\n            tensorboard_verbose: `int`. Logs verbose. Supports:\n                ```\n                0 - Loss, Accuracy.\n                1 - Loss, Accuracy, Gradients.\n                2 - Loss, Accuracy, Gradients, Weights.\n                3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity..\n                ```\n            clip_gradients: `float`. Option for clipping gradients.\n        """"""\n        self.session = session\n\n        # Variables holding mean validation loss, accuracy, and validation\n        # monitors, assigned after each model evaluation (by batch).\n        # For visualization in Tensorboard.\n        # Define variables, placeholders and assign ops.\n        self.val_loss_T = tf.Variable(0., name=\'val_loss\', trainable=False)\n        self.val_acc_T = tf.Variable(0., name=\'val_acc\', trainable=False)\n        self.validation_monitors_T = [tf.Variable(0., name=\'%s_T\' % v.name.rsplit(\':\', 1)[0], trainable=False) for v in self.validation_monitors]\n\n        self.val_loss_P = tf.placeholder(dtype=tf.float32, name=\'placeholder/%s\' % self.val_loss_T.name.rsplit(\':\')[0])\n        self.val_acc_P = tf.placeholder(dtype=tf.float32, name=\'placeholder/%s\' % self.val_acc_T.name.rsplit(\':\')[0])\n        self.val_monitors_P = [tf.placeholder(dtype=tf.float32, name=\'placeholder/%s\' % v.name.rsplit(\':\')[0]) for v in self.validation_monitors_T]\n\n        self.val_loss_assign = tf.assign(self.val_loss_T, self.val_loss_P,\n                                         name=\'assign/%s\' % self.val_loss_T.name.rsplit(\':\')[0])\n        self.val_acc_assign = tf.assign(self.val_acc_T, self.val_acc_P,\n                                        name=\'assign/%s\' % self.val_acc_T.name.rsplit(\':\')[0])\n        self.val_monitors_assign = [tf.assign(vmt, vmp, name=\'assign/%s\' % vmt.name.rsplit(\':\')[0]) for vmt, vmp in\n                                    zip(self.validation_monitors_T, self.val_monitors_P)]\n\n        # Creating the accuracy moving average, for better visualization.\n        if self.metric is not None:\n            self.acc_averages = \\\n                tf.train.ExponentialMovingAverage(0.9, self.training_steps,\n                                                  name=\'moving_avg\')\n            acc_avg_op = self.acc_averages.apply([self.metric])\n        else:\n            acc_avg_op = tf.no_op()\n\n        # Compute total loss, which is the loss of all optimizers plus the\n        # loss of all regularizers. Then, we summarize those losses for\n        # visualization in Tensorboard.\n        with tf.name_scope(self.name):\n            lss = [self.loss] + tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n            total_loss = tf.add_n(lss, name=""Total_Loss"")\n            loss_avg_op = summaries.add_loss_summaries(\n                total_loss,\n                self.loss,\n                regul_losses_collection_key=tf.GraphKeys.REGULARIZATION_LOSSES,\n                name_prefix=self.scope_name,\n                summaries_collection_key=self.name + ""_training_summaries"",\n                exp_moving_avg=0.9,\n                ema_num_updates=self.training_steps)\n\n            # Compute gradients operations\n            with tf.control_dependencies([loss_avg_op, acc_avg_op]):\n                self.grad = tf.gradients(total_loss, self.train_vars)\n                if clip_gradients > 0.0:\n                    self.grad, self.grad_norm = \\\n                        tf.clip_by_global_norm(self.grad, clip_gradients)\n\n            self.grad = list(zip(self.grad, self.train_vars))\n            self.apply_grad = self.optimizer.apply_gradients(\n                    grads_and_vars=self.grad,\n                    global_step=self.training_steps,\n                    name=""apply_grad_op_"" + str(i))\n\n            # Create other useful summary (weights, grads, activations...)\n            # according to \'tensorboard_verbose\' level.\n            self.create_summaries(tensorboard_verbose)\n\n            # Track the moving averages of trainable variables\n            if self.ema > 0.:\n                var_averages = tf.train.ExponentialMovingAverage(\n                        self.ema, self.training_steps)\n                var_averages_op = var_averages.apply(self.train_vars)\n\n                with tf.control_dependencies([var_averages_op]):\n                    with tf.control_dependencies([self.apply_grad]):\n                        self.train = tf.no_op(name=""train_op_"" + str(i))\n            else:\n                with tf.control_dependencies([self.apply_grad]):\n                    self.train = tf.no_op(name=""train_op_"" + str(i))\n\n    def initialize_fit(self, feed_dict, val_feed_dict, dprep_dict, daug_dict,\n                       show_metric, summ_writer, coord):\n        """""" initialize_fit.\n\n        Initialize data for feeding the training process. It is meant to\n        be used by `Trainer` before starting to fit data.\n\n        Arguments:\n            feed_dict: `dict`. The data dictionary to feed.\n            val_feed_dict: `dict` or `float`. The validation data dictionary to\n                feed or validation split.\n            dprep_dict: `dict`. Data Preprocessing dict (with placeholder as\n                key and corresponding `DataPreprocessing` object as value).\n            daug_dict: `dict`. Data Augmentation dict (with placeholder as\n                key and corresponding `DataAugmentation` object as value).\n            show_metric: `bool`. If True, display accuracy at every step.\n            summ_writer: `SummaryWriter`. The summary writer to use for\n                Tensorboard logging.\n\n        """"""\n        self.summary_writer = summ_writer\n        self.feed_dict = feed_dict\n        self.val_feed_dict = val_feed_dict\n        self.n_train_samples = len(get_dict_first_element(feed_dict))\n\n        self.index_array = np.arange(self.n_train_samples)\n        self.n_val_samples = 0\n        # Validation Split\n        #TODO: Optional per key validation split\n        if isinstance(val_feed_dict, float):\n            split_at = int(self.n_train_samples * (1 - val_feed_dict))\n            # Shuffle Data\n            np.random.shuffle(self.index_array)\n            self.val_index_array = self.index_array[split_at:]\n            self.index_array = self.index_array[:split_at]\n            self.n_train_samples = len(self.index_array)\n            self.n_val_samples = len(self.val_index_array)\n            val_feed_dict = feed_dict\n        elif val_feed_dict is not None:\n            self.val_index_array = None\n            self.n_val_samples = len(get_dict_first_element(val_feed_dict))\n\n        if dprep_dict:\n            for k in dprep_dict:\n                assert feed_dict[k] is not None, \\\n                    ""Unknown DataPreprocessing dict key!""\n                dprep_dict[k].initialize(feed_dict[k], self.session)\n        self.train_dflow = data_flow.FeedDictFlow(feed_dict, coord,\n                                                  continuous=True,\n                                                  batch_size=self.batch_size,\n                                                  dprep_dict=dprep_dict,\n                                                  daug_dict=daug_dict,\n                                                  index_array=self.index_array,\n                                                  num_threads=1,\n                                                  shuffle=self.shuffle)\n\n        self.n_batches = len(self.train_dflow.batches)\n        self.train_dflow.start()\n        # TODO: Optimize data_flow to not start/restart threads (cost time)\n        # every time testing\n        if val_feed_dict:\n            self.test_dflow = data_flow.FeedDictFlow(val_feed_dict, coord,\n                                                     batch_size=self.validation_batch_size,\n                                                     dprep_dict=dprep_dict,\n                                                     daug_dict=None,\n                                                     index_array=self.val_index_array,\n                                                     num_threads=1)\n\n        self.create_testing_summaries(show_metric, self.metric_summ_name,\n                                      val_feed_dict)\n\n    def _train(self, training_step, snapshot_epoch, snapshot_step,\n               show_metric):\n        """""" _train.\n\n        Training process for this optimizer.\n\n        Arguments:\n            training_step: `int`. The global step.\n            snapshot_epoch: `bool`. If True, snapshot network at each epoch.\n            snapshot_step: `int`. If not None, snapshot network given \'step\'.\n            show_metric: `bool`. If True, display accuracy at every step.\n\n        """"""\n        self.loss_value, self.acc_value = None, None\n        self.val_loss, self.val_acc = None, None\n        train_summ_str, test_summ_str = None, None\n        snapshot = False\n        epoch = self.train_dflow.data_status.epoch\n\n        feed_batch = self.train_dflow.next()\n        tflearn.is_training(True, session=self.session)\n        _, train_summ_str = self.session.run([self.train, self.summ_op],\n                                             feed_batch)\n\n        # Retrieve loss value from summary string\n        sname = ""Loss/"" + self.scope_name\n        self.loss_value = summaries.get_value_from_summary_string(\n            sname, train_summ_str)\n\n        if show_metric and self.metric is not None:\n            # Retrieve accuracy value from summary string\n            sname = self.metric_summ_name + ""/"" + self.scope_name\n            self.acc_value = summaries.get_value_from_summary_string(\n                sname, train_summ_str)\n\n        if epoch != self.train_dflow.data_status.epoch:\n            if snapshot_epoch:\n                snapshot = True\n\n        # Check if step reached snapshot step\n        if snapshot_step:\n            if training_step % snapshot_step == 0:\n                snapshot = True\n\n        # Calculate validation\n        if snapshot and self.val_feed_dict:\n            tflearn.is_training(False, session=self.session)\n            # Evaluation returns the mean over all batches.\n            eval_ops = [self.loss] + self.validation_monitors\t# compute loss as well as any extra validation monotor tensors\n            if show_metric and self.metric is not None:\n                eval_ops.append(self.metric)\n            e = evaluate_flow(self.session, eval_ops, self.test_dflow)\n            self.val_loss = e[0]\n            if show_metric and self.metric is not None:\n                self.validation_monitor_values = e[1:-1]\n                self.val_acc = e[-1]\n            else:\n                self.validation_monitor_values = e[1:]\n\n            # Set evaluation results to variables, to be summarized.\n            update_val_op = [self.val_loss_assign]\n            update_val_feed = {self.val_loss_P: self.val_loss}\n            if show_metric:\n                update_val_op.append(self.val_acc_assign)\n                update_val_feed[self.val_acc_P] = self.val_acc\n            if self.validation_monitors:\n                update_val_op.append(self.val_monitors_assign)\n                for vmp, vmv in zip(self.val_monitors_P, self.validation_monitor_values):\n                    update_val_feed[vmp] = vmv\n\n            self.session.run(update_val_op, feed_dict=update_val_feed)\n\n            # Run summary operation.\n            test_summ_str = self.session.run(self.val_summary_op)\n\n        # Write to Tensorboard\n        #TODO: Delete?\n        n_step = self.training_steps.eval(session=self.session)\n        if n_step > 1:\n            if train_summ_str:\n                self.summary_writer.add_summary(\n                    train_summ_str, n_step)\n            if test_summ_str:\n                self.summary_writer.add_summary(\n                    test_summ_str, n_step)\n\n        return snapshot\n\n    def _train_batch(self, feed_dict):\n        """""" _train_batch.\n\n        Train on a single batch.\n\n        Arguments:\n            feed_dict: `dict`. The data dictionary to feed.\n\n        """"""\n        tflearn.is_training(True, session=self.session)\n        _, loss, _ = self.session.run([self.train, self.loss, self.summ_op],\n                                      feed_dict=feed_dict)\n        tflearn.is_training(False, session=self.session)\n        return loss\n\n    def duplicate(self):\n        """""" Returns a duplicated `TrainOp` """"""\n        return TrainOp(self.loss, optimizer=self.optimizer,\n                       batch_size=self.batch_size, ema=self.ema,\n                       metric=self.metric,\n                       trainable_vars=self.train_vars,\n                       shuffle=self.shuffle)\n\n    def create_summaries(self, verbose=2):\n        """""" Create summaries with `verbose` level """"""\n\n        summ_collection = self.name + ""_training_summaries""\n\n        if verbose in [3]:\n            # Summarize activations\n            activations = tf.get_collection(tf.GraphKeys.ACTIVATIONS)\n            summarize_activations(activations, summ_collection)\n        if verbose in [2, 3]:\n            # Summarize variable weights\n            summarize_variables(self.train_vars, summ_collection)\n        if verbose in [1, 2, 3]:\n            # Summarize gradients\n            summarize_gradients(self.grad, summ_collection)\n\n        self.summ_op = merge_summary(tf.get_collection(summ_collection))\n\n    def create_testing_summaries(self, show_metric=False,\n                                 metric_name=""Accuracy"", validation_set=None):\n        """""" Create accuracy and validation summaries """"""\n\n        tr_summ_collection = self.name + ""_training_summaries""\n        te_summ_collection = self.name + ""_testing_summaries""\n\n        mn = metric_name.replace(\'/Mean:0/\', \'\')\n\n        if show_metric and self.metric is not None:\n            # Summarize Raw Accuracy\n            sname = mn + ""/"" + self.scope_name + "" (raw)""\n            summarize(self.metric, ""scalar"", sname, tr_summ_collection)\n            # Summarize Accuracy\'s moving averages\n            sname = mn + ""/"" + self.scope_name\n            self.summ_op = summarize(self.acc_averages.average(self.metric),\n                                     ""scalar"", sname, tr_summ_collection)\n\n        if validation_set is not None:\n            # Summarive Validation Loss\n            loss_val_name = ""Loss/"" + self.scope_name + ""/Validation""\n            loss_val_name = check_scope_path(loss_val_name)\n            self.val_summary_op = summarize(self.val_loss_T, ""scalar"",\n                                            loss_val_name, te_summ_collection)\n            if show_metric and self.metric is not None:\n                # Summarize Validation Accuracy\n                acc_val_name = mn + ""/"" + self.scope_name + ""/Validation""\n                acc_val_name = check_scope_path(acc_val_name)\n                self.val_summary_op = summarize(self.val_acc_T, ""scalar"",\n                                                acc_val_name,\n                                                te_summ_collection)\n            if self.validation_monitors:\n                # add summaries of additional validation monitor variables\n                for vm_op in self.validation_monitors_T:\n                    vm_name = vm_op.name + ""/"" + self.scope_name + ""/Validation""\n                    vm_name = check_scope_path(vm_name)\n                    self.val_summary_op = summarize(vm_op, ""scalar"",\n                                                    vm_name,\n                                                    te_summ_collection)\n\n\ndef duplicate_identical_ops(ops):\n    """""" Duplicate identical `TrainOp` """"""\n    for i in range(len(ops)):\n        for j in range(i+1, len(ops)):\n            if ops[i] == ops[j]:\n                ops[j] = ops[i].duplicate()\n\n\ndef get_current_batch_size(feed_batch, dataflow):\n    if hasattr(feed_batch, \'iteritems\'):\n        iterator = feed_batch.iteritems\n    else:\n        iterator = feed_batch.items\n    for k, v in iterator():\n        if k.get_shape()[0].value == None:\n            if type(v) is list:\n              return len(v)\n            else:\n              return int(v.shape[0])\n    return dataflow.batch_size\n\n\ndef evaluate_flow(session, ops_to_evaluate, dataflow):\n        if not isinstance(ops_to_evaluate, list):\n            ops_to_evaluate = [ops_to_evaluate]\n        tflearn.is_training(False, session)\n        dataflow.reset()\n        dataflow.start()\n        res = [0. for i in ops_to_evaluate]\n        feed_batch = dataflow.next()\n\n        while feed_batch:\n            r = session.run(ops_to_evaluate, feed_batch)\n            current_batch_size = get_current_batch_size(feed_batch, dataflow)\n            for i in range(len(r)):\n                res[i] += r[i] * current_batch_size\n            feed_batch = dataflow.next()\n        res = [r / dataflow.n_samples for r in res]\n        return res\n\n\ndef evaluate(session, op_to_evaluate, feed_dict, batch_size):\n        """""" evaluate.\n\n        Evaluate an operation with provided data dict using a batch size\n        to save GPU memory.\n\n        Args:\n            session: `tf.Session`. Session for running operations.\n            op_to_evaluate: `tf.Op`. Operation to be evaluated.\n            feed_dict: `dict`. Data dictionary to feed op_to_evaluate.\n            batch_size: `int`. Batch size to be used for evaluation.\n\n        Ret:\n            `float`. op_to_evaluate mean over all batches.\n\n        """"""\n        tflearn.is_training(False, session)\n        n_test_samples = len(get_dict_first_element(feed_dict))\n        batches = make_batches(n_test_samples, batch_size)\n        index_array = np.arange(n_test_samples)\n        avg = 0.0\n        for i, (batch_start, batch_end) in enumerate(batches):\n            batch_ids = index_array[batch_start:batch_end]\n            feed_batch = {}\n            for key in feed_dict:\n                # Make batch for multi-dimensional data\n                if np.ndim(feed_dict[key]) > 0:\n                    feed_batch[key] = slice_array(feed_dict[key], batch_ids)\n                else:\n                    feed_batch[key] = feed_dict[key]\n            avg += session.run(op_to_evaluate, feed_batch) / len(batches)\n        return avg\n\n\nclass TrainingState(object):\n\n    def __init__(self):\n        self.epoch = 0\n        self.step = 0\n        self.current_iter = 0\n        self.step_time = 0.0\n\n        self.acc_value = None\n        self.loss_value = None\n\n        self.val_acc = None\n        self.val_loss = None\n\n        self.best_accuracy = 0.0\n\n        self.global_acc = 0.0\n        self.global_loss = 0.0\n\n    def update(self, train_op, train_ops_count = 1):\n\n        data_status = train_op.train_dflow.data_status\n\n        self.acc_value = train_op.acc_value\n        self.loss_value = train_op.loss_value\n        self.val_acc = train_op.val_acc\n        self.val_loss = train_op.val_loss\n        self.current_iter = data_status.current_iter\n\n        # Update best validation accuracy\n        if self.val_acc is not None and self.val_acc > self.best_accuracy:\n            self.best_accuracy = self.val_acc\n\n        # Update global values\n        self.global_loss += self.loss_value\n\n        if self.acc_value and self.global_acc:\n            self.global_acc += self.acc_value / train_ops_count\n        else:\n            self.global_acc = None\n\n    def increaseEpoch(self):\n        self.epoch += 1\n\n    def increaseStep(self):\n        self.step += 1\n\n    def resetGlobal(self):\n        self.global_acc = 0.0\n        self.global_loss = 0.0\n\n\n# def initialize_uninit_variables(session, list_of_variables=None):\n#     if list_of_variables is None:\n#         list_of_variables = tf.global_variables()\n#     uninitialized_variables = list(tf.get_variable(name) for name in\n#                                    session.run(tf.report_uninitialized_variables(list_of_variables)))\n#     session.run(tf.variables_initializer(uninitialized_variables))\n#     return uninitialized_variables\n'"
tflearn/layers/__init__.py,0,"b'from __future__ import absolute_import\nfrom .conv import conv_2d, max_pool_2d, avg_pool_2d, conv_1d, \\\n    max_pool_1d, avg_pool_1d, residual_block, residual_bottleneck, \\\n    highway_conv_1d, highway_conv_2d, upsample_2d, conv_3d, max_pool_3d, \\\n    avg_pool_3d, resnext_block, upscore_layer, deconv_2d, densenet_block\nfrom .core import input_data, dropout, custom_layer, reshape, flatten, \\\n    activation, fully_connected, single_unit, one_hot_encoding, time_distributed, \\\n    multi_target_data\nfrom .normalization import batch_normalization, local_response_normalization\nfrom .estimator import regression\nfrom .recurrent import lstm, gru, simple_rnn, bidirectional_rnn, \\\n    BasicRNNCell, BasicLSTMCell, GRUCell\nfrom .embedding_ops import embedding\nfrom .merge_ops import merge, merge_outputs\n'"
tflearn/layers/conv.py,165,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport numpy as np\nfrom math import ceil\n\nimport tflearn\nfrom .. import variables as vs\nfrom .. import activations\nfrom .. import initializations\nfrom .. import regularizers\nfrom .. import utils\nfrom ..layers.normalization import batch_normalization\n\n\ndef conv_2d(incoming, nb_filter, filter_size, strides=1, padding=\'same\',\n            activation=\'linear\', bias=True, weights_init=\'uniform_scaling\',\n            bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n            trainable=True, restore=True, reuse=False, scope=None,\n            name=""Conv2D""):\n    """""" Convolution 2D.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or list of `int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`) or None.\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    strides = utils.autoformat_kernel_2d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = tf.nn.conv2d(incoming, W, strides, padding)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if activation:\n            if isinstance(activation, str):\n                inference = activations.get(activation)(inference)\n            elif hasattr(activation, \'__call__\'):\n                inference = activation(inference)\n            else:\n                raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef conv_2d_transpose(incoming, nb_filter, filter_size, output_shape,\n                      strides=1, padding=\'same\', activation=\'linear\',\n                      bias=True, weights_init=\'uniform_scaling\',\n                      bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n                      trainable=True, restore=True, reuse=False, scope=None,\n                      name=""Conv2DTranspose""):\n\n    """""" Convolution 2D Transpose.\n\n    This operation is sometimes called ""deconvolution"" after (Deconvolutional\n    Networks)[http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf], but is\n    actually the transpose (gradient) of `conv_2d` rather than an actual\n    deconvolution.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        output_shape: `list of int`. Dimensions of the output tensor.\n            Can optionally include the number of conv filters.\n            [new height, new width, nb_filter] or [new height, new width].\n        strides: `int` or list of `int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2DTranspose\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 nb_filter,\n                                                 input_shape[-1])\n    strides = utils.autoformat_kernel_2d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size,\n                        regularizer=W_regul, initializer=W_init,\n                        trainable=trainable, restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Determine the complete shape of the output tensor.\n        batch_size = tf.gather(tf.shape(incoming), tf.constant([0]))\n        if len(output_shape) == 2:\n            output_shape = output_shape + [nb_filter]\n        elif len(output_shape) != 3:\n            raise Exception(""output_shape length error: ""\n                            + str(len(output_shape))\n                            + "", only a length of 2 or 3 is supported."")\n        complete_out_shape = tf.concat([batch_size, tf.constant(output_shape)], 0)\n\n        inference = tf.nn.conv2d_transpose(incoming, W, complete_out_shape,\n                                           strides, padding)\n\n        # Reshape tensor so its shape is correct.\n        inference.set_shape([None] + output_shape)\n\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if isinstance(activation, str):\n            inference = activations.get(activation)(inference)\n        elif hasattr(activation, \'__call__\'):\n            inference = activation(inference)\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef atrous_conv_2d(incoming, nb_filter, filter_size, rate=1, padding=\'same\',\n                   activation=\'linear\', bias=True, weights_init=\'uniform_scaling\',\n                   bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n                   trainable=True, restore=True, reuse=False, scope=None,\n                   name=""AtrousConv2D""):\n    """""" Atrous Convolution 2D.\n\n    (a.k.a. convolution with holes or dilated convolution).\n\n    Computes a 2-D atrous convolution, also known as convolution with holes or\n    dilated convolution, given 4-D value and filters tensors. If the rate\n    parameter is equal to one, it performs regular 2-D convolution. If the rate\n    parameter is greater than one, it performs convolution with holes, sampling\n    the input values every rate pixels in the height and width dimensions. This\n    is equivalent to convolving the input with a set of upsampled filters,\n    produced by inserting rate - 1 zeros between two consecutive values of the\n    filters along the height and width dimensions, hence the name atrous\n    convolution or convolution with holes (the French word trous means holes\n    in English).\n\n    More specifically\n    ```\n    output[b, i, j, k] = sum_{di, dj, q} filters[di, dj, q, k] *\n        value[b, i + rate * di, j + rate * dj, q]\n    ```\n\n    Atrous convolution allows us to explicitly control how densely to compute\n    feature responses in fully convolutional networks. Used in conjunction\n    with bilinear interpolation, it offers an alternative to conv2d_transpose\n    in dense prediction tasks such as semantic image segmentation,\n    optical flow computation, or depth estimation. It also allows us to\n    effectively enlarge the field of view of filters without increasing the\n    number of parameters or the amount of computation.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        rate: `int`.  A positive int32. The stride with which we sample input\n            values across the height and width dimensions. Equivalently, the\n            rate by which we upsample the filter values by inserting zeros\n            across the height and width dimensions. In the literature, the\n            same parameter is sometimes called input `stride` or `dilation`.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`) or None.\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = tf.nn.atrous_conv2d(incoming, W, rate, padding)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if activation:\n            if isinstance(activation, str):\n                inference = activations.get(activation)(inference)\n            elif hasattr(activation, \'__call__\'):\n                inference = activation(inference)\n            else:\n                raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef grouped_conv_2d(incoming, channel_multiplier, filter_size, strides=1,\n                    padding=\'same\', activation=\'linear\', bias=False,\n                    weights_init=\'uniform_scaling\', bias_init=\'zeros\',\n                    regularizer=None, weight_decay=0.001, trainable=True,\n                    restore=True, reuse=False, scope=None,\n                    name=""GroupedConv2D""):\n    """""" Grouped Convolution 2D.\n\n    a.k.a DepthWise Convolution 2D.\n\n    Given a 4D input tensor (\'NHWC\' or \'NCHW\' data formats), a kernel_size and\n    a channel_multiplier, grouped_conv_2d applies a different filter to each\n    input channel (expanding from 1 channel to channel_multiplier channels\n    for each), then concatenates the results together. The output has\n    in_channels * channel_multiplier channels.\n\n    In detail,\n    ```\n    output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}\n         filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,\n                                         strides[2] * j + rate[1] * dj, k]\n    ```\n    Must have strides[0] = strides[3] = 1. For the most common case of the same\n    horizontal and vertical strides, strides = [1, stride, stride, 1]. If any\n    value in rate is greater than 1, we perform atrous depthwise convolution,\n    in which case all values in the strides tensor must be equal to 1.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, in_channels * channel_multiplier].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        channel_multiplier: `int`. The number of channels to expand to.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or list of `int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`) or None.\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    nb_filter = channel_multiplier * input_shape[-1]\n\n    strides = utils.autoformat_kernel_2d(strides)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 channel_multiplier)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = tf.nn.depthwise_conv2d(incoming, W, strides, padding)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if activation:\n            if isinstance(activation, str):\n                inference = activations.get(activation)(inference)\n            elif hasattr(activation, \'__call__\'):\n                inference = activation(inference)\n            else:\n                raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef max_pool_2d(incoming, kernel_size, strides=None, padding=\'same\',\n                name=""MaxPool2D""):\n    """""" Max Pooling 2D.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: same as kernel_size.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'MaxPool2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_2d(kernel_size)\n    strides = utils.autoformat_kernel_2d(strides) if strides else kernel\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.max_pool(incoming, kernel, strides, padding)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef avg_pool_2d(incoming, kernel_size, strides=None, padding=\'same\',\n                name=""AvgPool2D""):\n    """""" Average Pooling 2D.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: same as kernel_size.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'AvgPool2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_2d(kernel_size)\n    strides = utils.autoformat_kernel_2d(strides) if strides else kernel\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.avg_pool(incoming, kernel, strides, padding)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef upsample_2d(incoming, kernel_size, name=""UpSample2D""):\n    """""" UpSample 2D.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer to upsample.\n        kernel_size: `int` or `list of int`. Upsampling kernel size.\n        name: A name for this layer (optional). Default: \'UpSample2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n    kernel = utils.autoformat_kernel_2d(kernel_size)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.image.resize_nearest_neighbor(\n            incoming, size=input_shape[1:3] * tf.constant(kernel[1:3]))\n        inference.set_shape((None, input_shape[1] * kernel[1],\n                            input_shape[2] * kernel[2], None))\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n# Shortcut\ndeconv_2d = upsample_2d\n\n\ndef upscore_layer(incoming, num_classes, shape=None, kernel_size=4,\n                  strides=2, trainable=True, restore=True,\n                  reuse=False, scope=None, name=\'Upscore\'):\n    """""" Upscore.\n\n    This implements the upscore layer as used in\n    (Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038].\n    The upscore layer is initialized as bilinear upsampling filter.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [pooled height, pooled width].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer to upsample.\n        num_classes: `int`. Number of output feature maps.\n        shape: `list of int`. Dimension of the output map\n            [batch_size, new height, new width]. For convinience four values\n             are allows [batch_size, new height, new width, X], where X\n             is ignored.\n        kernel_size: `int` or `list of int`. Upsampling kernel size.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: [1 2 2 1].\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n            name: A name for this layer (optional). Default: \'Upscore\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    Links:\n        (Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038]\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    strides = utils.autoformat_kernel_2d(strides)\n    filter_size = utils.autoformat_filter_conv2d(kernel_size,\n                                                 num_classes,\n                                                 input_shape[-1])\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        in_shape = tf.shape(incoming)\n        if shape is None:\n            # Compute shape out of Bottom\n\n            h = ((in_shape[1] - 1) * strides[1]) + 1\n            w = ((in_shape[2] - 1) * strides[1]) + 1\n            new_shape = [in_shape[0], h, w, num_classes]\n        else:\n            new_shape = [in_shape[0], shape[0], shape[1], num_classes]\n        output_shape = tf.stack(new_shape)\n\n        def get_deconv_filter(f_shape):\n            """"""\n            Create filter weights initialized as bilinear upsampling.\n            """"""\n            width = f_shape[0]\n            heigh = f_shape[0]\n            f = ceil(width/2.0)\n            c = (2 * f - 1 - f % 2) / (2.0 * f)\n            bilinear = np.zeros([f_shape[0], f_shape[1]])\n            for x in range(width):\n                for y in range(heigh):\n                    value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n                    bilinear[x, y] = value\n            weights = np.zeros(f_shape)\n            for i in range(f_shape[2]):\n                weights[:, :, i, i] = bilinear\n\n            init = tf.constant_initializer(value=weights,\n                                           dtype=tf.float32)\n            W = vs.variable(name=""up_filter"", initializer=init,\n                            shape=weights.shape, trainable=trainable,\n                            restore=restore)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n            return W\n\n        weights = get_deconv_filter(filter_size)\n        deconv = tf.nn.conv2d_transpose(incoming, weights, output_shape,\n                                        strides=strides, padding=\'SAME\')\n\n    deconv.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, deconv)\n\n    return deconv\n\ndef upscore_layer3d(incoming, num_classes, shape=None, kernel_size=4,\n                  strides=2, trainable=True, restore=True,\n                  reuse=False, scope=None, name=\'Upscore\'):\n    """""" Upscore.\n\n    This implements the upscore layer as used in\n    (Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038].\n    The upscore layer is initialized as bilinear upsampling filter.\n\n    Input:\n        5-D Tensor [batch, height, width, depth, in_channels].\n\n    Output:\n        5-D Tensor [batch, pooled height, pooled width, pooled depth, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer to upsample.\n        num_classes: `int`. Number of output feature maps.\n        shape: `list of int`. Dimension of the output map\n            [new height, new width, new depth]. For convinience four values\n             are allows [new height, new width, new depth, X], where X\n             is ignored.\n        kernel_size: \'int` or `list of int`. Upsampling kernel size.\n        strides: \'int` or `list of int`. Strides of conv operation.\n            Default: [1 2 2 2 1].\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n            name: A name for this layer (optional). Default: \'Upscore\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    Links:\n        (Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038]\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 5, ""Incoming Tensor shape must be 5-D, not %d-D"" % len(input_shape)\n\n    strides = utils.autoformat_kernel_3d(strides)\n    filter_size = utils.autoformat_filter_conv3d(kernel_size,\n                                                 num_classes,\n                                                 input_shape[-1])\n\n    # Variable Scope fix for older TF\n    try:\n        vscope = tf.variable_scope(scope, default_name=name, values=[incoming],\n                                   reuse=reuse)\n    except Exception:\n        vscope = tf.variable_op_scope([incoming], scope, name, reuse=reuse)\n\n    with vscope as scope:\n        name = scope.name\n\n        in_shape = tf.shape(incoming)\n        if shape is None:\n            # Compute shape out of Bottom\n\n            h = ((in_shape[1] - 1) * strides[1]) + 1\n            w = ((in_shape[2] - 1) * strides[1]) + 1\n            d = ((in_shape[3] - 1) * strides[1]) + 1\n            new_shape = [in_shape[0], h, w, d, num_classes]\n        else:\n            new_shape = [in_shape[0], shape[0], shape[1], shape[2], num_classes]\n        output_shape = tf.stack(new_shape)\n\n        def get_deconv_filter(f_shape):\n            """"""\n            Create filter weights initialized as bilinear upsampling.\n            """"""\n            width = f_shape[0]\n            heigh = f_shape[0]\n            depth = f_shape[0]\n            f = ceil(width/2.0)\n            c = (2 * f - 1 - f % 2) / (2.0 * f)\n            bilinear = np.zeros([f_shape[0], f_shape[1], f_shape[2]])\n            for x in range(width):\n                for y in range(heigh):\n                    for z in range(depth):\n                        value = (1 - abs(x / f - c)) * (1 - abs(y / f - c)) * (1 - abs(z / f - c))\n                        bilinear[x, y, z] = value\n            weights = np.zeros(f_shape)\n            for i in range(f_shape[3]):\n                weights[:, :, :, i, i] = bilinear\n\n            init = tf.constant_initializer(value=weights,\n                                           dtype=tf.float32)\n            W = vs.variable(name=""up_filter"", initializer=init,\n                            shape=weights.shape, trainable=trainable,\n                            restore=restore)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n            return W\n\n        weights = get_deconv_filter(filter_size)\n        deconv = tf.nn.conv3d_transpose(incoming, weights, output_shape,\n                                        strides=strides, padding=\'SAME\')\n\n    deconv.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, deconv)\n\n    return deconv\n\n\ndef conv_1d(incoming, nb_filter, filter_size, strides=1, padding=\'same\',\n            activation=\'linear\', bias=True, weights_init=\'uniform_scaling\',\n            bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n            trainable=True, restore=True, reuse=False, scope=None,\n            name=""Conv1D""):\n    """""" Convolution 1D.\n\n    Input:\n        3-D Tensor [batch, steps, in_channels].\n\n    Output:\n        3-D Tensor [batch, new steps, nb_filters].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv1D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 3, ""Incoming Tensor shape must be 3-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    #filter_size = [1, filter_size[1], 1, 1]\n    filter_size[1] = 1\n    strides = utils.autoformat_kernel_2d(strides)\n    strides = [1, strides[1], 1, 1]\n    #strides[1] = 1\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Adding dummy dimension to fit with Tensorflow conv2d\n        inference = tf.expand_dims(incoming, 2)\n        inference = tf.nn.conv2d(inference, W, strides, padding)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n        inference = tf.squeeze(inference, [2])\n\n        if isinstance(activation, str):\n            inference = activations.get(activation)(inference)\n        elif hasattr(activation, \'__call__\'):\n            inference = activation(inference)\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef max_pool_1d(incoming, kernel_size, strides=None, padding=\'same\',\n                name=""MaxPool1D""):\n    """""" Max Pooling 1D.\n\n    Input:\n        3-D Tensor [batch, steps, in_channels].\n\n    Output:\n        3-D Tensor [batch, pooled steps, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: same as kernel_size.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'MaxPool1D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 3, ""Incoming Tensor shape must be 3-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_2d(kernel_size)\n    kernel = [1, kernel[1], 1, 1]\n    strides = utils.autoformat_kernel_2d(strides) if strides else kernel\n    strides = [1, strides[1], 1, 1]\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.expand_dims(incoming, 2)\n        inference = tf.nn.max_pool(inference, kernel, strides, padding)\n        inference = tf.squeeze(inference, [2])\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef avg_pool_1d(incoming, kernel_size, strides=None, padding=\'same\',\n                name=""AvgPool1D""):\n    """""" Average Pooling 1D.\n\n    Input:\n        3-D Tensor [batch, steps, in_channels].\n\n    Output:\n        3-D Tensor [batch, pooled steps, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: same as kernel_size.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'AvgPool1D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 3, ""Incoming Tensor shape must be 3-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_2d(kernel_size)\n    kernel = [1, kernel[1], 1, 1]\n    strides = utils.autoformat_kernel_2d(strides) if strides else kernel\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.expand_dims(incoming, 2)\n        inference = tf.nn.avg_pool(inference, kernel, strides, padding)\n        inference = tf.squeeze(inference, [2])\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef conv_3d(incoming, nb_filter, filter_size, strides=1, padding=\'same\',\n            activation=\'linear\', bias=True, weights_init=\'uniform_scaling\',\n            bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n            trainable=True, restore=True, reuse=False, scope=None,\n            name=""Conv3D""):\n    """""" Convolution 3D.\n\n    Input:\n        5-D Tensor [batch, in_depth, in_height, in_width, in_channels].\n\n    Output:\n        5-D Tensor [filter_depth, filter_height, filter_width, in_channels, out_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 5-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or list of `int`. Strides of conv operation.\n            Default: [1 1 1 1 1]. Must have strides[0] = strides[4] = 1.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv3D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 5, ""Incoming Tensor shape must be 5-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv3d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    strides = utils.autoformat_stride_3d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = tf.nn.conv3d(incoming, W, strides, padding)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if isinstance(activation, str):\n            inference = activations.get(activation)(inference)\n        elif hasattr(activation, \'__call__\'):\n            inference = activation(inference)\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef conv_3d_transpose(incoming, nb_filter, filter_size, output_shape,\n                      strides=1, padding=\'same\', activation=\'linear\',\n                      bias=True, weights_init=\'uniform_scaling\',\n                      bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n                      trainable=True, restore=True, reuse=False, scope=None,\n                      name=""Conv3DTranspose""):\n\n    """""" Convolution 3D Transpose.\n\n    This operation is sometimes called ""deconvolution"" after (Deconvolutional\n    Networks)[http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf], but is\n    actually the transpose (gradient) of `conv_3d` rather than an actual\n    deconvolution.\n\n    Input:\n        5-D Tensor [batch, depth, height, width, in_channels].\n\n    Output:\n        5-D Tensor [batch, new depth, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 5-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        output_shape: `list of int`. Dimensions of the output tensor.\n            Can optionally include the number of conv filters.\n            [new depth, new height, new width, nb_filter] or\n            [new depth, new height, new width].\n        strides: `int` or list of `int`. Strides of conv operation.\n            Default: [1 1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2DTranspose\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        b: `Variable`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 5, ""Incoming Tensor shape must be 5-D, not %d-D"" % len(input_shape)\n\n    filter_size = utils.autoformat_filter_conv3d(filter_size,\n                                                 nb_filter,\n                                                 input_shape[-1])\n    strides = utils.autoformat_stride_3d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size,\n                        regularizer=W_regul, initializer=W_init,\n                        trainable=trainable, restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [nb_filter]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            b = vs.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            # Track per layer variables\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Determine the complete shape of the output tensor.\n        batch_size = tf.gather(tf.shape(incoming), tf.constant([0]))\n        if len(output_shape) == 3:\n            output_shape = output_shape + [nb_filter]\n        elif len(output_shape) != 4:\n            raise Exception(""output_shape length error: ""\n                            + str(len(output_shape))\n                            + "", only a length of 3 or 4 is supported."")\n        complete_out_shape = tf.concat([batch_size, tf.constant(output_shape)], 0)\n\n        inference = tf.nn.conv3d_transpose(incoming, W, complete_out_shape,\n                                           strides, padding)\n\n        # Reshape tensor so its shape is correct.\n        inference.set_shape([None] + output_shape)\n\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n\n        if isinstance(activation, str):\n            inference = activations.get(activation)(inference)\n        elif hasattr(activation, \'__call__\'):\n            inference = activation(inference)\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef max_pool_3d(incoming, kernel_size, strides=1, padding=\'same\',\n                name=""MaxPool3D""):\n    """""" Max Pooling 3D.\n\n    Input:\n        5-D Tensor [batch, depth, rows, cols, channels].\n\n    Output:\n        5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 5-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n            Must have kernel_size[0] = kernel_size[1] = 1\n        strides: `int` or `list of int`. Strides of conv operation.\n            Must have strides[0] = strides[4] = 1. Default: [1 1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'MaxPool3D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 5, ""Incoming Tensor shape must be 5-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_3d(kernel_size)\n    strides = utils.autoformat_stride_3d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.max_pool3d(incoming, kernel, strides, padding)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef avg_pool_3d(incoming, kernel_size, strides=1, padding=\'same\',\n                name=""AvgPool3D""):\n    """""" Average Pooling 3D.\n\n    Input:\n        5-D Tensor [batch, depth, rows, cols, channels].\n\n    Output:\n        5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 5-D Layer.\n        kernel_size: `int` or `list of int`. Pooling kernel size.\n            Must have kernel_size[0] = kernel_size[1] = 1\n        strides: `int` or `list of int`. Strides of conv operation.\n            Must have strides[0] = strides[4] = 1.\n            Default: [1 1 1 1 1]\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'AvgPool3D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 5, ""Incoming Tensor shape must be 5-D, not %d-D"" % len(input_shape)\n\n    kernel = utils.autoformat_kernel_3d(kernel_size)\n    strides = utils.autoformat_stride_3d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.avg_pool3d(incoming, kernel, strides, padding)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef global_max_pool(incoming, name=""GlobalMaxPool""):\n    """""" Global Max Pooling.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        2-D Tensor [batch, pooled dim]\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        name: A name for this layer (optional). Default: \'GlobalMaxPool\'.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    with tf.name_scope(name):\n        inference = tf.reduce_max(incoming, [1, 2])\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef global_avg_pool(incoming, name=""GlobalAvgPool""):\n    """""" Global Average Pooling.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        2-D Tensor [batch, pooled dim]\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        name: A name for this layer (optional). Default: \'GlobalAvgPool\'.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n\n    with tf.name_scope(name):\n        inference = tf.reduce_mean(incoming, [1, 2])\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef residual_block(incoming, nb_blocks, out_channels, downsample=False,\n                   downsample_strides=2, activation=\'relu\', batch_norm=True,\n                   bias=True, weights_init=\'variance_scaling\',\n                   bias_init=\'zeros\', regularizer=\'L2\', weight_decay=0.0001,\n                   trainable=True, restore=True, reuse=False, scope=None,\n                   name=""ResidualBlock""):\n    """""" Residual Block.\n\n    A residual block as described in MSRA\'s Deep Residual Network paper.\n    Full pre-activation architecture is used here.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        nb_blocks: `int`. Number of layer blocks.\n        out_channels: `int`. The number of convolutional filters of the\n            convolution layers.\n        downsample: `bool`. If True, apply downsampling using\n            \'downsample_strides\' for strides.\n        downsample_strides: `int`. The strides to use when downsampling.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        batch_norm: `bool`. If True, apply batch normalization.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'uniform_scaling\'.\n        bias_init: `str` (name) or `tf.Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'ShallowBottleneck\'.\n\n    References:\n        - Deep Residual Learning for Image Recognition. Kaiming He, Xiangyu\n            Zhang, Shaoqing Ren, Jian Sun. 2015.\n        - Identity Mappings in Deep Residual Networks. Kaiming He, Xiangyu\n            Zhang, Shaoqing Ren, Jian Sun. 2015.\n\n    Links:\n        - [http://arxiv.org/pdf/1512.03385v1.pdf]\n            (http://arxiv.org/pdf/1512.03385v1.pdf)\n        - [Identity Mappings in Deep Residual Networks]\n            (https://arxiv.org/pdf/1603.05027v2.pdf)\n\n    """"""\n    resnet = incoming\n    in_channels = incoming.get_shape().as_list()[-1]\n\n    # Variable Scope fix for older TF\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        name = scope.name #TODO\n\n        for i in range(nb_blocks):\n\n            identity = resnet\n\n            if not downsample:\n                downsample_strides = 1\n\n            if batch_norm:\n                resnet = tflearn.batch_normalization(resnet)\n            resnet = tflearn.activation(resnet, activation)\n\n            resnet = conv_2d(resnet, out_channels, 3,\n                             downsample_strides, \'same\', \'linear\',\n                             bias, weights_init, bias_init,\n                             regularizer, weight_decay, trainable,\n                             restore)\n\n            if batch_norm:\n                resnet = tflearn.batch_normalization(resnet)\n            resnet = tflearn.activation(resnet, activation)\n\n            resnet = conv_2d(resnet, out_channels, 3, 1, \'same\',\n                             \'linear\', bias, weights_init,\n                             bias_init, regularizer, weight_decay,\n                             trainable, restore)\n\n            # Downsampling\n            if downsample_strides > 1:\n                identity = tflearn.avg_pool_2d(identity, downsample_strides,\n                                               downsample_strides)\n\n            # Projection to new dimension\n            if in_channels != out_channels:\n                ch = (out_channels - in_channels)//2\n                identity = tf.pad(identity,\n                                  [[0, 0], [0, 0], [0, 0], [ch, ch]])\n                in_channels = out_channels\n\n            resnet = resnet + identity\n\n    return resnet\n\n\ndef residual_bottleneck(incoming, nb_blocks, bottleneck_size, out_channels,\n                        downsample=False, downsample_strides=2,\n                        activation=\'relu\', batch_norm=True, bias=True,\n                        weights_init=\'variance_scaling\', bias_init=\'zeros\',\n                        regularizer=\'L2\', weight_decay=0.0001,\n                        trainable=True, restore=True, reuse=False, scope=None,\n                        name=""ResidualBottleneck""):\n    """""" Residual Bottleneck.\n\n    A residual bottleneck block as described in MSRA\'s Deep Residual Network\n    paper. Full pre-activation architecture is used here.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        nb_blocks: `int`. Number of layer blocks.\n        bottleneck_size: `int`. The number of convolutional filter of the\n            bottleneck convolutional layer.\n        out_channels: `int`. The number of convolutional filters of the\n            layers surrounding the bottleneck layer.\n        downsample: `bool`. If True, apply downsampling using\n            \'downsample_strides\' for strides.\n        downsample_strides: `int`. The strides to use when downsampling.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        batch_norm: `bool`. If True, apply batch normalization.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'uniform_scaling\'.\n        bias_init: `str` (name) or `tf.Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'DeepBottleneck\'.\n\n    References:\n        - Deep Residual Learning for Image Recognition. Kaiming He, Xiangyu\n            Zhang, Shaoqing Ren, Jian Sun. 2015.\n        - Identity Mappings in Deep Residual Networks. Kaiming He, Xiangyu\n            Zhang, Shaoqing Ren, Jian Sun. 2015.\n\n    Links:\n        - [http://arxiv.org/pdf/1512.03385v1.pdf]\n            (http://arxiv.org/pdf/1512.03385v1.pdf)\n        - [Identity Mappings in Deep Residual Networks]\n            (https://arxiv.org/pdf/1603.05027v2.pdf)\n\n    """"""\n    resnet = incoming\n    in_channels = incoming.get_shape().as_list()[-1]\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        name = scope.name #TODO\n\n        for i in range(nb_blocks):\n\n            identity = resnet\n\n            if not downsample:\n                downsample_strides = 1\n\n            if batch_norm:\n                resnet = tflearn.batch_normalization(resnet)\n            resnet = tflearn.activation(resnet, activation)\n\n            resnet = conv_2d(resnet, bottleneck_size, 1,\n                             downsample_strides, \'valid\',\n                             \'linear\', bias, weights_init,\n                             bias_init, regularizer, weight_decay,\n                             trainable, restore)\n\n            if batch_norm:\n                resnet = tflearn.batch_normalization(resnet)\n            resnet = tflearn.activation(resnet, activation)\n\n            resnet = conv_2d(resnet, bottleneck_size, 3, 1, \'same\',\n                             \'linear\', bias, weights_init,\n                             bias_init, regularizer, weight_decay,\n                             trainable, restore)\n\n            resnet = conv_2d(resnet, out_channels, 1, 1, \'valid\',\n                             activation, bias, weights_init,\n                             bias_init, regularizer, weight_decay,\n                             trainable, restore)\n\n            # Downsampling\n            if downsample_strides > 1:\n                identity = tflearn.avg_pool_2d(identity, downsample_strides,\n                                               downsample_strides)\n\n            # Projection to new dimension\n            if in_channels != out_channels:\n                ch = (out_channels - in_channels)//2\n                identity = tf.pad(identity,\n                                  [[0, 0], [0, 0], [0, 0], [ch, ch]])\n                in_channels = out_channels\n\n                resnet = resnet + identity\n                resnet = tflearn.activation(resnet, activation)\n\n    return resnet\n\n\ndef resnext_block(incoming, nb_blocks, out_channels, cardinality,\n                  downsample=False, downsample_strides=2, activation=\'relu\',\n                  batch_norm=True, weights_init=\'variance_scaling\',\n                  regularizer=\'L2\', weight_decay=0.0001, bias=True,\n                  bias_init=\'zeros\', trainable=True, restore=True,\n                  reuse=False, scope=None, name=""ResNeXtBlock""):\n    """""" ResNeXt Block.\n\n    A ResNeXt block as described in ResNeXt paper (Figure 3.c).\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, out_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        nb_blocks: `int`. Number of layer blocks.\n        out_channels: `int`. The number of convolutional filters of the\n            layers surrounding the bottleneck layer.\n        cardinality: `int`. Number of aggregated residual transformations.\n        downsample: `bool`. If True, apply downsampling using\n            \'downsample_strides\' for strides.\n        downsample_strides: `int`. The strides to use when downsampling.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        batch_norm: `bool`. If True, apply batch normalization.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'uniform_scaling\'.\n        bias_init: `str` (name) or `tf.Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'ResNeXtBlock\'.\n\n    References:\n        Aggregated Residual Transformations for Deep Neural Networks. Saining\n        Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, Kaiming He. 2016.\n\n    Links:\n        [https://arxiv.org/pdf/1611.05431.pdf]\n        (https://arxiv.org/pdf/1611.05431.pdf)\n\n    """"""\n    resnext = incoming\n    in_channels = incoming.get_shape().as_list()[-1]\n\n    # Bottleneck width related to cardinality for perplexity conservation\n    # compare to ResNet (see paper, Table 2).\n    card_values = [1, 2, 4, 8, 32]\n    bottleneck_values = [64, 40, 24, 14, 4]\n    bottleneck_size = bottleneck_values[card_values.index(cardinality)]\n    # Group width for reference\n    group_width = [64, 80, 96, 112, 128]\n\n    assert cardinality in card_values, ""cardinality must be in [1, 2, 4, 8, 32]""\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        for i in range(nb_blocks):\n\n            identity = resnext\n            if not downsample:\n                downsample_strides = 1\n\n            resnext = conv_2d(resnext, bottleneck_size, 1,\n                              downsample_strides, \'valid\',\n                              \'linear\', bias, weights_init,\n                              bias_init, regularizer, weight_decay,\n                              trainable, restore)\n\n            if batch_norm:\n                resnext = batch_normalization(resnext, trainable=trainable)\n            resnext = tflearn.activation(resnext, activation)\n\n            resnext = grouped_conv_2d(resnext, cardinality, 3, 1, \'same\',\n                                      \'linear\', False, weights_init,\n                                      bias_init, regularizer, weight_decay,\n                                      trainable, restore)\n            if batch_norm:\n                resnext = batch_normalization(resnext, trainable=trainable)\n            resnext = tflearn.activation(resnext, activation)\n\n            resnext = conv_2d(resnext, out_channels, 1, 1, \'valid\',\n                              activation, bias, weights_init,\n                              bias_init, regularizer, weight_decay,\n                              trainable, restore)\n\n            if batch_norm:\n                resnext = batch_normalization(resnext, trainable=trainable)\n\n            # Downsampling\n            if downsample_strides > 1:\n                identity = avg_pool_2d(identity, 1, downsample_strides)\n\n            # Projection to new dimension\n            if in_channels != out_channels:\n                ch = (out_channels - in_channels) // 2\n                identity = tf.pad(identity,\n                                  [[0, 0], [0, 0], [0, 0], [ch, ch]])\n                in_channels = out_channels\n\n            resnext = resnext + identity\n            resnext = tflearn.activation(resnext, activation)\n\n        return resnext\n\n\ndef densenet_block(incoming, nb_layers, growth, bottleneck=True,\n                   downsample=True, downsample_strides=2, activation=\'relu\',\n                   batch_norm=True, dropout=False, dropout_keep_prob=0.5,\n                   weights_init=\'variance_scaling\', regularizer=\'L2\',\n                   weight_decay=0.0001, bias=True, bias_init=\'zeros\',\n                   trainable=True, restore=True, reuse=False, scope=None,\n                   name=""DenseNetBlock""):\n    """""" DenseNet Block.\n\n    A DenseNet block as described in DenseNet paper.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, out_channels].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        nb_blocks: `int`. Number of layer blocks.\n        growth: `int`. DenseNet \'growth\': The number of convolutional\n            filters of each convolution.\n        bottleneck: `bool`. If True, add a 1x1 convolution before the 3x3 \n            convolution to reduce the number of input features map.\n        downsample: `bool`. If True, apply downsampling using\n            \'downsample_strides\' for strides.\n        downsample_strides: `int`. The strides to use when downsampling.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        batch_norm: `bool`. If True, apply batch normalization.\n        dropout: `bool`. If True, apply dropout. Use \'dropout_keep_prob\' to \n            specify the keep probability.\n        dropout_keep_prob: `float`. Keep probability parameter for dropout.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'uniform_scaling\'.\n        bias_init: `str` (name) or `tf.Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'ResNeXtBlock\'.\n\n    References:\n        Densely Connected Convolutional Networks, G. Huang, Z. Liu, \n        K. Q. Weinberger, L. van der Maaten. 2016.\n\n    Links:\n        [https://arxiv.org/abs/1608.06993]\n        (https://arxiv.org/abs/1608.06993)\n\n    """"""\n    densenet = incoming\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        for i in range(nb_layers):\n\n            # Identity\n            conn = densenet\n\n            # 1x1 Conv layer of the bottleneck block\n            if bottleneck:\n                if batch_norm:\n                    densenet = tflearn.batch_normalization(densenet)\n                densenet = tflearn.activation(densenet, activation)\n                densenet = conv_2d(densenet, nb_filter=growth,\n                                   filter_size=1,\n                                   bias=bias,\n                                   weights_init=weights_init,\n                                   bias_init=bias_init,\n                                   regularizer=regularizer,\n                                   weight_decay=weight_decay,\n                                   trainable=trainable,\n                                   restore=restore)\n\n            # 3x3 Conv layer\n            if batch_norm:\n                densenet = tflearn.batch_normalization(densenet)\n            densenet = tflearn.activation(densenet, activation)\n            densenet = conv_2d(densenet, nb_filter=growth,\n                               filter_size=3,\n                               bias=bias,\n                               weights_init=weights_init,\n                               bias_init=bias_init,\n                               regularizer=regularizer,\n                               weight_decay=weight_decay,\n                               trainable=trainable,\n                               restore=restore)\n\n            # Connections\n            densenet = tf.concat([densenet, conn], 3)\n\n        # 1x1 Transition Conv\n        if batch_norm:\n            densenet = tflearn.batch_normalization(densenet)\n        densenet = tflearn.activation(densenet, activation)\n        densenet = conv_2d(densenet, nb_filter=growth,\n                           filter_size=1,\n                           bias=bias,\n                           weights_init=weights_init,\n                           bias_init=bias_init,\n                           regularizer=regularizer,\n                           weight_decay=weight_decay,\n                           trainable=trainable,\n                           restore=restore)\n        if dropout:\n            densenet = tflearn.dropout(densenet, keep_prob=dropout_keep_prob)\n\n        # Downsampling\n        if downsample:\n            densenet = tflearn.avg_pool_2d(densenet, kernel_size=2,\n                                           strides=downsample_strides)\n\n    return densenet\n\n\ndef highway_conv_2d(incoming, nb_filter, filter_size, strides=1, padding=\'same\',\n                    activation=\'linear\', weights_init=\'uniform_scaling\',\n                    bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n                    trainable=True, restore=True, reuse=False, scope=None,\n                    name=""HighwayConv2D""):\n    """""" Highway Convolution 2D.\n\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n\n    Output:\n        4-D Tensor [batch, new height, new width, nb_filter].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Conv2D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        W_T: `Variable`. Variable representing gate weights.\n        b: `Variable`. Variable representing biases.\n        b_T: `Variable`. Variable representing gate biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    strides = utils.autoformat_kernel_2d(strides)\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        bias_init = initializations.get(bias_init)()\n        b = vs.variable(\'b\', shape=nb_filter, initializer=bias_init,\n                        trainable=trainable, restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Weight and bias for the transform gate\n        W_T = vs.variable(\'W_T\', shape=nb_filter,\n                          regularizer=None, initializer=W_init,\n                          trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' +\n                             name, W_T)\n\n        b_T = vs.variable(\'b_T\', shape=nb_filter,\n                          initializer=tf.constant_initializer(-3),\n                          trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' +\n                             name, b_T)\n\n        if isinstance(activation, str):\n            activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Shared convolution for gating\n        convolved = tf.nn.conv2d(incoming, W, strides, padding)\n        H = activation(convolved + b)\n        T = tf.sigmoid(tf.multiply(convolved, W_T) + b_T)\n        C = tf.subtract(1.0, T)\n        inference = tf.add(tf.multiply(H, T), tf.multiply(convolved, C))\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.W_T = W_T\n    inference.b = b\n    inference.b_T = b_T\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef highway_conv_1d(incoming, nb_filter, filter_size, strides=1, padding=\'same\',\n                    activation=\'linear\', weights_init=\'uniform_scaling\',\n                    bias_init=\'zeros\', regularizer=None, weight_decay=0.001,\n                    trainable=True, restore=True, reuse=False, scope=None,\n                    name=""HighwayConv1D""):\n    """""" Highway Convolution 1D.\n\n    Input:\n        3-D Tensor [batch, steps, in_channels].\n\n    Output:\n        3-D Tensor [batch, new steps, nb_filters].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Tensor.\n        nb_filter: `int`. The number of convolutional filters.\n        filter_size: `int` or `list of int`. Size of filters.\n        strides: `int` or `list of int`. Strides of conv operation.\n            Default: [1 1 1 1].\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'HighwayConv1D\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Variable`. Variable representing filter weights.\n        W_T: `Variable`. Variable representing gate weights.\n        b: `Variable`. Variable representing biases.\n        b_T: `Variable`. Variable representing gate biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 3, ""Incoming Tensor shape must be 3-D, not %d-D"" % len(input_shape)\n    filter_size = utils.autoformat_filter_conv2d(filter_size,\n                                                 input_shape[-1],\n                                                 nb_filter)\n    # filter_size = [1, filter_size[1], 1, 1]\n    filter_size[1] = 1\n    strides = utils.autoformat_kernel_2d(strides)\n    # strides = [1, strides[1], 1, 1]\n    strides[1] = 1\n    padding = utils.autoformat_padding(padding)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = vs.variable(\'W\', shape=filter_size,\n                        regularizer=W_regul, initializer=W_init,\n                        trainable=trainable, restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        bias_init = initializations.get(bias_init)()\n        b = vs.variable(\'b\', shape=nb_filter, initializer=bias_init,\n                        trainable=trainable, restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Weight and bias for the transform gate\n        W_T = vs.variable(\'W_T\', shape=nb_filter,\n                        regularizer=None, initializer=W_init,\n                        trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W_T)\n\n        b_T = vs.variable(\'b_T\', shape=nb_filter,\n                          initializer=tf.constant_initializer(-3),\n                          trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b_T)\n\n        if isinstance(activation, str):\n            activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Adding dummy dimension to fit with Tensorflow conv2d\n        inference = tf.expand_dims(incoming, 2)\n        # Shared convolution for gating\n        convolved = tf.nn.conv2d(inference, W, strides, padding)\n        H = activation(tf.squeeze(convolved + b, [2]))\n        T = tf.sigmoid(tf.squeeze(tf.multiply(convolved, W_T) + b_T, [2]))\n        C = tf.subtract(1.0, T)\n        Q = tf.multiply(H, T)\n        R = tf.multiply(tf.squeeze(convolved, [2]), C)\n        inference = tf.add(Q, R)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.W_T = W_T\n    inference.b = b\n    inference.b_T = b_T\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n'"
tflearn/layers/core.py,72,"b'from __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import standard_ops\n\nimport tflearn\n\nfrom tflearn import utils\nfrom tflearn import variables as va\nfrom tflearn import activations\nfrom tflearn import initializations\nfrom tflearn import regularizers\n\n\ndef input_data(shape=None, placeholder=None, dtype=tf.float32,\n               data_preprocessing=None, data_augmentation=None,\n               name=""InputData""):\n    """""" Input Data.\n\n    This layer is used for inputting (aka. feeding) data to a network.\n    A TensorFlow placeholder will be used if it is supplied,\n    otherwise a new placeholder will be created with the given shape.\n\n    Either a shape or placeholder must be provided, otherwise an\n    exception will be raised.\n\n    Furthermore, the placeholder is added to TensorFlow collections\n    so it can be retrieved using tf.get_collection(tf.GraphKeys.INPUTS)\n    as well as tf.GraphKeys.LAYER_TENSOR + \'/\' + name. Similarly for\n    the data preprocessing and augmentation objects which are stored in\n    the collections with tf.GraphKeys.DATA_PREP and tf.GraphKeys.DATA_AUG.\n    This allows other parts of TFLearn to easily retrieve and use these\n    objects by referencing these graph-keys.\n\n    Input:\n        List of `int` (Shape), to create a new placeholder.\n            Or\n        `Tensor` (Placeholder), to use an existing placeholder.\n\n    Output:\n        Placeholder Tensor with given shape.\n\n    Arguments:\n        shape: list of `int`. An array or tuple representing input data shape.\n            It is required if no placeholder is provided. First element should\n            be \'None\' (representing batch size), if not provided, it will be\n            added automatically.\n        placeholder: A Placeholder to use for feeding this layer (optional).\n            If not specified, a placeholder will be automatically created.\n            You can retrieve that placeholder through graph key: \'INPUTS\',\n            or the \'placeholder\' attribute of this function\'s returned tensor.\n        dtype: `tf.type`, Placeholder data type (optional). Default: float32.\n        data_preprocessing: A `DataPreprocessing` subclass object to manage\n            real-time data pre-processing when training and predicting (such\n            as zero center data, std normalization...).\n        data_augmentation: `DataAugmentation`. A `DataAugmentation` subclass\n            object to manage real-time data augmentation while training (\n            such as random image crop, random image flip, random sequence\n            reverse...).\n        name: `str`. A name for this layer (optional).\n\n    """"""\n\n    # We need either a placeholder or a shape, otherwise raise an exception.\n    if placeholder is None:\n        if shape is None:\n            raise Exception(""Either a `shape` or `placeholder` argument is required to consruct an input layer."")\n\n        # We have a shape but no placeholder, so we must now create a placeholder.\n\n        # Ensure the first element of shape is None by prepending None if necessary.\n        # TODO: Why is there a len(shape)>1 condition? Please explain here.\n        if len(shape) > 1 and shape[0] is not None:\n            shape = list(shape)\n            shape = [None] + shape\n\n        # Create a new tf.placeholder with the given shape.\n        with tf.name_scope(name):\n            placeholder = tf.placeholder(shape=shape, dtype=dtype, name=""X"")\n\n    # Store the placeholder object in TensorFlow collections so it can be\n    # retrieved and used elsewhere.\n    tf.add_to_collection(tf.GraphKeys.INPUTS, placeholder)\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, placeholder)\n\n    # Store the objects for data-preprocessing and -augmentation\n    # in TensorFlow collections so they can be retrieved and used elsewhere.\n    tf.add_to_collection(tf.GraphKeys.DATA_PREP, data_preprocessing)\n    tf.add_to_collection(tf.GraphKeys.DATA_AUG, data_augmentation)\n\n    return placeholder\n\n\ndef fully_connected(incoming, n_units, activation=\'linear\', bias=True,\n                    weights_init=\'truncated_normal\', bias_init=\'zeros\',\n                    regularizer=None, weight_decay=0.001, trainable=True,\n                    restore=True, reuse=False, scope=None,\n                    name=""FullyConnected""):\n    """""" Fully Connected.\n\n    A fully connected layer.\n\n    Input:\n        (2+)-D Tensor [samples, input dim]. If not 2D, input will be flatten.\n\n    Output:\n        2D Tensor [samples, n_units].\n\n    Arguments:\n        incoming: `Tensor`. Incoming (2+)D Tensor.\n        n_units: `int`, number of units for this layer.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'FullyConnected\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Tensor`. Variable representing units weights.\n        b: `Tensor`. Variable representing biases.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) > 1, ""Incoming Tensor shape must be at least 2-D""\n    n_inputs = int(np.prod(input_shape[1:]))\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        filter_size = [n_inputs, n_units]\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        elif type(W_init) in [tf.Tensor, np.ndarray, list]:\n            filter_size = None\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = va.variable(\'W\', shape=filter_size, regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b_shape = [n_units]\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            elif type(bias_init) in [tf.Tensor, np.ndarray, list]:\n                b_shape = None\n            if isinstance(bias_init, str):\n                bias_init = initializations.get(bias_init)()\n            b = va.variable(\'b\', shape=b_shape, initializer=bias_init,\n                            trainable=trainable, restore=restore)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = incoming\n        # If input is not 2d, flatten it.\n        if len(input_shape) > 2:\n            inference = tf.reshape(inference, [-1, n_inputs])\n\n        inference = tf.matmul(inference, W)\n        if b is not None: inference = tf.nn.bias_add(inference, b)\n        if activation:\n            if isinstance(activation, str):\n                inference = activations.get(activation)(inference)\n            elif hasattr(activation, \'__call__\'):\n                inference = activation(inference)\n            else:\n                raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef dropout(incoming, keep_prob, noise_shape=None, name=""Dropout""):\n    """""" Dropout.\n\n    Outputs the input element scaled up by `1 / keep_prob`. The scaling is so\n    that the expected sum is unchanged.\n\n    By default, each element is kept or dropped independently. If noise_shape\n    is specified, it must be broadcastable to the shape of x, and only dimensions\n    with noise_shape[i] == shape(x)[i] will make independent decisions. For\n    example, if shape(x) = [k, l, m, n] and noise_shape = [k, 1, 1, n], each\n    batch and channel component will be kept independently and each row and column\n    will be kept or not kept together.\n\n    Arguments:\n        incoming : A `Tensor`. The incoming tensor.\n        keep_prob : A float representing the probability that each element\n            is kept.\n        noise_shape : A 1-D Tensor of type int32, representing the shape for\n            randomly generated keep/drop flags.\n        name : A name for this layer (optional).\n\n    References:\n        Dropout: A Simple Way to Prevent Neural Networks from Overfitting.\n        N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever & R. Salakhutdinov,\n        (2014), Journal of Machine Learning Research, 5(Jun)(2), 1929-1958.\n\n    Links:\n      [https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf]\n        (https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n\n    """"""\n\n    with tf.name_scope(name) as scope:\n\n        inference = incoming\n\n        def apply_dropout():\n            if type(inference) in [list, np.array]:\n                for x in inference:\n                    x = tf.nn.dropout(x, keep_prob, noise_shape)\n                return inference\n            else:\n                return tf.nn.dropout(inference, keep_prob, noise_shape)\n\n        is_training = tflearn.get_training_mode()\n        inference = tf.cond(is_training, apply_dropout, lambda: inference)\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef custom_layer(incoming, custom_fn, **kwargs):\n    """""" Custom Layer.\n\n    A custom layer that can apply any operations to the incoming Tensor or\n    list of `Tensor`. The custom function can be pass as a parameter along\n    with its parameters.\n\n    Arguments:\n        incoming : A `Tensor` or list of `Tensor`. Incoming tensor.\n        custom_fn : A custom `function`, to apply some ops on incoming tensor.\n        **kwargs: Some custom parameters that custom function might need.\n\n    """"""\n    name = ""CustomLayer""\n    if \'name\' in kwargs:\n        name = kwargs[\'name\']\n    with tf.name_scope(name):\n        inference = custom_fn(incoming, **kwargs)\n\n    return inference\n\n\ndef reshape(incoming, new_shape, name=""Reshape""):\n    """""" Reshape.\n\n    A layer that reshape the incoming layer tensor output to the desired shape.\n\n    Arguments:\n        incoming: A `Tensor`. The incoming tensor.\n        new_shape: A list of `int`. The desired shape.\n        name: A name for this layer (optional).\n\n    """"""\n\n    with tf.name_scope(name) as scope:\n        inference = incoming\n        if isinstance(inference, list):\n            inference = tf.concat(0, inference)\n            inference = tf.cast(inference, tf.float32)\n        inference = tf.reshape(inference, shape=new_shape)\n\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef flatten(incoming, name=""Flatten""):\n    """""" Flatten.\n\n    Flatten the incoming Tensor.\n\n    Input:\n        (2+)-D `Tensor`.\n\n    Output:\n        2-D `Tensor` [batch, flatten_dims].\n\n    Arguments:\n        incoming: `Tensor`. The incoming tensor.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) > 1, ""Incoming Tensor shape must be at least 2-D""\n    dims = int(np.prod(input_shape[1:]))\n    x = reshape(incoming, [-1, dims], name)\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, x)\n\n    return x\n\n\ndef activation(incoming, activation=\'linear\', name=\'activation\'):\n\n    """""" Activation.\n\n    Apply given activation to incoming tensor.\n\n    Arguments:\n        incoming: A `Tensor`. The incoming tensor.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n\n    """"""\n\n    if isinstance(activation, str):\n        x = activations.get(activation)(incoming)\n    elif hasattr(activation, \'__call__\'):\n        x = activation(incoming)\n    else:\n        raise ValueError(\'Unknown activation type.\')\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, x)\n\n    return x\n\n\ndef single_unit(incoming, activation=\'linear\', bias=True, trainable=True,\n                restore=True, reuse=False, scope=None, name=""Linear""):\n    """""" Single Unit.\n\n    A single unit (Linear) Layer.\n\n    Input:\n        1-D Tensor [samples]. If not 2D, input will be flatten.\n\n    Output:\n        1-D Tensor [samples].\n\n    Arguments:\n        incoming: `Tensor`. Incoming Tensor.\n        activation: `str` (name) or `function`. Activation applied to this\n            layer (see tflearn.activations). Default: \'linear\'.\n        bias: `bool`. If True, a bias is used.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Linear\'.\n\n    Attributes:\n        W: `Tensor`. Variable representing weight.\n        b: `Tensor`. Variable representing bias.\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    n_inputs = int(np.prod(input_shape[1:]))\n\n    # Build variables and inference.\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W = va.variable(\'W\', shape=[n_inputs],\n                        initializer=tf.constant_initializer(np.random.randn()),\n                        trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        b = None\n        if bias:\n            b = va.variable(\'b\', shape=[n_inputs],\n                            initializer=tf.constant_initializer(np.random.randn()),\n                            trainable=trainable, restore=restore)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        inference = incoming\n        # If input is not 2d, flatten it.\n        if len(input_shape) > 1:\n            inference = tf.reshape(inference, [-1])\n\n        inference = tf.multiply(inference, W)\n        if b is not None: inference = tf.add(inference, b)\n\n        if isinstance(activation, str):\n            inference = activations.get(activation)(inference)\n        elif hasattr(activation, \'__call__\'):\n            inference = activation(inference)\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.b = b\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef highway(incoming, n_units, activation=\'linear\', transform_dropout=None,\n            weights_init=\'truncated_normal\', bias_init=\'zeros\',\n            regularizer=None, weight_decay=0.001, trainable=True,\n            restore=True, reuse=False, scope=None,\n            name=""FullyConnectedHighway""):\n    """""" Fully Connected Highway.\n\n    A fully connected highway network layer, with some inspiration from\n    [https://github.com/fomorians/highway-fcn](https://github.com/fomorians/highway-fcn).\n\n    Input:\n        (2+)-D Tensor [samples, input dim]. If not 2D, input will be flatten.\n\n    Output:\n        2D Tensor [samples, n_units].\n\n    Arguments:\n        incoming: `Tensor`. Incoming (2+)D Tensor.\n        n_units: `int`, number of units for this layer.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'linear\'.\n        transform_dropout: `float`: Keep probability on the highway transform gate.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        bias_init: `str` (name) or `Tensor`. Bias initialization.\n            (see tflearn.initializations) Default: \'zeros\'.\n        regularizer: `str` (name) or `Tensor`. Add a regularizer to this\n            layer weights (see tflearn.regularizers). Default: None.\n        weight_decay: `float`. Regularizer decay parameter. Default: 0.001.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'FullyConnectedHighway\'.\n\n    Attributes:\n        scope: `Scope`. This layer scope.\n        W: `Tensor`. Variable representing units weights.\n        W_t: `Tensor`. Variable representing units weights for transform gate.\n        b: `Tensor`. Variable representing biases.\n        b_t: `Tensor`. Variable representing biases for transform gate.\n\n    Links:\n        [https://arxiv.org/abs/1505.00387](https://arxiv.org/abs/1505.00387)\n\n    """"""\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) > 1, ""Incoming Tensor shape must be at least 2-D""\n    n_inputs = int(np.prod(input_shape[1:]))\n\n    # Build variables and inference.\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        W_init = weights_init\n        if isinstance(weights_init, str):\n            W_init = initializations.get(weights_init)()\n        W_regul = None\n        if regularizer is not None:\n            W_regul = lambda x: regularizers.get(regularizer)(x, weight_decay)\n        W = va.variable(\'W\', shape=[n_inputs, n_units], regularizer=W_regul,\n                        initializer=W_init, trainable=trainable,\n                        restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        if isinstance(bias_init, str):\n            bias_init = initializations.get(bias_init)()\n        b = va.variable(\'b\', shape=[n_units], initializer=bias_init,\n                        trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b)\n\n        # Weight and bias for the transform gate\n        W_T = va.variable(\'W_T\', shape=[n_inputs, n_units],\n                          regularizer=None, initializer=W_init,\n                          trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W_T)\n\n        b_T = va.variable(\'b_T\', shape=[n_units],\n                          initializer=tf.constant_initializer(-1),\n                          trainable=trainable, restore=restore)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, b_T)\n\n        # If input is not 2d, flatten it.\n        if len(input_shape) > 2:\n            incoming = tf.reshape(incoming, [-1, n_inputs])\n\n        if isinstance(activation, str):\n            activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n\n        H = activation(tf.matmul(incoming, W) + b)\n        T = tf.sigmoid(tf.matmul(incoming, W_T) + b_T)\n        if transform_dropout:\n            T = dropout(T, transform_dropout)\n        C = tf.subtract(1.0, T)\n\n        inference = tf.add(tf.multiply(H, T), tf.multiply(incoming, C))\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights.\n    inference.scope = scope\n    inference.W = W\n    inference.W_t = W_T\n    inference.b = b\n    inference.b_t = b_T\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef one_hot_encoding(target, n_classes, on_value=1.0, off_value=0.0,\n                     name=""OneHotEncoding""):\n    """""" One Hot Encoding.\n\n    Transform numeric labels into a binary vector.\n\n    Input:\n        The Labels Placeholder.\n\n    Output:\n        2-D Tensor, The encoded labels.\n\n    Arguments:\n        target: `Placeholder`. The labels placeholder.\n        n_classes: `int`. Total number of classes.\n        on_value: `scalar`. A scalar defining the on-value.\n        off_value: `scalar`. A scalar defining the off-value.\n        name: A name for this layer (optional). Default: \'OneHotEncoding\'.\n\n    """"""\n\n    with tf.name_scope(name):\n        if target.dtype != dtypes.int64:\n            target = standard_ops.to_int64(target)\n\n        target = standard_ops.one_hot(target, n_classes,\n                                      on_value=on_value,\n                                      off_value=off_value)\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, target)\n\n    return target\n\n\ndef time_distributed(incoming, fn, args=None, scope=None):\n    """""" Time Distributed.\n\n    This layer applies a function to every timestep of the input tensor. The\n    custom function first argument must be the input tensor at every timestep.\n    Additional parameters for the custom function may be specified in \'args\'\n    argument (as a list).\n\n    Examples:\n        ```python\n        # Applying a fully_connected layer at every timestep\n        x = time_distributed(input_tensor, fully_connected, [64])\n\n        # Using a conv layer at every timestep with a scope\n        x = time_distributed(input_tensor, conv_2d, [64, 3], scope=\'tconv\')\n        ```\n\n    Input:\n        (3+)-D Tensor [samples, timestep, input_dim].\n\n    Output:\n        (3+)-D Tensor [samples, timestep, output_dim].\n\n    Arguments:\n        incoming: `Tensor`. The incoming tensor.\n        fn: `function`. A function to apply at every timestep. This function\n            first parameter must be the input tensor per timestep. Additional\n            parameters may be specified in \'args\' argument.\n        args: `list`. A list of parameters to use with the provided function.\n        scope: `str`. A scope to give to each timestep tensor. Useful when\n            sharing weights. Each timestep tensor scope will be generated\n            as \'scope\'-\'i\' where i represents the timestep id. Note that your\n            custom function will be required to have a \'scope\' parameter.\n\n    Returns:\n        A Tensor.\n\n    """"""\n    if not args: args = list()\n    assert isinstance(args, list), ""\'args\' must be a list.""\n\n    if not isinstance(incoming, tf.Tensor):\n        incoming = tf.transpose(tf.stack(incoming), [1, 0, 2])\n\n    input_shape = utils.get_incoming_shape(incoming)\n    timestep = input_shape[1]\n    x = tf.unstack(incoming, axis=1)\n    if scope:\n        x = [fn(x[i], scope=scope+\'-\'+str(i), *args)\n             for i in range(timestep)]\n    else:\n        x = [fn(x[i], *args) for i in range(timestep)]\n\n    x = list(map(lambda t: tf.reshape(t, [-1, 1]+utils.get_incoming_shape(t)[1:]), x))\n    return tf.concat(x, 1)\n\n\ndef multi_target_data(name_list, shape, dtype=tf.float32):\n    """""" Multi Target Data.\n\n    Create and concatenate multiple placeholders. To be used when a regression\n    layer uses targets from different sources.\n\n    Arguments:\n        name_list: list of `str`. The names of the target placeholders.\n        shape: list of `int`. The shape of the placeholders.\n        dtype: `tf.type`, Placeholder data type (optional). Default: float32.\n\n    Return:\n        A `Tensor` of the concatenated placeholders.\n\n    """"""\n    placeholders = []\n    for i in range(len(name_list)):\n        with tf.name_scope(name_list[i]):\n            p = tf.placeholder(shape=shape, dtype=dtype, name=\'Y\')\n        if p not in tf.get_collection(tf.GraphKeys.TARGETS):\n            tf.add_to_collection(tf.GraphKeys.TARGETS, p)\n        placeholders.append(p)\n\n    return tf.concat(placeholders, axis=0)\n'"
tflearn/layers/embedding_ops.py,7,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom .recurrent import retrieve_seq_length_op\nfrom .. import variables as vs\nfrom .. import utils\nfrom .. import initializations\n\n\ndef embedding(incoming, input_dim, output_dim, validate_indices=False,\n              weights_init=\'truncated_normal\', trainable=True, restore=True,\n              reuse=False, scope=None, name=""Embedding""):\n    """""" Embedding.\n\n    Embedding layer for a sequence of integer ids or floats.\n\n    Input:\n        2-D Tensor [samples, ids].\n\n    Output:\n        3-D Tensor [samples, embedded_ids, features].\n\n    Arguments:\n        incoming: Incoming 2-D Tensor.\n        input_dim: list of `int`. Vocabulary size (number of ids).\n        output_dim: list of `int`. Embedding size.\n        validate_indices: `bool`. Whether or not to validate gather indices.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (see tflearn.initializations) Default: \'truncated_normal\'.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: A name for this layer (optional). Default: \'Embedding\'.\n\n    """"""\n\n    input_shape = utils.get_incoming_shape(incoming)\n    assert len(input_shape) == 2, ""Incoming Tensor shape must be 2-D""\n\n    W_init = weights_init\n    if isinstance(weights_init, str):\n        W_init = initializations.get(weights_init)()\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n        with tf.device(\'/cpu:0\'):\n            W = vs.variable(""W"", shape=[input_dim, output_dim],\n                            initializer=W_init, trainable=trainable,\n                            restore=restore)\n            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, W)\n\n        inference = tf.cast(incoming, tf.int32)\n        inference = tf.nn.embedding_lookup(W, inference,\n                                           validate_indices=validate_indices)\n\n    inference.W = W\n    inference.scope = scope\n    # Embedding doesn\'t support masking, so we save sequence length prior\n    # to the lookup. Expand dim to 3d.\n    shape = [-1] + inference.get_shape().as_list()[1:3] + [1]\n    inference.seq_length = retrieve_seq_length_op(tf.reshape(incoming, shape))\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n'"
tflearn/layers/estimator.py,19,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\nfrom ..layers import core\nfrom tflearn import utils\nfrom tflearn import objectives\nfrom tflearn import metrics\nfrom tflearn import optimizers\nfrom tflearn.helpers.trainer import TrainOp\n\n\ndef regression(incoming, placeholder=\'default\', optimizer=\'adam\',\n               loss=\'categorical_crossentropy\', metric=\'default\',\n               learning_rate=0.001, dtype=tf.float32, batch_size=64,\n               shuffle_batches=True, to_one_hot=False, n_classes=None,\n               trainable_vars=None, restore=True, op_name=None, \n               validation_monitors=None, validation_batch_size=None, name=None):\n    """""" Regression.\n\n    The regression layer is used in TFLearn to apply a regression (linear or\n    logistic) to the provided input. It requires to specify a TensorFlow\n    gradient descent optimizer \'optimizer\' that will minimize the provided\n    loss function \'loss\' (which calculate the errors). A metric can also be\n    provided, to evaluate the model performance.\n\n    A \'TrainOp\' is generated, holding all information about the optimization\n    process. It is added to TensorFlow collection \'tf.GraphKeys.TRAIN_OPS\'\n    and later used by TFLearn \'models\' classes to perform the training.\n\n    An optional placeholder \'placeholder\' can be specified to use a custom\n    TensorFlow target placeholder instead of creating a new one. The target\n    placeholder is added to the \'tf.GraphKeys.TARGETS\' TensorFlow\n    collection, so that it can be retrieved later. In case no target is used,\n    set the placeholder to None.\n\n    Additionaly, a list of variables \'trainable_vars\' can be specified,\n    so that only them will be updated when applying the backpropagation\n    algorithm.\n\n    Input:\n        2-D Tensor Layer.\n\n    Output:\n        2-D Tensor Layer (Same as input).\n\n    Arguments:\n        incoming: `Tensor`. Incoming 2-D Tensor.\n        placeholder: `Tensor`. This regression target (label) placeholder.\n            If \'default\', a placeholder will be added automatically.\n            You can retrieve that placeholder through graph key: \'TARGETS\',\n            or the \'placeholder\' attribute of this function\'s returned tensor.\n            If you do not want to use any target, set placeholder to \'None\'.\n        optimizer: `str` (name), `Optimizer` or `function`. Optimizer to use.\n            Default: \'adam\' (Adaptive Moment Estimation).\n        loss: `str` (name) or `function`. Loss function used by this layer\n            optimizer. Default: \'categorical_crossentropy\'.\n        metric: `str`, `Metric` or `function`. The metric to be used.\n            Default: \'default\' metric is \'accuracy\'. To disable metric\n            calculation, set it to \'None\'.\n        learning_rate: `float`. This layer optimizer\'s learning rate.\n        dtype: `tf.types`. This layer placeholder type. Default: tf.float32.\n        batch_size: `int`. Batch size of data to use for training. tflearn\n            supports different batch size for every optimizers. Default: 64.\n        shuffle_batches: `bool`. Shuffle or not this optimizer batches at\n            every epoch. Default: True.\n        to_one_hot: `bool`. If True, labels will be encoded to one hot vectors.\n            \'n_classes\' must then be specified.\n        n_classes: `int`. The total number of classes. Only required when using\n            \'to_one_hot\' option.\n        trainable_vars: list of `Variable`. If specified, this regression will\n            only update given variable weights. Else, all trainale variable\n            are going to be updated.\n        restore: `bool`. If False, variables related to optimizers such\n            as moving averages will not be restored when loading a\n            pre-trained model.\n        op_name: A name for this layer optimizer (optional).\n            Default: optimizer op name.\n        validation_monitors: `list` of `Tensor` objects.  List of variables\n            to compute during validation, which are also used to produce\n            summaries for output to TensorBoard.  For example, this can be\n            used to periodically record a confusion matrix or AUC metric, \n            during training.  Each variable should have rank 1, i.e. \n            shape [None].\n        validation_batch_size: `int` or None. Specifies the batch\n            size to be used for the validation data feed.\n        name: A name for this layer\'s placeholder scope.\n\n    Attributes:\n        placeholder: `Tensor`. Placeholder for feeding labels.\n\n    """"""\n\n    input_shape = utils.get_incoming_shape(incoming)\n\n    if placeholder == \'default\':\n        pscope = ""TargetsData"" if not name else name\n        with tf.name_scope(pscope):\n            p_shape = [None] if to_one_hot else input_shape\n            placeholder = tf.placeholder(shape=p_shape, dtype=dtype, name=""Y"")\n    elif placeholder is None:\n        placeholder = None\n\n    if placeholder is not None:\n        if placeholder not in tf.get_collection(tf.GraphKeys.TARGETS):\n            tf.add_to_collection(tf.GraphKeys.TARGETS, placeholder)\n\n    if to_one_hot:\n        if n_classes is None:\n            raise Exception(""\'n_classes\' is required when using \'to_one_hot\'."")\n        placeholder = core.one_hot_encoding(placeholder, n_classes)\n\n    step_tensor = None\n    # Building Optimizer\n    if isinstance(optimizer, str):\n        _opt = optimizers.get(optimizer)(learning_rate)\n        op_name = op_name if op_name else type(_opt).__name__\n        _opt.build()\n        optimizer = _opt.get_tensor()\n    elif isinstance(optimizer, optimizers.Optimizer):\n        op_name = op_name if op_name else type(optimizer).__name__\n        if optimizer.has_decay:\n            step_tensor = tf.Variable(0., name=""Training_step"",\n                                      trainable=False)\n        optimizer.build(step_tensor)\n        optimizer = optimizer.get_tensor()\n    elif hasattr(optimizer, \'__call__\'):\n        try:\n            optimizer, step_tensor = optimizer(learning_rate)\n        except Exception as e:\n            print(str(e))\n            print(""Reminder: Custom Optimizer function must return (optimizer, ""\n                  ""step_tensor) and take one argument: \'learning_rate\'. ""\n                  ""Note that returned step_tensor can be \'None\' if no decay."")\n            exit()\n    elif not isinstance(optimizer, tf.train.Optimizer):\n        raise ValueError(""Invalid Optimizer type."")\n\n    inputs = tf.get_collection(tf.GraphKeys.INPUTS)\n    #inputs = tf.concat(0, utils.get_tensor_parents_placeholders(incoming))\n\n    # Building metric\n    # No auto accuracy for linear regression\n    if len(input_shape) == 1 and metric == \'default\':\n        metric = None\n    # If no placeholder, only a Tensor can be pass as metric\n    if not isinstance(metric, tf.Tensor) and placeholder is None:\n        metric = None\n    if metric is not None:\n        # Default metric is accuracy\n        if metric == \'default\':\n            metric = \'accuracy\'\n        if isinstance(metric, str):\n            metric = metrics.get(metric)()\n            metric.build(incoming, placeholder, inputs)\n            metric = metric.get_tensor()\n        elif isinstance(metric, metrics.Metric):\n            metric.build(incoming, placeholder, inputs)\n            metric = metric.get_tensor()\n        elif hasattr(metric, \'__call__\'):\n            try:\n                metric = metric(incoming, placeholder, inputs)\n            except Exception as e:\n                print(str(e))\n                print(\'Reminder: Custom metric function arguments must be \'\n                      \'defined as: custom_metric(y_pred, y_true, x).\')\n                exit()\n        elif not isinstance(metric, tf.Tensor):\n            raise ValueError(""Invalid Metric type."")\n\n    # Building other ops (loss, training ops...)\n    if isinstance(loss, str):\n        loss = objectives.get(loss)(incoming, placeholder)\n    # Check if function\n    elif hasattr(loss, \'__call__\'):\n        try:\n            loss = loss(incoming, placeholder)\n        except Exception as e:\n            print(str(e))\n            print(\'Reminder: Custom loss function arguments must be defined as: \'\n                  \'custom_loss(y_pred, y_true).\')\n            exit()\n    elif not isinstance(loss, tf.Tensor):\n        raise ValueError(""Invalid Loss type."")\n\n    tr_vars = trainable_vars\n    if not tr_vars:\n        tr_vars = tf.trainable_variables()\n\n    if not restore:\n        tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS, \'moving_avg\')\n        tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS,\n                             optimizer._name + \'/\')\n\n    tr_op = TrainOp(loss=loss,\n                    optimizer=optimizer,\n                    metric=metric,\n                    trainable_vars=tr_vars,\n                    batch_size=batch_size,\n                    shuffle=shuffle_batches,\n                    step_tensor=step_tensor,\n                    validation_monitors=validation_monitors,\n                    validation_batch_size=validation_batch_size,\n                    name=op_name)\n\n    tf.add_to_collection(tf.GraphKeys.TRAIN_OPS, tr_op)\n\n    if not hasattr(incoming, \'__len__\'):\n        incoming.placeholder = placeholder\n\n    return incoming\n'"
tflearn/layers/merge_ops.py,15,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\n\ndef merge(tensors_list, mode, axis=1, name=""Merge""):\n    """""" Merge.\n\n    Merge a list of `Tensor` into a single one. A merging \'mode\' must be\n    specified, check below for the different options.\n\n    Input:\n        List of Tensors.\n\n    Output:\n        Merged Tensors.\n\n    Arguments:\n        tensors_list: A list of `Tensor`, A list of tensors to merge.\n        mode: `str`. Merging mode, it supports:\n            ```\n            \'concat\': concatenate outputs along specified axis\n            \'elemwise_sum\': outputs element-wise sum\n            \'elemwise_mul\': outputs element-wise mul\n            \'sum\': outputs element-wise sum along specified axis\n            \'mean\': outputs element-wise average along specified axis\n            \'prod\': outputs element-wise multiplication along specified axis\n            \'max\': outputs max elements along specified axis\n            \'min\': outputs min elements along specified axis\n            \'and\': `logical and` btw outputs elements along specified axis\n            \'or\': `logical or` btw outputs elements along specified axis\n            ```\n        axis: `int`. Represents the axis to use for merging mode.\n            In most cases: 0 for concat and 1 for other modes.\n        name: A name for this layer (optional). Default: \'Merge\'.\n\n    """"""\n\n    assert len(tensors_list) > 1, ""Merge required 2 or more tensors.""\n\n    with tf.name_scope(name) as scope:\n        tensors = [l for l in tensors_list]\n        if mode == \'concat\':\n            inference = tf.concat(tensors, axis)\n        elif mode == \'elemwise_sum\':\n            inference = tensors[0]\n            for i in range(1, len(tensors)):\n                inference = tf.add(inference, tensors[i])\n        elif mode == \'elemwise_mul\':\n            inference = tensors[0]\n            for i in range(1, len(tensors)):\n                inference = tf.multiply(inference, tensors[i])\n        elif mode == \'sum\':\n            inference = tf.reduce_sum(tf.concat(tensors, axis),\n                                      reduction_indices=axis)\n        elif mode == \'mean\':\n            inference = tf.reduce_mean(tf.concat(tensors, axis),\n                                       reduction_indices=axis)\n        elif mode == \'prod\':\n            inference = tf.reduce_prod(tf.concat(tensors, axis),\n                                       reduction_indices=axis)\n        elif mode == \'max\':\n            inference = tf.reduce_max(tf.concat(tensors, axis),\n                                      reduction_indices=axis)\n        elif mode == \'min\':\n            inference = tf.reduce_min(tf.concat(tensors, axis),\n                                      reduction_indices=axis)\n        elif mode == \'and\':\n            inference = tf.reduce_all(tf.concat(tensors, axis),\n                                      reduction_indices=axis)\n        elif mode == \'or\':\n            inference = tf.reduce_any(tf.concat(tensors, axis),\n                                      reduction_indices=axis)\n        else:\n            raise Exception(""Unknown merge mode"", str(mode))\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef merge_outputs(tensor_list, name=""MergeOutputs""):\n    """""" Merge Outputs.\n\n    A layer that concatenate all outputs of a network into a single tensor.\n\n    Input:\n        List of Tensors [_shape_].\n\n    Output:\n        Concatenated Tensors [nb_tensors, _shape_].\n\n    Arguments:\n        tensor_list: list of `Tensor`. The network outputs.\n        name: `str`. A name for this layer (optional).\n\n    Returns:\n        A `Tensor`.\n\n    """"""\n    with tf.name_scope(name) as scope:\n        x = tf.concat(tensor_list, 1)\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, x)\n\n    return x\n'"
tflearn/layers/normalization.py,23,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom tensorflow.python.training import moving_averages\n\nimport tflearn\nfrom .. import utils\nfrom .. import variables as vs\nfrom ..utils import get_from_module\n\n\ndef get(identifier):\n    if hasattr(identifier, \'__call__\'):\n        return identifier\n    else:\n        return get_from_module(identifier, globals(), \'normalization\')\n\n\ndef batch_normalization(incoming, beta=0.0, gamma=1.0, epsilon=1e-5,\n                        decay=0.9, stddev=0.002, trainable=True,\n                        restore=True, reuse=False, scope=None,\n                        name=""BatchNormalization""):\n    """""" Batch Normalization.\n\n    Normalize activations of the previous layer at each batch.\n\n    Arguments:\n        incoming: `Tensor`. Incoming Tensor.\n        beta: `float`. Default: 0.0.\n        gamma: `float`. Default: 1.0.\n        epsilon: `float`. Defalut: 1e-5.\n        decay: `float`. Default: 0.9.\n        stddev: `float`. Standard deviation for weights initialization.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: `str`. A name for this layer (optional).\n\n    References:\n        Batch Normalization: Accelerating Deep Network Training by Reducing\n        Internal Covariate Shif. Sergey Ioffe, Christian Szegedy. 2015.\n\n    Links:\n        [http://arxiv.org/pdf/1502.03167v3.pdf](http://arxiv.org/pdf/1502.03167v3.pdf)\n\n    """"""\n\n    input_shape = utils.get_incoming_shape(incoming)\n    input_ndim = len(input_shape)\n\n    gamma_init = tf.random_normal_initializer(mean=gamma, stddev=stddev)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n        beta = vs.variable(\'beta\', shape=[input_shape[-1]],\n                           initializer=tf.constant_initializer(beta),\n                           trainable=trainable, restore=restore)\n        gamma = vs.variable(\'gamma\', shape=[input_shape[-1]],\n                            initializer=gamma_init, trainable=trainable,\n                            restore=restore)\n        # Track per layer variables\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, beta)\n        tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + \'/\' + name, gamma)\n        if not restore:\n            tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS, beta)\n            tf.add_to_collection(tf.GraphKeys.EXCL_RESTORE_VARS, gamma)\n\n        axis = list(range(input_ndim - 1))\n\n        moving_mean = vs.variable(\'moving_mean\', input_shape[-1:],\n                                  initializer=tf.zeros_initializer(),\n                                  trainable=False, restore=restore)\n        moving_variance = vs.variable(\'moving_variance\',\n                                      input_shape[-1:],\n                                      initializer=tf.constant_initializer(1.),\n                                      trainable=False,\n                                      restore=restore)\n\n        # Define a function to update mean and variance\n        def update_mean_var():\n            mean, variance = tf.nn.moments(incoming, axis)\n\n            update_moving_mean = moving_averages.assign_moving_average(\n                moving_mean, mean, decay, zero_debias=False)\n            update_moving_variance = moving_averages.assign_moving_average(\n                moving_variance, variance, decay, zero_debias=False)\n\n            with tf.control_dependencies(\n                    [update_moving_mean, update_moving_variance]):\n                return tf.identity(mean), tf.identity(variance)\n\n        # Retrieve variable managing training mode\n        is_training = tflearn.get_training_mode()\n        mean, var = tf.cond(\n            is_training, update_mean_var, lambda: (moving_mean, moving_variance))\n\n        inference = tf.nn.batch_normalization(\n            incoming, mean, var, beta, gamma, epsilon)\n        inference.set_shape(input_shape)\n\n\n    # Add attributes for easy access\n    inference.scope = scope\n    inference.beta = beta\n    inference.gamma = gamma\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef local_response_normalization(incoming, depth_radius=5, bias=1.0,\n                                 alpha=0.0001, beta=0.75,\n                                 name=""LocalResponseNormalization""):\n    """""" Local Response Normalization.\n\n    Input:\n        4-D Tensor Layer.\n\n    Output:\n        4-D Tensor Layer. (Same dimension as input).\n\n    Arguments:\n        incoming: `Tensor`. Incoming Tensor.\n        depth_radius: `int`. 0-D.  Half-width of the 1-D normalization window.\n            Defaults to 5.\n        bias: `float`. An offset (usually positive to avoid dividing by 0).\n            Defaults to 1.0.\n        alpha: `float`. A scale factor, usually positive. Defaults to 0.0001.\n        beta: `float`. An exponent. Defaults to `0.5`.\n        name: `str`. A name for this layer (optional).\n\n    """"""\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.lrn(incoming, depth_radius=depth_radius,\n                              bias=bias, alpha=alpha,\n                              beta=beta, name=name)\n\n    inference.scope = scope\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef l2_normalize(incoming, dim, epsilon=1e-12, name=""l2_normalize""):\n    """""" L2 Normalization.\n\n    Normalizes along dimension `dim` using an L2 norm.\n\n    For a 1-D tensor with `dim = 0`, computes\n    ```\n    output = x / sqrt(max(sum(x**2), epsilon))\n    ```\n\n    For `x` with more dimensions, independently normalizes each 1-D slice along\n    dimension `dim`.\n\n    Arguments:\n        incoming: `Tensor`. Incoming Tensor.\n        dim: `int`. Dimension along which to normalize.\n        epsilon: `float`. A lower bound value for the norm. Will use\n            `sqrt(epsilon)` as the divisor if `norm < sqrt(epsilon)`.\n        name: `str`. A name for this layer (optional).\n\n    Returns:\n      A `Tensor` with the same shape as `x`.\n    """"""\n    with tf.name_scope(name) as name:\n        x = tf.convert_to_tensor(incoming, name=""x"")\n        square_sum = tf.reduce_sum(tf.square(x), [dim], keep_dims=True)\n        x_inv_norm = tf.rsqrt(tf.maximum(square_sum, epsilon))\n\n    return tf.multiply(x, x_inv_norm, name=name)\n'"
tflearn/layers/recurrent.py,64,"b'# -*- coding: utf-8 -*-\nfrom __future__ import division, print_function, absolute_import\n\nimport logging\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import array_ops\ntry:\n    from tensorflow.python.ops.rnn import rnn_cell_impl as _rnn_cell, dynamic_rnn as _drnn, static_rnn as _rnn, static_bidirectional_rnn as _brnn\n    core_rnn_cell = _rnn_cell\nexcept:\n    # Fix for TF 1.1.0 and under\n    from tensorflow.contrib.rnn.python.ops.core_rnn import static_rnn as _rnn, static_bidirectional_rnn as _brnn\n    from tensorflow.python.ops.rnn import rnn_cell_impl as _rnn_cell, dynamic_rnn as _drnn\n    from tensorflow.contrib.rnn.python.ops import core_rnn_cell\n\nfrom tensorflow.python.util.nest import is_sequence\n\nfrom .. import config\nfrom .. import utils\nfrom .. import activations\nfrom .. import initializations\nfrom .. import variables as va\nfrom .normalization import batch_normalization\n\n# --------------------------\n#  RNN Layers\n# --------------------------\n\ndef _rnn_template(incoming, cell, dropout=None, return_seq=False,\n                  return_state=False, initial_state=None, dynamic=False,\n                  scope=None, reuse=False, name=""LSTM""):\n    """""" RNN Layer Template. """"""\n    sequence_length = None\n    if dynamic:\n        sequence_length = retrieve_seq_length_op(\n            incoming if isinstance(incoming, tf.Tensor) else tf.stack(incoming))\n\n    input_shape = utils.get_incoming_shape(incoming)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming],\n                           reuse=reuse) as scope:\n        name = scope.name\n\n        _cell = cell\n        # Apply dropout\n        if dropout:\n            if type(dropout) in [tuple, list]:\n                in_keep_prob = dropout[0]\n                out_keep_prob = dropout[1]\n            elif isinstance(dropout, float):\n                in_keep_prob, out_keep_prob = dropout, dropout\n            else:\n                raise Exception(""Invalid dropout type (must be a 2-D tuple of ""\n                                ""float)"")\n            cell = DropoutWrapper(cell, in_keep_prob, out_keep_prob)\n\n        inference = incoming\n        # If a tensor given, convert it to a per timestep list\n        if type(inference) not in [list, np.array]:\n            ndim = len(input_shape)\n            assert ndim >= 3, ""Input dim should be at least 3.""\n            axes = [1, 0] + list(range(2, ndim))\n            inference = tf.transpose(inference, (axes))\n            inference = tf.unstack(inference)\n\n        outputs, state = _rnn(cell, inference, dtype=tf.float32,\n                              initial_state=initial_state, scope=name,\n                              sequence_length=sequence_length)\n\n        # Retrieve RNN Variables\n        c = tf.GraphKeys.LAYER_VARIABLES + \'/\' + scope.name\n        for v in [_cell.W, _cell.b]:\n            if hasattr(v, ""__len__""):\n                for var in v: tf.add_to_collection(c, var)\n            else:\n                tf.add_to_collection(c, v)\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, outputs[-1])\n\n    if dynamic:\n        if return_seq:\n            o = tf.stack(outputs, 1)\n        else:\n            outputs = tf.transpose(tf.stack(outputs), [1, 0, 2])\n            o = advanced_indexing_op(outputs, sequence_length)\n    else:\n        o = tf.stack(outputs, 1) if return_seq else outputs[-1]\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, o)\n\n    return (o, state) if return_state else o\n\n\ndef simple_rnn(incoming, n_units, activation=\'sigmoid\', dropout=None,\n               bias=True, weights_init=None, return_seq=False,\n               return_state=False, initial_state=None, dynamic=False,\n               trainable=True, restore=True, reuse=False, scope=None,\n               name=""SimpleRNN""):\n    """""" Simple RNN.\n\n    Simple Recurrent Layer.\n\n    Input:\n        3-D Tensor [samples, timesteps, input dim].\n\n    Output:\n        if `return_seq`: 3-D Tensor [samples, timesteps, output dim].\n        else: 2-D Tensor [samples, output dim].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Tensor.\n        n_units: `int`, number of units for this layer.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'sigmoid\'.\n        dropout: `tuple` of `float`: (input_keep_prob, output_keep_prob). The\n            input and output keep probability.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (See tflearn.initializations)\n        return_seq: `bool`. If True, returns the full sequence instead of\n            last sequence output only.\n        return_state: `bool`. If True, returns a tuple with output and\n            states: (output, states).\n        initial_state: `Tensor`. An initial state for the RNN.  This must be\n            a tensor of appropriate type and shape [batch_size x cell.state_size].\n        dynamic: `bool`. If True, dynamic computation is performed. It will not\n            compute RNN steps above the sequence length. Note that because TF\n            requires to feed sequences of same length, 0 is used as a mask.\n            So a sequence padded with 0 at the end must be provided. When\n            computation is performed, it will stop when it meets a step with\n            a value of 0.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: `str`. A name for this layer (optional).\n\n    """"""\n    cell = BasicRNNCell(n_units, activation=activation, bias=bias,\n                        weights_init=weights_init, trainable=trainable,\n                        restore=restore, reuse=reuse)\n    x = _rnn_template(incoming, cell=cell, dropout=dropout,\n                      return_seq=return_seq, return_state=return_state,\n                      initial_state=initial_state, dynamic=dynamic,\n                      scope=scope, name=name)\n\n    return x\n\n\ndef lstm(incoming, n_units, activation=\'tanh\', inner_activation=\'sigmoid\',\n         dropout=None, bias=True, weights_init=None, forget_bias=1.0,\n         return_seq=False, return_state=False, initial_state=None,\n         dynamic=False, trainable=True, restore=True, reuse=False,\n         scope=None, name=""LSTM""):\n    """""" LSTM.\n\n    Long Short Term Memory Recurrent Layer.\n\n    Input:\n        3-D Tensor [samples, timesteps, input dim].\n\n    Output:\n        if `return_seq`: 3-D Tensor [samples, timesteps, output dim].\n        else: 2-D Tensor [samples, output dim].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Tensor.\n        n_units: `int`, number of units for this layer.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'tanh\'.\n        inner_activation: `str` (name) or `function` (returning a `Tensor`).\n            LSTM inner activation. Default: \'sigmoid\'.\n        dropout: `tuple` of `float`: (input_keep_prob, output_keep_prob). The\n            input and output keep probability.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (See tflearn.initializations).\n        forget_bias: `float`. Bias of the forget gate. Default: 1.0.\n        return_seq: `bool`. If True, returns the full sequence instead of\n            last sequence output only.\n        return_state: `bool`. If True, returns a tuple with output and\n            states: (output, states).\n        initial_state: `Tensor`. An initial state for the RNN.  This must be\n            a tensor of appropriate type and shape [batch_size x cell.state_size].\n        dynamic: `bool`. If True, dynamic computation is performed. It will not\n            compute RNN steps above the sequence length. Note that because TF\n            requires to feed sequences of same length, 0 is used as a mask.\n            So a sequence padded with 0 at the end must be provided. When\n            computation is performed, it will stop when it meets a step with\n            a value of 0.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: `str`. A name for this layer (optional).\n\n    References:\n        Long Short Term Memory, Sepp Hochreiter & Jurgen Schmidhuber,\n        Neural Computation 9(8): 1735-1780, 1997.\n\n    Links:\n        [http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf]\n        (http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n\n    """"""\n    cell = BasicLSTMCell(n_units, activation=activation,\n                         inner_activation=inner_activation,\n                         forget_bias=forget_bias, bias=bias,\n                         weights_init=weights_init, trainable=trainable,\n                         restore=restore, reuse=reuse)\n    x = _rnn_template(incoming, cell=cell, dropout=dropout,\n                      return_seq=return_seq, return_state=return_state,\n                      initial_state=initial_state, dynamic=dynamic,\n                      scope=scope, name=name)\n\n    return x\n\n\ndef gru(incoming, n_units, activation=\'tanh\', inner_activation=\'sigmoid\',\n        dropout=None, bias=True, weights_init=None, return_seq=False,\n        return_state=False, initial_state=None, dynamic=False,\n        trainable=True, restore=True, reuse=False, scope=None, name=""GRU""):\n    """""" GRU.\n\n    Gated Recurrent Unit Layer.\n\n    Input:\n        3-D Tensor Layer [samples, timesteps, input dim].\n\n    Output:\n        if `return_seq`: 3-D Tensor [samples, timesteps, output dim].\n        else: 2-D Tensor [samples, output dim].\n\n    Arguments:\n        incoming: `Tensor`. Incoming 3-D Tensor.\n        n_units: `int`, number of units for this layer.\n        activation: `str` (name) or `function` (returning a `Tensor`).\n            Activation applied to this layer (see tflearn.activations).\n            Default: \'tanh\'.\n        inner_activation: `str` (name) or `function` (returning a `Tensor`).\n            GRU inner activation. Default: \'sigmoid\'.\n        dropout: `tuple` of `float`: (input_keep_prob, output_keep_prob). The\n            input and output keep probability.\n        bias: `bool`. If True, a bias is used.\n        weights_init: `str` (name) or `Tensor`. Weights initialization.\n            (See tflearn.initializations).\n        return_seq: `bool`. If True, returns the full sequence instead of\n            last sequence output only.\n        return_state: `bool`. If True, returns a tuple with output and\n            states: (output, states).\n        initial_state: `Tensor`. An initial state for the RNN.  This must be\n            a tensor of appropriate type and shape [batch_size x cell.state_size].\n        dynamic: `bool`. If True, dynamic computation is performed. It will not\n            compute RNN steps above the sequence length. Note that because TF\n            requires to feed sequences of same length, 0 is used as a mask.\n            So a sequence padded with 0 at the end must be provided. When\n            computation is performed, it will stop when it meets a step with\n            a value of 0.\n        trainable: `bool`. If True, weights will be trainable.\n        restore: `bool`. If True, this layer weights will be restored when\n            loading a model.\n        reuse: `bool`. If True and \'scope\' is provided, this layer variables\n            will be reused (shared).\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: `str`. A name for this layer (optional).\n\n    References:\n        Learning Phrase Representations using RNN Encoder\xe2\x80\x93Decoder for\n        Statistical Machine Translation, K. Cho et al., 2014.\n\n    Links:\n        [http://arxiv.org/abs/1406.1078](http://arxiv.org/abs/1406.1078)\n\n    """"""\n    cell = GRUCell(n_units, activation=activation,\n                   inner_activation=inner_activation, bias=bias,\n                   weights_init=weights_init, trainable=trainable,\n                   restore=restore, reuse=reuse)\n    x = _rnn_template(incoming, cell=cell, dropout=dropout,\n                      return_seq=return_seq, return_state=return_state,\n                      initial_state=initial_state, dynamic=dynamic,\n                      scope=scope, name=name)\n\n    return x\n\n\ndef bidirectional_rnn(incoming, rnncell_fw, rnncell_bw, return_seq=False,\n                      return_states=False, initial_state_fw=None,\n                      initial_state_bw=None, dynamic=False, scope=None,\n                      name=""BiRNN""):\n    """""" Bidirectional RNN.\n\n    Build a bidirectional recurrent neural network, it requires 2 RNN Cells\n    to process sequence in forward and backward order. Any RNN Cell can be\n    used i.e. SimpleRNN, LSTM, GRU... with its own parameters. But the two\n    cells number of units must match.\n\n    Input:\n        3-D Tensor Layer [samples, timesteps, input dim].\n\n    Output:\n        if `return_seq`: 3-D Tensor [samples, timesteps, output dim].\n        else: 2-D Tensor Layer [samples, output dim].\n\n    Arguments:\n        incoming: `Tensor`. The incoming Tensor.\n        rnncell_fw: `RNNCell`. The RNN Cell to use for foward computation.\n        rnncell_bw: `RNNCell`. The RNN Cell to use for backward computation.\n        return_seq: `bool`. If True, returns the full sequence instead of\n            last sequence output only.\n        return_states: `bool`. If True, returns a tuple with output and\n            states: (output, states).\n        initial_state_fw: `Tensor`. An initial state for the forward RNN.\n            This must be a tensor of appropriate type and shape [batch_size\n            x cell.state_size].\n        initial_state_bw: `Tensor`. An initial state for the backward RNN.\n            This must be a tensor of appropriate type and shape [batch_size\n            x cell.state_size].\n        dynamic: `bool`. If True, dynamic computation is performed. It will not\n            compute RNN steps above the sequence length. Note that because TF\n            requires to feed sequences of same length, 0 is used as a mask.\n            So a sequence padded with 0 at the end must be provided. When\n            computation is performed, it will stop when it meets a step with\n            a value of 0.\n        scope: `str`. Define this layer scope (optional). A scope can be\n            used to share variables between layers. Note that scope will\n            override name.\n        name: `str`. A name for this layer (optional).\n\n    """"""\n    assert (rnncell_fw._num_units == rnncell_bw._num_units), \\\n        ""RNN Cells number of units must match!""\n\n    sequence_length = None\n    if dynamic:\n        sequence_length = retrieve_seq_length_op(\n            incoming if isinstance(incoming, tf.Tensor) else tf.stack(incoming))\n\n    input_shape = utils.get_incoming_shape(incoming)\n\n    with tf.variable_scope(scope, default_name=name, values=[incoming]) as scope:\n        name = scope.name\n\n        # TODO: DropoutWrapper\n\n        inference = incoming\n        # If a tensor given, convert it to a per timestep list\n        if type(inference) not in [list, np.array]:\n            ndim = len(input_shape)\n            assert ndim >= 3, ""Input dim should be at least 3.""\n            axes = [1, 0] + list(range(2, ndim))\n            inference = tf.transpose(inference, (axes))\n            inference = tf.unstack(inference)\n\n        outputs, states_fw, states_bw = _brnn(\n            rnncell_fw, rnncell_bw, inference,\n            initial_state_fw=initial_state_fw,\n            initial_state_bw=initial_state_bw,\n            sequence_length=sequence_length,\n            dtype=tf.float32)\n\n        c = tf.GraphKeys.LAYER_VARIABLES + \'/\' + scope.name\n        for v in [rnncell_fw.W, rnncell_fw.b, rnncell_bw.W, rnncell_bw.b]:\n            if hasattr(v, ""__len__""):\n                for var in v: tf.add_to_collection(c, var)\n            else:\n                tf.add_to_collection(c, v)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, outputs[-1])\n\n    if dynamic:\n        if return_seq:\n            o = tf.stack(outputs, 1)\n        else:\n            outputs = tf.transpose(tf.stack(outputs), [1, 0, 2])\n            o = advanced_indexing_op(outputs, sequence_length)\n    else:\n        o = tf.stack(outputs, 1) if return_seq else outputs[-1]\n\n    sfw = states_fw\n    sbw = states_bw\n\n    # Track output tensor.\n    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, o)\n\n    return (o, sfw, sbw) if return_states else o\n\n\n# --------------------------\n#  RNN Cells\n# --------------------------\n\nclass BasicRNNCell(core_rnn_cell.RNNCell):\n    """""" TF basic RNN cell with extra customization params. """"""\n\n    def __init__(self, num_units, input_size=None, activation=tf.nn.tanh,\n                 bias=True, weights_init=None, trainable=True, restore=True,\n                 reuse=False):\n        if input_size is not None:\n            logging.warning(""%s: The input_size parameter is deprecated."" % self)\n        self._num_units = num_units\n        if isinstance(activation, str):\n            self._activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            self._activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n        self.bias = bias\n        self.weights_init = weights_init\n        if isinstance(weights_init, str):\n            self.weights_init = initializations.get(weights_init)()\n        self.trainable = trainable\n        self.restore = restore\n        self.reuse = reuse\n\n    @property\n    def state_size(self):\n        return self._num_units\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n    def __call__(self, inputs, state, scope=None):\n        """"""Most basic RNN: output = new_state = activation(W * input + U * state + B).""""""\n        with tf.variable_scope(scope or type(self).__name__):\n            # ""BasicRNNCell""\n            output = self._activation(\n                _linear([inputs, state], self._num_units, True, 0.,\n                        self.weights_init, self.trainable, self.restore,\n                        self.reuse))\n            # Retrieve RNN Variables\n            with tf.variable_scope(\'Linear\', reuse=True):\n                self.W = tf.get_variable(\'Matrix\')\n                self.b = tf.get_variable(\'Bias\')\n\n        return output, output\n\n\nclass BasicLSTMCell(core_rnn_cell.RNNCell):\n    """""" TF Basic LSTM recurrent network cell with extra customization params.\n\n    The implementation is based on: http://arxiv.org/abs/1409.2329.\n\n    We add forget_bias (default: 1) to the biases of the forget gate in order to\n    reduce the scale of forgetting in the beginning of the training.\n\n    It does not allow cell clipping, a projection layer, and does not\n    use peep-hole connections: it is the basic baseline.\n\n    For advanced models, please use the full LSTMCell that follows.\n    """"""\n\n    def __init__(self, num_units, forget_bias=1.0, input_size=None,\n                 state_is_tuple=True, activation=tf.tanh,\n                 inner_activation=tf.sigmoid, bias=True, weights_init=None,\n                 trainable=True, restore=True, reuse=False, batch_norm = False):\n        if not state_is_tuple:\n            logging.warning(\n                ""%s: Using a concatenated state is slower and will soon be ""\n                ""deprecated.  Use state_is_tuple=True."" % self)\n        if input_size is not None:\n            logging.warning(""%s: The input_size parameter is deprecated."" % self)\n        self._num_units = num_units\n        self._forget_bias = forget_bias\n        self._state_is_tuple = state_is_tuple\n        self.batch_norm = batch_norm\n        if isinstance(activation, str):\n            self._activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            self._activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n        if isinstance(inner_activation, str):\n            self._inner_activation = activations.get(inner_activation)\n        elif hasattr(inner_activation, \'__call__\'):\n            self._inner_activation = inner_activation\n        else:\n            raise ValueError(""Invalid Activation."")\n        self.bias = bias\n        self.weights_init = weights_init\n        if isinstance(weights_init, str):\n            self.weights_init = initializations.get(weights_init)()\n        self.trainable = trainable\n        self.restore = restore\n        self.reuse = reuse\n\n    @property\n    def state_size(self):\n        return (core_rnn_cell.LSTMStateTuple(self._num_units, self._num_units)\n                if self._state_is_tuple else 2 * self._num_units)\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n    def __call__(self, inputs, state, scope=None):\n        """"""Long short-term memory cell (LSTM).""""""\n        with tf.variable_scope(scope or type(self).__name__):  # ""BasicLSTMCell""\n            # Parameters of gates are concatenated into one multiply for efficiency.\n            if self._state_is_tuple:\n                c, h = state\n            else:\n                c, h = array_ops.split(1, 2, state)\n            concat = _linear([inputs, h], 4 * self._num_units, True, 0.,\n                             self.weights_init, self.trainable, self.restore,\n                             self.reuse)\n\n            # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n            i, j, f, o = array_ops.split(value=concat, num_or_size_splits=4,\n                                         axis=1)\n\n            # apply batch normalization to inner state and gates\n            if self.batch_norm == True:\n                i = batch_normalization(i, gamma=0.1, trainable=self.trainable, restore=self.restore, reuse=self.reuse)\n                j = batch_normalization(j, gamma=0.1, trainable=self.trainable, restore=self.restore, reuse=self.reuse)\n                f = batch_normalization(f, gamma=0.1, trainable=self.trainable, restore=self.restore, reuse=self.reuse)\n                o = batch_normalization(o, gamma=0.1, trainable=self.trainable, restore=self.restore, reuse=self.reuse)\n            \n            new_c = (c * self._inner_activation(f + self._forget_bias) +\n                     self._inner_activation(i) *\n                     self._activation(j))\n            \n            # hidden-to-hidden batch normalizaiton\n            if self.batch_norm == True:\n                batch_norm_new_c = batch_normalization(new_c, gamma=0.1, trainable=self.trainable, restore=self.restore, reuse=self.reuse)\n                new_h = self._activation(batch_norm_new_c) * self._inner_activation(o)\n            else:\n                new_h = self._activation(new_c) * self._inner_activation(o)\n\n            if self._state_is_tuple:\n                new_state = core_rnn_cell.LSTMStateTuple(new_c, new_h)\n            else:\n                new_state = array_ops.concat([new_c, new_h], 1)\n\n            # Retrieve RNN Variables\n            with tf.variable_scope(\'Linear\', reuse=True):\n                self.W = tf.get_variable(\'Matrix\')\n                self.b = tf.get_variable(\'Bias\')\n\n            return new_h, new_state\n\n\nclass GRUCell(core_rnn_cell.RNNCell):\n    """""" TF GRU Cell with extra customization params. """"""\n\n    def __init__(self, num_units, input_size=None, activation=tf.tanh,\n                 inner_activation=tf.sigmoid, bias=True, weights_init=None,\n                 trainable=True, restore=True, reuse=False):\n        if input_size is not None:\n            logging.warning(""%s: The input_size parameter is deprecated."" % self)\n        self._num_units = num_units\n        if isinstance(activation, str):\n            self._activation = activations.get(activation)\n        elif hasattr(activation, \'__call__\'):\n            self._activation = activation\n        else:\n            raise ValueError(""Invalid Activation."")\n        if isinstance(inner_activation, str):\n            self._inner_activation = activations.get(inner_activation)\n        elif hasattr(inner_activation, \'__call__\'):\n            self._inner_activation = inner_activation\n        else:\n            raise ValueError(""Invalid Activation."")\n        self.bias = bias\n        self.weights_init = weights_init\n        if isinstance(weights_init, str):\n            self.weights_init = initializations.get(weights_init)()\n        self.trainable = trainable\n        self.restore = restore\n        self.reuse = reuse\n\n    @property\n    def state_size(self):\n        return self._num_units\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n    def __call__(self, inputs, state, scope=None):\n        """"""Gated recurrent unit (GRU) with nunits cells.""""""\n        with tf.variable_scope(scope or type(self).__name__):  # ""GRUCell""\n            with tf.variable_scope(""Gates""):  # Reset gate and update gate.\n                # We start with bias of 1.0 to not reset and not update.\n                _w = _linear([inputs, state],\n                    2 * self._num_units, True, 1.0, self.weights_init,\n                    self.trainable, self.restore, self.reuse)\n                r, u = array_ops.split(value=_w, num_or_size_splits=2, axis=1)\n                r, u = self._inner_activation(r), self._inner_activation(u)\n            with tf.variable_scope(""Candidate""):\n                c = self._activation(\n                    _linear([inputs, r * state], self._num_units, True, 0.,\n                            self.weights_init, self.trainable, self.restore,\n                            self.reuse))\n            new_h = u * state + (1 - u) * c\n\n            self.W, self.b = list(), list()\n            # Retrieve RNN Variables\n            with tf.variable_scope(\'Gates/Linear\', reuse=True):\n                self.W.append(tf.get_variable(\'Matrix\'))\n                self.b.append(tf.get_variable(\'Bias\'))\n            with tf.variable_scope(\'Candidate/Linear\', reuse=True):\n                self.W.append(tf.get_variable(\'Matrix\'))\n                self.b.append(tf.get_variable(\'Bias\'))\n\n        return new_h, new_h\n\n\nclass DropoutWrapper(core_rnn_cell.RNNCell):\n    """"""Operator adding dropout to inputs and outputs of the given cell.""""""\n\n    def __init__(self, cell, input_keep_prob=1.0, output_keep_prob=1.0,\n                 seed=None):\n        """"""Create a cell with added input and/or output dropout.\n\n        Dropout is never used on the state.\n\n        Arguments:\n          cell: an RNNCell, a projection to output_size is added to it.\n          input_keep_prob: unit Tensor or float between 0 and 1, input keep\n            probability; if it is float and 1, no input dropout will be added.\n          output_keep_prob: unit Tensor or float between 0 and 1, output keep\n            probability; if it is float and 1, no output dropout will be added.\n          seed: (optional) integer, the randomness seed.\n\n        Raises:\n          TypeError: if cell is not an RNNCell.\n          ValueError: if keep_prob is not between 0 and 1.\n        """"""\n        if not isinstance(cell, core_rnn_cell.RNNCell):\n            raise TypeError(""The parameter cell is not a RNNCell."")\n        if (isinstance(input_keep_prob, float) and\n                not (input_keep_prob >= 0.0 and input_keep_prob <= 1.0)):\n            raise ValueError(\n                ""Parameter input_keep_prob must be between 0 and 1: %d""\n                % input_keep_prob)\n        if (isinstance(output_keep_prob, float) and\n                not (output_keep_prob >= 0.0 and output_keep_prob <= 1.0)):\n            raise ValueError(\n                ""Parameter output_keep_prob must be between 0 and 1: %d""\n                % output_keep_prob)\n        self._cell = cell\n        self._input_keep_prob = input_keep_prob\n        self._output_keep_prob = output_keep_prob\n        self._seed = seed\n\n    @property\n    def state_size(self):\n        return self._cell.state_size\n\n    @property\n    def output_size(self):\n        return self._cell.output_size\n\n    def __call__(self, inputs, state, scope=None):\n        """"""Run the cell with the declared dropouts.""""""\n\n        is_training = config.get_training_mode()\n\n        if (not isinstance(self._input_keep_prob, float) or\n                    self._input_keep_prob < 1):\n            inputs = tf.cond(is_training,\n                lambda: tf.nn.dropout(inputs,\n                                      self._input_keep_prob,\n                                      seed=self._seed),\n                lambda: inputs)\n        output, new_state = self._cell(inputs, state)\n        if (not isinstance(self._output_keep_prob, float) or\n                    self._output_keep_prob < 1):\n            output = tf.cond(is_training,\n                lambda: tf.nn.dropout(output,\n                                      self._output_keep_prob,\n                                      seed=self._seed),\n                lambda: output)\n        return output, new_state\n\n\n# --------------------\n#   TensorFlow Utils\n# --------------------\n\ndef _linear(args, output_size, bias, bias_start=0.0, weights_init=None,\n            trainable=True, restore=True, reuse=False, scope=None):\n    """"""Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n\n    Arguments:\n        args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n        output_size: int, second dimension of W[i].\n        bias: boolean, whether to add a bias term or not.\n        bias_start: starting value to initialize the bias; 0 by default.\n        scope: VariableScope for the created subgraph; defaults to ""Linear"".\n\n    Returns:\n        A 2D Tensor with shape [batch x output_size] equal to\n        sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n\n    Raises:\n        ValueError: if some of the arguments has unspecified or wrong shape.\n    """"""\n    if args is None or (is_sequence(args) and not args):\n        raise ValueError(""`args` must be specified"")\n    if not is_sequence(args):\n        args = [args]\n\n    # Calculate the total size of arguments on dimension 1.\n    total_arg_size = 0\n    shapes = [a.get_shape().as_list() for a in args]\n    for shape in shapes:\n        if len(shape) != 2:\n            raise ValueError(\n                ""Linear is expecting 2D arguments: %s"" % str(shapes))\n        if not shape[1]:\n            raise ValueError(\n                ""Linear expects shape[1] of arguments: %s"" % str(shapes))\n        else:\n            total_arg_size += shape[1]\n\n    # Now the computation.\n    with tf.variable_scope(scope or ""Linear"", reuse=reuse):\n        matrix = va.variable(""Matrix"", [total_arg_size, output_size],\n                             initializer=weights_init, trainable=trainable,\n                             restore=restore)\n        if len(args) == 1:\n            res = tf.matmul(args[0], matrix)\n        else:\n            res = tf.matmul(array_ops.concat(args, 1), matrix)\n        if not bias:\n            return res\n        bias_term = va.variable(\n            ""Bias"", [output_size],\n            initializer=tf.constant_initializer(bias_start),\n            trainable=trainable, restore=restore)\n    return res + bias_term\n\n\ndef retrieve_seq_length_op(data):\n    """""" An op to compute the length of a sequence. 0 are masked. """"""\n    with tf.name_scope(\'GetLength\'):\n        used = tf.sign(tf.reduce_max(tf.abs(data), reduction_indices=2))\n        length = tf.reduce_sum(used, reduction_indices=1)\n        length = tf.cast(length, tf.int32)\n    return length\n\n\ndef advanced_indexing_op(input, index):\n    """""" Advanced Indexing for Sequences. """"""\n    batch_size = tf.shape(input)[0]\n    max_length = int(input.get_shape()[1])\n    dim_size = int(input.get_shape()[2])\n    index = tf.range(0, batch_size) * max_length + (index - 1)\n    flat = tf.reshape(input, [-1, dim_size])\n    relevant = tf.gather(flat, index)\n    return relevant\n'"
tflearn/models/__init__.py,0,b'from __future__ import absolute_import\nfrom .dnn import DNN\nfrom .generator import SequenceGenerator'
tflearn/models/dnn.py,13,"b'from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom ..helpers.trainer import Trainer\nfrom ..helpers.evaluator import Evaluator\nfrom ..utils import feed_dict_builder, is_none, get_tensor_parents_placeholders\n\n\nclass DNN(object):\n    """""" Deep Neural Network Model.\n\n    TODO: complete description\n\n    Arguments:\n        network: `Tensor`. Neural network to be used.\n        tensorboard_verbose: `int`. Summary verbose level, it accepts\n            different levels of tensorboard logs:\n            ```python\n            0: Loss, Accuracy (Best Speed).\n            1: Loss, Accuracy, Gradients.\n            2: Loss, Accuracy, Gradients, Weights.\n            3: Loss, Accuracy, Gradients, Weights, Activations, Sparsity.\n                (Best visualization)\n            ```\n        tensorboard_dir: `str`. Directory to store tensorboard logs.\n            Default: ""/tmp/tflearn_logs/""\n        checkpoint_path: `str`. Path to store model checkpoints. If None,\n            no model checkpoint will be saved. Default: None.\n        best_checkpoint_path: `str`. Path to store the model when the validation rate reaches its\n            highest point of the current training session and also is above best_val_accuracy. Default: None.\n        max_checkpoints: `int` or None. Maximum amount of checkpoints. If\n            None, no limit. Default: None.\n        session: `Session`. A session for running ops. If None, a new one will\n            be created. Note: When providing a session, variables must have been\n            initialized already, otherwise an error will be raised.\n        best_val_accuracy: `float` The minimum validation accuracy that needs to be\n            achieved before a model weight\'s are saved to the best_checkpoint_path. This\n            allows the user to skip early saves and also set a minimum save point when continuing\n            to train a reloaded model. Default: 0.0.\n\n    Attributes:\n        trainer: `Trainer`. Handle model training.\n        predictor: `Predictor`. Handle model prediction.\n        session: `Session`. The current model session.\n\n    """"""\n\n    def __init__(self, network, clip_gradients=5.0, tensorboard_verbose=0,\n                 tensorboard_dir=""/tmp/tflearn_logs/"", checkpoint_path=None,\n                 best_checkpoint_path=None, max_checkpoints=None, session=None,\n                 best_val_accuracy=0.0):\n        assert isinstance(network, tf.Tensor), ""\'network\' arg is not a Tensor!""\n        self.net = network\n        self.train_ops = tf.get_collection(tf.GraphKeys.TRAIN_OPS)\n        self.trainer = Trainer(self.train_ops,\n                               clip_gradients=clip_gradients,\n                               tensorboard_dir=tensorboard_dir,\n                               tensorboard_verbose=tensorboard_verbose,\n                               checkpoint_path=checkpoint_path,\n                               best_checkpoint_path=best_checkpoint_path,\n                               max_checkpoints=max_checkpoints,\n                               session=session,\n                               best_val_accuracy=best_val_accuracy)\n        self.session = self.trainer.session\n\n        self.inputs = tf.get_collection(tf.GraphKeys.INPUTS)\n        if len(self.inputs) == 0:\n            raise Exception(""No input data! Please add an \'input_data\' layer ""\n                            ""to your model (or add your input data ""\n                            ""placeholder to tf.GraphKeys.INPUTS collection)."")\n        # verif_inputs = get_tensor_parents_placeholders(network)\n        # if len(self.inputs) != len(verif_inputs):\n        #     print(""WARNING: TFLearn detected "" + str(len(verif_inputs)) +\n        #           "" input placeholders, but tf collection \'"" +\n        #           tf.GraphKeys.INPUTS + ""\' only contains "" +\n        #           str(len(self.inputs)) + "". If you define placeholders ""\n        #           ""outside of TFLearn wrappers, make sure to add them to ""\n        #           ""that collection."")\n\n        self.targets = tf.get_collection(tf.GraphKeys.TARGETS)\n        # TODO: error tracking when targets are actually used\n        # if len(self.targets) == 0:\n        #     raise Exception(""No target data! Please add a \'regression\' layer ""\n        #                     ""to your model (or add your target data ""\n        #                     ""placeholder to tf.GraphKeys.TARGETS collection)."")\n        self.predictor = Evaluator([self.net],\n                                   session=self.session)\n\n    def fit(self, X_inputs, Y_targets, n_epoch=10, validation_set=None,\n            show_metric=False, batch_size=None, shuffle=None,\n            snapshot_epoch=True, snapshot_step=None, excl_trainops=None,\n            validation_batch_size=None, run_id=None, callbacks=[]):\n        """""" Fit.\n\n        Train model, feeding X_inputs and Y_targets to the network.\n\n        NOTE: When not feeding dicts, data assignations is made by\n            input/estimator layers creation order (For example, the second\n            input layer created will be feeded by the second value of\n            X_inputs list).\n\n        Examples:\n            ```python\n            model.fit(X, Y) # Single input and output\n            model.fit({\'input1\': X}, {\'output1\': Y}) # Single input and output\n            model.fit([X1, X2], Y) # Mutliple inputs, Single output\n\n            # validate with X_val and [Y1_val, Y2_val]\n            model.fit(X, [Y1, Y2], validation_set=(X_val, [Y1_val, Y2_val]))\n            # 10% of training data used for validation\n            model.fit(X, Y, validation_set=0.1)\n            ```\n\n        Arguments:\n            X_inputs: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed to train\n                model.\n            Y_targets: array, `list` of array (if multiple inputs) or `dict`\n                (with estimators layer name as keys). Targets (Labels) to\n                feed to train model.\n            n_epoch: `int`. Number of epoch to run. Default: None.\n            validation_set: `tuple`. Represents data used for validation.\n                `tuple` holds data and targets (provided as same type as\n                X_inputs and Y_targets). Additionally, it also accepts\n                `float` (<1) to performs a data split over training data.\n            show_metric: `bool`. Display or not accuracy at every step.\n            batch_size: `int` or None. If `int`, overrides all network\n                estimators \'batch_size\' by this value.  Also overrides\n                `validation_batch_size` if `int`, and if `validation_batch_size`\n                is None.\n            validation_batch_size: `int` or None. If `int`, overrides all network\n                estimators \'validation_batch_size\' by this value.\n            shuffle: `bool` or None. If `bool`, overrides all network\n                estimators \'shuffle\' by this value.\n            snapshot_epoch: `bool`. If True, it will snapshot model at the end\n                of every epoch. (Snapshot a model will evaluate this model\n                on validation set, as well as create a checkpoint if\n                \'checkpoint_path\' specified).\n            snapshot_step: `int` or None. If `int`, it will snapshot model\n                every \'snapshot_step\' steps.\n            excl_trainops: `list` of `TrainOp`. A list of train ops to\n                exclude from training process (TrainOps can be retrieve\n                through `tf.get_collection_ref(tf.GraphKeys.TRAIN_OPS)`).\n            run_id: `str`. Give a name for this run. (Useful for Tensorboard).\n            callbacks: `Callback` or `list`. Custom callbacks to use in the\n                training life cycle\n\n        """"""\n        if len(self.train_ops) == 0:\n            raise Exception(\'tf collection ""\' + tf.GraphKeys.TRAIN_OPS + \'"" \'\n                            \'is empty! Please make sure you are using \'\n                            \'`regression` layer in your network.\')\n\n        if batch_size:\n            for train_op in self.train_ops:\n                train_op.batch_size = batch_size\n\n        if batch_size is not None and validation_batch_size is None:\n            validation_batch_size = batch_size\n\n        if validation_batch_size:\n            for train_op in self.train_ops:\n                train_op.validation_batch_size = validation_batch_size\n\n        valX, valY = None, None\n        if validation_set:\n            if isinstance(validation_set, float):\n                valX = validation_set\n                valY = validation_set\n            elif type(validation_set) not in [tuple, list]:\n                raise ValueError(""validation_set must be a tuple or list: (""\n                                 ""valX, valY), "" + str(type(validation_set))\n                                 + "" is not compatible!"")\n            else:\n                valX = validation_set[0]\n                valY = validation_set[1]\n\n        # For simplicity we build sync dict synchronously but Trainer support\n        # asynchronous feed dict allocation.\n        # TODO: check memory impact for large data and multiple optimizers\n        feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n                                      self.targets)\n        feed_dicts = [feed_dict for i in self.train_ops]\n        val_feed_dicts = None\n        if not (is_none(valX) or is_none(valY)):\n            if isinstance(valX, float):\n                val_feed_dicts = valX\n            else:\n                val_feed_dict = feed_dict_builder(valX, valY, self.inputs,\n                                                  self.targets)\n                val_feed_dicts = [val_feed_dict for i in self.train_ops]\n        # Retrieve data preprocesing and augmentation\n        daug_dict, dprep_dict = self.retrieve_data_preprocessing_and_augmentation()\n        self.trainer.fit(feed_dicts, val_feed_dicts=val_feed_dicts,\n                         n_epoch=n_epoch,\n                         show_metric=show_metric,\n                         snapshot_step=snapshot_step,\n                         snapshot_epoch=snapshot_epoch,\n                         shuffle_all=shuffle,\n                         dprep_dict=dprep_dict,\n                         daug_dict=daug_dict,\n                         excl_trainops=excl_trainops,\n                         run_id=run_id,\n                         callbacks=callbacks)\n\n    def retrieve_data_preprocessing_and_augmentation(self):\n        dprep_dict, daug_dict = {}, {}\n        dprep_collection = tf.get_collection(tf.GraphKeys.DATA_PREP)\n        daug_collection = tf.get_collection(tf.GraphKeys.DATA_AUG)\n        for i in range(len(self.inputs)):\n            # Support for custom inputs not using dprep/daug\n            if len(dprep_collection) > i:\n                if dprep_collection[i] is not None:\n                    dprep_dict[self.inputs[i]] = dprep_collection[i]\n            if len(daug_collection) > i:\n                if daug_collection[i] is not None:\n                    daug_dict[self.inputs[i]] = daug_collection[i]\n        return daug_dict, dprep_dict\n\n    def fit_batch(self, X_inputs, Y_targets):\n\n        # For simplicity we build sync dict synchronously but Trainer support\n        # asynchronous feed dict allocation.\n        # TODO: check memory impact for large data and multiple optimizers\n        feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n                                      self.targets)\n        feed_dicts = [feed_dict for i in self.train_ops]\n\n        # Retrieve data preprocesing and augmentation\n        daug_dict, dprep_dict = self.retrieve_data_preprocessing_and_augmentation()\n        return self.trainer.fit_batch(feed_dicts,\n                                      dprep_dict=dprep_dict,\n                                      daug_dict=daug_dict)\n\n    def predict(self, X):\n        """""" Predict.\n\n        Model prediction for given input data.\n\n        Arguments:\n            X: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed for prediction.\n\n        Returns:\n            array or `list` of array. The predicted probabilities.\n\n        """"""\n        feed_dict = feed_dict_builder(X, None, self.inputs, None)\n        return self.predictor.predict(feed_dict)\n\n    def predict_label(self, X):\n        """""" Predict Label.\n\n        Predict class labels for input X.\n\n        Arguments:\n            X: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed for prediction.\n\n        Returns:\n            array or `list` of array. The predicted classes index array, sorted\n            by descendant probability value.\n\n        """"""\n        feed_dict = feed_dict_builder(X, None, self.inputs, None)\n        labels = np.argsort(self.predictor.predict(feed_dict))\n        if labels.ndim == 1:\n            return labels[::-1]\n        else:\n            return labels[:, ::-1]\n\n    def save(self, model_file):\n        """""" Save.\n\n        Save model weights.\n\n        Arguments:\n            model_file: `str`. Model path.\n\n        """"""\n        #with self.graph.as_default():\n        self.trainer.save(model_file)\n\n    def load(self, model_file, weights_only=False, **optargs):\n        """""" Load.\n\n        Restore model weights.\n\n        Arguments:\n            model_file: `str`. Model path.\n            weights_only: `bool`. If True, only weights will be restored (\n                and not intermediate variable, such as step counter, moving\n                averages...). Note that if you are using batch normalization,\n                averages will not be restored as well.\n            optargs: optional extra arguments for trainer.restore (see helpers/trainer.py)\n                     These optional arguments may be used to limit the scope of\n                     variables restored, and to control whether a new session is \n                     created for the restored variables.\n        """"""\n        self.trainer.restore(model_file, weights_only, **optargs)\n        self.session = self.trainer.session\n        self.predictor = Evaluator([self.net],\n                                   session=self.session,\n                                   model=None)\n        for d in tf.get_collection(tf.GraphKeys.DATA_PREP):\n            if d: d.restore_params(self.session)\n\n    def get_weights(self, weight_tensor):\n        """""" Get Weights.\n\n        Get a variable weights.\n\n        Examples:\n            ```\n            dnn = DNNTrainer(...)\n            w = dnn.get_weights(denselayer.W) # get a dense layer weights\n            w = dnn.get_weights(convlayer.b) # get a conv layer biases\n            ```\n\n        Arguments:\n            weight_tensor: `Tensor`. A Variable.\n\n        Returns:\n            `np.array`. The provided variable weights.\n        """"""\n        return weight_tensor.eval(self.trainer.session)\n\n    def set_weights(self, tensor, weights):\n        """""" Set Weights.\n\n        Assign a tensor variable a given value.\n\n        Arguments:\n            tensor: `Tensor`. The tensor variable to assign value.\n            weights: The value to be assigned.\n\n        """"""\n        op = tf.assign(tensor, weights)\n        self.trainer.session.run(op)\n\n    def evaluate(self, X, Y, batch_size=128):\n        """""" Evaluate.\n\n        Evaluate model metric(s) on given samples.\n\n        Arguments:\n            X: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed to train\n                model.\n            Y: array, `list` of array (if multiple inputs) or `dict`\n                (with estimators layer name as keys). Targets (Labels) to\n                feed to train model. Usually set as the next element of a\n                sequence, i.e. for x[0] => y[0] = x[1].\n            batch_size: `int`. The batch size. Default: 128.\n\n        Returns:\n            The metric(s) score.\n\n        """"""\n        feed_dict = feed_dict_builder(X, Y, self.inputs, self.targets)\n        ops = [o.metric for o in self.train_ops]\n        return self.predictor.evaluate(feed_dict, ops, batch_size)\n\n    def get_train_vars(self):\n        ret = list()\n        for tr_op in self.train_ops:\n            ret = ret + tr_op.train_vars\n        return ret\n'"
tflearn/models/generator.py,10,"b'from __future__ import division, print_function, absolute_import\n\nimport sys\nimport numpy as np\nimport tensorflow as tf\n\nfrom ..helpers.trainer import Trainer, evaluate as eval\nfrom ..helpers.evaluator import Evaluator\nfrom ..utils import feed_dict_builder, is_none\n\n\nclass SequenceGenerator(object):\n    """""" Sequence Generator Model.\n\n    A deep neural network model for generating sequences.\n\n    Arguments:\n        network: `Tensor`. Neural network to be used.\n        dictionary: `dict`. A dictionary associating each sample with a key (\n            usually integers). For example: {\'a\': 0, \'b\': 1, \'c\': 2, ...}.\n        seq_maxlen: `int`. The maximum length of a sequence.\n        tensorboard_verbose: `int`. Summary verbose level, it accepts\n            different levels of tensorboard logs:\n            ```python\n            0 - Loss, Accuracy (Best Speed).\n            1 - Loss, Accuracy, Gradients.\n            2 - Loss, Accuracy, Gradients, Weights.\n            3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity.\n                (Best visualization)\n            ```\n        tensorboard_dir: `str`. Directory to store tensorboard logs.\n            Default: ""/tmp/tflearn_logs/""\n        checkpoint_path: `str`. Path to store model checkpoints. If None,\n            no model checkpoint will be saved. Default: None.\n        max_checkpoints: `int` or None. Maximum amount of checkpoints. If\n            None, no limit. Default: None.\n        session: `Session`. A session for running ops. If None, a new one will\n            be created. Note: When providing a session, variables must have been\n            initialized already, otherwise an error will be raised.\n\n    Attributes:\n        trainer: `Trainer`. Handle model training.\n        predictor: `Predictor`. Handle model prediction.\n        session: `Session`. The current model session.\n\n    """"""\n\n    def __init__(self, network, dictionary=None, seq_maxlen=25,\n                 clip_gradients=0.0, tensorboard_verbose=0,\n                 tensorboard_dir=""/tmp/tflearn_logs/"",\n                 checkpoint_path=None, max_checkpoints=None,\n                 session=None):\n        assert isinstance(network, tf.Tensor), ""\'network\' arg is not a Tensor!""\n        self.net = network\n        self.train_ops = tf.get_collection(tf.GraphKeys.TRAIN_OPS)\n        self.trainer = Trainer(self.train_ops,\n                               clip_gradients=clip_gradients,\n                               tensorboard_dir=tensorboard_dir,\n                               tensorboard_verbose=tensorboard_verbose,\n                               checkpoint_path=checkpoint_path,\n                               max_checkpoints=max_checkpoints,\n                               session=session)\n        self.session = self.trainer.session\n        self.inputs = tf.get_collection(tf.GraphKeys.INPUTS)\n        self.targets = tf.get_collection(tf.GraphKeys.TARGETS)\n        self.predictor = Evaluator([self.net],\n                                   session=self.session)\n        self.dic = dictionary\n        self.rev_dic = reverse_dictionary(dictionary)\n        self.seq_maxlen = seq_maxlen\n\n    def fit(self, X_inputs, Y_targets, n_epoch=10, validation_set=None,\n            show_metric=False, batch_size=None, shuffle=None,\n            snapshot_epoch=True, snapshot_step=None, excl_trainops=None,\n            run_id=None):\n        """""" Fit.\n\n        Train model, feeding X_inputs and Y_targets to the network.\n\n        NOTE: When not feeding dicts, data assignations is made by\n            input/estimator layers creation order (For example, the second\n            input layer created will be feeded by the second value of\n            X_inputs list).\n\n        Examples:\n            ```python\n            model.fit(X, Y) # Single input and output\n            model.fit({\'input1\': X}, {\'output1\': Y}) # Single input and output\n            model.fit([X1, X2], Y) # Mutliple inputs, Single output\n\n            # validate with X_val and [Y1_val, Y2_val]\n            model.fit(X, [Y1, Y2], validation_set=(X_val, [Y1_val, Y2_val]))\n            # 10% of training data used for validation\n            model.fit(X, Y, validation_set=0.1)\n            ```\n\n        Arguments:\n            X_inputs: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed to train\n                model.\n            Y_targets: array, `list` of array (if multiple inputs) or `dict`\n                (with estimators layer name as keys). Targets (Labels) to\n                feed to train model. Usually set as the next element of a\n                sequence, i.e. for x[0] => y[0] = x[1].\n            n_epoch: `int`. Number of epoch to run. Default: None.\n            validation_set: `tuple`. Represents data used for validation.\n                `tuple` holds data and targets (provided as same type as\n                X_inputs and Y_targets). Additionally, it also accepts\n                `float` (<1) to performs a data split over training data.\n            show_metric: `bool`. Display or not accuracy at every step.\n            batch_size: `int` or None. If `int`, overrides all network\n                estimators \'batch_size\' by this value.\n            shuffle: `bool` or None. If `bool`, overrides all network\n                estimators \'shuffle\' by this value.\n            snapshot_epoch: `bool`. If True, it will snapshot model at the end\n                of every epoch. (Snapshot a model will evaluate this model\n                on validation set, as well as create a checkpoint if\n                \'checkpoint_path\' specified).\n            snapshot_step: `int` or None. If `int`, it will snapshot model\n                every \'snapshot_step\' steps.\n            excl_trainops: `list` of `TrainOp`. A list of train ops to\n                exclude from training process (TrainOps can be retrieve\n                through `tf.get_collection_ref(tf.GraphKeys.TRAIN_OPS)`).\n            run_id: `str`. Give a name for this run. (Useful for Tensorboard).\n\n        """"""\n        if batch_size:\n            for train_op in self.train_ops:\n                train_op.batch_size = batch_size\n\n        valX, valY = None, None\n        if validation_set:\n            if isinstance(validation_set, float):\n                valX = validation_set\n                valY = validation_set\n            else:\n                valX = validation_set[0]\n                valY = validation_set[1]\n\n        # For simplicity we build sync dict synchronously but\n        # Trainer support asynchronous feed dict allocation\n        feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n                                      self.targets)\n        feed_dicts = [feed_dict for i in self.train_ops]\n\n        val_feed_dicts = None\n        if not (is_none(valX) or is_none(valY)):\n            if isinstance(valX, float):\n                val_feed_dicts = valX\n            else:\n                val_feed_dict = feed_dict_builder(valX, valY, self.inputs,\n                                                  self.targets)\n                val_feed_dicts = [val_feed_dict for i in self.train_ops]\n\n        # Retrieve data preprocesing and augmentation\n        dprep_dict, daug_dict = {}, {}\n        dprep_collection = tf.get_collection(tf.GraphKeys.DATA_PREP)\n        daug_collection = tf.get_collection(tf.GraphKeys.DATA_AUG)\n        for i in range(len(self.inputs)):\n            if dprep_collection[i] is not None:\n                dprep_dict[self.inputs[i]] = dprep_collection[i]\n            if daug_collection[i] is not None:\n                daug_dict[self.inputs[i]] = daug_collection[i]\n\n        self.trainer.fit(feed_dicts, val_feed_dicts=val_feed_dicts,\n                         n_epoch=n_epoch,\n                         show_metric=show_metric,\n                         snapshot_step=snapshot_step,\n                         snapshot_epoch=snapshot_epoch,\n                         shuffle_all=shuffle,\n                         dprep_dict=dprep_dict,\n                         daug_dict=daug_dict,\n                         excl_trainops=excl_trainops,\n                         run_id=run_id)\n        self.predictor = Evaluator([self.net],\n                                   session=self.trainer.session)\n\n    def _predict(self, X):\n        feed_dict = feed_dict_builder(X, None, self.inputs, None)\n        return self.predictor.predict(feed_dict)\n\n    def generate(self, seq_length, temperature=0.5, seq_seed=None,\n                 display=False):\n        """""" Generate.\n\n        Generate a sequence. Temperature is controlling the novelty of\n        the created sequence, a temperature near 0 will looks like samples\n        used for training, while the higher the temperature, the more novelty.\n        For optimal results, it is suggested to set sequence seed as some\n        random sequence samples from training dataset.\n\n        Arguments:\n            seq_length: `int`. The generated sequence length.\n            temperature: `float`. Novelty rate.\n            seq_seed: `sequence`. A sequence used as a seed to generate a\n                new sequence. Suggested to be a sequence from data used for\n                training.\n            display: `bool`. If True, print sequence as it is generated.\n\n        Returns:\n            The generated sequence.\n\n        """"""\n\n        generated = seq_seed[:]\n        sequence = seq_seed[:]\n        whole_sequence = seq_seed[:]\n\n        if display: sys.stdout.write(str(generated))\n\n        for i in range(seq_length):\n            x = np.zeros((1, self.seq_maxlen, len(self.dic)))\n            for t, char in enumerate(sequence):\n                x[0, t, self.dic[char]] = 1.\n\n            preds = self._predict(x)[0].tolist()\n            next_index = _sample(preds, temperature)\n            next_char = self.rev_dic[next_index]\n\n            try: #Python 2\n                unicode_or_str = [str, unicode]\n            except: #Python 3\n                unicode_or_str = [str]\n            if type(sequence) in unicode_or_str:\n                generated += next_char\n                sequence = sequence[1:] + next_char\n                whole_sequence += next_char\n            else:\n                generated.append(next_char)\n                sequence = sequence[1:]\n                sequence.append(next_char)\n                whole_sequence.append(next_char)\n\n            if display:\n                sys.stdout.write(str(next_char))\n                sys.stdout.flush()\n\n        if display: print()\n\n        return whole_sequence\n\n    def save(self, model_file):\n        """""" Save.\n\n        Save model weights.\n\n        Arguments:\n            model_file: `str`. Model path.\n\n        """"""\n        self.trainer.save(model_file)\n\n    def load(self, model_file, **optargs):\n        """""" Load.\n\n        Restore model weights.\n\n        Arguments:\n            model_file: `str`. Model path.\n            optargs: optional extra arguments for trainer.restore (see helpers/trainer.py)\n                     These optional arguments may be used to limit the scope of\n                     variables restored, and to control whether a new session is\n                     created for the restored variables.\n\n        """"""\n        self.trainer.restore(model_file, **optargs)\n        self.session = self.trainer.session\n        self.predictor = Evaluator([self.net],\n                                   session=self.session,\n                                   model=None)\n        for d in tf.get_collection(tf.GraphKeys.DATA_PREP):\n            if d: d.restore_params(self.session)\n\n    def get_weights(self, weight_tensor):\n        """""" Get weights.\n\n        Get a variable weights.\n\n        Examples:\n            sgen = SequenceGenerator(...)\n            w = sgen.get_weights(denselayer.W) -- get a dense layer weights\n\n        Arguments:\n            weight_tensor: `tf.Tensor`. A Variable.\n\n        Returns:\n            `np.array`. The provided variable weights.\n        """"""\n        return weight_tensor.eval(self.trainer.session)\n\n    def set_weights(self, tensor, weights):\n        """""" Set Weights.\n\n        Assign a tensor variable a given value.\n\n        Arguments:\n            tensor: `Tensor`. The tensor variable to assign value.\n            weights: The value to be assigned.\n\n        """"""\n        op = tf.assign(tensor, weights)\n        self.trainer.session.run(op)\n\n    def evaluate(self, X, Y, batch_size=128):\n        """""" Evaluate.\n\n        Evaluate model on given samples.\n\n        Arguments:\n            X: array, `list` of array (if multiple inputs) or `dict`\n                (with inputs layer name as keys). Data to feed to train\n                model.\n            Y: array, `list` of array (if multiple inputs) or `dict`\n                (with estimators layer name as keys). Targets (Labels) to\n                feed to train model. Usually set as the next element of a\n                sequence, i.e. for x[0] => y[0] = x[1].\n            batch_size: `int`. The batch size. Default: 128.\n\n        Returns:\n            The metric score.\n\n        """"""\n        feed_dict = feed_dict_builder(X, Y, self.inputs, self.targets)\n        return eval(self.trainer.session, self.net, feed_dict, batch_size)\n\n\ndef reverse_dictionary(dic):\n    # Build reverse dict\n    rev_dic = {}\n    for key in dic:\n        rev_dic[dic[key]] = key\n    return rev_dic\n\n\ndef _sample(a, temperature=1.0):\n    # helper function to sample an index from a probability array\n    a = np.log(a) / temperature\n    a = np.exp(a) / np.sum(np.exp(a))\n    return np.argmax(np.random.multinomial(1, a, 1))\n'"
tflearn/vendor/__init__.py,0,b''
tflearn/vendor/arg_scope.py,4,"b'# This is a vendored copy of\n# tensorflow/contrib/framework/python/ops/arg_scope.py at \n# tensorflow@4292085f549afc7d7e9ac5dc517b2bab45c79ad3\n\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Contains the arg_scope used for scoping layers arguments.\n\n  Allows one to define models much more compactly by eliminating boilerplate\n  code. This is accomplished through the use of argument scoping (arg_scope).\n\n  Example of how to use tf.contrib.framework.arg_scope:\n\n  ```\n  from third_party.tensorflow.contrib.layers.python import layers\n\n  arg_scope = tf.contrib.framework.arg_scope\n\n  with arg_scope([layers.conv2d], padding=\'SAME\',\n                 initializer=layers.variance_scaling_initializer(),\n                 regularizer=layers.l2_regularizer(0.05)):\n    net = layers.conv2d(inputs, 64, [11, 11], 4, padding=\'VALID\', scope=\'conv1\')\n    net = layers.conv2d(net, 256, [5, 5], scope=\'conv2\')\n  ```\n  The first call to conv2d will behave as follows:\n    layers.conv2d(inputs, 64, [11, 11], 4, padding=\'VALID\',\n                  initializer=layers.variance_scaling_initializer(),\n                  regularizer=layers.l2_regularizer(0.05), scope=\'conv1\')\n\n  The second call to conv2d will also use the arg_scope\'s default for padding:\n    layers.conv2d(inputs, 256, [5, 5], padding=\'SAME\',\n                  initializer=layers.variance_scaling_initializer(),\n                  regularizer=layers.l2_regularizer(0.05), scope=\'conv2\')\n\n  Example of how to reuse an arg_scope:\n\n  ```\n  with arg_scope([layers.conv2d], padding=\'SAME\',\n                 initializer=layers.variance_scaling_initializer(),\n                 regularizer=layers.l2_regularizer(0.05)) as sc:\n    net = layers.conv2d(net, 256, [5, 5], scope=\'conv1\')\n    ....\n\n  with arg_scope(sc):\n    net = layers.conv2d(net, 256, [5, 5], scope=\'conv2\')\n  ```\n\n  Example of how to use tf.contrib.framework.add_arg_scope to enable your\n  function to be called within an arg_scope later:\n\n  @tf.contrib.framework.add_arg_scope\n  def conv2d(*args, **kwargs)\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.util import tf_contextlib\nfrom tensorflow.python.util import tf_decorator\n\n__all__ = [\n    \'arg_scope\', \'add_arg_scope\', \'current_arg_scope\', \'has_arg_scope\',\n    \'arg_scoped_arguments\', \'arg_scope_func_key\'\n]\n\n_ARGSTACK = [{}]\n\n_DECORATED_OPS = {}\n\n\ndef _get_arg_stack():\n  if _ARGSTACK:\n    return _ARGSTACK\n  else:\n    _ARGSTACK.append({})\n    return _ARGSTACK\n\n\ndef current_arg_scope():\n  stack = _get_arg_stack()\n  return stack[-1]\n\n\ndef arg_scope_func_key(op):\n  return getattr(op, \'_key_op\', str(op))\n\n\ndef _name_op(op):\n  return (op.__module__, op.__name__)\n\n\ndef _kwarg_names(func):\n  kwargs_length = len(func.__defaults__) if func.__defaults__ else 0\n  return func.__code__.co_varnames[-kwargs_length:func.__code__.co_argcount]\n\n\ndef _add_op(op):\n  key = arg_scope_func_key(op)\n  if key not in _DECORATED_OPS:\n    _DECORATED_OPS[key] = _kwarg_names(op)\n\n\n@tf_contextlib.contextmanager\ndef arg_scope(list_ops_or_scope, **kwargs):\n  """"""Stores the default arguments for the given set of list_ops.\n\n  For usage, please see examples at top of the file.\n\n  Args:\n    list_ops_or_scope: List or tuple of operations to set argument scope for or\n      a dictionary containing the current scope. When list_ops_or_scope is a\n      dict, kwargs must be empty. When list_ops_or_scope is a list or tuple,\n      then every op in it need to be decorated with @add_arg_scope to work.\n    **kwargs: keyword=value that will define the defaults for each op in\n              list_ops. All the ops need to accept the given set of arguments.\n\n  Yields:\n    the current_scope, which is a dictionary of {op: {arg: value}}\n  Raises:\n    TypeError: if list_ops is not a list or a tuple.\n    ValueError: if any op in list_ops has not be decorated with @add_arg_scope.\n  """"""\n  if isinstance(list_ops_or_scope, dict):\n    # Assumes that list_ops_or_scope is a scope that is being reused.\n    if kwargs:\n      raise ValueError(\'When attempting to re-use a scope by suppling a\'\n                       \'dictionary, kwargs must be empty.\')\n    current_scope = list_ops_or_scope.copy()\n    try:\n      _get_arg_stack().append(current_scope)\n      yield current_scope\n    finally:\n      _get_arg_stack().pop()\n  else:\n    # Assumes that list_ops_or_scope is a list/tuple of ops with kwargs.\n    if not isinstance(list_ops_or_scope, (list, tuple)):\n      raise TypeError(\'list_ops_or_scope must either be a list/tuple or reused \'\n                      \'scope (i.e. dict)\')\n    try:\n      current_scope = current_arg_scope().copy()\n      for op in list_ops_or_scope:\n        key = arg_scope_func_key(op)\n        if not has_arg_scope(op):\n          raise ValueError(\'%s is not decorated with @add_arg_scope\',\n                           _name_op(op))\n        if key in current_scope:\n          current_kwargs = current_scope[key].copy()\n          current_kwargs.update(kwargs)\n          current_scope[key] = current_kwargs\n        else:\n          current_scope[key] = kwargs.copy()\n      _get_arg_stack().append(current_scope)\n      yield current_scope\n    finally:\n      _get_arg_stack().pop()\n\n\ndef add_arg_scope(func):\n  """"""Decorates a function with args so it can be used within an arg_scope.\n\n  Args:\n    func: function to decorate.\n\n  Returns:\n    A tuple with the decorated function func_with_args().\n  """"""\n\n  def func_with_args(*args, **kwargs):\n    current_scope = current_arg_scope()\n    current_args = kwargs\n    key_func = arg_scope_func_key(func)\n    if key_func in current_scope:\n      current_args = current_scope[key_func].copy()\n      current_args.update(kwargs)\n    return func(*args, **current_args)\n\n  _add_op(func)\n  setattr(func_with_args, \'_key_op\', arg_scope_func_key(func))\n  return tf_decorator.make_decorator(func, func_with_args)\n\n\ndef has_arg_scope(func):\n  """"""Checks whether a func has been decorated with @add_arg_scope or not.\n\n  Args:\n    func: function to check.\n\n  Returns:\n    a boolean.\n  """"""\n  return arg_scope_func_key(func) in _DECORATED_OPS\n\n\ndef arg_scoped_arguments(func):\n  """"""Returns the list kwargs that arg_scope can set for a func.\n\n  Args:\n    func: function which has been decorated with @add_arg_scope.\n\n  Returns:\n    a list of kwargs names.\n  """"""\n  assert has_arg_scope(func)\n  return _DECORATED_OPS[arg_scope_func_key(func)]\n'"
tutorials/intro/quickstart.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import print_function\n\nimport numpy as np\nimport tflearn\n\n# Download the Titanic dataset\nfrom tflearn.datasets import titanic\ntitanic.download_dataset(\'titanic_dataset.csv\')\n\n# Load CSV file, indicate that the first column represents labels\nfrom tflearn.data_utils import load_csv\ndata, labels = load_csv(\'titanic_dataset.csv\', target_column=0,\n                        categorical_labels=True, n_classes=2)\n\ndef preprocess(passengers, columns_to_delete):\n    # Sort by descending id and delete columns\n    for column_to_delete in sorted(columns_to_delete, reverse=True):\n        [passenger.pop(column_to_delete) for passenger in passengers]\n    for i in range(len(passengers)):\n        # Converting \'sex\' field to float (id is 1 after removing labels column)\n        passengers[i][1] = 1. if passengers[i][1] == \'female\' else 0.\n    return np.array(passengers, dtype=np.float32)\n\n# Ignore \'name\' and \'ticket\' columns (id 1 & 6 of data array)\nto_ignore=[1, 6]\n\n# Preprocess data\ndata = preprocess(data, to_ignore)\n\n# Build neural network\nnet = tflearn.input_data(shape=[None, 6])\nnet = tflearn.fully_connected(net, 32)\nnet = tflearn.fully_connected(net, 32)\nnet = tflearn.fully_connected(net, 2, activation=\'softmax\')\nnet = tflearn.regression(net)\n\n# Define model\nmodel = tflearn.DNN(net)\n# Start training (apply gradient descent algorithm)\nmodel.fit(data, labels, n_epoch=10, batch_size=16, show_metric=True)\n\n# Let\'s create some data for DiCaprio and Winslet\ndicaprio = [3, \'Jack Dawson\', \'male\', 19, 0, 0, \'N/A\', 5.0000]\nwinslet = [1, \'Rose DeWitt Bukater\', \'female\', 17, 1, 2, \'N/A\', 100.0000]\n# Preprocess data\ndicaprio, winslet = preprocess([dicaprio, winslet], to_ignore)\n# Predict surviving chances (class 1 results)\npred = model.predict([dicaprio, winslet])\nprint(""DiCaprio Surviving Rate:"", pred[0][1])\nprint(""Winslet Surviving Rate:"", pred[1][1])\n'"
tflearn/estimators/cluster/__init__.py,0,"b'from .kmeans import KMeans, MiniBatchKMeans\n'"
tflearn/estimators/cluster/kmeans.py,10,"b'from __future__ import division, print_function, absolute_import\n\nfrom datetime import datetime\nimport os\nimport math\nimport numpy as np\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.contrib.factorization.python.ops import clustering_ops as c_ops\nfrom tensorflow.contrib.tensor_forest.python.ops import data_ops\nfrom tensorflow.python.ops import state_ops, array_ops, math_ops\n\nfrom ...utils import validate_dim, read_tensor_in_checkpoint, prepare_X\nfrom ...data_utils import get_num_features, get_num_sample\nfrom ...data_flow import generate_data_tensor\nfrom ...distances import euclidean, cosine\n\nfrom ..base import BaseEstimator\n\n\nclass KMeansBase(BaseEstimator):\n\n    def __init__(self, n_clusters, max_iter=300, init=c_ops.RANDOM_INIT,\n                 distance=c_ops.SQUARED_EUCLIDEAN_DISTANCE,\n                 metric=None, num_features=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n        super(KMeansBase, self).__init__(\n            metric=metric, log_dir=log_dir, global_step=global_step,\n            session=session, graph=graph, name=name)\n\n        self._estimator_built = False\n\n        # Params\n        self.n_clusters = n_clusters\n        self.max_iter = max_iter\n        self.init = init\n        self.distance = distance\n        self.num_features = num_features\n        self.use_mini_batch = False\n\n    def _build_estimator(self, X=None):\n\n        if not self._estimator_built:\n\n            if self.num_features is None:\n                self.num_features = get_num_features(X)\n\n            # Reload params from checkpoint if available\n            if self._to_be_restored and self.num_features is None:\n                self.num_features = read_tensor_in_checkpoint(\n                    \'num_features\', self._to_be_restored)\n            if self._to_be_restored and self.num_classes is None:\n                self.num_classes = read_tensor_in_checkpoint(\n                    \'num_classes\', self._to_be_restored)\n\n            # Purity checks\n            if self.num_features is None:\n                raise ValueError(""\'num_features\' cannot be None."")\n\n            # Persistent Parameters\n            tf.Variable(self.num_features, dtype=tf.int32, name=\'num_features\')\n\n            self._kmeans = c_ops.KMeans(X, self.n_clusters,\n                                        initial_clusters=self.init,\n                                        distance_metric=self.distance,\n                                        use_mini_batch=self.use_mini_batch)\n            (self._all_scores, self._cluster_idx, self._scores,\n             self._cluster_centers_initialized, self._cluster_centers_vars,\n             self._init_op, self._train_op) = self._kmeans.training_graph()\n\n            # fix for cluster_idx being a tuple\n            self._cluster_idx = self._cluster_idx[0]\n            self.avg_distance = tf.reduce_mean(self._scores)\n\n            self._estimator_built = True\n            self._init_graph()\n\n    @property\n    def cluster_centers_vars(self):\n        if self._estimator_built:\n            return self.session.run(self._cluster_centers_vars)\n        else:\n            return None\n\n    @property\n    def cluster_idx(self):\n        if self._estimator_built:\n            return self.session.run(self._cluster_idx)\n        else:\n            return None\n\n    @property\n    def scores(self):\n        if self._estimator_built:\n            return self.session.run(self._cluster_centers_vars)\n        else:\n            return None\n\n    @property\n    def all_scores(self):\n        if self._estimator_built:\n            return self.session.run(self._cluster_centers_vars)\n        else:\n            return None\n\n    # SKLearn bindings\n    @property\n    def cluster_centers_(self):\n        """""" Coordinates of cluster centers. """"""\n        return self.cluster_centers_vars\n\n    @property\n    def labels_(self):\n        """""" Labels of each point. """"""\n        return self.cluster_idx\n\n    @property\n    def distances_(self):\n        """""" Distances of each point to its closest cluster center. """"""\n        return self.session.run(self._scores)\n\n    @property\n    def all_distances_(self):\n        """""" Distances of each point to each cluster center. """"""\n        return self.session.run(self._all_scores)\n\n    def _init_graph(self):\n        super(KMeansBase, self)._init_graph()\n        # Initialize the kmeans op\n        self.session.run(self._init_op)\n\n    def fit(self, X, shuffle=True, display_step=500,\n            n_jobs=1, max_steps=None, verbose=0, **kwargs):\n\n        with self.graph.as_default():\n\n            # Verify data dimension\n            validate_dim(X, max_dim=2, min_dim=2, var_name=\'X\')\n\n            # Get data size\n            num_samples = get_num_sample(X)\n\n            # Set batch size\n            if \'batch_size\' in kwargs.keys():\n                batch_size = kwargs[\'batch_size\']\n            else:\n                batch_size = num_samples\n\n                # Build Tree Graph\n            self._build_estimator(X)\n\n            # Generate Data Tensors. Be aware that every fit with different\n            # data will re-create a data tensor.\n            if self._train.get_params(\'X\') != hex(id(X)) or \\\n                self._train.get_params(\'batch_size\') != batch_size or \\\n                not self._train.is_ready:\n\n                #TODO: raise Exception(""Fitting different data not supported"")\n\n                X, _, cr = generate_data_tensor(X, X, batch_size=batch_size,\n                                                shuffle=shuffle,\n                                                num_threads=8)\n                X, _, spec = data_ops.ParseDataTensorOrDict(X)\n\n                self._train_op = tf.group(\n                    self._train_op,\n                    state_ops.assign_add(self.global_step, 1))\n                self._loss_op = self.avg_distance\n                self._build_fit(X, X, batch_size)\n\n                # Start QueueRunners\n                tf.train.start_queue_runners(sess=self.session)\n                if cr: cr.launch_threads(self.session)\n\n            gstep = self.global_step.eval(session=self.session)\n\n            last_loss = []\n            loss_val = None\n            step = 0\n\n            # Set step to -1 to exit training\n            while True:\n                # Monitor loss\n                if loss_val: last_loss.append(loss_val)\n                if len(last_loss) > 10: last_loss.pop(0)\n\n                start_time = time.time()\n                if (step) % display_step == 0:\n                    _, loss_val, idx = self.session.run(\n                        [self._train_op, self._loss_op, self._cluster_idx])\n                else:\n                    _, loss_val, idx = self.session.run([self._train_op,\n                                                         self._loss_op,\n                                                         self._cluster_idx])\n                duration = time.time() - start_time\n\n                if (step) % display_step == 0:\n                    examples_per_sec = batch_size / duration\n                    sec_per_batch = duration\n                    if self.metric:\n                        format_str = \'%s: step %d, loss = %.2f, acc = %.2f, \' \\\n                                     \'(%.1f examples/sec; %.3f sec/batch)\'\n                        print(format_str % (\n                            datetime.now(), step + gstep, loss_val,\n                            examples_per_sec, sec_per_batch))\n                    else:\n                        format_str = \'%s: step %d, loss = %.2f, \' \\\n                                     \'(%.1f examples/sec; %.3f sec/batch)\'\n                        print(format_str % (\n                            datetime.now(), step + gstep, loss_val,\n                            examples_per_sec, sec_per_batch))\n\n                step += 1\n\n                # Automatic stop after ten flat loss\n                # TODO(aymeric): better stopping.\n                if len(last_loss) == 10 and np.var(last_loss) <= 0.01 and not max_steps:\n                    break\n\n                # Max Steps stop\n                if max_steps:\n                    if step == max_steps:\n                        break\n\n            # save_path = os.path.join(self.log_dir, \'kmeans.ckpt\')\n            # self.saver.save(sess=self.session,\n            #                 save_path=save_path,\n            #                 global_step=self.global_step)\n\n    # ------------\n    #  Prediction\n    # ------------\n\n    def predict(self, X, with_distances=False):\n        """""" predict.\n\n        Predict the closest cluster.\n\n        Arguments:\n            X: `1-D Array` or `2-D Array` of shape (n_samples, n_features).\n                The sample(s) to predict.\n\n        Return:\n            cluster_indices or (cluster_indices, distances).\n\n        """"""\n\n        X, orig_ndim = prepare_X(X, 2, max_dim=2, min_dim=1, debug_msg=""X"")\n\n        with self.graph.as_default():\n            # Build Tree Graph\n            self._build_estimator()\n            if not self._pred.is_ready:\n                input = tf.placeholder(tf.float32, name=\'pred_input\',\n                                       shape=[None, self.num_features])\n                output = c_ops.nearest_neighbors(\n                    input, self._cluster_centers_vars, k=1)\n                self._build_pred(input, output)\n            indices, distances = self.session.run(self._pred.output_tensor,\n                feed_dict={self._pred.input_tensor: X})\n            indices = indices[0]\n            distances = distances[0]\n            if orig_ndim == 1:\n                indices = indices[0]\n                distances = distances[0]\n            if with_distances:\n                return indices, distances\n            return indices\n\n    def transform(self, X):\n        """""" transform.\n\n        Transform X to a cluster-distance space.\n\n        Arguments:\n            X: `Array` or `list` of `Array`. The sample(s) to transform.\n\n        Returns:\n            `Array` of shape (n_clusters). The distance of X to each centroid.\n\n        """"""\n\n        X, orig_ndim = prepare_X(X, 2, max_dim=2, min_dim=1, debug_msg=""X"")\n\n        with self.graph.as_default():\n            # Build Tree Graph\n            self._build_estimator()\n            if not self._transform.is_ready:\n                input = tf.placeholder(tf.float32, name=\'transform_input\',\n                                       shape=[None, self.num_features])\n                centers = self._cluster_centers_vars\n                centers = tf.reshape(centers, shape=[self.n_clusters,\n                                                     self.num_features])\n\n                if self.distance == c_ops.SQUARED_EUCLIDEAN_DISTANCE:\n                    dist_fn = euclidean\n                elif self.distance == c_ops.COSINE_DISTANCE:\n                    dist_fn = cosine\n                else:\n                    raise Exception(""Incorrect distance metric."")\n\n                output = tf.map_fn(\n                    lambda x: tf.map_fn(\n                        lambda y: dist_fn(x, y),\n                        centers),\n                    input)\n\n                self._build_transform(input, output)\n            distances = self.session.run(self._transform.output_tensor,\n                feed_dict={self._transform.input_tensor: X})\n            if orig_ndim == 1:\n                distances = distances[0]\n            return distances\n\n    def save(self, save_path):\n        """""" save.\n\n        Save model to the given path.\n\n        Args:\n            save_path: `str`. The path to save the model.\n\n        """"""\n        if not self._estimator_built:\n            with self.graph.as_default():\n                self._build_estimator()\n        self.saver.save(self.session, os.path.abspath(save_path))\n\n    def load(self, load_path):\n        """""" load.\n\n        Restore model from the given path.\n\n        Args:\n            load_path: `str`. The model path.\n\n        """"""\n        with self.graph.as_default():\n            self.session = tf.Session()\n            if self._estimator_built:\n                self.saver.restore(self.session, os.path.abspath(load_path))\n            else:\n                self._to_be_restored = os.path.abspath(load_path)\n\n\nclass KMeans(KMeansBase):\n    """""" KMeans.\n\n    K-Means clustering algorithm.\n\n    """"""\n\n    def __init__(self, n_clusters, max_iter=300, init=c_ops.RANDOM_INIT,\n                 distance=c_ops.SQUARED_EUCLIDEAN_DISTANCE,\n                 metric=None, num_features=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n        super(KMeans, self).__init__(\n            n_clusters, max_iter=max_iter, init=init, distance=distance,\n            metric=metric, num_features=num_features, log_dir=log_dir,\n            global_step=global_step, session=session, graph=graph,\n            name=name)\n\n    def fit(self, X, shuffle=True, display_step=500, n_jobs=1,\n            max_steps=None):\n        """""" fit.\n\n        Compute the K-Means clustering for the input data.\n\n        Arguments:\n            X: `Array` or `list` of `Array` of shape (n_samples, n_features).\n                The training data.\n            shuffle: `bool`. If True, data are shuffled.\n            display_step: `int`. The step to display training information.\n            n_jobs: `int`. The number of jobs to use for the computation.\n            max_steps: `int`. Maximum number of optimization steps to run.\n\n        """"""\n\n        super(KMeans, self).fit(X, shuffle=shuffle, display_step=display_step,\n                                n_jobs=n_jobs, max_steps=max_steps)\n\n\nclass MiniBatchKMeans(KMeans):\n    """""" MiniBatchKMeans.\n\n    K-Means clustering algorithm with mini batch.\n\n    """"""\n\n    def __init__(self, n_clusters, max_iter=300, init=c_ops.RANDOM_INIT,\n                 distance=c_ops.SQUARED_EUCLIDEAN_DISTANCE,\n                 metric=None, num_features=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n        super(MiniBatchKMeans, self).__init__(\n            n_clusters, max_iter=max_iter, init=init, distance=distance,\n            metric=metric, num_features=num_features, log_dir=log_dir,\n            global_step=global_step, session=session, graph=graph,\n            name=name)\n\n        self.use_mini_batch = True\n\n    def fit(self, X, batch_size=1024, shuffle=True, display_step=500,\n            n_jobs=1, max_steps=None):\n        """""" fit.\n\n        Compute the K-Means clustering for the input data.\n\n        Arguments:\n            X: `Array` or `list` of `Array` of shape (n_samples, n_features).\n                The training data.\n            shuffle: `bool`. If True, data are shuffled.\n            batch_size: `int`. The batch size.\n            display_step: `int`. The step to display training information.\n            n_jobs: `int`. The number of jobs to use for the computation.\n            max_steps: `int`. Maximum number of optimization steps to run.\n\n        """"""\n        super(KMeans, self).fit(X, shuffle=shuffle, display_step=display_step,\n                                n_jobs=n_jobs, max_steps=max_steps,\n                                batch_size=batch_size)\n'"
tflearn/estimators/ensemble/__init__.py,0,"b'from .forest import RandomForestClassifier, RandomForestRegressor\n'"
tflearn/estimators/ensemble/forest.py,8,"b'from __future__ import division, print_function, absolute_import\n\nfrom datetime import datetime\nimport os\nimport math\nimport numpy as np\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.contrib.tensor_forest.python.ops import data_ops\nfrom tensorflow.python.ops import state_ops, array_ops, math_ops\n\nfrom ...utils import validate_dim, read_tensor_in_checkpoint\nfrom ...data_utils import get_num_features, get_num_classes, get_num_sample\nfrom ...data_flow import generate_data_tensor\nfrom ..base import BaseEstimator\n\n\nclass ForestEstimator(BaseEstimator):\n    """""" [WIP] ForesEstimator\n    """"""\n\n    def __init__(self, n_estimators=100, max_nodes=10000,\n                 split_after_samples=25, min_samples_split=2,\n                 bagging_fraction=1.0, num_splits_to_consider=0,\n                 feature_bagging_fraction=1.0, max_fertile_nodes=0,\n                 valid_leaf_threshold=1, dominate_method=\'bootstrap\',\n                 dominate_fraction=0.99, regression=False, n_classes=None,\n                 n_features=None, metric=None, log_dir=\'/tmp/tflearn_logs/\',\n                 global_step=None, session=None, graph=None, name=None):\n\n        super(ForestEstimator, self).__init__(metric=metric,\n                                              log_dir=log_dir,\n                                              global_step=global_step,\n                                              session=session,\n                                              graph=graph,\n                                              name=name)\n        self._estimator_built = False\n\n        # Tree Params\n        self.n_estimators = n_estimators\n        self.max_nodes = max_nodes\n        self.split_after_samples = split_after_samples\n        self.min_samples_split = min_samples_split\n        self.regression = regression\n        self.n_classes = n_classes\n        self.n_features = n_features\n        self.bagging_fraction = bagging_fraction\n        self.num_splits_to_consider = num_splits_to_consider\n        self.feature_bagging_fraction = feature_bagging_fraction\n        self.max_fertile_nodes = max_fertile_nodes\n        self.valid_leaf_threshold = valid_leaf_threshold\n        self.dominate_method = dominate_method\n        self.dominate_fraction = dominate_fraction\n\n    def _build_estimator(self, X=None, Y=None):\n\n        if not self._estimator_built:\n            if self.n_features is None:\n                self.n_features = get_num_features(X)\n            if self.n_classes is None:\n                if not self.regression:\n                    self.n_classes = get_num_classes(Y)\n                else:\n                    self.n_classes = get_num_features(Y)\n\n            # Reload params from checkpoint if available\n            if self._to_be_restored and self.n_features is None:\n                self.n_features = read_tensor_in_checkpoint(\n                    \'n_features\', self._to_be_restored)\n            if self._to_be_restored and self.n_classes is None:\n                self.n_classes = read_tensor_in_checkpoint(\n                    \'n_classes\', self._to_be_restored)\n\n            # Purity checks\n            if self.n_classes is None:\n                raise ValueError(""\'n_classes\' cannot be None."")\n            if self.n_features is None:\n                raise ValueError(""\'n_features\' cannot be None."")\n\n            # Persistent Parameters\n            tf.Variable(self.n_classes, dtype=tf.int32, name=\'n_classes\')\n            tf.Variable(self.n_features, dtype=tf.int32, name=\'n_features\')\n\n            # Random Forest Parameters\n            self.params = tensor_forest.ForestHParams(\n                num_classes=self.n_classes, num_features=self.n_features,\n                num_trees=self.n_estimators, max_nodes=self.max_nodes,\n                split_after_samples=self.split_after_samples,\n                min_split_samples=self.min_samples_split,\n                regression=self.regression,\n                bagging_fraction=self.bagging_fraction,\n                num_splits_to_consider=self.num_splits_to_consider,\n                feature_bagging_fraction=self.feature_bagging_fraction,\n                max_fertile_nodes=self.max_fertile_nodes,\n                valid_leaf_threshold=self.valid_leaf_threshold,\n                dominate_method=self.dominate_method,\n                dominate_fraction=self.dominate_fraction).fill()\n            self.forest_graph = tensor_forest.RandomForestGraphs(self.params)\n            self._estimator_built = True\n\n    def fit(self, X, Y, batch_size=1024, shuffle=True, display_step=500,\n            n_jobs=1, max_steps=None):\n        """""" fit.\n\n        Build a forest of trees from the data provided.\n\n        Arguments:\n            X: `Tensor` or `Tensor list`. The input data. It must be a list of\n                `Tensor` in case of multiple inputs.\n            Y: `Tensor`. The labels/targets tensor.\n            batch_size: `int`. The batch size.\n            shuffle: ` bool`. If True, data are shuffled.\n            display_step: `int`. The step to display training information.\n            n_jobs: `int`. The number of jobs to use for the computation.\n            max_steps: `int`. Maximum number of optimization steps to run.\n\n        """"""\n\n        with self.graph.as_default():\n\n            # Verify data dimension\n            validate_dim(X, max_dim=2, min_dim=2, var_name=\'X\')\n            if not self.regression:\n                validate_dim(Y, max_dim=1, min_dim=1, var_name=\'Y\')\n            else:\n                validate_dim(Y, min_dim=1, var_name=\'Y\')\n\n            # Get data size\n            num_samples = get_num_sample(X)\n\n            # Build Tree Graph\n            self._build_estimator(X, Y)\n\n            # Generate Data Tensors. Be aware that every fit with different\n            # data will re-create a data tensor.\n            if self._train.get_params(\'X\') != hex(id(X)) or \\\n                self._train.get_params(\'Y\') != hex(id(Y)) or \\\n                self._train.get_params(\'batch_size\') != batch_size or \\\n                not self._train.is_ready:\n\n                X, Y, cr = generate_data_tensor(X, Y, batch_size=batch_size,\n                                                shuffle=shuffle,\n                                                num_threads=8)\n                X, _, spec = data_ops.ParseDataTensorOrDict(X)\n                Y = data_ops.ParseLabelTensorOrDict(Y)\n\n                self._train_op = tf.group(\n                    self.forest_graph.training_graph(X, Y, num_trainers=n_jobs),\n                    state_ops.assign_add(self.global_step, 1))\n                self._loss_op = self.forest_graph.training_loss(X, Y)\n                self._build_fit(X, Y, batch_size)\n\n                # Start QueueRunners\n                tf.train.start_queue_runners(sess=self.session)\n                if cr: cr.launch_threads(self.session)\n\n                self._init_graph()\n\n            gstep = self.global_step.eval(session=self.session)\n\n            last_loss = []\n            loss_val = None\n            step = 0\n\n            # Set step to -1 to exit training\n            while True:\n                # Monitor loss\n                last_loss.append(loss_val)\n                if len(last_loss) > 10: last_loss.pop(0)\n\n                start_time = time.time()\n                if (step) % display_step == 0:\n                    _, loss_val = self.session.run(\n                        [self._train_op, self._loss_op])  # TODO: Add acc\n                else:\n                    _, loss_val = self.session.run([self._train_op, self._loss_op])\n                duration = time.time() - start_time\n\n                if (step) % display_step == 0:\n                    examples_per_sec = batch_size / duration\n                    sec_per_batch = duration\n                    if self.metric:\n                        format_str = \'%s: step %d, loss = %.2f, acc = %.2f, \' \\\n                                     \'(%.1f examples/sec; %.3f sec/batch)\'\n                        print(format_str % (\n                            datetime.now(), step + gstep, loss_val,\n                            examples_per_sec, sec_per_batch))\n                    else:\n                        format_str = \'%s: step %d, loss = %.2f, \' \\\n                                     \'(%.1f examples/sec; %.3f sec/batch)\'\n                        print(format_str % (\n                            datetime.now(), step + gstep, loss_val,\n                            examples_per_sec, sec_per_batch))\n\n                step += 1\n\n                # Automatic stop after ten flat loss\n                if len(last_loss) == 10 and len(set(last_loss)) <= 1 and not max_steps:\n                    break\n\n                # Max Steps stop\n                if max_steps:\n                    if step == max_steps:\n                        break\n\n            save_path = os.path.join(self.log_dir, \'randomforest.ckpt\')\n            self.saver.save(sess=self.session,\n                            save_path=save_path,\n                            global_step=self.global_step)\n\n    def predict(self, X):\n        """""" predict.\n\n        Predict scores for X.\n\n        Arguments:\n            X: `1-D Array` or `2-D Array` of shape (n_samples, n_features).\n                The sample(s) to predict.\n\n        Return:\n            `Array` or `list` of `Array`. Prediction scores result.\n\n        """"""\n        with self.graph.as_default():\n            # Build Tree Graph\n            self._build_estimator()\n            if not self._pred.is_ready:\n                input = tf.placeholder(tf.float32, name=\'pred_input\',\n                                       shape=[None, self.n_features])\n                output, _, _ = self.forest_graph.inference_graph(input)\n                self._build_pred(input, output)\n            return self.session.run(self._pred.output_tensor,\n                                    feed_dict={self._pred.input_tensor: X})\n\n    def evaluate(self, X, Y, metric, batch_size=None):\n        """""" evaluate.\n\n        Evaluate the forest model with the given data and metric.\n\n        Arguments:\n            X: `2-D Array` of shape (n_samples, n_features).\n                The input data to evaluate on.\n            Y: `1-D Array` of shape (n_samples). The labels/targets data.\n            metric: `func` returning a `Tensor`. The metric function.\n            batch_size: `int`. If specified, process the data by batch.\n\n        Return:\n            The metric value.\n\n        """"""\n\n        with self.graph.as_default():\n            # Verify data dimension\n            validate_dim(X, max_dim=2, min_dim=2, var_name=\'X\')\n            if not self.regression:\n                validate_dim(Y, max_dim=1, min_dim=1, var_name=\'Y\')\n            else:\n                validate_dim(Y, min_dim=1, var_name=\'Y\')\n\n            # Get data size\n            num_samples = get_num_sample(X)\n            capacity = None\n            if batch_size is None:\n                batch_size = num_samples\n                capacity = 1\n\n            # Build Tree Graph\n            self._build_estimator(X, Y)\n\n            # Generate Data Tensors. Be aware that every eval with different\n            # data will re-create a data tensor.\n            if self._eval.get_params(\'X\') != hex(id(X)) or \\\n                self._eval.get_params(\'Y\') != hex(id(Y)) or \\\n                self._eval.get_params(\'batch_size\') != batch_size or \\\n                self._eval.get_params(\'metric\') != metric or \\\n                not self._eval.is_ready:\n\n                X, Y, cr = generate_data_tensor(X, Y, batch_size=batch_size,\n                                                shuffle=False,\n                                                num_threads=8,\n                                                capacity=capacity)\n                X, _, spec = data_ops.ParseDataTensorOrDict(X)\n                Y = data_ops.ParseLabelTensorOrDict(Y)\n\n                if not self.params.regression:\n                    Y = math_ops.to_float(array_ops.one_hot(math_ops.to_int64(\n                        array_ops.squeeze(Y)), self.params.n_classes, 1, 0))\n                    Y = tf.reshape(Y, [-1, self.n_classes])\n\n                pred, _, _ = self.forest_graph.inference_graph(X)\n                self._eval_op = metric(pred, Y)\n                self._build_eval(X, Y, metric, batch_size)\n\n                # Start QueueRunners\n                tf.train.start_queue_runners(sess=self.session)\n                if cr: cr.launch_threads(self.session)\n\n            n_batches = int(math.ceil(float(num_samples) / batch_size))\n\n            m = 0.\n            for i in range(n_batches):\n                m += self.session.run(self._eval_op) / n_batches\n            return m\n\n    def save(self, save_path):\n        """""" save.\n\n        Save model to the given path.\n\n        Args:\n            path: `str`. The path to save the model.\n\n        """"""\n        if not self._estimator_built:\n            with self.graph.as_default():\n                self._build_estimator()\n        self.saver.save(self.session, os.path.abspath(save_path))\n\n    def load(self, load_path):\n        """""" load.\n\n        Restore model from the given path.\n\n        Args:\n            path: `str`. The model path.\n\n        """"""\n        with self.graph.as_default():\n            self.session = tf.Session()\n            if self._estimator_built:\n                self.saver.restore(self.session, os.path.abspath(load_path))\n            else:\n                self._to_be_restored = os.path.abspath(load_path)\n\n\nclass RandomForestClassifier(ForestEstimator):\n    """""" [WIP] Random Forest Classifier.\n\n    """"""\n\n    def __init__(self, n_estimators=10, max_nodes=100,\n                 split_after_samples=25, n_classes=None, n_features=None,\n                 metric=None, log_dir=\'/tmp/tflearn_logs/\', global_step=None,\n                 session=None, graph=None, name=None):\n        super(RandomForestClassifier, self).__init__(\n            n_estimators=n_estimators, max_nodes=max_nodes,\n            split_after_samples=split_after_samples, regression=False,\n            n_classes=n_classes, n_features=n_features, metric=metric,\n            log_dir=log_dir, global_step=global_step, session=session,\n            graph=graph, name=name)\n\n    def predict(self, X):\n        """""" predict.\n\n        Predict class for X.\n\n        Arguments:\n            X: array-like or sparse matrix of shape = [n_samples, n_features]\n                The input samples. Internally, its dtype will be converted to\n                ``dtype=np.float32``. If a sparse matrix is provided, it will be\n                converted into a sparse ``csr_matrix``.\n        Returns:\n            Y: array of shape = [n_samples] or [n_samples, n_outputs]\n                The predicted classes.\n        """"""\n        sc = super(RandomForestClassifier, self)\n        return np.argmax(sc.predict(X), axis=1)\n\n    def predict_proba(self, X):\n        """""" predict_proba.\n\n        Predict class probablities for X.\n\n        Arguments:\n            X: array-like or sparse matrix of shape = [n_samples, n_features]\n                The input samples. Internally, its dtype will be converted to\n                ``dtype=np.float32``. If a sparse matrix is provided, it will be\n                converted into a sparse ``csr_matrix``.\n\n        Returns:\n            p : array of shape = [n_samples, n_classes], or a list of n_outputs\n                such arrays if n_outputs > 1.\n                The class probabilities of the input samples. The order of the\n                classes corresponds to that in the attribute `classes_`.\n        """"""\n        sc = super(RandomForestClassifier, self)\n        return sc.predict(X)\n\n    def predict_log_proba(self, X):\n        """""" predict_log_proba.\n\n        Predict class log-probabilities for X.\n\n        Arguments:\n            X: array-like or sparse matrix of shape = [n_samples, n_features]\n                The input samples. Internally, its dtype will be converted to\n                ``dtype=np.float32``. If a sparse matrix is provided, it will be\n                converted into a sparse ``csr_matrix``.\n        Returns:\n            p: array of shape = [n_samples, n_classes], or a list of n_outputs\n                such arrays if n_outputs > 1.\n                The class probabilities of the input samples. The order of the\n                classes corresponds to that in the attribute `classes_`.\n        """"""\n        return np.log(self.predict_proba(X))\n\n\nclass RandomForestRegressor(ForestEstimator):\n    """""" [WIP] Random Forest Regressor.\n\n    """"""\n\n    def __init__(self, n_estimators=10, max_nodes=100,\n                 split_after_samples=25, n_features=None, num_output=None,\n                 metric=None, log_dir=\'/tmp/tflearn_logs/\', global_step=None,\n                 session=None, graph=None, name=None):\n        super(RandomForestRegressor, self).__init__(\n            n_estimators=n_estimators, max_nodes=max_nodes,\n            split_after_samples=split_after_samples, regression=True,\n            n_classes=num_output, n_features=n_features, metric=metric,\n            log_dir=log_dir, global_step=global_step, session=session,\n            graph=graph, name=name)\n'"
