file_path,api_count,code
cifar10_nasnet.py,0,"b'""""""\nAdapted from keras example cifar10_cnn.py\nTrain NASNet-CIFAR on the CIFAR10 small images dataset.\n""""""\nfrom __future__ import print_function\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import CSVLogger\nfrom keras.optimizers import Adam\nfrom nasnet import NASNetCIFAR, preprocess_input\nfrom cutout import cutout\nimport numpy as np\n\n\nweights_file = \'NASNet-CIFAR-10.h5\'\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.5), cooldown=0, patience=5, min_lr=0.5e-5)\ncsv_logger = CSVLogger(\'NASNet-CIFAR-10.csv\')\nmodel_checkpoint = ModelCheckpoint(weights_file, monitor=\'val_predictions_acc\', save_best_only=True,\n                                   save_weights_only=True, mode=\'max\')\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 200 # should be 600\ndata_augmentation = True\n\n# input image dimensions\nimg_rows, img_cols = 32, 32\n# The CIFAR10 images are RGB.\nimg_channels = 3\n\n# The data, shuffled and split between train and test sets:\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\n# Convert class vectors to binary class matrices.\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nX_train = X_train.astype(\'float32\')\nX_test = X_test.astype(\'float32\')\n\n# preprocess input\nX_train = preprocess_input(X_train)\nX_test = preprocess_input(X_test)\n\n# For training, the auxilary branch must be used to correctly train NASNet\nmodel = NASNetCIFAR((img_rows, img_cols, img_channels), use_auxiliary_branch=True)\nmodel.summary()\n\noptimizer = Adam(lr=1e-3, clipnorm=5)\nmodel.compile(loss=[\'categorical_crossentropy\', \'categorical_crossentropy\'],\n              optimizer=optimizer, metrics=[\'accuracy\'], loss_weights=[1.0, 0.4])\n\n# model.load_weights(\'NASNet-CIFAR-10.h5\', by_name=True)\n\nif not data_augmentation:\n    print(\'Not using data augmentation.\')\n    model.fit(X_train, [Y_train, Y_train],\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              validation_data=(X_test, [Y_test, Y_test]),\n              shuffle=True,\n              verbose=1,\n              callbacks=[lr_reducer, csv_logger, model_checkpoint])\nelse:\n    print(\'Using real-time data augmentation.\')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        preprocessing_function=cutout)  # randomly apply cutout\n\n    # Compute quantities required for featurewise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(X_train)\n\n    # wrap the ImageDataGenerator to yield two label batches [y, y] for each input batch X\n    def image_generator(image_datagenerator, batch_size):\n        iterator = datagen.flow(X_train, Y_train, batch_size=batch_size)\n\n        while True:\n            X, y = next(iterator)  # get the next batch\n            yield X, [y, y]  # duplicate the labels for each batch\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(image_generator(datagen, batch_size),\n                        steps_per_epoch=X_train.shape[0] // batch_size,\n                        validation_data=(X_test, [Y_test, Y_test]),\n                        epochs=nb_epoch, verbose=1,\n                        callbacks=[lr_reducer, csv_logger, model_checkpoint])\n\nscores = model.evaluate(X_test, [Y_test, Y_test], batch_size=batch_size)\nfor score, metric_name in zip(scores, model.metrics_names):\n    print(""%s : %0.4f"" % (metric_name, score))\n'"
cutout.py,0,"b""from __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom keras.preprocessing import image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef cutout(img):\n    MAX_CUTS = 5  # chance to get more cuts\n    MAX_LENGTH_MULTIPLIER = 5  # change to get larger cuts ; 16 for cifar 10, 8 for cifar 100\n\n    height = img.shape[1]\n    width = img.shape[2]\n\n    # normalize before adding the mask\n    mean = img.mean(keepdims=True)\n    img -= mean\n\n    mask = np.ones((height, width), np.float32)\n    nb_cuts = np.random.randint(0, MAX_CUTS + 1)\n\n    for i in range(nb_cuts):\n        y = np.random.randint(height)\n        x = np.random.randint(width)\n        length = 4 * np.random.randint(1, MAX_LENGTH_MULTIPLIER + 1)\n\n        y1 = np.clip(y - length // 2, 0, height)\n        y2 = np.clip(y + length // 2, 0, height)\n        x1 = np.clip(x - length // 2, 0, width)\n        x2 = np.clip(x + length // 2, 0, width)\n\n        mask[y1: y2, x1: x2] = 0.\n\n    # apply mask\n    img = img * mask\n\n    # denormalize\n    img += mean\n\n    return img\n\n\nif __name__ == '__main__':\n    size = 256\n\n    img_path = 'images/cheetah.jpg'\n    img = image.load_img(img_path, target_size=(size, size))\n    x = image.img_to_array(img)\n    x = (x / 255.0).astype('float32')\n\n    x = cutout(x)\n\n    plt.imshow(x)\n    plt.show()\n"""
imagenet_validation.py,8,"b'import glob\nfrom keras.preprocessing import image\nfrom keras.metrics import top_k_categorical_accuracy\nfrom keras import backend as K\n\nimport tensorflow as tf\nkeras_sess = tf.Session()\nK.set_session(keras_sess)\n\nfrom nasnet import NASNetLarge, NASNetMobile, preprocess_input, decode_predictions\n\nimport numpy as np\n\nbatch_size = 25\n\ndef process_images(filename, label):\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_png(image_string, channels=3)\n    image_resized = tf.image.resize_image_with_crop_or_pad(image_decoded, size, size)\n    image_resized = tf.cast(image_resized, tf.float32)\n    image_normalized = preprocess_input(image_resized)\n\n    label = tf.one_hot(label, depth=1000, dtype=tf.float32)\n    return image_normalized, label\n\n\ndef generator(batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices((files, labels))\n    dataset = dataset.map(process_images, 2)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(5)\n    iterator = dataset.make_one_shot_iterator()\n\n    batch = iterator.get_next()\n\n    while True:\n        yield K.get_session().run(batch)\n\n\ntype = \'mobile\'\n\nif __name__ == \'__main__\':\n    size = 331 if type == \'large\' else 224\n\n    if tf.device(\'/cpu:0\'):\n        if type == \'large\':\n            model = NASNetLarge(input_shape=(size, size, 3), weights=None)\n            model.load_weights(\'weights/NASNet-large.h5\')\n            print(""Loaded NASNet Large"")\n        else:\n            model = NASNetMobile(input_shape=(size, size, 3), weights=None)\n            model.load_weights(\'weights/NASNet-mobile.h5\')\n            print(""Loaded NASNet Mobile"")\n        #model.summary()\n\n\n        VAL_PATH = \'D:/Yue/Documents/Downloads/ILSVRC2012_img_val/*\'\n        files = sorted(glob.glob(VAL_PATH))\n\n        with open(\'ImageNet_Val.txt\', \'r\') as f:\n            labels = [int(x.split()[1]) for x in f]\n\n        files = files[:1000]\n        labels = labels[:1000]\n\n        files = np.array(files)\n        labels = np.array(labels)\n\n        model.compile(\'sgd\', loss=\'categorical_crossentropy\', metrics=[\'accuracy\', top_k_categorical_accuracy])\n\n        scores = model.evaluate_generator(generator(batch_size), steps=len(files) // batch_size, workers=0, verbose=1)\n        print(""Imagenet Validation scores : "", scores)\n'"
nasnet.py,2,"b'""""""NASNet-A models for Keras\n\nNASNet refers to Neural Architecture Search Network, a family of models\nthat were designed automatically by learning the model architectures\ndirectly on the dataset of interest.\n\nHere we consider NASNet-A, the highest performance model that was found\nfor the CIFAR-10 dataset, and then extended to ImageNet 2012 dataset,\nobtaining state of the art performance on CIFAR-10 and ImageNet 2012.\nOnly the NASNet-A models, and their respective weights, which are suited\nfor ImageNet 2012 are provided.\n\nThe below table describes the performance on ImageNet 2012:\n------------------------------------------------------------------------------------\n      Architecture       | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M)\n------------------------------------------------------------------------------------\n|   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3        |\n|   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9        |\n------------------------------------------------------------------------------------\n\nWeights obtained from the official Tensorflow repository found at\nhttps://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet\n\n# References:\n - [Learning Transferable Architectures for Scalable Image Recognition]\n    (https://arxiv.org/abs/1707.07012)\n\nBased on the following implementations:\n - [TF Slim Implementation]\n   (https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.)\n - [TensorNets implementation]\n   (https://github.com/taehoonlee/tensornets/blob/master/tensornets/nasnets.py)\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport warnings\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Activation\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import Conv2D\nfrom keras.layers import SeparableConv2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Flatten\nfrom keras.layers import Cropping2D\nfrom keras.layers import concatenate\nfrom keras.layers import add\nfrom keras.regularizers import l2\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras import backend as K\n\n_BN_DECAY = 0.9997\n_BN_EPSILON = 1e-3\n\nNASNET_MOBILE_WEIGHT_PATH = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-mobile.h5""\nNASNET_MOBILE_WEIGHT_PATH_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-mobile-no-top.h5""\nNASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-auxiliary-mobile.h5""\nNASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-auxiliary-mobile-no-top.h5""\nNASNET_LARGE_WEIGHT_PATH = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-large.h5""\nNASNET_LARGE_WEIGHT_PATH_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-large-no-top.h5""\nNASNET_LARGE_WEIGHT_PATH_WITH_auxiliary = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-auxiliary-large.h5""\nNASNET_LARGE_WEIGHT_PATH_WITH_auxiliary_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-auxiliary-large-no-top.h5""\n\n\ndef NASNet(input_shape=None,\n           penultimate_filters=4032,\n           nb_blocks=6,\n           stem_filters=96,\n           initial_reduction=True,\n           skip_reduction_layer_input=True,\n           use_auxiliary_branch=False,\n           filters_multiplier=2,\n           dropout=0.5,\n           weight_decay=5e-5,\n           include_top=True,\n           weights=None,\n           input_tensor=None,\n           pooling=None,\n           classes=1000,\n           default_size=None):\n    """"""Instantiates a NASNet architecture.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge or\n            `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        penultimate_filters: number of filters in the penultimate layer.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        nb_blocks: number of repeated blocks of the NASNet model.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        stem_filters: number of filters in the initial stem block\n        skip_reduction: Whether to skip the reduction step at the tail\n            end of the network. Set to `True` for CIFAR models.\n        skip_reduction_layer_input: Determines whether to skip the reduction layers\n            when calculating the previous layer to connect to.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        filters_multiplier: controls the width of the network.\n            - If `filters_multiplier` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `filters_multiplier` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `filters_multiplier` = 1, default number of filters from the paper\n                 are used at each layer.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    if K.backend() != \'tensorflow\':\n        raise RuntimeError(\'Only Tensorflow backend is currently supported, \'\n                           \'as other backends do not support \'\n                           \'separable convolution.\')\n\n    if weights not in {\'imagenet\', None}:\n        raise ValueError(\'The `weights` argument should be either \'\n                         \'`None` (random initialization) or `imagenet` \'\n                         \'(pre-training on ImageNet).\')\n\n    if weights == \'imagenet\' and include_top and classes != 1000:\n        raise ValueError(\'If using `weights` as ImageNet with `include_top` \'\n                         \'as true, `classes` should be 1000\')\n\n    if default_size is None:\n        default_size = 331\n\n    # Determine proper input shape and default size.\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top or weights)\n\n    if K.image_data_format() != \'channels_last\':\n        warnings.warn(\'The NASNet family of models is only available \'\n                      \'for the input data format ""channels_last"" \'\n                      \'(width, height, channels). \'\n                      \'However your settings specify the default \'\n                      \'data format ""channels_first"" (channels, width, height).\'\n                      \' You should set `image_data_format=""channels_last""` \'\n                      \'in your Keras config located at ~/.keras/keras.json. \'\n                      \'The model being returned right now will expect inputs \'\n                      \'to follow the ""channels_last"" data format.\')\n        K.set_image_data_format(\'channels_last\')\n        old_data_format = \'channels_first\'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    assert penultimate_filters % 24 == 0, ""`penultimate_filters` needs to be divisible "" \\\n                                          ""by 24.""\n\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    filters = penultimate_filters // 24\n\n    if initial_reduction:\n        x = Conv2D(stem_filters, (3, 3), strides=(2, 2), padding=\'valid\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(img_input)\n    else:\n        x = Conv2D(stem_filters, (3, 3), strides=(1, 1), padding=\'same\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(img_input)\n\n    x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                           name=\'stem_bn1\')(x)\n\n    p = None\n    if initial_reduction:  # imagenet / mobile mode\n        x, p = _reduction_A(x, p, filters // (filters_multiplier ** 2), weight_decay, id=\'stem_1\')\n        x, p = _reduction_A(x, p, filters // filters_multiplier, weight_decay, id=\'stem_2\')\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters, weight_decay, id=\'%d\' % (i))\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier, weight_decay, id=\'reduce_%d\' % (nb_blocks))\n\n    p = p0 if not skip_reduction_layer_input else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier, weight_decay, id=\'%d\' % (nb_blocks + i + 1))\n\n    auxiliary_x = None\n    if not initial_reduction:  # imagenet / mobile mode\n        if use_auxiliary_branch:\n            auxiliary_x = _add_auxiliary_head(x, classes, weight_decay, pooling, include_top)\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'reduce_%d\' % (2 * nb_blocks))\n\n    if initial_reduction:  # CIFAR mode\n        if use_auxiliary_branch:\n            auxiliary_x = _add_auxiliary_head(x, classes, weight_decay, pooling, include_top)\n\n    p = p0 if not skip_reduction_layer_input else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'%d\' % (2 * nb_blocks + i + 1))\n\n    x = Activation(\'relu\')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D()(x)\n        x = Dropout(dropout)(x)\n        x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay), name=\'predictions\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    if use_auxiliary_branch:\n        model = Model(inputs, [x, auxiliary_x], name=\'NASNet_with_auxiliary\')\n    else:\n        model = Model(inputs, x, name=\'NASNet\')\n\n    # load weights\n    if weights == \'imagenet\':\n        if default_size == 224:  # mobile version\n            if include_top:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY\n                    model_name = \'nasnet_mobile_with_aux.h5\'\n                else:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH\n                    model_name = \'nasnet_mobile.h5\'\n            else:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY_NO_TOP\n                    model_name = \'nasnet_mobile_with_aux_no_top.h5\'\n                else:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_NO_TOP\n                    model_name = \'nasnet_mobile_no_top.h5\'\n\n            weights_file = get_file(model_name, weight_path, cache_subdir=\'models\')\n            model.load_weights(weights_file)\n\n        elif default_size == 331:  # large version\n            if include_top:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_WITH_auxiliary\n                    model_name = \'nasnet_large_with_aux.h5\'\n                else:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH\n                    model_name = \'nasnet_large.h5\'\n            else:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_WITH_auxiliary_NO_TOP\n                    model_name = \'nasnet_large_with_aux_no_top.h5\'\n                else:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_NO_TOP\n                    model_name = \'nasnet_large_no_top.h5\'\n\n            weights_file = get_file(model_name, weight_path, cache_subdir=\'models\')\n            model.load_weights(weights_file)\n\n        else:\n            raise ValueError(\'ImageNet weights can only be loaded on NASNetLarge or NASNetMobile\')\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n\n    return model\n\n\ndef NASNetLarge(input_shape=(331, 331, 3),\n                dropout=0.5,\n                weight_decay=5e-5,\n                use_auxiliary_branch=False,\n                include_top=True,\n                weights=\'imagenet\',\n                input_tensor=None,\n                pooling=None,\n                classes=1000):\n    """"""Instantiates a NASNet architecture in ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    return NASNet(input_shape,\n                  penultimate_filters=4032,\n                  nb_blocks=6,\n                  stem_filters=96,\n                  initial_reduction=True,\n                  skip_reduction_layer_input=True,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=331)\n\n\ndef NASNetMobile(input_shape=(224, 224, 3),\n                 dropout=0.5,\n                 weight_decay=4e-5,\n                 use_auxiliary_branch=False,\n                 include_top=True,\n                 weights=\'imagenet\',\n                 input_tensor=None,\n                 pooling=None,\n                 classes=1000):\n    """"""Instantiates a NASNet architecture in Mobile ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    return NASNet(input_shape,\n                  penultimate_filters=1056,\n                  nb_blocks=4,\n                  stem_filters=32,\n                  initial_reduction=True,\n                  skip_reduction_layer_input=False,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef NASNetCIFAR(input_shape=(32, 32, 3),\n                dropout=0.0,\n                weight_decay=5e-4,\n                use_auxiliary_branch=False,\n                include_top=True,\n                weights=None,\n                input_tensor=None,\n                pooling=None,\n                classes=10):\n    """"""Instantiates a NASNet architecture in CIFAR mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(32, 32, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(32, 32, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9\n    _BN_EPSILON = 1e-5\n\n    return NASNet(input_shape,\n                  penultimate_filters=768,\n                  nb_blocks=6,\n                  stem_filters=32,\n                  initial_reduction=False,\n                  skip_reduction_layer_input=False,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1), weight_decay=5e-5, id=None):\n    \'\'\'Adds 2 blocks of [relu-separable conv-batchnorm]\n\n    # Arguments:\n        ip: input tensor\n        filters: number of output filters per layer\n        kernel_size: kernel size of separable convolutions\n        strides: strided convolution for downsampling\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'separable_conv_block_%s\' % id):\n        x = Activation(\'relu\')(ip)\n        x = SeparableConv2D(filters, kernel_size, strides=strides, name=\'separable_conv_1_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_1_bn_%s"" % (id))(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(filters, kernel_size, name=\'separable_conv_2_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_2_bn_%s"" % (id))(x)\n    return x\n\n\ndef _adjust_block(p, ip, filters, weight_decay=5e-5, id=None):\n    \'\'\'\n    Adjusts the input `p` to match the shape of the `input`\n    or situations where the output number of filters needs to\n    be changed\n\n    # Arguments:\n        p: input tensor which needs to be modified\n        ip: input tensor whose shape needs to be matched\n        filters: number of output filters to be matched\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        an adjusted Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    img_dim = 2 if K.image_data_format() == \'channels_first\' else -2\n\n    with K.name_scope(\'adjust_block\'):\n        if p is None:\n            p = ip\n\n        elif p._keras_shape[img_dim] != ip._keras_shape[img_dim]:\n            with K.name_scope(\'adjust_reduction_block_%s\' % id):\n                p = Activation(\'relu\', name=\'adjust_relu_1_%s\' % id)(p)\n\n                p1 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_1_%s\' % id)(p)\n                p1 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_1_%s\' % id, kernel_initializer=\'he_normal\')(p1)\n\n                p2 = ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n                p2 = Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n                p2 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_2_%s\' % id)(p2)\n                p2 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_2_%s\' % id, kernel_initializer=\'he_normal\')(p2)\n\n                p = concatenate([p1, p2], axis=channel_dim)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id)(p)\n\n        elif p._keras_shape[channel_dim] != filters:\n            with K.name_scope(\'adjust_projection_block_%s\' % id):\n                p = Activation(\'relu\')(p)\n                p = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'adjust_conv_projection_%s\' % id,\n                           use_bias=False, kernel_regularizer=l2(weight_decay), kernel_initializer=\'he_normal\')(p)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id)(p)\n    return p\n\n\ndef _normal_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'normal_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'normal_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'normal_bn_1_%s\' % id)(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, kernel_size=(5, 5), weight_decay=weight_decay,\n                                         id=\'normal_left1_%s\' % id)\n            x1_2 = _separable_conv_block(p, filters, weight_decay=weight_decay, id=\'normal_right1_%s\' % id)\n            x1 = add([x1_1, x1_2], name=\'normal_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = _separable_conv_block(p, filters, (5, 5), weight_decay=weight_decay, id=\'normal_left2_%s\' % id)\n            x2_2 = _separable_conv_block(p, filters, (3, 3), weight_decay=weight_decay, id=\'normal_right2_%s\' % id)\n            x2 = add([x2_1, x2_2], name=\'normal_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left3_%s\' % (id))(h)\n            x3 = add([x3, p], name=\'normal_add_3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4_1 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left4_%s\' % (id))(p)\n            x4_2 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_right4_%s\' % (id))(p)\n            x4 = add([x4_1, x4_2], name=\'normal_add_4_%s\' % id)\n\n        with K.name_scope(\'block_5\'):\n            x5 = _separable_conv_block(h, filters, weight_decay=weight_decay, id=\'normal_left5_%s\' % id)\n            x5 = add([x5, h], name=\'normal_add_5_%s\' % id)\n\n        x = concatenate([p, x1, x2, x3, x4, x5], axis=channel_dim, name=\'normal_concat_%s\' % id)\n    return x, ip\n\n\ndef _reduction_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    """"""""""""\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'reduction_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'reduction_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'reduction_bn_1_%s\' % id)(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_left1_%s\' % id)\n            x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_1_%s\' % id)\n            x1 = add([x1_1, x1_2], name=\'reduction_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left2_%s\' % id)(h)\n            x2_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right2_%s\' % id)\n            x2 = add([x2_1, x2_2], name=\'reduction_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3_1 = AveragePooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left3_%s\' % id)(h)\n            x3_2 = _separable_conv_block(p, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right3_%s\' % id)\n            x3 = add([x3_1, x3_2], name=\'reduction_add3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'reduction_left4_%s\' % id)(x1)\n            x4 = add([x2, x4])\n\n        with K.name_scope(\'block_5\'):\n            x5_1 = _separable_conv_block(x1, filters, (3, 3), weight_decay=weight_decay, id=\'reduction_left4_%s\' % id)\n            x5_2 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_right5_%s\' % id)(h)\n            x5 = add([x5_1, x5_2], name=\'reduction_add4_%s\' % id)\n\n        x = concatenate([x2, x3, x4, x5], axis=channel_dim, name=\'reduction_concat_%s\' % id)\n        return x, ip\n\n\ndef _add_auxiliary_head(x, classes, weight_decay, pooling, include_top):\n    \'\'\'Adds an auxiliary head for training the model\n\n    From section A.7 ""Training of ImageNet models"" of the paper, all NASNet models are\n    trained using an auxiliary classifier around 2/3 of the depth of the network, with\n    a loss weight of 0.4\n\n    # Arguments\n        x: input tensor\n        classes: number of output classes\n        weight_decay: l2 regularization weight\n\n    # Returns\n        a keras Tensor\n    \'\'\'\n    img_height = 1 if K.image_data_format() == \'channels_last\' else 2\n    img_width = 2 if K.image_data_format() == \'channels_last\' else 3\n    channel_axis = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'auxiliary_branch\'):\n        auxiliary_x = Activation(\'relu\')(x)\n        auxiliary_x = AveragePooling2D((5, 5), strides=(3, 3), padding=\'valid\', name=\'aux_pool\')(auxiliary_x)\n        auxiliary_x = Conv2D(128, (1, 1), padding=\'same\', use_bias=False, name=\'aux_conv_projection\',\n                            kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(auxiliary_x)\n        auxiliary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_projection\')(auxiliary_x)\n        auxiliary_x = Activation(\'relu\')(auxiliary_x)\n\n        auxiliary_x = Conv2D(768, (auxiliary_x._keras_shape[img_height], auxiliary_x._keras_shape[img_width]),\n                            padding=\'valid\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay), name=\'aux_conv_reduction\')(auxiliary_x)\n        auxiliary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_reduction\')(auxiliary_x)\n        auxiliary_x = Activation(\'relu\')(auxiliary_x)\n\n        if include_top:\n            auxiliary_x = Flatten()(auxiliary_x)\n            auxiliary_x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay),\n                                name=\'aux_predictions\')(auxiliary_x)\n        else:\n            if pooling == \'avg\':\n                auxiliary_x = GlobalAveragePooling2D()(auxiliary_x)\n            elif pooling == \'max\':\n                auxiliary_x = GlobalMaxPooling2D()(auxiliary_x)\n\n    return auxiliary_x\n\n\nif __name__ == \'__main__\':\n    import tensorflow as tf\n\n    sess = tf.Session()\n\n    K.set_session(sess)\n\n    model = NASNetLarge((331, 331, 3), use_auxiliary_branch=True, include_top=False, weights=None)\n    model.load_weights(\'weights/NASNet-auxilary-large-no-top.h5\')\n    model.summary()\n\n    # writer = tf.summary.FileWriter(\'./logs/\', graph=K.get_session().graph)\n    # writer.close()'"
predict_imagenet.py,1,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom keras.preprocessing import image\n\nimport tensorflow as tf\nfrom nasnet import NASNetLarge, NASNetMobile, preprocess_input, decode_predictions\n\nimport numpy as np\n\ntype = \'large\'\n\nif __name__ == \'__main__\':\n    size = 331 if type == \'large\' else 224\n\n    if tf.device(\'/cpu:0\'):\n        if type == \'large\':\n            model = NASNetLarge(input_shape=(size, size, 3), weights=None, use_auxiliary_branch=False)\n            model.load_weights(\'weights/NASNet-large.h5\')\n            print(""Loaded NASNet Large"")\n        else:\n            model = NASNetMobile(input_shape=(size, size, 3), weights=None, use_auxiliary_branch=False)\n            model.load_weights(\'weights/NASNet-mobile.h5\')\n            print(""Loaded NASNet Mobile"")\n        #model.summary()\n\n        img_path = \'images/cheetah.jpg\'\n        img = image.load_img(img_path, target_size=(size, size))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n\n        x = preprocess_input(x)\n\n        preds = model.predict(x, verbose=1)\n\n        # without auxiliary head\n        print(\'Predicted:\', decode_predictions(preds))\n\n        # with auxiliary head\n        #print(\'Predicted:\', decode_predictions(preds[0]))\n        #print(\'Predicted:\', decode_predictions(preds[1]))\n'"
tf_hub_compare.py,5,"b'import numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom keras.preprocessing import image\n\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom nasnet import NASNetLarge, NASNetMobile, preprocess_input\n\ntype = \'mobile\'\n\nsize = 331 if type == \'large\' else 224\n\n\nurl = \'https://tfhub.dev/google/imagenet\'\nmodel_name = \'nasnet_%s\' % type\n\nimg_path = \'images/cheetah.jpg\'\nimg = image.load_img(img_path, target_size=(size, size))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = x.astype(\'float32\')\n\nx_ = preprocess_input(x.copy())\n\nwith tf.device(\'/cpu:0\'):\n    print(""Initializing TF-Hub model"")\n    inputs = tf.placeholder(tf.float32, [None, size, size, 3])\n    tfhub = hub.Module(""%s/%s/classification/1"" % (url, model_name))\n    features = tfhub(inputs, signature=""image_classification"", as_dict=True)\n    model_tfhub = tf.nn.softmax(features[\'default\'])\n\n    if type == \'large\':\n        model = NASNetLarge(input_shape=(size, size, 3), weights=None)\n        model.load_weights(\'weights/NASNet-large.h5\')\n        print(""Loaded NASNet Large"")\n    else:\n        model = NASNetMobile(input_shape=(size, size, 3), weights=None)\n        model.load_weights(\'weights/NASNet-mobile.h5\')\n        print(""Loaded NASNet Mobile"")\n\n    preds = model.predict(x_)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        x /= 255.\n        preds_tfhub = sess.run(model_tfhub, feed_dict={inputs: x})\n\n    print(""Model "", decode_predictions(preds))\n    print(""TF Hub"", decode_predictions(preds_tfhub[:, 1:]))\n\n    np.testing.assert_allclose(preds, preds_tfhub[:, 1:], atol=1e-5)'"
weight_translation/extract_weights.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport os\nimport glob\nfrom tensorflow.python import pywrap_tensorflow\n\ncheckpoint_file = \'checkpoint/model.ckpt\'\n\nfp = ""weights/""\n\nif not os.path.exists(fp):\n    os.makedirs(fp)\n\n\ndef print_tensors_in_checkpoint_file(file_name, tensor_name, all_tensors):\n  """"""Prints tensors in a checkpoint file.\n\n  If no `tensor_name` is provided, prints the tensor names and shapes\n  in the checkpoint file.\n\n  If `tensor_name` is provided, prints the content of the tensor.\n\n  Args:\n    file_name: Name of the checkpoint file.\n    tensor_name: Name of the tensor in the checkpoint file to print.\n    all_tensors: Boolean indicating whether to print all tensors.\n  """"""\n\n  try:\n    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n    if all_tensors:\n      var_to_shape_map = reader.get_variable_to_shape_map()\n      for key in var_to_shape_map:\n        print(""tensor_name: "", key)\n\n        path = fp + str(key).replace(""/"", ""_"") + "".npy""\n        array = reader.get_tensor(key)\n\n        np.save(path, array)\n        print(""Saved weights"")\n\n    elif not tensor_name:\n      print(reader.debug_string().decode(""utf-8""))\n    else:\n      print(""tensor_name: "", tensor_name)\n      print(reader.get_tensor(tensor_name))\n  except Exception as e:  # pylint: disable=broad-except\n    print(str(e))\n    if ""corrupted compressed block contents"" in str(e):\n      print(""It\'s likely that your checkpoint file has been compressed ""\n            ""with SNAPPY."")\n    if (""Data loss"" in str(e) and\n        (any([e in file_name for e in ["".index"", "".meta"", "".data""]]))):\n      proposed_file = ""."".join(file_name.split(""."")[0:-1])\n      v2_file_error_template = """"""\nIt\'s likely that this is a V2 checkpoint and you need to provide the filename\n*prefix*.  Try removing the \'.\' and extension.  Try:\ninspect checkpoint --file_name = {}""""""\n      print(v2_file_error_template.format(proposed_file))\n\n\nprint_tensors_in_checkpoint_file(checkpoint_file, None, True)\n\nos.remove(\'weights/global_step.npy\')\nfor fn in glob.glob(\'weights/*_ExponentialMovingAverage.npy\'):\n  os.remove(fn)\n\n# Remove non EMA weights\n# for fn in glob.glob(\'weights/*.npy\'):\n#     if \'moving\' not in fn and \'Exponential\' not in fn:\n#         os.remove(fn)\n\nfor fn in glob.glob(\'weights/*_RMSProp.npy\'):\n  os.remove(fn)\n\nfor fn in glob.glob(\'weights/*_RMSProp_1.npy\'):\n  os.remove(fn)'"
weight_translation/nasnet.py,16,"b'""""""Collection of NASNet models\n\nThe reference paper:\n - [Learning Transferable Architectures for Scalable Image Recognition]\n    (https://arxiv.org/abs/1707.07012)\n\nThe reference implementation:\n1. TF Slim\n - https://github.com/tensorflow/models/blob/master/research/slim/nets/\n   nasnet/nasnet.py\n2. TensorNets\n - https://github.com/taehoonlee/tensornets/blob/master/tensornets/nasnets.py\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport warnings\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Activation\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import Conv2D\nfrom keras.layers import SeparableConv2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Cropping2D\nfrom keras.layers import concatenate\nfrom keras.layers import add\nfrom keras.regularizers import l2\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras import backend as K\n\n_BN_DECAY = 0.9997\n_BN_EPSILON = 1e-3\n\n\nSTEM_IDX = 0\nREDUCTION_IDX = 0\nNORMAL_IDX = 0\n\ndef NASNet(input_shape=None,\n           penultimate_filters=4032,\n           nb_blocks=6,\n           stem_filters=336,\n           initial_reduction=True,\n           skip_reduction_layer_input=True,\n           use_auxilary_branch=False,\n           filters_multiplier=2,\n           dropout=0.5,\n           weight_decay=5e-5,\n           include_top=True,\n           weights=None,\n           input_tensor=None,\n           pooling=None,\n           classes=1000,\n           default_size=None):\n    """"""Instantiates a NASNet architecture.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge or\n            `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        penultimate_filters: number of filters in the penultimate layer.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        nb_blocks: number of repeated blocks of the NASNet model.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        stem_filters: number of filters in the initial stem block\n        skip_reduction: Whether to skip the reduction step at the tail\n            end of the network. Set to `False` for CIFAR models.\n        use_auxilary_branch: Whether to use the auxilary branch during\n            training or evaluation.\n        filters_multiplier: controls the width of the network.\n            - If `filters_multiplier` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `filters_multiplier` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `filters_multiplier` = 1, default number of filters from the paper\n                 are used at each layer.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    if K.backend() != \'tensorflow\':\n        raise RuntimeError(\'Only Tensorflow backend is currently supported, \'\n                           \'as other backends do not support \'\n                           \'separable convolution.\')\n\n    if weights not in {\'imagenet\', None}:\n        raise ValueError(\'The `weights` argument should be either \'\n                         \'`None` (random initialization) or `imagenet` \'\n                         \'(pre-training on ImageNet).\')\n\n    if weights == \'imagenet\' and include_top and classes != 1000:\n        raise ValueError(\'If using `weights` as ImageNet with `include_top` \'\n                         \'as true, `classes` should be 1000\')\n\n    if default_size is None:\n        default_size = 331\n\n    # Determine proper input shape and default size.\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top or weights)\n\n    if K.image_data_format() != \'channels_last\':\n        warnings.warn(\'The MobileNet family of models is only available \'\n                      \'for the input data format ""channels_last"" \'\n                      \'(width, height, channels). \'\n                      \'However your settings specify the default \'\n                      \'data format ""channels_first"" (channels, width, height).\'\n                      \' You should set `image_data_format=""channels_last""` \'\n                      \'in your Keras config located at ~/.keras/keras.json. \'\n                      \'The model being returned right now will expect inputs \'\n                      \'to follow the ""channels_last"" data format.\')\n        K.set_image_data_format(\'channels_last\')\n        old_data_format = \'channels_first\'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    assert penultimate_filters % 24 == 0, ""`penultimate_filters` needs to be divisible "" \\\n                                          ""by 6 * (2^N).""\n\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    filters = penultimate_filters // 24\n\n    # load weights and set them during network creation itself\n    conv_0_weights = load_conv0()\n\n    if initial_reduction:\n        x = Conv2D(stem_filters, (3, 3), strides=(2, 2), padding=\'valid\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay),\n                   weights=[conv_0_weights[\'w\']])(img_input)\n    else:\n        x = Conv2D(stem_filters, (3, 3), strides=(1, 1), padding=\'same\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay),\n                   weights=[conv_0_weights[\'w\']])(img_input)\n\n    x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                           name=\'stem_bn1\', weights=conv_0_weights[\'bn\'])(x)\n\n    p = None\n    if initial_reduction:  # imagenet / mobile mode\n        x, p = _reduction_A(x, p, filters // (filters_multiplier ** 2), weight_decay, id=\'stem_1\')\n        x, p = _reduction_A(x, p, filters // filters_multiplier, weight_decay, id=\'stem_2\')\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters, weight_decay, id=\'%d\' % (i))\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier, weight_decay, id=\'reduce_%d\' % (nb_blocks))\n\n    p = p0 if not skip_reduction_layer_input else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier, weight_decay, id=\'%d\' % (nb_blocks + i + 1))\n\n    auxilary_x = None\n    if not skip_reduction_layer_input:  # imagenet / mobile mode\n        if use_auxilary_branch:\n            auxilary_x = _add_auxilary_head(x, classes, weight_decay, pooling, include_top)\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'reduce_%d\' % (2 * nb_blocks))\n\n    if skip_reduction_layer_input:  # CIFAR mode\n        if use_auxilary_branch:\n            auxilary_x = _add_auxilary_head(x, classes, weight_decay, pooling, include_top)\n\n    p = p0 if not skip_reduction_layer_input else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'%d\' % (2 * nb_blocks + i + 1))\n\n    x = Activation(\'relu\')(x)\n\n    head_weights = load_head()\n\n    if include_top:\n        x = GlobalAveragePooling2D()(x)\n        x = Dropout(dropout)(x)\n        x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay), name=\'predictions\',\n                  weights=head_weights)(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    if use_auxilary_branch:\n        model = Model(inputs, [x, auxilary_x], name=\'NASNet_with_auxilary\')\n    else:\n        model = Model(inputs, x, name=\'NASNet\')\n\n    # load weights (when available)\n    if weights is not None:\n        warnings.warn(\'Weights of NASNet models have not yet been ported to Keras\')\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n\n    return model\n\n\ndef NASNetLarge(input_shape=(331, 331, 3),\n                dropout=0.5,\n                weight_decay=5e-5,\n                use_auxilary_branch=False,\n                include_top=True,\n                weights=None,\n                input_tensor=None,\n                pooling=None,\n                classes=1000):\n    """"""Instantiates a NASNet architecture in ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxilary_branch: Whether to use the auxilary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON, STEM_IDX, REDUCTION_IDX, NORMAL_IDX\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    STEM_IDX = 0\n    REDUCTION_IDX = 0\n    NORMAL_IDX = 0\n\n    return NASNet(input_shape,\n                  penultimate_filters=4032,\n                  nb_blocks=6,\n                  stem_filters=96,\n                  initial_reduction=True,\n                  skip_reduction_layer_input=True,\n                  use_auxilary_branch=use_auxilary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=331)\n\n\ndef NASNetMobile(input_shape=(224, 224, 3),\n                 dropout=0.5,\n                 weight_decay=4e-5,\n                 use_auxilary_branch=False,\n                 include_top=True,\n                 weights=None,\n                 input_tensor=None,\n                 pooling=None,\n                 classes=1000):\n    """"""Instantiates a NASNet architecture in Mobile ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxilary_branch: Whether to use the auxilary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON, STEM_IDX, REDUCTION_IDX, NORMAL_IDX\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    STEM_IDX = 0\n    REDUCTION_IDX = 0\n    NORMAL_IDX = 0\n\n    return NASNet(input_shape,\n                  penultimate_filters=1056,\n                  nb_blocks=4,\n                  stem_filters=32,\n                  initial_reduction=True,\n                  skip_reduction_layer_input=False,\n                  use_auxilary_branch=use_auxilary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef NASNetCIFAR(input_shape=(32, 32, 3),\n                dropout=0.0,\n                weight_decay=5e-4,\n                use_auxilary_branch=False,\n                include_top=True,\n                weights=None,\n                input_tensor=None,\n                pooling=None,\n                classes=10):\n    """"""Instantiates a NASNet architecture in CIFAR mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(32, 32, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(32, 32, 3)` would be one valid value.\n        use_auxilary_branch: Whether to use the auxilary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON, STEM_IDX, REDUCTION_IDX, NORMAL_IDX\n    _BN_DECAY = 0.9\n    _BN_EPSILON = 1e-5\n\n    STEM_IDX = 0\n    REDUCTION_IDX = 0\n    NORMAL_IDX = 0\n\n    return NASNet(input_shape,\n                  penultimate_filters=768,\n                  nb_blocks=6,\n                  stem_filters=32,\n                  initial_reduction=False,\n                  skip_reduction_layer_input=False,\n                  use_auxilary_branch=use_auxilary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1), weight_decay=5e-5, id=None, weights=None):\n    \'\'\'Adds 2 blocks of [relu-separable conv-batchnorm]\n\n    # Arguments:\n        ip: input tensor\n        filters: number of output filters per layer\n        kernel_size: kernel size of separable convolutions\n        strides: strided convolution for downsampling\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'separable_conv_block_%s\' % id):\n        x = Activation(\'relu\')(ip)\n        x = SeparableConv2D(filters, kernel_size, strides=strides, name=\'separable_conv_1_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay),\n                            weights=[weights[\'d1\'], weights[\'p1\']])(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_1_bn_%s"" % (id),\n                               weights=weights[\'bn1\'])(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(filters, kernel_size, name=\'separable_conv_2_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay),\n                            weights=[weights[\'d2\'], weights[\'p2\']])(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_2_bn_%s"" % (id),\n                               weights=weights[\'bn2\'])(x)\n    return x\n\n\ndef _adjust_block(p, ip, filters, weight_decay=5e-5, id=None, weights=None):\n    \'\'\'\n    Adjusts the input `p` to match the shape of the `input`\n    or situations where the output number of filters needs to\n    be changed\n\n    # Arguments:\n        p: input tensor which needs to be modified\n        ip: input tensor whose shape needs to be matched\n        filters: number of output filters to be matched\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        an adjusted Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    img_dim = 2 if K.image_data_format() == \'channels_first\' else -2\n\n    with K.name_scope(\'adjust_block\'):\n        if p is None:\n            p = ip\n\n        elif p._keras_shape[img_dim] != ip._keras_shape[img_dim]:\n            with K.name_scope(\'adjust_reduction_block_%s\' % id):\n                p = Activation(\'relu\', name=\'adjust_relu_1_%s\' % id)(p)\n\n                p1 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_1_%s\' % id)(p)\n                p1 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_1_%s\' % id, kernel_initializer=\'he_normal\',\n                            weights=[weights[\'path1_conv\']])(p1)\n\n                p2 = ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n                p2 = Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n                p2 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_2_%s\' % id)(p2)\n                p2 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_2_%s\' % id, kernel_initializer=\'he_normal\',\n                            weights=[weights[\'path2_conv\']])(p2)\n\n                p = concatenate([p1, p2], axis=channel_dim)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id,\n                                       weights=weights[\'final_bn\'])(p)\n\n        elif p._keras_shape[channel_dim] != filters:\n            with K.name_scope(\'adjust_projection_block_%s\' % id):\n                p = Activation(\'relu\')(p)\n                p = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'adjust_conv_projection_%s\' % id,\n                           use_bias=False, kernel_regularizer=l2(weight_decay), kernel_initializer=\'he_normal\',\n                           weights=[weights[\'prev_conv\']])(p)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id,\n                                       weights=weights[\'prev_bn\'])(p)\n    return p\n\n\ndef _normal_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    global NORMAL_IDX\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    weights = load_normal_call(NORMAL_IDX)\n    NORMAL_IDX += 1\n\n    with K.name_scope(\'normal_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id, weights)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'normal_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay),\n                   weights=[weights[\'begin_W\']])(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'normal_bn_1_%s\' % id,\n                               weights=weights[\'begin_bn\'])(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, kernel_size=(5, 5), weight_decay=weight_decay,\n                                         id=\'normal_left1_%s\' % id,\n                                         weights=weights[\'left_0\'])\n            x1_2 = _separable_conv_block(p, filters, weight_decay=weight_decay, id=\'normal_right1_%s\' % id,\n                                         weights=weights[\'right_0\'])\n            x1 = add([x1_1, x1_2], name=\'normal_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = _separable_conv_block(p, filters, (5, 5), weight_decay=weight_decay, id=\'normal_left2_%s\' % id,\n                                         weights=weights[\'left_1\'])\n            x2_2 = _separable_conv_block(p, filters, (3, 3), weight_decay=weight_decay, id=\'normal_right2_%s\' % id,\n                                         weights=weights[\'right_1\'])\n            x2 = add([x2_1, x2_2], name=\'normal_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left3_%s\' % (id))(h)\n            x3 = add([x3, p], name=\'normal_add_3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4_1 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left4_%s\' % (id))(p)\n            x4_2 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_right4_%s\' % (id))(p)\n            x4 = add([x4_1, x4_2], name=\'normal_add_4_%s\' % id)\n\n        with K.name_scope(\'block_5\'):\n            x5 = _separable_conv_block(h, filters, weight_decay=weight_decay, id=\'normal_left5_%s\' % id,\n                                       weights=weights[\'left_4\'])\n            x5 = add([x5, h], name=\'normal_add_5_%s\' % id)\n\n        x = concatenate([p, x1, x2, x3, x4, x5], axis=channel_dim, name=\'normal_concat_%s\' % id)\n    return x, ip\n\n\ndef _reduction_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    """"""""""""\n    global STEM_IDX, REDUCTION_IDX\n\n    if \'stem\' in id:\n        if STEM_IDX == 0:\n            weights = load_stem_0()\n        else:\n            weights = load_stem_1()\n        STEM_IDX = 1\n\n    else:\n        weights = load_reduction_call(REDUCTION_IDX)\n        REDUCTION_IDX += 1\n\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'reduction_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id, weights)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'reduction_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay),\n                   weights=[weights[\'begin_W\']])(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'reduction_bn_1_%s\' % id,\n                               weights=weights[\'begin_bn\'])(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_left1_%s\' % id, weights=weights[\'left_0\'])\n            x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right1_%s\' % id, weights=weights[\'right_0\'])\n            x1 = add([x1_1, x1_2], name=\'reduction_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left2_%s\' % id)(h)\n            x2_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right2_%s\' % id, weights=weights[\'right_1\'])\n            x2 = add([x2_1, x2_2], name=\'reduction_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3_1 = AveragePooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left3_%s\' % id)(h)\n            x3_2 = _separable_conv_block(p, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right3_%s\' % id, weights=weights[\'right_2\'])\n            x3 = add([x3_1, x3_2], name=\'reduction_add3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'reduction_left4_%s\' % id)(x1)\n            x4 = add([x2, x4])\n\n        with K.name_scope(\'block_5\'):\n            x5_1 = _separable_conv_block(x1, filters, (3, 3), weight_decay=weight_decay, id=\'reduction_left4_%s\' % id,\n                                         weights=weights[\'left_4\'])\n            x5_2 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_right5_%s\' % id)(h)\n            x5 = add([x5_1, x5_2], name=\'reduction_add4_%s\' % id)\n\n        x = concatenate([x2, x3, x4, x5], axis=channel_dim, name=\'reduction_concat_%s\' % id)\n        return x, ip\n\n\ndef _add_auxilary_head(x, classes, weight_decay, pooling, include_top):\n    \'\'\'Adds an auxilary head for training the model\n\n    From section A.7 ""Training of ImageNet models"" of the paper, all NASNet models are\n    trained using an auxilary classifier around 2/3 of the depth of the network, with\n    a loss weight of 0.4\n\n    # Arguments\n        x: input tensor\n        classes: number of output classes\n        weight_decay: l2 regularization weight\n\n    # Returns\n        a keras Tensor\n    \'\'\'\n    weights = load_auxilary_branch()\n\n    img_height = 1 if K.image_data_format() == \'channels_last\' else 2\n    img_width = 2 if K.image_data_format() == \'channels_last\' else 3\n    channel_axis = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'auxilary_branch\'):\n        auxilary_x = Activation(\'relu\')(x)\n        auxilary_x = AveragePooling2D((5, 5), strides=(3, 3), padding=\'valid\', name=\'aux_pool\')(auxilary_x)\n        auxilary_x = Conv2D(128, (1, 1), padding=\'same\', use_bias=False, name=\'aux_conv_projection\',\n                            kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay),\n                            weights=[weights[\'conv1\']])(auxilary_x)\n        auxilary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_projection\',\n                                        weights=weights[\'bn1\'])(auxilary_x)\n        auxilary_x = Activation(\'relu\')(auxilary_x)\n\n        auxilary_x = Conv2D(768, (auxilary_x._keras_shape[img_height], auxilary_x._keras_shape[img_width]),\n                            padding=\'valid\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay), name=\'aux_conv_reduction\',\n                            weights=[weights[\'conv2\']])(auxilary_x)\n        auxilary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_reduction\',\n                                        weights=weights[\'bn2\'])(auxilary_x)\n        auxilary_x = Activation(\'relu\')(auxilary_x)\n\n        if include_top:\n            auxilary_x = GlobalAveragePooling2D()(auxilary_x)\n            auxilary_x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay),\n                                name=\'aux_predictions\', weights=weights[\'fc\'])(auxilary_x)\n        else:\n            if pooling == \'avg\':\n                auxilary_x = GlobalAveragePooling2D()(auxilary_x)\n            elif pooling == \'max\':\n                auxilary_x = GlobalMaxPooling2D()(auxilary_x)\n\n    return auxilary_x\n\n\nif __name__ == \'__main__\':\n    pass\n\n    import tensorflow as tf\n\n    \'\'\' NASNet Mobile models \'\'\'\n    # use weight_load_mobile for NASNetMobile\n    from weight_translation.weight_load_mobile import *\n\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetMobile(use_auxilary_branch=False, include_top=True)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-mobile.h5\')\n    #\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetMobile(use_auxilary_branch=False, include_top=False)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-mobile-no-top.h5\')\n\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetMobile(use_auxilary_branch=True, include_top=True)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-auxiliary-mobile.h5\')\n\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetMobile(use_auxilary_branch=True, include_top=False)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-auxiliary-mobile-no-top.h5\')\n\n    \'\'\' NASNet Large models \'\'\'\n\n    # use weight_load_large for NASNetLarge\n    # from weight_translation.weight_load_large import *\n    #\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetLarge(use_auxilary_branch=False, include_top=True)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-large.h5\')\n    #\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetLarge(use_auxilary_branch=False, include_top=False)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-large-no-top.h5\')\n    #\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetLarge(use_auxilary_branch=True, include_top=True)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-auxiliary-large.h5\')\n    #\n    # K.clear_session()\n    #\n    # sess = tf.Session()\n    # K.set_session(sess)\n    #\n    # with tf.device(\'/cpu:0\'):\n    #     model = NASNetLarge(use_auxilary_branch=True, include_top=False)\n    #     model.summary()\n    #     model.save_weights(\'NASNet-auxiliary-large-no-top.h5\')\n\n'"
weight_translation/weight_load_large.py,0,"b'import numpy as np\nimport glob\nimport os\n\nall_files = []\n\nconv0_path = \'weights/conv0_*.npy\'\nconv0_fns = (glob.glob(conv0_path))\nall_files.extend(conv0_fns)\n\nstem_0_path = \'weights/cell_stem_0_*.npy\'\nstem_0_fns = (glob.glob(stem_0_path))\nall_files.extend(stem_0_fns)\n\nstem_1_path = \'weights/cell_stem_1_*.npy\'\nstem_1_fns = (glob.glob(stem_1_path))\nall_files.extend(stem_1_fns)\n\n# alias for stems\nstems = [stem_0_fns, stem_1_fns]\n\nnormal_path_base = \'weights/cell_\'\nnormal_fns = {}\n\nNB_CELLS = 18\nfor i in range(NB_CELLS):\n    normal_path = normal_path_base + ""%d_*.npy"" % i\n    normal_fn = (glob.glob(normal_path))\n    normal_fns[i] = normal_fn\n\n    all_files.extend(normal_fn)\n\nreduction_0_path = \'weights/reduction_cell_0_*.npy\'\nreduction_0_fns = (glob.glob(reduction_0_path))\nall_files.extend(reduction_0_fns)\n\nreduction_1_path = \'weights/reduction_cell_1_*.npy\'\nreduction_1_fns = (glob.glob(reduction_1_path))\nall_files.extend(reduction_1_fns)\n\n# alias for reduction cells\nreduction_cells = [reduction_0_fns, reduction_1_fns]\n\naux_path = \'weights/aux_*.npy\'\naux_fns = glob.glob(aux_path)\nall_files.extend(aux_fns)\n\nfinal_dense_path = \'weights/final_layer_FC_*.npy\'\nfinal_dense_fns = (glob.glob(final_dense_path))\nall_files.extend(final_dense_fns)\n\nall_files_paths = (glob.glob(\'weights/*.npy\'))\ntotal_file_count = len(all_files_paths)\n\nprint(\'Total number of weight files : \', total_file_count)\nprint(\'Properly loaded weights count : \', len(all_files))\n\nif total_file_count != len(all_files):\n    print(""Printing files not loaded yet"")\n    print()\n\n    for fn in all_files_paths:\n        if fn not in all_files:\n            print(fn)\n\n    exit()\nelse:\n    print(""All files loaded up properly"")\n    print()\n\n\ndef correct_bn(bn_weights):\n    return [bn_weights[1], bn_weights[0], bn_weights[2], bn_weights[3]]\n\ndef load_conv0():\n    print(""Loading conv 0 weights"")\n    conv0_weights = np.load(conv0_fns[-1])\n    conv0_bn = [np.load(fn) for fn in conv0_fns[:4]]\n    return {\'w\': conv0_weights, \'bn\': correct_bn(conv0_bn)}\n\ndef load_stem_0():\n    print(""Loading stem 0 weights"")\n\n    stem_fn = stems[0]\n    stem_beginning_weights = np.load(stem_fn[0])\n    stem_beginning_bn = [np.load(fn) for fn in stem_fn[1:5]]\n\n    stem0 = {\'begin_W\': stem_beginning_weights,\n             \'begin_bn\': correct_bn(stem_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_stem_%d_comb_iter_%d_left_*.npy\' % (0, i)\n        right_path = \'weights/cell_stem_%d_comb_iter_%d_right_*.npy\' % (0, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            stem0[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            stem0[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    return stem0\n\ndef load_stem_1():\n    print(""Loading stem 1 weights"")\n\n    stem_fn = stems[1]\n    stem_beginning_weights = np.load(stem_fn[0])\n    stem_beginning_bn = [np.load(fn) for fn in stem_fn[1:5]]\n\n    stem1 = {\'begin_W\': stem_beginning_weights,\n             \'begin_bn\': correct_bn(stem_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_stem_%d_comb_iter_%d_left_*.npy\' % (1, i)\n        right_path = \'weights/cell_stem_%d_comb_iter_%d_right_*.npy\' % (1, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            stem1[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            stem1[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/cell_stem_1_final_path_bn_*.npy\'))\n    final_bn = [np.load(fn) for fn in final_bn]\n    path1_conv = np.load(stem_fn[-2])\n    path2_conv = np.load(stem_fn[-1])\n\n    stem1[\'final_bn\'] = correct_bn(final_bn)\n    stem1[\'path1_conv\'] = path1_conv\n    stem1[\'path2_conv\'] = path2_conv\n\n    return stem1\n\ndef load_normal_call(index):\n    print(""Loading Normal NASNet Cell #%d"" % (index))\n    cell_fn = normal_fns[index]\n    cell_beginning_weights = np.load(cell_fn[0])\n    cell_beginning_bn = [np.load(fn) for fn in cell_fn[1:5]]\n\n    cell = {\'begin_W\': cell_beginning_weights,\n             \'begin_bn\': correct_bn(cell_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_%d_comb_iter_%d_left_*.npy\' % (index, i)\n        right_path = \'weights/cell_%d_comb_iter_%d_right_*.npy\' % (index, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            cell[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            cell[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/cell_%d_final_path_bn_*.npy\' % (index)))\n    if len(final_bn) > 0:\n        print(""Loaded final path"")\n        final_bn = [np.load(fn) for fn in final_bn]\n        conv_paths = (glob.glob(\'weights/cell_%d_path*_conv_weights.npy\' % (index)))\n        path1_conv = np.load(conv_paths[0])\n        path2_conv = np.load(conv_paths[1])\n\n        cell[\'final_bn\'] = correct_bn(final_bn)\n        cell[\'path1_conv\'] = path1_conv\n        cell[\'path2_conv\'] = path2_conv\n\n    prev_bn = (glob.glob(\'weights/cell_%d_prev_bn_*.npy\' % (index)))\n    if len(prev_bn) > 0:\n        print(""Loaded previous path"")\n        prev_bn = [np.load(fn) for fn in prev_bn]\n        prev_conv = glob.glob(\'weights/cell_%d_prev_1x1_*.npy\' % (index))[0]\n\n        cell[\'prev_bn\'] = correct_bn(prev_bn)\n        cell[\'prev_conv\'] = np.load(prev_conv)\n\n    return cell\n\ndef load_reduction_call(index):\n    print(""Loading Reduction NASNet Cell #%d"" % (index))\n    cell_fn = reduction_cells[index]\n    cell_beginning_weights = np.load(cell_fn[0])\n    cell_beginning_bn = [np.load(fn) for fn in cell_fn[1:5]]\n\n    cell = {\'begin_W\': cell_beginning_weights,\n            \'begin_bn\': correct_bn(cell_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/reduction_cell_%d_comb_iter_%d_left_*.npy\' % (index, i)\n        right_path = \'weights/reduction_cell_%d_comb_iter_%d_right_*.npy\' % (index, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            cell[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            cell[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/reduction_cell_%d_final_path_bn_*.npy\' % (index)))\n    if len(final_bn) > 0:\n        print(""Loaded final"")\n        final_bn = [np.load(fn) for fn in final_bn]\n        conv_paths = glob.glob(\'weights/reduction_cell_%d_path*_conv_weights.npy\' % (index))\n        print(""Conv paths : "", conv_paths)\n        path1_conv = np.load(conv_paths[0])\n        path2_conv = np.load(conv_paths[1])\n\n        cell[\'final_bn\'] = correct_bn(final_bn)\n        cell[\'path1_conv\'] = path1_conv\n        cell[\'path2_conv\'] = path2_conv\n\n    prev_bn = (glob.glob(\'weights/reduction_cell_%d_prev_bn_*.npy\' % (index)))\n    if len(prev_bn) > 0:\n        print(""Loaded previous"")\n        prev_bn = [np.load(fn) for fn in prev_bn]\n        prev_conv = (glob.glob(\'weights/reduction_cell_%d_prev_1x1_*.npy\' % (index))[0])\n\n        cell[\'prev_bn\'] = correct_bn(prev_bn)\n        cell[\'prev_conv\'] = np.load(prev_conv)\n\n    return cell\n\ndef load_auxilary_branch():\n    print(""Loading auxilary branch"")\n    bn1 = [np.load(fn) for fn in aux_fns[:4]]\n    bn2 = [np.load(fn) for fn in aux_fns[4:8]]\n    conv_aux_2 = np.load(aux_fns[8])\n    fc_bias = np.load(aux_fns[9])\n    fc_weights = np.load(aux_fns[10])\n    conv_aux_1 = np.load(aux_fns[11])\n\n    fc_weights = fc_weights[:, 1:]\n    fc_bias = fc_bias[1:]\n\n    aux = {\'conv1\': conv_aux_1, \'conv2\': conv_aux_2, \'fc\': [fc_weights, fc_bias],\n           \'bn1\': correct_bn(bn1), \'bn2\': correct_bn(bn2)}\n    return aux\n\ndef load_head():\n    print(""Loading Head"")\n    weights = np.load(final_dense_fns[1])\n    bias = np.load(final_dense_fns[0])\n\n    weights = weights[:, 1:]\n    bias = bias[1:]\n\n    return [weights, bias]\n\nif __name__ == \'__main__\':\n    pass'"
weight_translation/weight_load_mobile.py,0,"b'import numpy as np\nimport glob\nimport os\n\nall_files = []\n\nconv0_path = \'weights/conv0_*.npy\'\nconv0_fns = (glob.glob(conv0_path))\nall_files.extend(conv0_fns)\n\nstem_0_path = \'weights/cell_stem_0_*.npy\'\nstem_0_fns = (glob.glob(stem_0_path))\nall_files.extend(stem_0_fns)\n\nstem_1_path = \'weights/cell_stem_1_*.npy\'\nstem_1_fns = (glob.glob(stem_1_path))\nall_files.extend(stem_1_fns)\n\n# alias for stems\nstems = [stem_0_fns, stem_1_fns]\n\nnormal_path_base = \'weights/cell_\'\nnormal_fns = {}\n\nNB_CELLS = 12\nfor i in range(NB_CELLS):\n    normal_path = normal_path_base + ""%d_*.npy"" % i\n    normal_fn = (glob.glob(normal_path))\n    normal_fns[i] = normal_fn\n\n    all_files.extend(normal_fn)\n\nreduction_0_path = \'weights/reduction_cell_0_*.npy\'\nreduction_0_fns = (glob.glob(reduction_0_path))\nall_files.extend(reduction_0_fns)\n\nreduction_1_path = \'weights/reduction_cell_1_*.npy\'\nreduction_1_fns = (glob.glob(reduction_1_path))\nall_files.extend(reduction_1_fns)\n\n# alias for reduction cells\nreduction_cells = [reduction_0_fns, reduction_1_fns]\n\naux_path = \'weights/aux_*.npy\'\naux_fns = (glob.glob(aux_path))\nall_files.extend(aux_fns)\n\nfinal_dense_path = \'weights/final_layer_FC_*.npy\'\nfinal_dense_fns = (glob.glob(final_dense_path))\nall_files.extend(final_dense_fns)\n\nall_files_paths = (glob.glob(\'weights/*.npy\'))\ntotal_file_count = len(all_files_paths)\n\nprint(\'Total number of weight files : \', total_file_count)\nprint(\'Properly loaded weights count : \', len(all_files))\n\nif total_file_count != len(all_files):\n    print(""Printing files not loaded yet"")\n    print()\n\n    for fn in all_files_paths:\n        if fn not in all_files:\n            print(fn)\n\n    exit()\nelse:\n    print(""All files loaded up properly"")\n    print()\n\n\ndef correct_bn(bn_weights):\n    return [bn_weights[1], bn_weights[0], bn_weights[2], bn_weights[3]]\n\ndef load_conv0():\n    print(""Loading conv 0 weights"")\n    conv0_weights = np.load(conv0_fns[-1])\n    conv0_bn = [np.load(fn) for fn in conv0_fns[:4]]\n    return {\'w\': conv0_weights, \'bn\': correct_bn(conv0_bn)}\n\ndef load_stem_0():\n    print(""Loading stem 0 weights"")\n\n    stem_fn = stems[0]\n    stem_beginning_weights = np.load(stem_fn[0])\n    stem_beginning_bn = [np.load(fn) for fn in stem_fn[1:5]]\n\n    stem0 = {\'begin_W\': stem_beginning_weights,\n             \'begin_bn\': correct_bn(stem_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_stem_%d_comb_iter_%d_left_*.npy\' % (0, i)\n        right_path = \'weights/cell_stem_%d_comb_iter_%d_right_*.npy\' % (0, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            stem0[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            stem0[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    return stem0\n\ndef load_stem_1():\n    print(""Loading stem 1 weights"")\n\n    stem_fn = stems[1]\n    stem_beginning_weights = np.load(stem_fn[0])\n    stem_beginning_bn = [np.load(fn) for fn in stem_fn[1:5]]\n\n    stem1 = {\'begin_W\': stem_beginning_weights,\n             \'begin_bn\': correct_bn(stem_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_stem_%d_comb_iter_%d_left_*.npy\' % (1, i)\n        right_path = \'weights/cell_stem_%d_comb_iter_%d_right_*.npy\' % (1, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            stem1[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            stem1[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/cell_stem_1_final_path_bn_*.npy\'))\n    final_bn = [np.load(fn) for fn in final_bn]\n    path1_conv = np.load(stem_fn[-2])\n    path2_conv = np.load(stem_fn[-1])\n\n    stem1[\'final_bn\'] = correct_bn(final_bn)\n    stem1[\'path1_conv\'] = path1_conv\n    stem1[\'path2_conv\'] = path2_conv\n\n    return stem1\n\ndef load_normal_call(index):\n    print(""Loading Normal NASNet Cell #%d"" % (index))\n    cell_fn = normal_fns[index]\n    cell_beginning_weights = np.load(cell_fn[0])\n    cell_beginning_bn = [np.load(fn) for fn in cell_fn[1:5]]\n\n    cell = {\'begin_W\': cell_beginning_weights,\n             \'begin_bn\': correct_bn(cell_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/cell_%d_comb_iter_%d_left_*.npy\' % (index, i)\n        right_path = \'weights/cell_%d_comb_iter_%d_right_*.npy\' % (index, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            cell[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            cell[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/cell_%d_final_path_bn_*.npy\' % (index)))\n    if len(final_bn) > 0:\n        print(""Loaded final path"")\n        final_bn = [np.load(fn) for fn in final_bn]\n        path1_conv = np.load(cell_fn[-2])\n        path2_conv = np.load(cell_fn[-1])\n\n        cell[\'final_bn\'] = correct_bn(final_bn)\n        cell[\'path1_conv\'] = path1_conv\n        cell[\'path2_conv\'] = path2_conv\n\n    prev_bn = (glob.glob(\'weights/cell_%d_prev_bn_*.npy\' % (index)))\n    if len(prev_bn) > 0:\n        print(""Loaded previous path"")\n        prev_bn = [np.load(fn) for fn in prev_bn]\n        prev_conv = glob.glob(\'weights/cell_%d_prev_1x1_*.npy\' % (index))[0]\n\n        cell[\'prev_bn\'] = correct_bn(prev_bn)\n        cell[\'prev_conv\'] = np.load(prev_conv)\n\n    return cell\n\ndef load_reduction_call(index):\n    print(""Loading Reduction NASNet Cell #%d"" % (index))\n    cell_fn = reduction_cells[index]\n    cell_beginning_weights = np.load(cell_fn[0])\n    cell_beginning_bn = [np.load(fn) for fn in cell_fn[1:5]]\n\n    cell = {\'begin_W\': cell_beginning_weights,\n            \'begin_bn\': correct_bn(cell_beginning_bn)}\n\n    for i in range(5):\n        left_path = \'weights/reduction_cell_%d_comb_iter_%d_left_*.npy\' % (index, i)\n        right_path = \'weights/reduction_cell_%d_comb_iter_%d_right_*.npy\' % (index, i)\n        left_fns = (glob.glob(left_path))\n        right_fns = (glob.glob(right_path))\n\n        if len(left_fns) > 0:\n            print(""Loaded left at %d"" % i)\n            left_bn_1 = [np.load(fn) for fn in left_fns[:4]]\n            left_bn_2 = [np.load(fn) for fn in left_fns[4:8]]\n            left_d1 = np.load(left_fns[8])\n            left_p1 = np.load(left_fns[9])\n            left_d2 = np.load(left_fns[10])\n            left_p2 = np.load(left_fns[11])\n\n        if len(right_fns) > 0:\n            print(""Loaded right at %d"" % i)\n            right_bn_1 = [np.load(fn) for fn in right_fns[:4]]\n            right_bn_2 = [np.load(fn) for fn in right_fns[4:8]]\n            right_d1 = np.load(right_fns[8])\n            right_p1 = np.load(right_fns[9])\n            right_d2 = np.load(right_fns[10])\n            right_p2 = np.load(right_fns[11])\n\n        if len(left_fns) > 0:\n            cell[\'left_%d\' % i] = {\'d1\': left_d1, \'d2\': left_d2, \'p1\': left_p1, \'p2\': left_p2,\n                                    \'bn1\': correct_bn(left_bn_1), \'bn2\': correct_bn(left_bn_2)}\n\n        if len(right_fns) > 0:\n            cell[\'right_%d\' % i] = {\'d1\': right_d1, \'d2\': right_d2, \'p1\': right_p1, \'p2\': right_p2,\n                                     \'bn1\': correct_bn(right_bn_1), \'bn2\': correct_bn(right_bn_2)}\n\n    final_bn = (glob.glob(\'weights/reduction_cell_%d_final_path_bn_*.npy\' % (index)))\n    if len(final_bn) > 0:\n        print(""Loaded final"")\n        final_bn = [np.load(fn) for fn in final_bn]\n        path1_conv = np.load(cell_fn[-2])\n        path2_conv = np.load(cell_fn[-1])\n\n        cell[\'final_bn\'] = correct_bn(final_bn)\n        cell[\'path1_conv\'] = path1_conv\n        cell[\'path2_conv\'] = path2_conv\n\n    prev_bn = (glob.glob(\'weights/reduction_cell_%d_prev_bn_*.npy\' % (index)))\n    if len(prev_bn) > 0:\n        print(""Loaded previous"")\n        prev_bn = [np.load(fn) for fn in prev_bn]\n        prev_conv = glob.glob(\'weights/reduction_cell_%d_prev_1x1_*.npy\' % (index))[0]\n\n        cell[\'prev_bn\'] = correct_bn(prev_bn)\n        cell[\'prev_conv\'] = np.load(prev_conv)\n\n    return cell\n\ndef load_auxilary_branch():\n    print(""Loading auxilary branch"")\n    bn1 = [np.load(fn) for fn in aux_fns[:4]]\n    bn2 = [np.load(fn) for fn in aux_fns[4:8]]\n    conv_aux_2 = np.load(aux_fns[8])\n    fc_bias = np.load(aux_fns[9])\n    fc_weights = np.load(aux_fns[10])\n    conv_aux_1 = np.load(aux_fns[11])\n\n    fc_weights = fc_weights[:, 1:]\n    fc_bias = fc_bias[1:]\n\n    aux = {\'conv1\': conv_aux_1, \'conv2\': conv_aux_2, \'fc\': [fc_weights, fc_bias],\n           \'bn1\': correct_bn(bn1), \'bn2\': correct_bn(bn2)}\n    return aux\n\ndef load_head():\n    print(""Loading Head"")\n    weights = np.load(final_dense_fns[1])\n    bias = np.load(final_dense_fns[0])\n\n    weights = weights[:, 1:]\n    bias = bias[1:]\n\n    return [weights, bias]\n\nif __name__ == \'__main__\':\n    for i, fn in enumerate(aux_fns):\n        print(i, fn)\n    pass'"
