file_path,api_count,code
evaluate_inception_resnet.py,1,"b'import numpy as np\nimport argparse\nfrom path import Path\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.inception_resnet_v2 import preprocess_input\nfrom keras.preprocessing.image import load_img, img_to_array\nimport tensorflow as tf\n\nfrom utils.score_utils import mean_score, std_score\n\nparser = argparse.ArgumentParser(description=\'Evaluate NIMA(Inception ResNet v2)\')\nparser.add_argument(\'-dir\', type=str, default=None,\n                    help=\'Pass a directory to evaluate the images in it\')\n\nparser.add_argument(\'-img\', type=str, default=[None], nargs=\'+\',\n                    help=\'Pass one or more image paths to evaluate them\')\n\nparser.add_argument(\'-resize\', type=str, default=\'false\',\n                    help=\'Resize images to 224x224 before scoring\')\n\nparser.add_argument(\'-rank\', type=str, default=\'true\',\n                    help=\'Whether to tank the images after they have been scored\')\n\nargs = parser.parse_args()\nresize_image = args.resize.lower() in (""true"", ""yes"", ""t"", ""1"")\ntarget_size = (224, 224) if resize_image else None\nrank_images = args.rank.lower() in (""true"", ""yes"", ""t"", ""1"")\n\n# give priority to directory\nif args.dir is not None:\n    print(""Loading images from directory : "", args.dir)\n    imgs = Path(args.dir).files(\'*.png\')\n    imgs += Path(args.dir).files(\'*.jpg\')\n    imgs += Path(args.dir).files(\'*.jpeg\')\n\nelif args.img[0] is not None:\n    print(""Loading images from path(s) : "", args.img)\n    imgs = args.img\n\nelse:\n    raise RuntimeError(\'Either -dir or -img arguments must be passed as argument\')\n\nwith tf.device(\'/CPU:0\'):\n    base_model = InceptionResNetV2(input_shape=(None, None, 3), include_top=False, pooling=\'avg\', weights=None)\n    x = Dropout(0.75)(base_model.output)\n    x = Dense(10, activation=\'softmax\')(x)\n\n    model = Model(base_model.input, x)\n    model.load_weights(\'weights/inception_resnet_weights.h5\')\n\n    score_list = []\n\n    for img_path in imgs:\n        img = load_img(img_path, target_size=target_size)\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n\n        x = preprocess_input(x)\n\n        scores = model.predict(x, batch_size=1, verbose=0)[0]\n\n        mean = mean_score(scores)\n        std = std_score(scores)\n\n        file_name = Path(img_path).name.lower()\n        score_list.append((file_name, mean))\n\n        print(""Evaluating : "", img_path)\n        print(""NIMA Score : %0.3f +- (%0.3f)"" % (mean, std))\n        print()\n\n    if rank_images:\n        print(""*"" * 40, ""Ranking Images"", ""*"" * 40)\n        score_list = sorted(score_list, key=lambda x: x[1], reverse=True)\n\n        for i, (name, score) in enumerate(score_list):\n            print(""%d)"" % (i + 1), ""%s : Score = %0.5f"" % (name, score))\n\n\n'"
evaluate_mobilenet.py,1,"b'import numpy as np\nimport argparse\nfrom path import Path\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import load_img, img_to_array\nimport tensorflow as tf\n\nfrom utils.score_utils import mean_score, std_score\n\nparser = argparse.ArgumentParser(description=\'Evaluate NIMA(Inception ResNet v2)\')\nparser.add_argument(\'-dir\', type=str, default=None,\n                    help=\'Pass a directory to evaluate the images in it\')\n\nparser.add_argument(\'-img\', type=str, default=[None], nargs=\'+\',\n                    help=\'Pass one or more image paths to evaluate them\')\n\nparser.add_argument(\'-resize\', type=str, default=\'false\',\n                    help=\'Resize images to 224x224 before scoring\')\n\nparser.add_argument(\'-rank\', type=str, default=\'true\',\n                    help=\'Whether to tank the images after they have been scored\')\n\nargs = parser.parse_args()\nresize_image = args.resize.lower() in (""true"", ""yes"", ""t"", ""1"")\ntarget_size = (224, 224) if resize_image else None\nrank_images = args.rank.lower() in (""true"", ""yes"", ""t"", ""1"")\n\n# give priority to directory\nif args.dir is not None:\n    print(""Loading images from directory : "", args.dir)\n    imgs = Path(args.dir).files(\'*.png\')\n    imgs += Path(args.dir).files(\'*.jpg\')\n    imgs += Path(args.dir).files(\'*.jpeg\')\n\nelif args.img[0] is not None:\n    print(""Loading images from path(s) : "", args.img)\n    imgs = args.img\n\nelse:\n    raise RuntimeError(\'Either -dir or -img arguments must be passed as argument\')\n\nwith tf.device(\'/CPU:0\'):\n    base_model = MobileNet((None, None, 3), alpha=1, include_top=False, pooling=\'avg\', weights=None)\n    x = Dropout(0.75)(base_model.output)\n    x = Dense(10, activation=\'softmax\')(x)\n\n    model = Model(base_model.input, x)\n    model.load_weights(\'weights/mobilenet_weights.h5\')\n\n    score_list = []\n\n    for img_path in imgs:\n        img = load_img(img_path, target_size=target_size)\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n\n        x = preprocess_input(x)\n\n        scores = model.predict(x, batch_size=1, verbose=0)[0]\n\n        mean = mean_score(scores)\n        std = std_score(scores)\n\n        file_name = Path(img_path).name.lower()\n        score_list.append((file_name, mean))\n\n        print(""Evaluating : "", img_path)\n        print(""NIMA Score : %0.3f +- (%0.3f)"" % (mean, std))\n        print()\n\n    if rank_images:\n        print(""*"" * 40, ""Ranking Images"", ""*"" * 40)\n        score_list = sorted(score_list, key=lambda x: x[1], reverse=True)\n\n        for i, (name, score) in enumerate(score_list):\n            print(""%d)"" % (i + 1), ""%s : Score = %0.5f"" % (name, score))\n\n\n'"
evaluate_nasnet.py,1,"b'import numpy as np\nimport argparse\nfrom path import Path\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.preprocessing.image import load_img, img_to_array\nimport tensorflow as tf\n\nfrom utils.nasnet import NASNetMobile, preprocess_input\nfrom utils.score_utils import mean_score, std_score\n\nparser = argparse.ArgumentParser(description=\'Evaluate NIMA(Inception ResNet v2)\')\nparser.add_argument(\'-dir\', type=str, default=None,\n                    help=\'Pass a directory to evaluate the images in it\')\n\nparser.add_argument(\'-img\', type=str, default=[None], nargs=\'+\',\n                    help=\'Pass one or more image paths to evaluate them\')\n\nparser.add_argument(\'-rank\', type=str, default=\'true\',\n                    help=\'Whether to tank the images after they have been scored\')\n\nargs = parser.parse_args()\ntarget_size = (224, 224)  # NASNet requires strict size set to 224x224\nrank_images = args.rank.lower() in (""true"", ""yes"", ""t"", ""1"")\n\n# give priority to directory\nif args.dir is not None:\n    print(""Loading images from directory : "", args.dir)\n    imgs = Path(args.dir).files(\'*.png\')\n    imgs += Path(args.dir).files(\'*.jpg\')\n    imgs += Path(args.dir).files(\'*.jpeg\')\n\nelif args.img[0] is not None:\n    print(""Loading images from path(s) : "", args.img)\n    imgs = args.img\n\nelse:\n    raise RuntimeError(\'Either -dir or -img arguments must be passed as argument\')\n\nwith tf.device(\'/CPU:0\'):\n    base_model = NASNetMobile((224, 224, 3), include_top=False, pooling=\'avg\', weights=None)\n    x = Dropout(0.75)(base_model.output)\n    x = Dense(10, activation=\'softmax\')(x)\n\n    model = Model(base_model.input, x)\n    model.load_weights(\'weights/nasnet_weights.h5\')\n\n    score_list = []\n\n    for img_path in imgs:\n        img = load_img(img_path, target_size=target_size)\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n\n        x = preprocess_input(x)\n\n        scores = model.predict(x, batch_size=1, verbose=0)[0]\n\n        mean = mean_score(scores)\n        std = std_score(scores)\n\n        file_name = Path(img_path).name.lower()\n        score_list.append((file_name, mean))\n\n        print(""Evaluating : "", img_path)\n        print(""NIMA Score : %0.3f +- (%0.3f)"" % (mean, std))\n        print()\n\n    if rank_images:\n        print(""*"" * 40, ""Ranking Images"", ""*"" * 40)\n        score_list = sorted(score_list, key=lambda x: x[1], reverse=True)\n\n        for i, (name, score) in enumerate(score_list):\n            print(""%d)"" % (i + 1), ""%s : Score = %0.5f"" % (name, score))\n\n\n'"
extract_inception_resnet_features.py,8,"b'import tensorflow as tf\nfrom keras import backend as K\n\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom utils.data_loader import train_generator, val_generator\n\nsess = tf.Session()\nK.set_session(sess)\n\nimage_size = 224\n\ndef _float32_feature_list(floats):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=floats))\n\nmodel = InceptionResNetV2(input_shape=(image_size, image_size, 3), include_top=False, pooling=\'avg\')\nmodel.summary()\n\n# \'\'\' TRAIN SET \'\'\'\nnb_samples = 250000 * 2\nbatchsize = 200\n\nwith sess.as_default():\n    generator = train_generator(batchsize, shuffle=False)\n    writer = tf.python_io.TFRecordWriter(\'weights/inception_resnet_train.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()\n\n\'\'\' TRAIN SET \'\'\'\nnb_samples = 5000\nbatchsize = 200\n\nwith sess.as_default():\n    generator = val_generator(batchsize)\n    writer = tf.python_io.TFRecordWriter(\'weights/inception_resnet_val.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()'"
extract_nasnet_features.py,8,"b'import tensorflow as tf\nfrom keras import backend as K\n\nfrom utils.nasnet import NASNetMobile\nfrom utils.data_loader import train_generator, val_generator\n\nsess = tf.Session()\nK.set_session(sess)\n\nimage_size = 224\n\ndef _float32_feature_list(floats):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=floats))\n\nmodel = NASNetMobile((image_size, image_size, 3), include_top=False, pooling=\'avg\')\nmodel.summary()\n\n# \'\'\' TRAIN SET \'\'\'\nnb_samples = 250000 * 2\nbatchsize = 200\n\nwith sess.as_default():\n    generator = train_generator(batchsize, shuffle=False)\n    writer = tf.python_io.TFRecordWriter(\'weights/nasnet_train.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()\n\n\'\'\' TRAIN SET \'\'\'\nnb_samples = 5000\nbatchsize = 200\n\nwith sess.as_default():\n    generator = val_generator(batchsize)\n    writer = tf.python_io.TFRecordWriter(\'weights/nasnet_val.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()'"
extract_nasnet_large_features.py,8,"b'import tensorflow as tf\nfrom keras import backend as K\n\nfrom utils.nasnet import NASNetLarge\nfrom utils.data_loader import train_generator, val_generator\n\nsess = tf.Session()\nK.set_session(sess)\n\nimage_size = 224\n\ndef _float32_feature_list(floats):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=floats))\n\nmodel = NASNetLarge((image_size, image_size, 3), include_top=False, pooling=\'avg\')\nmodel.summary()\n\n# \'\'\' TRAIN SET \'\'\'\nnb_samples = 250000 * 2\nbatchsize = 200\n\nwith sess.as_default():\n    generator = train_generator(batchsize, shuffle=False)\n    writer = tf.python_io.TFRecordWriter(\'weights/nasnet_large_train.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()\n\n\'\'\' TRAIN SET \'\'\'\nnb_samples = 5000\nbatchsize = 200\n\nwith sess.as_default():\n    generator = val_generator(batchsize)\n    writer = tf.python_io.TFRecordWriter(\'weights/nasnet_large_val.tfrecord\')\n\ncount = 0\nfor _ in range(nb_samples // batchsize):\n    x_batch, y_batch = next(generator)\n\n    with sess.as_default():\n        x_batch = model.predict(x_batch, batchsize, verbose=1)\n\n    for i, (x, y) in enumerate(zip(x_batch, y_batch)):\n        examples = {\n            \'features\': _float32_feature_list(x.flatten()),\n            \'scores\': _float32_feature_list(y.flatten()),\n        }\n        features = tf.train.Features(feature=examples)\n        example = tf.train.Example(features=features)\n        writer.write(example.SerializeToString())\n\n    count += batchsize\n\n    print(""Finished %0.2f percentage storing dataset"" % (count  * 100 / float(nb_samples)))\n\nwriter.close()'"
pretrain_inception_resnet.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.data_loader import features_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nNUM_FEATURES = 1536\n\nimage_size = 224\nip = Input(shape=(NUM_FEATURES,))\nx = Dropout(0.75)(ip)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(ip, x)\nmodel.summary()\noptimizer = Adam(lr=1e-4)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/inception_resnet_pretrained_weights.h5'):\n    model.load_weights('weights/inception_resnet_pretrained_weights.h5')\n\ncheckpoint = ModelCheckpoint('weights/inception_resnet_pretrained_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch(log_dir='./nasnet_logs/')\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nTRAIN_RECORD_PATH = 'weights/inception_resnet_train.tfrecord'\nVAL_RECORD_PATH = 'weights/inception_resnet_val.tfrecord'\n\nmodel.fit_generator(features_generator(TRAIN_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=True),\n                    steps_per_epoch=(500000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=features_generator(VAL_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=False),\n                    validation_steps=(5000. // batchsize))\n"""
pretrain_nasnet_large.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.data_loader import features_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nNUM_FEATURES = 1056\n\nimage_size = 224\nip = Input(shape=(1056,))\nx = Dropout(0.75)(ip)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(ip, x)\nmodel.summary()\noptimizer = Adam(lr=1e-4)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/nasnet_large_pretrained_weights.h5'):\n    model.load_weights('weights/nasnet_large_pretrained_weights.h5')\n\ncheckpoint = ModelCheckpoint('weights/nasnet_large_pretrained_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch(log_dir='./nasnet_logs/')\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nTRAIN_RECORD_PATH = 'weights/nasnet_large_train.tfrecord'\nVAL_RECORD_PATH = 'weights/nasnet_large_val.tfrecord'\n\nmodel.fit_generator(features_generator(TRAIN_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=True),\n                    steps_per_epoch=(500000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=features_generator(VAL_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=False),\n                    validation_steps=(5000. // batchsize))\n"""
pretrain_nasnet_mobile.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.data_loader import features_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nNUM_FEATURES = 1056\n\nimage_size = 224\nip = Input(shape=(NUM_FEATURES,))\nx = Dropout(0.75)(ip)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(ip, x)\nmodel.summary()\noptimizer = Adam(lr=1e-4)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/nasnet_pretrained_weights.h5'):\n    model.load_weights('weights/nasnet_pretrained_weights.h5')\n\ncheckpoint = ModelCheckpoint('weights/nasnet_pretrained_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch(log_dir='./nasnet_logs/')\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nTRAIN_RECORD_PATH = 'weights/nasnet_train.tfrecord'\nVAL_RECORD_PATH = 'weights/nasnet_val.tfrecord'\n\nmodel.fit_generator(features_generator(TRAIN_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=True),\n                    steps_per_epoch=(500000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=features_generator(VAL_RECORD_PATH, NUM_FEATURES, batchsize=batchsize, shuffle=False),\n                    validation_steps=(5000. // batchsize))\n"""
train_inception_resnet.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.data_loader import train_generator, val_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nimage_size = 224\n\nbase_model = InceptionResNetV2(input_shape=(image_size, image_size, 3), include_top=False, pooling='avg')\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = Dropout(0.75)(base_model.output)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(base_model.input, x)\nmodel.summary()\noptimizer = Adam(lr=1e-3)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/inception_resnet_weights.h5'):\n    model.load_weights('weights/inception_resnet_weights.h5')\n\n# load pre-trained NIMA(Inception ResNet V2) classifier weights\n# if os.path.exists('weights/inception_resnet_pretrained_weights.h5'):\n#     model.load_weights('weights/inception_resnet_pretrained_weights.h5', by_name=True)\n\ncheckpoint = ModelCheckpoint('weights/inception_resnet_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch()\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 100\nepochs = 20\n\nmodel.fit_generator(train_generator(batchsize=batchsize),\n                    steps_per_epoch=(250000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=val_generator(batchsize=batchsize),\n                    validation_steps=(5000. // batchsize))"""
train_mobilenet.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.data_loader import train_generator, val_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nimage_size = 224\n\nbase_model = MobileNet((image_size, image_size, 3), alpha=1, include_top=False, pooling='avg')\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = Dropout(0.75)(base_model.output)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(base_model.input, x)\nmodel.summary()\noptimizer = Adam(lr=1e-3)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/mobilenet_weights.h5'):\n    model.load_weights('weights/mobilenet_weights.h5')\n\ncheckpoint = ModelCheckpoint('weights/mobilenet_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch()\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nmodel.fit_generator(train_generator(batchsize=batchsize),\n                    steps_per_epoch=(250000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=val_generator(batchsize=batchsize),\n                    validation_steps=(5000. // batchsize))"""
train_nasnet_large.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.nasnet import NASNetLarge\n\nfrom utils.data_loader import train_generator, val_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nimage_size = 224\n\nbase_model = NASNetLarge((image_size, image_size, 3), include_top=False, pooling='avg', weight_decay=0, dropout=0)\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = Dropout(0.75)(base_model.output)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(base_model.input, x)\nmodel.summary()\noptimizer = Adam(lr=1e-4)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/nasnet_large_weights.h5'):\n    model.load_weights('weights/nasnet_large_weights.h5')\n\n# load pre-trained NIMA(NASNet Mobile) classifier weights\nif os.path.exists('weights/nasnet_large_pretrained_weights.h5'):\n    model.load_weights('weights/nasnet_large_pretrained_weights.h5', by_name=True)\n\ncheckpoint = ModelCheckpoint('weights/nasnet_large_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch(log_dir='./nasnet_logs/')\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nmodel.fit_generator(train_generator(batchsize=batchsize),\n                    steps_per_epoch=(250000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=val_generator(batchsize=batchsize),\n                    validation_steps=(5000. // batchsize))"""
train_nasnet_mobile.py,2,"b""import os\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom utils.nasnet import NASNetMobile\n\nfrom utils.data_loader import train_generator, val_generator\n\n'''\nBelow is a modification to the TensorBoard callback to perform \nbatchwise writing to the tensorboard, instead of only at the end\nof the batch.\n'''\nclass TensorBoardBatch(TensorBoard):\n    def __init__(self, *args, **kwargs):\n        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n\n        # conditionally import tensorflow iff TensorBoardBatch is created\n        self.tf = __import__('tensorflow')\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, batch)\n\n        self.writer.flush()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = self.tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch * self.batch_size)\n\n        self.writer.flush()\n\ndef earth_mover_loss(y_true, y_pred):\n    cdf_ytrue = K.cumsum(y_true, axis=-1)\n    cdf_ypred = K.cumsum(y_pred, axis=-1)\n    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n    return K.mean(samplewise_emd)\n\nimage_size = 224\n\nbase_model = NASNetMobile((image_size, image_size, 3), include_top=False, pooling='avg', weight_decay=0, dropout=0)\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = Dropout(0.75)(base_model.output)\nx = Dense(10, activation='softmax')(x)\n\nmodel = Model(base_model.input, x)\nmodel.summary()\noptimizer = Adam(lr=1e-4)\nmodel.compile(optimizer, loss=earth_mover_loss)\n\n# load weights from trained model if it exists\nif os.path.exists('weights/nasnet_weights.h5'):\n    model.load_weights('weights/nasnet_weights.h5')\n\n# load pre-trained NIMA(NASNet Mobile) classifier weights\n# if os.path.exists('weights/nasnet_pretrained_weights.h5'):\n#     model.load_weights('weights/nasnet_pretrained_weights.h5', by_name=True)\n\ncheckpoint = ModelCheckpoint('weights/nasnet_weights.h5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True,\n                             mode='min')\ntensorboard = TensorBoardBatch(log_dir='./nasnet_logs/')\ncallbacks = [checkpoint, tensorboard]\n\nbatchsize = 200\nepochs = 20\n\nmodel.fit_generator(train_generator(batchsize=batchsize),\n                    steps_per_epoch=(250000. // batchsize),\n                    epochs=epochs, verbose=1, callbacks=callbacks,\n                    validation_data=val_generator(batchsize=batchsize),\n                    validation_steps=(5000. // batchsize))"""
utils/check_dataset.py,5,"b'import numpy as np\nimport os\nimport glob\n\nimport tensorflow as tf\n\n\'\'\'\nChecks all images from the AVA dataset if they have corrupted jpegs, and lists them for removal.\n\nRemoval must be done manually !\n\'\'\'\n\nbase_images_path = r\'D:\\Yue\\Documents\\Datasets\\AVA_dataset\\images\\images\\\\\'\nava_dataset_path = r\'D:\\Yue\\Documents\\Datasets\\AVA_dataset\\AVA.txt\'\n\nIMAGE_SIZE = 128\nBASE_LEN = len(base_images_path) - 1\n\nfiles = glob.glob(base_images_path + ""*.jpg"")\nfiles = sorted(files)\n\ntrain_image_paths = []\ntrain_scores = []\n\nprint(""Loading training set and val set"")\nwith open(ava_dataset_path, mode=\'r\') as f:\n    lines = f.readlines()\n    for i, line in enumerate(lines):\n        token = line.split()\n        id = int(token[1])\n\n        values = np.array(token[2:12], dtype=\'float32\')\n        values /= values.sum()\n\n        file_path = base_images_path + str(id) + \'.jpg\'\n        if os.path.exists(file_path):\n            train_image_paths.append(file_path)\n            train_scores.append(values)\n\n        count = 255000 // 20\n        if i % count == 0 and i != 0:\n            print(\'Loaded %0.2f of the dataset\' % (i / 255000. * 100))\n\n\ntrain_image_paths = np.array(train_image_paths)\ntrain_scores = np.array(train_scores, dtype=\'float32\')\n\nval_image_paths = train_image_paths[-5000:]\nval_scores = train_scores[-5000:]\ntrain_image_paths = train_image_paths[:-5000]\ntrain_scores = train_scores[:-5000]\n\ndef parse_data(filename):\n    image = tf.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    return image\n\nsess = tf.Session()\nwith sess.as_default():\n    sess.run(tf.global_variables_initializer())\n\n    count = 0\n    fn = tf.placeholder(dtype=tf.string)\n    img = parse_data(fn)\n\n    for path in train_image_paths:\n        try:\n            sess.run(img, feed_dict={fn: path})\n        except Exception as e:\n            print(path, ""failed to load !"")\n            print()\n            count += 1\n\n    print(count, ""images failed to load !"")\n\nprint(""All done !"")\n\n""""""\nHad to delete file : 440774.jpg and remove row from AVA.txt\nHad to delete file : 179118.jpg and remove row from AVA.txt\nHad to delete file : 371434.jpg and remove row from AVA.txt\nHad to delete file : 277832.jpg and remove row from AVA.txt\nHad to delete file : 230701.jpg and remove row from AVA.txt\nHad to delete file : 729377.jpg and remove row from AVA.txt\n""""""'"
utils/data_loader.py,19,"b'import numpy as np\nimport os\nimport glob\n\nimport tensorflow as tf\n\n# path to the images and the text file which holds the scores and ids\nbase_images_path = r\'D:\\Yue\\Documents\\Datasets\\AVA_dataset\\images\\images\\\\\'\nava_dataset_path = r\'D:\\Yue\\Documents\\Datasets\\AVA_dataset\\AVA.txt\'\n\nIMAGE_SIZE = 224\n\nfiles = glob.glob(base_images_path + ""*.jpg"")\nfiles = sorted(files)\n\ntrain_image_paths = []\ntrain_scores = []\n\nprint(""Loading training set and val set"")\nwith open(ava_dataset_path, mode=\'r\') as f:\n    lines = f.readlines()\n    for i, line in enumerate(lines):\n        token = line.split()\n        id = int(token[1])\n\n        values = np.array(token[2:12], dtype=\'float32\')\n        values /= values.sum()\n\n        file_path = base_images_path + str(id) + \'.jpg\'\n        if os.path.exists(file_path):\n            train_image_paths.append(file_path)\n            train_scores.append(values)\n\n        count = 255000 // 20\n        if i % count == 0 and i != 0:\n            print(\'Loaded %d percent of the dataset\' % (i / 255000. * 100))\n\ntrain_image_paths = np.array(train_image_paths)\ntrain_scores = np.array(train_scores, dtype=\'float32\')\n\nval_image_paths = train_image_paths[-5000:]\nval_scores = train_scores[-5000:]\ntrain_image_paths = train_image_paths[:-5000]\ntrain_scores = train_scores[:-5000]\n\nprint(\'Train set size : \', train_image_paths.shape, train_scores.shape)\nprint(\'Val set size : \', val_image_paths.shape, val_scores.shape)\nprint(\'Train and validation datasets ready !\')\n\ndef parse_data(filename, scores):\n    \'\'\'\n    Loads the image file, and randomly applies crops and flips to each image.\n\n    Args:\n        filename: the filename from the record\n        scores: the scores from the record\n\n    Returns:\n        an image referred to by the filename and its scores\n    \'\'\'\n    image = tf.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize_images(image, (256, 256))\n    image = tf.random_crop(image, size=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    image = tf.image.random_flip_left_right(image)\n    image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n    return image, scores\n\ndef parse_data_without_augmentation(filename, scores):\n    \'\'\'\n    Loads the image file without any augmentation. Used for validation set.\n\n    Args:\n        filename: the filename from the record\n        scores: the scores from the record\n\n    Returns:\n        an image referred to by the filename and its scores\n    \'\'\'\n    image = tf.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize_images(image, (IMAGE_SIZE, IMAGE_SIZE))\n    image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n    return image, scores\n\ndef train_generator(batchsize, shuffle=True):\n    \'\'\'\n    Creates a python generator that loads the AVA dataset images with random data\n    augmentation and generates numpy arrays to feed into the Keras model for training.\n\n    Args:\n        batchsize: batchsize for training\n        shuffle: whether to shuffle the dataset\n\n    Returns:\n        a batch of samples (X_images, y_scores)\n    \'\'\'\n    with tf.Session() as sess:\n        # create a dataset\n        train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_scores))\n        train_dataset = train_dataset.map(parse_data, num_parallel_calls=2)\n\n        train_dataset = train_dataset.batch(batchsize)\n        train_dataset = train_dataset.repeat()\n        if shuffle:\n            train_dataset = train_dataset.shuffle(buffer_size=4)\n        train_iterator = train_dataset.make_initializable_iterator()\n\n        train_batch = train_iterator.get_next()\n\n        sess.run(train_iterator.initializer)\n\n        while True:\n            try:\n                X_batch, y_batch = sess.run(train_batch)\n                yield (X_batch, y_batch)\n            except:\n                train_iterator = train_dataset.make_initializable_iterator()\n                sess.run(train_iterator.initializer)\n                train_batch = train_iterator.get_next()\n\n                X_batch, y_batch = sess.run(train_batch)\n                yield (X_batch, y_batch)\n\ndef val_generator(batchsize):\n    \'\'\'\n    Creates a python generator that loads the AVA dataset images without random data\n    augmentation and generates numpy arrays to feed into the Keras model for training.\n\n    Args:\n        batchsize: batchsize for validation set\n\n    Returns:\n        a batch of samples (X_images, y_scores)\n    \'\'\'\n    with tf.Session() as sess:\n        val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_scores))\n        val_dataset = val_dataset.map(parse_data_without_augmentation)\n\n        val_dataset = val_dataset.batch(batchsize)\n        val_dataset = val_dataset.repeat()\n        val_iterator = val_dataset.make_initializable_iterator()\n\n        val_batch = val_iterator.get_next()\n\n        sess.run(val_iterator.initializer)\n\n        while True:\n            try:\n                X_batch, y_batch = sess.run(val_batch)\n                yield (X_batch, y_batch)\n            except:\n                val_iterator = val_dataset.make_initializable_iterator()\n                sess.run(val_iterator.initializer)\n                val_batch = val_iterator.get_next()\n\n                X_batch, y_batch = sess.run(val_batch)\n                yield (X_batch, y_batch)\n\ndef features_generator(record_path, faeture_size, batchsize, shuffle=True):\n    \'\'\'\n    Creates a python generator that loads pre-extracted features from a model\n    and serves it to Keras for pre-training.\n\n    Args:\n        record_path: path to the TF Record file\n        faeture_size: the number of features in each record. Depends on the base model.\n        batchsize: batchsize for training\n        shuffle: whether to shuffle the records\n\n    Returns:\n        a batch of samples (X_features, y_scores)\n    \'\'\'\n    with tf.Session() as sess:\n        # maps record examples to numpy arrays\n\n        def parse_single_record(serialized_example):\n            # parse a single record\n            example = tf.parse_single_example(\n                serialized_example,\n                features={\n                    \'features\': tf.FixedLenFeature([faeture_size], tf.float32),\n                    \'scores\': tf.FixedLenFeature([10], tf.float32),\n                })\n\n            features = example[\'features\']\n            scores = example[\'scores\']\n            return features, scores\n\n        # Loads the TF dataset\n        train_dataset = tf.data.TFRecordDataset([record_path])\n        train_dataset = train_dataset.map(parse_single_record, num_parallel_calls=4)\n\n        train_dataset = train_dataset.batch(batchsize)\n        train_dataset = train_dataset.repeat()\n        if shuffle:\n            train_dataset = train_dataset.shuffle(buffer_size=5)\n        train_iterator = train_dataset.make_initializable_iterator()\n\n        train_batch = train_iterator.get_next()\n\n        sess.run(train_iterator.initializer)\n\n        # indefinitely extract batches\n        while True:\n            try:\n                X_batch, y_batch = sess.run(train_batch)\n                yield (X_batch, y_batch)\n            except:\n                train_iterator = train_dataset.make_initializable_iterator()\n                sess.run(train_iterator.initializer)\n                train_batch = train_iterator.get_next()\n\n                X_batch, y_batch = sess.run(train_batch)\n                yield (X_batch, y_batch)'"
utils/nasnet.py,2,"b'""""""NASNet-A models for Keras\n\nNASNet refers to Neural Architecture Search Network, a family of models\nthat were designed automatically by learning the model architectures\ndirectly on the dataset of interest.\n\nHere we consider NASNet-A, the highest performance model that was found\nfor the CIFAR-10 dataset, and then extended to ImageNet 2012 dataset,\nobtaining state of the art performance on CIFAR-10 and ImageNet 2012.\nOnly the NASNet-A models, and their respective weights, which are suited\nfor ImageNet 2012 are provided.\n\nThe below table describes the performance on ImageNet 2012:\n------------------------------------------------------------------------------------\n      Architecture       | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M)\n------------------------------------------------------------------------------------\n|   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3        |\n|   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9        |\n------------------------------------------------------------------------------------\n\nWeights obtained from the official Tensorflow repository found at\nhttps://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet\n\n# References:\n - [Learning Transferable Architectures for Scalable Image Recognition]\n    (https://arxiv.org/abs/1707.07012)\n\nBased on the following implementations:\n - [TF Slim Implementation]\n   (https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.)\n - [TensorNets implementation]\n   (https://github.com/taehoonlee/tensornets/blob/master/tensornets/nasnets.py)\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\nimport warnings\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Activation\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import Conv2D\nfrom keras.layers import SeparableConv2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Cropping2D\nfrom keras.layers import concatenate\nfrom keras.layers import add\nfrom keras.regularizers import l2\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras_applications.inception_v3 import preprocess_input\nfrom keras_applications.imagenet_utils import decode_predictions\nfrom keras import backend as K\n\n_BN_DECAY = 0.9997\n_BN_EPSILON = 1e-3\n\nNASNET_MOBILE_WEIGHT_PATH = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-mobile.h5""\nNASNET_MOBILE_WEIGHT_PATH_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-mobile-no-top.h5""\nNASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-auxiliary-mobile.h5""\nNASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.0/NASNet-auxiliary-mobile-no-top.h5""\nNASNET_LARGE_WEIGHT_PATH = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-large.h5""\nNASNET_LARGE_WEIGHT_PATH_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-large-no-top.h5""\nNASNET_LARGE_WEIGHT_PATH_WITH_auxiliary = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-auxiliary-large.h5""\nNASNET_LARGE_WEIGHT_PATH_WITH_auxiliary_NO_TOP = ""https://github.com/titu1994/Keras-NASNet/releases/download/v1.1/NASNet-auxiliary-large-no-top.h5""\n\n\ndef NASNet(input_shape=None,\n           penultimate_filters=4032,\n           nb_blocks=6,\n           stem_filters=96,\n           skip_reduction=True,\n           use_auxiliary_branch=False,\n           filters_multiplier=2,\n           dropout=0.5,\n           weight_decay=5e-5,\n           include_top=True,\n           weights=None,\n           input_tensor=None,\n           pooling=None,\n           classes=1000,\n           default_size=None):\n    """"""Instantiates a NASNet architecture.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge or\n            `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        penultimate_filters: number of filters in the penultimate layer.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        nb_blocks: number of repeated blocks of the NASNet model.\n            NASNet models use the notation `NASNet (N @ P)`, where:\n                -   N is the number of blocks\n                -   P is the number of penultimate filters\n        stem_filters: number of filters in the initial stem block\n        skip_reduction: Whether to skip the reduction step at the tail\n            end of the network. Set to `False` for CIFAR models.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        filters_multiplier: controls the width of the network.\n            - If `filters_multiplier` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `filters_multiplier` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `filters_multiplier` = 1, default number of filters from the paper\n                 are used at each layer.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    if K.backend() != \'tensorflow\':\n        raise RuntimeError(\'Only Tensorflow backend is currently supported, \'\n                           \'as other backends do not support \'\n                           \'separable convolution.\')\n\n    if weights not in {\'imagenet\', None}:\n        raise ValueError(\'The `weights` argument should be either \'\n                         \'`None` (random initialization) or `imagenet` \'\n                         \'(pre-training on ImageNet).\')\n\n    if weights == \'imagenet\' and include_top and classes != 1000:\n        raise ValueError(\'If using `weights` as ImageNet with `include_top` \'\n                         \'as true, `classes` should be 1000\')\n\n    if default_size is None:\n        default_size = 331\n\n    # Determine proper input shape and default size.\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if K.image_data_format() != \'channels_last\':\n        warnings.warn(\'The NASNet family of models is only available \'\n                      \'for the input data format ""channels_last"" \'\n                      \'(width, height, channels). \'\n                      \'However your settings specify the default \'\n                      \'data format ""channels_first"" (channels, width, height).\'\n                      \' You should set `image_data_format=""channels_last""` \'\n                      \'in your Keras config located at ~/.keras/keras.json. \'\n                      \'The model being returned right now will expect inputs \'\n                      \'to follow the ""channels_last"" data format.\')\n        K.set_image_data_format(\'channels_last\')\n        old_data_format = \'channels_first\'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    assert penultimate_filters % 24 == 0, ""`penultimate_filters` needs to be divisible "" \\\n                                          ""by 24.""\n\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    filters = penultimate_filters // 24\n\n    if not skip_reduction:\n        x = Conv2D(stem_filters, (3, 3), strides=(2, 2), padding=\'valid\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(img_input)\n    else:\n        x = Conv2D(stem_filters, (3, 3), strides=(1, 1), padding=\'same\', use_bias=False, name=\'stem_conv1\',\n                   kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(img_input)\n\n    x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                           name=\'stem_bn1\')(x)\n\n    p = None\n    if not skip_reduction:  # imagenet / mobile mode\n        x, p = _reduction_A(x, p, filters // (filters_multiplier ** 2), weight_decay, id=\'stem_1\')\n        x, p = _reduction_A(x, p, filters // filters_multiplier, weight_decay, id=\'stem_2\')\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters, weight_decay, id=\'%d\' % (i))\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier, weight_decay, id=\'reduce_%d\' % (nb_blocks))\n\n    p = p0 if not skip_reduction else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier, weight_decay, id=\'%d\' % (nb_blocks + i + 1))\n\n    auxiliary_x = None\n    if not skip_reduction:  # imagenet / mobile mode\n        if use_auxiliary_branch:\n            auxiliary_x = _add_auxiliary_head(x, classes, weight_decay)\n\n    x, p0 = _reduction_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'reduce_%d\' % (2 * nb_blocks))\n\n    if skip_reduction:  # CIFAR mode\n        if use_auxiliary_branch:\n            auxiliary_x = _add_auxiliary_head(x, classes, weight_decay)\n\n    p = p0 if not skip_reduction else p\n\n    for i in range(nb_blocks):\n        x, p = _normal_A(x, p, filters * filters_multiplier ** 2, weight_decay, id=\'%d\' % (2 * nb_blocks + i + 1))\n\n    x = Activation(\'relu\')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D()(x)\n        x = Dropout(dropout)(x)\n        x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay), name=\'predictions\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    if use_auxiliary_branch:\n        model = Model(inputs, [x, auxiliary_x], name=\'NASNet_with_auxiliary\')\n    else:\n        model = Model(inputs, x, name=\'NASNet\')\n\n    # load weights\n    if weights == \'imagenet\':\n        if default_size == 224:  # mobile version\n            if include_top:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY\n                    model_name = \'nasnet_mobile_with_aux.h5\'\n                else:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH\n                    model_name = \'nasnet_mobile.h5\'\n            else:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_WITH_AUXULARY_NO_TOP\n                    model_name = \'nasnet_mobile_with_aux_no_top.h5\'\n                else:\n                    weight_path = NASNET_MOBILE_WEIGHT_PATH_NO_TOP\n                    model_name = \'nasnet_mobile_no_top.h5\'\n\n            weights_file = get_file(model_name, weight_path, cache_subdir=\'models\')\n            model.load_weights(weights_file, by_name=True)\n\n        elif default_size == 331:  # large version\n            if include_top:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_WITH_auxiliary\n                    model_name = \'nasnet_large_with_aux.h5\'\n                else:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH\n                    model_name = \'nasnet_large.h5\'\n            else:\n                if use_auxiliary_branch:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_WITH_auxiliary_NO_TOP\n                    model_name = \'nasnet_large_with_aux_no_top.h5\'\n                else:\n                    weight_path = NASNET_LARGE_WEIGHT_PATH_NO_TOP\n                    model_name = \'nasnet_large_no_top.h5\'\n\n            weights_file = get_file(model_name, weight_path, cache_subdir=\'models\')\n            model.load_weights(weights_file, by_name=True)\n\n        else:\n            raise ValueError(\'ImageNet weights can only be loaded on NASNetLarge or NASNetMobile\')\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n\n    return model\n\n\ndef NASNetLarge(input_shape=(331, 331, 3),\n                dropout=0.5,\n                weight_decay=5e-5,\n                use_auxiliary_branch=False,\n                include_top=True,\n                weights=\'imagenet\',\n                input_tensor=None,\n                pooling=None,\n                classes=1000):\n    """"""Instantiates a NASNet architecture in ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(331, 331, 3)` for NASNetLarge.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    return NASNet(input_shape,\n                  penultimate_filters=4032,\n                  nb_blocks=6,\n                  stem_filters=96,\n                  skip_reduction=False,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=331)\n\n\ndef NASNetMobile(input_shape=(224, 224, 3),\n                 dropout=0.5,\n                 weight_decay=4e-5,\n                 use_auxiliary_branch=False,\n                 include_top=True,\n                 weights=\'imagenet\',\n                 input_tensor=None,\n                 pooling=None,\n                 classes=1000):\n    """"""Instantiates a NASNet architecture in Mobile ImageNet mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9997\n    _BN_EPSILON = 1e-3\n\n    return NASNet(input_shape,\n                  penultimate_filters=1056,\n                  nb_blocks=4,\n                  stem_filters=32,\n                  skip_reduction=False,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef NASNetCIFAR(input_shape=(32, 32, 3),\n                dropout=0.0,\n                weight_decay=5e-4,\n                use_auxiliary_branch=False,\n                include_top=True,\n                weights=None,\n                input_tensor=None,\n                pooling=None,\n                classes=10):\n    """"""Instantiates a NASNet architecture in CIFAR mode.\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format=\'channels_last\'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(32, 32, 3)` for NASNetMobile\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(32, 32, 3)` would be one valid value.\n        use_auxiliary_branch: Whether to use the auxiliary branch during\n            training or evaluation.\n        dropout: dropout rate\n        weight_decay: l2 regularization weight\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        default_size: specifies the default image size of the model\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    """"""\n    global _BN_DECAY, _BN_EPSILON\n    _BN_DECAY = 0.9\n    _BN_EPSILON = 1e-5\n\n    return NASNet(input_shape,\n                  penultimate_filters=768,\n                  nb_blocks=6,\n                  stem_filters=32,\n                  skip_reduction=True,\n                  use_auxiliary_branch=use_auxiliary_branch,\n                  filters_multiplier=2,\n                  dropout=dropout,\n                  weight_decay=weight_decay,\n                  include_top=include_top,\n                  weights=weights,\n                  input_tensor=input_tensor,\n                  pooling=pooling,\n                  classes=classes,\n                  default_size=224)\n\n\ndef _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1), weight_decay=5e-5, id=None):\n    \'\'\'Adds 2 blocks of [relu-separable conv-batchnorm]\n\n    # Arguments:\n        ip: input tensor\n        filters: number of output filters per layer\n        kernel_size: kernel size of separable convolutions\n        strides: strided convolution for downsampling\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'separable_conv_block_%s\' % id):\n        x = Activation(\'relu\')(ip)\n        x = SeparableConv2D(filters, kernel_size, strides=strides, name=\'separable_conv_1_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_1_bn_%s"" % (id))(x)\n        x = Activation(\'relu\')(x)\n        x = SeparableConv2D(filters, kernel_size, name=\'separable_conv_2_%s\' % id,\n                            padding=\'same\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=""separable_conv_2_bn_%s"" % (id))(x)\n    return x\n\n\ndef _adjust_block(p, ip, filters, weight_decay=5e-5, id=None):\n    \'\'\'\n    Adjusts the input `p` to match the shape of the `input`\n    or situations where the output number of filters needs to\n    be changed\n\n    # Arguments:\n        p: input tensor which needs to be modified\n        ip: input tensor whose shape needs to be matched\n        filters: number of output filters to be matched\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        an adjusted Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n    img_dim = 2 if K.image_data_format() == \'channels_first\' else -2\n\n    with K.name_scope(\'adjust_block\'):\n        if p is None:\n            p = ip\n\n        elif p._keras_shape[img_dim] != ip._keras_shape[img_dim]:\n            with K.name_scope(\'adjust_reduction_block_%s\' % id):\n                p = Activation(\'relu\', name=\'adjust_relu_1_%s\' % id)(p)\n\n                p1 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_1_%s\' % id)(p)\n                p1 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_1_%s\' % id, kernel_initializer=\'he_normal\')(p1)\n\n                p2 = ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n                p2 = Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n                p2 = AveragePooling2D((1, 1), strides=(2, 2), padding=\'valid\', name=\'adjust_avg_pool_2_%s\' % id)(p2)\n                p2 = Conv2D(filters // 2, (1, 1), padding=\'same\', use_bias=False, kernel_regularizer=l2(weight_decay),\n                            name=\'adjust_conv_2_%s\' % id, kernel_initializer=\'he_normal\')(p2)\n\n                p = concatenate([p1, p2], axis=channel_dim)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id)(p)\n\n        elif p._keras_shape[channel_dim] != filters:\n            with K.name_scope(\'adjust_projection_block_%s\' % id):\n                p = Activation(\'relu\')(p)\n                p = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'adjust_conv_projection_%s\' % id,\n                           use_bias=False, kernel_regularizer=l2(weight_decay), kernel_initializer=\'he_normal\')(p)\n                p = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                       name=\'adjust_bn_%s\' % id)(p)\n    return p\n\n\ndef _normal_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'normal_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'normal_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'normal_bn_1_%s\' % id)(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, kernel_size=(5, 5), weight_decay=weight_decay,\n                                         id=\'normal_left1_%s\' % id)\n            x1_2 = _separable_conv_block(p, filters, weight_decay=weight_decay, id=\'normal_right1_%s\' % id)\n            x1 = add([x1_1, x1_2], name=\'normal_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = _separable_conv_block(p, filters, (5, 5), weight_decay=weight_decay, id=\'normal_left2_%s\' % id)\n            x2_2 = _separable_conv_block(p, filters, (3, 3), weight_decay=weight_decay, id=\'normal_right2_%s\' % id)\n            x2 = add([x2_1, x2_2], name=\'normal_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left3_%s\' % (id))(h)\n            x3 = add([x3, p], name=\'normal_add_3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4_1 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_left4_%s\' % (id))(p)\n            x4_2 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'normal_right4_%s\' % (id))(p)\n            x4 = add([x4_1, x4_2], name=\'normal_add_4_%s\' % id)\n\n        with K.name_scope(\'block_5\'):\n            x5 = _separable_conv_block(h, filters, weight_decay=weight_decay, id=\'normal_left5_%s\' % id)\n            x5 = add([x5, h], name=\'normal_add_5_%s\' % id)\n\n        x = concatenate([p, x1, x2, x3, x4, x5], axis=channel_dim, name=\'normal_concat_%s\' % id)\n    return x, ip\n\n\ndef _reduction_A(ip, p, filters, weight_decay=5e-5, id=None):\n    \'\'\'Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n\n    # Arguments:\n        ip: input tensor `x`\n        p: input tensor `p`\n        filters: number of output filters\n        weight_decay: l2 regularization weight\n        id: string id\n\n    # Returns:\n        a Keras tensor\n    \'\'\'\n    """"""""""""\n    channel_dim = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'reduction_A_block_%s\' % id):\n        p = _adjust_block(p, ip, filters, weight_decay, id)\n\n        h = Activation(\'relu\')(ip)\n        h = Conv2D(filters, (1, 1), strides=(1, 1), padding=\'same\', name=\'reduction_conv_1_%s\' % id,\n                   use_bias=False, kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(h)\n        h = BatchNormalization(axis=channel_dim, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                               name=\'reduction_bn_1_%s\' % id)(h)\n\n        with K.name_scope(\'block_1\'):\n            x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_left1_%s\' % id)\n            x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_1_%s\' % id)\n            x1 = add([x1_1, x1_2], name=\'reduction_add_1_%s\' % id)\n\n        with K.name_scope(\'block_2\'):\n            x2_1 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left2_%s\' % id)(h)\n            x2_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right2_%s\' % id)\n            x2 = add([x2_1, x2_2], name=\'reduction_add_2_%s\' % id)\n\n        with K.name_scope(\'block_3\'):\n            x3_1 = AveragePooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_left3_%s\' % id)(h)\n            x3_2 = _separable_conv_block(p, filters, (5, 5), strides=(2, 2), weight_decay=weight_decay,\n                                         id=\'reduction_right3_%s\' % id)\n            x3 = add([x3_1, x3_2], name=\'reduction_add3_%s\' % id)\n\n        with K.name_scope(\'block_4\'):\n            x4 = AveragePooling2D((3, 3), strides=(1, 1), padding=\'same\', name=\'reduction_left4_%s\' % id)(x1)\n            x4 = add([x2, x4])\n\n        with K.name_scope(\'block_5\'):\n            x5_1 = _separable_conv_block(x1, filters, (3, 3), weight_decay=weight_decay, id=\'reduction_left4_%s\' % id)\n            x5_2 = MaxPooling2D((3, 3), strides=(2, 2), padding=\'same\', name=\'reduction_right5_%s\' % id)(h)\n            x5 = add([x5_1, x5_2], name=\'reduction_add4_%s\' % id)\n\n        x = concatenate([x2, x3, x4, x5], axis=channel_dim, name=\'reduction_concat_%s\' % id)\n        return x, ip\n\n\ndef _add_auxiliary_head(x, classes, weight_decay):\n    \'\'\'Adds an auxiliary head for training the model\n\n    From section A.7 ""Training of ImageNet models"" of the paper, all NASNet models are\n    trained using an auxiliary classifier around 2/3 of the depth of the network, with\n    a loss weight of 0.4\n\n    # Arguments\n        x: input tensor\n        classes: number of output classes\n        weight_decay: l2 regularization weight\n\n    # Returns\n        a keras Tensor\n    \'\'\'\n    img_height = 1 if K.image_data_format() == \'channels_last\' else 2\n    img_width = 2 if K.image_data_format() == \'channels_last\' else 3\n    channel_axis = 1 if K.image_data_format() == \'channels_first\' else -1\n\n    with K.name_scope(\'auxiliary_branch\'):\n        auxiliary_x = Activation(\'relu\')(x)\n        auxiliary_x = AveragePooling2D((5, 5), strides=(3, 3), padding=\'valid\', name=\'aux_pool\')(auxiliary_x)\n        auxiliary_x = Conv2D(128, (1, 1), padding=\'same\', use_bias=False, name=\'aux_conv_projection\',\n                            kernel_initializer=\'he_normal\', kernel_regularizer=l2(weight_decay))(auxiliary_x)\n        auxiliary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_projection\')(auxiliary_x)\n        auxiliary_x = Activation(\'relu\')(auxiliary_x)\n\n        auxiliary_x = Conv2D(768, (auxiliary_x._keras_shape[img_height], auxiliary_x._keras_shape[img_width]),\n                            padding=\'valid\', use_bias=False, kernel_initializer=\'he_normal\',\n                            kernel_regularizer=l2(weight_decay), name=\'aux_conv_reduction\')(auxiliary_x)\n        auxiliary_x = BatchNormalization(axis=channel_axis, momentum=_BN_DECAY, epsilon=_BN_EPSILON,\n                                        name=\'aux_bn_reduction\')(auxiliary_x)\n        auxiliary_x = Activation(\'relu\')(auxiliary_x)\n\n        auxiliary_x = GlobalAveragePooling2D()(auxiliary_x)\n        auxiliary_x = Dense(classes, activation=\'softmax\', kernel_regularizer=l2(weight_decay),\n                           name=\'aux_predictions\')(auxiliary_x)\n    return auxiliary_x\n\n\nif __name__ == \'__main__\':\n    import tensorflow as tf\n\n    sess = tf.Session()\n\n    K.set_session(sess)\n\n    model = NASNetLarge((331, 331, 3))\n    model.summary()\n\n    writer = tf.summary.FileWriter(\'./logs/\', graph=K.get_session().graph)\n    writer.close()\n'"
utils/score_utils.py,0,"b'import numpy as np\n\n# calculate mean score for AVA dataset\ndef mean_score(scores):\n    si = np.arange(1, 11, 1)\n    mean = np.sum(scores * si)\n    return mean\n\n# calculate standard deviation of scores for AVA dataset\ndef std_score(scores):\n    si = np.arange(1, 11, 1)\n    mean = mean_score(scores)\n    std = np.sqrt(np.sum(((si - mean) ** 2) * scores))\n    return std'"
