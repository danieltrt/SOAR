file_path,api_count,code
setup.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nPython package setup file.\n""""""\n\nfrom setuptools import setup\n\nsetup(\n    name=""seq2seq"",\n    version=""0.1"",\n    install_requires=[\n        ""numpy"",\n        ""matplotlib"",\n        ""pyyaml"",\n        ""pyrouge""\n    ],\n    extras_require={\'tensorflow\': [\'tensorflow\'],\n                    \'tensorflow with gpu\': [\'tensorflow-gpu\']},\n)\n'"
bin/__init__.py,0,b''
bin/infer.py,18,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Generates model predictions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\n\nimport yaml\nfrom six import string_types\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq import tasks, models\nfrom seq2seq.configurable import _maybe_load_yaml, _deep_merge_dict\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.inference import create_inference_graph\nfrom seq2seq.training import utils as training_utils\n\ntf.flags.DEFINE_string(""tasks"", ""{}"", ""List of inference tasks to run."")\ntf.flags.DEFINE_string(""model_params"", ""{}"", """"""Optionally overwrite model\n                        parameters for inference"""""")\n\ntf.flags.DEFINE_string(""config_path"", None,\n                       """"""Path to a YAML configuration file defining FLAG\n                       values and hyperparameters. Refer to the documentation\n                       for more details."""""")\n\ntf.flags.DEFINE_string(""input_pipeline"", None,\n                       """"""Defines how input data should be loaded.\n                       A YAML string."""""")\n\ntf.flags.DEFINE_string(""model_dir"", None, ""directory to load model from"")\ntf.flags.DEFINE_string(""checkpoint_path"", None,\n                       """"""Full path to the checkpoint to be loaded. If None,\n                       the latest checkpoint in the model dir is used."""""")\ntf.flags.DEFINE_integer(""batch_size"", 32, ""the train/dev batch size"")\n\nFLAGS = tf.flags.FLAGS\n\ndef main(_argv):\n  """"""Program entry point.\n  """"""\n\n  # Load flags from config file\n  if FLAGS.config_path:\n    with gfile.GFile(FLAGS.config_path) as config_file:\n      config_flags = yaml.load(config_file)\n      for flag_key, flag_value in config_flags.items():\n        setattr(FLAGS, flag_key, flag_value)\n\n  if isinstance(FLAGS.tasks, string_types):\n    FLAGS.tasks = _maybe_load_yaml(FLAGS.tasks)\n\n  if isinstance(FLAGS.input_pipeline, string_types):\n    FLAGS.input_pipeline = _maybe_load_yaml(FLAGS.input_pipeline)\n\n  input_pipeline_infer = input_pipeline.make_input_pipeline_from_def(\n      FLAGS.input_pipeline, mode=tf.contrib.learn.ModeKeys.INFER,\n      shuffle=False, num_epochs=1)\n\n  # Load saved training options\n  train_options = training_utils.TrainOptions.load(FLAGS.model_dir)\n\n  # Create the model\n  model_cls = locate(train_options.model_class) or \\\n    getattr(models, train_options.model_class)\n  model_params = train_options.model_params\n  model_params = _deep_merge_dict(\n      model_params, _maybe_load_yaml(FLAGS.model_params))\n  model = model_cls(\n      params=model_params,\n      mode=tf.contrib.learn.ModeKeys.INFER)\n\n  # Load inference tasks\n  hooks = []\n  for tdict in FLAGS.tasks:\n    if not ""params"" in tdict:\n      tdict[""params""] = {}\n    task_cls = locate(tdict[""class""]) or getattr(tasks, tdict[""class""])\n    task = task_cls(tdict[""params""])\n    hooks.append(task)\n\n  # Create the graph used for inference\n  predictions, _, _ = create_inference_graph(\n      model=model,\n      input_pipeline=input_pipeline_infer,\n      batch_size=FLAGS.batch_size)\n\n  saver = tf.train.Saver()\n  checkpoint_path = FLAGS.checkpoint_path\n  if not checkpoint_path:\n    checkpoint_path = tf.train.latest_checkpoint(FLAGS.model_dir)\n\n  def session_init_op(_scaffold, sess):\n    saver.restore(sess, checkpoint_path)\n    tf.logging.info(""Restored model from %s"", checkpoint_path)\n\n  scaffold = tf.train.Scaffold(init_fn=session_init_op)\n  session_creator = tf.train.ChiefSessionCreator(scaffold=scaffold)\n  with tf.train.MonitoredSession(\n      session_creator=session_creator,\n      hooks=hooks) as sess:\n\n    # Run until the inputs are exhausted\n    while not sess.should_stop():\n      sess.run([])\n\nif __name__ == ""__main__"":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n'"
bin/train.py,31,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Main script to run training and evaluation of models.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport tempfile\n\nimport yaml\n\nimport tensorflow as tf\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.contrib.learn.python.learn.estimators import run_config\nfrom tensorflow import gfile\n\nfrom seq2seq import models\nfrom seq2seq.contrib.experiment import Experiment as PatchedExperiment\nfrom seq2seq.configurable import _maybe_load_yaml, _create_from_dict\nfrom seq2seq.configurable import _deep_merge_dict\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.metrics import metric_specs\nfrom seq2seq.training import hooks\nfrom seq2seq.training import utils as training_utils\n\ntf.flags.DEFINE_string(""config_paths"", """",\n                       """"""Path to a YAML configuration files defining FLAG\n                       values. Multiple files can be separated by commas.\n                       Files are merged recursively. Setting a key in these\n                       files is equivalent to setting the FLAG value with\n                       the same name."""""")\ntf.flags.DEFINE_string(""hooks"", ""[]"",\n                       """"""YAML configuration string for the\n                       training hooks to use."""""")\ntf.flags.DEFINE_string(""metrics"", ""[]"",\n                       """"""YAML configuration string for the\n                       training metrics to use."""""")\ntf.flags.DEFINE_string(""model"", """",\n                       """"""Name of the model class.\n                       Can be either a fully-qualified name, or the name\n                       of a class defined in `seq2seq.models`."""""")\ntf.flags.DEFINE_string(""model_params"", ""{}"",\n                       """"""YAML configuration string for the model\n                       parameters."""""")\n\ntf.flags.DEFINE_string(""input_pipeline_train"", ""{}"",\n                       """"""YAML configuration string for the training\n                       data input pipeline."""""")\ntf.flags.DEFINE_string(""input_pipeline_dev"", ""{}"",\n                       """"""YAML configuration string for the development\n                       data input pipeline."""""")\n\ntf.flags.DEFINE_string(""buckets"", None,\n                       """"""Buckets input sequences according to these length.\n                       A comma-separated list of sequence length buckets, e.g.\n                       ""10,20,30"" would result in 4 buckets:\n                       <10, 10-20, 20-30, >30. None disabled bucketing. """""")\ntf.flags.DEFINE_integer(""batch_size"", 16,\n                        """"""Batch size used for training and evaluation."""""")\ntf.flags.DEFINE_string(""output_dir"", None,\n                       """"""The directory to write model checkpoints and summaries\n                       to. If None, a local temporary directory is created."""""")\n\n# Training parameters\ntf.flags.DEFINE_string(""schedule"", ""continuous_train_and_eval"",\n                       """"""Estimator function to call, defaults to\n                       continuous_train_and_eval for local run"""""")\ntf.flags.DEFINE_integer(""train_steps"", None,\n                        """"""Maximum number of training steps to run.\n                         If None, train forever."""""")\ntf.flags.DEFINE_integer(""eval_every_n_steps"", 1000,\n                        ""Run evaluation on validation data every N steps."")\n\n# RunConfig Flags\ntf.flags.DEFINE_integer(""tf_random_seed"", None,\n                        """"""Random seed for TensorFlow initializers. Setting\n                        this value allows consistency between reruns."""""")\ntf.flags.DEFINE_integer(""save_checkpoints_secs"", None,\n                        """"""Save checkpoints every this many seconds.\n                        Can not be specified with save_checkpoints_steps."""""")\ntf.flags.DEFINE_integer(""save_checkpoints_steps"", None,\n                        """"""Save checkpoints every this many steps.\n                        Can not be specified with save_checkpoints_secs."""""")\ntf.flags.DEFINE_integer(""keep_checkpoint_max"", 5,\n                        """"""Maximum number of recent checkpoint files to keep.\n                        As new files are created, older files are deleted.\n                        If None or 0, all checkpoint files are kept."""""")\ntf.flags.DEFINE_integer(""keep_checkpoint_every_n_hours"", 4,\n                        """"""In addition to keeping the most recent checkpoint\n                        files, keep one checkpoint file for every N hours of\n                        training."""""")\ntf.flags.DEFINE_float(""gpu_memory_fraction"", 1.0,\n                      """"""Fraction of GPU memory used by the process on\n                      each GPU uniformly on the same machine."""""")\ntf.flags.DEFINE_boolean(""gpu_allow_growth"", False,\n                        """"""Allow GPU memory allocation to grow\n                        dynamically."""""")\ntf.flags.DEFINE_boolean(""log_device_placement"", False,\n                        """"""Log the op placement to devices"""""")\n\n\nFLAGS = tf.flags.FLAGS\n\ndef create_experiment(output_dir):\n  """"""\n  Creates a new Experiment instance.\n\n  Args:\n    output_dir: Output directory for model checkpoints and summaries.\n  """"""\n\n  config = run_config.RunConfig(\n      tf_random_seed=FLAGS.tf_random_seed,\n      save_checkpoints_secs=FLAGS.save_checkpoints_secs,\n      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n      keep_checkpoint_max=FLAGS.keep_checkpoint_max,\n      keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,\n      gpu_memory_fraction=FLAGS.gpu_memory_fraction)\n  config.tf_config.gpu_options.allow_growth = FLAGS.gpu_allow_growth\n  config.tf_config.log_device_placement = FLAGS.log_device_placement\n\n  train_options = training_utils.TrainOptions(\n      model_class=FLAGS.model,\n      model_params=FLAGS.model_params)\n  # On the main worker, save training options\n  if config.is_chief:\n    gfile.MakeDirs(output_dir)\n    train_options.dump(output_dir)\n\n  bucket_boundaries = None\n  if FLAGS.buckets:\n    bucket_boundaries = list(map(int, FLAGS.buckets.split("","")))\n\n  # Training data input pipeline\n  train_input_pipeline = input_pipeline.make_input_pipeline_from_def(\n      def_dict=FLAGS.input_pipeline_train,\n      mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  # Create training input function\n  train_input_fn = training_utils.create_input_fn(\n      pipeline=train_input_pipeline,\n      batch_size=FLAGS.batch_size,\n      bucket_boundaries=bucket_boundaries,\n      scope=""train_input_fn"")\n\n  # Development data input pipeline\n  dev_input_pipeline = input_pipeline.make_input_pipeline_from_def(\n      def_dict=FLAGS.input_pipeline_dev,\n      mode=tf.contrib.learn.ModeKeys.EVAL,\n      shuffle=False, num_epochs=1)\n\n  # Create eval input function\n  eval_input_fn = training_utils.create_input_fn(\n      pipeline=dev_input_pipeline,\n      batch_size=FLAGS.batch_size,\n      allow_smaller_final_batch=True,\n      scope=""dev_input_fn"")\n\n\n  def model_fn(features, labels, params, mode):\n    """"""Builds the model graph""""""\n    model = _create_from_dict({\n        ""class"": train_options.model_class,\n        ""params"": train_options.model_params\n    }, models, mode=mode)\n    return model(features, labels, params)\n\n  estimator = tf.contrib.learn.Estimator(\n      model_fn=model_fn,\n      model_dir=output_dir,\n      config=config,\n      params=FLAGS.model_params)\n\n  # Create hooks\n  train_hooks = []\n  for dict_ in FLAGS.hooks:\n    hook = _create_from_dict(\n        dict_, hooks,\n        model_dir=estimator.model_dir,\n        run_config=config)\n    train_hooks.append(hook)\n\n  # Create metrics\n  eval_metrics = {}\n  for dict_ in FLAGS.metrics:\n    metric = _create_from_dict(dict_, metric_specs)\n    eval_metrics[metric.name] = metric\n\n  experiment = PatchedExperiment(\n      estimator=estimator,\n      train_input_fn=train_input_fn,\n      eval_input_fn=eval_input_fn,\n      min_eval_frequency=FLAGS.eval_every_n_steps,\n      train_steps=FLAGS.train_steps,\n      eval_steps=None,\n      eval_metrics=eval_metrics,\n      train_monitors=train_hooks)\n\n  return experiment\n\n\ndef main(_argv):\n  """"""The entrypoint for the script""""""\n\n  # Parse YAML FLAGS\n  FLAGS.hooks = _maybe_load_yaml(FLAGS.hooks)\n  FLAGS.metrics = _maybe_load_yaml(FLAGS.metrics)\n  FLAGS.model_params = _maybe_load_yaml(FLAGS.model_params)\n  FLAGS.input_pipeline_train = _maybe_load_yaml(FLAGS.input_pipeline_train)\n  FLAGS.input_pipeline_dev = _maybe_load_yaml(FLAGS.input_pipeline_dev)\n\n  # Load flags from config file\n  final_config = {}\n  if FLAGS.config_paths:\n    for config_path in FLAGS.config_paths.split("",""):\n      config_path = config_path.strip()\n      if not config_path:\n        continue\n      config_path = os.path.abspath(config_path)\n      tf.logging.info(""Loading config from %s"", config_path)\n      with gfile.GFile(config_path.strip()) as config_file:\n        config_flags = yaml.load(config_file)\n        final_config = _deep_merge_dict(final_config, config_flags)\n\n  tf.logging.info(""Final Config:\\n%s"", yaml.dump(final_config))\n\n  # Merge flags with config values\n  for flag_key, flag_value in final_config.items():\n    if hasattr(FLAGS, flag_key) and isinstance(getattr(FLAGS, flag_key), dict):\n      merged_value = _deep_merge_dict(flag_value, getattr(FLAGS, flag_key))\n      setattr(FLAGS, flag_key, merged_value)\n    elif hasattr(FLAGS, flag_key):\n      setattr(FLAGS, flag_key, flag_value)\n    else:\n      tf.logging.warning(""Ignoring config flag: %s"", flag_key)\n\n  if FLAGS.save_checkpoints_secs is None \\\n    and FLAGS.save_checkpoints_steps is None:\n    FLAGS.save_checkpoints_secs = 600\n    tf.logging.info(""Setting save_checkpoints_secs to %d"",\n                    FLAGS.save_checkpoints_secs)\n\n  if not FLAGS.output_dir:\n    FLAGS.output_dir = tempfile.mkdtemp()\n\n  if not FLAGS.input_pipeline_train:\n    raise ValueError(""You must specify input_pipeline_train"")\n\n  if not FLAGS.input_pipeline_dev:\n    raise ValueError(""You must specify input_pipeline_dev"")\n\n  learn_runner.run(\n      experiment_fn=create_experiment,\n      output_dir=FLAGS.output_dir,\n      schedule=FLAGS.schedule)\n\n\nif __name__ == ""__main__"":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n'"
seq2seq/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nseq2seq library base module\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom seq2seq.graph_module import GraphModule\n\nfrom seq2seq import contrib\nfrom seq2seq import data\nfrom seq2seq import decoders\nfrom seq2seq import encoders\nfrom seq2seq import global_vars\nfrom seq2seq import graph_utils\nfrom seq2seq import inference\nfrom seq2seq import losses\nfrom seq2seq import metrics\nfrom seq2seq import models\nfrom seq2seq import test\nfrom seq2seq import training\n'"
seq2seq/configurable.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAbstract base class for objects that are configurable using\na parameters dictionary.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport copy\nfrom pydoc import locate\n\nimport six\nimport yaml\n\nimport tensorflow as tf\n\n\nclass abstractstaticmethod(staticmethod):  #pylint: disable=C0111,C0103\n  """"""Decorates a method as abstract and static""""""\n  __slots__ = ()\n\n  def __init__(self, function):\n    super(abstractstaticmethod, self).__init__(function)\n    function.__isabstractmethod__ = True\n\n  __isabstractmethod__ = True\n\n\ndef _create_from_dict(dict_, default_module, *args, **kwargs):\n  """"""Creates a configurable class from a dictionary. The dictionary must have\n  ""class"" and ""params"" properties. The class can be either fully qualified, or\n  it is looked up in the modules passed via `default_module`.\n  """"""\n  class_ = locate(dict_[""class""]) or getattr(default_module, dict_[""class""])\n  params = {}\n  if ""params"" in dict_:\n    params = dict_[""params""]\n  instance = class_(params, *args, **kwargs)\n  return instance\n\n\ndef _maybe_load_yaml(item):\n  """"""Parses `item` only if it is a string. If `item` is a dictionary\n  it is returned as-is.\n  """"""\n  if isinstance(item, six.string_types):\n    return yaml.load(item)\n  elif isinstance(item, dict):\n    return item\n  else:\n    raise ValueError(""Got {}, expected YAML string or dict"", type(item))\n\n\ndef _deep_merge_dict(dict_x, dict_y, path=None):\n  """"""Recursively merges dict_y into dict_x.\n  """"""\n  if path is None: path = []\n  for key in dict_y:\n    if key in dict_x:\n      if isinstance(dict_x[key], dict) and isinstance(dict_y[key], dict):\n        _deep_merge_dict(dict_x[key], dict_y[key], path + [str(key)])\n      elif dict_x[key] == dict_y[key]:\n        pass  # same leaf value\n      else:\n        dict_x[key] = dict_y[key]\n    else:\n      dict_x[key] = dict_y[key]\n  return dict_x\n\n\ndef _parse_params(params, default_params):\n  """"""Parses parameter values to the types defined by the default parameters.\n  Default parameters are used for missing values.\n  """"""\n  # Cast parameters to correct types\n  if params is None:\n    params = {}\n  result = copy.deepcopy(default_params)\n  for key, value in params.items():\n    # If param is unknown, drop it to stay compatible with past versions\n    if key not in default_params:\n      raise ValueError(""%s is not a valid model parameter"" % key)\n    # Param is a dictionary\n    if isinstance(value, dict):\n      default_dict = default_params[key]\n      if not isinstance(default_dict, dict):\n        raise ValueError(""%s should not be a dictionary"", key)\n      if default_dict:\n        value = _parse_params(value, default_dict)\n      else:\n        # If the default is an empty dict we do not typecheck it\n        # and assume it\'s done downstream\n        pass\n    if value is None:\n      continue\n    if default_params[key] is None:\n      result[key] = value\n    else:\n      result[key] = type(default_params[key])(value)\n  return result\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Configurable(object):\n  """"""Interface for all classes that are configurable\n  via a parameters dictionary.\n\n  Args:\n    params: A dictionary of parameters.\n    mode: A value in tf.contrib.learn.ModeKeys\n  """"""\n\n  def __init__(self, params, mode):\n    self._params = _parse_params(params, self.default_params())\n    self._mode = mode\n    self._print_params()\n\n  def _print_params(self):\n    """"""Logs parameter values""""""\n    classname = self.__class__.__name__\n    tf.logging.info(""Creating %s in mode=%s"", classname, self._mode)\n    tf.logging.info(""\\n%s"", yaml.dump({classname: self._params}))\n\n  @property\n  def mode(self):\n    """"""Returns a value in tf.contrib.learn.ModeKeys.\n    """"""\n    return self._mode\n\n  @property\n  def params(self):\n    """"""Returns a dictionary of parsed parameters.\n    """"""\n    return self._params\n\n  @abstractstaticmethod\n  def default_params():\n    """"""Returns a dictionary of default parameters. The default parameters\n    are used to define the expected type of passed parameters. Missing\n    parameter values are replaced with the defaults returned by this method.\n    """"""\n    raise NotImplementedError\n'"
seq2seq/global_vars.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of global variables.\n""""""\n\nSYNC_REPLICAS_OPTIMIZER = None\n'"
seq2seq/graph_module.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAll graph components that create Variables should inherit from this\nbase class defined in this file.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\nclass GraphModule(object):\n  """"""\n  Convenience class that makes it easy to share variables.\n  Each insance of this class creates its own set of variables, but\n  each subsequent execution of an instance will re-use its variables.\n\n  Graph components that define variables should inherit from this class\n  and implement their logic in the `_build` method.\n  """"""\n\n  def __init__(self, name):\n    """"""\n    Initialize the module. Each subclass must call this constructor with a name.\n\n    Args:\n      name: Name of this module. Used for `tf.make_template`.\n    """"""\n    self.name = name\n    self._template = tf.make_template(name, self._build, create_scope_now_=True)\n    # Docstrings for the class should be the docstring for the _build method\n    self.__doc__ = self._build.__doc__\n    # pylint: disable=E1101\n    self.__call__.__func__.__doc__ = self._build.__doc__\n\n  def _build(self, *args, **kwargs):\n    """"""Subclasses should implement their logic here.\n    """"""\n    raise NotImplementedError\n\n  def __call__(self, *args, **kwargs):\n    # pylint: disable=missing-docstring\n    return self._template(*args, **kwargs)\n\n  def variable_scope(self):\n    """"""Returns the proper variable scope for this module.\n    """"""\n    return tf.variable_scope(self._template.variable_scope)\n'"
seq2seq/graph_utils.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Miscellaneous utility function.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef templatemethod(name_):\n  """"""This decorator wraps a method with `tf.make_template`. For example,\n\n  @templatemethod\n  def my_method():\n    # Create variables\n  """"""\n\n  def template_decorator(func):\n    """"""Inner decorator function""""""\n\n    def func_wrapper(*args, **kwargs):\n      """"""Inner wrapper function""""""\n      templated_func = tf.make_template(name_, func)\n      return templated_func(*args, **kwargs)\n\n    return func_wrapper\n\n  return template_decorator\n\n\ndef add_dict_to_collection(dict_, collection_name):\n  """"""Adds a dictionary to a graph collection.\n\n  Args:\n    dict_: A dictionary of string keys to tensor values\n    collection_name: The name of the collection to add the dictionary to\n  """"""\n  key_collection = collection_name + ""_keys""\n  value_collection = collection_name + ""_values""\n  for key, value in dict_.items():\n    tf.add_to_collection(key_collection, key)\n    tf.add_to_collection(value_collection, value)\n\n\ndef get_dict_from_collection(collection_name):\n  """"""Gets a dictionary from a graph collection.\n\n  Args:\n    collection_name: A collection name to read a dictionary from\n\n  Returns:\n    A dictionary with string keys and tensor values\n  """"""\n  key_collection = collection_name + ""_keys""\n  value_collection = collection_name + ""_values""\n  keys = tf.get_collection(key_collection)\n  values = tf.get_collection(value_collection)\n  return dict(zip(keys, values))\n'"
seq2seq/losses.py,5,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Operations related to calculating sequence losses.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef cross_entropy_sequence_loss(logits, targets, sequence_length):\n  """"""Calculates the per-example cross-entropy loss for a sequence of logits and\n    masks out all losses passed the sequence length.\n\n  Args:\n    logits: Logits of shape `[T, B, vocab_size]`\n    targets: Target classes of shape `[T, B]`\n    sequence_length: An int32 tensor of shape `[B]` corresponding\n      to the length of each input\n\n  Returns:\n    A tensor of shape [T, B] that contains the loss per example, per time step.\n  """"""\n  with tf.name_scope(""cross_entropy_sequence_loss""):\n    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=targets)\n\n    # Mask out the losses we don\'t care about\n    loss_mask = tf.sequence_mask(\n        tf.to_int32(sequence_length), tf.to_int32(tf.shape(targets)[0]))\n    losses = losses * tf.transpose(tf.to_float(loss_mask), [1, 0])\n\n    return losses\n'"
bin/tools/generate_beam_viz.py,0,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Generate beam search visualization.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport json\nimport shutil\nfrom string import Template\nimport numpy as np\n\nimport networkx as nx\nfrom networkx.readwrite import json_graph\n\nPARSER = argparse.ArgumentParser(\n    description=""Generate beam search visualizations"")\nPARSER.add_argument(\n    ""-d"", ""--data"", type=str, required=True,\n    help=""path to the beam search data file"")\nPARSER.add_argument(\n    ""-o"", ""--output_dir"", type=str, required=True,\n    help=""path to the output directory"")\nPARSER.add_argument(\n    ""-v"", ""--vocab"", type=str, required=False,\n    help=""path to the vocabulary file"")\nARGS = PARSER.parse_args()\n\n\nHTML_TEMPLATE = Template(""""""\n<!DOCTYPE html>\n<html lang=""en"">\n  <head>\n    <meta charset=""utf-8"">\n    <title>Beam Search</title>\n    <link rel=""stylesheet"" type=""text/css"" href=""tree.css"">\n    <script src=""http://d3js.org/d3.v3.min.js""></script>\n  </head>\n  <body>\n    <script>\n      var treeData = $DATA\n    </script>\n    <script src=""tree.js""></script>\n  </body>\n</html>"""""")\n\n\ndef _add_graph_level(graph, level, parent_ids, names, scores):\n  """"""Adds a levelto the passed graph""""""\n  for i, parent_id in enumerate(parent_ids):\n    new_node = (level, i)\n    parent_node = (level - 1, parent_id)\n    graph.add_node(new_node)\n    graph.node[new_node][""name""] = names[i]\n    graph.node[new_node][""score""] = str(scores[i])\n    graph.node[new_node][""size""] = 100\n    # Add an edge to the parent\n    graph.add_edge(parent_node, new_node)\n\ndef create_graph(predicted_ids, parent_ids, scores, vocab=None):\n  def get_node_name(pred):\n    return vocab[pred] if vocab else str(pred)\n\n  seq_length = predicted_ids.shape[0]\n  graph = nx.DiGraph()\n  for level in range(seq_length):\n    names = [get_node_name(pred) for pred in predicted_ids[level]]\n    _add_graph_level(graph, level + 1, parent_ids[level], names, scores[level])\n  graph.node[(0, 0)][""name""] = ""START""\n  return graph\n\n\ndef main():\n  beam_data = np.load(ARGS.data)\n\n  # Optionally load vocabulary data\n  vocab = None\n  if ARGS.vocab:\n    with open(ARGS.vocab) as file:\n      vocab = file.readlines()\n    vocab = [_.strip() for _ in vocab]\n    vocab += [""UNK"", ""SEQUENCE_START"", ""SEQUENCE_END""]\n\n  if not os.path.exists(ARGS.output_dir):\n    os.makedirs(ARGS.output_dir)\n\n  # Copy required files\n  shutil.copy2(""./bin/tools/beam_search_viz/tree.css"", ARGS.output_dir)\n  shutil.copy2(""./bin/tools/beam_search_viz/tree.js"", ARGS.output_dir)\n\n  for idx in range(len(beam_data[""predicted_ids""])):\n    predicted_ids = beam_data[""predicted_ids""][idx]\n    parent_ids = beam_data[""beam_parent_ids""][idx]\n    scores = beam_data[""scores""][idx]\n\n    graph = create_graph(\n        predicted_ids=predicted_ids,\n        parent_ids=parent_ids,\n        scores=scores,\n        vocab=vocab)\n\n    json_str = json.dumps(\n        json_graph.tree_data(graph, (0, 0)),\n        ensure_ascii=False)\n\n    html_str = HTML_TEMPLATE.substitute(DATA=json_str)\n    output_path = os.path.join(ARGS.output_dir, ""{:06d}.html"".format(idx))\n    with open(output_path, ""w"") as file:\n      file.write(html_str)\n    print(output_path)\n\n\nif __name__ == ""__main__"":\n  main()'"
bin/tools/generate_toy_data.py,0,"b'#! /usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nFunctions to generate various toy datasets.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport numpy as np\nimport io\n\nPARSER = argparse.ArgumentParser(description=""Generates toy datasets."")\nPARSER.add_argument(\n    ""--vocab_size"", type=int, default=100, help=""size of the vocabulary"")\nPARSER.add_argument(\n    ""--num_examples"", type=int, default=10000, help=""number of examples"")\nPARSER.add_argument(\n    ""--min_len"", type=int, default=5, help=""minimum sequence length"")\nPARSER.add_argument(\n    ""--max_len"", type=int, default=40, help=""maximum sequence length"")\nPARSER.add_argument(\n    ""--type"",\n    type=str,\n    default=""copy"",\n    choices=[""copy"", ""reverse""],\n    help=""Type of dataet to generate. One of \\""copy\\"" or \\""reverse\\"""")\nPARSER.add_argument(\n    ""--output_dir"",\n    type=str,\n    help=""path to the output directory"",\n    required=True)\nARGS = PARSER.parse_args()\n\nVOCABULARY = list([str(x) for x in range(ARGS.vocab_size - 1)])\nVOCABULARY += [""\xe7\xac\x91""]\n\n\ndef make_copy(num_examples, min_len, max_len):\n  """"""\n  Generates a dataset where the target is equal to the source.\n  Sequence lengths are chosen randomly from [min_len, max_len].\n\n  Args:\n    num_examples: Number of examples to generate\n    min_len: Minimum sequence length\n    max_len: Maximum sequence length\n\n  Returns:\n    An iterator of (source, target) string tuples.\n  """"""\n  for _ in range(num_examples):\n    turn_length = np.random.choice(np.arange(min_len, max_len + 1))\n    source_tokens = np.random.choice(\n        list(VOCABULARY), size=turn_length, replace=True)\n    target_tokens = source_tokens\n    yield "" "".join(source_tokens), "" "".join(target_tokens)\n\n\ndef make_reverse(num_examples, min_len, max_len):\n  """"""\n  Generates a dataset where the target is equal to the source reversed.\n  Sequence lengths are chosen randomly from [min_len, max_len].\n\n  Args:\n    num_examples: Number of examples to generate\n    min_len: Minimum sequence length\n    max_len: Maximum sequence length\n\n  Returns:\n    An iterator of (source, target) string tuples.\n  """"""\n  for _ in range(num_examples):\n    turn_length = np.random.choice(np.arange(min_len, max_len + 1))\n    source_tokens = np.random.choice(\n        list(VOCABULARY), size=turn_length, replace=True)\n    target_tokens = source_tokens[::-1]\n    yield "" "".join(source_tokens), "" "".join(target_tokens)\n\n\ndef write_parallel_text(sources, targets, output_prefix):\n  """"""\n  Writes two files where each line corresponds to one example\n    - [output_prefix].sources.txt\n    - [output_prefix].targets.txt\n\n  Args:\n    sources: Iterator of source strings\n    targets: Iterator of target strings\n    output_prefix: Prefix for the output file\n  """"""\n  source_filename = os.path.abspath(os.path.join(output_prefix, ""sources.txt""))\n  target_filename = os.path.abspath(os.path.join(output_prefix, ""targets.txt""))\n\n  with io.open(source_filename, ""w"", encoding=\'utf8\') as source_file:\n    for record in sources:\n      source_file.write(record + ""\\n"")\n  print(""Wrote {}"".format(source_filename))\n\n  with io.open(target_filename, ""w"", encoding=\'utf8\') as target_file:\n    for record in targets:\n      target_file.write(record + ""\\n"")\n  print(""Wrote {}"".format(target_filename))\n\n\ndef main():\n  """"""Main function""""""\n\n  if ARGS.type == ""copy"":\n    generate_fn = make_copy\n  elif ARGS.type == ""reverse"":\n    generate_fn = make_reverse\n\n  # Generate dataset\n  examples = list(generate_fn(ARGS.num_examples, ARGS.min_len, ARGS.max_len))\n  try:\n    os.makedirs(ARGS.output_dir)\n  except OSError:\n    if not os.path.isdir(ARGS.output_dir):\n      raise\n\n  # Write train data\n  train_sources, train_targets = zip(*examples)\n  write_parallel_text(train_sources, train_targets, ARGS.output_dir)\n\n\nif __name__ == ""__main__"":\n  main()\n'"
bin/tools/generate_vocab.py,0,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#pylint: disable=invalid-name\n""""""\nGenerate vocabulary for a tokenized text file.\n""""""\n\nimport sys\nimport argparse\nimport collections\nimport logging\n\nparser = argparse.ArgumentParser(\n    description=""Generate vocabulary for a tokenized text file."")\nparser.add_argument(\n    ""--min_frequency"",\n    dest=""min_frequency"",\n    type=int,\n    default=0,\n    help=""Minimum frequency of a word to be included in the vocabulary."")\nparser.add_argument(\n    ""--max_vocab_size"",\n    dest=""max_vocab_size"",\n    type=int,\n    help=""Maximum number of tokens in the vocabulary"")\nparser.add_argument(\n    ""--downcase"",\n    dest=""downcase"",\n    type=bool,\n    help=""If set to true, downcase all text before processing."",\n    default=False)\nparser.add_argument(\n    ""infile"",\n    nargs=""?"",\n    type=argparse.FileType(""r""),\n    default=sys.stdin,\n    help=""Input tokenized text file to be processed."")\nparser.add_argument(\n    ""--delimiter"",\n    dest=""delimiter"",\n    type=str,\n    default="" "",\n    help=""Delimiter character for tokenizing. Use \\"" \\"" and \\""\\"" for word and char level respectively.""\n)\nargs = parser.parse_args()\n\n# Counter for all tokens in the vocabulary\ncnt = collections.Counter()\n\nfor line in args.infile:\n  if args.downcase:\n    line = line.lower()\n  if args.delimiter == """":\n    tokens = list(line.strip())\n  else:\n    tokens = line.strip().split(args.delimiter)\n  tokens = [_ for _ in tokens if len(_) > 0]\n  cnt.update(tokens)\n\nlogging.info(""Found %d unique tokens in the vocabulary."", len(cnt))\n\n# Filter tokens below the frequency threshold\nif args.min_frequency > 0:\n  filtered_tokens = [(w, c) for w, c in cnt.most_common()\n                     if c > args.min_frequency]\n  cnt = collections.Counter(dict(filtered_tokens))\n\nlogging.info(""Found %d unique tokens with frequency > %d."",\n             len(cnt), args.min_frequency)\n\n# Sort tokens by 1. frequency 2. lexically to break ties\nword_with_counts = cnt.most_common()\nword_with_counts = sorted(\n    word_with_counts, key=lambda x: (x[1], x[0]), reverse=True)\n\n# Take only max-vocab\nif args.max_vocab_size is not None:\n  word_with_counts = word_with_counts[:args.max_vocab_size]\n\nfor word, count in word_with_counts:\n  print(""{}\\t{}"".format(word, count))\n'"
bin/tools/profile.py,7,"b'#! /usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"""""" Script to generates model profiling information\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport six\n\n#pylint: disable=E0611\nfrom google.protobuf import text_format\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tfprof import model_analyzer\nfrom tensorflow.contrib.tfprof.python.tools.tfprof import tfprof_logger\nfrom tensorflow import gfile\nfrom tensorflow.tools.tfprof import tfprof_log_pb2\nfrom tensorflow.python.framework import op_def_registry # pylint: disable=E0611\nfrom tensorflow.python.framework.ops import RegisterShape # pylint: disable=E0611\nfrom tensorflow.python.framework import common_shapes # pylint: disable=E0611\n\n# Import custom ops\nfrom seq2seq.decoders.attention import att_sum_bahdanau, att_sum_dot\n\n\ntf.flags.DEFINE_string(""model_dir"", None, ""path to model directory"")\n\nFLAGS = tf.flags.FLAGS\nCUSTOM_OP_FUNCTIONS = [att_sum_bahdanau, att_sum_dot]\n\ndef _register_function_ops(func_list):\n  """"""Registers custom ops in the default graph. This is needed\n  Because our checkpoint is saved with ops that are not part of Tensorflow.""""""\n  op_dict = op_def_registry.get_registered_ops()\n  for func in func_list:\n    #pylint: disable=W0212\n    func._create_definition_if_needed()\n    op_def = func._definition.signature\n    op_dict[op_def.name] = op_def\n    RegisterShape(op_def.name)(common_shapes.unknown_shape)\n\ndef load_metadata(model_dir):\n  """"""Loads RunMetadata, Graph and OpLog from files\n  """"""\n  # Import RunMetadata\n  run_meta_path = os.path.join(model_dir, ""metadata/run_meta"")\n  run_meta = tf.RunMetadata()\n  if gfile.Exists(run_meta_path):\n    with gfile.GFile(run_meta_path, ""rb"") as file:\n      run_meta.MergeFromString(file.read())\n    print(""Loaded RunMetadata from {}"".format(run_meta_path))\n  else:\n    print(""RunMetadata does not exist a {}. Skipping."".format(run_meta_path))\n\n  # Import Graph\n  graph_def_path = os.path.join(model_dir, ""graph.pbtxt"")\n  graph = tf.Graph()\n  if gfile.Exists(graph_def_path):\n    with graph.as_default():\n      _register_function_ops(CUSTOM_OP_FUNCTIONS)\n      graph_def = tf.GraphDef()\n      with gfile.GFile(graph_def_path, ""rb"") as file:\n        text_format.Parse(file.read(), graph_def)\n      tf.import_graph_def(graph_def, name="""")\n      print(""Loaded Graph from {}"".format(graph_def_path))\n  else:\n    print(""Graph does not exist a {}. Skipping."".format(graph_def_path))\n\n  # Import OpLog\n  op_log_path = os.path.join(model_dir, ""metadata/tfprof_log"")\n  op_log = tfprof_log_pb2.OpLog()\n  if gfile.Exists(op_log_path):\n    with gfile.GFile(op_log_path, ""rb"") as file:\n      op_log.MergeFromString(file.read())\n      print(""Loaded OpLog from {}"".format(op_log_path))\n  else:\n    print(""OpLog does not exist a {}. Skipping."".format(op_log_path))\n\n  return run_meta, graph, op_log\n\n\ndef merge_default_with_oplog(graph, op_log=None, run_meta=None):\n  """"""Monkeypatch. There currently is a bug in tfprof_logger that\n    prevents it from being used with Python 3. So we override the method\n    manually until the fix comes in.\n  """"""\n  tmp_op_log = tfprof_log_pb2.OpLog()\n  # pylint: disable=W0212\n  logged_ops = tfprof_logger._get_logged_ops(graph, run_meta)\n  if not op_log:\n    tmp_op_log.log_entries.extend(logged_ops.values())\n  else:\n    all_ops = dict()\n    for entry in op_log.log_entries:\n      all_ops[entry.name] = entry\n    for op_name, entry in six.iteritems(logged_ops):\n      if op_name in all_ops:\n        all_ops[op_name].types.extend(entry.types)\n        if entry.float_ops > 0 and all_ops[op_name].float_ops == 0:\n          all_ops[op_name].float_ops = entry.float_ops\n      else:\n        all_ops[op_name] = entry\n    tmp_op_log.log_entries.extend(all_ops.values())\n  return tmp_op_log\n\n\ndef param_analysis_options(output_dir):\n  """"""Options for model parameter analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""params"", ""bytes""]\n  options[""order_by""] = ""params""\n  options[""account_type_regexes""] = [""Variable""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""params.txt"")\n  return ""scope"", options\n\n\ndef micro_anaylsis_options(output_dir):\n  """"""Options for microsecond analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""micros"", ""device""]\n  options[""min_micros""] = 1000\n  options[""account_type_regexes""] = ["".*""]\n  options[""order_by""] = ""micros""\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""micro.txt"")\n  return ""graph"", options\n\n\ndef flops_analysis_options(output_dir):\n  """"""Options for FLOPS analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""float_ops"", ""micros"", ""device""]\n  options[""min_float_ops""] = 1\n  options[""order_by""] = ""float_ops""\n  options[""account_type_regexes""] = ["".*""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""flops.txt"")\n  return ""scope"", options\n\n\ndef device_analysis_options(output_dir):\n  """"""Options for device placement analysis\n  """"""\n  options = model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS.copy()\n  options[""select""] = [""device"", ""float_ops"", ""micros""]\n  options[""order_by""] = ""name""\n  options[""account_type_regexes""] = ["".*""]\n  if output_dir:\n    options[""dump_to_file""] = os.path.join(output_dir, ""device.txt"")\n  return ""scope"", options\n\n\ndef main(_argv):\n  """"""Main functions. Runs all anaylses.""""""\n  # pylint: disable=W0212\n  tfprof_logger._merge_default_with_oplog = merge_default_with_oplog\n\n  FLAGS.model_dir = os.path.abspath(os.path.expanduser(FLAGS.model_dir))\n  output_dir = os.path.join(FLAGS.model_dir, ""profile"")\n  gfile.MakeDirs(output_dir)\n\n  run_meta, graph, op_log = load_metadata(FLAGS.model_dir)\n\n  param_arguments = [\n      param_analysis_options(output_dir),\n      micro_anaylsis_options(output_dir),\n      flops_analysis_options(output_dir),\n      device_analysis_options(output_dir),\n  ]\n\n  for tfprof_cmd, params in param_arguments:\n    model_analyzer.print_model_analysis(\n        graph=graph,\n        run_meta=run_meta,\n        op_log=op_log,\n        tfprof_cmd=tfprof_cmd,\n        tfprof_options=params)\n\n    if params[""dump_to_file""] != """":\n      print(""Wrote {}"".format(params[""dump_to_file""]))\n\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
seq2seq/contrib/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
seq2seq/contrib/experiment.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""A patched tf.learn Experiment class to handle GPU memory\nsharing issues.\n""""""\n\nimport tensorflow as tf\n\nclass Experiment(tf.contrib.learn.Experiment):\n  """"""A patched tf.learn Experiment class to handle GPU memory\n  sharing issues.""""""\n\n  def __init__(self, train_steps_per_iteration=None, *args, **kwargs):\n    super(Experiment, self).__init__(*args, **kwargs)\n    self._train_steps_per_iteration = train_steps_per_iteration\n\n  def _has_training_stopped(self, eval_result):\n    """"""Determines whether the training has stopped.""""""\n    if not eval_result:\n      return False\n\n    global_step = eval_result.get(tf.GraphKeys.GLOBAL_STEP)\n    return global_step and self._train_steps and (\n        global_step >= self._train_steps)\n\n  def continuous_train_and_eval(self,\n                                continuous_eval_predicate_fn=None):\n    """"""Interleaves training and evaluation.\n\n    The frequency of evaluation is controlled by the `train_steps_per_iteration`\n    (via constructor). The model will be first trained for\n    `train_steps_per_iteration`, and then be evaluated in turns.\n\n    This differs from `train_and_evaluate` as follows:\n      1. The procedure will have train and evaluation in turns. The model\n      will be trained for a number of steps (usuallly smaller than `train_steps`\n      if provided) and then be evaluated.  `train_and_evaluate` will train the\n      model for `train_steps` (no small training iteraions).\n\n      2. Due to the different approach this schedule takes, it leads to two\n      differences in resource control. First, the resources (e.g., memory) used\n      by training will be released before evaluation (`train_and_evaluate` takes\n      double resources). Second, more checkpoints will be saved as a checkpoint\n      is generated at the end of each small trainning iteration.\n\n    Args:\n      continuous_eval_predicate_fn: A predicate function determining whether to\n        continue after each iteration. `predicate_fn` takes the evaluation\n        results as its arguments. At the beginning of evaluation, the passed\n        eval results will be None so it\'s expected that the predicate function\n        handles that gracefully. When `predicate_fn` is not specified, this will\n        run in an infinite loop or exit when global_step reaches `train_steps`.\n\n    Returns:\n      A tuple of the result of the `evaluate` call to the `Estimator` and the\n      export results using the specified `ExportStrategy`.\n\n    Raises:\n      ValueError: if `continuous_eval_predicate_fn` is neither None nor\n        callable.\n    """"""\n\n    if (continuous_eval_predicate_fn is not None and\n        not callable(continuous_eval_predicate_fn)):\n      raise ValueError(\n          ""`continuous_eval_predicate_fn` must be a callable, or None."")\n\n    eval_result = None\n\n    # Set the default value for train_steps_per_iteration, which will be\n    # overriden by other settings.\n    train_steps_per_iteration = 1000\n    if self._train_steps_per_iteration is not None:\n      train_steps_per_iteration = self._train_steps_per_iteration\n    elif self._train_steps is not None:\n      # train_steps_per_iteration = int(self._train_steps / 10)\n      train_steps_per_iteration = min(\n          self._min_eval_frequency, self._train_steps)\n \n    while (not continuous_eval_predicate_fn or\n           continuous_eval_predicate_fn(eval_result)):\n\n      if self._has_training_stopped(eval_result):\n        # Exits once max steps of training is satisfied.\n        tf.logging.info(""Stop training model as max steps reached"")\n        break\n      \n      tf.logging.info(""Training model for %s steps"", train_steps_per_iteration)\n      self._estimator.fit(\n          input_fn=self._train_input_fn,\n          steps=train_steps_per_iteration,\n          monitors=self._train_monitors)\n\n      tf.logging.info(""Evaluating model now."")\n      eval_result = self._estimator.evaluate(\n          input_fn=self._eval_input_fn,\n          steps=self._eval_steps,\n          metrics=self._eval_metrics,\n          name=""one_pass"",\n          hooks=self._eval_hooks)\n\n    return eval_result, self._maybe_export(eval_result)\n'"
seq2seq/contrib/rnn_cell.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of RNN Cells\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport sys\nimport inspect\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import array_ops  # pylint: disable=E0611\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\nfrom tensorflow.contrib.rnn import MultiRNNCell  # pylint: disable=E0611\n\n# Import all cell classes from Tensorflow\nTF_CELL_CLASSES = [\n    x for x in tf.contrib.rnn.__dict__.values()\n    if inspect.isclass(x) and issubclass(x, tf.contrib.rnn.RNNCell)\n]\nfor cell_class in TF_CELL_CLASSES:\n  setattr(sys.modules[__name__], cell_class.__name__, cell_class)\n\n\nclass ExtendedMultiRNNCell(MultiRNNCell):\n  """"""Extends the Tensorflow MultiRNNCell with residual connections""""""\n\n  def __init__(self,\n               cells,\n               residual_connections=False,\n               residual_combiner=""add"",\n               residual_dense=False):\n    """"""Create a RNN cell composed sequentially of a number of RNNCells.\n\n    Args:\n      cells: list of RNNCells that will be composed in this order.\n      state_is_tuple: If True, accepted and returned states are n-tuples, where\n        `n = len(cells)`.  If False, the states are all\n        concatenated along the column axis.  This latter behavior will soon be\n        deprecated.\n      residual_connections: If true, add residual connections between all cells.\n        This requires all cells to have the same output_size. Also, iff the\n        input size is not equal to the cell output size, a linear transform\n        is added before the first layer.\n      residual_combiner: One of ""add"" or ""concat"". To create inputs for layer\n        t+1 either ""add"" the inputs from the prev layer or concat them.\n      residual_dense: Densely connect each layer to all other layers\n\n    Raises:\n      ValueError: if cells is empty (not allowed), or at least one of the cells\n        returns a state tuple but the flag `state_is_tuple` is `False`.\n    """"""\n    super(ExtendedMultiRNNCell, self).__init__(cells, state_is_tuple=True)\n    assert residual_combiner in [""add"", ""concat"", ""mean""]\n\n    self._residual_connections = residual_connections\n    self._residual_combiner = residual_combiner\n    self._residual_dense = residual_dense\n\n  def __call__(self, inputs, state, scope=None):\n    """"""Run this multi-layer cell on inputs, starting from state.""""""\n    if not self._residual_connections:\n      return super(ExtendedMultiRNNCell, self).__call__(\n          inputs, state, (scope or ""extended_multi_rnn_cell""))\n\n    with tf.variable_scope(scope or ""extended_multi_rnn_cell""):\n      # Adding Residual connections are only possible when input and output\n      # sizes are equal. Optionally transform the initial inputs to\n      # `cell[0].output_size`\n      if self._cells[0].output_size != inputs.get_shape().as_list()[1] and \\\n          (self._residual_combiner in [""add"", ""mean""]):\n        inputs = tf.contrib.layers.fully_connected(\n            inputs=inputs,\n            num_outputs=self._cells[0].output_size,\n            activation_fn=None,\n            scope=""input_transform"")\n\n      # Iterate through all layers (code from MultiRNNCell)\n      cur_inp = inputs\n      prev_inputs = [cur_inp]\n      new_states = []\n      for i, cell in enumerate(self._cells):\n        with tf.variable_scope(""cell_%d"" % i):\n          if not nest.is_sequence(state):\n            raise ValueError(\n                ""Expected state to be a tuple of length %d, but received: %s"" %\n                (len(self.state_size), state))\n          cur_state = state[i]\n          next_input, new_state = cell(cur_inp, cur_state)\n\n          # Either combine all previous inputs or only the current input\n          input_to_combine = prev_inputs[-1:]\n          if self._residual_dense:\n            input_to_combine = prev_inputs\n\n          # Add Residual connection\n          if self._residual_combiner == ""add"":\n            next_input = next_input + sum(input_to_combine)\n          if self._residual_combiner == ""mean"":\n            combined_mean = tf.reduce_mean(tf.stack(input_to_combine), 0)\n            next_input = next_input + combined_mean\n          elif self._residual_combiner == ""concat"":\n            next_input = tf.concat([next_input] + input_to_combine, 1)\n          cur_inp = next_input\n          prev_inputs.append(cur_inp)\n\n          new_states.append(new_state)\n    new_states = (tuple(new_states)\n                  if self._state_is_tuple else array_ops.concat(new_states, 1))\n    return cur_inp, new_states\n'"
seq2seq/data/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of input-related utlities.\n""""""\n\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.data import parallel_data_provider\nfrom seq2seq.data import postproc\nfrom seq2seq.data import split_tokens_decoder\nfrom seq2seq.data import vocab\n'"
seq2seq/data/input_pipeline.py,28,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of input pipelines.\n\nAn input pipeline defines how to read and parse data. It produces a tuple\nof (features, labels) that can be read by tf.learn estimators.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport sys\n\nimport six\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\n\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.data import split_tokens_decoder, parallel_data_provider\nfrom seq2seq.data.sequence_example_decoder import TFSEquenceExampleDecoder\n\n\ndef make_input_pipeline_from_def(def_dict, mode, **kwargs):\n  """"""Creates an InputPipeline object from a dictionary definition.\n\n  Args:\n    def_dict: A dictionary defining the input pipeline.\n      It must have ""class"" and ""params"" that correspond to the class\n      name and constructor parameters of an InputPipeline, respectively.\n    mode: A value in tf.contrib.learn.ModeKeys\n\n  Returns:\n    A new InputPipeline object\n  """"""\n  if not ""class"" in def_dict:\n    raise ValueError(""Input Pipeline definition must have a class property."")\n\n  class_ = def_dict[""class""]\n  if not hasattr(sys.modules[__name__], class_):\n    raise ValueError(""Invalid Input Pipeline class: {}"".format(class_))\n\n  pipeline_class = getattr(sys.modules[__name__], class_)\n\n  # Constructor arguments\n  params = {}\n  if ""params"" in def_dict:\n    params.update(def_dict[""params""])\n  params.update(kwargs)\n\n  return pipeline_class(params=params, mode=mode)\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass InputPipeline(Configurable):\n  """"""Abstract InputPipeline class. All input pipelines must inherit from this.\n  An InputPipeline defines how data is read, parsed, and separated into\n  features and labels.\n\n  Params:\n    shuffle: If true, shuffle the data.\n    num_epochs: Number of times to iterate through the dataset. If None,\n      iterate forever.\n  """"""\n\n  def __init__(self, params, mode):\n    Configurable.__init__(self, params, mode)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""shuffle"": True,\n        ""num_epochs"": None,\n    }\n\n  def make_data_provider(self, **kwargs):\n    """"""Creates DataProvider instance for this input pipeline. Additional\n    keyword arguments are passed to the DataProvider.\n    """"""\n    raise NotImplementedError(""Not implemented."")\n\n  @property\n  def feature_keys(self):\n    """"""Defines the features that this input pipeline provides. Returns\n      a set of strings.\n    """"""\n    return set()\n\n  @property\n  def label_keys(self):\n    """"""Defines the labels that this input pipeline provides. Returns\n      a set of strings.\n    """"""\n    return set()\n\n  @staticmethod\n  def read_from_data_provider(data_provider):\n    """"""Utility function to read all available items from a DataProvider.\n    """"""\n    item_values = data_provider.get(list(data_provider.list_items()))\n    items_dict = dict(zip(data_provider.list_items(), item_values))\n    return items_dict\n\n\nclass ParallelTextInputPipeline(InputPipeline):\n  """"""An input pipeline that reads two parallel (line-by-line aligned) text\n  files.\n\n  Params:\n    source_files: An array of file names for the source data.\n    target_files: An array of file names for the target data. These must\n      be aligned to the `source_files`.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""source_files"": [],\n        ""target_files"": [],\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" "",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n    decoder_source = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""source_delimiter""])\n\n    dataset_source = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""source_files""],\n        reader=tf.TextLineReader,\n        decoder=decoder_source,\n        num_samples=None,\n        items_to_descriptions={})\n\n    dataset_target = None\n    if len(self.params[""target_files""]) > 0:\n      decoder_target = split_tokens_decoder.SplitTokensDecoder(\n          tokens_feature_name=""target_tokens"",\n          length_feature_name=""target_len"",\n          prepend_token=""SEQUENCE_START"",\n          append_token=""SEQUENCE_END"",\n          delimiter=self.params[""target_delimiter""])\n\n      dataset_target = tf.contrib.slim.dataset.Dataset(\n          data_sources=self.params[""target_files""],\n          reader=tf.TextLineReader,\n          decoder=decoder_target,\n          num_samples=None,\n          items_to_descriptions={})\n\n    return parallel_data_provider.ParallelDataProvider(\n        dataset1=dataset_source,\n        dataset2=dataset_target,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""source_tokens"", ""source_len""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_len""])\n\nclass ParallelTextInputPipelineFairseq(InputPipeline):\n  """"""An input pipeline that reads two parallel (line-by-line aligned) text\n  files.\n\n  Params:\n    source_files: An array of file names for the source data.\n    target_files: An array of file names for the target data. These must\n      be aligned to the `source_files`.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""source_files"": [],\n        ""target_files"": [],\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" "",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n    decoder_source = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""source_delimiter""])\n\n    dataset_source = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""source_files""],\n        reader=tf.TextLineReader,\n        decoder=decoder_source,\n        num_samples=None,\n        items_to_descriptions={})\n\n    dataset_target = None\n    if len(self.params[""target_files""]) > 0:\n      decoder_target = split_tokens_decoder.SplitTokensDecoder(\n          tokens_feature_name=""target_tokens"",\n          length_feature_name=""target_len"",\n          prepend_token=""SEQUENCE_END"",\n          append_token=""SEQUENCE_END"",\n          delimiter=self.params[""target_delimiter""])\n\n      dataset_target = tf.contrib.slim.dataset.Dataset(\n          data_sources=self.params[""target_files""],\n          reader=tf.TextLineReader,\n          decoder=decoder_target,\n          num_samples=None,\n          items_to_descriptions={})\n\n    return parallel_data_provider.ParallelDataProvider(\n        dataset1=dataset_source,\n        dataset2=dataset_target,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""source_tokens"", ""source_len""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_len""])\n\n\nclass TFRecordInputPipeline(InputPipeline):\n  """"""An input pipeline that reads a TFRecords containing both source\n  and target sequences.\n\n  Params:\n    files: An array of file names to read from.\n    source_field: The TFRecord feature field containing the source text.\n    target_field: The TFRecord feature field containing the target text.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""files"": [],\n        ""source_field"": ""source"",\n        ""target_field"": ""target"",\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" "",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n\n    splitter_source = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""source_delimiter""])\n\n    splitter_target = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""target_tokens"",\n        length_feature_name=""target_len"",\n        prepend_token=""SEQUENCE_START"",\n        append_token=""SEQUENCE_END"",\n        delimiter=self.params[""target_delimiter""])\n\n    keys_to_features = {\n        self.params[""source_field""]: tf.FixedLenFeature((), tf.string),\n        self.params[""target_field""]: tf.FixedLenFeature(\n            (), tf.string, default_value="""")\n    }\n\n    items_to_handlers = {}\n    items_to_handlers[""source_tokens""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""source_field""]],\n        func=lambda dict: splitter_source.decode(\n            dict[self.params[""source_field""]], [""source_tokens""])[0])\n    items_to_handlers[""source_len""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""source_field""]],\n        func=lambda dict: splitter_source.decode(\n            dict[self.params[""source_field""]], [""source_len""])[0])\n    items_to_handlers[""target_tokens""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""target_field""]],\n        func=lambda dict: splitter_target.decode(\n            dict[self.params[""target_field""]], [""target_tokens""])[0])\n    items_to_handlers[""target_len""] = tfexample_decoder.ItemHandlerCallback(\n        keys=[self.params[""target_field""]],\n        func=lambda dict: splitter_target.decode(\n            dict[self.params[""target_field""]], [""target_len""])[0])\n\n    decoder = tfexample_decoder.TFExampleDecoder(keys_to_features,\n                                                 items_to_handlers)\n\n    dataset = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""files""],\n        reader=tf.TFRecordReader,\n        decoder=decoder,\n        num_samples=None,\n        items_to_descriptions={})\n\n    return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(\n        dataset=dataset,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""source_tokens"", ""source_len""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_len""])\n\n\nclass ImageCaptioningInputPipeline(InputPipeline):\n  """"""An input pipeline that reads a TFRecords containing both source\n  and target sequences.\n\n  Params:\n    files: An array of file names to read from.\n    source_field: The TFRecord feature field containing the source text.\n    target_field: The TFRecord feature field containing the target text.\n    source_delimiter: A character to split the source text on. Defaults\n      to  "" "" (space). For character-level training this can be set to the\n      empty string.\n    target_delimiter: Same as `source_delimiter` but for the target text.\n  """"""\n\n  @staticmethod\n  def default_params():\n    params = InputPipeline.default_params()\n    params.update({\n        ""files"": [],\n        ""image_field"": ""image/data"",\n        ""image_format"": ""jpg"",\n        ""caption_ids_field"": ""image/caption_ids"",\n        ""caption_tokens_field"": ""image/caption"",\n    })\n    return params\n\n  def make_data_provider(self, **kwargs):\n\n    context_keys_to_features = {\n        self.params[""image_field""]: tf.FixedLenFeature(\n            [], dtype=tf.string),\n        ""image/format"": tf.FixedLenFeature(\n            [], dtype=tf.string, default_value=self.params[""image_format""]),\n    }\n\n    sequence_keys_to_features = {\n        self.params[""caption_ids_field""]: tf.FixedLenSequenceFeature(\n            [], dtype=tf.int64),\n        self.params[""caption_tokens_field""]: tf.FixedLenSequenceFeature(\n            [], dtype=tf.string)\n    }\n\n    items_to_handlers = {\n        ""image"": tfexample_decoder.Image(\n            image_key=self.params[""image_field""],\n            format_key=""image/format"",\n            channels=3),\n        ""target_ids"":\n        tfexample_decoder.Tensor(self.params[""caption_ids_field""]),\n        ""target_tokens"":\n        tfexample_decoder.Tensor(self.params[""caption_tokens_field""]),\n        ""target_len"": tfexample_decoder.ItemHandlerCallback(\n            keys=[self.params[""caption_tokens_field""]],\n            func=lambda x: tf.size(x[self.params[""caption_tokens_field""]]))\n    }\n\n    decoder = TFSEquenceExampleDecoder(\n        context_keys_to_features, sequence_keys_to_features, items_to_handlers)\n\n    dataset = tf.contrib.slim.dataset.Dataset(\n        data_sources=self.params[""files""],\n        reader=tf.TFRecordReader,\n        decoder=decoder,\n        num_samples=None,\n        items_to_descriptions={})\n\n    return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(\n        dataset=dataset,\n        shuffle=self.params[""shuffle""],\n        num_epochs=self.params[""num_epochs""],\n        **kwargs)\n\n  @property\n  def feature_keys(self):\n    return set([""image""])\n\n  @property\n  def label_keys(self):\n    return set([""target_tokens"", ""target_ids"", ""target_len""])\n'"
seq2seq/data/parallel_data_provider.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A Data Provder that reads parallel (aligned) data.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_provider\nfrom tensorflow.contrib.slim.python.slim.data import parallel_reader\n\nfrom seq2seq.data import split_tokens_decoder\n\n\ndef make_parallel_data_provider(data_sources_source,\n                                data_sources_target,\n                                reader=tf.TextLineReader,\n                                num_samples=None,\n                                source_delimiter="" "",\n                                target_delimiter="" "",\n                                **kwargs):\n  """"""Creates a DataProvider that reads parallel text data.\n\n  Args:\n    data_sources_source: A list of data sources for the source text files.\n    data_sources_target: A list of data sources for the target text files.\n      Can be None for inference mode.\n    num_samples: Optional, number of records in the dataset\n    delimiter: Split tokens in the data on this delimiter. Defaults to space.\n    kwargs: Additional arguments (shuffle, num_epochs, etc) that are passed\n      to the data provider\n\n  Returns:\n    A DataProvider instance\n  """"""\n\n  decoder_source = split_tokens_decoder.SplitTokensDecoder(\n      tokens_feature_name=""source_tokens"",\n      length_feature_name=""source_len"",\n      append_token=""SEQUENCE_END"",\n      delimiter=source_delimiter)\n\n  dataset_source = tf.contrib.slim.dataset.Dataset(\n      data_sources=data_sources_source,\n      reader=reader,\n      decoder=decoder_source,\n      num_samples=num_samples,\n      items_to_descriptions={})\n\n  dataset_target = None\n  if data_sources_target is not None:\n    decoder_target = split_tokens_decoder.SplitTokensDecoder(\n        tokens_feature_name=""target_tokens"",\n        length_feature_name=""target_len"",\n        prepend_token=""SEQUENCE_START"",\n        append_token=""SEQUENCE_END"",\n        delimiter=target_delimiter)\n\n    dataset_target = tf.contrib.slim.dataset.Dataset(\n        data_sources=data_sources_target,\n        reader=reader,\n        decoder=decoder_target,\n        num_samples=num_samples,\n        items_to_descriptions={})\n\n  return ParallelDataProvider(\n      dataset1=dataset_source, dataset2=dataset_target, **kwargs)\n\n\nclass ParallelDataProvider(data_provider.DataProvider):\n  """"""Creates a ParallelDataProvider. This data provider reads two datasets\n  in parallel, keeping them aligned.\n\n  Args:\n    dataset1: The first dataset. An instance of the Dataset class.\n    dataset2: The second dataset. An instance of the Dataset class.\n      Can be None. If None, only `dataset1` is read.\n    num_readers: The number of parallel readers to use.\n    shuffle: Whether to shuffle the data sources and common queue when\n      reading.\n    num_epochs: The number of times each data source is read. If left as None,\n      the data will be cycled through indefinitely.\n    common_queue_capacity: The capacity of the common queue.\n    common_queue_min: The minimum number of elements in the common queue after\n      a dequeue.\n    seed: The seed to use if shuffling.\n  """"""\n\n  def __init__(self,\n               dataset1,\n               dataset2,\n               shuffle=True,\n               num_epochs=None,\n               common_queue_capacity=4096,\n               common_queue_min=1024,\n               seed=None):\n\n    if seed is None:\n      seed = np.random.randint(10e8)\n\n    _, data_source = parallel_reader.parallel_read(\n        dataset1.data_sources,\n        reader_class=dataset1.reader,\n        num_epochs=num_epochs,\n        num_readers=1,\n        shuffle=False,\n        capacity=common_queue_capacity,\n        min_after_dequeue=common_queue_min,\n        seed=seed)\n\n    data_target = """"\n    if dataset2 is not None:\n      _, data_target = parallel_reader.parallel_read(\n          dataset2.data_sources,\n          reader_class=dataset2.reader,\n          num_epochs=num_epochs,\n          num_readers=1,\n          shuffle=False,\n          capacity=common_queue_capacity,\n          min_after_dequeue=common_queue_min,\n          seed=seed)\n\n    # Optionally shuffle the data\n    if shuffle:\n      shuffle_queue = tf.RandomShuffleQueue(\n          capacity=common_queue_capacity,\n          min_after_dequeue=common_queue_min,\n          dtypes=[tf.string, tf.string],\n          seed=seed)\n      enqueue_ops = []\n      enqueue_ops.append(shuffle_queue.enqueue([data_source, data_target]))\n      tf.train.add_queue_runner(\n          tf.train.QueueRunner(shuffle_queue, enqueue_ops))\n      data_source, data_target = shuffle_queue.dequeue()\n\n    # Decode source items\n    items = dataset1.decoder.list_items()\n    tensors = dataset1.decoder.decode(data_source, items)\n\n    if dataset2 is not None:\n      # Decode target items\n      items2 = dataset2.decoder.list_items()\n      tensors2 = dataset2.decoder.decode(data_target, items2)\n\n      # Merge items and results\n      items = items + items2\n      tensors = tensors + tensors2\n\n    super(ParallelDataProvider, self).__init__(\n        items_to_tensors=dict(zip(items, tensors)),\n        num_samples=dataset1.num_samples)\n'"
seq2seq/data/postproc.py,0,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nA collection of commonly used post-processing functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\ndef strip_bpe(text):\n  """"""Deodes text that was processed using BPE from\n  https://github.com/rsennrich/subword-nmt""""""\n  return text.replace(""@@ "", """").strip()\n\ndef decode_sentencepiece(text):\n  """"""Decodes text that uses https://github.com/google/sentencepiece encoding.\n  Assumes that pieces are separated by a space""""""\n  return """".join(text.split("" "")).replace(""\xe2\x96\x81"", "" "").strip()\n\ndef slice_text(text,\n               eos_token=""SEQUENCE_END"",\n               sos_token=""SEQUENCE_START""):\n  """"""Slices text from SEQUENCE_START to SEQUENCE_END, not including\n  these special tokens.\n  """"""\n  eos_index = text.find(eos_token)\n  text = text[:eos_index] if eos_index > -1 else text\n  sos_index = text.find(sos_token)\n  text = text[sos_index+len(sos_token):] if sos_index > -1 else text\n  return text.strip()\n'"
seq2seq/data/sequence_example_decoder.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder for tf.SequenceExample""""""\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_decoder\n\n\nclass TFSEquenceExampleDecoder(data_decoder.DataDecoder):\n  """"""A decoder for TensorFlow Examples.\n  Decoding Example proto buffers is comprised of two stages: (1) Example parsing\n  and (2) tensor manipulation.\n  In the first stage, the tf.parse_example function is called with a list of\n  FixedLenFeatures and SparseLenFeatures. These instances tell TF how to parse\n  the example. The output of this stage is a set of tensors.\n  In the second stage, the resulting tensors are manipulated to provide the\n  requested \'item\' tensors.\n  To perform this decoding operation, an ExampleDecoder is given a list of\n  ItemHandlers. Each ItemHandler indicates the set of features for stage 1 and\n  contains the instructions for post_processing its tensors for stage 2.\n  """"""\n\n  def __init__(self, context_keys_to_features, sequence_keys_to_features,\n               items_to_handlers):\n    """"""Constructs the decoder.\n    Args:\n      keys_to_features: a dictionary from TF-Example keys to either\n        tf.VarLenFeature or tf.FixedLenFeature instances. See tensorflow\'s\n        parsing_ops.py.\n      items_to_handlers: a dictionary from items (strings) to ItemHandler\n        instances. Note that the ItemHandler\'s are provided the keys that they\n        use to return the final item Tensors.\n    """"""\n    self._context_keys_to_features = context_keys_to_features\n    self._sequence_keys_to_features = sequence_keys_to_features\n    self._items_to_handlers = items_to_handlers\n\n  def list_items(self):\n    """"""See base class.""""""\n    return list(self._items_to_handlers.keys())\n\n  def decode(self, serialized_example, items=None):\n    """"""Decodes the given serialized TF-example.\n    Args:\n      serialized_example: a serialized TF-example tensor.\n      items: the list of items to decode. These must be a subset of the item\n        keys in self._items_to_handlers. If `items` is left as None, then all\n        of the items in self._items_to_handlers are decoded.\n    Returns:\n      the decoded items, a list of tensor.\n    """"""\n    context, sequence = tf.parse_single_sequence_example(\n        serialized_example, self._context_keys_to_features,\n        self._sequence_keys_to_features)\n\n    # Merge context and sequence features\n    example = {}\n    example.update(context)\n    example.update(sequence)\n\n    all_features = {}\n    all_features.update(self._context_keys_to_features)\n    all_features.update(self._sequence_keys_to_features)\n\n    # Reshape non-sparse elements just once:\n    for k, value in all_features.items():\n      if isinstance(value, tf.FixedLenFeature):\n        example[k] = tf.reshape(example[k], value.shape)\n\n    if not items:\n      items = self._items_to_handlers.keys()\n\n    outputs = []\n    for item in items:\n      handler = self._items_to_handlers[item]\n      keys_to_tensors = {key: example[key] for key in handler.keys}\n      outputs.append(handler.tensors_to_item(keys_to_tensors))\n    return outputs\n'"
seq2seq/data/split_tokens_decoder.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder that splits a string into tokens and returns the\nindividual tokens and the length.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.data import data_decoder\n\n\nclass SplitTokensDecoder(data_decoder.DataDecoder):\n  """"""A DataProvider that splits a string tensor into individual tokens and\n  returns the tokens and the length.\n  Optionally prepends or appends special tokens.\n\n  Args:\n    delimiter: Delimiter to split on. Must be a single character.\n    tokens_feature_name: A descriptive feature name for the token values\n    length_feature_name: A descriptive feature name for the length value\n  """"""\n\n  def __init__(self,\n               delimiter="" "",\n               tokens_feature_name=""tokens"",\n               length_feature_name=""length"",\n               prepend_token=None,\n               append_token=None):\n    self.delimiter = delimiter\n    self.tokens_feature_name = tokens_feature_name\n    self.length_feature_name = length_feature_name\n    self.prepend_token = prepend_token\n    self.append_token = append_token\n\n  def decode(self, data, items):\n    decoded_items = {}\n\n    # Split tokens\n    tokens = tf.string_split([data], delimiter=self.delimiter).values\n\n    # Optionally prepend a special token\n    if self.prepend_token is not None:\n      tokens = tf.concat([[self.prepend_token], tokens], 0)\n\n    # Optionally append a special token\n    if self.append_token is not None:\n      tokens = tf.concat([tokens, [self.append_token]], 0)\n\n    decoded_items[self.length_feature_name] = tf.size(tokens)\n    decoded_items[self.tokens_feature_name] = tokens\n    return [decoded_items[_] for _ in items]\n\n  def list_items(self):\n    return [self.tokens_feature_name, self.length_feature_name]\n'"
seq2seq/data/vocab.py,13,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Vocabulary related functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nSpecialVocab = collections.namedtuple(""SpecialVocab"",\n                                      [""UNK"", ""SEQUENCE_START"", ""SEQUENCE_END""])\n\n\nclass VocabInfo(\n    collections.namedtuple(""VocbabInfo"",\n                           [""path"", ""vocab_size"", ""special_vocab""])):\n  """"""Convenience structure for vocabulary information.\n  """"""\n\n  @property\n  def total_size(self):\n    """"""Returns size the the base vocabulary plus the size of extra vocabulary""""""\n    return self.vocab_size + len(self.special_vocab)\n\n\ndef get_vocab_info(vocab_path):\n  """"""Creates a `VocabInfo` instance that contains the vocabulary size and\n    the special vocabulary for the given file.\n\n  Args:\n    vocab_path: Path to a vocabulary file with one word per line.\n\n  Returns:\n    A VocabInfo tuple.\n  """"""\n  with gfile.GFile(vocab_path) as file:\n    vocab_size = sum(1 for _ in file)\n  special_vocab = get_special_vocab(vocab_size)\n  return VocabInfo(vocab_path, vocab_size, special_vocab)\n\n\ndef get_special_vocab(vocabulary_size):\n  """"""Returns the `SpecialVocab` instance for a given vocabulary size.\n  """"""\n  return SpecialVocab(*range(vocabulary_size, vocabulary_size + 3))\n\n\ndef create_vocabulary_lookup_table(filename, default_value=None):\n  """"""Creates a lookup table for a vocabulary file.\n\n  Args:\n    filename: Path to a vocabulary file containg one word per line.\n      Each word is mapped to its line number.\n    default_value: UNK tokens will be mapped to this id.\n      If None, UNK tokens will be mapped to [vocab_size]\n\n    Returns:\n      A tuple (vocab_to_id_table, id_to_vocab_table,\n      word_to_count_table, vocab_size). The vocab size does not include\n      the UNK token.\n    """"""\n  if not gfile.Exists(filename):\n    raise ValueError(""File does not exist: {}"".format(filename))\n\n  # Load vocabulary into memory\n  with gfile.GFile(filename) as file:\n    vocab = list(line.strip(""\\n"") for line in file)\n  vocab_size = len(vocab)\n\n  has_counts = len(vocab[0].split(""\\t"")) == 2\n  if has_counts:\n    vocab, counts = zip(*[_.split(""\\t"") for _ in vocab])\n    counts = [float(_) for _ in counts]\n    vocab = list(vocab)\n  else:\n    counts = [-1. for _ in vocab]\n\n  # Add special vocabulary items\n  special_vocab = get_special_vocab(vocab_size)\n  vocab += list(special_vocab._fields)\n  vocab_size += len(special_vocab)\n  counts += [-1. for _ in list(special_vocab._fields)]\n\n  if default_value is None:\n    default_value = special_vocab.UNK\n\n  tf.logging.info(""Creating vocabulary lookup table of size %d"", vocab_size)\n\n  vocab_tensor = tf.constant(vocab)\n  count_tensor = tf.constant(counts, dtype=tf.float32)\n  vocab_idx_tensor = tf.range(vocab_size, dtype=tf.int64)\n\n  # Create ID -> word mapping\n  id_to_vocab_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_idx_tensor, vocab_tensor, tf.int64, tf.string)\n  id_to_vocab_table = tf.contrib.lookup.HashTable(id_to_vocab_init, ""UNK"")\n\n  # Create word -> id mapping\n  vocab_to_id_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_tensor, vocab_idx_tensor, tf.string, tf.int64)\n  vocab_to_id_table = tf.contrib.lookup.HashTable(vocab_to_id_init,\n                                                  default_value)\n\n  # Create word -> count mapping\n  word_to_count_init = tf.contrib.lookup.KeyValueTensorInitializer(\n      vocab_tensor, count_tensor, tf.string, tf.float32)\n  word_to_count_table = tf.contrib.lookup.HashTable(word_to_count_init, -1)\n\n  return vocab_to_id_table, id_to_vocab_table, word_to_count_table, vocab_size\n'"
seq2seq/decoders/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of decoders and decoder-related functions.\n""""""\n\nfrom seq2seq.decoders.rnn_decoder import *\nfrom seq2seq.decoders.attention import *\nfrom seq2seq.decoders.basic_decoder import *\nfrom seq2seq.decoders.attention_decoder import *\nfrom seq2seq.decoders.conv_decoder_fairseq import *\nfrom seq2seq.decoders.conv_decoder_fairseq_bs import *\n'"
seq2seq/decoders/attention.py,20,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n"""""" Implementations of attention layers.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport six\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import function  # pylint: disable=E0611\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\n\n\n@function.Defun(\n    tf.float32,\n    tf.float32,\n    tf.float32,\n    func_name=""att_sum_bahdanau"",\n    noinline=True)\ndef att_sum_bahdanau(v_att, keys, query):\n  """"""Calculates a batch- and timweise dot product with a variable""""""\n  return tf.reduce_sum(v_att * tf.tanh(keys + tf.expand_dims(query, 1)), [2])\n\n\n@function.Defun(tf.float32, tf.float32, func_name=""att_sum_dot"", noinline=True)\ndef att_sum_dot(keys, query):\n  """"""Calculates a batch- and timweise dot product""""""\n  return tf.reduce_sum(keys * tf.expand_dims(query, 1), [2])\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass AttentionLayer(GraphModule, Configurable):\n  """"""\n  Attention layer according to https://arxiv.org/abs/1409.0473.\n\n  Params:\n    num_units: Number of units used in the attention layer\n  """"""\n\n  def __init__(self, params, mode, name=""attention""):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n\n  @staticmethod\n  def default_params():\n    return {""num_units"": 128}\n\n  @abc.abstractmethod\n  def score_fn(self, keys, query):\n    """"""Computes the attention score""""""\n    raise NotImplementedError\n\n  def _build(self, query, keys, values, values_length):\n    """"""Computes attention scores and outputs.\n\n    Args:\n      query: The query used to calculate attention scores.\n        In seq2seq this is typically the current state of the decoder.\n        A tensor of shape `[B, ...]`\n      keys: The keys used to calculate attention scores. In seq2seq, these\n        are typically the outputs of the encoder and equivalent to `values`.\n        A tensor of shape `[B, T, ...]` where each element in the `T`\n        dimension corresponds to the key for that value.\n      values: The elements to compute attention over. In seq2seq, this is\n        typically the sequence of encoder outputs.\n        A tensor of shape `[B, T, input_dim]`.\n      values_length: An int32 tensor of shape `[B]` defining the sequence\n        length of the attention values.\n\n    Returns:\n      A tuple `(scores, context)`.\n      `scores` is vector of length `T` where each element is the\n      normalized ""score"" of the corresponding `inputs` element.\n      `context` is the final attention layer output corresponding to\n      the weighted inputs.\n      A tensor fo shape `[B, input_dim]`.\n    """"""\n    values_depth = values.get_shape().as_list()[-1]\n\n    # Fully connected layers to transform both keys and query\n    # into a tensor with `num_units` units\n    att_keys = tf.contrib.layers.fully_connected(\n        inputs=keys,\n        num_outputs=self.params[""num_units""],\n        activation_fn=None,\n        scope=""att_keys"")\n    att_query = tf.contrib.layers.fully_connected(\n        inputs=query,\n        num_outputs=self.params[""num_units""],\n        activation_fn=None,\n        scope=""att_query"")\n\n    scores = self.score_fn(att_keys, att_query)\n\n    # Replace all scores for padded inputs with tf.float32.min\n    num_scores = tf.shape(scores)[1]\n    scores_mask = tf.sequence_mask(\n        lengths=tf.to_int32(values_length),\n        maxlen=tf.to_int32(num_scores),\n        dtype=tf.float32)\n    scores = scores * scores_mask + ((1.0 - scores_mask) * tf.float32.min)\n\n    # Normalize the scores\n    scores_normalized = tf.nn.softmax(scores, name=""scores_normalized"")\n\n    # Calculate the weighted average of the attention inputs\n    # according to the scores\n    context = tf.expand_dims(scores_normalized, 2) * values\n    context = tf.reduce_sum(context, 1, name=""context"")\n    context.set_shape([None, values_depth])\n\n\n    return (scores_normalized, context)\n\n\nclass AttentionLayerDot(AttentionLayer):\n  """"""An attention layer that calculates attention scores using\n  a dot product.\n  """"""\n\n  def score_fn(self, keys, query):\n    return att_sum_dot(keys, query)\n\n\nclass AttentionLayerBahdanau(AttentionLayer):\n  """"""An attention layer that calculates attention scores using\n  a parameterized multiplication.""""""\n\n  def score_fn(self, keys, query):\n    v_att = tf.get_variable(\n        ""v_att"", shape=[self.params[""num_units""]], dtype=tf.float32)\n    return att_sum_bahdanau(v_att, keys, query)\n'"
seq2seq/decoders/attention_decoder.py,18,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nA basic sequence decoder that performs a softmax based on the RNN state.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\nimport tensorflow as tf\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder\n\nfrom seq2seq.contrib.seq2seq.helper import CustomHelper\n\n\nclass AttentionDecoderOutput(\n    namedtuple(""DecoderOutput"", [\n        ""logits"", ""predicted_ids"", ""cell_output"", ""attention_scores"",\n        ""attention_context""\n    ])):\n  """"""Augmented decoder output that also includes the attention scores.\n  """"""\n  pass\n\n\nclass AttentionDecoder(RNNDecoder):\n  """"""An RNN Decoder that uses attention over an input sequence.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    vocab_size: Output vocabulary size, i.e. number of units\n      in the softmax layer\n    attention_keys: The sequence used to calculate attention scores.\n      A tensor of shape `[B, T, ...]`.\n    attention_values: The sequence to attend over.\n      A tensor of shape `[B, T, input_dim]`.\n    attention_values_length: Sequence length of the attention values.\n      An int32 Tensor of shape `[B]`.\n    attention_fn: The attention function to use. This function map from\n      `(state, inputs)` to `(attention_scores, attention_context)`.\n      For an example, see `seq2seq.decoder.attention.AttentionLayer`.\n    reverse_scores: Optional, an array of sequence length. If set,\n      reverse the attention scores in the output. This is used for when\n      a reversed source sequence is fed as an input but you want to\n      return the scores in non-reversed order.\n  """"""\n\n  def __init__(self,\n               params,\n               mode,\n               vocab_size,\n               attention_keys,\n               attention_values,\n               attention_values_length,\n               attention_fn,\n               reverse_scores_lengths=None,\n               name=""attention_decoder""):\n    super(AttentionDecoder, self).__init__(params, mode, name)\n    self.vocab_size = vocab_size\n    self.attention_keys = attention_keys\n    self.attention_values = attention_values\n    self.attention_values_length = attention_values_length\n    self.attention_fn = attention_fn\n    self.reverse_scores_lengths = reverse_scores_lengths\n\n  @property\n  def output_size(self):\n    return AttentionDecoderOutput(\n        logits=self.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        cell_output=self.cell.output_size,\n        attention_scores=tf.shape(self.attention_values)[1:-1],\n        attention_context=self.attention_values.get_shape()[-1])\n\n  @property\n  def output_dtype(self):\n    return AttentionDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32,\n        cell_output=tf.float32,\n        attention_scores=tf.float32,\n        attention_context=tf.float32)\n\n  def initialize(self, name=None):\n    finished, first_inputs = self.helper.initialize()\n\n    # Concat empty attention context\n    attention_context = tf.zeros([\n        tf.shape(first_inputs)[0],\n        self.attention_values.get_shape().as_list()[-1]\n    ])\n    first_inputs = tf.concat([first_inputs, attention_context], 1)\n\n    return finished, first_inputs, self.initial_state\n\n  def compute_output(self, cell_output):\n    """"""Computes the decoder outputs.""""""\n\n    # Compute attention\n    att_scores, attention_context = self.attention_fn(\n        query=cell_output,\n        keys=self.attention_keys,\n        values=self.attention_values,\n        values_length=self.attention_values_length)\n\n    # TODO: Make this a parameter: We may or may not want this.\n    # Transform attention context.\n    # This makes the softmax smaller and allows us to synthesize information\n    # between decoder state and attention context\n    # see https://arxiv.org/abs/1508.04025v5\n    softmax_input = tf.contrib.layers.fully_connected(\n        inputs=tf.concat([cell_output, attention_context], 1),\n        num_outputs=self.cell.output_size,\n        activation_fn=tf.nn.tanh,\n        scope=""attention_mix"")\n\n    # Softmax computation\n    logits = tf.contrib.layers.fully_connected(\n        inputs=softmax_input,\n        num_outputs=self.vocab_size,\n        activation_fn=None,\n        scope=""logits"")\n\n    return softmax_input, logits, att_scores, attention_context\n\n  def _setup(self, initial_state, helper):\n    self.initial_state = initial_state\n\n    def att_next_inputs(time, outputs, state, sample_ids, name=None):\n      """"""Wraps the original decoder helper function to append the attention\n      context.\n      """"""\n      finished, next_inputs, next_state = helper.next_inputs(\n          time=time,\n          outputs=outputs,\n          state=state,\n          sample_ids=sample_ids,\n          name=name)\n      next_inputs = tf.concat([next_inputs, outputs.attention_context], 1)\n      return (finished, next_inputs, next_state)\n\n    self.helper = CustomHelper(\n        initialize_fn=helper.initialize,\n        sample_fn=helper.sample,\n        next_inputs_fn=att_next_inputs)\n\n  def step(self, time_, inputs, state, name=None):\n    cell_output, cell_state = self.cell(inputs, state)\n    cell_output_new, logits, attention_scores, attention_context = \\\n      self.compute_output(cell_output)\n\n    if self.reverse_scores_lengths is not None:\n      attention_scores = tf.reverse_sequence(\n          input=attention_scores,\n          seq_lengths=self.reverse_scores_lengths,\n          seq_dim=1,\n          batch_dim=0)\n\n    sample_ids = self.helper.sample(\n        time=time_, outputs=logits, state=cell_state)\n\n    outputs = AttentionDecoderOutput(\n        logits=logits,\n        predicted_ids=sample_ids,\n        cell_output=cell_output_new,\n        attention_scores=attention_scores,\n        attention_context=attention_context)\n\n    finished, next_inputs, next_state = self.helper.next_inputs(\n        time=time_, outputs=outputs, state=cell_state, sample_ids=sample_ids)\n\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/basic_decoder.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nA basic sequence decoder that performs a softmax based on the RNN state.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder, DecoderOutput\n\n\nclass BasicDecoder(RNNDecoder):\n  """"""Simple RNN decoder that performed a softmax operations on the cell output.\n  """"""\n\n  def __init__(self, params, mode, vocab_size, name=""basic_decoder""):\n    super(BasicDecoder, self).__init__(params, mode, name)\n    self.vocab_size = vocab_size\n\n  def compute_output(self, cell_output):\n    """"""Computes the decoder outputs.""""""\n    return tf.contrib.layers.fully_connected(\n        inputs=cell_output, num_outputs=self.vocab_size, activation_fn=None)\n\n  @property\n  def output_size(self):\n    return DecoderOutput(\n        logits=self.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        cell_output=self.cell.output_size)\n\n  @property\n  def output_dtype(self):\n    return DecoderOutput(\n        logits=tf.float32, predicted_ids=tf.int32, cell_output=tf.float32)\n\n  def initialize(self, name=None):\n    finished, first_inputs = self.helper.initialize()\n    return finished, first_inputs, self.initial_state\n\n  def step(self, time_, inputs, state, name=None):\n    cell_output, cell_state = self.cell(inputs, state)\n    logits = self.compute_output(cell_output)\n    sample_ids = self.helper.sample(\n        time=time_, outputs=logits, state=cell_state)\n    outputs = DecoderOutput(\n        logits=logits, predicted_ids=sample_ids, cell_output=cell_output)\n    finished, next_inputs, next_state = self.helper.next_inputs(\n        time=time_, outputs=outputs, state=cell_state, sample_ids=sample_ids)\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/beam_search_decoder.py,15,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A decoder that uses beam search. Can only be used for inference, not\ntraining.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.inference import beam_search\nfrom seq2seq.decoders.rnn_decoder import RNNDecoder\n\n\nclass FinalBeamDecoderOutput(\n    namedtuple(""FinalBeamDecoderOutput"",\n               [""predicted_ids"", ""beam_search_output""])):\n  """"""Final outputs returned by the beam search after all decoding is finished.\n\n  Args:\n    predicted_ids: The final prediction. A tensor of shape\n      `[T, 1, beam_width]`.\n    beam_search_output: An instance of `BeamDecoderOutput` that describes\n      the state of the beam search.\n  """"""\n  pass\n\n\nclass BeamDecoderOutput(\n    namedtuple(""BeamDecoderOutput"", [\n        ""logits"", ""predicted_ids"", ""log_probs"", ""scores"", ""beam_parent_ids"",\n        ""original_outputs""\n    ])):\n  """"""Structure for the output of a beam search decoder. This class is used\n  to define the output at each step as well as the final output of the decoder.\n  If used as the final output, a time dimension `T` is inserted after the\n  beam_size dimension.\n\n  Args:\n    logits: Logits at the current time step of shape `[beam_size, vocab_size]`\n    predicted_ids: Chosen softmax predictions at the current time step.\n      An int32 tensor of shape `[beam_size]`.\n    log_probs: Total log probabilities of all beams at the current time step.\n      A float32 tensor of shaep `[beam_size]`.\n    scores: Total scores of all beams at the current time step. This differs\n      from log probabilities in that the score may add additional processing\n      such as length normalization. A float32 tensor of shape `[beam_size]`.\n    beam_parent_ids: The indices of the beams that are being continued.\n      An int32 tensor of shape `[beam_size]`.\n  """"""\n  pass\n\n\nclass BeamSearchDecoder(RNNDecoder):\n  """"""The BeamSearchDecoder wraps another decoder to perform beam search instead\n  of greedy selection. This decoder must be used with batch size of 1, which\n  will result in an effective batch size of `beam_width`.\n\n  Args:\n    decoder: A instance of `RNNDecoder` to be used with beam search.\n    config: A `BeamSearchConfig` that defines beam search decoding parameters.\n  """"""\n\n  def __init__(self, decoder, config):\n    super(BeamSearchDecoder, self).__init__(decoder.params, decoder.mode,\n                                            decoder.name)\n    self.decoder = decoder\n    self.config = config\n\n  def __call__(self, *args, **kwargs):\n    with self.decoder.variable_scope():\n      return self._build(*args, **kwargs)\n\n  @property\n  def output_size(self):\n    return BeamDecoderOutput(\n        logits=self.decoder.vocab_size,\n        predicted_ids=tf.TensorShape([]),\n        log_probs=tf.TensorShape([]),\n        scores=tf.TensorShape([]),\n        beam_parent_ids=tf.TensorShape([]),\n        original_outputs=self.decoder.output_size)\n\n  @property\n  def output_dtype(self):\n    return BeamDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32,\n        log_probs=tf.float32,\n        scores=tf.float32,\n        beam_parent_ids=tf.int32,\n        original_outputs=self.decoder.output_dtype)\n\n  @property\n  def batch_size(self):\n    return self.config.beam_width\n\n  def initialize(self, name=None):\n    finished, first_inputs, initial_state = self.decoder.initialize()\n\n    # Create beam state\n    beam_state = beam_search.create_initial_beam_state(config=self.config)\n    return finished, first_inputs, (initial_state, beam_state)\n\n  def finalize(self, outputs, final_state):\n    # Gather according to beam search result\n    predicted_ids = beam_search.gather_tree(outputs.predicted_ids,\n                                            outputs.beam_parent_ids)\n\n    # We\'re using a batch size of 1, so we add an extra dimension to\n    # convert tensors to [1, beam_width, ...] shape. This way Tensorflow\n    # doesn\'t confuse batch_size with beam_width\n    outputs = nest.map_structure(lambda x: tf.expand_dims(x, 1), outputs)\n\n    final_outputs = FinalBeamDecoderOutput(\n        predicted_ids=tf.expand_dims(predicted_ids, 1),\n        beam_search_output=outputs)\n\n    return final_outputs, final_state\n\n  def _build(self, initial_state, helper):\n    # Tile initial state\n    initial_state = nest.map_structure(\n        lambda x: tf.tile(x, [self.batch_size, 1]), initial_state)\n    self.decoder._setup(initial_state, helper)  #pylint: disable=W0212\n    return super(BeamSearchDecoder, self)._build(self.decoder.initial_state,\n                                                 self.decoder.helper)\n\n  def step(self, time_, inputs, state, name=None):\n    decoder_state, beam_state = state\n\n    # Call the original decoder\n    (decoder_output, decoder_state, _, _) = self.decoder.step(time_, inputs,\n                                                              decoder_state)\n\n    # Perform a step of beam search\n    bs_output, beam_state = beam_search.beam_search_step(\n        time_=time_,\n        logits=decoder_output.logits,\n        beam_state=beam_state,\n        config=self.config)\n\n    # Shuffle everything according to beam search result\n    decoder_state = nest.map_structure(\n        lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_state)\n    decoder_output = nest.map_structure(\n        lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_output)\n\n    next_state = (decoder_state, beam_state)\n\n    outputs = BeamDecoderOutput(\n        logits=tf.zeros([self.config.beam_width, self.config.vocab_size]),\n        predicted_ids=bs_output.predicted_ids,\n        log_probs=beam_state.log_probs,\n        scores=bs_output.scores,\n        beam_parent_ids=bs_output.beam_parent_ids,\n        original_outputs=decoder_output)\n\n    finished, next_inputs, next_state = self.decoder.helper.next_inputs(\n        time=time_,\n        outputs=decoder_output,\n        state=next_state,\n        sample_ids=bs_output.predicted_ids)\n    next_inputs.set_shape([self.batch_size, None])\n\n    return (outputs, next_state, next_inputs, finished)\n'"
seq2seq/decoders/conv_decoder_fairseq.py,40,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nBase class for sequence decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom collections import namedtuple\nfrom pydoc import locate\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import math_ops\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.contrib.seq2seq.decoder import Decoder, dynamic_decode\nfrom seq2seq.contrib.seq2seq.decoder import _transpose_batch_time\n#from seq2seq.encoders.pooling_encoder import _create_position_embedding, position_encoding\nfrom seq2seq.encoders.conv_encoder_utils import *\nfrom seq2seq.inference import beam_search  \nfrom tensorflow.python.util import nest\nfrom tensorflow.python.ops import tensor_array_ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.python.ops import control_flow_ops\nfrom seq2seq.encoders.encoder import EncoderOutput\n\nclass ConvDecoderOutput(\n    #namedtuple(""ConvDecoderOutput"", [""logits"", ""predicted_ids"", ""cell_output"", ""attention_scores"", ""attention_context""])):\n    namedtuple(""ConvDecoderOutput"", [""logits"", ""predicted_ids""])): \n    pass\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass ConvDecoderFairseq(Decoder, GraphModule, Configurable):\n  """"""An RNN Decoder that uses attention over an input sequence.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    vocab_size: Output vocabulary size, i.e. number of units\n      in the softmax layer\n    attention_keys: The sequence used to calculate attention scores.\n      A tensor of shape `[B, T, ...]`.\n    attention_values: The sequence to attend over.\n      A tensor of shape `[B, T, input_dim]`.\n    attention_values_length: Sequence length of the attention values.\n      An int32 Tensor of shape `[B]`.\n    attention_fn: The attention function to use. This function map from\n      `(state, inputs)` to `(attention_scores, attention_context)`.\n      For an example, see `seq2seq.decoder.attention.AttentionLayer`.\n    reverse_scores: Optional, an array of sequence length. If set,\n      reverse the attention scores in the output. This is used for when\n      a reversed source sequence is fed as an input but you want to\n      return the scores in non-reversed order.\n  """"""\n\n  def __init__(self,\n               params,\n               mode,\n               vocab_size,\n               config,\n               target_embedding,\n               pos_embedding,\n               start_tokens,\n               name=""conv_decoder_fairseq""):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n    \n    self.vocab_size = vocab_size\n    self.config=config\n    self.target_embedding=target_embedding \n    self.start_tokens=start_tokens\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n    self.pos_embed = pos_embedding\n    self.current_inputs = None\n    self.initial_state = None\n\n  @staticmethod\n  def default_params():\n    return {\n        ""cnn.layers"": 3,\n        ""cnn.nhids"": ""256,256,256"",\n        ""cnn.kwidths"": ""3,3,3"",\n        ""cnn.nhid_default"": 256,\n        ""cnn.kwidth_default"": 3,\n        ""embedding_dropout_keep_prob"": 0.9,\n        ""nhid_dropout_keep_prob"": 0.9,\n        ""out_dropout_keep_prob"": 0.9,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.add"",\n        ""max_decode_length"": 49,\n        ""nout_embed"": 256,\n    }\n \n  @property\n  def batch_size(self):\n    return self.config.beam_width\n\n  @property\n  def output_size(self):\n    return ConvDecoderOutput(\n        logits=self.vocab_size,   # need pay attention\n        predicted_ids=tf.TensorShape([]))\n\n  @property\n  def output_dtype(self):\n    return ConvDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32)\n\n  def print_shape(self, name, tensor):\n    print(name, tensor.get_shape().as_list()) \n \n  def _setup(self, initial_state, helper=None):\n    self.initial_state = initial_state\n  \n  def initialize(self, name=None):\n    \n    finished = tf.tile([False], [self.config.beam_width])\n    \n    start_tokens_batch = tf.fill([self.config.beam_width], self.start_tokens)\n    first_inputs = tf.nn.embedding_lookup(self.target_embedding, start_tokens_batch)\n    first_inputs = tf.expand_dims(first_inputs, 1)\n    zeros_padding = tf.zeros([self.config.beam_width, self.params[\'max_decode_length\']-1, self.target_embedding.get_shape().as_list()[-1]])\n    first_inputs = tf.concat([first_inputs, zeros_padding], axis=1)\n    \n    outputs = tf.tile(self.initial_state.outputs, [self.config.beam_width,1,1]) \n    attention_values = tf.tile(self.initial_state.attention_values, [self.config.beam_width,1,1]) \n    enc_output = EncoderOutput(\n        outputs=outputs,\n        final_state=self.initial_state.final_state,\n        attention_values=attention_values,\n        attention_values_length=self.initial_state.attention_values_length)\n    \n    \n    return finished, first_inputs, enc_output\n  \n  def finalize(self, outputs, final_state):\n \n    return outputs, final_state\n   \n  def next_inputs(self, sample_ids,name=None):\n    finished = math_ops.equal(sample_ids, self.config.eos_token)\n    all_finished = math_ops.reduce_all(finished)\n    next_inputs = control_flow_ops.cond(\n        all_finished,\n        # If we\'re finished, the next_inputs value doesn\'t matter\n        lambda:  tf.nn.embedding_lookup(self.target_embedding, tf.tile([self.config.eos_token], [self.config.beam_width])),\n        lambda: tf.nn.embedding_lookup(self.target_embedding, sample_ids))\n    return all_finished, next_inputs\n\n  def _create_position_embedding(self, lengths, maxlen):\n\n    # Slice to size of current sequence\n    pe_slice = self.pos_embed[2:maxlen+2, :]\n    # Replicate encodings for each element in the batch\n    batch_size = tf.shape(lengths)[0]\n    pe_batch = tf.tile([pe_slice], [batch_size, 1, 1])\n\n    # Mask out positions that are padded\n    positions_mask = tf.sequence_mask(\n        lengths=lengths, maxlen=maxlen, dtype=tf.float32)\n    positions_embed = pe_batch * tf.expand_dims(positions_mask, 2)\n\n    return positions_embed\n  \n  def add_position_embedding(self, inputs, time):\n    seq_pos_embed = self.pos_embed[2:time+1+2,:]  \n    seq_pos_embed = tf.expand_dims(seq_pos_embed, axis=0) \n    seq_pos_embed_batch = tf.tile(seq_pos_embed, [self.config.beam_width,1,1])\n    \n    return self._combiner_fn(inputs, seq_pos_embed_batch)\n\n  def step(self, time, inputs, state, name=None):\n   \n    cur_inputs = inputs[:,0:time+1,:] \n    zeros_padding = inputs[:,time+2:,:] \n    cur_inputs_pos = self.add_position_embedding(cur_inputs, time)\n    \n    enc_output = state \n    logits = self.infer_conv_block(enc_output, cur_inputs_pos)\n    \n    sample_ids = tf.cast(tf.argmax(logits, axis=-1), dtypes.int32)\n\n    finished, next_inputs = self.next_inputs(sample_ids=sample_ids)\n    next_inputs = tf.reshape(next_inputs, [self.config.beam_width, 1, inputs.get_shape().as_list()[-1]])\n    next_inputs = tf.concat([cur_inputs, next_inputs], axis=1)\n    next_inputs = tf.concat([next_inputs, zeros_padding], axis=1)\n    next_inputs.set_shape([self.config.beam_width, self.params[\'max_decode_length\'], inputs.get_shape().as_list()[-1]])\n    outputs = ConvDecoderOutput(\n        logits=logits,\n        predicted_ids=sample_ids)\n    return outputs, enc_output, next_inputs, finished\n\n\n    \n\n  def infer_conv_block(self, enc_output, input_embed):\n    # Apply dropout to embeddings\n    input_embed = tf.contrib.layers.dropout(\n        inputs=input_embed,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.INFER)\n     \n    next_layer = self.conv_block(enc_output, input_embed, False)\n    shape = next_layer.get_shape().as_list()  \n    \n    logits = tf.reshape(next_layer, [-1,shape[-1]])   \n    return logits\n\n  def conv_block(self, enc_output, input_embed, is_train=True):\n    with tf.variable_scope(""decoder_cnn""):    \n      next_layer = input_embed\n      if self.params[""cnn.layers""] > 0:\n        nhids_list = parse_list_or_default(self.params[""cnn.nhids""], self.params[""cnn.layers""], self.params[""cnn.nhid_default""])\n        kwidths_list = parse_list_or_default(self.params[""cnn.kwidths""], self.params[""cnn.layers""], self.params[""cnn.kwidth_default""])\n        \n        # mapping emb dim to hid dim\n        next_layer = linear_mapping_weightnorm(next_layer, nhids_list[0], dropout=self.params[""embedding_dropout_keep_prob""], var_scope_name=""linear_mapping_before_cnn"")      \n         \n        next_layer = conv_decoder_stack(input_embed, enc_output, next_layer, nhids_list, kwidths_list, {\'src\':self.params[""embedding_dropout_keep_prob""], \'hid\': self.params[""nhid_dropout_keep_prob""]}, mode=self.mode)\n    \n    with tf.variable_scope(""softmax""):\n      if is_train:\n        next_layer = linear_mapping_weightnorm(next_layer, self.params[""nout_embed""], var_scope_name=""linear_mapping_after_cnn"")\n      else:         \n        next_layer = linear_mapping_weightnorm(next_layer[:,-1:,:], self.params[""nout_embed""], var_scope_name=""linear_mapping_after_cnn"")\n      next_layer = tf.contrib.layers.dropout(\n        inputs=next_layer,\n        keep_prob=self.params[""out_dropout_keep_prob""],\n        is_training=is_train)\n     \n      next_layer = linear_mapping_weightnorm(next_layer, self.vocab_size, in_dim=self.params[""nout_embed""], dropout=self.params[""out_dropout_keep_prob""], var_scope_name=""logits_before_softmax"")\n      \n    return next_layer \n \n  def init_params_in_loop(self):\n    with tf.variable_scope(""decoder""):\n      initial_finished, initial_inputs, initial_state = self.initialize()\n      enc_output = initial_state\n      logits = self.infer_conv_block(enc_output, initial_inputs)\n      \n\n  def print_tensor_shape(self, tensor, name):\n    print(name, tensor.get_shape().as_list()) \n  \n  def conv_decoder_infer(self):\n    maximum_iterations = self.params[""max_decode_length""]\n    \n    self.init_params_in_loop()\n    tf.get_variable_scope().reuse_variables()    \n    outputs, final_state = dynamic_decode(\n        decoder=self,\n        output_time_major=True,\n        impute_finished=False,\n        maximum_iterations=maximum_iterations)\n    \n    return outputs, final_state\n\n  def conv_decoder_train(self, enc_output, labels, sequence_length):\n    embed_size = labels.get_shape().as_list()[-1]\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = self._create_position_embedding(\n          lengths=sequence_length,\n          maxlen=tf.shape(labels)[1])\n      labels = self._combiner_fn(labels, positions_embed)\n     \n    # Apply dropout to embeddings\n    inputs = tf.contrib.layers.dropout(\n        inputs=labels,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n    \n    next_layer = self.conv_block(enc_output, inputs, True)\n      \n       \n    logits = _transpose_batch_time(next_layer)   \n\n    sample_ids = tf.cast(tf.argmax(logits, axis=-1), tf.int32)\n \n    return ConvDecoderOutput(logits=logits, predicted_ids=sample_ids)\n\n  def _build(self, enc_output, labels=None, sequence_length=None):\n    \n    if not self.initial_state:\n      self._setup(initial_state=enc_output)\n\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      outputs, states = self.conv_decoder_infer()\n      return self.finalize(outputs, states)\n    else:\n      with tf.variable_scope(""decoder""):  # when infer, dynamic decode will add decoder scope, so we add here to keep it the same  \n        outputs = self.conv_decoder_train(enc_output=enc_output, labels=labels, sequence_length=sequence_length)\n        states = None\n        return outputs, states\n'"
seq2seq/decoders/conv_decoder_fairseq_bs.py,48,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nBase class for sequence decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom collections import namedtuple\nfrom pydoc import locate\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import math_ops\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.contrib.seq2seq.decoder import Decoder, dynamic_decode\nfrom seq2seq.contrib.seq2seq.decoder import _transpose_batch_time\n#from seq2seq.encoders.pooling_encoder import _create_position_embedding, position_encoding\nfrom seq2seq.encoders.conv_encoder_utils import *\nfrom seq2seq.inference import beam_search  \nfrom tensorflow.python.util import nest\nfrom tensorflow.python.ops import tensor_array_ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.python.ops import control_flow_ops\nfrom seq2seq.encoders.encoder import EncoderOutput\n\nclass ConvDecoderOutput(\n    #namedtuple(""ConvDecoderOutput"", [""logits"", ""predicted_ids"", ""cell_output"", ""attention_scores"", ""attention_context""])):\n    namedtuple(""ConvDecoderOutput"", [""logits"", ""predicted_ids""])): \n    pass\n\nclass FinalBeamDecoderOutput(\n    namedtuple(""FinalBeamDecoderOutput"",\n               [""predicted_ids"", ""beam_search_output""])):\n    pass\n\nclass BeamDecoderOutput(\n    namedtuple(""BeamDecoderOutput"", [\n        ""logits"", ""predicted_ids"", ""log_probs"", ""scores"", ""beam_parent_ids""\n    ])):\n    pass\n\n@six.add_metaclass(abc.ABCMeta)\nclass ConvDecoderFairseqBS(Decoder, GraphModule, Configurable):\n  """"""An RNN Decoder that uses attention over an input sequence.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    vocab_size: Output vocabulary size, i.e. number of units\n      in the softmax layer\n    attention_keys: The sequence used to calculate attention scores.\n      A tensor of shape `[B, T, ...]`.\n    attention_values: The sequence to attend over.\n      A tensor of shape `[B, T, input_dim]`.\n    attention_values_length: Sequence length of the attention values.\n      An int32 Tensor of shape `[B]`.\n    attention_fn: The attention function to use. This function map from\n      `(state, inputs)` to `(attention_scores, attention_context)`.\n      For an example, see `seq2seq.decoder.attention.AttentionLayer`.\n    reverse_scores: Optional, an array of sequence length. If set,\n      reverse the attention scores in the output. This is used for when\n      a reversed source sequence is fed as an input but you want to\n      return the scores in non-reversed order.\n  """"""\n\n  def __init__(self,\n               params,\n               mode,\n               vocab_size,\n               config,\n               target_embedding,\n               pos_embedding,\n               start_tokens,\n               name=""conv_decoder_fairseq""):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n    \n    self.vocab_size = vocab_size\n    self.config=config\n    self.target_embedding=target_embedding \n    self.start_tokens=start_tokens\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n    self.pos_embed = pos_embedding\n    self.current_inputs = None\n    self.initial_state = None\n\n  @staticmethod\n  def default_params():\n    return {\n        ""cnn.layers"": 3,\n        ""cnn.nhids"": ""256,256,256"",\n        ""cnn.kwidths"": ""3,3,3"",\n        ""cnn.nhid_default"": 256,\n        ""cnn.kwidth_default"": 3,\n        ""embedding_dropout_keep_prob"": 0.9,\n        ""nhid_dropout_keep_prob"": 0.9,\n        ""out_dropout_keep_prob"": 0.9,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.add"",\n        ""max_decode_length"": 49,\n        ""nout_embed"": 256,\n    }\n \n  @property\n  def batch_size(self):\n    return self.config.beam_width\n\n  @property\n  def output_size(self):\n    return BeamDecoderOutput(\n        logits=self.vocab_size,   # need pay attention\n        predicted_ids=tf.TensorShape([]),\n        log_probs=tf.TensorShape([]),\n        scores=tf.TensorShape([]),\n        beam_parent_ids=tf.TensorShape([]))\n\n  @property\n  def output_dtype(self):\n    return BeamDecoderOutput(\n        logits=tf.float32,\n        predicted_ids=tf.int32,\n        log_probs=tf.float32,\n        scores=tf.float32,\n        beam_parent_ids=tf.int32)\n  def print_shape(self, name, tensor):\n    print(name, tensor.get_shape().as_list()) \n \n  def _setup(self, initial_state, helper=None):\n    self.initial_state = initial_state\n  \n  def initialize(self, name=None):\n    \n    finished = tf.tile([False], [self.config.beam_width])\n    \n    start_tokens_batch = tf.fill([self.config.beam_width], self.start_tokens)\n    first_inputs = tf.nn.embedding_lookup(self.target_embedding, start_tokens_batch)\n    first_inputs = tf.expand_dims(first_inputs, 1)\n    zeros_padding = tf.zeros([self.config.beam_width, self.params[\'max_decode_length\']-1, self.target_embedding.get_shape().as_list()[-1]])\n    first_inputs = tf.concat([first_inputs, zeros_padding], axis=1)\n    beam_state = beam_search.create_initial_beam_state(self.config)    \n    \n    outputs = tf.tile(self.initial_state.outputs, [self.config.beam_width,1,1]) \n    attention_values = tf.tile(self.initial_state.attention_values, [self.config.beam_width,1,1]) \n    enc_output = EncoderOutput(\n        outputs=outputs,\n        final_state=self.initial_state.final_state,\n        attention_values=attention_values,\n        attention_values_length=self.initial_state.attention_values_length)\n    \n    \n    return finished, first_inputs, (enc_output, beam_state)\n  \n  def finalize(self, outputs, final_state):\n    # Gather according to beam search result\n    predicted_ids = beam_search.gather_tree(outputs.predicted_ids,\n                                            outputs.beam_parent_ids)\n\n    # We\'re using a batch size of 1, so we add an extra dimension to\n    # convert tensors to [1, beam_width, ...] shape. This way Tensorflow\n    # doesn\'t confuse batch_size with beam_width\n    outputs = nest.map_structure(lambda x: tf.expand_dims(x, 1), outputs)\n    \n    final_outputs = FinalBeamDecoderOutput(\n        predicted_ids=tf.expand_dims(predicted_ids, 1),\n        beam_search_output=outputs)\n\n    return final_outputs, final_state\n  \n  def next_inputs(self, sample_ids,name=None):\n    finished = math_ops.equal(sample_ids, self.config.eos_token)\n    all_finished = math_ops.reduce_all(finished)\n    next_inputs = control_flow_ops.cond(\n        all_finished,\n        # If we\'re finished, the next_inputs value doesn\'t matter\n        lambda:  tf.nn.embedding_lookup(self.target_embedding, tf.tile([self.config.eos_token], [self.config.beam_width])),\n        lambda: tf.nn.embedding_lookup(self.target_embedding, sample_ids))\n    return all_finished, next_inputs\n\n  def _create_position_embedding(self, lengths, maxlen):\n\n    # Slice to size of current sequence\n    pe_slice = self.pos_embed[2:maxlen+2, :]\n    # Replicate encodings for each element in the batch\n    batch_size = tf.shape(lengths)[0]\n    pe_batch = tf.tile([pe_slice], [batch_size, 1, 1])\n\n    # Mask out positions that are padded\n    positions_mask = tf.sequence_mask(\n        lengths=lengths, maxlen=maxlen, dtype=tf.float32)\n    positions_embed = pe_batch * tf.expand_dims(positions_mask, 2)\n\n    return positions_embed\n  \n  def add_position_embedding(self, inputs, time):\n    seq_pos_embed = self.pos_embed[2:time+1+2,:]  \n    seq_pos_embed = tf.expand_dims(seq_pos_embed, axis=0) \n    seq_pos_embed_batch = tf.tile(seq_pos_embed, [self.config.beam_width,1,1])\n    \n    return self._combiner_fn(inputs, seq_pos_embed_batch)\n\n  def step(self, time, inputs, state, name=None):\n   \n    cur_inputs = inputs[:,0:time+1,:] \n    zeros_padding = inputs[:,time+2:,:] \n    cur_inputs_pos = self.add_position_embedding(cur_inputs, time)\n    \n    enc_output, beam_state = state \n    logits = self.infer_conv_block(enc_output, cur_inputs_pos)\n    \n    bs_output, beam_state = beam_search.beam_search_step(\n        time_=time,\n        logits=logits,\n        beam_state=beam_state,\n        config=self.config)\n\n    finished, next_inputs = self.next_inputs(sample_ids=bs_output.predicted_ids)\n    next_inputs = tf.reshape(next_inputs, [self.config.beam_width, 1, inputs.get_shape().as_list()[-1]])\n    next_inputs = tf.concat([cur_inputs, next_inputs], axis=1)\n    next_inputs = tf.concat([next_inputs, zeros_padding], axis=1)\n    next_inputs.set_shape([self.config.beam_width, self.params[\'max_decode_length\'], inputs.get_shape().as_list()[-1]])\n    outputs = BeamDecoderOutput(\n        logits=tf.zeros([self.config.beam_width, self.config.vocab_size]),\n        predicted_ids=bs_output.predicted_ids,\n        log_probs=beam_state.log_probs,\n        scores=bs_output.scores,\n        beam_parent_ids=bs_output.beam_parent_ids)\n    return outputs, (enc_output,beam_state), next_inputs, finished\n\n\n    \n\n  def infer_conv_block(self, enc_output, input_embed):\n    # Apply dropout to embeddings\n    input_embed = tf.contrib.layers.dropout(\n        inputs=input_embed,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.INFER)\n     \n    next_layer = self.conv_block(enc_output, input_embed, False)\n    shape = next_layer.get_shape().as_list()  \n    \n    logits = tf.reshape(next_layer, [-1,shape[-1]])   \n    return logits\n\n  def conv_block(self, enc_output, input_embed, is_train=True):\n    with tf.variable_scope(""decoder_cnn""):    \n      next_layer = input_embed\n      if self.params[""cnn.layers""] > 0:\n        nhids_list = parse_list_or_default(self.params[""cnn.nhids""], self.params[""cnn.layers""], self.params[""cnn.nhid_default""])\n        kwidths_list = parse_list_or_default(self.params[""cnn.kwidths""], self.params[""cnn.layers""], self.params[""cnn.kwidth_default""])\n        \n        # mapping emb dim to hid dim\n        next_layer = linear_mapping_weightnorm(next_layer, nhids_list[0], dropout=self.params[""embedding_dropout_keep_prob""], var_scope_name=""linear_mapping_before_cnn"")      \n         \n        next_layer = conv_decoder_stack(input_embed, enc_output, next_layer, nhids_list, kwidths_list, {\'src\':self.params[""embedding_dropout_keep_prob""], \'hid\': self.params[""nhid_dropout_keep_prob""]}, mode=self.mode)\n    \n    with tf.variable_scope(""softmax""):\n      if is_train:\n        next_layer = linear_mapping_weightnorm(next_layer, self.params[""nout_embed""], var_scope_name=""linear_mapping_after_cnn"")\n      else:         \n        next_layer = linear_mapping_weightnorm(next_layer[:,-1:,:], self.params[""nout_embed""], var_scope_name=""linear_mapping_after_cnn"")\n      next_layer = tf.contrib.layers.dropout(\n        inputs=next_layer,\n        keep_prob=self.params[""out_dropout_keep_prob""],\n        is_training=is_train)\n     \n      next_layer = linear_mapping_weightnorm(next_layer, self.vocab_size, in_dim=self.params[""nout_embed""], dropout=self.params[""out_dropout_keep_prob""], var_scope_name=""logits_before_softmax"")\n      \n    return next_layer \n \n  def init_params_in_loop(self):\n    with tf.variable_scope(""decoder""):\n      initial_finished, initial_inputs, initial_state = self.initialize()\n      enc_output, beam_sate = initial_state\n      logits = self.infer_conv_block(enc_output, initial_inputs)\n      \n\n  def print_tensor_shape(self, tensor, name):\n    print(name, tensor.get_shape().as_list()) \n  \n  def conv_decoder_infer(self):\n    maximum_iterations = self.params[""max_decode_length""]\n    \n    self.init_params_in_loop()\n    tf.get_variable_scope().reuse_variables()    \n    outputs, final_state = dynamic_decode(\n        decoder=self,\n        output_time_major=True,\n        impute_finished=False,\n        maximum_iterations=maximum_iterations)\n    \n    return outputs, final_state\n\n  def conv_decoder_train(self, enc_output, labels, sequence_length):\n    embed_size = labels.get_shape().as_list()[-1]\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = self._create_position_embedding(\n          lengths=sequence_length,\n          maxlen=tf.shape(labels)[1])\n      labels = self._combiner_fn(labels, positions_embed)\n     \n    # Apply dropout to embeddings\n    inputs = tf.contrib.layers.dropout(\n        inputs=labels,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n    \n    next_layer = self.conv_block(enc_output, inputs, True)\n      \n       \n    logits = _transpose_batch_time(next_layer)   \n\n    sample_ids = tf.cast(tf.argmax(logits, axis=-1), tf.int32)\n \n    return ConvDecoderOutput(logits=logits, predicted_ids=sample_ids)\n\n  def _build(self, enc_output, labels=None, sequence_length=None):\n    \n    if not self.initial_state:\n      self._setup(initial_state=enc_output)\n\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      outputs, states = self.conv_decoder_infer()\n      return self.finalize(outputs, states)\n    else:\n      with tf.variable_scope(""decoder""):  # when infer, dynamic decode will add decoder scope, so we add here to keep it the same  \n        outputs = self.conv_decoder_train(enc_output=enc_output, labels=labels, sequence_length=sequence_length)\n        states = None\n        return outputs, states\n'"
seq2seq/decoders/rnn_decoder.py,6,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nBase class for sequence decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom collections import namedtuple\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.graph_module import GraphModule\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.contrib.seq2seq.decoder import Decoder, dynamic_decode\nfrom seq2seq.encoders.rnn_encoder import _default_rnn_cell_params\nfrom seq2seq.encoders.rnn_encoder import _toggle_dropout\nfrom seq2seq.training import utils as training_utils\n\n\nclass DecoderOutput(\n    namedtuple(""DecoderOutput"", [""logits"", ""predicted_ids"", ""cell_output""])):\n  """"""Output of an RNN decoder.\n\n  Note that we output both the logits and predictions because during\n  dynamic decoding the predictions may not correspond to max(logits).\n  For example, we may be sampling from the logits instead.\n  """"""\n  pass\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass RNNDecoder(Decoder, GraphModule, Configurable):\n  """"""Base class for RNN decoders.\n\n  Args:\n    cell: An instance of ` tf.contrib.rnn.RNNCell`\n    helper: An instance of `tf.contrib.seq2seq.Helper` to assist decoding\n    initial_state: A tensor or tuple of tensors used as the initial cell\n      state.\n    name: A name for this module\n  """"""\n\n  def __init__(self, params, mode, name):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n    self.params[""rnn_cell""] = _toggle_dropout(self.params[""rnn_cell""], mode)\n    self.cell = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    # Not initialized yet\n    self.initial_state = None\n    self.helper = None\n\n  @abc.abstractmethod\n  def initialize(self, name=None):\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def step(self, name=None):\n    raise NotImplementedError\n\n  @property\n  def batch_size(self):\n    return tf.shape(nest.flatten([self.initial_state])[0])[0]\n\n  def _setup(self, initial_state, helper):\n    """"""Sets the initial state and helper for the decoder.\n    """"""\n    self.initial_state = initial_state\n    self.helper = helper\n\n  def finalize(self, outputs, final_state):\n    """"""Applies final transformation to the decoder output once decoding is\n    finished.\n    """"""\n    #pylint: disable=R0201\n    return (outputs, final_state)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""max_decode_length"": 100,\n        ""rnn_cell"": _default_rnn_cell_params(),\n        ""init_scale"": 0.04,\n    }\n\n  def _build(self, initial_state, helper):\n    if not self.initial_state:\n      self._setup(initial_state, helper)\n\n    scope = tf.get_variable_scope()\n    scope.set_initializer(tf.random_uniform_initializer(\n        -self.params[""init_scale""],\n        self.params[""init_scale""]))\n\n    maximum_iterations = None\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      maximum_iterations = self.params[""max_decode_length""]\n\n    outputs, final_state = dynamic_decode(\n        decoder=self,\n        output_time_major=True,\n        impute_finished=False,\n        maximum_iterations=maximum_iterations)\n    return self.finalize(outputs, final_state)\n'"
seq2seq/encoders/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of encoders""""""\n\nimport seq2seq.encoders.encoder\nimport seq2seq.encoders.rnn_encoder\n\nfrom seq2seq.encoders.rnn_encoder import *\nfrom seq2seq.encoders.image_encoder import *\nfrom seq2seq.encoders.pooling_encoder import PoolingEncoder\nfrom seq2seq.encoders.conv_encoder import ConvEncoder\nfrom seq2seq.encoders.conv_encoder_fairseq import ConvEncoderFairseq\n'"
seq2seq/encoders/conv_encoder.py,10,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that pools over embeddings, as described in\nhttps://arxiv.org/abs/1611.02344.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pydoc import locate\n\nimport tensorflow as tf\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\nfrom seq2seq.encoders.pooling_encoder import _create_position_embedding\n\n\nclass ConvEncoder(Encoder):\n  """"""A deep convolutional encoder, as described in\n  https://arxiv.org/abs/1611.02344. The encoder supports optional positions\n  embeddings.\n\n  Params:\n    attention_cnn.units: Number of units in `cnn_a`. Same in each layer.\n    attention_cnn.kernel_size: Kernel size for `cnn_a`.\n    attention_cnn.layers: Number of layers in `cnn_a`.\n    embedding_dropout_keep_prob: Dropout keep probability\n      applied to the embeddings.\n    output_cnn.units: Number of units in `cnn_c`. Same in each layer.\n    output_cnn.kernel_size: Kernel size for `cnn_c`.\n    output_cnn.layers: Number of layers in `cnn_c`.\n    position_embeddings.enable: If true, add position embeddings to the\n      inputs before pooling.\n    position_embeddings.combiner_fn: Function used to combine the\n      position embeddings with the inputs. For example, `tensorflow.add`.\n    position_embeddings.num_positions: Size of the position embedding matrix.\n      This should be set to the maximum sequence length of the inputs.\n  """"""\n\n  def __init__(self, params, mode, name=""conv_encoder""):\n    super(ConvEncoder, self).__init__(params, mode, name)\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n\n  @staticmethod\n  def default_params():\n    return {\n        ""attention_cnn.units"": 512,\n        ""attention_cnn.kernel_size"": 3,\n        ""attention_cnn.layers"": 15,\n        ""embedding_dropout_keep_prob"": 0.8,\n        ""output_cnn.units"": 256,\n        ""output_cnn.kernel_size"": 3,\n        ""output_cnn.layers"": 5,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.multiply"",\n        ""position_embeddings.num_positions"": 100,\n    }\n\n  def encode(self, inputs, sequence_length):\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = _create_position_embedding(\n          embedding_dim=inputs.get_shape().as_list()[-1],\n          num_positions=self.params[""position_embeddings.num_positions""],\n          lengths=sequence_length,\n          maxlen=tf.shape(inputs)[1])\n      inputs = self._combiner_fn(inputs, positions_embed)\n\n    # Apply dropout to embeddings\n    inputs = tf.contrib.layers.dropout(\n        inputs=inputs,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n\n    with tf.variable_scope(""cnn_a""):\n      cnn_a_output = inputs\n      for layer_idx in range(self.params[""attention_cnn.layers""]):\n        next_layer = tf.contrib.layers.conv2d(\n            inputs=cnn_a_output,\n            num_outputs=self.params[""attention_cnn.units""],\n            kernel_size=self.params[""attention_cnn.kernel_size""],\n            padding=""SAME"",\n            activation_fn=None)\n        # Add a residual connection, except for the first layer\n        if layer_idx > 0:\n          next_layer += cnn_a_output\n        cnn_a_output = tf.tanh(next_layer)\n\n    with tf.variable_scope(""cnn_c""):\n      cnn_c_output = inputs\n      for layer_idx in range(self.params[""output_cnn.layers""]):\n        next_layer = tf.contrib.layers.conv2d(\n            inputs=cnn_c_output,\n            num_outputs=self.params[""output_cnn.units""],\n            kernel_size=self.params[""output_cnn.kernel_size""],\n            padding=""SAME"",\n            activation_fn=None)\n        # Add a residual connection, except for the first layer\n        if layer_idx > 0:\n          next_layer += cnn_c_output\n        cnn_c_output = tf.tanh(next_layer)\n\n    final_state = tf.reduce_mean(cnn_c_output, 1)\n\n    return EncoderOutput(\n        outputs=cnn_a_output,\n        final_state=final_state,\n        attention_values=cnn_c_output,\n        attention_values_length=sequence_length)\n'"
seq2seq/encoders/conv_encoder_fairseq.py,13,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that conv over embeddings, as described in\nhttps://arxiv.org/abs/1705.03122.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pydoc import locate\n\nimport tensorflow as tf\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\n#from seq2seq.encoders.pooling_encoder import _create_position_embedding\nfrom seq2seq.encoders.conv_encoder_utils import *\n\n\nclass ConvEncoderFairseq(Encoder):\n  """"""A deep convolutional encoder, as described in\n  https://arxiv.org/abs/1705.03122. The encoder supports optional positions\n  embeddings.\n\n  Params:\n    attention_cnn.units: Number of units in `cnn_a`. Same in each layer.\n    attention_cnn.kernel_size: Kernel size for `cnn_a`.\n    attention_cnn.layers: Number of layers in `cnn_a`.\n    embedding_dropout_keep_prob: Dropout keep probability\n      applied to the embeddings.\n    output_cnn.units: Number of units in `cnn_c`. Same in each layer.\n    output_cnn.kernel_size: Kernel size for `cnn_c`.\n    output_cnn.layers: Number of layers in `cnn_c`.\n    position_embeddings.enable: If true, add position embeddings to the\n      inputs before pooling.\n    position_embeddings.combiner_fn: Function used to combine the\n      position embeddings with the inputs. For example, `tensorflow.add`.\n    position_embeddings.num_positions: Size of the position embedding matrix.\n      This should be set to the maximum sequence length of the inputs.\n  """"""\n\n  def __init__(self, params, mode, pos_embed, name=""conv_encoder""):\n    super(ConvEncoderFairseq, self).__init__(params, mode, name)\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n    self.pos_embed = pos_embed \n  @staticmethod\n  def default_params():\n    return {\n        ""cnn.layers"": 4,\n        ""cnn.nhids"": ""256,256,256,256"",\n        ""cnn.kwidths"": ""3,3,3,3"",\n        ""cnn.nhid_default"": 256,\n        ""cnn.kwidth_default"": 3,\n        ""embedding_dropout_keep_prob"": 0.9,\n        ""nhid_dropout_keep_prob"": 0.9,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.add"",\n    }\n   \n\n  def _create_position_embedding(self, lengths, maxlen):\n\n    # Slice to size of current sequence\n    pe_slice = self.pos_embed[2:maxlen+2, :]\n    # Replicate encodings for each element in the batch\n    batch_size = tf.shape(lengths)[0]\n    pe_batch = tf.tile([pe_slice], [batch_size, 1, 1])\n\n    # Mask out positions that are padded\n    positions_mask = tf.sequence_mask(\n        lengths=lengths, maxlen=maxlen, dtype=tf.float32)\n    positions_embed = pe_batch * tf.expand_dims(positions_mask, 2)\n    \n    positions_embed = tf.reverse_sequence(positions_embed, lengths, batch_dim=0, seq_dim=1)  # [[1,2,3,4,PAD,PAD,PAD],[2,3,PAD,PAD,PAD,PAD,PAD]]   [4,2]\n    positions_embed = tf.reverse(positions_embed,[1])  # --> [[4,3,2,1,PAD,PAD,PAD],[3,2,PAD,PAD,PAD,PAD,PAD]] --> [[PAD,PAD,PAD,1,2,3,4],[PAD,PAD,PAD,PAD,PAD,2,3]]\n\n    return positions_embed\n   \n\n\n  def encode(self, inputs, sequence_length):\n    \n    embed_size = inputs.get_shape().as_list()[-1]\n    \n    if self.params[""position_embeddings.enable""]:\n      positions_embed = self._create_position_embedding(\n          lengths=sequence_length,  # tensor, data lengths\n          maxlen=tf.shape(inputs)[1])  # max len in this batch\n      inputs = self._combiner_fn(inputs, positions_embed)\n    \n    \n    # Apply dropout to embeddings\n    inputs = tf.contrib.layers.dropout(\n        inputs=inputs,\n        keep_prob=self.params[""embedding_dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n    \n    with tf.variable_scope(""encoder_cnn""):    \n      next_layer = inputs\n      if self.params[""cnn.layers""] > 0:\n        nhids_list = parse_list_or_default(self.params[""cnn.nhids""], self.params[""cnn.layers""], self.params[""cnn.nhid_default""])\n        kwidths_list = parse_list_or_default(self.params[""cnn.kwidths""], self.params[""cnn.layers""], self.params[""cnn.kwidth_default""])\n        \n        # mapping emb dim to hid dim\n        next_layer = linear_mapping_weightnorm(next_layer, nhids_list[0], dropout=self.params[""embedding_dropout_keep_prob""], var_scope_name=""linear_mapping_before_cnn"")      \n        next_layer = conv_encoder_stack(next_layer, nhids_list, kwidths_list, {\'src\':self.params[""embedding_dropout_keep_prob""], \'hid\': self.params[""nhid_dropout_keep_prob""]}, mode=self.mode)\n        \n        next_layer = linear_mapping_weightnorm(next_layer, embed_size, var_scope_name=""linear_mapping_after_cnn"")\n      ## The encoder stack will receive gradients *twice* for each attention pass: dot product and weighted sum.\n      ##cnn = nn.GradMultiply(cnn, 1 / (2 * nattn))  \n      cnn_c_output = (next_layer + inputs) * tf.sqrt(0.5) \n            \n\n    final_state = tf.reduce_mean(cnn_c_output, 1)\n\n    return EncoderOutput(\n        outputs=next_layer,\n        final_state=final_state,\n        attention_values=cnn_c_output,\n        attention_values_length=sequence_length)\n'"
seq2seq/encoders/conv_encoder_utils.py,52,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that conv over embeddings, as described in\nhttps://arxiv.org/abs/1705.03122.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\ndef parse_list_or_default(params_str, number, default_val, delimitor=\',\'):\n  param_list = []\n  if params_str == """":\n    param_list = [default_val] * number\n  else:\n    param_list = [int(x) for x in params_str.strip().split(delimitor)]\n  return param_list\n\n\ndef linear_mapping_stupid(inputs, out_dim, in_dim=None, dropout=1.0, var_scope_name=""linear_mapping""):\n  with tf.variable_scope(var_scope_name):\n    print(\'name\', tf.get_variable_scope().name) \n    input_shape_tensor = tf.shape(inputs)   # dynamic shape, no None\n    input_shape = inputs.get_shape().as_list()    # static shape. may has None\n    print(\'input_shape\', input_shape)\n    assert len(input_shape) == 3\n    inputs = tf.reshape(inputs, [-1, input_shape_tensor[-1]])\n     \n    linear_mapping_w = tf.get_variable(""linear_mapping_w"", [input_shape[-1], out_dim], initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(dropout*1.0/input_shape[-1])))\n    linear_mapping_b = tf.get_variable(""linear_mapping_b"", [out_dim], initializer=tf.zeros_initializer())\n      \n\n    output = tf.matmul(inputs, linear_mapping_w) + linear_mapping_b\n    print(\'xxxxx_params\', input_shape, out_dim)\n    #output = tf.reshape(output, [input_shape[0], -1, out_dim])\n    output = tf.reshape(output, [input_shape_tensor[0], -1, out_dim])\n \n  return output\n \ndef linear_mapping(inputs, out_dim, in_dim=None, dropout=1.0, var_scope_name=""linear_mapping""):\n  with tf.variable_scope(var_scope_name):\n    input_shape = inputs.get_shape().as_list()    # static shape. may has None\n    return tf.contrib.layers.fully_connected(inputs=inputs,num_outputs=out_dim,activation_fn=None, weights_initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(dropout*1.0/input_shape[-1])), biases_initializer=tf.zeros_initializer()) \n \ndef linear_mapping_weightnorm(inputs, out_dim, in_dim=None, dropout=1.0, var_scope_name=""linear_mapping""):\n  with tf.variable_scope(var_scope_name):\n    input_shape = inputs.get_shape().as_list()    # static shape. may has None\n    input_shape_tensor = tf.shape(inputs)    \n    # use weight normalization (Salimans & Kingma, 2016)  w = g* v/2-norm(v)\n    V = tf.get_variable(\'V\', shape=[int(input_shape[-1]), out_dim], dtype=tf.float32, initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(dropout*1.0/int(input_shape[-1]))), trainable=True)\n    V_norm = tf.norm(V.initialized_value(), axis=0)  # V shape is M*N,  V_norm shape is N\n    g = tf.get_variable(\'g\', dtype=tf.float32, initializer=V_norm, trainable=True)\n    b = tf.get_variable(\'b\', shape=[out_dim], dtype=tf.float32, initializer=tf.zeros_initializer(), trainable=True)   # weightnorm bias is init zero\n    \n    assert len(input_shape) == 3\n    inputs = tf.reshape(inputs, [-1, input_shape[-1]])\n    inputs = tf.matmul(inputs, V)\n    inputs = tf.reshape(inputs, [input_shape_tensor[0], -1, out_dim])\n    #inputs = tf.matmul(inputs, V)    # x*v\n    \n    scaler = tf.div(g, tf.norm(V, axis=0))   # g/2-norm(v)\n    inputs = tf.reshape(scaler,[1, out_dim])*inputs + tf.reshape(b,[1, out_dim])   # x*v g/2-norm(v) + b\n    \n\n    return inputs \n \ndef conv1d_weightnorm(inputs, layer_idx, out_dim, kernel_size, padding=""SAME"", dropout=1.0,  var_scope_name=""conv_layer""):    #padding should take attention\n  \n  with tf.variable_scope(""conv_layer_""+str(layer_idx)):\n    in_dim = int(inputs.get_shape()[-1])\n    V = tf.get_variable(\'V\', shape=[kernel_size, in_dim, out_dim], dtype=tf.float32, initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(4.0*dropout/(kernel_size*in_dim))), trainable=True)\n    V_norm = tf.norm(V.initialized_value(), axis=[0,1])  # V shape is M*N*k,  V_norm shape is k  \n    g = tf.get_variable(\'g\', dtype=tf.float32, initializer=V_norm, trainable=True)\n    b = tf.get_variable(\'b\', shape=[out_dim], dtype=tf.float32, initializer=tf.zeros_initializer(), trainable=True)\n    \n    # use weight normalization (Salimans & Kingma, 2016)\n    W = tf.reshape(g, [1,1,out_dim])*tf.nn.l2_normalize(V,[0,1])\n    inputs = tf.nn.bias_add(tf.nn.conv1d(value=inputs, filters=W, stride=1, padding=padding), b)   \n    return inputs\n\n\ndef gated_linear_units(inputs):\n  input_shape = inputs.get_shape().as_list()\n  assert len(input_shape) == 3\n  input_pass = inputs[:,:,0:int(input_shape[2]/2)]\n  input_gate = inputs[:,:,int(input_shape[2]/2):]\n  input_gate = tf.sigmoid(input_gate)\n  return tf.multiply(input_pass, input_gate)\n \n\ndef conv_encoder_stack(inputs, nhids_list, kwidths_list, dropout_dict, mode):\n  next_layer = inputs\n  for layer_idx in range(len(nhids_list)):\n    nin = nhids_list[layer_idx] if layer_idx == 0 else nhids_list[layer_idx-1]\n    nout = nhids_list[layer_idx]\n    if nin != nout:\n      #mapping for res add\n      res_inputs = linear_mapping_weightnorm(next_layer, nout, dropout=dropout_dict[\'src\'], var_scope_name=""linear_mapping_cnn_"" + str(layer_idx))    \n    else:\n      res_inputs = next_layer\n    #dropout before input to conv\n    next_layer = tf.contrib.layers.dropout(\n      inputs=next_layer,\n      keep_prob=dropout_dict[\'hid\'],\n      is_training=mode == tf.contrib.learn.ModeKeys.TRAIN)\n   \n    next_layer = conv1d_weightnorm(inputs=next_layer, layer_idx=layer_idx, out_dim=nout*2, kernel_size=kwidths_list[layer_idx], padding=""SAME"", dropout=dropout_dict[\'hid\'], var_scope_name=""conv_layer_""+str(layer_idx)) \n    \'\'\' \n    next_layer = tf.contrib.layers.conv2d(\n        inputs=next_layer,\n        num_outputs=nout*2,\n        kernel_size=kwidths_list[layer_idx],\n        padding=""SAME"",   #should take attention\n        weights_initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(4 * dropout_dict[\'hid\'] / (kwidths_list[layer_idx] * next_layer.get_shape().as_list()[-1]))),\n        biases_initializer=tf.zeros_initializer(),\n        activation_fn=None,\n        scope=""conv_layer_""+str(layer_idx))\n    \'\'\'    \n    next_layer = gated_linear_units(next_layer)\n    next_layer = (next_layer + res_inputs) * tf.sqrt(0.5)\n\n  return next_layer \n\n\n\ndef conv_decoder_stack(target_embed, enc_output, inputs, nhids_list, kwidths_list, dropout_dict, mode):\n  next_layer = inputs\n  for layer_idx in range(len(nhids_list)):\n    nin = nhids_list[layer_idx] if layer_idx == 0 else nhids_list[layer_idx-1]\n    nout = nhids_list[layer_idx]\n    if nin != nout:\n      #mapping for res add\n      res_inputs = linear_mapping_weightnorm(next_layer, nout, dropout=dropout_dict[\'hid\'], var_scope_name=""linear_mapping_cnn_"" + str(layer_idx))      \n    else:\n      res_inputs = next_layer\n    #dropout before input to conv\n    next_layer = tf.contrib.layers.dropout(\n      inputs=next_layer,\n      keep_prob=dropout_dict[\'hid\'],\n      is_training=mode == tf.contrib.learn.ModeKeys.TRAIN)\n    # special process here, first padd then conv, because tf does not suport padding other than SAME and VALID\n    next_layer = tf.pad(next_layer, [[0, 0], [kwidths_list[layer_idx]-1, kwidths_list[layer_idx]-1], [0, 0]], ""CONSTANT"")\n    \n    next_layer = conv1d_weightnorm(inputs=next_layer, layer_idx=layer_idx, out_dim=nout*2, kernel_size=kwidths_list[layer_idx], padding=""VALID"", dropout=dropout_dict[\'hid\'], var_scope_name=""conv_layer_""+str(layer_idx)) \n    \'\'\'\n    next_layer = tf.contrib.layers.conv2d(\n        inputs=next_layer,\n        num_outputs=nout*2,\n        kernel_size=kwidths_list[layer_idx],\n        padding=""VALID"",   #should take attention, not SAME but VALID\n        weights_initializer=tf.random_normal_initializer(mean=0, stddev=tf.sqrt(4 * dropout_dict[\'hid\'] / (kwidths_list[layer_idx] * next_layer.get_shape().as_list()[-1]))),\n        biases_initializer=tf.zeros_initializer(),\n        activation_fn=None,\n        scope=""conv_layer_""+str(layer_idx))\n    \'\'\'\n    layer_shape = next_layer.get_shape().as_list()\n    assert len(layer_shape) == 3\n    # to avoid using future information \n    next_layer = next_layer[:,0:-kwidths_list[layer_idx]+1,:]\n\n    next_layer = gated_linear_units(next_layer)\n   \n    # add attention\n    # decoder output -->linear mapping to embed, + target embed,  query decoder output a, softmax --> scores, scores*encoder_output_c-->output,  output--> linear mapping to nhid+  decoder_output -->\n    att_out = make_attention(target_embed, enc_output, next_layer, layer_idx) \n    next_layer = (next_layer + att_out) * tf.sqrt(0.5) \n\n    # add res connections\n    next_layer += (next_layer + res_inputs) * tf.sqrt(0.5) \n  return next_layer\n\n \ndef make_attention(target_embed, encoder_output, decoder_hidden, layer_idx):\n  with tf.variable_scope(""attention_layer_"" + str(layer_idx)):\n    embed_size = target_embed.get_shape().as_list()[-1]      #k\n    dec_hidden_proj = linear_mapping_weightnorm(decoder_hidden, embed_size, var_scope_name=""linear_mapping_att_query"")  # M*N1*k1 --> M*N1*k\n    dec_rep = (dec_hidden_proj + target_embed) * tf.sqrt(0.5)\n \n    encoder_output_a = encoder_output.outputs\n    encoder_output_c = encoder_output.attention_values    # M*N2*K\n     \n    att_score = tf.matmul(dec_rep, encoder_output_a, transpose_b=True)  #M*N1*K  ** M*N2*K  --> M*N1*N2\n    att_score = tf.nn.softmax(att_score)        \n  \n    length = tf.cast(tf.shape(encoder_output_c), tf.float32)\n    att_out = tf.matmul(att_score, encoder_output_c) * length[1] * tf.sqrt(1.0/length[1])    #M*N1*N2  ** M*N2*K   --> M*N1*k\n     \n    att_out = linear_mapping_weightnorm(att_out, decoder_hidden.get_shape().as_list()[-1], var_scope_name=""linear_mapping_att_out"")\n  return att_out\n\n\n'"
seq2seq/encoders/encoder.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAbstract base class for encoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nfrom collections import namedtuple\n\nimport six\n\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.graph_module import GraphModule\n\nEncoderOutput = namedtuple(\n    ""EncoderOutput"",\n    ""outputs final_state attention_values attention_values_length"")\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Encoder(GraphModule, Configurable):\n  """"""Abstract encoder class. All encoders should inherit from this.\n\n  Args:\n    params: A dictionary of hyperparameters for the encoder.\n    name: A variable scope for the encoder graph.\n  """"""\n\n  def __init__(self, params, mode, name):\n    GraphModule.__init__(self, name)\n    Configurable.__init__(self, params, mode)\n\n  def _build(self, inputs, *args, **kwargs):\n    return self.encode(inputs, *args, **kwargs)\n\n  @abc.abstractmethod\n  def encode(self, *args, **kwargs):\n    """"""\n    Encodes an input sequence.\n\n    Args:\n      inputs: The inputs to encode. A float32 tensor of shape [B, T, ...].\n      sequence_length: The length of each input. An int32 tensor of shape [T].\n\n    Returns:\n      An `EncoderOutput` tuple containing the outputs and final state.\n    """"""\n    raise NotImplementedError\n'"
seq2seq/encoders/image_encoder.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nImage encoder classes\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.nets.inception_v3 \\\n  import inception_v3_base\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\n\n\nclass InceptionV3Encoder(Encoder):\n  """"""\n  A unidirectional RNN encoder. Stacking should be performed as\n  part of the cell.\n\n  Params:\n    resize_height: Resize the image to this height before feeding it\n      into the convolutional network.\n    resize_width: Resize the image to this width before feeding it\n      into the convolutional network.\n  """"""\n\n  def __init__(self, params, mode, name=""image_encoder""):\n    super(InceptionV3Encoder, self).__init__(params, mode, name)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""resize_height"": 299,\n        ""resize_width"": 299,\n    }\n\n  def encode(self, inputs):\n    inputs = tf.image.resize_images(\n        images=inputs,\n        size=[self.params[""resize_height""], self.params[""resize_width""]],\n        method=tf.image.ResizeMethod.BILINEAR)\n\n    outputs, _ = inception_v3_base(tf.to_float(inputs))\n    output_shape = outputs.get_shape()  #pylint: disable=E1101\n    shape_list = output_shape.as_list()\n\n    # Take attentin over output elemnts in width and height dimension:\n    # Shape: [B, W*H, ...]\n    outputs_flat = tf.reshape(outputs, [shape_list[0], -1, shape_list[-1]])\n\n    # Final state is the pooled output\n    # Shape: [B, W*H*...]\n    final_state = tf.contrib.slim.avg_pool2d(\n        outputs, output_shape[1:3], padding=""VALID"", scope=""pool"")\n    final_state = tf.contrib.slim.flatten(outputs, scope=""flatten"")\n\n    return EncoderOutput(\n        outputs=outputs_flat,\n        final_state=final_state,\n        attention_values=outputs_flat,\n        attention_values_length=tf.shape(outputs_flat)[1])\n'"
seq2seq/encoders/pooling_encoder.py,10,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAn encoder that pools over embeddings, as described in\nhttps://arxiv.org/abs/1611.02344.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pydoc import locate\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\n\n\ndef position_encoding(sentence_size, embedding_size):\n  """"""\n  Position Encoding described in section 4.1 of\n  End-To-End Memory Networks (https://arxiv.org/abs/1503.08895).\n\n  Args:\n    sentence_size: length of the sentence\n    embedding_size: dimensionality of the embeddings\n\n  Returns:\n    A numpy array of shape [sentence_size, embedding_size] containing\n    the fixed position encodings for each sentence position.\n  """"""\n  encoding = np.ones((sentence_size, embedding_size), dtype=np.float32)\n  ls = sentence_size + 1\n  le = embedding_size + 1\n  for k in range(1, le):\n    for j in range(1, ls):\n      encoding[j-1, k-1] = (1.0 - j/float(ls)) - (\n          k / float(le)) * (1. - 2. * j/float(ls))\n  return encoding\n\n\ndef _create_position_embedding(embedding_dim, num_positions, lengths, maxlen):\n  """"""Creates position embeddings.\n\n  Args:\n    embedding_dim: Dimensionality of the embeddings. An integer.\n    num_positions: The number of positions to be embedded. For example,\n      if you have inputs of length up to 100, this should be 100. An integer.\n    lengths: The lengths of the inputs to create position embeddings for.\n      An int32 tensor of shape `[batch_size]`.\n    maxlen: The maximum length of the input sequence to create position\n      embeddings for. An int32 tensor.\n\n  Returns:\n    A tensor of shape `[batch_size, maxlen, embedding_dim]` that contains\n    embeddings for each position. All elements past `lengths` are zero.\n  """"""\n  # Create constant position encodings\n  position_encodings = tf.constant(\n      position_encoding(num_positions, embedding_dim),\n      name=""position_encoding"")\n\n  # Slice to size of current sequence\n  pe_slice = position_encodings[:maxlen, :]\n  # Replicate encodings for each element in the batch\n  batch_size = tf.shape(lengths)[0]\n  pe_batch = tf.tile([pe_slice], [batch_size, 1, 1])\n\n  # Mask out positions that are padded\n  positions_mask = tf.sequence_mask(\n      lengths=lengths, maxlen=maxlen, dtype=tf.float32)\n  positions_embed = pe_batch * tf.expand_dims(positions_mask, 2)\n\n  return positions_embed\n\nclass PoolingEncoder(Encoder):\n  """"""An encoder that pools over embeddings, as described in\n  https://arxiv.org/abs/1611.02344. The encoder supports optional positions\n  embeddings and a configurable pooling window.\n\n  Params:\n    dropout_keep_prob: Dropout keep probability applied to the embeddings.\n    pooling_fn: The 1-d pooling function to use, e.g.\n      `tensorflow.layers.average_pooling1d`.\n    pool_size: The pooling window, passed as `pool_size` to\n      the pooling function.\n    strides: The stride during pooling, passed as `strides`\n      the pooling function.\n    position_embeddings.enable: If true, add position embeddings to the\n      inputs before pooling.\n    position_embeddings.combiner_fn: Function used to combine the\n      position embeddings with the inputs. For example, `tensorflow.add`.\n    position_embeddings.num_positions: Size of the position embedding matrix.\n      This should be set to the maximum sequence length of the inputs.\n  """"""\n\n  def __init__(self, params, mode, name=""pooling_encoder""):\n    super(PoolingEncoder, self).__init__(params, mode, name)\n    self._pooling_fn = locate(self.params[""pooling_fn""])\n    self._combiner_fn = locate(self.params[""position_embeddings.combiner_fn""])\n\n  @staticmethod\n  def default_params():\n    return {\n        ""dropout_keep_prob"": 0.8,\n        ""pooling_fn"": ""tensorflow.layers.average_pooling1d"",\n        ""pool_size"": 5,\n        ""strides"": 1,\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.combiner_fn"": ""tensorflow.multiply"",\n        ""position_embeddings.num_positions"": 100,\n    }\n\n  def encode(self, inputs, sequence_length):\n    if self.params[""position_embeddings.enable""]:\n      positions_embed = _create_position_embedding(\n          embedding_dim=inputs.get_shape().as_list()[-1],\n          num_positions=self.params[""position_embeddings.num_positions""],\n          lengths=sequence_length,\n          maxlen=tf.shape(inputs)[1])\n      inputs = self._combiner_fn(inputs, positions_embed)\n\n    # Apply dropout\n    inputs = tf.contrib.layers.dropout(\n        inputs=inputs,\n        keep_prob=self.params[""dropout_keep_prob""],\n        is_training=self.mode == tf.contrib.learn.ModeKeys.TRAIN)\n\n    outputs = self._pooling_fn(\n        inputs=inputs,\n        pool_size=self.params[""pool_size""],\n        strides=self.params[""strides""],\n        padding=""SAME"")\n\n    # Final state is the average representation of the pooled embeddings\n    final_state = tf.reduce_mean(outputs, 1)\n\n    return EncoderOutput(\n        outputs=outputs,\n        final_state=final_state,\n        attention_values=inputs,\n        attention_values_length=sequence_length)\n'"
seq2seq/encoders/rnn_encoder.py,17,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of RNN encoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport tensorflow as tf\nfrom tensorflow.contrib.rnn.python.ops import rnn\n\nfrom seq2seq.encoders.encoder import Encoder, EncoderOutput\nfrom seq2seq.training import utils as training_utils\n\n\ndef _unpack_cell(cell):\n  """"""Unpack the cells because the stack_bidirectional_dynamic_rnn\n  expects a list of cells, one per layer.""""""\n  if isinstance(cell, tf.contrib.rnn.MultiRNNCell):\n    return cell._cells  #pylint: disable=W0212\n  else:\n    return [cell]\n\n\ndef _default_rnn_cell_params():\n  """"""Creates default parameters used by multiple RNN encoders.\n  """"""\n  return {\n      ""cell_class"": ""BasicLSTMCell"",\n      ""cell_params"": {\n          ""num_units"": 128\n      },\n      ""dropout_input_keep_prob"": 1.0,\n      ""dropout_output_keep_prob"": 1.0,\n      ""num_layers"": 1,\n      ""residual_connections"": False,\n      ""residual_combiner"": ""add"",\n      ""residual_dense"": False\n  }\n\n\ndef _toggle_dropout(cell_params, mode):\n  """"""Disables dropout during eval/inference mode\n  """"""\n  cell_params = copy.deepcopy(cell_params)\n  if mode != tf.contrib.learn.ModeKeys.TRAIN:\n    cell_params[""dropout_input_keep_prob""] = 1.0\n    cell_params[""dropout_output_keep_prob""] = 1.0\n  return cell_params\n\n\nclass UnidirectionalRNNEncoder(Encoder):\n  """"""\n  A unidirectional RNN encoder. Stacking should be performed as\n  part of the cell.\n\n  Args:\n    cell: An instance of tf.contrib.rnn.RNNCell\n    name: A name for the encoder\n  """"""\n\n  def __init__(self, params, mode, name=""forward_rnn_encoder""):\n    super(UnidirectionalRNNEncoder, self).__init__(params, mode, name)\n    self.params[""rnn_cell""] = _toggle_dropout(self.params[""rnn_cell""], mode)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""rnn_cell"": _default_rnn_cell_params(),\n        ""init_scale"": 0.04,\n    }\n\n  def encode(self, inputs, sequence_length, **kwargs):\n    scope = tf.get_variable_scope()\n    scope.set_initializer(tf.random_uniform_initializer(\n        -self.params[""init_scale""],\n        self.params[""init_scale""]))\n\n    cell = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    outputs, state = tf.nn.dynamic_rnn(\n        cell=cell,\n        inputs=inputs,\n        sequence_length=sequence_length,\n        dtype=tf.float32,\n        **kwargs)\n    return EncoderOutput(\n        outputs=outputs,\n        final_state=state,\n        attention_values=outputs,\n        attention_values_length=sequence_length)\n\n\nclass BidirectionalRNNEncoder(Encoder):\n  """"""\n  A bidirectional RNN encoder. Uses the same cell for both the\n  forward and backward RNN. Stacking should be performed as part of\n  the cell.\n\n  Args:\n    cell: An instance of tf.contrib.rnn.RNNCell\n    name: A name for the encoder\n  """"""\n\n  def __init__(self, params, mode, name=""bidi_rnn_encoder""):\n    super(BidirectionalRNNEncoder, self).__init__(params, mode, name)\n    self.params[""rnn_cell""] = _toggle_dropout(self.params[""rnn_cell""], mode)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""rnn_cell"": _default_rnn_cell_params(),\n        ""init_scale"": 0.04,\n    }\n\n  def encode(self, inputs, sequence_length, **kwargs):\n    scope = tf.get_variable_scope()\n    scope.set_initializer(tf.random_uniform_initializer(\n        -self.params[""init_scale""],\n        self.params[""init_scale""]))\n\n    cell_fw = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    cell_bw = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    outputs, states = tf.nn.bidirectional_dynamic_rnn(\n        cell_fw=cell_fw,\n        cell_bw=cell_bw,\n        inputs=inputs,\n        sequence_length=sequence_length,\n        dtype=tf.float32,\n        **kwargs)\n\n    # Concatenate outputs and states of the forward and backward RNNs\n    outputs_concat = tf.concat(outputs, 2)\n\n    return EncoderOutput(\n        outputs=outputs_concat,\n        final_state=states,\n        attention_values=outputs_concat,\n        attention_values_length=sequence_length)\n\n\nclass StackBidirectionalRNNEncoder(Encoder):\n  """"""\n  A stacked bidirectional RNN encoder. Uses the same cell for both the\n  forward and backward RNN. Stacking should be performed as part of\n  the cell.\n\n  Args:\n    cell: An instance of tf.contrib.rnn.RNNCell\n    name: A name for the encoder\n  """"""\n\n  def __init__(self, params, mode, name=""stacked_bidi_rnn_encoder""):\n    super(StackBidirectionalRNNEncoder, self).__init__(params, mode, name)\n    self.params[""rnn_cell""] = _toggle_dropout(self.params[""rnn_cell""], mode)\n\n  @staticmethod\n  def default_params():\n    return {\n        ""rnn_cell"": _default_rnn_cell_params(),\n        ""init_scale"": 0.04,\n    }\n\n  def encode(self, inputs, sequence_length, **kwargs):\n    scope = tf.get_variable_scope()\n    scope.set_initializer(tf.random_uniform_initializer(\n        -self.params[""init_scale""],\n        self.params[""init_scale""]))\n\n    cell_fw = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n    cell_bw = training_utils.get_rnn_cell(**self.params[""rnn_cell""])\n\n    cells_fw = _unpack_cell(cell_fw)\n    cells_bw = _unpack_cell(cell_bw)\n\n    result = rnn.stack_bidirectional_dynamic_rnn(\n        cells_fw=cells_fw,\n        cells_bw=cells_bw,\n        inputs=inputs,\n        dtype=tf.float32,\n        sequence_length=sequence_length,\n        **kwargs)\n    outputs_concat, _output_state_fw, _output_state_bw = result\n    final_state = (_output_state_fw, _output_state_bw)\n    return EncoderOutput(\n        outputs=outputs_concat,\n        final_state=final_state,\n        attention_values=outputs_concat,\n        attention_values_length=sequence_length)\n'"
seq2seq/inference/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Modules related to running model inference.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom seq2seq.inference.inference import *\nimport seq2seq.inference.beam_search\n'"
seq2seq/inference/beam_search.py,34,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""In-Graph Beam Search Implementation.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import namedtuple\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\n\nclass BeamSearchState(\n    namedtuple(""BeamSearchState"", [""log_probs"", ""finished"", ""lengths""])):\n  """"""State for a single step of beam search.\n\n  Args:\n    log_probs: The current log probabilities of all beams\n    finished: A boolean vector that specifies which beams are finished\n    lengths: Lengths of all beams\n  """"""\n  pass\n\n\nclass BeamSearchStepOutput(\n    namedtuple(""BeamSearchStepOutput"",\n               [""scores"", ""predicted_ids"", ""beam_parent_ids""])):\n  """"""Outputs for a single step of beam search.\n\n  Args:\n    scores: Score for each beam, a float32 vector\n    predicted_ids: predictions for this step step, an int32 vector\n    beam_parent_ids: an int32 vector containing the beam indices of the\n      continued beams from the previous step\n  """"""\n  pass\n\n\nclass BeamSearchConfig(\n    namedtuple(""BeamSearchConfig"", [\n        ""beam_width"", ""vocab_size"", ""eos_token"", ""length_penalty_weight"",\n        ""choose_successors_fn""\n    ])):\n  """"""Configuration object for beam search.\n\n  Args:\n    beam_width: Number of beams to use, an integer\n    vocab_size: Output vocabulary size\n    eos_token: The id of the EOS token, used to mark beams as ""done""\n    length_penalty_weight: Weight for the length penalty factor. 0.0 disables\n      the penalty.\n    choose_successors_fn: A function used to choose beam successors based\n      on their scores. Maps from (scores, config) => (chosen scores, chosen_ids)\n  """"""\n  pass\n\n\ndef gather_tree_py(values, parents):\n  """"""Gathers path through a tree backwards from the leave nodes. Used\n  to reconstruct beams given their parents.""""""\n  beam_length = values.shape[0]\n  num_beams = values.shape[1]\n  res = np.zeros_like(values)\n  res[-1, :] = values[-1, :]\n  for beam_id in range(num_beams):\n    parent = parents[-1][beam_id]\n    for level in reversed(range(beam_length - 1)):\n      res[level, beam_id] = values[level][parent]\n      parent = parents[level][parent]\n  return np.array(res).astype(values.dtype)\n\n\ndef gather_tree(values, parents):\n  """"""Tensor version of gather_tree_py""""""\n  res = tf.py_func(\n      func=gather_tree_py, inp=[values, parents], Tout=values.dtype)\n  res.set_shape(values.get_shape().as_list())\n  return res\n\n\ndef create_initial_beam_state(config):\n  """"""Creates an instance of `BeamState` that can be used on the first\n  call to `beam_step`.\n\n  Args:\n    config: A BeamSearchConfig\n\n  Returns:\n    An instance of `BeamState`.\n  """"""\n  return BeamSearchState(\n      log_probs=tf.zeros([config.beam_width]),\n      finished=tf.zeros(\n          [config.beam_width], dtype=tf.bool),\n      lengths=tf.zeros(\n          [config.beam_width], dtype=tf.int32))\n\n\ndef length_penalty(sequence_lengths, penalty_factor):\n  """"""Calculates the length penalty according to\n  https://arxiv.org/abs/1609.08144\n\n   Args:\n    sequence_lengths: The sequence length of all hypotheses, a tensor\n      of shape [beam_size, vocab_size].\n    penalty_factor: A scalar that weights the length penalty.\n\n  Returns:\n    The length penalty factor, a tensor fo shape [beam_size].\n   """"""\n  return tf.div((5. + tf.to_float(sequence_lengths))**penalty_factor, (5. + 1.)\n                **penalty_factor)\n\ndef length_penalty_fairseq(sequence_lengths, penalty_factor):\n  return (tf.to_float(sequence_lengths))**penalty_factor\n\n\ndef hyp_score(log_probs, sequence_lengths, config):\n  """"""Calculates scores for beam search hypotheses.\n  """"""\n\n  # Calculate the length penality\n  length_penality_ = length_penalty_fairseq(\n      sequence_lengths=sequence_lengths,\n      penalty_factor=config.length_penalty_weight)\n\n  score = log_probs / length_penality_\n  return score\n\n\ndef choose_top_k(scores_flat, config):\n  """"""Chooses the top-k beams as successors.\n  """"""\n  next_beam_scores, word_indices = tf.nn.top_k(scores_flat, k=config.beam_width)\n  return next_beam_scores, word_indices\n\n\ndef nest_map(inputs, map_fn, name=None):\n  """"""Applies a function to (possibly nested) tuple of tensors.\n  """"""\n  if nest.is_sequence(inputs):\n    inputs_flat = nest.flatten(inputs)\n    y_flat = [map_fn(_) for _ in inputs_flat]\n    outputs = nest.pack_sequence_as(inputs, y_flat)\n  else:\n    outputs = map_fn(inputs)\n  if name:\n    outputs = tf.identity(outputs, name=name)\n  return outputs\n\n\ndef mask_probs(probs, eos_token, finished):\n  """"""Masks log probabilities such that finished beams\n  allocate all probability mass to eos. Unfinished beams remain unchanged.\n\n  Args:\n    probs: Log probabiltiies of shape `[beam_width, vocab_size]`\n    eos_token: An int32 id corresponding to the EOS token to allocate\n      probability to\n    finished: A boolean tensor of shape `[beam_width]` that specifies which\n      elements in the beam are finished already.\n\n  Returns:\n    A tensor of shape `[beam_width, vocab_size]`, where unfinished beams\n    stay unchanged and finished beams are replaced with a tensor that has all\n    probability on the EOS token.\n  """"""\n  vocab_size = tf.shape(probs)[1]\n  finished_mask = tf.expand_dims(tf.to_float(1. - tf.to_float(finished)), 1)\n  # These examples are not finished and we leave them\n  non_finished_examples = finished_mask * probs\n  # All finished examples are replaced with a vector that has all\n  # probability on EOS\n  finished_row = tf.one_hot(\n      eos_token,\n      vocab_size,\n      dtype=tf.float32,\n      on_value=0.,\n      off_value=tf.float32.min)\n  finished_examples = (1. - finished_mask) * finished_row\n  return finished_examples + non_finished_examples\n\n\ndef beam_search_step(time_, logits, beam_state, config):\n  """"""Performs a single step of Beam Search Decoding.\n\n  Args:\n    time_: Beam search time step, should start at 0. At time 0 we assume\n      that all beams are equal and consider only the first beam for\n      continuations.\n    logits: Logits at the current time step. A tensor of shape `[B, vocab_size]`\n    beam_state: Current state of the beam search. An instance of `BeamState`\n    config: An instance of `BeamSearchConfig`\n\n  Returns:\n    A new beam state.\n  """"""\n\n  # Calculate the current lengths of the predictions\n  prediction_lengths = beam_state.lengths\n  previously_finished = beam_state.finished\n\n  # Calculate the total log probs for the new hypotheses\n  # Final Shape: [beam_width, vocab_size]\n  probs = tf.nn.log_softmax(logits)\n  probs = mask_probs(probs, config.eos_token, previously_finished)\n  total_probs = tf.expand_dims(beam_state.log_probs, 1) + probs\n\n  # Calculate the continuation lengths\n  # We add 1 to all continuations that are not EOS and were not\n  # finished previously\n  lengths_to_add = tf.one_hot([config.eos_token] * config.beam_width,\n                              config.vocab_size, 0, 1)\n  add_mask = (1 - tf.to_int32(previously_finished))\n  lengths_to_add = tf.expand_dims(add_mask, 1) * lengths_to_add\n  new_prediction_lengths = tf.expand_dims(prediction_lengths,\n                                          1) + lengths_to_add\n\n  # Calculate the scores for each beam\n  scores = hyp_score(\n      log_probs=total_probs,\n      sequence_lengths=new_prediction_lengths,\n      config=config)\n\n  scores_flat = tf.reshape(scores, [-1])\n  # During the first time step we only consider the initial beam\n  scores_flat = tf.cond(\n      tf.convert_to_tensor(time_) > 0, lambda: scores_flat, lambda: scores[0])\n\n  # Pick the next beams according to the specified successors function\n  next_beam_scores, word_indices = config.choose_successors_fn(scores_flat,\n                                                               config)\n  next_beam_scores.set_shape([config.beam_width])\n  word_indices.set_shape([config.beam_width])\n\n  # Pick out the probs, beam_ids, and states according to the chosen predictions\n  total_probs_flat = tf.reshape(total_probs, [-1], name=""total_probs_flat"")\n  next_beam_probs = tf.gather(total_probs_flat, word_indices)\n  next_beam_probs.set_shape([config.beam_width])\n  next_word_ids = tf.mod(word_indices, config.vocab_size)\n  next_beam_ids = tf.div(word_indices, config.vocab_size)\n\n  # Append new ids to current predictions\n  next_finished = tf.logical_or(\n      tf.gather(beam_state.finished, next_beam_ids),\n      tf.equal(next_word_ids, config.eos_token))\n\n  # Calculate the length of the next predictions.\n  # 1. Finished beams remain unchanged\n  # 2. Beams that are now finished (EOS predicted) remain unchanged\n  # 3. Beams that are not yet finished have their length increased by 1\n  lengths_to_add = tf.to_int32(tf.not_equal(next_word_ids, config.eos_token))\n  lengths_to_add = (1 - tf.to_int32(next_finished)) * lengths_to_add\n  next_prediction_len = tf.gather(beam_state.lengths, next_beam_ids)\n  next_prediction_len += lengths_to_add\n\n  next_state = BeamSearchState(\n      log_probs=next_beam_probs,\n      lengths=next_prediction_len,\n      finished=next_finished)\n\n  output = BeamSearchStepOutput(\n      scores=next_beam_scores,\n      predicted_ids=next_word_ids,\n      beam_parent_ids=next_beam_ids)\n\n  return output, next_state\n'"
seq2seq/inference/inference.py,1,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n"""""" Generates model predictions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom seq2seq.training import utils as training_utils\n\n\ndef create_inference_graph(model, input_pipeline, batch_size=32):\n  """"""Creates a graph to perform inference.\n\n  Args:\n    task: An `InferenceTask` instance.\n    input_pipeline: An instance of `InputPipeline` that defines\n      how to read and parse data.\n    batch_size: The batch size used for inference\n\n  Returns:\n    The return value of the model function, typically a tuple of\n    (predictions, loss, train_op).\n  """"""\n\n  # TODO: This doesn\'t really belong here.\n  # How to get rid of this?\n  if hasattr(model, ""use_beam_search""):\n    if model.use_beam_search:\n      tf.logging.info(""Setting batch size to 1 for beam search."")\n      batch_size = 1\n\n  input_fn = training_utils.create_input_fn(\n      pipeline=input_pipeline,\n      batch_size=batch_size,\n      allow_smaller_final_batch=True)\n\n  # Build the graph\n  features, labels = input_fn()\n  return model(features=features, labels=labels, params=None)\n'"
seq2seq/metrics/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n"""""" Collection of metric-related functions\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'"
seq2seq/metrics/bleu.py,3,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""BLEU metric implementation.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport re\nimport subprocess\nimport tempfile\nimport numpy as np\n\nfrom six.moves import urllib\nimport tensorflow as tf\n\n\ndef moses_multi_bleu(hypotheses, references, lowercase=False):\n  """"""Calculate the bleu score for hypotheses and references\n  using the MOSES ulti-bleu.perl script.\n\n  Args:\n    hypotheses: A numpy array of strings where each string is a single example.\n    references: A numpy array of strings where each string is a single example.\n    lowercase: If true, pass the ""-lc"" flag to the multi-bleu script\n\n  Returns:\n    The BLEU score as a float32 value.\n  """"""\n\n  if np.size(hypotheses) == 0:\n    return np.float32(0.0)\n\n  # Get MOSES multi-bleu script\n  try:\n    multi_bleu_path, _ = urllib.request.urlretrieve(\n        ""https://raw.githubusercontent.com/moses-smt/mosesdecoder/""\n        ""master/scripts/generic/multi-bleu.perl"")\n    os.chmod(multi_bleu_path, 0o755)\n  except: #pylint: disable=W0702\n    tf.logging.info(""Unable to fetch multi-bleu.perl script, using local."")\n    metrics_dir = os.path.dirname(os.path.realpath(__file__))\n    bin_dir = os.path.abspath(os.path.join(metrics_dir, "".."", "".."", ""bin""))\n    multi_bleu_path = os.path.join(bin_dir, ""tools/multi-bleu.perl"")\n\n  # Dump hypotheses and references to tempfiles\n  hypothesis_file = tempfile.NamedTemporaryFile()\n  hypothesis_file.write(""\\n"".join(hypotheses).encode(""utf-8""))\n  hypothesis_file.write(b""\\n"")\n  hypothesis_file.flush()\n  reference_file = tempfile.NamedTemporaryFile()\n  reference_file.write(""\\n"".join(references).encode(""utf-8""))\n  reference_file.write(b""\\n"")\n  reference_file.flush()\n\n  # Calculate BLEU using multi-bleu script\n  with open(hypothesis_file.name, ""r"") as read_pred:\n    bleu_cmd = [multi_bleu_path]\n    if lowercase:\n      bleu_cmd += [""-lc""]\n    bleu_cmd += [reference_file.name]\n    try:\n      bleu_out = subprocess.check_output(\n          bleu_cmd, stdin=read_pred, stderr=subprocess.STDOUT)\n      bleu_out = bleu_out.decode(""utf-8"")\n      bleu_score = re.search(r""BLEU = (.+?),"", bleu_out).group(1)\n      bleu_score = float(bleu_score)\n    except subprocess.CalledProcessError as error:\n      if error.output is not None:\n        tf.logging.warning(""multi-bleu.perl script returned non-zero exit code"")\n        tf.logging.warning(error.output)\n      bleu_score = np.float32(0.0)\n\n  # Close temp files\n  hypothesis_file.close()\n  reference_file.close()\n\n  return np.float32(bleu_score)\n'"
seq2seq/metrics/metric_specs.py,18,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Collection of MetricSpecs for training and evaluation\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\nimport abc\n\nimport numpy as np\nimport six\n\nimport tensorflow as tf\nfrom tensorflow.contrib import metrics\nfrom tensorflow.contrib.learn import MetricSpec\n\nfrom seq2seq.data import postproc\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.metrics import rouge\nfrom seq2seq.metrics import bleu\n\n\ndef accumulate_strings(values, name=""strings""):\n  """"""Accumulates strings into a vector.\n\n  Args:\n    values: A 1-d string tensor that contains values to add to the accumulator.\n\n  Returns:\n    A tuple (value_tensor, update_op).\n  """"""\n  tf.assert_type(values, tf.string)\n  strings = tf.Variable(\n      name=name,\n      initial_value=[],\n      dtype=tf.string,\n      trainable=False,\n      collections=[],\n      validate_shape=True)\n  value_tensor = tf.identity(strings)\n  update_op = tf.assign(\n      ref=strings, value=tf.concat([strings, values], 0), validate_shape=False)\n  return value_tensor, update_op\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass TextMetricSpec(Configurable, MetricSpec):\n  """"""Abstract class for text-based metrics calculated based on\n  hypotheses and references. Subclasses must implement `metric_fn`.\n\n  Args:\n    name: A name for the metric\n    separator: A separator used to join predicted tokens. Default to space.\n    eos_token: A string token used to find the end of a sequence. Hypotheses\n      and references will be slcied until this token is found.\n  """"""\n\n  def __init__(self, params, name):\n    # We don\'t call the super constructor on purpose\n    #pylint: disable=W0231\n    """"""Initializer""""""\n    Configurable.__init__(self, params, tf.contrib.learn.ModeKeys.EVAL)\n    self._name = name\n    self._eos_token = self.params[""eos_token""]\n    self._sos_token = self.params[""sos_token""]\n    self._separator = self.params[""separator""]\n    self._postproc_fn = None\n    if self.params[""postproc_fn""]:\n      self._postproc_fn = locate(self.params[""postproc_fn""])\n      if self._postproc_fn is None:\n        raise ValueError(""postproc_fn not found: {}"".format(\n            self.params[""postproc_fn""]))\n\n  @property\n  def name(self):\n    """"""Name of the metric""""""\n    return self._name\n\n  @staticmethod\n  def default_params():\n    return {\n        ""sos_token"": ""SEQUENCE_START"",\n        ""eos_token"": ""SEQUENCE_END"",\n        ""separator"": "" "",\n        ""postproc_fn"": """",\n    }\n\n  def create_metric_ops(self, _inputs, labels, predictions):\n    """"""Creates (value, update_op) tensors\n    """"""\n    with tf.variable_scope(self._name):\n\n      # Join tokens into single strings\n      predictions_flat = tf.reduce_join(\n          predictions[""predicted_tokens""], 1, separator=self._separator)\n      labels_flat = tf.reduce_join(\n          labels[""target_tokens""], 1, separator=self._separator)\n\n      sources_value, sources_update = accumulate_strings(\n          values=predictions_flat, name=""sources"")\n      targets_value, targets_update = accumulate_strings(\n          values=labels_flat, name=""targets"")\n\n      metric_value = tf.py_func(\n          func=self._py_func,\n          inp=[sources_value, targets_value],\n          Tout=tf.float32,\n          name=""value"")\n\n    with tf.control_dependencies([sources_update, targets_update]):\n      update_op = tf.identity(metric_value, name=""update_op"")\n\n    return metric_value, update_op\n\n  def _py_func(self, hypotheses, references):\n    """"""Wrapper function that converts tensors to unicode and slices\n      them until the EOS token is found.\n    """"""\n    # Deal with byte chars\n    if hypotheses.dtype.kind == np.dtype(""U""):\n      hypotheses = np.char.encode(hypotheses, ""utf-8"")\n    if references.dtype.kind == np.dtype(""U""):\n      references = np.char.encode(references, ""utf-8"")\n\n    # Convert back to unicode object\n    hypotheses = [_.decode(""utf-8"") for _ in hypotheses]\n    references = [_.decode(""utf-8"") for _ in references]\n\n    # Slice all hypotheses and references up to SOS -> EOS\n    sliced_hypotheses = [postproc.slice_text(\n        _, self._eos_token, self._sos_token) for _ in hypotheses]\n    sliced_references = [postproc.slice_text(\n        _, self._eos_token, self._sos_token) for _ in references]\n\n    # Apply postprocessing function\n    if self._postproc_fn:\n      sliced_hypotheses = [self._postproc_fn(_) for _ in sliced_hypotheses]\n      sliced_references = [self._postproc_fn(_) for _ in sliced_references]\n\n    return self.metric_fn(sliced_hypotheses, sliced_references) #pylint: disable=E1102\n\n  def metric_fn(self, hypotheses, references):\n    """"""Calculates the value of the metric.\n\n    Args:\n      hypotheses: A python list of strings, each corresponding to a\n        single hypothesis/example.\n      references: A python list of strings, each corresponds to a single\n        reference. Must have the same number of elements of `hypotheses`.\n\n    Returns:\n      A float value.\n    """"""\n    raise NotImplementedError()\n\n\nclass BleuMetricSpec(TextMetricSpec):\n  """"""Calculates BLEU score using the Moses multi-bleu.perl script.\n  """"""\n\n  def __init__(self, params):\n    super(BleuMetricSpec, self).__init__(params, ""bleu"")\n\n  def metric_fn(self, hypotheses, references):\n    return bleu.moses_multi_bleu(hypotheses, references, lowercase=False)\n\n\nclass RougeMetricSpec(TextMetricSpec):\n  """"""Calculates BLEU score using the Moses multi-bleu.perl script.\n  """"""\n\n  def __init__(self, params, **kwargs):\n    if not params[""rouge_type""]:\n      raise ValueError(""You must provide a rouge_type for ROUGE"")\n    super(RougeMetricSpec, self).__init__(\n        params, params[""rouge_type""], **kwargs)\n    self._rouge_type = self.params[""rouge_type""]\n\n  @staticmethod\n  def default_params():\n    params = TextMetricSpec.default_params()\n    params.update({\n        ""rouge_type"": """",\n    })\n    return params\n\n  def metric_fn(self, hypotheses, references):\n    if not hypotheses or not references:\n      return np.float32(0.0)\n    return np.float32(rouge.rouge(hypotheses, references)[self._rouge_type])\n\n\nclass LogPerplexityMetricSpec(MetricSpec, Configurable):\n  """"""A MetricSpec to calculate straming log perplexity""""""\n\n  def __init__(self, params):\n    """"""Initializer""""""\n    # We don\'t call the super constructor on purpose\n    #pylint: disable=W0231\n    Configurable.__init__(self, params, tf.contrib.learn.ModeKeys.EVAL)\n\n  @staticmethod\n  def default_params():\n    return {}\n\n  @property\n  def name(self):\n    """"""Name of the metric""""""\n    return ""log_perplexity""\n\n  def create_metric_ops(self, _inputs, labels, predictions):\n    """"""Creates the metric op""""""\n    loss_mask = tf.sequence_mask(\n        lengths=tf.to_int32(labels[""target_len""] - 1),\n        maxlen=tf.to_int32(tf.shape(predictions[""losses""])[1]))\n    return metrics.streaming_mean(predictions[""losses""], loss_mask)\n'"
seq2seq/metrics/rouge.py,0,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""ROUGe metric implementation.\n\nThis is a modified and slightly extended verison of\nhttps://github.com/miso-belica/sumy/blob/dev/sumy/evaluation/rouge.py.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport itertools\nimport numpy as np\n\n#pylint: disable=C0103\n\n\ndef _get_ngrams(n, text):\n  """"""Calcualtes n-grams.\n\n  Args:\n    n: which n-grams to calculate\n    text: An array of tokens\n\n  Returns:\n    A set of n-grams\n  """"""\n  ngram_set = set()\n  text_length = len(text)\n  max_index_ngram_start = text_length - n\n  for i in range(max_index_ngram_start + 1):\n    ngram_set.add(tuple(text[i:i + n]))\n  return ngram_set\n\n\ndef _split_into_words(sentences):\n  """"""Splits multiple sentences into words and flattens the result""""""\n  return list(itertools.chain(*[_.split("" "") for _ in sentences]))\n\n\ndef _get_word_ngrams(n, sentences):\n  """"""Calculates word n-grams for multiple sentences.\n  """"""\n  assert len(sentences) > 0\n  assert n > 0\n\n  words = _split_into_words(sentences)\n  return _get_ngrams(n, words)\n\n\ndef _len_lcs(x, y):\n  """"""\n  Returns the length of the Longest Common Subsequence between sequences x\n  and y.\n  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n\n  Args:\n    x: sequence of words\n    y: sequence of words\n\n  Returns\n    integer: Length of LCS between x and y\n  """"""\n  table = _lcs(x, y)\n  n, m = len(x), len(y)\n  return table[n, m]\n\n\ndef _lcs(x, y):\n  """"""\n  Computes the length of the longest common subsequence (lcs) between two\n  strings. The implementation below uses a DP programming algorithm and runs\n  in O(nm) time where n = len(x) and m = len(y).\n  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n\n  Args:\n    x: collection of words\n    y: collection of words\n\n  Returns:\n    Table of dictionary of coord and len lcs\n  """"""\n  n, m = len(x), len(y)\n  table = dict()\n  for i in range(n + 1):\n    for j in range(m + 1):\n      if i == 0 or j == 0:\n        table[i, j] = 0\n      elif x[i - 1] == y[j - 1]:\n        table[i, j] = table[i - 1, j - 1] + 1\n      else:\n        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n  return table\n\n\ndef _recon_lcs(x, y):\n  """"""\n  Returns the Longest Subsequence between x and y.\n  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n\n  Args:\n    x: sequence of words\n    y: sequence of words\n\n  Returns:\n    sequence: LCS of x and y\n  """"""\n  i, j = len(x), len(y)\n  table = _lcs(x, y)\n\n  def _recon(i, j):\n    """"""private recon calculation""""""\n    if i == 0 or j == 0:\n      return []\n    elif x[i - 1] == y[j - 1]:\n      return _recon(i - 1, j - 1) + [(x[i - 1], i)]\n    elif table[i - 1, j] > table[i, j - 1]:\n      return _recon(i - 1, j)\n    else:\n      return _recon(i, j - 1)\n\n  recon_tuple = tuple(map(lambda x: x[0], _recon(i, j)))\n  return recon_tuple\n\n\ndef rouge_n(evaluated_sentences, reference_sentences, n=2):\n  """"""\n  Computes ROUGE-N of two text collections of sentences.\n  Sourece: http://research.microsoft.com/en-us/um/people/cyl/download/\n  papers/rouge-working-note-v1.3.1.pdf\n\n  Args:\n    evaluated_sentences: The sentences that have been picked by the summarizer\n    reference_sentences: The sentences from the referene set\n    n: Size of ngram.  Defaults to 2.\n\n  Returns:\n    A tuple (f1, precision, recall) for ROUGE-N\n\n  Raises:\n    ValueError: raises exception if a param has len <= 0\n  """"""\n  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n    raise ValueError(""Collections must contain at least 1 sentence."")\n\n  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n  reference_count = len(reference_ngrams)\n  evaluated_count = len(evaluated_ngrams)\n\n  # Gets the overlapping ngrams between evaluated and reference\n  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n  overlapping_count = len(overlapping_ngrams)\n\n  # Handle edge case. This isn\'t mathematically correct, but it\'s good enough\n  if evaluated_count == 0:\n    precision = 0.0\n  else:\n    precision = overlapping_count / evaluated_count\n\n  if reference_count == 0:\n    recall = 0.0\n  else:\n    recall = overlapping_count / reference_count\n\n  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n\n  # return overlapping_count / reference_count\n  return f1_score, precision, recall\n\n\ndef _f_p_r_lcs(llcs, m, n):\n  """"""\n  Computes the LCS-based F-measure score\n  Source: http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n  rouge-working-note-v1.3.1.pdf\n\n  Args:\n    llcs: Length of LCS\n    m: number of words in reference summary\n    n: number of words in candidate summary\n\n  Returns:\n    Float. LCS-based F-measure score\n  """"""\n  r_lcs = llcs / m\n  p_lcs = llcs / n\n  beta = p_lcs / (r_lcs + 1e-12)\n  num = (1 + (beta**2)) * r_lcs * p_lcs\n  denom = r_lcs + ((beta**2) * p_lcs)\n  f_lcs = num / (denom + 1e-12)\n  return f_lcs, p_lcs, r_lcs\n\n\ndef rouge_l_sentence_level(evaluated_sentences, reference_sentences):\n  """"""\n  Computes ROUGE-L (sentence level) of two text collections of sentences.\n  http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n  rouge-working-note-v1.3.1.pdf\n\n  Calculated according to:\n  R_lcs = LCS(X,Y)/m\n  P_lcs = LCS(X,Y)/n\n  F_lcs = ((1 + beta^2)*R_lcs*P_lcs) / (R_lcs + (beta^2) * P_lcs)\n\n  where:\n  X = reference summary\n  Y = Candidate summary\n  m = length of reference summary\n  n = length of candidate summary\n\n  Args:\n    evaluated_sentences: The sentences that have been picked by the summarizer\n    reference_sentences: The sentences from the referene set\n\n  Returns:\n    A float: F_lcs\n\n  Raises:\n    ValueError: raises exception if a param has len <= 0\n  """"""\n  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n    raise ValueError(""Collections must contain at least 1 sentence."")\n  reference_words = _split_into_words(reference_sentences)\n  evaluated_words = _split_into_words(evaluated_sentences)\n  m = len(reference_words)\n  n = len(evaluated_words)\n  lcs = _len_lcs(evaluated_words, reference_words)\n  return _f_p_r_lcs(lcs, m, n)\n\n\ndef _union_lcs(evaluated_sentences, reference_sentence):\n  """"""\n  Returns LCS_u(r_i, C) which is the LCS score of the union longest common\n  subsequence between reference sentence ri and candidate summary C. For example\n  if r_i= w1 w2 w3 w4 w5, and C contains two sentences: c1 = w1 w2 w6 w7 w8 and\n  c2 = w1 w3 w8 w9 w5, then the longest common subsequence of r_i and c1 is\n  \xe2\x80\x9cw1 w2\xe2\x80\x9d and the longest common subsequence of r_i and c2 is \xe2\x80\x9cw1 w3 w5\xe2\x80\x9d. The\n  union longest common subsequence of r_i, c1, and c2 is \xe2\x80\x9cw1 w2 w3 w5\xe2\x80\x9d and\n  LCS_u(r_i, C) = 4/5.\n\n  Args:\n    evaluated_sentences: The sentences that have been picked by the summarizer\n    reference_sentence: One of the sentences in the reference summaries\n\n  Returns:\n    float: LCS_u(r_i, C)\n\n  ValueError:\n    Raises exception if a param has len <= 0\n  """"""\n  if len(evaluated_sentences) <= 0:\n    raise ValueError(""Collections must contain at least 1 sentence."")\n\n  lcs_union = set()\n  reference_words = _split_into_words([reference_sentence])\n  combined_lcs_length = 0\n  for eval_s in evaluated_sentences:\n    evaluated_words = _split_into_words([eval_s])\n    lcs = set(_recon_lcs(reference_words, evaluated_words))\n    combined_lcs_length += len(lcs)\n    lcs_union = lcs_union.union(lcs)\n\n  union_lcs_count = len(lcs_union)\n  union_lcs_value = union_lcs_count / combined_lcs_length\n  return union_lcs_value\n\n\ndef rouge_l_summary_level(evaluated_sentences, reference_sentences):\n  """"""\n  Computes ROUGE-L (summary level) of two text collections of sentences.\n  http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n  rouge-working-note-v1.3.1.pdf\n\n  Calculated according to:\n  R_lcs = SUM(1, u)[LCS<union>(r_i,C)]/m\n  P_lcs = SUM(1, u)[LCS<union>(r_i,C)]/n\n  F_lcs = ((1 + beta^2)*R_lcs*P_lcs) / (R_lcs + (beta^2) * P_lcs)\n\n  where:\n  SUM(i,u) = SUM from i through u\n  u = number of sentences in reference summary\n  C = Candidate summary made up of v sentences\n  m = number of words in reference summary\n  n = number of words in candidate summary\n\n  Args:\n    evaluated_sentences: The sentences that have been picked by the summarizer\n    reference_sentence: One of the sentences in the reference summaries\n\n  Returns:\n    A float: F_lcs\n\n  Raises:\n    ValueError: raises exception if a param has len <= 0\n  """"""\n  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n    raise ValueError(""Collections must contain at least 1 sentence."")\n\n  # total number of words in reference sentences\n  m = len(_split_into_words(reference_sentences))\n\n  # total number of words in evaluated sentences\n  n = len(_split_into_words(evaluated_sentences))\n\n  union_lcs_sum_across_all_references = 0\n  for ref_s in reference_sentences:\n    union_lcs_sum_across_all_references += _union_lcs(evaluated_sentences,\n                                                      ref_s)\n  return _f_p_r_lcs(union_lcs_sum_across_all_references, m, n)\n\n\ndef rouge(hypotheses, references):\n  """"""Calculates average rouge scores for a list of hypotheses and\n  references""""""\n\n  # Filter out hyps that are of 0 length\n  # hyps_and_refs = zip(hypotheses, references)\n  # hyps_and_refs = [_ for _ in hyps_and_refs if len(_[0]) > 0]\n  # hypotheses, references = zip(*hyps_and_refs)\n\n  # Calculate ROUGE-1 F1, precision, recall scores\n  rouge_1 = [\n      rouge_n([hyp], [ref], 1) for hyp, ref in zip(hypotheses, references)\n  ]\n  rouge_1_f, rouge_1_p, rouge_1_r = map(np.mean, zip(*rouge_1))\n\n  # Calculate ROUGE-2 F1, precision, recall scores\n  rouge_2 = [\n      rouge_n([hyp], [ref], 2) for hyp, ref in zip(hypotheses, references)\n  ]\n  rouge_2_f, rouge_2_p, rouge_2_r = map(np.mean, zip(*rouge_2))\n\n  # Calculate ROUGE-L F1, precision, recall scores\n  rouge_l = [\n      rouge_l_sentence_level([hyp], [ref])\n      for hyp, ref in zip(hypotheses, references)\n  ]\n  rouge_l_f, rouge_l_p, rouge_l_r = map(np.mean, zip(*rouge_l))\n\n  return {\n      ""rouge_1/f_score"": rouge_1_f,\n      ""rouge_1/r_score"": rouge_1_r,\n      ""rouge_1/p_score"": rouge_1_p,\n      ""rouge_2/f_score"": rouge_2_f,\n      ""rouge_2/r_score"": rouge_2_r,\n      ""rouge_2/p_score"": rouge_2_p,\n      ""rouge_l/f_score"": rouge_l_f,\n      ""rouge_l/r_score"": rouge_l_r,\n      ""rouge_l/p_score"": rouge_l_p,\n  }\n'"
seq2seq/models/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This module contains various Encoder-Decoder models\n""""""\n\nfrom seq2seq.models.basic_seq2seq import BasicSeq2Seq\nfrom seq2seq.models.attention_seq2seq import AttentionSeq2Seq\nfrom seq2seq.models.image2seq import Image2Seq\nfrom seq2seq.models.conv_seq2seq import ConvSeq2Seq\n\n\nimport seq2seq.models.bridges\nimport seq2seq.models.model_base\n'"
seq2seq/models/attention_seq2seq.py,1,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nSequence to Sequence model with attention\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\n\nimport tensorflow as tf\n\nfrom seq2seq import decoders\nfrom seq2seq.models.basic_seq2seq import BasicSeq2Seq\n\n\nclass AttentionSeq2Seq(BasicSeq2Seq):\n  """"""Sequence2Sequence model with attention mechanism.\n\n  Args:\n    source_vocab_info: An instance of `VocabInfo`\n      for the source vocabulary\n    target_vocab_info: An instance of `VocabInfo`\n      for the target vocabulary\n    params: A dictionary of hyperparameters\n  """"""\n\n  def __init__(self, params, mode, name=""att_seq2seq""):\n    super(AttentionSeq2Seq, self).__init__(params, mode, name)\n\n  @staticmethod\n  def default_params():\n    params = BasicSeq2Seq.default_params().copy()\n    params.update({\n        ""attention.class"": ""AttentionLayerBahdanau"",\n        ""attention.params"": {}, # Arbitrary attention layer parameters\n        ""bridge.class"": ""seq2seq.models.bridges.ZeroBridge"",\n        ""encoder.class"": ""seq2seq.encoders.BidirectionalRNNEncoder"",\n        ""encoder.params"": {},  # Arbitrary parameters for the encoder\n        ""decoder.class"": ""seq2seq.decoders.AttentionDecoder"",\n        ""decoder.params"": {}  # Arbitrary parameters for the decoder\n    })\n    return params\n\n  def _create_decoder(self, encoder_output, features, _labels):\n    attention_class = locate(self.params[""attention.class""]) or \\\n      getattr(decoders.attention, self.params[""attention.class""])\n    attention_layer = attention_class(\n        params=self.params[""attention.params""], mode=self.mode)\n\n    # If the input sequence is reversed we also need to reverse\n    # the attention scores.\n    reverse_scores_lengths = None\n    if self.params[""source.reverse""]:\n      reverse_scores_lengths = features[""source_len""]\n      if self.use_beam_search:\n        reverse_scores_lengths = tf.tile(\n            input=reverse_scores_lengths,\n            multiples=[self.params[""inference.beam_search.beam_width""]])\n\n    return self.decoder_class(\n        params=self.params[""decoder.params""],\n        mode=self.mode,\n        vocab_size=self.target_vocab_info.total_size,\n        attention_values=encoder_output.attention_values,\n        attention_values_length=encoder_output.attention_values_length,\n        attention_keys=encoder_output.outputs,\n        attention_fn=attention_layer,\n        reverse_scores_lengths=reverse_scores_lengths)\n'"
seq2seq/models/basic_seq2seq.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nDefinition of a basic seq2seq model\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\nimport tensorflow as tf\nfrom seq2seq.contrib.seq2seq import helper as tf_decode_helper\n\nfrom seq2seq.models.seq2seq_model import Seq2SeqModel\nfrom seq2seq.graph_utils import templatemethod\nfrom seq2seq.models import bridges\n\n\nclass BasicSeq2Seq(Seq2SeqModel):\n  """"""Basic Sequence2Sequence model with a unidirectional encoder and decoder.\n  The last encoder state is used to initialize the decoder and thus both\n  must share the same type of RNN cell.\n\n  Args:\n    source_vocab_info: An instance of `VocabInfo`\n      for the source vocabulary\n    target_vocab_info: An instance of `VocabInfo`\n      for the target vocabulary\n    params: A dictionary of hyperparameters\n  """"""\n\n  def __init__(self, params, mode, name=""basic_seq2seq""):\n    super(BasicSeq2Seq, self).__init__(params, mode, name)\n    self.encoder_class = locate(self.params[""encoder.class""])\n    self.decoder_class = locate(self.params[""decoder.class""])\n\n  @staticmethod\n  def default_params():\n    params = Seq2SeqModel.default_params().copy()\n    params.update({\n        ""bridge.class"": ""seq2seq.models.bridges.InitialStateBridge"",\n        ""bridge.params"": {},\n        ""encoder.class"": ""seq2seq.encoders.UnidirectionalRNNEncoder"",\n        ""encoder.params"": {},  # Arbitrary parameters for the encoder\n        ""decoder.class"": ""seq2seq.decoders.BasicDecoder"",\n        ""decoder.params"": {}  # Arbitrary parameters for the decoder\n    })\n    return params\n\n  def _create_bridge(self, encoder_outputs, decoder_state_size):\n    """"""Creates the bridge to be used between encoder and decoder""""""\n    bridge_class = locate(self.params[""bridge.class""]) or \\\n      getattr(bridges, self.params[""bridge.class""])\n    return bridge_class(\n        encoder_outputs=encoder_outputs,\n        decoder_state_size=decoder_state_size,\n        params=self.params[""bridge.params""],\n        mode=self.mode)\n\n  def _create_decoder(self, _encoder_output, _features, _labels):\n    """"""Creates a decoder instance based on the passed parameters.""""""\n    return self.decoder_class(\n        params=self.params[""decoder.params""],\n        mode=self.mode,\n        vocab_size=self.target_vocab_info.total_size)\n\n  def _decode_train(self, decoder, bridge, _encoder_output, _features, labels):\n    """"""Runs decoding in training mode""""""\n    target_embedded = tf.nn.embedding_lookup(self.target_embedding,\n                                             labels[""target_ids""])\n    helper_train = tf_decode_helper.TrainingHelper(\n        inputs=target_embedded[:, :-1],\n        sequence_length=labels[""target_len""] - 1)\n    decoder_initial_state = bridge()\n    return decoder(decoder_initial_state, helper_train)\n\n  def _decode_infer(self, decoder, bridge, _encoder_output, features, labels):\n    """"""Runs decoding in inference mode""""""\n    batch_size = self.batch_size(features, labels)\n    if self.use_beam_search:\n      batch_size = self.params[""inference.beam_search.beam_width""]\n\n    target_start_id = self.target_vocab_info.special_vocab.SEQUENCE_START\n    helper_infer = tf_decode_helper.GreedyEmbeddingHelper(\n        embedding=self.target_embedding,\n        start_tokens=tf.fill([batch_size], target_start_id),\n        end_token=self.target_vocab_info.special_vocab.SEQUENCE_END)\n    decoder_initial_state = bridge()\n    return decoder(decoder_initial_state, helper_infer)\n\n  @templatemethod(""encode"")\n  def encode(self, features, labels):\n    source_embedded = tf.nn.embedding_lookup(self.source_embedding,\n                                             features[""source_ids""])\n    encoder_fn = self.encoder_class(self.params[""encoder.params""], self.mode)\n    return encoder_fn(source_embedded, features[""source_len""])\n\n  @templatemethod(""decode"")\n  def decode(self, encoder_output, features, labels):\n    decoder = self._create_decoder(encoder_output, features, labels)\n    if self.use_beam_search:\n      decoder = self._get_beam_search_decoder(decoder)\n\n    bridge = self._create_bridge(\n        encoder_outputs=encoder_output,\n        decoder_state_size=decoder.cell.state_size)\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      return self._decode_infer(decoder, bridge, encoder_output, features,\n                                labels)\n    else:\n      return self._decode_train(decoder, bridge, encoder_output, features,\n                                labels)\n'"
seq2seq/models/bridges.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""A collection of bridges between encoder and decoder. A bridge defines\nhow encoder information are passed to the decoder.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nfrom pydoc import locate\n\nimport six\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.configurable import Configurable\n\n\ndef _total_tensor_depth(tensor):\n  """"""Returns the size of a tensor without the first (batch) dimension""""""\n  return np.prod(tensor.get_shape().as_list()[1:])\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Bridge(Configurable):\n  """"""An abstract bridge class. A bridge defines how state is passed\n  between encoder and decoder.\n\n  All logic is contained in the `_create` method, which returns an\n  initial state for the decoder.\n\n  Args:\n    encoder_outputs: A namedtuple that corresponds to the the encoder outputs.\n    decoder_state_size: An integer or tuple of integers defining the\n      state size of the decoder.\n  """"""\n\n  def __init__(self, encoder_outputs, decoder_state_size, params, mode):\n    Configurable.__init__(self, params, mode)\n    self.encoder_outputs = encoder_outputs\n    self.decoder_state_size = decoder_state_size\n    self.batch_size = tf.shape(\n        nest.flatten(self.encoder_outputs.final_state)[0])[0]\n\n  def __call__(self):\n    """"""Runs the bridge function.\n\n    Returns:\n      An initial decoder_state tensor or tuple of tensors.\n    """"""\n    return self._create()\n\n  @abc.abstractmethod\n  def _create(self):\n    """""" Implements the logic for this bridge.\n    This function should be implemented by child classes.\n\n    Returns:\n      A tuple initial_decoder_state tensor or tuple of tensors.\n    """"""\n    raise NotImplementedError(""Must be implemented by child class"")\n\n\nclass ZeroBridge(Bridge):\n  """"""A bridge that does not pass any information between encoder and decoder\n  and sets the initial decoder state to 0. The input function is not modified.\n  """"""\n\n  @staticmethod\n  def default_params():\n    return {}\n\n  def _create(self):\n    zero_state = nest.map_structure(\n        lambda x: tf.zeros([self.batch_size, x], dtype=tf.float32),\n        self.decoder_state_size)\n    return zero_state\n\n\nclass PassThroughBridge(Bridge):\n  """"""Passes the encoder state through to the decoder as-is. This bridge\n  can only be used if encoder and decoder have the exact same state size, i.e.\n  use the same RNN cell.\n  """"""\n\n  @staticmethod\n  def default_params():\n    return {}\n\n  def _create(self):\n    nest.assert_same_structure(self.encoder_outputs.final_state,\n                               self.decoder_state_size)\n    return self.encoder_outputs.final_state\n\n\nclass InitialStateBridge(Bridge):\n  """"""A bridge that creates an initial decoder state based on the output\n  of the encoder. This state is created by passing the encoder outputs\n  through an additional layer to match them to the decoder state size.\n  The input function remains unmodified.\n\n  Args:\n    encoder_outputs: A namedtuple that corresponds to the the encoder outputs.\n    decoder_state_size: An integer or tuple of integers defining the\n      state size of the decoder.\n    bridge_input: Which attribute of the `encoder_outputs` to use for the\n      initial state calculation. For example, ""final_state"" means that\n      `encoder_outputs.final_state` will be used.\n    activation_fn: An optional activation function for the extra\n      layer inserted between encoder and decoder. A string for a function\n      name contained in `tf.nn`, e.g. ""tanh"".\n  """"""\n\n  def __init__(self, encoder_outputs, decoder_state_size, params, mode):\n    super(InitialStateBridge, self).__init__(encoder_outputs,\n                                             decoder_state_size, params, mode)\n\n    if not hasattr(encoder_outputs, self.params[""bridge_input""]):\n      raise ValueError(""Invalid bridge_input not in encoder outputs."")\n\n    self._bridge_input = getattr(encoder_outputs, self.params[""bridge_input""])\n    self._activation_fn = locate(self.params[""activation_fn""])\n\n  @staticmethod\n  def default_params():\n    return {\n        ""bridge_input"": ""final_state"",\n        ""activation_fn"": ""tensorflow.identity"",\n    }\n\n  def _create(self):\n    # Concat bridge inputs on the depth dimensions\n    bridge_input = nest.map_structure(\n        lambda x: tf.reshape(x, [self.batch_size, _total_tensor_depth(x)]),\n        self._bridge_input)\n    bridge_input_flat = nest.flatten([bridge_input])\n    bridge_input_concat = tf.concat(bridge_input_flat, 1)\n\n    state_size_splits = nest.flatten(self.decoder_state_size)\n    total_decoder_state_size = sum(state_size_splits)\n\n    # Pass bridge inputs through a fully connected layer layer\n    initial_state_flat = tf.contrib.layers.fully_connected(\n        inputs=bridge_input_concat,\n        num_outputs=total_decoder_state_size,\n        activation_fn=self._activation_fn)\n\n    # Shape back into required state size\n    initial_state = tf.split(initial_state_flat, state_size_splits, axis=1)\n    return nest.pack_sequence_as(self.decoder_state_size, initial_state)\n'"
seq2seq/models/conv_seq2seq.py,14,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nDefinition of a basic seq2seq model\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom pydoc import locate\nimport tensorflow as tf\nfrom seq2seq.contrib.seq2seq import helper as tf_decode_helper\n\nfrom seq2seq.models.seq2seq_model import Seq2SeqModel\nfrom seq2seq.graph_utils import templatemethod\nfrom seq2seq.models import bridges\nfrom seq2seq.inference import beam_search\n\nclass ConvSeq2Seq(Seq2SeqModel):\n  """"""Basic Sequence2Sequence model with a unidirectional encoder and decoder.\n  The last encoder state is used to initialize the decoder and thus both\n  must share the same type of RNN cell.\n\n  Args:\n    source_vocab_info: An instance of `VocabInfo`\n      for the source vocabulary\n    target_vocab_info: An instance of `VocabInfo`\n      for the target vocabulary\n    params: A dictionary of hyperparameters\n  """"""\n\n  def __init__(self, params, mode, name=""conv_seq2seq""):\n    super(ConvSeq2Seq, self).__init__(params, mode, name)\n    self.encoder_class = locate(self.params[""encoder.class""])\n    self.decoder_class = locate(self.params[""decoder.class""])\n\n  @staticmethod\n  def default_params():\n    params = Seq2SeqModel.default_params().copy()\n    params.update({\n        ""encoder.class"": ""seq2seq.encoders.ConvEncoderFairseq"",\n        ""encoder.params"": {},  # Arbitrary parameters for the encoder\n        ""decoder.class"": ""seq2seq.decoders.ConvDecoder"",\n        ""decoder.params"": {},  # Arbitrary parameters for the decoder\n        ""source.max_seq_len"": 50,\n        ""source.reverse"": False,\n        ""target.max_seq_len"": 50,\n        ""embedding.dim"": 256,\n        ""embedding.init_scale"": 0.04,\n        ""embedding.share"": False,\n        ""position_embeddings.num_positions"": 100,\n        ""inference.beam_search.beam_width"": 0,\n        ""inference.beam_search.length_penalty_weight"": 1.0,\n        ""inference.beam_search.choose_successors_fn"": ""choose_top_k"",\n        ""vocab_source"": """",\n        ""vocab_target"": """", \n        ""optimizer.name"": ""Momentum"",\n        ""optimizer.learning_rate"": 0.25,\n        ""optimizer.params"": {""momentum"": 0.99, ""use_nesterov"": True}, # Arbitrary parameters for the optimizer\n        #""optimizer.params"": { ""epsilon"": 0.0000008}, # Arbitrary parameters for the optimizer\n        ""optimizer.lr_decay_type"": ""exponential_decay"",\n        ""optimizer.lr_decay_steps"": 5000,  # one epoch steps\n        ""optimizer.lr_decay_rate"": 0.9,  \n        ""optimizer.lr_start_decay_at"": 0,  # start annealing epoch 0\n        ""optimizer.lr_stop_decay_at"": tf.int32.max,\n        ""optimizer.lr_min_learning_rate"": 1e-5,\n        ""optimizer.lr_staircase"": True,\n        ""optimizer.clip_gradients"": 0.1,\n        ""optimizer.clip_embed_gradients"": 5,\n        ""optimizer.sync_replicas"": 0,\n        ""optimizer.sync_replicas_to_aggregate"": 0,\n        \n})\n    return params\n  \n  def source_embedding_fairseq(self):\n    """"""Returns the embedding used for the source sequence.\n    """"""\n    return tf.get_variable(\n        name=""W"",\n        shape=[self.source_vocab_info.total_size, self.params[""embedding.dim""]],\n        initializer=tf.random_normal_initializer(\n            mean=0.0,\n            stddev=0.1))\n\n  def target_embedding_fairseq(self):\n    """"""Returns the embedding used for the target sequence.\n    """"""\n    if self.params[""embedding.share""]:\n      return self.source_embedding_fairseq()\n    return tf.get_variable(\n        name=""W"",\n        shape=[self.target_vocab_info.total_size, self.params[""embedding.dim""]],\n        initializer=tf.random_normal_initializer(\n            mean=0.0,\n            stddev=0.1))\n\n  def source_pos_embedding_fairseq(self):\n    return tf.get_variable(\n        name=""pos"",\n        shape=[self.params[""position_embeddings.num_positions""], self.params[""embedding.dim""]],\n        initializer=tf.random_normal_initializer(\n            mean=0.0,\n            stddev=0.1))\n    \n  def target_pos_embedding_fairseq(self):\n    return tf.get_variable(\n        name=""pos"",\n        shape=[self.params[""position_embeddings.num_positions""], self.params[""embedding.dim""]],\n        initializer=tf.random_normal_initializer(\n            mean=0.0,\n            stddev=0.1))\n\n  def _create_decoder(self, encoder_output, features, _labels):\n\n    config = beam_search.BeamSearchConfig(\n        beam_width=self.params[""inference.beam_search.beam_width""],\n        vocab_size=self.target_vocab_info.total_size,\n        eos_token=self.target_vocab_info.special_vocab.SEQUENCE_END,\n        length_penalty_weight=self.params[\n            ""inference.beam_search.length_penalty_weight""],\n        choose_successors_fn=getattr(\n            beam_search,\n            self.params[""inference.beam_search.choose_successors_fn""]))\n    \n    return self.decoder_class(\n        params=self.params[""decoder.params""],\n        mode=self.mode,\n        vocab_size=self.target_vocab_info.total_size,\n        config=config,\n        target_embedding=self.target_embedding_fairseq(),\n        pos_embedding=self.target_pos_embedding_fairseq(),\n        start_tokens=self.target_vocab_info.special_vocab.SEQUENCE_END)\n\n  def _decode_train(self, decoder, _encoder_output, _features, labels):\n    """"""Runs decoding in training mode""""""\n    target_embedded = tf.nn.embedding_lookup(decoder.target_embedding,\n                                             labels[""target_ids""])\n\n    return decoder(_encoder_output, labels=target_embedded[:,:-1], sequence_length=labels[""target_len""]-1)\n\n  def _decode_infer(self, decoder, _encoder_output, features, labels):\n    """"""Runs decoding in inference mode""""""\n\n    return decoder(_encoder_output, labels)\n\n  @templatemethod(""encode"")\n  def encode(self, features, labels):\n    \n    features[""source_ids""] = tf.reverse_sequence(features[""source_ids""], features[""source_len""], batch_dim=0, seq_dim=1)  # [[1,2,3,4,PAD,PAD,PAD],[2,3,PAD,PAD,PAD,PAD,PAD]]   [4,2]\n    features[""source_ids""] = tf.reverse(features[""source_ids""],[1])  # --> [[4,3,2,1,PAD,PAD,PAD],[3,2,PAD,PAD,PAD,PAD,PAD]] --> [[PAD,PAD,PAD,1,2,3,4],[PAD,PAD,PAD,PAD,PAD,2,3]]\n     \n    source_embedded = tf.nn.embedding_lookup(self.source_embedding_fairseq(),\n                                             features[""source_ids""])\n    encoder_fn = self.encoder_class(self.params[""encoder.params""], self.mode, self.source_pos_embedding_fairseq())\n    return encoder_fn(source_embedded, features[""source_len""])\n\n  @templatemethod(""decode"")\n  def decode(self, encoder_output, features, labels):\n    \n    decoder = self._create_decoder(encoder_output, features, labels)\n     \n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      return self._decode_infer(decoder, encoder_output, features,\n                                labels)\n    else:\n      return self._decode_train(decoder, encoder_output, features,\n                                labels)\n'"
seq2seq/models/image2seq.py,4,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nDefinition of a basic seq2seq model\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\n\nfrom seq2seq import graph_utils\nfrom seq2seq.data import vocab\nfrom seq2seq.graph_utils import templatemethod\nfrom seq2seq.models.model_base import ModelBase\nfrom seq2seq.models.attention_seq2seq import AttentionSeq2Seq\n\n\nclass Image2Seq(AttentionSeq2Seq):\n  """"""A model that encodes an image and produces a sequence\n  of tokens.\n  """"""\n\n  def __init__(self, params, mode, name=""image_seq2seq""):\n    super(Image2Seq, self).__init__(params, mode, name)\n    self.params[""source.reverse""] = False\n    self.params[""embedding.share""] = False\n\n  @staticmethod\n  def default_params():\n    params = ModelBase.default_params()\n    params.update({\n        ""attention.class"": ""AttentionLayerBahdanau"",\n        ""attention.params"": {\n            ""num_units"": 128\n        },\n        ""bridge.class"": ""seq2seq.models.bridges.ZeroBridge"",\n        ""bridge.params"": {},\n        ""encoder.class"": ""seq2seq.encoders.InceptionV3Encoder"",\n        ""encoder.params"": {},  # Arbitrary parameters for the encoder\n        ""decoder.class"": ""seq2seq.decoders.AttentionDecoder"",\n        ""decoder.params"": {},  # Arbitrary parameters for the decoder\n        ""target.max_seq_len"": 50,\n        ""embedding.dim"": 100,\n        ""inference.beam_search.beam_width"": 0,\n        ""inference.beam_search.length_penalty_weight"": 0.0,\n        ""inference.beam_search.choose_successors_fn"": ""choose_top_k"",\n        ""vocab_target"": """",\n    })\n    return params\n\n  @templatemethod(""encode"")\n  def encode(self, features, _labels):\n    encoder_fn = self.encoder_class(self.params[""encoder.params""], self.mode)\n    return encoder_fn(features[""image""])\n\n  def batch_size(self, features, _labels):\n    return tf.shape(features[""image""])[0]\n\n  def _preprocess(self, features, labels):\n    """"""Model-specific preprocessing for features and labels:\n\n    - Creates vocabulary lookup tables for target vocab\n    - Converts tokens into vocabulary ids\n    - Prepends a speical ""SEQUENCE_START"" token to the target\n    - Appends a speical ""SEQUENCE_END"" token to the target\n    """"""\n\n    # Create vocabulary look for target\n    target_vocab_to_id, target_id_to_vocab, target_word_to_count, _ = \\\n      vocab.create_vocabulary_lookup_table(self.target_vocab_info.path)\n\n    # Add vocab tables to graph colection so that we can access them in\n    # other places.\n    graph_utils.add_dict_to_collection({\n        ""target_vocab_to_id"": target_vocab_to_id,\n        ""target_id_to_vocab"": target_id_to_vocab,\n        ""target_word_to_count"": target_word_to_count\n    }, ""vocab_tables"")\n\n    if labels is None:\n      return features, None\n\n    labels = labels.copy()\n\n    # Slices targets to max length\n    if self.params[""target.max_seq_len""] is not None:\n      labels[""target_tokens""] = labels[""target_tokens""][:, :self.params[\n          ""target.max_seq_len""]]\n      labels[""target_len""] = tf.minimum(labels[""target_len""],\n                                        self.params[""target.max_seq_len""])\n\n    # Look up the target ids in the vocabulary\n    labels[""target_ids""] = target_vocab_to_id.lookup(labels[""target_tokens""])\n\n    labels[""target_len""] = tf.to_int32(labels[""target_len""])\n    tf.summary.histogram(""target_len"", tf.to_float(labels[""target_len""]))\n\n    # Add to graph collection for later use\n    graph_utils.add_dict_to_collection(features, ""features"")\n    if labels:\n      graph_utils.add_dict_to_collection(labels, ""labels"")\n\n    return features, labels\n'"
seq2seq/models/model_base.py,10,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for models""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport collections\nimport tensorflow as tf\n\nfrom seq2seq.configurable import Configurable\nfrom seq2seq.training import utils as training_utils\nfrom seq2seq import global_vars\n\n\ndef _flatten_dict(dict_, parent_key="""", sep="".""):\n  """"""Flattens a nested dictionary. Namedtuples within\n  the dictionary are converted to dicts.\n\n  Args:\n    dict_: The dictionary to flatten.\n    parent_key: A prefix to prepend to each key.\n    sep: Separator between parent and child keys, a string. For example\n      { ""a"": { ""b"": 3 } } will become { ""a.b"": 3 } if the separator is ""."".\n\n  Returns:\n    A new flattened dictionary.\n  """"""\n  items = []\n  for key, value in dict_.items():\n    new_key = parent_key + sep + key if parent_key else key\n    if isinstance(value, collections.MutableMapping):\n      items.extend(_flatten_dict(value, new_key, sep=sep).items())\n    elif isinstance(value, tuple) and hasattr(value, ""_asdict""):\n      dict_items = collections.OrderedDict(zip(value._fields, value))\n      items.extend(_flatten_dict(dict_items, new_key, sep=sep).items())\n    else:\n      items.append((new_key, value))\n  return dict(items)\n\n\nclass ModelBase(Configurable):\n  """"""Abstract base class for models.\n\n  Args:\n    params: A dictionary of hyperparameter values\n    name: A name for this model to be used as a variable scope\n  """"""\n\n  def __init__(self, params, mode, name):\n    self.name = name\n    Configurable.__init__(self, params, mode)\n\n  def _clip_gradients(self, grads_and_vars):\n    """"""Clips gradients by global norm.""""""\n    gradients, variables = zip(*grads_and_vars)\n    clipped_gradients, _ = tf.clip_by_global_norm(\n        gradients, self.params[""optimizer.clip_gradients""])\n    return list(zip(clipped_gradients, variables))\n\n  def _create_optimizer(self):\n    """"""Creates the optimizer""""""\n    name = self.params[""optimizer.name""]\n    optimizer = tf.contrib.layers.OPTIMIZER_CLS_NAMES[name](\n        learning_rate=self.params[""optimizer.learning_rate""],\n        **self.params[""optimizer.params""])\n\n    # Optionally wrap with SyncReplicasOptimizer\n    if self.params[""optimizer.sync_replicas""] > 0:\n      optimizer = tf.train.SyncReplicasOptimizer(\n          opt=optimizer,\n          replicas_to_aggregate=self.params[\n              ""optimizer.sync_replicas_to_aggregate""],\n          total_num_replicas=self.params[""optimizer.sync_replicas""])\n      # This is really ugly, but we need to do this to make the optimizer\n      # accessible outside of the model.\n      global_vars.SYNC_REPLICAS_OPTIMIZER = optimizer\n\n    return optimizer\n\n  def _build_train_op(self, loss, gradient_multipliers=None):\n    """"""Creates the training operation""""""\n    learning_rate_decay_fn = training_utils.create_learning_rate_decay_fn(\n        decay_type=self.params[""optimizer.lr_decay_type""] or None,\n        decay_steps=self.params[""optimizer.lr_decay_steps""],\n        decay_rate=self.params[""optimizer.lr_decay_rate""],\n        start_decay_at=self.params[""optimizer.lr_start_decay_at""],\n        stop_decay_at=self.params[""optimizer.lr_stop_decay_at""],\n        min_learning_rate=self.params[""optimizer.lr_min_learning_rate""],\n        staircase=self.params[""optimizer.lr_staircase""])\n\n    optimizer = self._create_optimizer()\n    train_op = tf.contrib.layers.optimize_loss(\n        loss=loss,\n        global_step=tf.contrib.framework.get_global_step(),\n        learning_rate=self.params[""optimizer.learning_rate""],\n        learning_rate_decay_fn=learning_rate_decay_fn,\n        clip_gradients=self._clip_gradients,\n        optimizer=optimizer,\n        gradient_multipliers=gradient_multipliers,\n        summaries=[""learning_rate"", ""loss"", ""gradients"", ""gradient_norm""])\n\n    return train_op\n\n  @staticmethod\n  def default_params():\n    """"""Returns a dictionary of default parameters for this model.""""""\n    return {\n        ""optimizer.name"": ""Adam"",\n        ""optimizer.learning_rate"": 1e-4,\n        ""optimizer.params"": {}, # Arbitrary parameters for the optimizer\n        ""optimizer.lr_decay_type"": """",\n        ""optimizer.lr_decay_steps"": 100,\n        ""optimizer.lr_decay_rate"": 0.99,\n        ""optimizer.lr_start_decay_at"": 0,\n        ""optimizer.lr_stop_decay_at"": tf.int32.max,\n        ""optimizer.lr_min_learning_rate"": 1e-12,\n        ""optimizer.lr_staircase"": False,\n        ""optimizer.clip_gradients"": 5.0,\n        ""optimizer.sync_replicas"": 0,\n        ""optimizer.sync_replicas_to_aggregate"": 0,\n    }\n\n  def batch_size(self, features, labels):\n    """"""Returns the batch size for a batch of examples""""""\n    raise NotImplementedError()\n\n  def __call__(self, features, labels, params):\n    """"""Creates the model graph. See the model_fn documentation in\n    tf.contrib.learn.Estimator class for a more detailed explanation.\n    """"""\n    with tf.variable_scope(""model""):\n      with tf.variable_scope(self.name):\n        return self._build(features, labels, params)\n\n  def _build(self, features, labels, params):\n    """"""Subclasses should implement this method. See the `model_fn` documentation\n    in tf.contrib.learn.Estimator class for a more detailed explanation.\n    """"""\n    raise NotImplementedError\n'"
seq2seq/models/seq2seq_model.py,30,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Base class for models""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport collections\n\nimport tensorflow as tf\n\nfrom seq2seq import graph_utils\nfrom seq2seq import losses as seq2seq_losses\nfrom seq2seq.contrib.seq2seq.decoder import _transpose_batch_time\nfrom seq2seq.data import vocab\nfrom seq2seq.graph_utils import templatemethod\nfrom seq2seq.decoders.beam_search_decoder import BeamSearchDecoder\nfrom seq2seq.inference import beam_search\nfrom seq2seq.models.model_base import ModelBase, _flatten_dict\n\n\nclass Seq2SeqModel(ModelBase):\n  """"""Base class for seq2seq models with embeddings\n  """"""\n\n  def __init__(self, params, mode, name):\n    super(Seq2SeqModel, self).__init__(params, mode, name)\n\n    self.source_vocab_info = None\n    if ""vocab_source"" in self.params and self.params[""vocab_source""]:\n      self.source_vocab_info = vocab.get_vocab_info(self.params[""vocab_source""])\n\n    self.target_vocab_info = None\n    if ""vocab_target"" in self.params and self.params[""vocab_target""]:\n      self.target_vocab_info = vocab.get_vocab_info(self.params[""vocab_target""])\n\n  @staticmethod\n  def default_params():\n    params = ModelBase.default_params()\n    params.update({\n        ""source.max_seq_len"": 50,\n        ""source.reverse"": True,\n        ""target.max_seq_len"": 50,\n        ""embedding.dim"": 100,\n        ""embedding.init_scale"": 0.04,\n        ""embedding.share"": False,\n        ""inference.beam_search.beam_width"": 0,\n        ""inference.beam_search.length_penalty_weight"": 0.0,\n        ""inference.beam_search.choose_successors_fn"": ""choose_top_k"",\n        ""optimizer.clip_embed_gradients"": 0.1,\n        ""vocab_source"": """",\n        ""vocab_target"": """",\n    })\n    return params\n\n  def _clip_gradients(self, grads_and_vars):\n    """"""In addition to standard gradient clipping, also clips embedding\n    gradients to a specified value.""""""\n    grads_and_vars = super(Seq2SeqModel, self)._clip_gradients(grads_and_vars)\n\n    clipped_gradients = []\n    variables = []\n    for gradient, variable in grads_and_vars:\n      if ""embedding"" in variable.name:\n        tmp = tf.clip_by_norm(\n            gradient.values, self.params[""optimizer.clip_embed_gradients""])\n        gradient = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)\n      clipped_gradients.append(gradient)\n      variables.append(variable)\n    return list(zip(clipped_gradients, variables))\n\n  def _create_predictions(self, decoder_output, features, labels, losses=None):\n    """"""Creates the dictionary of predictions that is returned by the model.\n    """"""\n    predictions = {}\n\n    # Add features and, if available, labels to predictions\n    predictions.update(_flatten_dict({""features"": features}))\n    if labels is not None:\n      predictions.update(_flatten_dict({""labels"": labels}))\n\n    if losses is not None:\n      predictions[""losses""] = _transpose_batch_time(losses)\n\n    # Decoders returns output in time-major form [T, B, ...]\n    # Here we transpose everything back to batch-major for the user\n    output_dict = collections.OrderedDict(\n        zip(decoder_output._fields, decoder_output))\n    decoder_output_flat = _flatten_dict(output_dict)\n    \n    decoder_output_flat = {\n        k: _transpose_batch_time(v)\n        for k, v in decoder_output_flat.items()\n    }\n    predictions.update(decoder_output_flat)\n\n    # If we predict the ids also map them back into the vocab and process them\n    if ""predicted_ids"" in predictions.keys():\n      vocab_tables = graph_utils.get_dict_from_collection(""vocab_tables"")\n      target_id_to_vocab = vocab_tables[""target_id_to_vocab""]\n      predicted_tokens = target_id_to_vocab.lookup(\n          tf.to_int64(predictions[""predicted_ids""]))\n      # Raw predicted tokens\n      predictions[""predicted_tokens""] = predicted_tokens\n\n    return predictions\n\n  def batch_size(self, features, labels):\n    """"""Returns the batch size of the curren batch based on the passed\n    features.\n    """"""\n    return tf.shape(features[""source_ids""])[0]\n\n  @property\n  @templatemethod(""source_embedding"")\n  def source_embedding(self):\n    """"""Returns the embedding used for the source sequence.\n    """"""\n    return tf.get_variable(\n        name=""W"",\n        shape=[self.source_vocab_info.total_size, self.params[""embedding.dim""]],\n        initializer=tf.random_uniform_initializer(\n            -self.params[""embedding.init_scale""],\n            self.params[""embedding.init_scale""]))\n\n  @property\n  @templatemethod(""target_embedding"")\n  def target_embedding(self):\n    """"""Returns the embedding used for the target sequence.\n    """"""\n    if self.params[""embedding.share""]:\n      return self.source_embedding\n    return tf.get_variable(\n        name=""W"",\n        shape=[self.target_vocab_info.total_size, self.params[""embedding.dim""]],\n        initializer=tf.random_uniform_initializer(\n            -self.params[""embedding.init_scale""],\n            self.params[""embedding.init_scale""]))\n\n  @templatemethod(""encode"")\n  def encode(self, features, labels):\n    """"""Encodes the inputs.\n    """"""\n    raise NotImplementedError()\n\n  @templatemethod(""decode"")\n  def decode(self, encoder_output, features, labels):\n    """"""Runs decoding based on the encoder outputs.\n    """"""\n    raise NotImplementedError()\n\n  def _get_beam_search_decoder(self, decoder):\n    """"""Wraps a decoder into a Beam Search decoder.\n\n    Args:\n      decoder: The original decoder\n\n    Returns:\n      A BeamSearchDecoder with the same interfaces as the original decoder.\n    """"""\n    config = beam_search.BeamSearchConfig(\n        beam_width=self.params[""inference.beam_search.beam_width""],\n        vocab_size=self.target_vocab_info.total_size,\n        eos_token=self.target_vocab_info.special_vocab.SEQUENCE_END,\n        length_penalty_weight=self.params[\n            ""inference.beam_search.length_penalty_weight""],\n        choose_successors_fn=getattr(\n            beam_search,\n            self.params[""inference.beam_search.choose_successors_fn""]))\n    return BeamSearchDecoder(decoder=decoder, config=config)\n\n  @property\n  def use_beam_search(self):\n    """"""Returns true iff the model should perform beam search.\n    """"""\n    return self.params[""inference.beam_search.beam_width""] > 0\n\n  def _preprocess(self, features, labels):\n    """"""Model-specific preprocessing for features and labels:\n\n    - Creates vocabulary lookup tables for source and target vocab\n    - Converts tokens into vocabulary ids\n    """"""\n\n    # Create vocabulary lookup for source\n    source_vocab_to_id, source_id_to_vocab, source_word_to_count, _ = \\\n      vocab.create_vocabulary_lookup_table(self.source_vocab_info.path)\n\n    # Create vocabulary look for target\n    target_vocab_to_id, target_id_to_vocab, target_word_to_count, _ = \\\n      vocab.create_vocabulary_lookup_table(self.target_vocab_info.path)\n\n    # Add vocab tables to graph colection so that we can access them in\n    # other places.\n    graph_utils.add_dict_to_collection({\n        ""source_vocab_to_id"": source_vocab_to_id,\n        ""source_id_to_vocab"": source_id_to_vocab,\n        ""source_word_to_count"": source_word_to_count,\n        ""target_vocab_to_id"": target_vocab_to_id,\n        ""target_id_to_vocab"": target_id_to_vocab,\n        ""target_word_to_count"": target_word_to_count\n    }, ""vocab_tables"")\n\n    # Slice source to max_len\n    if self.params[""source.max_seq_len""] is not None:\n      features[""source_tokens""] = features[""source_tokens""][:, :self.params[\n          ""source.max_seq_len""]]\n      features[""source_len""] = tf.minimum(features[""source_len""],\n                                          self.params[""source.max_seq_len""])\n\n    # Look up the source ids in the vocabulary\n    features[""source_ids""] = source_vocab_to_id.lookup(features[\n        ""source_tokens""])\n\n    # Maybe reverse the source\n    if self.params[""source.reverse""] is True:\n      features[""source_ids""] = tf.reverse_sequence(\n          input=features[""source_ids""],\n          seq_lengths=features[""source_len""],\n          seq_dim=1,\n          batch_dim=0,\n          name=None)\n\n    features[""source_len""] = tf.to_int32(features[""source_len""])\n    tf.summary.histogram(""source_len"", tf.to_float(features[""source_len""]))\n\n    if labels is None:\n      return features, None\n\n    labels = labels.copy()\n\n    # Slices targets to max length\n    if self.params[""target.max_seq_len""] is not None:\n      labels[""target_tokens""] = labels[""target_tokens""][:, :self.params[\n          ""target.max_seq_len""]]\n      labels[""target_len""] = tf.minimum(labels[""target_len""],\n                                        self.params[""target.max_seq_len""])\n\n    # Look up the target ids in the vocabulary\n    labels[""target_ids""] = target_vocab_to_id.lookup(labels[""target_tokens""])\n\n    labels[""target_len""] = tf.to_int32(labels[""target_len""])\n    tf.summary.histogram(""target_len"", tf.to_float(labels[""target_len""]))\n\n    # Keep track of the number of processed tokens\n    num_tokens = tf.reduce_sum(labels[""target_len""])\n    num_tokens += tf.reduce_sum(features[""source_len""])\n    token_counter_var = tf.Variable(0, ""tokens_counter"")\n    total_tokens = tf.assign_add(token_counter_var, num_tokens)\n    tf.summary.scalar(""num_tokens"", total_tokens)\n\n    with tf.control_dependencies([total_tokens]):\n      features[""source_tokens""] = tf.identity(features[""source_tokens""])\n\n    # Add to graph collection for later use\n    graph_utils.add_dict_to_collection(features, ""features"")\n    if labels:\n      graph_utils.add_dict_to_collection(labels, ""labels"")\n\n    return features, labels\n\n  def compute_loss(self, decoder_output, _features, labels):\n    """"""Computes the loss for this model.\n\n    Returns a tuple `(losses, loss)`, where `losses` are the per-batch\n    losses and loss is a single scalar tensor to minimize.\n    """"""\n    #pylint: disable=R0201\n    # Calculate loss per example-timestep of shape [B, T]\n    \n    losses = seq2seq_losses.cross_entropy_sequence_loss(\n        logits=decoder_output.logits[:, :, :],\n        targets=tf.transpose(labels[""target_ids""][:, 1:], [1, 0]),\n        sequence_length=labels[""target_len""] - 1)\n\n    # Calculate the average log perplexity\n    loss = tf.reduce_sum(losses) / tf.to_float(\n        tf.reduce_sum(labels[""target_len""] - 1))\n\n    return losses, loss\n\n  def _build(self, features, labels, params):\n    # Pre-process features and labels\n    features, labels = self._preprocess(features, labels)\n\n    encoder_output = self.encode(features, labels)\n    decoder_output, _, = self.decode(encoder_output, features, labels)\n\n    if self.mode == tf.contrib.learn.ModeKeys.INFER:\n      loss = None\n      train_op = None\n      \n      predictions = self._create_predictions(\n          decoder_output=decoder_output, features=features, labels=labels)\n    else:\n      losses, loss = self.compute_loss(decoder_output, features, labels)\n\n      train_op = None\n      if self.mode == tf.contrib.learn.ModeKeys.TRAIN:\n        gradient_multipliers = {}\n        # multiply the gradient by 1.0/(2*#att_layer)       \n        for i in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\'model/conv_seq2seq/encode\'):\n          if \'encode/W\' in i.name or \'encode/pos\' in i.name:\n            continue\n          tf.logging.info(""tensor %s, name is %s"", i, i.name)\n          gradient_multipliers[i] = 1.0/(2*self.params[""decoder.params""][""cnn.layers""])\n        #tf.logging.info(""gradient_multipliers %s"",gradient_multipliers)\n        train_op = self._build_train_op(loss, gradient_multipliers=gradient_multipliers)\n      \n      predictions = self._create_predictions(\n          decoder_output=decoder_output,\n          features=features,\n          labels=labels,\n          losses=losses)\n\n    # We add ""useful"" tensors to the graph collection so that we\n    # can easly find them in our hooks/monitors.\n    graph_utils.add_dict_to_collection(predictions, ""predictions"")\n\n    return predictions, loss, train_op\n'"
seq2seq/tasks/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nCollection of task types.\n""""""\n\nfrom seq2seq.tasks.inference_task import InferenceTask\nfrom seq2seq.tasks.decode_text import DecodeText\nfrom seq2seq.tasks.dump_attention import DumpAttention\nfrom seq2seq.tasks.dump_beams import DumpBeams\n'"
seq2seq/tasks/decode_text.py,1,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTask where both the input and output sequence are plain text.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport functools\nfrom pydoc import locate\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq.tasks.inference_task import InferenceTask, unbatch_dict\n\n\ndef _get_prediction_length(predictions_dict):\n  """"""Returns the length of the prediction based on the index\n  of the first SEQUENCE_END token.\n  """"""\n  tokens_iter = enumerate(predictions_dict[""predicted_tokens""])\n  return next(((i + 1) for i, _ in tokens_iter if _ == ""SEQUENCE_END""),\n              len(predictions_dict[""predicted_tokens""]))\n\n\ndef _get_unk_mapping(filename):\n  """"""Reads a file that specifies a mapping from source to target tokens.\n  The file must contain lines of the form <source>\\t<target>""\n\n  Args:\n    filename: path to the mapping file\n\n  Returns:\n    A dictionary that maps from source -> target tokens.\n  """"""\n  with gfile.GFile(filename, ""r"") as mapping_file:\n    lines = mapping_file.readlines()\n    mapping = dict([_.split(""\\t"")[0:2] for _ in lines])\n    mapping = {k.strip(): v.strip() for k, v in mapping.items()}\n  return mapping\n\n\ndef _unk_replace(source_tokens,\n                 predicted_tokens,\n                 attention_scores,\n                 mapping=None):\n  """"""Replaces UNK tokens with tokens from the source or a\n  provided mapping based on the attention scores.\n\n  Args:\n    source_tokens: A numpy array of strings.\n    predicted_tokens: A numpy array of strings.\n    attention_scores: A numeric numpy array\n      of shape `[prediction_length, source_length]` that contains\n      the attention scores.\n    mapping: If not provided, an UNK token is replaced with the\n      source token that has the highest attention score. If provided\n      the token is insead replaced with `mapping[chosen_source_token]`.\n\n  Returns:\n    A new `predicted_tokens` array.\n  """"""\n  result = []\n  for token, scores in zip(predicted_tokens, attention_scores):\n    if token == ""UNK"":\n      max_score_index = np.argmax(scores)\n      chosen_source_token = source_tokens[max_score_index]\n      new_target = chosen_source_token\n      if mapping is not None and chosen_source_token in mapping:\n        new_target = mapping[chosen_source_token]\n      result.append(new_target)\n    else:\n      result.append(token)\n  return np.array(result)\n\n\nclass DecodeText(InferenceTask):\n  """"""Defines inference for tasks where both the input and output sequences\n  are plain text.\n\n  Params:\n    delimiter: Character by which tokens are delimited. Defaults to space.\n    unk_replace: If true, enable unknown token replacement based on attention\n      scores.\n    unk_mapping: If `unk_replace` is true, this can be the path to a file\n      defining a dictionary to improve UNK token replacement. Refer to the\n      documentation for more details.\n    dump_attention_dir: Save attention scores and plots to this directory.\n    dump_attention_no_plot: If true, only save attention scores, not\n      attention plots.\n    dump_beams: Write beam search debugging information to this file.\n  """"""\n\n  def __init__(self, params):\n    super(DecodeText, self).__init__(params)\n    self._unk_mapping = None\n    self._unk_replace_fn = None\n\n    if self.params[""unk_mapping""] is not None:\n      self._unk_mapping = _get_unk_mapping(self.params[""unk_mapping""])\n    if self.params[""unk_replace""]:\n      self._unk_replace_fn = functools.partial(\n          _unk_replace, mapping=self._unk_mapping)\n\n    self._postproc_fn = None\n    if self.params[""postproc_fn""]:\n      self._postproc_fn = locate(self.params[""postproc_fn""])\n      if self._postproc_fn is None:\n        raise ValueError(""postproc_fn not found: {}"".format(\n            self.params[""postproc_fn""]))\n\n  @staticmethod\n  def default_params():\n    params = {}\n    params.update({\n        ""delimiter"": "" "",\n        ""postproc_fn"": """",\n        ""unk_replace"": False,\n        ""unk_mapping"": None,\n    })\n    return params\n\n  def before_run(self, _run_context):\n    fetches = {}\n    fetches[""predicted_tokens""] = self._predictions[""predicted_tokens""]\n    fetches[""features.source_len""] = self._predictions[""features.source_len""]\n    fetches[""features.source_tokens""] = self._predictions[\n        ""features.source_tokens""]\n\n    if ""attention_scores"" in self._predictions:\n      fetches[""attention_scores""] = self._predictions[""attention_scores""]\n\n    return tf.train.SessionRunArgs(fetches)\n\n  def after_run(self, _run_context, run_values):\n    fetches_batch = run_values.results\n    for fetches in unbatch_dict(fetches_batch):\n      # Convert to unicode\n      fetches[""predicted_tokens""] = np.char.decode(\n          fetches[""predicted_tokens""].astype(""S""), ""utf-8"")\n      predicted_tokens = fetches[""predicted_tokens""]\n\n      # If we\'re using beam search we take the first beam\n      if np.ndim(predicted_tokens) > 1:\n        predicted_tokens = predicted_tokens[:, 0]\n\n      fetches[""features.source_tokens""] = np.char.decode(\n          fetches[""features.source_tokens""].astype(""S""), ""utf-8"")\n      source_tokens = fetches[""features.source_tokens""]\n      source_len = fetches[""features.source_len""]\n\n      if self._unk_replace_fn is not None:\n        # We slice the attention scores so that we do not\n        # accidentially replace UNK with a SEQUENCE_END token\n        attention_scores = fetches[""attention_scores""]\n        attention_scores = attention_scores[:, :source_len - 1]\n        predicted_tokens = self._unk_replace_fn(\n            source_tokens=source_tokens,\n            predicted_tokens=predicted_tokens,\n            attention_scores=attention_scores)\n\n      sent = self.params[""delimiter""].join(predicted_tokens).split(\n          ""SEQUENCE_END"")[0]\n\n      # Apply postproc\n      if self._postproc_fn:\n        sent = self._postproc_fn(sent)\n\n      sent = sent.strip()\n\n      print(sent)\n'"
seq2seq/tasks/dump_attention.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTask where both the input and output sequence are plain text.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq.tasks.decode_text import _get_prediction_length\nfrom seq2seq.tasks.inference_task import InferenceTask, unbatch_dict\n\n\ndef _get_scores(predictions_dict):\n  """"""Returns the attention scores, sliced by source and target length.\n  """"""\n  prediction_len = _get_prediction_length(predictions_dict)\n  source_len = predictions_dict[""features.source_len""]\n  return predictions_dict[""attention_scores""][:prediction_len, :source_len]\n\n\ndef _create_figure(predictions_dict):\n  """"""Creates and returns a new figure that visualizes\n  attention scores for for a single model predictions.\n  """"""\n\n  # Find out how long the predicted sequence is\n  target_words = list(predictions_dict[""predicted_tokens""])\n\n  prediction_len = _get_prediction_length(predictions_dict)\n\n  # Get source words\n  source_len = predictions_dict[""features.source_len""]\n  source_words = predictions_dict[""features.source_tokens""][:source_len]\n\n  # Plot\n  fig = plt.figure(figsize=(8, 8))\n  plt.imshow(\n      X=predictions_dict[""attention_scores""][:prediction_len, :source_len],\n      interpolation=""nearest"",\n      cmap=plt.cm.Blues)\n  plt.xticks(np.arange(source_len), source_words, rotation=45)\n  plt.yticks(np.arange(prediction_len), target_words, rotation=-45)\n  fig.tight_layout()\n\n  return fig\n\n\nclass DumpAttention(InferenceTask):\n  """"""Defines inference for tasks where both the input and output sequences\n  are plain text.\n\n  Params:\n    delimiter: Character by which tokens are delimited. Defaults to space.\n    unk_replace: If true, enable unknown token replacement based on attention\n      scores.\n    unk_mapping: If `unk_replace` is true, this can be the path to a file\n      defining a dictionary to improve UNK token replacement. Refer to the\n      documentation for more details.\n    dump_attention_dir: Save attention scores and plots to this directory.\n    dump_attention_no_plot: If true, only save attention scores, not\n      attention plots.\n    dump_beams: Write beam search debugging information to this file.\n  """"""\n\n  def __init__(self, params):\n    super(DumpAttention, self).__init__(params)\n    self._attention_scores_accum = []\n    self._idx = 0\n\n    if not self.params[""output_dir""]:\n      raise ValueError(""Must specify output_dir for DumpAttention"")\n\n  @staticmethod\n  def default_params():\n    params = {}\n    params.update({""output_dir"": """", ""dump_plots"": True})\n    return params\n\n  def begin(self):\n    super(DumpAttention, self).begin()\n    gfile.MakeDirs(self.params[""output_dir""])\n\n  def before_run(self, _run_context):\n    fetches = {}\n    fetches[""predicted_tokens""] = self._predictions[""predicted_tokens""]\n    fetches[""features.source_len""] = self._predictions[""features.source_len""]\n    fetches[""features.source_tokens""] = self._predictions[\n        ""features.source_tokens""]\n    fetches[""attention_scores""] = self._predictions[""attention_scores""]\n    return tf.train.SessionRunArgs(fetches)\n\n  def after_run(self, _run_context, run_values):\n    fetches_batch = run_values.results\n    for fetches in unbatch_dict(fetches_batch):\n      # Convert to unicode\n      fetches[""predicted_tokens""] = np.char.decode(\n          fetches[""predicted_tokens""].astype(""S""), ""utf-8"")\n      fetches[""features.source_tokens""] = np.char.decode(\n          fetches[""features.source_tokens""].astype(""S""), ""utf-8"")\n\n      if self.params[""dump_plots""]:\n        output_path = os.path.join(self.params[""output_dir""],\n                                   ""{:05d}.png"".format(self._idx))\n        _create_figure(fetches)\n        plt.savefig(output_path)\n        plt.close()\n        tf.logging.info(""Wrote %s"", output_path)\n        self._idx += 1\n      self._attention_scores_accum.append(_get_scores(fetches))\n\n  def end(self, _session):\n    scores_path = os.path.join(self.params[""output_dir""],\n                               ""attention_scores.npz"")\n    np.savez(scores_path, *self._attention_scores_accum)\n    tf.logging.info(""Wrote %s"", scores_path)\n'"
seq2seq/tasks/dump_beams.py,1,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTask where both the input and output sequence are plain text.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom seq2seq.tasks.inference_task import InferenceTask, unbatch_dict\n\n\nclass DumpBeams(InferenceTask):\n  """"""Defines inference for tasks where both the input and output sequences\n  are plain text.\n\n  Params:\n    file: File to write beam search information to.\n  """"""\n\n  def __init__(self, params):\n    super(DumpBeams, self).__init__(params)\n    self._beam_accum = {\n        ""predicted_ids"": [],\n        ""predicted_tokens"": [],\n        ""beam_parent_ids"": [],\n        ""scores"": [],\n        ""log_probs"": []\n    }\n\n    if not self.params[""file""]:\n      raise ValueError(""Must specify file for DumpBeams"")\n\n  @staticmethod\n  def default_params():\n    params = {}\n    params.update({""file"": """",})\n    return params\n\n  def before_run(self, _run_context):\n    fetches = {}\n    fetches[""beam_search_output.predicted_ids""] = self._predictions[\n        ""beam_search_output.predicted_ids""]\n    fetches[""beam_search_output.beam_parent_ids""] = self._predictions[\n        ""beam_search_output.beam_parent_ids""]\n    fetches[""beam_search_output.scores""] = self._predictions[\n        ""beam_search_output.scores""]\n    fetches[""beam_search_output.log_probs""] = self._predictions[\n        ""beam_search_output.log_probs""]\n    fetches[""predicted_tokens""] = self._predictions[\n        ""predicted_tokens""]\n    return tf.train.SessionRunArgs(fetches)\n\n  def after_run(self, _run_context, run_values):\n    fetches_batch = run_values.results\n    for fetches in unbatch_dict(fetches_batch):\n      self._beam_accum[""predicted_ids""].append(fetches[\n          ""beam_search_output.predicted_ids""])\n      self._beam_accum[""beam_parent_ids""].append(fetches[\n          ""beam_search_output.beam_parent_ids""])\n      self._beam_accum[""scores""].append(fetches[""beam_search_output.scores""])\n      self._beam_accum[""log_probs""].append(fetches[\n          ""beam_search_output.log_probs""])\n      self._beam_accum[""predicted_tokens""].append(fetches[""predicted_tokens""])\n\n  def end(self, _session):\n    np.savez(self.params[""file""], **self._beam_accum)\n'"
seq2seq/tasks/inference_task.py,2,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nAbstract base class for inference tasks.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\n\nimport six\nimport tensorflow as tf\n\nfrom seq2seq import graph_utils\nfrom seq2seq.configurable import Configurable, abstractstaticmethod\n\n\ndef unbatch_dict(dict_):\n  """"""Converts a dictionary of batch items to a batch/list of\n  dictionary items.\n  """"""\n  batch_size = list(dict_.values())[0].shape[0]\n  for i in range(batch_size):\n    yield {key: value[i] for key, value in dict_.items()}\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass InferenceTask(tf.train.SessionRunHook, Configurable):\n  """"""\n  Abstract base class for inference tasks. Defines the logic used to make\n  predictions for a specific type of task.\n\n  Params:\n    model_class: The model class to instantiate. If undefined,\n      re-uses the class used during training.\n    model_params: Model hyperparameters. Specified hyperparameters will\n      overwrite those used during training.\n\n  Args:\n    params: See Params above.\n  """"""\n\n  def __init__(self, params):\n    Configurable.__init__(self, params, tf.contrib.learn.ModeKeys.INFER)\n    self._predictions = None\n\n  def begin(self):\n    self._predictions = graph_utils.get_dict_from_collection(""predictions"")\n\n  @abstractstaticmethod\n  def default_params():\n    raise NotImplementedError()\n'"
seq2seq/test/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests and testing utilities\n""""""\n\nfrom seq2seq.test import utils\n'"
seq2seq/test/attention_test.py,9,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for attention functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.decoders.attention import AttentionLayerDot\nfrom seq2seq.decoders.attention import AttentionLayerBahdanau\n\n\nclass AttentionLayerTest(tf.test.TestCase):\n  """"""\n  Tests the AttentionLayer module.\n  """"""\n\n  def setUp(self):\n    super(AttentionLayerTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 8\n    self.attention_dim = 128\n    self.input_dim = 16\n    self.seq_len = 10\n    self.state_dim = 32\n\n  def _create_layer(self):\n    """"""Creates the attention layer. Should be implemented by child classes""""""\n    raise NotImplementedError\n\n  def _test_layer(self):\n    """"""Tests Attention layer with a  given score type""""""\n    inputs_pl = tf.placeholder(tf.float32, (None, None, self.input_dim))\n    inputs_length_pl = tf.placeholder(tf.int32, [None])\n    state_pl = tf.placeholder(tf.float32, (None, self.state_dim))\n    attention_fn = self._create_layer()\n    scores, context = attention_fn(\n        query=state_pl,\n        keys=inputs_pl,\n        values=inputs_pl,\n        values_length=inputs_length_pl)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      feed_dict = {}\n      feed_dict[inputs_pl] = np.random.randn(self.batch_size, self.seq_len,\n                                             self.input_dim)\n      feed_dict[state_pl] = np.random.randn(self.batch_size, self.state_dim)\n      feed_dict[inputs_length_pl] = np.arange(self.batch_size) + 1\n      scores_, context_ = sess.run([scores, context], feed_dict)\n\n    np.testing.assert_array_equal(scores_.shape,\n                                  [self.batch_size, self.seq_len])\n    np.testing.assert_array_equal(context_.shape,\n                                  [self.batch_size, self.input_dim])\n\n    for idx, batch in enumerate(scores_, 1):\n      # All scores that are padded should be zero\n      np.testing.assert_array_equal(batch[idx:], np.zeros_like(batch[idx:]))\n\n    # Scores should sum to 1\n    scores_sum = np.sum(scores_, axis=1)\n    np.testing.assert_array_almost_equal(scores_sum, np.ones([self.batch_size]))\n\n\nclass AttentionLayerDotTest(AttentionLayerTest):\n  """"""Tests the AttentionLayerDot class""""""\n\n  def _create_layer(self):\n    return AttentionLayerDot(\n        params={""num_units"": self.attention_dim},\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  def test_layer(self):\n    self._test_layer()\n\n\nclass AttentionLayerBahdanauTest(AttentionLayerTest):\n  """"""Tests the AttentionLayerBahdanau class""""""\n\n  def _create_layer(self):\n    return AttentionLayerBahdanau(\n        params={""num_units"": self.attention_dim},\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  def test_layer(self):\n    self._test_layer()\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/beam_search_test.py,30,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTests for Beam Search and related functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.inference import beam_search\n\n\nclass TestGatherTree(tf.test.TestCase):\n  """"""Tests the gather_tree function""""""\n\n  def test_gather_tree(self):\n    predicted_ids = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    parent_ids = np.array([[0, 0, 0], [0, 1, 1], [2, 1, 2]])\n    expected_result = np.array([[2, 2, 2], [6, 5, 6], [7, 8, 9]])\n\n    res = beam_search.gather_tree(\n        tf.convert_to_tensor(predicted_ids), tf.convert_to_tensor(parent_ids))\n    with self.test_session() as sess:\n      res_ = sess.run(res)\n\n    np.testing.assert_array_equal(expected_result, res_)\n\n\nclass TestLengthNorm(tf.test.TestCase):\n  """"""Tests the length normalization score""""""\n\n  def test_length_norm(self):\n    #log_probs_ = np.ones([2, 3]) / 3.0\n    lengths_ = np.array([[1, 2, 3], [3, 3, 3]])\n    penalty_factor_ = 0.6\n    length_pen = beam_search.length_penalty(\n        sequence_lengths=tf.convert_to_tensor(lengths_),\n        penalty_factor=penalty_factor_)\n\n    with self.test_session() as sess:\n      length_pen_ = sess.run(length_pen)\n\n    np.testing.assert_almost_equal(length_pen_[0, 0], 1.0, decimal=5)\n    np.testing.assert_almost_equal(length_pen_[0, 1], 1.0969027, decimal=4)\n    np.testing.assert_almost_equal(length_pen_[0, 2], 1.1884017, decimal=4)\n\n\nclass TestBeamStep(tf.test.TestCase):\n  """"""Tests a single step of beam search\n  """"""\n\n  def setUp(self):\n    super(TestBeamStep, self).setUp()\n    self.state_size = 10\n    config = beam_search.BeamSearchConfig(\n        beam_width=3,\n        vocab_size=5,\n        eos_token=0,\n        length_penalty_weight=0.6,\n        choose_successors_fn=beam_search.choose_top_k)\n    self.config = config\n\n  def test_step(self):\n    beam_state = beam_search.BeamSearchState(\n        log_probs=tf.nn.log_softmax(tf.ones(self.config.beam_width)),\n        lengths=tf.constant(\n            2, shape=[self.config.beam_width], dtype=tf.int32),\n        finished=tf.zeros(\n            [self.config.beam_width], dtype=tf.bool))\n\n    logits_ = np.full([self.config.beam_width, self.config.vocab_size], 0.0001)\n    logits_[0, 2] = 1.9\n    logits_[0, 3] = 2.1\n    logits_[1, 3] = 3.1\n    logits_[1, 4] = 0.9\n    logits = tf.convert_to_tensor(logits_, dtype=tf.float32)\n    log_probs = tf.nn.log_softmax(logits)\n\n    outputs, next_beam_state = beam_search.beam_search_step(\n        time_=2, logits=logits, beam_state=beam_state, config=self.config)\n\n    with self.test_session() as sess:\n      outputs_, next_state_, state_, log_probs_ = sess.run(\n          [outputs, next_beam_state, beam_state, log_probs])\n\n    np.testing.assert_array_equal(outputs_.predicted_ids, [3, 3, 2])\n    np.testing.assert_array_equal(outputs_.beam_parent_ids, [1, 0, 0])\n    np.testing.assert_array_equal(next_state_.lengths, [3, 3, 3])\n    np.testing.assert_array_equal(next_state_.finished, [False, False, False])\n\n    expected_log_probs = state_.log_probs[[1, 0, 0]]\n    expected_log_probs[0] += log_probs_[1, 3]\n    expected_log_probs[1] += log_probs_[0, 3]\n    expected_log_probs[2] += log_probs_[0, 2]\n    np.testing.assert_array_equal(next_state_.log_probs, expected_log_probs)\n\n  def test_step_with_eos(self):\n    beam_state = beam_search.BeamSearchState(\n        log_probs=tf.nn.log_softmax(tf.ones(self.config.beam_width)),\n        lengths=tf.convert_to_tensor(\n            [2, 1, 2], dtype=tf.int32),\n        finished=tf.constant(\n            [False, True, False], dtype=tf.bool))\n\n    logits_ = np.full([self.config.beam_width, self.config.vocab_size], 0.0001)\n    logits_[0, 2] = 1.1\n    logits_[1, 2] = 1.0\n    logits_[2, 2] = 1.0\n    logits = tf.convert_to_tensor(logits_, dtype=tf.float32)\n    log_probs = tf.nn.log_softmax(logits)\n\n    outputs, next_beam_state = beam_search.beam_search_step(\n        time_=2, logits=logits, beam_state=beam_state, config=self.config)\n\n    with self.test_session() as sess:\n      outputs_, next_state_, state_, log_probs_ = sess.run(\n          [outputs, next_beam_state, beam_state, log_probs])\n\n    np.testing.assert_array_equal(outputs_.predicted_ids, [0, 2, 2])\n    np.testing.assert_array_equal(outputs_.beam_parent_ids, [1, 0, 2])\n    np.testing.assert_array_equal(next_state_.lengths, [1, 3, 3])\n    np.testing.assert_array_equal(next_state_.finished, [True, False, False])\n\n    expected_log_probs = state_.log_probs[outputs_.beam_parent_ids]\n    expected_log_probs[1] += log_probs_[0, 2]\n    expected_log_probs[2] += log_probs_[2, 2]\n    np.testing.assert_array_equal(next_state_.log_probs, expected_log_probs)\n\n  def test_step_with_new_eos(self):\n    beam_state = beam_search.BeamSearchState(\n        log_probs=tf.nn.log_softmax(tf.ones(self.config.beam_width)),\n        lengths=tf.constant(\n            2, shape=[self.config.beam_width], dtype=tf.int32),\n        finished=tf.zeros(\n            [self.config.beam_width], dtype=tf.bool))\n\n    logits_ = np.full([self.config.beam_width, self.config.vocab_size], 0.0001)\n    logits_[0, 0] = 1.9\n    logits_[0, 3] = 2.1\n    logits_[1, 3] = 3.1\n    logits_[1, 4] = 0.9\n    logits = tf.convert_to_tensor(logits_, dtype=tf.float32)\n    log_probs = tf.nn.log_softmax(logits)\n\n    outputs, next_beam_state = beam_search.beam_search_step(\n        time_=2, logits=logits, beam_state=beam_state, config=self.config)\n\n    with self.test_session() as sess:\n      outputs_, next_state_, state_, log_probs_ = sess.run(\n          [outputs, next_beam_state, beam_state, log_probs])\n\n    np.testing.assert_array_equal(outputs_.predicted_ids, [3, 3, 0])\n    np.testing.assert_array_equal(outputs_.beam_parent_ids, [1, 0, 0])\n    np.testing.assert_array_equal(next_state_.lengths, [3, 3, 2])\n    np.testing.assert_array_equal(next_state_.finished, [False, False, True])\n\n    expected_log_probs = state_.log_probs[[1, 0, 0]]\n    expected_log_probs[0] += log_probs_[1, 3]\n    expected_log_probs[1] += log_probs_[0, 3]\n    expected_log_probs[2] += log_probs_[0, 0]\n    np.testing.assert_array_equal(next_state_.log_probs, expected_log_probs)\n\n\nclass TestEosMasking(tf.test.TestCase):\n  """"""Tests EOS masking used in beam search\n  """"""\n\n  def test_eos_masking(self):\n    probs = tf.constant([[-.2, -.2, -.2, -.2, -.2], [-.3, -.3, -.3, 3, 0],\n                         [5, 6, 0, 0, 0]])\n    eos_token = 0\n    previously_finished = tf.constant([0, 1, 0], dtype=tf.float32)\n    masked = beam_search.mask_probs(probs, eos_token, previously_finished)\n\n    with self.test_session() as sess:\n      probs = sess.run(probs)\n      masked = sess.run(masked)\n\n      np.testing.assert_array_equal(probs[0], masked[0])\n      np.testing.assert_array_equal(probs[2], masked[2])\n      np.testing.assert_equal(masked[1][0], 0)\n      np.testing.assert_approx_equal(masked[1][1], np.finfo(\'float32\').min)\n      np.testing.assert_approx_equal(masked[1][2], np.finfo(\'float32\').min)\n      np.testing.assert_approx_equal(masked[1][3], np.finfo(\'float32\').min)\n      np.testing.assert_approx_equal(masked[1][4], np.finfo(\'float32\').min)\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/bridges_test.py,17,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTests for Encoder-Decoder bridges.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.util import nest  # pylint: disable=E0611\n\nfrom seq2seq.encoders.encoder import EncoderOutput\nfrom seq2seq.models.bridges import ZeroBridge, InitialStateBridge\nfrom seq2seq.models.bridges import PassThroughBridge\n\nDecoderOutput = namedtuple(""DecoderOutput"", [""predicted_ids""])\n\n\nclass BridgeTest(tf.test.TestCase):\n  """"""Abstract class for bridge tests""""""\n\n  def setUp(self):\n    super(BridgeTest, self).setUp()\n    self.batch_size = 4\n    self.encoder_cell = tf.contrib.rnn.MultiRNNCell(\n        [tf.contrib.rnn.GRUCell(4), tf.contrib.rnn.GRUCell(8)])\n    self.decoder_cell = tf.contrib.rnn.MultiRNNCell(\n        [tf.contrib.rnn.LSTMCell(16), tf.contrib.rnn.GRUCell(8)])\n    final_encoder_state = nest.map_structure(\n        lambda x: tf.convert_to_tensor(\n            value=np.random.randn(self.batch_size, x),\n            dtype=tf.float32),\n        self.encoder_cell.state_size)\n    self.encoder_outputs = EncoderOutput(\n        outputs=tf.convert_to_tensor(\n            value=np.random.randn(self.batch_size, 10, 16), dtype=tf.float32),\n        attention_values=tf.convert_to_tensor(\n            value=np.random.randn(self.batch_size, 10, 16), dtype=tf.float32),\n        attention_values_length=np.full([self.batch_size], 10),\n        final_state=final_encoder_state)\n\n  def _create_bridge(self):\n    """"""Creates the bridge class to be tests. Must be implemented by\n    child classes""""""\n    raise NotImplementedError()\n\n  def _assert_correct_outputs(self):\n    """"""Asserts bridge outputs are correct. Must be implemented by\n    child classes""""""\n    raise NotImplementedError()\n\n  def _run(self, scope=None, **kwargs):\n    """"""Runs the bridge with the given arguments\n    """"""\n\n    with tf.variable_scope(scope or ""bridge""):\n      bridge = self._create_bridge(**kwargs)\n      initial_state = bridge()\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      initial_state_ = sess.run(initial_state)\n\n    return initial_state_\n\n\nclass TestZeroBridge(BridgeTest):\n  """"""Tests for the ZeroBridge class""""""\n\n  def _create_bridge(self, **kwargs):\n    return ZeroBridge(\n        encoder_outputs=self.encoder_outputs,\n        decoder_state_size=self.decoder_cell.state_size,\n        params=kwargs,\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  def _assert_correct_outputs(self, initial_state_):\n    initial_state_flat_ = nest.flatten(initial_state_)\n    for element in initial_state_flat_:\n      np.testing.assert_array_equal(element, np.zeros_like(element))\n\n  def test_zero_bridge(self):\n    self._assert_correct_outputs(self._run())\n\n\nclass TestPassThroughBridge(BridgeTest):\n  """"""Tests for the ZeroBridge class""""""\n\n  def _create_bridge(self, **kwargs):\n    return PassThroughBridge(\n        encoder_outputs=self.encoder_outputs,\n        decoder_state_size=self.decoder_cell.state_size,\n        params=kwargs,\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  def _assert_correct_outputs(self, initial_state_):\n    nest.assert_same_structure(initial_state_, self.decoder_cell.state_size)\n    nest.assert_same_structure(initial_state_, self.encoder_outputs.final_state)\n\n    encoder_state_flat = nest.flatten(self.encoder_outputs.final_state)\n    with self.test_session() as sess:\n      encoder_state_flat_ = sess.run(encoder_state_flat)\n\n    initial_state_flat_ = nest.flatten(initial_state_)\n    for e_dec, e_enc in zip(initial_state_flat_, encoder_state_flat_):\n      np.testing.assert_array_equal(e_dec, e_enc)\n\n  def test_passthrough_bridge(self):\n    self.decoder_cell = self.encoder_cell\n    self._assert_correct_outputs(self._run())\n\n\nclass TestInitialStateBridge(BridgeTest):\n  """"""Tests for the InitialStateBridge class""""""\n\n  def _create_bridge(self, **kwargs):\n    return InitialStateBridge(\n        encoder_outputs=self.encoder_outputs,\n        decoder_state_size=self.decoder_cell.state_size,\n        params=kwargs,\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n  def _assert_correct_outputs(self, initial_state_):\n    nest.assert_same_structure(initial_state_, self.decoder_cell.state_size)\n\n  def test_with_final_state(self):\n    self._assert_correct_outputs(self._run(bridge_input=""final_state""))\n\n  def test_with_outputs(self):\n    self._assert_correct_outputs(self._run(bridge_input=""outputs""))\n\n  def test_with_activation_fn(self):\n    self._assert_correct_outputs(\n        self._run(\n            bridge_input=""final_state"", activation_fn=""tanh""))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/conv_encoder_test.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for PoolingEncoder.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.encoders import ConvEncoder\n\n\nclass ConvEncoderTest(tf.test.TestCase):\n  """"""\n  Tests the ConvEncoder class.\n  """"""\n\n  def setUp(self):\n    super(ConvEncoderTest, self).setUp()\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.mode = tf.contrib.learn.ModeKeys.TRAIN\n\n  def _test_with_params(self, params):\n    """"""Tests the encoder with a given parameter configuration""""""\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    example_length = tf.ones(\n        self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    encode_fn = ConvEncoder(params, self.mode)\n    encoder_output = encode_fn(inputs, example_length)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      encoder_output_ = sess.run(encoder_output)\n\n    att_value_units = encode_fn.params[""attention_cnn.units""]\n    output_units = encode_fn.params[""output_cnn.units""]\n\n    np.testing.assert_array_equal(\n        encoder_output_.outputs.shape,\n        [self.batch_size, self.sequence_length, att_value_units])\n    np.testing.assert_array_equal(\n        encoder_output_.attention_values.shape,\n        [self.batch_size, self.sequence_length, output_units])\n    np.testing.assert_array_equal(\n        encoder_output_.final_state.shape,\n        [self.batch_size, output_units])\n\n  def test_encode_with_pos(self):\n    self._test_with_params({\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.num_positions"": self.sequence_length,\n        ""attention_cnn.units"": 5,\n        ""output_cnn.units"": 6\n    })\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/data_test.py,10,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for input-related operations.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tempfile\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.data import split_tokens_decoder\nfrom seq2seq.data.parallel_data_provider import make_parallel_data_provider\n\n\nclass SplitTokensDecoderTest(tf.test.TestCase):\n  """"""Tests the SplitTokensDecoder class\n  """"""\n\n  def test_decode(self):\n    decoder = split_tokens_decoder.SplitTokensDecoder(\n        delimiter="" "",\n        tokens_feature_name=""source_tokens"",\n        length_feature_name=""source_len"")\n\n    self.assertEqual(decoder.list_items(), [""source_tokens"", ""source_len""])\n\n    data = tf.constant(""Hello world ! \xe7\xac\x91\xef\xbd\x97"")\n\n    decoded_tokens = decoder.decode(data, [""source_tokens""])\n    decoded_length = decoder.decode(data, [""source_len""])\n    decoded_both = decoder.decode(data, decoder.list_items())\n\n    with self.test_session() as sess:\n      decoded_tokens_ = sess.run(decoded_tokens)[0]\n      decoded_length_ = sess.run(decoded_length)[0]\n      decoded_both_ = sess.run(decoded_both)\n\n    self.assertEqual(decoded_length_, 4)\n    np.testing.assert_array_equal(\n        np.char.decode(decoded_tokens_.astype(""S""), ""utf-8""),\n        [""Hello"", ""world"", ""!"", ""\xe7\xac\x91\xef\xbd\x97""])\n\n    self.assertEqual(decoded_both_[1], 4)\n    np.testing.assert_array_equal(\n        np.char.decode(decoded_both_[0].astype(""S""), ""utf-8""),\n        [""Hello"", ""world"", ""!"", ""\xe7\xac\x91\xef\xbd\x97""])\n\n\nclass ParallelDataProviderTest(tf.test.TestCase):\n  """"""Tests the ParallelDataProvider class\n  """"""\n\n  def setUp(self):\n    super(ParallelDataProviderTest, self).setUp()\n    # Our data\n    self.source_lines = [""Hello"", ""World"", ""!"", ""\xe7\xac\x91""]\n    self.target_lines = [""1"", ""2"", ""3"", ""\xe7\xac\x91""]\n    self.source_to_target = dict(zip(self.source_lines, self.target_lines))\n\n    # Create two parallel text files\n    self.source_file = tempfile.NamedTemporaryFile()\n    self.target_file = tempfile.NamedTemporaryFile()\n    self.source_file.write(""\\n"".join(self.source_lines).encode(""utf-8""))\n    self.source_file.flush()\n    self.target_file.write(""\\n"".join(self.target_lines).encode(""utf-8""))\n    self.target_file.flush()\n\n  def tearDown(self):\n    super(ParallelDataProviderTest, self).tearDown()\n    self.source_file.close()\n    self.target_file.close()\n\n  def test_reading(self):\n    num_epochs = 50\n    data_provider = make_parallel_data_provider(\n        data_sources_source=[self.source_file.name],\n        data_sources_target=[self.target_file.name],\n        num_epochs=num_epochs,\n        shuffle=True)\n\n    item_keys = list(data_provider.list_items())\n    item_values = data_provider.get(item_keys)\n    items_dict = dict(zip(item_keys, item_values))\n\n    self.assertEqual(\n        set(item_keys),\n        set([""source_tokens"", ""source_len"", ""target_tokens"", ""target_len""]))\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        item_dicts_ = [sess.run(items_dict) for _ in range(num_epochs * 3)]\n\n    for item_dict in item_dicts_:\n      item_dict[""target_tokens""] = np.char.decode(\n          item_dict[""target_tokens""].astype(""S""), ""utf-8"")\n      item_dict[""source_tokens""] = np.char.decode(\n          item_dict[""source_tokens""].astype(""S""), ""utf-8"")\n\n      # Source is Data + SEQUENCE_END\n      self.assertEqual(item_dict[""source_len""], 2)\n      self.assertEqual(item_dict[""source_tokens""][-1], ""SEQUENCE_END"")\n      # Target is SEQUENCE_START + Data + SEQUENCE_END\n      self.assertEqual(item_dict[""target_len""], 3)\n      self.assertEqual(item_dict[""target_tokens""][0], ""SEQUENCE_START"")\n      self.assertEqual(item_dict[""target_tokens""][-1], ""SEQUENCE_END"")\n\n      # Make sure data is aligned\n      source_joined = "" "".join(item_dict[""source_tokens""][:-1])\n      expected_target = self.source_to_target[source_joined]\n      np.testing.assert_array_equal(\n          item_dict[""target_tokens""],\n          [""SEQUENCE_START""] + expected_target.split("" "") + [""SEQUENCE_END""])\n\n  def test_reading_without_targets(self):\n    num_epochs = 50\n    data_provider = make_parallel_data_provider(\n        data_sources_source=[self.source_file.name],\n        data_sources_target=None,\n        num_epochs=num_epochs,\n        shuffle=True)\n\n    item_keys = list(data_provider.list_items())\n    item_values = data_provider.get(item_keys)\n    items_dict = dict(zip(item_keys, item_values))\n\n    self.assertEqual(set(item_keys), set([""source_tokens"", ""source_len""]))\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        item_dicts_ = [sess.run(items_dict) for _ in range(num_epochs * 3)]\n\n    for item_dict in item_dicts_:\n      self.assertEqual(item_dict[""source_len""], 2)\n      item_dict[""source_tokens""] = np.char.decode(\n          item_dict[""source_tokens""].astype(""S""), ""utf-8"")\n      self.assertEqual(item_dict[""source_tokens""][-1], ""SEQUENCE_END"")\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/decoder_test.py,34,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for decoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.decoders import BasicDecoder, AttentionDecoder, AttentionLayerDot\nfrom seq2seq.decoders import beam_search_decoder\nfrom seq2seq.inference import beam_search\nfrom seq2seq.contrib.seq2seq import helper as decode_helper\n\n\nclass DecoderTests(object):\n  """"""\n  A collection of decoder tests. This class should be inherited together with\n  `tf.test.TestCase`.\n  """"""\n\n  def __init__(self):\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.vocab_size = 100\n    self.max_decode_length = 20\n\n  def create_decoder(self, helper, mode):\n    """"""Creates the decoder module.\n\n    This must be implemented by child classes and instantiate the appropriate\n    decoder to be tested.\n    """"""\n    raise NotImplementedError\n\n  def test_with_fixed_inputs(self):\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    helper = decode_helper.TrainingHelper(\n        inputs=inputs, sequence_length=seq_length)\n    decoder_fn = self.create_decoder(\n        helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)\n    initial_state = decoder_fn.cell.zero_state(\n        self.batch_size, dtype=tf.float32)\n    decoder_output, _ = decoder_fn(initial_state, helper)\n\n    #pylint: disable=E1101\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      decoder_output_ = sess.run(decoder_output)\n\n    np.testing.assert_array_equal(\n        decoder_output_.logits.shape,\n        [self.sequence_length, self.batch_size, self.vocab_size])\n    np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,\n                                  [self.sequence_length, self.batch_size])\n\n    return decoder_output_\n\n  def test_gradients(self):\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length\n    labels = np.random.randint(0, self.vocab_size,\n                               [self.batch_size, self.sequence_length])\n\n    helper = decode_helper.TrainingHelper(\n        inputs=inputs, sequence_length=seq_length)\n    decoder_fn = self.create_decoder(\n        helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)\n    initial_state = decoder_fn.cell.zero_state(\n        self.batch_size, dtype=tf.float32)\n    decoder_output, _ = decoder_fn(initial_state, helper)\n\n    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=decoder_output.logits, labels=labels)\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n    grads_and_vars = optimizer.compute_gradients(tf.reduce_mean(losses))\n\n    #pylint: disable=E1101\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      grads_and_vars_ = sess.run(grads_and_vars)\n\n    for grad, _ in grads_and_vars_:\n      self.assertFalse(np.isnan(grad).any())\n\n    return grads_and_vars_\n\n  def test_with_dynamic_inputs(self):\n    embeddings = tf.get_variable(""W_embed"", [self.vocab_size, self.input_depth])\n\n    helper = decode_helper.GreedyEmbeddingHelper(\n        embedding=embeddings, start_tokens=[0] * self.batch_size, end_token=-1)\n    decoder_fn = self.create_decoder(\n        helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)\n    initial_state = decoder_fn.cell.zero_state(\n        self.batch_size, dtype=tf.float32)\n    decoder_output, _ = decoder_fn(initial_state, helper)\n\n    #pylint: disable=E1101\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      decoder_output_ = sess.run(decoder_output)\n\n    np.testing.assert_array_equal(\n        decoder_output_.logits.shape,\n        [self.max_decode_length, self.batch_size, self.vocab_size])\n    np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,\n                                  [self.max_decode_length, self.batch_size])\n\n  def test_with_beam_search(self):\n    self.batch_size = 1\n\n    # Batch size for beam search must be 1.\n    config = beam_search.BeamSearchConfig(\n        beam_width=10,\n        vocab_size=self.vocab_size,\n        eos_token=self.vocab_size - 2,\n        length_penalty_weight=0.6,\n        choose_successors_fn=beam_search.choose_top_k)\n\n    embeddings = tf.get_variable(""W_embed"", [self.vocab_size, self.input_depth])\n\n    helper = decode_helper.GreedyEmbeddingHelper(\n        embedding=embeddings,\n        start_tokens=[0] * config.beam_width,\n        end_token=-1)\n    decoder_fn = self.create_decoder(\n        helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)\n    decoder_fn = beam_search_decoder.BeamSearchDecoder(\n        decoder=decoder_fn, config=config)\n\n    initial_state = decoder_fn.cell.zero_state(\n        self.batch_size, dtype=tf.float32)\n    decoder_output, _ = decoder_fn(initial_state, helper)\n\n    #pylint: disable=E1101\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      decoder_output_ = sess.run(decoder_output)\n\n    np.testing.assert_array_equal(\n        decoder_output_.predicted_ids.shape,\n        [self.max_decode_length, 1, config.beam_width])\n    np.testing.assert_array_equal(\n        decoder_output_.beam_search_output.beam_parent_ids.shape,\n        [self.max_decode_length, 1, config.beam_width])\n    np.testing.assert_array_equal(\n        decoder_output_.beam_search_output.scores.shape,\n        [self.max_decode_length, 1, config.beam_width])\n    np.testing.assert_array_equal(\n        decoder_output_.beam_search_output.original_outputs.predicted_ids.shape,\n        [self.max_decode_length, 1, config.beam_width])\n    np.testing.assert_array_equal(\n        decoder_output_.beam_search_output.original_outputs.logits.shape,\n        [self.max_decode_length, 1, config.beam_width, self.vocab_size])\n\n    return decoder_output\n\n\nclass BasicDecoderTest(tf.test.TestCase, DecoderTests):\n  """"""Tests the `BasicDecoder` class.\n  """"""\n\n  def setUp(self):\n    tf.test.TestCase.setUp(self)\n    tf.logging.set_verbosity(tf.logging.INFO)\n    DecoderTests.__init__(self)\n\n  def create_decoder(self, helper, mode):\n    params = BasicDecoder.default_params()\n    params[""max_decode_length""] = self.max_decode_length\n    decoder = BasicDecoder(params=params, mode=mode, vocab_size=self.vocab_size)\n\n    return decoder\n\n\nclass AttentionDecoderTest(tf.test.TestCase, DecoderTests):\n  """"""Tests the `AttentionDecoder` class.\n  """"""\n\n  def setUp(self):\n    tf.test.TestCase.setUp(self)\n    tf.logging.set_verbosity(tf.logging.INFO)\n    DecoderTests.__init__(self)\n    self.attention_dim = 64\n    self.input_seq_len = 10\n\n  def create_decoder(self, helper, mode):\n    attention_fn = AttentionLayerDot(\n        params={""num_units"": self.attention_dim},\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n    attention_values = tf.convert_to_tensor(\n        np.random.randn(self.batch_size, self.input_seq_len, 32),\n        dtype=tf.float32)\n    attention_keys = tf.convert_to_tensor(\n        np.random.randn(self.batch_size, self.input_seq_len, 32),\n        dtype=tf.float32)\n    params = AttentionDecoder.default_params()\n    params[""max_decode_length""] = self.max_decode_length\n    return AttentionDecoder(\n        params=params,\n        mode=mode,\n        vocab_size=self.vocab_size,\n        attention_keys=attention_keys,\n        attention_values=attention_values,\n        attention_values_length=np.arange(self.batch_size) + 1,\n        attention_fn=attention_fn)\n\n  def test_attention_scores(self):\n    decoder_output_ = self.test_with_fixed_inputs()\n    np.testing.assert_array_equal(\n        decoder_output_.attention_scores.shape,\n        [self.sequence_length, self.batch_size, self.input_seq_len])\n\n    # Make sure the attention scores sum to 1 for each step\n    scores_sum = np.sum(decoder_output_.attention_scores, axis=2)\n    np.testing.assert_array_almost_equal(\n        scores_sum, np.ones([self.sequence_length, self.batch_size]))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/example_config_test.py,1,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for example configuration files.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nfrom pydoc import locate\n\nimport yaml\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq.test.models_test import EncoderDecoderTests\nfrom seq2seq import models\n\nEXAMPLE_CONFIG_DIR = os.path.abspath(\n    os.path.join(os.path.dirname(__file__), ""../../example_configs""))\n\n\ndef _load_model_from_config(config_path, hparam_overrides, vocab_file, mode):\n  """"""Loads model from a configuration file""""""\n  with gfile.GFile(config_path) as config_file:\n    config = yaml.load(config_file)\n  model_cls = locate(config[""model""]) or getattr(models, config[""model""])\n  model_params = config[""model_params""]\n  if hparam_overrides:\n    model_params.update(hparam_overrides)\n  # Change the max decode length to make the test run faster\n  model_params[""decoder.params""][""max_decode_length""] = 5\n  model_params[""vocab_source""] = vocab_file\n  model_params[""vocab_target""] = vocab_file\n  return model_cls(params=model_params, mode=mode)\n\n\nclass ExampleConfigTest(object):\n  """"""Interface for configuration-based tests""""""\n\n  def __init__(self, *args, **kwargs):\n    super(ExampleConfigTest, self).__init__(*args, **kwargs)\n    self.vocab_file = None\n\n  def _config_path(self):\n    """"""Returns the path to the configuration to be tested""""""\n    raise NotImplementedError()\n\n  def create_model(self, mode, params=None):\n    """"""Creates the model""""""\n    return _load_model_from_config(\n        config_path=self._config_path(),\n        hparam_overrides=params,\n        vocab_file=self.vocab_file.name,\n        mode=mode)\n\n\nclass TestNMTLarge(ExampleConfigTest, EncoderDecoderTests):\n  """"""Tests nmt_large.yml""""""\n\n  def _config_path(self):\n    return os.path.join(EXAMPLE_CONFIG_DIR, ""nmt_large.yml"")\n\n\nclass TestNMTMedium(ExampleConfigTest, EncoderDecoderTests):\n  """"""Tests nmt_medium.yml""""""\n\n  def _config_path(self):\n    return os.path.join(EXAMPLE_CONFIG_DIR, ""nmt_medium.yml"")\n\n\nclass TestNMTSmall(ExampleConfigTest, EncoderDecoderTests):\n  """"""Tests nmt_small.yml""""""\n\n  def _config_path(self):\n    return os.path.join(EXAMPLE_CONFIG_DIR, ""nmt_small.yml"")\n\nclass TestNMTConv(ExampleConfigTest, EncoderDecoderTests):\n  """"""Tests nmt_small.yml""""""\n\n  def _config_path(self):\n    return os.path.join(EXAMPLE_CONFIG_DIR, ""nmt_conv.yml"")\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/hooks_test.py,25,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for SessionRunHooks.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport tempfile\nimport shutil\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.python.training import monitored_session  # pylint: disable=E0611\nfrom tensorflow import gfile\n\nfrom seq2seq import graph_utils\nfrom seq2seq.training import hooks\n\n\nclass TestPrintModelAnalysisHook(tf.test.TestCase):\n  """"""Tests the `PrintModelAnalysisHook` hook""""""\n\n  def test_begin(self):\n    model_dir = tempfile.mkdtemp()\n    outfile = tempfile.NamedTemporaryFile()\n    tf.get_variable(""weigths"", [128, 128])\n    hook = hooks.PrintModelAnalysisHook(\n        params={}, model_dir=model_dir, run_config=tf.contrib.learn.RunConfig())\n    hook.begin()\n\n    with gfile.GFile(os.path.join(model_dir, ""model_analysis.txt"")) as file:\n      file_contents = file.read().strip()\n\n    self.assertEqual(file_contents.decode(), ""_TFProfRoot (--/16.38k params)\\n""\n                     ""  weigths (128x128, 16.38k/16.38k params)"")\n    outfile.close()\n\n\nclass TestTrainSampleHook(tf.test.TestCase):\n  """"""Tests `TrainSampleHook` class.\n  """"""\n\n  def setUp(self):\n    super(TestTrainSampleHook, self).setUp()\n    self.model_dir = tempfile.mkdtemp()\n    self.sample_dir = os.path.join(self.model_dir, ""samples"")\n\n    # The hook expects these collections to be in the graph\n    pred_dict = {}\n    pred_dict[""predicted_tokens""] = tf.constant([[""Hello"", ""World"", ""\xe7\xac\x91w""]])\n    pred_dict[""labels.target_tokens""] = tf.constant([[""Hello"", ""World"", ""\xe7\xac\x91w""]])\n    pred_dict[""labels.target_len""] = tf.constant(2),\n    graph_utils.add_dict_to_collection(pred_dict, ""predictions"")\n\n  def tearDown(self):\n    super(TestTrainSampleHook, self).tearDown()\n    shutil.rmtree(self.model_dir)\n\n  def test_sampling(self):\n    hook = hooks.TrainSampleHook(\n        params={""every_n_steps"": 10}, model_dir=self.model_dir,\n        run_config=tf.contrib.learn.RunConfig())\n\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    no_op = tf.no_op()\n    hook.begin()\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      sess.run(tf.tables_initializer())\n\n      #pylint: disable=W0212\n      mon_sess = monitored_session._HookedSession(sess, [hook])\n      # Should trigger for step 0\n      sess.run(tf.assign(global_step, 0))\n      mon_sess.run(no_op)\n\n      outfile = os.path.join(self.sample_dir, ""samples_000000.txt"")\n      with open(outfile, ""rb"") as readfile:\n        self.assertIn(""Prediction followed by Target @ Step 0"",\n                      readfile.read().decode(""utf-8""))\n\n      # Should not trigger for step 9\n      sess.run(tf.assign(global_step, 9))\n      mon_sess.run(no_op)\n      outfile = os.path.join(self.sample_dir, ""samples_000009.txt"")\n      self.assertFalse(os.path.exists(outfile))\n\n      # Should trigger for step 10\n      sess.run(tf.assign(global_step, 10))\n      mon_sess.run(no_op)\n      outfile = os.path.join(self.sample_dir, ""samples_000010.txt"")\n      with open(outfile, ""rb"") as readfile:\n        self.assertIn(""Prediction followed by Target @ Step 10"",\n                      readfile.read().decode(""utf-8""))\n\n\nclass TestMetadataCaptureHook(tf.test.TestCase):\n  """"""Test for the MetadataCaptureHook""""""\n\n  def setUp(self):\n    super(TestMetadataCaptureHook, self).setUp()\n    self.model_dir = tempfile.mkdtemp()\n\n  def tearDown(self):\n    super(TestMetadataCaptureHook, self).tearDown()\n    shutil.rmtree(self.model_dir)\n\n  def test_capture(self):\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    # Some test computation\n    some_weights = tf.get_variable(""weigths"", [2, 128])\n    computation = tf.nn.softmax(some_weights)\n\n    hook = hooks.MetadataCaptureHook(\n        params={""step"": 5}, model_dir=self.model_dir,\n        run_config=tf.contrib.learn.RunConfig())\n    hook.begin()\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      #pylint: disable=W0212\n      mon_sess = monitored_session._HookedSession(sess, [hook])\n      # Should not trigger for step 0\n      sess.run(tf.assign(global_step, 0))\n      mon_sess.run(computation)\n      self.assertEqual(gfile.ListDirectory(self.model_dir), [])\n      # Should trigger *after* step 5\n      sess.run(tf.assign(global_step, 5))\n      mon_sess.run(computation)\n      self.assertEqual(gfile.ListDirectory(self.model_dir), [])\n      mon_sess.run(computation)\n      self.assertEqual(\n          set(gfile.ListDirectory(self.model_dir)),\n          set([""run_meta"", ""tfprof_log"", ""timeline.json""]))\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/input_pipeline_test.py,16,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for input-related operations.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\nimport yaml\n\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.test import utils as test_utils\n\n\nclass TestInputPipelineDef(tf.test.TestCase):\n  """"""Tests InputPipeline string definitions""""""\n\n  def test_without_extra_args(self):\n    pipeline_def = yaml.load(""""""\n      class: ParallelTextInputPipeline\n      params:\n        source_files: [""file1""]\n        target_files: [""file2""]\n        num_epochs: 1\n        shuffle: True\n    """""")\n    pipeline = input_pipeline.make_input_pipeline_from_def(\n        pipeline_def, tf.contrib.learn.ModeKeys.TRAIN)\n    self.assertIsInstance(pipeline, input_pipeline.ParallelTextInputPipeline)\n    #pylint: disable=W0212\n    self.assertEqual(pipeline.params[""source_files""], [""file1""])\n    self.assertEqual(pipeline.params[""target_files""], [""file2""])\n    self.assertEqual(pipeline.params[""num_epochs""], 1)\n    self.assertEqual(pipeline.params[""shuffle""], True)\n\n  def test_with_extra_args(self):\n    pipeline_def = yaml.load(""""""\n      class: ParallelTextInputPipeline\n      params:\n        source_files: [""file1""]\n        target_files: [""file2""]\n        num_epochs: 1\n        shuffle: True\n    """""")\n    pipeline = input_pipeline.make_input_pipeline_from_def(\n        def_dict=pipeline_def,\n        mode=tf.contrib.learn.ModeKeys.TRAIN,\n        num_epochs=5,\n        shuffle=False)\n    self.assertIsInstance(pipeline, input_pipeline.ParallelTextInputPipeline)\n    #pylint: disable=W0212\n    self.assertEqual(pipeline.params[""source_files""], [""file1""])\n    self.assertEqual(pipeline.params[""target_files""], [""file2""])\n    self.assertEqual(pipeline.params[""num_epochs""], 5)\n    self.assertEqual(pipeline.params[""shuffle""], False)\n\n\nclass TFRecordsInputPipelineTest(tf.test.TestCase):\n  """"""\n  Tests Data Provider operations.\n  """"""\n\n  def setUp(self):\n    super(TFRecordsInputPipelineTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n  def test_pipeline(self):\n    tfrecords_file = test_utils.create_temp_tfrecords(\n        sources=[""Hello World . \xe7\xac\x91""], targets=[""Bye \xe6\xb3\xa3""])\n\n    pipeline = input_pipeline.TFRecordInputPipeline(\n        params={\n            ""files"": [tfrecords_file.name],\n            ""source_field"": ""source"",\n            ""target_field"": ""target"",\n            ""num_epochs"": 5,\n            ""shuffle"": False\n        },\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n    data_provider = pipeline.make_data_provider()\n\n    features = pipeline.read_from_data_provider(data_provider)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        res = sess.run(features)\n\n    self.assertEqual(res[""source_len""], 5)\n    self.assertEqual(res[""target_len""], 4)\n    np.testing.assert_array_equal(\n        np.char.decode(res[""source_tokens""].astype(""S""), ""utf-8""),\n        [""Hello"", ""World"", ""."", ""\xe7\xac\x91"", ""SEQUENCE_END""])\n    np.testing.assert_array_equal(\n        np.char.decode(res[""target_tokens""].astype(""S""), ""utf-8""),\n        [""SEQUENCE_START"", ""Bye"", ""\xe6\xb3\xa3"", ""SEQUENCE_END""])\n\n\nclass ParallelTextInputPipelineTest(tf.test.TestCase):\n  """"""\n  Tests Data Provider operations.\n  """"""\n\n  def setUp(self):\n    super(ParallelTextInputPipelineTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n  def test_pipeline(self):\n    file_source, file_target = test_utils.create_temp_parallel_data(\n        sources=[""Hello World . \xe7\xac\x91""], targets=[""Bye \xe6\xb3\xa3""])\n\n    pipeline = input_pipeline.ParallelTextInputPipeline(\n        params={\n            ""source_files"": [file_source.name],\n            ""target_files"": [file_target.name],\n            ""num_epochs"": 5,\n            ""shuffle"": False\n        },\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n\n    data_provider = pipeline.make_data_provider()\n\n    features = pipeline.read_from_data_provider(data_provider)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        res = sess.run(features)\n\n    self.assertEqual(res[""source_len""], 5)\n    self.assertEqual(res[""target_len""], 4)\n    np.testing.assert_array_equal(\n        np.char.decode(res[""source_tokens""].astype(""S""), ""utf-8""),\n        [""Hello"", ""World"", ""."", ""\xe7\xac\x91"", ""SEQUENCE_END""])\n    np.testing.assert_array_equal(\n        np.char.decode(res[""target_tokens""].astype(""S""), ""utf-8""),\n        [""SEQUENCE_START"", ""Bye"", ""\xe6\xb3\xa3"", ""SEQUENCE_END""])\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/losses_test.py,3,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for loss-related operations.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom seq2seq import losses as seq2seq_losses\nimport tensorflow as tf\nimport numpy as np\n\n\nclass CrossEntropySequenceLossTest(tf.test.TestCase):\n  """"""\n  Test for `sqe2seq.losses.sequence_mask`.\n  """"""\n\n  def setUp(self):\n    super(CrossEntropySequenceLossTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 4\n    self.sequence_length = 10\n    self.vocab_size = 50\n\n  def test_op(self):\n    logits = np.random.randn(self.sequence_length, self.batch_size,\n                             self.vocab_size)\n    logits = logits.astype(np.float32)\n    sequence_length = np.array([1, 2, 3, 4])\n    targets = np.random.randint(0, self.vocab_size,\n                                [self.sequence_length, self.batch_size])\n    losses = seq2seq_losses.cross_entropy_sequence_loss(logits, targets,\n                                                        sequence_length)\n\n    with self.test_session() as sess:\n      losses_ = sess.run(losses)\n\n    # Make sure all losses not past the sequence length are > 0\n    np.testing.assert_array_less(np.zeros_like(losses_[:1, 0]), losses_[:1, 0])\n    np.testing.assert_array_less(np.zeros_like(losses_[:2, 1]), losses_[:2, 1])\n    np.testing.assert_array_less(np.zeros_like(losses_[:3, 2]), losses_[:3, 2])\n\n    # Make sure all losses past the sequence length are 0\n    np.testing.assert_array_equal(losses_[1:, 0], np.zeros_like(losses_[1:, 0]))\n    np.testing.assert_array_equal(losses_[2:, 1], np.zeros_like(losses_[2:, 1]))\n    np.testing.assert_array_equal(losses_[3:, 2], np.zeros_like(losses_[3:, 2]))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/metrics_test.py,8,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for Metrics.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom seq2seq.metrics import bleu\nfrom seq2seq.metrics import rouge\nfrom seq2seq.metrics.metric_specs import BleuMetricSpec\nfrom seq2seq.metrics.metric_specs import RougeMetricSpec\n\n\nclass TestMosesBleu(tf.test.TestCase):\n  """"""Tests using the Moses multi-bleu script to calcualte BLEU score\n  """"""\n\n  def _test_multi_bleu(self, hypotheses, references, lowercase, expected_bleu):\n    #pylint: disable=R0201\n    """"""Runs a multi-bleu test.""""""\n    result = bleu.moses_multi_bleu(\n        hypotheses=hypotheses, references=references, lowercase=lowercase)\n    np.testing.assert_almost_equal(result, expected_bleu, decimal=2)\n\n  def test_multi_bleu(self):\n    self._test_multi_bleu(\n        hypotheses=np.array([\n            ""The brown fox jumps over the dog \xe7\xac\x91"",\n            ""The brown fox jumps over the dog 2 \xe7\xac\x91""\n        ]),\n        references=np.array([\n            ""The quick brown fox jumps over the lazy dog \xe7\xac\x91"",\n            ""The quick brown fox jumps over the lazy dog \xe7\xac\x91""\n        ]),\n        lowercase=False,\n        expected_bleu=46.51)\n\n  def test_empty(self):\n    self._test_multi_bleu(\n        hypotheses=np.array([]),\n        references=np.array([]),\n        lowercase=False,\n        expected_bleu=0.00)\n\n  def test_multi_bleu_lowercase(self):\n    self._test_multi_bleu(\n        hypotheses=np.array([\n            ""The brown fox jumps over The Dog \xe7\xac\x91"",\n            ""The brown fox jumps over The Dog 2 \xe7\xac\x91""\n        ]),\n        references=np.array([\n            ""The quick brown fox jumps over the lazy dog \xe7\xac\x91"",\n            ""The quick brown fox jumps over the lazy dog \xe7\xac\x91""\n        ]),\n        lowercase=True,\n        expected_bleu=46.51)\n\n\nclass TestTextMetricSpec(tf.test.TestCase):\n  """"""Abstract class for testing TextMetricSpecs\n  based on hypotheses and references""""""\n\n  def _test_metric_spec(self, metric_spec, hyps, refs, expected_scores):\n    """"""Tests a MetricSpec""""""\n    predictions = {""predicted_tokens"": tf.placeholder(dtype=tf.string)}\n    labels = {""target_tokens"": tf.placeholder(dtype=tf.string)}\n\n    value, update_op = metric_spec.create_metric_ops(None, labels, predictions)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n\n      scores = []\n      for hyp, ref in zip(hyps, refs):\n        hyp = hyp.split("" "")\n        ref = ref.split("" "")\n        sess.run(update_op, {\n            predictions[""predicted_tokens""]: [hyp],\n            labels[""target_tokens""]: [ref]\n        })\n        scores.append(sess.run(value))\n\n      for score, expected in zip(scores, expected_scores):\n        np.testing.assert_almost_equal(score, expected, decimal=2)\n        np.testing.assert_almost_equal(score, expected, decimal=2)\n\n\nclass TestBleuMetricSpec(TestTextMetricSpec):\n  """"""Tests the `BleuMetricSpec`""""""\n\n  def test_bleu(self):\n    metric_spec = BleuMetricSpec({})\n    return self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A B C D E F"", ""A B C D E F""],\n        refs=[""A B C D E F"", ""A B A D E F""],\n        expected_scores=[100.0, 69.19])\n\n\nclass TestRougeMetricSpec(TestTextMetricSpec):\n  """"""Tests the `RougeMetricSpec`""""""\n\n  def test_rouge_1_f_score(self):\n    metric_spec = RougeMetricSpec({""rouge_type"":  ""rouge_1/f_score""})\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A B C D E F"", ""A B C D E F""],\n        refs=[""A B C D E F"", ""A B A D E F""],\n        expected_scores=[1.0, 0.954])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[],\n        refs=[],\n        expected_scores=[0.0])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A""],\n        refs=[""B""],\n        expected_scores=[0.0])\n\n\n  def test_rouge_2_f_score(self):\n    metric_spec = RougeMetricSpec({""rouge_type"":  ""rouge_2/f_score""})\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A B C D E F"", ""A B C D E F""],\n        refs=[""A B C D E F"", ""A B A D E F""],\n        expected_scores=[1.0, 0.8])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[],\n        refs=[],\n        expected_scores=[0.0])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A""],\n        refs=[""B""],\n        expected_scores=[0.0])\n\n  def test_rouge_l_f_score(self):\n    metric_spec = RougeMetricSpec({""rouge_type"":  ""rouge_l/f_score""})\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A B C D E F"", ""A B C D E F""],\n        refs=[""A B C D E F"", ""A B A D E F""],\n        expected_scores=[1.0, 0.916])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[],\n        refs=[],\n        expected_scores=[0.0])\n\n    self._test_metric_spec(\n        metric_spec=metric_spec,\n        hyps=[""A""],\n        refs=[""B""],\n        expected_scores=[0.0])\n\n\nclass TestRougeMetric(tf.test.TestCase):\n  """"""Tests the RougeMetric""""""\n\n  def test_rouge(self):\n    #pylint: disable=R0201\n    hypotheses = np.array([\n        ""The brown fox jumps over the dog \xe7\xac\x91"",\n        ""The brown fox jumps over the dog 2 \xe7\xac\x91""\n    ])\n    references = np.array([\n        ""The quick brown fox jumps over the lazy dog \xe7\xac\x91"",\n        ""The quick brown fox jumps over the lazy dog \xe7\xac\x91""\n    ])\n    output = rouge.rouge(hypotheses, references)\n    # pyrouge result: 0.84926\n    np.testing.assert_almost_equal(output[""rouge_1/f_score""], 0.865, decimal=2)\n    # pyrouge result: 0.55238\n    np.testing.assert_almost_equal(output[""rouge_2/f_score""], 0.548, decimal=2)\n    # pyrouge result 0.84926\n    np.testing.assert_almost_equal(output[""rouge_l/f_score""], 0.852, decimal=2)\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/models_test.py,14,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Tests for Models\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nimport yaml\nimport numpy as np\nimport tensorflow as tf\n\nfrom seq2seq.data import vocab, input_pipeline\nfrom seq2seq.training import utils as training_utils\nfrom seq2seq.test import utils as test_utils\nfrom seq2seq.models import BasicSeq2Seq, AttentionSeq2Seq\n\nTEST_PARAMS = yaml.load(""""""\nembedding.dim: 5\nencoder.params:\n  rnn_cell:\n    dropout_input_keep_prob: 0.8\n    num_layers: 2\n    residual_connections: True,\n    cell_class: LSTMCell\n    cell_params:\n      num_units: 4\ndecoder.params:\n  rnn_cell:\n    num_layers: 2\n    cell_class: LSTMCell\n    cell_params:\n      num_units: 4\n"""""")\n\n\nclass EncoderDecoderTests(tf.test.TestCase):\n  """"""Base class for EncoderDecoder tests. Tests for specific classes should\n  inherit from this and tf.test.TestCase.\n  """"""\n\n  def setUp(self):\n    super(EncoderDecoderTests, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 2\n    self.input_depth = 4\n    self.sequence_length = 10\n\n    # Create vocabulary\n    self.vocab_list = [str(_) for _ in range(10)]\n    self.vocab_list += [""\xe7\xac\x91\xe3\x81\x86"", ""\xe6\xb3\xa3\xe3\x81\x8f"", ""\xe4\xba\x86\xe8\xa7\xa3"", ""\xe3\x81\xaf\xe3\x81\x84"", ""\xef\xbc\xbe\xef\xbc\xbf\xef\xbc\xbe""]\n    self.vocab_size = len(self.vocab_list)\n    self.vocab_file = test_utils.create_temporary_vocab_file(self.vocab_list)\n    self.vocab_info = vocab.get_vocab_info(self.vocab_file.name)\n\n    tf.contrib.framework.get_or_create_global_step()\n\n  def tearDown(self):\n    self.vocab_file.close()\n\n  def create_model(self, _mode, _params=None):\n    """"""Creates model class to be tested. Subclasses must implement this method.\n    """"""\n    self.skipTest(""Base module should not be tested."")\n\n  def _create_example(self):\n    """"""Creates example data for a test""""""\n    source = np.random.randn(self.batch_size, self.sequence_length,\n                             self.input_depth)\n    source_len = np.random.randint(0, self.sequence_length, [self.batch_size])\n    target_len = np.random.randint(0, self.sequence_length * 2,\n                                   [self.batch_size])\n    target = np.random.randn(self.batch_size,\n                             np.max(target_len), self.input_depth)\n    labels = np.random.randint(0, self.vocab_size,\n                               [self.batch_size, np.max(target_len) - 1])\n\n    example_ = namedtuple(\n        ""Example"", [""source"", ""source_len"", ""target"", ""target_len"", ""labels""])\n    return example_(source, source_len, target, target_len, labels)\n\n  def _test_pipeline(self, mode, params=None):\n    """"""Helper function to test the full model pipeline.\n    """"""\n    # Create source and target example\n    source_len = self.sequence_length + 5\n    target_len = self.sequence_length + 10\n    source = "" "".join(np.random.choice(self.vocab_list, source_len))\n    target = "" "".join(np.random.choice(self.vocab_list, target_len))\n    sources_file, targets_file = test_utils.create_temp_parallel_data(\n        sources=[source], targets=[target])\n\n    # Build model graph\n    model = self.create_model(mode, params)\n    input_pipeline_ = input_pipeline.ParallelTextInputPipeline(\n        params={\n            ""source_files"": [sources_file.name],\n            ""target_files"": [targets_file.name]\n        },\n        mode=mode)\n    input_fn = training_utils.create_input_fn(\n        pipeline=input_pipeline_, batch_size=self.batch_size)\n    features, labels = input_fn()\n    fetches = model(features, labels, None)\n    fetches = [_ for _ in fetches if _ is not None]\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      sess.run(tf.tables_initializer())\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        fetches_ = sess.run(fetches)\n\n    sources_file.close()\n    targets_file.close()\n\n    return model, fetches_\n\n  def test_train(self):\n    model, fetches_ = self._test_pipeline(tf.contrib.learn.ModeKeys.TRAIN)\n    predictions_, loss_, _ = fetches_\n\n    target_len = self.sequence_length + 10 + 2\n    max_decode_length = model.params[""target.max_seq_len""]\n    expected_decode_len = np.minimum(target_len, max_decode_length)\n\n    np.testing.assert_array_equal(predictions_[""logits""].shape, [\n        self.batch_size, expected_decode_len - 1,\n        model.target_vocab_info.total_size\n    ])\n    np.testing.assert_array_equal(predictions_[""losses""].shape,\n                                  [self.batch_size, expected_decode_len - 1])\n    np.testing.assert_array_equal(predictions_[""predicted_ids""].shape,\n                                  [self.batch_size, expected_decode_len - 1])\n    self.assertFalse(np.isnan(loss_))\n\n  def test_infer(self):\n    model, fetches_ = self._test_pipeline(tf.contrib.learn.ModeKeys.INFER)\n    predictions_, = fetches_\n    pred_len = predictions_[""predicted_ids""].shape[1]\n\n    np.testing.assert_array_equal(predictions_[""logits""].shape, [\n        self.batch_size, pred_len, model.target_vocab_info.total_size\n    ])\n    np.testing.assert_array_equal(predictions_[""predicted_ids""].shape,\n                                  [self.batch_size, pred_len])\n\n  def test_infer_beam_search(self):\n    self.batch_size = 1\n    beam_width = 10\n    model, fetches_ = self._test_pipeline(\n        mode=tf.contrib.learn.ModeKeys.INFER,\n        params={""inference.beam_search.beam_width"": 10})\n    predictions_, = fetches_\n    pred_len = predictions_[""predicted_ids""].shape[1]\n\n    vocab_size = model.target_vocab_info.total_size\n    np.testing.assert_array_equal(predictions_[""predicted_ids""].shape,\n                                  [1, pred_len, beam_width])\n    np.testing.assert_array_equal(\n        predictions_[""beam_search_output.beam_parent_ids""].shape,\n        [1, pred_len, beam_width])\n    np.testing.assert_array_equal(\n        predictions_[""beam_search_output.scores""].shape,\n        [1, pred_len, beam_width])\n    np.testing.assert_array_equal(\n        predictions_[""beam_search_output.original_outputs.predicted_ids""].shape,\n        [1, pred_len, beam_width])\n    np.testing.assert_array_equal(\n        predictions_[""beam_search_output.original_outputs.logits""].shape,\n        [1, pred_len, beam_width, vocab_size])\n\n\nclass TestBasicSeq2Seq(EncoderDecoderTests):\n  """"""Tests the seq2seq.models.BasicSeq2Seq model.\n  """"""\n\n  def setUp(self):\n    super(TestBasicSeq2Seq, self).setUp()\n\n  def create_model(self, mode, params=None):\n    params_ = BasicSeq2Seq.default_params().copy()\n    params_.update(TEST_PARAMS)\n    params_.update({\n        ""vocab_source"": self.vocab_file.name,\n        ""vocab_target"": self.vocab_file.name,\n        ""bridge.class"": ""PassThroughBridge""\n    })\n    params_.update(params or {})\n    return BasicSeq2Seq(params=params_, mode=mode)\n\n\nclass TestAttentionSeq2Seq(EncoderDecoderTests):\n  """"""Tests the seq2seq.models.AttentionSeq2Seq model.\n  """"""\n\n  def setUp(self):\n    super(TestAttentionSeq2Seq, self).setUp()\n    self.encoder_rnn_cell = tf.contrib.rnn.LSTMCell(32)\n    self.decoder_rnn_cell = tf.contrib.rnn.LSTMCell(32)\n    self.attention_dim = 128\n\n  def create_model(self, mode, params=None):\n    params_ = AttentionSeq2Seq.default_params().copy()\n    params_.update(TEST_PARAMS)\n    params_.update({\n        ""source.reverse"": True,\n        ""vocab_source"": self.vocab_file.name,\n        ""vocab_target"": self.vocab_file.name,\n    })\n    params_.update(params or {})\n    return AttentionSeq2Seq(params=params_, mode=mode)\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/pipeline_test.py,27,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for RNN encoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport imp\nimport os\nimport shutil\nimport tempfile\nimport yaml\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq.test import utils as test_utils\n\nBIN_FOLDER = os.path.abspath(\n    os.path.join(os.path.dirname(__file__), ""../../bin""))\n\n\ndef _clear_flags():\n  """"""Resets Tensorflow\'s FLAG values""""""\n  #pylint: disable=W0212\n  tf.app.flags.FLAGS = tf.app.flags._FlagValues()\n  tf.app.flags._global_parser = argparse.ArgumentParser()\n\n\nclass PipelineTest(tf.test.TestCase):\n  """"""Tests training and inference scripts.\n  """"""\n\n  def setUp(self):\n    super(PipelineTest, self).setUp()\n    self.output_dir = tempfile.mkdtemp()\n    self.bin_folder = os.path.abspath(\n        os.path.join(os.path.dirname(__file__), ""../../bin""))\n    tf.contrib.framework.get_or_create_global_step()\n\n  def tearDown(self):\n    shutil.rmtree(self.output_dir, ignore_errors=True)\n    super(PipelineTest, self).tearDown()\n\n  def test_train_infer(self):\n    """"""Tests training and inference scripts.\n    """"""\n    # Create dummy data\n    sources_train, targets_train = test_utils.create_temp_parallel_data(\n        sources=[""a a a a"", ""b b b b"", ""c c c c"", ""\xe7\xac\x91 \xe7\xac\x91 \xe7\xac\x91 \xe7\xac\x91""],\n        targets=[""b b b b"", ""a a a a"", ""c c c c"", ""\xe6\xb3\xa3 \xe6\xb3\xa3 \xe6\xb3\xa3 \xe6\xb3\xa3""])\n    sources_dev, targets_dev = test_utils.create_temp_parallel_data(\n        sources=[""a a"", ""b b"", ""c c c"", ""\xe7\xac\x91 \xe7\xac\x91 \xe7\xac\x91""],\n        targets=[""b b"", ""a a"", ""c c c"", ""\xe6\xb3\xa3 \xe6\xb3\xa3 \xe6\xb3\xa3""])\n    vocab_source = test_utils.create_temporary_vocab_file([""a"", ""b"", ""c"", ""\xe7\xac\x91""])\n    vocab_target = test_utils.create_temporary_vocab_file([""a"", ""b"", ""c"", ""\xe6\xb3\xa3""])\n\n    _clear_flags()\n    tf.reset_default_graph()\n    train_script = imp.load_source(""seq2seq.test.train_bin"",\n                                   os.path.join(BIN_FOLDER, ""train.py""))\n\n    # Set training flags\n    tf.app.flags.FLAGS.output_dir = self.output_dir\n    tf.app.flags.FLAGS.hooks = """"""\n      - class: PrintModelAnalysisHook\n      - class: MetadataCaptureHook\n      - class: TrainSampleHook\n    """"""\n    tf.app.flags.FLAGS.metrics = """"""\n      - class: LogPerplexityMetricSpec\n      - class: BleuMetricSpec\n      - class: RougeMetricSpec\n        params:\n          rouge_type: rouge_1/f_score\n    """"""\n    tf.app.flags.FLAGS.model = ""AttentionSeq2Seq""\n    tf.app.flags.FLAGS.model_params = """"""\n    attention.params:\n      num_units: 10\n    vocab_source: {}\n    vocab_target: {}\n    """""".format(vocab_source.name, vocab_target.name)\n    tf.app.flags.FLAGS.batch_size = 2\n\n    # We pass a few flags via a config file\n    config_path = os.path.join(self.output_dir, ""train_config.yml"")\n    with gfile.GFile(config_path, ""w"") as config_file:\n      yaml.dump({\n          ""input_pipeline_train"": {\n              ""class"": ""ParallelTextInputPipeline"",\n              ""params"": {\n                  ""source_files"": [sources_train.name],\n                  ""target_files"": [targets_train.name],\n              }\n          },\n          ""input_pipeline_dev"": {\n              ""class"": ""ParallelTextInputPipeline"",\n              ""params"": {\n                  ""source_files"": [sources_dev.name],\n                  ""target_files"": [targets_dev.name],\n              }\n          },\n          ""train_steps"": 50,\n          ""model_params"": {\n              ""embedding.dim"": 10,\n              ""decoder.params"": {\n                  ""rnn_cell"": {\n                      ""cell_class"": ""GRUCell"",\n                      ""cell_params"": {\n                          ""num_units"": 8\n                      }\n                  }\n              },\n              ""encoder.params"": {\n                  ""rnn_cell"": {\n                      ""cell_class"": ""GRUCell"",\n                      ""cell_params"": {\n                          ""num_units"": 8\n                      }\n                  }\n              }\n          }\n      }, config_file)\n\n    tf.app.flags.FLAGS.config_paths = config_path\n\n    # Run training\n    tf.logging.set_verbosity(tf.logging.INFO)\n    train_script.main([])\n\n    # Make sure a checkpoint was written\n    expected_checkpoint = os.path.join(self.output_dir,\n                                       ""model.ckpt-50.data-00000-of-00001"")\n    self.assertTrue(os.path.exists(expected_checkpoint))\n\n    # Reset flags and import inference script\n    _clear_flags()\n    tf.reset_default_graph()\n    infer_script = imp.load_source(""seq2seq.test.infer_bin"",\n                                   os.path.join(BIN_FOLDER, ""infer.py""))\n\n    # Set inference flags\n    attention_dir = os.path.join(self.output_dir, ""att"")\n    tf.app.flags.FLAGS.model_dir = self.output_dir\n    tf.app.flags.FLAGS.input_pipeline = """"""\n      class: ParallelTextInputPipeline\n      params:\n        source_files:\n          - {}\n        target_files:\n          - {}\n    """""".format(sources_dev.name, targets_dev.name)\n    tf.app.flags.FLAGS.batch_size = 2\n    tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,\n                                                      ""model.ckpt-50"")\n\n    # Use DecodeText Task\n    tf.app.flags.FLAGS.tasks = """"""\n    - class: DecodeText\n    - class: DumpAttention\n      params:\n        output_dir: {}\n    """""".format(attention_dir)\n\n    # Make sure inference runs successfully\n    infer_script.main([])\n\n    # Make sure attention scores and visualizations exist\n    self.assertTrue(\n        os.path.exists(os.path.join(attention_dir, ""attention_scores.npz"")))\n    self.assertTrue(os.path.exists(os.path.join(attention_dir, ""00002.png"")))\n\n    # Load attention scores and assert shape\n    scores = np.load(os.path.join(attention_dir, ""attention_scores.npz""))\n    self.assertIn(""arr_0"", scores)\n    self.assertEqual(scores[""arr_0""].shape[1], 3)\n    self.assertIn(""arr_1"", scores)\n    self.assertEqual(scores[""arr_1""].shape[1], 3)\n    self.assertIn(""arr_2"", scores)\n    self.assertEqual(scores[""arr_2""].shape[1], 4)\n    self.assertIn(""arr_3"", scores)\n    self.assertEqual(scores[""arr_3""].shape[1], 4)\n\n    # Test inference with beam search\n    _clear_flags()\n    tf.reset_default_graph()\n    infer_script = imp.load_source(""seq2seq.test.infer_bin"",\n                                   os.path.join(BIN_FOLDER, ""infer.py""))\n\n    # Set inference flags\n    tf.app.flags.FLAGS.model_dir = self.output_dir\n    tf.app.flags.FLAGS.input_pipeline = """"""\n      class: ParallelTextInputPipeline\n      params:\n        source_files:\n          - {}\n        target_files:\n          - {}\n    """""".format(sources_dev.name, targets_dev.name)\n    tf.app.flags.FLAGS.batch_size = 2\n    tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,\n                                                      ""model.ckpt-50"")\n    tf.app.flags.FLAGS.model_params = """"""\n      inference.beam_search.beam_width: 5\n    """"""\n    tf.app.flags.FLAGS.tasks = """"""\n    - class: DecodeText\n      params:\n        postproc_fn: seq2seq.data.postproc.decode_sentencepiece\n    - class: DumpBeams\n      params:\n        file: {}\n    """""".format(os.path.join(self.output_dir, ""beams.npz""))\n\n    # Run inference w/ beam search\n    infer_script.main([])\n    self.assertTrue(os.path.exists(os.path.join(self.output_dir, ""beams.npz"")))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/pooling_encoder_test.py,7,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for PoolingEncoder.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.encoders import PoolingEncoder\n\n\nclass PoolingEncoderTest(tf.test.TestCase):\n  """"""\n  Tests the PoolingEncoder class.\n  """"""\n\n  def setUp(self):\n    super(PoolingEncoderTest, self).setUp()\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.mode = tf.contrib.learn.ModeKeys.TRAIN\n\n  def _test_with_params(self, params):\n    """"""Tests the encoder with a given parameter configuration""""""\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    example_length = tf.ones(\n        self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    encode_fn = PoolingEncoder(params, self.mode)\n    encoder_output = encode_fn(inputs, example_length)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      encoder_output_ = sess.run(encoder_output)\n\n    np.testing.assert_array_equal(\n        encoder_output_.outputs.shape,\n        [self.batch_size, self.sequence_length, self.input_depth])\n    np.testing.assert_array_equal(\n        encoder_output_.attention_values.shape,\n        [self.batch_size, self.sequence_length, self.input_depth])\n    np.testing.assert_array_equal(encoder_output_.final_state.shape,\n                                  [self.batch_size, self.input_depth])\n\n  def test_encode_with_pos(self):\n    self._test_with_params({\n        ""position_embeddings.enable"": True,\n        ""position_embeddings.num_positions"": self.sequence_length\n    })\n\n  def test_encode_without_pos(self):\n    self._test_with_params({\n        ""position_embeddings.enable"": False,\n        ""position_embeddings.num_positions"": 0\n    })\n\nif __name__ == ""__main__"":\n  tf.test.main()'"
seq2seq/test/rnn_cell_test.py,24,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for input-related operations.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom seq2seq.contrib import rnn_cell\n\nimport numpy as np\n\n\nclass ExtendedMultiRNNCellTest(tf.test.TestCase):\n  """"""Tests the ExtendedMultiRNNCell""""""\n\n  def test_without_residuals(self):\n    inputs = tf.constant(np.random.randn(1, 2))\n    state = (tf.constant(np.random.randn(1, 2)),\n             tf.constant(np.random.randn(1, 2)))\n\n    with tf.variable_scope(""root"", initializer=tf.constant_initializer(0.5)):\n      standard_cell = tf.contrib.rnn.MultiRNNCell(\n          [tf.contrib.rnn.GRUCell(2) for _ in range(2)], state_is_tuple=True)\n      res_standard = standard_cell(inputs, state, scope=""standard"")\n\n      test_cell = rnn_cell.ExtendedMultiRNNCell(\n          [tf.contrib.rnn.GRUCell(2) for _ in range(2)])\n      res_test = test_cell(inputs, state, scope=""test"")\n\n    with self.test_session() as sess:\n      sess.run([tf.global_variables_initializer()])\n      res_standard_, res_test_, = sess.run([res_standard, res_test])\n\n    # Make sure it produces the same results as the standard cell\n    self.assertAllClose(res_standard_[0], res_test_[0])\n    self.assertAllClose(res_standard_[1][0], res_test_[1][0])\n    self.assertAllClose(res_standard_[1][1], res_test_[1][1])\n\n  def _test_with_residuals(self, inputs, **kwargs):\n    """"""Runs the cell in a session""""""\n    inputs = tf.convert_to_tensor(inputs)\n    state = (tf.constant(np.random.randn(1, 2)),\n             tf.constant(np.random.randn(1, 2)))\n\n    with tf.variable_scope(""root"", initializer=tf.constant_initializer(0.5)):\n      test_cell = rnn_cell.ExtendedMultiRNNCell(\n          [tf.contrib.rnn.GRUCell(2) for _ in range(2)],\n          residual_connections=True,\n          **kwargs)\n      res_test = test_cell(inputs, state, scope=""test"")\n\n    with self.test_session() as sess:\n      sess.run([tf.global_variables_initializer()])\n      return sess.run(res_test)\n\n  def _test_constant_shape(self, combiner):\n    """"""Tests a residual combiner whose shape doesn\'t change\n    with depth""""""\n    inputs = np.random.randn(1, 2)\n    with tf.variable_scope(""same_input_size""):\n      res_ = self._test_with_residuals(inputs, residual_combiner=combiner)\n      self.assertEqual(res_[0].shape, (1, 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    inputs = np.random.randn(1, 5)\n    with tf.variable_scope(""diff_input_size""):\n      res_ = self._test_with_residuals(inputs, residual_combiner=combiner)\n      self.assertEqual(res_[0].shape, (1, 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    with tf.variable_scope(""same_input_size_dense""):\n      res_ = self._test_with_residuals(\n          inputs, residual_combiner=combiner, residual_dense=True)\n      self.assertEqual(res_[0].shape, (1, 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    inputs = np.random.randn(1, 5)\n    with tf.variable_scope(""diff_input_size_dense""):\n      res_ = self._test_with_residuals(\n          inputs, residual_combiner=combiner, residual_dense=True)\n      self.assertEqual(res_[0].shape, (1, 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n  def test_residuals_mean(self):\n    self._test_constant_shape(combiner=""mean"")\n\n  def test_residuals_add(self):\n    self._test_constant_shape(combiner=""add"")\n\n  def test_residuals_concat(self):\n    inputs = np.random.randn(1, 2)\n    with tf.variable_scope(""same_input_size""):\n      res_ = self._test_with_residuals(inputs, residual_combiner=""concat"")\n      self.assertEqual(res_[0].shape, (1, 6))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    inputs = np.random.randn(1, 5)\n    with tf.variable_scope(""diff_input_size""):\n      res_ = self._test_with_residuals(inputs, residual_combiner=""concat"")\n      self.assertEqual(res_[0].shape, (1, 5 + 2 + 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    inputs = np.random.randn(1, 2)\n    with tf.variable_scope(""same_input_size_dense""):\n      res_ = self._test_with_residuals(\n          inputs, residual_combiner=""concat"", residual_dense=True)\n      self.assertEqual(res_[0].shape, (1, 2 + 4 + 2))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n    inputs = np.random.randn(1, 5)\n    with tf.variable_scope(""diff_input_size_dense""):\n      res_ = self._test_with_residuals(\n          inputs, residual_combiner=""concat"", residual_dense=True)\n      self.assertEqual(res_[0].shape, (1, 2 + (5 + 2) + 5))\n      self.assertEqual(res_[1][0].shape, (1, 2))\n      self.assertEqual(res_[1][1].shape, (1, 2))\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/rnn_encoder_test.py,29,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for RNN encoders.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.encoders import rnn_encoder\n\n\nclass UnidirectionalRNNEncoderTest(tf.test.TestCase):\n  """"""\n  Tests the UnidirectionalRNNEncoder class.\n  """"""\n\n  def setUp(self):\n    super(UnidirectionalRNNEncoderTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.mode = tf.contrib.learn.ModeKeys.TRAIN\n    self.params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n    self.params[""rnn_cell""][""cell_params""][""num_units""] = 32\n    self.params[""rnn_cell""][""cell_class""] = ""BasicLSTMCell""\n\n  def test_encode(self):\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    example_length = tf.ones(\n        self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    encode_fn = rnn_encoder.UnidirectionalRNNEncoder(self.params, self.mode)\n    encoder_output = encode_fn(inputs, example_length)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      encoder_output_ = sess.run(encoder_output)\n\n    np.testing.assert_array_equal(encoder_output_.outputs.shape,\n                                  [self.batch_size, self.sequence_length, 32])\n    self.assertIsInstance(encoder_output_.final_state,\n                          tf.contrib.rnn.LSTMStateTuple)\n    np.testing.assert_array_equal(encoder_output_.final_state.h.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state.c.shape,\n                                  [self.batch_size, 32])\n\n\nclass BidirectionalRNNEncoderTest(tf.test.TestCase):\n  """"""\n  Tests the BidirectionalRNNEncoder class.\n  """"""\n\n  def setUp(self):\n    super(BidirectionalRNNEncoderTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.params = rnn_encoder.BidirectionalRNNEncoder.default_params()\n    self.params[""rnn_cell""][""cell_params""][""num_units""] = 32\n    self.params[""rnn_cell""][""cell_class""] = ""BasicLSTMCell""\n    self.mode = tf.contrib.learn.ModeKeys.TRAIN\n\n  def test_encode(self):\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    example_length = tf.ones(\n        self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    encode_fn = rnn_encoder.BidirectionalRNNEncoder(self.params, self.mode)\n    encoder_output = encode_fn(inputs, example_length)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      encoder_output_ = sess.run(encoder_output)\n\n    np.testing.assert_array_equal(\n        encoder_output_.outputs.shape,\n        [self.batch_size, self.sequence_length, 32 * 2])\n\n    self.assertIsInstance(encoder_output_.final_state[0],\n                          tf.contrib.rnn.LSTMStateTuple)\n    self.assertIsInstance(encoder_output_.final_state[1],\n                          tf.contrib.rnn.LSTMStateTuple)\n    np.testing.assert_array_equal(encoder_output_.final_state[0].h.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[0].c.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[1].h.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[1].c.shape,\n                                  [self.batch_size, 32])\n\n\nclass StackBidirectionalRNNEncoderTest(tf.test.TestCase):\n  """"""\n  Tests the StackBidirectionalRNNEncoder class.\n  """"""\n\n  def setUp(self):\n    super(StackBidirectionalRNNEncoderTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.batch_size = 4\n    self.sequence_length = 16\n    self.input_depth = 10\n    self.mode = tf.contrib.learn.ModeKeys.TRAIN\n\n  def _test_encode_with_params(self, params):\n    """"""Tests the StackBidirectionalRNNEncoder with a specific cell""""""\n    inputs = tf.random_normal(\n        [self.batch_size, self.sequence_length, self.input_depth])\n    example_length = tf.ones(\n        self.batch_size, dtype=tf.int32) * self.sequence_length\n\n    encode_fn = rnn_encoder.StackBidirectionalRNNEncoder(params, self.mode)\n    encoder_output = encode_fn(inputs, example_length)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      encoder_output_ = sess.run(encoder_output)\n\n    output_size = encode_fn.params[""rnn_cell""][""cell_params""][""num_units""]\n\n    np.testing.assert_array_equal(\n        encoder_output_.outputs.shape,\n        [self.batch_size, self.sequence_length, output_size * 2])\n\n    return encoder_output_\n\n  def test_encode_with_single_cell(self):\n    encoder_output_ = self._test_encode_with_params({\n        ""rnn_cell"": {\n            ""num_layers"": 1,\n            ""cell_params"": {\n                ""num_units"": 32\n            }\n        }\n    })\n\n    self.assertIsInstance(encoder_output_.final_state[0][0],\n                          tf.contrib.rnn.LSTMStateTuple)\n    self.assertIsInstance(encoder_output_.final_state[1][0],\n                          tf.contrib.rnn.LSTMStateTuple)\n    np.testing.assert_array_equal(encoder_output_.final_state[0][0].h.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[0][0].c.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[1][0].h.shape,\n                                  [self.batch_size, 32])\n    np.testing.assert_array_equal(encoder_output_.final_state[1][0].c.shape,\n                                  [self.batch_size, 32])\n\n  def test_encode_with_multi_cell(self):\n    encoder_output_ = self._test_encode_with_params({\n        ""rnn_cell"": {\n            ""num_layers"": 4,\n            ""cell_params"": {\n                ""num_units"": 32\n            }\n        }\n    })\n\n    for layer_idx in range(4):\n      self.assertIsInstance(encoder_output_.final_state[0][layer_idx],\n                            tf.contrib.rnn.LSTMStateTuple)\n      self.assertIsInstance(encoder_output_.final_state[1][layer_idx],\n                            tf.contrib.rnn.LSTMStateTuple)\n      np.testing.assert_array_equal(\n          encoder_output_.final_state[0][layer_idx].h.shape,\n          [self.batch_size, 32])\n      np.testing.assert_array_equal(\n          encoder_output_.final_state[0][layer_idx].c.shape,\n          [self.batch_size, 32])\n      np.testing.assert_array_equal(\n          encoder_output_.final_state[1][layer_idx].h.shape,\n          [self.batch_size, 32])\n      np.testing.assert_array_equal(\n          encoder_output_.final_state[1][layer_idx].c.shape,\n          [self.batch_size, 32])\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/test/train_utils_test.py,11,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest Cases for Training utils.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tempfile\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.contrib import rnn_cell\nfrom seq2seq.data import input_pipeline\nfrom seq2seq.test import utils as test_utils\nfrom seq2seq.training import utils as training_utils\n\n\nclass TestGetRNNCell(tf.test.TestCase):\n  """"""Tests the get_rnn_cell function.\n  """"""\n\n  def test_single_layer(self):\n    cell = training_utils.get_rnn_cell(\n        cell_class=""BasicLSTMCell"", cell_params={""num_units"": 16}, num_layers=1)\n    self.assertIsInstance(cell, tf.contrib.rnn.BasicLSTMCell)\n    self.assertEqual(cell.output_size, 16)\n\n  def test_multi_layer(self):\n    cell = training_utils.get_rnn_cell(\n        cell_class=""BasicLSTMCell"", cell_params={""num_units"": 16}, num_layers=2)\n    self.assertIsInstance(cell, rnn_cell.ExtendedMultiRNNCell)\n    self.assertEqual(cell.output_size, 16)\n\n  def test_full_class_path(self):\n    cell = training_utils.get_rnn_cell(\n        cell_class=""tensorflow.contrib.rnn.BasicRNNCell"",\n        cell_params={""num_units"": 16},\n        num_layers=1)\n    self.assertIsInstance(cell, tf.contrib.rnn.BasicRNNCell)\n    self.assertEqual(cell.output_size, 16)\n\n  def test_dropout(self):\n    cell = training_utils.get_rnn_cell(\n        cell_class=""BasicLSTMCell"",\n        cell_params={""num_units"": 16},\n        num_layers=1,\n        dropout_input_keep_prob=0.5)\n    self.assertIsInstance(cell, tf.contrib.rnn.DropoutWrapper)\n    self.assertEqual(cell.output_size, 16)\n\n  def test_extra_args(self):\n    # Invalid args should raise a ValueError\n    with self.assertRaises(ValueError):\n      training_utils.get_rnn_cell(\n          cell_class=""LSTMCell"",\n          cell_params={""num_units"": 16,\n                       ""use_peepholesERROR"": True},\n          num_layers=1)\n\n    cell = training_utils.get_rnn_cell(\n        cell_class=""LSTMCell"",\n        cell_params={""num_units"": 8,\n                     ""use_peepholes"": True,\n                     ""forget_bias"": 0.5},\n        num_layers=1)\n    self.assertIsInstance(cell, tf.contrib.rnn.LSTMCell)\n    #pylint: disable=E1101,W0212\n    self.assertEqual(cell._use_peepholes, True)\n    self.assertEqual(cell._forget_bias, 0.5)\n    self.assertEqual(cell.output_size, 8)\n\n\nclass TestTrainOptions(tf.test.TestCase):\n  """"""Tests reading and writing of training options""""""\n\n  def setUp(self):\n    super(TestTrainOptions, self).setUp()\n    self.model_dir = tempfile.mkdtemp()\n    self.model_params = {""num_layers"": 4}\n    self.model_class = ""AttentionSeq2Seq""\n\n  def test_read_write(self):\n    saved_opts = training_utils.TrainOptions(\n        model_class=self.model_class, model_params=self.model_params)\n    saved_opts.dump(self.model_dir)\n\n    loaded_opt = training_utils.TrainOptions.load(model_dir=self.model_dir)\n\n    self.assertEqual(saved_opts.model_params, loaded_opt.model_params)\n    self.assertEqual(saved_opts.model_class, loaded_opt.model_class)\n\n\nclass TestInputFn(tf.test.TestCase):\n  """"""Tests create_input_fn""""""\n\n  def _test_with_args(self, **kwargs):\n    """"""Helper function to test create_input_fn with keyword arguments""""""\n    sources_file, targets_file = test_utils.create_temp_parallel_data(\n        sources=[""Hello World .""], targets=[""Goodbye .""])\n\n    pipeline = input_pipeline.ParallelTextInputPipeline(\n        params={\n            ""source_files"": [sources_file.name],\n            ""target_files"": [targets_file.name]\n        },\n        mode=tf.contrib.learn.ModeKeys.TRAIN)\n    input_fn = training_utils.create_input_fn(pipeline=pipeline, **kwargs)\n    features, labels = input_fn()\n\n    with self.test_session() as sess:\n      with tf.contrib.slim.queues.QueueRunners(sess):\n        features_, labels_ = sess.run([features, labels])\n\n    self.assertEqual(\n        set(features_.keys()), set([""source_tokens"", ""source_len""]))\n    self.assertEqual(set(labels_.keys()), set([""target_tokens"", ""target_len""]))\n\n  def test_without_buckets(self):\n    self._test_with_args(batch_size=10)\n\n  def test_wit_buckets(self):\n    self._test_with_args(batch_size=10, bucket_boundaries=[0, 5, 10])\n\n\nclass TestLRDecay(tf.test.TestCase):\n  """"""Tests learning rate decay function.\n  """"""\n\n  def test_no_decay(self):\n    decay_fn = training_utils.create_learning_rate_decay_fn(\n        decay_type=None, decay_steps=5, decay_rate=2.0)\n    self.assertEqual(decay_fn, None)\n\n    decay_fn = training_utils.create_learning_rate_decay_fn(\n        decay_type="""", decay_steps=5, decay_rate=2.0)\n    self.assertEqual(decay_fn, None)\n\n  def test_decay_without_min(self):\n    decay_fn = training_utils.create_learning_rate_decay_fn(\n        decay_type=""exponential_decay"",\n        decay_steps=10,\n        decay_rate=0.9,\n        start_decay_at=100,\n        stop_decay_at=1000,\n        staircase=False)\n\n    initial_lr = 1.0\n    with self.test_session() as sess:\n      # Should not decay before start_decay_at\n      np.testing.assert_equal(sess.run(decay_fn(initial_lr, 50)), initial_lr)\n      # Proper decay\n      np.testing.assert_almost_equal(\n          sess.run(decay_fn(initial_lr, 115)), initial_lr * 0.9**(15.0 / 10.0))\n      # Should not decay past stop_decay_at\n      np.testing.assert_almost_equal(\n          sess.run(decay_fn(initial_lr, 5000)), initial_lr * 0.9**(\n              (1000.0 - 100.0) / 10.0))\n\n  def test_decay_with_min(self):\n    decay_fn = training_utils.create_learning_rate_decay_fn(\n        decay_type=""exponential_decay"",\n        decay_steps=10,\n        decay_rate=0.9,\n        start_decay_at=100,\n        stop_decay_at=1000.0,\n        min_learning_rate=0.01,\n        staircase=False)\n\n    initial_lr = 1.0\n    with self.test_session() as sess:\n      # Should not decay past min_learning_rate\n      np.testing.assert_almost_equal(sess.run(decay_fn(initial_lr, 900)), 0.01)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
seq2seq/test/utils.py,2,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Various testing utilities\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tempfile\nimport tensorflow as tf\n\n\ndef create_temp_parallel_data(sources, targets):\n  """"""\n  Creates a temporary TFRecords file.\n\n  Args:\n    source: List of source sentences\n    target: List of target sentences\n\n  Returns:\n    A tuple (sources_file, targets_file).\n  """"""\n  file_source = tempfile.NamedTemporaryFile()\n  file_target = tempfile.NamedTemporaryFile()\n  file_source.write(""\\n"".join(sources).encode(""utf-8""))\n  file_source.flush()\n  file_target.write(""\\n"".join(targets).encode(""utf-8""))\n  file_target.flush()\n  return file_source, file_target\n\n\ndef create_temp_tfrecords(sources, targets):\n  """"""\n  Creates a temporary TFRecords file.\n\n  Args:\n    source: List of source sentences\n    target: List of target sentences\n\n  Returns:\n    A tuple (sources_file, targets_file).\n  """"""\n\n  output_file = tempfile.NamedTemporaryFile()\n  writer = tf.python_io.TFRecordWriter(output_file.name)\n  for source, target in zip(sources, targets):\n    ex = tf.train.Example()\n    #pylint: disable=E1101\n    ex.features.feature[""source""].bytes_list.value.extend(\n        [source.encode(""utf-8"")])\n    ex.features.feature[""target""].bytes_list.value.extend(\n        [target.encode(""utf-8"")])\n    writer.write(ex.SerializeToString())\n  writer.close()\n\n  return output_file\n\n\ndef create_temporary_vocab_file(words, counts=None):\n  """"""\n  Creates a temporary vocabulary file.\n\n  Args:\n    words: List of words in the vocabulary\n\n  Returns:\n    A temporary file object with one word per line\n  """"""\n  vocab_file = tempfile.NamedTemporaryFile()\n  if counts is None:\n    for token in words:\n      vocab_file.write((token + ""\\n"").encode(""utf-8""))\n  else:\n    for token, count in zip(words, counts):\n      vocab_file.write(""{}\\t{}\\n"".format(token, count).encode(""utf-8""))\n  vocab_file.flush()\n  return vocab_file\n'"
seq2seq/test/vocab_test.py,17,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for input-related operations.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom seq2seq.data import vocab\nfrom seq2seq.test import utils as test_utils\n\n\nclass VocabInfoTest(tf.test.TestCase):\n  """"""Tests VocabInfo class""""""\n\n  def setUp(self):\n    super(VocabInfoTest, self).setUp()\n    tf.logging.set_verbosity(tf.logging.INFO)\n    self.vocab_list = [""Hello"", ""."", ""Bye""]\n    self.vocab_file = test_utils.create_temporary_vocab_file(self.vocab_list)\n\n  def tearDown(self):\n    super(VocabInfoTest, self).tearDown()\n    self.vocab_file.close()\n\n  def test_vocab_info(self):\n    vocab_info = vocab.get_vocab_info(self.vocab_file.name)\n    self.assertEqual(vocab_info.vocab_size, 3)\n    self.assertEqual(vocab_info.path, self.vocab_file.name)\n    self.assertEqual(vocab_info.special_vocab.UNK, 3)\n    self.assertEqual(vocab_info.special_vocab.SEQUENCE_START, 4)\n    self.assertEqual(vocab_info.special_vocab.SEQUENCE_END, 5)\n    self.assertEqual(vocab_info.total_size, 6)\n\n\nclass CreateVocabularyLookupTableTest(tf.test.TestCase):\n  """"""\n  Tests Vocabulary lookup table operations.\n  """"""\n\n  def test_without_counts(self):\n    vocab_list = [""Hello"", ""."", ""\xe7\xac\x91""]\n    vocab_file = test_utils.create_temporary_vocab_file(vocab_list)\n\n    vocab_to_id_table, id_to_vocab_table, _, vocab_size = \\\n      vocab.create_vocabulary_lookup_table(vocab_file.name)\n\n    self.assertEqual(vocab_size, 6)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      sess.run(tf.tables_initializer())\n\n      ids = vocab_to_id_table.lookup(\n          tf.convert_to_tensor([""Hello"", ""."", ""\xe7\xac\x91"", ""??"", ""xxx""]))\n      ids = sess.run(ids)\n      np.testing.assert_array_equal(ids, [0, 1, 2, 3, 3])\n\n      words = id_to_vocab_table.lookup(\n          tf.convert_to_tensor(\n              [0, 1, 2, 3], dtype=tf.int64))\n      words = sess.run(words)\n      np.testing.assert_array_equal(\n          np.char.decode(words.astype(""S""), ""utf-8""),\n          [""Hello"", ""."", ""\xe7\xac\x91"", ""UNK""])\n\n  def test_with_counts(self):\n    vocab_list = [""Hello"", ""."", ""\xe7\xac\x91""]\n    vocab_counts = [100, 200, 300]\n    vocab_file = test_utils.create_temporary_vocab_file(vocab_list,\n                                                        vocab_counts)\n\n    vocab_to_id_table, id_to_vocab_table, word_to_count_table, vocab_size = \\\n      vocab.create_vocabulary_lookup_table(vocab_file.name)\n\n    self.assertEqual(vocab_size, 6)\n\n    with self.test_session() as sess:\n      sess.run(tf.global_variables_initializer())\n      sess.run(tf.local_variables_initializer())\n      sess.run(tf.tables_initializer())\n\n      ids = vocab_to_id_table.lookup(\n          tf.convert_to_tensor([""Hello"", ""."", ""\xe7\xac\x91"", ""??"", ""xxx""]))\n      ids = sess.run(ids)\n      np.testing.assert_array_equal(ids, [0, 1, 2, 3, 3])\n\n      words = id_to_vocab_table.lookup(\n          tf.convert_to_tensor(\n              [0, 1, 2, 3], dtype=tf.int64))\n      words = sess.run(words)\n      np.testing.assert_array_equal(\n          np.char.decode(words.astype(""S""), ""utf-8""),\n          [""Hello"", ""."", ""\xe7\xac\x91"", ""UNK""])\n\n      counts = word_to_count_table.lookup(\n          tf.convert_to_tensor([""Hello"", ""."", ""\xe7\xac\x91"", ""??"", ""xxx""]))\n      counts = sess.run(counts)\n      np.testing.assert_array_equal(counts, [100, 200, 300, -1, -1])\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
seq2seq/training/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Operatations and wrappers to help with model training.\n""""""\n\nfrom seq2seq.training import hooks\nfrom seq2seq.training import utils\n'"
seq2seq/training/hooks.py,31,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n"""""" Collection of tf.train.SessionRunHooks\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport abc\nimport os\n\nimport numpy as np\nimport six\nimport yaml\n\n\nimport tensorflow as tf\nfrom tensorflow.python.training.basic_session_run_hooks import SecondOrStepTimer  # pylint: disable=E0611\nfrom tensorflow.python.training import session_manager # pylint: disable=E0611\nfrom tensorflow.python.client import timeline  # pylint: disable=E0611\nfrom tensorflow import gfile\n\nfrom seq2seq.configurable import Configurable, abstractstaticmethod\nfrom seq2seq import graph_utils, global_vars\n\nFLAGS = tf.flags.FLAGS\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass TrainingHook(tf.train.SessionRunHook, Configurable):\n  """"""Abstract base class for training hooks.\n  """"""\n\n  def __init__(self, params, model_dir, run_config):\n    tf.train.SessionRunHook.__init__(self)\n    Configurable.__init__(self, params, tf.contrib.learn.ModeKeys.TRAIN)\n    self._model_dir = model_dir\n    self._run_config = run_config\n\n  @property\n  def model_dir(self):\n    """"""Returns the directory model checkpoints are written to.\n    """"""\n    return os.path.abspath(self._model_dir)\n\n  @property\n  def is_chief(self):\n    """"""Returns true if and only if the current process is the chief.\n    This is used for distributed training.\n    """"""\n    return self._run_config.is_chief\n\n  @abstractstaticmethod\n  def default_params():\n    raise NotImplementedError()\n\n\nclass MetadataCaptureHook(TrainingHook):\n  """"""A hook to capture metadata for a single step.\n  Useful for performance debugging. It performs a full trace and saves\n  run_metadata and Chrome timeline information to a file.\n\n  Args:\n    step: The step number to trace. The hook is only enable for this step.\n  """"""\n\n  def __init__(self, params, model_dir, run_config):\n    super(MetadataCaptureHook, self).__init__(params, model_dir, run_config)\n    self._active = False\n    self._done = False\n    self._global_step = None\n    self._output_dir = os.path.abspath(self.model_dir)\n\n  @staticmethod\n  def default_params():\n    return {""step"": 10}\n\n  def begin(self):\n    self._global_step = tf.train.get_global_step()\n\n  def before_run(self, _run_context):\n    if not self.is_chief or self._done:\n      return\n    if not self._active:\n      return tf.train.SessionRunArgs(self._global_step)\n    else:\n      tf.logging.info(""Performing full trace on next step."")\n      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) #pylint: disable=E1101\n      return tf.train.SessionRunArgs(self._global_step, options=run_options)\n\n  def after_run(self, _run_context, run_values):\n    if not self.is_chief or self._done:\n      return\n\n    step_done = run_values.results\n    if self._active:\n      tf.logging.info(""Captured full trace at step %s"", step_done)\n      # Create output directory\n      gfile.MakeDirs(self._output_dir)\n\n      # Save run metadata\n      trace_path = os.path.join(self._output_dir, ""run_meta"")\n      with gfile.GFile(trace_path, ""wb"") as trace_file:\n        trace_file.write(run_values.run_metadata.SerializeToString())\n        tf.logging.info(""Saved run_metadata to %s"", trace_path)\n\n      # Save timeline\n      timeline_path = os.path.join(self._output_dir, ""timeline.json"")\n      with gfile.GFile(timeline_path, ""w"") as timeline_file:\n        tl_info = timeline.Timeline(run_values.run_metadata.step_stats)\n        tl_chrome = tl_info.generate_chrome_trace_format(show_memory=True)\n        timeline_file.write(tl_chrome)\n        tf.logging.info(""Saved timeline to %s"", timeline_path)\n\n      # Save tfprof op log\n      tf.contrib.tfprof.tfprof_logger.write_op_log(\n          graph=tf.get_default_graph(),\n          log_dir=self._output_dir,\n          run_meta=run_values.run_metadata)\n      tf.logging.info(""Saved op log to %s"", self._output_dir)\n      self._active = False\n      self._done = True\n\n    self._active = (step_done >= self.params[""step""])\n\n\nclass TrainSampleHook(TrainingHook):\n  """"""Occasionally samples predictions from the training run and prints them.\n\n  Params:\n    every_n_secs: Sample predictions every N seconds.\n      If set, `every_n_steps` must be None.\n    every_n_steps: Sample predictions every N steps.\n      If set, `every_n_secs` must be None.\n    sample_dir: Optional, a directory to write samples to.\n    delimiter: Join tokens on this delimiter. Defaults to space.\n  """"""\n\n  #pylint: disable=missing-docstring\n\n  def __init__(self, params, model_dir, run_config):\n    super(TrainSampleHook, self).__init__(params, model_dir, run_config)\n    self._sample_dir = os.path.join(self.model_dir, ""samples"")\n    self._timer = SecondOrStepTimer(\n        every_secs=self.params[""every_n_secs""],\n        every_steps=self.params[""every_n_steps""])\n    self._pred_dict = {}\n    self._should_trigger = False\n    self._iter_count = 0\n    self._global_step = None\n    self._source_delimiter = self.params[""source_delimiter""]\n    self._target_delimiter = self.params[""target_delimiter""]\n\n  @staticmethod\n  def default_params():\n    return {\n        ""every_n_secs"": None,\n        ""every_n_steps"": 1000,\n        ""source_delimiter"": "" "",\n        ""target_delimiter"": "" ""\n    }\n\n  def begin(self):\n    self._iter_count = 0\n    self._global_step = tf.train.get_global_step()\n    self._pred_dict = graph_utils.get_dict_from_collection(""predictions"")\n    # Create the sample directory\n    if self._sample_dir is not None:\n      gfile.MakeDirs(self._sample_dir)\n\n  def before_run(self, _run_context):\n    self._should_trigger = self._timer.should_trigger_for_step(self._iter_count)\n    if self._should_trigger:\n      fetches = {\n          ""predicted_tokens"": self._pred_dict[""predicted_tokens""],\n          ""target_words"": self._pred_dict[""labels.target_tokens""],\n          ""target_len"": self._pred_dict[""labels.target_len""]\n      }\n      return tf.train.SessionRunArgs([fetches, self._global_step])\n    return tf.train.SessionRunArgs([{}, self._global_step])\n\n  def after_run(self, _run_context, run_values):\n    result_dict, step = run_values.results\n    self._iter_count = step\n\n    if not self._should_trigger:\n      return None\n\n    # Convert dict of lists to list of dicts\n    result_dicts = [\n        dict(zip(result_dict, t)) for t in zip(*result_dict.values())\n    ]\n\n    # Print results\n    result_str = """"\n    result_str += ""Prediction followed by Target @ Step {}\\n"".format(step)\n    result_str += (""="" * 100) + ""\\n""\n    for result in result_dicts:\n      target_len = result[""target_len""]\n      predicted_slice = result[""predicted_tokens""][:target_len - 1]\n      target_slice = result[""target_words""][1:target_len]\n      result_str += self._target_delimiter.encode(""utf-8"").join(\n          predicted_slice).decode(""utf-8"") + ""\\n""\n      result_str += self._target_delimiter.encode(""utf-8"").join(\n          target_slice).decode(""utf-8"") + ""\\n\\n""\n    result_str += (""="" * 100) + ""\\n\\n""\n    tf.logging.info(result_str)\n    if self._sample_dir:\n      filepath = os.path.join(self._sample_dir,\n                              ""samples_{:06d}.txt"".format(step))\n      with gfile.GFile(filepath, ""w"") as file:\n        file.write(result_str)\n    self._timer.update_last_triggered_step(self._iter_count - 1)\n\n\nclass PrintModelAnalysisHook(TrainingHook):\n  """"""Writes the parameters of the model to a file and stdout.\n  """"""\n\n  #pylint: disable=missing-docstring\n  def __init__(self, params, model_dir, run_config):\n    super(PrintModelAnalysisHook, self).__init__(params, model_dir, run_config)\n    self._filename = os.path.join(self.model_dir, ""model_analysis.txt"")\n\n  @staticmethod\n  def default_params():\n    return {}\n\n  def begin(self):\n    # Dump to file on the chief worker\n    if self.is_chief:\n      opts = tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS\n      opts[\'dump_to_file\'] = os.path.abspath(self._filename)\n      tf.contrib.tfprof.model_analyzer.print_model_analysis(\n          tf.get_default_graph(), tfprof_options=opts)\n\n    # Print the model analysis\n    with gfile.GFile(self._filename) as file:\n      tf.logging.info(file.read())\n\n\nclass VariableRestoreHook(TrainingHook):\n  """"""A hooks that restored variables from a given checkpoints.\n\n  Params:\n    prefix: Variables matching this prefix are restored.\n    checkpoint_path: Path to the checkpoint to restore variables from.\n  """"""\n\n  def __init__(self, params, model_dir, run_config):\n    super(VariableRestoreHook, self).__init__(params, model_dir, run_config)\n    self._saver = None\n\n  @staticmethod\n  def default_params():\n    return {""prefix"": """", ""checkpoint_path"": """"}\n\n  def begin(self):\n    variables = tf.contrib.framework.get_variables(scope=self.params[""prefix""])\n\n    def varname_in_checkpoint(name):\n      """"""Removes the prefix from the variable name.\n      """"""\n      prefix_parts = self.params[""prefix""].split(""/"")\n      checkpoint_prefix = ""/"".join(prefix_parts[:-1])\n      return name.replace(checkpoint_prefix + ""/"", """")\n\n    target_names = [varname_in_checkpoint(_.op.name) for _ in variables]\n    restore_map = {k: v for k, v in zip(target_names, variables)}\n\n    tf.logging.info(""Restoring variables: \\n%s"",\n                    yaml.dump({k: v.op.name\n                               for k, v in restore_map.items()}))\n\n    self._saver = tf.train.Saver(restore_map)\n\n  def after_create_session(self, session, coord):\n    self._saver.restore(session, self.params[""checkpoint_path""])\n    tf.logging.info(""Successfully restored all variables"")\n\n\nclass DelayStartHook(TrainingHook, tf.train.GlobalStepWaiterHook):\n  """"""Delays the start of the current worker process until global step\n  K * task_id is reached. K is a parameter.\n  """"""\n  def __init__(self, params, model_dir, run_config):\n    TrainingHook.__init__(self, params, model_dir, run_config)\n    self._task_id = self._run_config.task_id\n    self._delay_k = self.params[""delay_k""]\n    self._wait_until_step = int(self._delay_k * self._task_id)\n    tf.train.GlobalStepWaiterHook.__init__(self, self._wait_until_step)\n\n  @staticmethod\n  def default_params():\n    return {""delay_k"": 500}\n\n\nclass SyncReplicasOptimizerHook(TrainingHook):\n  """"""A SessionRunHook handles ops related to SyncReplicasOptimizer.""""""\n\n  def __init__(self, params, model_dir, run_config):\n    super(SyncReplicasOptimizerHook, self).__init__(\n        params, model_dir, run_config)\n    self._sync_optimizer = None\n    self._num_tokens = -1\n\n    self._local_init_op = None\n    self._ready_for_local_init_op = None\n    self._q_runner = None\n    self._init_tokens_op = None\n\n  @staticmethod\n  def default_params():\n    return {}\n\n  def begin(self):\n    if global_vars.SYNC_REPLICAS_OPTIMIZER is not None:\n      self._sync_optimizer = global_vars.SYNC_REPLICAS_OPTIMIZER\n    else:\n      return\n\n    if self._sync_optimizer._gradients_applied is False:  # pylint: disable=protected-access\n      raise ValueError(\n          ""SyncReplicasOptimizer.apply_gradient should be called before using ""\n          ""the hook."")\n    if self.is_chief:\n      self._local_init_op = self._sync_optimizer.chief_init_op\n      self._ready_for_local_init_op = (\n          self._sync_optimizer.ready_for_local_init_op)\n      self._q_runner = self._sync_optimizer.get_chief_queue_runner()\n      self._init_tokens_op = self._sync_optimizer.get_init_tokens_op(\n          self._num_tokens)\n    else:\n      self._local_init_op = self._sync_optimizer.local_step_init_op\n      self._ready_for_local_init_op = (\n          self._sync_optimizer.ready_for_local_init_op)\n      self._q_runner = None\n      self._init_tokens_op = None\n\n  def after_create_session(self, session, coord):\n    """"""Runs SyncReplicasOptimizer initialization ops.""""""\n\n    if not self._sync_optimizer:\n      return\n\n    tf.logging.info(""Found SyncReplicasOptimizer. Initializing."")\n\n    local_init_success, msg = session_manager._ready(  # pylint: disable=protected-access\n        self._ready_for_local_init_op, session,\n        ""Model is not ready for SyncReplicasOptimizer local init."")\n    if not local_init_success:\n      raise RuntimeError(\n          ""Init operations did not make model ready for SyncReplicasOptimizer ""\n          ""local_init. Init op: %s, error: %s"" %\n          (self._local_init_op.name, msg))\n    session.run(self._local_init_op)\n    if self._init_tokens_op is not None:\n      session.run(self._init_tokens_op)\n    if self._q_runner is not None:\n      self._q_runner.create_threads(\n          session, coord=coord, daemon=True, start=True)\n'"
seq2seq/training/utils.py,15,"b'# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Miscellaneous training utility functions.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport inspect\nimport os\nfrom collections import defaultdict\nfrom pydoc import locate\n\nimport json\n\nimport tensorflow as tf\nfrom tensorflow import gfile\n\nfrom seq2seq.contrib import rnn_cell\n\n\nclass TrainOptions(object):\n  """"""A collection of options that are passed to the training script\n  and can be saved to perform inference later.\n\n  Args:\n    task: Name of the training task class.\n    task_params: A dictionary of parameters passed to the training task.\n  """"""\n\n  def __init__(self, model_class, model_params):\n    self._model_class = model_class\n    self._model_params = model_params\n\n  @property\n  def model_class(self):\n    """"""Returns the training task parameters""""""\n    return self._model_class\n\n  @property\n  def model_params(self):\n    """"""Returns the training task class""""""\n    return self._model_params\n\n  @staticmethod\n  def path(model_dir):\n    """"""Returns the path to the options file.\n\n    Args:\n      model_dir: The model directory\n    """"""\n    return os.path.join(model_dir, ""train_options.json"")\n\n  def dump(self, model_dir):\n    """"""Dumps the options to a file in the model directory.\n\n    Args:\n      model_dir: Path to the model directory. The options will be\n      dumped into a file in this directory.\n    """"""\n    gfile.MakeDirs(model_dir)\n    options_dict = {\n        ""model_class"": self.model_class,\n        ""model_params"": self.model_params,\n    }\n\n    with gfile.GFile(TrainOptions.path(model_dir), ""wb"") as file:\n      file.write(json.dumps(options_dict).encode(""utf-8""))\n\n  @staticmethod\n  def load(model_dir):\n    """""" Loads options from the given model directory.\n\n    Args:\n      model_dir: Path to the model directory.\n    """"""\n    with gfile.GFile(TrainOptions.path(model_dir), ""rb"") as file:\n      options_dict = json.loads(file.read().decode(""utf-8""))\n    options_dict = defaultdict(None, options_dict)\n\n    return TrainOptions(\n        model_class=options_dict[""model_class""],\n        model_params=options_dict[""model_params""])\n\n\ndef cell_from_spec(cell_classname, cell_params):\n  """"""Create a RNN Cell instance from a JSON string.\n\n  Args:\n    cell_classname: Name of the cell class, e.g. ""BasicLSTMCell"".\n    cell_params: A dictionary of parameters to pass to the cell constructor.\n\n  Returns:\n    A RNNCell instance.\n  """"""\n\n  cell_params = cell_params.copy()\n\n  # Find the cell class\n  cell_class = locate(cell_classname) or getattr(rnn_cell, cell_classname)\n\n  # Make sure additional arguments are valid\n  cell_args = set(inspect.getargspec(cell_class.__init__).args[1:])\n  for key in cell_params.keys():\n    if key not in cell_args:\n      raise ValueError(\n          """"""{} is not a valid argument for {} class. Available arguments\n          are: {}"""""".format(key, cell_class.__name__, cell_args))\n\n  # Create cell\n  return cell_class(**cell_params)\n\n\ndef get_rnn_cell(cell_class,\n                 cell_params,\n                 num_layers=1,\n                 dropout_input_keep_prob=1.0,\n                 dropout_output_keep_prob=1.0,\n                 residual_connections=False,\n                 residual_combiner=""add"",\n                 residual_dense=False):\n  """"""Creates a new RNN Cell\n\n  Args:\n    cell_class: Name of the cell class, e.g. ""BasicLSTMCell"".\n    cell_params: A dictionary of parameters to pass to the cell constructor.\n    num_layers: Number of layers. The cell will be wrapped with\n      `tf.contrib.rnn.MultiRNNCell`\n    dropout_input_keep_prob: Dropout keep probability applied\n      to the input of cell *at each layer*\n    dropout_output_keep_prob: Dropout keep probability applied\n      to the output of cell *at each layer*\n    residual_connections: If true, add residual connections\n      between all cells\n\n  Returns:\n    An instance of `tf.contrib.rnn.RNNCell`.\n  """"""\n\n  cells = []\n  for _ in range(num_layers):\n    cell = cell_from_spec(cell_class, cell_params)\n    if dropout_input_keep_prob < 1.0 or dropout_output_keep_prob < 1.0:\n      cell = tf.contrib.rnn.DropoutWrapper(\n          cell=cell,\n          input_keep_prob=dropout_input_keep_prob,\n          output_keep_prob=dropout_output_keep_prob)\n    cells.append(cell)\n\n  if len(cells) > 1:\n    final_cell = rnn_cell.ExtendedMultiRNNCell(\n        cells=cells,\n        residual_connections=residual_connections,\n        residual_combiner=residual_combiner,\n        residual_dense=residual_dense)\n  else:\n    final_cell = cells[0]\n\n  return final_cell\n\n\ndef create_learning_rate_decay_fn(decay_type,\n                                  decay_steps,\n                                  decay_rate,\n                                  start_decay_at=0,\n                                  stop_decay_at=1e9,\n                                  min_learning_rate=None,\n                                  staircase=False):\n  """"""Creates a function that decays the learning rate.\n\n  Args:\n    decay_steps: How often to apply decay.\n    decay_rate: A Python number. The decay rate.\n    start_decay_at: Don\'t decay before this step\n    stop_decay_at: Don\'t decay after this step\n    min_learning_rate: Don\'t decay below this number\n    decay_type: A decay function name defined in `tf.train`\n    staircase: Whether to apply decay in a discrete staircase,\n      as opposed to continuous, fashion.\n\n  Returns:\n    A function that takes (learning_rate, global_step) as inputs\n    and returns the learning rate for the given step.\n    Returns `None` if decay_type is empty or None.\n  """"""\n  if decay_type is None or decay_type == """":\n    return None\n\n  start_decay_at = tf.to_int32(start_decay_at)\n  stop_decay_at = tf.to_int32(stop_decay_at)\n\n  def decay_fn(learning_rate, global_step):\n    """"""The computed learning rate decay function.\n    """"""\n    global_step = tf.to_int32(global_step)\n\n    decay_type_fn = getattr(tf.train, decay_type)\n    decayed_learning_rate = decay_type_fn(\n        learning_rate=learning_rate,\n        global_step=tf.minimum(global_step, stop_decay_at) - start_decay_at,\n        decay_steps=decay_steps,\n        decay_rate=decay_rate,\n        staircase=staircase,\n        name=""decayed_learning_rate"")\n\n    final_lr = tf.train.piecewise_constant(\n        x=global_step,\n        boundaries=[start_decay_at],\n        values=[learning_rate, decayed_learning_rate])\n\n    if min_learning_rate:\n      final_lr = tf.maximum(final_lr, min_learning_rate)\n\n    return final_lr\n\n  return decay_fn\n\n\ndef create_input_fn(pipeline,\n                    batch_size,\n                    bucket_boundaries=None,\n                    allow_smaller_final_batch=False,\n                    scope=None):\n  """"""Creates an input function that can be used with tf.learn estimators.\n    Note that you must pass ""factory funcitons"" for both the data provider and\n    featurizer to ensure that everything will be created in  the same graph.\n\n  Args:\n    pipeline: An instance of `seq2seq.data.InputPipeline`.\n    batch_size: Create batches of this size. A queue to hold a\n      reasonable number of batches in memory is created.\n    bucket_boundaries: int list, increasing non-negative numbers.\n      If None, no bucket is performed.\n\n  Returns:\n    An input function that returns `(feature_batch, labels_batch)`\n    tuples when called.\n  """"""\n\n  def input_fn():\n    """"""Creates features and labels.\n    """"""\n\n    with tf.variable_scope(scope or ""input_fn""):\n      data_provider = pipeline.make_data_provider()\n      features_and_labels = pipeline.read_from_data_provider(data_provider)\n\n      if bucket_boundaries:\n        _, batch = tf.contrib.training.bucket_by_sequence_length(\n            input_length=features_and_labels[""source_len""],\n            bucket_boundaries=bucket_boundaries,\n            tensors=features_and_labels,\n            batch_size=batch_size,\n            keep_input=features_and_labels[""source_len""] >= 1,\n            dynamic_pad=True,\n            capacity=5000 + 16 * batch_size,\n            allow_smaller_final_batch=allow_smaller_final_batch,\n            name=""bucket_queue"")\n      else:\n        batch = tf.train.batch(\n            tensors=features_and_labels,\n            enqueue_many=False,\n            batch_size=batch_size,\n            dynamic_pad=True,\n            capacity=5000 + 16 * batch_size,\n            allow_smaller_final_batch=allow_smaller_final_batch,\n            name=""batch_queue"")\n\n      # Separate features and labels\n      features_batch = {k: batch[k] for k in pipeline.feature_keys}\n      if set(batch.keys()).intersection(pipeline.label_keys):\n        labels_batch = {k: batch[k] for k in pipeline.label_keys}\n      else:\n        labels_batch = None\n\n      return features_batch, labels_batch\n\n  return input_fn\n'"
bin/data/cnn_daily_mail_summarization/process_story.py,0,"b'#! /usr/bin/env python\n\n# -*- coding: utf-8 -*-\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n""""""\nProcesses a CNN/Daily Mail story file into a format that can\nbe used for summarization.\n""""""\n\nimport fileinput\nimport re\n\ndef process_story(text):\n  """"""Processed a story text into an (article, summary) tuple.\n  """"""\n  # Split by highlights\n  elements = text.split(""@highlight"")\n  elements = [_.strip() for _ in elements]\n\n  story_text = elements[0]\n  highlights = elements[1:]\n\n  # Join all highlights into a single blob\n  highlights_joined = ""; "".join(highlights)\n  highlights_joined = re.sub(r""\\s+"", "" "", highlights_joined)\n  highlights_joined = highlights_joined.strip()\n\n  # Remove newlines from story\n  # story_text = story_text.replace(""\\n"", "" "")\n  story_text = re.sub(r""\\s+"", "" "", story_text)\n  story_text = story_text.strip()\n\n  return story_text, highlights_joined\n\ndef main(*args, **kwargs):\n  """"""Program entry point""""""\n  story_text = ""\\n"".join(list(fileinput.input()))\n  story, highlights = process_story(story_text)\n\n  if story and highlights:\n    print(""{}\\t{}"".format(story, highlights))\n\nif __name__ == \'__main__\':\n  main()\n'"
seq2seq/contrib/seq2seq/__init__.py,0,"b'# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n'"
seq2seq/contrib/seq2seq/decoder.py,2,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""\nIMPORTANT: This code is taken directly from Tensorflow\n(https://github.com/tensorflow/tensorflow) and is copied temporarily\nuntil it is available in a packaged Tensorflow version on pypi.\n\nTODO(dennybritz): Delete this code when it becomes available in TF.\n\nSeq2seq layer operations for use in neural networks.\n""""""\n\n# pylint: skip-file\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\n\nimport six\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import tensor_array_ops\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.util import nest\n\n__all__ = [""Decoder"", ""dynamic_decode""]\n\n\ndef _transpose_batch_time(x):\n  """"""Transpose the batch and time dimensions of a Tensor.\n\n  Retains as much of the static shape information as possible.\n\n  Args:\n    x: A tensor of rank 2 or higher.\n\n  Returns:\n    x transposed along the first two dimensions.\n\n  Raises:\n    ValueError: if `x` is rank 1 or lower.\n  """"""\n  x_static_shape = x.get_shape()\n  if x_static_shape.ndims is not None and x_static_shape.ndims < 2:\n    raise ValueError(\n        ""Expected input tensor %s to have rank at least 2, but saw shape: %s"" %\n        (x, x_static_shape))\n  x_rank = array_ops.rank(x)\n  x_t = array_ops.transpose(\n      x, array_ops.concat(\n          ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  x_t.set_shape(\n      tensor_shape.TensorShape([\n          x_static_shape[1].value, x_static_shape[0].value\n      ]).concatenate(x_static_shape[2:]))\n  return x_t\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Decoder(object):\n  """"""An RNN Decoder abstract interface object.""""""\n\n  @property\n  def batch_size(self):\n    """"""The batch size of the inputs returned by `sample`.""""""\n    raise NotImplementedError\n\n  @property\n  def output_size(self):\n    """"""A (possibly nested tuple of...) integer[s] or `TensorShape` object[s].""""""\n    raise NotImplementedError\n\n  @property\n  def output_dtype(self):\n    """"""A (possibly nested tuple of...) dtype[s].""""""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def initialize(self, name=None):\n    """"""Called before any decoding iterations.\n\n    Args:\n      name: Name scope for any created operations.\n\n    Returns:\n      `(finished, first_inputs, initial_state)`.\n    """"""\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def step(self, time, inputs, state, name=None):\n    """"""Called per step of decoding (but only once for dynamic decoding).\n\n    Args:\n      time: Scalar `int32` tensor.\n      inputs: Input (possibly nested tuple of) tensor[s] for this time step.\n      state: State (possibly nested tuple of) tensor[s] from previous time step.\n      name: Name scope for any created operations.\n\n    Returns:\n      `(outputs, next_state, next_inputs, finished)`.\n    """"""\n    raise NotImplementedError\n\n\ndef _create_zero_outputs(size, dtype, batch_size):\n  """"""Create a zero outputs Tensor structure.""""""\n  def _t(s):\n    return (s if isinstance(s, ops.Tensor) else constant_op.constant(\n        tensor_shape.TensorShape(s).as_list(),\n        dtype=dtypes.int32,\n        name=""zero_suffix_shape""))\n\n  def _create(s, d):\n    return array_ops.zeros(\n        array_ops.concat(\n            ([batch_size], _t(s)), axis=0), dtype=d)\n\n  return nest.map_structure(_create, size, dtype)\n\n\ndef dynamic_decode(decoder,\n                   output_time_major=False,\n                   impute_finished=False,\n                   maximum_iterations=None,\n                   parallel_iterations=32,\n                   swap_memory=False,\n                   scope=None):\n  """"""Perform dynamic decoding with `decoder`.\n\n  Args:\n    decoder: A `Decoder` instance.\n    output_time_major: Python boolean.  Default: `False` (batch major).  If\n      `True`, outputs are returned as time major tensors (this mode is faster).\n      Otherwise, outputs are returned as batch major tensors (this adds extra\n      time to the computation).\n    impute_finished: Python boolean.  If `True`, then states for batch\n      entries which are marked as finished get copied through and the\n      corresponding outputs get zeroed out.  This causes some slowdown at\n      each time step, but ensures that the final state and outputs have\n      the correct values and that backprop ignores time steps that were\n      marked as finished.\n    maximum_iterations: `int32` scalar, maximum allowed number of decoding\n       steps.  Default is `None` (decode until the decoder is fully done).\n    parallel_iterations: Argument passed to `tf.while_loop`.\n    swap_memory: Argument passed to `tf.while_loop`.\n    scope: Optional variable scope to use.\n\n  Returns:\n    `(final_outputs, final_state)`.\n\n  Raises:\n    TypeError: if `decoder` is not an instance of `Decoder`.\n    ValueError: if maximum_iterations is provided but is not a scalar.\n  """"""\n  if not isinstance(decoder, Decoder):\n    raise TypeError(""Expected decoder to be type Decoder, but saw: %s"" %\n                    type(decoder))\n\n  with variable_scope.variable_scope(scope or ""decoder"") as varscope:\n    # Properly cache variable values inside the while_loop\n    if varscope.caching_device is None:\n      varscope.set_caching_device(lambda op: op.device)\n\n    if maximum_iterations is not None:\n      maximum_iterations = ops.convert_to_tensor(\n          maximum_iterations, dtype=dtypes.int32, name=""maximum_iterations"")\n      if maximum_iterations.get_shape().ndims != 0:\n        raise ValueError(""maximum_iterations must be a scalar"")\n\n    initial_finished, initial_inputs, initial_state = decoder.initialize()\n\n    zero_outputs = _create_zero_outputs(decoder.output_size,\n                                        decoder.output_dtype,\n                                        decoder.batch_size)\n\n    if maximum_iterations is not None:\n      initial_finished = math_ops.logical_or(\n          initial_finished, 0 >= maximum_iterations)\n    initial_time = constant_op.constant(0, dtype=dtypes.int32)\n\n    def _shape(batch_size, from_shape):\n      if not isinstance(from_shape, tensor_shape.TensorShape):\n        return tensor_shape.TensorShape(None)\n      else:\n        batch_size = tensor_util.constant_value(\n            ops.convert_to_tensor(\n                batch_size, name=""batch_size""))\n        return tensor_shape.TensorShape([batch_size]).concatenate(from_shape)\n\n    def _create_ta(s, d):\n      return tensor_array_ops.TensorArray(\n          dtype=d,\n          size=0,\n          dynamic_size=True,\n          element_shape=_shape(decoder.batch_size, s))\n\n    initial_outputs_ta = nest.map_structure(_create_ta, decoder.output_size,\n                                            decoder.output_dtype)\n\n    def condition(unused_time, unused_outputs_ta, unused_state, unused_inputs,\n                  finished):\n      return math_ops.logical_not(math_ops.reduce_all(finished))\n\n    def body(time, outputs_ta, state, inputs, finished):\n      """"""Internal while_loop body.\n\n      Args:\n        time: scalar int32 tensor.\n        outputs_ta: structure of TensorArray.\n        state: (structure of) state tensors and TensorArrays.\n        inputs: (structure of) input tensors.\n        finished: 1-D bool tensor.\n\n      Returns:\n        `(time + 1, outputs_ta, next_state, next_inputs, next_finished)`.\n      """"""\n      (next_outputs, decoder_state, next_inputs,\n       decoder_finished) = decoder.step(time, inputs, state)\n      next_finished = math_ops.logical_or(decoder_finished, finished)\n      if maximum_iterations is not None:\n        next_finished = math_ops.logical_or(\n            next_finished, time + 1 >= maximum_iterations)\n\n      nest.assert_same_structure(state, decoder_state)\n      nest.assert_same_structure(outputs_ta, next_outputs)\n      nest.assert_same_structure(inputs, next_inputs)\n\n      # Zero out output values past finish\n      if impute_finished:\n        emit = nest.map_structure(\n            lambda out, zero: array_ops.where(finished, zero, out),\n            next_outputs,\n            zero_outputs)\n      else:\n        emit = next_outputs\n\n      # Copy through states past finish\n      def _maybe_copy_state(new, cur):\n        # TensorArrays and scalar states get passed through.\n        if isinstance(cur, tensor_array_ops.TensorArray):\n          pass_through = True\n        else:\n          new.set_shape(cur.shape)\n          pass_through = (new.shape.ndims == 0)\n        return new if pass_through else array_ops.where(finished, cur, new)\n\n      if impute_finished:\n        next_state = nest.map_structure(\n            _maybe_copy_state, decoder_state, state)\n      else:\n        next_state = decoder_state\n\n      outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),\n                                      outputs_ta, emit)\n      return (time + 1, outputs_ta, next_state, next_inputs, next_finished)\n\n    res = control_flow_ops.while_loop(\n        condition,\n        body,\n        loop_vars=[\n            initial_time, initial_outputs_ta, initial_state, initial_inputs,\n            initial_finished\n        ],\n        parallel_iterations=parallel_iterations,\n        swap_memory=swap_memory)\n\n    final_outputs_ta = res[1]\n    final_state = res[2]\n\n    final_outputs = nest.map_structure(lambda ta: ta.stack(), final_outputs_ta)\n    if not output_time_major:\n      final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n\n  return final_outputs, final_state\n'"
seq2seq/contrib/seq2seq/helper.py,2,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""\nIMPORTANT: This code is taken directly from Tensorflow\n(https://github.com/tensorflow/tensorflow) and is copied temporarily\nuntil it is available in a packaged Tensorflow version on pypi.\n\nTODO(dennybritz): Delete this code when it becomes available in TF.\n\nA library of helpers for use with SamplingDecoders.\n""""""\n\n# pylint: skip-file\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\n\nimport six\n\nfrom tensorflow.contrib.distributions.python.ops import bernoulli\nfrom tensorflow.contrib.distributions.python.ops import categorical\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.layers import base as layers_base\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import embedding_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import random_ops\nfrom tensorflow.python.ops import tensor_array_ops\nfrom tensorflow.python.util import nest\n\nfrom seq2seq.contrib.seq2seq import decoder\n\n__all__ = [\n    ""Helper"",\n    ""TrainingHelper"",\n    ""GreedyEmbeddingHelper"",\n    ""CustomHelper"",\n    ""ScheduledEmbeddingTrainingHelper"",\n    ""ScheduledOutputTrainingHelper"",\n]\n\n_transpose_batch_time = decoder._transpose_batch_time  # pylint: disable=protected-access\n\n\ndef _unstack_ta(inp):\n  return tensor_array_ops.TensorArray(\n      dtype=inp.dtype, size=array_ops.shape(inp)[0],\n      element_shape=inp.get_shape()[1:]).unstack(inp)\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass Helper(object):\n  """"""Helper interface.  Helper instances are used by SamplingDecoder.""""""\n\n  @abc.abstractproperty\n  def batch_size(self):\n    """"""Returns a scalar int32 tensor.""""""\n    raise NotImplementedError(""batch_size has not been implemented"")\n\n  @abc.abstractmethod\n  def initialize(self, name=None):\n    """"""Returns `(initial_finished, initial_inputs)`.""""""\n    pass\n\n  @abc.abstractmethod\n  def sample(self, time, outputs, state, name=None):\n    """"""Returns `sample_ids`.""""""\n    pass\n\n  @abc.abstractmethod\n  def next_inputs(self, time, outputs, state, sample_ids, name=None):\n    """"""Returns `(finished, next_inputs, next_state)`.""""""\n    pass\n\n\nclass CustomHelper(Helper):\n  """"""Base abstract class that allows the user to customize sampling.""""""\n\n  def __init__(self, initialize_fn, sample_fn, next_inputs_fn):\n    """"""Initializer.\n\n    Args:\n      initialize_fn: callable that returns `(finished, next_inputs)`\n        for the first iteration.\n      sample_fn: callable that takes `(time, outputs, state)`\n        and emits tensor `sample_ids`.\n      next_inputs_fn: callable that takes `(time, outputs, state, sample_ids)`\n        and emits `(finished, next_inputs, next_state)`.\n    """"""\n    self._initialize_fn = initialize_fn\n    self._sample_fn = sample_fn\n    self._next_inputs_fn = next_inputs_fn\n    self._batch_size = None\n\n  @property\n  def batch_size(self):\n    if self._batch_size is None:\n      raise ValueError(""batch_size accessed before initialize was called"")\n    return self._batch_size\n\n  def initialize(self, name=None):\n    with ops.name_scope(name, ""%sInitialize"" % type(self).__name__):\n      (finished, next_inputs) = self._initialize_fn()\n      if self._batch_size is None:\n        self._batch_size = array_ops.size(finished)\n    return (finished, next_inputs)\n\n  def sample(self, time, outputs, state, name=None):\n    with ops.name_scope(\n        name, ""%sSample"" % type(self).__name__, (time, outputs, state)):\n      return self._sample_fn(time=time, outputs=outputs, state=state)\n\n  def next_inputs(self, time, outputs, state, sample_ids, name=None):\n    with ops.name_scope(\n        name, ""%sNextInputs"" % type(self).__name__, (time, outputs, state)):\n      return self._next_inputs_fn(\n          time=time, outputs=outputs, state=state, sample_ids=sample_ids)\n\n\nclass TrainingHelper(Helper):\n  """"""A helper for use during training.  Only reads inputs.\n\n  Returned sample_ids are the argmax of the RNN output logits.\n  """"""\n\n  def __init__(self, inputs, sequence_length, time_major=False, name=None):\n    """"""Initializer.\n\n    Args:\n      inputs: A (structure of) input tensors.\n      sequence_length: An int32 vector tensor.\n      time_major: Python bool.  Whether the tensors in `inputs` are time major.\n        If `False` (default), they are assumed to be batch major.\n      name: Name scope for any created operations.\n\n    Raises:\n      ValueError: if `sequence_length` is not a 1D tensor.\n    """"""\n    with ops.name_scope(name, ""TrainingHelper"", [inputs, sequence_length]):\n      inputs = ops.convert_to_tensor(inputs, name=""inputs"")\n      if not time_major:\n        inputs = nest.map_structure(_transpose_batch_time, inputs)\n\n      self._input_tas = nest.map_structure(_unstack_ta, inputs)\n      self._sequence_length = ops.convert_to_tensor(\n          sequence_length, name=""sequence_length"")\n      if self._sequence_length.get_shape().ndims != 1:\n        raise ValueError(\n            ""Expected sequence_length to be a vector, but received shape: %s"" %\n            self._sequence_length.get_shape())\n\n      self._zero_inputs = nest.map_structure(\n          lambda inp: array_ops.zeros_like(inp[0, :]), inputs)\n\n      self._batch_size = array_ops.size(sequence_length)\n\n  @property\n  def batch_size(self):\n    return self._batch_size\n\n  def initialize(self, name=None):\n    with ops.name_scope(name, ""TrainingHelperInitialize""):\n      finished = math_ops.equal(0, self._sequence_length)\n      all_finished = math_ops.reduce_all(finished)\n      next_inputs = control_flow_ops.cond(\n          all_finished, lambda: self._zero_inputs,\n          lambda: nest.map_structure(lambda inp: inp.read(0), self._input_tas))\n      return (finished, next_inputs)\n\n  def sample(self, time, outputs, name=None, **unused_kwargs):\n    with ops.name_scope(name, ""TrainingHelperSample"", [time, outputs]):\n      sample_ids = math_ops.cast(\n          math_ops.argmax(outputs, axis=-1), dtypes.int32)\n      return sample_ids\n\n  def next_inputs(self, time, outputs, state, name=None, **unused_kwargs):\n    """"""next_inputs_fn for TrainingHelper.""""""\n    with ops.name_scope(name, ""TrainingHelperNextInputs"",\n                        [time, outputs, state]):\n      next_time = time + 1\n      finished = (next_time >= self._sequence_length)\n      all_finished = math_ops.reduce_all(finished)\n      def read_from_ta(inp):\n        return inp.read(next_time)\n      next_inputs = control_flow_ops.cond(\n          all_finished, lambda: self._zero_inputs,\n          lambda: nest.map_structure(read_from_ta, self._input_tas))\n      return (finished, next_inputs, state)\n\n\nclass ScheduledEmbeddingTrainingHelper(TrainingHelper):\n  """"""A training helper that adds scheduled sampling.\n\n  Returns -1s for sample_ids where no sampling took place; valid sample id\n  values elsewhere.\n  """"""\n\n  def __init__(self, inputs, sequence_length, embedding, sampling_probability,\n               time_major=False, seed=None, scheduling_seed=None, name=None):\n    """"""Initializer.\n\n    Args:\n      inputs: A (structure of) input tensors.\n      sequence_length: An int32 vector tensor.\n      embedding: A callable that takes a vector tensor of `ids` (argmax ids),\n        or the `params` argument for `embedding_lookup`.\n      sampling_probability: A 0D `float32` tensor: the probability of sampling\n        categorically from the output ids instead of reading directly from the\n        inputs.\n      time_major: Python bool.  Whether the tensors in `inputs` are time major.\n        If `False` (default), they are assumed to be batch major.\n      seed: The sampling seed.\n      scheduling_seed: The schedule decision rule sampling seed.\n      name: Name scope for any created operations.\n\n    Raises:\n      ValueError: if `sampling_probability` is not a scalar or vector.\n    """"""\n    with ops.name_scope(name, ""ScheduledEmbeddingSamplingWrapper"",\n                        [embedding, sampling_probability]):\n      if callable(embedding):\n        self._embedding_fn = embedding\n      else:\n        self._embedding_fn = (\n            lambda ids: embedding_ops.embedding_lookup(embedding, ids))\n      self._sampling_probability = ops.convert_to_tensor(\n          sampling_probability, name=""sampling_probability"")\n      if self._sampling_probability.get_shape().ndims not in (0, 1):\n        raise ValueError(\n            ""sampling_probability must be either a scalar or a vector. ""\n            ""saw shape: %s"" % (self._sampling_probability.get_shape()))\n      self._seed = seed\n      self._scheduling_seed = scheduling_seed\n      super(ScheduledEmbeddingTrainingHelper, self).__init__(\n          inputs=inputs,\n          sequence_length=sequence_length,\n          time_major=time_major,\n          name=name)\n\n  def initialize(self, name=None):\n    return super(ScheduledEmbeddingTrainingHelper, self).initialize(name=name)\n\n  def sample(self, time, outputs, state, name=None):\n    with ops.name_scope(name, ""ScheduledEmbeddingTrainingHelperSample"",\n                        [time, outputs, state]):\n      # Return -1s where we did not sample, and sample_ids elsewhere\n      select_sample_noise = random_ops.random_uniform(\n          [self.batch_size], seed=self._scheduling_seed)\n      select_sample = (self._sampling_probability > select_sample_noise)\n      sample_id_sampler = categorical.Categorical(logits=outputs)\n      return array_ops.where(\n          select_sample,\n          sample_id_sampler.sample(seed=self._seed),\n          array_ops.tile([-1], [self.batch_size]))\n\n  def next_inputs(self, time, outputs, state, sample_ids, name=None):\n    with ops.name_scope(name, ""ScheduledEmbeddingTrainingHelperSample"",\n                        [time, outputs, state, sample_ids]):\n      (finished, base_next_inputs, state) = (\n          super(ScheduledEmbeddingTrainingHelper, self).next_inputs(\n              time=time,\n              outputs=outputs,\n              state=state,\n              sample_ids=sample_ids,\n              name=name))\n\n      def maybe_sample():\n        """"""Perform scheduled sampling.""""""\n        where_sampling = math_ops.cast(\n            array_ops.where(sample_ids > -1), dtypes.int32)\n        where_not_sampling = math_ops.cast(\n            array_ops.where(sample_ids <= -1), dtypes.int32)\n        where_sampling_flat = array_ops.reshape(where_sampling, [-1])\n        where_not_sampling_flat = array_ops.reshape(where_not_sampling, [-1])\n        sample_ids_sampling = array_ops.gather(sample_ids, where_sampling_flat)\n        inputs_not_sampling = array_ops.gather(\n            base_next_inputs, where_not_sampling_flat)\n        sampled_next_inputs = self._embedding_fn(sample_ids_sampling)\n        base_shape = array_ops.shape(base_next_inputs)\n        return (array_ops.scatter_nd(indices=where_sampling,\n                                     updates=sampled_next_inputs,\n                                     shape=base_shape)\n                + array_ops.scatter_nd(indices=where_not_sampling,\n                                       updates=inputs_not_sampling,\n                                       shape=base_shape))\n\n      all_finished = math_ops.reduce_all(finished)\n      next_inputs = control_flow_ops.cond(\n          all_finished, lambda: base_next_inputs, maybe_sample)\n      return (finished, next_inputs, state)\n\n\nclass ScheduledOutputTrainingHelper(TrainingHelper):\n  """"""A training helper that adds scheduled sampling directly to outputs.\n\n  Returns False for sample_ids where no sampling took place; True elsewhere.\n  """"""\n\n  def __init__(self, inputs, sequence_length, sampling_probability,\n               time_major=False, seed=None, next_input_layer=None,\n               auxiliary_inputs=None, name=None):\n    """"""Initializer.\n\n    Args:\n      inputs: A (structure) of input tensors.\n      sequence_length: An int32 vector tensor.\n      sampling_probability: A 0D `float32` tensor: the probability of sampling\n        from the outputs instead of reading directly from the inputs.\n      time_major: Python bool.  Whether the tensors in `inputs` are time major.\n        If `False` (default), they are assumed to be batch major.\n      seed: The sampling seed.\n      next_input_layer: (Optional) An instance of `tf.layers.Layer`, i.e.,\n        `tf.layers.Dense`.  Optional layer to apply to the RNN output to create\n        the next input.\n      auxiliary_inputs: An optional (structure of) auxiliary input tensors with\n        a shape that matches `inputs` in all but (potentially) the final\n        dimension. These tensors will be concatenated to the sampled output or\n        the `inputs` when not sampling for use as the next input.\n      name: Name scope for any created operations.\n\n    Raises:\n      ValueError: if `sampling_probability` is not a scalar or vector.\n    """"""\n    with ops.name_scope(name, ""ScheduledOutputTrainingHelper"",\n                        [inputs, auxiliary_inputs, sampling_probability]):\n      self._sampling_probability = ops.convert_to_tensor(\n          sampling_probability, name=""sampling_probability"")\n      if self._sampling_probability.get_shape().ndims not in (0, 1):\n        raise ValueError(\n            ""sampling_probability must be either a scalar or a vector. ""\n            ""saw shape: %s"" % (self._sampling_probability.get_shape()))\n\n      if auxiliary_inputs is None:\n        maybe_concatenated_inputs = inputs\n      else:\n        inputs = ops.convert_to_tensor(inputs, name=""inputs"")\n        auxiliary_inputs = ops.convert_to_tensor(\n            auxiliary_inputs, name=""auxiliary_inputs"")\n        maybe_concatenated_inputs = nest.map_structure(\n            lambda x, y: array_ops.concat((x, y), -1),\n            inputs, auxiliary_inputs)\n        if not time_major:\n          auxiliary_inputs = nest.map_structure(\n              _transpose_batch_time, auxiliary_inputs)\n\n      self._auxiliary_input_tas = (\n          nest.map_structure(_unstack_ta, auxiliary_inputs)\n          if auxiliary_inputs is not None else None)\n\n      self._seed = seed\n\n      if (next_input_layer is not None and not isinstance(next_input_layer,\n                                                          layers_base._Layer)):  # pylint: disable=protected-access\n        raise TypeError(""next_input_layer must be a Layer, received: %s"" %\n                        type(next_input_layer))\n      self._next_input_layer = next_input_layer\n\n      super(ScheduledOutputTrainingHelper, self).__init__(\n          inputs=maybe_concatenated_inputs,\n          sequence_length=sequence_length,\n          time_major=time_major,\n          name=name)\n\n  def initialize(self, name=None):\n    return super(ScheduledOutputTrainingHelper, self).initialize(name=name)\n\n  def sample(self, time, outputs, state, name=None):\n    with ops.name_scope(name, ""ScheduledOutputTrainingHelperSample"",\n                        [time, outputs, state]):\n      sampler = bernoulli.Bernoulli(probs=self._sampling_probability)\n      return math_ops.cast(\n          sampler.sample(sample_shape=self.batch_size, seed=self._seed),\n          dtypes.bool)\n\n  def next_inputs(self, time, outputs, state, sample_ids, name=None):\n    with ops.name_scope(name, ""ScheduledOutputTrainingHelperNextInputs"",\n                        [time, outputs, state, sample_ids]):\n      (finished, base_next_inputs, state) = (\n          super(ScheduledOutputTrainingHelper, self).next_inputs(\n              time=time,\n              outputs=outputs,\n              state=state,\n              sample_ids=sample_ids,\n              name=name))\n\n      def maybe_sample():\n        """"""Perform scheduled sampling.""""""\n\n        def maybe_concatenate_auxiliary_inputs(outputs_, indices=None):\n          """"""Concatenate outputs with auxiliary inputs, if they exist.""""""\n          if self._auxiliary_input_tas is None:\n            return outputs_\n\n          next_time = time + 1\n          auxiliary_inputs = nest.map_structure(\n              lambda ta: ta.read(next_time), self._auxiliary_input_tas)\n          if indices is not None:\n            auxiliary_inputs = array_ops.gather_nd(auxiliary_inputs, indices)\n          return nest.map_structure(\n              lambda x, y: array_ops.concat((x, y), -1),\n              outputs_, auxiliary_inputs)\n\n        if self._next_input_layer is None:\n          return array_ops.where(\n              sample_ids, maybe_concatenate_auxiliary_inputs(outputs),\n              base_next_inputs)\n\n        where_sampling = math_ops.cast(\n            array_ops.where(sample_ids), dtypes.int32)\n        where_not_sampling = math_ops.cast(\n            array_ops.where(math_ops.logical_not(sample_ids)), dtypes.int32)\n        outputs_sampling = array_ops.gather_nd(outputs, where_sampling)\n        inputs_not_sampling = array_ops.gather_nd(base_next_inputs,\n                                                  where_not_sampling)\n        sampled_next_inputs = maybe_concatenate_auxiliary_inputs(\n            self._next_input_layer(outputs_sampling), where_sampling)\n\n        base_shape = array_ops.shape(base_next_inputs)\n        return (array_ops.scatter_nd(indices=where_sampling,\n                                     updates=sampled_next_inputs,\n                                     shape=base_shape)\n                + array_ops.scatter_nd(indices=where_not_sampling,\n                                       updates=inputs_not_sampling,\n                                       shape=base_shape))\n\n      all_finished = math_ops.reduce_all(finished)\n      next_inputs = control_flow_ops.cond(\n          all_finished, lambda: base_next_inputs, maybe_sample)\n      return (finished, next_inputs, state)\n\n\nclass GreedyEmbeddingHelper(Helper):\n  """"""A helper for use during inference.\n\n  Uses the argmax of the output (treated as logits) and passes the\n  result through an embedding layer to get the next input.\n  """"""\n\n  def __init__(self, embedding, start_tokens, end_token):\n    """"""Initializer.\n\n    Args:\n      embedding: A callable that takes a vector tensor of `ids` (argmax ids),\n        or the `params` argument for `embedding_lookup`.\n      start_tokens: `int32` vector shaped `[batch_size]`, the start tokens.\n      end_token: `int32` scalar, the token that marks end of decoding.\n\n    Raises:\n      ValueError: if `sequence_length` is not a 1D tensor.\n    """"""\n    if callable(embedding):\n      self._embedding_fn = embedding\n    else:\n      self._embedding_fn = (\n          lambda ids: embedding_ops.embedding_lookup(embedding, ids))\n\n    self._start_tokens = ops.convert_to_tensor(\n        start_tokens, dtype=dtypes.int32, name=""start_tokens"")\n    self._end_token = ops.convert_to_tensor(\n        end_token, dtype=dtypes.int32, name=""end_token"")\n    if self._start_tokens.get_shape().ndims != 1:\n      raise ValueError(""start_tokens must be a vector"")\n    self._batch_size = array_ops.size(start_tokens)\n    if self._end_token.get_shape().ndims != 0:\n      raise ValueError(""end_token must be a scalar"")\n    self._start_inputs = self._embedding_fn(self._start_tokens)\n\n  @property\n  def batch_size(self):\n    return self._batch_size\n\n  def initialize(self, name=None):\n    finished = array_ops.tile([False], [self._batch_size])\n    return (finished, self._start_inputs)\n\n  def sample(self, time, outputs, state, name=None):\n    """"""sample for GreedyEmbeddingHelper.""""""\n    del time, state  # unused by sample_fn\n    # Outputs are logits, use argmax to get the most probable id\n    if not isinstance(outputs, ops.Tensor):\n      raise TypeError(""Expected outputs to be a single Tensor, got: %s"" %\n                      type(outputs))\n    sample_ids = math_ops.cast(\n        math_ops.argmax(outputs, axis=-1), dtypes.int32)\n    return sample_ids\n\n  def next_inputs(self, time, outputs, state, sample_ids, name=None):\n    """"""next_inputs_fn for GreedyEmbeddingHelper.""""""\n    del time, outputs  # unused by next_inputs_fn\n    finished = math_ops.equal(sample_ids, self._end_token)\n    all_finished = math_ops.reduce_all(finished)\n    next_inputs = control_flow_ops.cond(\n        all_finished,\n        # If we\'re finished, the next_inputs value doesn\'t matter\n        lambda: self._start_inputs,\n        lambda: self._embedding_fn(sample_ids))\n    return (finished, next_inputs, state)\n'"
