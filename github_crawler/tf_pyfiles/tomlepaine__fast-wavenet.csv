file_path,api_count,code
wavenet/__init__.py,0,b''
wavenet/layers.py,30,"b""import numpy as np\nimport tensorflow as tf\n\n\ndef time_to_batch(inputs, rate):\n    '''If necessary zero-pads inputs and reshape by rate.\n    \n    Used to perform 1D dilated convolution.\n    \n    Args:\n      inputs: (tensor) \n      rate: (int)\n    Outputs:\n      outputs: (tensor)\n      pad_left: (int)\n    '''\n    _, width, num_channels = inputs.get_shape().as_list()\n\n    width_pad = int(rate * np.ceil((width + rate) * 1.0 / rate))\n    pad_left = width_pad - width\n\n    perm = (1, 0, 2)\n    shape = (width_pad / rate, -1, num_channels) # missing dim: batch_size * rate\n    padded = tf.pad(inputs, [[0, 0], [pad_left, 0], [0, 0]])\n    transposed = tf.transpose(padded, perm)\n    reshaped = tf.reshape(transposed, shape)\n    outputs = tf.transpose(reshaped, perm)\n    return outputs\n\ndef batch_to_time(inputs, rate, crop_left=0):\n    ''' Reshape to 1d signal, and remove excess zero-padding.\n    \n    Used to perform 1D dilated convolution.\n    \n    Args:\n      inputs: (tensor)\n      crop_left: (int)\n      rate: (int)\n    Ouputs:\n      outputs: (tensor)\n    '''\n    shape = tf.shape(inputs)\n    batch_size = shape[0] / rate\n    width = shape[1]\n    \n    out_width = tf.to_int32(width * rate)\n    _, _, num_channels = inputs.get_shape().as_list()\n    \n    perm = (1, 0, 2)\n    new_shape = (out_width, -1, num_channels) # missing dim: batch_size\n    transposed = tf.transpose(inputs, perm)    \n    reshaped = tf.reshape(transposed, new_shape)\n    outputs = tf.transpose(reshaped, perm)\n    cropped = tf.slice(outputs, [0, crop_left, 0], [-1, -1, -1])\n    return cropped\n\ndef conv1d(inputs,\n           out_channels,\n           filter_width=2,\n           stride=1,\n           padding='VALID',\n           data_format='NHWC',\n           gain=np.sqrt(2),\n           activation=tf.nn.relu,\n           bias=False):\n    '''One dimension convolution helper function.\n    \n    Sets variables with good defaults.\n    \n    Args:\n      inputs:\n      out_channels:\n      filter_width:\n      stride:\n      paddding:\n      data_format:\n      gain:\n      activation:\n      bias:\n      \n    Outputs:\n      outputs:\n    '''\n    in_channels = inputs.get_shape().as_list()[-1]\n\n    stddev = gain / np.sqrt(filter_width**2 * in_channels)\n    w_init = tf.random_normal_initializer(stddev=stddev)\n\n    w = tf.get_variable(name='w',\n                        shape=(filter_width, in_channels, out_channels),\n                        initializer=w_init)\n\n    outputs = tf.nn.conv1d(inputs,\n                           w,\n                           stride=stride,\n                           padding=padding,\n                           data_format=data_format)\n\n    if bias:\n        b_init = tf.constant_initializer(0.0)\n        b = tf.get_variable(name='b',\n                            shape=(out_channels, ),\n                            initializer=b_init)\n\n        outputs = outputs + tf.expand_dims(tf.expand_dims(b, 0), 0)\n\n    if activation:\n        outputs = activation(outputs)\n\n    return outputs\n\ndef dilated_conv1d(inputs,\n                   out_channels,\n                   filter_width=2,\n                   rate=1,\n                   padding='VALID',\n                   name=None,\n                   gain=np.sqrt(2),\n                   activation=tf.nn.relu):\n    '''\n    \n    Args:\n      inputs: (tensor)\n      output_channels:\n      filter_width:\n      rate:\n      padding:\n      name:\n      gain:\n      activation:\n\n    Outputs:\n      outputs: (tensor)\n    '''\n    assert name\n    with tf.variable_scope(name):\n        _, width, _ = inputs.get_shape().as_list()\n        inputs_ = time_to_batch(inputs, rate=rate)\n        outputs_ = conv1d(inputs_,\n                          out_channels=out_channels,\n                          filter_width=filter_width,\n                          padding=padding,\n                          gain=gain,\n                          activation=activation)\n        _, conv_out_width, _ = outputs_.get_shape().as_list()\n        new_width = conv_out_width * rate\n        diff = new_width - width\n        outputs = batch_to_time(outputs_, rate=rate, crop_left=diff)\n\n        # Add additional shape information.\n        tensor_shape = [tf.Dimension(None),\n                        tf.Dimension(width),\n                        tf.Dimension(out_channels)]\n        outputs.set_shape(tf.TensorShape(tensor_shape))\n\n    return outputs\n\ndef _causal_linear(inputs, state, name=None, activation=None):\n    assert name\n    '''\n    '''\n    with tf.variable_scope(name, reuse=True) as scope:\n        w = tf.get_variable('w')\n        w_r = w[0, :, :]\n        w_e = w[1, :, :]\n\n        output = tf.matmul(inputs, w_e) + tf.matmul(state, w_r)\n\n        if activation:\n            output = activation(output)\n    return output\n\ndef _output_linear(h, name=''):\n    with tf.variable_scope(name, reuse=True):\n        w = tf.get_variable('w')[0, :, :]\n        b = tf.get_variable('b')\n\n        output = tf.matmul(h, w) + tf.expand_dims(b, 0)\n    return output\n"""
wavenet/models.py,14,"b""import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom layers import (_causal_linear, _output_linear, conv1d,\n                    dilated_conv1d)\n\n\nclass Model(object):\n    def __init__(self,\n                 num_time_samples,\n                 num_channels=1,\n                 num_classes=256,\n                 num_blocks=2,\n                 num_layers=14,\n                 num_hidden=128,\n                 gpu_fraction=1.0):\n        \n        self.num_time_samples = num_time_samples\n        self.num_channels = num_channels\n        self.num_classes = num_classes\n        self.num_blocks = num_blocks\n        self.num_layers = num_layers\n        self.num_hidden = num_hidden\n        self.gpu_fraction = gpu_fraction\n        \n        inputs = tf.placeholder(tf.float32,\n                                shape=(None, num_time_samples, num_channels))\n        targets = tf.placeholder(tf.int32, shape=(None, num_time_samples))\n\n        h = inputs\n        hs = []\n        for b in range(num_blocks):\n            for i in range(num_layers):\n                rate = 2**i\n                name = 'b{}-l{}'.format(b, i)\n                h = dilated_conv1d(h, num_hidden, rate=rate, name=name)\n                hs.append(h)\n\n        outputs = conv1d(h,\n                         num_classes,\n                         filter_width=1,\n                         gain=1.0,\n                         activation=None,\n                         bias=True)\n\n        costs = tf.nn.sparse_softmax_cross_entropy_with_logits(\n            outputs, targets)\n        cost = tf.reduce_mean(costs)\n\n        train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n\n        gpu_options = tf.GPUOptions(\n            per_process_gpu_memory_fraction=gpu_fraction)\n        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n        sess.run(tf.initialize_all_variables())\n\n        self.inputs = inputs\n        self.targets = targets\n        self.outputs = outputs\n        self.hs = hs\n        self.costs = costs\n        self.cost = cost\n        self.train_step = train_step\n        self.sess = sess\n\n    def _train(self, inputs, targets):\n        feed_dict = {self.inputs: inputs, self.targets: targets}\n        cost, _ = self.sess.run(\n            [self.cost, self.train_step],\n            feed_dict=feed_dict)\n        return cost\n\n    def train(self, inputs, targets):\n        losses = []\n        terminal = False\n        i = 0\n        while not terminal:\n            i += 1\n            cost = self._train(inputs, targets)\n            if cost < 1e-1:\n                terminal = True\n            losses.append(cost)\n            if i % 50 == 0:\n                plt.plot(losses)\n                plt.show()\n\n\nclass Generator(object):\n    def __init__(self, model, batch_size=1, input_size=1):\n        self.model = model\n        self.bins = np.linspace(-1, 1, self.model.num_classes)\n\n        inputs = tf.placeholder(tf.float32, [batch_size, input_size],\n                                name='inputs')\n\n        print('Make Generator.')\n\n        count = 0\n        h = inputs\n\n        init_ops = []\n        push_ops = []\n        for b in range(self.model.num_blocks):\n            for i in range(self.model.num_layers):\n                rate = 2**i\n                name = 'b{}-l{}'.format(b, i)\n                if count == 0:\n                    state_size = 1\n                else:\n                    state_size = self.model.num_hidden\n                    \n                q = tf.FIFOQueue(rate,\n                                 dtypes=tf.float32,\n                                 shapes=(batch_size, state_size))\n                init = q.enqueue_many(tf.zeros((rate, batch_size, state_size)))\n\n                state_ = q.dequeue()\n                push = q.enqueue([h])\n                init_ops.append(init)\n                push_ops.append(push)\n\n                h = _causal_linear(h, state_, name=name, activation=tf.nn.relu)\n                count += 1\n\n        outputs = _output_linear(h)\n\n        out_ops = [tf.nn.softmax(outputs)]\n        out_ops.extend(push_ops)\n\n        self.inputs = inputs\n        self.init_ops = init_ops\n        self.out_ops = out_ops\n        \n        # Initialize queues.\n        self.model.sess.run(self.init_ops)\n\n    def run(self, input, num_samples):\n        predictions = []\n        for step in range(num_samples):\n\n            feed_dict = {self.inputs: input}\n            output = self.model.sess.run(self.out_ops, feed_dict=feed_dict)[0] # ignore push ops\n            value = np.argmax(output[0, :])\n\n            input = np.array(self.bins[value])[None, None]\n            predictions.append(input)\n\n            if step % 1000 == 0:\n                predictions_ = np.concatenate(predictions, axis=1)\n                plt.plot(predictions_[0, :], label='pred')\n                plt.legend()\n                plt.xlabel('samples from start')\n                plt.ylabel('signal')\n                plt.show()\n\n        predictions_ = np.concatenate(predictions, axis=1)\n        return predictions_\n"""
wavenet/utils.py,0,"b'import numpy as np\n\nfrom scipy.io import wavfile\n\n\ndef normalize(data):\n    temp = np.float32(data) - np.min(data)\n    out = (temp / np.max(temp) - 0.5) * 2\n    return out\n\n\ndef make_batch(path):\n    data = wavfile.read(path)[1][:, 0]\n\n    data_ = normalize(data)\n    # data_f = np.sign(data_) * (np.log(1 + 255*np.abs(data_)) / np.log(1 + 255))\n\n    bins = np.linspace(-1, 1, 256)\n    # Quantize inputs.\n    inputs = np.digitize(data_[0:-1], bins, right=False) - 1\n    inputs = bins[inputs][None, :, None]\n\n    # Encode targets as ints.\n    targets = (np.digitize(data_[1::], bins, right=False) - 1)[None, :]\n    return inputs, targets\n'"
