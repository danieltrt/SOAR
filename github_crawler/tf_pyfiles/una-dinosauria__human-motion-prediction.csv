file_path,api_count,code
src/baselines.py,3,"b'\n""""""Super-simple baselines for short term human motion prediction.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nimport translate\nfrom translate import define_actions\nimport data_utils\nimport seq2seq_model\n\n\n# Dummy object to create parameters for also-dummy model\nclass Object(object):\n    pass\n\ndef running_average( actions_dict, actions, k ):\n  """"""\n  Compute the error if we simply take the average of the last k frames.\n\n  Args\n    actions_dict: Dictionary where keys are the actions, and each entry has a\n                  tuple of (enc_in, dec_in, dec_out) poses.\n    actions: List of strings. The keys of actions_dict.\n    k:Integer. Number of frames to use for running average.\n\n  Returns\n    errs: a dictionary where, for each action, we have a 100-long list with the\n          error at each point in time.\n  """"""\n\n  # Get how many batches we have\n  enc_in, dec_in, dec_out = actions_dict[ actions[0] ]\n\n  n_sequences = len( enc_in )\n  seq_length_out = dec_out[0].shape[0]\n\n  errs = dict()\n\n  for action in actions:\n\n    # Make space for the error\n    errs[ action ] = np.zeros( (n_sequences, seq_length_out) )\n\n    # Get the lists for this action\n    enc_in, dec_in, dec_out = actions_dict[action]\n\n    for i in np.arange( n_sequences ):\n\n      n, d = dec_out[i].shape\n\n      # The last frame\n      last_frame = dec_in[i][0, :]\n      last_frame[0:6] = 0\n\n      if k > 1:\n        # Get the last k-1 frames\n        last_k = enc_in[i][(-k+1):, :]\n        assert( last_k.shape[0] == (k-1) )\n\n        # Merge and average them\n        avg = np.mean( np.vstack( (last_k, last_frame) ), 0 )\n      else:\n        avg = last_frame\n\n      dec_out[i][:, 0:6] = 0\n      idx_to_use = np.where( np.std( dec_out[i], 0 ) > 1e-4 )[0]\n\n      ee = np.power( dec_out[i][:,idx_to_use] - avg[idx_to_use], 2 )\n      ee = np.sum( ee, 1 )\n      ee = np.sqrt( ee )\n      errs[ action ][i, :] = ee\n\n    errs[action] = np.mean( errs[action], 0 )\n\n  return errs\n\n\ndef denormalize_and_convert_to_euler( data, data_mean, data_std, dim_to_ignore, actions, one_hot ):\n  """"""\n  Denormalizes data and converts to Euler angles\n  (all losses are computed on Euler angles).\n\n  Args\n    data: dictionary with human poses.\n    data_mean: d-long vector with the mean of the training data.\n    data_std: d-long vector with the standard deviation of the training data.\n    dim_to_ignore: dimensions to ignore because the std is too small or for other reasons.\n    actions: list of strings with the actions in the data dictionary.\n    one_hot: whether the data comes with one-hot encoding.\n\n  Returns\n    all_denormed: a list with nbatch entries. Each entry is an n-by-d matrix\n                  that corresponds to a denormalized sequence in Euler angles\n  """"""\n\n  all_denormed = []\n\n  # expmap -> rotmat -> euler\n  for i in np.arange( data.shape[0] ):\n    denormed = data_utils.unNormalizeData(data[i,:,:], data_mean, data_std, dim_to_ignore, actions, one_hot )\n\n    for j in np.arange( denormed.shape[0] ):\n      for k in np.arange(3,97,3):\n        denormed[j,k:k+3] = data_utils.rotmat2euler( data_utils.expmap2rotmat( denormed[j,k:k+3] ))\n\n    all_denormed.append( denormed )\n\n  return all_denormed\n\n\ndef main():\n\n  actions = define_actions( tf.app.flags.FLAGS.action )\n\n  # Parameters for dummy model. We only build the model to load the data.\n  one_hot = False\n  FLAGS = Object()\n  FLAGS.data_dir = ""./data/h3.6m/dataset""\n  FLAGS.architecture = ""tied""\n  FLAGS.seq_length_in = 50\n  FLAGS.seq_length_out = 100\n  FLAGS.num_layers = 1\n  FLAGS.size = 128\n  FLAGS.max_gradient_norm = 5\n  FLAGS.batch_size = 8\n  FLAGS.learning_rate = 0.005\n  FLAGS.learning_rate_decay_factor = 1\n  summaries_dir = ""./log/""\n  FLAGS.loss_to_use = ""sampling_based""\n  FLAGS.omit_one_hot = True,\n  FLAGS.residual_velocities = False,\n  dtype = tf.float32\n\n  # Baselines are very simple. No need to use the GPU.\n  with tf.Session(config=tf.ConfigProto( device_count = {""GPU"": 0})) as sess:\n\n    model = seq2seq_model.Seq2SeqModel(\n        FLAGS.architecture,\n        FLAGS.seq_length_in,\n        FLAGS.seq_length_out,\n        FLAGS.size, # hidden layer size\n        FLAGS.num_layers,\n        FLAGS.max_gradient_norm,\n        FLAGS.batch_size,\n        FLAGS.learning_rate,\n        FLAGS.learning_rate_decay_factor,\n        summaries_dir,\n        FLAGS.loss_to_use,\n        len( actions ),\n        not FLAGS.omit_one_hot,\n        FLAGS.residual_velocities,\n        dtype=dtype)\n\n    # Load the data\n    _, test_set, data_mean, data_std, dim_to_ignore, dim_to_use =  translate.read_all_data(\n      actions, FLAGS.seq_length_in, FLAGS.seq_length_out, FLAGS.data_dir, not FLAGS.omit_one_hot )\n\n    # Get all the data, denormalize and convert it to euler angles\n    poses_data = {}\n    for action in actions:\n      enc_in, dec_in, dec_out = model.get_batch_srnn( test_set, action )\n\n      enc_in  = denormalize_and_convert_to_euler(\n        enc_in, data_mean, data_std, dim_to_ignore, actions, not FLAGS.omit_one_hot )\n      dec_in  = denormalize_and_convert_to_euler(\n        dec_in, data_mean, data_std, dim_to_ignore, actions, not FLAGS.omit_one_hot )\n      dec_out = denormalize_and_convert_to_euler(\n        dec_out, data_mean, data_std, dim_to_ignore, actions, not FLAGS.omit_one_hot )\n\n      poses_data[action] = (enc_in, dec_in, dec_out)\n\n    # Compute baseline errors\n    errs_constant_frame = running_average( poses_data, actions, 1 )\n    running_average_2   = running_average( poses_data, actions, 2 )\n    running_average_4   = running_average( poses_data, actions, 4 )\n\n    print()\n    print(""=== Zero-velocity (running avg. 1) ==="")\n    print(""{0: <16} | {1:4d} | {2:4d} | {3:4d} | {4:4d}"".format(""milliseconds"", 80, 160, 380, 400))\n    for action in actions:\n      print(""{0: <16} | {1:.2f} | {2:.2f} | {3:.2f} | {4:.2f}"".format( action,\n            errs_constant_frame[action][1], errs_constant_frame[action][3],\n            errs_constant_frame[action][7], errs_constant_frame[action][9] ))\n\n    print()\n    print(""=== Runnning avg. 2 ==="")\n    print(""{0: <16} | {1:4d} | {2:4d} | {3:4d} | {4:4d}"".format(""milliseconds"", 80, 160, 380, 400))\n    for action in actions:\n      print(""{0: <16} | {1:.2f} | {2:.2f} | {3:.2f} | {4:.2f}"".format( action,\n            running_average_2[action][1], running_average_2[action][3],\n            running_average_2[action][7], running_average_2[action][9] ))\n\n    print()\n    print(""=== Runnning avg. 4 ==="")\n    print(""{0: <16} | {1:4d} | {2:4d} | {3:4d} | {4:4d}"".format(""milliseconds"", 80, 160, 380, 400))\n    for action in actions:\n      print(""{0: <16} | {1:.2f} | {2:.2f} | {3:.2f} | {4:.2f}"".format( action,\n            running_average_4[action][1], running_average_4[action][3],\n            running_average_4[action][7], running_average_4[action][9] ))\n\n\nif __name__ == ""__main__"":\n  main()\n'"
src/data_utils.py,0,"b'\n""""""Functions that help with data processing for human3.6m""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six.moves import xrange # pylint: disable=redefined-builtin\nimport copy\n\ndef rotmat2euler( R ):\n  """"""\n  Converts a rotation matrix to Euler angles\n  Matlab port to python for evaluation purposes\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/mhmublv/Motion/RotMat2Euler.m#L1\n\n  Args\n    R: a 3x3 rotation matrix\n  Returns\n    eul: a 3x1 Euler angle representation of R\n  """"""\n  if R[0,2] == 1 or R[0,2] == -1:\n    # special case\n    E3   = 0 # set arbitrarily\n    dlta = np.arctan2( R[0,1], R[0,2] );\n\n    if R[0,2] == -1:\n      E2 = np.pi/2;\n      E1 = E3 + dlta;\n    else:\n      E2 = -np.pi/2;\n      E1 = -E3 + dlta;\n\n  else:\n    E2 = -np.arcsin( R[0,2] )\n    E1 = np.arctan2( R[1,2]/np.cos(E2), R[2,2]/np.cos(E2) )\n    E3 = np.arctan2( R[0,1]/np.cos(E2), R[0,0]/np.cos(E2) )\n\n  eul = np.array([E1, E2, E3]);\n  return eul\n\n\ndef quat2expmap(q):\n  """"""\n  Converts a quaternion to an exponential map\n  Matlab port to python for evaluation purposes\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/mhmublv/Motion/quat2expmap.m#L1\n\n  Args\n    q: 1x4 quaternion\n  Returns\n    r: 1x3 exponential map\n  Raises\n    ValueError if the l2 norm of the quaternion is not close to 1\n  """"""\n  if (np.abs(np.linalg.norm(q)-1)>1e-3):\n    raise(ValueError, ""quat2expmap: input quaternion is not norm 1"")\n\n  sinhalftheta = np.linalg.norm(q[1:])\n  coshalftheta = q[0]\n\n  r0    = np.divide( q[1:], (np.linalg.norm(q[1:]) + np.finfo(np.float32).eps));\n  theta = 2 * np.arctan2( sinhalftheta, coshalftheta )\n  theta = np.mod( theta + 2*np.pi, 2*np.pi )\n\n  if theta > np.pi:\n    theta =  2 * np.pi - theta\n    r0    = -r0\n\n  r = r0 * theta\n  return r\n\ndef rotmat2quat(R):\n  """"""\n  Converts a rotation matrix to a quaternion\n  Matlab port to python for evaluation purposes\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/mhmublv/Motion/rotmat2quat.m#L4\n\n  Args\n    R: 3x3 rotation matrix\n  Returns\n    q: 1x4 quaternion\n  """"""\n  rotdiff = R - R.T;\n\n  r = np.zeros(3)\n  r[0] = -rotdiff[1,2]\n  r[1] =  rotdiff[0,2]\n  r[2] = -rotdiff[0,1]\n  sintheta = np.linalg.norm(r) / 2;\n  r0 = np.divide(r, np.linalg.norm(r) + np.finfo(np.float32).eps );\n\n  costheta = (np.trace(R)-1) / 2;\n\n  theta = np.arctan2( sintheta, costheta );\n\n  q      = np.zeros(4)\n  q[0]   = np.cos(theta/2)\n  q[1:] = r0*np.sin(theta/2)\n  return q\n\ndef rotmat2expmap(R):\n  return quat2expmap( rotmat2quat(R) );\n\ndef expmap2rotmat(r):\n  """"""\n  Converts an exponential map angle to a rotation matrix\n  Matlab port to python for evaluation purposes\n  I believe this is also called Rodrigues\' formula\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/mhmublv/Motion/expmap2rotmat.m\n\n  Args\n    r: 1x3 exponential map\n  Returns\n    R: 3x3 rotation matrix\n  """"""\n  theta = np.linalg.norm( r )\n  r0  = np.divide( r, theta + np.finfo(np.float32).eps )\n  r0x = np.array([0, -r0[2], r0[1], 0, 0, -r0[0], 0, 0, 0]).reshape(3,3)\n  r0x = r0x - r0x.T\n  R = np.eye(3,3) + np.sin(theta)*r0x + (1-np.cos(theta))*(r0x).dot(r0x);\n  return R\n\n\ndef unNormalizeData(normalizedData, data_mean, data_std, dimensions_to_ignore, actions, one_hot ):\n  """"""Borrowed from SRNN code. Reads a csv file and returns a float32 matrix.\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/generateMotionData.py#L12\n\n  Args\n    normalizedData: nxd matrix with normalized data\n    data_mean: vector of mean used to normalize the data\n    data_std: vector of standard deviation used to normalize the data\n    dimensions_to_ignore: vector with dimensions not used by the model\n    actions: list of strings with the encoded actions\n    one_hot: whether the data comes with one-hot encoding\n  Returns\n    origData: data originally used to\n  """"""\n  T = normalizedData.shape[0]\n  D = data_mean.shape[0]\n\n  origData = np.zeros((T, D), dtype=np.float32)\n  dimensions_to_use = []\n  for i in range(D):\n    if i in dimensions_to_ignore:\n      continue\n    dimensions_to_use.append(i)\n  dimensions_to_use = np.array(dimensions_to_use)\n\n  if one_hot:\n    origData[:, dimensions_to_use] = normalizedData[:, :-len(actions)]\n  else:\n    origData[:, dimensions_to_use] = normalizedData\n\n  # potentially ineficient, but only done once per experiment\n  stdMat = data_std.reshape((1, D))\n  stdMat = np.repeat(stdMat, T, axis=0)\n  meanMat = data_mean.reshape((1, D))\n  meanMat = np.repeat(meanMat, T, axis=0)\n  origData = np.multiply(origData, stdMat) + meanMat\n  return origData\n\n\ndef revert_output_format(poses, data_mean, data_std, dim_to_ignore, actions, one_hot):\n  """"""\n  Converts the output of the neural network to a format that is more easy to\n  manipulate for, e.g. conversion to other format or visualization\n\n  Args\n    poses: The output from the TF model. A list with (seq_length) entries,\n    each with a (batch_size, dim) output\n  Returns\n    poses_out: A tensor of size (batch_size, seq_length, dim) output. Each\n    batch is an n-by-d sequence of poses.\n  """"""\n  seq_len = len(poses)\n  if seq_len == 0:\n    return []\n\n  batch_size, dim = poses[0].shape\n\n  poses_out = np.concatenate(poses)\n  poses_out = np.reshape(poses_out, (seq_len, batch_size, dim))\n  poses_out = np.transpose(poses_out, [1, 0, 2])\n\n  poses_out_list = []\n  for i in xrange(poses_out.shape[0]):\n    poses_out_list.append(\n      unNormalizeData(poses_out[i, :, :], data_mean, data_std, dim_to_ignore, actions, one_hot))\n\n  return poses_out_list\n\n\ndef readCSVasFloat(filename):\n  """"""\n  Borrowed from SRNN code. Reads a csv and returns a float matrix.\n  https://github.com/asheshjain399/NeuralModels/blob/master/neuralmodels/utils.py#L34\n\n  Args\n    filename: string. Path to the csv file\n  Returns\n    returnArray: the read data in a float32 matrix\n  """"""\n  returnArray = []\n  lines = open(filename).readlines()\n  for line in lines:\n    line = line.strip().split(\',\')\n    if len(line) > 0:\n      returnArray.append(np.array([np.float32(x) for x in line]))\n\n  returnArray = np.array(returnArray)\n  return returnArray\n\n\ndef load_data(path_to_dataset, subjects, actions, one_hot):\n  """"""\n  Borrowed from SRNN code. This is how the SRNN code reads the provided .txt files\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/processdata.py#L270\n\n  Args\n    path_to_dataset: string. directory where the data resides\n    subjects: list of numbers. The subjects to load\n    actions: list of string. The actions to load\n    one_hot: Whether to add a one-hot encoding to the data\n  Returns\n    trainData: dictionary with k:v\n      k=(subject, action, subaction, \'even\'), v=(nxd) un-normalized data\n    completeData: nxd matrix with all the data. Used to normlization stats\n  """"""\n  nactions = len( actions )\n\n  trainData = {}\n  completeData = []\n  for subj in subjects:\n    for action_idx in np.arange(len(actions)):\n\n      action = actions[ action_idx ]\n\n      for subact in [1, 2]:  # subactions\n\n        print(""Reading subject {0}, action {1}, subaction {2}"".format(subj, action, subact))\n\n        filename = \'{0}/S{1}/{2}_{3}.txt\'.format( path_to_dataset, subj, action, subact)\n        action_sequence = readCSVasFloat(filename)\n\n        n, d = action_sequence.shape\n        even_list = range(0, n, 2)\n\n        if one_hot:\n          # Add a one-hot encoding at the end of the representation\n          the_sequence = np.zeros( (len(even_list), d + nactions), dtype=float )\n          the_sequence[ :, 0:d ] = action_sequence[even_list, :]\n          the_sequence[ :, d+action_idx ] = 1\n          trainData[(subj, action, subact, \'even\')] = the_sequence\n        else:\n          trainData[(subj, action, subact, \'even\')] = action_sequence[even_list, :]\n\n\n        if len(completeData) == 0:\n          completeData = copy.deepcopy(action_sequence)\n        else:\n          completeData = np.append(completeData, action_sequence, axis=0)\n\n  return trainData, completeData\n\n\ndef normalize_data( data, data_mean, data_std, dim_to_use, actions, one_hot ):\n  """"""\n  Normalize input data by removing unused dimensions, subtracting the mean and\n  dividing by the standard deviation\n\n  Args\n    data: nx99 matrix with data to normalize\n    data_mean: vector of mean used to normalize the data\n    data_std: vector of standard deviation used to normalize the data\n    dim_to_use: vector with dimensions used by the model\n    actions: list of strings with the encoded actions\n    one_hot: whether the data comes with one-hot encoding\n  Returns\n    data_out: the passed data matrix, but normalized\n  """"""\n  data_out = {}\n  nactions = len(actions)\n\n  if not one_hot:\n    # No one-hot encoding... no need to do anything special\n    for key in data.keys():\n      data_out[ key ] = np.divide( (data[key] - data_mean), data_std )\n      data_out[ key ] = data_out[ key ][ :, dim_to_use ]\n\n  else:\n    # TODO hard-coding 99 dimensions for un-normalized human poses\n    for key in data.keys():\n      data_out[ key ] = np.divide( (data[key][:, 0:99] - data_mean), data_std )\n      data_out[ key ] = data_out[ key ][ :, dim_to_use ]\n      data_out[ key ] = np.hstack( (data_out[key], data[key][:,-nactions:]) )\n\n  return data_out\n\n\ndef normalization_stats(completeData):\n  """"""""\n  Also borrowed for SRNN code. Computes mean, stdev and dimensions to ignore.\n  https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/processdata.py#L33\n\n  Args\n    completeData: nx99 matrix with data to normalize\n  Returns\n    data_mean: vector of mean used to normalize the data\n    data_std: vector of standard deviation used to normalize the data\n    dimensions_to_ignore: vector with dimensions not used by the model\n    dimensions_to_use: vector with dimensions used by the model\n  """"""\n  data_mean = np.mean(completeData, axis=0)\n  data_std  =  np.std(completeData, axis=0)\n\n  dimensions_to_ignore = []\n  dimensions_to_use    = []\n\n  dimensions_to_ignore.extend( list(np.where(data_std < 1e-4)[0]) )\n  dimensions_to_use.extend( list(np.where(data_std >= 1e-4)[0]) )\n\n  data_std[dimensions_to_ignore] = 1.0\n\n  return data_mean, data_std, dimensions_to_ignore, dimensions_to_use\n'"
src/forward_kinematics.py,0,"b'from __future__ import division\n\nimport numpy as np\nimport h5py\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom mpl_toolkits.mplot3d import Axes3D\nimport viz\nimport time\nimport copy\nimport data_utils\n\ndef fkl( angles, parent, offset, rotInd, expmapInd ):\n  """"""\n  Convert joint angles and bone lenghts into the 3d points of a person.\n  Based on expmap2xyz.m, available at\n  https://github.com/asheshjain399/RNNexp/blob/7fc5a53292dc0f232867beb66c3a9ef845d705cb/structural_rnn/CRFProblems/H3.6m/mhmublv/Motion/exp2xyz.m\n\n  Args\n    angles: 99-long vector with 3d position and 3d joint angles in expmap format\n    parent: 32-long vector with parent-child relationships in the kinematic tree\n    offset: 96-long vector with bone lenghts\n    rotInd: 32-long list with indices into angles\n    expmapInd: 32-long list with indices into expmap angles\n  Returns\n    xyz: 32x3 3d points that represent a person in 3d space\n  """"""\n\n  assert len(angles) == 99\n\n  # Structure that indicates parents for each joint\n  njoints   = 32\n  xyzStruct = [dict() for x in range(njoints)]\n\n  for i in np.arange( njoints ):\n\n    if not rotInd[i] : # If the list is empty\n      xangle, yangle, zangle = 0, 0, 0\n    else:\n      xangle = angles[ rotInd[i][0]-1 ]\n      yangle = angles[ rotInd[i][1]-1 ]\n      zangle = angles[ rotInd[i][2]-1 ]\n\n    r = angles[ expmapInd[i] ]\n\n    thisRotation = data_utils.expmap2rotmat(r)\n    thisPosition = np.array([xangle, yangle, zangle])\n\n    if parent[i] == -1: # Root node\n      xyzStruct[i][\'rotation\'] = thisRotation\n      xyzStruct[i][\'xyz\']      = np.reshape(offset[i,:], (1,3)) + thisPosition\n    else:\n      xyzStruct[i][\'xyz\'] = (offset[i,:] + thisPosition).dot( xyzStruct[ parent[i] ][\'rotation\'] ) + xyzStruct[ parent[i] ][\'xyz\']\n      xyzStruct[i][\'rotation\'] = thisRotation.dot( xyzStruct[ parent[i] ][\'rotation\'] )\n\n  xyz = [xyzStruct[i][\'xyz\'] for i in range(njoints)]\n  xyz = np.array( xyz ).squeeze()\n  xyz = xyz[:,[0,2,1]]\n  # xyz = xyz[:,[2,0,1]]\n\n\n  return np.reshape( xyz, [-1] )\n\ndef revert_coordinate_space(channels, R0, T0):\n  """"""\n  Bring a series of poses to a canonical form so they are facing the camera when they start.\n  Adapted from\n  https://github.com/asheshjain399/RNNexp/blob/7fc5a53292dc0f232867beb66c3a9ef845d705cb/structural_rnn/CRFProblems/H3.6m/dataParser/Utils/revertCoordinateSpace.m\n\n  Args\n    channels: n-by-99 matrix of poses\n    R0: 3x3 rotation for the first frame\n    T0: 1x3 position for the first frame\n  Returns\n    channels_rec: The passed poses, but the first has T0 and R0, and the\n                  rest of the sequence is modified accordingly.\n  """"""\n  n, d = channels.shape\n\n  channels_rec = copy.copy(channels)\n  R_prev = R0\n  T_prev = T0\n  rootRotInd = np.arange(3,6)\n\n  # Loop through the passed posses\n  for ii in range(n):\n    R_diff = data_utils.expmap2rotmat( channels[ii, rootRotInd] )\n    R = R_diff.dot( R_prev )\n\n    channels_rec[ii, rootRotInd] = data_utils.rotmat2expmap(R)\n    T = T_prev + ((R_prev.T).dot( np.reshape(channels[ii,:3],[3,1]))).reshape(-1)\n    channels_rec[ii,:3] = T\n    T_prev = T\n    R_prev = R\n\n  return channels_rec\n\n\ndef _some_variables():\n  """"""\n  We define some variables that are useful to run the kinematic tree\n\n  Args\n    None\n  Returns\n    parent: 32-long vector with parent-child relationships in the kinematic tree\n    offset: 96-long vector with bone lenghts\n    rotInd: 32-long list with indices into angles\n    expmapInd: 32-long list with indices into expmap angles\n  """"""\n\n  parent = np.array([0, 1, 2, 3, 4, 5, 1, 7, 8, 9,10, 1,12,13,14,15,13,\n                    17,18,19,20,21,20,23,13,25,26,27,28,29,28,31])-1\n\n  offset = np.array([0.000000,0.000000,0.000000,-132.948591,0.000000,0.000000,0.000000,-442.894612,0.000000,0.000000,-454.206447,0.000000,0.000000,0.000000,162.767078,0.000000,0.000000,74.999437,132.948826,0.000000,0.000000,0.000000,-442.894413,0.000000,0.000000,-454.206590,0.000000,0.000000,0.000000,162.767426,0.000000,0.000000,74.999948,0.000000,0.100000,0.000000,0.000000,233.383263,0.000000,0.000000,257.077681,0.000000,0.000000,121.134938,0.000000,0.000000,115.002227,0.000000,0.000000,257.077681,0.000000,0.000000,151.034226,0.000000,0.000000,278.882773,0.000000,0.000000,251.733451,0.000000,0.000000,0.000000,0.000000,0.000000,0.000000,99.999627,0.000000,100.000188,0.000000,0.000000,0.000000,0.000000,0.000000,257.077681,0.000000,0.000000,151.031437,0.000000,0.000000,278.892924,0.000000,0.000000,251.728680,0.000000,0.000000,0.000000,0.000000,0.000000,0.000000,99.999888,0.000000,137.499922,0.000000,0.000000,0.000000,0.000000])\n  offset = offset.reshape(-1,3)\n\n  rotInd = [[5, 6, 4],\n            [8, 9, 7],\n            [11, 12, 10],\n            [14, 15, 13],\n            [17, 18, 16],\n            [],\n            [20, 21, 19],\n            [23, 24, 22],\n            [26, 27, 25],\n            [29, 30, 28],\n            [],\n            [32, 33, 31],\n            [35, 36, 34],\n            [38, 39, 37],\n            [41, 42, 40],\n            [],\n            [44, 45, 43],\n            [47, 48, 46],\n            [50, 51, 49],\n            [53, 54, 52],\n            [56, 57, 55],\n            [],\n            [59, 60, 58],\n            [],\n            [62, 63, 61],\n            [65, 66, 64],\n            [68, 69, 67],\n            [71, 72, 70],\n            [74, 75, 73],\n            [],\n            [77, 78, 76],\n            []]\n\n  expmapInd = np.split(np.arange(4,100)-1,32)\n\n  return parent, offset, rotInd, expmapInd\n\ndef main():\n\n  # Load all the data\n  parent, offset, rotInd, expmapInd = _some_variables()\n\n  # numpy implementation\n  with h5py.File( \'samples.h5\', \'r\' ) as h5f:\n    expmap_gt = h5f[\'expmap/gt/walking_0\'][:]\n    expmap_pred = h5f[\'expmap/preds/walking_0\'][:]\n\n  nframes_gt, nframes_pred = expmap_gt.shape[0], expmap_pred.shape[0]\n\n  # Put them together and revert the coordinate space\n  expmap_all = revert_coordinate_space( np.vstack((expmap_gt, expmap_pred)), np.eye(3), np.zeros(3) )\n  expmap_gt   = expmap_all[:nframes_gt,:]\n  expmap_pred = expmap_all[nframes_gt:,:]\n\n  # Compute 3d points for each frame\n  xyz_gt, xyz_pred = np.zeros((nframes_gt, 96)), np.zeros((nframes_pred, 96))\n  for i in range( nframes_gt ):\n    xyz_gt[i,:] = fkl( expmap_gt[i,:], parent, offset, rotInd, expmapInd )\n  for i in range( nframes_pred ):\n    xyz_pred[i,:] = fkl( expmap_pred[i,:], parent, offset, rotInd, expmapInd )\n\n  # === Plot and animate ===\n  fig = plt.figure()\n  ax = plt.gca(projection=\'3d\')\n  ob = viz.Ax3DPose(ax)\n\n  # Plot the conditioning ground truth\n  for i in range(nframes_gt):\n    ob.update( xyz_gt[i,:] )\n    plt.show(block=False)\n    fig.canvas.draw()\n    plt.pause(0.01)\n\n  # Plot the prediction\n  for i in range(nframes_pred):\n    ob.update( xyz_pred[i,:], lcolor=""#9b59b6"", rcolor=""#2ecc71"" )\n    plt.show(block=False)\n    fig.canvas.draw()\n    plt.pause(0.01)\n\n\nif __name__ == \'__main__\':\n  main()\n'"
src/rnn_cell_extensions.py,9,"b'\n"""""" Extensions to TF RNN class by una_dinosaria""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom tensorflow.contrib.rnn.python.ops.core_rnn_cell import RNNCell\n\n# The import for LSTMStateTuple changes in TF >= 1.2.0\nfrom pkg_resources import parse_version as pv\nif pv(tf.__version__) >= pv(\'1.2.0\'):\n  from tensorflow.contrib.rnn import LSTMStateTuple\nelse:\n  from tensorflow.contrib.rnn.python.ops.core_rnn_cell import LSTMStateTuple\ndel pv\n\nfrom tensorflow.python.ops import variable_scope as vs\n\nimport collections\nimport math\n\nclass ResidualWrapper(RNNCell):\n  """"""Operator adding residual connections to a given cell.""""""\n\n  def __init__(self, cell):\n    """"""Create a cell with added residual connection.\n\n    Args:\n      cell: an RNNCell. The input is added to the output.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n    """"""\n    if not isinstance(cell, RNNCell):\n      raise TypeError(""The parameter cell is not a RNNCell."")\n\n    self._cell = cell\n\n  @property\n  def state_size(self):\n    return self._cell.state_size\n\n  @property\n  def output_size(self):\n    return self._cell.output_size\n\n  def __call__(self, inputs, state, scope=None):\n    """"""Run the cell and add a residual connection.""""""\n\n    # Run the rnn as usual\n    output, new_state = self._cell(inputs, state, scope)\n\n    # Add the residual connection\n    output = tf.add(output, inputs)\n\n    return output, new_state\n\nclass LinearSpaceDecoderWrapper(RNNCell):\n  """"""Operator adding a linear encoder to an RNN cell""""""\n\n  def __init__(self, cell, output_size):\n    """"""Create a cell with with a linear encoder in space.\n\n    Args:\n      cell: an RNNCell. The input is passed through a linear layer.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n    """"""\n    if not isinstance(cell, RNNCell):\n      raise TypeError(""The parameter cell is not a RNNCell."")\n\n    self._cell = cell\n\n    print( \'output_size = {0}\'.format(output_size) )\n    print( \' state_size = {0}\'.format(self._cell.state_size) )\n\n    # Tuple if multi-rnn\n    if isinstance(self._cell.state_size,tuple):\n\n      # Fine if GRU...\n      insize = self._cell.state_size[-1]\n\n      # LSTMStateTuple if LSTM\n      if isinstance( insize, LSTMStateTuple ):\n        insize = insize.h\n\n    else:\n      # Fine if not multi-rnn\n      insize = self._cell.state_size\n\n    self.w_out = tf.get_variable(""proj_w_out"",\n        [insize, output_size],\n        dtype=tf.float32,\n        initializer=tf.random_uniform_initializer(minval=-0.04, maxval=0.04))\n    self.b_out = tf.get_variable(""proj_b_out"", [output_size],\n        dtype=tf.float32,\n        initializer=tf.random_uniform_initializer(minval=-0.04, maxval=0.04))\n\n    self.linear_output_size = output_size\n\n\n  @property\n  def state_size(self):\n    return self._cell.state_size\n\n  @property\n  def output_size(self):\n    return self.linear_output_size\n\n  def __call__(self, inputs, state, scope=None):\n    """"""Use a linear layer and pass the output to the cell.""""""\n\n    # Run the rnn as usual\n    output, new_state = self._cell(inputs, state, scope)\n\n    # Apply the multiplication to everything\n    output = tf.matmul(output, self.w_out) + self.b_out\n\n    return output, new_state\n'"
src/seq2seq_model.py,227,"b'\n""""""Sequence-to-sequence model for human motion prediction.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import variable_scope as vs\n\nimport random\n\nimport numpy as np\nimport os\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\nimport rnn_cell_extensions # my extensions of the tf repos\nimport data_utils\n\nclass Seq2SeqModel(object):\n  """"""Sequence-to-sequence model for human motion prediction""""""\n\n  def __init__(self,\n               architecture,\n               source_seq_len,\n               target_seq_len,\n               rnn_size, # hidden recurrent layer size\n               num_layers,\n               max_gradient_norm,\n               batch_size,\n               learning_rate,\n               learning_rate_decay_factor,\n               summaries_dir,\n               loss_to_use,\n               number_of_actions,\n               one_hot=True,\n               residual_velocities=False,\n               dtype=tf.float32):\n    """"""Create the model.\n\n    Args:\n      architecture: [basic, tied] whether to tie the decoder and decoder.\n      source_seq_len: lenght of the input sequence.\n      target_seq_len: lenght of the target sequence.\n      rnn_size: number of units in the rnn.\n      num_layers: number of rnns to stack.\n      max_gradient_norm: gradients will be clipped to maximally this norm.\n      batch_size: the size of the batches used during training;\n        the model construction is independent of batch_size, so it can be\n        changed after initialization if this is convenient, e.g., for decoding.\n      learning_rate: learning rate to start with.\n      learning_rate_decay_factor: decay learning rate by this much when needed.\n      summaries_dir: where to log progress for tensorboard.\n      loss_to_use: [supervised, sampling_based]. Whether to use ground truth in\n        each timestep to compute the loss after decoding, or to feed back the\n        prediction from the previous time-step.\n      number_of_actions: number of classes we have.\n      one_hot: whether to use one_hot encoding during train/test (sup models).\n      residual_velocities: whether to use a residual connection that models velocities.\n      dtype: the data type to use to store internal variables.\n    """"""\n\n    self.HUMAN_SIZE = 54\n    self.input_size = self.HUMAN_SIZE + number_of_actions if one_hot else self.HUMAN_SIZE\n\n    print( ""One hot is "", one_hot )\n    print( ""Input size is %d"" % self.input_size )\n\n    # Summary writers for train and test runs\n    self.train_writer = tf.summary.FileWriter(os.path.normpath(os.path.join( summaries_dir, \'train\')))\n    self.test_writer  = tf.summary.FileWriter(os.path.normpath(os.path.join( summaries_dir, \'test\')))\n\n    self.source_seq_len = source_seq_len\n    self.target_seq_len = target_seq_len\n    self.rnn_size = rnn_size\n    self.batch_size = batch_size\n    self.learning_rate = tf.Variable( float(learning_rate), trainable=False, dtype=dtype )\n    self.learning_rate_decay_op = self.learning_rate.assign( self.learning_rate * learning_rate_decay_factor )\n    self.global_step = tf.Variable(0, trainable=False)\n\n    # === Create the RNN that will keep the state ===\n    print(\'rnn_size = {0}\'.format( rnn_size ))\n    cell = tf.contrib.rnn.GRUCell( self.rnn_size )\n\n    if num_layers > 1:\n      cell = tf.contrib.rnn.MultiRNNCell( [tf.contrib.rnn.GRUCell(self.rnn_size) for _ in range(num_layers)] )\n\n    # === Transform the inputs ===\n    with tf.name_scope(""inputs""):\n\n      enc_in = tf.placeholder(dtype, shape=[None, source_seq_len-1, self.input_size], name=""enc_in"")\n      dec_in = tf.placeholder(dtype, shape=[None, target_seq_len, self.input_size], name=""dec_in"")\n      dec_out = tf.placeholder(dtype, shape=[None, target_seq_len, self.input_size], name=""dec_out"")\n\n      self.encoder_inputs = enc_in\n      self.decoder_inputs = dec_in\n      self.decoder_outputs = dec_out\n\n      enc_in = tf.transpose(enc_in, [1, 0, 2])\n      dec_in = tf.transpose(dec_in, [1, 0, 2])\n      dec_out = tf.transpose(dec_out, [1, 0, 2])\n\n      enc_in = tf.reshape(enc_in, [-1, self.input_size])\n      dec_in = tf.reshape(dec_in, [-1, self.input_size])\n      dec_out = tf.reshape(dec_out, [-1, self.input_size])\n\n      enc_in = tf.split(enc_in, source_seq_len-1, axis=0)\n      dec_in = tf.split(dec_in, target_seq_len, axis=0)\n      dec_out = tf.split(dec_out, target_seq_len, axis=0)\n\n    # === Add space decoder ===\n    cell = rnn_cell_extensions.LinearSpaceDecoderWrapper( cell, self.input_size )\n\n    # Finally, wrap everything in a residual layer if we want to model velocities\n    if residual_velocities:\n      cell = rnn_cell_extensions.ResidualWrapper( cell )\n\n    # Store the outputs here\n    outputs  = []\n\n    # Define the loss function\n    lf = None\n    if loss_to_use == ""sampling_based"":\n      def lf(prev, i): # function for sampling_based loss\n        return prev\n    elif loss_to_use == ""supervised"":\n      pass\n    else:\n      raise(ValueError, ""unknown loss: %s"" % loss_to_use)\n\n    # Build the RNN\n    if architecture == ""basic"":\n      # Basic RNN does not have a loop function in its API, so copying here.\n      with vs.variable_scope(""basic_rnn_seq2seq""):\n        _, enc_state = tf.contrib.rnn.static_rnn(cell, enc_in, dtype=tf.float32) # Encoder\n        outputs, self.states = tf.contrib.legacy_seq2seq.rnn_decoder( dec_in, enc_state, cell, loop_function=lf ) # Decoder\n    elif architecture == ""tied"":\n      outputs, self.states = tf.contrib.legacy_seq2seq.tied_rnn_seq2seq( enc_in, dec_in, cell, loop_function=lf )\n    else:\n      raise(ValueError, ""Uknown architecture: %s"" % architecture )\n\n    self.outputs = outputs\n\n    with tf.name_scope(""loss_angles""):\n      loss_angles = tf.reduce_mean(tf.square(tf.subtract(dec_out, outputs)))\n\n    self.loss         = loss_angles\n    self.loss_summary = tf.summary.scalar(\'loss/loss\', self.loss)\n\n    # Gradients and SGD update operation for training the model.\n    params = tf.trainable_variables()\n\n    opt = tf.train.GradientDescentOptimizer( self.learning_rate )\n\n    # Update all the trainable parameters\n    gradients = tf.gradients( self.loss, params )\n\n    clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient_norm)\n    self.gradient_norms = norm\n    self.updates = opt.apply_gradients(\n      zip(clipped_gradients, params), global_step=self.global_step)\n\n    # Keep track of the learning rate\n    self.learning_rate_summary = tf.summary.scalar(\'learning_rate/learning_rate\', self.learning_rate)\n\n    # === variables for loss in Euler Angles -- for each action\n    with tf.name_scope( ""euler_error_walking"" ):\n      self.walking_err80   = tf.placeholder( tf.float32, name=""walking_srnn_seeds_0080"" )\n      self.walking_err160  = tf.placeholder( tf.float32, name=""walking_srnn_seeds_0160"" )\n      self.walking_err320  = tf.placeholder( tf.float32, name=""walking_srnn_seeds_0320"" )\n      self.walking_err400  = tf.placeholder( tf.float32, name=""walking_srnn_seeds_0400"" )\n      self.walking_err560  = tf.placeholder( tf.float32, name=""walking_srnn_seeds_0560"" )\n      self.walking_err1000 = tf.placeholder( tf.float32, name=""walking_srnn_seeds_1000"" )\n\n      self.walking_err80_summary   = tf.summary.scalar( \'euler_error_walking/srnn_seeds_0080\', self.walking_err80 )\n      self.walking_err160_summary  = tf.summary.scalar( \'euler_error_walking/srnn_seeds_0160\', self.walking_err160 )\n      self.walking_err320_summary  = tf.summary.scalar( \'euler_error_walking/srnn_seeds_0320\', self.walking_err320 )\n      self.walking_err400_summary  = tf.summary.scalar( \'euler_error_walking/srnn_seeds_0400\', self.walking_err400 )\n      self.walking_err560_summary  = tf.summary.scalar( \'euler_error_walking/srnn_seeds_0560\', self.walking_err560 )\n      self.walking_err1000_summary = tf.summary.scalar( \'euler_error_walking/srnn_seeds_1000\', self.walking_err1000 )\n    with tf.name_scope( ""euler_error_eating"" ):\n      self.eating_err80   = tf.placeholder( tf.float32, name=""eating_srnn_seeds_0080"" )\n      self.eating_err160  = tf.placeholder( tf.float32, name=""eating_srnn_seeds_0160"" )\n      self.eating_err320  = tf.placeholder( tf.float32, name=""eating_srnn_seeds_0320"" )\n      self.eating_err400  = tf.placeholder( tf.float32, name=""eating_srnn_seeds_0400"" )\n      self.eating_err560  = tf.placeholder( tf.float32, name=""eating_srnn_seeds_0560"" )\n      self.eating_err1000 = tf.placeholder( tf.float32, name=""eating_srnn_seeds_1000"" )\n\n      self.eating_err80_summary   = tf.summary.scalar( \'euler_error_eating/srnn_seeds_0080\', self.eating_err80 )\n      self.eating_err160_summary  = tf.summary.scalar( \'euler_error_eating/srnn_seeds_0160\', self.eating_err160 )\n      self.eating_err320_summary  = tf.summary.scalar( \'euler_error_eating/srnn_seeds_0320\', self.eating_err320 )\n      self.eating_err400_summary  = tf.summary.scalar( \'euler_error_eating/srnn_seeds_0400\', self.eating_err400 )\n      self.eating_err560_summary  = tf.summary.scalar( \'euler_error_eating/srnn_seeds_0560\', self.eating_err560 )\n      self.eating_err1000_summary = tf.summary.scalar( \'euler_error_eating/srnn_seeds_1000\', self.eating_err1000 )\n    with tf.name_scope( ""euler_error_smoking"" ):\n      self.smoking_err80   = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_0080"" )\n      self.smoking_err160  = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_0160"" )\n      self.smoking_err320  = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_0320"" )\n      self.smoking_err400  = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_0400"" )\n      self.smoking_err560  = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_0560"" )\n      self.smoking_err1000 = tf.placeholder( tf.float32, name=""smoking_srnn_seeds_1000"" )\n\n      self.smoking_err80_summary   = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_0080\', self.smoking_err80 )\n      self.smoking_err160_summary  = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_0160\', self.smoking_err160 )\n      self.smoking_err320_summary  = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_0320\', self.smoking_err320 )\n      self.smoking_err400_summary  = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_0400\', self.smoking_err400 )\n      self.smoking_err560_summary  = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_0560\', self.smoking_err560 )\n      self.smoking_err1000_summary = tf.summary.scalar( \'euler_error_smoking/srnn_seeds_1000\', self.smoking_err1000 )\n    with tf.name_scope( ""euler_error_discussion"" ):\n      self.discussion_err80   = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_0080"" )\n      self.discussion_err160  = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_0160"" )\n      self.discussion_err320  = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_0320"" )\n      self.discussion_err400  = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_0400"" )\n      self.discussion_err560  = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_0560"" )\n      self.discussion_err1000 = tf.placeholder( tf.float32, name=""discussion_srnn_seeds_1000"" )\n\n      self.discussion_err80_summary   = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_0080\', self.discussion_err80 )\n      self.discussion_err160_summary  = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_0160\', self.discussion_err160 )\n      self.discussion_err320_summary  = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_0320\', self.discussion_err320 )\n      self.discussion_err400_summary  = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_0400\', self.discussion_err400 )\n      self.discussion_err560_summary  = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_0560\', self.discussion_err560 )\n      self.discussion_err1000_summary = tf.summary.scalar( \'euler_error_discussion/srnn_seeds_1000\', self.discussion_err1000 )\n    with tf.name_scope( ""euler_error_directions"" ):\n      self.directions_err80   = tf.placeholder( tf.float32, name=""directions_srnn_seeds_0080"" )\n      self.directions_err160  = tf.placeholder( tf.float32, name=""directions_srnn_seeds_0160"" )\n      self.directions_err320  = tf.placeholder( tf.float32, name=""directions_srnn_seeds_0320"" )\n      self.directions_err400  = tf.placeholder( tf.float32, name=""directions_srnn_seeds_0400"" )\n      self.directions_err560  = tf.placeholder( tf.float32, name=""directions_srnn_seeds_0560"" )\n      self.directions_err1000 = tf.placeholder( tf.float32, name=""directions_srnn_seeds_1000"" )\n\n      self.directions_err80_summary   = tf.summary.scalar( \'euler_error_directions/srnn_seeds_0080\', self.directions_err80 )\n      self.directions_err160_summary  = tf.summary.scalar( \'euler_error_directions/srnn_seeds_0160\', self.directions_err160 )\n      self.directions_err320_summary  = tf.summary.scalar( \'euler_error_directions/srnn_seeds_0320\', self.directions_err320 )\n      self.directions_err400_summary  = tf.summary.scalar( \'euler_error_directions/srnn_seeds_0400\', self.directions_err400 )\n      self.directions_err560_summary  = tf.summary.scalar( \'euler_error_directions/srnn_seeds_0560\', self.directions_err560 )\n      self.directions_err1000_summary = tf.summary.scalar( \'euler_error_directions/srnn_seeds_1000\', self.directions_err1000 )\n    with tf.name_scope( ""euler_error_greeting"" ):\n      self.greeting_err80   = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_0080"" )\n      self.greeting_err160  = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_0160"" )\n      self.greeting_err320  = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_0320"" )\n      self.greeting_err400  = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_0400"" )\n      self.greeting_err560  = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_0560"" )\n      self.greeting_err1000 = tf.placeholder( tf.float32, name=""greeting_srnn_seeds_1000"" )\n\n      self.greeting_err80_summary   = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_0080\', self.greeting_err80 )\n      self.greeting_err160_summary  = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_0160\', self.greeting_err160 )\n      self.greeting_err320_summary  = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_0320\', self.greeting_err320 )\n      self.greeting_err400_summary  = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_0400\', self.greeting_err400 )\n      self.greeting_err560_summary  = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_0560\', self.greeting_err560 )\n      self.greeting_err1000_summary = tf.summary.scalar( \'euler_error_greeting/srnn_seeds_1000\', self.greeting_err1000 )\n    with tf.name_scope( ""euler_error_phoning"" ):\n      self.phoning_err80   = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_0080"" )\n      self.phoning_err160  = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_0160"" )\n      self.phoning_err320  = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_0320"" )\n      self.phoning_err400  = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_0400"" )\n      self.phoning_err560  = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_0560"" )\n      self.phoning_err1000 = tf.placeholder( tf.float32, name=""phoning_srnn_seeds_1000"" )\n\n      self.phoning_err80_summary   = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_0080\', self.phoning_err80 )\n      self.phoning_err160_summary  = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_0160\', self.phoning_err160 )\n      self.phoning_err320_summary  = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_0320\', self.phoning_err320 )\n      self.phoning_err400_summary  = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_0400\', self.phoning_err400 )\n      self.phoning_err560_summary  = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_0560\', self.phoning_err560 )\n      self.phoning_err1000_summary = tf.summary.scalar( \'euler_error_phoning/srnn_seeds_1000\', self.phoning_err1000 )\n    with tf.name_scope( ""euler_error_posing"" ):\n      self.posing_err80   = tf.placeholder( tf.float32, name=""posing_srnn_seeds_0080"" )\n      self.posing_err160  = tf.placeholder( tf.float32, name=""posing_srnn_seeds_0160"" )\n      self.posing_err320  = tf.placeholder( tf.float32, name=""posing_srnn_seeds_0320"" )\n      self.posing_err400  = tf.placeholder( tf.float32, name=""posing_srnn_seeds_0400"" )\n      self.posing_err560  = tf.placeholder( tf.float32, name=""posing_srnn_seeds_0560"" )\n      self.posing_err1000 = tf.placeholder( tf.float32, name=""posing_srnn_seeds_1000"" )\n\n      self.posing_err80_summary   = tf.summary.scalar( \'euler_error_posing/srnn_seeds_0080\', self.posing_err80 )\n      self.posing_err160_summary  = tf.summary.scalar( \'euler_error_posing/srnn_seeds_0160\', self.posing_err160 )\n      self.posing_err320_summary  = tf.summary.scalar( \'euler_error_posing/srnn_seeds_0320\', self.posing_err320 )\n      self.posing_err400_summary  = tf.summary.scalar( \'euler_error_posing/srnn_seeds_0400\', self.posing_err400 )\n      self.posing_err560_summary  = tf.summary.scalar( \'euler_error_posing/srnn_seeds_0560\', self.posing_err560 )\n      self.posing_err1000_summary = tf.summary.scalar( \'euler_error_posing/srnn_seeds_1000\', self.posing_err1000 )\n    with tf.name_scope( ""euler_error_purchases"" ):\n      self.purchases_err80   = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_0080"" )\n      self.purchases_err160  = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_0160"" )\n      self.purchases_err320  = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_0320"" )\n      self.purchases_err400  = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_0400"" )\n      self.purchases_err560  = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_0560"" )\n      self.purchases_err1000 = tf.placeholder( tf.float32, name=""purchases_srnn_seeds_1000"" )\n\n      self.purchases_err80_summary   = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_0080\', self.purchases_err80 )\n      self.purchases_err160_summary  = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_0160\', self.purchases_err160 )\n      self.purchases_err320_summary  = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_0320\', self.purchases_err320 )\n      self.purchases_err400_summary  = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_0400\', self.purchases_err400 )\n      self.purchases_err560_summary  = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_0560\', self.purchases_err560 )\n      self.purchases_err1000_summary = tf.summary.scalar( \'euler_error_purchases/srnn_seeds_1000\', self.purchases_err1000 )\n    with tf.name_scope( ""euler_error_sitting"" ):\n      self.sitting_err80   = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_0080"" )\n      self.sitting_err160  = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_0160"" )\n      self.sitting_err320  = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_0320"" )\n      self.sitting_err400  = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_0400"" )\n      self.sitting_err560  = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_0560"" )\n      self.sitting_err1000 = tf.placeholder( tf.float32, name=""sitting_srnn_seeds_1000"" )\n\n      self.sitting_err80_summary   = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_0080\', self.sitting_err80 )\n      self.sitting_err160_summary  = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_0160\', self.sitting_err160 )\n      self.sitting_err320_summary  = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_0320\', self.sitting_err320 )\n      self.sitting_err400_summary  = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_0400\', self.sitting_err400 )\n      self.sitting_err560_summary  = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_0560\', self.sitting_err560 )\n      self.sitting_err1000_summary = tf.summary.scalar( \'euler_error_sitting/srnn_seeds_1000\', self.sitting_err1000 )\n    with tf.name_scope( ""euler_error_sittingdown"" ):\n      self.sittingdown_err80   = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_0080"" )\n      self.sittingdown_err160  = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_0160"" )\n      self.sittingdown_err320  = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_0320"" )\n      self.sittingdown_err400  = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_0400"" )\n      self.sittingdown_err560  = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_0560"" )\n      self.sittingdown_err1000 = tf.placeholder( tf.float32, name=""sittingdown_srnn_seeds_1000"" )\n\n      self.sittingdown_err80_summary   = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_0080\', self.sittingdown_err80 )\n      self.sittingdown_err160_summary  = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_0160\', self.sittingdown_err160 )\n      self.sittingdown_err320_summary  = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_0320\', self.sittingdown_err320 )\n      self.sittingdown_err400_summary  = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_0400\', self.sittingdown_err400 )\n      self.sittingdown_err560_summary  = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_0560\', self.sittingdown_err560 )\n      self.sittingdown_err1000_summary = tf.summary.scalar( \'euler_error_sittingdown/srnn_seeds_1000\', self.sittingdown_err1000 )\n    with tf.name_scope( ""euler_error_takingphoto"" ):\n      self.takingphoto_err80   = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_0080"" )\n      self.takingphoto_err160  = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_0160"" )\n      self.takingphoto_err320  = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_0320"" )\n      self.takingphoto_err400  = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_0400"" )\n      self.takingphoto_err560  = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_0560"" )\n      self.takingphoto_err1000 = tf.placeholder( tf.float32, name=""takingphoto_srnn_seeds_1000"" )\n\n      self.takingphoto_err80_summary   = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_0080\', self.takingphoto_err80 )\n      self.takingphoto_err160_summary  = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_0160\', self.takingphoto_err160 )\n      self.takingphoto_err320_summary  = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_0320\', self.takingphoto_err320 )\n      self.takingphoto_err400_summary  = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_0400\', self.takingphoto_err400 )\n      self.takingphoto_err560_summary  = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_0560\', self.takingphoto_err560 )\n      self.takingphoto_err1000_summary = tf.summary.scalar( \'euler_error_takingphoto/srnn_seeds_1000\', self.takingphoto_err1000 )\n    with tf.name_scope( ""euler_error_waiting"" ):\n      self.waiting_err80   = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_0080"" )\n      self.waiting_err160  = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_0160"" )\n      self.waiting_err320  = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_0320"" )\n      self.waiting_err400  = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_0400"" )\n      self.waiting_err560  = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_0560"" )\n      self.waiting_err1000 = tf.placeholder( tf.float32, name=""waiting_srnn_seeds_1000"" )\n\n      self.waiting_err80_summary   = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_0080\', self.waiting_err80 )\n      self.waiting_err160_summary  = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_0160\', self.waiting_err160 )\n      self.waiting_err320_summary  = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_0320\', self.waiting_err320 )\n      self.waiting_err400_summary  = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_0400\', self.waiting_err400 )\n      self.waiting_err560_summary  = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_0560\', self.waiting_err560 )\n      self.waiting_err1000_summary = tf.summary.scalar( \'euler_error_waiting/srnn_seeds_1000\', self.waiting_err1000 )\n    with tf.name_scope( ""euler_error_walkingdog"" ):\n      self.walkingdog_err80   = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_0080"" )\n      self.walkingdog_err160  = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_0160"" )\n      self.walkingdog_err320  = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_0320"" )\n      self.walkingdog_err400  = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_0400"" )\n      self.walkingdog_err560  = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_0560"" )\n      self.walkingdog_err1000 = tf.placeholder( tf.float32, name=""walkingdog_srnn_seeds_1000"" )\n\n      self.walkingdog_err80_summary   = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_0080\', self.walkingdog_err80 )\n      self.walkingdog_err160_summary  = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_0160\', self.walkingdog_err160 )\n      self.walkingdog_err320_summary  = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_0320\', self.walkingdog_err320 )\n      self.walkingdog_err400_summary  = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_0400\', self.walkingdog_err400 )\n      self.walkingdog_err560_summary  = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_0560\', self.walkingdog_err560 )\n      self.walkingdog_err1000_summary = tf.summary.scalar( \'euler_error_walkingdog/srnn_seeds_1000\', self.walkingdog_err1000 )\n    with tf.name_scope( ""euler_error_walkingtogether"" ):\n      self.walkingtogether_err80   = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_0080"" )\n      self.walkingtogether_err160  = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_0160"" )\n      self.walkingtogether_err320  = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_0320"" )\n      self.walkingtogether_err400  = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_0400"" )\n      self.walkingtogether_err560  = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_0560"" )\n      self.walkingtogether_err1000 = tf.placeholder( tf.float32, name=""walkingtogether_srnn_seeds_1000"" )\n\n      self.walkingtogether_err80_summary   = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_0080\', self.walkingtogether_err80 )\n      self.walkingtogether_err160_summary  = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_0160\', self.walkingtogether_err160 )\n      self.walkingtogether_err320_summary  = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_0320\', self.walkingtogether_err320 )\n      self.walkingtogether_err400_summary  = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_0400\', self.walkingtogether_err400 )\n      self.walkingtogether_err560_summary  = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_0560\', self.walkingtogether_err560 )\n      self.walkingtogether_err1000_summary = tf.summary.scalar( \'euler_error_walkingtogether/srnn_seeds_1000\', self.walkingtogether_err1000 )\n\n    self.saver = tf.train.Saver( tf.global_variables(), max_to_keep=10 )\n\n  def step(self, session, encoder_inputs, decoder_inputs, decoder_outputs,\n             forward_only, srnn_seeds=False ):\n    """"""Run a step of the model feeding the given inputs.\n\n    Args\n      session: tensorflow session to use.\n      encoder_inputs: list of numpy vectors to feed as encoder inputs.\n      decoder_inputs: list of numpy vectors to feed as decoder inputs.\n      decoder_outputs: list of numpy vectors that are the expected decoder outputs.\n      forward_only: whether to do the backward step or only forward.\n      srnn_seeds: True if you want to evaluate using the sequences of SRNN\n    Returns\n      A triple consisting of gradient norm (or None if we did not do backward),\n      mean squared error, and the outputs.\n    Raises\n      ValueError: if length of encoder_inputs, decoder_inputs, or\n        target_weights disagrees with bucket size for the specified bucket_id.\n    """"""\n    input_feed = {self.encoder_inputs: encoder_inputs,\n                  self.decoder_inputs: decoder_inputs,\n                  self.decoder_outputs: decoder_outputs}\n\n    # Output feed: depends on whether we do a backward step or not.\n    if not srnn_seeds:\n      if not forward_only:\n\n        # Training step\n        output_feed = [self.updates,         # Update Op that does SGD.\n                       self.gradient_norms,  # Gradient norm.\n                       self.loss,\n                       self.loss_summary,\n                       self.learning_rate_summary]\n\n        outputs = session.run( output_feed, input_feed )\n        return outputs[1], outputs[2], outputs[3], outputs[4]  # Gradient norm, loss, summaries\n\n      else:\n        # Validation step, not on SRNN\'s seeds\n        output_feed = [self.loss, # Loss for this batch.\n                       self.loss_summary]\n\n        outputs = session.run(output_feed, input_feed)\n        return outputs[0], outputs[1]  # No gradient norm\n    else:\n      # Validation on SRNN\'s seeds\n      output_feed = [self.loss, # Loss for this batch.\n                     self.outputs,\n                     self.loss_summary]\n\n      outputs = session.run(output_feed, input_feed)\n\n      return outputs[0], outputs[1], outputs[2]  # No gradient norm, loss, outputs.\n\n\n\n  def get_batch( self, data, actions ):\n    """"""Get a random batch of data from the specified bucket, prepare for step.\n\n    Args\n      data: a list of sequences of size n-by-d to fit the model to.\n      actions: a list of the actions we are using\n    Returns\n      The tuple (encoder_inputs, decoder_inputs, decoder_outputs);\n      the constructed batches have the proper format to call step(...) later.\n    """"""\n\n    # Select entries at random\n    all_keys    = list(data.keys())\n    chosen_keys = np.random.choice( len(all_keys), self.batch_size )\n\n    # How many frames in total do we need?\n    total_frames = self.source_seq_len + self.target_seq_len\n\n    encoder_inputs  = np.zeros((self.batch_size, self.source_seq_len-1, self.input_size), dtype=float)\n    decoder_inputs  = np.zeros((self.batch_size, self.target_seq_len, self.input_size), dtype=float)\n    decoder_outputs = np.zeros((self.batch_size, self.target_seq_len, self.input_size), dtype=float)\n\n    for i in xrange( self.batch_size ):\n\n      the_key = all_keys[ chosen_keys[i] ]\n\n      # Get the number of frames\n      n, _ = data[ the_key ].shape\n\n      # Sample somewherein the middle\n      idx = np.random.randint( 16, n-total_frames )\n\n      # Select the data around the sampled points\n      data_sel = data[ the_key ][idx:idx+total_frames ,:]\n\n      # Add the data\n      encoder_inputs[i,:,0:self.input_size]  = data_sel[0:self.source_seq_len-1, :]\n      decoder_inputs[i,:,0:self.input_size]  = data_sel[self.source_seq_len-1:self.source_seq_len+self.target_seq_len-1, :]\n      decoder_outputs[i,:,0:self.input_size] = data_sel[self.source_seq_len:, 0:self.input_size]\n\n    return encoder_inputs, decoder_inputs, decoder_outputs\n\n\n  def find_indices_srnn( self, data, action ):\n    """"""\n    Find the same action indices as in SRNN.\n    See https://github.com/asheshjain399/RNNexp/blob/master/structural_rnn/CRFProblems/H3.6m/processdata.py#L325\n    """"""\n\n    # Used a fixed dummy seed, following\n    # https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/forecastTrajectories.py#L29\n    SEED = 1234567890\n    rng = np.random.RandomState( SEED )\n\n    subject = 5\n    subaction1 = 1\n    subaction2 = 2\n\n    T1 = data[ (subject, action, subaction1, \'even\') ].shape[0]\n    T2 = data[ (subject, action, subaction2, \'even\') ].shape[0]\n    prefix, suffix = 50, 100\n\n    idx = []\n    idx.append( rng.randint( 16,T1-prefix-suffix ))\n    idx.append( rng.randint( 16,T2-prefix-suffix ))\n    idx.append( rng.randint( 16,T1-prefix-suffix ))\n    idx.append( rng.randint( 16,T2-prefix-suffix ))\n    idx.append( rng.randint( 16,T1-prefix-suffix ))\n    idx.append( rng.randint( 16,T2-prefix-suffix ))\n    idx.append( rng.randint( 16,T1-prefix-suffix ))\n    idx.append( rng.randint( 16,T2-prefix-suffix ))\n    return idx\n\n  def get_batch_srnn(self, data, action ):\n    """"""\n    Get a random batch of data from the specified bucket, prepare for step.\n\n    Args\n      data: dictionary with k:v, k=((subject, action, subsequence, \'even\')),\n        v=nxd matrix with a sequence of poses\n      action: the action to load data from\n    Returns\n      The tuple (encoder_inputs, decoder_inputs, decoder_outputs);\n      the constructed batches have the proper format to call step(...) later.\n    """"""\n\n    actions = [""directions"", ""discussion"", ""eating"", ""greeting"", ""phoning"",\n              ""posing"", ""purchases"", ""sitting"", ""sittingdown"", ""smoking"",\n              ""takingphoto"", ""waiting"", ""walking"", ""walkingdog"", ""walkingtogether""]\n\n    if not action in actions:\n      raise ValueError(""Unrecognized action {0}"".format(action))\n\n    frames = {}\n    frames[ action ] = self.find_indices_srnn( data, action )\n\n    batch_size = 8 # we always evaluate 8 seeds\n    subject    = 5 # we always evaluate on subject 5\n    source_seq_len = self.source_seq_len\n    target_seq_len = self.target_seq_len\n\n    seeds = [( action, (i%2)+1, frames[action][i] ) for i in range(batch_size)]\n\n    encoder_inputs  = np.zeros( (batch_size, source_seq_len-1, self.input_size), dtype=float )\n    decoder_inputs  = np.zeros( (batch_size, target_seq_len, self.input_size), dtype=float )\n    decoder_outputs = np.zeros( (batch_size, target_seq_len, self.input_size), dtype=float )\n\n    # Compute the number of frames needed\n    total_frames = source_seq_len + target_seq_len\n\n    # Reproducing SRNN\'s sequence subsequence selection as done in\n    # https://github.com/asheshjain399/RNNexp/blob/master/structural_rnn/CRFProblems/H3.6m/processdata.py#L343\n    for i in xrange( batch_size ):\n\n      _, subsequence, idx = seeds[i]\n      idx = idx + 50\n\n      data_sel = data[ (subject, action, subsequence, \'even\') ]\n\n      data_sel = data_sel[(idx-source_seq_len):(idx+target_seq_len) ,:]\n\n      encoder_inputs[i, :, :]  = data_sel[0:source_seq_len-1, :]\n      decoder_inputs[i, :, :]  = data_sel[source_seq_len-1:(source_seq_len+target_seq_len-1), :]\n      decoder_outputs[i, :, :] = data_sel[source_seq_len:, :]\n\n\n    return encoder_inputs, decoder_inputs, decoder_outputs\n'"
src/translate.py,30,"b'\n""""""Simple code for training an RNN for motion prediction.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport os\nimport random\nimport sys\nimport time\nimport h5py\n\nimport numpy as np\nfrom six.moves import xrange # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nimport data_utils\nimport seq2seq_model\n\n# Learning\ntf.app.flags.DEFINE_float(""learning_rate"", .005, ""Learning rate."")\ntf.app.flags.DEFINE_float(""learning_rate_decay_factor"", 0.95, ""Learning rate is multiplied by this much. 1 means no decay."")\ntf.app.flags.DEFINE_integer(""learning_rate_step"", 10000, ""Every this many steps, do decay."")\ntf.app.flags.DEFINE_float(""max_gradient_norm"", 5, ""Clip gradients to this norm."")\ntf.app.flags.DEFINE_integer(""batch_size"", 16, ""Batch size to use during training."")\ntf.app.flags.DEFINE_integer(""iterations"", int(1e5), ""Iterations to train for."")\n# Architecture\ntf.app.flags.DEFINE_string(""architecture"", ""tied"", ""Seq2seq architecture to use: [basic, tied]."")\ntf.app.flags.DEFINE_integer(""size"", 1024, ""Size of each model layer."")\ntf.app.flags.DEFINE_integer(""num_layers"", 1, ""Number of layers in the model."")\ntf.app.flags.DEFINE_integer(""seq_length_in"", 50, ""Number of frames to feed into the encoder. 25 fps"")\ntf.app.flags.DEFINE_integer(""seq_length_out"", 10, ""Number of frames that the decoder has to predict. 25fps"")\ntf.app.flags.DEFINE_boolean(""omit_one_hot"", False, ""Whether to remove one-hot encoding from the data"")\ntf.app.flags.DEFINE_boolean(""residual_velocities"", False, ""Add a residual connection that effectively models velocities"")\n# Directories\ntf.app.flags.DEFINE_string(""data_dir"", os.path.normpath(""./data/h3.6m/dataset""), ""Data directory"")\ntf.app.flags.DEFINE_string(""train_dir"", os.path.normpath(""./experiments/""), ""Training directory."")\n\ntf.app.flags.DEFINE_string(""action"",""all"", ""The action to train on. all means all the actions, all_periodic means walking, eating and smoking"")\ntf.app.flags.DEFINE_string(""loss_to_use"",""sampling_based"", ""The type of loss to use, supervised or sampling_based"")\n\ntf.app.flags.DEFINE_integer(""test_every"", 1000, ""How often to compute error on the test set."")\ntf.app.flags.DEFINE_integer(""save_every"", 1000, ""How often to compute error on the test set."")\ntf.app.flags.DEFINE_boolean(""sample"", False, ""Set to True for sampling."")\ntf.app.flags.DEFINE_boolean(""use_cpu"", False, ""Whether to use the CPU"")\ntf.app.flags.DEFINE_integer(""load"", 0, ""Try to load a previous checkpoint."")\n\nFLAGS = tf.app.flags.FLAGS\n\ntrain_dir = os.path.normpath(os.path.join( FLAGS.train_dir, FLAGS.action,\n  \'out_{0}\'.format(FLAGS.seq_length_out),\n  \'iterations_{0}\'.format(FLAGS.iterations),\n  FLAGS.architecture,\n  FLAGS.loss_to_use,\n  \'omit_one_hot\' if FLAGS.omit_one_hot else \'one_hot\',\n  \'depth_{0}\'.format(FLAGS.num_layers),\n  \'size_{0}\'.format(FLAGS.size),\n  \'lr_{0}\'.format(FLAGS.learning_rate),\n  \'residual_vel\' if FLAGS.residual_velocities else \'not_residual_vel\'))\n\nsummaries_dir = os.path.normpath(os.path.join( train_dir, ""log"" )) # Directory for TB summaries\n\ndef create_model(session, actions, sampling=False):\n  """"""Create translation model and initialize or load parameters in session.""""""\n\n  model = seq2seq_model.Seq2SeqModel(\n      FLAGS.architecture,\n      FLAGS.seq_length_in if not sampling else 50,\n      FLAGS.seq_length_out if not sampling else 100,\n      FLAGS.size, # hidden layer size\n      FLAGS.num_layers,\n      FLAGS.max_gradient_norm,\n      FLAGS.batch_size,\n      FLAGS.learning_rate,\n      FLAGS.learning_rate_decay_factor,\n      summaries_dir,\n      FLAGS.loss_to_use if not sampling else ""sampling_based"",\n      len( actions ),\n      not FLAGS.omit_one_hot,\n      FLAGS.residual_velocities,\n      dtype=tf.float32)\n\n  if FLAGS.load <= 0:\n    print(""Creating model with fresh parameters."")\n    session.run(tf.global_variables_initializer())\n    return model\n\n  ckpt = tf.train.get_checkpoint_state( train_dir, latest_filename=""checkpoint"")\n  print( ""train_dir"", train_dir )\n\n  if ckpt and ckpt.model_checkpoint_path:\n    # Check if the specific checkpoint exists\n    if FLAGS.load > 0:\n      if os.path.isfile(os.path.join(train_dir,""checkpoint-{0}.index"".format(FLAGS.load))):\n        ckpt_name = os.path.normpath(os.path.join( os.path.join(train_dir,""checkpoint-{0}"".format(FLAGS.load)) ))\n      else:\n        raise ValueError(""Asked to load checkpoint {0}, but it does not seem to exist"".format(FLAGS.load))\n    else:\n      ckpt_name = os.path.basename( ckpt.model_checkpoint_path )\n\n    print(""Loading model {0}"".format( ckpt_name ))\n    model.saver.restore( session, ckpt.model_checkpoint_path )\n    return model\n  else:\n    print(""Could not find checkpoint. Aborting."")\n    raise( ValueError, ""Checkpoint {0} does not seem to exist"".format( ckpt.model_checkpoint_path ) )\n\n  return model\n\n\ndef train():\n  """"""Train a seq2seq model on human motion""""""\n\n  actions = define_actions( FLAGS.action )\n\n  number_of_actions = len( actions )\n\n  train_set, test_set, data_mean, data_std, dim_to_ignore, dim_to_use = read_all_data(\n    actions, FLAGS.seq_length_in, FLAGS.seq_length_out, FLAGS.data_dir, not FLAGS.omit_one_hot )\n\n  # Limit TF to take a fraction of the GPU memory\n  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n  device_count = {""GPU"": 0} if FLAGS.use_cpu else {""GPU"": 1}\n\n  with tf.Session(config=tf.ConfigProto( gpu_options=gpu_options, device_count = device_count )) as sess:\n\n    # === Create the model ===\n    print(""Creating %d layers of %d units."" % (FLAGS.num_layers, FLAGS.size))\n\n    model = create_model( sess, actions )\n    model.train_writer.add_graph( sess.graph )\n    print( ""Model created"" )\n\n    # === Read and denormalize the gt with srnn\'s seeds, as we\'ll need them\n    # many times for evaluation in Euler Angles ===\n    srnn_gts_euler = get_srnn_gts( actions, model, test_set, data_mean,\n                              data_std, dim_to_ignore, not FLAGS.omit_one_hot )\n\n    #=== This is the training loop ===\n    step_time, loss, val_loss = 0.0, 0.0, 0.0\n    current_step = 0 if FLAGS.load <= 0 else FLAGS.load + 1\n    previous_losses = []\n\n    step_time, loss = 0, 0\n\n    for _ in xrange( FLAGS.iterations ):\n\n      start_time = time.time()\n\n      # === Training step ===\n      encoder_inputs, decoder_inputs, decoder_outputs = model.get_batch( train_set, not FLAGS.omit_one_hot )\n      _, step_loss, loss_summary, lr_summary = model.step( sess, encoder_inputs, decoder_inputs, decoder_outputs, False )\n      model.train_writer.add_summary( loss_summary, current_step )\n      model.train_writer.add_summary( lr_summary, current_step )\n\n      if current_step % 10 == 0:\n        print(""step {0:04d}; step_loss: {1:.4f}"".format(current_step, step_loss ))\n\n      step_time += (time.time() - start_time) / FLAGS.test_every\n      loss += step_loss / FLAGS.test_every\n      current_step += 1\n\n      # === step decay ===\n      if current_step % FLAGS.learning_rate_step == 0:\n        sess.run(model.learning_rate_decay_op)\n\n      # Once in a while, we save checkpoint, print statistics, and run evals.\n      if current_step % FLAGS.test_every == 0:\n\n        # === Validation with randomly chosen seeds ===\n        forward_only = True\n\n        encoder_inputs, decoder_inputs, decoder_outputs = model.get_batch( test_set, not FLAGS.omit_one_hot )\n        step_loss, loss_summary = model.step(sess,\n            encoder_inputs, decoder_inputs, decoder_outputs, forward_only)\n        val_loss = step_loss # Loss book-keeping\n\n        model.test_writer.add_summary(loss_summary, current_step)\n\n        print()\n        print(""{0: <16} |"".format(""milliseconds""), end="""")\n        for ms in [80, 160, 320, 400, 560, 1000]:\n          print("" {0:5d} |"".format(ms), end="""")\n        print()\n\n        # === Validation with srnn\'s seeds ===\n        for action in actions:\n\n          # Evaluate the model on the test batches\n          encoder_inputs, decoder_inputs, decoder_outputs = model.get_batch_srnn( test_set, action )\n          srnn_loss, srnn_poses, _ = model.step(sess, encoder_inputs, decoder_inputs,\n                                                   decoder_outputs, True, True)\n\n          # Denormalize the output\n          srnn_pred_expmap = data_utils.revert_output_format( srnn_poses,\n            data_mean, data_std, dim_to_ignore, actions, not FLAGS.omit_one_hot )\n\n          # Save the errors here\n          mean_errors = np.zeros( (len(srnn_pred_expmap), srnn_pred_expmap[0].shape[0]) )\n\n          # Training is done in exponential map, but the error is reported in\n          # Euler angles, as in previous work.\n          # See https://github.com/asheshjain399/RNNexp/issues/6#issuecomment-247769197\n          N_SEQUENCE_TEST = 8\n          for i in np.arange(N_SEQUENCE_TEST):\n            eulerchannels_pred = srnn_pred_expmap[i]\n\n            # Convert from exponential map to Euler angles\n            for j in np.arange( eulerchannels_pred.shape[0] ):\n              for k in np.arange(3,97,3):\n                eulerchannels_pred[j,k:k+3] = data_utils.rotmat2euler(\n                  data_utils.expmap2rotmat( eulerchannels_pred[j,k:k+3] ))\n\n            # The global translation (first 3 entries) and global rotation\n            # (next 3 entries) are also not considered in the error, so the_key\n            # are set to zero.\n            # See https://github.com/asheshjain399/RNNexp/issues/6#issuecomment-249404882\n            gt_i=np.copy(srnn_gts_euler[action][i])\n            gt_i[:,0:6] = 0\n\n            # Now compute the l2 error. The following is numpy port of the error\n            # function provided by Ashesh Jain (in matlab), available at\n            # https://github.com/asheshjain399/RNNexp/blob/srnn/structural_rnn/CRFProblems/H3.6m/dataParser/Utils/motionGenerationError.m#L40-L54\n            idx_to_use = np.where( np.std( gt_i, 0 ) > 1e-4 )[0]\n            \n            euc_error = np.power( gt_i[:,idx_to_use] - eulerchannels_pred[:,idx_to_use], 2)\n            euc_error = np.sum(euc_error, 1)\n            euc_error = np.sqrt( euc_error )\n            mean_errors[i,:] = euc_error\n\n          # This is simply the mean error over the N_SEQUENCE_TEST examples\n          mean_mean_errors = np.mean( mean_errors, 0 )\n\n          # Pretty print of the results for 80, 160, 320, 400, 560 and 1000 ms\n          print(""{0: <16} |"".format(action), end="""")\n          for ms in [1,3,7,9,13,24]:\n            if FLAGS.seq_length_out >= ms+1:\n              print("" {0:.3f} |"".format( mean_mean_errors[ms] ), end="""")\n            else:\n              print(""   n/a |"", end="""")\n          print()\n\n          # Ugly massive if-then to log the error to tensorboard :shrug:\n          if action == ""walking"":\n            summaries = sess.run(\n              [model.walking_err80_summary,\n               model.walking_err160_summary,\n               model.walking_err320_summary,\n               model.walking_err400_summary,\n               model.walking_err560_summary,\n               model.walking_err1000_summary],\n              {model.walking_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.walking_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.walking_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.walking_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.walking_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.walking_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""eating"":\n            summaries = sess.run(\n              [model.eating_err80_summary,\n               model.eating_err160_summary,\n               model.eating_err320_summary,\n               model.eating_err400_summary,\n               model.eating_err560_summary,\n               model.eating_err1000_summary],\n              {model.eating_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.eating_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.eating_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.eating_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.eating_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.eating_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""smoking"":\n            summaries = sess.run(\n              [model.smoking_err80_summary,\n               model.smoking_err160_summary,\n               model.smoking_err320_summary,\n               model.smoking_err400_summary,\n               model.smoking_err560_summary,\n               model.smoking_err1000_summary],\n              {model.smoking_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.smoking_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.smoking_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.smoking_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.smoking_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.smoking_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""discussion"":\n            summaries = sess.run(\n              [model.discussion_err80_summary,\n               model.discussion_err160_summary,\n               model.discussion_err320_summary,\n               model.discussion_err400_summary,\n               model.discussion_err560_summary,\n               model.discussion_err1000_summary],\n              {model.discussion_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.discussion_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.discussion_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.discussion_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.discussion_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.discussion_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""directions"":\n            summaries = sess.run(\n              [model.directions_err80_summary,\n               model.directions_err160_summary,\n               model.directions_err320_summary,\n               model.directions_err400_summary,\n               model.directions_err560_summary,\n               model.directions_err1000_summary],\n              {model.directions_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.directions_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.directions_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.directions_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.directions_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.directions_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""greeting"":\n            summaries = sess.run(\n              [model.greeting_err80_summary,\n               model.greeting_err160_summary,\n               model.greeting_err320_summary,\n               model.greeting_err400_summary,\n               model.greeting_err560_summary,\n               model.greeting_err1000_summary],\n              {model.greeting_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.greeting_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.greeting_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.greeting_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.greeting_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.greeting_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""phoning"":\n            summaries = sess.run(\n              [model.phoning_err80_summary,\n               model.phoning_err160_summary,\n               model.phoning_err320_summary,\n               model.phoning_err400_summary,\n               model.phoning_err560_summary,\n               model.phoning_err1000_summary],\n              {model.phoning_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.phoning_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.phoning_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.phoning_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.phoning_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.phoning_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""posing"":\n            summaries = sess.run(\n              [model.posing_err80_summary,\n               model.posing_err160_summary,\n               model.posing_err320_summary,\n               model.posing_err400_summary,\n               model.posing_err560_summary,\n               model.posing_err1000_summary],\n              {model.posing_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.posing_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.posing_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.posing_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.posing_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.posing_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""purchases"":\n            summaries = sess.run(\n              [model.purchases_err80_summary,\n               model.purchases_err160_summary,\n               model.purchases_err320_summary,\n               model.purchases_err400_summary,\n               model.purchases_err560_summary,\n               model.purchases_err1000_summary],\n              {model.purchases_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.purchases_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.purchases_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.purchases_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.purchases_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.purchases_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""sitting"":\n            summaries = sess.run(\n              [model.sitting_err80_summary,\n               model.sitting_err160_summary,\n               model.sitting_err320_summary,\n               model.sitting_err400_summary,\n               model.sitting_err560_summary,\n               model.sitting_err1000_summary],\n              {model.sitting_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.sitting_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.sitting_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.sitting_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.sitting_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.sitting_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""sittingdown"":\n            summaries = sess.run(\n              [model.sittingdown_err80_summary,\n               model.sittingdown_err160_summary,\n               model.sittingdown_err320_summary,\n               model.sittingdown_err400_summary,\n               model.sittingdown_err560_summary,\n               model.sittingdown_err1000_summary],\n              {model.sittingdown_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.sittingdown_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.sittingdown_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.sittingdown_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.sittingdown_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.sittingdown_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""takingphoto"":\n            summaries = sess.run(\n              [model.takingphoto_err80_summary,\n               model.takingphoto_err160_summary,\n               model.takingphoto_err320_summary,\n               model.takingphoto_err400_summary,\n               model.takingphoto_err560_summary,\n               model.takingphoto_err1000_summary],\n              {model.takingphoto_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.takingphoto_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.takingphoto_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.takingphoto_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.takingphoto_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.takingphoto_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""waiting"":\n            summaries = sess.run(\n              [model.waiting_err80_summary,\n               model.waiting_err160_summary,\n               model.waiting_err320_summary,\n               model.waiting_err400_summary,\n               model.waiting_err560_summary,\n               model.waiting_err1000_summary],\n              {model.waiting_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.waiting_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.waiting_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.waiting_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.waiting_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.waiting_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""walkingdog"":\n            summaries = sess.run(\n              [model.walkingdog_err80_summary,\n               model.walkingdog_err160_summary,\n               model.walkingdog_err320_summary,\n               model.walkingdog_err400_summary,\n               model.walkingdog_err560_summary,\n               model.walkingdog_err1000_summary],\n              {model.walkingdog_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.walkingdog_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.walkingdog_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.walkingdog_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.walkingdog_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.walkingdog_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n          elif action == ""walkingtogether"":\n            summaries = sess.run(\n              [model.walkingtogether_err80_summary,\n               model.walkingtogether_err160_summary,\n               model.walkingtogether_err320_summary,\n               model.walkingtogether_err400_summary,\n               model.walkingtogether_err560_summary,\n               model.walkingtogether_err1000_summary],\n              {model.walkingtogether_err80: mean_mean_errors[1] if FLAGS.seq_length_out >= 2 else None,\n               model.walkingtogether_err160: mean_mean_errors[3] if FLAGS.seq_length_out >= 4 else None,\n               model.walkingtogether_err320: mean_mean_errors[7] if FLAGS.seq_length_out >= 8 else None,\n               model.walkingtogether_err400: mean_mean_errors[9] if FLAGS.seq_length_out >= 10 else None,\n               model.walkingtogether_err560: mean_mean_errors[13] if FLAGS.seq_length_out >= 14 else None,\n               model.walkingtogether_err1000: mean_mean_errors[24] if FLAGS.seq_length_out >= 25 else None})\n\n          for i in np.arange(len( summaries )):\n            model.test_writer.add_summary(summaries[i], current_step)\n\n\n        print()\n        print(""============================\\n""\n              ""Global step:         %d\\n""\n              ""Learning rate:       %.4f\\n""\n              ""Step-time (ms):     %.4f\\n""\n              ""Train loss avg:      %.4f\\n""\n              ""--------------------------\\n""\n              ""Val loss:            %.4f\\n""\n              ""srnn loss:           %.4f\\n""\n              ""============================"" % (model.global_step.eval(),\n              model.learning_rate.eval(), step_time*1000, loss,\n              val_loss, srnn_loss))\n        print()\n\n        previous_losses.append(loss)\n\n        # Save the model\n        if current_step % FLAGS.save_every == 0:\n          print( ""Saving the model..."" ); start_time = time.time()\n          model.saver.save(sess, os.path.normpath(os.path.join(train_dir, \'checkpoint\')), global_step=current_step )\n          print( ""done in {0:.2f} ms"".format( (time.time() - start_time)*1000) )\n\n        # Reset global time and loss\n        step_time, loss = 0, 0\n\n        sys.stdout.flush()\n\n\ndef get_srnn_gts( actions, model, test_set, data_mean, data_std, dim_to_ignore, one_hot, to_euler=True ):\n  """"""\n  Get the ground truths for srnn\'s sequences, and convert to Euler angles.\n  (the error is always computed in Euler angles).\n\n  Args\n    actions: a list of actions to get ground truths for.\n    model: training model we are using (we only use the ""get_batch"" method).\n    test_set: dictionary with normalized training data.\n    data_mean: d-long vector with the mean of the training data.\n    data_std: d-long vector with the standard deviation of the training data.\n    dim_to_ignore: dimensions that we are not using to train/predict.\n    one_hot: whether the data comes with one-hot encoding indicating action.\n    to_euler: whether to convert the angles to Euler format or keep thm in exponential map\n\n  Returns\n    srnn_gts_euler: a dictionary where the keys are actions, and the values\n      are the ground_truth, denormalized expected outputs of srnns\'s seeds.\n  """"""\n  srnn_gts_euler = {}\n\n  for action in actions:\n\n    srnn_gt_euler = []\n    _, _, srnn_expmap = model.get_batch_srnn( test_set, action )\n\n    # expmap -> rotmat -> euler\n    for i in np.arange( srnn_expmap.shape[0] ):\n      denormed = data_utils.unNormalizeData(srnn_expmap[i,:,:], data_mean, data_std, dim_to_ignore, actions, one_hot )\n\n      if to_euler:\n        for j in np.arange( denormed.shape[0] ):\n          for k in np.arange(3,97,3):\n            denormed[j,k:k+3] = data_utils.rotmat2euler( data_utils.expmap2rotmat( denormed[j,k:k+3] ))\n\n      srnn_gt_euler.append( denormed );\n\n    # Put back in the dictionary\n    srnn_gts_euler[action] = srnn_gt_euler\n\n  return srnn_gts_euler\n\n\ndef sample():\n  """"""Sample predictions for srnn\'s seeds""""""\n\n  if FLAGS.load <= 0:\n    raise( ValueError, ""Must give an iteration to read parameters from"")\n\n  actions = define_actions( FLAGS.action )\n\n  # Use the CPU if asked to\n  device_count = {""GPU"": 0} if FLAGS.use_cpu else {""GPU"": 1}\n  with tf.Session(config=tf.ConfigProto( device_count = device_count )) as sess:\n\n    # === Create the model ===\n    print(""Creating %d layers of %d units."" % (FLAGS.num_layers, FLAGS.size))\n    sampling     = True\n    model = create_model(sess, actions, sampling)\n    print(""Model created"")\n\n    # Load all the data\n    train_set, test_set, data_mean, data_std, dim_to_ignore, dim_to_use = read_all_data(\n      actions, FLAGS.seq_length_in, FLAGS.seq_length_out, FLAGS.data_dir, not FLAGS.omit_one_hot )\n\n    # === Read and denormalize the gt with srnn\'s seeds, as we\'ll need them\n    # many times for evaluation in Euler Angles ===\n    srnn_gts_expmap = get_srnn_gts( actions, model, test_set, data_mean,\n                              data_std, dim_to_ignore, not FLAGS.omit_one_hot, to_euler=False )\n    srnn_gts_euler = get_srnn_gts( actions, model, test_set, data_mean,\n                              data_std, dim_to_ignore, not FLAGS.omit_one_hot )\n\n    # Clean and create a new h5 file of samples\n    SAMPLES_FNAME = \'samples.h5\'\n    try:\n      os.remove( SAMPLES_FNAME )\n    except OSError:\n      pass\n\n    # Predict and save for each action\n    for action in actions:\n\n      # Make prediction with srnn\' seeds\n      encoder_inputs, decoder_inputs, decoder_outputs = model.get_batch_srnn( test_set, action )\n      forward_only = True\n      srnn_seeds = True\n      srnn_loss, srnn_poses, _ = model.step(sess, encoder_inputs, decoder_inputs, decoder_outputs, forward_only, srnn_seeds)\n\n      # denormalizes too\n      srnn_pred_expmap = data_utils.revert_output_format( srnn_poses, data_mean, data_std, dim_to_ignore, actions, not FLAGS.omit_one_hot )\n\n      # Save the conditioning seeds\n\n      # Save the samples\n      with h5py.File( SAMPLES_FNAME, \'a\' ) as hf:\n        for i in np.arange(8):\n          # Save conditioning ground truth\n          node_name = \'expmap/gt/{1}_{0}\'.format(i, action)\n          hf.create_dataset( node_name, data=srnn_gts_expmap[action][i] )\n          # Save prediction\n          node_name = \'expmap/preds/{1}_{0}\'.format(i, action)\n          hf.create_dataset( node_name, data=srnn_pred_expmap[i] )\n\n      # Compute and save the errors here\n      mean_errors = np.zeros( (len(srnn_pred_expmap), srnn_pred_expmap[0].shape[0]) )\n\n      for i in np.arange(8):\n\n        eulerchannels_pred = srnn_pred_expmap[i]\n\n        for j in np.arange( eulerchannels_pred.shape[0] ):\n          for k in np.arange(3,97,3):\n            eulerchannels_pred[j,k:k+3] = data_utils.rotmat2euler(\n              data_utils.expmap2rotmat( eulerchannels_pred[j,k:k+3] ))\n\n        eulerchannels_pred[:,0:6] = 0\n\n        # Pick only the dimensions with sufficient standard deviation. Others are ignored.\n        idx_to_use = np.where( np.std( eulerchannels_pred, 0 ) > 1e-4 )[0]\n\n        euc_error = np.power( srnn_gts_euler[action][i][:,idx_to_use] - eulerchannels_pred[:,idx_to_use], 2)\n        euc_error = np.sum(euc_error, 1)\n        euc_error = np.sqrt( euc_error )\n        mean_errors[i,:] = euc_error\n\n      mean_mean_errors = np.mean( mean_errors, 0 )\n      print( action )\n      print( \',\'.join(map(str, mean_mean_errors.tolist() )) )\n\n      with h5py.File( SAMPLES_FNAME, \'a\' ) as hf:\n        node_name = \'mean_{0}_error\'.format( action )\n        hf.create_dataset( node_name, data=mean_mean_errors )\n\n  return\n\n\ndef define_actions( action ):\n  """"""\n  Define the list of actions we are using.\n\n  Args\n    action: String with the passed action. Could be ""all""\n  Returns\n    actions: List of strings of actions\n  Raises\n    ValueError if the action is not included in H3.6M\n  """"""\n\n  actions = [""walking"", ""eating"", ""smoking"", ""discussion"",  ""directions"",\n              ""greeting"", ""phoning"", ""posing"", ""purchases"", ""sitting"",\n              ""sittingdown"", ""takingphoto"", ""waiting"", ""walkingdog"",\n              ""walkingtogether""]\n\n  if action in actions:\n    return [action]\n\n  if action == ""all"":\n    return actions\n\n  if action == ""all_srnn"":\n    return [""walking"", ""eating"", ""smoking"", ""discussion""]\n\n  raise( ValueError, ""Unrecognized action: %d"" % action )\n\n\ndef read_all_data( actions, seq_length_in, seq_length_out, data_dir, one_hot ):\n  """"""\n  Loads data for training/testing and normalizes it.\n\n  Args\n    actions: list of strings (actions) to load\n    seq_length_in: number of frames to use in the burn-in sequence\n    seq_length_out: number of frames to use in the output sequence\n    data_dir: directory to load the data from\n    one_hot: whether to use one-hot encoding per action\n  Returns\n    train_set: dictionary with normalized training data\n    test_set: dictionary with test data\n    data_mean: d-long vector with the mean of the training data\n    data_std: d-long vector with the standard dev of the training data\n    dim_to_ignore: dimensions that are not used becaused stdev is too small\n    dim_to_use: dimensions that we are actually using in the model\n  """"""\n\n  # === Read training data ===\n  print (""Reading training data (seq_len_in: {0}, seq_len_out {1})."".format(\n           seq_length_in, seq_length_out))\n\n  train_subject_ids = [1,6,7,8,9,11]\n  test_subject_ids = [5]\n\n  train_set, complete_train = data_utils.load_data( data_dir, train_subject_ids, actions, one_hot )\n  test_set,  complete_test  = data_utils.load_data( data_dir, test_subject_ids,  actions, one_hot )\n\n  # Compute normalization stats\n  data_mean, data_std, dim_to_ignore, dim_to_use = data_utils.normalization_stats(complete_train)\n\n  # Normalize -- subtract mean, divide by stdev\n  train_set = data_utils.normalize_data( train_set, data_mean, data_std, dim_to_use, actions, one_hot )\n  test_set  = data_utils.normalize_data( test_set,  data_mean, data_std, dim_to_use, actions, one_hot )\n  print(""done reading data."")\n\n  return train_set, test_set, data_mean, data_std, dim_to_ignore, dim_to_use\n\n\ndef main(_):\n  if FLAGS.sample:\n    sample()\n  else:\n    train()\n\nif __name__ == ""__main__"":\n  tf.app.run()\n'"
src/viz.py,0,"b'""""""Functions to visualize human poses""""""\n\nimport matplotlib.pyplot as plt\nimport data_utils\nimport numpy as np\nimport h5py\nimport os\nfrom mpl_toolkits.mplot3d import Axes3D\n\nclass Ax3DPose(object):\n  def __init__(self, ax, lcolor=""#3498db"", rcolor=""#e74c3c""):\n    """"""\n    Create a 3d pose visualizer that can be updated with new poses.\n\n    Args\n      ax: 3d axis to plot the 3d pose on\n      lcolor: String. Colour for the left part of the body\n      rcolor: String. Colour for the right part of the body\n    """"""\n\n    # Start and endpoints of our representation\n    self.I   = np.array([1,2,3,1,7,8,1, 13,14,15,14,18,19,14,26,27])-1\n    self.J   = np.array([2,3,4,7,8,9,13,14,15,16,18,19,20,26,27,28])-1\n    # Left / right indicator\n    self.LR  = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n    self.ax = ax\n\n    vals = np.zeros((32, 3))\n\n    # Make connection matrix\n    self.plots = []\n    for i in np.arange( len(self.I) ):\n      x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n      y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n      z = np.array( [vals[self.I[i], 2], vals[self.J[i], 2]] )\n      self.plots.append(self.ax.plot(x, y, z, lw=2, c=lcolor if self.LR[i] else rcolor))\n\n    self.ax.set_xlabel(""x"")\n    self.ax.set_ylabel(""y"")\n    self.ax.set_zlabel(""z"")\n\n  def update(self, channels, lcolor=""#3498db"", rcolor=""#e74c3c""):\n    """"""\n    Update the plotted 3d pose.\n\n    Args\n      channels: 96-dim long np array. The pose to plot.\n      lcolor: String. Colour for the left part of the body.\n      rcolor: String. Colour for the right part of the body.\n    Returns\n      Nothing. Simply updates the axis with the new pose.\n    """"""\n\n    assert channels.size == 96, ""channels should have 96 entries, it has %d instead"" % channels.size\n    vals = np.reshape( channels, (32, -1) )\n\n    for i in np.arange( len(self.I) ):\n      x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n      y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n      z = np.array( [vals[self.I[i], 2], vals[self.J[i], 2]] )\n      self.plots[i][0].set_xdata(x)\n      self.plots[i][0].set_ydata(y)\n      self.plots[i][0].set_3d_properties(z)\n      self.plots[i][0].set_color(lcolor if self.LR[i] else rcolor)\n\n    r = 750;\n    xroot, yroot, zroot = vals[0,0], vals[0,1], vals[0,2]\n    self.ax.set_xlim3d([-r+xroot, r+xroot])\n    self.ax.set_zlim3d([-r+zroot, r+zroot])\n    self.ax.set_ylim3d([-r+yroot, r+yroot])\n\n    self.ax.set_aspect(\'equal\')\n'"
