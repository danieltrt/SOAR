file_path,api_count,code
build_data.py,12,"b'import tensorflow as tf\nimport random\nimport os\n\ntry:\n  from os import scandir\nexcept ImportError:\n  # Python 2 polyfill module\n  from scandir import scandir\n    \n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_string(\'X_input_dir\', \'data/apple2orange/trainA\',\n                       \'X input directory, default: data/apple2orange/trainA\')\ntf.flags.DEFINE_string(\'Y_input_dir\', \'data/apple2orange/trainB\',\n                       \'Y input directory, default: data/apple2orange/trainB\')\ntf.flags.DEFINE_string(\'X_output_file\', \'data/tfrecords/apple.tfrecords\',\n                       \'X output tfrecords file, default: data/tfrecords/apple.tfrecords\')\ntf.flags.DEFINE_string(\'Y_output_file\', \'data/tfrecords/orange.tfrecords\',\n                       \'Y output tfrecords file, default: data/tfrecords/orange.tfrecords\')\n\n\ndef data_reader(input_dir, shuffle=True):\n  """"""Read images from input_dir then shuffle them\n  Args:\n    input_dir: string, path of input dir, e.g., /path/to/dir\n  Returns:\n    file_paths: list of strings\n  """"""\n  file_paths = []\n\n  for img_file in scandir(input_dir):\n    if img_file.name.endswith(\'.jpg\') and img_file.is_file():\n      file_paths.append(img_file.path)\n\n  if shuffle:\n    # Shuffle the ordering of all image files in order to guarantee\n    # random ordering of the images with respect to label in the\n    # saved TFRecord files. Make the randomization repeatable.\n    shuffled_index = list(range(len(file_paths)))\n    random.seed(12345)\n    random.shuffle(shuffled_index)\n\n    file_paths = [file_paths[i] for i in shuffled_index]\n\n  return file_paths\n\n\ndef _int64_feature(value):\n  """"""Wrapper for inserting int64 features into Example proto.""""""\n  if not isinstance(value, list):\n    value = [value]\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef _bytes_feature(value):\n  """"""Wrapper for inserting bytes features into Example proto.""""""\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _convert_to_example(file_path, image_buffer):\n  """"""Build an Example proto for an example.\n  Args:\n    file_path: string, path to an image file, e.g., \'/path/to/example.JPG\'\n    image_buffer: string, JPEG encoding of RGB image\n  Returns:\n    Example proto\n  """"""\n  file_name = file_path.split(\'/\')[-1]\n\n  example = tf.train.Example(features=tf.train.Features(feature={\n      \'image/file_name\': _bytes_feature(tf.compat.as_bytes(os.path.basename(file_name))),\n      \'image/encoded_image\': _bytes_feature((image_buffer))\n    }))\n  return example\n\ndef data_writer(input_dir, output_file):\n  """"""Write data to tfrecords\n  """"""\n  file_paths = data_reader(input_dir)\n\n  # create tfrecords dir if not exists\n  output_dir = os.path.dirname(output_file)\n  try:\n    os.makedirs(output_dir)\n  except os.error as e:\n    pass\n\n  images_num = len(file_paths)\n\n  # dump to tfrecords file\n  writer = tf.python_io.TFRecordWriter(output_file)\n\n  for i in range(len(file_paths)):\n    file_path = file_paths[i]\n\n    with tf.gfile.FastGFile(file_path, \'rb\') as f:\n      image_data = f.read()\n\n    example = _convert_to_example(file_path, image_data)\n    writer.write(example.SerializeToString())\n\n    if i % 500 == 0:\n      print(""Processed {}/{}."".format(i, images_num))\n  print(""Done."")\n  writer.close()\n\ndef main(unused_argv):\n  print(""Convert X data to tfrecords..."")\n  data_writer(FLAGS.X_input_dir, FLAGS.X_output_file)\n  print(""Convert Y data to tfrecords..."")\n  data_writer(FLAGS.Y_input_dir, FLAGS.Y_output_file)\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
discriminator.py,2,"b'import tensorflow as tf\nimport ops\n\nclass Discriminator:\n  def __init__(self, name, is_training, norm=\'instance\', use_sigmoid=False):\n    self.name = name\n    self.is_training = is_training\n    self.norm = norm\n    self.reuse = False\n    self.use_sigmoid = use_sigmoid\n\n  def __call__(self, input):\n    """"""\n    Args:\n      input: batch_size x image_size x image_size x 3\n    Returns:\n      output: 4D tensor batch_size x out_size x out_size x 1 (default 1x5x5x1)\n              filled with 0.9 if real, 0.0 if fake\n    """"""\n    with tf.variable_scope(self.name):\n      # convolution layers\n      C64 = ops.Ck(input, 64, reuse=self.reuse, norm=None,\n          is_training=self.is_training, name=\'C64\')             # (?, w/2, h/2, 64)\n      C128 = ops.Ck(C64, 128, reuse=self.reuse, norm=self.norm,\n          is_training=self.is_training, name=\'C128\')            # (?, w/4, h/4, 128)\n      C256 = ops.Ck(C128, 256, reuse=self.reuse, norm=self.norm,\n          is_training=self.is_training, name=\'C256\')            # (?, w/8, h/8, 256)\n      C512 = ops.Ck(C256, 512,reuse=self.reuse, norm=self.norm,\n          is_training=self.is_training, name=\'C512\')            # (?, w/16, h/16, 512)\n\n      # apply a convolution to produce a 1 dimensional output (1 channel?)\n      # use_sigmoid = False if use_lsgan = True\n      output = ops.last_conv(C512, reuse=self.reuse,\n          use_sigmoid=self.use_sigmoid, name=\'output\')          # (?, w/16, h/16, 1)\n\n    self.reuse = True\n    self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n\n    return output\n'"
export_graph.py,20,"b'"""""" Freeze variables and convert 2 generator networks to 2 GraphDef files.\nThis makes file size smaller and can be used for inference in production.\nAn example of command-line usage is:\npython export_graph.py --checkpoint_dir checkpoints/20170424-1152 \\\n                       --XtoY_model apple2orange.pb \\\n                       --YtoX_model orange2apple.pb \\\n                       --image_size 256\n""""""\n\nimport tensorflow as tf\nimport os\nfrom tensorflow.python.tools.freeze_graph import freeze_graph\nfrom model import CycleGAN\nimport utils\n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_string(\'checkpoint_dir\', \'\', \'checkpoints directory path\')\ntf.flags.DEFINE_string(\'XtoY_model\', \'apple2orange.pb\', \'XtoY model name, default: apple2orange.pb\')\ntf.flags.DEFINE_string(\'YtoX_model\', \'orange2apple.pb\', \'YtoX model name, default: orange2apple.pb\')\ntf.flags.DEFINE_integer(\'image_size\', \'256\', \'image size, default: 256\')\ntf.flags.DEFINE_integer(\'ngf\', 64,\n                        \'number of gen filters in first conv layer, default: 64\')\ntf.flags.DEFINE_string(\'norm\', \'instance\',\n                       \'[instance, batch] use instance norm or batch norm, default: instance\')\n\ndef export_graph(model_name, XtoY=True):\n  graph = tf.Graph()\n\n  with graph.as_default():\n    cycle_gan = CycleGAN(ngf=FLAGS.ngf, norm=FLAGS.norm, image_size=FLAGS.image_size)\n\n    input_image = tf.placeholder(tf.float32, shape=[FLAGS.image_size, FLAGS.image_size, 3], name=\'input_image\')\n    cycle_gan.model()\n    if XtoY:\n      output_image = cycle_gan.G.sample(tf.expand_dims(input_image, 0))\n    else:\n      output_image = cycle_gan.F.sample(tf.expand_dims(input_image, 0))\n\n    output_image = tf.identity(output_image, name=\'output_image\')\n    restore_saver = tf.train.Saver()\n    export_saver = tf.train.Saver()\n\n  with tf.Session(graph=graph) as sess:\n    sess.run(tf.global_variables_initializer())\n    latest_ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n    restore_saver.restore(sess, latest_ckpt)\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\n        sess, graph.as_graph_def(), [output_image.op.name])\n\n    tf.train.write_graph(output_graph_def, \'pretrained\', model_name, as_text=False)\n\ndef main(unused_argv):\n  print(\'Export XtoY model...\')\n  export_graph(FLAGS.XtoY_model, XtoY=True)\n  print(\'Export YtoX model...\')\n  export_graph(FLAGS.YtoX_model, XtoY=False)\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
generator.py,3,"b'import tensorflow as tf\nimport ops\nimport utils\n\nclass Generator:\n  def __init__(self, name, is_training, ngf=64, norm=\'instance\', image_size=128):\n    self.name = name\n    self.reuse = False\n    self.ngf = ngf\n    self.norm = norm\n    self.is_training = is_training\n    self.image_size = image_size\n\n  def __call__(self, input):\n    """"""\n    Args:\n      input: batch_size x width x height x 3\n    Returns:\n      output: same size as input\n    """"""\n    with tf.variable_scope(self.name):\n      # conv layers\n      c7s1_32 = ops.c7s1_k(input, self.ngf, is_training=self.is_training, norm=self.norm,\n          reuse=self.reuse, name=\'c7s1_32\')                             # (?, w, h, 32)\n      d64 = ops.dk(c7s1_32, 2*self.ngf, is_training=self.is_training, norm=self.norm,\n          reuse=self.reuse, name=\'d64\')                                 # (?, w/2, h/2, 64)\n      d128 = ops.dk(d64, 4*self.ngf, is_training=self.is_training, norm=self.norm,\n          reuse=self.reuse, name=\'d128\')                                # (?, w/4, h/4, 128)\n\n      if self.image_size <= 128:\n        # use 6 residual blocks for 128x128 images\n        res_output = ops.n_res_blocks(d128, reuse=self.reuse, n=6)      # (?, w/4, h/4, 128)\n      else:\n        # 9 blocks for higher resolution\n        res_output = ops.n_res_blocks(d128, reuse=self.reuse, n=9)      # (?, w/4, h/4, 128)\n\n      # fractional-strided convolution\n      u64 = ops.uk(res_output, 2*self.ngf, is_training=self.is_training, norm=self.norm,\n          reuse=self.reuse, name=\'u64\')                                 # (?, w/2, h/2, 64)\n      u32 = ops.uk(u64, self.ngf, is_training=self.is_training, norm=self.norm,\n          reuse=self.reuse, name=\'u32\', output_size=self.image_size)         # (?, w, h, 32)\n\n      # conv layer\n      # Note: the paper said that ReLU and _norm were used\n      # but actually tanh was used and no _norm here\n      output = ops.c7s1_k(u32, 3, norm=None,\n          activation=\'tanh\', reuse=self.reuse, name=\'output\')           # (?, w, h, 3)\n    # set reuse=True for next call\n    self.reuse = True\n    self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n\n    return output\n\n  def sample(self, input):\n    image = utils.batch_convert2int(self.__call__(input))\n    image = tf.image.encode_jpeg(tf.squeeze(image, [0]))\n    return image\n'"
inference.py,14,"b'""""""Translate an image to another image\nAn example of command-line usage is:\npython export_graph.py --model pretrained/apple2orange.pb \\\n                       --input input_sample.jpg \\\n                       --output output_sample.jpg \\\n                       --image_size 256\n""""""\n\nimport tensorflow as tf\nimport os\nfrom model import CycleGAN\nimport utils\n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_string(\'model\', \'\', \'model path (.pb)\')\ntf.flags.DEFINE_string(\'input\', \'input_sample.jpg\', \'input image path (.jpg)\')\ntf.flags.DEFINE_string(\'output\', \'output_sample.jpg\', \'output image path (.jpg)\')\ntf.flags.DEFINE_integer(\'image_size\', \'256\', \'image size, default: 256\')\n\ndef inference():\n  graph = tf.Graph()\n\n  with graph.as_default():\n    with tf.gfile.FastGFile(FLAGS.input, \'rb\') as f:\n      image_data = f.read()\n      input_image = tf.image.decode_jpeg(image_data, channels=3)\n      input_image = tf.image.resize_images(input_image, size=(FLAGS.image_size, FLAGS.image_size))\n      input_image = utils.convert2float(input_image)\n      input_image.set_shape([FLAGS.image_size, FLAGS.image_size, 3])\n\n    with tf.gfile.FastGFile(FLAGS.model, \'rb\') as model_file:\n      graph_def = tf.GraphDef()\n      graph_def.ParseFromString(model_file.read())\n    [output_image] = tf.import_graph_def(graph_def,\n                          input_map={\'input_image\': input_image},\n                          return_elements=[\'output_image:0\'],\n                          name=\'output\')\n\n  with tf.Session(graph=graph) as sess:\n    generated = output_image.eval()\n    with open(FLAGS.output, \'wb\') as f:\n      f.write(generated)\n\ndef main(unused_argv):\n  inference()\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
model.py,32,"b'import tensorflow as tf\nimport ops\nimport utils\nfrom reader import Reader\nfrom discriminator import Discriminator\nfrom generator import Generator\n\nREAL_LABEL = 0.9\n\nclass CycleGAN:\n  def __init__(self,\n               X_train_file=\'\',\n               Y_train_file=\'\',\n               batch_size=1,\n               image_size=256,\n               use_lsgan=True,\n               norm=\'instance\',\n               lambda1=10,\n               lambda2=10,\n               learning_rate=2e-4,\n               beta1=0.5,\n               ngf=64\n              ):\n    """"""\n    Args:\n      X_train_file: string, X tfrecords file for training\n      Y_train_file: string Y tfrecords file for training\n      batch_size: integer, batch size\n      image_size: integer, image size\n      lambda1: integer, weight for forward cycle loss (X->Y->X)\n      lambda2: integer, weight for backward cycle loss (Y->X->Y)\n      use_lsgan: boolean\n      norm: \'instance\' or \'batch\'\n      learning_rate: float, initial learning rate for Adam\n      beta1: float, momentum term of Adam\n      ngf: number of gen filters in first conv layer\n    """"""\n    self.lambda1 = lambda1\n    self.lambda2 = lambda2\n    self.use_lsgan = use_lsgan\n    use_sigmoid = not use_lsgan\n    self.batch_size = batch_size\n    self.image_size = image_size\n    self.learning_rate = learning_rate\n    self.beta1 = beta1\n    self.X_train_file = X_train_file\n    self.Y_train_file = Y_train_file\n\n    self.is_training = tf.placeholder_with_default(True, shape=[], name=\'is_training\')\n\n    self.G = Generator(\'G\', self.is_training, ngf=ngf, norm=norm, image_size=image_size)\n    self.D_Y = Discriminator(\'D_Y\',\n        self.is_training, norm=norm, use_sigmoid=use_sigmoid)\n    self.F = Generator(\'F\', self.is_training, ngf=ngf, norm=norm, image_size=image_size)\n    self.D_X = Discriminator(\'D_X\',\n        self.is_training, norm=norm, use_sigmoid=use_sigmoid)\n\n    self.fake_x = tf.placeholder(tf.float32,\n        shape=[batch_size, image_size, image_size, 3])\n    self.fake_y = tf.placeholder(tf.float32,\n        shape=[batch_size, image_size, image_size, 3])\n\n  def model(self):\n    X_reader = Reader(self.X_train_file, name=\'X\',\n        image_size=self.image_size, batch_size=self.batch_size)\n    Y_reader = Reader(self.Y_train_file, name=\'Y\',\n        image_size=self.image_size, batch_size=self.batch_size)\n\n    x = X_reader.feed()\n    y = Y_reader.feed()\n\n    cycle_loss = self.cycle_consistency_loss(self.G, self.F, x, y)\n\n    # X -> Y\n    fake_y = self.G(x)\n    G_gan_loss = self.generator_loss(self.D_Y, fake_y, use_lsgan=self.use_lsgan)\n    G_loss =  G_gan_loss + cycle_loss\n    D_Y_loss = self.discriminator_loss(self.D_Y, y, self.fake_y, use_lsgan=self.use_lsgan)\n\n    # Y -> X\n    fake_x = self.F(y)\n    F_gan_loss = self.generator_loss(self.D_X, fake_x, use_lsgan=self.use_lsgan)\n    F_loss = F_gan_loss + cycle_loss\n    D_X_loss = self.discriminator_loss(self.D_X, x, self.fake_x, use_lsgan=self.use_lsgan)\n\n    # summary\n    tf.summary.histogram(\'D_Y/true\', self.D_Y(y))\n    tf.summary.histogram(\'D_Y/fake\', self.D_Y(self.G(x)))\n    tf.summary.histogram(\'D_X/true\', self.D_X(x))\n    tf.summary.histogram(\'D_X/fake\', self.D_X(self.F(y)))\n\n    tf.summary.scalar(\'loss/G\', G_gan_loss)\n    tf.summary.scalar(\'loss/D_Y\', D_Y_loss)\n    tf.summary.scalar(\'loss/F\', F_gan_loss)\n    tf.summary.scalar(\'loss/D_X\', D_X_loss)\n    tf.summary.scalar(\'loss/cycle\', cycle_loss)\n\n    tf.summary.image(\'X/generated\', utils.batch_convert2int(self.G(x)))\n    tf.summary.image(\'X/reconstruction\', utils.batch_convert2int(self.F(self.G(x))))\n    tf.summary.image(\'Y/generated\', utils.batch_convert2int(self.F(y)))\n    tf.summary.image(\'Y/reconstruction\', utils.batch_convert2int(self.G(self.F(y))))\n\n    return G_loss, D_Y_loss, F_loss, D_X_loss, fake_y, fake_x\n\n  def optimize(self, G_loss, D_Y_loss, F_loss, D_X_loss):\n    def make_optimizer(loss, variables, name=\'Adam\'):\n      """""" Adam optimizer with learning rate 0.0002 for the first 100k steps (~100 epochs)\n          and a linearly decaying rate that goes to zero over the next 100k steps\n      """"""\n      global_step = tf.Variable(0, trainable=False)\n      starter_learning_rate = self.learning_rate\n      end_learning_rate = 0.0\n      start_decay_step = 100000\n      decay_steps = 100000\n      beta1 = self.beta1\n      learning_rate = (\n          tf.where(\n                  tf.greater_equal(global_step, start_decay_step),\n                  tf.train.polynomial_decay(starter_learning_rate, global_step-start_decay_step,\n                                            decay_steps, end_learning_rate,\n                                            power=1.0),\n                  starter_learning_rate\n          )\n\n      )\n      tf.summary.scalar(\'learning_rate/{}\'.format(name), learning_rate)\n\n      learning_step = (\n          tf.train.AdamOptimizer(learning_rate, beta1=beta1, name=name)\n                  .minimize(loss, global_step=global_step, var_list=variables)\n      )\n      return learning_step\n\n    G_optimizer = make_optimizer(G_loss, self.G.variables, name=\'Adam_G\')\n    D_Y_optimizer = make_optimizer(D_Y_loss, self.D_Y.variables, name=\'Adam_D_Y\')\n    F_optimizer =  make_optimizer(F_loss, self.F.variables, name=\'Adam_F\')\n    D_X_optimizer = make_optimizer(D_X_loss, self.D_X.variables, name=\'Adam_D_X\')\n\n    with tf.control_dependencies([G_optimizer, D_Y_optimizer, F_optimizer, D_X_optimizer]):\n      return tf.no_op(name=\'optimizers\')\n\n  def discriminator_loss(self, D, y, fake_y, use_lsgan=True):\n    """""" Note: default: D(y).shape == (batch_size,5,5,1),\n                       fake_buffer_size=50, batch_size=1\n    Args:\n      G: generator object\n      D: discriminator object\n      y: 4D tensor (batch_size, image_size, image_size, 3)\n    Returns:\n      loss: scalar\n    """"""\n    if use_lsgan:\n      # use mean squared error\n      error_real = tf.reduce_mean(tf.squared_difference(D(y), REAL_LABEL))\n      error_fake = tf.reduce_mean(tf.square(D(fake_y)))\n    else:\n      # use cross entropy\n      error_real = -tf.reduce_mean(ops.safe_log(D(y)))\n      error_fake = -tf.reduce_mean(ops.safe_log(1-D(fake_y)))\n    loss = (error_real + error_fake) / 2\n    return loss\n\n  def generator_loss(self, D, fake_y, use_lsgan=True):\n    """"""  fool discriminator into believing that G(x) is real\n    """"""\n    if use_lsgan:\n      # use mean squared error\n      loss = tf.reduce_mean(tf.squared_difference(D(fake_y), REAL_LABEL))\n    else:\n      # heuristic, non-saturating loss\n      loss = -tf.reduce_mean(ops.safe_log(D(fake_y))) / 2\n    return loss\n\n  def cycle_consistency_loss(self, G, F, x, y):\n    """""" cycle consistency loss (L1 norm)\n    """"""\n    forward_loss = tf.reduce_mean(tf.abs(F(G(x))-x))\n    backward_loss = tf.reduce_mean(tf.abs(G(F(y))-y))\n    loss = self.lambda1*forward_loss + self.lambda2*backward_loss\n    return loss\n'"
ops.py,36,"b'import tensorflow as tf\n\n## Layers: follow the naming convention used in the original paper\n### Generator layers\ndef c7s1_k(input, k, reuse=False, norm=\'instance\', activation=\'relu\', is_training=True, name=\'c7s1_k\'):\n  """""" A 7x7 Convolution-BatchNorm-ReLU layer with k filters and stride 1\n  Args:\n    input: 4D tensor\n    k: integer, number of filters (output depth)\n    norm: \'instance\' or \'batch\' or None\n    activation: \'relu\' or \'tanh\'\n    name: string, e.g. \'c7sk-32\'\n    is_training: boolean or BoolTensor\n    name: string\n    reuse: boolean\n  Returns:\n    4D tensor\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    weights = _weights(""weights"",\n      shape=[7, 7, input.get_shape()[3], k])\n\n    padded = tf.pad(input, [[0,0],[3,3],[3,3],[0,0]], \'REFLECT\')\n    conv = tf.nn.conv2d(padded, weights,\n        strides=[1, 1, 1, 1], padding=\'VALID\')\n\n    normalized = _norm(conv, is_training, norm)\n\n    if activation == \'relu\':\n      output = tf.nn.relu(normalized)\n    if activation == \'tanh\':\n      output = tf.nn.tanh(normalized)\n    return output\n\ndef dk(input, k, reuse=False, norm=\'instance\', is_training=True, name=None):\n  """""" A 3x3 Convolution-BatchNorm-ReLU layer with k filters and stride 2\n  Args:\n    input: 4D tensor\n    k: integer, number of filters (output depth)\n    norm: \'instance\' or \'batch\' or None\n    is_training: boolean or BoolTensor\n    name: string\n    reuse: boolean\n    name: string, e.g. \'d64\'\n  Returns:\n    4D tensor\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    weights = _weights(""weights"",\n      shape=[3, 3, input.get_shape()[3], k])\n\n    conv = tf.nn.conv2d(input, weights,\n        strides=[1, 2, 2, 1], padding=\'SAME\')\n    normalized = _norm(conv, is_training, norm)\n    output = tf.nn.relu(normalized)\n    return output\n\ndef Rk(input, k,  reuse=False, norm=\'instance\', is_training=True, name=None):\n  """""" A residual block that contains two 3x3 convolutional layers\n      with the same number of filters on both layer\n  Args:\n    input: 4D Tensor\n    k: integer, number of filters (output depth)\n    reuse: boolean\n    name: string\n  Returns:\n    4D tensor (same shape as input)\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    with tf.variable_scope(\'layer1\', reuse=reuse):\n      weights1 = _weights(""weights1"",\n        shape=[3, 3, input.get_shape()[3], k])\n      padded1 = tf.pad(input, [[0,0],[1,1],[1,1],[0,0]], \'REFLECT\')\n      conv1 = tf.nn.conv2d(padded1, weights1,\n          strides=[1, 1, 1, 1], padding=\'VALID\')\n      normalized1 = _norm(conv1, is_training, norm)\n      relu1 = tf.nn.relu(normalized1)\n\n    with tf.variable_scope(\'layer2\', reuse=reuse):\n      weights2 = _weights(""weights2"",\n        shape=[3, 3, relu1.get_shape()[3], k])\n\n      padded2 = tf.pad(relu1, [[0,0],[1,1],[1,1],[0,0]], \'REFLECT\')\n      conv2 = tf.nn.conv2d(padded2, weights2,\n          strides=[1, 1, 1, 1], padding=\'VALID\')\n      normalized2 = _norm(conv2, is_training, norm)\n    output = input+normalized2\n    return output\n\ndef n_res_blocks(input, reuse, norm=\'instance\', is_training=True, n=6):\n  depth = input.get_shape()[3]\n  for i in range(1,n+1):\n    output = Rk(input, depth, reuse, norm, is_training, \'R{}_{}\'.format(depth, i))\n    input = output\n  return output\n\ndef uk(input, k, reuse=False, norm=\'instance\', is_training=True, name=None, output_size=None):\n  """""" A 3x3 fractional-strided-Convolution-BatchNorm-ReLU layer\n      with k filters, stride 1/2\n  Args:\n    input: 4D tensor\n    k: integer, number of filters (output depth)\n    norm: \'instance\' or \'batch\' or None\n    is_training: boolean or BoolTensor\n    reuse: boolean\n    name: string, e.g. \'c7sk-32\'\n    output_size: integer, desired output size of layer\n  Returns:\n    4D tensor\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    input_shape = input.get_shape().as_list()\n\n    weights = _weights(""weights"",\n      shape=[3, 3, k, input_shape[3]])\n\n    if not output_size:\n      output_size = input_shape[1]*2\n    output_shape = [input_shape[0], output_size, output_size, k]\n    fsconv = tf.nn.conv2d_transpose(input, weights,\n        output_shape=output_shape,\n        strides=[1, 2, 2, 1], padding=\'SAME\')\n    normalized = _norm(fsconv, is_training, norm)\n    output = tf.nn.relu(normalized)\n    return output\n\n### Discriminator layers\ndef Ck(input, k, slope=0.2, stride=2, reuse=False, norm=\'instance\', is_training=True, name=None):\n  """""" A 4x4 Convolution-BatchNorm-LeakyReLU layer with k filters and stride 2\n  Args:\n    input: 4D tensor\n    k: integer, number of filters (output depth)\n    slope: LeakyReLU\'s slope\n    stride: integer\n    norm: \'instance\' or \'batch\' or None\n    is_training: boolean or BoolTensor\n    reuse: boolean\n    name: string, e.g. \'C64\'\n  Returns:\n    4D tensor\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    weights = _weights(""weights"",\n      shape=[4, 4, input.get_shape()[3], k])\n\n    conv = tf.nn.conv2d(input, weights,\n        strides=[1, stride, stride, 1], padding=\'SAME\')\n\n    normalized = _norm(conv, is_training, norm)\n    output = _leaky_relu(normalized, slope)\n    return output\n\ndef last_conv(input, reuse=False, use_sigmoid=False, name=None):\n  """""" Last convolutional layer of discriminator network\n      (1 filter with size 4x4, stride 1)\n  Args:\n    input: 4D tensor\n    reuse: boolean\n    use_sigmoid: boolean (False if use lsgan)\n    name: string, e.g. \'C64\'\n  """"""\n  with tf.variable_scope(name, reuse=reuse):\n    weights = _weights(""weights"",\n      shape=[4, 4, input.get_shape()[3], 1])\n    biases = _biases(""biases"", [1])\n\n    conv = tf.nn.conv2d(input, weights,\n        strides=[1, 1, 1, 1], padding=\'SAME\')\n    output = conv + biases\n    if use_sigmoid:\n      output = tf.sigmoid(output)\n    return output\n\n### Helpers\ndef _weights(name, shape, mean=0.0, stddev=0.02):\n  """""" Helper to create an initialized Variable\n  Args:\n    name: name of the variable\n    shape: list of ints\n    mean: mean of a Gaussian\n    stddev: standard deviation of a Gaussian\n  Returns:\n    A trainable variable\n  """"""\n  var = tf.get_variable(\n    name, shape,\n    initializer=tf.random_normal_initializer(\n      mean=mean, stddev=stddev, dtype=tf.float32))\n  return var\n\ndef _biases(name, shape, constant=0.0):\n  """""" Helper to create an initialized Bias with constant\n  """"""\n  return tf.get_variable(name, shape,\n            initializer=tf.constant_initializer(constant))\n\ndef _leaky_relu(input, slope):\n  return tf.maximum(slope*input, input)\n\ndef _norm(input, is_training, norm=\'instance\'):\n  """""" Use Instance Normalization or Batch Normalization or None\n  """"""\n  if norm == \'instance\':\n    return _instance_norm(input)\n  elif norm == \'batch\':\n    return _batch_norm(input, is_training)\n  else:\n    return input\n\ndef _batch_norm(input, is_training):\n  """""" Batch Normalization\n  """"""\n  with tf.variable_scope(""batch_norm""):\n    return tf.contrib.layers.batch_norm(input,\n                                        decay=0.9,\n                                        scale=True,\n                                        updates_collections=None,\n                                        is_training=is_training)\n\ndef _instance_norm(input):\n  """""" Instance Normalization\n  """"""\n  with tf.variable_scope(""instance_norm""):\n    depth = input.get_shape()[3]\n    scale = _weights(""scale"", [depth], mean=1.0)\n    offset = _biases(""offset"", [depth])\n    mean, variance = tf.nn.moments(input, axes=[1,2], keep_dims=True)\n    epsilon = 1e-5\n    inv = tf.rsqrt(variance + epsilon)\n    normalized = (input-mean)*inv\n    return scale*normalized + offset\n\ndef safe_log(x, eps=1e-12):\n  return tf.log(x + eps)\n'"
reader.py,16,"b'import tensorflow as tf\nimport utils\n\nclass Reader():\n  def __init__(self, tfrecords_file, image_size=256,\n    min_queue_examples=1000, batch_size=1, num_threads=8, name=\'\'):\n    """"""\n    Args:\n      tfrecords_file: string, tfrecords file path\n      min_queue_examples: integer, minimum number of samples to retain in the queue that provides of batches of examples\n      batch_size: integer, number of images per batch\n      num_threads: integer, number of preprocess threads\n    """"""\n    self.tfrecords_file = tfrecords_file\n    self.image_size = image_size\n    self.min_queue_examples = min_queue_examples\n    self.batch_size = batch_size\n    self.num_threads = num_threads\n    self.reader = tf.TFRecordReader()\n    self.name = name\n\n  def feed(self):\n    """"""\n    Returns:\n      images: 4D tensor [batch_size, image_width, image_height, image_depth]\n    """"""\n    with tf.name_scope(self.name):\n      filename_queue = tf.train.string_input_producer([self.tfrecords_file])\n      reader = tf.TFRecordReader()\n\n      _, serialized_example = self.reader.read(filename_queue)\n      features = tf.parse_single_example(\n          serialized_example,\n          features={\n            \'image/file_name\': tf.FixedLenFeature([], tf.string),\n            \'image/encoded_image\': tf.FixedLenFeature([], tf.string),\n          })\n\n      image_buffer = features[\'image/encoded_image\']\n      image = tf.image.decode_jpeg(image_buffer, channels=3)\n      image = self._preprocess(image)\n      images = tf.train.shuffle_batch(\n            [image], batch_size=self.batch_size, num_threads=self.num_threads,\n            capacity=self.min_queue_examples + 3*self.batch_size,\n            min_after_dequeue=self.min_queue_examples\n          )\n\n      tf.summary.image(\'_input\', images)\n    return images\n\n  def _preprocess(self, image):\n    image = tf.image.resize_images(image, size=(self.image_size, self.image_size))\n    image = utils.convert2float(image)\n    image.set_shape([self.image_size, self.image_size, 3])\n    return image\n\ndef test_reader():\n  TRAIN_FILE_1 = \'data/tfrecords/apple.tfrecords\'\n  TRAIN_FILE_2 = \'data/tfrecords/orange.tfrecords\'\n\n  with tf.Graph().as_default():\n    reader1 = Reader(TRAIN_FILE_1, batch_size=2)\n    reader2 = Reader(TRAIN_FILE_2, batch_size=2)\n    images_op1 = reader1.feed()\n    images_op2 = reader2.feed()\n\n    sess = tf.Session()\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n      step = 0\n      while not coord.should_stop():\n        batch_images1, batch_images2 = sess.run([images_op1, images_op2])\n        print(""image shape: {}"".format(batch_images1))\n        print(""image shape: {}"".format(batch_images2))\n        print(""=""*10)\n        step += 1\n    except KeyboardInterrupt:\n      print(\'Interrupted\')\n      coord.request_stop()\n    except Exception as e:\n      coord.request_stop(e)\n    finally:\n      # When done, ask the threads to stop.\n      coord.request_stop()\n      coord.join(threads)\n\nif __name__ == \'__main__\':\n  test_reader()\n'"
train.py,26,"b'import tensorflow as tf\nfrom model import CycleGAN\nfrom reader import Reader\nfrom datetime import datetime\nimport os\nimport logging\nfrom utils import ImagePool\n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_integer(\'batch_size\', 1, \'batch size, default: 1\')\ntf.flags.DEFINE_integer(\'image_size\', 256, \'image size, default: 256\')\ntf.flags.DEFINE_bool(\'use_lsgan\', True,\n                     \'use lsgan (mean squared error) or cross entropy loss, default: True\')\ntf.flags.DEFINE_string(\'norm\', \'instance\',\n                       \'[instance, batch] use instance norm or batch norm, default: instance\')\ntf.flags.DEFINE_integer(\'lambda1\', 10,\n                        \'weight for forward cycle loss (X->Y->X), default: 10\')\ntf.flags.DEFINE_integer(\'lambda2\', 10,\n                        \'weight for backward cycle loss (Y->X->Y), default: 10\')\ntf.flags.DEFINE_float(\'learning_rate\', 2e-4,\n                      \'initial learning rate for Adam, default: 0.0002\')\ntf.flags.DEFINE_float(\'beta1\', 0.5,\n                      \'momentum term of Adam, default: 0.5\')\ntf.flags.DEFINE_float(\'pool_size\', 50,\n                      \'size of image buffer that stores previously generated images, default: 50\')\ntf.flags.DEFINE_integer(\'ngf\', 64,\n                        \'number of gen filters in first conv layer, default: 64\')\n\ntf.flags.DEFINE_string(\'X\', \'data/tfrecords/apple.tfrecords\',\n                       \'X tfrecords file for training, default: data/tfrecords/apple.tfrecords\')\ntf.flags.DEFINE_string(\'Y\', \'data/tfrecords/orange.tfrecords\',\n                       \'Y tfrecords file for training, default: data/tfrecords/orange.tfrecords\')\ntf.flags.DEFINE_string(\'load_model\', None,\n                        \'folder of saved model that you wish to continue training (e.g. 20170602-1936), default: None\')\n\n\ndef train():\n  if FLAGS.load_model is not None:\n    checkpoints_dir = ""checkpoints/"" + FLAGS.load_model.lstrip(""checkpoints/"")\n  else:\n    current_time = datetime.now().strftime(""%Y%m%d-%H%M"")\n    checkpoints_dir = ""checkpoints/{}"".format(current_time)\n    try:\n      os.makedirs(checkpoints_dir)\n    except os.error:\n      pass\n\n  graph = tf.Graph()\n  with graph.as_default():\n    cycle_gan = CycleGAN(\n        X_train_file=FLAGS.X,\n        Y_train_file=FLAGS.Y,\n        batch_size=FLAGS.batch_size,\n        image_size=FLAGS.image_size,\n        use_lsgan=FLAGS.use_lsgan,\n        norm=FLAGS.norm,\n        lambda1=FLAGS.lambda1,\n        lambda2=FLAGS.lambda2,\n        learning_rate=FLAGS.learning_rate,\n        beta1=FLAGS.beta1,\n        ngf=FLAGS.ngf\n    )\n    G_loss, D_Y_loss, F_loss, D_X_loss, fake_y, fake_x = cycle_gan.model()\n    optimizers = cycle_gan.optimize(G_loss, D_Y_loss, F_loss, D_X_loss)\n\n    summary_op = tf.summary.merge_all()\n    train_writer = tf.summary.FileWriter(checkpoints_dir, graph)\n    saver = tf.train.Saver()\n\n  with tf.Session(graph=graph) as sess:\n    if FLAGS.load_model is not None:\n      checkpoint = tf.train.get_checkpoint_state(checkpoints_dir)\n      meta_graph_path = checkpoint.model_checkpoint_path + "".meta""\n      restore = tf.train.import_meta_graph(meta_graph_path)\n      restore.restore(sess, tf.train.latest_checkpoint(checkpoints_dir))\n      step = int(meta_graph_path.split(""-"")[2].split(""."")[0])\n    else:\n      sess.run(tf.global_variables_initializer())\n      step = 0\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n      fake_Y_pool = ImagePool(FLAGS.pool_size)\n      fake_X_pool = ImagePool(FLAGS.pool_size)\n\n      while not coord.should_stop():\n        # get previously generated images\n        fake_y_val, fake_x_val = sess.run([fake_y, fake_x])\n\n        # train\n        _, G_loss_val, D_Y_loss_val, F_loss_val, D_X_loss_val, summary = (\n              sess.run(\n                  [optimizers, G_loss, D_Y_loss, F_loss, D_X_loss, summary_op],\n                  feed_dict={cycle_gan.fake_y: fake_Y_pool.query(fake_y_val),\n                             cycle_gan.fake_x: fake_X_pool.query(fake_x_val)}\n              )\n        )\n\n        train_writer.add_summary(summary, step)\n        train_writer.flush()\n\n        if step % 100 == 0:\n          logging.info(\'-----------Step %d:-------------\' % step)\n          logging.info(\'  G_loss   : {}\'.format(G_loss_val))\n          logging.info(\'  D_Y_loss : {}\'.format(D_Y_loss_val))\n          logging.info(\'  F_loss   : {}\'.format(F_loss_val))\n          logging.info(\'  D_X_loss : {}\'.format(D_X_loss_val))\n\n        if step % 10000 == 0:\n          save_path = saver.save(sess, checkpoints_dir + ""/model.ckpt"", global_step=step)\n          logging.info(""Model saved in file: %s"" % save_path)\n\n        step += 1\n\n    except KeyboardInterrupt:\n      logging.info(\'Interrupted\')\n      coord.request_stop()\n    except Exception as e:\n      coord.request_stop(e)\n    finally:\n      save_path = saver.save(sess, checkpoints_dir + ""/model.ckpt"", global_step=step)\n      logging.info(""Model saved in file: %s"" % save_path)\n      # When done, ask the threads to stop.\n      coord.request_stop()\n      coord.join(threads)\n\ndef main(unused_argv):\n  train()\n\nif __name__ == \'__main__\':\n  logging.basicConfig(level=logging.INFO)\n  tf.app.run()\n'"
utils.py,4,"b'import tensorflow as tf\nimport random\n\ndef convert2int(image):\n  """""" Transfrom from float tensor ([-1.,1.]) to int image ([0,255])\n  """"""\n  return tf.image.convert_image_dtype((image+1.0)/2.0, tf.uint8)\n\ndef convert2float(image):\n  """""" Transfrom from int image ([0,255]) to float tensor ([-1.,1.])\n  """"""\n  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n  return (image/127.5) - 1.0\n\ndef batch_convert2int(images):\n  """"""\n  Args:\n    images: 4D float tensor (batch_size, image_size, image_size, depth)\n  Returns:\n    4D int tensor\n  """"""\n  return tf.map_fn(convert2int, images, dtype=tf.uint8)\n\ndef batch_convert2float(images):\n  """"""\n  Args:\n    images: 4D int tensor (batch_size, image_size, image_size, depth)\n  Returns:\n    4D float tensor\n  """"""\n  return tf.map_fn(convert2float, images, dtype=tf.float32)\n\nclass ImagePool:\n  """""" History of generated images\n      Same logic as https://github.com/junyanz/CycleGAN/blob/master/util/image_pool.lua\n  """"""\n  def __init__(self, pool_size):\n    self.pool_size = pool_size\n    self.images = []\n\n  def query(self, image):\n    if self.pool_size == 0:\n      return image\n\n    if len(self.images) < self.pool_size:\n      self.images.append(image)\n      return image\n    else:\n      p = random.random()\n      if p > 0.5:\n        # use old image\n        random_id = random.randrange(0, self.pool_size)\n        tmp = self.images[random_id].copy()\n        self.images[random_id] = image.copy()\n        return tmp\n      else:\n        return image\n\n'"
