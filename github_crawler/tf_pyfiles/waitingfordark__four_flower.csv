file_path,api_count,code
create record.py,18,"b'# \xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe5\xb9\xb6\xe5\xb0\x86\xe5\x85\xb6\xe4\xbf\x9d\xe5\xad\x98\n# ========================================================================================\nimport os\nimport tensorflow as tf\nfrom PIL import Image\n\n# \xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\xad\x98\xe5\x82\xa8\xe4\xbd\x8d\xe7\xbd\xae\norig_picture = \'D:/ML/flower/flower_photos/\'\n\n# \xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\xad\x98\xe5\x82\xa8\xe4\xbd\x8d\xe7\xbd\xae\ngen_picture = \'D:/ML/flower/input_data/\'\n\n# \xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe8\xaf\x86\xe5\x88\xab\xe7\xb1\xbb\xe5\x9e\x8b\nclasses = {\'dandelion\', \'roses\', \'sunflowers\',\'tulips\'}\n\n# \xe6\xa0\xb7\xe6\x9c\xac\xe6\x80\xbb\xe6\x95\xb0\nnum_samples = 4000\n\n\n# \xe5\x88\xb6\xe4\xbd\x9cTFRecords\xe6\x95\xb0\xe6\x8d\xae\ndef create_record():\n    writer = tf.python_io.TFRecordWriter(""flower_train.tfrecords"")\n    for index, name in enumerate(classes):\n        class_path = orig_picture + ""/"" + name + ""/""\n        for img_name in os.listdir(class_path):\n            img_path = class_path + img_name\n            img = Image.open(img_path)\n            img = img.resize((64, 64))  # \xe8\xae\xbe\xe7\xbd\xae\xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe6\x8d\xa2\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\n            img_raw = img.tobytes()  # \xe5\xb0\x86\xe5\x9b\xbe\xe7\x89\x87\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe5\x8e\x9f\xe7\x94\x9fbytes\n            print(index, img_raw)\n            example = tf.train.Example(\n                features=tf.train.Features(feature={\n                    ""label"": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n                    \'img_raw\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n                }))\n            writer.write(example.SerializeToString())\n    writer.close()\n\n\n# =======================================================================================\ndef read_and_decode(filename):\n    # \xe5\x88\x9b\xe5\xbb\xba\xe6\x96\x87\xe4\xbb\xb6\xe9\x98\x9f\xe5\x88\x97,\xe4\xb8\x8d\xe9\x99\x90\xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe9\x87\x8f\n    filename_queue = tf.train.string_input_producer([filename])\n    # create a reader from file queue\n    reader = tf.TFRecordReader()\n    # reader\xe4\xbb\x8e\xe6\x96\x87\xe4\xbb\xb6\xe9\x98\x9f\xe5\x88\x97\xe4\xb8\xad\xe8\xaf\xbb\xe5\x85\xa5\xe4\xb8\x80\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe5\x8c\x96\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\n    _, serialized_example = reader.read(filename_queue)\n    # get feature from serialized example\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe7\xac\xa6\xe5\x8f\xb7\xe5\x8c\x96\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\n    features = tf.parse_single_example(\n        serialized_example,\n        features={\n            \'label\': tf.FixedLenFeature([], tf.int64),\n            \'img_raw\': tf.FixedLenFeature([], tf.string)\n        })\n    label = features[\'label\']\n    img = features[\'img_raw\']\n    img = tf.decode_raw(img, tf.uint8)\n    img = tf.reshape(img, [64, 64, 3])\n    # img = tf.cast(img, tf.float32) * (1. / 255) - 0.5\n    label = tf.cast(label, tf.int32)\n    return img, label\n\n\n# =======================================================================================\nif __name__ == \'__main__\':\n    create_record()\n    batch = read_and_decode(\'flower_train.tfrecords\')\n    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n\n    with tf.Session() as sess:  # \xe5\xbc\x80\xe5\xa7\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbc\x9a\xe8\xaf\x9d\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n\n        for i in range(num_samples):\n            example, lab = sess.run(batch)  # \xe5\x9c\xa8\xe4\xbc\x9a\xe8\xaf\x9d\xe4\xb8\xad\xe5\x8f\x96\xe5\x87\xbaimage\xe5\x92\x8clabel\n            img = Image.fromarray(example, \'RGB\')  # \xe8\xbf\x99\xe9\x87\x8cImage\xe6\x98\xaf\xe4\xb9\x8b\xe5\x89\x8d\xe6\x8f\x90\xe5\x88\xb0\xe7\x9a\x84\n            img.save(gen_picture + \'/\' + str(i) + \'samples\' + str(lab) + \'.jpg\')  # \xe5\xad\x98\xe4\xb8\x8b\xe5\x9b\xbe\xe7\x89\x87;\xe6\xb3\xa8\xe6\x84\x8fcwd\xe5\x90\x8e\xe8\xbe\xb9\xe5\x8a\xa0\xe4\xb8\x8a\xe2\x80\x98/\xe2\x80\x99\n            print(example, lab)\n        coord.request_stop()\n        coord.join(threads)\n        sess.close()'"
gui.py,0,"b'#!/bin/python\n\nimport wx\nfrom test import evaluate_one_image\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\n\n\nclass HelloFrame(wx.Frame):\n\n    def __init__(self,*args,**kw):\n        super(HelloFrame,self).__init__(*args,**kw)\n\n        pnl = wx.Panel(self)\n\n        self.pnl = pnl\n        st = wx.StaticText(pnl, label=""\xe8\x8a\xb1\xe6\x9c\xb5\xe8\xaf\x86\xe5\x88\xab"", pos=(200, 0))\n        font = st.GetFont()\n        font.PointSize += 10\n        font = font.Bold()\n        st.SetFont(font)\n\n        # \xe9\x80\x89\xe6\x8b\xa9\xe5\x9b\xbe\xe5\x83\x8f\xe6\x96\x87\xe4\xbb\xb6\xe6\x8c\x89\xe9\x92\xae\n        btn = wx.Button(pnl, -1, ""select"")\n        btn.Bind(wx.EVT_BUTTON, self.OnSelect)\n\n        self.makeMenuBar()\n\n        self.CreateStatusBar()\n        self.SetStatusText(""Welcome to flower world"")\n\n    def makeMenuBar(self):\n        fileMenu = wx.Menu()\n        helloItem = fileMenu.Append(-1, ""&Hello...\\tCtrl-H"",\n                                    ""Help string shown in status bar for this menu item"")\n        fileMenu.AppendSeparator()\n\n        exitItem = fileMenu.Append(wx.ID_EXIT)\n        helpMenu = wx.Menu()\n        aboutItem = helpMenu.Append(wx.ID_ABOUT)\n\n        menuBar = wx.MenuBar()\n        menuBar.Append(fileMenu, ""&File"")\n        menuBar.Append(helpMenu, ""Help"")\n\n        self.SetMenuBar(menuBar)\n\n        self.Bind(wx.EVT_MENU, self.OnHello, helloItem)\n        self.Bind(wx.EVT_MENU, self.OnExit, exitItem)\n        self.Bind(wx.EVT_MENU, self.OnAbout, aboutItem)\n\n    def OnExit(self, event):\n        self.Close(True)\n\n    def OnHello(self, event):\n        wx.MessageBox(""Hello again from wxPython"")\n\n    def OnAbout(self, event):\n        """"""Display an About Dialog""""""\n        wx.MessageBox(""This is a wxPython Hello World sample"",\n                      ""About Hello World 2"",\n                      wx.OK | wx.ICON_INFORMATION)\n\n    def OnSelect(self, event):\n        wildcard = ""image source(*.jpg)|*.jpg|"" \\\n                   ""Compile Python(*.pyc)|*.pyc|"" \\\n                   ""All file(*.*)|*.*""\n        dialog = wx.FileDialog(None, ""Choose a file"", os.getcwd(),\n                               """", wildcard, wx.ID_OPEN)\n        if dialog.ShowModal() == wx.ID_OK:\n            print(dialog.GetPath())\n            img = Image.open(dialog.GetPath())\n            imag = img.resize([64, 64])\n            image = np.array(imag)\n            result = evaluate_one_image(image)\n            result_text = wx.StaticText(self.pnl, label=result, pos=(320, 0))\n            font = result_text.GetFont()\n            font.PointSize += 8\n            result_text.SetFont(font)\n            self.initimage(name= dialog.GetPath())\n\n    # \xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe7\x89\x87\xe6\x8e\xa7\xe4\xbb\xb6\n    def initimage(self, name):\n        imageShow = wx.Image(name, wx.BITMAP_TYPE_ANY)\n        sb = wx.StaticBitmap(self.pnl, -1, imageShow.ConvertToBitmap(), pos=(0,30), size=(600,400))\n        return sb\n\n\nif __name__ == \'__main__\':\n\n    app = wx.App()\n    frm = HelloFrame(None, title=\'flower wolrd\', size=(1000,600))\n    frm.Show()\n    app.MainLoop()'"
input_data.py,13,"b""import os\nimport math\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# ============================================================================\n# -----------------\xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84List------------------------------------\n\ntrain_dir = 'D:/ML/flower/input_data'\n\nroses = []\nlabel_roses = []\ntulips = []\nlabel_tulips = []\ndandelion = []\nlabel_dandelion = []\nsunflowers = []\nlabel_sunflowers = []\n\n\n# step1\xef\xbc\x9a\xe8\x8e\xb7\xe5\x8f\x96\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\xe5\x90\x8d\xef\xbc\x8c\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0\n# \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xad\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe8\xb4\xb4\xe4\xb8\x8a\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x8c\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0label\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xad\xe3\x80\x82\ndef get_files(file_dir, ratio):\n    for file in os.listdir(file_dir + '/roses'):\n        roses.append(file_dir + '/roses' + '/' + file)\n        label_roses.append(0)\n    for file in os.listdir(file_dir + '/tulips'):\n        tulips.append(file_dir + '/tulips' + '/' + file)\n        label_tulips.append(1)\n    for file in os.listdir(file_dir + '/dandelion'):\n        dandelion.append(file_dir + '/dandelion' + '/' + file)\n        label_dandelion.append(2)\n    for file in os.listdir(file_dir + '/sunflowers'):\n        sunflowers.append(file_dir + '/sunflowers' + '/' + file)\n        label_sunflowers.append(3)\n\n    # step2\xef\xbc\x9a\xe5\xaf\xb9\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbeList\xe5\x81\x9a\xe6\x89\x93\xe4\xb9\xb1\xe5\xa4\x84\xe7\x90\x86\n    image_list = np.hstack((roses, tulips, dandelion, sunflowers))\n    label_list = np.hstack((label_roses, label_tulips, label_dandelion, label_sunflowers))\n\n    # \xe5\x88\xa9\xe7\x94\xa8shuffle\xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\n    temp = np.array([image_list, label_list])\n    temp = temp.transpose()\n    np.random.shuffle(temp)\n\n    # \xe4\xbb\x8e\xe6\x89\x93\xe4\xb9\xb1\xe7\x9a\x84temp\xe4\xb8\xad\xe5\x86\x8d\xe5\x8f\x96\xe5\x87\xbalist\xef\xbc\x88img\xe5\x92\x8clab\xef\xbc\x89\n    # image_list = list(temp[:, 0])\n    # label_list = list(temp[:, 1])\n    # label_list = [int(i) for i in label_list]\n    # return image_list, label_list\n\n    # \xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84img\xe5\x92\x8clab\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90list\n    all_image_list = list(temp[:, 0])\n    all_label_list = list(temp[:, 1])\n\n    # \xe5\xb0\x86\xe6\x89\x80\xe5\xbe\x97List\xe5\x88\x86\xe4\xb8\xba\xe4\xb8\xa4\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x8c\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xe7\x94\xa8\xe6\x9d\xa5\xe8\xae\xad\xe7\xbb\x83tra\xef\xbc\x8c\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xe7\x94\xa8\xe6\x9d\xa5\xe6\xb5\x8b\xe8\xaf\x95val\n    # ratio\xe6\x98\xaf\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\n    n_sample = len(all_label_list)\n    n_val = int(math.ceil(n_sample * ratio))  # \xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\n    n_train = n_sample - n_val  # \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\n\n    tra_images = all_image_list[0:n_train]\n    tra_labels = all_label_list[0:n_train]\n    tra_labels = [int(float(i)) for i in tra_labels]\n    val_images = all_image_list[n_train:-1]\n    val_labels = all_label_list[n_train:-1]\n    val_labels = [int(float(i)) for i in val_labels]\n\n    return tra_images, tra_labels, val_images, val_labels\n\n\n# ---------------------------------------------------------------------------\n# --------------------\xe7\x94\x9f\xe6\x88\x90Batch----------------------------------------------\n\n# step1\xef\xbc\x9a\xe5\xb0\x86\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84List\xe4\xbc\xa0\xe5\x85\xa5get_batch() \xef\xbc\x8c\xe8\xbd\xac\xe6\x8d\xa2\xe7\xb1\xbb\xe5\x9e\x8b\xef\xbc\x8c\xe4\xba\xa7\xe7\x94\x9f\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbe\x93\xe5\x85\xa5\xe9\x98\x9f\xe5\x88\x97queue\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbaimg\xe5\x92\x8clab\n# \xe6\x98\xaf\xe5\x88\x86\xe5\xbc\x80\xe7\x9a\x84\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xbd\xbf\xe7\x94\xa8tf.train.slice_input_producer()\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\x94\xa8tf.read_file()\xe4\xbb\x8e\xe9\x98\x9f\xe5\x88\x97\xe4\xb8\xad\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\n#   image_W, image_H, \xef\xbc\x9a\xe8\xae\xbe\xe7\xbd\xae\xe5\xa5\xbd\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe9\xab\x98\xe5\xba\xa6\xe5\x92\x8c\xe5\xae\xbd\xe5\xba\xa6\n#   \xe8\xae\xbe\xe7\xbd\xaebatch_size\xef\xbc\x9a\xe6\xaf\x8f\xe4\xb8\xaabatch\xe8\xa6\x81\xe6\x94\xbe\xe5\xa4\x9a\xe5\xb0\x91\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\n#   capacity\xef\xbc\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe9\x98\x9f\xe5\x88\x97\xe6\x9c\x80\xe5\xa4\xa7\xe5\xa4\x9a\xe5\xb0\x91\ndef get_batch(image, label, image_W, image_H, batch_size, capacity):\n    # \xe8\xbd\xac\xe6\x8d\xa2\xe7\xb1\xbb\xe5\x9e\x8b\n    image = tf.cast(image, tf.string)\n    label = tf.cast(label, tf.int32)\n\n    # make an input queue\n    input_queue = tf.train.slice_input_producer([image, label])\n\n    label = input_queue[1]\n    image_contents = tf.read_file(input_queue[0])  # read img from a queue\n\n    # step2\xef\xbc\x9a\xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8f\xe8\xa7\xa3\xe7\xa0\x81\xef\xbc\x8c\xe4\xb8\x8d\xe5\x90\x8c\xe7\xb1\xbb\xe5\x9e\x8b\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe4\xb8\x8d\xe8\x83\xbd\xe6\xb7\xb7\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\xef\xbc\x8c\xe8\xa6\x81\xe4\xb9\x88\xe5\x8f\xaa\xe7\x94\xa8jpeg\xef\xbc\x8c\xe8\xa6\x81\xe4\xb9\x88\xe5\x8f\xaa\xe7\x94\xa8png\xe7\xad\x89\xe3\x80\x82\n    image = tf.image.decode_jpeg(image_contents, channels=3)\n\n    # step3\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x97\x8b\xe8\xbd\xac\xe3\x80\x81\xe7\xbc\xa9\xe6\x94\xbe\xe3\x80\x81\xe8\xa3\x81\xe5\x89\xaa\xe3\x80\x81\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\xad\x89\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe8\xae\xa9\xe8\xae\xa1\xe7\xae\x97\xe5\x87\xba\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9b\xb4\xe5\x81\xa5\xe5\xa3\xae\xe3\x80\x82\n    image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)\n    image = tf.image.per_image_standardization(image)\n\n    # step4\xef\xbc\x9a\xe7\x94\x9f\xe6\x88\x90batch\n    # image_batch: 4D tensor [batch_size, width, height, 3],dtype=tf.float32\n    # label_batch: 1D tensor [batch_size], dtype=tf.int32\n    image_batch, label_batch = tf.train.batch([image, label],\n                                              batch_size=batch_size,\n                                              num_threads=32,\n                                              capacity=capacity)\n    # \xe9\x87\x8d\xe6\x96\xb0\xe6\x8e\x92\xe5\x88\x97label\xef\xbc\x8c\xe8\xa1\x8c\xe6\x95\xb0\xe4\xb8\xba[batch_size]\n    label_batch = tf.reshape(label_batch, [batch_size])\n    image_batch = tf.cast(image_batch, tf.float32)\n    return image_batch, label_batch\n"""
model.py,56,"b""# =========================================================================\nimport tensorflow as tf\n\n\n# =========================================================================\n# \xe7\xbd\x91\xe7\xbb\x9c\xe7\xbb\x93\xe6\x9e\x84\xe5\xae\x9a\xe4\xb9\x89\n# \xe8\xbe\x93\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9aimages\xef\xbc\x8cimage batch\xe3\x80\x814D tensor\xe3\x80\x81tf.float32\xe3\x80\x81[batch_size, width, height, channels]\n# \xe8\xbf\x94\xe5\x9b\x9e\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9alogits, float\xe3\x80\x81 [batch_size, n_classes]\ndef inference(images, batch_size, n_classes):\n    # \xe4\xb8\x80\xe4\xb8\xaa\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe5\x8d\xb7\xe7\xa7\xaf\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe5\x8d\xb7\xe7\xa7\xaf+\xe6\xb1\xa0\xe5\x8c\x96\xe5\xb1\x82x2\xef\xbc\x8c\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82x2\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaasoftmax\xe5\xb1\x82\xe5\x81\x9a\xe5\x88\x86\xe7\xb1\xbb\xe3\x80\x82\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe5\xb1\x821\n    # 64\xe4\xb8\xaa3x3\xe7\x9a\x84\xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xef\xbc\x883\xe9\x80\x9a\xe9\x81\x93\xef\xbc\x89\xef\xbc\x8cpadding=\xe2\x80\x99SAME\xe2\x80\x99\xef\xbc\x8c\xe8\xa1\xa8\xe7\xa4\xbapadding\xe5\x90\x8e\xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9a\x84\xe5\x9b\xbe\xe4\xb8\x8e\xe5\x8e\x9f\xe5\x9b\xbe\xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0relu()\n    with tf.variable_scope('conv1') as scope:\n        weights = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], stddev=1.0, dtype=tf.float32),\n                              name='weights', dtype=tf.float32)\n\n        biases = tf.Variable(tf.constant(value=0.1, dtype=tf.float32, shape=[64]),\n                             name='biases', dtype=tf.float32)\n\n        conv = tf.nn.conv2d(images, weights, strides=[1, 1, 1, 1], padding='SAME')\n        pre_activation = tf.nn.bias_add(conv, biases)\n        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n\n    # \xe6\xb1\xa0\xe5\x8c\x96\xe5\xb1\x821\n    # 3x3\xe6\x9c\x80\xe5\xa4\xa7\xe6\xb1\xa0\xe5\x8c\x96\xef\xbc\x8c\xe6\xad\xa5\xe9\x95\xbfstrides\xe4\xb8\xba2\xef\xbc\x8c\xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe6\x89\xa7\xe8\xa1\x8clrn()\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\xe5\xb1\x80\xe9\x83\xa8\xe5\x93\x8d\xe5\xba\x94\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x8c\xe5\xaf\xb9\xe8\xae\xad\xe7\xbb\x83\xe6\x9c\x89\xe5\x88\xa9\xe3\x80\x82\n    with tf.variable_scope('pooling1_lrn') as scope:\n        pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pooling1')\n        norm1 = tf.nn.lrn(pool1, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe5\xb1\x822\n    # 16\xe4\xb8\xaa3x3\xe7\x9a\x84\xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xef\xbc\x8816\xe9\x80\x9a\xe9\x81\x93\xef\xbc\x89\xef\xbc\x8cpadding=\xe2\x80\x99SAME\xe2\x80\x99\xef\xbc\x8c\xe8\xa1\xa8\xe7\xa4\xbapadding\xe5\x90\x8e\xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9a\x84\xe5\x9b\xbe\xe4\xb8\x8e\xe5\x8e\x9f\xe5\x9b\xbe\xe5\xb0\xba\xe5\xaf\xb8\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0relu()\n    with tf.variable_scope('conv2') as scope:\n        weights = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 16], stddev=0.1, dtype=tf.float32),\n                              name='weights', dtype=tf.float32)\n\n        biases = tf.Variable(tf.constant(value=0.1, dtype=tf.float32, shape=[16]),\n                             name='biases', dtype=tf.float32)\n\n        conv = tf.nn.conv2d(norm1, weights, strides=[1, 1, 1, 1], padding='SAME')\n        pre_activation = tf.nn.bias_add(conv, biases)\n        conv2 = tf.nn.relu(pre_activation, name='conv2')\n\n    # \xe6\xb1\xa0\xe5\x8c\x96\xe5\xb1\x822\n    # 3x3\xe6\x9c\x80\xe5\xa4\xa7\xe6\xb1\xa0\xe5\x8c\x96\xef\xbc\x8c\xe6\xad\xa5\xe9\x95\xbfstrides\xe4\xb8\xba2\xef\xbc\x8c\xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe6\x89\xa7\xe8\xa1\x8clrn()\xe6\x93\x8d\xe4\xbd\x9c\xef\xbc\x8c\n    # pool2 and norm2\n    with tf.variable_scope('pooling2_lrn') as scope:\n        norm2 = tf.nn.lrn(conv2, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n        pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='pooling2')\n\n    # \xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x823\n    # 128\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xef\xbc\x8c\xe5\xb0\x86\xe4\xb9\x8b\xe5\x89\x8dpool\xe5\xb1\x82\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xbareshape\xe6\x88\x90\xe4\xb8\x80\xe8\xa1\x8c\xef\xbc\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0relu()\n    with tf.variable_scope('local3') as scope:\n        reshape = tf.reshape(pool2, shape=[batch_size, -1])\n        dim = reshape.get_shape()[1].value\n        weights = tf.Variable(tf.truncated_normal(shape=[dim, 128], stddev=0.005, dtype=tf.float32),\n                              name='weights', dtype=tf.float32)\n\n        biases = tf.Variable(tf.constant(value=0.1, dtype=tf.float32, shape=[128]),\n                             name='biases', dtype=tf.float32)\n\n        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n\n    # \xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x824\n    # 128\xe4\xb8\xaa\xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xef\xbc\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0relu()\n    with tf.variable_scope('local4') as scope:\n        weights = tf.Variable(tf.truncated_normal(shape=[128, 128], stddev=0.005, dtype=tf.float32),\n                              name='weights', dtype=tf.float32)\n\n        biases = tf.Variable(tf.constant(value=0.1, dtype=tf.float32, shape=[128]),\n                             name='biases', dtype=tf.float32)\n\n        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name='local4')\n\n    # dropout\xe5\xb1\x82\n    #    with tf.variable_scope('dropout') as scope:\n    #        drop_out = tf.nn.dropout(local4, 0.8)\n\n    # Softmax\xe5\x9b\x9e\xe5\xbd\x92\xe5\xb1\x82\n    # \xe5\xb0\x86\xe5\x89\x8d\xe9\x9d\xa2\xe7\x9a\x84FC\xe5\xb1\x82\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe5\x81\x9a\xe4\xb8\x80\xe4\xb8\xaa\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\x87\xba\xe6\xaf\x8f\xe4\xb8\x80\xe7\xb1\xbb\xe7\x9a\x84\xe5\xbe\x97\xe5\x88\x86\n    with tf.variable_scope('softmax_linear') as scope:\n        weights = tf.Variable(tf.truncated_normal(shape=[128, n_classes], stddev=0.005, dtype=tf.float32),\n                              name='softmax_linear', dtype=tf.float32)\n\n        biases = tf.Variable(tf.constant(value=0.1, dtype=tf.float32, shape=[n_classes]),\n                             name='biases', dtype=tf.float32)\n\n        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name='softmax_linear')\n\n    return softmax_linear\n\n\n# -----------------------------------------------------------------------------\n# loss\xe8\xae\xa1\xe7\xae\x97\n# \xe4\xbc\xa0\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9alogits\xef\xbc\x8c\xe7\xbd\x91\xe7\xbb\x9c\xe8\xae\xa1\xe7\xae\x97\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\xe3\x80\x82labels\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe6\x98\xaf0\xe6\x88\x96\xe8\x80\x851\n# \xe8\xbf\x94\xe5\x9b\x9e\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9aloss\xef\xbc\x8c\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x80\xbc\ndef losses(logits, labels):\n    with tf.variable_scope('loss') as scope:\n        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels,\n                                                                       name='xentropy_per_example')\n        loss = tf.reduce_mean(cross_entropy, name='loss')\n        tf.summary.scalar(scope.name + '/loss', loss)\n    return loss\n\n\n# --------------------------------------------------------------------------\n# loss\xe6\x8d\x9f\xe5\xa4\xb1\xe5\x80\xbc\xe4\xbc\x98\xe5\x8c\x96\n# \xe8\xbe\x93\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9aloss\xe3\x80\x82learning_rate\xef\xbc\x8c\xe5\xad\xa6\xe4\xb9\xa0\xe9\x80\x9f\xe7\x8e\x87\xe3\x80\x82\n# \xe8\xbf\x94\xe5\x9b\x9e\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9atrain_op\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83op\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe8\xa6\x81\xe8\xbe\x93\xe5\x85\xa5sess.run\xe4\xb8\xad\xe8\xae\xa9\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x8e\xbb\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x82\ndef trainning(loss, learning_rate):\n    with tf.name_scope('optimizer'):\n        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        train_op = optimizer.minimize(loss, global_step=global_step)\n    return train_op\n\n\n# -----------------------------------------------------------------------\n# \xe8\xaf\x84\xe4\xbb\xb7/\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\xe8\xae\xa1\xe7\xae\x97\n# \xe8\xbe\x93\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9alogits\xef\xbc\x8c\xe7\xbd\x91\xe7\xbb\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x80\xbc\xe3\x80\x82labels\xef\xbc\x8c\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe6\x98\xaf0\xe6\x88\x96\xe8\x80\x851\xe3\x80\x82\n# \xe8\xbf\x94\xe5\x9b\x9e\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9aaccuracy\xef\xbc\x8c\xe5\xbd\x93\xe5\x89\x8dstep\xe7\x9a\x84\xe5\xb9\xb3\xe5\x9d\x87\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe5\x9c\xa8\xe8\xbf\x99\xe4\xba\x9bbatch\xe4\xb8\xad\xe5\xa4\x9a\xe5\xb0\x91\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe8\xa2\xab\xe6\xad\xa3\xe7\xa1\xae\xe5\x88\x86\xe7\xb1\xbb\xe4\xba\x86\xe3\x80\x82\ndef evaluation(logits, labels):\n    with tf.variable_scope('accuracy') as scope:\n        correct = tf.nn.in_top_k(logits, labels, 1)\n        correct = tf.cast(correct, tf.float16)\n        accuracy = tf.reduce_mean(correct)\n        tf.summary.scalar(scope.name + '/accuracy', accuracy)\n    return accuracy\n"""
test.py,9,"b'from PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport model\nfrom input_data import get_files\n\n# \xe8\x8e\xb7\xe5\x8f\x96\xe4\xb8\x80\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\ndef get_one_image(train):\n    # \xe8\xbe\x93\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9atrain,\xe8\xae\xad\xe7\xbb\x83\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9aimage\xef\xbc\x8c\xe4\xbb\x8e\xe8\xae\xad\xe7\xbb\x83\xe5\x9b\xbe\xe7\x89\x87\xe4\xb8\xad\xe9\x9a\x8f\xe6\x9c\xba\xe6\x8a\xbd\xe5\x8f\x96\xe4\xb8\x80\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\n    n = len(train)\n    ind = np.random.randint(0, n)\n    img_dir = train[ind]  # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n\n    img = Image.open(img_dir)\n    plt.imshow(img)\n    plt.show()\n    image = np.array(img)\n    return image\n\n\n# \xe6\xb5\x8b\xe8\xaf\x95\xe5\x9b\xbe\xe7\x89\x87\ndef evaluate_one_image(image_array):\n    with tf.Graph().as_default():\n        BATCH_SIZE = 1\n        N_CLASSES = 4\n\n        image = tf.cast(image_array, tf.float32)\n        image = tf.image.per_image_standardization(image)\n        image = tf.reshape(image, [1, 64, 64, 3])\n\n        logit = model.inference(image, BATCH_SIZE, N_CLASSES)\n\n        logit = tf.nn.softmax(logit)\n\n        x = tf.placeholder(tf.float32, shape=[64, 64, 3])\n\n        # you need to change the directories to yours.\n        logs_train_dir = \'D:/ML/flower/save/\'\n\n        saver = tf.train.Saver()\n\n        with tf.Session() as sess:\n\n            print(""Reading checkpoints..."")\n            ckpt = tf.train.get_checkpoint_state(logs_train_dir)\n            if ckpt and ckpt.model_checkpoint_path:\n                global_step = ckpt.model_checkpoint_path.split(\'/\')[-1].split(\'-\')[-1]\n                saver.restore(sess, ckpt.model_checkpoint_path)\n                print(\'Loading success, global_step is %s\' % global_step)\n            else:\n                print(\'No checkpoint file found\')\n\n            prediction = sess.run(logit, feed_dict={x: image_array})\n            max_index = np.argmax(prediction)\n            if max_index == 0:\n                result = (\'\xe8\xbf\x99\xe6\x98\xaf\xe7\x8e\xab\xe7\x91\xb0\xe8\x8a\xb1\xe7\x9a\x84\xe5\x8f\xaf\xe8\x83\xbd\xe6\x80\xa7\xe4\xb8\xba\xef\xbc\x9a %.6f\' % prediction[:, 0])\n            elif max_index == 1:\n                result = (\'\xe8\xbf\x99\xe6\x98\xaf\xe9\x83\x81\xe9\x87\x91\xe9\xa6\x99\xe7\x9a\x84\xe5\x8f\xaf\xe8\x83\xbd\xe6\x80\xa7\xe4\xb8\xba\xef\xbc\x9a %.6f\' % prediction[:, 1])\n            elif max_index == 2:\n                result = (\'\xe8\xbf\x99\xe6\x98\xaf\xe8\x92\xb2\xe5\x85\xac\xe8\x8b\xb1\xe7\x9a\x84\xe5\x8f\xaf\xe8\x83\xbd\xe6\x80\xa7\xe4\xb8\xba\xef\xbc\x9a %.6f\' % prediction[:, 2])\n            else:\n                result = (\'\xe8\xbf\x99\xe6\x98\xaf\xe8\xbf\x99\xe6\x98\xaf\xe5\x90\x91\xe6\x97\xa5\xe8\x91\xb5\xe7\x9a\x84\xe5\x8f\xaf\xe8\x83\xbd\xe6\x80\xa7\xe4\xb8\xba\xef\xbc\x9a %.6f\' % prediction[:, 3])\n            return result\n\n\n# ------------------------------------------------------------------------\n\nif __name__ == \'__main__\':\n    img = Image.open(\'D:/ML/flower/flower_photos/roses/12240303_80d87f77a3_n.jpg\')\n    plt.imshow(img)\n    plt.show()\n    imag = img.resize([64, 64])\n    image = np.array(imag)\n    evaluate_one_image(image)\n'"
train.py,9,"b""# \xe5\xaf\xbc\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport input_data\nimport model\n\n# \xe5\x8f\x98\xe9\x87\x8f\xe5\xa3\xb0\xe6\x98\x8e\nN_CLASSES = 4  # \xe5\x9b\x9b\xe7\xa7\x8d\xe8\x8a\xb1\xe7\xb1\xbb\xe5\x9e\x8b\nIMG_W = 64  # resize\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x8c\xe5\xa4\xaa\xe5\xa4\xa7\xe7\x9a\x84\xe8\xaf\x9d\xe8\xae\xad\xe7\xbb\x83\xe6\x97\xb6\xe9\x97\xb4\xe4\xb9\x85\nIMG_H = 64\nBATCH_SIZE = 20\nCAPACITY = 200\nMAX_STEP = 10000  # \xe4\xb8\x80\xe8\x88\xac\xe5\xa4\xa7\xe4\xba\x8e10K\nlearning_rate = 0.0001  # \xe4\xb8\x80\xe8\x88\xac\xe5\xb0\x8f\xe4\xba\x8e0.0001\n\n# \xe8\x8e\xb7\xe5\x8f\x96\xe6\x89\xb9\xe6\xac\xa1batch\ntrain_dir = 'D:/ML/flower/input_data'  # \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xbb\xe5\x85\xa5\xe8\xb7\xaf\xe5\xbe\x84\nlogs_train_dir = 'D:/ML/flower/save'  # logs\xe5\xad\x98\xe5\x82\xa8\xe8\xb7\xaf\xe5\xbe\x84\n\n# train, train_label = input_data.get_files(train_dir)\ntrain, train_label, val, val_label = input_data.get_files(train_dir, 0.3)\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\x8a\xe6\xa0\x87\xe7\xad\xbe\ntrain_batch, train_label_batch = input_data.get_batch(train, train_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\x8a\xe6\xa0\x87\xe7\xad\xbe\nval_batch, val_label_batch = input_data.get_batch(val, val_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x93\x8d\xe4\xbd\x9c\xe5\xae\x9a\xe4\xb9\x89\ntrain_logits = model.inference(train_batch, BATCH_SIZE, N_CLASSES)\ntrain_loss = model.losses(train_logits, train_label_batch)\ntrain_op = model.trainning(train_loss, learning_rate)\ntrain_acc = model.evaluation(train_logits, train_label_batch)\n\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x93\x8d\xe4\xbd\x9c\xe5\xae\x9a\xe4\xb9\x89\ntest_logits = model.inference(val_batch, BATCH_SIZE, N_CLASSES)\ntest_loss = model.losses(test_logits, val_label_batch)\ntest_acc = model.evaluation(test_logits, val_label_batch)\n\n# \xe8\xbf\x99\xe4\xb8\xaa\xe6\x98\xaflog\xe6\xb1\x87\xe6\x80\xbb\xe8\xae\xb0\xe5\xbd\x95\nsummary_op = tf.summary.merge_all()\n\n# \xe4\xba\xa7\xe7\x94\x9f\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbc\x9a\xe8\xaf\x9d\nsess = tf.Session()\n# \xe4\xba\xa7\xe7\x94\x9f\xe4\xb8\x80\xe4\xb8\xaawriter\xe6\x9d\xa5\xe5\x86\x99log\xe6\x96\x87\xe4\xbb\xb6\ntrain_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n# val_writer = tf.summary.FileWriter(logs_test_dir, sess.graph)\n# \xe4\xba\xa7\xe7\x94\x9f\xe4\xb8\x80\xe4\xb8\xaasaver\xe6\x9d\xa5\xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\nsaver = tf.train.Saver()\n# \xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\nsess.run(tf.global_variables_initializer())\n# \xe9\x98\x9f\xe5\x88\x97\xe7\x9b\x91\xe6\x8e\xa7\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n# \xe8\xbf\x9b\xe8\xa1\x8cbatch\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\ntry:\n    # \xe6\x89\xa7\xe8\xa1\x8cMAX_STEP\xe6\xad\xa5\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe4\xb8\x80\xe6\xad\xa5\xe4\xb8\x80\xe4\xb8\xaabatch\n    for step in np.arange(MAX_STEP):\n        if coord.should_stop():\n            break\n        _, tra_loss, tra_acc = sess.run([train_op, train_loss, train_acc])\n\n        # \xe6\xaf\x8f\xe9\x9a\x9450\xe6\xad\xa5\xe6\x89\x93\xe5\x8d\xb0\xe4\xb8\x80\xe6\xac\xa1\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84loss\xe4\xbb\xa5\xe5\x8f\x8aacc\xef\xbc\x8c\xe5\x90\x8c\xe6\x97\xb6\xe8\xae\xb0\xe5\xbd\x95log\xef\xbc\x8c\xe5\x86\x99\xe5\x85\xa5writer\n        if step % 10 == 0:\n            print('Step %d, train loss = %.2f, train accuracy = %.2f%%' % (step, tra_loss, tra_acc * 100.0))\n            summary_str = sess.run(summary_op)\n            train_writer.add_summary(summary_str, step)\n        # \xe6\xaf\x8f\xe9\x9a\x94100\xe6\xad\xa5\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xad\xe7\xbb\x83\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\n        if (step + 1) == MAX_STEP:\n            checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n            saver.save(sess, checkpoint_path, global_step=step)\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\n\nfinally:\n    coord.request_stop()"""
