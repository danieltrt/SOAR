file_path,api_count,code
setup.py,0,"b'import setuptools\n\nsetuptools.setup(\n    name = \'hiddenlayer\',\n    # packages = [\'hiddenlayer\'],\n    packages = setuptools.find_packages(),\n    version = \'0.2\',\n    license=""MIT"",\n    description = \'Neural network graphs and training metrics for PyTorch and TensorFlow\',\n    author = \'Waleed Abdulla <waleed.abdulla@gmail.com>, Phil Ferriere <pferriere@hotmail.com>\',\n    url = \'https://github.com/waleedka/hiddenlayer\',\n    classifiers = [\n    # How mature is this project? Common values are\n    #   3 - Alpha\n    #   4 - Beta\n    #   5 - Production/Stable\n    \'Development Status :: 4 - Beta\',\n\n    # Indicate who your project is intended for\n    \'Intended Audience :: Developers\',\n    \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n    \'Topic :: Scientific/Engineering :: Visualization\',\n\n    # Pick your license as you wish (should match ""license"" above)\n    \'License :: OSI Approved :: MIT License\',\n\n    # Specify the Python versions you support here. In particular, ensure\n    # that you indicate whether you support Python 2, Python 3 or both.\n    \'Programming Language :: Python :: 3.5\',\n\n    \'Operating System :: OS Independent\',\n    ],\n)\n'"
demos/history_canvas.py,0,"b'# Set matplotlib backend to Agg\n# *MUST* be done BEFORE importing hiddenlayer or libs that import matplotlib\nimport matplotlib\nmatplotlib.use(""Agg"")\n\nimport os\nimport time\nimport random\nimport numpy as np\nimport hiddenlayer as hl\n\n# Create output directory in project root\nROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nOUTPUT_DIR = os.path.join(ROOT_DIR, ""demo_output"")\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\n# A History object to store metrics\nh = hl.History()\n\n# A Canvas object to draw the metrics\nc = hl.Canvas()\n\n# Simulate a training loop with two metrics: loss and accuracy\nloss = 1\naccuracy = 0\nfor step in range(1000):\n    # Fake loss and accuracy\n    loss -= loss * np.random.uniform(-.09, 0.1)\n    accuracy += (1 - accuracy) * np.random.uniform(-.09, 0.1)\n\n    # Log metrics and display them at certain intervals\n    if step % 10 == 0:\n        # Store metrics in the history object\n        h.log(step, loss=loss, accuracy=accuracy)\n\n        # Print progress status\n        h.progress()\n\n        # Less occasionally, save a snapshot of the graphs\n        if step % 100 == 0:\n            # Plot the two metrics in one graph\n            c.draw_plot([h[""loss""], h[""accuracy""]])\n            # Save the canvas\n            c.save(os.path.join(OUTPUT_DIR, ""training_progress.png""))\n\n            # You can also save the history to a file to load and inspect layer\n            h.save(os.path.join(OUTPUT_DIR, ""training_progress.pkl""))\n\n        time.sleep(0.1)\n'"
demos/tf_cifar10.py,50,"b'""""""\nWrapper for CIFAR-10 dataset and TF model.\n\nWritten by Phil Ferriere\n\nLoosely based on https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10.py\nCopyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nNote: we use the exact same format and folders as in the PyTorch sample\n\nLicensed under the MIT License\n""""""\n\nfrom __future__ import absolute_import, division, print_function\nimport os, sys, tarfile, pickle\nimport tensorflow as tf\nimport numpy as np\nfrom urllib.request import urlretrieve\n\n# Global constants describing the CIFAR-10 data set.\nIMAGE_SIZE = 32\nNUM_CHANNELS = 3\nNUM_CLASSES = 10\nNUM_TRAIN_SAMPLES = 50000\nNUM_TEST_SAMPLES = 10000\nCIFAR10_URL = \'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\'\n\n\nclass CIFAR10():\n    """"""TF data handler for CIFAR-10 dataset and model.""""""\n\n    def __init__(self, batch_size=8, data_dir=None):\n        """"""CIFAR-10 dataset and TF model constructor.\n        Args:\n            batch_size: dataset batch size.\n        """"""\n        self._train_data, self._train_labels = None, None\n        self._test_data, self._test_labels = None, None\n        self._batch_size = batch_size\n        self.img_size = IMAGE_SIZE\n        self.num_channels = NUM_CHANNELS\n        self.num_classes = NUM_CLASSES\n        self.train_len = NUM_TRAIN_SAMPLES\n        self.test_len = NUM_TEST_SAMPLES\n        self.data_dir = data_dir or ""./test_data""\n        self.cifar10_dir = os.path.join(self.data_dir, \'cifar-10-batches-py\')\n        self.cifar10_tarball = os.path.join(self.data_dir, CIFAR10_URL.split(\'/\')[-1])\n        self.maybe_download_and_extract()\n\n    @property\n    def train_data(self):\n        if self._train_data is None:\n            self._load(\'train\')\n\n        return self._train_data\n\n    @property\n    def train_labels(self):\n        if self._train_labels is None:\n            self._load(\'train\')\n\n        return self._train_labels\n\n    @property\n    def test_data(self):\n        if self._test_data is None:\n            self._load(\'test\')\n\n        return self._test_data\n\n    @property\n    def test_labels(self):\n        if self._test_labels is None:\n            self._load(\'test\')\n\n        return self._test_labels\n\n    def _load(self, dataset=\'train\'):\n        """"""Load the data in memory.\n        Args:\n            dataset: string in [\'train\', \'test\']\n        """"""\n        data, labels = None, None\n        if dataset is \'train\':\n            files = [os.path.join(self.cifar10_dir, \'data_batch_%d\' % i) for i in range(1, 6)]\n        else:\n            files = [os.path.join(self.cifar10_dir, \'test_batch\')]\n\n        for file in files:\n            if not os.path.exists(file):\n                raise FileNotFoundError(\'Failed to find file: \' + file)\n\n        # Load the data from the batch files\n        for file in files:\n            with open(file, \'rb\') as f:\n                cifar10 = pickle.load(f, encoding=\'latin1\')\n\n            if labels is None:\n                labels = np.array(cifar10[\'labels\'])\n            else:\n                labels = np.concatenate((labels, cifar10[\'labels\']), axis=0)\n\n            if data is None:\n                data = cifar10[\'data\']\n            else:\n                data = np.concatenate((data, cifar10[\'data\']), axis=0)\n\n        # Adapt the format of the data to our convnet\n        data = np.array(data, dtype=float) / 255.0\n        data = data.reshape([-1, self.num_channels, self.img_size, self.img_size])\n        data = data.transpose([0, 2, 3, 1])\n\n        # One-hot encode labels (see https://stackoverflow.com/a/42874726)\n        labels = np.eye(self.num_classes)[np.array(labels).reshape(-1)]\n\n        if dataset is \'train\':\n            self._train_data, self._train_labels = data, labels\n        else:\n            self._test_data, self._test_labels = data, labels\n\n    def model(self, inputs, mode=\'train\'):\n        """"""Build a simple convnet (BN before ReLU).\n        Args:\n            inputs: a tensor of size [batch_size, height, width, channels]\n            mode: string in [\'train\', \'test\']\n        Returns:\n            the last op containing the predictions\n        Note:\n            Best score\n            Step:  7015 - Epoch: 18/20 - best batch acc: 0.8984 - loss: 1.5656\n            Worst score\n            Step:  7523 - Epoch: 20/20 - best batch acc: 0.7734 - loss: 1.6874\n        """"""\n        # Extract features\n        training = (mode == \'train\')\n        with tf.variable_scope(\'conv1\') as scope:\n            conv = tf.layers.conv2d(inputs=inputs, filters=16, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            conv = tf.layers.conv2d(inputs=bn, filters=16, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        with tf.variable_scope(\'conv2\') as scope:\n            conv = tf.layers.conv2d(inputs=pool, filters=32, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            conv = tf.layers.conv2d(inputs=bn, filters=32, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        with tf.variable_scope(\'conv3\') as scope:\n            conv = tf.layers.conv2d(inputs=pool, filters=32, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            conv = tf.layers.conv2d(inputs=bn, filters=32, kernel_size=[3, 3], padding=\'SAME\')\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            bn = tf.nn.relu(bn)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        # Classify\n        with tf.variable_scope(\'fc\') as scope:\n            flat = tf.layers.flatten(pool)\n            fc = tf.layers.dense(inputs=flat, units=32, activation=tf.nn.relu)\n            softmax = tf.layers.dense(inputs=fc, units=self.num_classes, activation=tf.nn.softmax)\n\n        return softmax\n\n    def model2(self, inputs, mode=\'train\'):\n        """"""Build a simple convnet (ReLU before BN).\n        Args:\n            inputs: a tensor of size [batch_size, height, width, channels]\n            mode: string in [\'train\', \'test\']\n        Returns:\n            the last op containing the predictions\n        Note:\n            Best score\n            Step:  7411 - Epoch: 20/20 - best batch acc: 0.8438 - loss: 1.6347\n            Worst score\n            Step:  7751 - Epoch: 20/20 - best batch acc: 0.8047 - loss: 1.6616\n        """"""\n        # Extract features\n        training = (mode == \'train\')\n        with tf.variable_scope(\'conv1\') as scope:\n            conv = tf.layers.conv2d(inputs=inputs, filters=16, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            conv = tf.layers.conv2d(inputs=bn, filters=16, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        with tf.variable_scope(\'conv2\') as scope:\n            conv = tf.layers.conv2d(inputs=pool, filters=32, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            conv = tf.layers.conv2d(inputs=bn, filters=32, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        with tf.variable_scope(\'conv3\') as scope:\n            conv = tf.layers.conv2d(inputs=pool, filters=32, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            conv = tf.layers.conv2d(inputs=bn, filters=32, kernel_size=[3, 3], padding=\'SAME\', activation=tf.nn.relu)\n            bn = tf.layers.batch_normalization(inputs=conv, training=training)\n            pool = tf.layers.max_pooling2d(bn, pool_size=[2, 2], strides=2, padding=\'SAME\', name=scope.name)\n\n        # Classify\n        with tf.variable_scope(\'fc\') as scope:\n            flat = tf.layers.flatten(pool)\n            fc = tf.layers.dense(inputs=flat, units=32, activation=tf.nn.relu)\n            softmax = tf.layers.dense(inputs=fc, units=self.num_classes, activation=tf.nn.softmax)\n\n        return softmax\n\n    def maybe_download_and_extract(self):\n        """"""Download and extract the tarball from Alex Krizhevsky\'s website.""""""\n        if not os.path.exists(self.cifar10_dir):\n\n            if not os.path.exists(self.data_dir):\n                os.makedirs(self.data_dir)\n\n            def _progress(count, block_size, total_size):\n                status_msg = \'\\r>> Downloading {} {:>3}%   \'\n                sys.stdout.write(status_msg.format(self.cifar10_tarball, float(count * block_size) / total_size * 100.0))\n                sys.stdout.flush()\n\n            file_path, _ = urlretrieve(CIFAR10_URL, self.cifar10_tarball, _progress)\n\n            stat_info = os.stat(file_path)\n            print(\'\\nSuccessfully downloaded\', file_path, stat_info.st_size, \'bytes.\\n\')\n\n            tarfile.open(file_path, \'r:gz\').extractall(self.data_dir)\n\n'"
hiddenlayer/__init__.py,0,"b'# Import methods to expose in the library\r\nfrom .graph import Graph, Node, build_graph\r\nfrom .history import History\r\nfrom .canvas import show_images\r\nfrom .canvas import Canvas\r\nfrom .utils import write\r\nfrom . import transforms\r\n'"
hiddenlayer/canvas.py,0,"b'""""""\nHiddenLayer\n\nImplementation of the Canvas class to render visualizations.\n\nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nimport itertools\nimport math\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport IPython.display\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.collections import PolyCollection\n\n\nDEFAULT_THEME = {\n    ""fig_width"": 12,  # inches\n    ""hist_outline_color"": [0, 0, 0.9],\n    ""hist_color"": [0.5, 0, 0.9],\n}\n\n\ndef norm(image):\n    """"""Normalize an image to [0, 1] range.""""""\n    min_value = image.min()\n    max_value = image.max()\n    if min_value == max_value:\n        return image - min_value\n    return (image - min_value) / (max_value - min_value)\n\n\n# TODO: Move inside Canvas and merge with draw_images\ndef show_images(images, titles=None, cols=5, **kwargs):\n    """"""\n    images: A list of images. I can be either:\n        - A list of Numpy arrays. Each array represents an image.\n        - A list of lists of Numpy arrays. In this case, the images in\n          the inner lists are concatentated to make one image.\n    """"""\n    # The images param can be a list or an array\n\n    titles = titles or [""""] * len(images)\n    rows = math.ceil(len(images) / cols)\n    height_ratio = 1.2 * (rows/cols) * (0.5 if type(images[0]) is not np.ndarray else 1)\n    plt.figure(figsize=(11, 11 * height_ratio))\n    i = 1\n    for image, title in zip(images, titles):\n        plt.subplot(rows, cols, i)\n        plt.axis(""off"")\n        # Is image a list? If so, merge them into one image.\n        if type(image) is not np.ndarray:\n            image = [norm(g) for g in image]\n            image = np.concatenate(image, axis=1)\n        else:\n            image = norm(image)\n        plt.title(title, fontsize=9)\n        plt.imshow(image, cmap=""Greys_r"", **kwargs)\n        i += 1\n    plt.tight_layout(h_pad=0, w_pad=0)\n\n\n###############################################################################\n# Canvas Class\n###############################################################################\n\nclass Canvas():\n\n    def __init__(self):\n        self._context = None\n        self.theme = DEFAULT_THEME\n        self.figure = None\n        self.backend = matplotlib.get_backend()\n        self.drawing_calls = []\n        self.theme = DEFAULT_THEME\n\n    def __enter__(self):\n        self._context = ""build""\n        self.drawing_calls = []\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.render()\n\n    def render(self):\n        self._context = ""run""\n        # Clear output\n        if \'inline\' in self.backend:\n            IPython.display.clear_output(wait=True)\n            self.figure = None\n\n        # Separate the draw_*() calls that generate a grid cell\n        grid_calls = []\n        silent_calls = []\n        for c in self.drawing_calls:\n            if c[0] == ""draw_summary"":\n                silent_calls.append(c)\n            else:\n                grid_calls.append(c)\n\n        # Header area\n        # TODO: ideally, compute how much header area we need based on the\n        #       length of text to show there. Right now, we\'re just using\n        #       a fixed number multiplied by the number of calls. Since there\n        #       is only one silent call, draw_summary(), then the header padding\n        #       is either 0 or 0.1\n        head_pad = 0.1 * len(silent_calls)\n\n        width = self.theme[\'fig_width\']\n        if not self.figure:\n            self.figure = plt.figure(figsize=(width, width/3 * (head_pad + len(grid_calls))))\n        self.figure.clear()\n\n        # Divide figure area by number of grid calls\n        gs = matplotlib.gridspec.GridSpec(len(grid_calls), 1)\n\n        # Call silent calls\n        for c in silent_calls:\n            getattr(self, c[0])(*c[1], **c[2])\n\n        # Call grid methods\n        for i, c in enumerate(grid_calls):\n            method = c[0]\n            # Create an axis for each call\n            # Save in in self.ax so the drawing function has access to it\n            self.ax = self.figure.add_subplot(gs[i])\n            # Save the GridSpec as well\n            self.gs = gs[i]\n            # Call the method\n            getattr(self, method)(*c[1], **c[2])\n        # Cleanup after drawing\n        self.ax = None\n        self.gs = None\n        gs.tight_layout(self.figure, rect=(0, 0, 1, 1-head_pad))\n\n        # TODO: pause() allows the GUI to render but it\'s sluggish because it\n        # only has 0.1 seconds of CPU time at each step. A better solution would be to\n        # launch a separate process to render the GUI and pipe data to it.\n        plt.pause(0.1)\n        plt.show(block=False)\n        self.drawing_calls = []\n        self._context = None\n\n\n    def __getattribute__(self, name):\n        if name.startswith(""draw_"") and self._context != ""run"":\n            def wrapper(*args, **kwargs):\n                self.drawing_calls.append((name, args, kwargs))\n                if not self._context:\n                    self.render()\n            return wrapper\n        else:\n            return object.__getattribute__(self, name)\n\n    def save(self, file_name):\n        self.figure.savefig(file_name)\n\n    def draw_summary(self, history, title=""""):\n        """"""Inserts a text summary at the top that lists the number of steps and total\n        training time.""""""\n        # Generate summary string\n        time_str = str(history.get_total_time()).split(""."")[0]  # remove microseconds\n        summary = ""Step: {}      Time: {}"".format(history.step, time_str)\n        if title:\n            summary = title + ""\\n\\n"" + summary\n        self.figure.suptitle(summary)\n\n    def draw_plot(self, metrics, labels=None, ylabel="""", title=None):\n        """"""\n        metrics: One or more metrics parameters. Each represents the history\n            of one metric.\n        """"""\n        metrics = metrics if isinstance(metrics, list) else [metrics]\n        # Loop through metrics\n        default_title = """"\n        for i, m in enumerate(metrics):\n            label = labels[i] if labels else m.name\n            # TODO: use a standard formating function for values\n            default_title += (""   "" if default_title else """") + ""{}: {}"".format(label, m.data[-1])\n            self.ax.plot(m.formatted_steps, m.data, label=label)\n        title = default_title if title is None else title\n        self.ax.set_title(title)\n        self.ax.set_ylabel(ylabel)\n        self.ax.legend()\n        self.ax.set_xlabel(""Steps"")\n        self.ax.xaxis.set_major_locator(plt.AutoLocator())\n\n\n    def draw_image(self, metric, limit=5):\n        """"""Display a series of images at different time steps.""""""\n        rows = 1\n        cols = limit\n        self.ax.axis(""off"")\n        # Take the Axes gridspec and divide it into a grid\n        gs = matplotlib.gridspec.GridSpecFromSubplotSpec(\n            rows, cols, subplot_spec=self.gs)\n        # Loop through images in last few steps\n        for i, image in enumerate(metric.data[-cols:]):\n            ax = self.figure.add_subplot(gs[0, i])\n            ax.axis(\'off\')\n            ax.set_title(metric.formatted_steps[-cols:][i])\n            ax.imshow(norm(image))\n\n    def draw_hist(self, metric, title=""""):\n        """"""Draw a series of histograms of the selected keys over different\n        training steps.\n        """"""\n        # TODO: assert isinstance(list(values.values())[0], np.ndarray)\n\n        rows = 1\n        cols = 1\n        limit = 10  # max steps to show\n\n        # We need a 3D projection Subplot, so ignore the one provided to\n        # as an create a new one.\n        ax = self.figure.add_subplot(self.gs, projection=""3d"")\n        ax.view_init(30, -80)\n\n        # Compute histograms\n        verts = []\n        area_colors = []\n        edge_colors = []\n        for i, s in enumerate(metric.steps[-limit:]):\n            hist, edges = np.histogram(metric.data[-i-1:])\n            # X is bin centers\n            x = np.diff(edges)/2 + edges[:-1]\n            # Y is hist values\n            y = hist\n            x = np.concatenate([x[0:1], x, x[-1:]])\n            y = np.concatenate([[0], y, [0]])\n\n            # Ranges\n            if i == 0:\n                x_min = x.min()\n                x_max = x.max()\n                y_min = y.min()\n                y_max = y.max()\n            x_min = np.minimum(x_min, x.min())\n            x_max = np.maximum(x_max, x.max())\n            y_min = np.minimum(y_min, y.min())\n            y_max = np.maximum(y_max, y.max())\n\n            alpha = 0.8 * (i+1) / min(limit, len(metric.steps))\n            verts.append(list(zip(x, y)))\n            area_colors.append(np.array(self.theme[""hist_color""] + [alpha]))\n            edge_colors.append(np.array(self.theme[""hist_outline_color""] + [alpha]))\n\n        poly = PolyCollection(verts, facecolors=area_colors, edgecolors=edge_colors)\n        ax.add_collection3d(poly, zs=list(range(min(limit, len(metric.steps)))), zdir=\'y\')\n\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(0, limit)\n        ax.set_yticklabels(metric.formatted_steps[-limit:])\n        ax.set_zlim(y_min, y_max)\n        ax.set_title(metric.name)\n\n'"
hiddenlayer/ge.py,0,"b'""""""\nHiddenLayer\n\nImplementation graph expressions to find nodes in a graph based on a pattern.\n \nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nimport re\n\n\n\nclass GEParser():\n    def __init__(self, text):\n        self.index = 0\n        self.text = text\n\n    def parse(self):\n        return self.serial() or self.parallel() or self.expression()\n\n    def parallel(self):\n        index = self.index\n        expressions = []\n        while len(expressions) == 0 or self.token(""|""):\n            e = self.expression()\n            if not e:\n                break\n            expressions.append(e)\n        if len(expressions) >= 2:\n            return ParallelPattern(expressions)\n        # No match. Reset index\n        self.index = index\n    \n    def serial(self):\n        index = self.index\n        expressions = []\n        while len(expressions) == 0 or self.token("">""):\n            e = self.expression()\n            if not e:\n                break\n            expressions.append(e)\n\n        if len(expressions) >= 2:\n            return SerialPattern(expressions)\n        self.index = index\n\n    def expression(self):\n        index = self.index\n        \n        if self.token(""(""):\n            e = self.serial() or self.parallel() or self.op()\n            if e and self.token("")""):\n                return e\n        self.index = index\n        e = self.op()\n        return e\n\n    def op(self):\n        t = self.re(r""\\w+"")\n        if t:\n            c = self.condition()\n            return NodePattern(t, c)\n    \n    def condition(self):\n        # TODO: not implemented yet. This function is a placeholder\n        index = self.index\n        if self.token(""[""):\n            c = self.token(""1x1"") or self.token(""3x3"")\n            if c:\n                if self.token(""]""):\n                    return c\n            self.index = index\n    \n    def token(self, s):\n        return self.re(r""\\s*("" + re.escape(s) + r"")\\s*"", 1)\n\n    def string(self, s):\n        if s == self.text[self.index:self.index+len(s)]:\n            self.index += len(s)\n            return s\n\n    def re(self, regex, group=0):\n        m = re.match(regex, self.text[self.index:])\n        if m:\n            self.index += len(m.group(0))\n            return m.group(group)\n            \n\nclass NodePattern():\n    def __init__(self, op, condition=None):\n        self.op = op\n        self.condition = condition  # TODO: not implemented yet\n    \n    def match(self, graph, node):\n        if isinstance(node, list):\n            return [], None\n        if self.op == node.op:\n            following = graph.outgoing(node)\n            if len(following) == 1:\n                following = following[0]\n            return [node], following\n        else:\n            return [], None\n\n\nclass SerialPattern():\n    def __init__(self, patterns):\n        self.patterns = patterns\n\n    def match(self, graph, node):\n        all_matches = []\n        for i, p in enumerate(self.patterns):\n            matches, following = p.match(graph, node)\n            if not matches:\n                return [], None\n            all_matches.extend(matches)\n            if i < len(self.patterns) - 1:\n                node = following  # Might be more than one node\n        return all_matches, following\n\n\nclass ParallelPattern():\n    def __init__(self, patterns):\n        self.patterns = patterns\n\n    def match(self, graph, nodes):\n        if not nodes:\n            return [], None\n        nodes = nodes if isinstance(nodes, list) else [nodes]\n        # If a single node, assume we need to match with its siblings\n        if len(nodes) == 1:\n            nodes = graph.siblings(nodes[0])\n        else:\n            # Verify all nodes have the same parent or all have no parent\n            parents = [graph.incoming(n) for n in nodes]\n            matches = [set(p) == set(parents[0]) for p in parents[1:]]\n            if not all(matches):\n                return [], None\n\n        # TODO: If more nodes than patterns, we should consider\n        #       all permutations of the nodes\n        if len(self.patterns) != len(nodes):\n            return [], None\n        \n        patterns = self.patterns.copy()\n        nodes = nodes.copy()\n        all_matches = []\n        end_node = None\n        for p in patterns:\n            found = False\n            for n in nodes:\n                matches, following = p.match(graph, n)\n                if matches:\n                    found = True\n                    nodes.remove(n)\n                    all_matches.extend(matches)\n                    # Verify all branches end in the same node\n                    if end_node:\n                        if end_node != following:\n                            return [], None\n                    else:\n                        end_node = following\n                    break\n            if not found:\n                return [], None\n        return all_matches, end_node\n\n\n'"
hiddenlayer/graph.py,0,"b'""""""\nHiddenLayer\n\nImplementation of the Graph class. A framework independent directed graph to\nrepresent a neural network.\n\nWritten by Waleed Abdulla. Additions by Phil Ferriere.\nLicensed under the MIT License\n""""""\nfrom __future__ import absolute_import, division, print_function\nimport os\nimport re\nfrom random import getrandbits\nimport inspect\nimport numpy as np\n\n\nTHEMES = {\n    ""basic"": {\n        ""background_color"": ""#FFFFFF"",\n        ""fill_color"": ""#E8E8E8"",\n        ""outline_color"": ""#000000"",\n        ""font_color"": ""#000000"",\n        ""font_name"": ""Times"",\n        ""font_size"": ""10"",\n        ""margin"": ""0,0"",\n        ""padding"":  ""1.0,0.5"",\n    },\n    ""blue"": {\n        ""background_color"": ""#FFFFFF"",\n        ""fill_color"": ""#BCD6FC"",\n        ""outline_color"": ""#7C96BC"",\n        ""font_color"": ""#202020"",\n        ""font_name"": ""Verdana"",\n        ""font_size"": ""10"",\n        ""margin"": ""0,0"",\n        ""padding"":  ""1.0,0.5"",\n    },\n}\n\n\n###########################################################################\n# Utility Functions\n###########################################################################\n\ndef detect_framework(value):\n    # Get all base classes\n    classes = inspect.getmro(value.__class__)\n    for c in classes:\n        if c.__module__.startswith(""torch""):\n            return ""torch""\n        elif c.__module__.startswith(""tensorflow""):\n            return ""tensorflow""\n\n\n###########################################################################\n# Node\n###########################################################################\n\nclass Node():\n    """"""Represents a framework-agnostic neural network layer in a directed graph.""""""\n\n    def __init__(self, uid, name, op, output_shape=None, params=None):\n        """"""\n        uid: unique ID for the layer that doesn\'t repeat in the computation graph.\n        name: Name to display\n        op: Framework-agnostic operation name.\n        """"""\n        self.id = uid\n        self.name = name  # TODO: clarify the use of op vs name vs title\n        self.op = op\n        self.repeat = 1\n        if output_shape:\n            assert isinstance(output_shape, (tuple, list)),\\\n            ""output_shape must be a tuple or list but received {}"".format(type(output_shape))\n        self.output_shape = output_shape\n        self.params = params if params else {}\n        self._caption = """"\n\n    @property\n    def title(self):\n        # Default\n        title = self.name or self.op\n\n        if ""kernel_shape"" in self.params:\n            # Kernel\n            kernel = self.params[""kernel_shape""]\n            title += ""x"".join(map(str, kernel))\n        if ""stride"" in self.params:\n            stride = self.params[""stride""]\n            if np.unique(stride).size == 1:\n                stride = stride[0]\n            if stride != 1:\n                title += ""/s{}"".format(str(stride))\n        #         # Transposed\n        #         if node.transposed:\n        #             name = ""Transposed"" + name\n        return title\n\n    @property\n    def caption(self):\n        if self._caption:\n            return self._caption\n\n        caption = """"\n\n        # Stride\n        # if ""stride"" in self.params:\n        #     stride = self.params[""stride""]\n        #     if np.unique(stride).size == 1:\n        #         stride = stride[0]\n        #     if stride != 1:\n        #         caption += ""/{}"".format(str(stride))\n        return caption\n\n    def __repr__(self):\n        args = (self.op, self.name, self.id, self.title, self.repeat)\n        f = ""<Node: op: {}, name: {}, id: {}, title: {}, repeat: {}""\n        if self.output_shape:\n            args += (str(self.output_shape),)\n            f += "", shape: {:}""\n        if self.params:\n            args += (str(self.params),)\n            f += "", params: {:}""\n        f += "">""\n        return f.format(*args)\n\n\n###########################################################################\n# Graph\n###########################################################################\n\ndef build_graph(model=None, args=None, input_names=None,\n                transforms=""default"", framework_transforms=""default""):\n    # Initialize an empty graph\n    g = Graph()\n\n    # Detect framwork\n    framework = detect_framework(model)\n    if framework == ""torch"":\n        from .pytorch_builder import import_graph, FRAMEWORK_TRANSFORMS\n        assert args is not None, ""Argument args must be provided for Pytorch models.""\n        import_graph(g, model, args)\n    elif framework == ""tensorflow"":\n        from .tf_builder import import_graph, FRAMEWORK_TRANSFORMS\n        import_graph(g, model)\n    else:\n        raise ValueError(""`model` input param must be a PyTorch, TensorFlow, or Keras-with-TensorFlow-backend model."") \n\n    # Apply Transforms\n    if framework_transforms:\n        if framework_transforms == ""default"":\n            framework_transforms = FRAMEWORK_TRANSFORMS\n        for t in framework_transforms:\n            g = t.apply(g)\n    if transforms:\n        if transforms == ""default"":\n            from .transforms import SIMPLICITY_TRANSFORMS\n            transforms = SIMPLICITY_TRANSFORMS\n        for t in transforms:\n            g = t.apply(g)\n    return g\n\n\nclass Graph():\n    """"""Tracks nodes and edges of a directed graph and supports basic operations on them.""""""\n\n    def __init__(self, model=None, args=None, input_names=None,\n                 transforms=""default"", framework_transforms=""default"",\n                 meaningful_ids=False):\n        self.nodes = {}\n        self.edges = []\n        self.meaningful_ids = meaningful_ids # TODO\n        self.theme = THEMES[""basic""]\n\n        if model:\n            # Detect framwork\n            framework = detect_framework(model)\n            if framework == ""torch"":\n                from .pytorch_builder import import_graph, FRAMEWORK_TRANSFORMS\n                assert args is not None, ""Argument args must be provided for Pytorch models.""\n                import_graph(self, model, args)\n            elif framework == ""tensorflow"":\n                from .tf_builder import import_graph, FRAMEWORK_TRANSFORMS\n                import_graph(self, model)\n            \n            # Apply Transforms\n            if framework_transforms:\n                if framework_transforms == ""default"":\n                    framework_transforms = FRAMEWORK_TRANSFORMS\n                for t in framework_transforms:\n                    t.apply(self)\n            if transforms:\n                if transforms == ""default"":\n                    from .transforms import SIMPLICITY_TRANSFORMS\n                    transforms = SIMPLICITY_TRANSFORMS\n                for t in transforms:\n                    t.apply(self)\n\n\n    def id(self, node):\n        """"""Returns a unique node identifier. If the node has an id\n        attribute (preferred), it\'s used. Otherwise, the hash() is returned.""""""\n        return node.id if hasattr(node, ""id"") else hash(node)\n\n    def add_node(self, node):\n        id = self.id(node)\n        # assert(id not in self.nodes)\n        self.nodes[id] = node\n\n    def add_edge(self, node1, node2, label=None):\n        # If the edge is already present, don\'t add it again.\n        # TODO: If an edge exists with a different label, still don\'t add it again.\n        edge = (self.id(node1), self.id(node2), label)\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_edge_by_id(self, vid1, vid2, label=None):\n        self.edges.append((vid1, vid2, label))\n\n    def outgoing(self, node):\n        """"""Returns nodes connecting out of the given node (or list of nodes).""""""\n        nodes = node if isinstance(node, list) else [node]\n        node_ids = [self.id(n) for n in nodes]\n        # Find edges outgoing from this group but not incoming to it\n        outgoing = [self[e[1]] for e in self.edges\n                    if e[0] in node_ids and e[1] not in node_ids]\n        return outgoing\n\n    def incoming(self, node):\n        """"""Returns nodes connecting to the given node (or list of nodes).""""""\n        nodes = node if isinstance(node, list) else [node]\n        node_ids = [self.id(n) for n in nodes]\n        # Find edges incoming to this group but not outgoing from it\n        incoming = [self[e[0]] for e in self.edges\n                    if e[1] in node_ids and e[0] not in node_ids]\n        return incoming\n\n    def siblings(self, node):\n        """"""Returns all nodes that share the same parent (incoming node) with\n        the given node, including the node itself.\n        """"""\n        incoming = self.incoming(node)\n        # TODO: Not handling the case of multiple incoming nodes yet\n        if len(incoming) == 1:\n            incoming = incoming[0]\n            siblings = self.outgoing(incoming)\n            return siblings\n        else:\n            return [node]\n\n    def __getitem__(self, key):\n        if isinstance(key, list):\n            return [self.nodes.get(k) for k in key]\n        else:\n            return self.nodes.get(key)\n\n    def remove(self, nodes):\n        """"""Remove a node and its edges.""""""\n        nodes = nodes if isinstance(nodes, list) else [nodes]\n        for node in nodes:\n            k = self.id(node)\n            self.edges = list(filter(lambda e: e[0] != k and e[1] != k, self.edges))\n            del self.nodes[k]\n\n    def replace(self, nodes, node):\n        """"""Replace nodes with node. Edges incoming to nodes[0] are connected to\n        the new node, and nodes outgoing from nodes[-1] become outgoing from\n        the new node.""""""\n        nodes = nodes if isinstance(nodes, list) else [nodes]\n        # Is the new node part of the replace nodes (i.e. want to collapse\n        # a group of nodes into one of them)?\n        collapse = self.id(node) in self.nodes\n        # Add new node and edges\n        if not collapse:\n            self.add_node(node)\n        for in_node in self.incoming(nodes):\n            # TODO: check specifically for output_shape is not generic. Consider refactoring.\n            self.add_edge(in_node, node, in_node.output_shape if hasattr(in_node, ""output_shape"") else None)\n        for out_node in self.outgoing(nodes):\n            self.add_edge(node, out_node, node.output_shape if hasattr(node, ""output_shape"") else None)\n        # Remove the old nodes\n        for n in nodes:\n            if collapse and n == node:\n                continue\n            self.remove(n)\n\n    def search(self, pattern):\n        """"""Searches the graph for a sub-graph that matches the given pattern\n        and returns the first match it finds.\n        """"""\n        for node in self.nodes.values():\n            match, following = pattern.match(self, node)\n            if match:\n                return match, following\n        return [], None\n\n\n    def sequence_id(self, sequence):\n        """"""Make up an ID for a sequence (list) of nodes.\n        Note: `getrandbits()` is very uninformative as a ""readable"" ID. Here, we build a name\n        such that when the mouse hovers over the drawn node in Jupyter, one can figure out\n        which original nodes make up the sequence. This is actually quite useful.\n        """"""\n        if self.meaningful_ids:\n            # TODO: This might fail if the ID becomes too long\n            return ""><"".join([node.id for node in sequence])\n        else:\n            return getrandbits(64)\n\n    def build_dot(self):\n        """"""Generate a GraphViz Dot graph.\n\n        Returns a GraphViz Digraph object.\n        """"""\n        from graphviz import Digraph\n\n        # Build GraphViz Digraph\n        dot = Digraph()\n        dot.attr(""graph"", \n                 bgcolor=self.theme[""background_color""],\n                 color=self.theme[""outline_color""],\n                 fontsize=self.theme[""font_size""],\n                 fontcolor=self.theme[""font_color""],\n                 fontname=self.theme[""font_name""],\n                 margin=self.theme[""margin""],\n                 rankdir=""LR"",\n                 pad=self.theme[""padding""])\n        dot.attr(""node"", shape=""box"", \n                 style=""filled"", margin=""0,0"",\n                 fillcolor=self.theme[""fill_color""],\n                 color=self.theme[""outline_color""],\n                 fontsize=self.theme[""font_size""],\n                 fontcolor=self.theme[""font_color""],\n                 fontname=self.theme[""font_name""])\n        dot.attr(""edge"", style=""solid"", \n                 color=self.theme[""outline_color""],\n                 fontsize=self.theme[""font_size""],\n                 fontcolor=self.theme[""font_color""],\n                 fontname=self.theme[""font_name""])\n\n        for k, n in self.nodes.items():\n            label = ""<tr><td cellpadding=\'6\'>{}</td></tr>"".format(n.title)\n            if n.caption:\n                label += ""<tr><td>{}</td></tr>"".format(n.caption)\n            if n.repeat > 1:\n                label += ""<tr><td align=\'right\' cellpadding=\'2\'>x{}</td></tr>"".format(n.repeat)\n            label = ""<<table border=\'0\' cellborder=\'0\' cellpadding=\'0\'>"" + label + ""</table>>""\n            dot.node(str(k), label)\n        for a, b, label in self.edges:\n            if isinstance(label, (list, tuple)):\n                label = ""x"".join([str(l or ""?"") for l in label])\n\n            dot.edge(str(a), str(b), label)\n        return dot\n\n    def _repr_svg_(self):\n        """"""Allows Jupyter notebook to render the graph automatically.""""""\n        return self.build_dot()._repr_svg_()\n    \n    def save(self, path, format=""pdf""):\n        # TODO: assert on acceptable format values\n        dot = self.build_dot()\n        dot.format = format\n        directory, file_name = os.path.split(path)\n        # Remove extension from file name. dot.render() adds it.\n        file_name = file_name.replace(""."" + format, """")\n        dot.render(file_name, directory=directory, cleanup=True)\n'"
hiddenlayer/history.py,0,"b'""""""\nHiddenLayer\n\nImplementation of the History class to train training metrics.\n \nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nimport math\nimport random\nimport io\nimport itertools\nimport time\nimport datetime\nimport pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom . import utils\n\n\n###############################################################################\n# Helper Functions\n###############################################################################\n\ndef format_step(step, zero_prefix=False):\n    """"""Return the step value in format suitable for display.""""""\n    if isinstance(step, int):\n        return ""{:06}"".format(step) if zero_prefix else ""{}"".format(step)\n    elif isinstance(step, tuple):\n        return ""{:04}:{:06}"".format(*step) if zero_prefix else ""{}:{}"".format(*step)\n\n\n###############################################################################\n# Metric Class\n###############################################################################\n\nclass Metric():\n    """"""Represents the history of a single metric.""""""\n    def __init__(self, history, name):\n        self.name = name\n        self.steps = history.steps\n        self.data = np.array([history.history[s].get(name)\n                              for s in self.steps])\n\n    @property\n    def formatted_steps(self):\n        return [format_step(s) for s in self.steps]\n\n\n###############################################################################\n# History Class\n###############################################################################\n\nclass History():\n    """"""Tracks training progress and visualizes it.\n    For example, use it to track the training and validation loss and accuracy\n    and plot them.\n    """"""\n    \n    def __init__(self):\n        self.step = None  # Last reported step\n        self.metrics = set()  # Names of all metrics reported so far\n        self.history = {}  # Dict of steps and metrics {step: [metrics...]}\n\n    def log(self, step, **kwargs):\n        """"""Record metrics at a specific step. E.g.\n\n        my_history.log(34, loss=2.3, accuracy=0.2)\n\n        Okay to call multiple times for the same step. New values overwrite\n        older ones if they have the same metric name.\n\n        step: An integer or tuple of integers. If a tuple, then the first\n            value is considered to be the epoch and the second is the step\n            within the epoch.\n        """"""\n        assert isinstance(step, (int, tuple)), ""Step must be an int or a tuple of two ints""\n        self.step = step\n        # Any new metrics we haven\'t seen before?\n        self.metrics |= set(kwargs.keys())\n        # Insert (or update) record of the step\n        if step not in self.history:\n            self.history[step] = {}\n        self.history[step].update({k:utils.to_data(v) for k, v in kwargs.items()})\n        # Update step timestamp\n        self.history[step][""__timestamp__""] = time.time()\n\n    @property\n    def steps(self):\n        """"""Returns a list of all steps logged so far. Guaranteed to be\n        sorted correctly.""""""\n        if not self.history:\n            return []\n        # TODO: Consider caching the sorted steps for performance\n        return sorted(self.history.keys())\n\n    @property\n    def formatted_steps(self):\n        return [format_step(s) for s in self.steps]\n\n    def __getitem__(self, metric):\n        return Metric(self, metric)\n\n    def progress(self):\n        # TODO: Erase the previous progress text to update in place\n        text = ""Step {}: "".format(self.step)\n        metrics = self.history[self.step]\n        for k, v in metrics.items():\n            # Skip timestamp\n            if k == ""__timestamp__"":\n                continue\n            # Exclude lists, dicts, and arrays\n            # TODO: ideally, include the skipped types with a compact representation\n            if not isinstance(v, (list, dict, np.ndarray)):\n                text += ""{}: {}  "".format(k, v)\n        print(text)\n\n    def summary(self):\n        # TODO: Include more details in the summary\n        print(""Last Step: {}"".format(self.step))\n        print(""Training Time: {}"".format(self.get_total_time()))\n\n    def get_total_time(self):\n        """"""Returns the total period between when the first and last steps\n        where logged. This usually correspnods to the total training time\n        if there were no gaps in the training.\n        """"""\n        first_step = self.steps[0]\n        last_step = self.steps[-1]\n        seconds = self.history[last_step][""__timestamp__""] \\\n                  - self.history[first_step][""__timestamp__""]\n        return datetime.timedelta(seconds=seconds)\n\n    def save(self, file_name):\n        with open(file_name, ""wb"") as f:\n            pickle.dump(self.history, f)\n\n    def load(self, file_name):\n        with open(file_name, ""rb"") as f:\n            self.history = pickle.load(f)\n        # Set last step and metrics\n        self.step = self.steps[-1]\n        unique_metrics = set(itertools.chain(*[m.keys() for m in self.history.values()]))\n        self.metrics = unique_metrics - {""__timestamp__"",}\n'"
hiddenlayer/pytorch_builder.py,0,"b'""""""\nHiddenLayer\n\nPyTorch graph importer.\n \nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nfrom __future__ import absolute_import, division, print_function\nimport re\nfrom .graph import Graph, Node\nfrom . import transforms as ht\nimport torch\n\n# PyTorch Graph Transforms\nFRAMEWORK_TRANSFORMS = [\n    # Hide onnx: prefix\n    ht.Rename(op=r""onnx::(.*)"", to=r""\\1""),\n    # ONNX uses Gemm for linear layers (stands for General Matrix Multiplication).\n    # It\'s an odd name that noone recognizes. Rename it. \n    ht.Rename(op=r""Gemm"", to=r""Linear""),\n    # PyTorch layers that don\'t have an ONNX counterpart\n    ht.Rename(op=r""aten::max\\_pool2d\\_with\\_indices"", to=""MaxPool""),\n    # Shorten op name\n    ht.Rename(op=r""BatchNormalization"", to=""BatchNorm""),\n]\n\n\ndef dump_pytorch_graph(graph):\n    """"""List all the nodes in a PyTorch graph.""""""\n    f = ""{:25} {:40}   {} -> {}""\n    print(f.format(""kind"", ""scopeName"", ""inputs"", ""outputs""))\n    for node in graph.nodes():\n        print(f.format(node.kind(), node.scopeName(),\n                       [i.unique() for i in node.inputs()],\n                       [i.unique() for i in node.outputs()]\n                       ))\n\n\ndef pytorch_id(node):\n    """"""Returns a unique ID for a node.""""""\n    # After ONNX simplification, the scopeName is not unique anymore\n    # so append node outputs to guarantee uniqueness\n    return node.scopeName() + ""/outputs/"" + ""/"".join([""{}"".format(o.unique()) for o in node.outputs()])\n\n\ndef get_shape(torch_node):\n    """"""Return the output shape of the given Pytorch node.""""""\n    # Extract node output shape from the node string representation\n    # This is a hack because there doesn\'t seem to be an official way to do it.\n    # See my quesiton in the PyTorch forum:\n    # https://discuss.pytorch.org/t/node-output-shape-from-trace-graph/24351/2\n    # TODO: find a better way to extract output shape\n    # TODO: Assuming the node has one output. Update if we encounter a multi-output node.\n    m = re.match(r"".*Float\\(([\\d\\s\\,]+)\\).*"", str(next(torch_node.outputs())))\n    if m:\n        shape = m.group(1)\n        shape = shape.split("","")\n        shape = tuple(map(int, shape))\n    else:\n        shape = None\n    return shape\n\n\ndef import_graph(hl_graph, model, args, input_names=None, verbose=False):\n    # TODO: add input names to graph\n\n    # Run the Pytorch graph to get a trace and generate a graph from it\n    trace, out = torch.jit._get_trace_graph(model, args)\n    torch_graph = torch.onnx._optimize_trace(trace, torch.onnx.OperatorExportTypes.ONNX)\n\n    # Dump list of nodes (DEBUG only)\n    if verbose:\n        dump_pytorch_graph(torch_graph)\n\n    # Loop through nodes and build HL graph\n    for torch_node in torch_graph.nodes():\n        # Op\n        op = torch_node.kind()\n        # Parameters\n        params = {k: torch_node[k] for k in torch_node.attributeNames()} \n        # Inputs/outputs\n        # TODO: inputs = [i.unique() for i in node.inputs()]\n        outputs = [o.unique() for o in torch_node.outputs()]\n        # Get output shape\n        shape = get_shape(torch_node)\n        # Add HL node\n        hl_node = Node(uid=pytorch_id(torch_node), name=None, op=op, \n                       output_shape=shape, params=params)\n        hl_graph.add_node(hl_node)\n        # Add edges\n        for target_torch_node in torch_graph.nodes():\n            target_inputs = [i.unique() for i in target_torch_node.inputs()]\n            if set(outputs) & set(target_inputs):\n                hl_graph.add_edge_by_id(pytorch_id(torch_node), pytorch_id(target_torch_node), shape)\n    return hl_graph\n'"
hiddenlayer/tf_builder.py,4,"b'""""""\nHiddenLayer\n\nTensorFlow graph importer.\n \nWritten by Phil Ferriere. Edits by Waleed Abdulla.\nLicensed under the MIT License\n""""""\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\nimport logging\nimport tensorflow as tf\nfrom .graph import Graph, Node\nfrom . import transforms as ht\n\n\nFRAMEWORK_TRANSFORMS = [\n    # Rename VariableV2 op to Variable. Same for anything V2, V3, ...etc.\n    ht.Rename(op=r""(\\w+)V\\d"", to=r""\\1""),\n    ht.Prune(""Const""),\n    ht.Prune(""PlaceholderWithDefault""),\n    ht.Prune(""Variable""),\n    ht.Prune(""VarIsInitializedOp""),\n    ht.Prune(""VarHandleOp""),\n    ht.Prune(""ReadVariableOp""),\n    ht.PruneBranch(""Assign""),\n    ht.PruneBranch(""AssignSub""),\n    ht.PruneBranch(""AssignAdd""),\n    ht.PruneBranch(""AssignVariableOp""),\n    ht.Prune(""ApplyMomentum""),\n    ht.Prune(""ApplyAdam""),\n    ht.FoldId(r""^(gradients)/.*"", ""NoOp""),  # Fold to NoOp then delete in the next step\n    ht.Prune(""NoOp""),\n    ht.Rename(op=r""DepthwiseConv2dNative"", to=""SeparableConv""),\n    ht.Rename(op=r""Conv2D"", to=""Conv""),\n    ht.Rename(op=r""FusedBatchNorm"", to=""BatchNorm""),\n    ht.Rename(op=r""MatMul"", to=""Linear""),\n    ht.Fold(""Conv > BiasAdd"", ""__first__""),\n    ht.Fold(""Linear > BiasAdd"", ""__first__""),\n    ht.Fold(""Shape > StridedSlice > Pack > Reshape"", ""__last__""),\n    ht.FoldId(r""(.+)/dropout/.*"", ""Dropout""),\n    ht.FoldId(r""(softmax_cross\\_entropy)\\_with\\_logits.*"", ""SoftmaxCrossEntropy""),\n]\n\n\ndef dump_tf_graph(tfgraph, tfgraphdef):\n    """"""List all the nodes in a TF graph.\n    tfgraph: A TF Graph object.\n    tfgraphdef: A TF GraphDef object.\n    """"""\n    print(""Nodes ({})"".format(len(tfgraphdef.node)))\n    f = ""{:15} {:59} {:20} {}""\n    print(f.format(""kind"", ""scopeName"", ""shape"", ""inputs""))\n    for node in tfgraphdef.node:\n        scopename = node.name\n        kind = node.op\n        inputs = node.input\n        shape = tf.graph_util.tensor_shape_from_node_def_name(tfgraph, scopename)\n        print(f.format(kind, scopename, str(shape), inputs))\n\n\ndef import_graph(hl_graph, tf_graph, output=None, verbose=False):\n    """"""Convert TF graph to directed graph\n    tfgraph: A TF Graph object.\n    output: Name of the output node (string).\n    verbose: Set to True for debug print output\n    """"""\n    # Get clean(er) list of nodes\n    graph_def = tf_graph.as_graph_def(add_shapes=True)\n    graph_def = tf.graph_util.remove_training_nodes(graph_def)\n\n    # Dump list of TF nodes (DEBUG only)\n    if verbose:\n        dump_tf_graph(tf_graph, graph_def)\n\n    # Loop through nodes and build the matching directed graph\n    for tf_node in graph_def.node:\n        # Read node details\n        try:\n            op,  uid, name, shape, params = import_node(tf_node, tf_graph, verbose)\n        except:\n            if verbose:\n                logging.exception(""Failed to read node {}"".format(tf_node))\n            continue\n\n        # Add node\n        hl_node = Node(uid=uid, name=name, op=op, output_shape=shape, params=params)\n        hl_graph.add_node(hl_node)\n\n        # Add edges\n        for target_node in graph_def.node:\n            target_inputs = target_node.input\n            if uid in target_node.input:\n                hl_graph.add_edge_by_id(uid, target_node.name, shape)\n    return hl_graph\n\n\ndef import_node(tf_node, tf_graph, verbose=False):\n    # Operation type and name\n    op = tf_node.op\n    uid = tf_node.name\n    name = None\n\n    # Shape\n    shape = None\n    if tf_node.op != ""NoOp"":\n        try:\n            shape = tf.graph_util.tensor_shape_from_node_def_name(tf_graph, tf_node.name)\n            # Is the shape is known, convert to a list\n            if shape.ndims is not None:\n                shape = shape.as_list()\n        except:\n            if verbose:\n                logging.exception(""Error reading shape of {}"".format(tf_node.name))\n\n    # Parameters\n    # At this stage, we really only care about two parameters:\n    # 1/ the kernel size used by convolution layers\n    # 2/ the stride used by convolutional and pooling layers  (TODO: not fully working yet)\n\n    # 1/ The kernel size is actually not stored in the convolution tensor but in its weight input.\n    # The weights input has the shape [shape=[kernel, kernel, in_channels, filters]]\n    # So we must fish for it\n    params = {}\n    if op == ""Conv2D"" or op == ""DepthwiseConv2dNative"":\n        kernel_shape = tf.graph_util.tensor_shape_from_node_def_name(tf_graph, tf_node.input[1])\n        kernel_shape = [int(a) for a in kernel_shape]\n        params[""kernel_shape""] = kernel_shape[0:2]\n        if \'strides\' in tf_node.attr.keys():\n            strides = [int(a) for a in tf_node.attr[\'strides\'].list.i]\n            params[""stride""] = strides[1:3]\n    elif op == ""MaxPool"" or op == ""AvgPool"":\n        # 2/ the stride used by pooling layers\n        # See https://stackoverflow.com/questions/44124942/how-to-access-values-in-protos-in-tensorflow\n        if \'ksize\' in tf_node.attr.keys():\n            kernel_shape = [int(a) for a in tf_node.attr[\'ksize\'].list.i]\n            params[""kernel_shape""] = kernel_shape[1:3]\n        if \'strides\' in tf_node.attr.keys():\n            strides = [int(a) for a in tf_node.attr[\'strides\'].list.i]\n            params[""stride""] = strides[1:3]\n\n    return op, uid, name, shape, params\n'"
hiddenlayer/transforms.py,0,"b'""""""\nHiddenLayer\n\nTransforms that apply to and modify graph nodes.\n \nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nimport re\nimport copy\nfrom .graph import Node\nfrom . import ge\n\n\n\n###########################################################################\n# Transforms\n###########################################################################\n\nclass Fold():\n    def __init__(self, pattern, op, name=None):\n        # TODO: validate that op and name are valid\n        self.pattern = ge.GEParser(pattern).parse()\n        self.op = op\n        self.name = name\n\n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        while True:\n            matches, _ = graph.search(self.pattern)\n            if not matches:\n                break\n\n            # Replace pattern with new node\n            if self.op == ""__first__"":\n                combo = matches[0]\n            elif self.op == ""__last__"":\n                combo = matches[-1]\n            else:\n                combo = Node(uid=graph.sequence_id(matches),\n                                name=self.name or "" &gt; "".join([l.title for l in matches]),\n                                op=self.op or self.pattern,\n                                output_shape=matches[-1].output_shape)\n                combo._caption = ""/"".join(filter(None, [l.caption for l in matches]))\n            graph.replace(matches, combo)\n        return graph\n\n\nclass FoldId():\n    def __init__(self, id_regex, op, name=None):\n        # TODO: validate op and name are valid\n        self.id_regex = re.compile(id_regex)\n        self.op = op\n        self.name = name\n\n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        # Group nodes by the first matching group of the regex\n        groups = {}\n        for node in graph.nodes.values():\n            m = self.id_regex.match(node.id)\n            if not m:\n                continue\n            \n            assert m.groups(), ""Regular expression must have a matching group to avoid folding unrelated nodes.""\n            key = m.group(1)\n            if key not in groups:\n                groups[key] = []\n            groups[key].append(node)\n            \n        # Fold each group of nodes together\n        for key, nodes in groups.items():\n            # Replace with a new node\n            # TODO: Find last node in the sub-graph and get the output shape from it\n            combo = Node(uid=key,\n                         name=self.name,\n                         op=self.op)\n            graph.replace(nodes, combo)\n        return graph\n\n\nclass Prune():\n    def __init__(self, pattern):\n        self.pattern = ge.GEParser(pattern).parse()\n\n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        while True:\n            matches, _ = graph.search(self.pattern)\n            if not matches:\n                break\n            # Remove found nodes\n            graph.remove(matches)\n        return graph\n\n\nclass PruneBranch():\n    def __init__(self, pattern):\n        self.pattern = ge.GEParser(pattern).parse()\n\n    def tag(self, node, tag, graph, conditional=False):\n        # Return if the node is already tagged\n        if hasattr(node, ""__tag__"") and node.__tag__ == ""tag"":\n            return\n        # If conditional, then tag the node if and only if all its\n        # outgoing nodes already have the same tag.\n        if conditional:\n            # Are all outgoing nodes already tagged?\n            outgoing = graph.outgoing(node)\n            tagged = filter(lambda n: hasattr(n, ""__tag__"") and n.__tag__ == tag,\n                            outgoing)\n            if len(list(tagged)) != len(outgoing):\n                # Not all outgoing are tagged\n                return\n        # Tag the node\n        node.__tag__ = tag\n        # Tag incoming nodes\n        for n in graph.incoming(node):\n            self.tag(n, tag, graph, conditional=True)\n\n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        while True:\n            matches, _ = graph.search(self.pattern)\n            if not matches:\n                break\n            # Tag found nodes and their incoming branches\n            for n in matches:\n                self.tag(n, ""delete"", graph)\n            # Find all tagged nodes and delete them\n            tagged = [n for n in graph.nodes.values()\n                      if hasattr(n, ""__tag__"") and n.__tag__ == ""delete""]\n            graph.remove(tagged)\n        return graph\n\n\nclass FoldDuplicates():\n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        matches = True\n        while matches:\n            for node in graph.nodes.values():\n                pattern = ge.SerialPattern([ge.NodePattern(node.op), ge.NodePattern(node.op)])\n                matches, _ = pattern.match(graph, node)\n                if matches:\n                    # Use op and name from the first node, and output_shape from the last\n                    combo = Node(uid=graph.sequence_id(matches),\n                                name=node.name,\n                                op=node.op,\n                                output_shape=matches[-1].output_shape)\n                    combo._caption = node.caption\n                    combo.repeat = sum([n.repeat for n in matches])\n                    graph.replace(matches, combo)\n                    break\n        return graph\n\n\nclass Rename():\n    def __init__(self, op=None, name=None, to=None):\n        assert op or name, ""Either op or name must be provided""\n        assert not(op and name), ""Either op or name should be provided, but not both""\n        assert bool(to), ""The to parameter is required"" \n        self.to = to\n        self.op = re.compile(op) if op else None\n        self.name = re.compile(name) if name else None\n    \n    def apply(self, graph):\n        # Copy the graph. Don\'t change the original.\n        graph = copy.deepcopy(graph)\n\n        for node in graph.nodes.values():\n            if self.op:\n                node.op = self.op.sub(self.to, node.op)\n            # TODO: name is not tested yet\n            if self.name:\n                node.name = self.name.sub(self.to, node.name)\n        return graph\n\n\n# Transforms to simplify graphs by folding layers that tend to be \n# used together often, such as Conv/BN/Relu.\n# These transforms are used AFTER the framework specific transforms\n# that map TF and PyTorch graphs to a common representation.\nSIMPLICITY_TRANSFORMS = [\n    Fold(""Conv > Conv > BatchNorm > Relu"", ""ConvConvBnRelu""),\n    Fold(""Conv > BatchNorm > Relu"", ""ConvBnRelu""),\n    Fold(""Conv > BatchNorm"", ""ConvBn""),\n    Fold(""Conv > Relu"", ""ConvRelu""),\n    Fold(""Linear > Relu"", ""LinearRelu""),\n    # Fold(""ConvBnRelu > MaxPool"", ""ConvBnReluMaxpool""),\n    # Fold(""ConvRelu > MaxPool"", ""ConvReluMaxpool""),\n    FoldDuplicates(),\n]\n'"
hiddenlayer/utils.py,0,"b'""""""\nHiddenLayer\n\nUtility functions.\n \nWritten by Waleed Abdulla\nLicensed under the MIT License\n""""""\n\nimport numpy as np\n\n\n###############################################################################\n# Misc functions\n###############################################################################\n\ndef to_data(value):\n    """"""Standardize data types. Converts PyTorch tensors to Numpy arrays,\n    and Numpy scalars to Python scalars.""""""\n    # TODO: Use get_framework() for better detection.\n    if value.__class__.__module__.startswith(""torch""):\n        import torch\n        if isinstance(value, torch.nn.parameter.Parameter):\n            value = value.data\n        if isinstance(value, torch.Tensor):\n            if value.requires_grad:\n                value = value.detach()\n            value = value.cpu().numpy().copy()\n        # If 0-dim array, convert to scalar\n        if not value.shape:\n            value = value.item()\n    # Convert Numpy scalar types to Python types\n    if value.__class__.__module__ == ""numpy"" and value.__class__.__name__ != ""ndarray"":\n        value = value.item()\n    return value\n\n\ndef write(*args):\n    """"""Like print(), but recognizes tensors and arrays and show\n    more details about them.\n\n    Example:\n        hl.write(""My Tensor"", my_tensor)\n    \n        Prints:\n            My Tensor  float32 (10, 3, 224, 224)  min: 0.0  max: 1.0\n    """"""\n    s = """"\n    for a in args:\n        # Convert tensors to Numpy arrays\n        a = to_data(a)\n\n        if isinstance(a, np.ndarray):\n            # Numpy Array\n            s += (""\\t"" if s else """") + ""Tensor  {} {}  min: {:.3f}  max: {:.3f}"".format(\n                a.dtype, a.shape, a.min(), a.max())\n            print(s)\n            s = """"\n        elif isinstance(a, list):\n            s += (""\\t"" if s else """") + ""list    len: {}  {}"".format(len(a), a[:10])\n        else:\n            s += ("" "" if s else """") + str(a)\n    if s:\n        print(s)\n'"
tests/test_ge.py,0,"b'import unittest\nimport hiddenlayer as hl\nimport hiddenlayer.ge as ge\nimport hiddenlayer.transforms as ht\n\n\nclass TestGEParser(unittest.TestCase):\n\n    def test_basics(self):\n        p = ge.GEParser("" (hello )"")\n        self.assertTrue(p.token(""("") and p.re(r""\\w+"") and p.token("")""))\n\n        p = ge.GEParser(""[1x1]"")\n        self.assertTrue(p.condition() == ""1x1"" and p.index == 5)\n\n        p = ge.GEParser("" [ 1x1 ] "")\n        self.assertTrue(p.condition() == ""1x1"" and p.index == 9)\n\n        p = ge.GEParser(""[1x1"")\n        self.assertTrue(not p.condition() and p.index == 0)\n\n        p = ge.GEParser(""Conv[1x1]"")\n        self.assertTrue(isinstance(p.op(), ge.NodePattern))\n\n        p = ge.GEParser(""Conv[1x1]"")\n        self.assertTrue(isinstance(p.expression(), ge.NodePattern))\n\n        p = ge.GEParser(""(Conv[1x1])"")\n        self.assertTrue(isinstance(p.expression(), ge.NodePattern))\n\n    def test_serial(self):\n        p = ge.GEParser(""Conv>Conv"")\n        self.assertTrue(isinstance(p.serial(), ge.SerialPattern))\n\n        p = ge.GEParser(""Conv > Conv[1x1]"")\n        self.assertTrue(isinstance(p.serial(), ge.SerialPattern))\n\n        p = ge.GEParser(""Conv > (Conv[1x1] > Conv)"")\n        self.assertTrue(isinstance(p.serial(), ge.SerialPattern))\n\n        p = ge.GEParser(""Conv > Conv[1x1] > Conv"")\n        self.assertTrue(isinstance(p.serial(), ge.SerialPattern))\n        self.assertEqual(p.index, 23)\n\n        p = ge.GEParser(""(Conv > Conv[1x1])"")\n        self.assertTrue(isinstance(p.expression(), ge.SerialPattern))\n\n    def test_parallel(self):\n        p = ge.GEParser(""Conv|Conv[1x1]"")\n        self.assertTrue(isinstance(p.parallel(), ge.ParallelPattern))\n\n        p = ge.GEParser(""Conv | Conv[1x1]"")\n        self.assertTrue(isinstance(p.parallel(), ge.ParallelPattern))\n\n        p = ge.GEParser(""Conv | (Conv[1x1] | Conv)"")\n        self.assertTrue(isinstance(p.parallel(), ge.ParallelPattern))\n\n        p = ge.GEParser(""Conv | Conv[1x1] | Conv"")\n        self.assertTrue(isinstance(p.parallel(), ge.ParallelPattern))\n        self.assertEqual(p.index, 23)\n\n        p = ge.GEParser(""(Conv | Conv[1x1])"")\n        self.assertTrue(isinstance(p.expression(), ge.ParallelPattern))\n\n    def test_combinations(self):\n        p = ge.GEParser(""Conv | (Conv[1x1] > Conv)"")\n        self.assertTrue(isinstance(p.parallel(), ge.ParallelPattern))\n\n        p = ge.GEParser(""Conv > (Conv [1x1] | Conv)"")\n        self.assertTrue(isinstance(p.serial(), ge.SerialPattern))\n\n    def test_parsing(self):\n        p = ge.GEParser(""Conv"")\n        self.assertTrue(isinstance(p.parse(), ge.NodePattern))\n\n        p = ge.GEParser(""Conv | Conv[1x1] "")\n        self.assertTrue(isinstance(p.parse(), ge.ParallelPattern))\n\n        p = ge.GEParser(""Conv | (Conv[1x1] > Conv)"")\n        self.assertTrue(isinstance(p.parse(), ge.ParallelPattern))\n\n        p = ge.GEParser(""(Conv | (Conv[1x1] > Conv))"")\n        self.assertTrue(isinstance(p.parse(), ge.ParallelPattern))\n\n\nclass TestGraph(unittest.TestCase):\n    def test_directed_graph(self):\n        g = hl.Graph()\n        g.add_node(""a"")\n        g.add_node(""b"")\n        g.add_node(""c"")\n        g.add_edge(""a"", ""b"")\n        g.add_edge(""b"", ""c"")\n\n        self.assertEqual(g.incoming(""b"")[0], ""a"")\n        self.assertEqual(g.outgoing(""b"")[0], ""c"")\n        g.replace([""b""], ""x"")\n        self.assertEqual(sorted(list(g.nodes.values())), sorted([""a"", ""c"", ""x""]))\n        self.assertEqual(g.incoming(""x"")[0], ""a"")\n        self.assertEqual(g.outgoing(""x"")[0], ""c"")\n\n\nclass TestPatterns(unittest.TestCase):\n    def test_basics(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        e = hl.Node(uid=""e"", name=""e"", op=""e"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_node(e)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(b, d)\n        g.add_edge(c, e)\n        g.add_edge(d, e)\n\n        rule = ge.GEParser(""a > b"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, a)\n        self.assertTrue(match)\n        self.assertCountEqual(following, [c, d])\n        match, following = rule.match(g, b)\n        self.assertFalse(match)\n\n        rule = ge.GEParser(""b > c"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, b)\n        self.assertFalse(match)\n\n        rule = ge.GEParser(""c | d"").parse()\n        self.assertIsInstance(rule, ge.ParallelPattern)\n        match, following = rule.match(g, [c, d])\n        self.assertTrue(match)\n        self.assertEqual(following, e)\n        match, following = rule.match(g, [c])\n        self.assertTrue(match)\n        self.assertEqual(following, e)\n        match, following = rule.match(g, d)\n        self.assertTrue(match)\n        self.assertEqual(following, e)\n        match, following = rule.match(g, b)\n        self.assertFalse(match)\n\n        rule = ge.GEParser(""a > b > (c | d)"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, a)\n        self.assertTrue(match, following)\n\n        rule = ge.GEParser(""(a > b) > (c | d)"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, a)\n        self.assertTrue(match)\n\n        rule = ge.GEParser(""a > b > (c | d) > e"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, a)\n        self.assertTrue(match)\n\n        rule = ge.GEParser(""(c | d) > e"").parse()\n        self.assertIsInstance(rule, ge.SerialPattern)\n        match, following = rule.match(g, [c, d])\n        self.assertTrue(match)\n\n    def test_search(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(b, d)\n\n        pattern = ge.GEParser(""a > b"").parse()\n        match, following = g.search(pattern)\n        self.assertCountEqual(match, [a, b])\n        self.assertCountEqual(following, [c, d])\n\n        pattern = ge.GEParser(""b > (c | d)"").parse()\n        match, following = g.search(pattern)\n        self.assertCountEqual(match, [b, c, d])\n        self.assertEqual(following, [])\n\n        pattern = ge.GEParser(""c|d"").parse()\n        match, following = g.search(pattern)\n        self.assertCountEqual(match, [c, d])\n        self.assertEqual(following, [])\n\n\nclass TestTransforms(unittest.TestCase):\n    def test_regex(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(b, d)\n\n        t = ht.Rename(op=r""a"", to=""bbb"")\n        g = t.apply(g)\n        self.assertEqual(g[""a""].op, ""bbb"")\n\n        t = ht.Rename(op=r""b(.*)"", to=r""x\\1"")\n        g = t.apply(g)\n        self.assertEqual(g[""a""].op, ""xbb"")\n        self.assertEqual(g[""b""].op, ""x"")\n\n    def test_fold(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(b, d)\n\n        t = ht.Fold(""a > b"", ""ab"")\n        g = t.apply(g)\n        self.assertEqual(g.incoming(g[""c""])[0].op, ""ab"")\n\n    def test_fold_duplicates(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b1 = hl.Node(uid=""b1"", name=""b1"", op=""b"", output_shape=(3, 3))\n        b2 = hl.Node(uid=""b2"", name=""b2"", op=""b"", output_shape=(4, 4))\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        g.add_node(a)\n        g.add_node(b1)\n        g.add_node(b2)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_edge(a, b1)\n        g.add_edge(b1, b2)\n        g.add_edge(b2, c)\n        g.add_edge(b2, d)\n\n        t = ht.FoldDuplicates()\n        g = t.apply(g)\n        self.assertEqual(g.incoming(g[""c""])[0].op, ""b"")\n        self.assertEqual(g.incoming(g[""c""])[0].name, ""b1"")\n        self.assertEqual(g.incoming(g[""c""])[0].output_shape, (4, 4))\n\n    def test_parallel_fold(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        e = hl.Node(uid=""e"", name=""e"", op=""e"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_node(e)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(a, d)\n        g.add_edge(c, e)\n        g.add_edge(d, e)\n\n        t = ht.Fold(""((b > c) | d) > e"", ""bcde"")\n        g = t.apply(g)\n        self.assertEqual(g.outgoing(g[""a""])[0].op, ""bcde"")\n\n    def test_prune(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        e = hl.Node(uid=""e"", name=""e"", op=""e"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_node(e)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(a, d)\n        g.add_edge(c, e)\n        g.add_edge(d, e)\n\n        t = ht.Prune(""e"")\n        g = t.apply(g)\n        self.assertFalse(g.outgoing(d))\n\n    def test_prune_branch(self):\n        g = hl.Graph()\n        a = hl.Node(uid=""a"", name=""a"", op=""a"")\n        b = hl.Node(uid=""b"", name=""b"", op=""b"")\n        c = hl.Node(uid=""c"", name=""c"", op=""c"")\n        d = hl.Node(uid=""d"", name=""d"", op=""d"")\n        e = hl.Node(uid=""e"", name=""e"", op=""e"")\n        g.add_node(a)\n        g.add_node(b)\n        g.add_node(c)\n        g.add_node(d)\n        g.add_node(e)\n        g.add_edge(a, b)\n        g.add_edge(b, c)\n        g.add_edge(a, d)\n        g.add_edge(c, e)\n        g.add_edge(d, e)\n\n        t = ht.PruneBranch(""c"")\n        g = t.apply(g)\n        self.assertFalse(g[""b""])\n        self.assertFalse(g[""c""])\n        self.assertTrue(g[""a""])\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_history.py,0,"b'import os\nimport sys\nimport shutil\nimport unittest\nimport hiddenlayer as hl\n\n# Create output directory in project root\nROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nOUTPUT_DIR = os.path.join(ROOT_DIR, ""test_output"")\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\n\nclass TestHistory(unittest.TestCase):\n    def test_steps(self):\n        # Create History object\n        h = hl.History()\n\n        for s in range(100):\n            loss = (100-s)/100\n            accuracy = s / 100\n            h.log(s, loss=loss)\n            h.log(s, accuracy=accuracy)\n\n        self.assertEqual(h[""loss""].data[0], 1)\n        self.assertEqual(h[""accuracy""].data[0], 0)\n        self.assertEqual(h.metrics, {""loss"", ""accuracy""})\n\n        # Save and load\n        if not os.path.exists(OUTPUT_DIR):\n            os.makedirs(OUTPUT_DIR)\n        h.save(os.path.join(OUTPUT_DIR, ""history.pkl""))\n        \n        # Load it\n        h2 = hl.History()\n        h2.load(os.path.join(OUTPUT_DIR, ""history.pkl""))\n        self.assertEqual(h[""loss""].data[0], h2[""loss""].data[0])\n        self.assertEqual(h[""accuracy""].data[0], h2[""accuracy""].data[0])\n        self.assertEqual(h2.step, 99)\n        self.assertEqual(h2.metrics, {""loss"", ""accuracy""})\n        self.assertEqual(hl.history.format_step(h2.step), ""99"")\n        self.assertEqual(hl.history.format_step(h2.step, zero_prefix=True), ""000099"")\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n    def test_epochs(self):\n        # Create History object\n        h = hl.History()\n\n        for e in range(10):\n            for s in range(100):\n                loss = (100-s)/100\n                accuracy = s / 100\n                h.log((e, s), loss=loss)\n                h.log((e, s), accuracy=accuracy)\n\n        self.assertEqual(h[""loss""].data[0], 1)\n        self.assertEqual(h[""accuracy""].data[0], 0)\n\n        # Save and load\n        if not os.path.exists(OUTPUT_DIR):\n            os.makedirs(OUTPUT_DIR)\n        h.save(os.path.join(OUTPUT_DIR, ""history_epoch.pkl""))\n        \n        # Load it\n        h2 = hl.History()\n        h2.load(os.path.join(OUTPUT_DIR, ""history_epoch.pkl""))\n        self.assertEqual(h[""loss""].data[0], h2[""loss""].data[0])\n        self.assertEqual(h[""accuracy""].data[0], h2[""accuracy""].data[0])\n        self.assertEqual(h2.step, (9, 99))\n        self.assertEqual(h2.metrics, {""loss"", ""accuracy""})\n        self.assertEqual(hl.history.format_step(h2.step), ""9:99"")\n        self.assertEqual(hl.history.format_step(h2.step, zero_prefix=True), ""0009:000099"")\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_pytorch_graph.py,0,"b'import os\nimport sys\nimport shutil\nimport unittest\nimport torch\nimport torchvision.models\nimport hiddenlayer as hl\nfrom hiddenlayer import transforms as ht\n\n# Create output directory in project root\nROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nOUTPUT_DIR = os.path.join(ROOT_DIR, ""test_output"")\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\n\nclass TestPytorchGraph(unittest.TestCase):\n    def test_graph(self):\n        model = torchvision.models.vgg16()\n        g = hl.build_graph(model, torch.zeros([1, 3, 224, 224]))\n        g.save(os.path.join(OUTPUT_DIR, ""pytorch_vgg16.pdf""))\n\n        model = torchvision.models.resnet50()\n        g = hl.build_graph(model, torch.zeros([1, 3, 224, 224]))\n        g.save(os.path.join(OUTPUT_DIR, ""pytorch_resnet50.pdf""))\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n\n    def test_resnet_blocks(self):\n        # Resnet101\n        model = torchvision.models.resnet101()\n\n        transforms = [\n            # Fold Conv, BN, RELU layers into one\n            ht.Fold(""Conv > BatchNormalization > Relu"", ""ConvBnRelu""),\n            # Fold Conv, BN layers together\n            ht.Fold(""Conv > BatchNormalization"", ""ConvBn""),\n            # Fold bottleneck blocks\n            ht.Fold(""""""\n                ((ConvBnRelu > ConvBnRelu > ConvBn) | ConvBn) > Add > Relu\n                """""", ""BottleneckBlock"", ""Bottleneck Block""),\n            # Fold residual blocks\n            ht.Fold(""""""ConvBnRelu > ConvBnRelu > ConvBn > Add > Relu"""""",\n                            ""ResBlock"", ""Residual Block""),\n            # Fold repeated blocks\n            ht.FoldDuplicates(),\n        ]\n\n        # Display graph using the transforms above\n        g = hl.build_graph(model, torch.zeros([1, 3, 224, 224]), transforms=transforms)\n        g.save(os.path.join(OUTPUT_DIR, ""pytorch_resnet_bloks.pdf""))\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_pytorch_train.py,0,"b'import os\nimport sys\nimport shutil\nimport unittest\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models\nfrom torchvision import datasets, transforms\n\nimport matplotlib\nmatplotlib.use(""Agg"")\n\nimport hiddenlayer as hl\n\n# Create output and data directories in project root\nROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nOUTPUT_DIR = os.path.join(ROOT_DIR, ""test_output"")\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\nDATA_DIR = os.path.join(ROOT_DIR, ""test_data"")\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            model.history.log((epoch, batch_idx),\n                loss=loss,\n                conv1_weight=model.conv1.weight)\n\n            # At the end of each batch\n            with model.canvas:\n                model.canvas.draw_plot(model.history[""loss""])\n                model.canvas.draw_hist(model.history[""conv1_weight""])\n                # TODO: c.draw_image(model.history[""conv1_weight""])\n\n            if batch_idx % 100 == 0:\n                model.canvas.save(os.path.join(OUTPUT_DIR, ""pytorch_train_{}.png"").format(epoch))\n            model.history.progress()\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction=\'sum\').item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nclass TestPytorchWatcher(unittest.TestCase):\n    def test_train(self):\n        device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n\n        train_loader = torch.utils.data.DataLoader(\n            datasets.MNIST(DATA_DIR, train=True, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Normalize((0.1307,), (0.3081,))\n                        ])),\n            batch_size=64, shuffle=True)\n        test_loader = torch.utils.data.DataLoader(\n            datasets.MNIST(DATA_DIR, train=False, transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Normalize((0.1307,), (0.3081,))\n                        ])),\n            batch_size=1000, shuffle=True)\n\n        model = Net().to(device)\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n\n        # Create History object\n        model.history = hl.History()\n        model.canvas = hl.Canvas()\n\n        for epoch in range(1, 3):\n            train(model, device, train_loader, optimizer, epoch)\n            test(model, device, test_loader)\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_tf_graph.py,28,"b'import os\nimport sys\nimport shutil\nimport unittest\nimport tensorflow as tf\nimport tensorflow.contrib.slim.nets as nets\nfrom tensorflow.contrib import layers\nimport hiddenlayer as hl\n\n# Hide GPUs. Not needed for this test.\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Create output directory in project root\nROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nOUTPUT_DIR = os.path.join(ROOT_DIR, ""test_output"")\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\nDATA_DIR = os.path.join(ROOT_DIR, ""test_data"")\n\ndef lrelu(x):\n    return tf.maximum(0.01 * x, x)\n\nclass TrafficSignsModel():\n    """"""Model taken from my traffic signs recognition repo.\n    https://github.com/waleedka/traffic-signs-tensorflow\n    """"""\n    def conv(self, input, num_outputs, name=None):\n        return layers.convolution2d(\n            input, num_outputs=num_outputs, kernel_size=(5, 5), stride=(1, 1), \n            padding=""SAME"", activation_fn=lrelu,\n            normalizer_fn=layers.batch_norm\n        )\n    \n    def pool(self, input):\n        return layers.max_pool2d(input, kernel_size=(2, 2), \n                                 stride=(2, 2), padding=""SAME"")\n        \n    def __init__(self):\n        self.graph = tf.Graph()\n        with self.graph.as_default():\n            # Global step counter\n            self.global_step = tf.Variable(0, trainable=False, name=\'global_step\')\n            # Placeholders\n            self.images = tf.placeholder(tf.float32, [None, 32, 32, 3], name=""images"")\n            self.labels = tf.placeholder(tf.int32, [None], name=""labels"")\n            # Layers\n            self.conv1 = self.conv(self.images, 8)\n            self.pool1 = self.pool(self.conv1)\n            self.conv2 = self.conv(self.pool1, 12)\n            self.pool2 = self.pool(self.conv2)\n            self.conv3 = self.conv(self.pool2, 16)\n            self.pool3 = self.pool(self.conv3)\n            self.flat = layers.flatten(self.pool3)\n# TODO             self.h1 = layers.fully_connected(self.flat, 200, lrelu)\n            self.logits = layers.fully_connected(self.flat, 62, lrelu)\n            # Convert one-hot vector to label index (int). \n            self.predicted_labels = tf.argmax(self.logits, 1)\n            # Loss\n            self.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n                    logits=self.logits, labels=self.labels, name=""test_name""))\n            # Training Ops\n            self.train = tf.train.AdamOptimizer(learning_rate=0.001)\\\n                                 .minimize(self.loss, global_step=self.global_step)\n            self.init = tf.global_variables_initializer()\n            # Create session\n            self.session = tf.Session()\n            # Run initialization op\n            self.session.run(self.init)\n\n\nclass TestTensorFlow(unittest.TestCase):\n    def test_graph(self):\n        m = TrafficSignsModel()\n\n        dot = hl.build_graph(m.graph).build_dot()\n        dot.format = \'pdf\'\n        dot.render(""tf_traffic_signs"", directory=OUTPUT_DIR, cleanup=True)\n\n        # Import CIFAR from the demos folder\n        sys.path.append(""../demos"")\n        import tf_cifar10\n\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                tf_cifar10.CIFAR10(data_dir=DATA_DIR).model(inputs=tf.placeholder(tf.float32, shape=(8, 32, 32, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_cifar10"", directory=OUTPUT_DIR, cleanup=True)\n\n\nclass TestSlimModels(unittest.TestCase):\n    def test_graph(self):\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                nets.vgg.vgg_16(tf.placeholder(tf.float32, shape=(1, 224, 224, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_vgg16"", directory=OUTPUT_DIR, cleanup=True)\n\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                nets.resnet_v1.resnet_v1_50(\n                    tf.placeholder(tf.float32, shape=(1, 224, 224, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_resnet50"", directory=OUTPUT_DIR, cleanup=True)\n\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                nets.inception.inception_v1(\n                    tf.placeholder(tf.float32, shape=(1, 224, 224, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_inception"", directory=OUTPUT_DIR, cleanup=True)\n\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                nets.alexnet.alexnet_v2(\n                    tf.placeholder(tf.float32, shape=(1, 224, 224, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_alexnet"", directory=OUTPUT_DIR, cleanup=True)\n\n        with tf.Session():\n            with tf.Graph().as_default() as g:\n                nets.overfeat.overfeat(\n                    tf.placeholder(tf.float32, shape=(1, 231, 231, 3)))\n                dot = hl.build_graph(g).build_dot()\n                dot.format = \'pdf\'\n                dot.render(""tf_overfeat"", directory=OUTPUT_DIR, cleanup=True)\n\n        # Clean up\n        shutil.rmtree(OUTPUT_DIR)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
