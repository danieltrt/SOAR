file_path,api_count,code
code/attention.py,25,"b'# -*- coding: UTF-8 -*- \n# Authorized by Vlon Jang\n# Created on 2017-09-26\n# Blog: www.wangqingbaidu.cn\n# Email: wangqingbaidu@gmail.com\n# \xc2\xa92015-2017 All Rights Reserved.\n#\n\n""""""\n    Attention Model:\n    WARNING: Use BatchNorm layer otherwise no accuracy gain.\n    Lower layer with SpatialAttention, high layer with ChannelWiseAttention.\n    In Visual155, Accuracy at 1, from 75.39% to 75.72%(\xe2\x86\x910.33%).\n""""""\nimport tensorflow as tf\ndef spatial_attention(feature_map, K=1024, weight_decay=0.00004, scope="""", reuse=None):\n    """"""This method is used to add spatial attention to model.\n    \n    Parameters\n    ---------------\n    @feature_map: Which visual feature map as branch to use.\n    @K: Map `H*W` units to K units. Now unused.\n    @reuse: reuse variables if use multi gpus.\n    \n    Return\n    ---------------\n    @attended_fm: Feature map with Spatial Attention.\n    """"""\n    with tf.variable_scope(scope, \'SpatialAttention\', reuse=reuse):\n        # Tensorflow\'s tensor is in BHWC format. H for row split while W for column split.\n        _, H, W, C = tuple([int(x) for x in feature_map.get_shape()])\n        w_s = tf.get_variable(""SpatialAttention_w_s"", [C, 1],\n                              dtype=tf.float32,\n                              initializer=tf.initializers.orthogonal,\n                              regularizer=tf.contrib.layers.l2_regularizer(weight_decay))\n        b_s = tf.get_variable(""SpatialAttention_b_s"", [1],\n                              dtype=tf.float32,\n                              initializer=tf.initializers.zeros)\n        spatial_attention_fm = tf.matmul(tf.reshape(feature_map, [-1, C]), w_s) + b_s\n        spatial_attention_fm = tf.nn.sigmoid(tf.reshape(spatial_attention_fm, [-1, W * H]))\n#         spatial_attention_fm = tf.clip_by_value(tf.nn.relu(tf.reshape(spatial_attention_fm, \n#                                                                       [-1, W * H])), \n#                                                 clip_value_min = 0, \n#                                                 clip_value_max = 1)\n        attention = tf.reshape(tf.concat([spatial_attention_fm] * C, axis=1), [-1, H, W, C])\n        attended_fm = attention * feature_map\n        return attended_fm\n    \ndef channel_wise_attention(feature_map, K=1024, weight_decay=0.00004, scope=\'\', reuse=None):\n    """"""This method is used to add spatial attention to model.\n    \n    Parameters\n    ---------------\n    @feature_map: Which visual feature map as branch to use.\n    @K: Map `H*W` units to K units. Now unused.\n    @reuse: reuse variables if use multi gpus.\n    \n    Return\n    ---------------\n    @attended_fm: Feature map with Channel-Wise Attention.\n    """"""\n    with tf.variable_scope(scope, \'ChannelWiseAttention\', reuse=reuse):\n        # Tensorflow\'s tensor is in BHWC format. H for row split while W for column split.\n        _, H, W, C = tuple([int(x) for x in feature_map.get_shape()])\n        w_s = tf.get_variable(""ChannelWiseAttention_w_s"", [C, C],\n                              dtype=tf.float32,\n                              initializer=tf.initializers.orthogonal,\n                              regularizer=tf.contrib.layers.l2_regularizer(weight_decay))\n        b_s = tf.get_variable(""ChannelWiseAttention_b_s"", [C],\n                              dtype=tf.float32,\n                              initializer=tf.initializers.zeros)\n        transpose_feature_map = tf.transpose(tf.reduce_mean(feature_map, [1, 2], keep_dims=True), \n                                             perm=[0, 3, 1, 2])\n        channel_wise_attention_fm = tf.matmul(tf.reshape(transpose_feature_map, \n                                                         [-1, C]), w_s) + b_s\n        channel_wise_attention_fm = tf.nn.sigmoid(channel_wise_attention_fm)\n#         channel_wise_attention_fm = tf.clip_by_value(tf.nn.relu(channel_wise_attention_fm), \n#                                                      clip_value_min = 0, \n#                                                      clip_value_max = 1)\n        attention = tf.reshape(tf.concat([channel_wise_attention_fm] * (H * W), \n                                         axis=1), [-1, H, W, C])\n        attended_fm = attention * feature_map\n        return attended_fm\n'"
code/distance.py,7,"b'# -*- coding: UTF-8 -*- \n# Authorized by Vlon Jang\n# Created on 2018-01-24\n# Blog: www.wangqingbaidu.cn\n# Email: wangqingbaidu@gmail.com\n# \xc2\xa92015-2018 All Rights Reserved.\n#\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\ndef check_dim(x, dim):\n    assert x == dim, \'Dimension is not equal. x=%d, dim=%d\' %(x, dim)\n\ndef cosine_distance(x, y):\n    """"""Compute cosine distance between two tensor.""""""\n    x_shape = x.get_shape()\n    y_shape = y.get_shape()\n    check_dim(len(x_shape), 2)\n    check_dim(len(y_shape), 2)\n    x_norm = tf.sqrt(tf.reduce_sum(tf.square(x), axis=1))\n    y_norm = tf.sqrt(tf.reduce_sum(tf.square(y), axis=1))\n    xy = tf.reduce_sum(tf.multiply(x, y), axis=1)\n    cos_distance = xy / (x_norm * y_norm)\n    return cos_distance\n\ndef cosine_distance_for_each_y(x, y):\n    """"""Compute cosine distance between two tensor. y\'s tensor rank - x\'s tensor rank = 1.""""""\n    x_shape = x.get_shape()\n    y_shape = y.get_shape()\n    check_dim(len(x_shape), 2)\n    check_dim(len(y_shape), 3)\n    batch_size = y_shape[0].value\n    duplicate_num = y_shape[1].value\n    assert len(x_shape) + 1 == len(y_shape), ""#y(%d) - #x(%d) != 1."" %(len(x_shape), len(y_shape))\n    x_expanded = tf.tile(tf.expand_dims(x, axis=1), [1, duplicate_num, 1])\n    dis = cosine_distance(tf.reshape(x_expanded, [batch_size * duplicate_num, -1]),\n                          tf.reshape(y, [batch_size * duplicate_num, -1]))\n    cos_distance = tf.reshape(dis, [batch_size, duplicate_num])\n    return cos_distance\n'"
code/losses.py,64,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Classification and regression loss functions for object detection.\n\nLocalization losses:\n * WeightedL2LocalizationLoss\n * WeightedSmoothL1LocalizationLoss\n * WeightedIOULocalizationLoss\n\nClassification losses:\n * WeightedSigmoidClassificationLoss\n * WeightedSoftmaxClassificationLoss\n * WeightedSoftmaxClassificationAgainstLogitsLoss\n * BootstrappedSigmoidClassificationLoss\n""""""\nfrom abc import ABCMeta\nfrom abc import abstractmethod\n\nimport tensorflow as tf\n\nfrom object_detection.core import box_list\nfrom object_detection.core import box_list_ops\nfrom object_detection.utils import ops\n\nslim = tf.contrib.slim\n\n\nclass Loss(object):\n    """"""Abstract base class for loss functions.""""""\n    __metaclass__ = ABCMeta\n\n    def __call__(self,\n                 prediction_tensor,\n                 target_tensor,\n                 ignore_nan_targets=False,\n                 scope=None,\n                 **params):\n        """"""Call the loss function.\n\n        Args:\n          prediction_tensor: an N-d tensor of shape [batch, anchors, ...]\n            representing predicted quantities.\n          target_tensor: an N-d tensor of shape [batch, anchors, ...] representing\n            regression or classification targets.\n          ignore_nan_targets: whether to ignore nan targets in the loss computation.\n            E.g. can be used if the target tensor is missing groundtruth data that\n            shouldn\'t be factored into the loss.\n          scope: Op scope name. Defaults to \'Loss\' if None.\n          **params: Additional keyword arguments for specific implementations of\n                  the Loss.\n\n        Returns:\n          loss: a tensor representing the value of the loss function.\n        """"""\n        with tf.name_scope(scope, \'Loss\',\n                           [prediction_tensor, target_tensor, params]) as scope:\n            if ignore_nan_targets:\n                target_tensor = tf.where(tf.is_nan(target_tensor),\n                                         prediction_tensor,\n                                         target_tensor)\n            return self._compute_loss(prediction_tensor, target_tensor, **params)\n\n    @abstractmethod\n    def _compute_loss(self, prediction_tensor, target_tensor, **params):\n        """"""Method to be overridden by implementations.\n\n        Args:\n          prediction_tensor: a tensor representing predicted quantities\n          target_tensor: a tensor representing regression or classification targets\n          **params: Additional keyword arguments for specific implementations of\n                  the Loss.\n\n        Returns:\n          loss: an N-d tensor of shape [batch, anchors, ...] containing the loss per\n            anchor\n        """"""\n        pass\n\n\nclass WeightedL2LocalizationLoss(Loss):\n    """"""L2 localization loss function with anchorwise output support.\n\n    Loss[b,a] = .5 * ||weights[b,a] * (prediction[b,a,:] - target[b,a,:])||^2\n    """"""\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            code_size] representing the (encoded) predicted locations of objects.\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            code_size] representing the regression targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors] tensor\n            representing the value of the loss function.\n        """"""\n        weighted_diff = (prediction_tensor - target_tensor) * tf.expand_dims(\n            weights, 2)\n        square_diff = 0.5 * tf.square(weighted_diff)\n        return tf.reduce_sum(square_diff, 2)\n\n\nclass WeightedSmoothL1LocalizationLoss(Loss):\n    """"""Smooth L1 localization loss function aka Huber Loss..\n\n    The smooth L1_loss is defined elementwise as .5 x^2 if |x| <= delta and\n    delta * (|x|- 0.5*delta) otherwise, where x is the difference between\n    predictions and target.\n\n    See also Equation (3) in the Fast R-CNN paper by Ross Girshick (ICCV 2015)\n    """"""\n\n    def __init__(self, delta=1.0):\n        """"""Constructor.\n\n        Args:\n          delta: delta for smooth L1 loss.\n        """"""\n        self._delta = delta\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            code_size] representing the (encoded) predicted locations of objects.\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            code_size] representing the regression targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors] tensor\n            representing the value of the loss function.\n        """"""\n        return tf.reduce_sum(tf.losses.huber_loss(\n            target_tensor,\n            prediction_tensor,\n            delta=self._delta,\n            weights=tf.expand_dims(weights, axis=2),\n            loss_collection=None,\n            reduction=tf.losses.Reduction.NONE\n        ), axis=2)\n\n\nclass WeightedIOULocalizationLoss(Loss):\n    """"""IOU localization loss function.\n\n    Sums the IOU for corresponding pairs of predicted/groundtruth boxes\n    and for each pair assign a loss of 1 - IOU.  We then compute a weighted\n    sum over all pairs which is returned as the total loss.\n    """"""\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors, 4]\n            representing the decoded predicted boxes\n          target_tensor: A float tensor of shape [batch_size, num_anchors, 4]\n            representing the decoded target boxes\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors] tensor\n            representing the value of the loss function.\n        """"""\n        predicted_boxes = box_list.BoxList(\n            tf.reshape(prediction_tensor, [-1, 4]))\n        target_boxes = box_list.BoxList(tf.reshape(target_tensor, [-1, 4]))\n        per_anchor_iou_loss = 1.0 - box_list_ops.matched_iou(predicted_boxes,\n                                                             target_boxes)\n        return tf.reshape(weights, [-1]) * per_anchor_iou_loss\n\n\nclass WeightedSigmoidClassificationLoss(Loss):\n    """"""Sigmoid cross entropy classification loss function.""""""\n\n    def _compute_loss(self,\n                      prediction_tensor,\n                      target_tensor,\n                      weights,\n                      class_indices=None):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing the predicted logits for each class\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing one-hot encoded classification targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n          class_indices: (Optional) A 1-D integer tensor of class indices.\n            If provided, computes loss only for the specified class indices.\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors, num_classes]\n            representing the value of the loss function.\n        """"""\n        weights = tf.expand_dims(weights, 2)\n        if class_indices is not None:\n            weights *= tf.reshape(\n                ops.indices_to_dense_vector(class_indices,\n                                            tf.shape(prediction_tensor)[2]),\n                [1, 1, -1])\n        per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(\n            labels=target_tensor, logits=prediction_tensor))\n        return per_entry_cross_ent * weights\n\n\nclass SigmoidFocalClassificationLoss(Loss):\n    """"""Sigmoid focal cross entropy loss.\n\n    Focal loss down-weights well classified examples and focusses on the hard\n    examples. See https://arxiv.org/pdf/1708.02002.pdf for the loss definition.\n    """"""\n\n    def __init__(self, gamma=2.0, alpha=0.25):\n        """"""Constructor.\n\n        Args:\n          gamma: exponent of the modulating factor (1 - p_t) ^ gamma.\n          alpha: optional alpha weighting factor to balance positives vs negatives.\n        """"""\n        self._alpha = alpha\n        self._gamma = gamma\n\n    def _compute_loss(self,\n                      prediction_tensor,\n                      target_tensor,\n                      weights,\n                      class_indices=None):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing the predicted logits for each class\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing one-hot encoded classification targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n          class_indices: (Optional) A 1-D integer tensor of class indices.\n            If provided, computes loss only for the specified class indices.\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors, num_classes]\n            representing the value of the loss function.\n        """"""\n        weights = tf.expand_dims(weights, 2)\n        if class_indices is not None:\n            weights *= tf.reshape(\n                ops.indices_to_dense_vector(class_indices,\n                                            tf.shape(prediction_tensor)[2]),\n                [1, 1, -1])\n        per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(\n            labels=target_tensor, logits=prediction_tensor))\n        prediction_probabilities = tf.sigmoid(prediction_tensor)\n        p_t = ((target_tensor * prediction_probabilities) +\n               ((1 - target_tensor) * (1 - prediction_probabilities)))\n        modulating_factor = 1.0\n        if self._gamma:\n            modulating_factor = tf.pow(1.0 - p_t, self._gamma)\n        alpha_weight_factor = 1.0\n        if self._alpha is not None:\n            alpha_weight_factor = (target_tensor * self._alpha +\n                                   (1 - target_tensor) * (1 - self._alpha))\n        focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor *\n                                    per_entry_cross_ent)\n        return focal_cross_entropy_loss * weights\n\n\nclass WeightedSoftmaxClassificationLoss(Loss):\n    """"""Softmax loss function.""""""\n\n    def __init__(self, logit_scale=1.0):\n        """"""Constructor.\n\n        Args:\n          logit_scale: When this value is high, the prediction is ""diffused"" and\n                       when this value is low, the prediction is made peakier.\n                       (default 1.0)\n\n        """"""\n        self._logit_scale = logit_scale\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing the predicted logits for each class\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing one-hot encoded classification targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors]\n            representing the value of the loss function.\n        """"""\n        num_classes = prediction_tensor.get_shape().as_list()[-1]\n        prediction_tensor = tf.divide(\n            prediction_tensor, self._logit_scale, name=\'scale_logit\')\n        per_row_cross_ent = (tf.nn.softmax_cross_entropy_with_logits(\n            labels=tf.reshape(target_tensor, [-1, num_classes]),\n            logits=tf.reshape(prediction_tensor, [-1, num_classes])))\n        return tf.reshape(per_row_cross_ent, tf.shape(weights)) * weights\n\n\nclass WeightedSoftmaxClassificationAgainstLogitsLoss(Loss):\n    """"""Softmax loss function against logits.\n\n     Targets are expected to be provided in logits space instead of ""one hot"" or\n     ""probability distribution"" space.\n    """"""\n\n    def __init__(self, logit_scale=1.0):\n        """"""Constructor.\n\n        Args:\n          logit_scale: When this value is high, the target is ""diffused"" and\n                       when this value is low, the target is made peakier.\n                       (default 1.0)\n\n        """"""\n        self._logit_scale = logit_scale\n\n    def _scale_and_softmax_logits(self, logits):\n        """"""Scale logits then apply softmax.""""""\n        scaled_logits = tf.divide(\n            logits, self._logit_scale, name=\'scale_logits\')\n        return tf.nn.softmax(scaled_logits, name=\'convert_scores\')\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing the predicted logits for each class\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing logit classification targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors]\n            representing the value of the loss function.\n        """"""\n        num_classes = prediction_tensor.get_shape().as_list()[-1]\n        target_tensor = self._scale_and_softmax_logits(target_tensor)\n        prediction_tensor = tf.divide(prediction_tensor, self._logit_scale,\n                                      name=\'scale_logits\')\n\n        per_row_cross_ent = (tf.nn.softmax_cross_entropy_with_logits(\n            labels=tf.reshape(target_tensor, [-1, num_classes]),\n            logits=tf.reshape(prediction_tensor, [-1, num_classes])))\n        return tf.reshape(per_row_cross_ent, tf.shape(weights)) * weights\n\n\nclass BootstrappedSigmoidClassificationLoss(Loss):\n    """"""Bootstrapped sigmoid cross entropy classification loss function.\n\n    This loss uses a convex combination of training labels and the current model\'s\n    predictions as training targets in the classification loss. The idea is that\n    as the model improves over time, its predictions can be trusted more and we\n    can use these predictions to mitigate the damage of noisy/incorrect labels,\n    because incorrect labels are likely to be eventually highly inconsistent with\n    other stimuli predicted to have the same label by the model.\n\n    In ""soft"" bootstrapping, we use all predicted class probabilities, whereas in\n    ""hard"" bootstrapping, we use the single class favored by the model.\n\n    See also Training Deep Neural Networks On Noisy Labels with Bootstrapping by\n    Reed et al. (ICLR 2015).\n    """"""\n\n    def __init__(self, alpha, bootstrap_type=\'soft\'):\n        """"""Constructor.\n\n        Args:\n          alpha: a float32 scalar tensor between 0 and 1 representing interpolation\n            weight\n          bootstrap_type: set to either \'hard\' or \'soft\' (default)\n\n        Raises:\n          ValueError: if bootstrap_type is not either \'hard\' or \'soft\'\n        """"""\n        if bootstrap_type != \'hard\' and bootstrap_type != \'soft\':\n            raise ValueError(\'Unrecognized bootstrap_type: must be one of \'\n                             \'\\\'hard\\\' or \\\'soft.\\\'\')\n        self._alpha = alpha\n        self._bootstrap_type = bootstrap_type\n\n    def _compute_loss(self, prediction_tensor, target_tensor, weights):\n        """"""Compute loss function.\n\n        Args:\n          prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing the predicted logits for each class\n          target_tensor: A float tensor of shape [batch_size, num_anchors,\n            num_classes] representing one-hot encoded classification targets\n          weights: a float tensor of shape [batch_size, num_anchors]\n\n        Returns:\n          loss: a float tensor of shape [batch_size, num_anchors, num_classes]\n            representing the value of the loss function.\n        """"""\n        if self._bootstrap_type == \'soft\':\n            bootstrap_target_tensor = self._alpha * target_tensor + (\n                1.0 - self._alpha) * tf.sigmoid(prediction_tensor)\n        else:\n            bootstrap_target_tensor = self._alpha * target_tensor + (\n                1.0 - self._alpha) * tf.cast(\n                    tf.sigmoid(prediction_tensor) > 0.5, tf.float32)\n        per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(\n            labels=bootstrap_target_tensor, logits=prediction_tensor))\n        return per_entry_cross_ent * tf.expand_dims(weights, 2)\n\n\nclass HardExampleMiner(object):\n    """"""Hard example mining for regions in a list of images.\n\n    Implements hard example mining to select a subset of regions to be\n    back-propagated. For each image, selects the regions with highest losses,\n    subject to the condition that a newly selected region cannot have\n    an IOU > iou_threshold with any of the previously selected regions.\n    This can be achieved by re-using a greedy non-maximum suppression algorithm.\n    A constraint on the number of negatives mined per positive region can also be\n    enforced.\n\n    Reference papers: ""Training Region-based Object Detectors with Online\n    Hard Example Mining"" (CVPR 2016) by Srivastava et al., and\n    ""SSD: Single Shot MultiBox Detector"" (ECCV 2016) by Liu et al.\n    """"""\n\n    def __init__(self,\n                 num_hard_examples=64,\n                 iou_threshold=0.7,\n                 loss_type=\'both\',\n                 cls_loss_weight=0.05,\n                 loc_loss_weight=0.06,\n                 max_negatives_per_positive=None,\n                 min_negatives_per_image=0):\n        """"""Constructor.\n\n        The hard example mining implemented by this class can replicate the behavior\n        in the two aforementioned papers (Srivastava et al., and Liu et al).\n        To replicate the A2 paper (Srivastava et al), num_hard_examples is set\n        to a fixed parameter (64 by default) and iou_threshold is set to .7 for\n        running non-max-suppression the predicted boxes prior to hard mining.\n        In order to replicate the SSD paper (Liu et al), num_hard_examples should\n        be set to None, max_negatives_per_positive should be 3 and iou_threshold\n        should be 1.0 (in order to effectively turn off NMS).\n\n        Args:\n          num_hard_examples: maximum number of hard examples to be\n            selected per image (prior to enforcing max negative to positive ratio\n            constraint).  If set to None, all examples obtained after NMS are\n            considered.\n          iou_threshold: minimum intersection over union for an example\n            to be discarded during NMS.\n          loss_type: use only classification losses (\'cls\', default),\n            localization losses (\'loc\') or both losses (\'both\').\n            In the last case, cls_loss_weight and loc_loss_weight are used to\n            compute weighted sum of the two losses.\n          cls_loss_weight: weight for classification loss.\n          loc_loss_weight: weight for location loss.\n          max_negatives_per_positive: maximum number of negatives to retain for\n            each positive anchor. By default, num_negatives_per_positive is None,\n            which means that we do not enforce a prespecified negative:positive\n            ratio.  Note also that num_negatives_per_positives can be a float\n            (and will be converted to be a float even if it is passed in otherwise).\n          min_negatives_per_image: minimum number of negative anchors to sample for\n            a given image. Setting this to a positive number allows sampling\n            negatives in an image without any positive anchors and thus not biased\n            towards at least one detection per image.\n        """"""\n        self._num_hard_examples = num_hard_examples\n        self._iou_threshold = iou_threshold\n        self._loss_type = loss_type\n        self._cls_loss_weight = cls_loss_weight\n        self._loc_loss_weight = loc_loss_weight\n        self._max_negatives_per_positive = max_negatives_per_positive\n        self._min_negatives_per_image = min_negatives_per_image\n        if self._max_negatives_per_positive is not None:\n            self._max_negatives_per_positive = float(\n                self._max_negatives_per_positive)\n        self._num_positives_list = None\n        self._num_negatives_list = None\n\n    def __call__(self,\n                 location_losses,\n                 cls_losses,\n                 decoded_boxlist_list,\n                 match_list=None):\n        """"""Computes localization and classification losses after hard mining.\n\n        Args:\n          location_losses: a float tensor of shape [num_images, num_anchors]\n            representing anchorwise localization losses.\n          cls_losses: a float tensor of shape [num_images, num_anchors]\n            representing anchorwise classification losses.\n          decoded_boxlist_list: a list of decoded BoxList representing location\n            predictions for each image.\n          match_list: an optional list of matcher.Match objects encoding the match\n            between anchors and groundtruth boxes for each image of the batch,\n            with rows of the Match objects corresponding to groundtruth boxes\n            and columns corresponding to anchors.  Match objects in match_list are\n            used to reference which anchors are positive, negative or ignored.  If\n            self._max_negatives_per_positive exists, these are then used to enforce\n            a prespecified negative to positive ratio.\n\n        Returns:\n          mined_location_loss: a float scalar with sum of localization losses from\n            selected hard examples.\n          mined_cls_loss: a float scalar with sum of classification losses from\n            selected hard examples.\n        Raises:\n          ValueError: if location_losses, cls_losses and decoded_boxlist_list do\n            not have compatible shapes (i.e., they must correspond to the same\n            number of images).\n          ValueError: if match_list is specified but its length does not match\n            len(decoded_boxlist_list).\n        """"""\n        mined_location_losses = []\n        mined_cls_losses = []\n        location_losses = tf.unstack(location_losses)\n        cls_losses = tf.unstack(cls_losses)\n        num_images = len(decoded_boxlist_list)\n        if not match_list:\n            match_list = num_images * [None]\n        if not len(location_losses) == len(decoded_boxlist_list) == len(cls_losses):\n            raise ValueError(\'location_losses, cls_losses and decoded_boxlist_list \'\n                             \'do not have compatible shapes.\')\n        if not isinstance(match_list, list):\n            raise ValueError(\'match_list must be a list.\')\n        if len(match_list) != len(decoded_boxlist_list):\n            raise ValueError(\'match_list must either be None or have \'\n                             \'length=len(decoded_boxlist_list).\')\n        num_positives_list = []\n        num_negatives_list = []\n        for ind, detection_boxlist in enumerate(decoded_boxlist_list):\n            box_locations = detection_boxlist.get()\n            match = match_list[ind]\n            image_losses = cls_losses[ind]\n            if self._loss_type == \'loc\':\n                image_losses = location_losses[ind]\n            elif self._loss_type == \'both\':\n                image_losses *= self._cls_loss_weight\n                image_losses += location_losses[ind] * self._loc_loss_weight\n            if self._num_hard_examples is not None:\n                num_hard_examples = self._num_hard_examples\n            else:\n                num_hard_examples = detection_boxlist.num_boxes()\n            selected_indices = tf.image.non_max_suppression(\n                box_locations, image_losses, num_hard_examples, self._iou_threshold)\n            if self._max_negatives_per_positive is not None and match:\n                (selected_indices, num_positives,\n                 num_negatives) = self._subsample_selection_to_desired_neg_pos_ratio(\n                     selected_indices, match, self._max_negatives_per_positive,\n                     self._min_negatives_per_image)\n                num_positives_list.append(num_positives)\n                num_negatives_list.append(num_negatives)\n            mined_location_losses.append(\n                tf.reduce_sum(tf.gather(location_losses[ind], selected_indices)))\n            mined_cls_losses.append(\n                tf.reduce_sum(tf.gather(cls_losses[ind], selected_indices)))\n        location_loss = tf.reduce_sum(tf.stack(mined_location_losses))\n        cls_loss = tf.reduce_sum(tf.stack(mined_cls_losses))\n        if match and self._max_negatives_per_positive:\n            self._num_positives_list = num_positives_list\n            self._num_negatives_list = num_negatives_list\n        return (location_loss, cls_loss)\n\n    def summarize(self):\n        """"""Summarize the number of positives and negatives after mining.""""""\n        if self._num_positives_list and self._num_negatives_list:\n            avg_num_positives = tf.reduce_mean(\n                tf.to_float(self._num_positives_list))\n            avg_num_negatives = tf.reduce_mean(\n                tf.to_float(self._num_negatives_list))\n            tf.summary.scalar(\n                \'HardExampleMiner/NumPositives\', avg_num_positives)\n            tf.summary.scalar(\n                \'HardExampleMiner/NumNegatives\', avg_num_negatives)\n\n    def _subsample_selection_to_desired_neg_pos_ratio(self,\n                                                      indices,\n                                                      match,\n                                                      max_negatives_per_positive,\n                                                      min_negatives_per_image=0):\n        """"""Subsample a collection of selected indices to a desired neg:pos ratio.\n\n        This function takes a subset of M indices (indexing into a large anchor\n        collection of N anchors where M<N) which are labeled as positive/negative\n        via a Match object (matched indices are positive, unmatched indices\n        are negative).  It returns a subset of the provided indices retaining all\n        positives as well as up to the first K negatives, where:\n          K=floor(num_negative_per_positive * num_positives).\n\n        For example, if indices=[2, 4, 5, 7, 9, 10] (indexing into 12 anchors),\n        with positives=[2, 5] and negatives=[4, 7, 9, 10] and\n        num_negatives_per_positive=1, then the returned subset of indices\n        is [2, 4, 5, 7].\n\n        Args:\n          indices: An integer tensor of shape [M] representing a collection\n            of selected anchor indices\n          match: A matcher.Match object encoding the match between anchors and\n            groundtruth boxes for a given image, with rows of the Match objects\n            corresponding to groundtruth boxes and columns corresponding to anchors.\n          max_negatives_per_positive: (float) maximum number of negatives for\n            each positive anchor.\n          min_negatives_per_image: minimum number of negative anchors for a given\n            image. Allow sampling negatives in image without any positive anchors.\n\n        Returns:\n          selected_indices: An integer tensor of shape [M\'] representing a\n            collection of selected anchor indices with M\' <= M.\n          num_positives: An integer tensor representing the number of positive\n            examples in selected set of indices.\n          num_negatives: An integer tensor representing the number of negative\n            examples in selected set of indices.\n        """"""\n        positives_indicator = tf.gather(\n            match.matched_column_indicator(), indices)\n        negatives_indicator = tf.gather(\n            match.unmatched_column_indicator(), indices)\n        num_positives = tf.reduce_sum(tf.to_int32(positives_indicator))\n        max_negatives = tf.maximum(min_negatives_per_image,\n                                   tf.to_int32(max_negatives_per_positive *\n                                               tf.to_float(num_positives)))\n        topk_negatives_indicator = tf.less_equal(\n            tf.cumsum(tf.to_int32(negatives_indicator)), max_negatives)\n        subsampled_selection_indices = tf.where(\n            tf.logical_or(positives_indicator, topk_negatives_indicator))\n        num_negatives = tf.size(subsampled_selection_indices) - num_positives\n        return (tf.reshape(tf.gather(indices, subsampled_selection_indices), [-1]),\n                num_positives, num_negatives)\n'"
code/numpy_fc.py,0,"b'# -*- coding: utf-8 -*-\nimport numpy as np\n\n# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# Create random input and output data\nx = np.random.randn(N, D_in)\ny = np.random.randn(N, D_out)\n\n# Randomly initialize weights\nw1 = np.random.randn(D_in, H)\nw2 = np.random.randn(H, D_out)\n\nlearning_rate = 1e-6\nfor t in range(500):\n    # Forward pass: compute predicted y\n    h = x.dot(w1)\n    h_relu = np.maximum(h, 0)\n    y_pred = h_relu.dot(w2)\n\n    # Compute and print loss\n    loss = np.square(y_pred - y).sum()\n    print(t, loss)\n\n    # Backprop to compute gradients of w1 and w2 with respect to loss\n    grad_y_pred = 2.0 * (y_pred - y)\n    grad_w2 = h_relu.T.dot(grad_y_pred)\n    grad_h_relu = grad_y_pred.dot(w2.T)\n    grad_h = grad_h_relu.copy()\n    grad_h[h < 0] = 0\n    grad_w1 = x.T.dot(grad_h)\n\n    # Update weights\n    w1 -= learning_rate * grad_w1\n    w2 -= learning_rate * grad_w2\n'"
