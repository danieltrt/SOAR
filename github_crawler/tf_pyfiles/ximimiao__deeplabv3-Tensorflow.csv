file_path,api_count,code
color_utils.py,0,"b""import numpy as np\nimport cv2\n\n# \xe7\xbb\x99\xe6\xa0\x87\xe7\xad\xbe\xe5\x9b\xbe\xe4\xb8\x8a\xe8\x89\xb2\ndef color_predicts(img):\n\n    '''\n    \xe7\xbb\x99class\xe5\x9b\xbe\xe4\xb8\x8a\xe8\x89\xb2\n\n    '''\n    # img = cv2.imread(label_path,cv2.CAP_MODE_GRAY)\n    color = np.ones([img.shape[0], img.shape[1], 3])\n    color[img==0] = [255, 255, 255] #\xe5\x85\xb6\xe4\xbb\x96\xef\xbc\x8c\xe7\x99\xbd\xe8\x89\xb2\xef\xbc\x8c0\n    color[img==1] = [0, 255, 0]     #\xe6\xa4\x8d\xe8\xa2\xab\xef\xbc\x8c\xe7\xbb\xbf\xe8\x89\xb2\xef\xbc\x8c1\n    color[img==2] = [0, 0, 0]       #\xe9\x81\x93\xe8\xb7\xaf\xef\xbc\x8c\xe9\xbb\x91\xe8\x89\xb2\xef\xbc\x8c2\n    color[img==3] = [131, 139, 139] #\xe5\xbb\xba\xe7\xad\x91\xef\xbc\x8c\xe9\xbb\x84\xe8\x89\xb2\xef\xbc\x8c3\n    color[img==4] = [139, 69, 19]   #\xe6\xb0\xb4\xe4\xbd\x93\xef\xbc\x8c\xe8\x93\x9d\xe8\x89\xb2\xef\xbc\x8c4\n\n    return color\ndef color_annotation(label_path, output_path):\n\n    '''\n\n    \xe7\xbb\x99class\xe5\x9b\xbe\xe4\xb8\x8a\xe8\x89\xb2\n\n    '''\n\n    img = cv2.imread(label_path,cv2.CAP_MODE_GRAY)\n\n    color = np.ones([img.shape[0], img.shape[1], 3])\n\n    color[img==0] = [255, 255, 255] #\xe5\x85\xb6\xe4\xbb\x96\xef\xbc\x8c\xe7\x99\xbd\xe8\x89\xb2\xef\xbc\x8c0\n    color[img==1] = [0, 255, 0]     #\xe6\xa4\x8d\xe8\xa2\xab\xef\xbc\x8c\xe7\xbb\xbf\xe8\x89\xb2\xef\xbc\x8c1\n    color[img==2] = [0, 0, 0]       #\xe9\x81\x93\xe8\xb7\xaf\xef\xbc\x8c\xe9\xbb\x91\xe8\x89\xb2\xef\xbc\x8c2\n    color[img==3] = [131, 139, 139] #\xe5\xbb\xba\xe7\xad\x91\xef\xbc\x8c\xe9\xbb\x84\xe8\x89\xb2\xef\xbc\x8c3\n    color[img==4] = [139, 69, 19]   #\xe6\xb0\xb4\xe4\xbd\x93\xef\xbc\x8c\xe8\x93\x9d\xe8\x89\xb2\xef\xbc\x8c4\n\n    cv2.imwrite(output_path,color)"""
data_utils.py,0,"b""import cv2, os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n\nclass DataSet():\n    '''\n    \xe9\x80\x9a\xe8\xbf\x87\xe8\xaf\xbb\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    '''\n\n    def __init__(self, image_path, label_path):\n\n        self.image_path = np.array(image_path)\n        self.label_path = np.array(label_path)\n        self.batch_count = 0\n        self.epoch_count = 0\n\n    def num_examples(self):\n        '''\n        \xe5\xbe\x97\xe5\x88\xb0\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe6\x95\xb0\xe9\x87\x8f\n        :return:\n        '''\n\n        return self.image_path.shape[0]\n\n\n    def next_batch(self, batch_size):\n        '''\n        next_batch\xe5\x87\xbd\xe6\x95\xb0\n        :param batch_size:\n        :return:\n        '''\n\n        start = self.batch_count * batch_size\n        end = start + batch_size\n        self.batch_count += 1\n\n        if end > self.image_path.shape[0]:\n            self.batch_count = 0\n            random_index = np.random.permutation(self.image_path.shape[0])\n            self.image_path = self.image_path[random_index]\n            self.label_path = self.label_path[random_index]\n            self.epoch_count += 1\n            start = self.batch_count * batch_size\n            end = start + batch_size\n            self.batch_count += 1\n\n        image_batch, label_batch = self.read_path(self.image_path[start:end],\n                                                  self.label_path[start:end])\n        return image_batch, label_batch\n\n    def read_path(self, x_path, y_path):\n        '''\n        \xe5\xb0\x86\xe8\xb7\xaf\xe5\xbe\x84\xe8\xaf\xbb\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\n        :param x_path:\n        :param y_path:\n        :return:\n        '''\n        x = []\n        y = []\n        for i in range(x_path.shape[0]):\n            x.append(self.transform(cv2.imread(x_path[i], cv2.CAP_MODE_RGB)))\n            y.append(cv2.imread(y_path[i], cv2.CAP_MODE_GRAY))\n\n        return np.array(x), np.array(y)\n\n    def transform(self, img):\n\n        return img"""
deeplab_v3.py,50,"b'""""""ResNet model.\nRelated papers:\nhttps://arxiv.org/pdf/1603.05027v2.pdf\nhttps://arxiv.org/pdf/1512.03385v1.pdf\nhttps://arxiv.org/pdf/1605.07146v1.pdf\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow.python.training import moving_averages\n\nimport tensorflow as tf\n\n\n# \xe4\xb8\xba\xe4\xba\x86finetune resnet_v2_50 \xe5\xaf\xb9\xe6\x95\xb0\xe6\x8d\xae\xe6\xaf\x8f\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe4\xb8\xad\xe5\xbf\x83\xe5\x8c\x96\n_R_MEAN = 123.68\n_G_MEAN = 116.78\n_B_MEAN = 103.94\n\n\nclass Deeplab_v3():\n    def __init__(self,\n                 batch_norm_decay=0.99,\n                 batch_norm_epsilon=1e-3,):\n\n        self._batch_norm_decay = batch_norm_decay\n        self._batch_norm_epsilon = batch_norm_epsilon\n        # \xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xe5\xbc\x80\xe5\x85\xb3\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\n        self._is_training = tf.placeholder(tf.bool, name=\'is_training\')\n        self.num_class = 5\n        self.filters = [64, 256, 512, 1024, 2048]\n        self.strides = [2, 2, 1, 1]\n        self.n = [3, 4, 6, 3]\n\n    def forward_pass(self, x):\n        """"""Build the core model within the graph""""""\n        with tf.variable_scope(\'resnet_v2_50\', reuse=tf.AUTO_REUSE):\n            size = tf.shape(x)[1:3]\n\n            x = x - [_R_MEAN, _G_MEAN, _B_MEAN]\n\n            x = self._conv(x, 7, 64, 2, \'conv1\', False, False)\n            x = self._max_pool(x, 3, 2, \'max\')\n\n            res_func = self._bottleneck_residual_v2\n\n            for i in range(4):\n                with tf.variable_scope(\'block%d\' % (i + 1)):\n                    for j in range(self.n[i]):\n                        with tf.variable_scope(\'unit_%d\' % (j + 1)):\n                            if j == 0:\n                                x = res_func(x, self.filters[i], self.filters[i+1], 1)\n                            elif j == self.n[i] - 1:\n                                x = res_func(x, self.filters[i+1], self.filters[i+1], self.strides[i])\n                            else:\n                                x = res_func(x, self.filters[i+1], self.filters[i+1], 1)\n                tf.logging.info(\'the shape of features after block%d is %s\' % (i+1, x.get_shape()))\n\n        # DeepLab_v3\xe7\x9a\x84\xe9\x83\xa8\xe5\x88\x86\n        with tf.variable_scope(\'DeepLab_v3\', reuse=tf.AUTO_REUSE):\n            x = self._atrous_spatial_pyramid_pooling(x)\n            x = self._conv(x, 1, 5, 1, \'logits\', False, False)\n            x = tf.image.resize_bilinear(x, size)\n            return x\n    def _A_ASPP(self):\n        pass\n    def _atrous_spatial_pyramid_pooling(self, x):\n        """"""\xe7\xa9\xba\xe6\xb4\x9e\xe7\xa9\xba\xe9\x97\xb4\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe6\xb1\xa0\xe5\x8c\x96\n        """"""\n        with tf.variable_scope(\'ASSP_layers\'):\n\n            feature_map_size = tf.shape(x)\n\n            image_level_features = tf.reduce_mean(x, [1, 2], keep_dims=True)\n            image_level_features = self._conv(image_level_features, 1, 256, 1, \'global_avg_pool\', True)\n            image_level_features = tf.image.resize_bilinear(image_level_features, (feature_map_size[1],\n                                                                                   feature_map_size[2]))\n\n            at_pool1x1   = self._conv(x, kernel_size=1, filters=256, strides=1, scope=\'assp1\', batch_norm=True)\n            at_pool3x3_1 = self._conv(x, kernel_size=3, filters=256, strides=1, scope=\'assp2\', batch_norm=True, rate=6)\n            at_pool3x3_2 = self._conv(x, kernel_size=3, filters=256, strides=1, scope=\'assp3\', batch_norm=True, rate=12)\n            at_pool3x3_3 = self._conv(x, kernel_size=3, filters=256, strides=1, scope=\'assp4\', batch_norm=True, rate=18)\n\n            net = tf.concat((image_level_features, at_pool1x1, at_pool3x3_1, at_pool3x3_2, at_pool3x3_3), axis=3)\n\n            net = self._conv(net, kernel_size=1, filters=256, strides=1, scope=\'concat\', batch_norm=True)\n\n            return net\n\n    def _bottleneck_residual_v2(self,\n                                x,\n                                in_filter,\n                                out_filter,\n                                stride,):\n\n        """"""Bottleneck residual unit with 3 sub layers, plan B shortcut.""""""\n\n        with tf.variable_scope(\'bottleneck_v2\'):\n            origin_x = x\n            with tf.variable_scope(\'preact\'):\n                preact = self._batch_norm(x)\n                preact = self._relu(preact)\n\n            residual = self._conv(preact, 1, out_filter // 4, stride, \'conv1\', True, True)\n            residual = self._conv(residual, 3, out_filter // 4, 1, \'conv2\', True, True)\n            residual = self._conv(residual, 1, out_filter, 1, \'conv3\', False, False)\n\n            if in_filter != out_filter:\n                short_cut = self._conv(preact, 1, out_filter, stride, \'shortcut\', False, False)\n            else:\n                short_cut = self._subsample(origin_x, stride, \'shortcut\')\n            x = tf.add(residual, short_cut)\n            return x\n\n    def _conv(self,\n              x,\n              kernel_size,\n              filters,\n              strides,\n              scope,\n              batch_norm=False,\n              activation=False,\n              rate=None\n              ):\n        """"""Convolution.""""""\n        with tf.variable_scope(scope):\n            x_shape = x.get_shape().as_list()\n            w = tf.get_variable(name=\'weights\',\n                                shape=[kernel_size, kernel_size, x_shape[3], filters])\n            if rate == None:\n                x = tf.nn.conv2d(input=x,\n                                 filter=w,\n                                 padding=\'SAME\',\n                                 strides=[1, strides, strides, 1],\n                                 name=\'conv\', )\n            else:\n                x = tf.nn.atrous_conv2d(value=x,\n                                        filters=w,\n                                        padding=\'SAME\',\n                                        name=\'conv\',\n                                        rate=rate)\n\n            if batch_norm:\n                with tf.variable_scope(\'BatchNorm\'):\n                    x = self._batch_norm(x)\n            else:\n                b = tf.get_variable(name=\'biases\', shape=[filters])\n                x = x + b\n            if activation:\n                x = tf.nn.relu(x)\n            return x\n\n    def _batch_norm(self, x):\n        x_shape = x.get_shape()\n        params_shape = x_shape[-1:]\n\n        axis = list(range(len(x_shape) - 1))\n        beta = tf.get_variable(name=\'beta\',\n                               shape=params_shape,\n                               initializer=tf.zeros_initializer)\n\n        gamma = tf.get_variable(name=\'gamma\',\n                                shape=params_shape,\n                                initializer=tf.ones_initializer)\n\n        moving_mean = tf.get_variable(name=\'moving_mean\',\n                                      shape=params_shape,\n                                      initializer=tf.zeros_initializer,\n                                      trainable=False)\n\n        moving_variance = tf.get_variable(name=\'moving_variance\',\n                                          shape=params_shape,\n                                          initializer=tf.ones_initializer,\n                                          trainable=False)\n\n        tf.add_to_collection(\'BN_MEAN_VARIANCE\', moving_mean)\n        tf.add_to_collection(\'BN_MEAN_VARIANCE\', moving_variance)\n\n        # These ops will only be preformed when training.\n        mean, variance = tf.nn.moments(x, axis)\n        update_moving_mean = moving_averages.assign_moving_average(moving_mean,\n                                                                   mean,\n                                                                   self._batch_norm_decay,\n                                                                   name=\'MovingAvgMean\')\n        update_moving_variance = moving_averages.assign_moving_average(moving_variance,\n                                                                       variance,\n                                                                       self._batch_norm_decay,\n                                                                       name=\'MovingAvgVariance\')\n\n        tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_moving_mean)\n        tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_moving_variance)\n\n        mean, variance = tf.cond(\n            pred=self._is_training,\n            true_fn=lambda: (mean, variance),\n            false_fn=lambda: (moving_mean, moving_variance)\n        )\n        x = tf.nn.batch_normalization(x, mean, variance, beta, gamma, self._batch_norm_epsilon)\n        return x\n\n    def _relu(self, x):\n        return tf.nn.relu(x)\n\n    def _max_pool(self, x, pool_size, stride, scope):\n        with tf.name_scope(\'max_pool\') as name_scope:\n            x = tf.layers.max_pooling2d(\n                x, pool_size, stride, \'SAME\', name=scope\n            )\n        return x\n\n    def _avg_pool(self, x, pool_size, stride):\n        with tf.name_scope(\'avg_pool\') as name_scope:\n            x = tf.layers.average_pooling2d(\n                x, pool_size, stride, \'SAME\')\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n    def _global_avg_pool(self, x):\n        with tf.name_scope(\'global_avg_pool\') as name_scope:\n            assert x.get_shape().ndims == 4\n\n            x = tf.reduce_mean(x, [1, 2])\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n    def _concat(self, x, y):\n        with tf.name_scope(\'concat\') as name_scope:\n            assert x.get_shape().ndims == 4\n            assert y.get_shape().ndims == 4\n\n            x = tf.concat([x, y], 3)\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n    def _subsample(self, inputs, stride, scope=None):\n        """"""Subsamples the input along the spatial dimensions.""""""\n        if stride == 1:\n            return inputs\n        else:\n            return self._max_pool(inputs, 3, stride, scope)'"
metric_utils.py,0,"b""import numpy as np\nfrom sklearn.metrics import confusion_matrix\n# \xe5\x85\xb6\xe4\xbb\x96\xef\xbc\x8c\xe7\x99\xbd\xe8\x89\xb2\xef\xbc\x8c0\n# \xe6\xa4\x8d\xe8\xa2\xab\xef\xbc\x8c\xe7\xbb\xbf\xe8\x89\xb2\xef\xbc\x8c1\n# \xe9\x81\x93\xe8\xb7\xaf\xef\xbc\x8c\xe9\xbb\x91\xe8\x89\xb2\xef\xbc\x8c2\n# \xe5\xbb\xba\xe7\xad\x91\xef\xbc\x8c\xe9\xbb\x84\xe8\x89\xb2\xef\xbc\x8c3\n# \xe6\xb0\xb4\xe4\xbd\x93\xef\xbc\x8c\xe8\x93\x9d\xe8\x89\xb2\xef\xbc\x8c4\n\ndef iou(y_pre: np.ndarray, y_true: np.ndarray) -> 'dict':\n    # cm\xe6\x98\xaf\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\n    cm = confusion_matrix(\n        y_true=y_true,\n        y_pred=y_pre,\n        labels=[0, 1, 2, 3, 4])\n\n    result_iou = [\n        cm[i][i] / (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i]) for i in range(len(cm))\n    ]\n\n    metric_dict = {}\n    metric_dict['IOU_\xe5\x85\xb6\xe4\xbb\x96/other'] = result_iou[0]\n    metric_dict['IOU_\xe6\xa4\x8d\xe7\x89\xa9/plant'] = result_iou[1]\n    metric_dict['IOU_\xe9\x81\x93\xe8\xb7\xaf/road']  = result_iou[2]\n    metric_dict['IOU_\xe5\xbb\xba\xe7\xad\x91/arch']  = result_iou[3]\n    metric_dict['IOU_\xe6\xb0\xb4\xe4\xbd\x93/water'] = result_iou[4]\n\n    metric_dict['iou'] = np.mean(result_iou)\n    metric_dict['accuracy'] = sum(np.diag(cm)) / sum(np.reshape(cm, -1))\n\n    return metric_dict\n\n"""
predicts_utils.py,14,"b'import cv2\nimport numpy as np\nimport tensorflow as tf\n\ndef predict(image: np.ndarray, input_placeholder: tf.placeholder,\n    is_training_placeholder: tf.placeholder, logits_prob_node: tf.Tensor,\n    sess: tf.Session, prob: bool) -> np.ndarray:\n    """"""\n    \xe4\xbd\xbf\xe7\x94\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\x80\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\xb9\xb6\xe8\xbe\x93\xe5\x87\xba\xe5\x85\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe6\xa6\x82\xe7\x8e\x87\xe5\x88\x86\xe5\xb8\x83\n    Args:\n        image: np.ndarray [size, size, 3] \xe9\x9c\x80\xe8\xa6\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe7\xbb\x84\n        input_placeholder: tf.placeholder\n        is_training_placeholder: tf.placeholder\n        logits_prob_node: tf.Tensor [size, size, num_classes]\n        sess: tf.Session\n        prob: bool \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe6\x98\xaf\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x8c\xe8\xbf\x98\xe6\x98\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\n    Returns:\n        image_predict: np.ndarray [size, size, 5] if porb is True\n                       np.ndarray [size, size] if prob is not True\n    """"""\n    assert image.shape == (256, 256, 3), print(image.shape)\n    # \xe7\xbb\x99image\xe5\x8d\x87\xe7\xbb\xb4 [256, 256, 3] -> [1, 256, 256, 3]\n    feed_dict = {input_placeholder: np.expand_dims(image, 0),\n                 is_training_placeholder: False}\n    image_predict_prob = sess.run(logits_prob_node, feed_dict=feed_dict)\n    # \xe7\xbb\x99image\xe9\x99\x8d\xe7\xbb\xb4 [1, 256, 256, 5] -> [256, 256, 5]\n    image_predict_prob = np.squeeze(image_predict_prob, 0)\n    if prob:\n        # \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\xa6\x82\xe7\x8e\x87\xe5\x88\x86\xe5\xb8\x83\n        return image_predict_prob\n    else:\n        # \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\n        image_predict = np.argmax(image_predict_prob, -1)\n        return image_predict\n\ndef rotate(x, angle, size=256):\n    """""" \xe6\x97\x8b\xe8\xbd\xac\xe5\x87\xbd\xe6\x95\xb0\n    """"""\n    M_rotate = cv2.getRotationMatrix2D((size / 2, size / 2), angle, 1)\n    x = cv2.warpAffine(x, M_rotate, (size, size))\n    return x\n\ndef multi_scale_predict(image: np.ndarray, input_placeholder: tf.placeholder,\n    is_training_placeholder: tf.placeholder, logits_prob_node: tf.Tensor,\n    sess: tf.Session, multi: bool):\n    """"""\n\n    Args:\n        image:\n        input_placeholder:\n        is_training_placeholder:\n        logits_prob_node:\n        sess:\n        multi:\n\n    Returns:\n        np.ndarray [size, size]\n    """"""\n\n    # \xe6\x97\x8b\xe8\xbd\xac\xe5\x87\xbd\xe6\x95\xb0\n    kwargs = {\n        \'input_placeholder\':input_placeholder,\n        \'is_training_placeholder\':is_training_placeholder,\n        \'logits_prob_node\':logits_prob_node,\n        \'sess\':sess,\n        \'prob\':True,\n    }\n    if multi:\n        image_predict_prob_list = [\n            predict(image=image, **kwargs)\n        ]\n        # \xe6\x97\x8b\xe8\xbd\xac\xe4\xb8\x89\xe4\xb8\xaa\n        angle_list = [90, 180, 270]\n        for angle in angle_list:\n            image_rotate = rotate(image, angle)\n\n            image_rotate_predict_prob = predict(image=image_rotate, **kwargs)\n            image_predict_prob = rotate(image_rotate_predict_prob, -1 * angle)\n            image_predict_prob_list.append(image_predict_prob)\n        # \xe7\xbf\xbb\xe8\xbd\xac\xe4\xb8\xa4\xe4\xb8\xaa\n        flip_list = [1, 0]\n        for mode in flip_list:\n            image_flip = cv2.flip(image, mode)\n\n            image_flip_predict_prob = predict(image=image_flip, **kwargs)\n            image_predict_prob = cv2.flip(image_flip_predict_prob, mode)\n            image_predict_prob_list.append(image_predict_prob)\n        # \xe6\xb1\x82\xe5\x92\x8c\xe5\xb9\xb3\xe5\x9d\x87\n        final_predict_prob = sum(image_predict_prob_list) / len(image_predict_prob_list)\n        return np.argmax(final_predict_prob, -1)\n    else:\n        kwargs[\'prob\'] = False\n        return predict(image, **kwargs)\n\n\ndef total_image_predict(ori_image_path: str,\n                        input_placeholder: tf.placeholder,\n                        is_training_placeholder: tf.placeholder,\n                        logits_prob_node: tf.Tensor,\n                        sess: tf.Session,\n                        multi_scale = False\n                        ) -> np.ndarray:\n\n    ori_image = cv2.imread(ori_image_path, cv2.CAP_MODE_RGB)\n\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\x87\xe5\x9b\xbe cut\n    h_step = ori_image.shape[0] // 256\n    w_step = ori_image.shape[1] // 256\n\n    h_rest = -(ori_image.shape[0] - 256 * h_step)\n    w_rest = -(ori_image.shape[1] - 256 * w_step)\n\n    image_list = []\n    predict_list = []\n    # \xe5\xbe\xaa\xe7\x8e\xaf\xe5\x88\x87\xe5\x9b\xbe\n    for h in range(h_step):\n        for w in range(w_step):\n            # \xe5\x88\x92\xe7\xaa\x97\xe9\x87\x87\xe6\xa0\xb7\n            image_sample = ori_image[(h * 256):(h * 256 + 256),\n                           (w * 256):(w * 256 + 256), :]\n            image_list.append(image_sample)\n        image_list.append(ori_image[(h * 256):(h * 256 + 256), -256:, :])\n    for w in range(w_step - 1):\n        image_list.append(ori_image[-256:, (w * 256):(w * 256 + 256), :])\n    image_list.append(ori_image[-256:, -256:, :])\n\n    # \xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x9b\xbe\xe5\x83\x8f\xe5\x9d\x97\xe9\xa2\x84\xe6\xb5\x8b\n    # predict\n    for image in image_list:\n\n        predict = multi_scale_predict(\n            image=image,\n            input_placeholder=input_placeholder,\n            is_training_placeholder=is_training_placeholder,\n            logits_prob_node=logits_prob_node,\n            sess=sess,\n            multi=multi_scale\n        )\n        # \xe4\xbf\x9d\xe5\xad\x98\xe8\xa6\x86\xe7\x9b\x96\xe5\xb0\x8f\xe5\x9b\xbe\xe7\x89\x87\n        predict_list.append(predict)\n\n    # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe5\x9d\x97\xe5\x86\x8d\xe6\x8b\xbc\xe6\x8e\xa5\xe8\xb5\xb7\xe6\x9d\xa5\n    count_temp = 0\n    tmp = np.ones([ori_image.shape[0], ori_image.shape[1]])\n    for h in range(h_step):\n        for w in range(w_step):\n            tmp[\n            h * 256:(h + 1) * 256,\n            w * 256:(w + 1) * 256\n            ] = predict_list[count_temp]\n            count_temp += 1\n        tmp[h * 256:(h + 1) * 256, w_rest:] = predict_list[count_temp][:, w_rest:]\n        count_temp += 1\n    for w in range(w_step - 1):\n        tmp[h_rest:, (w * 256):(w * 256 + 256)] = predict_list[count_temp][h_rest:, :]\n        count_temp += 1\n    tmp[h_rest:, w_rest:] = predict_list[count_temp][h_rest:, w_rest:]\n    return tmp\n\n\n\n\n\n'"
preprocess.py,0,"b""import cv2\nimport numpy as np\nimport random\n\n\nfrom tqdm import tqdm\nimport pandas as pd\nimport os\n\nsize = 256\n\n\n\n# \xe9\x9a\x8f\xe6\x9c\xba\xe7\xaa\x97\xe5\x8f\xa3\xe9\x87\x87\xe6\xa0\xb7\ndef generate_train_dataset(image_num = 99999,\n                           train_image_path='dataset/train/images/',\n                           train_label_path='dataset/train/labels/'):\n    '''\n    \xe8\xaf\xa5\xe5\x87\xbd\xe6\x95\xb0\xe7\x94\xa8\xe6\x9d\xa5\xe7\x94\x9f\xe6\x88\x90\xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xef\xbc\x8c\xe5\x88\x87\xe5\x9b\xbe\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xba\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\x87\xe5\x9b\xbe\xe9\x87\x87\xe6\xa0\xb7\n    :param image_num: \xe7\x94\x9f\xe6\x88\x90\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\n    :param train_image_path: \xe5\x88\x87\xe5\x9b\xbe\xe4\xbf\x9d\xe5\xad\x98\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\x9c\xb0\xe5\x9d\x80\n    :param train_label_path: \xe5\x88\x87\xe5\x9b\xbe\xe4\xbf\x9d\xe5\xad\x98\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\x9c\xb0\xe5\x9d\x80\n    :return:\n    '''\n\n    # \xe7\x94\xa8\xe6\x9d\xa5\xe8\xae\xb0\xe5\xbd\x95\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xad\x90\xe5\x9b\xbe\xe7\x9a\x84\xe6\x95\xb0\xe7\x9b\xae\n    g_count = 1\n\n    images_path = ['dataset/origin/1.png','dataset/origin/2.png',\n                   'dataset/origin/3.png','dataset/origin/4.png']\n    labels_path = ['dataset/origin/1_class.png','dataset/origin/2_class.png',\n                   'dataset/origin/3_class.png','dataset/origin/4_class.png']\n\n    # \xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe7\x94\x9f\xe6\x88\x90\xe5\xad\x90\xe5\x9b\xbe\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\n    image_each = image_num // len(images_path)\n    image_path, label_path = [], []\n    for i in tqdm(range(len(images_path))):\n        count = 0\n        image = cv2.imread(images_path[i])\n        label = cv2.imread(labels_path[i], cv2.CAP_MODE_GRAY)\n        X_height, X_width = image.shape[0], image.shape[1]\n        while count < image_each:\n            random_width = random.randint(0, X_width - size - 1)\n            random_height = random.randint(0, X_height - size - 1)\n            image_ogi = image[random_height: random_height + size, random_width: random_width + size,:]\n            label_ogi = label[random_height: random_height + size, random_width: random_width + size]\n\n            image_d, label_d = data_augment(image_ogi, label_ogi)\n\n            image_path.append(train_image_path+'%05d.png' % g_count)\n            label_path.append(train_label_path+'%05d.png' % g_count)\n            cv2.imwrite((train_image_path+'%05d.png' % g_count), image_d)\n            cv2.imwrite((train_label_path+'%05d.png' % g_count), label_d)\n\n            count += 1\n            g_count += 1\n    df = pd.DataFrame({'image':image_path, 'label':label_path})\n    df.to_csv('dataset/path_list.csv', index=False)\n\n# \xe4\xbb\xa5\xe4\xb8\x8b\xe5\x87\xbd\xe6\x95\xb0\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe4\xba\x9b\xe6\x95\xb0\xe6\x8d\xae\xe5\xa2\x9e\xe5\xbc\xba\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\ndef gamma_transform(img, gamma):\n    gamma_table = [np.power(x / 255.0, gamma) * 255.0 for x in range(size)]\n\n    gamma_table = np.round(np.array(gamma_table)).astype(np.uint8)\n\n    return cv2.LUT(img, gamma_table)\n\n\ndef random_gamma_transform(img, gamma_vari):\n    log_gamma_vari = np.log(gamma_vari)\n\n    alpha = np.random.uniform(-log_gamma_vari, log_gamma_vari)\n\n    gamma = np.exp(alpha)\n\n    return gamma_transform(img, gamma)\n\n\ndef rotate(xb, yb, angle):\n    M_rotate = cv2.getRotationMatrix2D((size /2, size / 2), angle, 1)\n\n    xb = cv2.warpAffine(xb, M_rotate, (size, size))\n\n    yb = cv2.warpAffine(yb, M_rotate, (size, size))\n\n    return xb, yb\n\n\ndef blur(img):\n    img = cv2.blur(img, (3, 3))\n\n    return img\n\n\ndef add_noise(img):\n    for i in range(size):  # \xe6\xb7\xbb\xe5\x8a\xa0\xe7\x82\xb9\xe5\x99\xaa\xe5\xa3\xb0\n\n        temp_x = np.random.randint(0, img.shape[0])\n\n        temp_y = np.random.randint(0, img.shape[1])\n\n        img[temp_x][temp_y] = 255\n\n    return img\n\n\ndef data_augment(xb, yb):\n    if np.random.random() < 0.25:\n        xb, yb = rotate(xb, yb, 90)\n\n    if np.random.random() < 0.25:\n        xb, yb = rotate(xb, yb, 180)\n\n    if np.random.random() < 0.25:\n        xb, yb = rotate(xb, yb, 270)\n\n    if np.random.random() < 0.25:\n        xb = cv2.flip(xb, 1)  # flipcode > 0\xef\xbc\x9a\xe6\xb2\xbfy\xe8\xbd\xb4\xe7\xbf\xbb\xe8\xbd\xac\n\n        yb = cv2.flip(yb, 1)\n\n    if np.random.random() < 0.25:\n        xb = random_gamma_transform(xb, 1.0)\n\n    if np.random.random() < 0.25:\n        xb = blur(xb)\n\n    # \xe5\x8f\x8c\xe8\xbe\xb9\xe8\xbf\x87\xe6\xbb\xa4\n    if np.random.random() < 0.25:\n        xb =cv2.bilateralFilter(xb,9,75,75)\n\n    #  \xe9\xab\x98\xe6\x96\xaf\xe6\xbb\xa4\xe6\xb3\xa2\n    if np.random.random() < 0.25:\n        xb = cv2.GaussianBlur(xb,(5,5),1.5)\n\n    if np.random.random() < 0.2:\n        xb = add_noise(xb)\n\n    return xb, yb\n\nif __name__ == '__main__':\n    if not os.path.exists('dataset/train/images'): os.mkdir('dataset/train/images')\n    if not os.path.exists('dataset/train/labels'): os.mkdir('dataset/train/labels')\n    generate_train_dataset()\n"""
train.py,31,"b'from deeplab_v3 import Deeplab_v3\nfrom data_utils import DataSet\n\n\nimport cv2\nimport os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom color_utils import color_predicts\nfrom predicts_utils import total_image_predict\n\nfrom metric_utils import iou\n\n\nclass args:\n    batch_size = 16\n    lr = 2e-4\n    test_display = 2000\n    weight_decay = 5e-4\n    model_name = \'baseline\'\n    batch_norm_decay = 0.95\n    test_image_path = \'dataset/origin/5.png\'\n    test_label_path = \'dataset/origin/5_class.png\'\n    multi_scale = True # \xe6\x98\xaf\xe5\x90\xa6\xe5\xa4\x9a\xe5\xb0\xba\xe5\xba\xa6\xe9\xa2\x84\xe6\xb5\x8b\n    gpu_num = 0\n    pretraining = False\n\n# \xe6\x89\x93\xe5\x8d\xb0\xe4\xbb\xa5\xe4\xb8\x8b\xe8\xb6\x85\xe5\x8f\x82\xe6\x95\xb0\nfor key in args.__dict__:\n    if key.find(\'__\') == -1:\n        offset = 20 - key.__len__()\n        print(key + \' \' * offset, args.__dict__[key])\n\n# \xe4\xbd\xbf\xe7\x94\xa8\xe9\x82\xa3\xe4\xb8\x80\xe5\x9d\x97\xe6\x98\xbe\xe5\x8d\xa1\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""%d"" % args.gpu_num\n\ndata_path_df = pd.read_csv(\'dataset/path_list.csv\')\ndata_path_df = data_path_df.sample(frac=1) # \xe7\xac\xac\xe4\xb8\x80\xe6\xac\xa1\xe6\x89\x93\xe4\xb9\xb1\n\ndataset = DataSet(image_path=data_path_df[\'image\'].values, label_path=data_path_df[\'label\'].values)\n\nmodel = Deeplab_v3(batch_norm_decay=args.batch_norm_decay)\n\nimage = tf.placeholder(tf.float32, [None, 256, 256, 3], name=\'input_x\')\nlabel = tf.placeholder(tf.int32, [None, 256, 256])\nlr = tf.placeholder(tf.float32, )\n\nlogits = model.forward_pass(image)\nlogits_prob = tf.nn.softmax(logits=logits, name=\'logits_prob\')\npredicts = tf.argmax(logits, axis=-1, name=\'predicts\')\n\nvariables_to_restore = tf.trainable_variables(scope=\'resnet_v2_50\')\n\n# finetune resnet_v2_50\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0(block1\xe5\x88\xb0block4)\nrestorer = tf.train.Saver(variables_to_restore)\n# cross_entropy\ncross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label))\n\n\n# \xe5\x8f\xaa\xe5\xb0\x86weight\xe5\x8a\xa0\xe5\x85\xa5\xe5\x88\xb0weight_decay\xe4\xb8\xad\n# https://arxiv.org/pdf/1807.11205.pdf\n# weight_for_weightdecay = []\n# for var in tf.trainable_variables():\n#     if var.name.__contains__(\'weight\'):\n#         weight_for_weightdecay.append(var)\n#         print(var.op.name)\n#     else:\n#         continue\n# l2_norm l2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\nwith tf.name_scope(\'weight_decay\'):\n    l2_loss = args.weight_decay * tf.add_n(\n         [tf.nn.l2_loss(tf.cast(v, tf.float32)) for v in tf.trainable_variables()])\n\n\noptimizer = tf.train.AdamOptimizer(learning_rate=lr)\nloss = cross_entropy + l2_loss\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n# \xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\ngrads = optimizer.compute_gradients(loss=loss, var_list=tf.trainable_variables())\n# for grad, var in grads:\n#     if grad is not None:\n#         tf.summary.histogram(name=\'%s_gradients\' % var.op.name, values=grad)\n#         tf.summary.histogram(name=\'%s\' % var.op.name, values=var)\n# \xe6\xa2\xaf\xe5\xba\xa6\xe8\xa3\x81\xe5\x89\xaa\n# gradients, variables = zip(*grads)\n# gradients, global_norm = tf.clip_by_global_norm(gradients, 5)\n\n#\xe6\x9b\xb4\xe6\x96\xb0\xe6\xa2\xaf\xe5\xba\xa6\napply_gradient_op = optimizer.apply_gradients(grads_and_vars=grads, global_step=tf.train.get_or_create_global_step())\nbatch_norm_updates_op = tf.group(*tf.get_collection(tf.GraphKeys.UPDATE_OPS))\ntrain_op = tf.group(apply_gradient_op, batch_norm_updates_op)\n\nsaver = tf.train.Saver(tf.all_variables())\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n# summary_op = tf.summary.merge_all()\n\nwith tf.Session(config=config) as sess:\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n    graph = tf.get_default_graph()\n\n    if args.pretraining:\n        # finetune resnet_v2_50\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\x8b\xe8\xbd\xbd\xe6\x9d\x83\xe9\x87\x8d\xe6\x96\x87\xe4\xbb\xb6\n        restorer.restore(sess, \'ckpts/resnet_v2_50/resnet_v2_50.ckpt\')\n\n    log_path = \'logs/%s/\' % args.model_name\n    model_path = \'ckpts/%s/\' % args.model_name\n    \n    if not os.path.exists(model_path): os.makedirs(model_path)\n    if not os.path.exists(\'./logs\'): os.makedirs(\'./logs\')\n    if not os.path.exists(log_path): os.makedirs(log_path)\n        \n\n    summary_writer = tf.summary.FileWriter(\'%s/\' % log_path, sess.graph)\n\n    learning_rate = args.lr\n    for step in range(1, 50001):\n        if step == 30000 or step == 40000:\n            learning_rate = learning_rate / 10\n        x_tr, y_tr = dataset.next_batch(args.batch_size)\n\n\n        loss_tr, l2_loss_tr, predicts_tr, _ = sess.run(\n            fetches=[cross_entropy, l2_loss, predicts, train_op],\n            feed_dict={\n                image: x_tr,\n                label: y_tr,\n                model._is_training: True,\n                lr: learning_rate})\n\n        # \xe5\x89\x8d50, 100, 200 \xe7\x9c\x8b\xe4\xb8\x80\xe4\xb8\x8b\xe6\x98\xaf\xe5\x90\xa6\xe6\x90\x9e\xe9\x94\x99\xe4\xba\x86\n        if (step in [50, 100, 200]) or (step > 0 and step % args.test_display == 0):\n\n            test_predict = total_image_predict(\n                ori_image_path=args.test_image_path,\n                input_placeholder=image,\n                logits_prob_node=logits_prob,\n                is_training_placeholder=model._is_training,\n                sess=sess,\n                multi_scale=args.multi_scale\n            )\n\n            test_label = cv2.imread(args.test_label_path, cv2.IMREAD_GRAYSCALE)\n\n            # \xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe7\x89\x87\n            cv2.imwrite(filename=\'%spredict_color_%d.png\' % (log_path, step),\n                        img=color_predicts(img=test_predict))\n\n            result = iou(y_pre=np.reshape(test_predict, -1),\n                         y_true=np.reshape(test_label, -1))\n\n            print(""======================%d======================"" % step)\n            for key in result.keys():\n                offset = 40 - key.__len__()\n                print(key + \' \' * offset + \'%.4f\' % result[key])\n\n\n            test_summary = tf.Summary(\n                value=[tf.Summary.Value(tag=key, simple_value=result[key]) for key in result.keys()]\n            )\n\n\n            # \xe8\xae\xb0\xe5\xbd\x95summary\n            summary_writer.add_summary(test_summary, step)\n            summary_writer.flush()\n'"
