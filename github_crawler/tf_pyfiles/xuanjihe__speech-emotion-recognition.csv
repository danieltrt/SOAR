file_path,api_count,code
ExtractMel.py,0,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Jan  9 20:32:28 2018\n\n@author: hxj\n""""""\n\nimport wave\nimport numpy as np\nimport python_speech_features as ps\nimport os\nimport glob\nimport cPickle\n#import base\n#import sigproc\neps = 1e-5\ndef wgn(x, snr):\n    snr = 10**(snr/10.0)\n    xpower = np.sum(x**2)/len(x)\n    npower = xpower / snr\n    return np.random.randn(len(x)) * np.sqrt(npower)\ndef getlogspec(signal,samplerate=16000,winlen=0.02,winstep=0.01,\n               nfilt=26,nfft=399,lowfreq=0,highfreq=None,preemph=0.97,\n               winfunc=lambda x:np.ones((x,))):\n    highfreq= highfreq or samplerate/2\n    signal = ps.sigproc.preemphasis(signal,preemph)\n    frames = ps.sigproc.framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n    pspec = ps.sigproc.logpowspec(frames,nfft)\n    return pspec \ndef read_file(filename):\n    file = wave.open(filename,\'r\')    \n    params = file.getparams()\n    nchannels, sampwidth, framerate, wav_length = params[:4]\n    str_data = file.readframes(wav_length)\n    wavedata = np.fromstring(str_data, dtype = np.short)\n    #wavedata = np.float(wavedata*1.0/max(abs(wavedata)))  # normalization)\n    time = np.arange(0,wav_length) * (1.0/framerate)\n    file.close()\n    return wavedata, time, framerate\ndef dense_to_one_hot(labels_dense, num_classes):\n  """"""Convert class labels from scalars to one-hot vectors.""""""\n  num_labels = labels_dense.shape[0]\n  index_offset = np.arange(num_labels) * num_classes\n  labels_one_hot = np.zeros((num_labels, num_classes))\n  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n  return labels_one_hot\n\ndef zscore(data,mean,std):\n    shape = np.array(data.shape,dtype = np.int32)\n    for i in range(shape[0]):\n        data[i,:,:,0] = (data[i,:,:,0]-mean)/(std)\n    return data\n\ndef normalization(data):\n    \'\'\'\n    #apply zscore\n    mean = np.mean(data,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n    std = np.std(data,axis=0)\n    train_data = zscore(train_data,mean,std)\n    test_data = zscore(test_data,mean,std)\n    \'\'\'\n    mean = np.mean(data,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n    std = np.std(data,axis=0)\n    data = (data-mean)/std\n    return data\ndef mapminmax(data):\n    shape = np.array(data.shape,dtype = np.int32)\n    for i in range(shape[0]):\n        min = np.min(data[i,:,:,0])\n        max = np.max(data[i,:,:,0])\n        data[i,:,:,0] = (data[i,:,:,0] - min)/((max - min)+eps)\n    return data\ndef generate_label(emotion,classnum):\n    label = -1\n    if(emotion == \'ang\'):\n        label = 0\n    elif(emotion == \'sad\'):\n        label = 1\n    elif(emotion == \'hap\'):\n        label = 2\n    elif(emotion == \'neu\'):\n        label = 3\n    elif(emotion == \'fear\'):\n        label = 4\n    else:\n        label = 5\n    return label\ndef load_data():\n    f = open(\'./zscore40.pkl\',\'rb\')\n    mean1,std1,mean2,std2,mean3,std3 = cPickle.load(f)\n    return mean1,std1,mean2,std2,mean3,std3\n        \n        \ndef read_IEMOCAP():\n    eps = 1e-5\n    tnum = 259 #the number of test utterance\n    vnum = 298\n    test_num = 420#the number of test 2s segments\n    valid_num = 436\n    train_num = 2928\n    filter_num = 40\n    pernums_test = np.arange(tnum)#remerber each utterance contain how many segments\n    pernums_valid = np.arange(vnum)\n    rootdir = \'/home/jamhan/hxj/datasets/IEMOCAP_full_release\'\n    \n    mean1,std1,mean2,std2,mean3,std3 = load_data()\n    \n    #2774\n    hapnum = 434#2\n    angnum = 433#0\n    neunum = 1262#3\n    sadnum = 799#1\n    pernum = 300#np.min([hapnum,angnum,sadnum,neunum])\n    #valid_num = divmod((train_num),10)[0]\n    train_label = np.empty((train_num,1), dtype = np.int8)\n    test_label = np.empty((tnum,1), dtype = np.int8)\n    valid_label = np.empty((vnum,1), dtype = np.int8)\n    Test_label = np.empty((test_num,1), dtype = np.int8)\n    Valid_label = np.empty((valid_num,1), dtype = np.int8)\n    train_data = np.empty((train_num,300,filter_num,3),dtype = np.float32)\n    test_data = np.empty((test_num,300,filter_num,3),dtype = np.float32)\n    valid_data = np.empty((valid_num,300,filter_num,3),dtype = np.float32)\n    \n    tnum = 0\n    vnum = 0\n    train_num = 0\n    test_num = 0\n    valid_num = 0\n    train_emt = {\'hap\':0,\'ang\':0,\'neu\':0,\'sad\':0 }\n    test_emt = {\'hap\':0,\'ang\':0,\'neu\':0,\'sad\':0 }\n    valid_emt = {\'hap\':0,\'ang\':0,\'neu\':0,\'sad\':0 }\n    for speaker in os.listdir(rootdir):\n        if(speaker[0] == \'S\'):\n            sub_dir = os.path.join(rootdir,speaker,\'sentences/wav\')\n            emoevl = os.path.join(rootdir,speaker,\'dialog/EmoEvaluation\')\n            for sess in os.listdir(sub_dir):\n                if(sess[7] == \'i\'):\n                    emotdir = emoevl+\'/\'+sess+\'.txt\'\n                    #emotfile = open(emotdir)\n                    emot_map = {}\n                    with open(emotdir,\'r\') as emot_to_read:\n                        while True:\n                            line = emot_to_read.readline()\n                            if not line:\n                                break\n                            if(line[0] == \'[\'):\n                                t = line.split()\n                                emot_map[t[3]] = t[4]\n                                \n        \n                    file_dir = os.path.join(sub_dir, sess, \'*.wav\')\n                    files = glob.glob(file_dir)\n                    for filename in files:\n                        #wavname = filename[-23:-4]\n                        wavname = filename.split(""/"")[-1][:-4]\n                        emotion = emot_map[wavname]\n                        if(emotion in [\'hap\',\'ang\',\'neu\',\'sad\']):\n                             data, time, rate = read_file(filename)\n                             mel_spec = ps.logfbank(data,rate,nfilt = filter_num)\n                             delta1 = ps.delta(mel_spec, 2)\n                             delta2 = ps.delta(delta1, 2)\n                             #apply zscore\n                             \n                             time = mel_spec.shape[0] \n                             if(speaker in [\'Session1\',\'Session2\',\'Session3\',\'Session4\']):\n                                 #training set\n                                 if(time <= 300):\n                                      part = mel_spec\n                                      delta11 = delta1\n                                      delta21 = delta2\n                                      part = np.pad(part,((0,300 - part.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      delta11 = np.pad(delta11,((0,300 - delta11.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      delta21 = np.pad(delta21,((0,300 - delta21.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      train_data[train_num,:,:,0] = (part -mean1)/(std1+eps)\n                                      train_data[train_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                      train_data[train_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n\n                                      em = generate_label(emotion,6)\n                                      train_label[train_num] = em\n                                      train_emt[emotion] = train_emt[emotion] + 1\n                                      train_num = train_num + 1\n                                 else:\n                                      \n                                     if(emotion in [\'ang\',\'neu\',\'sad\']):\n                                         \n                                         for i in range(2):\n                                             if(i == 0):\n                                                 begin = 0\n                                                 end = begin + 300\n                                             else:\n                                                 begin = time - 300\n                                                 end = time\n                                          \n                                             part = mel_spec[begin:end,:]\n                                             delta11 = delta1[begin:end,:]\n                                             delta21 = delta2[begin:end,:]\n                                             train_data[train_num,:,:,0] = (part -mean1)/(std1+eps)\n                                             train_data[train_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                             train_data[train_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n\n                                             em = generate_label(emotion,6)\n                                             train_label[train_num] = em\n                                             train_emt[emotion] = train_emt[emotion] + 1\n                                             train_num = train_num + 1\n                                     else:\n                                        frames = divmod(time-300,100)[0] + 1\n                                        for i in range(frames):\n                                            begin = 100*i\n                                            end = begin + 300\n                                            part = mel_spec[begin:end,:]\n                                            delta11 = delta1[begin:end,:]\n                                            delta21 = delta2[begin:end,:]\n                                            train_data[train_num,:,:,0] = (part -mean1)/(std1+eps)\n                                            train_data[train_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                            train_data[train_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n                                            em = generate_label(emotion,6)\n                                            train_label[train_num] = em\n                                            train_emt[emotion] = train_emt[emotion] + 1\n                                            train_num = train_num + 1\n                                          \n                             else:\n                                 em = generate_label(emotion,6)\n                                 if(wavname[-4] == \'M\'):\n                                     #test_set\n                                     test_label[tnum] = em\n                                     if(time <= 300):\n                                         pernums_test[tnum] = 1\n                                         part = mel_spec\n                                         delta11 = delta1\n                                         delta21 = delta2\n                                         part = np.pad(part,((0,300 - part.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         delta11 = np.pad(delta11,((0,300 - delta11.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         delta21 = np.pad(delta21,((0,300 - delta21.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         test_data[test_num,:,:,0] = (part -mean1)/(std1+eps)\n                                         test_data[test_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                         test_data[test_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n                                         test_emt[emotion] = test_emt[emotion] + 1\n                                         Test_label[test_num] = em\n                                         test_num = test_num + 1\n                                         tnum = tnum + 1\n                                     else:\n                                         pernums_test[tnum] = 2\n                                         tnum = tnum + 1\n                                         for i in range(2):\n                                             if(i == 0):\n                                                 begin = 0\n                                                 end = begin + 300\n                                             else:\n                                                 end = time\n                                                 begin = time - 300\n                                             part = mel_spec[begin:end,:]\n                                             delta11 = delta1[begin:end,:]\n                                             delta21 = delta2[begin:end,:]\n                                             test_data[test_num,:,:,0] = (part -mean1)/(std1+eps)\n                                             test_data[test_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                             test_data[test_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n\n                                             test_emt[emotion] = test_emt[emotion] + 1\n                                             Test_label[test_num] = em\n                                             test_num = test_num + 1\n                                     \n                                 else:\n                                     #valid_set\n                                     em = generate_label(emotion,6)\n                                     valid_label[vnum] = em\n                                     if(time <= 300):\n                                         pernums_valid[vnum] = 1\n                                         part = mel_spec\n                                         delta11 = delta1\n                                         delta21 = delta2\n                                         part = np.pad(part,((0,300 - part.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         delta11 = np.pad(delta11,((0,300 - delta11.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         delta21 = np.pad(delta21,((0,300 - delta21.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                         valid_data[valid_num,:,:,0] = (part -mean1)/(std1+eps)\n                                         valid_data[valid_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                         valid_data[valid_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n                                         valid_emt[emotion] = valid_emt[emotion] + 1\n                                         Valid_label[valid_num] = em\n                                         valid_num = valid_num + 1\n                                         vnum = vnum + 1\n                                     else:\n                                         pernums_valid[vnum] = 2\n                                         vnum = vnum + 1\n                                         for i in range(2):\n                                             if(i == 0):\n                                                 begin = 0\n                                                 end = begin + 300\n                                             else:\n                                                 end = time\n                                                 begin = time - 300\n                                             part = mel_spec[begin:end,:]\n                                             delta11 = delta1[begin:end,:]\n                                             delta21 = delta2[begin:end,:]\n                                             valid_data[valid_num,:,:,0] = (part -mean1)/(std1+eps)\n                                             valid_data[valid_num,:,:,1] = (delta11 - mean2)/(std2+eps)\n                                             valid_data[valid_num,:,:,2] = (delta21 - mean3)/(std3+eps)\n                                             valid_emt[emotion] = valid_emt[emotion] + 1\n                                             Valid_label[valid_num] = em\n                                             valid_num = valid_num + 1\n                                     \n                                    \n                                 \n                        else:\n                            pass\n    \n    \n    \n    hap_index = np.arange(hapnum)\n    neu_index = np.arange(neunum)\n    sad_index = np.arange(sadnum)\n    ang_index = np.arange(angnum)\n    h2 = 0\n    a0 = 0\n    n3 = 0\n    s1 = 0\n    for l in range(train_num):\n        if(train_label[l] == 0):\n            ang_index[a0] = l\n            a0 = a0 + 1\n        elif (train_label[l] == 1):\n            sad_index[s1] = l\n            s1 = s1 + 1\n        elif (train_label[l] == 2):\n            hap_index[h2] = l\n            h2 = h2 + 1\n        else:\n            neu_index[n3] = l\n            n3 = n3 + 1\n    for m in range(1):\n        np.random.shuffle(neu_index)\n        np.random.shuffle(hap_index)\n        np.random.shuffle(sad_index)\n        np.random.shuffle(ang_index)\n        #define emotional array\n        hap_label = np.empty((pernum,1), dtype = np.int8)\n        ang_label = np.empty((pernum,1), dtype = np.int8)\n        sad_label = np.empty((pernum,1), dtype = np.int8)\n        neu_label = np.empty((pernum,1), dtype = np.int8)\n        hap_data = np.empty((pernum,300,filter_num,3),dtype = np.float32)\n        neu_data = np.empty((pernum,300,filter_num,3),dtype = np.float32)\n        sad_data = np.empty((pernum,300,filter_num,3),dtype = np.float32)\n        ang_data = np.empty((pernum,300,filter_num,3),dtype = np.float32)    \n    \n        hap_data = train_data[hap_index[0:pernum]].copy()\n        hap_label = train_label[hap_index[0:pernum]].copy()\n        ang_data = train_data[ang_index[0:pernum]].copy()\n        ang_label = train_label[ang_index[0:pernum]].copy()\n        sad_data = train_data[sad_index[0:pernum]].copy()\n        sad_label = train_label[sad_index[0:pernum]].copy()\n        neu_data = train_data[neu_index[0:pernum]].copy()\n        neu_label = train_label[neu_index[0:pernum]].copy()\n        train_num = 4*pernum\n    \n        Train_label = np.empty((train_num,1), dtype = np.int8)\n        Train_data = np.empty((train_num,300,filter_num,3),dtype = np.float32)\n        Train_data[0:pernum] = hap_data\n        Train_label[0:pernum] = hap_label\n        Train_data[pernum:2*pernum] = sad_data\n        Train_label[pernum:2*pernum] = sad_label  \n        Train_data[2*pernum:3*pernum] = neu_data\n        Train_label[2*pernum:3*pernum] = neu_label \n        Train_data[3*pernum:4*pernum] = ang_data\n        Train_label[3*pernum:4*pernum] = ang_label \n    \n        arr = np.arange(train_num)\n        np.random.shuffle(arr)\n        Train_data = Train_data[arr[0:]]\n        Train_label = Train_label[arr[0:]]\n        print train_label.shape\n        print train_emt\n        print test_emt\n        print valid_emt\n        #print test_label[0:500,:]\n        #f=open(\'./CASIA_40_delta.pkl\',\'wb\') \n        #output = \'./IEMOCAP40.pkl\'\n        output = \'./IEMOCAP.pkl\'\n        f=open(output,\'wb\') \n        cPickle.dump((Train_data,Train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid),f)\n        f.close()           \n    return\n                \n        \n\n\nif __name__==\'__main__\':\n    read_IEMOCAP()\n    #print ""test_num:"", test_num\n    #print ""train_num:"", train_num\n#    n = wgn(x, 6)\n#    xn = x+n # \xe5\xa2\x9e\xe5\x8a\xa0\xe4\xba\x866dBz\xe4\xbf\xa1\xe5\x99\xaa\xe6\xaf\x94\xe5\x99\xaa\xe5\xa3\xb0\xe7\x9a\x84\xe4\xbf\xa1\xe5\x8f\xb7\n'"
acrnn1.py,78,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Jul 19 14:54:52 2018\n\n@author: hexuanji\n""""""\n\n\n\nimport tensorflow as tf\nfrom attention import attention\n\nepsilon = 1e-3\ndef leaky_relu(x, leakiness=0.0):\n    return tf.where(tf.less(x, 0.0), leakiness * x, x, name=\'leaky_relu\')\n\ndef batch_norm_wrapper(inputs, is_training, decay = 0.999):\n\n    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n    pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n    pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n\n    if is_training is not None:\n        batch_mean, batch_var = tf.nn.moments(inputs,[0])\n        train_mean = tf.assign(pop_mean,\n                               pop_mean * decay + batch_mean * (1 - decay))\n        train_var = tf.assign(pop_var,\n                              pop_var * decay + batch_var * (1 - decay))\n        with tf.control_dependencies([train_mean, train_var]):\n            return tf.nn.batch_normalization(inputs,\n                batch_mean, batch_var, beta, scale, epsilon)\n    else:\n        return tf.nn.batch_normalization(inputs,\n            pop_mean, pop_var, beta, scale, epsilon)\n\ndef acrnn(inputs, num_classes=4,\n                  is_training=True,\n                  L1=128,\n                  L2=256,\n                  cell_units=128,\n                  num_linear=768,\n                  p=10,\n                  time_step=150,\n                  F1=64,\n                  dropout_keep_prob=1):\n    layer1_filter = tf.get_variable(\'layer1_filter\', shape=[5, 3, 3, L1], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer1_bias = tf.get_variable(\'layer1_bias\', shape=[L1], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer1_stride = [1, 1, 1, 1]\n    layer2_filter = tf.get_variable(\'layer2_filter\', shape=[5, 3, L1, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer2_bias = tf.get_variable(\'layer2_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer2_stride = [1, 1, 1, 1]\n    layer3_filter = tf.get_variable(\'layer3_filter\', shape=[5, 3, L2, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer3_bias = tf.get_variable(\'layer3_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer3_stride = [1, 1, 1, 1]\n    layer4_filter = tf.get_variable(\'layer4_filter\', shape=[5, 3, L2, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer4_bias = tf.get_variable(\'layer4_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer4_stride = [1, 1, 1, 1]\n    layer5_filter = tf.get_variable(\'layer5_filter\', shape=[5, 3, L2, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer5_bias = tf.get_variable(\'layer5_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer5_stride = [1, 1, 1, 1]\n    layer6_filter = tf.get_variable(\'layer6_filter\', shape=[5, 3, L2, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer6_bias = tf.get_variable(\'layer6_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer6_stride = [1, 1, 1, 1]\n    \n    linear1_weight = tf.get_variable(\'linear1_weight\', shape=[p*L2,num_linear], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    linear1_bias = tf.get_variable(\'linear1_bias\', shape=[num_linear], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n \n    fully1_weight = tf.get_variable(\'fully1_weight\', shape=[2*cell_units,F1], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    fully1_bias = tf.get_variable(\'fully1_bias\', shape=[F1], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    fully2_weight = tf.get_variable(\'fully2_weight\', shape=[F1,num_classes], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    fully2_bias = tf.get_variable(\'fully2_bias\', shape=[num_classes], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    \n    layer1 = tf.nn.conv2d(inputs, layer1_filter, layer1_stride, padding=\'SAME\')\n    layer1 = tf.nn.bias_add(layer1,layer1_bias)\n    layer1 = leaky_relu(layer1, 0.01)\n    layer1 = tf.nn.max_pool(layer1,ksize=[1, 2, 4, 1], strides=[1, 2, 4, 1], padding=\'VALID\', name=\'max_pool\')\n    layer1 = tf.contrib.layers.dropout(layer1, keep_prob=dropout_keep_prob, is_training=is_training)\n    \n    layer2 = tf.nn.conv2d(layer1, layer2_filter, layer2_stride, padding=\'SAME\')\n    layer2 = tf.nn.bias_add(layer2,layer2_bias)\n    layer2 = leaky_relu(layer2, 0.01)\n    layer2 = tf.contrib.layers.dropout(layer2, keep_prob=dropout_keep_prob, is_training=is_training)\n    \n    layer3 = tf.nn.conv2d(layer2, layer3_filter, layer3_stride, padding=\'SAME\')\n    layer3 = tf.nn.bias_add(layer3,layer3_bias)\n    layer3 = leaky_relu(layer3, 0.01)\n    layer3 = tf.contrib.layers.dropout(layer3, keep_prob=dropout_keep_prob, is_training=is_training)\n    \n    layer4 = tf.nn.conv2d(layer3, layer4_filter, layer4_stride, padding=\'SAME\')\n    layer4 = tf.nn.bias_add(layer4,layer4_bias)\n    layer4 = leaky_relu(layer4, 0.01)\n    layer4 = tf.contrib.layers.dropout(layer4, keep_prob=dropout_keep_prob, is_training=is_training)\n    \n    layer5 = tf.nn.conv2d(layer4, layer5_filter, layer5_stride, padding=\'SAME\')\n    layer5 = tf.nn.bias_add(layer5,layer5_bias)\n    layer5 = leaky_relu(layer5, 0.01)    \n    layer5 = tf.contrib.layers.dropout(layer5, keep_prob=dropout_keep_prob, is_training=is_training)\n\n    layer6 = tf.nn.conv2d(layer5, layer6_filter, layer6_stride, padding=\'SAME\')\n    layer6 = tf.nn.bias_add(layer6,layer6_bias)\n    layer6 = leaky_relu(layer6, 0.01)    \n    layer6 = tf.contrib.layers.dropout(layer6, keep_prob=dropout_keep_prob, is_training=is_training)\n    \n    layer6 = tf.reshape(layer6,[-1,time_step,L2*p])\n    layer6 = tf.reshape(layer6, [-1,p*L2])\n    \n    linear1 = tf.matmul(layer6,linear1_weight) + linear1_bias\n    linear1 = batch_norm_wrapper(linear1,is_training)\n    linear1 = leaky_relu(linear1, 0.01)\n    #linear1 = batch_norm_wrapper(linear1,is_training)\n    linear1 = tf.reshape(linear1, [-1, time_step, num_linear])\n    \n    \n    \n    # Define lstm cells with tensorflow\n    # Forward direction cell\n    gru_fw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units, forget_bias=1.0)\n    # Backward direction cell\n    gru_bw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units, forget_bias=1.0)\n    \n    # Now we feed `layer_3` into the LSTM BRNN cell and obtain the LSTM BRNN output.\n    outputs1, output_states1 = tf.nn.bidirectional_dynamic_rnn(cell_fw=gru_fw_cell1,\n                                                             cell_bw=gru_bw_cell1,\n                                                             inputs= linear1,\n                                                             dtype=tf.float32,\n                                                             time_major=False,\n                                                             scope=\'LSTM1\')\n\n    # Attention layer\n    gru, alphas = attention(outputs1, 1, return_alphas=True)\n    \n    \n    fully1 = tf.matmul(gru,fully1_weight) + fully1_bias\n    fully1 = leaky_relu(fully1, 0.01)\n    fully1 = tf.nn.dropout(fully1, dropout_keep_prob)\n    \n    \n    Ylogits = tf.matmul(fully1, fully2_weight) + fully2_bias\n    #Ylogits = tf.nn.softmax(Ylogits)\n    return Ylogits\n'"
attention.py,10,"b'import tensorflow as tf\n\n\ndef attention(inputs, attention_size, time_major=False, return_alphas=False):\n    """"""\n    Attention mechanism layer which reduces RNN/Bi-RNN outputs with Attention vector.\n\n    The idea was proposed in the article by Z. Yang et al., ""Hierarchical Attention Networks\n     for Document Classification"", 2016: http://www.aclweb.org/anthology/N16-1174.\n    Variables notation is also inherited from the article\n    \n    Args:\n        inputs: The Attention inputs.\n            Matches outputs of RNN/Bi-RNN layer (not final state):\n                In case of RNN, this must be RNN outputs `Tensor`:\n                    If time_major == False (default), this must be a tensor of shape:\n                        `[batch_size, max_time, cell.output_size]`.\n                    If time_major == True, this must be a tensor of shape:\n                        `[max_time, batch_size, cell.output_size]`.\n                In case of Bidirectional RNN, this must be a tuple (outputs_fw, outputs_bw) containing the forward and\n                the backward RNN outputs `Tensor`.\n                    If time_major == False (default),\n                        outputs_fw is a `Tensor` shaped:\n                        `[batch_size, max_time, cell_fw.output_size]`\n                        and outputs_bw is a `Tensor` shaped:\n                        `[batch_size, max_time, cell_bw.output_size]`.\n                    If time_major == True,\n                        outputs_fw is a `Tensor` shaped:\n                        `[max_time, batch_size, cell_fw.output_size]`\n                        and outputs_bw is a `Tensor` shaped:\n                        `[max_time, batch_size, cell_bw.output_size]`.\n        attention_size: Linear size of the Attention weights.\n        time_major: The shape format of the `inputs` Tensors.\n            If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n            If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n            Using `time_major = True` is a bit more efficient because it avoids\n            transposes at the beginning and end of the RNN calculation.  However,\n            most TensorFlow data is batch-major, so by default this function\n            accepts input and emits output in batch-major form.\n        return_alphas: Whether to return attention coefficients variable along with layer\'s output.\n            Used for visualization purpose.\n    Returns:\n        The Attention output `Tensor`.\n        In case of RNN, this will be a `Tensor` shaped:\n            `[batch_size, cell.output_size]`.\n        In case of Bidirectional RNN, this will be a `Tensor` shaped:\n            `[batch_size, cell_fw.output_size + cell_bw.output_size]`.\n    """"""\n\n    if isinstance(inputs, tuple):\n        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs.\n        inputs = tf.concat(inputs, 2)\n\n    if time_major:\n        # (T,B,D) => (B,T,D)\n        inputs = tf.array_ops.transpose(inputs, [1, 0, 2])\n\n    hidden_size = inputs.shape[2].value  # D value - hidden size of the RNN layer\n\n    # Trainable parameters\n    W_omega = tf.Variable(tf.random_normal([hidden_size, attention_size], stddev=0.1))\n    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n\n    # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n    #  the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n    #v = tf.tanh(tf.tensordot(inputs, W_omega, axes=1) + b_omega)\n    v = tf.sigmoid(tf.tensordot(inputs, W_omega, axes=1) + b_omega)\n    # For each of the timestamps its vector of size A from `v` is reduced with `u` vector\n    vu = tf.tensordot(v, u_omega, axes=1)   # (B,T) shape\n    alphas = tf.nn.softmax(vu)              # (B,T) shape also\n\n    # Output of (Bi-)RNN is reduced with attention vector; the result has (B,D) shape\n    output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)\n\n    if not return_alphas:\n        return output\n    else:\n        return output, alphas\n'"
crnn.py,118,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Jan 31 16:56:02 2018\n\n@author: hxj\n""""""\n\nimport tensorflow as tf\nfrom tensorflow.python.training import moving_averages\n# Importer and Exporting\n# ========\n\ntf.app.flags.DEFINE_string  (\'data_path\',  \'./IEMOCAP1.pkl\',   \'total dataset includes training set, valid set and test set\')\ntf.app.flags.DEFINE_string  (\'checkpoint\', \'./checkpoint/\',   \'the checkpoint dir\')\ntf.app.flags.DEFINE_string  (\'model_name\', \'model.ckpt\',      \'model name\')\ntf.app.flags.DEFINE_string  (\'pred_name\',  \'./pred0.pkl\',        \'the test output dir\')\ntf.app.flags.DEFINE_integer (\'checkpoint_secs\',  60,         \'checkpoint saving interval in seconds\')\n\n# Global Constants\n# ================\n\ntf.app.flags.DEFINE_float   (\'dropout_conv\',     1,        \'dropout rate for covvolutional layers\')\ntf.app.flags.DEFINE_float   (\'dropout_linear\',   1,        \'dropout rate for linear layer\')\ntf.app.flags.DEFINE_float   (\'dropout_lstm\',     1,        \'dropout rate for lstm\')\ntf.app.flags.DEFINE_float   (\'dropout_fully1\',   1,        \'dropout rate for fully connected layer1\')\ntf.app.flags.DEFINE_float   (\'dropout_fully2\',   1,        \'dropout rate for fully connected layer1\')\n\n#decayed_learning rate\ntf.app.flags.DEFINE_float(\'decay_rate\', 0.99, \'the lr decay rate\')\ntf.app.flags.DEFINE_float(\'beta1\', 0.9, \'parameter of adam optimizer beta1\')\ntf.app.flags.DEFINE_float(\'beta2\', 0.999, \'adam parameter beta2\')\n\n#Moving Average\ntf.app.flags.DEFINE_integer(\'decay_steps\', 570, \'the lr decay_step for optimizer\')\ntf.app.flags.DEFINE_float(\'momentum\', 0.99, \'the momentum\')\ntf.app.flags.DEFINE_integer(\'num_epochs\', 30000, \'maximum epochs\')\ntf.app.flags.DEFINE_float   (\'relu_clip\',        20.0,        \'ReLU clipping value for non-recurrant layers\')\n\n# Adam optimizer (http://arxiv.org/abs/1412.6980) parameters\n\ntf.app.flags.DEFINE_float   (\'adam_beta1\',            0.9,         \'beta 1 parameter of Adam optimizer\')\ntf.app.flags.DEFINE_float   (\'adam_beta2\',            0.999,       \'beta 2 parameter of Adam optimizer\')\ntf.app.flags.DEFINE_float   (\'epsilon\',          1e-8,        \'epsilon parameter of Adam optimizer\')\ntf.app.flags.DEFINE_float   (\'learning_rate\',    0.0001,       \'learning rate of Adam optimizer\')\n\n# Batch sizes\n\ntf.app.flags.DEFINE_integer (\'train_batch_size\', 40,           \'number of elements in a training batch\')\ntf.app.flags.DEFINE_integer (\'valid_batch_size\',   40,           \'number of elements in a validation batch\')\ntf.app.flags.DEFINE_integer (\'test_batch_size\',  40,           \'number of elements in a test batch\')\n\ntf.app.flags.DEFINE_integer(\'save_steps\', 10, \'the step to save checkpoint\')\n\ntf.app.flags.DEFINE_integer(\'image_height\', 300, \'image height\')\ntf.app.flags.DEFINE_integer(\'image_width\', 40, \'image width\')\ntf.app.flags.DEFINE_integer(\'image_channel\', 3, \'image channels as input\')\ntf.app.flags.DEFINE_integer(\'linear_num\', 786, \'hidden number of linear layer\')\ntf.app.flags.DEFINE_integer(\'seq_len\', 150, \'sequence length of lstm\')\ntf.app.flags.DEFINE_integer(\'cell_num\', 128, \'cell units of the lstm\')\ntf.app.flags.DEFINE_integer(\'hidden1\', 64, \'number of hidden units of fully connected layer\')\ntf.app.flags.DEFINE_integer(\'hidden2\', 4, \'number of softmax layer\')\ntf.app.flags.DEFINE_integer(\'attention_size\', 1, \'attention_size\')\ntf.app.flags.DEFINE_boolean(\'attention\', False, \'whether to use attention, False mean use max-pooling\')\n\nFLAGS = tf.app.flags.FLAGS\n\n\nclass CRNN(object):\n    def __init__(self, mode):\n        self.mode = mode\n        # log Mel-spectrogram\n        self.attention = FLAGS.attention\n        self.inputs = tf.placeholder(tf.float32, [None, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channel])\n        # emotion label\n        self.labels = tf.placeholder(tf.int32, shape=[None, 4])\n        # lstm time step\n        #self.seq_len = tf.placeholder(tf.int32, [None])\n        # l2\n        self._extra_train_ops = []\n    def _conv2d(self, x, name, filter_size, in_channels, out_channels, strides):\n        with tf.variable_scope(name):\n            kernel = tf.get_variable(name=\'DW\',\n                                     shape=[filter_size[0], filter_size[1], in_channels, out_channels],\n                                     dtype=tf.float32,\n                                     initializer=tf.contrib.layers.xavier_initializer())\n\n            b = tf.get_variable(name=\'bais\',\n                                shape=[out_channels],\n                                dtype=tf.float32,\n                                initializer=tf.constant_initializer())\n\n            con2d_op = tf.nn.conv2d(x, kernel, [1, strides[0], strides[1], 1], padding=\'SAME\')\n\n        return tf.nn.bias_add(con2d_op, b) \n    def _max_pool(self, x, ksize, strides):\n        return tf.nn.max_pool(x,\n                              ksize=[1, ksize[0], ksize[1], 1],\n                              strides=[1, strides[0], strides[1], 1],\n                              padding=\'VALID\',\n                              name=\'max_pool\')\n    def _linear(self,x,names,shapes):\n        with tf.variable_scope(names):\n            weights = tf.get_variable(name=\'weights\',\n                                      shape=shapes,\n                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n            bias = tf.get_variable(name=\'bias\',\n                                   shape=shapes[1],\n                                   initializer=tf.constant_initializer(0.0))\n        return tf.matmul(x,weights) + bias\n    def _leaky_relu(self, x, leakiness=0.0):\n        return tf.where(tf.less(x, 0.0), leakiness * x, x, name=\'leaky_relu\')\n    def _batch_norm(self, name, x):\n        """"""Batch normalization.""""""\n        with tf.variable_scope(name):\n            params_shape = [x.get_shape()[-1]]\n\n            beta = tf.get_variable(\n                \'beta\', params_shape, tf.float32,\n                initializer=tf.constant_initializer(0.0, tf.float32))\n            gamma = tf.get_variable(\n                \'gamma\', params_shape, tf.float32,\n                initializer=tf.constant_initializer(1.0, tf.float32))\n\n            if self.mode == \'train\':\n                mean, variance = tf.nn.moments(x, [0, 1, 2], name=\'moments\')\n\n                moving_mean = tf.get_variable(\n                    \'moving_mean\', params_shape, tf.float32,\n                    initializer=tf.constant_initializer(0.0, tf.float32),\n                    trainable=False)\n                moving_variance = tf.get_variable(\n                    \'moving_variance\', params_shape, tf.float32,\n                    initializer=tf.constant_initializer(1.0, tf.float32),\n                    trainable=False)\n\n                self._extra_train_ops.append(moving_averages.assign_moving_average(\n                    moving_mean, mean, 0.9))\n                self._extra_train_ops.append(moving_averages.assign_moving_average(\n                    moving_variance, variance, 0.9))\n            else:\n                mean = tf.get_variable(\n                    \'moving_mean\', params_shape, tf.float32,\n                    initializer=tf.constant_initializer(0.0, tf.float32),\n                    trainable=False)\n                variance = tf.get_variable(\n                    \'moving_variance\', params_shape, tf.float32,\n                    initializer=tf.constant_initializer(1.0, tf.float32),\n                    trainable=False)\n\n#                tf.summary.histogram(mean.op.name, mean)\n#                tf.summary.histogram(variance.op.name, variance)\n            # elipson used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.\n            x_bn = tf.nn.batch_normalization(x, mean, variance, beta, gamma, 0.001)\n            x_bn.set_shape(x.get_shape())\n\n            return x_bn\n    def _batch_norm_wrapper(self, name, inputs, decay = 0.999):\n        #batch normalization for fully connected layer\n        with tf.variable_scope(name):\n            scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n            beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n            pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n            pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n\n            if self.mode == \'train\':\n                batch_mean, batch_var = tf.nn.moments(inputs,[0])\n                train_mean = tf.assign(pop_mean,\n                                       pop_mean * decay + batch_mean * (1 - decay))\n                train_var = tf.assign(pop_var,\n                                      pop_var * decay + batch_var * (1 - decay))\n                with tf.control_dependencies([train_mean, train_var]):\n                    return tf.nn.batch_normalization(inputs,\n                                                     batch_mean, batch_var, beta, scale, FLAGS.epsilon)\n            else:\n                return tf.nn.batch_normalization(inputs,\n                                                 pop_mean, pop_var, beta, scale, FLAGS.epsilon)\n    def _attention(self,inputs, attention_size, time_major=False, return_alphas=False):\n        \n        if isinstance(inputs, tuple):\n        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs.\n            inputs = tf.concat(inputs, 2)\n\n        if time_major:\n        # (T,B,D) => (B,T,D)\n            inputs = tf.array_ops.transpose(inputs, [1, 0, 2])\n\n        hidden_size = inputs.shape[2].value  # D value - hidden size of the RNN layer\n\n        # Trainable parameters\n        W_omega = tf.Variable(tf.random_normal([hidden_size, attention_size], stddev=0.1))\n        b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n        u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n\n        # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n        #  the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n        #v = tf.tanh(tf.tensordot(inputs, W_omega, axes=1) + b_omega)\n        v = tf.sigmoid(tf.tensordot(inputs, W_omega, axes=1) + b_omega)\n        # For each of the timestamps its vector of size A from `v` is reduced with `u` vector\n        vu = tf.tensordot(v, u_omega, axes=1)   # (B,T) shape\n        alphas = tf.nn.softmax(vu)              # (B,T) shape also\n        \n        # Output of (Bi-)RNN is reduced with attention vector; the result has (B,D) shape\n        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)\n\n        if not return_alphas:\n            return output\n        else:\n            return output, alphas\n    def _build_model(self):\n        filters = [128, 512]\n        filter_size = [5, 3]\n        filter_strides = [1, 1]\n        pool1_size = [2, 4]\n        pool2_size = [1, 2]\n        p = 5\n        with tf.variable_scope(\'cnn\'):\n            with tf.variable_scope(\'unit-1\'):\n                x = self._conv2d(self.inputs, \'cnn-1\', filter_size, FLAGS.image_channel, filters[0], filter_strides)\n                x = self._batch_norm(\'bn1\', x)\n                x = self._leaky_relu(x, 0.01)\n                x = self._max_pool(x, pool1_size, pool1_size)\n#                print x.get_shape()\n            with tf.variable_scope(\'unit-2\'):\n                x = self._conv2d(x, \'cnn-2\',  filter_size, filters[0], filters[1], filter_strides)\n                x = self._batch_norm(\'bn2\', x)\n                x = self._leaky_relu(x, 0.01)\n                x = self._max_pool(x, pool2_size, pool2_size)\n#                print x.get_shape()\n        with tf.variable_scope(\'linear\'):\n            # linear layer for dim reduction\n            x = tf.reshape(x,[-1,p*filters[1]])\n            x = self._linear(x,\'linear1\',[p*filters[1],FLAGS.linear_num])\n#            print x.get_shape()\n        with tf.variable_scope(\'lstm\'):\n            x = tf.reshape(x,[-1,FLAGS.seq_len,FLAGS.linear_num])\n            \n            cell_fw = tf.contrib.rnn.BasicLSTMCell(FLAGS.cell_num, forget_bias=1.0)\n            if self.mode == \'train\':\n                cell_fw = tf.contrib.rnn.DropoutWrapper(cell=cell_fw, output_keep_prob=FLAGS.dropout_lstm)\n\n            cell_bw = tf.contrib.rnn.BasicLSTMCell(FLAGS.cell_num, forget_bias=1.0)\n            if self.mode == \'train\':\n                cell_bw = tf.contrib.rnn.DropoutWrapper(cell=cell_bw, output_keep_prob=FLAGS.dropout_lstm)\n            \n            # Now we feed `linear` into the LSTM BRNN cell and obtain the LSTM BRNN output.\n            outputs, output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell_fw,\n                                                                       cell_bw=cell_bw,\n                                                                       inputs= x,\n                                                                       dtype=tf.float32,\n                                                                       time_major=False,\n                                                                       scope=\'LSTM1\')\n        with tf.variable_scope(\'time_pooling\'):\n            if self.attention is not None:\n                outputs, alphas = self._attention(outputs, FLAGS.attention_size, return_alphas=True)\n            else:\n                outputs = tf.concat(outputs,2)\n                outputs = tf.reshape(outputs, [-1, FLAGS.seq_len,2*FLAGS.cell_num, 1])\n                outputs = self._max_pool(outputs,[FLAGS.seq_len,1],[FLAGS.seq_len,1])\n                outputs = tf.reshape(outputs, [-1,2*FLAGS.cell_num])\n#            print outputs.get_shape()\n        \n        with tf.variable_scope(\'dense\'):\n            y = self._linear(outputs,\'dense-matmul\',[2*FLAGS.cell_num,FLAGS.hidden1])\n            y = self._batch_norm_wrapper(\'dense-bn\', y)\n            y = self._leaky_relu(y, 0.01)\n        \n        self.logits = self._linear(y,\'softmax\',[FLAGS.hidden1,FLAGS.hidden2])\n            \n        \n        \n    '"
decsion.py,0,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Jan 11 09:57:51 2018\n\n@author: hxj\n""""""\n\nimport cPickle\nimport math\nimport numpy as np\nimport os\nfrom sklearn.metrics import recall_score as recall\nfrom sklearn.metrics import confusion_matrix as confusion\n\ndef read_data(dir):\n    f = open(dir,\'rb\')\n    best_valid_uw,best_valid_w,pred_test_w,test_acc_w,confusion_w,pred_test_uw,test_acc_uw,confusion_uw = cPickle.load(f)\n    f.close()\n    return best_valid_uw,best_valid_w,pred_test_w,test_acc_w,confusion_w,pred_test_uw,test_acc_uw,confusion_uw\n\ndef load_data():\n    f = open(\'./IEMOCAP7.pkl\',\'rb\')\n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid = cPickle.load(f)\n    return test_label\n\n\ndef softmax(x):\n    e_x = np.exp(x-np.max(x))\n    return e_x / e_x.sum(axis=0)\ndef decsion():\n    dir0 = \'./model_max0.pkl\'\n    dir1 = \'./model_max1.pkl\'\n    dir2 = \'./model_max2.pkl\'\n    dir3 = \'./model_max3.pkl\'\n    dir4 = \'./model_max4.pkl\'\n    dir5 = \'./model_max5.pkl\'\n    dir6 = \'./model_max6.pkl\'\n    dir7 = \'./model_max7.pkl\'\n    test_label = load_data()\n    best_valid_uw0,best_valid_w0,pred_test_w0,test_acc_w0,confusion_w0,pred_test_uw0,test_acc_uw0,confusion_uw0 = read_data(dir0)\n    best_valid_uw1,best_valid_w1,pred_test_w1,test_acc_w1,confusion_w1,pred_test_uw1,test_acc_uw1,confusion_uw1 = read_data(dir1)\n    best_valid_uw2,best_valid_w2,pred_test_w2,test_acc_w2,confusion_w2,pred_test_uw2,test_acc_uw2,confusion_uw2 = read_data(dir2)\n    best_valid_uw3,best_valid_w3,pred_test_w3,test_acc_w3,confusion_w3,pred_test_uw3,test_acc_uw3,confusion_uw3 = read_data(dir3)\n    best_valid_uw4,best_valid_w4,pred_test_w4,test_acc_w4,confusion_w4,pred_test_uw4,test_acc_uw4,confusion_uw4 = read_data(dir4)\n    best_valid_uw5,best_valid_w5,pred_test_w5,test_acc_w5,confusion_w5,pred_test_uw5,test_acc_uw5,confusion_uw5 = read_data(dir5)\n    best_valid_uw6,best_valid_w6,pred_test_w6,test_acc_w6,confusion_w6,pred_test_uw6,test_acc_uw6,confusion_uw6 = read_data(dir6)\n    best_valid_uw7,best_valid_w7,pred_test_w7,test_acc_w7,confusion_w7,pred_test_uw7,test_acc_uw7,confusion_uw7 = read_data(dir7)\n   \n    \n    print test_acc_uw0,test_acc_w0\n    print test_acc_uw1,test_acc_w1\n    print test_acc_uw2,test_acc_w2\n    print test_acc_uw3,test_acc_w3\n    print test_acc_uw4,test_acc_w4\n    print test_acc_uw7,test_acc_w7\n    print test_acc_uw6,test_acc_w6\n    print test_acc_uw5,test_acc_w5\n    \n    #voting\n    size = pred_test_uw0[0]\n    Pred_w_vote = np.empty((size,8),dtype=np.int8)\n    Pred_w_vote[:,0] = np.argmax(pred_test_w0,1)\n    Pred_w_vote[:,1] = np.argmax(pred_test_w1,1)\n    Pred_w_vote[:,2] = np.argmax(pred_test_w2,1)\n    Pred_w_vote[:,3] = np.argmax(pred_test_w3,1)\n    Pred_w_vote[:,4] = np.argmax(pred_test_w4,1)\n    Pred_w_vote[:,5] = np.argmax(pred_test_w5,1)\n    Pred_w_vote[:,6] = np.argmax(pred_test_w6,1)\n    Pred_w_vote[:,7] = np.argmax(pred_test_w7,1)\n#    print Pred_w0.shape, Pred_w1.shape, Pred_w2.shape, Pred_w3.shape\n#    Pred_w_vote = np.concatenate((Pred_w0,Pred_w1,Pred_w2,Pred_w3),axis=1)\n    pred_w_vote = np.empty((Pred_w_vote.shape[0],1),dtype=np.int8)\n    for l in range(Pred_w_vote.shape[0]):\n        pred_w_vote[l] = np.argmax(np.bincount(Pred_w_vote[l]))\n    Pred_uw_vote = np.empty((size,8),dtype=np.int8)\n    Pred_uw_vote[:,0] = np.argmax(pred_test_uw0,1)\n    Pred_uw_vote[:,1] = np.argmax(pred_test_uw1,1)\n    Pred_uw_vote[:,2] = np.argmax(pred_test_uw2,1)\n    Pred_uw_vote[:,3] = np.argmax(pred_test_uw3,1)\n    Pred_uw_vote[:,4] = np.argmax(pred_test_uw4,1)\n    Pred_uw_vote[:,5] = np.argmax(pred_test_uw5,1)\n    Pred_uw_vote[:,6] = np.argmax(pred_test_uw6,1)\n    Pred_uw_vote[:,7] = np.argmax(pred_test_uw7,1)\n#    print Pred_uw0.shape, Pred_uw1.shape, Pred_uw2.shape, Pred_uw3.shape\n#    Pred_uw_vote = np.concatenate((Pred_uw0,Pred_uw1,Pred_uw2,Pred_uw3),axis=1)\n    pred_uw_vote = np.empty((Pred_uw_vote.shape[0],1),dtype=np.int8)\n    for l in range(Pred_uw_vote.shape[0]):\n        pred_uw_vote[l] = np.argmax(np.bincount(Pred_uw_vote[l]))\n    acc_uw_vote = recall(np.argmax(test_label, 1),pred_uw_vote,average=\'macro\')\n    acc_w_vote = recall(np.argmax(test_label, 1),pred_w_vote,average=\'weighted\')\n    conf_uw_vote = confusion(np.argmax(test_label, 1),pred_uw_vote)\n    conf_w_vote = confusion(np.argmax(test_label, 1),pred_w_vote)\n    print \'*\'*30\n    print ""Voting UW Accuracy: %3.4g"" %acc_uw_vote\n    print \'Confusion Matrix(UA):[""ang"",""sad"",""hap"",""neu""]\'\n    print conf_uw_vote\n    print ""Voting W Accuracy: %3.4g"" %acc_w_vote\n    print \'Confusion Matrix(A):[""ang"",""sad"",""hap"",""neu""]\'\n    print conf_w_vote\n   \n    \nif __name__==\'__main__\':\n    decsion()   \n    \n    '"
model.py,30,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Feb  1 19:05:03 2017\n\n@author: hxj\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\n#from __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nfrom acrnn1 import acrnn\nimport cPickle\nfrom sklearn.metrics import recall_score as recall\nfrom sklearn.metrics import confusion_matrix as confusion\nimport os\n\ntf.app.flags.DEFINE_integer(\'num_epoch\', 5000, \'The number of epoches for training.\')\ntf.app.flags.DEFINE_integer(\'num_classes\', 4, \'The number of emotion classes.\')\ntf.app.flags.DEFINE_integer(\'batch_size\', 60, \'The number of samples in each batch.\')\ntf.app.flags.DEFINE_boolean(\'is_adam\', True,\'whether to use adam optimizer.\')\ntf.app.flags.DEFINE_float(\'learning_rate\', 0.00001, \'learning rate of Adam optimizer\')\ntf.app.flags.DEFINE_float   (\'dropout_keep_prob\',     1,        \'the prob of every unit keep in dropout layer\')\ntf.app.flags.DEFINE_integer(\'image_height\', 300, \'image height\')\ntf.app.flags.DEFINE_integer(\'image_width\', 40, \'image width\')\ntf.app.flags.DEFINE_integer(\'image_channel\', 3, \'image channels as input\')\n\ntf.app.flags.DEFINE_string  (\'traindata_path\', \'./IEMOCAP.pkl\', \'total dataset includes training set\')\ntf.app.flags.DEFINE_string  (\'validdata_path\', \'inputs/valid.pkl\', \'total dataset includes valid set\')\ntf.app.flags.DEFINE_string  (\'checkpoint\', \'./checkpoint/\', \'the checkpoint dir\')\ntf.app.flags.DEFINE_string  (\'model_name\', \'model4.ckpt\', \'model name\')\n\nFLAGS = tf.app.flags.FLAGS\n\ndef load_data(in_dir):\n    f = open(in_dir,\'rb\')\n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid = cPickle.load(f)\n    #train_data,train_label,test_data,test_label,valid_data,valid_label = cPickle.load(f)\n    return train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid\ndef dense_to_one_hot(labels_dense, num_classes):\n    """"""Convert class labels from scalars to one-hot vectors.""""""\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\ndef train():\n    #####load data##########\n    \n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid = load_data(FLAGS.traindata_path)\n    train_label = dense_to_one_hot(train_label,FLAGS.num_classes)\n    valid_label = dense_to_one_hot(valid_label,FLAGS.num_classes)\n    Valid_label = dense_to_one_hot(Valid_label,FLAGS.num_classes)\n    valid_size = valid_data.shape[0]\n    dataset_size = train_data.shape[0]\n    vnum = pernums_valid.shape[0]\n    best_valid_uw = 0\n    \n    \n    ##########tarin model###########\n    X = tf.placeholder(tf.float32, shape=[None, FLAGS.image_height,FLAGS.image_width,FLAGS.image_channel])\n    Y = tf.placeholder(tf.int32, shape=[None, FLAGS.num_classes])\n    is_training = tf.placeholder(tf.bool)\n    lr = tf.placeholder(tf.float32)\n    keep_prob = tf.placeholder(tf.float32)\n    Ylogits = acrnn(X, is_training=is_training, dropout_keep_prob=keep_prob)\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels =  Y, logits =  Ylogits)\n    cost = tf.reduce_mean(cross_entropy)\n    var_trainable_op = tf.trainable_variables()\n    if FLAGS.is_adam:\n        # not apply gradient clipping\n        train_op = tf.train.AdamOptimizer(lr).minimize(cost)            \n    else:\n        # apply gradient clipping\n        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, var_trainable_op), 5)\n        opti = tf.train.AdamOptimizer(lr)\n        train_op = opti.apply_gradients(zip(grads, var_trainable_op))\n    correct_pred = tf.equal(tf.argmax(Ylogits, 1), tf.argmax(Y,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    saver=tf.train.Saver(tf.global_variables())\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        for i in range(FLAGS.num_epoch):\n            #learning_rate = FLAGS.learning_rate            \n            start = (i * FLAGS.batch_size) % dataset_size\n            end = min(start+FLAGS.batch_size, dataset_size)\n            [_,tcost,tracc] = sess.run([train_op,cost,accuracy], feed_dict={X:train_data[start:end,:,:,:], Y:train_label[start:end,:],\n                                            is_training:True, keep_prob:FLAGS.dropout_keep_prob, lr:FLAGS.learning_rate})\n            if i % 5 == 0:\n                #for valid data\n                valid_iter = divmod((valid_size),FLAGS.batch_size)[0]\n                y_pred_valid = np.empty((valid_size,FLAGS.num_classes),dtype=np.float32)\n                y_valid = np.empty((vnum,4),dtype=np.float32)\n                index = 0\n                cost_valid = 0\n                if(valid_size < FLAGS.batch_size):\n                    loss, y_pred_valid = sess.run([cross_entropy,Ylogits],feed_dict = {X:valid_data, Y:Valid_label,is_training:False, keep_prob:1})\n                    cost_valid = cost_valid + np.sum(loss)\n                for v in range(valid_iter):\n                    v_begin = v*FLAGS.batch_size\n                    v_end = (v+1)*FLAGS.batch_size\n                    if(v == valid_iter-1):\n                        if(v_end < valid_size):\n                            v_end = valid_size\n                    loss, y_pred_valid[v_begin:v_end,:] = sess.run([cross_entropy,Ylogits],feed_dict = {X:valid_data[v_begin:v_end],Y:Valid_label[v_begin:v_end],is_training:False, keep_prob:1})\n                    cost_valid = cost_valid + np.sum(loss)\n                cost_valid = cost_valid/valid_size\n                for s in range(vnum):\n                    y_valid[s,:] = np.max(y_pred_valid[index:index+pernums_valid[s],:],0)\n                    index = index + pernums_valid[s]\n    \n                valid_acc_uw = recall(np.argmax(valid_label,1),np.argmax(y_valid,1),average=\'macro\')\n                valid_conf = confusion(np.argmax(valid_label, 1),np.argmax(y_valid,1))\n                if valid_acc_uw > best_valid_uw:\n                    best_valid_uw = valid_acc_uw\n                    best_valid_conf = valid_conf\n                    saver.save(sess, os.path.join(FLAGS.checkpoint, FLAGS.model_name), global_step = i+1)\n                print (""*****************************************************************"")\n                print (""Epoch: %05d"" %(i+1))\n                print (""Training cost: %2.3g"" %tcost)   \n                print (""Training accuracy: %3.4g"" %tracc) \n                print (""Valid cost: %2.3g"" %cost_valid)\n                print (""Valid_UA: %3.4g"" %valid_acc_uw)    \n                print (""Best valid_UA: %3.4g"" %best_valid_uw) \n                print (\'Valid Confusion Matrix:[""ang"",""sad"",""hap"",""neu""]\')\n                print (valid_conf)\n                print (\'Best Valid Confusion Matrix:[""ang"",""sad"",""hap"",""neu""]\')\n                print (best_valid_conf)\n                print (""*****************************************************************"" )\n                 \n                \nif __name__==\'__main__\':\n    train()\n'"
model1.py,104,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Mon Dec 18 16:34:21 2017\n@author: hxj\n""""""\n\n\n\nfrom attention import attention\nimport cPickle\nimport tensorflow as tf\nimport math\nimport numpy as np\nimport os\nfrom tensorflow.contrib.layers import batch_norm\nfrom tensorflow.contrib.framework import arg_scope\nepsilon = 1e-3\n\ndef Batch_Normalization(x, training, scope):\n    with arg_scope([batch_norm],\n                   scope=scope,\n                   updates_collections=None,\n                   decay=0.9,\n                   center=True,\n                   scale=True,\n                   zero_debias_moving_mean=True) :\n        return tf.cond(training,\n                       lambda : batch_norm(inputs=x, is_training=training, reuse=None),\n                       lambda : batch_norm(inputs=x, is_training=training, reuse=True))\n\ndef leaky_relu(x, leakiness=0.0):\n    return tf.where(tf.less(x, 0.0), leakiness * x, x, name=\'leaky_relu\')\ndef load_data():\n    f = open(\'./CASIA_40_delta.pkl\',\'rb\')\n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid = cPickle.load(f)\n    #train_data,train_label,test_data,test_label,valid_data,valid_label = cPickle.load(f)\n    return train_data,train_label,test_data,test_label,valid_data,valid_label\ndef batch_norm_wrapper(inputs, is_training, decay = 0.999):\n\n    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n    pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n    pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n\n    if is_training is not None:\n        batch_mean, batch_var = tf.nn.moments(inputs,[0])\n        train_mean = tf.assign(pop_mean,\n                               pop_mean * decay + batch_mean * (1 - decay))\n        train_var = tf.assign(pop_var,\n                              pop_var * decay + batch_var * (1 - decay))\n        with tf.control_dependencies([train_mean, train_var]):\n            return tf.nn.batch_normalization(inputs,\n                batch_mean, batch_var, beta, scale, epsilon)\n    else:\n        return tf.nn.batch_normalization(inputs,\n            pop_mean, pop_var, beta, scale, epsilon)\n\ndef batchnorm(Ylogits, is_test, iteration, offset, convolutional=False):\n    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999, iteration) # adding the iteration prevents from averaging across non-existing iterations\n    bnepsilon = 1e-5\n    if convolutional:\n        mean, variance = tf.nn.moments(Ylogits, [0, 1, 2])\n    else:\n        mean, variance = tf.nn.moments(Ylogits, [0])\n    update_moving_averages = exp_moving_avg.apply([mean, variance])\n    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n    Ybn = tf.nn.batch_normalization(Ylogits, m, v, offset, None, bnepsilon)\n    return Ybn, update_moving_averages\ndef dense_to_one_hot(labels_dense, num_classes):\n  """"""Convert class labels from scalars to one-hot vectors.""""""\n  num_labels = labels_dense.shape[0]\n  index_offset = np.arange(num_labels) * num_classes\n  labels_one_hot = np.zeros((num_labels, num_classes))\n  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n  return labels_one_hot\ndef build_model(inputX, is_training,keep_prob):\n    # 3 2-D convolution layers\n    L1 = 256\n    L2 = 512\n    L3 = 512\n    Li1 = 768\n    F1 = 64\n    F2 = 6\n    p = 5\n    cell_units1 = 128\n    timesteps = 200\n    ATTENTION_SIZE = 1\n    layer1_filter = tf.get_variable(\'layer1_filter\', shape=[5, 3, 3, L1], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer1_bias = tf.get_variable(\'layer1_bias\', shape=[L1], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer1_stride = [1, 1, 1, 1]\n    layer2_filter = tf.get_variable(\'layer2_filter\', shape=[5, 3, L1, L2], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer2_bias = tf.get_variable(\'layer2_bias\', shape=[L2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer2_stride = [1, 1, 1, 1]\n    layer3_filter = tf.get_variable(\'layer3_filter\', shape=[5, 3, L2, L3], dtype=tf.float32, \n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    layer3_bias = tf.get_variable(\'layer3_bias\', shape=[L3], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer3_stride = [1, 1, 1, 1]\n    \n    linear1_weight = tf.get_variable(\'linear1_weight\', shape=[p*L2,Li1], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    linear1_bias = tf.get_variable(\'linear1_bias\', shape=[Li1], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n \n    fully1_weight = tf.get_variable(\'fully1_weight\', shape=[2*cell_units1,F1], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    fully1_bias = tf.get_variable(\'fully1_bias\', shape=[F1], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    fully2_weight = tf.get_variable(\'fully2_weight\', shape=[F1,F2], dtype=tf.float32,\n                                    initializer=tf.truncated_normal_initializer(stddev=0.1))\n    fully2_bias = tf.get_variable(\'fully2_bias\', shape=[F2], dtype=tf.float32,\n                                  initializer=tf.constant_initializer(0.1))\n    layer1 = tf.nn.conv2d(inputX, layer1_filter, layer1_stride, padding=\'SAME\')\n    layer1 = tf.nn.bias_add(layer1,layer1_bias)\n    #layer1 = tf.layers.batch_normalization(layer1, training=is_training)\n    #layer1 = Batch_Normalization(layer1, training=is_training, scope=\'layer1_batch\')\n    layer1 = leaky_relu(layer1, 0.01)\n    #layer1 = Batch_Normalization(layer1, training=is_training, scope=\'layer1_batch\')\n    #print layer1.get_shape()\n    layer1 = tf.nn.max_pool(layer1,ksize=[1, 1, 4, 1], strides=[1, 1, 4, 1], padding=\'VALID\', name=\'max_pool\')\n    #print layer1.get_shape()\n    layer1 = tf.contrib.layers.dropout(layer1, keep_prob=keep_prob, is_training=is_training)\n    #layer1 = tf.reshape(layer1,[-1,timesteps,L1*p])\n    \n    layer2 = tf.nn.conv2d(layer1, layer2_filter, layer2_stride, padding=\'SAME\')\n    layer2 = tf.nn.bias_add(layer2,layer2_bias)\n    #layer1 = tf.layers.batch_normalization(layer1, training=is_training)\n    \n    layer2 = leaky_relu(layer2, 0.01)\n    #print layer2.get_shape()\n    #layer2 = Batch_Normalization(layer2, training=is_training, scope=\'layer1_batch\')\n    layer2 = tf.nn.max_pool(layer2,ksize=[1, 1, 2, 1], strides=[1, 1, 2, 1], padding=\'VALID\', name=\'max_pool\')\n    #print layer2.get_shape()\n    layer2 = tf.contrib.layers.dropout(layer2, keep_prob=keep_prob, is_training=is_training)\n    layer2 = tf.reshape(layer2,[-1,timesteps,L2*p])\n    \n    \n    layer2 = tf.reshape(layer2, [-1,p*L2])\n    \n    #layer1 = tf.reshape(layer1,[-1,p*L1])\n    linear1 = tf.matmul(layer2,linear1_weight) + linear1_bias\n    linear1 = batch_norm_wrapper(linear1,is_training)\n    linear1 = leaky_relu(linear1, 0.01)\n    #linear1 = batch_norm_wrapper(linear1,is_training)\n    linear1 = tf.reshape(linear1, [-1, timesteps, Li1])\n    \n    \n    \'\'\'\n    #adding gru cell\n    gru_bw_cell1 = tf.nn.rnn_cell.GRUCell(cell_units)\n    #if is_training is not None:\n    #    gru_bw_cell1 = tf.contrib.rnn.DropoutWrapper(cell=gru_bw_cell1, output_keep_prob=keep_prob)\n    # Forward direction cell: (if else required for TF 1.0 and 1.1 compat)\n    gru_fw_cell1 = tf.nn.rnn_cell.GRUCell(cell_units)\n    #if is_training is not None:\n    #    gru_fw_cell1 = tf.contrib.rnn.DropoutWrapper(cell=gru_fw_cell1, output_keep_prob=keep_prob)\n    \n    \'\'\'\n    # Define lstm cells with tensorflow\n    # Forward direction cell\n    gru_fw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units1, forget_bias=1.0)\n    # Backward direction cell\n    gru_bw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units1, forget_bias=1.0)\n    \n    \'\'\'\n    # Define lstm cells with tensorflow\n    # Forward direction cell\n    gru_fw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units, forget_bias=1.0)\n    if is_training is not None:\n        gru_fw_cell1 = tf.contrib.rnn.DropoutWrapper(cell=gru_fw_cell1, output_keep_prob=keep_prob)\n    # Backward direction cell\n    gru_bw_cell1 = tf.contrib.rnn.BasicLSTMCell(cell_units, forget_bias=1.0)\n    if is_training is not None:\n        gru_bw_cell1 = tf.contrib.rnn.DropoutWrapper(cell=gru_bw_cell1, output_keep_prob=keep_prob)\n    \'\'\'\n    # Now we feed `layer_3` into the LSTM BRNN cell and obtain the LSTM BRNN output.\n    outputs1, output_states1 = tf.nn.bidirectional_dynamic_rnn(cell_fw=gru_fw_cell1,\n                                                             cell_bw=gru_bw_cell1,\n                                                             inputs= linear1,\n                                                             dtype=tf.float32,\n                                                             time_major=False,\n                                                             scope=\'LSTM1\')\n    \'\'\'\n    outputs1 = tf.concat(outputs1,2)\n     # Forward direction cell\n    gru_fw_cell2 = tf.contrib.rnn.BasicLSTMCell(cell_units2, forget_bias=1.0)\n    # Backward direction cell\n    gru_bw_cell2 = tf.contrib.rnn.BasicLSTMCell(cell_units2, forget_bias=1.0)\n    # Now we feed `layer_3` into the LSTM BRNN cell and obtain the LSTM BRNN output.\n    outputs, output_states2 = tf.nn.bidirectional_dynamic_rnn(cell_fw=gru_fw_cell2,\n                                                             cell_bw=gru_bw_cell2,\n                                                             inputs= outputs1,\n                                                             dtype=tf.float32,\n                                                             time_major=False,\n                                                             scope=\'LSTM2\')\n    \'\'\'\n    #time_major=false,tensor\xe7\x9a\x84shape\xe4\xb8\xba[batch_size, max_time, depth]\xe3\x80\x82\xe5\xae\x9e\xe9\xaa\x8c\xe4\xb8\xad\xe4\xbd\xbf\xe7\x94\xa8tf.concat(outputs, 2)\xe5\xb0\x86\xe5\x85\xb6\xe6\x8b\xbc\xe6\x8e\xa5\n    \n    outputs = tf.concat(outputs1,2)\n    outputs = tf.reshape(outputs, [-1, timesteps,2*cell_units1, 1])\n    gru = tf.nn.max_pool(outputs,ksize=[1,timesteps,1,1], strides=[1,timesteps,1,1], padding=\'VALID\', name=\'max_pool\')\n    gru = tf.reshape(gru, [-1,2*cell_units1])    \n    \'\'\'\n    # Attention layer\n    gru, alphas = attention(outputs1, ATTENTION_SIZE, return_alphas=True)\n    \'\'\' \n    \n    fully1 = tf.matmul(gru,fully1_weight) + fully1_bias\n    #fully1 = batch_norm_wrapper(fully1,is_training)\n    fully1 = leaky_relu(fully1, 0.01)\n    #fully1 = batch_norm_wrapper(fully1,is_training) \n    fully1 = tf.nn.dropout(fully1, keep_prob)\n    \n    \n    Ylogits = tf.matmul(fully1, fully2_weight) + fully2_bias\n    #Ylogits = tf.nn.softmax(Ylogits)\n    \'\'\'\n    fully2 = tf.matmul(fully1,fully2_weight) + fully2_bias  \n    fully2 = leaky_relu(fully2, 0.01)\n    #fully2 = batch_norm_wrapper(fully2,is_training) \n    Ylogits = tf.matmul(fully2, fully3_weight) + fully3_bias\n    #Ylogits = tf.nn.softmax(Ylogits)\n    \'\'\'\n    return Ylogits\n    \ndef train_op(norm):\n    STEPS = 50000\n    batch_size = 60\n    grad_clip = 5\n    MODEL_SAVE_PATH = ""./model2/""\n    MODEL_NAME = ""model.ckpt""\n    X = tf.placeholder(tf.float32, shape=[None, 300,40,3])\n    Y = tf.placeholder(tf.int32, shape=[None, 4])\n    is_training = tf.placeholder(tf.bool)\n    # variable learning rate\n    lr = tf.placeholder(tf.float32)\n    keep_prob = tf.placeholder(tf.float32)\n    Ylogits = build_model(X, is_training, keep_prob)\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels =  Y, logits =  Ylogits)\n    cost = tf.reduce_mean(cross_entropy)\n    #train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n    var_trainable_op = tf.trainable_variables()\n    if norm == -1:\n        # not apply gradient clipping\n        train_op = tf.train.AdamOptimizer(lr).minimize(cost)            \n    else:\n        # apply gradient clipping\n        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, var_trainable_op), grad_clip)\n        opti = tf.train.AdamOptimizer(lr)\n        train_op = opti.apply_gradients(zip(grads, var_trainable_op))\n    correct_pred = tf.equal(tf.argmax(Ylogits, 1), tf.argmax(Y,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))   \n    saver=tf.train.Saver(tf.global_variables())\n    \n    train_data,train_label,test_data,test_label,valid_data,valid_label = load_data()\n    train_label = dense_to_one_hot(train_label,len(np.unique(train_label)))\n    test_label = dense_to_one_hot(test_label,len(np.unique(test_label)))\n    valid_label = dense_to_one_hot(valid_label,len(np.unique(valid_label)))\n    max_learning_rate = 0.0001\n    min_learning_rate = 0.000001\n    decay_speed = 1600\n    dataset_size = train_data.shape[0]\n    # init\n    init = tf.global_variables_initializer()\n    best_acc = 0\n    with tf.Session() as sess:\n        sess.run(init)\n        for i in range(STEPS):\n            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-i/decay_speed)\n            start = (i * batch_size) % dataset_size\n            end = min(start+batch_size, dataset_size)\n            if i % 5 == 0:\n                loss, train_acc = sess.run([cost,accuracy],feed_dict = {X:valid_data, Y:valid_label,is_training:False, keep_prob:1})\n                test_acc = sess.run(accuracy, feed_dict = {X:test_data, Y:test_label, is_training:False, keep_prob:1})\n                if test_acc > best_acc:\n                    best_acc = test_acc\n                print ""After %5d trainging step(s), validation cross entropy is %2.2g, validation accuracy is %3.2g, test accuracy is %3.2g, the best accuracy is %3.2g"" %(i, loss, train_acc, test_acc, best_acc)\n                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME),global_step = i)\n            sess.run(train_op, feed_dict={X:train_data[start:end,:,:,:], Y:train_label[start:end,:],\n                                            is_training:True, keep_prob:1, lr:learning_rate})\n                                    \nif __name__==\'__main__\':\n    train_op(1)\n'"
train.py,19,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Feb  1 19:05:03 2018\n\n@author: hxj\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nimport crnn\nimport cPickle\nimport os\nFLAGS = crnn.FLAGS\ndef load_data():\n    f = open(FLAGS.data_path,\'rb\')\n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,\\\n        Test_label,pernums_test,pernums_valid = cPickle.load(f)\n    return train_data,train_label\n\ndef dense_to_one_hot(labels_dense, num_classes):\n    """"""Convert class labels from scalars to one-hot vectors.""""""\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\ndef train(train_dir=None, model_dir=None, mode=\'train\'):\n    model = crnn.CRNN(mode)\n    model._build_model()\n    global_step = tf.Variable(0, trainable=False)\n    #sess1 = tf.InteractiveSession()\n    #load training data\n    train_data,train_label = load_data()\n    train_label = dense_to_one_hot(train_label,4)\n    training_size = train_data.shape[0]\n    with tf.name_scope(\'cross_entropy\'):\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels =  model.labels, logits =  model.logits)\n        loss = tf.reduce_mean(cross_entropy)\n#        print model.logits.get_shape()  \n    with tf.name_scope(\'accuracy\'):\n        correct_pred = tf.equal(tf.argmax(model.logits, 1), tf.argmax(model.labels,1))\n        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) \n    with tf.name_scope(""moving_average""):\n        variable_averages = tf.train.ExponentialMovingAverage(FLAGS.momentum, global_step)\n        variable_averages_op = variable_averages.apply(tf.trainable_variables())\n    \n    with tf.name_scope(""train_step""):\n        lr = tf.train.exponential_decay(FLAGS.learning_rate,\n                                        global_step,\n                                        training_size/FLAGS.train_batch_size,\n                                        FLAGS.decay_rate,\n                                        staircase=True)\n        #print (lr.eval())        \n        train_step = tf.train.AdamOptimizer(lr).minimize(loss,global_step=global_step)\n        with tf.control_dependencies([train_step, variable_averages_op]):\n            train_op = tf.no_op(name=\'train\')\n    saver = tf.train.Saver()\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        for i in range(FLAGS.num_epochs):\n            start = (i * FLAGS.train_batch_size) % training_size\n            end = min(start+FLAGS.train_batch_size, training_size)\n            _, loss_value, step,acc = sess.run([train_op, loss, global_step,accuracy],\n                                           feed_dict={model.inputs:train_data[start:end],model.labels:train_label[start:end]})\n            if i % 10 == 0:\n                print ""After %d training step(s), loss on training batch is %.2f, accuracy is %.3f."" %(step, loss_value,acc)\n                saver.save(\n                        sess, os.path.join(FLAGS.checkpoint, FLAGS.model_name), global_step = global_step)\n                \nif __name__==\'__main__\':\n    train()'"
utils.py,6,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Feb  1 19:05:03 2018\n\n@author: hxj\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nimport crnn\nimport cPickle\nfrom sklearn.metrics import recall_score as recall\nfrom sklearn.metrics import confusion_matrix as confusion\nFLAGS = crnn.FLAGS\n\ndef load_data():\n    f = open(FLAGS.data_path,\'rb\')\n    train_data,train_label,test_data,test_label,valid_data,valid_label,Valid_label,\\\n        Test_label,pernums_test,pernums_valid = cPickle.load(f)\n    return test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid\n\ndef dense_to_one_hot(labels_dense, num_classes):\n    """"""Convert class labels from scalars to one-hot vectors.""""""\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\ndef evaluate():\n    with tf.Graph().as_default() as g:\n        model = crnn.CRNN(\'test\')\n        model._build_model()\n        \n        #load training data\n        test_data,test_label,valid_data,valid_label,Valid_label,Test_label,pernums_test,pernums_valid = load_data()\n        test_label = dense_to_one_hot(test_label,4)\n        valid_label = dense_to_one_hot(valid_label,4)\n        Test_label = dense_to_one_hot(Test_label,4)\n        Valid_label = dense_to_one_hot(Valid_label,4)\n        test_size = test_data.shape[0]\n        valid_size = valid_data.shape[0]\n        tnum = pernums_test.shape[0]\n        vnum = pernums_valid.shape[0]\n        pred_test_uw = np.empty((tnum,4),dtype = np.float32)\n        pred_test_w = np.empty((tnum,4),dtype = np.float32)\n        valid_iter = divmod((valid_size),FLAGS.valid_batch_size)[0]\n        test_iter = divmod((test_size),FLAGS.test_batch_size)[0]\n        y_pred_valid = np.empty((valid_size,4),dtype=np.float32)\n        y_pred_test = np.empty((test_size,4),dtype=np.float32)\n        y_test = np.empty((tnum,4),dtype=np.float32)\n        y_valid = np.empty((vnum,4),dtype=np.float32)\n        \n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels =  model.labels, logits =  model.logits)        \n        variable_averages = tf.train.ExponentialMovingAverage(FLAGS.momentum)\n        variable_to_restore = variable_averages.variables_to_restore()\n        saver = tf.train.Saver(variable_to_restore)\n        flag = False\n        best_valid_uw = 0\n        best_valid_w = 0\n        while True:\n            with tf.Session() as sess:\n                ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint)\n                if ckpt and ckpt.model_checkpoint_path:\n                    saver.restore(sess,ckpt.model_checkpoint_path)\n                    global_step = ckpt.model_checkpoint_path.split(\'/\')[-1].split(\'-\')[-1]\n                    \n                    #for validation data\n                    index = 0\n                    cost_valid = 0\n                    if(valid_size < FLAGS.valid_batch_size):\n                        validate_feed = {model.inputs:valid_data,model.labels:Valid_label}\n                        y_pred_valid,loss = sess.run([model.logits,cross_entropy],feed_dict = validate_feed)\n                        cost_valid = cost_valid + np.sum(loss)\n                    for v in range(valid_iter):\n                        v_begin = v*FLAGS.valid_batch_size\n                        v_end = (v+1)*FLAGS.valid_batch_size\n                        if(v == valid_iter-1):\n                            if(v_end < valid_size):\n                                v_end = valid_size\n                        validate_feed = {model.inputs:valid_data[v_begin:v_end],model.labels:Valid_label[v_begin:v_end]}\n                        loss, y_pred_valid[v_begin:v_end,:] = sess.run([cross_entropy,model.logits],feed_dict = validate_feed)\n                        cost_valid = cost_valid + np.sum(loss)\n                    cost_valid = cost_valid/valid_size\n                    for s in range(vnum):\n                        y_valid[s,:] = np.max(y_pred_valid[index:index+pernums_valid[s],:],0)\n                        index = index + pernums_valid[s]\n                    valid_acc_uw = recall(np.argmax(valid_label,1),np.argmax(y_valid,1),average=\'macro\')\n                    valid_acc_w = recall(np.argmax(valid_label, 1),np.argmax(y_valid,1),average=\'weighted\')\n                    valid_conf = confusion(np.argmax(valid_label, 1),np.argmax(y_valid,1))\n                    \n                    #for test set\n                    index = 0\n                    for t in range(test_iter):\n                        t_begin = t*FLAGS.test_batch_size\n                        t_end = (t+1)*FLAGS.test_batch_size\n                        if(t == test_iter-1):\n                            if(t_end < test_size):\n                                t_end = test_size\n                        #print t_begin,t_end,t,test_iter\n                        test_feed = {model.inputs:test_data[t_begin:t_end],model.labels:Test_label[t_begin:t_end]}\n                        y_pred_test[t_begin:t_end,:] = sess.run(model.logits, feed_dict = test_feed)\n                        \n                    for s in range(tnum):\n                        y_test[s,:] = np.max(y_pred_test[index:index+pernums_test[s],:],0)\n                        index = index + pernums_test[s]\n                    \n                    if valid_acc_uw > best_valid_uw:\n                        best_valid_uw = valid_acc_uw\n                        pred_test_uw = y_test\n                        test_acc_uw = recall(np.argmax(test_label, 1),np.argmax(y_test,1),average=\'macro\')\n                        test_conf = confusion(np.argmax(test_label, 1),np.argmax(y_test,1))\n                        confusion_uw = test_conf\n                        flag = True\n                   \n                    if valid_acc_w > best_valid_w:\n                        best_valid_w = valid_acc_w\n                        pred_test_w = y_test\n                        test_acc_w = recall(np.argmax(test_label, 1),np.argmax(y_test,1),average=\'weighted\')\n                        test_conf = confusion(np.argmax(test_label, 1),np.argmax(y_test,1))\n                        confusion_w = test_conf\n                        flag = True\n                    #export\n                    print ""*****************************************************************""\n                    print global_step                    \n                    print ""Epoch: %s"" %global_step\n                    print ""Valid cost: %2.3g"" %cost_valid\n                    print ""Valid_UA: %3.4g"" %valid_acc_uw    \n                    print ""Valid_WA: %3.4g"" %valid_acc_w\n                    print ""Best valid_UA: %3.4g"" %best_valid_uw \n                    print ""Best valid_WA: %3.4g"" %best_valid_w\n                    print \'Valid Confusion Matrix:[""ang"",""sad"",""hap"",""neu""]\'\n                    print valid_conf\n                    print ""Test_UA: %3.4g"" %test_acc_uw   \n                    print ""Test_WA: %3.4g"" %test_acc_w\n                    print \'Test Confusion Matrix:[""ang"",""sad"",""hap"",""neu""]\'\n                    print confusion_uw\n                    print ""*****************************************************************"" \n                    if(flag):\n                        f=open(FLAGS.pred_name,\'wb\') \n                        cPickle.dump((best_valid_uw,best_valid_w,pred_test_w,test_acc_w,confusion_w,pred_test_uw,test_acc_uw,confusion_uw,),f)\n                        f.close()\n                        flag = False \n\n                \nif __name__==\'__main__\':\n    evaluate()'"
zscore.py,0,"b'#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Mon Jan 15 16:23:45 2018\n\n@author: hxj\n""""""\n\n#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Jan  9 20:32:28 2018\n\n@author: hxj\n""""""\n\nimport wave\nimport numpy as np\nimport python_speech_features as ps\nimport os\nimport glob\nimport cPickle\n#import base\n#import sigproc\neps = 1e-5\ndef wgn(x, snr):\n    snr = 10**(snr/10.0)\n    xpower = np.sum(x**2)/len(x)\n    npower = xpower / snr\n    return np.random.randn(len(x)) * np.sqrt(npower)\ndef getlogspec(signal,samplerate=16000,winlen=0.02,winstep=0.01,\n               nfilt=26,nfft=399,lowfreq=0,highfreq=None,preemph=0.97,\n               winfunc=lambda x:np.ones((x,))):\n    highfreq= highfreq or samplerate/2\n    signal = ps.sigproc.preemphasis(signal,preemph)\n    frames = ps.sigproc.framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n    pspec = ps.sigproc.logpowspec(frames,nfft)\n    return pspec \ndef read_file(filename):\n    file = wave.open(filename,\'r\')    \n    params = file.getparams()\n    nchannels, sampwidth, framerate, wav_length = params[:4]\n    str_data = file.readframes(wav_length)\n    wavedata = np.fromstring(str_data, dtype = np.short)\n    #wavedata = np.float(wavedata*1.0/max(abs(wavedata)))  # normalization)\n    time = np.arange(0,wav_length) * (1.0/framerate)\n    file.close()\n    return wavedata, time, framerate\ndef dense_to_one_hot(labels_dense, num_classes):\n  """"""Convert class labels from scalars to one-hot vectors.""""""\n  num_labels = labels_dense.shape[0]\n  index_offset = np.arange(num_labels) * num_classes\n  labels_one_hot = np.zeros((num_labels, num_classes))\n  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n  return labels_one_hot\n\ndef zscore(data,mean,std):\n    shape = np.array(data.shape,dtype = np.int32)\n    for i in range(shape[0]):\n        data[i,:,:,0] = (data[i,:,:,0]-mean)/(std)\n    return data\n\ndef normalization(data):\n    \'\'\'\n    #apply zscore\n    mean = np.mean(data,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n    std = np.std(data,axis=0)\n    train_data = zscore(train_data,mean,std)\n    test_data = zscore(test_data,mean,std)\n    \'\'\'\n    mean = np.mean(data,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n    std = np.std(data,axis=0)\n    data = (data-mean)/std\n    return data\ndef mapminmax(data):\n    shape = np.array(data.shape,dtype = np.int32)\n    for i in range(shape[0]):\n        min = np.min(data[i,:,:,0])\n        max = np.max(data[i,:,:,0])\n        data[i,:,:,0] = (data[i,:,:,0] - min)/((max - min)+eps)\n    return data\ndef generate_label(emotion,classnum):\n    label = -1\n    if(emotion == \'ang\'):\n        label = 0\n    elif(emotion == \'sad\'):\n        label = 1\n    elif(emotion == \'hap\'):\n        label = 2\n    elif(emotion == \'neu\'):\n        label = 3\n    elif(emotion == \'fear\'):\n        label = 4\n    else:\n        label = 5\n    return label\n        \n        \ndef read_IEMOCAP():\n    \n    train_num = 2928\n    filter_num = 40\n    rootdir = \'/home/jamhan/hxj/datasets/IEMOCAP_full_release\'\n    traindata1 = np.empty((train_num*300,filter_num),dtype=np.float32)\n    traindata2 = np.empty((train_num*300,filter_num),dtype=np.float32)\n    traindata3 = np.empty((train_num*300,filter_num),dtype=np.float32)\n    train_num = 0\n    \n    \n    for speaker in os.listdir(rootdir):\n        if(speaker[0] == \'S\'):\n            sub_dir = os.path.join(rootdir,speaker,\'sentences/wav\')\n            emoevl = os.path.join(rootdir,speaker,\'dialog/EmoEvaluation\')\n            for sess in os.listdir(sub_dir):\n                if(sess[7] == \'i\'):\n                    emotdir = emoevl+\'/\'+sess+\'.txt\'\n                    #emotfile = open(emotdir)\n                    emot_map = {}\n                    with open(emotdir,\'r\') as emot_to_read:\n                        while True:\n                            line = emot_to_read.readline()\n                            if not line:\n                                break\n                            if(line[0] == \'[\'):\n                                t = line.split()\n                                emot_map[t[3]] = t[4]\n                                \n        \n                    file_dir = os.path.join(sub_dir, sess, \'*.wav\')\n                    files = glob.glob(file_dir)\n                    for filename in files:\n                        #wavname = filename[-23:-4]\n                        wavname = filename.split(""/"")[-1][:-4]\n                        emotion = emot_map[wavname]\n                        if(emotion in [\'hap\',\'ang\',\'neu\',\'sad\']):\n                             data, time, rate = read_file(filename)\n                             mel_spec = ps.logfbank(data,rate,nfilt = filter_num)\n                             delta1 = ps.delta(mel_spec, 2)\n                             delta2 = ps.delta(delta1, 2)\n                             \n                             time = mel_spec.shape[0] \n                             if(speaker in [\'Session1\',\'Session2\',\'Session3\',\'Session4\']):\n                                 #training set\n                                 if(time <= 300):\n                                      part = mel_spec\n                                      delta11 = delta1\n                                      delta21 = delta2\n                                      part = np.pad(part,((0,300 - part.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      delta11 = np.pad(delta11,((0,300 - delta11.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      delta21 = np.pad(delta21,((0,300 - delta21.shape[0]),(0,0)),\'constant\',constant_values = 0)\n                                      traindata1[train_num*300:(train_num+1)*300] = part\n                                      traindata2[train_num*300:(train_num+1)*300] = delta11\n                                      traindata3[train_num*300:(train_num+1)*300] = delta21\n                                      \n                                      em = generate_label(emotion,6)\n                                      train_num = train_num + 1\n                                 else:\n                                      \n                                     if(emotion in [\'ang\',\'neu\',\'sad\']):\n                                         \n                                         for i in range(2):\n                                             if(i == 0):\n                                                 begin = 0\n                                                 end = begin + 300\n                                             else:\n                                                 begin = time - 300\n                                                 end = time\n                                          \n                                             part = mel_spec[begin:end,:]\n                                             delta11 = delta1[begin:end,:]\n                                             delta21 = delta2[begin:end,:]\n                                             traindata1[train_num*300:(train_num+1)*300] = part\n                                             traindata2[train_num*300:(train_num+1)*300] = delta11\n                                             traindata3[train_num*300:(train_num+1)*300] = delta21\n                                             train_num = train_num + 1\n                                     else:\n                                        frames = divmod(time-300,100)[0] + 1\n                                        for i in range(frames):\n                                            begin = 100*i\n                                            end = begin + 300\n                                            part = mel_spec[begin:end,:]\n                                            delta11 = delta1[begin:end,:]\n                                            delta21 = delta2[begin:end,:]\n                                            traindata1[train_num*300:(train_num+1)*300] = part\n                                            traindata2[train_num*300:(train_num+1)*300] = delta11\n                                            traindata3[train_num*300:(train_num+1)*300] = delta21\n                                            train_num = train_num + 1\n                                          \n                             else:\n                                 pass\n                                    \n                                 \n                        else:\n                            pass\n    \n    \n        mean1 = np.mean(traindata1,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n        std1 = np.std(traindata1,axis=0)\n        mean2 = np.mean(traindata2,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n        std2 = np.std(traindata2,axis=0)\n        mean3 = np.mean(traindata3,axis=0)#axis=0\xe7\xba\xb5\xe8\xbd\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\xb1\x82\xe5\x9d\x87\xe5\x80\xbc\n        std3 = np.std(traindata3,axis=0)\n        output = \'./zscore\'+str(filter_num)+\'.pkl\'\n        #output = \'./IEMOCAP\'+str(m)+\'_\'+str(filter_num)+\'.pkl\'\n        f=open(output,\'wb\') \n        cPickle.dump((mean1,std1,mean2,std2,mean3,std3),f)\n        f.close()           \n    return\n                \n        \n\n\nif __name__==\'__main__\':\n    read_IEMOCAP()\n    #print ""test_num:"", test_num\n    #print ""train_num:"", train_num\n#    n = wgn(x, 6)\n#    xn = x+n # \xe5\xa2\x9e\xe5\x8a\xa0\xe4\xba\x866dBz\xe4\xbf\xa1\xe5\x99\xaa\xe6\xaf\x94\xe5\x99\xaa\xe5\xa3\xb0\xe7\x9a\x84\xe4\xbf\xa1\xe5\x8f\xb7\n'"
