file_path,api_count,code
scripts/env.py,1,"b'import numpy as np\nimport random\nfrom utils import *\n\nclass Env(object):\n\t""""""knowledge graph environment definition""""""\n\tdef __init__(self, dataPath, task=None):\n\t\tf1 = open(dataPath + \'entity2id.txt\')\n\t\tf2 = open(dataPath + \'relation2id.txt\')\n\t\tself.entity2id = f1.readlines()\n\t\tself.relation2id = f2.readlines()\n\t\tf1.close()\n\t\tf2.close()\n\t\tself.entity2id_ = {}\n\t\tself.relation2id_ = {}\n\t\tself.relations = []\n\t\tfor line in self.entity2id:\n\t\t\tself.entity2id_[line.split()[0]] =int(line.split()[1])\n\t\tfor line in self.relation2id:\n\t\t\tself.relation2id_[line.split()[0]] = int(line.split()[1])\n\t\t\tself.relations.append(line.split()[0])\n\t\tself.entity2vec = np.loadtxt(dataPath + \'entity2vec.bern\')\n\t\tself.relation2vec = np.loadtxt(dataPath + \'relation2vec.bern\')\n\n\n\t\tself.path = []\n\t\tself.path_relations = []\n\n\t\t# Knowledge Graph for path finding\n\t\tf = open(dataPath + \'kb_env_rl.txt\')\n\t\tkb_all = f.readlines()\n\t\tf.close()\n\n\t\tself.kb = []\n\t\tif task != None:\n\t\t\trelation = task.split()[2]\n\t\t\tfor line in kb_all:\n\t\t\t\trel = line.split()[2]\n\t\t\t\tif rel != relation and rel != relation + \'_inv\':\n\t\t\t\t\tself.kb.append(line)\n\n\t\tself.die = 0 # record how many times does the agent choose an invalid path\n\n\tdef interact(self, state, action):\n\t\t\'\'\'\n\t\tThis function process the interact from the agent\n\t\tstate: is [current_position, target_position] \n\t\taction: an integer\n\t\treturn: (reward, [new_postion, target_position], done)\n\t\t\'\'\'\n\t\tdone = 0 # Whether the episode has finished\n\t\tcurr_pos = state[0]\n\t\ttarget_pos = state[1]\n\t\tchosed_relation = self.relations[action]\n\t\tchoices = []\n\t\tfor line in self.kb:\n\t\t\ttriple = line.rsplit()\n\t\t\te1_idx = self.entity2id_[triple[0]]\n\t\t\t\n\t\t\tif curr_pos == e1_idx and triple[2] == chosed_relation and triple[1] in self.entity2id_:\n\t\t\t\tchoices.append(triple)\n\t\tif len(choices) == 0:\n\t\t\treward = -1\n\t\t\tself.die += 1\n\t\t\tnext_state = state # stay in the initial state\n\t\t\tnext_state[-1] = self.die\n\t\t\treturn (reward, next_state, done)\n\t\telse: # find a valid step\n\t\t\tpath = random.choice(choices)\n\t\t\tself.path.append(path[2] + \' -> \' + path[1])\n\t\t\tself.path_relations.append(path[2])\n\t\t\t# print(\'Find a valid step\', path)\n\t\t\t# print(\'Action index\', action)\n\t\t\tself.die = 0\n\t\t\tnew_pos = self.entity2id_[path[1]]\n\t\t\treward = 0\n\t\t\tnew_state = [new_pos, target_pos, self.die]\n\n\t\t\tif new_pos == target_pos:\n\t\t\t\tprint(\'Find a path:\', self.path)\n\t\t\t\tdone = 1\n\t\t\t\treward = 0\n\t\t\t\tnew_state = None\n\t\t\treturn (reward, new_state, done)\n\n\tdef idx_state(self, idx_list):\n\t\tif idx_list != None:\n\t\t\tcurr = self.entity2vec[idx_list[0],:]\n\t\t\ttarg = self.entity2vec[idx_list[1],:]\n\t\t\treturn np.expand_dims(np.concatenate((curr, targ - curr)),axis=0)\n\t\telse:\n\t\t\treturn None\n\n\tdef get_valid_actions(self, entityID):\n\t\tactions = set()\n\t\tfor line in self.kb:\n\t\t\ttriple = line.split()\n\t\t\te1_idx = self.entity2id_[triple[0]]\n\t\t\tif e1_idx == entityID:\n\t\t\t\tactions.add(self.relation2id_[triple[2]])\n\t\treturn np.array(list(actions))\n\n\tdef path_embedding(self, path):\n\t\tembeddings = [self.relation2vec[self.relation2id_[relation],:] for relation in path]\n\t\tembeddings = np.reshape(embeddings, (-1,embedding_dim))\n\t\tpath_encoding = np.sum(embeddings, axis=0)\n\t\treturn np.reshape(path_encoding,(-1, embedding_dim))\n\n\n'"
scripts/evaluate.py,6,"b""#!/usr/bin/python\n\nimport sys\nimport numpy as np\nfrom BFS.KB import *\nfrom sklearn import linear_model\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Activation\n\nrelation = sys.argv[1]\n\ndataPath_ = '../NELL-995/tasks/'  + relation\nfeaturePath = dataPath_ + '/path_to_use.txt'\nfeature_stats = dataPath_ + '/path_stats.txt'\nrelationId_path = '../NELL-995/relation2id.txt'\n\ndef train(kb, kb_inv, named_paths):\n\tf = open(dataPath_ + '/train.pairs')\n\ttrain_data = f.readlines()\n\tf.close()\n\ttrain_pairs = []\n\ttrain_labels = []\n\tfor line in train_data:\n\t\te1 = line.split(',')[0].replace('thing$','')\n\t\te2 = line.split(',')[1].split(':')[0].replace('thing$','')\n\t\tif (e1 not in kb.entities) or (e2 not in kb.entities):\n\t\t\tcontinue\n\t\ttrain_pairs.append((e1,e2))\n\t\tlabel = 1 if line[-2] == '+' else 0\n\t\ttrain_labels.append(label)\n\ttraining_features = []\n\tfor sample in train_pairs:\n\t\tfeature = []\n\t\tfor path in named_paths:\n\t\t\t\tfeature.append(int(bfs_two(sample[0], sample[1], path, kb, kb_inv)))\n\t\ttraining_features.append(feature)\n\tmodel = Sequential()\n\tinput_dim = len(named_paths)\n\tmodel.add(Dense(1, activation='sigmoid' ,input_dim=input_dim))\n\tmodel.compile(optimizer = 'rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\tmodel.fit(training_features, train_labels, nb_epoch=300, batch_size=128)\n\treturn model\n\ndef get_features():\n\tstats = {}\n\tf = open(feature_stats)\n\tpath_freq = f.readlines()\n\tf.close()\n\tfor line in path_freq:\n\t\tpath = line.split('\\t')[0]\n\t\tnum = int(line.split('\\t')[1])\n\t\tstats[path] = num\n\tmax_freq = np.max(stats.values())\n\n\trelation2id = {}\n\tf = open(relationId_path)\n\tcontent = f.readlines()\n\tf.close()\n\tfor line in content:\n\t\trelation2id[line.split()[0]] = int(line.split()[1])\n\n\tuseful_paths = []\n\tnamed_paths = []\n\tf = open(featurePath)\n\tpaths = f.readlines()\n\tf.close()\n\n\tprint len(paths)\n\n\tfor line in paths:\n\t\tpath = line.rstrip()\n\n\t\tlength = len(path.split(' -> '))\n\n\t\tif length <= 10:\n\t\t\tpathIndex = []\n\t\t\tpathName = []\n\t\t\trelations = path.split(' -> ')\n\n\t\t\tfor rel in relations:\n\t\t\t\tpathName.append(rel)\n\t\t\t\trel_id = relation2id[rel]\n\t\t\t\tpathIndex.append(rel_id)\n\t\t\tuseful_paths.append(pathIndex)\n\t\t\tnamed_paths.append(pathName)\n\n\tprint 'How many paths used: ', len(useful_paths)\n\treturn useful_paths, named_paths\n\ndef evaluate_logic():\n\tkb = KB()\n\tkb_inv = KB()\n\n\tf = open(dataPath_ + '/graph.txt')\n\tkb_lines = f.readlines()\n\tf.close()\n\n\tfor line in kb_lines:\n\t\te1 = line.split()[0]\n\t\trel = line.split()[1]\n\t\te2 = line.split()[2]\n\t\tkb.addRelation(e1,rel,e2)\n\t\tkb_inv.addRelation(e2,rel,e1)\n\n\t_, named_paths = get_features()\n\n\tmodel = train(kb, kb_inv, named_paths)\n\n\n\tf = open(dataPath_ + '/sort_test.pairs')\n\ttest_data = f.readlines()\n\tf.close()\n\ttest_pairs = []\n\ttest_labels = []\n\t# queries = set()\n\tfor line in test_data:\n\t\te1 = line.split(',')[0].replace('thing$','')\n\t\t# e1 = '/' + e1[0] + '/' + e1[2:]\n\t\te2 = line.split(',')[1].split(':')[0].replace('thing$','')\n\t\t# e2 = '/' + e2[0] + '/' + e2[2:]\n\t\tif (e1 not in kb.entities) or (e2 not in kb.entities):\n\t\t\tcontinue\n\t\ttest_pairs.append((e1,e2))\n\t\tlabel = 1 if line[-2] == '+' else 0\n\t\ttest_labels.append(label)\n\n\taps = []\n\tquery = test_pairs[0][0]\n\ty_true = []\n\ty_score = []\n\n\tscore_all = []\n\n\tfor idx, sample in enumerate(test_pairs):\n\t\t#print 'query node: ', sample[0], idx\n\t\tif sample[0] == query:\n\t\t\tfeatures = []\n\t\t\tfor path in named_paths:\n\t\t\t\tfeatures.append(int(bfs_two(sample[0], sample[1], path, kb, kb_inv)))\n\n\t\t\t#features = features*path_weights\n\n\t\t\tscore = model.predict(np.reshape(features, [1,-1]))\n\t\t\t#score = np.sum(features)\n\n\t\t\tscore_all.append(score[0])\n\t\t\ty_score.append(score)\n\t\t\ty_true.append(test_labels[idx])\n\t\telse:\n\t\t\tquery = sample[0]\n\t\t\tcount = zip(y_score, y_true)\n\t\t\tcount.sort(key = lambda x:x[0], reverse=True)\n\t\t\tranks = []\n\t\t\tcorrect = 0\n\t\t\tfor idx_, item in enumerate(count):\n\t\t\t\tif item[1] == 1:\n\t\t\t\t\tcorrect +=  1\n\t\t\t\t\tranks.append(correct/(1.0+idx_))\n\t\t\t\t\t#break\n\t\t\tif len(ranks) ==0:\n\t\t\t\taps.append(0)\n\t\t\telse:\n\t\t\t\taps.append(np.mean(ranks))\n\t\t\t#print np.mean(ranks)\n\t\t\t# if len(aps) % 10 == 0:\n\t\t\t# \tprint 'How many queries:', len(aps)\n\t\t\t# \tprint np.mean(aps)\n\t\t\ty_true = []\n\t\t\ty_score = []\n\t\t\tfeatures = []\n\t\t\tfor path in named_paths:\n\t\t\t\tfeatures.append(int(bfs_two(sample[0], sample[1], path, kb, kb_inv)))\n\n\t\t\t#features = features*path_weights\n\t\t\t#score = np.inner(features, path_weights)\n\t\t\t#score = np.sum(features)\n\t\t\tscore = model.predict(np.reshape(features,[1,-1]))\n\n\t\t\tscore_all.append(score[0])\n\t\t\ty_score.append(score)\n\t\t\ty_true.append(test_labels[idx])\n\t\t\t# print y_score, y_true\n\n\tcount = zip(y_score, y_true)\n\tcount.sort(key = lambda x:x[0], reverse=True)\n\tranks = []\n\tcorrect = 0\n\tfor idx_, item in enumerate(count):\n\t\tif item[1] == 1:\n\t\t\tcorrect +=  1\n\t\t\tranks.append(correct/(1.0+idx_))\n\taps.append(np.mean(ranks))\n\n\tscore_label = zip(score_all, test_labels)\n\tscore_label_ranked = sorted(score_label, key = lambda x:x[0], reverse=True)\n\n\tmean_ap = np.mean(aps)\n\tprint 'RL MAP: ', mean_ap\n\n\ndef bfs_two(e1,e2,path,kb,kb_inv):\n\t'''the bidirectional search for reasoning'''\n\tstart = 0\n\tend = len(path)\n\tleft = set()\n\tright = set()\n\tleft.add(e1)\n\tright.add(e2)\n\n\tleft_path = []\n\tright_path = []\n\twhile(start < end):\n\t\tleft_step = path[start]\n\t\tleft_next = set()\n\t\tright_step = path[end-1]\n\t\tright_next = set()\n\n\t\tif len(left) < len(right):\n\t\t\tleft_path.append(left_step)\n\t\t\tstart += 1\n\t\t\t#print 'left',start\n\t\t\t# for triple in kb:\n\t\t\t# \tif triple[2] == left_step and triple[0] in left:\n\t\t\t# \t\tleft_next.add(triple[1])\n\t\t\t# left = left_next\n\t\t\tfor entity in left:\n\t\t\t\ttry:\n\t\t\t\t\tfor path_ in kb.getPathsFrom(entity):\n\t\t\t\t\t\tif path_.relation == left_step:\n\t\t\t\t\t\t\tleft_next.add(path_.connected_entity)\n\t\t\t\texcept Exception as e:\n\t\t\t\t\t# print 'left', len(left)\n\t\t\t\t\t# print left\n\t\t\t\t\t# print 'not such entity'\n\t\t\t\t\treturn False\n\t\t\tleft = left_next\n\n\t\telse: \n\t\t\tright_path.append(right_step)\n\t\t\tend -= 1\n\t\t\tfor entity in right:\n\t\t\t\ttry:\n\t\t\t\t\tfor path_ in kb_inv.getPathsFrom(entity):\n\t\t\t\t\t\tif path_.relation == right_step:\n\t\t\t\t\t\t\tright_next.add(path_.connected_entity)\n\t\t\t\texcept Exception as e:\n\t\t\t\t\t# print 'right', len(right)\n\t\t\t\t\t# print 'no such entity'\n\t\t\t\t\treturn False\n\t\t\tright = right_next\n\n\tif len(right & left) != 0:\n\t\treturn True \n\treturn False\n\n\nif __name__ == '__main__':\n\tevaluate_logic()\n\n\n"""
scripts/fact_prediction_eval.py,3,"b'#!/usr/bin/python\n\nimport numpy as np \nimport sys\nfrom BFS.KB import *\n\nrelation = sys.argv[1]\n\ndataPath_ = \'../NELL-995/tasks/\'  + relation\nfeaturePath = dataPath_ + \'/path_to_use.txt\'\nfeature_stats = dataPath_ + \'/path_stats.txt\'\nrelationId_path =\'../NELL-995/\' + \'relation2id.txt\'\nent_id_path = \'../NELL-995/\' + \'entity2id.txt\'\nrel_id_path = \'../NELL-995/\' + \'relation2id.txt\'\ntest_data_path = \'../NELL-995/tasks/\'  + relation + \'/sort_test.pairs\'\n\ndef bfs_two(e1,e2,path,kb,kb_inv):\n\tstart = 0\n\tend = len(path)\n\tleft = set()\n\tright = set()\n\tleft.add(e1)\n\tright.add(e2)\n\n\tleft_path = []\n\tright_path = []\n\twhile(start < end):\n\t\tleft_step = path[start]\n\t\tleft_next = set()\n\t\tright_step = path[end-1]\n\t\tright_next = set()\n\n\t\tif len(left) < len(right):\n\t\t\tleft_path.append(left_step)\n\t\t\tstart += 1\n\t\t\tfor entity in left:\n\t\t\t\ttry:\n\t\t\t\t\tfor path_ in kb.getPathsFrom(entity):\n\t\t\t\t\t\tif path_.relation == left_step:\n\t\t\t\t\t\t\tleft_next.add(path_.connected_entity)\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tprint \'left\', len(left)\n\t\t\t\t\tprint left\n\t\t\t\t\tprint \'not such entity\'\n\t\t\t\t\treturn False\n\t\t\tleft = left_next\n\n\t\telse: \n\t\t\tright_path.append(right_step)\n\t\t\tend -= 1\n\t\t\tfor entity in right:\n\t\t\t\ttry:\n\t\t\t\t\tfor path_ in kb_inv.getPathsFrom(entity):\n\t\t\t\t\t\tif path_.relation == right_step:\n\t\t\t\t\t\t\tright_next.add(path_.connected_entity)\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tprint \'right\', len(right)\n\t\t\t\t\tprint \'no such entity\'\n\t\t\t\t\treturn False\n\t\t\tright = right_next\n\n\tif len(right & left) != 0:\n\t\treturn True \n\treturn False\n\treturn False\n\ndef get_features():\n\tstats = {}\n\tf = open(feature_stats)\n\tpath_freq = f.readlines()\n\tf.close()\n\tfor line in path_freq:\n\t\tpath = line.split(\'\\t\')[0]\n\t\tnum = int(line.split(\'\\t\')[1])\n\t\tstats[path] = num\n\tmax_freq = np.max(stats.values())\n\n\trelation2id = {}\n\tf = open(relationId_path)\n\tcontent = f.readlines()\n\tf.close()\n\tfor line in content:\n\t\trelation2id[line.split()[0]] = int(line.split()[1])\n\n\tuseful_paths = []\n\tnamed_paths = []\n\tf = open(featurePath)\n\tpaths = f.readlines()\n\tf.close()\n\n\tfor line in paths:\n\t\tpath = line.rstrip()\n\n\t\tif path not in stats:\n\t\t\tcontinue\n\t\telif max_freq > 1 and stats[path] < 2:\n\t\t\tcontinue\n\n\t\tlength = len(path.split(\' -> \'))\n\n\t\tif length <= 10:\n\t\t\tpathIndex = []\n\t\t\tpathName = []\n\t\t\trelations = path.split(\' -> \')\n\n\t\t\tfor rel in relations:\n\t\t\t\tpathName.append(rel)\n\t\t\t\trel_id = relation2id[rel]\n\t\t\t\tpathIndex.append(rel_id)\n\t\t\tuseful_paths.append(pathIndex)\n\t\t\tnamed_paths.append(pathName)\n\n\tprint \'How many paths used: \', len(useful_paths)\n\treturn useful_paths, named_paths\n\nf1 = open(ent_id_path)\nf2 = open(rel_id_path)\ncontent1 = f1.readlines()\ncontent2 = f2.readlines()\nf1.close()\nf2.close()\n\nentity2id = {}\nrelation2id = {}\nfor line in content1:\n\tentity2id[line.split()[0]] = int(line.split()[1])\n\nfor line in content2:\n\trelation2id[line.split()[0]] = int(line.split()[1])\n\nent_vec_E = np.loadtxt(dataPath_ + \'/entity2vec.unif\')\nrel_vec_E = np.loadtxt(dataPath_ + \'/relation2vec.unif\')\nrel = relation.replace(""_"", "":"")\nrelation_vec_E = rel_vec_E[relation2id[rel],:]\n\nent_vec_R = np.loadtxt(dataPath_ + \'/entity2vec.bern\')\nrel_vec_R = np.loadtxt(dataPath_ + \'/relation2vec.bern\')\nM = np.loadtxt(dataPath_ + \'/A.bern\')\nM = M.reshape([-1,50,50])\nrelation_vec_R = rel_vec_R[relation2id[rel],:]\nM_vec = M[relation2id[rel],:,:]\n\n_, named_paths = get_features()\npath_weights = []\nfor path in named_paths:\n\tweight = 1.0/len(path)\n\tpath_weights.append(weight)\npath_weights = np.array(path_weights)\nkb = KB()\nkb_inv = KB()\n\nf = open(dataPath_ + \'/graph.txt\')\nkb_lines = f.readlines()\nf.close()\n\nfor line in kb_lines:\n\te1 = line.split()[0]\n\trel = line.split()[1]\n\te2 = line.split()[2]\n\tkb.addRelation(e1,rel,e2)\n\tkb_inv.addRelation(e2,rel,e1)\n\nf = open(test_data_path)\ntest_data = f.readlines()\nf.close()\ntest_pairs = []\ntest_labels = []\ntest_set = set()\nfor line in test_data:\n\te1 = line.split(\',\')[0].replace(\'thing$\',\'\')\n\t#e1 = \'/\' + e1[0] + \'/\' + e1[2:]\n\te2 = line.split(\',\')[1].split(\':\')[0].replace(\'thing$\',\'\')\n\t#e2 = \'/\' + e2[0] + \'/\' + e2[2:]\n\t#if (e1 not in kb.entities) or (e2 not in kb.entities):\n\t#\tcontinue\n\ttest_pairs.append((e1,e2))\n\tlabel = 1 if line[-2] == \'+\' else 0\n\ttest_labels.append(label)\n\n\nscores_E = []\nscores_R = []\nscores_rl = []\n\nprint \'How many queries: \', len(test_pairs)\nfor idx, sample in enumerate(test_pairs):\n\tprint \'Query No.%d of %d\' % (idx, len(test_pairs))\n\te1_vec_E = ent_vec_E[entity2id[sample[0]],:]\n\te2_vec_E = ent_vec_E[entity2id[sample[1]],:]\n\tscore_E = -np.sum(np.square(e1_vec_E + relation_vec_E - e2_vec_E))\n\tscores_E.append(score_E)\n\n\te1_vec_R = ent_vec_R[entity2id[sample[0]],:]\n\te2_vec_R = ent_vec_R[entity2id[sample[1]],:]\n\te1_vec_rel = np.matmul(e1_vec_R, M_vec)\n\te2_vec_rel = np.matmul(e2_vec_R, M_vec)\n\tscore_R = -np.sum(np.square(e1_vec_rel + relation_vec_R - e2_vec_rel))\n\tscores_R.append(score_R)\n\n\tfeatures = []\n\tfor path in named_paths:\n\t\tfeatures.append(int(bfs_two(sample[0], sample[1], path, kb, kb_inv)))\n\t#features = features*path_weights\n\tscore_rl = sum(features)\n\tscores_rl.append(score_rl)\n\nrank_stats_E = zip(scores_E, test_labels)\nrank_stats_R = zip(scores_R, test_labels)\nrank_stats_rl = zip(scores_rl, test_labels)\nrank_stats_E.sort(key = lambda x:x[0], reverse=True)\nrank_stats_R.sort(key = lambda x:x[0], reverse=True)\nrank_stats_rl.sort(key = lambda x:x[0], reverse=True)\n\ncorrect = 0\nranks = []\nfor idx, item in enumerate(rank_stats_E):\n\tif item[1] == 1:\n\t\tcorrect += 1\n\t\tranks.append(correct/(1.0+idx))\nap1 = np.mean(ranks)\nprint \'TransE: \', ap1\n\ncorrect = 0\nranks = []\nfor idx, item in enumerate(rank_stats_R):\n\tif item[1] == 1:\n\t\tcorrect += 1\n\t\tranks.append(correct/(1.0+idx))\nap2 = np.mean(ranks)\nprint \'TransR: \', ap2\n\n\ncorrect = 0\nranks = []\nfor idx, item in enumerate(rank_stats_rl):\n\tif item[1] == 1:\n\t\tcorrect += 1\n\t\tranks.append(correct/(1.0+idx))\nap3 = np.mean(ranks)\nprint \'RL: \', ap3\n\nf1 = open(ent_id_path)\nf2 = open(rel_id_path)\ncontent1 = f1.readlines()\ncontent2 = f2.readlines()\nf1.close()\nf2.close()\n\nentity2id = {}\nrelation2id = {}\nfor line in content1:\n\tentity2id[line.split()[0]] = int(line.split()[1])\n\nfor line in content2:\n\trelation2id[line.split()[0]] = int(line.split()[1])\n\nent_vec = np.loadtxt(dataPath_ + \'/entity2vec.vec\')\nrel_vec = np.loadtxt(dataPath_ + \'/relation2vec.vec\')\nM = np.loadtxt(dataPath_ + \'/A.vec\')\nM = M.reshape([rel_vec.shape[0],-1])\n\nf = open(test_data_path)\ntest_data = f.readlines()\nf.close()\ntest_pairs = []\ntest_labels = []\n# queries = set()\nfor line in test_data:\n\te1 = line.split(\',\')[0].replace(\'thing$\',\'\')\n\t#e1 = \'/\' + e1[0] + \'/\' + e1[2:]\n\te2 = line.split(\',\')[1].split(\':\')[0].replace(\'thing$\',\'\')\n\t#e2 = \'/\' + e2[0] + \'/\' + e2[2:]\n\ttest_pairs.append((e1,e2))\n\tlabel = 1 if line[-2] == \'+\' else 0\n\ttest_labels.append(label)\n\nscore_all = []\nrel = relation.replace(""_"", "":"")\nd_r = np.expand_dims(rel_vec[relation2id[rel],:],1)\nw_r = np.expand_dims(M[relation2id[rel],:],1)\n\nfor idx, sample in enumerate(test_pairs):\n\t#print \'query node: \', sample[0], idx\n\th = np.expand_dims(ent_vec[entity2id[sample[0]],:],1)\n\tt = np.expand_dims(ent_vec[entity2id[sample[1]],:],1)\n\n\th_ = h - np.matmul(w_r.transpose(), h)*w_r\n\tt_ = t - np.matmul(w_r.transpose(), t)*w_r\n\n\tscore = -np.sum(np.square(h_ + d_r - t_))\n\tscore_all.append(score)\n\nscore_label = zip(score_all, test_labels)\nstats = sorted(score_label, key = lambda x:x[0], reverse=True)\n\ncorrect = 0\nranks = []\nfor idx, item in enumerate(stats):\n\tif item[1] == 1:\n\t\tcorrect += 1\n\t\tranks.append(correct/(1.0+idx))\nap4 = np.mean(ranks)\nprint \'TransH: \', ap4\n\nent_vec_D = np.loadtxt(dataPath_ + \'/entity2vec.vec_D\')\nrel_vec_D = np.loadtxt(dataPath_ + \'/relation2vec.vec_D\')\nM_D = np.loadtxt(dataPath_ + \'/A.vec_D\')\nent_num = ent_vec_D.shape[0]\nrel_num = rel_vec_D.shape[0]\nrel_tran = M_D[0:rel_num,:]\nent_tran = M_D[rel_num:,:]\ndim = ent_vec_D.shape[1]\n\nrel_id = relation2id[rel]\nr = np.expand_dims(rel_vec_D[rel_id,:], 1)\nr_p = np.expand_dims(rel_tran[rel_id,:], 1)\nscores_all_D = []\nfor idx, sample in enumerate(test_pairs):\n\th = np.expand_dims(ent_vec_D[entity2id[sample[0]],:], 1)\n\th_p = np.expand_dims(ent_tran[entity2id[sample[0]],:], 1)\n\tt = np.expand_dims(ent_vec_D[entity2id[sample[1]],:], 1)\n\tt_p = np.expand_dims(ent_tran[entity2id[sample[1]],:], 1)\n\tM_rh = np.matmul(r_p, h_p.transpose()) + np.identity(dim)\n\tM_rt = np.matmul(r_p, t_p.transpose()) + np.identity(dim)\n\tscore = - np.sum(np.square(M_rh.dot(h) + r - M_rt.dot(t)))\n\tscores_all_D.append(score)\n\nscore_label = zip(scores_all_D, test_labels)\nstats = sorted(score_label, key = lambda x:x[0], reverse=True)\n\ncorrect = 0\nranks = []\nfor idx, item in enumerate(stats):\n\tif item[1] == 1:\n\t\tcorrect += 1\n\t\tranks.append(correct/(1.0+idx))\nap5 = np.mean(ranks)\nprint \'TransD: \', ap5\n\n'"
scripts/networks.py,25,"b""import tensorflow as tf \n\ndef policy_nn(state, state_dim, action_dim, initializer):\n\tw1 = tf.get_variable('W1', [state_dim, 512], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\tb1 = tf.get_variable('b1', [512], initializer = tf.constant_initializer(0.0))\n\th1 = tf.nn.relu(tf.matmul(state, w1) + b1)\n\tw2 = tf.get_variable('w2', [512, 1024], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\tb2 = tf.get_variable('b2', [1024], initializer = tf.constant_initializer(0.0))\n\th2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n\tw3 = tf.get_variable('w3', [1024, action_dim], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\tb3 = tf.get_variable('b3', [action_dim], initializer = tf.constant_initializer(0.0))\n\taction_prob = tf.nn.softmax(tf.matmul(h2,w3) + b3)\n\treturn action_prob\n\ndef value_nn(state, state_dim, initializer):\n\tw1 = tf.get_variable('w1', [state_dim, 64], initializer = initializer)\n\tb1 = tf.get_variable('b1', [64], initializer = tf.constant_initializer(0.0))\n\th1 = tf.nn.relu(tf.matmul(state,w1) + b1)\n\tw2 = tf.get_variable('w2', [64,1], initializer = initializer)\n\tb2 = tf.get_variable('b2', [1], initializer = tf.constant_initializer(0.0))\n\tvalue_estimated = tf.matmul(h1, w2) + b2\n\treturn tf.squeeze(value_estimated)\n\ndef q_network(state, state_dim, action_space, initializer):\n\tw1 = tf.get_variable('w1', [state_dim, 128], initializer=initializer)\n\tb1 = tf.get_variable('b1', [128], initializer = tf.constant_initializer(0))\n\th1 = tf.nn.relu(tf.matmul(state, w1) + b1)\n\tw2 = tf.get_variable('w2', [128, 64], initializer = initializer)\n\tb2 = tf.get_variable('b2', [64], initializer = tf.constant_initializer(0))\n\th2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n\tw3 = tf.get_variable('w3', [64, action_space], initializer = initializer)\n\tb3 = tf.get_variable('b3', [action_space], initializer = tf.constant_initializer(0))\n\taction_values = tf.matmul(h2, w3) + b3\n\treturn [w1,b1,w2,b2,w3,b3,action_values]\n"""
scripts/policy_agent.py,23,"b'from __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport collections\nfrom itertools import count\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport time\nimport sys\n\nfrom networks import policy_nn, value_nn\nfrom utils import *\nfrom env import Env\n\n\nrelation = sys.argv[1]\ntask = sys.argv[2]\ngraphpath = dataPath + \'tasks/\' + relation + \'/\' + \'graph.txt\'\nrelationPath = dataPath + \'tasks/\' + relation + \'/\' + \'train_pos\'\n\nclass PolicyNetwork(object):\n\n\tdef __init__(self, scope = \'policy_network\', learning_rate = 0.001):\n\t\tself.initializer = tf.contrib.layers.xavier_initializer()\n\t\twith tf.variable_scope(scope):\n\t\t\tself.state = tf.placeholder(tf.float32, [None, state_dim], name = \'state\')\n\t\t\tself.action = tf.placeholder(tf.int32, [None], name = \'action\')\n\t\t\tself.target = tf.placeholder(tf.float32, name = \'target\')\n\t\t\tself.action_prob = policy_nn(self.state, state_dim, action_space, self.initializer)\n\n\t\t\taction_mask = tf.cast(tf.one_hot(self.action, depth = action_space), tf.bool)\n\t\t\tself.picked_action_prob = tf.boolean_mask(self.action_prob, action_mask)\n\n\t\t\tself.loss = tf.reduce_sum(-tf.log(self.picked_action_prob)*self.target) + sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=scope))\n\t\t\tself.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n\t\t\tself.train_op = self.optimizer.minimize(self.loss)\n\n\tdef predict(self, state, sess = None):\n\t\tsess = sess or tf.get_default_session()\n\t\treturn sess.run(self.action_prob, {self.state:state})\n\n\tdef update(self, state, target, action, sess=None):\n\t\tsess = sess or tf.get_default_session()\n\t\tfeed_dict = { self.state: state, self.target: target, self.action: action  }\n\t\t_, loss = sess.run([self.train_op, self.loss], feed_dict)\n\t\treturn loss\n\n\ndef REINFORCE(training_pairs, policy_nn, num_episodes):\n\ttrain = training_pairs\n\n\tsuccess = 0\n\n\t# path_found = set()\n\tpath_found_entity = []\n\tpath_relation_found = []\n\n\tfor i_episode in range(num_episodes):\n\t\tstart = time.time()\n\t\tprint(\'Episode %d\' % i_episode)\n\t\tprint(\'Training sample: \', train[i_episode][:-1])\n\n\t\tenv = Env(dataPath, train[i_episode])\n\n\t\tsample = train[i_episode].split()\n\t\tstate_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n\n\t\tepisode = []\n\t\tstate_batch_negative = []\n\t\taction_batch_negative = []\n\t\tfor t in count():\n\t\t\tstate_vec = env.idx_state(state_idx)\n\t\t\taction_probs = policy_nn.predict(state_vec)\n\t\t\taction_chosen = np.random.choice(np.arange(action_space), p = np.squeeze(action_probs))\n\t\t\treward, new_state, done = env.interact(state_idx, action_chosen)\n\n\t\t\tif reward == -1: # the action fails for this step\n\t\t\t\tstate_batch_negative.append(state_vec)\n\t\t\t\taction_batch_negative.append(action_chosen)\n\n\t\t\tnew_state_vec = env.idx_state(new_state)\n\t\t\tepisode.append(Transition(state = state_vec, action = action_chosen, next_state = new_state_vec, reward = reward))\n\n\t\t\tif done or t == max_steps:\n\t\t\t\tbreak\n\n\t\t\tstate_idx = new_state\n\n\t\t# Discourage the agent when it choose an invalid step\n\t\tif len(state_batch_negative) != 0:\n\t\t\tprint(\'Penalty to invalid steps:\', len(state_batch_negative))\n\t\t\tpolicy_nn.update(np.reshape(state_batch_negative, (-1, state_dim)), -0.05, action_batch_negative)\n\n\t\tprint(\'----- FINAL PATH -----\')\n\t\tprint(\'\\t\'.join(env.path))\n\t\tprint(\'PATH LENGTH\', len(env.path))\n\t\tprint(\'----- FINAL PATH -----\')\n\n\t\t# If the agent success, do one optimization\n\t\tif done == 1:\n\t\t\tprint(\'Success\')\n\n\t\t\tpath_found_entity.append(path_clean(\' -> \'.join(env.path)))\n\n\t\t\tsuccess += 1\n\t\t\tpath_length = len(env.path)\n\t\t\tlength_reward = 1/path_length\n\t\t\tglobal_reward = 1\n\t\t\t\n\t\t\t# if len(path_found) != 0:\n\t\t\t# \tpath_found_embedding = [env.path_embedding(path.split(\' -> \')) for path in path_found]\n\t\t\t# \tcurr_path_embedding = env.path_embedding(env.path_relations)\n\t\t\t# \tpath_found_embedding = np.reshape(path_found_embedding, (-1,embedding_dim))\n\t\t\t# \tcos_sim = cosine_similarity(path_found_embedding, curr_path_embedding)\n\t\t\t# \tdiverse_reward = -np.mean(cos_sim)\n\t\t\t# \tprint \'diverse_reward\', diverse_reward\n\t\t\t# \ttotal_reward = 0.1*global_reward + 0.8*length_reward + 0.1*diverse_reward \n\t\t\t# else:\n\t\t\t# \ttotal_reward = 0.1*global_reward + 0.9*length_reward\n\t\t\t# path_found.add(\' -> \'.join(env.path_relations))\n\t\t\t\n\t\t\ttotal_reward = 0.1*global_reward + 0.9*length_reward\n\t\t\tstate_batch = []\n\t\t\taction_batch = []\n\t\t\tfor t, transition in enumerate(episode):\n\t\t\t\tif transition.reward == 0:\n\t\t\t\t\tstate_batch.append(transition.state)\n\t\t\t\t\taction_batch.append(transition.action)\n\t\t\tpolicy_nn.update(np.reshape(state_batch,(-1,state_dim)), total_reward, action_batch)\n\t\telse:\n\t\t\tglobal_reward = -0.05\n\t\t\t# length_reward = 1/len(env.path)\n\n\t\t\tstate_batch = []\n\t\t\taction_batch = []\n\t\t\ttotal_reward = global_reward\n\t\t\tfor t, transition in enumerate(episode):\n\t\t\t\tif transition.reward == 0:\n\t\t\t\t\tstate_batch.append(transition.state)\n\t\t\t\t\taction_batch.append(transition.action)\n\t\t\tpolicy_nn.update(np.reshape(state_batch, (-1,state_dim)), total_reward, action_batch)\n\n\t\t\tprint(\'Failed, Do one teacher guideline\')\n\t\t\ttry:\n\t\t\t\tgood_episodes = teacher(sample[0], sample[1], 1, env, graphpath)\n\t\t\t\tfor item in good_episodes:\n\t\t\t\t\tteacher_state_batch = []\n\t\t\t\t\tteacher_action_batch = []\n\t\t\t\t\ttotal_reward = 0.0*1 + 1*1/len(item)\n\t\t\t\t\tfor t, transition in enumerate(item):\n\t\t\t\t\t\tteacher_state_batch.append(transition.state)\n\t\t\t\t\t\tteacher_action_batch.append(transition.action)\n\t\t\t\t\tpolicy_nn.update(np.squeeze(teacher_state_batch), 1, teacher_action_batch)\n\n\t\t\texcept Exception as e:\n\t\t\t\tprint(\'Teacher guideline failed\')\n\t\tprint(\'Episode time: \', time.time() - start)\n\t\tprint(\'\\n\')\n\tprint(\'Success percentage:\', success/num_episodes)\n\n\tfor path in path_found_entity:\n\t\trel_ent = path.split(\' -> \')\n\t\tpath_relation = []\n\t\tfor idx, item in enumerate(rel_ent):\n\t\t\tif idx%2 == 0:\n\t\t\t\tpath_relation.append(item)\n\t\tpath_relation_found.append(\' -> \'.join(path_relation))\n\n\trelation_path_stats = collections.Counter(path_relation_found).items()\n\trelation_path_stats = sorted(relation_path_stats, key = lambda x:x[1], reverse=True)\n\n\tf = open(dataPath + \'tasks/\' + relation + \'/\' + \'path_stats.txt\', \'w\')\n\tfor item in relation_path_stats:\n\t\tf.write(item[0]+\'\\t\'+str(item[1])+\'\\n\')\n\tf.close()\n\tprint(\'Path stats saved\')\n\n\treturn \n\ndef retrain():\n\tprint(\'Start retraining\')\n\ttf.reset_default_graph()\n\tpolicy_network = PolicyNetwork(scope = \'supervised_policy\')\n\n\tf = open(relationPath)\n\ttraining_pairs = f.readlines()\n\tf.close()\n\n\tsaver = tf.train.Saver()\n\twith tf.Session() as sess:\n\t\tsaver.restore(sess, \'models/policy_supervised_\' + relation)\n\t\tprint(""sl_policy restored"")\n\t\tepisodes = len(training_pairs)\n\t\tif episodes > 300:\n\t\t\tepisodes = 300\n\t\tREINFORCE(training_pairs, policy_network, episodes)\n\t\tsaver.save(sess, \'models/policy_retrained\' + relation)\n\tprint(\'Retrained model saved\')\n\ndef test():\n\ttf.reset_default_graph()\n\tpolicy_network = PolicyNetwork(scope = \'supervised_policy\')\n\n\tf = open(relationPath)\n\tall_data = f.readlines()\n\tf.close()\n\n\ttest_data = all_data\n\ttest_num = len(test_data)\n\n\tsuccess = 0\n\n\tsaver = tf.train.Saver()\n\tpath_found = []\n\tpath_relation_found = []\n\tpath_set = set()\n\n\twith tf.Session() as sess:\n\t\tsaver.restore(sess, \'models/policy_retrained\' + relation)\n\t\tprint(\'Model reloaded\')\n\n\t\tif test_num > 500:\n\t\t\ttest_num = 500\n\n\t\tfor episode in range(test_num):\n\t\t\tprint(\'Test sample %d: %s\' % (episode,test_data[episode][:-1]))\n\t\t\tenv = Env(dataPath, test_data[episode])\n\t\t\tsample = test_data[episode].split()\n\t\t\tstate_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n\n\t\t\ttransitions = []\n\n\t\t\tfor t in count():\n\t\t\t\tstate_vec = env.idx_state(state_idx)\n\t\t\t\taction_probs = policy_network.predict(state_vec)\n\n\t\t\t\taction_probs = np.squeeze(action_probs)\n\n\t\t\t\taction_chosen = np.random.choice(np.arange(action_space), p = action_probs)\n\t\t\t\treward, new_state, done = env.interact(state_idx, action_chosen)\n\t\t\t\tnew_state_vec = env.idx_state(new_state)\n\t\t\t\ttransitions.append(Transition(state = state_vec, action = action_chosen, next_state = new_state_vec, reward = reward))\n\n\t\t\t\tif done or t == max_steps_test:\n\t\t\t\t\tif done:\n\t\t\t\t\t\tsuccess += 1\n\t\t\t\t\t\tprint(""Success\\n"")\n\t\t\t\t\t\tpath = path_clean(\' -> \'.join(env.path))\n\t\t\t\t\t\tpath_found.append(path)\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint(\'Episode ends due to step limit\\n\')\n\t\t\t\t\tbreak\n\t\t\t\tstate_idx = new_state\n\t\t\t\n\t\t\tif done:\n\t\t\t\tif len(path_set) != 0:\n\t\t\t\t\tpath_found_embedding = [env.path_embedding(path.split(\' -> \')) for path in path_set]\n\t\t\t\t\tcurr_path_embedding = env.path_embedding(env.path_relations)\n\t\t\t\t\tpath_found_embedding = np.reshape(path_found_embedding, (-1,embedding_dim))\n\t\t\t\t\tcos_sim = cosine_similarity(path_found_embedding, curr_path_embedding)\n\t\t\t\t\tdiverse_reward = -np.mean(cos_sim)\n\t\t\t\t\tprint(\'diverse_reward\', diverse_reward)\n\t\t\t\t\t#total_reward = 0.1*global_reward + 0.8*length_reward + 0.1*diverse_reward \n\t\t\t\t\tstate_batch = []\n\t\t\t\t\taction_batch = []\n\t\t\t\t\tfor t, transition in enumerate(transitions):\n\t\t\t\t\t\tif transition.reward == 0:\n\t\t\t\t\t\t\tstate_batch.append(transition.state)\n\t\t\t\t\t\t\taction_batch.append(transition.action)\n\t\t\t\t\tpolicy_network.update(np.reshape(state_batch,(-1,state_dim)), 0.1*diverse_reward, action_batch)\n\t\t\t\tpath_set.add(\' -> \'.join(env.path_relations))\n\n\n\tfor path in path_found:\n\t\trel_ent = path.split(\' -> \')\n\t\tpath_relation = []\n\t\tfor idx, item in enumerate(rel_ent):\n\t\t\tif idx%2 == 0:\n\t\t\t\tpath_relation.append(item)\n\t\tpath_relation_found.append(\' -> \'.join(path_relation))\n\n\t# path_stats = collections.Counter(path_found).items()\n\trelation_path_stats = collections.Counter(path_relation_found).items()\n\trelation_path_stats = sorted(relation_path_stats, key = lambda x:x[1], reverse=True)\n\n\tranking_path = []\n\tfor item in relation_path_stats:\n\t\tpath = item[0]\n\t\tlength = len(path.split(\' -> \'))\n\t\tranking_path.append((path, length))\n\n\tranking_path = sorted(ranking_path, key = lambda x:x[1])\n\tprint(\'Success persentage:\', success/test_num)\n\n\tf = open(dataPath + \'tasks/\' + relation + \'/\' + \'path_to_use.txt\', \'w\')\n\tfor item in ranking_path:\n\t\tf.write(item[0] + \'\\n\')\n\tf.close()\n\tprint(\'path to use saved\')\n\treturn\n\nif __name__ == ""__main__"":\n\tif task == \'test\':\n\t\ttest()\n\telif task == \'retrain\':\n\t\tretrain()\n\telse:\n\t\tretrain()\n\t\ttest()\n\t# retrain()\t\n\n\n\n'"
scripts/sl_policy.py,19,"b'from __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf \nimport numpy as np\nfrom itertools import count\nimport sys\n\nfrom networks import policy_nn\nfrom utils import *\nfrom env import Env\nfrom BFS.KB import KB\nfrom BFS.BFS import BFS\nimport time\n\nrelation = sys.argv[1]\n# episodes = int(sys.argv[2])\ngraphpath = dataPath + \'tasks/\' + relation + \'/\' + \'graph.txt\'\nrelationPath = dataPath + \'tasks/\' + relation + \'/\' + \'train_pos\'\n\nclass SupervisedPolicy(object):\n\t""""""docstring for SupervisedPolicy""""""\n\tdef __init__(self, learning_rate = 0.001):\n\t\tself.initializer = tf.contrib.layers.xavier_initializer()\n\t\twith tf.variable_scope(\'supervised_policy\'):\n\t\t\tself.state = tf.placeholder(tf.float32, [None, state_dim], name = \'state\')\n\t\t\tself.action = tf.placeholder(tf.int32, [None], name = \'action\')\n\t\t\tself.action_prob = policy_nn(self.state, state_dim, action_space, self.initializer)\n\n\t\t\taction_mask = tf.cast(tf.one_hot(self.action, depth = action_space), tf.bool)\n\t\t\tself.picked_action_prob = tf.boolean_mask(self.action_prob, action_mask)\n\n\t\t\tself.loss = tf.reduce_sum(-tf.log(self.picked_action_prob)) + sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope = \'supervised_policy\'))\n\t\t\tself.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n\t\t\tself.train_op = self.optimizer.minimize(self.loss)\n\n\tdef predict(self, state, sess = None):\n\t\tsess = sess or tf.get_default_session()\n\t\treturn sess.run(self.action_prob, {self.state: state})\n\n\tdef update(self, state, action, sess = None):\n\t\tsess = sess or tf.get_default_session()\n\t\t_, loss = sess.run([self.train_op, self.loss], {self.state: state, self.action: action})\n\t\treturn loss\n\ndef train():\n\ttf.reset_default_graph()\n\tpolicy_nn = SupervisedPolicy()\n\n\tf = open(relationPath)\n\ttrain_data = f.readlines()\n\tf.close()\n\n\tnum_samples = len(train_data)\n\n\tsaver = tf.train.Saver()\n\twith tf.Session() as sess:\n\t\tsess.run(tf.global_variables_initializer())\n\t\tif num_samples > 500:\n\t\t\tnum_samples = 500\n\t\telse:\n\t\t\tnum_episodes = num_samples\n\n\t\tfor episode in range(num_samples):\n\t\t\tprint(""Episode %d"" % episode)\n\t\t\tprint(\'Training Sample:\', train_data[episode%num_samples][:-1])\n\n\t\t\tenv = Env(dataPath, train_data[episode%num_samples])\n\t\t\tsample = train_data[episode%num_samples].split()\n\n\t\t\ttry:\n\t\t\t\tgood_episodes = teacher(sample[0], sample[1], 5, env, graphpath)\n\t\t\texcept Exception as e:\n\t\t\t\tprint(\'Cannot find a path\')\n\t\t\t\tcontinue\n\n\t\t\tfor item in good_episodes:\n\t\t\t\tstate_batch = []\n\t\t\t\taction_batch = []\n\t\t\t\tfor t, transition in enumerate(item):\n\t\t\t\t\tstate_batch.append(transition.state)\n\t\t\t\t\taction_batch.append(transition.action)\n\t\t\t\tstate_batch = np.squeeze(state_batch)\n\t\t\t\tstate_batch = np.reshape(state_batch, [-1, state_dim])\n\t\t\t\tpolicy_nn.update(state_batch, action_batch)\n\n\t\tsaver.save(sess, \'models/policy_supervised_\' + relation)\n\t\tprint(\'Model saved\')\n\n\ndef test(test_episodes):\n\ttf.reset_default_graph()\n\tpolicy_nn = SupervisedPolicy()\n\n\tf = open(relationPath)\n\ttest_data = f.readlines()\n\tf.close()\n\n\ttest_num = len(test_data)\n\n\ttest_data = test_data[-test_episodes:]\n\tprint(len(test_data))\n\t\n\tsuccess = 0\n\n\tsaver = tf.train.Saver()\n\twith tf.Session() as sess:\n\t\tsaver.restore(sess, \'models/policy_supervised_\'+ relation)\n\t\tprint(\'Model reloaded\')\n\t\tfor episode in range(len(test_data)):\n\t\t\tprint(\'Test sample %d: %s\' % (episode,test_data[episode][:-1]))\n\t\t\tenv = Env(dataPath, test_data[episode])\n\t\t\tsample = test_data[episode].split()\n\t\t\tstate_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n\t\t\tfor t in count():\n\t\t\t\tstate_vec = env.idx_state(state_idx)\n\t\t\t\taction_probs = policy_nn.predict(state_vec)\n\t\t\t\taction_chosen = np.random.choice(np.arange(action_space), p = np.squeeze(action_probs))\n\t\t\t\treward, new_state, done = env.interact(state_idx, action_chosen)\n\t\t\t\tif done or t == max_steps_test:\n\t\t\t\t\tif done:\n\t\t\t\t\t\tprint(\'Success\')\n\t\t\t\t\t\tsuccess += 1\n\t\t\t\t\tprint(\'Episode ends\\n\')\n\t\t\t\t\tbreak\n\t\t\t\tstate_idx = new_state\n\n\tprint(\'Success persentage:\', success/test_episodes)\n\nif __name__ == ""__main__"":\n\ttrain()\n\t# test(50)\n\n'"
scripts/transE_eval.py,0,"b'import cPickle\nimport sys\nimport numpy as np\n\nrelation = sys.argv[1]\n\ndataPath_ = \'../NELL-995/tasks/\'  + relation\n\nent_id_path = \'../NELL-995/\' + \'entity2id.txt\'\nrel_id_path = \'../NELL-995/\' + \'relation2id.txt\'\ntest_data_path = \'../NELL-995/tasks/\'  + relation + \'/sort_test.pairs\'\n\nf1 = open(ent_id_path)\nf2 = open(rel_id_path)\ncontent1 = f1.readlines()\ncontent2 = f2.readlines()\nf1.close()\nf2.close()\n\nentity2id = {}\nrelation2id = {}\nfor line in content1:\n\tentity2id[line.split()[0]] = int(line.split()[1])\n\nfor line in content2:\n\trelation2id[line.split()[0]] = int(line.split()[1])\n\n\nent_vec = np.loadtxt(dataPath_ + \'/entity2vec.unif\')\nrel_vec = np.loadtxt(dataPath_ + \'/relation2vec.unif\')\n\nf = open(test_data_path)\ntest_data = f.readlines()\nf.close()\n\ntest_pairs = []\ntest_labels = []\n# queries = set()\nfor line in test_data:\n\te1 = line.split(\',\')[0].replace(\'thing$\',\'\')\n\t#e1 = \'/\' + e1[0] + \'/\' + e1[2:]\n\te2 = line.split(\',\')[1].split(\':\')[0].replace(\'thing$\',\'\')\n\t#e2 = \'/\' + e2[0] + \'/\' + e2[2:]\n\ttest_pairs.append((e1,e2))\n\tlabel = 1 if line[-2] == \'+\' else 0\n\ttest_labels.append(label)\n\n\naps = []\nquery = test_pairs[0][0]\ny_true = []\ny_score = []\nquery_samples = []\n\nscore_all = []\n\nrel = relation.replace(""_"", "":"")\nrelation_vec = rel_vec[relation2id[rel],:]\n\n\nfor idx, sample in enumerate(test_pairs):\n\tif sample[0] == query:\n\t\te1_vec = ent_vec[entity2id[sample[0]],:]\n\t\te2_vec = ent_vec[entity2id[sample[1]],:]\n\t\tscore = -np.sum(np.square(e1_vec + relation_vec - e2_vec))\n\t\tscore_all.append(score)\n\t\ty_score.append(score)\n\t\ty_true.append(test_labels[idx])\n\t\tquery_samples.append(sample)\n\telse:\n\t\tquery = sample[0]\n\t\tcount = zip(y_score, y_true, query_samples)\n\t\tcount.sort(key = lambda x:x[0], reverse=True)\n\n\t\tranks = []\n\t\tcorrect = 0\n\t\tfor idx_, item in enumerate(count):\n\t\t\tif item[1] == 1:\n\t\t\t\tcorrect +=  1\n\t\t\t\tranks.append(correct/(1.0+idx_))\n\t\tif len(ranks)==0:\n\t\t\tranks.append(0)\n\t\taps.append(np.mean(ranks))\n\t\t# if len(aps) % 10 == 0:\n\t\t\t# print \'How many queries:\', len(aps)\n\t\t\t# print np.mean(aps)\n\t\ty_true = []\n\t\ty_score = []\n\t\tquery_samples = []\n\t\te1_vec = ent_vec[entity2id[sample[0]],:]\n\t\te2_vec = ent_vec[entity2id[sample[1]],:]\n\n\t\tscore = -np.sum(np.square(e1_vec + relation_vec - e2_vec))\n\t\tscore_all.append(score)\n\t\ty_score.append(score)\n\t\ty_true.append(test_labels[idx])\n\t\tquery_samples.append(sample)\n\nscore_label = zip(score_all, test_labels)\nscore_label_ranked = sorted(score_label, key = lambda x:x[0], reverse=True)\n\n\nmean_ap = np.mean(aps)\nprint \'TransE MAP: \', mean_ap\n\n\n\n'"
scripts/transR_eval.py,0,"b'import cPickle\nimport sys\nimport numpy as np\n\nrelation = sys.argv[1]\n\ndataPath_ = \'../NELL-995/tasks/\'  + relation\n\nent_id_path = \'../NELL-995/\' + \'entity2id.txt\'\nrel_id_path = \'../NELL-995/\' + \'relation2id.txt\'\ntest_data_path = \'../NELL-995/tasks/\'  + relation + \'/sort_test.pairs\'\n\nf1 = open(ent_id_path)\nf2 = open(rel_id_path)\ncontent1 = f1.readlines()\ncontent2 = f2.readlines()\nf1.close()\nf2.close()\n\nentity2id = {}\nrelation2id = {}\nfor line in content1:\n\tentity2id[line.split()[0]] = int(line.split()[1])\n\nfor line in content2:\n\trelation2id[line.split()[0]] = int(line.split()[1])\n\n\nent_vec = np.loadtxt(dataPath_ + \'/entity2vec.bern\')\nrel_vec = np.loadtxt(dataPath_ + \'/relation2vec.bern\')\nM = np.loadtxt(dataPath_ + \'/A.bern\')\nM = M.reshape([-1,50,50])\n\nf = open(test_data_path)\ntest_data = f.readlines()\nf.close()\n\ntest_pairs = []\ntest_labels = []\n# queries = set()\nfor line in test_data:\n\te1 = line.split(\',\')[0].replace(\'thing$\',\'\')\n\t#e1 = \'/\' + e1[0] + \'/\' + e1[2:]\n\te2 = line.split(\',\')[1].split(\':\')[0].replace(\'thing$\',\'\')\n\t#e2 = \'/\' + e2[0] + \'/\' + e2[2:]\n\ttest_pairs.append((e1,e2))\n\tlabel = 1 if line[-2] == \'+\' else 0\n\ttest_labels.append(label)\n\n\naps = []\nquery = test_pairs[0][0]\ny_true = []\ny_score = []\n\nscore_all = []\n\nrel = relation.replace(""_"", "":"")\nrelation_vec = np.expand_dims(rel_vec[relation2id[rel],:],0)\nM_vec = M[relation2id[rel],:,:]\n\nfor idx, sample in enumerate(test_pairs):\n\t#print \'query node: \', sample[0], idx\n\tif sample[0] == query:\n\t\te1_vec = np.expand_dims(ent_vec[entity2id[sample[0]],:],0)\n\t\te2_vec = np.expand_dims(ent_vec[entity2id[sample[1]],:],0)\n\n\t\te1_vec_rel = np.matmul(e1_vec, M_vec)\n\t\te2_vec_rel = np.matmul(e2_vec, M_vec)\n\t\tscore = -np.sum(np.square(e1_vec_rel + relation_vec - e2_vec_rel))\n\n\t\tscore_all.append(score)\n\t\ty_score.append(score)\n\t\ty_true.append(test_labels[idx])\n\telse:\n\t\tquery = sample[0]\n\t\tcount = zip(y_score, y_true)\n\t\tcount.sort(key = lambda x:x[0], reverse=True)\n\t\t#print count\n\t\tranks = []\n\t\tcorrect = 0\n\t\tfor idx_, item in enumerate(count):\n\t\t\tif item[1] == 1:\n\t\t\t\tcorrect +=  1\n\t\t\t\tranks.append(correct/(1.0+idx_))\n\t\tif len(ranks)==0:\n\t\t\tranks.append(0)\n\t\taps.append(np.mean(ranks))\n\t\t# if len(aps) % 10 == 0:\n\t\t\t# print \'How many queries:\', len(aps)\n\t\t\t# print np.mean(aps)\n\t\ty_true = []\n\t\ty_score = []\n\n\t\te1_vec = np.expand_dims(ent_vec[entity2id[sample[0]],:],0)\n\t\te2_vec = np.expand_dims(ent_vec[entity2id[sample[1]],:],0)\n\t\te1_vec_rel = np.matmul(e1_vec, M_vec)\n\t\te2_vec_rel = np.matmul(e2_vec, M_vec)\n\t\tscore = -np.sum(np.square(e1_vec_rel + relation_vec - e2_vec_rel))\n\t\tscore_all.append(score)\n\t\ty_score.append(score)\n\t\ty_true.append(test_labels[idx])\n\n\nscore_label = zip(score_all, test_labels)\nscore_label_ranked = sorted(score_label, key = lambda x:x[0], reverse=True)\n\nmean_ap = np.mean(aps)\nprint \'TransR MAP: \', mean_ap\n\n\n'"
scripts/utils.py,1,"b""from __future__ import division\nfrom __future__ import print_function\nimport random\nfrom collections import namedtuple, Counter\nimport numpy as np\n\nfrom BFS.KB import KB\nfrom BFS.BFS import BFS\n\n# hyperparameters\nstate_dim = 200\naction_space = 400\neps_start = 1\neps_end = 0.1\nepe_decay = 1000\nreplay_memory_size = 10000\nbatch_size = 128\nembedding_dim = 100\ngamma = 0.99\ntarget_update_freq = 1000\nmax_steps = 50\nmax_steps_test = 50\n\ndataPath = '../NELL-995/'\n\nTransition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n\ndef distance(e1, e2):\n    return np.sqrt(np.sum(np.square(e1 - e2)))\n\ndef compare(v1, v2):\n    return sum(v1 == v2)\n\ndef teacher(e1, e2, num_paths, env, path = None):\n\tf = open(path)\n\tcontent = f.readlines()\n\tf.close()\n\tkb = KB()\n\tfor line in content:\n\t\tent1, rel, ent2 = line.rsplit()\n\t\tkb.addRelation(ent1, rel, ent2)\n\t# kb.removePath(e1, e2)\n\tintermediates = kb.pickRandomIntermediatesBetween(e1, e2, num_paths)\n\tres_entity_lists = []\n\tres_path_lists = []\n\tfor i in range(num_paths):\n\t\tsuc1, entity_list1, path_list1 = BFS(kb, e1, intermediates[i])\n\t\tsuc2, entity_list2, path_list2 = BFS(kb, intermediates[i], e2)\n\t\tif suc1 and suc2:\n\t\t\tres_entity_lists.append(entity_list1 + entity_list2[1:])\n\t\t\tres_path_lists.append(path_list1 + path_list2)\n\tprint('BFS found paths:', len(res_path_lists))\n\t\n\t# ---------- clean the path --------\n\tres_entity_lists_new = []\n\tres_path_lists_new = []\n\tfor entities, relations in zip(res_entity_lists, res_path_lists):\n\t\trel_ents = []\n\t\tfor i in range(len(entities)+len(relations)):\n\t\t\tif i%2 == 0:\n\t\t\t\trel_ents.append(entities[int(i/2)])\n\t\t\telse:\n\t\t\t\trel_ents.append(relations[int(i/2)])\n\n\t\t#print(rel_ents)\n\n\t\tentity_stats = Counter(entities).items()\n\t\tduplicate_ents = [item for item in entity_stats if item[1]!=1]\n\t\tduplicate_ents.sort(key = lambda x:x[1], reverse=True)\n\t\tfor item in duplicate_ents:\n\t\t\tent = item[0]\n\t\t\tent_idx = [i for i, x in enumerate(rel_ents) if x == ent]\n\t\t\tif len(ent_idx)!=0:\n\t\t\t\tmin_idx = min(ent_idx)\n\t\t\t\tmax_idx = max(ent_idx)\n\t\t\t\tif min_idx!=max_idx:\n\t\t\t\t\trel_ents = rel_ents[:min_idx] + rel_ents[max_idx:]\n\t\tentities_new = []\n\t\trelations_new = []\n\t\tfor idx, item in enumerate(rel_ents):\n\t\t\tif idx%2 == 0:\n\t\t\t\tentities_new.append(item)\n\t\t\telse:\n\t\t\t\trelations_new.append(item)\n\t\tres_entity_lists_new.append(entities_new)\n\t\tres_path_lists_new.append(relations_new)\n\t\n\tprint(res_entity_lists_new)\n\tprint(res_path_lists_new)\n\n\tgood_episodes = []\n\ttargetID = env.entity2id_[e2]\n\tfor path in zip(res_entity_lists_new, res_path_lists_new):\n\t\tgood_episode = []\n\t\tfor i in range(len(path[0]) -1):\n\t\t\tcurrID = env.entity2id_[path[0][i]]\n\t\t\tnextID = env.entity2id_[path[0][i+1]]\n\t\t\tstate_curr = [currID, targetID, 0]\n\t\t\tstate_next = [nextID, targetID, 0]\n\t\t\tactionID = env.relation2id_[path[1][i]]\n\t\t\tgood_episode.append(Transition(state = env.idx_state(state_curr), action = actionID, next_state = env.idx_state(state_next), reward = 1))\n\t\tgood_episodes.append(good_episode)\n\treturn good_episodes\n\ndef path_clean(path):\n\trel_ents = path.split(' -> ')\n\trelations = []\n\tentities = []\n\tfor idx, item in enumerate(rel_ents):\n\t\tif idx%2 == 0:\n\t\t\trelations.append(item)\n\t\telse:\n\t\t\tentities.append(item)\n\tentity_stats = Counter(entities).items()\n\tduplicate_ents = [item for item in entity_stats if item[1]!=1]\n\tduplicate_ents.sort(key = lambda x:x[1], reverse=True)\n\tfor item in duplicate_ents:\n\t\tent = item[0]\n\t\tent_idx = [i for i, x in enumerate(rel_ents) if x == ent]\n\t\tif len(ent_idx)!=0:\n\t\t\tmin_idx = min(ent_idx)\n\t\t\tmax_idx = max(ent_idx)\n\t\t\tif min_idx!=max_idx:\n\t\t\t\trel_ents = rel_ents[:min_idx] + rel_ents[max_idx:]\n\treturn ' -> '.join(rel_ents)\n\ndef prob_norm(probs):\n\treturn probs/sum(probs)\n\nif __name__ == '__main__':\n\tprint(prob_norm(np.array([1,1,1])))\n\t#path_clean('/common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/01d34b -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/0lfyx -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/01y67v -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/028qyn -> /people/person/nationality -> /m/09c7w0')\n\n\n\n\n\n"""
scripts/BFS/BFS.py,0,"b'try:\n    from Queue import Queue\nexcept ImportError:\n    from queue import Queue\nimport random\n\ndef BFS(kb, entity1, entity2):\n\tres = foundPaths(kb)\n\tres.markFound(entity1, None, None)\n\tq = Queue()\n\tq.put(entity1)\n\twhile(not q.empty()):\n\t\tcurNode = q.get()\n\t\tfor path in kb.getPathsFrom(curNode):\n\t\t\tnextEntity = path.connected_entity\n\t\t\tconnectRelation = path.relation\n\t\t\tif(not res.isFound(nextEntity)):\n\t\t\t\tq.put(nextEntity)\n\t\t\t\tres.markFound(nextEntity, curNode, connectRelation)\n\t\t\tif(nextEntity == entity2):\n\t\t\t\tentity_list, path_list = res.reconstructPath(entity1, entity2)\n\t\t\t\treturn (True, entity_list, path_list)\n\treturn (False, None, None)\n\ndef test():\n\tpass\n\nclass foundPaths(object):\n\tdef __init__(self, kb):\n\t\tself.entities = {}\n\t\tfor entity, relations in kb.entities.iteritems():\n\t\t\tself.entities[entity] = (False, """", """")\n\n\tdef isFound(self, entity):\n\t\treturn self.entities[entity][0]\n\t\t\t\n\n\tdef markFound(self, entity, prevNode, relation):\n\t\tself.entities[entity] = (True, prevNode, relation)\n\n\tdef reconstructPath(self, entity1, entity2):\n\t\tentity_list = []\n\t\tpath_list = []\n\t\tcurNode = entity2\n\t\twhile(curNode != entity1):\n\t\t\tentity_list.append(curNode)\n\n\t\t\tpath_list.append(self.entities[curNode][2])\n\t\t\tcurNode = self.entities[curNode][1]\n\t\tentity_list.append(curNode)\n\t\tentity_list.reverse()\n\t\tpath_list.reverse()\n\t\treturn (entity_list, path_list)\n\n\tdef __str__(self):\n\t\tres = """"\n\t\tfor entity, status in self.entities.iteritems():\n\t\t\tres += entity + ""[{},{},{}]"".format(status[0],status[1],status[2])\n\t\treturn res\t\t\t\n'"
scripts/BFS/KB.py,0,"b'class KB(object):\n\tdef __init__(self):\n\t\tself.entities = {}\n\n\tdef addRelation(self, entity1, relation, entity2):\n\t\tif self.entities.has_key(entity1):\n\t\t\tself.entities[entity1].append(Path(relation, entity2))\n\t\telse:\n\t\t\tself.entities[entity1] = [Path(relation, entity2)]\n\n\tdef getPathsFrom(self, entity):\n\t\treturn self.entities[entity]\n\n\tdef removePath(self, entity1, entity2):\n\t\tfor idx, path in enumerate(self.entities[entity1]):\n\t\t\tif(path.connected_entity == entity2):\n\t\t\t\tdel self.entities[entity1][idx]\n\t\t\t\tbreak\n\t\tfor idx, path in enumerate(self.entities[entity2]):\n\t\t\tif(path.connected_entity == entity1):\n\t\t\t\tdel self.entities[entity2][idx]\n\t\t\t\tbreak\n\n\tdef pickRandomIntermediatesBetween(self, entity1, entity2, num):\n\t\t#TO DO: COULD BE IMPROVED BY NARROWING THE RANGE OF RANDOM EACH TIME ITERATIVELY CHOOSE AN INTERMEDIATE  \n\t\tfrom sets import Set\n\t\timport random\n\n\t\tres = Set()\n\t\tif num > len(self.entities) - 2:\n\t\t\traise ValueError(\'Number of Intermediates picked is larger than possible\', \'num_entities: {}\'.format(len(self.entities)), \'num_itermediates: {}\'.format(num))\n\t\tfor i in range(num):\n\t\t\titermediate = random.choice(self.entities.keys())\n\t\t\twhile itermediate in res or itermediate == entity1 or itermediate == entity2:\n\t\t\t\titermediate = random.choice(self.entities.keys())\n\t\t\tres.add(itermediate)\n\t\treturn list(res)\n\n\tdef __str__(self):\n\t\tstring = """"\n\t\tfor entity in self.entities:\n\t\t\tstring += entity + \',\'.join(str(x) for x in self.entities[entity])\n\t\t\tstring += \'\\n\'\n\t\treturn string\n\n\nclass Path(object):\n\tdef __init__(self, relation, connected_entity):\n\t\tself.relation = relation\n\t\tself.connected_entity = connected_entity\n\n\tdef __str__(self):\n\t\treturn ""\\t{}\\t{}"".format(self.relation, self.connected_entity)\n\n\t__repr__ = __str__'"
scripts/BFS/__init__.py,0,b''
scripts/BFS/run.py,0,"b'#!/usr/bin/env python\n\nfrom KB import KB\nfrom BFS import BFS\nimport sys\n\ndef main():\n\tif len(sys.argv) != 5:\n\t\tprint ""Please use the following format: ./run dataFromKB entity1 entity2 number_of_diff_paths""\n\t\treturn\n\tkb = KB()\n\twith open(sys.argv[1], \'r\') as f:\n\t\tfor line in f.readlines():\n\t\t\tent1, rel, ent2 = extract(line.rstrip())\n\t\t\trel_inv = rel + \'_inv\'\n\t\t\tkb.addRelation(ent1, rel, ent2)\n\t\t\tkb.addRelation(ent2, rel_inv, ent1)\n\tprint \'Finishing building\'\n\tentity1 = sys.argv[2]\n\tentity2 = sys.argv[3]\n\tnum_intermediates = int(sys.argv[4])\n\tintermediates = pickRandomIntermediatesFrom(kb, entity1, entity2, num_intermediates)\n\tres_entity_lists = []\n\tres_path_lists = []\n\tfor i in range(num_intermediates):\n\t\tsuc1, entity_list1, path_list1 = BFS(kb, entity1, intermediates[i])\n\t\tif not suc1:\n\t\t\tcontinue\n\t\tsuc2, entity_list2, path_list2 = BFS(kb, intermediates[i], entity2)\n\t\tres_entity_lists.append(entity_list1 + entity_list2[1:])\n\t\tres_path_lists.append(path_list1 + path_list2)\n\tprettyPrint(res_entity_lists, res_path_lists)\n\ndef extract(line):\n\treturn line.split(\'\\t\')\n\ndef pickRandomIntermediatesFrom(kb, entity1, entity2, num_intermediates):\n\ttry:\n\t\treturn kb.pickRandomIntermediatesBetween(entity1, entity2, num_intermediates)\t\n\texcept ValueError as err:\n\t\tprint(err.args)\n\ndef prettyPrint(entity_lists, path_lists):\n\tif len(entity_lists) == 0:\n\t\tprint \'Cannot find any path\'\n\tfor i in range(len(entity_lists)):\n\t\tprint ""Entities List:"", entity_lists[i]\n\t\tprint ""Paths List:"", path_lists[i]\n\t\tprint \'------------------\'\n\nif __name__ == ""__main__"":\n\tmain()\n'"
