file_path,api_count,code
config.py,0,"b'# -*- coding:utf-8 -*-\n\nimport os\nimport configparser\n\ncurrent_dir = os.path.abspath(os.path.dirname(__file__))\n\nclass OperationalError(Exception):\n    """"""operation error.""""""\n\nclass Dictionary(dict):\n    """""" custom dict.""""""\n\n    def __getattr__(self, key):\n        return self.get(key, None)\n\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\nclass Config:\n    def __init__(self, file_name=""conf"", cfg=None):\n        """"""\n        @param file_name: file name without extension.\n        @param cfg: configuration file path.\n        """"""\n        #print(os.environ.items())\n        env = {}\n        for key, value in os.environ.items():\n            if key.startswith(""TEST_""):\n                env[key] = value\n\n        config = configparser.ConfigParser(env)\n\n        if cfg:\n            config.read(cfg)\n        else:\n            config.read(os.path.join(current_dir, ""conf"", ""%s.ini"" % file_name))\n\n        for section in config.sections():\n            setattr(self, section, Dictionary())\n            for name, raw_value in config.items(section):\n                try:\n                    # Ugly fix to avoid \'0\' and \'1\' to be parsed as a\n                    # boolean value.\n                    # We raise an exception to goto fail^w parse it\n                    # as integer.\n                    if config.get(section, name) in [""0"", ""1""]:\n                        raise ValueError\n\n                    value = config.getboolean(section, name)\n                except ValueError:\n                    try:\n                        value = config.getint(section, name)\n                    except ValueError:\n                        value = config.get(section, name)\n\n                setattr(getattr(self, section), name, value)\n\n    def get(self, section):\n        """"""Get option.\n        @param section: section to fetch.\n        @return: option value.\n        """"""\n        try:\n            return getattr(self, section)\n        except AttributeError as e:\n            raise OperationalError(""Option %s is not found in ""\n                                   ""configuration, error: %s"" %\n                                   (section, e))\n\n\nif __name__ == ""__main__"":\n    conf = Config()\n    #print(conf.get(""FILE_DATA"").wav_path)\n\n    #print(conf.get(""FILE_DATA"").label_file)\n\n'"
model.py,65,"b'# -*- coding:utf-8 -*-\n\nimport time\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import ctc_ops\n\nimport utils\nfrom config import Config\n\nb_stddev = 0.046875\nh_stddev = 0.046875\n\nn_hidden = 512\nn_hidden_1 = 512\nn_hidden_2 = 512\nn_hidden_5 = 512\nn_cell_dim = 512\nn_hidden_3 = 2 * 512\n\nlearning_rate = 0.001\nkeep_dropout_rate = 0.95\nkeep_dropout_rate = 0.95\nrelu_clip = 20\n\nn_input = 26  # \xe8\xae\xa1\xe7\xae\x97\xe7\xbe\x8e\xe5\xb0\x94\xe5\x80\x92\xe8\xb0\xb1\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\nn_context = 9  # \xe5\xaf\xb9\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe6\x97\xb6\xe9\x97\xb4\xe7\x82\xb9\xef\xbc\x8c\xe8\xa6\x81\xe5\x8c\x85\xe5\x90\xab\xe4\xb8\x8a\xe4\xb8\x8b\xe6\x96\x87\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\nbatch_size = 8\n\n\nclass BiRNN(object):\n    def __init__(self, wav_files, text_labels, words_size, words, word_num_map):\n        self.conf = Config()\n        self.wav_files = wav_files\n        self.text_labels = text_labels\n        self.words_size = words_size\n        self.words = words\n        self.word_num_map = word_num_map\n\n    def add_placeholders(self):\n        # the batch_size and max_stepsize\xe6\xaf\x8f\xe6\xad\xa5\xe9\x83\xbd\xe6\x98\xaf\xe5\x8f\x98\xe9\x95\xbf\xe7\x9a\x84\xe3\x80\x82\n        self.input_tensor = tf.placeholder(tf.float32, [None, None, n_input + (2 * n_input * n_context)],\n                                           name=\'input\')  # \xe8\xaf\xad\xe9\x9f\xb3log filter bank or MFCC features\n\n        self.text = tf.sparse_placeholder(tf.int32, name=\'text\')  # \xe6\x96\x87\xe6\x9c\xac\n        self.seq_length = tf.placeholder(tf.int32, [None], name=\'seq_length\')  # \xe5\xba\x8f\xe5\x88\x97\xe9\x95\xbf\n        self.keep_dropout = tf.placeholder(tf.float32)\n\n    def bi_rnn_layer(self):\n        \'\'\'\n        \xe5\xbb\xba\xe7\xab\x8b\xe7\xbd\x91\xe7\xbb\x9c\xe6\xa8\xa1\xe5\x9e\x8b\n        :param batch_x:\n        :param seq_length:\n        :param n_input:\n        :param n_context:\n        :param n_character:\n        :param keep_dropout:\n        \'\'\'\n        batch_x = self.input_tensor\n        seq_length = self.seq_length\n        n_character = self.words_size + 1\n        keep_dropout = self.keep_dropout\n\n        # batch_x_shape: [batch_size, n_steps, n_input + 2*n_input*n_context]\n        batch_x_shape = tf.shape(batch_x)\n\n        # \xe5\xb0\x86\xe8\xbe\x93\xe5\x85\xa5\xe8\xbd\xac\xe6\x88\x90\xe6\x97\xb6\xe9\x97\xb4\xe5\xba\x8f\xe5\x88\x97\xe4\xbc\x98\xe5\x85\x88\n        batch_x = tf.transpose(batch_x, [1, 0, 2])\n        # \xe5\x86\x8d\xe8\xbd\xac\xe6\x88\x902\xe7\xbb\xb4\xe4\xbc\xa0\xe5\x85\xa5\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\n        batch_x = tf.reshape(batch_x,\n                             [-1,\n                              n_input + 2 * n_input * n_context])  # (n_steps*batch_size, n_input + 2*n_input*n_context)\n\n        # 1st layer\n        with tf.name_scope(\'layer1\'):\n            b1 = self.variable_on_device(\'b1\', [n_hidden_1], tf.random_normal_initializer(stddev=b_stddev))\n            h1 = self.variable_on_device(\'h1\', [n_input + 2 * n_input * n_context, n_hidden_1],\n                                         tf.random_normal_initializer(stddev=h_stddev))\n            layer_1 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(batch_x, h1), b1)), relu_clip)\n            layer_1 = tf.nn.dropout(layer_1, keep_dropout)\n\n        # 2nd layer\n        with tf.name_scope(\'layer2\'):\n            b2 = self.variable_on_device(\'b2\', [n_hidden_2], tf.random_normal_initializer(stddev=b_stddev))\n            h2 = self.variable_on_device(\'h2\', [n_hidden_1, n_hidden_2], tf.random_normal_initializer(stddev=h_stddev))\n            layer_2 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_1, h2), b2)), relu_clip)\n            layer_2 = tf.nn.dropout(layer_2, keep_dropout)\n\n        # 3rd layer\n        with tf.name_scope(\'layer3\'):\n            b3 = self.variable_on_device(\'b3\', [n_hidden_3], tf.random_normal_initializer(stddev=b_stddev))\n            h3 = self.variable_on_device(\'h3\', [n_hidden_2, n_hidden_3], tf.random_normal_initializer(stddev=h_stddev))\n            layer_3 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_2, h3), b3)), relu_clip)\n            layer_3 = tf.nn.dropout(layer_3, keep_dropout)\n\n        # \xe5\x8f\x8c\xe5\x90\x91rnn\n        with tf.name_scope(\'birnn\'):\n            # \xe5\x89\x8d\xe5\x90\x91\n            lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\n            lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(lstm_fw_cell,\n                                                         input_keep_prob=keep_dropout)\n            # \xe5\x90\x8e\xe5\x90\x91\n            lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\n            lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(lstm_bw_cell,\n                                                         input_keep_prob=keep_dropout)\n\n            # `layer_3`  `[n_steps, batch_size, 2*n_cell_dim]`\n            # print(batch_x_shape[0])\n            # print(batch_x_shape[1])\n            # print(batch_x_shape[2])\n            layer_3 = tf.reshape(layer_3, [-1, batch_x_shape[0], n_hidden_3])\n\n            outputs, output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_fw_cell,\n                                                                     cell_bw=lstm_bw_cell,\n                                                                     inputs=layer_3,\n                                                                     dtype=tf.float32,\n                                                                     time_major=True,\n                                                                     sequence_length=seq_length)\n\n            # \xe8\xbf\x9e\xe6\x8e\xa5\xe6\xad\xa3\xe5\x8f\x8d\xe5\x90\x91\xe7\xbb\x93\xe6\x9e\x9c[n_steps, batch_size, 2*n_cell_dim]\n            outputs = tf.concat(outputs, 2)\n            # to a single tensor of shape [n_steps*batch_size, 2*n_cell_dim]\n            outputs = tf.reshape(outputs, [-1, 2 * n_cell_dim])\n\n        with tf.name_scope(\'layer5\'):\n            b5 = self.variable_on_device(\'b5\', [n_hidden_5], tf.random_normal_initializer(stddev=b_stddev))\n            h5 = self.variable_on_device(\'h5\', [(2 * n_cell_dim), n_hidden_5],\n                                         tf.random_normal_initializer(stddev=h_stddev))\n            layer_5 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(outputs, h5), b5)), relu_clip)\n            layer_5 = tf.nn.dropout(layer_5, keep_dropout)\n\n        with tf.name_scope(\'layer6\'):\n            # \xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb1\x82\xe7\x94\xa8\xe4\xba\x8esoftmax\xe5\x88\x86\xe7\xb1\xbb\n            b6 = self.variable_on_device(\'b6\', [n_character], tf.random_normal_initializer(stddev=b_stddev))\n            h6 = self.variable_on_device(\'h6\', [n_hidden_5, n_character], tf.random_normal_initializer(stddev=h_stddev))\n            layer_6 = tf.add(tf.matmul(layer_5, h6), b6)\n\n        # \xe5\xb0\x862\xe7\xbb\xb4[n_steps*batch_size, n_character]\xe8\xbd\xac\xe6\x88\x903\xe7\xbb\xb4 time-major [n_steps, batch_size, n_character].\n        layer_6 = tf.reshape(layer_6, [-1, batch_x_shape[0], n_character])\n\n        # Output shape: [n_steps, batch_size, n_character]\n        self.logits = layer_6\n\n    def loss(self):\n        """"""\n        \xe5\xae\x9a\xe4\xb9\x89loss\n        :return:\n        """"""\n        # \xe8\xb0\x83\xe7\x94\xa8ctc loss\n        with tf.name_scope(\'loss\'): #\xe6\x8d\x9f\xe5\xa4\xb1\n            self.avg_loss = tf.reduce_mean(ctc_ops.ctc_loss(self.text, self.logits, self.seq_length))\n            tf.summary.scalar(\'loss\',self.avg_loss)\n        # [optimizer]\n        with tf.name_scope(\'train\'): #\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\n            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.avg_loss)\n\n        with tf.name_scope(""decode""):\n            self.decoded, log_prob = ctc_ops.ctc_beam_search_decoder(self.logits, self.seq_length, merge_repeated=False)\n\n        with tf.name_scope(""accuracy""):\n            self.distance = tf.edit_distance(tf.cast(self.decoded[0], tf.int32), self.text)\n            # \xe8\xae\xa1\xe7\xae\x97label error rate (accuracy)\n            self.label_err = tf.reduce_mean(self.distance, name=\'label_error_rate\')\n            tf.summary.scalar(\'accuracy\', self.label_err)\n\n    def get_feed_dict(self, dropout=None):\n        """"""\n        \xe5\xae\x9a\xe4\xb9\x89\xe5\x8f\x98\xe9\x87\x8f\n        :param dropout:\n        :return:\n        """"""\n        feed_dict = {self.input_tensor: self.audio_features,\n                     self.text: self.sparse_labels,\n                     self.seq_length: self.audio_features_len}\n\n        if dropout != None:\n            feed_dict[self.keep_dropout] = dropout\n        else:\n            feed_dict[self.keep_dropout] = keep_dropout_rate\n\n        return feed_dict\n\n    def init_session(self):\n        self.savedir = self.conf.get(""FILE_DATA"").savedir\n        self.saver = tf.train.Saver(max_to_keep=1)  # \xe7\x94\x9f\xe6\x88\x90saver\n        # create the session\n        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n        # sess = tf.Session()\n        # \xe6\xb2\xa1\xe6\x9c\x89\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\x9d\xef\xbc\x8c\xe5\xb0\xb1\xe9\x87\x8d\xe6\x96\xb0\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\n        self.sess.run(tf.global_variables_initializer())\n\n        ckpt = tf.train.latest_checkpoint(self.savedir)\n        print(""ckpt:"", ckpt)\n        self.startepo = 0\n        if ckpt != None:\n            self.saver.restore(self.sess, ckpt)\n            ind = ckpt.rfind(""-"")\n            self.startepo = int(ckpt[ind + 1:])\n            print(self.startepo)\n        print()\n\n    def add_summary(self):\n        self.merged = tf.summary.merge_all()\n        self.writer = tf.summary.FileWriter(self.conf.get(""FILE_DATA"").tensorboardfile, self.sess.graph)\n\n    def train(self):\n        epochs = 120\n\n        # \xe5\x87\x86\xe5\xa4\x87\xe8\xbf\x90\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\xad\xa5\xe9\xaa\xa4\n        section = \'\\n{0:=^40}\\n\'\n        print(section.format(\'\xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\'))\n\n        train_start = time.time()\n        for epoch in range(epochs):  # \xe6\xa0\xb7\xe6\x9c\xac\xe9\x9b\x86\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\n            epoch_start = time.time()\n            if epoch < self.startepo:\n                continue\n\n            print(""\xe7\xac\xac\xef\xbc\x9a"", epoch, "" \xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xef\xbc\x8c\xe4\xb8\x80\xe5\x85\xb1\xe8\xa6\x81\xe8\xbf\xad\xe4\xbb\xa3 "", epochs, ""\xe6\xac\xa1"")\n            #######################run batch####\n            n_batches_epoch = int(np.ceil(len(self.text_labels) / batch_size))\n            print(""\xe5\x9c\xa8\xe6\x9c\xac\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\xad\xe4\xb8\x80\xe5\x85\xb1\xe5\xbe\xaa\xe7\x8e\xaf\xef\xbc\x9a "", n_batches_epoch, ""\xe6\xaf\x8f\xe6\xac\xa1\xe5\x8f\x96\xef\xbc\x9a"", batch_size)\n\n            train_cost = 0\n            train_err = 0\n            next_idx = 0\n\n            for batch in range(n_batches_epoch):  # \xe4\xb8\x80\xe6\xac\xa1batch_size\xef\xbc\x8c\xe5\x8f\x96\xe5\xa4\x9a\xe5\xb0\x91\xe6\xac\xa1\n                # \xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\n                # temp_next_idx, temp_audio_features, temp_audio_features_len, temp_sparse_labels\n                next_idx, self.audio_features, self.audio_features_len, self.sparse_labels, wav_files = utils.next_batch(\n                    next_idx,\n                    batch_size,\n                    n_input,\n                    n_context,\n                    self.text_labels,\n                    self.wav_files,\n                    self.word_num_map)\n\n                # \xe8\xae\xa1\xe7\xae\x97 avg_loss optimizer ;\n                batch_cost, _ = self.sess.run([self.avg_loss, self.optimizer], feed_dict=self.get_feed_dict())\n                train_cost += batch_cost\n\n                if (batch + 1) % 70 == 0:\n                    rs = self.sess.run(self.merged, feed_dict=self.get_feed_dict())\n                    self.writer.add_summary(rs, batch)\n\n                    print(\'\xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0:\', batch, \'\xe6\x8d\x9f\xe5\xa4\xb1: \', train_cost / (batch + 1))\n\n                    d, train_err = self.sess.run([self.decoded[0], self.label_err], feed_dict=self.get_feed_dict(dropout=1.0))\n                    dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=self.sess)\n                    dense_labels = utils.trans_tuple_to_texts_ch(self.sparse_labels, self.words)\n\n                    print(\'\xe9\x94\x99\xe8\xaf\xaf\xe7\x8e\x87: \', train_err)\n                    for orig, decoded_array in zip(dense_labels, dense_decoded):\n                        # convert to strings\n                        decoded_str = utils.trans_array_to_text_ch(decoded_array, self.words)\n                        print(\'\xe8\xaf\xad\xe9\x9f\xb3\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x96\x87\xe6\x9c\xac: {}\'.format(orig))\n                        print(\'\xe8\xaf\x86\xe5\x88\xab\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac:  {}\'.format(decoded_str))\n                        break\n\n            epoch_duration = time.time() - epoch_start\n\n            log = \'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0 {}/{}, \xe8\xae\xad\xe7\xbb\x83\xe6\x8d\x9f\xe5\xa4\xb1: {:.3f}, \xe9\x94\x99\xe8\xaf\xaf\xe7\x8e\x87: {:.3f}, time: {:.2f} sec\'\n            print(log.format(epoch, epochs, train_cost, train_err, epoch_duration))\n            self.saver.save(self.sess, self.savedir + self.conf.get(""FILE_DATA"").savefile, global_step=epoch)\n\n        train_duration = time.time() - train_start\n        print(\'Training complete, total duration: {:.2f} min\'.format(train_duration / 60))\n        self.sess.close()\n\n    def test(self):\n        index = 0\n        next_idx = 20\n        \n        for index in range(10):\n           next_idx, self.audio_features, self.audio_features_len, self.sparse_labels, wav_files = utils.next_batch(\n               next_idx,\n               1,\n               n_input,\n               n_context,\n               self.text_labels,\n               self.wav_files,\n               self.word_num_map)\n\n           print(\'\xe8\xaf\xbb\xe5\x85\xa5\xe8\xaf\xad\xe9\x9f\xb3\xe6\x96\x87\xe4\xbb\xb6: \', wav_files[0])\n           print(\'\xe5\xbc\x80\xe5\xa7\x8b\xe8\xaf\x86\xe5\x88\xab\xe8\xaf\xad\xe9\x9f\xb3\xe6\x95\xb0\xe6\x8d\xae......\')\n\n           d, train_ler = self.sess.run([self.decoded[0], self.label_err], feed_dict=self.get_feed_dict(dropout=1.0))\n           dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=self.sess)\n           dense_labels = utils.trans_tuple_to_texts_ch(self.sparse_labels, self.words)\n        \n           for orig, decoded_array in zip(dense_labels, dense_decoded):\n               # \xe8\xbd\xac\xe6\x88\x90string\n               decoded_str = utils.trans_array_to_text_ch(decoded_array, self.words)\n               print(\'\xe8\xaf\xad\xe9\x9f\xb3\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x96\x87\xe6\x9c\xac: {}\'.format(orig))\n               print(\'\xe8\xaf\x86\xe5\x88\xab\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac:  {}\'.format(decoded_str))\n               break\n\n        self.sess.close()\n\n    def test_target_wav_file(self, wav_files, txt_labels):\n        print(\'\xe8\xaf\xbb\xe5\x85\xa5\xe8\xaf\xad\xe9\x9f\xb3\xe6\x96\x87\xe4\xbb\xb6: \', wav_files[0])\n        print(\'\xe5\xbc\x80\xe5\xa7\x8b\xe8\xaf\x86\xe5\x88\xab\xe8\xaf\xad\xe9\x9f\xb3\xe6\x95\xb0\xe6\x8d\xae......\')\n\n        self.audio_features, self.audio_features_len, text_vector, text_vector_len = utils.get_audio_mfcc_features(\n            None,\n            wav_files,\n            n_input,\n            n_context,\n            self.word_num_map,\n            txt_labels)\n        self.sparse_labels = utils.sparse_tuple_from(text_vector)\n        d, train_ler = self.sess.run([self.decoded[0], self.label_err], feed_dict=self.get_feed_dict(dropout=1.0))\n        dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=self.sess)\n        decoded_str = utils.trans_array_to_text_ch(dense_decoded[0], self.words)\n        print(\'\xe8\xaf\xad\xe9\x9f\xb3\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x96\x87\xe6\x9c\xac: {}\'.format(txt_labels[0]))\n        print(\'\xe8\xaf\x86\xe5\x88\xab\xe5\x87\xba\xe6\x9d\xa5\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac:  {}\'.format(decoded_str))\n\n        self.sess.close()\n\n    def build_train(self):\n        self.add_placeholders()\n        self.bi_rnn_layer()\n        self.loss()\n        self.init_session()\n        self.add_summary()\n        self.train()\n\n    def build_test(self):\n        self.add_placeholders()\n        self.bi_rnn_layer()\n        self.loss()\n        self.init_session()\n        self.test()\n\n    def build_target_wav_file_test(self, wav_files, txt_labels):\n        self.add_placeholders()\n        self.bi_rnn_layer()\n        self.loss()\n        self.init_session()\n        self.test_target_wav_file(wav_files, txt_labels)\n\n    def variable_on_device(self, name, shape, initializer):\n        with tf.device(\'/gpu:0\'):\n            var = tf.get_variable(name=name, shape=shape, initializer=initializer)\n        return var\n'"
test.py,0,"b""# -*- coding: utf-8 -*-\n\nimport os\n\nimport utils\nfrom config import Config\nfrom model import BiRNN\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nconf = Config()\n\nwav_files, text_labels = utils.get_wavs_lables()\n\nwords_size, words, word_num_map = utils.create_dict(text_labels)\n\nbi_rnn = BiRNN(wav_files, text_labels, words_size, words, word_num_map)\nbi_rnn.build_test()\n\n# wav_files = ['E:\\\\wav\\\\train\\\\A2\\\\A2_11.wav']\n# txt_labels = ['\xe5\x8c\x97\xe4\xba\xac \xe4\xb8\xb0\xe5\x8f\xb0\xe5\x8c\xba \xe5\x86\x9c\xe6\xb0\x91 \xe8\x87\xaa\xe5\xb7\xb1 \xe8\x8a\xb1\xe9\x92\xb1 \xe7\xad\xb9\xe5\x8a\x9e \xe4\xb8\x87 \xe4\xbd\x9b \xe5\xbb\xb6\xe5\xaf\xbf \xe5\xaf\xba \xe8\xbf\x8e\xe6\x98\xa5 \xe5\xba\x99\xe4\xbc\x9a \xe5\x90\xb8\xe5\xbc\x95 \xe4\xba\x86 \xe5\x8c\xba\xe5\x86\x85 \xe5\x85\xad\xe5\x8d\x81 \xe6\x94\xaf \xe7\xa7\xa7\xe6\xad\x8c\xe9\x98\x9f \xe5\x8f\x82\xe8\xb5\x9b']\n# bi_rnn = BiRNN(wav_files, text_labels, words_size, words, word_num_map)\n# bi_rnn.build_target_wav_file_test(wav_files, txt_labels)\n"""
train.py,0,"b""# -*- coding: utf-8 -*-\n\nimport os\n\nimport utils\nfrom config import Config\nfrom model import BiRNN\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nconf = Config()\n\nwav_files, text_labels = utils.get_wavs_lables()\n\nwords_size, words, word_num_map = utils.create_dict(text_labels)\n\n\nbi_rnn = BiRNN(wav_files, text_labels, words_size, words, word_num_map)\nbi_rnn.build_train()\n"""
utils.py,1,"b'# -*- coding: utf-8 -*-\n\nimport os\nfrom collections import Counter\n\nimport numpy as np\nimport scipy.io.wavfile as wav\nfrom python_speech_features import mfcc\n\nfrom config import Config\n\n\ndef get_wavs_lables():\n    conf = Config()\n    wav_files, text_labels = do_get_wavs_lables(conf.get(""FILE_DATA"").wav_path,\n                                                conf.get(""FILE_DATA"").label_file)\n    print(wav_files[0], text_labels[0])\n    # wav/train/A11/A11_0.WAV -> \xe7\xbb\xbf \xe6\x98\xaf \xe9\x98\xb3\xe6\x98\xa5 \xe7\x83\x9f \xe6\x99\xaf \xe5\xa4\xa7\xe5\x9d\x97 \xe6\x96\x87\xe7\xab\xa0 \xe7\x9a\x84 \xe5\xba\x95\xe8\x89\xb2 \xe5\x9b\x9b\xe6\x9c\x88 \xe7\x9a\x84 \xe6\x9e\x97 \xe5\xb3\xa6 \xe6\x9b\xb4\xe6\x98\xaf \xe7\xbb\xbf \xe5\xbe\x97 \xe9\xb2\x9c\xe6\xb4\xbb \xe7\xa7\x80\xe5\xaa\x9a \xe8\xaf\x97\xe6\x84\x8f \xe7\x9b\x8e\xe7\x84\xb6\n    print(""wav:"", len(wav_files), ""label"", len(text_labels))\n\n    return wav_files, text_labels\n\n\ndef do_get_wavs_lables(wav_path, label_file):\n    """"""\n    \xe8\xaf\xbb\xe5\x8f\x96wav\xe6\x96\x87\xe4\xbb\xb6\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84label\n    :param wav_path:\n    :param label_file:\n    :return:\n    """"""\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe8\xae\xad\xe7\xbb\x83\xe7\x94\xa8\xe7\x9a\x84wav\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\xe5\x88\x97\xe8\xa1\xa8\n    wav_files = []\n    for (dirpath, dirnames, filenames) in os.walk(wav_path):\n        for filename in filenames:\n            if filename.endswith(\'.wav\') or filename.endswith(\'.WAV\'):\n                filename_path = os.sep.join([dirpath, filename])\n                if os.stat(filename_path).st_size < 240000:  # \xe5\x89\x94\xe9\x99\xa4\xe6\x8e\x89\xe4\xb8\x80\xe4\xba\x9b\xe5\xb0\x8f\xe6\x96\x87\xe4\xbb\xb6\n                    continue\n                wav_files.append(filename_path)\n\n    labels_dict = {}\n    with open(label_file, \'rb\') as f:\n        for label in f:\n            label = label.strip(b\'\\n\')\n            label_id = label.split(b\' \', 1)[0]\n            label_text = label.split(b\' \', 1)[1]\n            labels_dict[label_id.decode(\'ascii\')] = label_text.decode(\'utf-8\')\n\n    labels = []\n    new_wav_files = []\n    for wav_file in wav_files:\n        # print(os.path.basename(wav_file))\n        wav_id = os.path.basename(wav_file).split(\'.\')[0]\n\n        if wav_id in labels_dict:\n            labels.append(labels_dict[wav_id])\n            new_wav_files.append(wav_file)\n\n    return new_wav_files, labels\n\n\ndef create_dict(text_labels):\n    """"""\n    \xe6\x9e\x84\xe5\xbb\xba\xe5\xad\x97\xe5\x85\xb8\n    :param text_labels:\n    :return:\n    """"""\n    all_words = []\n    for label in text_labels:\n        # print(label)\n        all_words += [word for word in label]\n    counter = Counter(all_words)\n    words = sorted(counter)\n    words_size = len(words)\n    word_num_map = dict(zip(words, range(words_size)))\n    print(\'\xe5\xad\x97\xe8\xa1\xa8\xe5\xa4\xa7\xe5\xb0\x8f:\', words_size)\n\n    return words_size, words, word_num_map\n\n\ndef next_batch(start_idx=0,\n               batch_size=1,\n               n_input=None,\n               n_context=None,\n               labels=None,\n               wav_files=None,\n               word_num_map=None):\n    """"""\n    \xe6\x8c\x89\xe6\x89\xb9\xe6\xac\xa1\xe8\x8e\xb7\xe5\x8f\x96\xe6\xa0\xb7\xe6\x9c\xac\n    :param start_idx:\n    :param batch_size:\n    :param n_input:\n    :param n_context:\n    :param labels:\n    :param wav_files:\n    :param word_num_map:\n    :return:\n    """"""\n    filesize = len(labels)\n    end_idx = min(filesize, start_idx + batch_size)\n    idx_list = range(start_idx, end_idx)\n    txt_labels = [labels[i] for i in idx_list]\n    wav_files = [wav_files[i] for i in idx_list]\n    audio_features, audio_features_len, text_vector, text_vector_len = get_audio_mfcc_features(None,\n                                                                                               wav_files,\n                                                                                               n_input,\n                                                                                               n_context,\n                                                                                               word_num_map,\n                                                                                               txt_labels)\n\n    start_idx += batch_size\n    # \xe9\xaa\x8c\xe8\xaf\x81 start_idx\n    if start_idx >= filesize:\n        start_idx = -1\n\n    # \xe5\xa6\x82\xe6\x9e\x9c\xe5\xa4\x9a\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xe5\xb0\x86\xe9\x95\xbf\xe5\xba\xa6\xe7\xbb\x9f\xe4\xb8\x80\xef\xbc\x8c\xe6\x94\xaf\xe6\x8c\x81\xe6\x8c\x89\xe6\x9c\x80\xe5\xa4\xa7\xe6\x88\xaa\xe6\x96\xad\xe6\x88\x96\xe8\xa1\xa50\n    audio_features, audio_features_len = pad_sequences(audio_features)\n    sparse_labels = sparse_tuple_from(text_vector)\n\n    return start_idx, audio_features, audio_features_len, sparse_labels, wav_files\n\n\ndef get_audio_mfcc_features(txt_files, wav_files, n_input, n_context, word_num_map, txt_labels=None):\n    """"""\n    \xe6\x8f\x90\xe5\x8f\x96\xe9\x9f\xb3\xe9\xa2\x91\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84MFCC\xe7\x89\xb9\xe5\xbe\x81\n    :param txt_files:\n    :param wav_files:\n    :param n_input:\n    :param n_context:\n    :param word_num_map:\n    :param txt_labels:\n    :return:\n    """"""\n    audio_features = []\n    audio_features_len = []\n    text_vector = []\n    text_vector_len = []\n    if txt_files != None:\n        txt_labels = txt_files\n\n    for txt_obj, wav_file in zip(txt_labels, wav_files):\n        # \xe8\xbd\xbd\xe5\x85\xa5\xe9\x9f\xb3\xe9\xa2\x91\xe6\x95\xb0\xe6\x8d\xae\xe5\xb9\xb6\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\n        audio_data = audiofile_to_input_vector(wav_file, n_input, n_context)\n        audio_data = audio_data.astype(\'float32\')\n\n        audio_features.append(audio_data)\n        audio_features_len.append(np.int32(len(audio_data)))\n\n        # \xe8\xbd\xbd\xe5\x85\xa5\xe9\x9f\xb3\xe9\xa2\x91\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\n        target = []\n        if txt_files != None:  # txt_obj\xe6\x98\xaf\xe6\x96\x87\xe4\xbb\xb6\n            target = trans_text_ch_to_vector(txt_obj, word_num_map)\n        else:\n            target = trans_text_ch_to_vector(None, word_num_map, txt_obj)  # txt_obj\xe6\x98\xaflabels\n        # target = text_to_char_array(target)\n        text_vector.append(target)\n        text_vector_len.append(len(target))\n\n    audio_features = np.asarray(audio_features)\n    audio_features_len = np.asarray(audio_features_len)\n    text_vector = np.asarray(text_vector)\n    text_vector_len = np.asarray(text_vector_len)\n    return audio_features, audio_features_len, text_vector, text_vector_len\n\n\ndef sparse_tuple_from(sequences, dtype=np.int32):\n    """"""\n    \xe5\xaf\x86\xe9\x9b\x86\xe7\x9f\xa9\xe9\x98\xb5\xe8\xbd\xac\xe7\xa8\x80\xe7\x96\x8f\xe7\x9f\xa9\xe9\x98\xb5\n    :param sequences:\n    :param dtype:\n    :return:\n    """"""\n    indices = []\n    values = []\n\n    for n, seq in enumerate(sequences):\n        indices.extend(zip([n] * len(seq), range(len(seq))))\n        values.extend(seq)\n\n    indices = np.asarray(indices, dtype=np.int64)\n    values = np.asarray(values, dtype=dtype)\n    # temp = indices.max(0)\n    shape = np.asarray([len(sequences), indices.max(0)[1] + 1], dtype=np.int64)\n\n    # return tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n    return indices, values, shape\n\n\ndef trans_text_ch_to_vector(txt_file, word_num_map, txt_label=None):\n    """"""\n    \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe7\xac\xa6\xe5\x88\xb0\xe5\x90\x91\xe9\x87\x8f\n    :param txt_file:\n    :param word_num_map:\n    :param txt_label:\n    :return:\n    """"""\n    words_size = len(word_num_map)\n\n    to_num = lambda word: word_num_map.get(word, words_size)\n\n    if txt_file != None:\n        txt_label = get_ch_lable(txt_file)\n\n    # print(txt_label)\n    labels_vector = list(map(to_num, txt_label))\n    # print(labels_vector)\n    return labels_vector\n\n\ndef get_ch_lable(txt_file):\n    labels = """"\n    with open(txt_file, \'rb\') as f:\n        for label in f:\n            # labels =label.decode(\'utf-8\')\n            labels = labels + label.decode(\'gb2312\')\n            # labels.append(label.decode(\'gb2312\'))\n\n    return labels\n\n\ndef trans_tuple_to_texts_ch(tuple, words):\n    """"""\n    \xe5\x90\x91\xe9\x87\x8f\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe6\x96\x87\xe5\xad\x97\n    :param tuple:\n    :param words:\n    :return:\n    """"""\n    indices = tuple[0]\n    values = tuple[1]\n    results = [\'\'] * tuple[2][0]\n    #print(\'word len is:\' , len(words))\n    for i in range(len(indices)):\n        index = indices[i][0]\n        c = values[i]\n        c = \' \' if c == 0 else words[c]  # chr(c + FIRST_INDEX)\n        results[index] = results[index] + c\n\n    return results\n\n\ndef trans_array_to_text_ch(value, words):\n    results = \'\'\n    #print(\'trans_array_to_text_ch len:\', len(value))\n    for i in range(len(value)):\n        results += words[value[i]]  # chr(value[i] + FIRST_INDEX)\n    return results.replace(\'`\', \' \')\n\n\ndef audiofile_to_input_vector(audio_filename, n_input, n_context):\n    """"""\n    \xe5\xb0\x86\xe9\x9f\xb3\xe9\xa2\x91\xe8\xa3\x85\xe6\x8d\xa2\xe6\x88\x90MFCC\n    :param audio_filename:\n    :param n_input:\n    :param n_context:\n    :return:\n    """"""\n    # \xe5\x8a\xa0\xe8\xbd\xbdwav\xe6\x96\x87\xe4\xbb\xb6\n    fs, audio = wav.read(audio_filename)\n\n    # \xe8\x8e\xb7\xe5\x8f\x96mfcc\xe6\x95\xb0\xe5\x80\xbc\n    orig_inputs = mfcc(audio, samplerate=fs, numcep=n_input)\n    # print(np.shape(orig_inputs))  #(277, 26)\n    orig_inputs = orig_inputs[::2]  # (139, 26) \xe6\xaf\x8f\xe9\x9a\x94\xe4\xb8\x80\xe8\xa1\x8c\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xb8\x80\xe6\xac\xa1\xe5\x8f\x96\xe6\xa0\xb7\n\n    # train_inputs = np.array([], np.float32)\n    # print(orig_inputs.shape[0])\n    train_inputs = np.zeros((orig_inputs.shape[0], n_input + 2 * n_input * n_context))\n    # print(np.shape(train_inputs))#)(139, 494)\n    # empty_mfcc = np.array([])\n    empty_mfcc = np.zeros((n_input))\n\n    # \xe5\x87\x86\xe5\xa4\x87\xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe6\x95\xb0\xe6\x8d\xae\xe7\x94\xb1\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xe5\xae\x89\xe9\xa1\xba\xe5\xba\x8f\xe6\x8b\xbc\xe6\x8e\xa5\xe8\x80\x8c\xe6\x88\x90\xef\xbc\x8c\xe5\x88\x86\xe4\xb8\xba\xe5\xbd\x93\xe5\x89\x8d\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\x89\x8d9\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe5\xbd\x93\xe5\x89\x8d\xe6\xa0\xb7\xe6\x9c\xac\xe5\xba\x8f\xe5\x88\x97\xef\xbc\x8c\xe5\x90\x8e9\xe4\xb8\xaa\xe5\xba\x8f\xe5\x88\x97\xe6\xa0\xb7\xe6\x9c\xac\n    time_slices = range(train_inputs.shape[0])  # 139\xe4\xb8\xaa\xe5\x88\x87\xe7\x89\x87\n    context_past_min = time_slices[0] + n_context\n    context_future_max = time_slices[-1] - n_context  # [9,1,2...,137,129]\n    for time_slice in time_slices:\n        # \xe5\x89\x8d9\xe4\xb8\xaa\xe8\xa1\xa50\xef\xbc\x8cmfcc features\n        need_empty_past = max(0, (context_past_min - time_slice))\n        empty_source_past = list(empty_mfcc for empty_slots in range(need_empty_past))\n        data_source_past = orig_inputs[max(0, time_slice - n_context):time_slice]\n\n        # \xe5\x90\x8e9\xe4\xb8\xaa\xe8\xa1\xa50\xef\xbc\x8cmfcc features\n        need_empty_future = max(0, (time_slice - context_future_max))\n        empty_source_future = list(empty_mfcc for empty_slots in range(need_empty_future))\n        data_source_future = orig_inputs[time_slice + 1:time_slice + n_context + 1]\n\n        if need_empty_past:\n            past = np.concatenate((empty_source_past, data_source_past))\n        else:\n            past = data_source_past\n\n        if need_empty_future:\n            future = np.concatenate((data_source_future, empty_source_future))\n        else:\n            future = data_source_future\n\n        past = np.reshape(past, n_context * n_input)\n        now = orig_inputs[time_slice]\n        future = np.reshape(future, n_context * n_input)\n        # 234, 26, 234\n        # train_data = np.concatenate((past, now, future));\n        train_inputs[time_slice] = np.concatenate((past, now, future))\n\n    # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xbd\xbf\xe7\x94\xa8\xe6\xad\xa3\xe5\xa4\xaa\xe5\x88\x86\xe5\xb8\x83\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xef\xbc\x8c\xe5\x87\x8f\xe5\x8e\xbb\xe5\x9d\x87\xe5\x80\xbc\xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x99\xa4\xe4\xbb\xa5\xe6\x96\xb9\xe5\xb7\xae\n    train_inputs = (train_inputs - np.mean(train_inputs)) / np.std(train_inputs)\n    return train_inputs\n\n\ndef pad_sequences(sequences, maxlen=None, dtype=np.float32,\n                  padding=\'post\', truncating=\'post\', value=0.):\n    """"""\n    \xe9\x9f\xb3\xe9\xa2\x91\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe9\xbd\x90\n    post\xe8\xa1\xa8\xe7\xa4\xba\xe5\x90\x8e\xe8\xa1\xa50  pre\xe8\xa1\xa8\xe7\xa4\xba\xe5\x89\x8d\xe8\xa1\xa50\n    :param sequences:\n    :param maxlen:\n    :param dtype:\n    :param padding:\n    :param truncating:\n    :param value:\n    :return:\n    """"""\n    sequences_each_len = np.asarray([len(s) for s in sequences], dtype=np.int64)\n\n    nb_samples = len(sequences)\n    if maxlen is None:\n        maxlen = np.max(sequences_each_len)\n\n    # \xe4\xbb\x8e\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9d\x9e\xe7\xa9\xba\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe4\xb8\xad\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe5\xbd\xa2\xe7\x8a\xb6\n    sample_shape = tuple()\n    for s in sequences:\n        if len(s) > 0:\n            # test\n            # temp = np.asarray(s)\n            sample_shape = np.asarray(s).shape[1:]\n            break\n\n    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n    for idx, s in enumerate(sequences):\n        if len(s) == 0:\n            continue\n        if truncating == \'pre\':\n            trunc = s[-maxlen:]\n        elif truncating == \'post\':\n            trunc = s[:maxlen]\n        else:\n            raise ValueError(\'Truncating type ""%s"" not understood\' % truncating)\n\n        # check `trunc` has expected shape\n        trunc = np.asarray(trunc, dtype=dtype)\n        if trunc.shape[1:] != sample_shape:\n            raise ValueError(\'Shape of sample %s of sequence at position %s is different from expected shape %s\' %\n                             (trunc.shape[1:], idx, sample_shape))\n\n        if padding == \'post\':\n            x[idx, :len(trunc)] = trunc\n        elif padding == \'pre\':\n            x[idx, -len(trunc):] = trunc\n        else:\n            raise ValueError(\'Padding type ""%s"" not understood\' % padding)\n    return x, sequences_each_len\n\n\nif __name__ == ""__main__"":\n    conf = Config()\n\n    get_wavs_lables(conf.get(""FILE_DATA"").wav_path, conf.get(""FILE_DATA"").label_file)\n    print()\n'"
