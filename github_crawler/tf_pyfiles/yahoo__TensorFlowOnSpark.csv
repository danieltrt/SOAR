file_path,api_count,code
setup.py,0,"b""from setuptools import setup\n\nwith open('README.md') as f:\n  long_description = f.read()\n\nsetup(\n  name='tensorflowonspark',\n  packages=['tensorflowonspark'],\n  version='2.2.1',\n  description='Deep learning with TensorFlow on Apache Spark clusters',\n  long_description=long_description,\n  long_description_content_type='text/markdown',\n  author='Yahoo, Inc.',\n  url='https://github.com/yahoo/TensorFlowOnSpark',\n  keywords=['tensorflowonspark', 'tensorflow', 'spark', 'machine learning', 'yahoo'],\n  install_requires=['packaging'],\n  license='Apache 2.0',\n  classifiers=[\n    'Intended Audience :: Developers',\n    'Intended Audience :: Science/Research',\n    'License :: OSI Approved :: Apache Software License',\n    'Topic :: Software Development :: Libraries',\n    'Programming Language :: Python :: 2',\n    'Programming Language :: Python :: 2.7',\n    'Programming Language :: Python :: 3',\n    'Programming Language :: Python :: 3.5',\n    'Programming Language :: Python :: 3.6'\n  ]\n)\n"""
scripts/spark_ec2.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#\n# This script is modified from https://github.com/amplab/spark-ec2/blob/branch-1.6/spark_ec2.py.\n# The modification enables us to use Hadoop 2.6 and avoid RStudio.\n#\n\nfrom __future__ import division, print_function, with_statement\n\nimport codecs\nimport hashlib\nimport itertools\nimport logging\nimport os\nimport os.path\nimport pipes\nimport random\nimport shutil\nimport string\nfrom stat import S_IRUSR\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nimport textwrap\nimport time\nimport warnings\nfrom datetime import datetime\nfrom optparse import OptionParser\nfrom sys import stderr\n\nif sys.version < ""3"":\n    from urllib2 import urlopen, Request, HTTPError\nelse:\n    from urllib.request import urlopen, Request\n    from urllib.error import HTTPError\n    raw_input = input\n    xrange = range\n\nSPARK_EC2_VERSION = ""1.6.0""\nSPARK_EC2_DIR = os.path.dirname(os.path.realpath(__file__))\n\nVALID_SPARK_VERSIONS = set([\n    ""0.7.3"",\n    ""0.8.0"",\n    ""0.8.1"",\n    ""0.9.0"",\n    ""0.9.1"",\n    ""0.9.2"",\n    ""1.0.0"",\n    ""1.0.1"",\n    ""1.0.2"",\n    ""1.1.0"",\n    ""1.1.1"",\n    ""1.2.0"",\n    ""1.2.1"",\n    ""1.3.0"",\n    ""1.3.1"",\n    ""1.4.0"",\n    ""1.4.1"",\n    ""1.5.0"",\n    ""1.5.1"",\n    ""1.5.2"",\n    ""1.6.0"",\n])\n\nSPARK_TACHYON_MAP = {\n    ""1.0.0"": ""0.4.1"",\n    ""1.0.1"": ""0.4.1"",\n    ""1.0.2"": ""0.4.1"",\n    ""1.1.0"": ""0.5.0"",\n    ""1.1.1"": ""0.5.0"",\n    ""1.2.0"": ""0.5.0"",\n    ""1.2.1"": ""0.5.0"",\n    ""1.3.0"": ""0.5.0"",\n    ""1.3.1"": ""0.5.0"",\n    ""1.4.0"": ""0.6.4"",\n    ""1.4.1"": ""0.6.4"",\n    ""1.5.0"": ""0.7.1"",\n    ""1.5.1"": ""0.7.1"",\n    ""1.5.2"": ""0.7.1"",\n    ""1.6.0"": ""0.8.2"",\n}\n\nDEFAULT_SPARK_VERSION = SPARK_EC2_VERSION\nDEFAULT_SPARK_GITHUB_REPO = ""https://github.com/apache/spark""\n\n# Default location to get the spark-ec2 scripts (and ami-list) from\nDEFAULT_SPARK_EC2_GITHUB_REPO = ""https://github.com/anfeng/spark-ec2""\nDEFAULT_SPARK_EC2_BRANCH = ""branch-2.6""\n\n\ndef setup_external_libs(libs):\n    """"""\n    Download external libraries from PyPI to SPARK_EC2_DIR/lib/ and prepend them to our PATH.\n    """"""\n    PYPI_URL_PREFIX = ""https://pypi.python.org/packages/source""\n    SPARK_EC2_LIB_DIR = os.path.join(SPARK_EC2_DIR, ""lib"")\n\n    if not os.path.exists(SPARK_EC2_LIB_DIR):\n        print(""Downloading external libraries that spark-ec2 needs from PyPI to {path}..."".format(\n            path=SPARK_EC2_LIB_DIR\n        ))\n        print(""This should be a one-time operation."")\n        os.mkdir(SPARK_EC2_LIB_DIR)\n\n    for lib in libs:\n        versioned_lib_name = ""{n}-{v}"".format(n=lib[""name""], v=lib[""version""])\n        lib_dir = os.path.join(SPARK_EC2_LIB_DIR, versioned_lib_name)\n\n        if not os.path.isdir(lib_dir):\n            tgz_file_path = os.path.join(SPARK_EC2_LIB_DIR, versioned_lib_name + "".tar.gz"")\n            print("" - Downloading {lib}..."".format(lib=lib[""name""]))\n            download_stream = urlopen(\n                ""{prefix}/{first_letter}/{lib_name}/{lib_name}-{lib_version}.tar.gz"".format(\n                    prefix=PYPI_URL_PREFIX,\n                    first_letter=lib[""name""][:1],\n                    lib_name=lib[""name""],\n                    lib_version=lib[""version""]\n                )\n            )\n            with open(tgz_file_path, ""wb"") as tgz_file:\n                tgz_file.write(download_stream.read())\n            with open(tgz_file_path, ""rb"") as tar:\n                if hashlib.md5(tar.read()).hexdigest() != lib[""md5""]:\n                    print(""ERROR: Got wrong md5sum for {lib}."".format(lib=lib[""name""]), file=stderr)\n                    sys.exit(1)\n            tar = tarfile.open(tgz_file_path)\n            tar.extractall(path=SPARK_EC2_LIB_DIR)\n            tar.close()\n            os.remove(tgz_file_path)\n            print("" - Finished downloading {lib}."".format(lib=lib[""name""]))\n        sys.path.insert(1, lib_dir)\n\n\n# Only PyPI libraries are supported.\nexternal_libs = [\n    {\n        ""name"": ""boto"",\n        ""version"": ""2.34.0"",\n        ""md5"": ""5556223d2d0cc4d06dd4829e671dcecd""\n    }\n]\n\nsetup_external_libs(external_libs)\n\nimport boto\nfrom boto.ec2.blockdevicemapping import BlockDeviceMapping, BlockDeviceType, EBSBlockDeviceType\nfrom boto import ec2\n\n\nclass UsageError(Exception):\n    pass\n\n\n# Configure and parse our command-line arguments\ndef parse_args():\n    parser = OptionParser(\n        prog=""spark-ec2"",\n        version=""%prog {v}"".format(v=SPARK_EC2_VERSION),\n        usage=""%prog [options] <action> <cluster_name>\\n\\n""\n        + ""<action> can be: launch, destroy, login, stop, start, get-master, reboot-slaves"")\n\n    parser.add_option(\n        ""-s"", ""--slaves"", type=""int"", default=1,\n        help=""Number of slaves to launch (default: %default)"")\n    parser.add_option(\n        ""-w"", ""--wait"", type=""int"",\n        help=""DEPRECATED (no longer necessary) - Seconds to wait for nodes to start"")\n    parser.add_option(\n        ""-k"", ""--key-pair"",\n        help=""Key pair to use on instances"")\n    parser.add_option(\n        ""-i"", ""--identity-file"",\n        help=""SSH private key file to use for logging into instances"")\n    parser.add_option(\n        ""-p"", ""--profile"", default=None,\n        help=""If you have multiple profiles (AWS or boto config), you can configure "" +\n             ""additional, named profiles by using this option (default: %default)"")\n    parser.add_option(\n        ""-t"", ""--instance-type"", default=""m1.large"",\n        help=""Type of instance to launch (default: %default). "" +\n             ""WARNING: must be 64-bit; small instances won\'t work"")\n    parser.add_option(\n        ""-m"", ""--master-instance-type"", default="""",\n        help=""Master instance type (leave empty for same as instance-type)"")\n    parser.add_option(\n        ""-r"", ""--region"", default=""us-east-1"",\n        help=""EC2 region used to launch instances in, or to find them in (default: %default)"")\n    parser.add_option(\n        ""-z"", ""--zone"", default="""",\n        help=""Availability zone to launch instances in, or \'all\' to spread "" +\n             ""slaves across multiple (an additional $0.01/Gb for bandwidth"" +\n             ""between zones applies) (default: a single zone chosen at random)"")\n    parser.add_option(\n        ""-a"", ""--ami"",\n        help=""Amazon Machine Image ID to use"")\n    parser.add_option(\n        ""-v"", ""--spark-version"", default=DEFAULT_SPARK_VERSION,\n        help=""Version of Spark to use: \'X.Y.Z\' or a specific git hash (default: %default)"")\n    parser.add_option(\n        ""--spark-git-repo"",\n        default=DEFAULT_SPARK_GITHUB_REPO,\n        help=""Github repo from which to checkout supplied commit hash (default: %default)"")\n    parser.add_option(\n        ""--spark-ec2-git-repo"",\n        default=DEFAULT_SPARK_EC2_GITHUB_REPO,\n        help=""Github repo from which to checkout spark-ec2 (default: %default)"")\n    parser.add_option(\n        ""--spark-ec2-git-branch"",\n        default=DEFAULT_SPARK_EC2_BRANCH,\n        help=""Github repo branch of spark-ec2 to use (default: %default)"")\n    parser.add_option(\n        ""--deploy-root-dir"",\n        default=None,\n        help=""A directory to copy into / on the first master. "" +\n             ""Must be absolute. Note that a trailing slash is handled as per rsync: "" +\n             ""If you omit it, the last directory of the --deploy-root-dir path will be created "" +\n             ""in / before copying its contents. If you append the trailing slash, "" +\n             ""the directory is not created and its contents are copied directly into /. "" +\n             ""(default: %default)."")\n    parser.add_option(\n        ""--hadoop-major-version"", default=""1"",\n        help=""Major version of Hadoop. Valid options are 1 (Hadoop 1.0.4), 2 (CDH 4.2.0), yarn "" +\n             ""(Hadoop 2.4.0) (default: %default)"")\n    parser.add_option(\n        ""-D"", metavar=""[ADDRESS:]PORT"", dest=""proxy_port"",\n        help=""Use SSH dynamic port forwarding to create a SOCKS proxy at "" +\n             ""the given local address (for use with login)"")\n    parser.add_option(\n        ""--resume"", action=""store_true"", default=False,\n        help=""Resume installation on a previously launched cluster "" +\n             ""(for debugging)"")\n    parser.add_option(\n        ""--ebs-vol-size"", metavar=""SIZE"", type=""int"", default=0,\n        help=""Size (in GB) of each EBS volume."")\n    parser.add_option(\n        ""--ebs-vol-type"", default=""standard"",\n        help=""EBS volume type (e.g. \'gp2\', \'standard\')."")\n    parser.add_option(\n        ""--ebs-vol-num"", type=""int"", default=1,\n        help=""Number of EBS volumes to attach to each node as /vol[x]. "" +\n             ""The volumes will be deleted when the instances terminate. "" +\n             ""Only possible on EBS-backed AMIs. "" +\n             ""EBS volumes are only attached if --ebs-vol-size > 0. "" +\n             ""Only support up to 8 EBS volumes."")\n    parser.add_option(\n        ""--placement-group"", type=""string"", default=None,\n        help=""Which placement group to try and launch "" +\n             ""instances into. Assumes placement group is already "" +\n             ""created."")\n    parser.add_option(\n        ""--swap"", metavar=""SWAP"", type=""int"", default=1024,\n        help=""Swap space to set up per node, in MB (default: %default)"")\n    parser.add_option(\n        ""--spot-price"", metavar=""PRICE"", type=""float"",\n        help=""If specified, launch slaves as spot instances with the given "" +\n             ""maximum price (in dollars)"")\n    parser.add_option(\n        ""--ganglia"", action=""store_true"", default=True,\n        help=""Setup Ganglia monitoring on cluster (default: %default). NOTE: "" +\n             ""the Ganglia page will be publicly accessible"")\n    parser.add_option(\n        ""--no-ganglia"", action=""store_false"", dest=""ganglia"",\n        help=""Disable Ganglia monitoring for the cluster"")\n    parser.add_option(\n        ""-u"", ""--user"", default=""root"",\n        help=""The SSH user you want to connect as (default: %default)"")\n    parser.add_option(\n        ""--delete-groups"", action=""store_true"", default=False,\n        help=""When destroying a cluster, delete the security groups that were created"")\n    parser.add_option(\n        ""--use-existing-master"", action=""store_true"", default=False,\n        help=""Launch fresh slaves, but use an existing stopped master if possible"")\n    parser.add_option(\n        ""--worker-instances"", type=""int"", default=1,\n        help=""Number of instances per worker: variable SPARK_WORKER_INSTANCES. Not used if YARN "" +\n             ""is used as Hadoop major version (default: %default)"")\n    parser.add_option(\n        ""--master-opts"", type=""string"", default="""",\n        help=""Extra options to give to master through SPARK_MASTER_OPTS variable "" +\n             ""(e.g -Dspark.worker.timeout=180)"")\n    parser.add_option(\n        ""--user-data"", type=""string"", default="""",\n        help=""Path to a user-data file (most AMIs interpret this as an initialization script)"")\n    parser.add_option(\n        ""--authorized-address"", type=""string"", default=""0.0.0.0/0"",\n        help=""Address to authorize on created security groups (default: %default)"")\n    parser.add_option(\n        ""--additional-security-group"", type=""string"", default="""",\n        help=""Additional security group to place the machines in"")\n    parser.add_option(\n        ""--additional-tags"", type=""string"", default="""",\n        help=""Additional tags to set on the machines; tags are comma-separated, while name and "" +\n             ""value are colon separated; ex: \\""Task:MySparkProject,Env:production\\"""")\n    parser.add_option(\n        ""--copy-aws-credentials"", action=""store_true"", default=False,\n        help=""Add AWS credentials to hadoop configuration to allow Spark to access S3"")\n    parser.add_option(\n        ""--subnet-id"", default=None,\n        help=""VPC subnet to launch instances in"")\n    parser.add_option(\n        ""--vpc-id"", default=None,\n        help=""VPC to launch instances in"")\n    parser.add_option(\n        ""--private-ips"", action=""store_true"", default=False,\n        help=""Use private IPs for instances rather than public if VPC/subnet "" +\n             ""requires that."")\n    parser.add_option(\n        ""--instance-initiated-shutdown-behavior"", default=""stop"",\n        choices=[""stop"", ""terminate""],\n        help=""Whether instances should terminate when shut down or just stop"")\n    parser.add_option(\n        ""--instance-profile-name"", default=None,\n        help=""IAM profile name to launch instances under"")\n\n    (opts, args) = parser.parse_args()\n    if len(args) != 2:\n        parser.print_help()\n        sys.exit(1)\n    (action, cluster_name) = args\n\n    # Boto config check\n    # http://boto.cloudhackers.com/en/latest/boto_config_tut.html\n    home_dir = os.getenv(\'HOME\')\n    if home_dir is None or not os.path.isfile(home_dir + \'/.boto\'):\n        if not os.path.isfile(\'/etc/boto.cfg\'):\n            # If there is no boto config, check aws credentials\n            if not os.path.isfile(home_dir + \'/.aws/credentials\'):\n                if os.getenv(\'AWS_ACCESS_KEY_ID\') is None:\n                    print(""ERROR: The environment variable AWS_ACCESS_KEY_ID must be set"",\n                          file=stderr)\n                    sys.exit(1)\n                if os.getenv(\'AWS_SECRET_ACCESS_KEY\') is None:\n                    print(""ERROR: The environment variable AWS_SECRET_ACCESS_KEY must be set"",\n                          file=stderr)\n                    sys.exit(1)\n    return (opts, action, cluster_name)\n\n\n# Get the EC2 security group of the given name, creating it if it doesn\'t exist\ndef get_or_make_group(conn, name, vpc_id):\n    groups = conn.get_all_security_groups()\n    group = [g for g in groups if g.name == name]\n    if len(group) > 0:\n        return group[0]\n    else:\n        print(""Creating security group "" + name)\n        return conn.create_security_group(name, ""Spark EC2 group"", vpc_id)\n\n\ndef get_validate_spark_version(version, repo):\n    if ""."" in version:\n        version = version.replace(""v"", """")\n        if version not in VALID_SPARK_VERSIONS:\n            print(""Don\'t know about Spark version: {v}"".format(v=version), file=stderr)\n            sys.exit(1)\n        return version\n    else:\n        github_commit_url = ""{repo}/commit/{commit_hash}"".format(repo=repo, commit_hash=version)\n        request = Request(github_commit_url)\n        request.get_method = lambda: \'HEAD\'\n        try:\n            response = urlopen(request)\n        except HTTPError as e:\n            print(""Couldn\'t validate Spark commit: {url}"".format(url=github_commit_url),\n                  file=stderr)\n            print(""Received HTTP response code of {code}."".format(code=e.code), file=stderr)\n            sys.exit(1)\n        return version\n\n\n# Source: http://aws.amazon.com/amazon-linux-ami/instance-type-matrix/\n# Last Updated: 2015-06-19\n# For easy maintainability, please keep this manually-inputted dictionary sorted by key.\nEC2_INSTANCE_TYPES = {\n    ""c1.medium"":   ""pvm"",\n    ""c1.xlarge"":   ""pvm"",\n    ""c3.large"":    ""pvm"",\n    ""c3.xlarge"":   ""pvm"",\n    ""c3.2xlarge"":  ""pvm"",\n    ""c3.4xlarge"":  ""pvm"",\n    ""c3.8xlarge"":  ""pvm"",\n    ""c4.large"":    ""hvm"",\n    ""c4.xlarge"":   ""hvm"",\n    ""c4.2xlarge"":  ""hvm"",\n    ""c4.4xlarge"":  ""hvm"",\n    ""c4.8xlarge"":  ""hvm"",\n    ""cc1.4xlarge"": ""hvm"",\n    ""cc2.8xlarge"": ""hvm"",\n    ""cg1.4xlarge"": ""hvm"",\n    ""cr1.8xlarge"": ""hvm"",\n    ""d2.xlarge"":   ""hvm"",\n    ""d2.2xlarge"":  ""hvm"",\n    ""d2.4xlarge"":  ""hvm"",\n    ""d2.8xlarge"":  ""hvm"",\n    ""g2.2xlarge"":  ""hvm"",\n    ""g2.8xlarge"":  ""hvm"",\n    ""hi1.4xlarge"": ""pvm"",\n    ""hs1.8xlarge"": ""pvm"",\n    ""i2.xlarge"":   ""hvm"",\n    ""i2.2xlarge"":  ""hvm"",\n    ""i2.4xlarge"":  ""hvm"",\n    ""i2.8xlarge"":  ""hvm"",\n    ""m1.small"":    ""pvm"",\n    ""m1.medium"":   ""pvm"",\n    ""m1.large"":    ""pvm"",\n    ""m1.xlarge"":   ""pvm"",\n    ""m2.xlarge"":   ""pvm"",\n    ""m2.2xlarge"":  ""pvm"",\n    ""m2.4xlarge"":  ""pvm"",\n    ""m3.medium"":   ""hvm"",\n    ""m3.large"":    ""hvm"",\n    ""m3.xlarge"":   ""hvm"",\n    ""m3.2xlarge"":  ""hvm"",\n    ""m4.large"":    ""hvm"",\n    ""m4.xlarge"":   ""hvm"",\n    ""m4.2xlarge"":  ""hvm"",\n    ""m4.4xlarge"":  ""hvm"",\n    ""m4.10xlarge"": ""hvm"",\n    ""p2.large"":    ""hvm"",\n    ""p2.8xlarge"":  ""hvm"",\n    ""p2.16xlarge"": ""hvm"",\n    ""r3.large"":    ""hvm"",\n    ""r3.xlarge"":   ""hvm"",\n    ""r3.2xlarge"":  ""hvm"",\n    ""r3.4xlarge"":  ""hvm"",\n    ""r3.8xlarge"":  ""hvm"",\n    ""t1.micro"":    ""pvm"",\n    ""t2.micro"":    ""hvm"",\n    ""t2.small"":    ""hvm"",\n    ""t2.medium"":   ""hvm"",\n    ""t2.large"":    ""hvm"",\n}\n\n\ndef get_tachyon_version(spark_version):\n    return SPARK_TACHYON_MAP.get(spark_version, """")\n\n\n# Attempt to resolve an appropriate AMI given the architecture and region of the request.\ndef get_spark_ami(opts):\n    if opts.instance_type in EC2_INSTANCE_TYPES:\n        instance_type = EC2_INSTANCE_TYPES[opts.instance_type]\n    else:\n        instance_type = ""pvm""\n        print(""Don\'t recognize %s, assuming type is pvm"" % opts.instance_type, file=stderr)\n\n    # URL prefix from which to fetch AMI information\n    ami_prefix = ""{r}/{b}/ami-list"".format(\n        r=opts.spark_ec2_git_repo.replace(""https://github.com"", ""https://raw.github.com"", 1),\n        b=opts.spark_ec2_git_branch)\n\n    ami_path = ""%s/%s/%s"" % (ami_prefix, opts.region, instance_type)\n    reader = codecs.getreader(""ascii"")\n    try:\n        ami = reader(urlopen(ami_path)).read().strip()\n    except:\n        print(""Could not resolve AMI at: "" + ami_path, file=stderr)\n        sys.exit(1)\n\n    print(""Spark AMI: "" + ami)\n    return ami\n\n\n# Launch a cluster of the given name, by setting up its security groups,\n# and then starting new instances in them.\n# Returns a tuple of EC2 reservation objects for the master and slaves\n# Fails if there already instances running in the cluster\'s groups.\ndef launch_cluster(conn, opts, cluster_name):\n    if opts.identity_file is None:\n        print(""ERROR: Must provide an identity file (-i) for ssh connections."", file=stderr)\n        sys.exit(1)\n\n    if opts.key_pair is None:\n        print(""ERROR: Must provide a key pair name (-k) to use on instances."", file=stderr)\n        sys.exit(1)\n\n    user_data_content = None\n    if opts.user_data:\n        with open(opts.user_data) as user_data_file:\n            user_data_content = user_data_file.read()\n\n    print(""Setting up security groups..."")\n    master_group = get_or_make_group(conn, cluster_name + ""-master"", opts.vpc_id)\n    slave_group = get_or_make_group(conn, cluster_name + ""-slaves"", opts.vpc_id)\n    authorized_address = opts.authorized_address\n    if master_group.rules == []:  # Group was just now created\n        if opts.vpc_id is None:\n            master_group.authorize(src_group=master_group)\n            master_group.authorize(src_group=slave_group)\n        else:\n            master_group.authorize(ip_protocol=\'icmp\', from_port=-1, to_port=-1,\n                                   src_group=master_group)\n            master_group.authorize(ip_protocol=\'tcp\', from_port=0, to_port=65535,\n                                   src_group=master_group)\n            master_group.authorize(ip_protocol=\'udp\', from_port=0, to_port=65535,\n                                   src_group=master_group)\n            master_group.authorize(ip_protocol=\'icmp\', from_port=-1, to_port=-1,\n                                   src_group=slave_group)\n            master_group.authorize(ip_protocol=\'tcp\', from_port=0, to_port=65535,\n                                   src_group=slave_group)\n            master_group.authorize(ip_protocol=\'udp\', from_port=0, to_port=65535,\n                                   src_group=slave_group)\n        master_group.authorize(\'tcp\', 22, 22, authorized_address)\n        master_group.authorize(\'tcp\', 8080, 8081, authorized_address)\n        master_group.authorize(\'tcp\', 18080, 18080, authorized_address)\n        master_group.authorize(\'tcp\', 19999, 19999, authorized_address)\n        master_group.authorize(\'tcp\', 50030, 50030, authorized_address)\n        master_group.authorize(\'tcp\', 50070, 50070, authorized_address)\n        master_group.authorize(\'tcp\', 60070, 60070, authorized_address)\n        master_group.authorize(\'tcp\', 4040, 4045, authorized_address)\n        # HDFS NFS gateway requires 111,2049,4242 for tcp & udp\n        master_group.authorize(\'tcp\', 111, 111, authorized_address)\n        master_group.authorize(\'udp\', 111, 111, authorized_address)\n        master_group.authorize(\'tcp\', 2049, 2049, authorized_address)\n        master_group.authorize(\'udp\', 2049, 2049, authorized_address)\n        master_group.authorize(\'tcp\', 4242, 4242, authorized_address)\n        master_group.authorize(\'udp\', 4242, 4242, authorized_address)\n        # RM in YARN mode uses 8088\n        master_group.authorize(\'tcp\', 8088, 8088, authorized_address)\n        if opts.ganglia:\n            master_group.authorize(\'tcp\', 5080, 5080, authorized_address)\n    if slave_group.rules == []:  # Group was just now created\n        if opts.vpc_id is None:\n            slave_group.authorize(src_group=master_group)\n            slave_group.authorize(src_group=slave_group)\n        else:\n            slave_group.authorize(ip_protocol=\'icmp\', from_port=-1, to_port=-1,\n                                  src_group=master_group)\n            slave_group.authorize(ip_protocol=\'tcp\', from_port=0, to_port=65535,\n                                  src_group=master_group)\n            slave_group.authorize(ip_protocol=\'udp\', from_port=0, to_port=65535,\n                                  src_group=master_group)\n            slave_group.authorize(ip_protocol=\'icmp\', from_port=-1, to_port=-1,\n                                  src_group=slave_group)\n            slave_group.authorize(ip_protocol=\'tcp\', from_port=0, to_port=65535,\n                                  src_group=slave_group)\n            slave_group.authorize(ip_protocol=\'udp\', from_port=0, to_port=65535,\n                                  src_group=slave_group)\n        slave_group.authorize(\'tcp\', 22, 22, authorized_address)\n        slave_group.authorize(\'tcp\', 8080, 8081, authorized_address)\n        slave_group.authorize(\'tcp\', 50060, 50060, authorized_address)\n        slave_group.authorize(\'tcp\', 50075, 50075, authorized_address)\n        slave_group.authorize(\'tcp\', 60060, 60060, authorized_address)\n        slave_group.authorize(\'tcp\', 60075, 60075, authorized_address)\n\n    # Check if instances are already running in our groups\n    existing_masters, existing_slaves = get_existing_cluster(conn, opts, cluster_name,\n                                                             die_on_error=False)\n    if existing_slaves or (existing_masters and not opts.use_existing_master):\n        print(""ERROR: There are already instances running in group %s or %s"" %\n              (master_group.name, slave_group.name), file=stderr)\n        sys.exit(1)\n\n    # Figure out Spark AMI\n    if opts.ami is None:\n        opts.ami = get_spark_ami(opts)\n\n    # we use group ids to work around https://github.com/boto/boto/issues/350\n    additional_group_ids = []\n    if opts.additional_security_group:\n        additional_group_ids = [sg.id\n                                for sg in conn.get_all_security_groups()\n                                if opts.additional_security_group in (sg.name, sg.id)]\n    print(""Launching instances..."")\n\n    try:\n        image = conn.get_all_images(image_ids=[opts.ami])[0]\n    except:\n        print(""Could not find AMI "" + opts.ami, file=stderr)\n        sys.exit(1)\n\n    # Create block device mapping so that we can add EBS volumes if asked to.\n    # The first drive is attached as /dev/sds, 2nd as /dev/sdt, ... /dev/sdz\n    block_map = BlockDeviceMapping()\n    if opts.ebs_vol_size > 0:\n        for i in range(opts.ebs_vol_num):\n            device = EBSBlockDeviceType()\n            device.size = opts.ebs_vol_size\n            device.volume_type = opts.ebs_vol_type\n            device.delete_on_termination = True\n            block_map[""/dev/sd"" + chr(ord(\'s\') + i)] = device\n\n    # AWS ignores the AMI-specified block device mapping for M3 (see SPARK-3342).\n    if opts.instance_type.startswith(\'m3.\'):\n        for i in range(get_num_disks(opts.instance_type)):\n            dev = BlockDeviceType()\n            dev.ephemeral_name = \'ephemeral%d\' % i\n            # The first ephemeral drive is /dev/sdb.\n            name = \'/dev/sd\' + string.ascii_letters[i + 1]\n            block_map[name] = dev\n\n    # Launch slaves\n    if opts.spot_price is not None:\n        # Launch spot instances with the requested price\n        print(""Requesting %d slaves as spot instances with price $%.3f"" %\n              (opts.slaves, opts.spot_price))\n        zones = get_zones(conn, opts)\n        num_zones = len(zones)\n        i = 0\n        my_req_ids = []\n        for zone in zones:\n            num_slaves_this_zone = get_partition(opts.slaves, num_zones, i)\n            slave_reqs = conn.request_spot_instances(\n                price=opts.spot_price,\n                image_id=opts.ami,\n                launch_group=""launch-group-%s"" % cluster_name,\n                placement=zone,\n                count=num_slaves_this_zone,\n                key_name=opts.key_pair,\n                security_group_ids=[slave_group.id] + additional_group_ids,\n                instance_type=opts.instance_type,\n                block_device_map=block_map,\n                subnet_id=opts.subnet_id,\n                placement_group=opts.placement_group,\n                user_data=user_data_content,\n                instance_profile_name=opts.instance_profile_name)\n            my_req_ids += [req.id for req in slave_reqs]\n            i += 1\n\n        print(""Waiting for spot instances to be granted..."")\n        try:\n            while True:\n                time.sleep(10)\n                reqs = conn.get_all_spot_instance_requests()\n                id_to_req = {}\n                for r in reqs:\n                    id_to_req[r.id] = r\n                active_instance_ids = []\n                for i in my_req_ids:\n                    if i in id_to_req and id_to_req[i].state == ""active"":\n                        active_instance_ids.append(id_to_req[i].instance_id)\n                if len(active_instance_ids) == opts.slaves:\n                    print(""All %d slaves granted"" % opts.slaves)\n                    reservations = conn.get_all_reservations(active_instance_ids)\n                    slave_nodes = []\n                    for r in reservations:\n                        slave_nodes += r.instances\n                    break\n                else:\n                    print(""%d of %d slaves granted, waiting longer"" % (\n                        len(active_instance_ids), opts.slaves))\n        except:\n            print(""Canceling spot instance requests"")\n            conn.cancel_spot_instance_requests(my_req_ids)\n            # Log a warning if any of these requests actually launched instances:\n            (master_nodes, slave_nodes) = get_existing_cluster(\n                conn, opts, cluster_name, die_on_error=False)\n            running = len(master_nodes) + len(slave_nodes)\n            if running:\n                print((""WARNING: %d instances are still running"" % running), file=stderr)\n            sys.exit(0)\n    else:\n        # Launch non-spot instances\n        zones = get_zones(conn, opts)\n        num_zones = len(zones)\n        i = 0\n        slave_nodes = []\n        for zone in zones:\n            num_slaves_this_zone = get_partition(opts.slaves, num_zones, i)\n            if num_slaves_this_zone > 0:\n                slave_res = image.run(\n                    key_name=opts.key_pair,\n                    security_group_ids=[slave_group.id] + additional_group_ids,\n                    instance_type=opts.instance_type,\n                    placement=zone,\n                    min_count=num_slaves_this_zone,\n                    max_count=num_slaves_this_zone,\n                    block_device_map=block_map,\n                    subnet_id=opts.subnet_id,\n                    placement_group=opts.placement_group,\n                    user_data=user_data_content,\n                    instance_initiated_shutdown_behavior=opts.instance_initiated_shutdown_behavior,\n                    instance_profile_name=opts.instance_profile_name)\n                slave_nodes += slave_res.instances\n                print(""Launched {s} slave{plural_s} in {z}, regid = {r}"".format(\n                      s=num_slaves_this_zone,\n                      plural_s=(\'\' if num_slaves_this_zone == 1 else \'s\'),\n                      z=zone,\n                      r=slave_res.id))\n            i += 1\n\n    # Launch or resume masters\n    if existing_masters:\n        print(""Starting master..."")\n        for inst in existing_masters:\n            if inst.state not in [""shutting-down"", ""terminated""]:\n                inst.start()\n        master_nodes = existing_masters\n    else:\n        master_type = opts.master_instance_type\n        if master_type == """":\n            master_type = opts.instance_type\n        if opts.zone == \'all\':\n            opts.zone = random.choice(conn.get_all_zones()).name\n        master_res = image.run(\n            key_name=opts.key_pair,\n            security_group_ids=[master_group.id] + additional_group_ids,\n            instance_type=master_type,\n            placement=opts.zone,\n            min_count=1,\n            max_count=1,\n            block_device_map=block_map,\n            subnet_id=opts.subnet_id,\n            placement_group=opts.placement_group,\n            user_data=user_data_content,\n            instance_initiated_shutdown_behavior=opts.instance_initiated_shutdown_behavior,\n            instance_profile_name=opts.instance_profile_name)\n\n        master_nodes = master_res.instances\n        print(""Launched master in %s, regid = %s"" % (zone, master_res.id))\n\n    # This wait time corresponds to SPARK-4983\n    print(""Waiting for AWS to propagate instance metadata..."")\n    time.sleep(15)\n\n    # Give the instances descriptive names and set additional tags\n    additional_tags = {}\n    if opts.additional_tags.strip():\n        additional_tags = dict(\n            map(str.strip, tag.split(\':\', 1)) for tag in opts.additional_tags.split(\',\')\n        )\n\n    for master in master_nodes:\n        master.add_tags(\n            dict(additional_tags, Name=\'{cn}-master-{iid}\'.format(cn=cluster_name, iid=master.id))\n        )\n\n    for slave in slave_nodes:\n        slave.add_tags(\n            dict(additional_tags, Name=\'{cn}-slave-{iid}\'.format(cn=cluster_name, iid=slave.id))\n        )\n\n    # Return all the instances\n    return (master_nodes, slave_nodes)\n\n\ndef get_existing_cluster(conn, opts, cluster_name, die_on_error=True):\n    """"""\n    Get the EC2 instances in an existing cluster if available.\n    Returns a tuple of lists of EC2 instance objects for the masters and slaves.\n    """"""\n    print(""Searching for existing cluster {c} in region {r}..."".format(\n          c=cluster_name, r=opts.region))\n\n    def get_instances(group_names):\n        """"""\n        Get all non-terminated instances that belong to any of the provided security groups.\n\n        EC2 reservation filters and instance states are documented here:\n            http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html#options\n        """"""\n        reservations = conn.get_all_reservations(\n            filters={""instance.group-name"": group_names})\n        instances = itertools.chain.from_iterable(r.instances for r in reservations)\n        return [i for i in instances if i.state not in [""shutting-down"", ""terminated""]]\n\n    master_instances = get_instances([cluster_name + ""-master""])\n    slave_instances = get_instances([cluster_name + ""-slaves""])\n\n    if any((master_instances, slave_instances)):\n        print(""Found {m} master{plural_m}, {s} slave{plural_s}."".format(\n              m=len(master_instances),\n              plural_m=(\'\' if len(master_instances) == 1 else \'s\'),\n              s=len(slave_instances),\n              plural_s=(\'\' if len(slave_instances) == 1 else \'s\')))\n\n    if not master_instances and die_on_error:\n        print(""ERROR: Could not find a master for cluster {c} in region {r}."".format(\n              c=cluster_name, r=opts.region), file=sys.stderr)\n        sys.exit(1)\n\n    return (master_instances, slave_instances)\n\n\n\n# Execute a cmd on master and slave nodes\ndef ssh_cluster(master_nodes, slave_nodes, opts, cmd):\n    master = get_dns_name(master_nodes[0], opts.private_ips)\n    ssh(master, opts, cmd)\n    for slave in slave_nodes:\n        slave_address = get_dns_name(slave, opts.private_ips)\n        ssh(slave_address, opts, cmd)\n\n# Deploy configuration files and run setup scripts on a newly launched\n# or started EC2 cluster.\ndef setup_cluster(conn, master_nodes, slave_nodes, opts, deploy_ssh_key):\n    master = get_dns_name(master_nodes[0], opts.private_ips)\n    if deploy_ssh_key:\n        print(""Generating cluster\'s SSH key on master..."")\n        key_setup = """"""\n          [ -f ~/.ssh/id_rsa ] ||\n            (ssh-keygen -q -t rsa -N \'\' -f ~/.ssh/id_rsa &&\n             cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\n        """"""\n        ssh(master, opts, key_setup)\n        dot_ssh_tar = ssh_read(master, opts, [\'tar\', \'c\', \'.ssh\'])\n        print(""Transferring cluster\'s SSH key to slaves..."")\n        for slave in slave_nodes:\n            slave_address = get_dns_name(slave, opts.private_ips)\n            print(slave_address)\n            ssh_write(slave_address, opts, [\'tar\', \'x\'], dot_ssh_tar)\n\n    modules = [\'spark\', \'ephemeral-hdfs\', \'persistent-hdfs\',\n               \'mapreduce\', \'spark-standalone\']\n\n    if opts.hadoop_major_version == ""1"":\n        modules = list(filter(lambda x: x != ""mapreduce"", modules))\n\n    if opts.ganglia:\n        modules.append(\'ganglia\')\n\n    # Clear SPARK_WORKER_INSTANCES if running on YARN\n    if opts.hadoop_major_version == ""yarn"":\n        opts.worker_instances = """"\n\n    # NOTE: We should clone the repository before running deploy_files to\n    # prevent ec2-variables.sh from being overwritten\n    print(""Cloning spark-ec2 scripts from {r}/tree/{b} on master..."".format(\n        r=opts.spark_ec2_git_repo, b=opts.spark_ec2_git_branch))\n    ssh(\n        host=master,\n        opts=opts,\n        command=""rm -rf spark-ec2""\n        + "" && ""\n        + ""git clone {r} -b {b} spark-ec2"".format(r=opts.spark_ec2_git_repo,\n                                                  b=opts.spark_ec2_git_branch)\n    )\n\n    print(""Deploying files to master..."")\n    deploy_files(\n        conn=conn,\n        root_dir=SPARK_EC2_DIR + ""/"" + ""deploy.generic"",\n        opts=opts,\n        master_nodes=master_nodes,\n        slave_nodes=slave_nodes,\n        modules=modules\n    )\n\n    if opts.deploy_root_dir is not None:\n        print(""Deploying {s} to master..."".format(s=opts.deploy_root_dir))\n        deploy_user_files(\n            root_dir=opts.deploy_root_dir,\n            opts=opts,\n            master_nodes=master_nodes\n        )\n\n    print(""Running setup on master..."")\n    setup_spark_cluster(master, opts)\n\n    print(""Done!"")\n\n\ndef setup_spark_cluster(master, opts):\n    ssh(master, opts, ""chmod u+x spark-ec2/setup.sh"")\n    ssh(master, opts, ""spark-ec2/setup.sh"")\n    print(""Spark standalone cluster started at http://%s:8080"" % master)\n\n    if opts.ganglia:\n        print(""Ganglia started at http://%s:5080/ganglia"" % master)\n\n\ndef is_ssh_available(host, opts, print_ssh_output=True):\n    """"""\n    Check if SSH is available on a host.\n    """"""\n    s = subprocess.Popen(\n        ssh_command(opts) + [\'-t\', \'-t\', \'-o\', \'ConnectTimeout=3\',\n                             \'%s@%s\' % (opts.user, host), stringify_command(\'true\')],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT  # we pipe stderr through stdout to preserve output order\n    )\n    cmd_output = s.communicate()[0]  # [1] is stderr, which we redirected to stdout\n\n    if s.returncode != 0 and print_ssh_output:\n        # extra leading newline is for spacing in wait_for_cluster_state()\n        print(textwrap.dedent(""""""\\n\n            Warning: SSH connection error. (This could be temporary.)\n            Host: {h}\n            SSH return code: {r}\n            SSH output: {o}\n        """""").format(\n            h=host,\n            r=s.returncode,\n            o=cmd_output.strip()\n        ))\n\n    return s.returncode == 0\n\n\ndef is_cluster_ssh_available(cluster_instances, opts):\n    """"""\n    Check if SSH is available on all the instances in a cluster.\n    """"""\n    for i in cluster_instances:\n        dns_name = get_dns_name(i, opts.private_ips)\n        if not is_ssh_available(host=dns_name, opts=opts):\n            return False\n    else:\n        return True\n\n\ndef wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n    """"""\n    Wait for all the instances in the cluster to reach a designated state.\n\n    cluster_instances: a list of boto.ec2.instance.Instance\n    cluster_state: a string representing the desired state of all the instances in the cluster\n           value can be \'ssh-ready\' or a valid value from boto.ec2.instance.InstanceState such as\n           \'running\', \'terminated\', etc.\n           (would be nice to replace this with a proper enum: http://stackoverflow.com/a/1695250)\n    """"""\n    sys.stdout.write(\n        ""Waiting for cluster to enter \'{s}\' state."".format(s=cluster_state)\n    )\n    sys.stdout.flush()\n\n    start_time = datetime.now()\n    num_attempts = 0\n\n    while True:\n        time.sleep(5 * num_attempts)  # seconds\n\n        for i in cluster_instances:\n            i.update()\n\n        max_batch = 100\n        statuses = []\n        for j in xrange(0, len(cluster_instances), max_batch):\n            batch = [i.id for i in cluster_instances[j:j + max_batch]]\n            statuses.extend(conn.get_all_instance_status(instance_ids=batch))\n\n        if cluster_state == \'ssh-ready\':\n            if all(i.state == \'running\' for i in cluster_instances) and \\\n               all(s.system_status.status == \'ok\' for s in statuses) and \\\n               all(s.instance_status.status == \'ok\' for s in statuses) and \\\n               is_cluster_ssh_available(cluster_instances, opts):\n                break\n        else:\n            if all(i.state == cluster_state for i in cluster_instances):\n                break\n\n        num_attempts += 1\n\n        sys.stdout.write(""."")\n        sys.stdout.flush()\n\n    sys.stdout.write(""\\n"")\n\n    end_time = datetime.now()\n    print(""Cluster is now in \'{s}\' state. Waited {t} seconds."".format(\n        s=cluster_state,\n        t=(end_time - start_time).seconds\n    ))\n\n\n# Get number of local disks available for a given EC2 instance type.\ndef get_num_disks(instance_type):\n    # Source: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html\n    # Last Updated: 2015-06-19\n    # For easy maintainability, please keep this manually-inputted dictionary sorted by key.\n    disks_by_instance = {\n        ""c1.medium"":   1,\n        ""c1.xlarge"":   4,\n        ""c3.large"":    2,\n        ""c3.xlarge"":   2,\n        ""c3.2xlarge"":  2,\n        ""c3.4xlarge"":  2,\n        ""c3.8xlarge"":  2,\n        ""c4.large"":    0,\n        ""c4.xlarge"":   0,\n        ""c4.2xlarge"":  0,\n        ""c4.4xlarge"":  0,\n        ""c4.8xlarge"":  0,\n        ""cc1.4xlarge"": 2,\n        ""cc2.8xlarge"": 4,\n        ""cg1.4xlarge"": 2,\n        ""cr1.8xlarge"": 2,\n        ""d2.xlarge"":   3,\n        ""d2.2xlarge"":  6,\n        ""d2.4xlarge"":  12,\n        ""d2.8xlarge"":  24,\n        ""g2.2xlarge"":  1,\n        ""g2.8xlarge"":  2,\n        ""hi1.4xlarge"": 2,\n        ""hs1.8xlarge"": 24,\n        ""i2.xlarge"":   1,\n        ""i2.2xlarge"":  2,\n        ""i2.4xlarge"":  4,\n        ""i2.8xlarge"":  8,\n        ""m1.small"":    1,\n        ""m1.medium"":   1,\n        ""m1.large"":    2,\n        ""m1.xlarge"":   4,\n        ""m2.xlarge"":   1,\n        ""m2.2xlarge"":  1,\n        ""m2.4xlarge"":  2,\n        ""m3.medium"":   1,\n        ""m3.large"":    1,\n        ""m3.xlarge"":   2,\n        ""m3.2xlarge"":  2,\n        ""m4.large"":    0,\n        ""m4.xlarge"":   0,\n        ""m4.2xlarge"":  0,\n        ""m4.4xlarge"":  0,\n        ""m4.10xlarge"": 0,\n        ""p2.large"":    0,\n        ""p2.8xlarge"":  0,\n        ""p2.16xlarge"": 0,\n        ""r3.large"":    1,\n        ""r3.xlarge"":   1,\n        ""r3.2xlarge"":  1,\n        ""r3.4xlarge"":  1,\n        ""r3.8xlarge"":  2,\n        ""t1.micro"":    0,\n        ""t2.micro"":    0,\n        ""t2.small"":    0,\n        ""t2.medium"":   0,\n        ""t2.large"":    0,\n    }\n    if instance_type in disks_by_instance:\n        return disks_by_instance[instance_type]\n    else:\n        print(""WARNING: Don\'t know number of disks on instance type %s; assuming 1""\n              % instance_type, file=stderr)\n        return 1\n\n\n# Deploy the configuration file templates in a given local directory to\n# a cluster, filling in any template parameters with information about the\n# cluster (e.g. lists of masters and slaves). Files are only deployed to\n# the first master instance in the cluster, and we expect the setup\n# script to be run on that instance to copy them to other nodes.\n#\n# root_dir should be an absolute path to the directory with the files we want to deploy.\ndef deploy_files(conn, root_dir, opts, master_nodes, slave_nodes, modules):\n    active_master = get_dns_name(master_nodes[0], opts.private_ips)\n\n    num_disks = get_num_disks(opts.instance_type)\n    hdfs_data_dirs = ""/mnt/ephemeral-hdfs/data""\n    mapred_local_dirs = ""/mnt/hadoop/mrlocal""\n    spark_local_dirs = ""/mnt/spark""\n    if num_disks > 1:\n        for i in range(2, num_disks + 1):\n            hdfs_data_dirs += "",/mnt%d/ephemeral-hdfs/data"" % i\n            mapred_local_dirs += "",/mnt%d/hadoop/mrlocal"" % i\n            spark_local_dirs += "",/mnt%d/spark"" % i\n\n    cluster_url = ""%s:7077"" % active_master\n\n    if ""."" in opts.spark_version:\n        # Pre-built Spark deploy\n        spark_v = get_validate_spark_version(opts.spark_version, opts.spark_git_repo)\n        tachyon_v = get_tachyon_version(spark_v)\n    else:\n        # Spark-only custom deploy\n        spark_v = ""%s|%s"" % (opts.spark_git_repo, opts.spark_version)\n        tachyon_v = """"\n        print(""Deploying Spark via git hash; Tachyon won\'t be set up"")\n        modules = filter(lambda x: x != ""tachyon"", modules)\n\n    master_addresses = [get_dns_name(i, opts.private_ips) for i in master_nodes]\n    slave_addresses = [get_dns_name(i, opts.private_ips) for i in slave_nodes]\n    worker_instances_str = ""%d"" % opts.worker_instances if opts.worker_instances else """"\n    template_vars = {\n        ""master_list"": \'\\n\'.join(master_addresses),\n        ""active_master"": active_master,\n        ""slave_list"": \'\\n\'.join(slave_addresses),\n        ""cluster_url"": cluster_url,\n        ""hdfs_data_dirs"": hdfs_data_dirs,\n        ""mapred_local_dirs"": mapred_local_dirs,\n        ""spark_local_dirs"": spark_local_dirs,\n        ""swap"": str(opts.swap),\n        ""modules"": \'\\n\'.join(modules),\n        ""spark_version"": spark_v,\n        ""tachyon_version"": tachyon_v,\n        ""hadoop_major_version"": opts.hadoop_major_version,\n        ""spark_worker_instances"": worker_instances_str,\n        ""spark_master_opts"": opts.master_opts\n    }\n\n    if opts.copy_aws_credentials:\n        template_vars[""aws_access_key_id""] = conn.aws_access_key_id\n        template_vars[""aws_secret_access_key""] = conn.aws_secret_access_key\n    else:\n        template_vars[""aws_access_key_id""] = """"\n        template_vars[""aws_secret_access_key""] = """"\n\n    # Create a temp directory in which we will place all the files to be\n    # deployed after we substitue template parameters in them\n    tmp_dir = tempfile.mkdtemp()\n    for path, dirs, files in os.walk(root_dir):\n        if path.find("".svn"") == -1:\n            dest_dir = os.path.join(\'/\', path[len(root_dir):])\n            local_dir = tmp_dir + dest_dir\n            if not os.path.exists(local_dir):\n                os.makedirs(local_dir)\n            for filename in files:\n                if filename[0] not in \'#.~\' and filename[-1] != \'~\':\n                    dest_file = os.path.join(dest_dir, filename)\n                    local_file = tmp_dir + dest_file\n                    with open(os.path.join(path, filename)) as src:\n                        with open(local_file, ""w"") as dest:\n                            text = src.read()\n                            for key in template_vars:\n                                text = text.replace(""{{"" + key + ""}}"", template_vars[key])\n                            dest.write(text)\n                            dest.close()\n    # rsync the whole directory over to the master machine\n    command = [\n        \'rsync\', \'-rv\',\n        \'-e\', stringify_command(ssh_command(opts)),\n        ""%s/"" % tmp_dir,\n        ""%s@%s:/"" % (opts.user, active_master)\n    ]\n    subprocess.check_call(command)\n    # Remove the temp directory we created above\n    shutil.rmtree(tmp_dir)\n\n\n# Deploy a given local directory to a cluster, WITHOUT parameter substitution.\n# Note that unlike deploy_files, this works for binary files.\n# Also, it is up to the user to add (or not) the trailing slash in root_dir.\n# Files are only deployed to the first master instance in the cluster.\n#\n# root_dir should be an absolute path.\ndef deploy_user_files(root_dir, opts, master_nodes):\n    active_master = get_dns_name(master_nodes[0], opts.private_ips)\n    command = [\n        \'rsync\', \'-rv\',\n        \'-e\', stringify_command(ssh_command(opts)),\n        ""%s"" % root_dir,\n        ""%s@%s:/"" % (opts.user, active_master)\n    ]\n    subprocess.check_call(command)\n\n\ndef stringify_command(parts):\n    if isinstance(parts, str):\n        return parts\n    else:\n        return \' \'.join(map(pipes.quote, parts))\n\n\ndef ssh_args(opts):\n    parts = [\'-o\', \'StrictHostKeyChecking=no\']\n    parts += [\'-o\', \'UserKnownHostsFile=/dev/null\']\n    if opts.identity_file is not None:\n        parts += [\'-i\', opts.identity_file]\n    return parts\n\n\ndef ssh_command(opts):\n    return [\'ssh\'] + ssh_args(opts)\n\n\n# Run a command on a host through ssh, retrying up to five times\n# and then throwing an exception if ssh continues to fail.\ndef ssh(host, opts, command):\n    tries = 0\n    while True:\n        try:\n            return subprocess.check_call(\n                ssh_command(opts) + [\'-t\', \'-t\', \'%s@%s\' % (opts.user, host),\n                                     stringify_command(command)])\n        except subprocess.CalledProcessError as e:\n            if tries > 5:\n                # If this was an ssh failure, provide the user with hints.\n                if e.returncode == 255:\n                    raise UsageError(\n                        ""Failed to SSH to remote host {0}.\\n""\n                        ""Please check that you have provided the correct --identity-file and ""\n                        ""--key-pair parameters and try again."".format(host))\n                else:\n                    raise e\n            print(""Error executing remote command, retrying after 30 seconds: {0}"".format(e),\n                  file=stderr)\n            time.sleep(30)\n            tries = tries + 1\n\n\n# Backported from Python 2.7 for compatiblity with 2.6 (See SPARK-1990)\ndef _check_output(*popenargs, **kwargs):\n    if \'stdout\' in kwargs:\n        raise ValueError(\'stdout argument not allowed, it will be overridden.\')\n    process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)\n    output, unused_err = process.communicate()\n    retcode = process.poll()\n    if retcode:\n        cmd = kwargs.get(""args"")\n        if cmd is None:\n            cmd = popenargs[0]\n        raise subprocess.CalledProcessError(retcode, cmd, output=output)\n    return output\n\n\ndef ssh_read(host, opts, command):\n    return _check_output(\n        ssh_command(opts) + [\'%s@%s\' % (opts.user, host), stringify_command(command)])\n\n\ndef ssh_write(host, opts, command, arguments):\n    tries = 0\n    while True:\n        proc = subprocess.Popen(\n            ssh_command(opts) + [\'%s@%s\' % (opts.user, host), stringify_command(command)],\n            stdin=subprocess.PIPE)\n        proc.stdin.write(arguments)\n        proc.stdin.close()\n        status = proc.wait()\n        if status == 0:\n            break\n        elif tries > 5:\n            raise RuntimeError(""ssh_write failed with error %s"" % proc.returncode)\n        else:\n            print(""Error {0} while executing remote command, retrying after 30 seconds"".\n                  format(status), file=stderr)\n            time.sleep(30)\n            tries = tries + 1\n\n\n# Gets a list of zones to launch instances in\ndef get_zones(conn, opts):\n    if opts.zone == \'all\':\n        zones = [z.name for z in conn.get_all_zones()]\n    else:\n        zones = [opts.zone]\n    return zones\n\n\n# Gets the number of items in a partition\ndef get_partition(total, num_partitions, current_partitions):\n    num_slaves_this_zone = total // num_partitions\n    if (total % num_partitions) - current_partitions > 0:\n        num_slaves_this_zone += 1\n    return num_slaves_this_zone\n\n\n# Gets the IP address, taking into account the --private-ips flag\ndef get_ip_address(instance, private_ips=False):\n    ip = instance.ip_address if not private_ips else \\\n        instance.private_ip_address\n    return ip\n\n\n# Gets the DNS name, taking into account the --private-ips flag\ndef get_dns_name(instance, private_ips=False):\n    dns = instance.public_dns_name if not private_ips else \\\n        instance.private_ip_address\n    return dns\n\n\ndef real_main():\n    (opts, action, cluster_name) = parse_args()\n\n    # Input parameter validation\n    get_validate_spark_version(opts.spark_version, opts.spark_git_repo)\n\n    if opts.wait is not None:\n        # NOTE: DeprecationWarnings are silent in 2.7+ by default.\n        #       To show them, run Python with the -Wdefault switch.\n        # See: https://docs.python.org/3.5/whatsnew/2.7.html\n        warnings.warn(\n            ""This option is deprecated and has no effect. ""\n            ""spark-ec2 automatically waits as long as necessary for clusters to start up."",\n            DeprecationWarning\n        )\n\n    if opts.identity_file is not None:\n        if not os.path.exists(opts.identity_file):\n            print(""ERROR: The identity file \'{f}\' doesn\'t exist."".format(f=opts.identity_file),\n                  file=stderr)\n            sys.exit(1)\n\n        file_mode = os.stat(opts.identity_file).st_mode\n        if not (file_mode & S_IRUSR) or not oct(file_mode)[-2:] == \'00\':\n            print(""ERROR: The identity file must be accessible only by you."", file=stderr)\n            print(\'You can fix this with: chmod 400 ""{f}""\'.format(f=opts.identity_file),\n                  file=stderr)\n            sys.exit(1)\n\n    if opts.instance_type not in EC2_INSTANCE_TYPES:\n        print(""Warning: Unrecognized EC2 instance type for instance-type: {t}"".format(\n              t=opts.instance_type), file=stderr)\n\n    if opts.master_instance_type != """":\n        if opts.master_instance_type not in EC2_INSTANCE_TYPES:\n            print(""Warning: Unrecognized EC2 instance type for master-instance-type: {t}"".format(\n                  t=opts.master_instance_type), file=stderr)\n        # Since we try instance types even if we can\'t resolve them, we check if they resolve first\n        # and, if they do, see if they resolve to the same virtualization type.\n        if opts.instance_type in EC2_INSTANCE_TYPES and \\\n           opts.master_instance_type in EC2_INSTANCE_TYPES:\n            if EC2_INSTANCE_TYPES[opts.instance_type] != \\\n               EC2_INSTANCE_TYPES[opts.master_instance_type]:\n                print(""Error: spark-ec2 currently does not support having a master and slaves ""\n                      ""with different AMI virtualization types."", file=stderr)\n                print(""master instance virtualization type: {t}"".format(\n                      t=EC2_INSTANCE_TYPES[opts.master_instance_type]), file=stderr)\n                print(""slave instance virtualization type: {t}"".format(\n                      t=EC2_INSTANCE_TYPES[opts.instance_type]), file=stderr)\n                sys.exit(1)\n\n    if opts.ebs_vol_num > 8:\n        print(""ebs-vol-num cannot be greater than 8"", file=stderr)\n        sys.exit(1)\n\n    # Prevent breaking ami_prefix (/, .git and startswith checks)\n    # Prevent forks with non spark-ec2 names for now.\n    if opts.spark_ec2_git_repo.endswith(""/"") or \\\n            opts.spark_ec2_git_repo.endswith("".git"") or \\\n            not opts.spark_ec2_git_repo.startswith(""https://github.com"") or \\\n            not opts.spark_ec2_git_repo.endswith(""spark-ec2""):\n        print(""spark-ec2-git-repo must be a github repo and it must not have a trailing / or .git. ""\n              ""Furthermore, we currently only support forks named spark-ec2."", file=stderr)\n        sys.exit(1)\n\n    if not (opts.deploy_root_dir is None or\n            (os.path.isabs(opts.deploy_root_dir) and\n             os.path.isdir(opts.deploy_root_dir) and\n             os.path.exists(opts.deploy_root_dir))):\n        print(""--deploy-root-dir must be an absolute path to a directory that exists ""\n              ""on the local file system"", file=stderr)\n        sys.exit(1)\n\n    try:\n        if opts.profile is None:\n            conn = ec2.connect_to_region(opts.region)\n        else:\n            conn = ec2.connect_to_region(opts.region, profile_name=opts.profile)\n    except Exception as e:\n        print((e), file=stderr)\n        sys.exit(1)\n\n    # Select an AZ at random if it was not specified.\n    if opts.zone == """":\n        opts.zone = random.choice(conn.get_all_zones()).name\n\n    if action == ""launch"":\n        if opts.slaves <= 0:\n            print(""ERROR: You have to start at least 1 slave"", file=sys.stderr)\n            sys.exit(1)\n        if opts.resume:\n            (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n        else:\n            (master_nodes, slave_nodes) = launch_cluster(conn, opts, cluster_name)\n        wait_for_cluster_state(\n            conn=conn,\n            opts=opts,\n            cluster_instances=(master_nodes + slave_nodes),\n            cluster_state=\'ssh-ready\'\n        )\n        setup_cluster(conn, master_nodes, slave_nodes, opts, True)\n\n    elif action == ""destroy"":\n        (master_nodes, slave_nodes) = get_existing_cluster(\n            conn, opts, cluster_name, die_on_error=False)\n\n        if any(master_nodes + slave_nodes):\n            print(""The following instances will be terminated:"")\n            for inst in master_nodes + slave_nodes:\n                print(""> %s"" % get_dns_name(inst, opts.private_ips))\n            print(""ALL DATA ON ALL NODES WILL BE LOST!!"")\n\n        msg = ""Are you sure you want to destroy the cluster {c}? (y/N) "".format(c=cluster_name)\n        response = raw_input(msg)\n        if response == ""y"":\n            print(""Terminating master..."")\n            for inst in master_nodes:\n                inst.terminate()\n            print(""Terminating slaves..."")\n            for inst in slave_nodes:\n                inst.terminate()\n\n            # Delete security groups as well\n            if opts.delete_groups:\n                group_names = [cluster_name + ""-master"", cluster_name + ""-slaves""]\n                wait_for_cluster_state(\n                    conn=conn,\n                    opts=opts,\n                    cluster_instances=(master_nodes + slave_nodes),\n                    cluster_state=\'terminated\'\n                )\n                print(""Deleting security groups (this will take some time)..."")\n                attempt = 1\n                while attempt <= 3:\n                    print(""Attempt %d"" % attempt)\n                    groups = [g for g in conn.get_all_security_groups() if g.name in group_names]\n                    success = True\n                    # Delete individual rules in all groups before deleting groups to\n                    # remove dependencies between them\n                    for group in groups:\n                        print(""Deleting rules in security group "" + group.name)\n                        for rule in group.rules:\n                            for grant in rule.grants:\n                                success &= group.revoke(ip_protocol=rule.ip_protocol,\n                                                        from_port=rule.from_port,\n                                                        to_port=rule.to_port,\n                                                        src_group=grant)\n\n                    # Sleep for AWS eventual-consistency to catch up, and for instances\n                    # to terminate\n                    time.sleep(30)  # Yes, it does have to be this long :-(\n                    for group in groups:\n                        try:\n                            # It is needed to use group_id to make it work with VPC\n                            conn.delete_security_group(group_id=group.id)\n                            print(""Deleted security group %s"" % group.name)\n                        except boto.exception.EC2ResponseError:\n                            success = False\n                            print(""Failed to delete security group %s"" % group.name)\n\n                    # Unfortunately, group.revoke() returns True even if a rule was not\n                    # deleted, so this needs to be rerun if something fails\n                    if success:\n                        break\n\n                    attempt += 1\n\n                if not success:\n                    print(""Failed to delete all security groups after 3 tries."")\n                    print(""Try re-running in a few minutes."")\n\n    elif action == ""login"":\n        (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n        if not master_nodes[0].public_dns_name and not opts.private_ips:\n            print(""Master has no public DNS name.  Maybe you meant to specify --private-ips?"")\n        else:\n            master = get_dns_name(master_nodes[0], opts.private_ips)\n            print(""Logging into master "" + master + ""..."")\n            proxy_opt = []\n            if opts.proxy_port is not None:\n                proxy_opt = [\'-D\', opts.proxy_port]\n            subprocess.check_call(\n                ssh_command(opts) + proxy_opt + [\'-t\', \'-t\', ""%s@%s"" % (opts.user, master)])\n\n    elif action == ""reboot-slaves"":\n        response = raw_input(\n            ""Are you sure you want to reboot the cluster "" +\n            cluster_name + "" slaves?\\n"" +\n            ""Reboot cluster slaves "" + cluster_name + "" (y/N): "")\n        if response == ""y"":\n            (master_nodes, slave_nodes) = get_existing_cluster(\n                conn, opts, cluster_name, die_on_error=False)\n            print(""Rebooting slaves..."")\n            for inst in slave_nodes:\n                if inst.state not in [""shutting-down"", ""terminated""]:\n                    print(""Rebooting "" + inst.id)\n                    inst.reboot()\n\n    elif action == ""get-master"":\n        (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n        if not master_nodes[0].public_dns_name and not opts.private_ips:\n            print(""Master has no public DNS name.  Maybe you meant to specify --private-ips?"")\n        else:\n            print(get_dns_name(master_nodes[0], opts.private_ips))\n\n    elif action == ""stop"":\n        response = raw_input(\n            ""Are you sure you want to stop the cluster "" +\n            cluster_name + ""?\\nDATA ON EPHEMERAL DISKS WILL BE LOST, "" +\n            ""BUT THE CLUSTER WILL KEEP USING SPACE ON\\n"" +\n            ""AMAZON EBS IF IT IS EBS-BACKED!!\\n"" +\n            ""All data on spot-instance slaves will be lost.\\n"" +\n            ""Stop cluster "" + cluster_name + "" (y/N): "")\n        if response == ""y"":\n            (master_nodes, slave_nodes) = get_existing_cluster(\n                conn, opts, cluster_name, die_on_error=False)\n            print(""Stopping master..."")\n            for inst in master_nodes:\n                if inst.state not in [""shutting-down"", ""terminated""]:\n                    inst.stop()\n            print(""Stopping slaves..."")\n            for inst in slave_nodes:\n                if inst.state not in [""shutting-down"", ""terminated""]:\n                    if inst.spot_instance_request_id:\n                        inst.terminate()\n                    else:\n                        inst.stop()\n\n    elif action == ""start"":\n        (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n        print(""Starting slaves..."")\n        for inst in slave_nodes:\n            if inst.state not in [""shutting-down"", ""terminated""]:\n                inst.start()\n        print(""Starting master..."")\n        for inst in master_nodes:\n            if inst.state not in [""shutting-down"", ""terminated""]:\n                inst.start()\n        wait_for_cluster_state(\n            conn=conn,\n            opts=opts,\n            cluster_instances=(master_nodes + slave_nodes),\n            cluster_state=\'ssh-ready\'\n        )\n\n        # Determine types of running instances\n        existing_master_type = master_nodes[0].instance_type\n        existing_slave_type = slave_nodes[0].instance_type\n        # Setting opts.master_instance_type to the empty string indicates we\n        # have the same instance type for the master and the slaves\n        if existing_master_type == existing_slave_type:\n            existing_master_type = """"\n        opts.master_instance_type = existing_master_type\n        opts.instance_type = existing_slave_type\n\n        setup_cluster(conn, master_nodes, slave_nodes, opts, False)\n\n    else:\n        print(""Invalid action: %s"" % action, file=stderr)\n        sys.exit(1)\n\n\ndef main():\n    try:\n        real_main()\n    except UsageError as e:\n        print(""\\nError:\\n"", e, file=stderr)\n        sys.exit(1)\n\n\nif __name__ == ""__main__"":\n    logging.basicConfig()\n    main()\n'"
tensorflowonspark/TFCluster.py,1,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""\nThis module provides a high-level API to manage the TensorFlowOnSpark cluster.\n\nThere are three main phases of operation:\n\n1. **Reservation/Startup** - reserves a port for the TensorFlow process on each executor, starts a multiprocessing.Manager to\n   listen for data/control messages, and then launches the Tensorflow main function on the executors.\n\n2. **Data feeding** - *For InputMode.SPARK only*. Sends RDD data to the TensorFlow nodes via each executor\'s multiprocessing.Manager.  PS\n   nodes will tie up their executors, so they won\'t receive any subsequent data feeding tasks.\n\n3. **Shutdown** - sends a shutdown control message to the multiprocessing.Managers of the PS nodes and pushes end-of-feed markers into the data\n   queues of the worker nodes.\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport logging\nimport os\nimport random\nimport signal\nimport sys\nimport threading\nimport time\nfrom pyspark.streaming import DStream\nfrom . import reservation\nfrom . import TFManager\nfrom . import TFSparkNode\n\nlogger = logging.getLogger(__name__)\n\n# status of TF background job\ntf_status = {}\n\n\nclass InputMode(object):\n  """"""Enum for the input modes of data feeding.""""""\n  TENSORFLOW = 0                #: TensorFlow application is responsible for reading any data.\n  SPARK = 1                     #: Spark is responsible for feeding data to the TensorFlow application via an RDD.\n\n\nclass TFCluster(object):\n\n  sc = None                     #: SparkContext\n  defaultFS = None              #: Default FileSystem string, e.g. ``file://`` or ``hdfs://<namenode>/``\n  working_dir = None            #: Current working directory\n  num_executors = None          #: Number of executors in the Spark job (and therefore, the number of nodes in the TensorFlow cluster).\n  nodeRDD = None                #: RDD representing the nodes of the cluster, i.e. ``sc.parallelize(range(num_executors), num_executors)``\n  cluster_id = None             #: Unique ID for this cluster, used to invalidate state for new clusters.\n  cluster_info = None           #: Cluster node reservations\n  cluster_meta = None           #: Cluster metadata dictionary, e.g. cluster_id, defaultFS, reservation.Server address, etc.\n  input_mode = None             #: TFCluster.InputMode for this cluster\n  queues = None                 #: *INTERNAL_USE*\n  server = None                 #: reservation.Server for this cluster\n\n  def train(self, dataRDD, num_epochs=0, feed_timeout=600, qname=\'input\'):\n    """"""*For InputMode.SPARK only*.  Feeds Spark RDD partitions into the TensorFlow worker nodes\n\n    It is the responsibility of the TensorFlow ""main"" function to interpret the rows of the RDD.\n\n    Since epochs are implemented via ``RDD.union()`` and the entire RDD must generally be processed in full, it is recommended\n    to set ``num_epochs`` to closely match your training termination condition (e.g. steps or accuracy).  See ``TFNode.DataFeed``\n    for more details.\n\n    Args:\n      :dataRDD: input data as a Spark RDD.\n      :num_epochs: number of times to repeat the dataset during training.\n      :feed_timeout: number of seconds after which data feeding times out (600 sec default)\n      :qname: *INTERNAL USE*.\n    """"""\n    logger.info(""Feeding training data"")\n    assert self.input_mode == InputMode.SPARK, ""TFCluster.train() requires InputMode.SPARK""\n    assert qname in self.queues, ""Unknown queue: {}"".format(qname)\n    assert num_epochs >= 0, ""num_epochs cannot be negative""\n\n    if isinstance(dataRDD, DStream):\n      # Spark Streaming\n      dataRDD.foreachRDD(lambda rdd: rdd.foreachPartition(TFSparkNode.train(self.cluster_info, self.cluster_meta, feed_timeout=feed_timeout, qname=qname)))\n    else:\n      # Spark RDD\n      # if num_epochs unspecified, pick an arbitrarily ""large"" number for now\n      # TODO: calculate via dataRDD.count() / batch_size / max_steps\n      if num_epochs == 0:\n        num_epochs = 10\n      rdds = [dataRDD] * num_epochs\n      unionRDD = self.sc.union(rdds)\n      unionRDD.foreachPartition(TFSparkNode.train(self.cluster_info, self.cluster_meta, feed_timeout=feed_timeout, qname=qname))\n\n  def inference(self, dataRDD, feed_timeout=600, qname=\'input\'):\n    """"""*For InputMode.SPARK only*: Feeds Spark RDD partitions into the TensorFlow worker nodes and returns an RDD of results\n\n    It is the responsibility of the TensorFlow ""main"" function to interpret the rows of the RDD and provide valid data for the output RDD.\n\n    This will use the distributed TensorFlow cluster for inferencing, so the TensorFlow ""main"" function should be capable of inferencing.\n    Per Spark design, the output RDD will be lazily-executed only when a Spark action is invoked on the RDD.\n\n    Args:\n      :dataRDD: input data as a Spark RDD\n      :feed_timeout: number of seconds after which data feeding times out (600 sec default)\n      :qname: *INTERNAL_USE*\n\n    Returns:\n      A Spark RDD representing the output of the TensorFlow inferencing\n    """"""\n    logger.info(""Feeding inference data"")\n    assert self.input_mode == InputMode.SPARK, ""TFCluster.inference() requires InputMode.SPARK""\n    assert qname in self.queues, ""Unknown queue: {}"".format(qname)\n    return dataRDD.mapPartitions(TFSparkNode.inference(self.cluster_info, feed_timeout=feed_timeout, qname=qname))\n\n  def shutdown(self, ssc=None, grace_secs=0, timeout=259200):\n    """"""Stops the distributed TensorFlow cluster.\n\n    For InputMode.SPARK, this will be executed AFTER the `TFCluster.train()` or `TFCluster.inference()` method completes.\n    For InputMode.TENSORFLOW, this will be executed IMMEDIATELY after `TFCluster.run()` and will wait until the TF worker nodes complete.\n\n    Args:\n      :ssc: *For Streaming applications only*. Spark StreamingContext\n      :grace_secs: Grace period to wait after all executors have completed their tasks before terminating the Spark application, e.g. to allow the chief worker to perform any final/cleanup duties like exporting or evaluating the model.  Default is 0.\n      :timeout: Time in seconds to wait for TF cluster to complete before terminating the Spark application.  This can be useful if the TF code hangs for any reason.  Default is 3 days.  Use -1 to disable timeout.\n    """"""\n    logger.info(""Waiting for TensorFlow nodes to complete..."")\n\n    # identify ps/workers\n    ps_list, worker_list, eval_list = [], [], []\n    for node in self.cluster_info:\n      (ps_list if node[\'job_name\'] == \'ps\' else eval_list if node[\'job_name\'] == \'evaluator\' else worker_list).append(node)\n\n    # setup execution timeout\n    if timeout > 0:\n      def timeout_handler(signum, frame):\n        logger.error(""TensorFlow execution timed out, exiting Spark application with error status"")\n        self.sc.cancelAllJobs()\n        self.sc.stop()\n        sys.exit(1)\n\n      signal.signal(signal.SIGALRM, timeout_handler)\n      signal.alarm(timeout)\n\n    # wait for Spark Streaming termination or TF app completion for InputMode.TENSORFLOW\n    if ssc is not None:\n      # Spark Streaming\n      while not ssc.awaitTerminationOrTimeout(1):\n        if self.server.done:\n          logger.info(""Server done, stopping StreamingContext"")\n          ssc.stop(stopSparkContext=False, stopGraceFully=True)\n          break\n    elif self.input_mode == InputMode.TENSORFLOW:\n      # in TENSORFLOW mode, there is no ""data feeding"" job, only a ""start"" job, so we must wait for the TensorFlow workers\n      # to complete all tasks, while accounting for any PS tasks which run indefinitely.\n      count = 0\n      while count < 3:\n        st = self.sc.statusTracker()\n        jobs = st.getActiveJobsIds()\n        if len(jobs) == 0:\n          break\n        stages = st.getActiveStageIds()\n        for i in stages:\n          si = st.getStageInfo(i)\n          if si.numActiveTasks == len(ps_list) + len(eval_list):\n            # if we only have PS tasks left, check that we see this condition a couple times\n            count += 1\n        time.sleep(5)\n\n    # shutdown queues and managers for ""worker"" executors.\n    # note: in SPARK mode, this job will immediately queue up behind the ""data feeding"" job.\n    # in TENSORFLOW mode, this will only run after all workers have finished.\n    workers = len(worker_list)\n    workerRDD = self.sc.parallelize(range(workers), workers)\n    workerRDD.foreachPartition(TFSparkNode.shutdown(self.cluster_info, grace_secs, self.queues))\n\n    # exit Spark application w/ err status if TF job had any errors\n    if \'error\' in tf_status:\n      logger.error(""Exiting Spark application with error status."")\n      self.sc.cancelAllJobs()\n      self.sc.stop()\n      sys.exit(1)\n\n    logger.info(""Shutting down cluster"")\n    # shutdown queues and managers for ""PS"" executors.\n    # note: we have to connect/shutdown from the spark driver, because these executors are ""busy"" and won\'t accept any other tasks.\n    for node in ps_list + eval_list:\n      addr = node[\'addr\']\n      authkey = node[\'authkey\']\n      m = TFManager.connect(addr, authkey)\n      q = m.get_queue(\'control\')\n      q.put(None)\n      q.join()\n\n    # wait for all jobs to finish\n    while True:\n      time.sleep(5)\n      st = self.sc.statusTracker()\n      jobs = st.getActiveJobsIds()\n      if len(jobs) == 0:\n        break\n\n    # stop reservation server\n    self.server.stop()\n\n  def tensorboard_url(self):\n    """"""Utility function to get the Tensorboard URL""""""\n    for node in self.cluster_info:\n      if node[\'tb_port\'] != 0:\n        return ""http://{0}:{1}"".format(node[\'host\'], node[\'tb_port\'])\n    return None\n\n\ndef run(sc, map_fun, tf_args, num_executors, num_ps, tensorboard=False, input_mode=InputMode.TENSORFLOW,\n        log_dir=None, driver_ps_nodes=False, master_node=None, reservation_timeout=600, queues=[\'input\', \'output\', \'error\'],\n        eval_node=False):\n  """"""Starts the TensorFlowOnSpark cluster and Runs the TensorFlow ""main"" function on the Spark executors\n\n  Args:\n    :sc: SparkContext\n    :map_fun: user-supplied TensorFlow ""main"" function\n    :tf_args: ``argparse`` args, or command-line ``ARGV``.  These will be passed to the ``map_fun``.\n    :num_executors: number of Spark executors.  This should match your Spark job\'s ``--num_executors``.\n    :num_ps: number of Spark executors which are reserved for TensorFlow PS nodes.  All other executors will be used as TensorFlow worker nodes.\n    :tensorboard: boolean indicating if the chief worker should spawn a Tensorboard server.\n    :input_mode: TFCluster.InputMode\n    :log_dir: directory to save tensorboard event logs.  If None, defaults to a fixed path on local filesystem.\n    :driver_ps_nodes: run the PS nodes on the driver locally instead of on the spark executors; this help maximizing computing resources (esp. GPU). You will need to set cluster_size = num_executors + num_ps\n    :master_node: name of the ""master"" or ""chief"" node in the cluster_template, used for `tf.estimator` applications.\n    :reservation_timeout: number of seconds after which cluster reservation times out (600 sec default)\n    :queues: *INTERNAL_USE*\n    :eval_node: run evaluator node for distributed Tensorflow\n\n  Returns:\n    A TFCluster object representing the started cluster.\n  """"""\n  logger.info(""Reserving TFSparkNodes {0}"".format(""w/ TensorBoard"" if tensorboard else """"))\n\n  if driver_ps_nodes and input_mode != InputMode.TENSORFLOW:\n    raise Exception(\'running PS nodes on driver locally is only supported in InputMode.TENSORFLOW\')\n\n  if eval_node and input_mode != InputMode.TENSORFLOW:\n    raise Exception(\'running evaluator nodes is only supported in InputMode.TENSORFLOW\')\n\n  # compute size of TF cluster and validate against number of Spark executors\n  num_master = 1 if master_node else 0\n  num_eval = 1 if eval_node else 0\n  num_workers = max(num_executors - num_ps - num_eval - num_master, 0)\n  total_nodes = num_ps + num_master + num_eval + num_workers\n\n  assert total_nodes == num_executors, ""TensorFlow cluster requires {} nodes, but only {} executors available"".format(total_nodes, num_executors)\n  assert num_master + num_workers > 0, ""TensorFlow cluster requires at least one worker or master/chief node""\n\n  # create a cluster template for scheduling TF nodes onto executors\n  executors = list(range(num_executors))\n  cluster_template = {}\n\n  if num_ps > 0:\n    cluster_template[\'ps\'] = executors[:num_ps]\n    del executors[:num_ps]\n  if master_node:\n    cluster_template[master_node] = executors[:1]\n    del executors[:1]\n  if eval_node:\n    cluster_template[\'evaluator\'] = executors[:1]\n    del executors[:1]\n  if num_workers > 0:\n    cluster_template[\'worker\'] = executors[:num_workers]\n\n  logger.info(""cluster_template: {}"".format(cluster_template))\n\n  # get default filesystem from spark\n  defaultFS = sc._jsc.hadoopConfiguration().get(""fs.defaultFS"")\n  # strip trailing ""root"" slash from ""file:///"" to be consistent w/ ""hdfs://...""\n  if defaultFS.startswith(""file://"") and len(defaultFS) > 7 and defaultFS.endswith(""/""):\n    defaultFS = defaultFS[:-1]\n\n  # get current working dir of spark launch\n  working_dir = os.getcwd()\n\n  # start a server to listen for reservations and broadcast cluster_spec\n  server = reservation.Server(num_executors)\n  server_addr = server.start()\n\n  # start TF nodes on all executors\n  logger.info(""Starting TensorFlow on executors"")\n  cluster_meta = {\n    \'id\': random.getrandbits(64),\n    \'cluster_template\': cluster_template,\n    \'num_executors\': num_executors,\n    \'default_fs\': defaultFS,\n    \'working_dir\': working_dir,\n    \'server_addr\': server_addr\n  }\n  if driver_ps_nodes:\n    nodeRDD = sc.parallelize(range(num_ps, num_executors), num_executors - num_ps)\n  else:\n    nodeRDD = sc.parallelize(range(num_executors), num_executors)\n\n  if driver_ps_nodes:\n    def _start_ps(node_index):\n      logger.info(""starting ps node locally %d"" % node_index)\n      TFSparkNode.run(map_fun,\n                      tf_args,\n                      cluster_meta,\n                      tensorboard,\n                      log_dir,\n                      queues,\n                      background=(input_mode == InputMode.SPARK))([node_index])\n    for i in cluster_template[\'ps\']:\n      ps_thread = threading.Thread(target=lambda: _start_ps(i))\n      ps_thread.daemon = True\n      ps_thread.start()\n\n  # start TF on a background thread (on Spark driver) to allow for feeding job\n  def _start(status):\n    try:\n      nodeRDD.foreachPartition(TFSparkNode.run(map_fun,\n                                                tf_args,\n                                                cluster_meta,\n                                                tensorboard,\n                                                log_dir,\n                                                queues,\n                                                background=(input_mode == InputMode.SPARK)))\n    except Exception as e:\n      logger.error(""Exception in TF background thread"")\n      status[\'error\'] = str(e)\n\n  t = threading.Thread(target=_start, args=(tf_status,))\n  # run as daemon thread so that in spark mode main thread can exit\n  # if feeder spark stage fails and main thread can\'t do explicit shutdown\n  t.daemon = True\n  t.start()\n\n  # wait for executors to register and start TFNodes before continuing\n  logger.info(""Waiting for TFSparkNodes to start"")\n  cluster_info = server.await_reservations(sc, tf_status, reservation_timeout)\n  logger.info(""All TFSparkNodes started"")\n\n  # print cluster_info and extract TensorBoard URL\n  tb_url = None\n  for node in cluster_info:\n    logger.info(node)\n    if node[\'tb_port\'] != 0:\n      tb_url = ""http://{0}:{1}"".format(node[\'host\'], node[\'tb_port\'])\n\n  if tb_url is not None:\n    logger.info(""========================================================================================"")\n    logger.info("""")\n    logger.info(""TensorBoard running at:       {0}"".format(tb_url))\n    logger.info("""")\n    logger.info(""========================================================================================"")\n\n  # since our ""primary key"" for each executor\'s TFManager is (host, executor_id), sanity check for duplicates\n  # Note: this may occur if Spark retries failed Python tasks on the same executor.\n  tb_nodes = set()\n  for node in cluster_info:\n    node_id = (node[\'host\'], node[\'executor_id\'])\n    if node_id in tb_nodes:\n      msg = \'\'\'\nDuplicate cluster node id detected (host={0}, executor_id={1})\nPlease ensure that:\n1. Number of executors >= number of TensorFlow nodes\n2. Number of tasks per executors is 1\n3, TFCluster.shutdown() is successfully invoked when done.\n\'\'\'.strip()\n      raise Exception(msg.format(node_id[0], node_id[1]))\n    else:\n      tb_nodes.add(node_id)\n\n  # create TFCluster object\n  cluster = TFCluster()\n  cluster.sc = sc\n  cluster.meta = cluster_meta\n  cluster.nodeRDD = nodeRDD\n  cluster.cluster_info = cluster_info\n  cluster.cluster_meta = cluster_meta\n  cluster.input_mode = input_mode\n  cluster.queues = queues\n  cluster.server = server\n\n  return cluster\n'"
tensorflowonspark/TFManager.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nfrom multiprocessing.managers import BaseManager\nfrom multiprocessing import JoinableQueue\n\n\nclass TFManager(BaseManager):\n  """"""Python multiprocessing.Manager for distributed, multi-process communication.""""""\n  pass\n\n\n# global to each Spark executor\'s python worker\nmgr = None        # TFManager\nqdict = {}        # dictionary of queues\nkdict = {}        # dictionary of key-values\n\n\ndef _get(key):\n  return kdict[key]\n\n\ndef _set(key, value):\n  kdict[key] = value\n\n\ndef _get_queue(qname):\n  try:\n    return qdict[qname]\n  except KeyError:\n    return None\n\n\ndef start(authkey, queues, mode=\'local\'):\n  """"""Create a new multiprocess.Manager (or return existing one).\n\n  Args:\n    :authkey: string authorization key\n    :queues: *INTERNAL_USE*\n    :mode: \'local\' indicates that the manager will only be accessible from the same host, otherwise remotely accessible.\n\n  Returns:\n    A TFManager instance, which is also cached in local memory of the Python worker process.\n  """"""\n  global mgr, qdict, kdict\n  qdict.clear()\n  kdict.clear()\n  for q in queues:\n    qdict[q] = JoinableQueue()\n\n  TFManager.register(\'get_queue\', callable=lambda qname: _get_queue(qname))\n  TFManager.register(\'get\', callable=lambda key: _get(key))\n  TFManager.register(\'set\', callable=lambda key, value: _set(key, value))\n  if mode == \'remote\':\n    mgr = TFManager(address=(\'\', 0), authkey=authkey)\n  else:\n    mgr = TFManager(authkey=authkey)\n  mgr.start()\n  return mgr\n\n\ndef connect(address, authkey):\n  """"""Connect to a multiprocess.Manager.\n\n  Args:\n    :address: unique address to the TFManager, either a unique connection string for \'local\', or a (host, port) tuple for remote.\n    :authkey: string authorization key\n\n  Returns:\n    A TFManager instance referencing the remote TFManager at the supplied address.\n  """"""\n  TFManager.register(\'get_queue\')\n  TFManager.register(\'get\')\n  TFManager.register(\'set\')\n  m = TFManager(address, authkey=authkey)\n  m.connect()\n  return m\n'"
tensorflowonspark/TFNode.py,16,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""This module provides helper functions for the TensorFlow application.\n\nPrimarily, these functions help with:\n\n* starting the TensorFlow ``tf.train.Server`` for the node (allocating GPUs as desired, and determining the node\'s role in the cluster).\n* managing input/output data for *InputMode.SPARK*.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport getpass\nimport logging\nimport pkg_resources\n\nfrom packaging import version\nfrom six.moves.queue import Empty\nfrom . import compat, marker\n\nlogger = logging.getLogger(__name__)\nTF_VERSION = pkg_resources.get_distribution(\'tensorflow\').version\n\n\ndef hdfs_path(ctx, path):\n  """"""Convenience function to create a Tensorflow-compatible absolute HDFS path from relative paths\n\n  Args:\n    :ctx: TFNodeContext containing the metadata specific to this node in the cluster.\n    :path: path to convert\n\n  Returns:\n    An absolute path prefixed with the correct filesystem scheme.\n  """"""\n  #  All Hadoop-Compatible File System Schemes (as of Hadoop 3.0.x):\n  HADOOP_SCHEMES = [\'adl://\',\n                    \'file://\',\n                    \'hdfs://\',\n                    \'oss://\',\n                    \'s3://\',\n                    \'s3a://\',\n                    \'s3n://\',\n                    \'swift://\',\n                    \'viewfs://\',\n                    \'wasb://\']\n  if (any(path.startswith(scheme) for scheme in HADOOP_SCHEMES)):\n    # absolute path w/ scheme, just return as-is\n    return path\n  elif path.startswith(""/""):\n    # absolute path w/o scheme, just prepend w/ defaultFS\n    return ctx.defaultFS + path\n  else:\n    # relative path, prepend defaultFS + standard working dir\n    if ctx.defaultFS.startswith(""hdfs://"") or ctx.defaultFS.startswith(""viewfs://""):\n      return ""{0}/user/{1}/{2}"".format(ctx.defaultFS, getpass.getuser(), path)\n    elif ctx.defaultFS.startswith(""file://""):\n      return ""{0}/{1}/{2}"".format(ctx.defaultFS, ctx.working_dir[1:], path)\n    else:\n      logger.warn(""Unknown scheme {0} with relative path: {1}"".format(ctx.defaultFS, path))\n      return ""{0}/{1}"".format(ctx.defaultFS, path)\n\n\ndef start_cluster_server(ctx, num_gpus=1, rdma=False):\n  """"""Function that wraps the creation of TensorFlow ``tf.train.Server`` for a node in a distributed TensorFlow cluster.\n\n  This is intended to be invoked from within the TF ``map_fun``, replacing explicit code to instantiate ``tf.train.ClusterSpec``\n  and ``tf.train.Server`` objects.\n\n  DEPRECATED for TensorFlow 2.x+\n\n  Args:\n    :ctx: TFNodeContext containing the metadata specific to this node in the cluster.\n    :num_gpu: number of GPUs desired\n    :rdma: boolean indicating if RDMA \'iverbs\' should be used for cluster communications.\n\n  Returns:\n    A tuple of (cluster_spec, server)\n  """"""\n  import os\n  import time\n  from . import gpu_info\n\n  if version.parse(TF_VERSION) >= version.parse(""2.0.0""):\n    raise Exception(""DEPRECATED: Use higher-level APIs like `tf.keras` or `tf.estimator`"")\n\n  logging.info(""{0}: ======== {1}:{2} ========"".format(ctx.worker_num, ctx.job_name, ctx.task_index))\n  cluster_spec = ctx.cluster_spec\n  logging.info(""{0}: Cluster spec: {1}"".format(ctx.worker_num, cluster_spec))\n\n  if compat.is_gpu_available() and num_gpus > 0:\n    # compute my index relative to other nodes placed on the same host (for GPU allocation)\n    my_addr = cluster_spec[ctx.job_name][ctx.task_index]\n    my_host = my_addr.split(\':\')[0]\n    flattened = [v for sublist in cluster_spec.values() for v in sublist]\n    local_peers = [p for p in flattened if p.startswith(my_host)]\n    my_index = local_peers.index(my_addr)\n\n    # GPU\n    gpu_initialized = False\n    retries = 3\n    while not gpu_initialized and retries > 0:\n      try:\n        # override PS jobs to only reserve one GPU\n        if ctx.job_name == \'ps\':\n          num_gpus = 0\n\n        # Find a free gpu(s) to use\n        gpus_to_use = gpu_info.get_gpus(num_gpus, my_index)\n        gpu_prompt = ""GPU"" if num_gpus == 1 else ""GPUs""\n        logging.info(""{0}: Using {1}: {2}"".format(ctx.worker_num, gpu_prompt, gpus_to_use))\n\n        # Set GPU device to use for TensorFlow\n        os.environ[\'CUDA_VISIBLE_DEVICES\'] = gpus_to_use\n\n        # Import tensorflow after gpu allocation\n        import tensorflow as tf\n\n        # Create a cluster from the parameter server and worker hosts.\n        cluster = tf.train.ClusterSpec(cluster_spec)\n\n        # Create and start a server for the local task.\n        if rdma:\n          server = tf.train.Server(cluster, ctx.job_name, ctx.task_index, protocol=""grpc+verbs"")\n        else:\n          server = tf.train.Server(cluster, ctx.job_name, ctx.task_index)\n        gpu_initialized = True\n      except Exception as e:\n        print(e)\n        logging.error(""{0}: Failed to allocate GPU, trying again..."".format(ctx.worker_num))\n        retries -= 1\n        time.sleep(10)\n    if not gpu_initialized:\n      raise Exception(""Failed to allocate GPU"")\n  else:\n    # CPU\n    import tensorflow as tf\n\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = \'\'\n    logging.info(""{0}: Using CPU"".format(ctx.worker_num))\n\n    # Create a cluster from the parameter server and worker hosts.\n    cluster = tf.train.ClusterSpec(cluster_spec)\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster, ctx.job_name, ctx.task_index)\n\n  return (cluster, server)\n\n\ndef next_batch(mgr, batch_size, qname=\'input\'):\n  """"""*DEPRECATED*. Use TFNode.DataFeed class instead.""""""\n  raise Exception(""DEPRECATED: Use TFNode.DataFeed class instead"")\n\n\ndef export_saved_model(sess, export_dir, tag_set, signatures):\n  """"""Convenience function to export a saved_model using provided arguments\n\n  The caller specifies the saved_model signatures in a simplified python dictionary form, as follows::\n\n    signatures = {\n      \'signature_def_key\': {\n        \'inputs\': { \'input_tensor_alias\': input_tensor_name },\n        \'outputs\': { \'output_tensor_alias\': output_tensor_name },\n        \'method_name\': \'method\'\n      }\n    }\n\n  And this function will generate the `signature_def_map` and export the saved_model.\n\n  DEPRECATED for TensorFlow 2.x+.\n\n  Args:\n    :sess: a tf.Session instance\n    :export_dir: path to save exported saved_model\n    :tag_set: string tag_set to identify the exported graph\n    :signatures: simplified dictionary representation of a TensorFlow signature_def_map\n\n  Returns:\n    A saved_model exported to disk at ``export_dir``.\n  """"""\n  import tensorflow as tf\n\n  if version.parse(tf.__version__) >= version.parse(""2.0.0""):\n    raise Exception(""DEPRECATED: Use TF provided APIs instead."")\n\n  g = sess.graph\n  g._unsafe_unfinalize()           # https://github.com/tensorflow/serving/issues/363\n  builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n\n  logging.info(""===== signatures: {}"".format(signatures))\n  signature_def_map = {}\n  for key, sig in signatures.items():\n    signature_def_map[key] = tf.saved_model.signature_def_utils.build_signature_def(\n        inputs={name: tf.saved_model.utils.build_tensor_info(tensor) for name, tensor in sig[\'inputs\'].items()},\n        outputs={name: tf.saved_model.utils.build_tensor_info(tensor) for name, tensor in sig[\'outputs\'].items()},\n        method_name=sig[\'method_name\'] if \'method_name\' in sig else key)\n  logging.info(""===== signature_def_map: {}"".format(signature_def_map))\n  builder.add_meta_graph_and_variables(\n      sess,\n      tag_set.split(\',\'),\n      signature_def_map=signature_def_map,\n      clear_devices=True)\n  g.finalize()\n  builder.save()\n\n\ndef batch_results(mgr, results, qname=\'output\'):\n  """"""*DEPRECATED*. Use TFNode.DataFeed class instead.""""""\n  raise Exception(""DEPRECATED: Use TFNode.DataFeed class instead"")\n\n\ndef terminate(mgr, qname=\'input\'):\n  """"""*DEPRECATED*. Use TFNode.DataFeed class instead.""""""\n  raise Exception(""DEPRECATED: Use TFNode.DataFeed class instead"")\n\n\nclass DataFeed(object):\n  """"""This class manages the *InputMode.SPARK* data feeding process from the perspective of the TensorFlow application.\n\n  Args:\n    :mgr: TFManager instance associated with this Python worker process.\n    :train_mode: boolean indicating if the data feed is expecting an output response (e.g. inferencing).\n    :qname_in: *INTERNAL_USE*\n    :qname_out: *INTERNAL_USE*\n    :input_mapping: *For Spark ML Pipelines only*.  Dictionary of input DataFrame columns to input TensorFlow tensors.\n  """"""\n  def __init__(self, mgr, train_mode=True, qname_in=\'input\', qname_out=\'output\', input_mapping=None):\n\n    self.mgr = mgr\n    self.train_mode = train_mode\n    self.qname_in = qname_in\n    self.qname_out = qname_out\n    self.done_feeding = False\n    self.input_tensors = [tensor for col, tensor in sorted(input_mapping.items())] if input_mapping is not None else None\n\n    self.queue_in = mgr.get_queue(qname_in)\n    self.queue_out = mgr.get_queue(qname_out)\n\n  def next_batch(self, batch_size):\n    """"""Gets a batch of items from the input RDD.\n\n    If multiple tensors are provided per row in the input RDD, e.g. tuple of (tensor1, tensor2, ..., tensorN) and:\n\n    * no ``input_mapping`` was provided to the DataFeed constructor, this will return an array of ``batch_size`` tuples,\n      and the caller is responsible for separating the tensors.\n    * an ``input_mapping`` was provided to the DataFeed constructor, this will return a dictionary of N tensors,\n      with tensor names as keys and arrays of length ``batch_size`` as values.\n\n    Note: if the end of the data is reached, this may return with fewer than ``batch_size`` items.\n\n    Args:\n      :batch_size: number of items to retrieve.\n\n    Returns:\n      A batch of items or a dictionary of tensors.\n    """"""\n    tensors = [] if self.input_tensors is None else {tensor: [] for tensor in self.input_tensors}\n    count = 0\n    queue_in = self.queue_in\n    no_input_tensors = self.input_tensors is None\n    while count < batch_size:\n      item = queue_in.get(block=True)\n      if item is None:\n        # End of Feed\n        logger.info(""next_batch() got None"")\n        queue_in.task_done()\n        self.done_feeding = True\n        break\n      elif type(item) is marker.EndPartition:\n        # End of Partition\n        logger.info(""next_batch() got EndPartition"")\n        queue_in.task_done()\n        if not self.train_mode and count > 0:\n          break\n      else:\n        # Normal item\n        if no_input_tensors:\n          tensors.append(item)\n        else:\n          for i in range(len(self.input_tensors)):\n            tensors[self.input_tensors[i]].append(item[i])\n        count += 1\n        queue_in.task_done()\n    return tensors\n\n  def should_stop(self):\n    """"""Check if the feed process was told to stop (by a call to ``terminate``).""""""\n    return self.done_feeding\n\n  def batch_results(self, results):\n    """"""Push a batch of output results to the Spark output RDD of ``TFCluster.inference()``.\n\n    Note: this currently expects a one-to-one mapping of input to output data, so the length of the ``results`` array should match the length of\n    the previously retrieved batch of input data.\n\n    Args:\n      :results: array of output data for the equivalent batch of input data.\n    """"""\n    queue = self.queue_out\n    for item in results:\n      queue.put(item, block=True)\n\n  def terminate(self):\n    """"""Terminate data feeding early.\n\n    Since TensorFlow applications can often terminate on conditions unrelated to the training data (e.g. steps, accuracy, etc),\n    this method signals the data feeding process to ignore any further incoming data.  Note that Spark itself does not have a mechanism\n    to terminate an RDD operation early, so the extra partitions will still be sent to the executors (but will be ignored).  Because\n    of this, you should size your input data accordingly to avoid excessive overhead.\n    """"""\n    logger.info(""terminate() invoked"")\n    self.mgr.set(\'state\', \'terminating\')\n\n    # drop remaining items in the queue\n    queue = self.mgr.get_queue(self.qname_in)\n    count = 0\n    done = False\n    while not done:\n      try:\n        queue.get(block=True, timeout=5)\n        queue.task_done()\n        count += 1\n      except Empty:\n        logger.info(""dropped {0} items from queue"".format(count))\n        done = True\n'"
tensorflowonspark/TFParallel.py,0,"b'# Copyright 2019 Yahoo Inc / Verizon Media\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport logging\nfrom . import TFSparkNode\nfrom . import gpu_info, util\n\nlogger = logging.getLogger(__name__)\n\n\ndef run(sc, map_fn, tf_args, num_executors):\n  """"""Runs the user map_fn as parallel, independent instances of TF on the Spark executors.\n\n  Args:\n    :sc: SparkContext\n    :map_fun: user-supplied TensorFlow ""main"" function\n    :tf_args: ``argparse`` args, or command-line ``ARGV``.  These will be passed to the ``map_fun``.\n    :num_executors: number of Spark executors.  This should match your Spark job\'s ``--num_executors``.\n\n  Returns:\n    None\n  """"""\n\n  # get default filesystem from spark\n  defaultFS = sc._jsc.hadoopConfiguration().get(""fs.defaultFS"")\n  # strip trailing ""root"" slash from ""file:///"" to be consistent w/ ""hdfs://...""\n  if defaultFS.startswith(""file://"") and len(defaultFS) > 7 and defaultFS.endswith(""/""):\n    defaultFS = defaultFS[:-1]\n\n  def _run(it):\n    from pyspark import BarrierTaskContext\n\n    for i in it:\n      worker_num = i\n\n    # use BarrierTaskContext to get placement of all nodes\n    ctx = BarrierTaskContext.get()\n    tasks = ctx.getTaskInfos()\n    nodes = [t.address for t in tasks]\n\n    # use the placement info to help allocate GPUs\n    num_gpus = tf_args.num_gpus if \'num_gpus\' in tf_args else 1\n    util.single_node_env(num_gpus=num_gpus, worker_index=worker_num, nodes=nodes)\n\n    # run the user map_fn\n    ctx = TFSparkNode.TFNodeContext()\n    ctx.defaultFS = defaultFS\n    ctx.worker_num = worker_num\n    ctx.executor_id = worker_num\n    ctx.num_workers = len(nodes)\n\n    map_fn(tf_args, ctx)\n\n    # return a dummy iterator (since we have to use mapPartitions)\n    return [0]\n\n  nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n  nodeRDD.barrier().mapPartitions(_run).collect()\n'"
tensorflowonspark/TFSparkNode.py,2,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""This module provides low-level functions for managing the TensorFlowOnSpark cluster.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport json\nimport logging\nimport multiprocessing\nimport os\nimport pkg_resources\nimport platform\nimport socket\nimport subprocess\nimport sys\nimport uuid\nimport time\nimport traceback\nfrom packaging import version\nfrom threading import Thread\n\nfrom . import TFManager\nfrom . import TFNode\nfrom . import gpu_info\nfrom . import marker\nfrom . import reservation\nfrom . import util\n\nlogger = logging.getLogger(__name__)\nTF_VERSION = pkg_resources.get_distribution(\'tensorflow\').version\n\n\ndef _has_spark_resource_api():\n  """"""Returns true if Spark 3+ resource API is available""""""\n  import pyspark\n  return version.parse(pyspark.__version__).base_version >= version.parse(""3.0.0"").base_version\n\n\ndef _get_cluster_spec(sorted_cluster_info):\n  """"""Given a list of node metadata sorted by executor_id, returns a tensorflow cluster_spec""""""\n  cluster_spec = {}\n  last_executor_id = -1\n  for node in sorted_cluster_info:\n    if (node[\'executor_id\'] == last_executor_id):\n      raise Exception(""Duplicate worker/task in cluster_info"")\n    last_executor_id = node[\'executor_id\']\n    logger.info(""node: {0}"".format(node))\n    (njob, nhost, nport) = (node[\'job_name\'], node[\'host\'], node[\'port\'])\n    hosts = [] if njob not in cluster_spec else cluster_spec[njob]\n    hosts.append(""{0}:{1}"".format(nhost, nport))\n    cluster_spec[njob] = hosts\n  return cluster_spec\n\n\nclass TFNodeContext:\n  """"""Encapsulates unique metadata for a TensorFlowOnSpark node/executor and provides methods to interact with Spark and HDFS.\n\n  An instance of this object will be passed to the TensorFlow ""main"" function via the `ctx` argument.\n  To simply the end-user API, this class now mirrors the functions of the TFNode module.\n\n  Args:\n    :executor_id: integer identifier for this executor, per ``nodeRDD = sc.parallelize(range(num_executors), num_executors).``\n    :job_name: TensorFlow job name (e.g. \'ps\' or \'worker\') of this TF node, per cluster_spec.\n    :task_index: integer rank per job_name, e.g. ""worker:0"", ""worker:1"", ""ps:0"".\n    :cluster_spec: dictionary for constructing a tf.train.ClusterSpec.\n    :defaultFS: string representation of default FileSystem, e.g. ``file://`` or ``hdfs://<namenode>:8020/``.\n    :working_dir: the current working directory for local filesystems, or YARN containers.\n    :mgr: TFManager instance for this Python worker.\n  """"""\n  def __init__(self, executor_id=0, job_name=\'\', task_index=0, cluster_spec={}, defaultFS=\'file://\', working_dir=\'.\', mgr=None):\n    self.worker_num = executor_id       # for backwards-compatibility\n    self.executor_id = executor_id\n    self.job_name = job_name\n    self.task_index = task_index\n    self.cluster_spec = cluster_spec\n    self.num_workers = sum([len(v) for k, v in cluster_spec.items() if k == \'master\' or k == \'chief\' or k == \'worker\'])\n    self.defaultFS = defaultFS\n    self.working_dir = working_dir\n    self.mgr = mgr\n\n  def absolute_path(self, path):\n    """"""Convenience function to access ``TFNode.hdfs_path`` directly from this object instance.""""""\n    return TFNode.hdfs_path(self, path)\n\n  def start_cluster_server(self, num_gpus=1, rdma=False):\n    """"""Convenience function to access ``TFNode.start_cluster_server`` directly from this object instance.""""""\n    return TFNode.start_cluster_server(self, num_gpus, rdma)\n\n  def export_saved_model(self, sess, export_dir, tag_set, signatures):\n    """"""Convenience function to access ``TFNode.export_saved_model`` directly from this object instance.""""""\n    TFNode.export_saved_model(sess, export_dir, tag_set, signatures)\n\n  def get_data_feed(self, train_mode=True, qname_in=\'input\', qname_out=\'output\', input_mapping=None):\n    """"""Convenience function to access ``TFNode.DataFeed`` directly from this object instance.""""""\n    return TFNode.DataFeed(self.mgr, train_mode, qname_in, qname_out, input_mapping)\n\n\nclass TFSparkNode(object):\n  """"""Low-level functions used by the high-level TFCluster APIs to manage cluster state.\n\n  **This class is not intended for end-users (see TFNode for end-user APIs)**.\n\n  For cluster management, this wraps the per-node cluster logic as Spark RDD mapPartitions functions, where the RDD is expected to be\n  a ""nodeRDD"" of the form: ``nodeRDD = sc.parallelize(range(num_executors), num_executors)``.\n\n  For data feeding, this wraps the feeding logic as Spark RDD mapPartitions functions on a standard ""dataRDD"".\n\n  This also manages a reference to the TFManager ""singleton"" per executor.  Since Spark can spawn more than one python-worker\n  per executor, this will reconnect to the ""singleton"" instance as needed.\n  """"""\n  mgr = None                #: TFManager instance\n  cluster_id = None         #: Unique ID for a given TensorFlowOnSpark cluster, used for invalidating state for new clusters.\n\n\ndef _get_manager(cluster_info, host, executor_id):\n  """"""Returns this executor\'s ""singleton"" instance of the multiprocessing.Manager, reconnecting per python-worker if needed.\n\n  Args:\n    :cluster_info: cluster node reservations\n    :host: host IP address\n    :executor_id: unique id per executor (created during initial call to run())\n\n  Returns:\n    TFManager instance for this executor/python-worker\n  """"""\n  for node in cluster_info:\n    if node[\'host\'] == host and node[\'executor_id\'] == executor_id:\n      addr = node[\'addr\']\n      authkey = node[\'authkey\']\n      TFSparkNode.mgr = TFManager.connect(addr, authkey)\n      break\n\n  if TFSparkNode.mgr is None:\n    msg = ""No TFManager found on this node, please ensure that:\\n"" + \\\n          ""1. Spark num_executors matches TensorFlow cluster_size\\n"" + \\\n          ""2. Spark tasks per executor is 1\\n"" + \\\n          ""3. Spark dynamic allocation is disabled\\n"" + \\\n          ""4. There are no other root-cause exceptions on other nodes\\n""\n    raise Exception(msg)\n\n  logger.info(""Connected to TFSparkNode.mgr on {0}, executor={1}, state={2}"".format(host, executor_id, str(TFSparkNode.mgr.get(\'state\'))))\n  return TFSparkNode.mgr\n\n\ndef run(fn, tf_args, cluster_meta, tensorboard, log_dir, queues, background):\n  """"""Wraps the user-provided TensorFlow main function in a Spark mapPartitions function.\n\n  Args:\n    :fn: TensorFlow ""main"" function provided by the user.\n    :tf_args: ``argparse`` args, or command line ``ARGV``.  These will be passed to the ``fn``.\n    :cluster_meta: dictionary of cluster metadata (e.g. cluster_id, reservation.Server address, etc).\n    :tensorboard: boolean indicating if the chief worker should spawn a Tensorboard server.\n    :log_dir: directory to save tensorboard event logs.  If None, defaults to a fixed path on local filesystem.\n    :queues: *INTERNAL_USE*\n    :background: boolean indicating if the TensorFlow ""main"" function should be run in a background process.\n\n  Returns:\n    A nodeRDD.mapPartitions() function.\n  """"""\n  def _mapfn(iter):\n\n    # Note: consuming the input iterator helps Pyspark re-use this worker,\n    for i in iter:\n      executor_id = i\n\n    def _get_gpus(cluster_spec=None):\n      gpus = []\n      is_k8s = \'SPARK_EXECUTOR_POD_IP\' in os.environ\n\n      # handle explicitly configured tf_args.num_gpus\n      if \'num_gpus\' in tf_args:\n        requested_gpus = tf_args.num_gpus\n        user_requested = True\n      else:\n        requested_gpus = 0\n        user_requested = False\n\n      # first, try Spark 3 resources API, returning all visible GPUs\n      # note: num_gpus arg is only used (if supplied) to limit/truncate visible devices\n      if _has_spark_resource_api():\n        from pyspark import TaskContext\n        context = TaskContext()\n        resources = context.resources()\n        if resources and \'gpu\' in resources:\n          # get all GPUs assigned by resource manager\n          gpus = context.resources()[\'gpu\'].addresses\n          logger.info(""Spark gpu resources: {}"".format(gpus))\n          if user_requested:\n            if requested_gpus < len(gpus):\n              # override/truncate list, if explicitly configured\n              logger.warn(""Requested {} GPU(s), but {} available"".format(requested_gpus, len(gpus)))\n              gpus = gpus[:requested_gpus]\n          else:\n            # implicitly requested by Spark 3\n            requested_gpus = len(gpus)\n\n      # if not in K8s pod and GPUs available, just use original allocation code (defaulting to 1 GPU if available)\n      # Note: for K8s, there is a bug with the Nvidia device_plugin which can show GPUs for non-GPU pods that are hosted on GPU nodes\n      if not is_k8s and gpu_info.is_gpu_available() and not gpus:\n        # default to one GPU if not specified explicitly\n        requested_gpus = max(1, requested_gpus) if not user_requested else requested_gpus\n        if requested_gpus > 0:\n          if cluster_spec:\n            # compute my index relative to other nodes on the same host (for GPU allocation)\n            my_addr = cluster_spec[job_name][task_index]\n            my_host = my_addr.split(\':\')[0]\n            flattened = [v for sublist in cluster_spec.values() for v in sublist]\n            local_peers = [p for p in flattened if p.startswith(my_host)]\n            my_index = local_peers.index(my_addr)\n          else:\n            my_index = 0\n\n          # try to allocate a GPU\n          gpus = gpu_info.get_gpus(requested_gpus, my_index, format=gpu_info.AS_LIST)\n\n      if user_requested and len(gpus) < requested_gpus:\n        raise Exception(""Unable to allocate {} GPU(s) from available GPUs: {}"".format(requested_gpus, gpus))\n\n      gpus_to_use = \',\'.join(gpus)\n      if gpus:\n        logger.info(""Requested {} GPU(s), setting CUDA_VISIBLE_DEVICES={}"".format(requested_gpus if user_requested else len(gpus), gpus_to_use))\n      os.environ[\'CUDA_VISIBLE_DEVICES\'] = gpus_to_use\n\n    # try GPU allocation at executor startup so we can try to fail out if unsuccessful\n    _get_gpus()\n\n    # assign TF job/task based on provided cluster_spec template (or use default/null values)\n    job_name = \'default\'\n    task_index = -1\n    cluster_id = cluster_meta[\'id\']\n    cluster_template = cluster_meta[\'cluster_template\']\n    for jobtype in cluster_template:\n      nodes = cluster_template[jobtype]\n      if executor_id in nodes:\n        job_name = jobtype\n        task_index = nodes.index(executor_id)\n        break\n\n    # get unique key (hostname, executor_id) for this executor\n    host = util.get_ip_address()\n    util.write_executor_id(executor_id)\n    port = 0\n\n    # check for existing TFManagers\n    if TFSparkNode.mgr is not None and str(TFSparkNode.mgr.get(\'state\')) != ""\'stopped\'"":\n      if TFSparkNode.cluster_id == cluster_id:\n        # raise an exception to force Spark to retry this ""reservation"" task on another executor\n        raise Exception(""TFManager already started on {0}, executor={1}, state={2}"".format(host, executor_id, str(TFSparkNode.mgr.get(""state""))))\n      else:\n        # old state, just continue with creating new manager\n        logger.warn(""Ignoring old TFManager with cluster_id {0}, requested cluster_id {1}"".format(TFSparkNode.cluster_id, cluster_id))\n\n    # start a TFManager and get a free port\n    # use a random uuid as the authkey\n    authkey = uuid.uuid4().bytes\n    addr = None\n    if job_name in (\'ps\', \'evaluator\'):\n      # PS nodes must be remotely accessible in order to shutdown from Spark driver.\n      TFSparkNode.mgr = TFManager.start(authkey, [\'control\', \'error\'], \'remote\')\n      addr = (host, TFSparkNode.mgr.address[1])\n    else:\n      # worker nodes only need to be locally accessible within the executor for data feeding\n      TFSparkNode.mgr = TFManager.start(authkey, queues)\n      addr = TFSparkNode.mgr.address\n\n    # initialize mgr state\n    TFSparkNode.mgr.set(\'state\', \'running\')\n    TFSparkNode.cluster_id = cluster_id\n\n    # expand Hadoop classpath wildcards for JNI (Spark 2.x)\n    if \'HADOOP_PREFIX\' in os.environ:\n      classpath = os.environ[\'CLASSPATH\']\n      hadoop_path = os.path.join(os.environ[\'HADOOP_PREFIX\'], \'bin\', \'hadoop\')\n      hadoop_classpath = subprocess.check_output([hadoop_path, \'classpath\', \'--glob\']).decode()\n      logger.debug(""CLASSPATH: {0}"".format(hadoop_classpath))\n      os.environ[\'CLASSPATH\'] = classpath + os.pathsep + hadoop_classpath\n\n    # start TensorBoard if requested, on \'worker:0\' if available (for backwards-compatibility), otherwise on \'chief:0\' or \'master:0\'\n    job_names = sorted([k for k in cluster_template.keys() if k in [\'chief\', \'master\', \'worker\']])\n    tb_job_name = \'worker\' if \'worker\' in job_names else job_names[0]\n    tb_pid = 0\n    tb_port = 0\n    if tensorboard and job_name == tb_job_name and task_index == 0:\n      if \'TENSORBOARD_PORT\' in os.environ:\n        # use port defined in env var\n        tb_port = int(os.environ[\'TENSORBOARD_PORT\'])\n      else:\n        # otherwise, find a free port\n        tb_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        tb_sock.bind((\'\', 0))\n        tb_port = tb_sock.getsockname()[1]\n        tb_sock.close()\n      logdir = log_dir if log_dir else ""tensorboard_%d"" % executor_id\n\n      # search for tensorboard in python/bin, PATH, and PYTHONPATH\n      pypath = sys.executable\n      pydir = os.path.dirname(pypath)\n      sys_path = os.pathsep.join(sys.path)\n      search_path = os.pathsep.join([pydir, sys_path, os.environ[\'PATH\'], os.environ[\'PYTHONPATH\']])\n\n      tb_path = util.find_in_path(search_path, \'tensorboard\')                             # executable in PATH\n      if not tb_path:\n        tb_path = util.find_in_path(search_path, \'tensorboard/main.py\')                   # TF 1.3+\n      if not tb_path:\n        tb_path = util.find_in_path(search_path, \'tensorflow/tensorboard/__main__.py\')    # TF 1.2-\n      if not tb_path:\n        raise Exception(""Unable to find \'tensorboard\' in: {}"".format(search_path))\n\n      # launch tensorboard\n      if version.parse(TF_VERSION) >= version.parse(\'2.0.0\'):\n        tb_proc = subprocess.Popen([pypath, tb_path, ""--reload_multifile=True"", ""--logdir=%s"" % logdir, ""--port=%d"" % tb_port], env=os.environ)\n      else:\n        tb_proc = subprocess.Popen([pypath, tb_path, ""--logdir=%s"" % logdir, ""--port=%d"" % tb_port], env=os.environ)\n\n      tb_pid = tb_proc.pid\n\n    # check server to see if this task is being retried (i.e. already reserved)\n    client = reservation.Client(cluster_meta[\'server_addr\'])\n    cluster_info = client.get_reservations()\n    tmp_sock = None\n    node_meta = None\n    for node in cluster_info:\n      (nhost, nexec) = (node[\'host\'], node[\'executor_id\'])\n      if nhost == host and nexec == executor_id:\n        node_meta = node\n        port = node[\'port\']\n\n    # if not already done, register everything we need to set up the cluster\n    if node_meta is None:\n      if \'TENSORFLOW_PORT\' in os.environ:\n        # use port defined in env var\n        port = int(os.environ[\'TENSORFLOW_PORT\'])\n      else:\n        # otherwise, find a free port\n        tmp_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        tmp_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        tmp_sock.bind((\'\', port))\n        port = tmp_sock.getsockname()[1]\n\n      node_meta = {\n          \'executor_id\': executor_id,\n          \'host\': host,\n          \'job_name\': job_name,\n          \'task_index\': task_index,\n          \'port\': port,\n          \'tb_pid\': tb_pid,\n          \'tb_port\': tb_port,\n          \'addr\': addr,\n          \'authkey\': authkey\n      }\n      # register node metadata with server\n      logger.info(""TFSparkNode.reserve: {0}"".format(node_meta))\n      client.register(node_meta)\n      # wait for other nodes to finish reservations\n      cluster_info = client.await_reservations()\n      client.close()\n\n    # construct a TensorFlow clusterspec from cluster_info\n    sorted_cluster_info = sorted(cluster_info, key=lambda k: k[\'executor_id\'])\n    cluster_spec = _get_cluster_spec(sorted_cluster_info)\n\n    # update TF_CONFIG if cluster spec has a \'master\' node (i.e. tf.estimator)\n    if \'master\' in cluster_spec or \'chief\' in cluster_spec:\n      tf_config = json.dumps({\n        \'cluster\': cluster_spec,\n        \'task\': {\'type\': job_name, \'index\': task_index},\n        \'environment\': \'cloud\'\n      })\n      logger.info(""export TF_CONFIG: {}"".format(tf_config))\n      os.environ[\'TF_CONFIG\'] = tf_config\n\n    # reserve GPU(s) again, just before launching TF process (in case situation has changed)\n    # and setup CUDA_VISIBLE_DEVICES accordingly\n    _get_gpus(cluster_spec=cluster_spec)\n\n    # create a context object to hold metadata for TF\n    ctx = TFNodeContext(executor_id, job_name, task_index, cluster_spec, cluster_meta[\'default_fs\'], cluster_meta[\'working_dir\'], TFSparkNode.mgr)\n\n    # release port reserved for TF as late as possible\n    if tmp_sock is not None:\n      tmp_sock.close()\n\n    # Background mode relies reuse of python worker in Spark.\n    if background:\n      # However, reuse of python worker can\'t work on Windows, we need to check if the current\n      # script runs on Windows or not.\n      if os.name == \'nt\' or platform.system() == \'Windows\':\n        raise Exception(""Background mode is not supported on Windows."")\n      # Check if the config of reuse python worker is enabled on Spark.\n      if not os.environ.get(""SPARK_REUSE_WORKER""):\n        raise Exception(""Background mode relies reuse of python worker on Spark. This config \'spark.python.worker.reuse\' is not enabled on Spark. Please enable it before using background."")\n\n    def wrapper_fn(args, context):\n      """"""Wrapper function that sets the sys.argv of the executor.""""""\n      if isinstance(args, list):\n        sys.argv = args\n      fn(args, context)\n\n    def wrapper_fn_background(args, context):\n      """"""Wrapper function that signals exceptions to foreground process.""""""\n      errq = TFSparkNode.mgr.get_queue(\'error\')\n      try:\n        wrapper_fn(args, context)\n      except Exception:\n        errq.put(traceback.format_exc())\n\n    if job_name in (\'ps\', \'evaluator\') or background:\n      # invoke the TensorFlow main function in a background thread\n      logger.info(""Starting TensorFlow {0}:{1} as {2} on cluster node {3} on background process"".format(\n        job_name, task_index, job_name, executor_id))\n\n      p = multiprocessing.Process(target=wrapper_fn_background, args=(tf_args, ctx))\n      if job_name in (\'ps\', \'evaluator\'):\n        p.daemon = True\n      p.start()\n\n      # for ps and evaluator nodes, wait indefinitely in foreground thread for a ""control"" event (None == ""stop"")\n      if job_name in (\'ps\', \'evaluator\'):\n        queue = TFSparkNode.mgr.get_queue(\'control\')\n        equeue = TFSparkNode.mgr.get_queue(\'error\')\n        done = False\n        while not done:\n          while (queue.empty() and equeue.empty()):\n            time.sleep(1)\n          if (not equeue.empty()):\n            e_str = equeue.get()\n            raise Exception(""Exception in "" + job_name + "":\\n"" + e_str)\n          msg = queue.get(block=True)\n          logger.info(""Got msg: {0}"".format(msg))\n          if msg is None:\n            logger.info(""Terminating {}"".format(job_name))\n            TFSparkNode.mgr.set(\'state\', \'stopped\')\n            done = True\n          queue.task_done()\n    else:\n      # otherwise, just run TF function in the main executor/worker thread\n      logger.info(""Starting TensorFlow {0}:{1} on cluster node {2} on foreground thread"".format(job_name, task_index, executor_id))\n      wrapper_fn(tf_args, ctx)\n      logger.info(""Finished TensorFlow {0}:{1} on cluster node {2}"".format(job_name, task_index, executor_id))\n\n  return _mapfn\n\n\ndef train(cluster_info, cluster_meta, feed_timeout=600, qname=\'input\'):\n  """"""Feeds Spark partitions into the shared multiprocessing.Queue.\n\n  Args:\n    :cluster_info: node reservation information for the cluster (e.g. host, executor_id, pid, ports, etc)\n    :cluster_meta: dictionary of cluster metadata (e.g. cluster_id, reservation.Server address, etc)\n    :feed_timeout: number of seconds after which data feeding times out (600 sec default)\n    :qname: *INTERNAL_USE*\n\n  Returns:\n    A dataRDD.mapPartitions() function\n  """"""\n  def _train(iter):\n    # get shared queue, reconnecting if necessary\n    mgr = _get_manager(cluster_info, util.get_ip_address(), util.read_executor_id())\n    try:\n      queue = mgr.get_queue(qname)\n      equeue = mgr.get_queue(\'error\')\n    except (AttributeError, KeyError):\n      msg = ""Queue \'{}\' not found on this node, check for exceptions on other nodes."".format(qname)\n      raise Exception(msg)\n\n    state = str(mgr.get(\'state\'))\n    logger.info(""mgr.state={0}"".format(state))\n    terminating = state == ""\'terminating\'""\n    if terminating:\n      logger.info(""mgr is terminating, skipping partition"")\n      count = sum(1 for item in iter)\n      logger.info(""Skipped {0} items from partition"".format(count))\n    else:\n      logger.info(""Feeding partition {0} into {1} queue {2}"".format(iter, qname, queue))\n      count = 0\n      for item in iter:\n        count += 1\n        queue.put(item, block=True)\n\n      # wait for consumers to finish processing all items in queue before ""finishing"" this iterator\n      joinThr = Thread(target=queue.join)\n      joinThr.start()\n      timeout = feed_timeout\n      while (joinThr.isAlive()):\n        if (not equeue.empty()):\n          e_str = equeue.get()\n          raise Exception(""Exception in worker:\\n"" + e_str)\n        time.sleep(1)\n        timeout -= 1\n        if timeout <= 0:\n          raise Exception(""Timeout while feeding partition"")\n\n      logger.info(""Processed {0} items in partition"".format(count))\n\n    # check if TF is terminating feed after this partition\n    if not terminating:\n      state = str(mgr.get(\'state\'))\n      terminating = state == ""\'terminating\'""\n      if terminating:\n        try:\n          logger.info(""TFSparkNode: requesting stop"")\n          client = reservation.Client(cluster_meta[\'server_addr\'])\n          client.request_stop()\n          client.close()\n        except Exception as e:\n          # ignore any errors while requesting stop\n          logger.debug(""Error while requesting stop: {0}"".format(e))\n\n    return [terminating]\n\n  return _train\n\n\ndef inference(cluster_info, feed_timeout=600, qname=\'input\'):\n  """"""Feeds Spark partitions into the shared multiprocessing.Queue and returns inference results.\n\n  Args:\n    :cluster_info: node reservation information for the cluster (e.g. host, executor_id, pid, ports, etc)\n    :feed_timeout: number of seconds after which data feeding times out (600 sec default)\n    :qname: *INTERNAL_USE*\n\n  Returns:\n    A dataRDD.mapPartitions() function\n  """"""\n  def _inference(iter):\n    # get shared queue, reconnecting if necessary\n    mgr = _get_manager(cluster_info, util.get_ip_address(), util.read_executor_id())\n    try:\n      queue_in = mgr.get_queue(qname)\n      equeue = mgr.get_queue(\'error\')\n    except (AttributeError, KeyError):\n      msg = ""Queue \'{}\' not found on this node, check for exceptions on other nodes."".format(qname)\n      raise Exception(msg)\n\n    logger.info(""Feeding partition {0} into {1} queue {2}"".format(iter, qname, queue_in))\n    count = 0\n    for item in iter:\n      count += 1\n      queue_in.put(item, block=True)\n\n    # signal ""end of partition""\n    queue_in.put(marker.EndPartition())\n\n    # skip empty partitions\n    if count == 0:\n      return []\n\n    # wait for consumers to finish processing all items in queue before ""finishing"" this iterator\n    joinThr = Thread(target=queue_in.join)\n    joinThr.start()\n    timeout = feed_timeout\n    while (joinThr.isAlive()):\n      if (not equeue.empty()):\n        e_str = equeue.get()\n        raise Exception(""Exception in worker:\\n"" + e_str)\n      time.sleep(1)\n      timeout -= 1\n      if timeout <= 0:\n        raise Exception(""Timeout while feeding partition"")\n\n    logger.info(""Processed {0} items in partition"".format(count))\n\n    # read result queue\n    results = []\n    queue_out = mgr.get_queue(\'output\')\n    while count > 0:\n      result = queue_out.get(block=True)\n      results.append(result)\n      count -= 1\n      queue_out.task_done()\n\n    logger.info(""Finished processing partition"")\n    return results\n\n  return _inference\n\n\ndef shutdown(cluster_info, grace_secs=0, queues=[\'input\']):\n  """"""Stops all TensorFlow nodes by feeding ``None`` into the multiprocessing.Queues.\n\n  Args:\n    :cluster_info: node reservation information for the cluster (e.g. host, executor_id, pid, ports, etc).\n    :queues: *INTERNAL_USE*\n\n  Returns:\n    A nodeRDD.mapPartitions() function\n  """"""\n  def _shutdown(iter):\n    host = util.get_ip_address()\n    executor_id = util.read_executor_id()\n\n    # reconnect to shared queue\n    mgr = _get_manager(cluster_info, host, executor_id)\n\n    # send SIGTERM to Tensorboard proc (if running)\n    for node in cluster_info:\n      if node[\'host\'] == host and node[\'executor_id\'] == executor_id:\n        tb_pid = node[\'tb_pid\']\n        if tb_pid != 0:\n          logger.info(""Stopping tensorboard (pid={0})"".format(tb_pid))\n          subprocess.Popen([""kill"", str(tb_pid)])\n\n    # terminate any listening queues\n    logger.info(""Stopping all queues"")\n    for q in queues:\n      if q != \'error\':\n        try:\n          queue = mgr.get_queue(q)\n          logger.info(""Feeding None into {0} queue"".format(q))\n          queue.put(None, block=True)\n        except (AttributeError, KeyError):\n          msg = ""Queue \'{}\' not found on this node, check for exceptions on other nodes."".format(q)\n          raise Exception(msg)\n\n    # wait for grace period (after terminating feed queues)\n    if grace_secs > 0:\n      logger.info(""Waiting for {} second grace period"".format(grace_secs))\n      time.sleep(grace_secs)\n\n    # then check for any late exceptions\n    equeue = mgr.get_queue(\'error\')\n    if (not equeue.empty()):\n      # note: ""peek"" this queue, since otherwise Spark might retry this ""failed"" task, find no errors in queue, and finish the job with SUCCESS\n      e_str = equeue.get()\n      equeue.put(e_str)\n      raise Exception(""Exception in worker:\\n"" + e_str)\n\n    logger.info(""Setting mgr.state to \'stopped\'"")\n    mgr.set(\'state\', \'stopped\')\n    return [True]\n\n  return _shutdown\n'"
tensorflowonspark/__init__.py,0,"b'import logging\n\nlogging.basicConfig(level=logging.INFO, format=""%(asctime)s %(levelname)s (%(threadName)s-%(process)d) %(message)s"")\n\n__version__ = ""2.2.1""\n'"
tensorflowonspark/compat.py,7,"b'# Copyright 2019 Yahoo Inc / Verizon Media\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""Helper functions to abstract API changes between TensorFlow versions, intended for end-user TF code.""""""\n\nimport tensorflow as tf\nfrom packaging import version\n\n\ndef export_saved_model(model, export_dir, is_chief=False):\n  if version.parse(tf.__version__) < version.parse(\'2.1.0\'):\n    if is_chief:\n      tf.keras.experimental.export_saved_model(model, export_dir)\n  else:\n    # non-chief nodes save to dummy location on local disk\n    export_dir = export_dir if is_chief else \'worker_model\'\n    model.save(export_dir, save_format=\'tf\')\n\n\ndef disable_auto_shard(options):\n  if version.parse(tf.__version__) < version.parse(\'2.1.0\'):\n    options.experimental_distribute.auto_shard = False\n  else:\n    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n\n\ndef is_gpu_available():\n  if version.parse(tf.__version__) < version.parse(\'2.1.0\'):\n    return tf.test.is_built_with_cuda()\n  else:\n    return len(tf.config.list_physical_devices(\'GPU\')) > 0\n'"
tensorflowonspark/dfutil.py,27,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""A collection of utility functions for loading/saving TensorFlow TFRecords files as Spark DataFrames.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import ArrayType, BinaryType, DoubleType, LongType, StringType, StructField, StructType\n\nloadedDF = {}       # Stores origin paths of loaded DataFrames (df => path)\n\n\ndef isLoadedDF(df):\n  """"""Returns True if the input DataFrame was produced by the loadTFRecords() method.\n\n  This is primarily used by the Spark ML Pipelines APIs.\n\n  Args:\n    :df: Spark Dataframe\n  """"""\n  return df in loadedDF\n\n\ndef saveAsTFRecords(df, output_dir):\n  """"""Save a Spark DataFrame as TFRecords.\n\n  This will convert the DataFrame rows to TFRecords prior to saving.\n\n  Args:\n    :df: Spark DataFrame\n    :output_dir: Path to save TFRecords\n  """"""\n  tf_rdd = df.rdd.mapPartitions(toTFExample(df.dtypes))\n  tf_rdd.saveAsNewAPIHadoopFile(output_dir, ""org.tensorflow.hadoop.io.TFRecordFileOutputFormat"",\n                                keyClass=""org.apache.hadoop.io.BytesWritable"",\n                                valueClass=""org.apache.hadoop.io.NullWritable"")\n\n\ndef loadTFRecords(sc, input_dir, binary_features=[]):\n  """"""Load TFRecords from disk into a Spark DataFrame.\n\n  This will attempt to automatically convert the tf.train.Example features into Spark DataFrame columns of equivalent types.\n\n  Note: TensorFlow represents both strings and binary types as tf.train.BytesList, and we need to\n  disambiguate these types for Spark DataFrames DTypes (StringType and BinaryType), so we require a ""hint""\n  from the caller in the ``binary_features`` argument.\n\n  Args:\n    :sc: SparkContext\n    :input_dir: location of TFRecords on disk.\n    :binary_features: a list of tf.train.Example features which are expected to be binary/bytearrays.\n\n  Returns:\n    A Spark DataFrame mirroring the tf.train.Example schema.\n  """"""\n  import tensorflow as tf\n\n  tfr_rdd = sc.newAPIHadoopFile(input_dir, ""org.tensorflow.hadoop.io.TFRecordFileInputFormat"",\n                                keyClass=""org.apache.hadoop.io.BytesWritable"",\n                                valueClass=""org.apache.hadoop.io.NullWritable"")\n\n  # infer Spark SQL types from tf.Example\n  record = tfr_rdd.take(1)[0]\n  example = tf.train.Example()\n  example.ParseFromString(bytes(record[0]))\n  schema = infer_schema(example, binary_features)\n\n  # convert serialized protobuf to tf.Example to Row\n  example_rdd = tfr_rdd.mapPartitions(lambda x: fromTFExample(x, binary_features))\n\n  # create a Spark DataFrame from RDD[Row]\n  df = example_rdd.toDF(schema)\n\n  # save reference of this dataframe\n  loadedDF[df] = input_dir\n  return df\n\n\ndef toTFExample(dtypes):\n  """"""mapPartition function to convert a Spark RDD of Row into an RDD of serialized tf.train.Example bytestring.\n\n  Note that tf.train.Example is a fairly flat structure with limited datatypes, e.g. tf.train.FloatList,\n  tf.train.Int64List, and tf.train.BytesList, so most DataFrame types will be coerced into one of these types.\n\n  Args:\n    :dtypes: the DataFrame.dtypes of the source DataFrame.\n\n  Returns:\n    A mapPartition function which converts the source DataFrame into tf.train.Example bytestrings.\n  """"""\n  def _toTFExample(iter):\n\n    # supported type mappings between DataFrame.dtypes and tf.train.Feature types\n    float_dtypes = [\'float\', \'double\']\n    int64_dtypes = [\'boolean\', \'tinyint\', \'smallint\', \'int\', \'bigint\', \'long\']\n    bytes_dtypes = [\'binary\', \'string\']\n    float_list_dtypes = [\'array<float>\', \'array<double>\']\n    int64_list_dtypes = [\'array<boolean>\', \'array<tinyint>\', \'array<smallint>\', \'array<int>\', \'array<bigint>\', \'array<long>\']\n\n    def _toTFFeature(name, dtype, row):\n      feature = None\n      if dtype in float_dtypes:\n        feature = (name, tf.train.Feature(float_list=tf.train.FloatList(value=[row[name]])))\n      elif dtype in int64_dtypes:\n        feature = (name, tf.train.Feature(int64_list=tf.train.Int64List(value=[row[name]])))\n      elif dtype in bytes_dtypes:\n        if dtype == \'binary\':\n          feature = (name, tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(row[name])])))\n        else:\n          feature = (name, tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(row[name]).encode(\'utf-8\')])))\n      elif dtype in float_list_dtypes:\n        feature = (name, tf.train.Feature(float_list=tf.train.FloatList(value=row[name])))\n      elif dtype in int64_list_dtypes:\n        feature = (name, tf.train.Feature(int64_list=tf.train.Int64List(value=row[name])))\n      else:\n        raise Exception(""Unsupported dtype: {0}"".format(dtype))\n      return feature\n\n    results = []\n    for row in iter:\n      features = dict([_toTFFeature(name, dtype, row) for name, dtype in dtypes])\n      example = tf.train.Example(features=tf.train.Features(feature=features))\n      results.append((bytearray(example.SerializeToString()), None))\n    return results\n\n  return _toTFExample\n\n\ndef infer_schema(example, binary_features=[]):\n  """"""Given a tf.train.Example, infer the Spark DataFrame schema (StructFields).\n\n  Note: TensorFlow represents both strings and binary types as tf.train.BytesList, and we need to\n  disambiguate these types for Spark DataFrames DTypes (StringType and BinaryType), so we require a ""hint""\n  from the caller in the ``binary_features`` argument.\n\n  Args:\n    :example: a tf.train.Example\n    :binary_features: a list of tf.train.Example features which are expected to be binary/bytearrays.\n\n  Returns:\n    A DataFrame StructType schema\n  """"""\n  def _infer_sql_type(k, v):\n    # special handling for binary features\n    if k in binary_features:\n      return BinaryType()\n\n    if v.int64_list.value:\n      result = v.int64_list.value\n      sql_type = LongType()\n    elif v.float_list.value:\n      result = v.float_list.value\n      sql_type = DoubleType()\n    else:\n      result = v.bytes_list.value\n      sql_type = StringType()\n\n    if len(result) > 1:             # represent multi-item tensors as Spark SQL ArrayType() of base types\n      return ArrayType(sql_type)\n    else:                           # represent everything else as base types (and empty tensors as StringType())\n      return sql_type\n\n  return StructType([StructField(k, _infer_sql_type(k, v), True) for k, v in sorted(example.features.feature.items())])\n\n\ndef fromTFExample(iter, binary_features=[]):\n  """"""mapPartition function to convert an RDD of serialized tf.train.Example bytestring into an RDD of Row.\n\n  Note: TensorFlow represents both strings and binary types as tf.train.BytesList, and we need to\n  disambiguate these types for Spark DataFrames DTypes (StringType and BinaryType), so we require a ""hint""\n  from the caller in the ``binary_features`` argument.\n\n  Args:\n    :iter: the RDD partition iterator\n    :binary_features: a list of tf.train.Example features which are expected to be binary/bytearrays.\n\n  Returns:\n    An array/iterator of DataFrame Row with features converted into columns.\n  """"""\n  # convert from protobuf-like dict to DataFrame-friendly dict\n  def _get_value(k, v):\n    if v.int64_list.value:\n      result = v.int64_list.value\n    elif v.float_list.value:\n      result = v.float_list.value\n    else:  # string or bytearray\n      if k in binary_features:\n        return bytearray(v.bytes_list.value[0])\n      else:\n        return v.bytes_list.value[0].decode(\'utf-8\')\n\n    if len(result) > 1:         # represent multi-item tensors as python lists\n      return list(result)\n    elif len(result) == 1:      # extract scalars from single-item tensors\n      return result[0]\n    else:                       # represent empty tensors as python None\n      return None\n\n  results = []\n  for record in iter:\n    example = tf.train.Example()\n    example.ParseFromString(bytes(record[0]))       # record is (bytestr, None)\n    d = {k: _get_value(k, v) for k, v in sorted(example.features.feature.items())}\n    row = Row(**d)\n    results.append(row)\n\n  return results\n'"
tensorflowonspark/gpu_info.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport logging\nimport random\nimport subprocess\nimport time\n\nlogger = logging.getLogger(__name__)\n\nMAX_RETRIES = 3           #: Maximum retries to allocate GPUs\nAS_STRING = \'string\'\nAS_LIST = \'list\'\n\n\ndef is_gpu_available():\n  """"""Determine if GPUs are available on the host""""""\n  try:\n    subprocess.check_output([""nvidia-smi"", ""--list-gpus""])\n    return True\n  except Exception:\n    return False\n\n\ndef get_gpus(num_gpu=1, worker_index=-1, format=AS_STRING):\n  """"""Get list of free GPUs according to nvidia-smi.\n\n  This will retry for ``MAX_RETRIES`` times until the requested number of GPUs are available.\n\n  Args:\n    :num_gpu: number of GPUs desired.\n    :worker_index: index ""hint"" for allocation of available GPUs.\n\n  Returns:\n    Comma-delimited string of GPU ids, or raises an Exception if the requested number of GPUs could not be found.\n  """"""\n  # get list of gpus (index, uuid)\n  list_gpus = subprocess.check_output([""nvidia-smi"", ""--list-gpus""]).decode()\n  logger.debug(""all GPUs:\\n{0}"".format(list_gpus))\n\n  # parse index and guid\n  gpus = [x for x in list_gpus.split(\'\\n\') if len(x) > 0]\n\n  def parse_gpu(gpu_str):\n    cols = gpu_str.split(\' \')\n    return cols[5].split(\')\')[0], cols[1].split(\':\')[0]\n\n  gpu_list = [parse_gpu(gpu) for gpu in gpus]\n\n  free_gpus = []\n  retries = 0\n  while len(free_gpus) < num_gpu and retries < MAX_RETRIES:\n    smi_output = subprocess.check_output([""nvidia-smi"", ""--format=csv,noheader,nounits"", ""--query-compute-apps=gpu_uuid""]).decode()\n    logger.debug(""busy GPUs:\\n{0}"".format(smi_output))\n    busy_uuids = [x for x in smi_output.split(\'\\n\') if len(x) > 0]\n    for uuid, index in gpu_list:\n      if uuid not in busy_uuids:\n        free_gpus.append(index)\n\n    if len(free_gpus) < num_gpu:\n      logger.warn(""Unable to find available GPUs: requested={0}, available={1}"".format(num_gpu, len(free_gpus)))\n      retries += 1\n      time.sleep(30 * retries)\n      free_gpus = []\n\n  logger.info(""Available GPUs: {}"".format(free_gpus))\n\n  # if still can\'t find available GPUs, raise exception\n  if len(free_gpus) < num_gpu:\n    smi_output = subprocess.check_output([""nvidia-smi"", ""--format=csv"", ""--query-compute-apps=gpu_uuid,pid,process_name,used_gpu_memory""]).decode()\n    logger.info("": {0}"".format(smi_output))\n    raise Exception(""Unable to find {} free GPU(s)\\n{}"".format(num_gpu, smi_output))\n\n  # Get logical placement\n  num_available = len(free_gpus)\n  if worker_index == -1:\n    # use original random placement\n    random.shuffle(free_gpus)\n    proposed_gpus = free_gpus[:num_gpu]\n  else:\n    # ordered by worker index\n    if worker_index * num_gpu + num_gpu > num_available:\n      worker_index = worker_index * num_gpu % num_available\n    proposed_gpus = free_gpus[worker_index * num_gpu:(worker_index * num_gpu + num_gpu)]\n  logger.info(""Proposed GPUs: {}"".format(proposed_gpus))\n\n  if format == AS_STRING:\n    return \',\'.join(str(x) for x in proposed_gpus)\n  elif format == AS_LIST:\n    return proposed_gpus\n  else:\n    raise Exception(""Unknown GPU format"")\n'"
tensorflowonspark/marker.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\n\nclass Marker(object):\n  """"""Base class for special marker objects in the data queue""""""\n  pass\n\n\nclass EndPartition(Marker):\n  """"""Marks the end of an RDD Partition during data feeding""""""\n  pass\n'"
tensorflowonspark/pipeline.py,9,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""This module extends the TensorFlowOnSpark API to support Spark ML Pipelines.\n\nIt provides a TFEstimator class to fit a TFModel using TensorFlow.  The TFEstimator will actually spawn a TensorFlowOnSpark cluster\nto conduct distributed training, but due to architectural limitations, the TFModel will only run single-node TensorFlow instances\nwhen inferencing on the executors.  The executors will run in parallel, so the TensorFlow model must fit in the memory\nof each executor.\n\n\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom pyspark.context import SparkContext\nfrom pyspark.ml.param.shared import Param, Params, TypeConverters\nfrom pyspark.ml.pipeline import Estimator, Model\nfrom pyspark.sql import Row, SparkSession\n\nimport argparse\nimport copy\nimport logging\nimport pkg_resources\nimport sys\n\nfrom . import TFCluster, util\nfrom packaging import version\n\n\nlogger = logging.getLogger(__name__)\nTF_VERSION = pkg_resources.get_distribution(\'tensorflow\').version\n\n\n# TensorFlowOnSpark Params\n\nclass TFTypeConverters(object):\n  """"""Custom DataFrame TypeConverter for dictionary types (since this is not provided by Spark core).""""""\n  @staticmethod\n  def toDict(value):\n    if type(value) == dict:\n      return value\n    else:\n      raise TypeError(""Could not convert %s to OrderedDict"" % value)\n\n\nclass HasBatchSize(Params):\n  batch_size = Param(Params._dummy(), ""batch_size"", ""Number of records per batch"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasBatchSize, self).__init__()\n\n  def setBatchSize(self, value):\n    return self._set(batch_size=value)\n\n  def getBatchSize(self):\n    return self.getOrDefault(self.batch_size)\n\n\nclass HasClusterSize(Params):\n  cluster_size = Param(Params._dummy(), ""cluster_size"", ""Number of nodes in the cluster"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasClusterSize, self).__init__()\n\n  def setClusterSize(self, value):\n    return self._set(cluster_size=value)\n\n  def getClusterSize(self):\n    return self.getOrDefault(self.cluster_size)\n\n\nclass HasEpochs(Params):\n  epochs = Param(Params._dummy(), ""epochs"", ""Number of epochs to train"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasEpochs, self).__init__()\n\n  def setEpochs(self, value):\n    return self._set(epochs=value)\n\n  def getEpochs(self):\n    return self.getOrDefault(self.epochs)\n\n\nclass HasGraceSecs(Params):\n  grace_secs = Param(Params._dummy(), ""grace_secs"", ""Number of seconds to wait after feeding data (for final tasks like exporting a saved_model)"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasGraceSecs, self).__init__()\n\n  def setGraceSecs(self, value):\n    return self._set(grace_secs=value)\n\n  def getGraceSecs(self):\n    return self.getOrDefault(self.grace_secs)\n\n\nclass HasInputMapping(Params):\n  input_mapping = Param(Params._dummy(), ""input_mapping"", ""Mapping of input DataFrame column to input tensor"", typeConverter=TFTypeConverters.toDict)\n\n  def __init__(self):\n    super(HasInputMapping, self).__init__()\n\n  def setInputMapping(self, value):\n    return self._set(input_mapping=value)\n\n  def getInputMapping(self):\n    return self.getOrDefault(self.input_mapping)\n\n\nclass HasInputMode(Params):\n  input_mode = Param(Params._dummy(), ""input_mode"", ""Input data feeding mode (0=TENSORFLOW, 1=SPARK)"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasInputMode, self).__init__()\n\n  def setInputMode(self, value):\n    if value == TFCluster.InputMode.TENSORFLOW:\n      raise Exception(""InputMode.TENSORFLOW is deprecated"")\n\n    return self._set(input_mode=value)\n\n  def getInputMode(self):\n    return self.getOrDefault(self.input_mode)\n\n\nclass HasMasterNode(Params):\n  master_node = Param(Params._dummy(), ""master_node"", ""Job name of master/chief worker node"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasMasterNode, self).__init__()\n\n  def setMasterNode(self, value):\n    return self._set(master_node=value)\n\n  def getMasterNode(self):\n    return self.getOrDefault(self.master_node)\n\n\nclass HasModelDir(Params):\n  model_dir = Param(Params._dummy(), ""model_dir"", ""Path to save/load model checkpoints"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasModelDir, self).__init__()\n\n  def setModelDir(self, value):\n    return self._set(model_dir=value)\n\n  def getModelDir(self):\n    return self.getOrDefault(self.model_dir)\n\n\nclass HasNumPS(Params):\n  num_ps = Param(Params._dummy(), ""num_ps"", ""Number of PS nodes in cluster"", typeConverter=TypeConverters.toInt)\n  driver_ps_nodes = Param(Params._dummy(), ""driver_ps_nodes"", ""Run PS nodes on driver locally"", typeConverter=TypeConverters.toBoolean)\n\n  def __init__(self):\n    super(HasNumPS, self).__init__()\n\n  def setNumPS(self, value):\n    return self._set(num_ps=value)\n\n  def getNumPS(self):\n    return self.getOrDefault(self.num_ps)\n\n  def setDriverPSNodes(self, value):\n    return self._set(driver_ps_nodes=value)\n\n  def getDriverPSNodes(self):\n    return self.getOrDefault(self.driver_ps_nodes)\n\n\nclass HasOutputMapping(Params):\n  output_mapping = Param(Params._dummy(), ""output_mapping"", ""Mapping of output tensor to output DataFrame column"", typeConverter=TFTypeConverters.toDict)\n\n  def __init__(self):\n    super(HasOutputMapping, self).__init__()\n\n  def setOutputMapping(self, value):\n    return self._set(output_mapping=value)\n\n  def getOutputMapping(self):\n    return self.getOrDefault(self.output_mapping)\n\n\nclass HasProtocol(Params):\n  protocol = Param(Params._dummy(), ""protocol"", ""Network protocol for Tensorflow (grpc|rdma)"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasProtocol, self).__init__()\n\n  def setProtocol(self, value):\n    return self._set(protocol=value)\n\n  def getProtocol(self):\n    return self.getOrDefault(self.protocol)\n\n\nclass HasReaders(Params):\n  readers = Param(Params._dummy(), ""readers"", ""number of reader/enqueue threads"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasReaders, self).__init__()\n\n  def setReaders(self, value):\n    return self._set(readers=value)\n\n  def getReaders(self):\n    return self.getOrDefault(self.readers)\n\n\nclass HasSteps(Params):\n  steps = Param(Params._dummy(), ""steps"", ""Maximum number of steps to train"", typeConverter=TypeConverters.toInt)\n\n  def __init__(self):\n    super(HasSteps, self).__init__()\n\n  def setSteps(self, value):\n    return self._set(steps=value)\n\n  def getSteps(self):\n    return self.getOrDefault(self.steps)\n\n\nclass HasTensorboard(Params):\n  tensorboard = Param(Params._dummy(), ""tensorboard"", ""Launch tensorboard process"", typeConverter=TypeConverters.toBoolean)\n\n  def __init__(self):\n    super(HasTensorboard, self).__init__()\n\n  def setTensorboard(self, value):\n    return self._set(tensorboard=value)\n\n  def getTensorboard(self):\n    return self.getOrDefault(self.tensorboard)\n\n\nclass HasTFRecordDir(Params):\n  tfrecord_dir = Param(Params._dummy(), ""tfrecord_dir"", ""Path to temporarily export a DataFrame as TFRecords (for InputMode.TENSORFLOW apps)"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasTFRecordDir, self).__init__()\n\n  def setTFRecordDir(self, value):\n    return self._set(tfrecord_dir=value)\n\n  def getTFRecordDir(self):\n    return self.getOrDefault(self.tfrecord_dir)\n\n\n# SavedModelBuilder Params\n\nclass HasExportDir(Params):\n  export_dir = Param(Params._dummy(), ""export_dir"", ""Directory to export saved_model"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasExportDir, self).__init__()\n\n  def setExportDir(self, value):\n    return self._set(export_dir=value)\n\n  def getExportDir(self):\n    return self.getOrDefault(self.export_dir)\n\n\nclass HasSignatureDefKey(Params):\n  signature_def_key = Param(Params._dummy(), ""signature_def_key"", ""Identifier for a specific saved_model signature"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasSignatureDefKey, self).__init__()\n    self._setDefault(signature_def_key=None)\n\n  def setSignatureDefKey(self, value):\n    return self._set(signature_def_key=value)\n\n  def getSignatureDefKey(self):\n    return self.getOrDefault(self.signature_def_key)\n\n\nclass HasTagSet(Params):\n  tag_set = Param(Params._dummy(), ""tag_set"", ""Comma-delimited list of tags identifying a saved_model metagraph"", typeConverter=TypeConverters.toString)\n\n  def __init__(self):\n    super(HasTagSet, self).__init__()\n\n  def setTagSet(self, value):\n    return self._set(tag_set=value)\n\n  def getTagSet(self):\n    return self.getOrDefault(self.tag_set)\n\n\nclass Namespace(object):\n  """"""\n  Utility class to convert dictionaries to Namespace-like objects.\n\n  Based on https://docs.python.org/dev/library/types.html#types.SimpleNamespace\n  """"""\n  argv = None\n\n  def __init__(self, d):\n    if isinstance(d, list):\n      self.argv = d\n    elif isinstance(d, dict):\n      self.__dict__.update(d)\n    elif isinstance(d, argparse.Namespace):\n      self.__dict__.update(vars(d))\n    elif isinstance(d, Namespace):\n      self.__dict__.update(d.__dict__)\n    else:\n      raise Exception(""Unsupported Namespace args: {}"".format(d))\n\n  def __iter__(self):\n    if self.argv:\n      for item in self.argv:\n        yield item\n    else:\n      for key in self.__dict__.keys():\n        yield key\n\n  def __repr__(self):\n    if self.argv:\n      return ""{}"".format(self.argv)\n    else:\n      keys = sorted(self.__dict__)\n      items = (""{}={!r}"".format(k, self.__dict__[k]) for k in keys)\n      return ""{}({})"".format(type(self).__name__, "", "".join(items))\n\n  def __eq__(self, other):\n    if self.argv:\n      return self.argv == other\n    else:\n      return self.__dict__ == other.__dict__\n\n\nclass TFParams(Params):\n  """"""Mix-in class to store namespace-style args and merge w/ SparkML-style params.""""""\n  args = None\n\n  def merge_args_params(self):\n    local_args = copy.copy(self.args)                 # make a local copy of args\n    args_dict = vars(local_args)                      # get dictionary view\n    for p in self.params:\n      args_dict[p.name] = self.getOrDefault(p.name)   # update with params\n    return local_args\n\n\nclass TFEstimator(Estimator, TFParams, HasInputMapping,\n                  HasClusterSize, HasNumPS, HasInputMode, HasMasterNode, HasProtocol, HasGraceSecs,\n                  HasTensorboard, HasModelDir, HasExportDir, HasTFRecordDir,\n                  HasBatchSize, HasEpochs, HasReaders, HasSteps):\n  """"""Spark ML Estimator which launches a TensorFlowOnSpark cluster for distributed training.\n\n  The columns of the DataFrame passed to the ``fit()`` method will be mapped to TensorFlow tensors according to the ``setInputMapping()`` method.\n  Since the Spark ML Estimator API inherently relies on DataFrames/DataSets, InputMode.TENSORFLOW is not supported.\n\n  Args:\n    :train_fn: TensorFlow ""main"" function for training.\n    :tf_args: Arguments specific to the TensorFlow ""main"" function.\n    :export_fn: TensorFlow function for exporting a saved_model.  DEPRECATED for TF2.x.\n  """"""\n\n  train_fn = None\n  export_fn = None\n\n  def __init__(self, train_fn, tf_args, export_fn=None):\n    super(TFEstimator, self).__init__()\n    self.train_fn = train_fn\n    self.args = Namespace(tf_args)\n\n    master_node = \'chief\' if version.parse(TF_VERSION) >= version.parse(""2.0.0"") else None\n    self._setDefault(input_mapping={},\n                     cluster_size=1,\n                     num_ps=0,\n                     driver_ps_nodes=False,\n                     input_mode=TFCluster.InputMode.SPARK,\n                     master_node=master_node,\n                     protocol=\'grpc\',\n                     tensorboard=False,\n                     model_dir=None,\n                     export_dir=None,\n                     tfrecord_dir=None,\n                     batch_size=100,\n                     epochs=1,\n                     readers=1,\n                     steps=1000,\n                     grace_secs=30)\n\n  def _fit(self, dataset):\n    """"""Trains a TensorFlow model and returns a TFModel instance with the same args/params pointing to a checkpoint or saved_model on disk.\n\n    Args:\n      :dataset: A Spark DataFrame with columns that will be mapped to TensorFlow tensors.\n\n    Returns:\n      A TFModel representing the trained model, backed on disk by a TensorFlow checkpoint or saved_model.\n    """"""\n    sc = SparkContext.getOrCreate()\n\n    logger.info(""===== 1. train args: {0}"".format(self.args))\n    logger.info(""===== 2. train params: {0}"".format(self._paramMap))\n    local_args = self.merge_args_params()\n    logger.info(""===== 3. train args + params: {0}"".format(local_args))\n\n    tf_args = self.args.argv if self.args.argv else local_args\n    cluster = TFCluster.run(sc, self.train_fn, tf_args, local_args.cluster_size, local_args.num_ps,\n                            local_args.tensorboard, TFCluster.InputMode.SPARK, master_node=local_args.master_node, driver_ps_nodes=local_args.driver_ps_nodes)\n    # feed data, using a deterministic order for input columns (lexicographic by key)\n    input_cols = sorted(self.getInputMapping())\n    cluster.train(dataset.select(input_cols).rdd, local_args.epochs)\n    cluster.shutdown(grace_secs=self.getGraceSecs())\n\n    if self.export_fn:\n      if version.parse(TF_VERSION) < version.parse(""2.0.0""):\n        # For TF1.x, run export function, if provided\n        assert local_args.export_dir, ""Export function requires --export_dir to be set""\n        logging.info(""Exporting saved_model (via export_fn) to: {}"".format(local_args.export_dir))\n\n        def _export(iterator, fn, args):\n          single_node_env(args)\n          fn(args)\n\n        # Run on a single exeucutor\n        sc.parallelize([1], 1).foreachPartition(lambda it: _export(it, self.export_fn, tf_args))\n      else:\n        # for TF2.x\n        raise Exception(""Please use native TF2.x APIs to export a saved_model."")\n\n    return self._copyValues(TFModel(self.args))\n\n\nclass TFModel(Model, TFParams,\n              HasInputMapping, HasOutputMapping,\n              HasBatchSize,\n              HasModelDir, HasExportDir, HasSignatureDefKey, HasTagSet):\n  """"""Spark ML Model backed by a TensorFlow model checkpoint/saved_model on disk.\n\n  During ``transform()``, each executor will run an independent, single-node instance of TensorFlow in parallel, so the model must fit in memory.\n  The model/session will be loaded/initialized just once for each Spark Python worker, and the session will be cached for\n  subsequent tasks/partitions to avoid re-loading the model for each partition.\n\n  Args:\n    :tf_args: Dictionary of arguments specific to TensorFlow ""main"" function.\n  """"""\n\n  def __init__(self, tf_args):\n    super(TFModel, self).__init__()\n    self.args = Namespace(tf_args)\n    self._setDefault(input_mapping={},\n                     output_mapping={},\n                     batch_size=100,\n                     model_dir=None,\n                     export_dir=None,\n                     signature_def_key=None,\n                     tag_set=None)\n\n  def _transform(self, dataset):\n    """"""Transforms the input DataFrame by applying the _run_model() mapPartitions function.\n\n    Args:\n      :dataset: A Spark DataFrame for TensorFlow inferencing.\n    """"""\n    spark = SparkSession.builder.getOrCreate()\n\n    # set a deterministic order for input/output columns (lexicographic by key)\n    input_cols = [col for col, tensor in sorted(self.getInputMapping().items())]      # input col => input tensor\n    output_cols = [col for tensor, col in sorted(self.getOutputMapping().items())]    # output tensor => output col\n\n    # run single-node inferencing on each executor\n    logger.info(""input_cols: {}"".format(input_cols))\n    logger.info(""output_cols: {}"".format(output_cols))\n\n    # merge args + params\n    logger.info(""===== 1. inference args: {0}"".format(self.args))\n    logger.info(""===== 2. inference params: {0}"".format(self._paramMap))\n    local_args = self.merge_args_params()\n    logger.info(""===== 3. inference args + params: {0}"".format(local_args))\n\n    tf_args = self.args.argv if self.args.argv else local_args\n\n    _run_model = _run_model_tf1 if version.parse(TF_VERSION) < version.parse(""2.0.0"") else _run_model_tf2\n    rdd_out = dataset.select(input_cols).rdd.mapPartitions(lambda it: _run_model(it, local_args, tf_args))\n\n    # convert to a DataFrame-friendly format\n    rows_out = rdd_out.map(lambda x: Row(*x))\n    return spark.createDataFrame(rows_out, output_cols)\n\n\n# global on each python worker process on the executors\npred_fn = None           # saved_model prediction function/signature.\nglobal_sess = None       # tf.Session cache (TF1.x)\nglobal_args = None       # args provided to the _run_model() method.  Any change will invalidate the pred_fn.\nglobal_model = None      # this needs to be global for TF2.1+\n\n\ndef _run_model_tf1(iterator, args, tf_args):\n  """"""mapPartitions function (for TF1.x) to run single-node inferencing from a saved_model, using input/output mappings.\n\n  Args:\n    :iterator: input RDD partition iterator.\n    :args: arguments for TFModel, in argparse format\n    :tf_args: arguments for TensorFlow inferencing code, in argparse or ARGV format.\n\n  Returns:\n    An iterator of result data.\n  """"""\n  from tensorflow.python.saved_model import loader\n\n  single_node_env(tf_args)\n\n  logger.info(""===== input_mapping: {}"".format(args.input_mapping))\n  logger.info(""===== output_mapping: {}"".format(args.output_mapping))\n  input_tensor_names = [tensor for col, tensor in sorted(args.input_mapping.items())]\n  output_tensor_names = [tensor for tensor, col in sorted(args.output_mapping.items())]\n\n  # if using a signature_def_key, get input/output tensor info from the requested signature\n  if version.parse(TF_VERSION) < version.parse(""2.0.0"") and args.signature_def_key:\n    assert args.export_dir, ""Inferencing with signature_def_key requires --export_dir argument""\n    logging.info(""===== loading meta_graph_def for tag_set ({0}) from saved_model: {1}"".format(args.tag_set, args.export_dir))\n    meta_graph_def = get_meta_graph_def(args.export_dir, args.tag_set)\n    signature = meta_graph_def.signature_def[args.signature_def_key]\n    logging.debug(""signature: {}"".format(signature))\n    inputs_tensor_info = signature.inputs\n    logging.debug(""inputs_tensor_info: {0}"".format(inputs_tensor_info))\n    outputs_tensor_info = signature.outputs\n    logging.debug(""outputs_tensor_info: {0}"".format(outputs_tensor_info))\n\n  result = []\n  global global_sess, global_args\n  if global_sess and global_args == args:\n    # if graph/session already loaded/started (and using same args), just reuse it\n    sess = global_sess\n  else:\n    # otherwise, create new session and load graph from disk\n    import tensorflow as tf\n    tf.reset_default_graph()\n    sess = tf.Session(graph=tf.get_default_graph())\n    if args.export_dir:\n      assert args.tag_set, ""Inferencing from a saved_model requires --tag_set""\n      # load graph from a saved_model\n      logging.info(""===== restoring from saved_model: {}"".format(args.export_dir))\n      loader.load(sess, args.tag_set.split(\',\'), args.export_dir)\n    elif args.model_dir:\n      # load graph from a checkpoint\n      ckpt = tf.train.latest_checkpoint(args.model_dir)\n      assert ckpt, ""Invalid model checkpoint path: {}"".format(args.model_dir)\n      logging.info(""===== restoring from checkpoint: {}"".format(ckpt + "".meta""))\n      saver = tf.train.import_meta_graph(ckpt + "".meta"", clear_devices=True)\n      saver.restore(sess, ckpt)\n    else:\n      raise Exception(""Inferencing requires either --model_dir or --export_dir argument"")\n    global_sess = sess\n    global_args = args\n\n  # get list of input/output tensors (by name)\n  if args.signature_def_key:\n    input_tensors = [inputs_tensor_info[t].name for t in input_tensor_names]\n    output_tensors = [outputs_tensor_info[t].name for t in output_tensor_names]\n  else:\n    input_tensors = [t + \':0\' for t in input_tensor_names]\n    output_tensors = [t + \':0\' for t in output_tensor_names]\n\n  logging.info(""input_tensors: {0}"".format(input_tensors))\n  logging.info(""output_tensors: {0}"".format(output_tensors))\n\n  # feed data in batches and return output tensors\n  for tensors in yield_batch(iterator, args.batch_size, len(input_tensor_names)):\n    inputs_feed_dict = {}\n    for i in range(len(input_tensors)):\n      inputs_feed_dict[input_tensors[i]] = tensors[i]\n\n    outputs = sess.run(output_tensors, feed_dict=inputs_feed_dict)\n    lengths = [len(output) for output in outputs]\n    input_size = len(tensors[0])\n    assert all([length == input_size for length in lengths]), ""Output array sizes {} must match input size: {}"".format(lengths, input_size)\n    python_outputs = [output.tolist() for output in outputs]      # convert from numpy to standard python types\n    result.extend(zip(*python_outputs))                           # convert to an array of tuples of ""output columns""\n\n  return result\n\n\ndef _run_model_tf2(iterator, args, tf_args):\n  """"""mapPartitions function (for TF2.x) to run single-node inferencing from a saved_model, using input/output mappings.""""""\n  single_node_env(tf_args)\n\n  import tensorflow as tf\n\n  logger.info(""===== input_mapping: {}"".format(args.input_mapping))\n  logger.info(""===== output_mapping: {}"".format(args.output_mapping))\n  input_tensor_names = [tensor for col, tensor in sorted(args.input_mapping.items())]\n  output_tensor_names = [tensor for tensor, col in sorted(args.output_mapping.items())]\n\n  global pred_fn, global_args, global_model\n\n  if not pred_fn or args != global_args:\n    # cache pred_fn to avoid reloading model for each partition\n    assert args.export_dir, ""Inferencing requires --export_dir argument""\n    logger.info(""===== loading saved_model from: {}"".format(args.export_dir))\n    global_model = tf.saved_model.load(args.export_dir, tags=args.tag_set)\n    logger.info(""===== signature_def_key: {}"".format(args.signature_def_key))\n    pred_fn = global_model.signatures[args.signature_def_key]\n    global_args = args\n\n  inputs_tensor_info = {i.name: i for i in pred_fn.inputs}\n  logger.info(""===== inputs_tensor_info: {0}"".format(inputs_tensor_info))\n  outputs_tensor_info = pred_fn.outputs\n  logger.info(""===== outputs_tensor_info: {0}"".format(outputs_tensor_info))\n\n  result = []\n\n  # feed data in batches and return output tensors\n  for tensors in yield_batch(iterator, args.batch_size, len(input_tensor_names)):\n    inputs = {}\n    for i in range(len(input_tensor_names)):\n      name = input_tensor_names[i]\n      t = inputs_tensor_info[name + "":0""]\n      tensor = tf.constant(tensors[i], dtype=t.dtype)\n      # coerce shape if needed, since Spark only supports flat arrays\n      # and since saved_models don\'t encode tf.data operations\n      expected_shape = list(t.shape)\n      expected_shape[0] = tensor.shape[0]\n      if tensor.shape != expected_shape:\n        tensor = tf.reshape(tensor, expected_shape)\n      inputs[name] = tensor\n\n    predictions = pred_fn(**inputs)\n    outputs = {k: v for k, v in predictions.items() if k in output_tensor_names}\n\n    # validate that all output sizes match input size\n    output_sizes = [len(v) for k, v in outputs.items()]\n\n    input_size = len(tensors[0])\n    assert all([osize == input_size for osize in output_sizes]), ""Output array sizes {} must match input size: {}"".format(output_sizes, input_size)\n\n    # convert to standard python types\n    python_outputs = [v.numpy().tolist() for k, v in outputs.items()]\n\n    # convert to an array of tuples of ""output columns""\n    result.extend(zip(*python_outputs))\n\n  return result\n\n\ndef single_node_env(args):\n  """"""Sets up environment for a single-node TF session.\n\n  Args:\n    :args: command line arguments as either argparse args or argv list\n  """"""\n  # setup ARGV for the TF process\n  if isinstance(args, list):\n      sys.argv = args\n  elif args.argv:\n      sys.argv = args.argv\n\n  # setup ENV for Hadoop-compatibility and/or GPU allocation\n  num_gpus = args.num_gpus if \'num_gpus\' in args else 1\n  util.single_node_env(num_gpus)\n\n\ndef get_meta_graph_def(saved_model_dir, tag_set):\n  """"""Utility function to read a meta_graph_def from disk.\n\n  From `saved_model_cli.py <https://github.com/tensorflow/tensorflow/blob/8e0e8d41a3a8f2d4a6100c2ea1dc9d6c6c4ad382/tensorflow/python/tools/saved_model_cli.py#L186>`_\n\n  DEPRECATED for TF2.0+\n\n  Args:\n    :saved_model_dir: path to saved_model.\n    :tag_set: list of string tags identifying the TensorFlow graph within the saved_model.\n\n  Returns:\n    A TensorFlow meta_graph_def, or raises an Exception otherwise.\n  """"""\n  from tensorflow.contrib.saved_model.python.saved_model import reader\n\n  saved_model = reader.read_saved_model(saved_model_dir)\n  set_of_tags = set(tag_set.split(\',\'))\n  for meta_graph_def in saved_model.meta_graphs:\n    if set(meta_graph_def.meta_info_def.tags) == set_of_tags:\n      return meta_graph_def\n  raise RuntimeError(""MetaGraphDef associated with tag-set {0} could not be found in SavedModel"".format(tag_set))\n\n\ndef yield_batch(iterable, batch_size, num_tensors=1):\n  """"""Generator that yields batches of a DataFrame iterator.\n\n  Args:\n    :iterable: Spark partition iterator.\n    :batch_size: number of items to retrieve per invocation.\n    :num_tensors: number of tensors (columns) expected in each item.\n\n  Returns:\n    An array of ``num_tensors`` arrays, each of length `batch_size`\n  """"""\n  tensors = [[] for i in range(num_tensors)]\n  for item in iterable:\n    if item is None:\n      break\n    for i in range(num_tensors):\n      tmp = str(item[i]) if type(item[i]) is bytearray else item[i]\n      tensors[i].append(tmp)\n    if len(tensors[0]) >= batch_size:\n      yield tensors\n      tensors = [[] for i in range(num_tensors)]\n  if len(tensors[0]) > 0:\n      yield tensors\n'"
tensorflowonspark/reservation.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""This module contains client/server methods to manage node reservations during TFCluster startup.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport logging\nimport os\nimport pickle\nimport select\nimport socket\nimport struct\nimport sys\nimport threading\nimport time\n\nfrom . import util\n\nlogger = logging.getLogger(__name__)\n\nTFOS_SERVER_PORT = ""TFOS_SERVER_PORT""\nTFOS_SERVER_HOST = ""TFOS_SERVER_HOST""\nBUFSIZE = 1024\nMAX_RETRIES = 3\n\n\nclass Reservations:\n  """"""Thread-safe store for node reservations.\n\n  Args:\n    :required: expected number of nodes in the cluster.\n  """"""\n\n  def __init__(self, required):\n    self.required = required\n    self.lock = threading.RLock()\n    self.reservations = []\n\n  def add(self, meta):\n    """"""Add a reservation.\n\n    Args:\n      :meta: a dictonary of metadata about a node\n    """"""\n    with self.lock:\n      self.reservations.append(meta)\n\n  def done(self):\n    """"""Returns True if the ``required`` number of reservations have been fulfilled.""""""\n    with self.lock:\n      return len(self.reservations) >= self.required\n\n  def get(self):\n    """"""Get the list of current reservations.""""""\n    with self.lock:\n      return self.reservations\n\n  def remaining(self):\n    """"""Get a count of remaining/unfulfilled reservations.""""""\n    with self.lock:\n      return self.required - len(self.reservations)\n\n\nclass MessageSocket(object):\n  """"""Abstract class w/ length-prefixed socket send/receive functions.""""""\n\n  def receive(self, sock):\n    """"""Receive a message on ``sock``.""""""\n    msg = None\n    data = b\'\'\n    recv_done = False\n    recv_len = -1\n    while not recv_done:\n      buf = sock.recv(BUFSIZE)\n      if buf is None or len(buf) == 0:\n        raise Exception(""socket closed"")\n      if recv_len == -1:\n        recv_len = struct.unpack(\'>I\', buf[:4])[0]\n        data += buf[4:]\n        recv_len -= len(data)\n      else:\n        data += buf\n        recv_len -= len(buf)\n      recv_done = (recv_len == 0)\n\n    msg = pickle.loads(data)\n    return msg\n\n  def send(self, sock, msg):\n    """"""Send ``msg`` to destination ``sock``.""""""\n    data = pickle.dumps(msg)\n    buf = struct.pack(\'>I\', len(data)) + data\n    sock.sendall(buf)\n\n\nclass Server(MessageSocket):\n  """"""Simple socket server with length-prefixed pickle messages.\n\n  Args:\n    :count: expected number of nodes in the cluster.\n  """"""\n  reservations = None             #: List of reservations managed by this server.\n  done = False                    #: boolean indicating if server should be shutdown.\n\n  def __init__(self, count):\n    assert count > 0, ""Expected number of reservations should be greater than zero""\n    self.reservations = Reservations(count)\n\n  def await_reservations(self, sc, status={}, timeout=600):\n    """"""Block until all reservations are received.""""""\n    timespent = 0\n    while not self.reservations.done():\n      logger.info(""waiting for {0} reservations"".format(self.reservations.remaining()))\n      # check status flags for any errors\n      if \'error\' in status:\n        sc.cancelAllJobs()\n        sc.stop()\n        sys.exit(1)\n      time.sleep(1)\n      timespent += 1\n      if (timespent > timeout):\n        raise Exception(""timed out waiting for reservations to complete"")\n    logger.info(""all reservations completed"")\n    return self.reservations.get()\n\n  def _handle_message(self, sock, msg):\n    logger.debug(""received: {0}"".format(msg))\n    msg_type = msg[\'type\']\n    if msg_type == \'REG\':\n      self.reservations.add(msg[\'data\'])\n      MessageSocket.send(self, sock, \'OK\')\n    elif msg_type == \'QUERY\':\n      MessageSocket.send(self, sock, self.reservations.done())\n    elif msg_type == \'QINFO\':\n      rinfo = self.reservations.get()\n      MessageSocket.send(self, sock, rinfo)\n    elif msg_type == \'STOP\':\n      logger.info(""setting server.done"")\n      MessageSocket.send(self, sock, \'OK\')\n      self.done = True\n    else:\n      MessageSocket.send(self, sock, \'ERR\')\n\n  def start(self):\n    """"""Start listener in a background thread\n\n    Returns:\n      address of the Server as a tuple of (host, port)\n    """"""\n    server_sock = self.start_listening_socket()\n\n    # hostname may not be resolvable but IP address probably will be\n    host = self.get_server_ip()\n    port = server_sock.getsockname()[1]\n    addr = (host, port)\n    logger.info(""listening for reservations at {0}"".format(addr))\n\n    def _listen(self, sock):\n      CONNECTIONS = []\n      CONNECTIONS.append(sock)\n\n      while not self.done:\n        read_socks, write_socks, err_socks = select.select(CONNECTIONS, [], [], 60)\n        for sock in read_socks:\n          if sock == server_sock:\n            client_sock, client_addr = sock.accept()\n            CONNECTIONS.append(client_sock)\n            logger.debug(""client connected from {0}"".format(client_addr))\n          else:\n            try:\n              msg = self.receive(sock)\n              self._handle_message(sock, msg)\n            except Exception as e:\n              logger.debug(e)\n              sock.close()\n              CONNECTIONS.remove(sock)\n\n      server_sock.close()\n\n    t = threading.Thread(target=_listen, args=(self, server_sock))\n    t.daemon = True\n    t.start()\n\n    return addr\n\n  def get_server_ip(self):\n    """"""Returns the value of TFOS_SERVER_HOST environment variable (if set), otherwise defaults to current host/IP.""""""\n    return os.getenv(TFOS_SERVER_HOST, util.get_ip_address())\n\n  def get_server_ports(self):\n    """"""Returns a list of target ports as defined in the TFOS_SERVER_PORT environment (if set), otherwise defaults to 0 (any port).\n\n    TFOS_SERVER_PORT should be either a single port number or a range, e.g. \'8888\' or \'9997-9999\'\n    """"""\n    port_string = os.getenv(TFOS_SERVER_PORT, ""0"")\n    if \'-\' not in port_string:\n      return [int(port_string)]\n    else:\n      ports = port_string.split(\'-\')\n      if len(ports) != 2:\n        raise Exception(""Invalid TFOS_SERVER_PORT: {}"".format(port_string))\n      return list(range(int(ports[0]), int(ports[1]) + 1))\n\n  def start_listening_socket(self):\n    """"""Starts the registration server socket listener.""""""\n    port_list = self.get_server_ports()\n    for port in port_list:\n      try:\n        server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        server_sock.bind((\'\', port))\n        server_sock.listen(10)\n        logger.info(""Reservation server binding to port {}"".format(port))\n        break\n      except Exception as e:\n        logger.warn(""Unable to bind to port {}, error {}"".format(port, e))\n        server_sock = None\n        pass\n\n    if not server_sock:\n      raise Exception(""Reservation server unable to bind to any ports, port_list = {}"".format(port_list))\n\n    return server_sock\n\n  def stop(self):\n    """"""Stop the Server\'s socket listener.""""""\n    self.done = True\n\n\nclass Client(MessageSocket):\n  """"""Client to register and await node reservations.\n\n  Args:\n    :server_addr: a tuple of (host, port) pointing to the Server.\n  """"""\n  sock = None                   #: socket to server TCP connection\n  server_addr = None            #: address of server\n\n  def __init__(self, server_addr):\n    self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    self.sock.connect(server_addr)\n    self.server_addr = server_addr\n    logger.info(""connected to server at {0}"".format(server_addr))\n\n  def _request(self, msg_type, msg_data=None):\n    """"""Helper function to wrap msg w/ msg_type.""""""\n    msg = {}\n    msg[\'type\'] = msg_type\n    if msg_data:\n      msg[\'data\'] = msg_data\n\n    done = False\n    tries = 0\n    while not done and tries < MAX_RETRIES:\n      try:\n        MessageSocket.send(self, self.sock, msg)\n        done = True\n      except socket.error as e:\n        tries += 1\n        if tries >= MAX_RETRIES:\n          raise\n        print(""Socket error: {}"".format(e))\n        self.sock.close()\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect(self.server_addr)\n\n    logger.debug(""sent: {0}"".format(msg))\n    resp = MessageSocket.receive(self, self.sock)\n    logger.debug(""received: {0}"".format(resp))\n    return resp\n\n  def close(self):\n    """"""Close the client socket.""""""\n    self.sock.close()\n\n  def register(self, reservation):\n    """"""Register ``reservation`` with server.""""""\n    resp = self._request(\'REG\', reservation)\n    return resp\n\n  def get_reservations(self):\n    """"""Get current list of reservations.""""""\n    cluster_info = self._request(\'QINFO\')\n    return cluster_info\n\n  def await_reservations(self):\n    """"""Poll until all reservations completed, then return cluster_info.""""""\n    done = False\n    while not done:\n      done = self._request(\'QUERY\')\n      time.sleep(1)\n    return self.get_reservations()\n\n  def request_stop(self):\n    """"""Request server stop.""""""\n    resp = self._request(\'STOP\')\n    return resp\n'"
tensorflowonspark/util.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import nested_scopes\nfrom __future__ import print_function\n\nimport logging\nimport os\nimport socket\nimport subprocess\nimport errno\nfrom socket import error as socket_error\nfrom . import gpu_info\n\nlogger = logging.getLogger(__name__)\n\n\ndef single_node_env(num_gpus=1, worker_index=-1, nodes=[]):\n  """"""Setup environment variables for Hadoop compatibility and GPU allocation""""""\n  # ensure expanded CLASSPATH w/o glob characters (required for Spark 2.1 + JNI)\n  if \'HADOOP_PREFIX\' in os.environ and \'TFOS_CLASSPATH_UPDATED\' not in os.environ:\n      classpath = os.environ[\'CLASSPATH\']\n      hadoop_path = os.path.join(os.environ[\'HADOOP_PREFIX\'], \'bin\', \'hadoop\')\n      hadoop_classpath = subprocess.check_output([hadoop_path, \'classpath\', \'--glob\']).decode()\n      os.environ[\'CLASSPATH\'] = classpath + os.pathsep + hadoop_classpath\n      os.environ[\'TFOS_CLASSPATH_UPDATED\'] = \'1\'\n\n  if gpu_info.is_gpu_available() and num_gpus > 0:\n    # reserve GPU(s), if requested\n    if worker_index >= 0 and len(nodes) > 0:\n      # compute my index relative to other nodes on the same host, if known\n      my_addr = nodes[worker_index]\n      my_host = my_addr.split(\':\')[0]\n      local_peers = [n for n in nodes if n.startswith(my_host)]\n      my_index = local_peers.index(my_addr)\n    else:\n      # otherwise, just use global worker index\n      my_index = worker_index\n\n    gpus_to_use = gpu_info.get_gpus(num_gpus, my_index)\n    logger.info(""Using gpu(s): {0}"".format(gpus_to_use))\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = gpus_to_use\n  else:\n    # CPU\n    logger.info(""Using CPU"")\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = \'\'\n\n\ndef get_ip_address():\n  """"""Simple utility to get host IP address.""""""\n  try:\n    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    s.connect((""8.8.8.8"", 80))\n    ip_address = s.getsockname()[0]\n  except socket_error as sockerr:\n    if sockerr.errno != errno.ENETUNREACH:\n      raise sockerr\n    ip_address = socket.gethostbyname(socket.getfqdn())\n  finally:\n    s.close()\n\n  return ip_address\n\n\ndef find_in_path(path, file):\n  """"""Find a file in a given path string.""""""\n  for p in path.split(os.pathsep):\n    candidate = os.path.join(p, file)\n    if os.path.exists(candidate) and os.path.isfile(candidate):\n      return candidate\n  return False\n\n\ndef write_executor_id(num):\n  """"""Write executor_id into a local file in the executor\'s current working directory""""""\n  with open(""executor_id"", ""w"") as f:\n    f.write(str(num))\n\n\ndef read_executor_id():\n  """"""Read worker id from a local file in the executor\'s current working directory""""""\n  if os.path.isfile(""executor_id""):\n    with open(""executor_id"", ""r"") as f:\n      return int(f.read())\n  else:\n    msg = ""No executor_id file found on this node, please ensure that:\\n"" + \\\n          ""1. Spark num_executors matches TensorFlow cluster_size\\n"" + \\\n          ""2. Spark tasks per executor is 1\\n"" + \\\n          ""3. Spark dynamic allocation is disabled\\n"" + \\\n          ""4. There are no other root-cause exceptions on other nodes\\n""\n    raise Exception(msg)\n'"
test/test.py,0,"b'import os\nimport unittest\n\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession\n\n\nclass SparkTest(unittest.TestCase):\n  """"""Base class for unittests using Spark.  Sets up and tears down a cluster per test class""""""\n\n  @classmethod\n  def setUpClass(cls):\n    master = os.getenv(\'MASTER\')\n    assert master is not None, ""Please start a Spark standalone cluster and export MASTER to your env.""\n\n    num_workers = os.getenv(\'SPARK_WORKER_INSTANCES\')\n    assert num_workers is not None, ""Please export SPARK_WORKER_INSTANCES to your env.""\n    cls.num_workers = int(num_workers)\n\n    spark_jars = os.getenv(\'SPARK_CLASSPATH\')\n    assert spark_jars, ""Please add path to tensorflow/ecosystem/hadoop jar to SPARK_CLASSPATH.""\n\n    cls.conf = SparkConf().set(\'spark.jars\', spark_jars)\n    cls.sc = SparkContext(master, cls.__name__, conf=cls.conf)\n    cls.spark = SparkSession.builder.getOrCreate()\n\n  @classmethod\n  def tearDownClass(cls):\n    cls.spark.stop()\n    cls.sc.stop()\n\n  def setUp(self):\n    print(""\\n==========================================================="")\n    print(self.id())\n    print(""===========================================================\\n"")\n\n\nclass SimpleTest(SparkTest):\n  """"""Check that basic Spark is working""""""\n  def test_spark(self):\n    sum = self.sc.parallelize(range(1000)).sum()\n    self.assertEqual(sum, 499500)\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_TFCluster.py,6,"b'import unittest\nimport test\nimport time\nfrom tensorflowonspark import TFCluster, TFNode\n\n\nclass TFClusterTest(test.SparkTest):\n  @classmethod\n  def setUpClass(cls):\n    super(TFClusterTest, cls).setUpClass()\n\n  @classmethod\n  def tearDownClass(cls):\n    super(TFClusterTest, cls).tearDownClass()\n\n  def test_basic_tf(self):\n    """"""Single-node TF graph (w/ args) running independently on multiple executors.""""""\n    def _map_fun(args, ctx):\n      import tensorflow as tf\n      x = tf.constant(args[\'x\'])\n      y = tf.constant(args[\'y\'])\n      sum = tf.math.add(x, y)\n      assert sum.numpy() == 3\n\n    args = {\'x\': 1, \'y\': 2}\n    cluster = TFCluster.run(self.sc, _map_fun, tf_args=args, num_executors=self.num_workers, num_ps=0)\n    cluster.shutdown()\n\n  def test_inputmode_spark(self):\n    """"""Distributed TF cluster w/ InputMode.SPARK""""""\n    def _map_fun(args, ctx):\n      import tensorflow as tf\n\n      tf_feed = TFNode.DataFeed(ctx.mgr, False)\n      while not tf_feed.should_stop():\n        batch = tf_feed.next_batch(batch_size=10)\n        print(""batch: {}"".format(batch))\n        squares = tf.math.square(batch)\n        print(""squares: {}"".format(squares))\n        tf_feed.batch_results(squares.numpy())\n\n    input = [[x] for x in range(1000)]    # set up input as tensors of shape [1] to match placeholder\n    rdd = self.sc.parallelize(input, 10)\n    cluster = TFCluster.run(self.sc, _map_fun, tf_args={}, num_executors=self.num_workers, num_ps=0, input_mode=TFCluster.InputMode.SPARK)\n    rdd_out = cluster.inference(rdd)\n    rdd_sum = rdd_out.sum()\n    self.assertEqual(rdd_sum, sum([x * x for x in range(1000)]))\n    cluster.shutdown()\n\n  def test_inputmode_spark_exception(self):\n    """"""Distributed TF cluster w/ InputMode.SPARK and exception during feeding""""""\n    def _map_fun(args, ctx):\n      import tensorflow as tf\n\n      tf_feed = TFNode.DataFeed(ctx.mgr, False)\n      while not tf_feed.should_stop():\n        batch = tf_feed.next_batch(10)\n        if len(batch) > 0:\n          squares = tf.math.square(batch)\n          tf_feed.batch_results(squares.numpy())\n          raise Exception(""FAKE exception during feeding"")\n\n    input = [[x] for x in range(1000)]    # set up input as tensors of shape [1] to match placeholder\n    rdd = self.sc.parallelize(input, 10)\n    with self.assertRaises(Exception):\n      cluster = TFCluster.run(self.sc, _map_fun, tf_args={}, num_executors=self.num_workers, num_ps=0, input_mode=TFCluster.InputMode.SPARK)\n      cluster.inference(rdd, feed_timeout=1).count()\n      cluster.shutdown()\n\n  def test_inputmode_spark_late_exception(self):\n    """"""Distributed TF cluster w/ InputMode.SPARK and exception after feeding""""""\n    def _map_fun(args, ctx):\n      import tensorflow as tf\n\n      tf_feed = TFNode.DataFeed(ctx.mgr, False)\n      while not tf_feed.should_stop():\n        batch = tf_feed.next_batch(10)\n        if len(batch) > 0:\n          squares = tf.math.square(batch)\n          tf_feed.batch_results(squares.numpy())\n\n      # simulate post-feed actions that raise an exception\n      time.sleep(2)\n      raise Exception(""FAKE exception after feeding"")\n\n    input = [[x] for x in range(1000)]    # set up input as tensors of shape [1] to match placeholder\n    rdd = self.sc.parallelize(input, 10)\n    with self.assertRaises(Exception):\n      cluster = TFCluster.run(self.sc, _map_fun, tf_args={}, num_executors=self.num_workers, num_ps=0, input_mode=TFCluster.InputMode.SPARK)\n      cluster.inference(rdd).count()\n      cluster.shutdown(grace_secs=5)      # note: grace_secs must be larger than the time needed for post-feed actions\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_TFNode.py,0,"b'import getpass\nimport os\nimport unittest\nfrom tensorflowonspark import TFManager, TFNode\n\n\nclass TFNodeTest(unittest.TestCase):\n  def test_hdfs_path(self):\n    """"""Normalization of absolution & relative string paths depending on filesystem""""""\n    cwd = os.getcwd()\n    user = getpass.getuser()\n    fs = [""file://"", ""hdfs://"", ""viewfs://""]\n    paths = {\n      ""hdfs://foo/bar"": [""hdfs://foo/bar"", ""hdfs://foo/bar"", ""hdfs://foo/bar""],\n      ""viewfs://foo/bar"": [""viewfs://foo/bar"", ""viewfs://foo/bar"", ""viewfs://foo/bar""],\n      ""file://foo/bar"": [""file://foo/bar"", ""file://foo/bar"", ""file://foo/bar""],\n      ""/foo/bar"": [""file:///foo/bar"", ""hdfs:///foo/bar"", ""viewfs:///foo/bar""],\n      ""foo/bar"": [""file://{}/foo/bar"".format(cwd), ""hdfs:///user/{}/foo/bar"".format(user), ""viewfs:///user/{}/foo/bar"".format(user)],\n    }\n\n    for i in range(len(fs)):\n      ctx = type(\'MockContext\', (), {\'defaultFS\': fs[i], \'working_dir\': cwd})\n      for path, expected in paths.items():\n        final_path = TFNode.hdfs_path(ctx, path)\n        self.assertEqual(final_path, expected[i], ""fs({}) + path({}) => {}, expected {}"".format(fs[i], path, final_path, expected[i]))\n\n  def test_datafeed(self):\n    """"""TFNode.DataFeed basic operations""""""\n    mgr = TFManager.start(\'abc\'.encode(\'utf-8\'), [\'input\', \'output\'], \'local\')\n\n    # insert 10 numbers followed by an end-of-feed marker\n    q = mgr.get_queue(\'input\')\n    for i in range(10):\n      q.put(i)\n    q.put(None)                           # end-of-feed marker\n\n    feed = TFNode.DataFeed(mgr)\n\n    # [0,1]\n    self.assertFalse(feed.done_feeding)\n    batch = feed.next_batch(2)\n    self.assertEqual(len(batch), 2)\n    self.assertEqual(sum(batch), 1)\n\n    # [2,3,4,5]\n    self.assertFalse(feed.done_feeding)\n    batch = feed.next_batch(4)\n    self.assertEqual(len(batch), 4)\n    self.assertEqual(sum(batch), 14)\n\n    # [6,7,8,9]\n    self.assertFalse(feed.done_feeding)\n    batch = feed.next_batch(10)           # ask for more than available\n    self.assertEqual(len(batch), 4)\n    self.assertEqual(sum(batch), 30)\n\n    # should be done\n    self.assertTrue(feed.should_stop())\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_TFSparkNode.py,0,"b'import argparse\n\nimport os\nimport random\nimport unittest\nfrom tensorflowonspark import gpu_info, reservation, TFSparkNode\nfrom unittest.mock import patch\n\n\nclass TFSparkNodeTest(unittest.TestCase):\n  def setUp(self):\n    self.server = reservation.Server(1)\n    self.server_addr = self.server.start()\n\n    self.parser = argparse.ArgumentParser()\n\n    self.default_fn = lambda args, ctx: print(""{}:{} args: {}"".format(ctx.job_name, ctx.task_index, args))\n    self.job_name = \'chief\'\n    self.task_index = 0\n    self.cluster_meta = {\n      \'id\': random.getrandbits(64),\n      \'cluster_template\': {self.job_name: [0]},\n      \'num_executors\': 1,\n      \'default_fs\': \'file://\',\n      \'working_dir\': \'.\',\n      \'server_addr\': self.server_addr\n    }\n    self.tensorboard = False\n    self.log_dir = None\n    self.queues = [\'input\']\n    self.background = False\n\n  def tearDown(self):\n    client = reservation.Client(self.server_addr)\n    client.request_stop()\n    client.close()\n\n  def test_run(self):\n    """"""Minimal function w/ args and ctx""""""\n    def fn(args, ctx):\n      print(""{}:{} args: {}"".format(ctx.job_name, ctx.task_index, args))\n      self.assertEqual(ctx.job_name, self.job_name)\n      self.assertEqual(ctx.task_index, 0)\n\n    tf_args = self.parser.parse_args([])\n    map_fn = TFSparkNode.run(fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n\n  def test_gpu_unavailable(self):\n    """"""Request GPU with no GPUs available, expecting an exception""""""\n    self.parser.add_argument(""--num_gpus"", help=""number of gpus to use"", type=int)\n    tf_args = self.parser.parse_args([""--num_gpus"", ""1""])\n\n    with self.assertRaises(Exception):\n      map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n      map_fn([0])\n\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_available(self, mock_available, mock_get_gpus):\n    """"""Request available GPU""""""\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n\n    self.parser.add_argument(""--num_gpus"", help=""number of gpus to use"", type=int)\n    tf_args = self.parser.parse_args([""--num_gpus"", ""1""])\n\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n    self.assertEqual(os.environ[\'CUDA_VISIBLE_DEVICES\'], \'0\')\n\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_default(self, mock_available, mock_get_gpus):\n    """"""Default to one GPU if not explicitly requested""""""\n\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n\n    tf_args = self.parser.parse_args([])\n\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n    self.assertEqual(os.environ[\'CUDA_VISIBLE_DEVICES\'], \'0\')\n    mock_get_gpus.assert_called_with(1, 0, format=gpu_info.AS_LIST)\n\n  @patch(\'tensorflowonspark.TFSparkNode._get_cluster_spec\')\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_cluster_spec(self, mock_available, mock_get_gpus, mock_get_spec):\n    """"""Request GPU when multiple TF nodes land on same executor""""""\n\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n    mock_get_spec.return_value = {\'chief\': [\'1.1.1.1:2222\'], \'worker\': [\'1.1.1.1:2223\', \'1.1.1.1:2224\', \'2.2.2.2:2222\']}\n\n    self.cluster_meta[\'cluster_template\'] = {\'chief\': [0], \'worker\': [1, 2, 3]}\n    self.parser.add_argument(""--num_gpus"", help=""number of gpus to use"", type=int)\n    tf_args = self.parser.parse_args([""--num_gpus"", ""1""])\n    print(""tf_args:"", tf_args)\n\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([2])     # worker:1\n    mock_get_gpus.assert_called_with(1, 2, format=gpu_info.AS_LIST)\n\n  @patch(\'pyspark.TaskContext\')\n  @patch(\'tensorflowonspark.TFSparkNode._has_spark_resource_api\')\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_spark_available(self, mock_available, mock_get_gpus, mock_spark_resources, mock_context):\n    """"""Spark resource API w/ available GPU""""""\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n    mock_spark_resources.return_value = True\n    mock_context_instance = mock_context.return_value\n    mock_context_instance.resources.return_value = {\'gpu\': type(""ResourceInformation"", (object,), {""addresses"": [\'0\']})}\n\n    tf_args = self.parser.parse_args([])\n    print(""tf_args:"", tf_args)\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n\n    self.assertEqual(os.environ[\'CUDA_VISIBLE_DEVICES\'], \'0\')\n    mock_get_gpus.assert_not_called()\n\n  @patch(\'pyspark.TaskContext\')\n  @patch(\'tensorflowonspark.TFSparkNode._has_spark_resource_api\')\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_spark_fallback(self, mock_available, mock_get_gpus, mock_spark_resources, mock_context):\n    """"""Spark resource API w/ no available GPU with fallback to original resource allocation""""""\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n    mock_spark_resources.return_value = True\n    mock_context_instance = mock_context.return_value\n    mock_context_instance.resources.return_value = {}\n\n    tf_args = self.parser.parse_args([])\n    print(""tf_args:"", tf_args)\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n\n    self.assertEqual(os.environ[\'CUDA_VISIBLE_DEVICES\'], \'0\')\n    mock_get_gpus.assert_called_with(1, 0, format=gpu_info.AS_LIST)\n\n  @patch.dict(os.environ, {\'SPARK_EXECUTOR_POD_IP\': \'1.2.3.4\'})\n  @patch(\'pyspark.TaskContext\')\n  @patch(\'tensorflowonspark.TFSparkNode._has_spark_resource_api\')\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_spark_unavailable_default(self, mock_available, mock_get_gpus, mock_spark_resources, mock_context):\n    """"""Spark resource API w/ no available GPU and no fallback (in K8s)""""""\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n    mock_spark_resources.return_value = True\n    mock_context_instance = mock_context.return_value\n    mock_context_instance.resources.return_value = {}\n\n    tf_args = self.parser.parse_args([])\n    print(""tf_args:"", tf_args)\n\n    map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n    map_fn([0])\n\n    self.assertEqual(os.environ[\'CUDA_VISIBLE_DEVICES\'], \'\')\n    mock_get_gpus.assert_not_called()\n\n  @patch.dict(os.environ, {\'SPARK_EXECUTOR_POD_IP\': \'1.2.3.4\'})\n  @patch(\'pyspark.TaskContext\')\n  @patch(\'tensorflowonspark.TFSparkNode._has_spark_resource_api\')\n  @patch(\'tensorflowonspark.gpu_info.get_gpus\')\n  @patch(\'tensorflowonspark.gpu_info.is_gpu_available\')\n  def test_gpu_spark_unavailable_but_requested(self, mock_available, mock_get_gpus, mock_spark_resources, mock_context):\n    """"""Spark resource API w/ no available GPU and no fallback (in K8s) with num_gpus set""""""\n    mock_available.return_value = True\n    mock_get_gpus.return_value = [\'0\']\n    mock_spark_resources.return_value = True\n    mock_context_instance = mock_context.return_value\n    mock_context_instance.resources.return_value = {}\n\n    self.parser.add_argument(""--num_gpus"", help=""number of gpus to use"", type=int)\n    tf_args = self.parser.parse_args([""--num_gpus"", ""1""])\n    print(""tf_args:"", tf_args)\n\n    with self.assertRaises(Exception):\n      map_fn = TFSparkNode.run(self.default_fn, tf_args, self.cluster_meta, self.tensorboard, self.log_dir, self.queues, self.background)\n      map_fn([0])\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_dfutil.py,0,"b'import os\nimport shutil\nimport test\nimport unittest\n\nfrom tensorflowonspark import dfutil\n\n\nclass DFUtilTest(test.SparkTest):\n  @classmethod\n  def setUpClass(cls):\n    super(DFUtilTest, cls).setUpClass()\n\n    # define model_dir and export_dir for tests\n    cls.tfrecord_dir = os.getcwd() + os.sep + ""test_tfr""\n\n  @classmethod\n  def tearDownClass(cls):\n    super(DFUtilTest, cls).tearDownClass()\n\n  def setUp(self):\n    super(DFUtilTest, self).setUp()\n    # remove any prior test artifacts\n    shutil.rmtree(self.tfrecord_dir, ignore_errors=True)\n\n  def tearDown(self):\n    # Note: don\'t clean up artifacts after test (in case we need to view/debug)\n    pass\n\n  def test_dfutils(self):\n    # create a DataFrame of a single row consisting of standard types (str, int, int_array, float, float_array, binary)\n    row1 = (\'text string\', 1, [2, 3, 4, 5], -1.1, [-2.2, -3.3, -4.4, -5.5], bytearray(b\'\\xff\\xfe\\xfd\\xfc\'))\n    rdd = self.sc.parallelize([row1])\n    df1 = self.spark.createDataFrame(rdd, [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\'])\n    print(""schema: {}"".format(df1.schema))\n\n    # save the DataFrame as TFRecords\n    dfutil.saveAsTFRecords(df1, self.tfrecord_dir)\n    self.assertTrue(os.path.isdir(self.tfrecord_dir))\n\n    # reload the DataFrame from exported TFRecords\n    df2 = dfutil.loadTFRecords(self.sc, self.tfrecord_dir, binary_features=[\'f\'])\n    row2 = df2.take(1)[0]\n\n    print(""row_saved: {}"".format(row1))\n    print(""row_loaded: {}"".format(row2))\n\n    # confirm loaded values match original/saved values\n    self.assertEqual(row1[0], row2[\'a\'])\n    self.assertEqual(row1[1], row2[\'b\'])\n    self.assertEqual(row1[2], row2[\'c\'])\n    self.assertAlmostEqual(row1[3], row2[\'d\'], 6)\n    for i in range(len(row1[4])):\n      self.assertAlmostEqual(row1[4][i], row2[\'e\'][i], 6)\n    print(""type(f): {}"".format(type(row2[\'f\'])))\n    for i in range(len(row1[5])):\n      self.assertEqual(row1[5][i], row2[\'f\'][i])\n\n    # check origin of each DataFrame\n    self.assertFalse(dfutil.isLoadedDF(df1))\n    self.assertTrue(dfutil.isLoadedDF(df2))\n\n    # references are equivalent\n    df_ref = df2\n    self.assertTrue(dfutil.isLoadedDF(df_ref))\n\n    # mutated DFs are not equal, even if contents are identical\n    df3 = df2.filter(df2.a == \'string_label\')\n    self.assertFalse(dfutil.isLoadedDF(df3))\n\n    # re-used/re-assigned variables are not equal\n    df2 = df3\n    self.assertFalse(dfutil.isLoadedDF(df2))\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_pipeline.py,23,"b'import numpy as np\nimport os\nimport shutil\nimport test\nimport unittest\n\nfrom tensorflowonspark import compat\nfrom tensorflowonspark.pipeline import HasBatchSize, HasSteps, Namespace, TFEstimator, TFParams\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\n\n\nclass PipelineTest(test.SparkTest):\n  @classmethod\n  def setUpClass(cls):\n    super(PipelineTest, cls).setUpClass()\n\n    # create an artificial training dataset of two features with labels computed from known weights\n    np.random.seed(1234)\n    cls.features = np.random.rand(1000, 2)\n    cls.weights = np.array([3.14, 1.618])\n    cls.labels = np.matmul(cls.features, cls.weights)\n    # convert to Python types for use with Spark DataFrames\n    cls.train_examples = [(cls.features[i].tolist(), [cls.labels[i].item()]) for i in range(1000)]\n    # create a simple test dataset\n    cls.test_examples = [([1.0, 1.0], [0.0])]\n\n    # define model_dir and export_dir for tests\n    cls.model_dir = os.getcwd() + os.sep + ""test_model""\n    cls.export_dir = os.getcwd() + os.sep + ""test_export""\n    cls.tfrecord_dir = os.getcwd() + os.sep + ""test_tfr""\n\n  @classmethod\n  def tearDownClass(cls):\n    super(PipelineTest, cls).tearDownClass()\n\n  def setUp(self):\n    super(PipelineTest, self).setUp()\n    # remove any prior test artifacts\n    shutil.rmtree(self.model_dir, ignore_errors=True)\n    shutil.rmtree(self.export_dir, ignore_errors=True)\n    shutil.rmtree(self.tfrecord_dir, ignore_errors=True)\n\n  def tearDown(self):\n    # Note: don\'t clean up artifacts after test (in case we need to view/debug)\n    pass\n\n  def test_namespace(self):\n    """"""Namespace class initializers""""""\n    # from dictionary\n    d = {\'string\': \'foo\', \'integer\': 1, \'float\': 3.14, \'array\': [1, 2, 3], \'map\': {\'a\': 1, \'b\': 2}}\n    n1 = Namespace(d)\n    self.assertEqual(n1.string, \'foo\')\n    self.assertEqual(n1.integer, 1)\n    self.assertEqual(n1.float, 3.14)\n    self.assertEqual(n1.array, [1, 2, 3])\n    self.assertEqual(n1.map, {\'a\': 1, \'b\': 2})\n    self.assertTrue(\'string\' in n1)\n    self.assertFalse(\'extra\' in n1)\n\n    # from namespace\n    n2 = Namespace(n1)\n    self.assertEqual(n2.string, \'foo\')\n    self.assertEqual(n2.integer, 1)\n    self.assertEqual(n2.float, 3.14)\n    self.assertEqual(n2.array, [1, 2, 3])\n    self.assertEqual(n2.map, {\'a\': 1, \'b\': 2})\n    self.assertTrue(\'string\' in n2)\n    self.assertFalse(\'extra\' in n2)\n\n    # from argv list\n    argv = [""--foo"", ""1"", ""--bar"", ""test"", ""--baz"", ""3.14""]\n    n3 = Namespace(argv)\n    self.assertEqual(n3.argv, argv)\n\n  def test_TFParams(self):\n    """"""Merging namespace args w/ ML Params""""""\n    class Foo(TFParams, HasBatchSize, HasSteps):\n      def __init__(self, args):\n        super(Foo, self).__init__()\n        self.args = args\n\n    n = Namespace({\'a\': 1, \'b\': 2})\n    f = Foo(n).setBatchSize(10).setSteps(100)\n    combined_args = f.merge_args_params()\n    expected_args = Namespace({\'a\': 1, \'b\': 2, \'batch_size\': 10, \'steps\': 100})\n    self.assertEqual(combined_args, expected_args)\n\n  def test_spark_saved_model(self):\n    """"""InputMode.SPARK TFEstimator w/ explicit saved_model export for TFModel inferencing""""""\n\n    def _spark_train(args, ctx):\n      """"""Basic linear regression in a distributed TF cluster using InputMode.SPARK""""""\n      import tensorflow as tf\n      from tensorflowonspark import TFNode\n\n      tf.compat.v1.reset_default_graph()\n      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n      with strategy.scope():\n        model = Sequential()\n        model.add(Dense(1, activation=\'linear\', input_shape=[2]))\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.2), loss=\'mse\', metrics=[\'mse\'])\n        model.summary()\n\n      tf_feed = TFNode.DataFeed(ctx.mgr, input_mapping=args.input_mapping)\n\n      def rdd_generator():\n        while not tf_feed.should_stop():\n          batch = tf_feed.next_batch(1)\n          if len(batch[\'x\']) > 0:\n            features = batch[\'x\'][0]\n            label = batch[\'y_\'][0]\n            yield (features, label)\n          else:\n            return\n\n      ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([2]), tf.TensorShape([1])))\n      # disable auto-sharding since we\'re feeding from an RDD generator\n      options = tf.data.Options()\n      compat.disable_auto_shard(options)\n      ds = ds.with_options(options)\n      ds = ds.batch(args.batch_size)\n\n      # only train 90% of each epoch to account for uneven RDD partition sizes\n      steps_per_epoch = 1000 * 0.9 // (args.batch_size * ctx.num_workers)\n\n      tf.io.gfile.makedirs(args.model_dir)\n      filepath = args.model_dir + ""/weights-{epoch:04d}""\n      callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, load_weights_on_restart=True, save_weights_only=True)]\n\n      model.fit(ds, epochs=args.epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)\n\n      # This fails with: ""NotImplementedError: `fit_generator` is not supported for models compiled with tf.distribute.Strategy""\n      # model.fit_generator(ds, epochs=args.epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)\n\n      if args.export_dir:\n        print(""exporting model to: {}"".format(args.export_dir))\n        compat.export_saved_model(model, args.export_dir, ctx.job_name == \'chief\')\n\n      tf_feed.terminate()\n\n    # create a Spark DataFrame of training examples (features, labels)\n    rdd = self.sc.parallelize(self.train_examples, 2)\n    trainDF = rdd.toDF([\'col1\', \'col2\'])\n\n    # train and export model\n    args = {}\n    estimator = TFEstimator(_spark_train, args) \\\n                  .setInputMapping({\'col1\': \'x\', \'col2\': \'y_\'}) \\\n                  .setModelDir(self.model_dir) \\\n                  .setExportDir(self.export_dir) \\\n                  .setClusterSize(self.num_workers) \\\n                  .setMasterNode(""chief"") \\\n                  .setNumPS(0) \\\n                  .setBatchSize(1) \\\n                  .setEpochs(1)\n    model = estimator.fit(trainDF)\n    self.assertTrue(os.path.isdir(self.export_dir))\n\n    # create a Spark DataFrame of test examples (features, labels)\n    testDF = self.spark.createDataFrame(self.test_examples, [\'c1\', \'c2\'])\n\n    # test saved_model using exported signature\n    model.setTagSet(\'serve\') \\\n          .setSignatureDefKey(\'serving_default\') \\\n          .setInputMapping({\'c1\': \'dense_input\'}) \\\n          .setOutputMapping({\'dense\': \'cout\'})\n    preds = model.transform(testDF).head()                  # take first/only result\n    pred = preds.cout[0]                                    # unpack scalar from tensor\n    expected = np.sum(self.weights)\n    self.assertAlmostEqual(pred, expected, 2)\n\n#  def test_spark_sparse_tensor(self):\n#    """"""InputMode.SPARK feeding sparse tensors""""""\n#    def sparse_train(args, ctx):\n#        import tensorflow as tf\n#\n#        # reset graph in case we\'re re-using a Spark python worker (during tests)\n#        tf.compat.v1.reset_default_graph()\n#\n#        cluster, server = ctx.start_cluster_server(ctx)\n#        if ctx.job_name == ""ps"":\n#          server.join()\n#        elif ctx.job_name == ""worker"":\n#          with tf.device(tf.compat.v1.train.replica_device_setter(\n#            worker_device=""/job:worker/task:%d"" % ctx.task_index,\n#            cluster=cluster)):\n#            y_ = tf.compat.v1.placeholder(tf.float32, name=\'y_label\')\n#            label = tf.identity(y_, name=\'label\')\n#\n#            row_indices = tf.compat.v1.placeholder(tf.int64, name=\'x_row_indices\')\n#            col_indices = tf.compat.v1.placeholder(tf.int64, name=\'x_col_indices\')\n#            values = tf.compat.v1.placeholder(tf.float32, name=\'x_values\')\n#            indices = tf.stack([row_indices[0], col_indices[0]], axis=1)\n#            data = values[0]\n#\n#            x = tf.SparseTensor(indices=indices, values=data, dense_shape=[args.batch_size, 10])\n#            w = tf.Variable(tf.random.truncated_normal([10, 1]), name=\'w\')\n#            y = tf.sparse.sparse_dense_matmul(x, w, name=\'y\')\n#\n#            global_step = tf.compat.v1.train.get_or_create_global_step()\n#            cost = tf.reduce_mean(input_tensor=tf.square(y_ - y), name=\'cost\')\n#            optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.1).minimize(cost, global_step)\n#\n#          with tf.compat.v1.train.MonitoredTrainingSession(master=server.target,\n#                                                           is_chief=(ctx.task_index == 0),\n#                                                           checkpoint_dir=args.model_dir,\n#                                                           save_checkpoint_steps=20) as sess:\n#            tf_feed = ctx.get_data_feed(input_mapping=args.input_mapping)\n#            while not sess.should_stop() and not tf_feed.should_stop():\n#              batch = tf_feed.next_batch(args.batch_size)\n#              if len(batch) > 0:\n#                print(""batch: {}"".format(batch))\n#                feed = {y_: batch[\'y_label\'],\n#                        row_indices: batch[\'x_row_indices\'],\n#                        col_indices: batch[\'x_col_indices\'],\n#                        values: batch[\'x_values\']}\n#                _, pred, trained_weights = sess.run([optimizer, y, w], feed_dict=feed)\n#                print(""trained_weights: {}"".format(trained_weights))\n#            sess.close()\n#\n#          # wait for MonitoredTrainingSession to save last checkpoint\n#          time.sleep(10)\n#\n#    args = {}\n#    estimator = TFEstimator(sparse_train, args) \\\n#              .setInputMapping({\'labels\': \'y_label\', \'row_indices\': \'x_row_indices\', \'col_indices\': \'x_col_indices\', \'values\': \'x_values\'}) \\\n#              .setInputMode(TFCluster.InputMode.SPARK) \\\n#              .setModelDir(self.model_dir) \\\n#              .setClusterSize(self.num_workers) \\\n#              .setNumPS(1) \\\n#              .setBatchSize(1)\n#\n#    model_weights = np.array([[1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0]]).T\n#    examples = [scipy.sparse.random(1, 10, density=0.5,) for i in range(200)]\n#    rdd = self.sc.parallelize(examples).map(lambda e: ((e * model_weights).tolist()[0][0], e.row.tolist(), e.col.tolist(), e.data.tolist()))\n#    df = rdd.toDF([""labels"", ""row_indices"", ""col_indices"", ""values""])\n#    df.show(5)\n#    model = estimator.fit(df)\n#\n#    model.setOutputMapping({\'label\': \'label\', \'y/SparseTensorDenseMatMul\': \'predictions\'})\n#    test_examples = [scipy.sparse.random(1, 10, density=0.5,) for i in range(50)]\n#    test_rdd = self.sc.parallelize(test_examples).map(lambda e: ((e * model_weights).tolist()[0][0], e.row.tolist(), e.col.tolist(), e.data.tolist()))\n#    test_df = test_rdd.toDF([""labels"", ""row_indices"", ""col_indices"", ""values""])\n#    test_df.show(5)\n#    preds = model.transform(test_df)\n#    preds.show(5)\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
test/test_reservation.py,0,"b'import os\nimport threading\nimport time\nimport unittest\n\nfrom tensorflowonspark import util\nfrom tensorflowonspark.reservation import Reservations, Server, Client\nfrom unittest import mock\n\n\nclass ReservationTest(unittest.TestCase):\n  def test_reservation_class(self):\n    """"""Test core reservation class, expecting 2 reservations""""""\n    r = Reservations(2)\n    self.assertFalse(r.done())\n\n    # add first reservation\n    r.add({\'node\': 1})\n    self.assertFalse(r.done())\n    self.assertEqual(r.remaining(), 1)\n\n    # add second reservation\n    r.add({\'node\': 2})\n    self.assertTrue(r.done())\n    self.assertEqual(r.remaining(), 0)\n\n    # get final list\n    reservations = r.get()\n    self.assertEqual(len(reservations), 2)\n\n  def test_reservation_server(self):\n    """"""Test reservation server, expecting 1 reservation""""""\n    s = Server(1)\n    addr = s.start()\n\n    # add first reservation\n    c = Client(addr)\n    resp = c.register({\'node\': 1})\n    self.assertEqual(resp, \'OK\')\n\n    # get list of reservations\n    reservations = c.get_reservations()\n    self.assertEqual(len(reservations), 1)\n\n    # should return immediately with list of reservations\n    reservations = c.await_reservations()\n    self.assertEqual(len(reservations), 1)\n\n    # request server stop\n    c.request_stop()\n    time.sleep(1)\n    self.assertEqual(s.done, True)\n\n  def test_reservation_environment_exists_get_server_ip_return_environment_value(self):\n      tfos_server = Server(5)\n      with mock.patch.dict(os.environ, {\'TFOS_SERVER_HOST\': \'my_host_ip\'}):\n        assert tfos_server.get_server_ip() == ""my_host_ip""\n\n  def test_reservation_environment_not_exists_get_server_ip_return_actual_host_ip(self):\n    tfos_server = Server(5)\n    assert tfos_server.get_server_ip() == util.get_ip_address()\n\n  def test_reservation_environment_exists_start_listening_socket_return_socket_listening_to_environment_port_value(self):\n    tfos_server = Server(1)\n    with mock.patch.dict(os.environ, {\'TFOS_SERVER_PORT\': \'9999\'}):\n      assert tfos_server.start_listening_socket().getsockname()[1] == 9999\n\n  def test_reservation_environment_not_exists_start_listening_socket_return_socket(self):\n    tfos_server = Server(1)\n    print(tfos_server.start_listening_socket().getsockname()[1])\n    assert type(tfos_server.start_listening_socket().getsockname()[1]) == int\n\n  def test_reservation_environment_exists_port_spec(self):\n    tfos_server = Server(1)\n    with mock.patch.dict(os.environ, {\'TFOS_SERVER_PORT\': \'9999\'}):\n      self.assertEqual(tfos_server.get_server_ports(), [9999])\n\n    with mock.patch.dict(os.environ, {\'TFOS_SERVER_PORT\': \'9997-9999\'}):\n      self.assertEqual(tfos_server.get_server_ports(), [9997, 9998, 9999])\n\n  def test_reservation_environment_exists_start_listening_socket_return_socket_listening_to_environment_port_range(self):\n    tfos_server1 = Server(1)\n    tfos_server2 = Server(1)\n    tfos_server3 = Server(1)\n    with mock.patch.dict(os.environ, {\'TFOS_SERVER_PORT\': \'9998-9999\'}):\n      s1 = tfos_server1.start_listening_socket()\n      self.assertEqual(s1.getsockname()[1], 9998)\n      s2 = tfos_server2.start_listening_socket()\n      self.assertEqual(s2.getsockname()[1], 9999)\n      with self.assertRaises(Exception):\n        tfos_server3.start_listening_socket()\n    tfos_server1.stop()\n    tfos_server2.stop()\n\n  def test_reservation_server_multi(self):\n    """"""Test reservation server, expecting multiple reservations""""""\n    num_clients = 4\n    s = Server(num_clients)\n    addr = s.start()\n\n    def reserve(num):\n      c = Client(addr)\n      # time.sleep(random.randint(0,5))     # simulate varying start times\n      resp = c.register({\'node\': num})\n      self.assertEqual(resp, \'OK\')\n      c.await_reservations()\n      c.close()\n\n    # start/register clients\n    threads = [None] * num_clients\n    for i in range(num_clients):\n      threads[i] = threading.Thread(target=reserve, args=(i,))\n      threads[i].start()\n\n    # wait for clients to complete\n    for i in range(num_clients):\n      threads[i].join()\n    print(""all done"")\n\n    # get list of reservations\n    c = Client(addr)\n    reservations = c.get_reservations()\n    self.assertEqual(len(reservations), num_clients)\n\n    # request server stop\n    c.request_stop()\n    time.sleep(1)\n    self.assertEqual(s.done, True)\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sphinx_rtd_theme\nimport sys\n\n_pysrc = os.path.abspath(os.path.join(os.path.abspath(__file__), \'..\', \'..\', \'..\'))\nsys.path.insert(0, _pysrc)\n\nautodoc_mock_imports = [""pyspark"", ""tensorflow""]\n\n# -- Project information -----------------------------------------------------\n\nproject = \'TensorFlowOnSpark\'\ncopyright = \'2020, Yahoo Inc / Verizon Media\'\nauthor = \'Yahoo Inc\'\n\n# The short X.Y version\nversion = \'2.2.1\'\n# The full version, including alpha/beta/rc tags\nrelease = \'2.2.1\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'sphinx_rtd_theme\'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = \'en\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#\nadd_module_names = False\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'TensorFlowOnSparkdoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'TensorFlowOnSpark.tex\', \'TensorFlowOnSpark Documentation\',\n     \'Lee Yang\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tensorflowonspark\', \'TensorFlowOnSpark Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'TensorFlowOnSpark\', \'TensorFlowOnSpark Documentation\',\n     author, \'TensorFlowOnSpark\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Extension configuration -------------------------------------------------\n'"
examples/mnist/mnist_data_setup.py,4,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nif __name__ == ""__main__"":\n  import argparse\n\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  import tensorflow as tf\n  import tensorflow_datasets as tfds\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--num_partitions"", help=""Number of output partitions"", type=int, default=10)\n  parser.add_argument(""--output"", help=""HDFS directory to save examples in parallelized format"", default=""data/mnist"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_data_setup""))\n\n  mnist, info = tfds.load(\'mnist\', with_info=True)\n  print(info.as_json)\n\n  # convert to numpy, then RDDs\n  mnist_train = tfds.as_numpy(mnist[\'train\'])\n  mnist_test = tfds.as_numpy(mnist[\'test\'])\n\n  train_rdd = sc.parallelize(mnist_train, args.num_partitions).cache()\n  test_rdd = sc.parallelize(mnist_test, args.num_partitions).cache()\n\n  # save as CSV (label,comma-separated-features)\n  def to_csv(example):\n    return str(example[\'label\']) + \',\' + \',\'.join([str(i) for i in example[\'image\'].reshape(784)])\n\n  train_rdd.map(to_csv).saveAsTextFile(args.output + ""/csv/train"")\n  test_rdd.map(to_csv).saveAsTextFile(args.output + ""/csv/test"")\n\n  # save as TFRecords (numpy vs. PNG)\n  # note: the MNIST tensorflow_dataset is already provided as TFRecords but with a PNG bytes_list\n  # this export format is less-efficient, but easier to work with later\n  def to_tfr(example):\n    ex = tf.train.Example(\n      features=tf.train.Features(\n        feature={\n          \'label\': tf.train.Feature(int64_list=tf.train.Int64List(value=[example[\'label\'].astype(""int64"")])),\n          \'image\': tf.train.Feature(int64_list=tf.train.Int64List(value=example[\'image\'].reshape(784).astype(""int64"")))\n        }\n      )\n    )\n    return (bytearray(ex.SerializeToString()), None)\n\n  train_rdd.map(to_tfr).saveAsNewAPIHadoopFile(args.output + ""/tfr/train"",\n                                               ""org.tensorflow.hadoop.io.TFRecordFileOutputFormat"",\n                                               keyClass=""org.apache.hadoop.io.BytesWritable"",\n                                               valueClass=""org.apache.hadoop.io.NullWritable"")\n  test_rdd.map(to_tfr).saveAsNewAPIHadoopFile(args.output + ""/tfr/test"",\n                                               ""org.tensorflow.hadoop.io.TFRecordFileOutputFormat"",\n                                               keyClass=""org.apache.hadoop.io.BytesWritable"",\n                                               valueClass=""org.apache.hadoop.io.NullWritable"")\n'"
examples/resnet/__init__.py,0,b''
examples/resnet/resnet_cifar_dist.py,9,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Runs a ResNet model on the Cifar-10 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# from absl import app\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nimport tensorflow as tf\nfrom official.benchmark.models import cifar_preprocessing\nfrom official.benchmark.models import resnet_cifar_model\nfrom official.benchmark.models import synthetic_util\nfrom official.utils.flags import core as flags_core\nfrom official.utils.misc import distribution_utils\nfrom official.utils.misc import keras_utils\nfrom official.vision.image_classification.resnet import common\n\n\nLR_SCHEDULE = [  # (multiplier, epoch to start) tuples\n    (0.1, 91), (0.01, 136), (0.001, 182)\n]\n\n\ndef learning_rate_schedule(current_epoch,\n                           current_batch,\n                           batches_per_epoch,\n                           batch_size):\n  """"""Handles linear scaling rule and LR decay.\n\n  Scale learning rate at epoch boundaries provided in LR_SCHEDULE by the\n  provided scaling factor.\n\n  Args:\n    current_epoch: integer, current epoch indexed from 0.\n    current_batch: integer, current batch in the current epoch, indexed from 0.\n    batches_per_epoch: integer, number of steps in an epoch.\n    batch_size: integer, total batch sized.\n\n  Returns:\n    Adjusted learning rate.\n  """"""\n  del current_batch, batches_per_epoch  # not used\n  initial_learning_rate = common.BASE_LEARNING_RATE * batch_size / 128\n  learning_rate = initial_learning_rate\n  for mult, start_epoch in LR_SCHEDULE:\n    if current_epoch >= start_epoch:\n      learning_rate = initial_learning_rate * mult\n    else:\n      break\n  return learning_rate\n\n\nclass LearningRateBatchScheduler(tf.keras.callbacks.Callback):\n  """"""Callback to update learning rate on every batch (not epoch boundaries).\n\n  N.B. Only support Keras optimizers, not TF optimizers.\n\n  Attributes:\n      schedule: a function that takes an epoch index and a batch index as input\n          (both integer, indexed from 0) and returns a new learning rate as\n          output (float).\n  """"""\n\n  def __init__(self, schedule, batch_size, steps_per_epoch):\n    super(LearningRateBatchScheduler, self).__init__()\n    self.schedule = schedule\n    self.steps_per_epoch = steps_per_epoch\n    self.batch_size = batch_size\n    self.epochs = -1\n    self.prev_lr = -1\n\n  def on_epoch_begin(self, epoch, logs=None):\n    if not hasattr(self.model.optimizer, \'learning_rate\'):\n      raise ValueError(\'Optimizer must have a ""learning_rate"" attribute.\')\n    self.epochs += 1\n\n  def on_batch_begin(self, batch, logs=None):\n    """"""Executes before step begins.""""""\n    lr = self.schedule(self.epochs,\n                       batch,\n                       self.steps_per_epoch,\n                       self.batch_size)\n    if not isinstance(lr, (float, np.float32, np.float64)):\n      raise ValueError(\'The output of the ""schedule"" function should be float.\')\n    if lr != self.prev_lr:\n      self.model.optimizer.learning_rate = lr  # lr should be a float here\n      self.prev_lr = lr\n      logging.debug(\n          \'Epoch %05d Batch %05d: LearningRateBatchScheduler \'\n          \'change learning rate to %s.\', self.epochs, batch, lr)\n\n\ndef run(flags_obj):\n  """"""Run ResNet Cifar-10 training and eval loop using native Keras APIs.\n\n  Args:\n    flags_obj: An object containing parsed flag values.\n\n  Raises:\n    ValueError: If fp16 is passed as it is not currently supported.\n\n  Returns:\n    Dictionary of training and eval stats.\n  """"""\n  keras_utils.set_session_config(\n      enable_xla=flags_obj.enable_xla)\n\n  # Execute flag override logic for better model performance\n  if flags_obj.tf_gpu_thread_mode:\n    keras_utils.set_gpu_thread_mode_and_count(\n        per_gpu_thread_count=flags_obj.per_gpu_thread_count,\n        gpu_thread_mode=flags_obj.tf_gpu_thread_mode,\n        num_gpus=flags_obj.num_gpus,\n        datasets_num_private_threads=flags_obj.datasets_num_private_threads)\n  common.set_cudnn_batchnorm_mode()\n\n  dtype = flags_core.get_tf_dtype(flags_obj)\n  if dtype == \'fp16\':\n    raise ValueError(\'dtype fp16 is not supported in Keras. Use the default \'\n                     \'value(fp32).\')\n\n  data_format = flags_obj.data_format\n  if data_format is None:\n    data_format = (\'channels_first\' if tf.config.list_physical_devices(\'GPU\')\n                   else \'channels_last\')\n  tf.keras.backend.set_image_data_format(data_format)\n\n  strategy = distribution_utils.get_distribution_strategy(\n      distribution_strategy=flags_obj.distribution_strategy,\n      num_gpus=flags_obj.num_gpus,\n      all_reduce_alg=flags_obj.all_reduce_alg,\n      num_packs=flags_obj.num_packs)\n\n  if strategy:\n    # flags_obj.enable_get_next_as_optional controls whether enabling\n    # get_next_as_optional behavior in DistributedIterator. If true, last\n    # partial batch can be supported.\n    strategy.extended.experimental_enable_get_next_as_optional = (\n        flags_obj.enable_get_next_as_optional\n    )\n\n  strategy_scope = distribution_utils.get_strategy_scope(strategy)\n\n  if flags_obj.use_synthetic_data:\n    synthetic_util.set_up_synthetic_data()\n    input_fn = common.get_synth_input_fn(\n        height=cifar_preprocessing.HEIGHT,\n        width=cifar_preprocessing.WIDTH,\n        num_channels=cifar_preprocessing.NUM_CHANNELS,\n        num_classes=cifar_preprocessing.NUM_CLASSES,\n        dtype=flags_core.get_tf_dtype(flags_obj),\n        drop_remainder=True)\n  else:\n    synthetic_util.undo_set_up_synthetic_data()\n    input_fn = cifar_preprocessing.input_fn\n\n  train_input_dataset = input_fn(\n      is_training=True,\n      data_dir=flags_obj.data_dir,\n      batch_size=flags_obj.batch_size,\n      parse_record_fn=cifar_preprocessing.parse_record,\n      datasets_num_private_threads=flags_obj.datasets_num_private_threads,\n      dtype=dtype,\n      # Setting drop_remainder to avoid the partial batch logic in normalization\n      # layer, which triggers tf.where and leads to extra memory copy of input\n      # sizes between host and GPU.\n      drop_remainder=(not flags_obj.enable_get_next_as_optional))\n\n  eval_input_dataset = None\n  if not flags_obj.skip_eval:\n    eval_input_dataset = input_fn(\n        is_training=False,\n        data_dir=flags_obj.data_dir,\n        batch_size=flags_obj.batch_size,\n        parse_record_fn=cifar_preprocessing.parse_record)\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n    eval_input_dataset = eval_input_dataset.with_options(options)\n\n  steps_per_epoch = (\n      cifar_preprocessing.NUM_IMAGES[\'train\'] // flags_obj.batch_size)\n  lr_schedule = 0.1\n  if flags_obj.use_tensor_lr:\n    initial_learning_rate = common.BASE_LEARNING_RATE * flags_obj.batch_size / 128\n    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n        boundaries=list(p[1] * steps_per_epoch for p in LR_SCHEDULE),\n        values=[initial_learning_rate] +\n        list(p[0] * initial_learning_rate for p in LR_SCHEDULE))\n\n  with strategy_scope:\n    optimizer = common.get_optimizer(lr_schedule)\n    model = resnet_cifar_model.resnet56(classes=cifar_preprocessing.NUM_CLASSES)\n    model.compile(\n        loss=\'sparse_categorical_crossentropy\',\n        optimizer=optimizer,\n        metrics=([\'sparse_categorical_accuracy\']\n                 if flags_obj.report_accuracy_metrics else None),\n        run_eagerly=flags_obj.run_eagerly)\n\n  train_epochs = flags_obj.train_epochs\n\n  callbacks = common.get_callbacks()\n\n  if not flags_obj.use_tensor_lr:\n    lr_callback = LearningRateBatchScheduler(\n        schedule=learning_rate_schedule,\n        batch_size=flags_obj.batch_size,\n        steps_per_epoch=steps_per_epoch)\n    callbacks.append(lr_callback)\n\n  # if mutliple epochs, ignore the train_steps flag.\n  if train_epochs <= 1 and flags_obj.train_steps:\n    steps_per_epoch = min(flags_obj.train_steps, steps_per_epoch)\n    train_epochs = 1\n\n  num_eval_steps = (cifar_preprocessing.NUM_IMAGES[\'validation\'] //\n                    flags_obj.batch_size)\n\n  validation_data = eval_input_dataset\n  if flags_obj.skip_eval:\n    if flags_obj.set_learning_phase_to_train:\n      # TODO(haoyuzhang): Understand slowdown of setting learning phase when\n      # not using distribution strategy.\n      tf.keras.backend.set_learning_phase(1)\n    num_eval_steps = None\n    validation_data = None\n\n  if not strategy and flags_obj.explicit_gpu_placement:\n    # TODO(b/135607227): Add device scope automatically in Keras training loop\n    # when not using distribition strategy.\n    no_dist_strat_device = tf.device(\'/device:GPU:0\')\n    no_dist_strat_device.__enter__()\n\n  history = model.fit(train_input_dataset,\n                      epochs=train_epochs,\n                      steps_per_epoch=steps_per_epoch,\n                      callbacks=callbacks,\n                      validation_steps=num_eval_steps,\n                      validation_data=validation_data,\n                      validation_freq=flags_obj.epochs_between_evals,\n                      verbose=2)\n  eval_output = None\n  if not flags_obj.skip_eval:\n    eval_output = model.evaluate(eval_input_dataset,\n                                 steps=num_eval_steps,\n                                 verbose=2)\n\n  if not strategy and flags_obj.explicit_gpu_placement:\n    no_dist_strat_device.__exit__()\n\n  stats = common.build_stats(history, eval_output, callbacks)\n  return stats\n\n\ndef define_cifar_flags():\n  common.define_keras_flags(dynamic_loss_scale=False)\n\n  flags_core.set_defaults(data_dir=\'/tmp/cifar10_data/cifar-10-batches-bin\',\n                          model_dir=\'/tmp/cifar10_model\',\n                          epochs_between_evals=10,\n                          batch_size=128)\n\n\ndef main_fun(argv, ctx):\n  logging.set_verbosity(logging.INFO)\n  define_cifar_flags()\n  flags.FLAGS(argv)\n  print(flags.FLAGS.flag_values_dict())\n  return run(flags.FLAGS)\n'"
examples/resnet/resnet_cifar_main.py,9,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Runs a ResNet model on the Cifar-10 dataset.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport numpy as np\nimport tensorflow as tf\nfrom official.benchmark.models import cifar_preprocessing\nfrom official.benchmark.models import resnet_cifar_model\nfrom official.benchmark.models import synthetic_util\nfrom official.utils.flags import core as flags_core\nfrom official.utils.misc import distribution_utils\nfrom official.utils.misc import keras_utils\nfrom official.vision.image_classification.resnet import common\n\n\nLR_SCHEDULE = [  # (multiplier, epoch to start) tuples\n    (0.1, 91), (0.01, 136), (0.001, 182)\n]\n\n\ndef learning_rate_schedule(current_epoch,\n                           current_batch,\n                           batches_per_epoch,\n                           batch_size):\n  """"""Handles linear scaling rule and LR decay.\n\n  Scale learning rate at epoch boundaries provided in LR_SCHEDULE by the\n  provided scaling factor.\n\n  Args:\n    current_epoch: integer, current epoch indexed from 0.\n    current_batch: integer, current batch in the current epoch, indexed from 0.\n    batches_per_epoch: integer, number of steps in an epoch.\n    batch_size: integer, total batch sized.\n\n  Returns:\n    Adjusted learning rate.\n  """"""\n  del current_batch, batches_per_epoch  # not used\n  initial_learning_rate = common.BASE_LEARNING_RATE * batch_size / 128\n  learning_rate = initial_learning_rate\n  for mult, start_epoch in LR_SCHEDULE:\n    if current_epoch >= start_epoch:\n      learning_rate = initial_learning_rate * mult\n    else:\n      break\n  return learning_rate\n\n\nclass LearningRateBatchScheduler(tf.keras.callbacks.Callback):\n  """"""Callback to update learning rate on every batch (not epoch boundaries).\n\n  N.B. Only support Keras optimizers, not TF optimizers.\n\n  Attributes:\n      schedule: a function that takes an epoch index and a batch index as input\n          (both integer, indexed from 0) and returns a new learning rate as\n          output (float).\n  """"""\n\n  def __init__(self, schedule, batch_size, steps_per_epoch):\n    super(LearningRateBatchScheduler, self).__init__()\n    self.schedule = schedule\n    self.steps_per_epoch = steps_per_epoch\n    self.batch_size = batch_size\n    self.epochs = -1\n    self.prev_lr = -1\n\n  def on_epoch_begin(self, epoch, logs=None):\n    if not hasattr(self.model.optimizer, \'learning_rate\'):\n      raise ValueError(\'Optimizer must have a ""learning_rate"" attribute.\')\n    self.epochs += 1\n\n  def on_batch_begin(self, batch, logs=None):\n    """"""Executes before step begins.""""""\n    lr = self.schedule(self.epochs,\n                       batch,\n                       self.steps_per_epoch,\n                       self.batch_size)\n    if not isinstance(lr, (float, np.float32, np.float64)):\n      raise ValueError(\'The output of the ""schedule"" function should be float.\')\n    if lr != self.prev_lr:\n      self.model.optimizer.learning_rate = lr  # lr should be a float here\n      self.prev_lr = lr\n      logging.debug(\n          \'Epoch %05d Batch %05d: LearningRateBatchScheduler \'\n          \'change learning rate to %s.\', self.epochs, batch, lr)\n\n\ndef run(flags_obj):\n  """"""Run ResNet Cifar-10 training and eval loop using native Keras APIs.\n\n  Args:\n    flags_obj: An object containing parsed flag values.\n\n  Raises:\n    ValueError: If fp16 is passed as it is not currently supported.\n\n  Returns:\n    Dictionary of training and eval stats.\n  """"""\n  keras_utils.set_session_config(\n      enable_xla=flags_obj.enable_xla)\n\n  # Execute flag override logic for better model performance\n  if flags_obj.tf_gpu_thread_mode:\n    keras_utils.set_gpu_thread_mode_and_count(\n        per_gpu_thread_count=flags_obj.per_gpu_thread_count,\n        gpu_thread_mode=flags_obj.tf_gpu_thread_mode,\n        num_gpus=flags_obj.num_gpus,\n        datasets_num_private_threads=flags_obj.datasets_num_private_threads)\n  common.set_cudnn_batchnorm_mode()\n\n  dtype = flags_core.get_tf_dtype(flags_obj)\n  if dtype == \'fp16\':\n    raise ValueError(\'dtype fp16 is not supported in Keras. Use the default \'\n                     \'value(fp32).\')\n\n  data_format = flags_obj.data_format\n  if data_format is None:\n    data_format = (\'channels_first\' if tf.config.list_physical_devices(\'GPU\')\n                   else \'channels_last\')\n  tf.keras.backend.set_image_data_format(data_format)\n\n  strategy = distribution_utils.get_distribution_strategy(\n      distribution_strategy=flags_obj.distribution_strategy,\n      num_gpus=flags_obj.num_gpus,\n      all_reduce_alg=flags_obj.all_reduce_alg,\n      num_packs=flags_obj.num_packs)\n\n  if strategy:\n    # flags_obj.enable_get_next_as_optional controls whether enabling\n    # get_next_as_optional behavior in DistributedIterator. If true, last\n    # partial batch can be supported.\n    strategy.extended.experimental_enable_get_next_as_optional = (\n        flags_obj.enable_get_next_as_optional\n    )\n\n  strategy_scope = distribution_utils.get_strategy_scope(strategy)\n\n  if flags_obj.use_synthetic_data:\n    synthetic_util.set_up_synthetic_data()\n    input_fn = common.get_synth_input_fn(\n        height=cifar_preprocessing.HEIGHT,\n        width=cifar_preprocessing.WIDTH,\n        num_channels=cifar_preprocessing.NUM_CHANNELS,\n        num_classes=cifar_preprocessing.NUM_CLASSES,\n        dtype=flags_core.get_tf_dtype(flags_obj),\n        drop_remainder=True)\n  else:\n    synthetic_util.undo_set_up_synthetic_data()\n    input_fn = cifar_preprocessing.input_fn\n\n  train_input_dataset = input_fn(\n      is_training=True,\n      data_dir=flags_obj.data_dir,\n      batch_size=flags_obj.batch_size,\n      parse_record_fn=cifar_preprocessing.parse_record,\n      datasets_num_private_threads=flags_obj.datasets_num_private_threads,\n      dtype=dtype,\n      # Setting drop_remainder to avoid the partial batch logic in normalization\n      # layer, which triggers tf.where and leads to extra memory copy of input\n      # sizes between host and GPU.\n      drop_remainder=(not flags_obj.enable_get_next_as_optional))\n\n  eval_input_dataset = None\n  if not flags_obj.skip_eval:\n    eval_input_dataset = input_fn(\n        is_training=False,\n        data_dir=flags_obj.data_dir,\n        batch_size=flags_obj.batch_size,\n        parse_record_fn=cifar_preprocessing.parse_record)\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n    eval_input_dataset = eval_input_dataset.with_options(options)\n\n  steps_per_epoch = (\n      cifar_preprocessing.NUM_IMAGES[\'train\'] // flags_obj.batch_size)\n  lr_schedule = 0.1\n  if flags_obj.use_tensor_lr:\n    initial_learning_rate = common.BASE_LEARNING_RATE * flags_obj.batch_size / 128\n    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n        boundaries=list(p[1] * steps_per_epoch for p in LR_SCHEDULE),\n        values=[initial_learning_rate] +\n        list(p[0] * initial_learning_rate for p in LR_SCHEDULE))\n\n  with strategy_scope:\n    optimizer = common.get_optimizer(lr_schedule)\n    model = resnet_cifar_model.resnet56(classes=cifar_preprocessing.NUM_CLASSES)\n    model.compile(\n        loss=\'sparse_categorical_crossentropy\',\n        optimizer=optimizer,\n        metrics=([\'sparse_categorical_accuracy\']\n                 if flags_obj.report_accuracy_metrics else None),\n        run_eagerly=flags_obj.run_eagerly)\n\n  train_epochs = flags_obj.train_epochs\n\n  callbacks = common.get_callbacks()\n\n  if not flags_obj.use_tensor_lr:\n    lr_callback = LearningRateBatchScheduler(\n        schedule=learning_rate_schedule,\n        batch_size=flags_obj.batch_size,\n        steps_per_epoch=steps_per_epoch)\n    callbacks.append(lr_callback)\n\n  # if mutliple epochs, ignore the train_steps flag.\n  if train_epochs <= 1 and flags_obj.train_steps:\n    steps_per_epoch = min(flags_obj.train_steps, steps_per_epoch)\n    train_epochs = 1\n\n  num_eval_steps = (cifar_preprocessing.NUM_IMAGES[\'validation\'] //\n                    flags_obj.batch_size)\n\n  validation_data = eval_input_dataset\n  if flags_obj.skip_eval:\n    if flags_obj.set_learning_phase_to_train:\n      # TODO(haoyuzhang): Understand slowdown of setting learning phase when\n      # not using distribution strategy.\n      tf.keras.backend.set_learning_phase(1)\n    num_eval_steps = None\n    validation_data = None\n\n  if not strategy and flags_obj.explicit_gpu_placement:\n    # TODO(b/135607227): Add device scope automatically in Keras training loop\n    # when not using distribition strategy.\n    no_dist_strat_device = tf.device(\'/device:GPU:0\')\n    no_dist_strat_device.__enter__()\n\n  history = model.fit(train_input_dataset,\n                      epochs=train_epochs,\n                      steps_per_epoch=steps_per_epoch,\n                      callbacks=callbacks,\n                      validation_steps=num_eval_steps,\n                      validation_data=validation_data,\n                      validation_freq=flags_obj.epochs_between_evals,\n                      verbose=2)\n  eval_output = None\n  if not flags_obj.skip_eval:\n    eval_output = model.evaluate(eval_input_dataset,\n                                 steps=num_eval_steps,\n                                 verbose=2)\n\n  if not strategy and flags_obj.explicit_gpu_placement:\n    no_dist_strat_device.__exit__()\n\n  stats = common.build_stats(history, eval_output, callbacks)\n  return stats\n\n\ndef define_cifar_flags():\n  common.define_keras_flags(dynamic_loss_scale=False)\n\n  flags_core.set_defaults(data_dir=\'/tmp/cifar10_data/cifar-10-batches-bin\',\n                          model_dir=\'/tmp/cifar10_model\',\n                          epochs_between_evals=10,\n                          batch_size=128)\n\n\ndef main(_):\n  return run(flags.FLAGS)\n\n\nif __name__ == \'__main__\':\n  logging.set_verbosity(logging.INFO)\n  define_cifar_flags()\n  app.run(main)\n'"
examples/resnet/resnet_cifar_spark.py,1,"b'import resnet_cifar_dist\n\nif __name__ == \'__main__\':\n  # tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n  # absl_app.run(main)\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n  import argparse\n\n  sc = SparkContext(conf=SparkConf().setAppName(""resnet_cifar""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster (for Spark Standalone)"", type=int, default=num_executors)\n  parser.add_argument(""--num_ps"", help=""number of parameter servers"", type=int, default=0)\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n  args, rem = parser.parse_known_args()\n\n  cluster = TFCluster.run(sc, resnet_cifar_dist.main_fun, rem, args.cluster_size, args.num_ps, args.tensorboard, TFCluster.InputMode.TENSORFLOW, master_node=\'chief\')\n  cluster.shutdown()\n'"
examples/segmentation/segmentation.py,21,"b'# Copyright 2019 The TensorFlow Authors.\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n#\n#@title Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\ndataset, info = tfds.load(\'oxford_iiit_pet:3.2.0\', with_info=True)\n\n\ndef normalize(input_image, input_mask):\n  input_image = tf.cast(input_image, tf.float32)/128.0 - 1\n  input_mask -= 1\n  return input_image, input_mask\n\n\n@tf.function\ndef load_image_train(datapoint):\n  input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n  input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n\n  if tf.random.uniform(()) > 0.5:\n    input_image = tf.image.flip_left_right(input_image)\n    input_mask = tf.image.flip_left_right(input_mask)\n\n  input_image, input_mask = normalize(input_image, input_mask)\n\n  return input_image, input_mask\n\n\ndef load_image_test(datapoint):\n  input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n  input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n  input_image, input_mask = normalize(input_image, input_mask)\n  return input_image, input_mask\n\n\nTRAIN_LENGTH = info.splits[\'train\'].num_examples\nBATCH_SIZE = 64\nBUFFER_SIZE = 1000\nSTEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n\ntrain = dataset[\'train\'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntest = dataset[\'test\'].map(load_image_test)\n\ntrain_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\ntest_dataset = test.batch(BATCH_SIZE)\n\nOUTPUT_CHANNELS = 3\n\nbase_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\n# Use the activations of these layers\nlayer_names = [\n    \'block_1_expand_relu\',   # 64x64\n    \'block_3_expand_relu\',   # 32x32\n    \'block_6_expand_relu\',   # 16x16\n    \'block_13_expand_relu\',  # 8x8\n    \'block_16_project\',      # 4x4\n]\nlayers = [base_model.get_layer(name).output for name in layer_names]\n\n# Create the feature extraction model\ndown_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n\ndown_stack.trainable = False\n\nup_stack = [\n    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n]\n\n\ndef unet_model(output_channels):\n\n  # This is the last layer of the model\n  last = tf.keras.layers.Conv2DTranspose(\n      output_channels, 3, strides=2,\n      padding=\'same\', activation=\'softmax\')  # 64x64 -> 128x128\n\n  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n  x = inputs\n\n  # Downsampling through the model\n  skips = down_stack(x)\n  x = skips[-1]\n  skips = reversed(skips[:-1])\n\n  # Upsampling and establishing the skip connections\n  for up, skip in zip(up_stack, skips):\n    x = up(x)\n    concat = tf.keras.layers.Concatenate()\n    x = concat([x, skip])\n\n  x = last(x)\n\n  return tf.keras.Model(inputs=inputs, outputs=x)\n\n\nmodel = unet_model(OUTPUT_CHANNELS)\nmodel.compile(optimizer=\'adam\', loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\n# Training only (since we\'re using command-line)\n# def create_mask(pred_mask):\n#   pred_mask = tf.argmax(pred_mask, axis=-1)\n#   pred_mask = pred_mask[..., tf.newaxis]\n#   return pred_mask[0]\n#\n#\n# def show_predictions(dataset=None, num=1):\n#   if dataset:\n#     for image, mask in dataset.take(num):\n#       pred_mask = model.predict(image)\n#       display([image[0], mask[0], create_mask(pred_mask)])\n#   else:\n#     display([sample_image, sample_mask,\n#              create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n#\n#\n# class DisplayCallback(tf.keras.callbacks.Callback):\n#   def on_epoch_end(self, epoch, logs=None):\n#     clear_output(wait=True)\n#     show_predictions()\n#     print (\'\\nSample Prediction after epoch {}\\n\'.format(epoch+1))\n#\n\n# EPOCHS = 20\nEPOCHS = 1\nVAL_SUBSPLITS = 5\nVALIDATION_STEPS = info.splits[\'test\'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n\nmodel_history = model.fit(train_dataset, epochs=EPOCHS,\n                          steps_per_epoch=STEPS_PER_EPOCH,\n                          validation_steps=VALIDATION_STEPS,\n                          validation_data=test_dataset)\n\nmodel.save_weights(""keras_weights"")\n'"
examples/segmentation/segmentation_dist.py,22,"b'# Copyright 2019 The TensorFlow Authors.\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n#\n#@title Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport json\nimport os\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\ntf_config = json.loads(os.environ.get(\'TF_CONFIG\'))\nprint(""tf_config = "", tf_config)\nprint(""I\'m {}:{}"".format(tf_config[\'task\'][\'type\'], tf_config[\'task\'][\'index\']))\n\ndataset, info = tfds.load(\'oxford_iiit_pet:3.2.0\', with_info=True)\n\n\ndef normalize(input_image, input_mask):\n  input_image = tf.cast(input_image, tf.float32)/128.0 - 1\n  input_mask -= 1\n  return input_image, input_mask\n\n\n@tf.function\ndef load_image_train(datapoint):\n  input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n  input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n\n  if tf.random.uniform(()) > 0.5:\n    input_image = tf.image.flip_left_right(input_image)\n    input_mask = tf.image.flip_left_right(input_mask)\n\n  input_image, input_mask = normalize(input_image, input_mask)\n\n  return input_image, input_mask\n\n\ndef load_image_test(datapoint):\n  input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n  input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n  input_image, input_mask = normalize(input_image, input_mask)\n  return input_image, input_mask\n\n\nTRAIN_LENGTH = info.splits[\'train\'].num_examples\nBATCH_SIZE = 64\nBUFFER_SIZE = 1000\nSTEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n\ntrain = dataset[\'train\'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntest = dataset[\'test\'].map(load_image_test)\n\ntrain_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\ntest_dataset = test.batch(BATCH_SIZE)\n\nOUTPUT_CHANNELS = 3\n\nwith strategy.scope():\n  base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\n  # Use the activations of these layers\n  layer_names = [\n      \'block_1_expand_relu\',   # 64x64\n      \'block_3_expand_relu\',   # 32x32\n      \'block_6_expand_relu\',   # 16x16\n      \'block_13_expand_relu\',  # 8x8\n      \'block_16_project\',      # 4x4\n  ]\n  layers = [base_model.get_layer(name).output for name in layer_names]\n\n  # Create the feature extraction model\n  down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n\n  down_stack.trainable = False\n\n  up_stack = [\n      pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n      pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n      pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n      pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n  ]\n\n  def unet_model(output_channels):\n\n    # This is the last layer of the model\n    last = tf.keras.layers.Conv2DTranspose(\n        output_channels, 3, strides=2,\n        padding=\'same\', activation=\'softmax\')  # 64x64 -> 128x128\n\n    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n    x = inputs\n\n    # Downsampling through the model\n    skips = down_stack(x)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n      x = up(x)\n      concat = tf.keras.layers.Concatenate()\n      x = concat([x, skip])\n\n    x = last(x)\n\n    return tf.keras.Model(inputs=inputs, outputs=x)\n\n  model = unet_model(OUTPUT_CHANNELS)\n  model.compile(optimizer=\'adam\', loss=\'sparse_categorical_crossentropy\',\n                metrics=[\'accuracy\'])\n\n# Training only (since we\'re using command-line)\n# def create_mask(pred_mask):\n#   pred_mask = tf.argmax(pred_mask, axis=-1)\n#   pred_mask = pred_mask[..., tf.newaxis]\n#   return pred_mask[0]\n#\n#\n# def show_predictions(dataset=None, num=1):\n#   if dataset:\n#     for image, mask in dataset.take(num):\n#       pred_mask = model.predict(image)\n#       display([image[0], mask[0], create_mask(pred_mask)])\n#   else:\n#     display([sample_image, sample_mask,\n#              create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n#\n#\n# class DisplayCallback(tf.keras.callbacks.Callback):\n#   def on_epoch_end(self, epoch, logs=None):\n#     clear_output(wait=True)\n#     show_predictions()\n#     print (\'\\nSample Prediction after epoch {}\\n\'.format(epoch+1))\n#\n\n# EPOCHS = 20\nEPOCHS = 1\nVAL_SUBSPLITS = 5\nVALIDATION_STEPS = info.splits[\'test\'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n\nmodel_history = model.fit(train_dataset, epochs=EPOCHS,\n                          steps_per_epoch=STEPS_PER_EPOCH,\n                          validation_steps=VALIDATION_STEPS,\n                          validation_data=test_dataset)\n\nif tf_config[\'task\'][\'index\'] == 0:\n  model.save_weights(""keras_weights"", save_format=\'h5\')\n'"
examples/segmentation/segmentation_spark.py,28,"b'# Copyright 2019 The TensorFlow Authors.\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n#\n# @title Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  from tensorflow_examples.models.pix2pix import pix2pix\n  import tensorflow_datasets as tfds\n  import tensorflow as tf\n\n  print(""TensorFlow version: "", tf.__version__)\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  dataset, info = tfds.load(\'oxford_iiit_pet:3.2.0\', with_info=True)\n\n  def normalize(input_image, input_mask):\n    input_image = tf.cast(input_image, tf.float32)/128.0 - 1\n    input_mask -= 1\n    return input_image, input_mask\n\n  @tf.function\n  def load_image_train(datapoint):\n    input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n    input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n\n    if tf.random.uniform(()) > 0.5:\n      input_image = tf.image.flip_left_right(input_image)\n      input_mask = tf.image.flip_left_right(input_mask)\n\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask\n\n  def load_image_test(datapoint):\n    input_image = tf.image.resize(datapoint[\'image\'], (128, 128))\n    input_mask = tf.image.resize(datapoint[\'segmentation_mask\'], (128, 128))\n    input_image, input_mask = normalize(input_image, input_mask)\n    return input_image, input_mask\n\n  TRAIN_LENGTH = info.splits[\'train\'].num_examples\n  BATCH_SIZE = args.batch_size\n  BUFFER_SIZE = args.buffer_size\n  STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n\n  train = dataset[\'train\'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  test = dataset[\'test\'].map(load_image_test)\n\n  train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n  train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n  test_dataset = test.batch(BATCH_SIZE)\n\n  OUTPUT_CHANNELS = 3\n\n  with strategy.scope():\n    base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\n    # Use the activations of these layers\n    layer_names = [\n        \'block_1_expand_relu\',   # 64x64\n        \'block_3_expand_relu\',   # 32x32\n        \'block_6_expand_relu\',   # 16x16\n        \'block_13_expand_relu\',  # 8x8\n        \'block_16_project\',      # 4x4\n    ]\n    layers = [base_model.get_layer(name).output for name in layer_names]\n\n    # Create the feature extraction model\n    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n\n    down_stack.trainable = False\n\n    up_stack = [\n        pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n        pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n        pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n        pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n    ]\n\n    def unet_model(output_channels):\n\n      # This is the last layer of the model\n      last = tf.keras.layers.Conv2DTranspose(\n          output_channels, 3, strides=2,\n          padding=\'same\', activation=\'softmax\')  # 64x64 -> 128x128\n\n      inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n      x = inputs\n\n      # Downsampling through the model\n      skips = down_stack(x)\n      x = skips[-1]\n      skips = reversed(skips[:-1])\n\n      # Upsampling and establishing the skip connections\n      for up, skip in zip(up_stack, skips):\n        x = up(x)\n        concat = tf.keras.layers.Concatenate()\n        x = concat([x, skip])\n\n      x = last(x)\n\n      return tf.keras.Model(inputs=inputs, outputs=x)\n\n    model = unet_model(OUTPUT_CHANNELS)\n    model.compile(optimizer=\'adam\', loss=\'sparse_categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n\n# Training only (since we\'re using command-line)\n# def create_mask(pred_mask):\n#   pred_mask = tf.argmax(pred_mask, axis=-1)\n#   pred_mask = pred_mask[..., tf.newaxis]\n#   return pred_mask[0]\n#\n#\n# def show_predictions(dataset=None, num=1):\n#   if dataset:\n#     for image, mask in dataset.take(num):\n#       pred_mask = model.predict(image)\n#       display([image[0], mask[0], create_mask(pred_mask)])\n#   else:\n#     display([sample_image, sample_mask,\n#              create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n#\n#\n# class DisplayCallback(tf.keras.callbacks.Callback):\n#   def on_epoch_end(self, epoch, logs=None):\n#     clear_output(wait=True)\n#     show_predictions()\n#     print (\'\\nSample Prediction after epoch {}\\n\'.format(epoch+1))\n#\n\n  EPOCHS = args.epochs\n  VAL_SUBSPLITS = 5\n  VALIDATION_STEPS = info.splits[\'test\'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n\n  tf.io.gfile.makedirs(args.model_dir)\n  filepath = args.model_dir + ""/weights-{epoch:04d}""\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_weights_only=True)\n\n  model_history = model.fit(train_dataset, epochs=EPOCHS,\n                            steps_per_epoch=STEPS_PER_EPOCH,\n                            callbacks=[ckpt_callback],\n                            validation_steps=VALIDATION_STEPS,\n                            validation_data=test_dataset)\n\n  if tf.__version__ == \'2.0.0\':\n    # Workaround for: https://github.com/tensorflow/tensorflow/issues/30251\n    # Save model locally as h5py and reload it w/o distribution strategy\n    if ctx.job_name == \'chief\':\n      model.save(args.model_dir + "".h5"")\n      new_model = tf.keras.models.load_model(args.model_dir + "".h5"")\n      tf.keras.experimental.export_saved_model(new_model, args.export_dir)\n  else:\n    model.save(args.export_dir, save_format=\'tf\')\n\n\nif __name__ == \'__main__\':\n  import argparse\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n\n  sc = SparkContext(conf=SparkConf().setAppName(""segmentation""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=1000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--model_dir"", help=""path to save model/checkpoint"", default=""segmentation_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""segmentation_export"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.TENSORFLOW, master_node=\'chief\')\n  cluster.shutdown(grace_secs=30)\n'"
examples/utils/mnist_reshape.py,0,"b""# Copyright 2019 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\nimport sys\nimport numpy as np\nvec = [int(x) for x in next(sys.stdin).split(',')]\nimg = np.reshape(vec[1:], (28, 28, 1))\nprint(np.array2string(img).replace('\\n ', ','))\n"""
examples/utils/stop_streaming.py,0,"b'# Copyright 2017 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n""""""\nSimple utility to shutdown a Spark StreamingContext by signaling the reservation Server.\nNote: use the reservation server address (host, port) reported in the driver logs.\n""""""\n\nfrom tensorflowonspark import reservation\nimport sys\n\nif __name__ == ""__main__"":\n  host = sys.argv[1]\n  port = int(sys.argv[2])\n  addr = (host, port)\n  client = reservation.Client(addr)\n  client.request_stop()\n  client.close()\n'"
examples/mnist/estimator/mnist_inference.py,13,"b'# Copyright 2018 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\n# This example demonstrates how to leverage Spark for parallel inferencing from a SavedModel.\n#\n# Normally, you can use TensorFlowOnSpark to just form a TensorFlow cluster for training and inferencing.\n# However, in some situations, you may have a SavedModel without the original code for defining the inferencing\n# graph.  In these situations, we can use Spark to instantiate a single-node TensorFlow instance on each executor,\n# where each executor can independently load the model and inference on input data.\n#\n# Note: this particular example demonstrates use of `tf.data.Dataset` to read the input data for inferencing,\n# but it could also be adapted to just use an RDD of TFRecords from Spark.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport numpy as np\nimport tensorflow as tf\n\n\ndef inference(it, num_workers, args):\n  from tensorflowonspark import util\n\n  # consume worker number from RDD partition iterator\n  for i in it:\n    worker_num = i\n  print(""worker_num: {}"".format(i))\n\n  # setup env for single-node TF\n  util.single_node_env()\n\n  # load saved_model\n  saved_model = tf.saved_model.load(args.export_dir, tags=\'serve\')\n  predict = saved_model.signatures[\'serving_default\']\n\n  # parse function for TFRecords\n  def parse_tfr(example_proto):\n    feature_def = {""label"": tf.io.FixedLenFeature(1, tf.int64),\n                   ""image"": tf.io.FixedLenFeature(784, tf.int64)}\n    features = tf.io.parse_single_example(serialized=example_proto, features=feature_def)\n    image = tf.cast(features[\'image\'], dtype=tf.float32) / 255.0\n    image = tf.reshape(image, [28, 28, 1])\n    label = tf.cast(features[\'label\'], dtype=tf.float32)\n    return (image, label)\n\n  # define a new tf.data.Dataset (for inferencing)\n  ds = tf.data.Dataset.list_files(""{}/part-*"".format(args.images_labels), shuffle=False)\n  ds = ds.shard(num_workers, worker_num)\n  ds = ds.interleave(tf.data.TFRecordDataset)\n  ds = ds.map(parse_tfr)\n  ds = ds.batch(10)\n\n  # create an output file per spark worker for the predictions\n  tf.io.gfile.makedirs(args.output)\n  output_file = tf.io.gfile.GFile(""{}/part-{:05d}"".format(args.output, worker_num), mode=\'w\')\n\n  for batch in ds:\n    predictions = predict(conv2d_input=batch[0])\n    labels = np.reshape(batch[1], -1).astype(np.int)\n    preds = np.argmax(predictions[\'logits\'], axis=1)\n    for x in zip(labels, preds):\n      output_file.write(""{} {}\\n"".format(x[0], x[1]))\n\n  output_file.close()\n\n\nif __name__ == \'__main__\':\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_inference""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster (for S with labelspark Standalone)"", type=int, default=num_executors)\n  parser.add_argument(\'--images_labels\', type=str, help=\'Directory for input images with labels\')\n  parser.add_argument(""--export_dir"", help=""HDFS path to export model"", type=str, default=""mnist_export"")\n  parser.add_argument(""--output"", help=""HDFS path to save predictions"", type=str, default=""predictions"")\n  args, _ = parser.parse_known_args()\n  print(""args: {}"".format(args))\n\n  # Not using TFCluster... just running single-node TF instances on each executor\n  nodes = list(range(args.cluster_size))\n  nodeRDD = sc.parallelize(list(range(args.cluster_size)), args.cluster_size)\n  nodeRDD.foreachPartition(lambda worker_num: inference(worker_num, args.cluster_size, args))\n'"
examples/mnist/estimator/mnist_pipeline.py,30,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  import numpy as np\n  import tensorflow as tf\n  import tensorflow_datasets as tfds\n  from tensorflowonspark import TFNode\n\n  tfds.disable_progress_bar()\n\n  class StopFeedHook(tf.estimator.SessionRunHook):\n    """"""SessionRunHook to terminate InputMode.SPARK RDD feeding if the training loop exits before the entire RDD is consumed.""""""\n\n    def __init__(self, feed):\n      self.feed = feed\n\n    def end(self, session):\n      self.feed.terminate()\n      self.feed.next_batch(1)\n\n  BATCH_SIZE = args.batch_size\n  LEARNING_RATE = args.learning_rate\n\n  tf_feed = TFNode.DataFeed(ctx.mgr)\n\n  def rdd_generator():\n    while not tf_feed.should_stop():\n      batch = tf_feed.next_batch(1)\n      if len(batch) > 0:\n        example = batch[0]\n        image = np.array(example[0]).astype(np.float32) / 255.0\n        image = np.reshape(image, (28, 28, 1))\n        label = np.array(example[1]).astype(np.float32)\n        label = np.reshape(label, (1,))\n        yield (image, label)\n      else:\n        return\n\n  def input_fn(mode, input_context=None):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      # Note: Spark is responsible for sharding/repeating/shuffling the data via RDD\n      ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([28, 28, 1]), tf.TensorShape([1])))\n      return ds.batch(BATCH_SIZE)\n    else:\n      # read evaluation data from tensorflow_datasets directly\n      def scale(image, label):\n        image = tf.cast(image, tf.float32) / 255.0\n        return image, label\n\n      mnist = tfds.load(name=\'mnist\', with_info=True, as_supervised=True)\n      ds = mnist[\'test\']\n      if input_context:\n        ds = ds.shard(input_context.num_input_pipelines, input_context.input_pipeline_id)\n      return ds.map(scale).batch(BATCH_SIZE)\n\n  def serving_input_receiver_fn():\n    features = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name=\'features\')\n    receiver_tensors = {\'features\': features}\n    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)\n\n  def model_fn(features, labels, mode):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    logits = model(features, training=False)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      predictions = {\'logits\': logits}\n      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n        learning_rate=LEARNING_RATE)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n    loss = tf.reduce_sum(input_tensor=loss) * (1. / BATCH_SIZE)\n    if mode == tf.estimator.ModeKeys.EVAL:\n      return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        loss=loss,\n        train_op=optimizer.minimize(\n            loss, tf.compat.v1.train.get_or_create_global_step()))\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n  config = tf.estimator.RunConfig(train_distribute=strategy, save_checkpoints_steps=100)\n\n  classifier = tf.estimator.Estimator(\n      model_fn=model_fn, model_dir=args.model_dir, config=config)\n\n  # exporter = tf.estimator.FinalExporter(""serving"", serving_input_receiver_fn=serving_input_receiver_fn)\n\n  # Note: MultiWorkerMirroredStrategy (CollectiveAllReduceStrategy) is synchronous,\n  # so we need to ensure that all workers complete training before any of them run out of data from the RDD.\n  # And given that Spark RDD partitions (and partition sizes) can be non-evenly divisible by num_workers,\n  # we\'ll just stop training at 90% of the total expected number of steps.\n  steps = 60000 * args.epochs / args.batch_size\n  steps_per_worker = steps / ctx.num_workers\n  max_steps_per_worker = steps_per_worker * 0.9\n\n  tf.estimator.train_and_evaluate(\n      classifier,\n      train_spec=tf.estimator.TrainSpec(input_fn=input_fn, max_steps=max_steps_per_worker, hooks=[StopFeedHook(tf_feed)]),\n      eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n      # eval_spec=tf.estimator.EvalSpec(input_fn=input_fn, exporters=exporter)\n  )\n\n  if ctx.job_name == \'chief\':\n    print(""Exporting saved_model to {}"".format(args.export_dir))\n    classifier.export_saved_model(args.export_dir, serving_input_receiver_fn)\n\n\nif __name__ == ""__main__"":\n\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from pyspark.sql import SparkSession\n  from pyspark.sql.functions import udf\n  from pyspark.sql.types import IntegerType\n  from tensorflowonspark import dfutil\n  from tensorflowonspark.pipeline import TFEstimator, TFModel\n  import argparse\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_estimator""))\n  spark = SparkSession(sc)\n\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--format"", help=""example format: (csv|tfr)"", choices=[""csv"", ""tfr""], default=""csv"")\n  parser.add_argument(""--images_labels"", help=""path to MNIST images and labels in parallelized format"")\n  parser.add_argument(""--learning_rate"", help=""learning rate"", type=float, default=1e-3)\n  parser.add_argument(""--mode"", help=""train|inference"", choices=[""train"", ""inference""], default=""train"")\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--output"", help=""HDFS path to save predictions"", type=str, default=""predictions"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  if args.format == \'tfr\':\n    # load TFRecords as a DataFrame\n    df = dfutil.loadTFRecords(sc, args.images_labels)\n  else:  # args.format == \'csv\':\n    # create RDD of input data\n    def parse(ln):\n      vec = [int(x) for x in ln.split(\',\')]\n      return (vec[1:], vec[0])\n\n    images_labels = sc.textFile(args.images_labels).map(parse)\n    df = spark.createDataFrame(images_labels, [\'image\', \'label\'])\n\n  df.show()\n\n  if args.mode == \'train\':\n    estimator = TFEstimator(main_fun, args) \\\n        .setInputMapping({\'image\': \'image\', \'label\': \'label\'}) \\\n        .setModelDir(args.model_dir) \\\n        .setExportDir(args.export_dir) \\\n        .setClusterSize(args.cluster_size) \\\n        .setTensorboard(args.tensorboard) \\\n        .setEpochs(args.epochs) \\\n        .setBatchSize(args.batch_size) \\\n        .setGraceSecs(60)\n    model = estimator.fit(df)\n  else:  # args.mode == \'inference\':\n    # using a trained/exported model\n    model = TFModel(args) \\\n        .setInputMapping({\'image\': \'features\'}) \\\n        .setOutputMapping({\'logits\': \'prediction\'}) \\\n        .setSignatureDefKey(\'serving_default\') \\\n        .setExportDir(args.export_dir) \\\n        .setBatchSize(args.batch_size)\n\n    def argmax_fn(l):\n      return max(range(len(l)), key=lambda i: l[i])\n\n    argmax = udf(argmax_fn, IntegerType())\n\n    preds = model.transform(df).withColumn(\'argmax\', argmax(\'prediction\'))\n    preds.show()\n    preds.write.json(args.output)\n'"
examples/mnist/estimator/mnist_spark.py,30,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator\n\n\ndef main_fun(args, ctx):\n  import numpy as np\n  import tensorflow as tf\n  import tensorflow_datasets as tfds\n  from tensorflowonspark import TFNode\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  tfds.disable_progress_bar()\n\n  class StopFeedHook(tf.estimator.SessionRunHook):\n    """"""SessionRunHook to terminate InputMode.SPARK RDD feeding if the training loop exits before the entire RDD is consumed.""""""\n\n    def __init__(self, feed):\n      self.feed = feed\n\n    def end(self, session):\n      self.feed.terminate()\n      self.feed.next_batch(1)\n\n  BUFFER_SIZE = args.buffer_size\n  BATCH_SIZE = args.batch_size\n  LEARNING_RATE = args.learning_rate\n\n  tf_feed = TFNode.DataFeed(ctx.mgr)\n\n  def rdd_generator():\n    while not tf_feed.should_stop():\n      batch = tf_feed.next_batch(1)\n      if len(batch) > 0:\n        example = batch[0]\n        image = np.array(example[0]).astype(np.float32) / 255.0\n        image = np.reshape(image, (28, 28, 1))\n        label = np.array(example[1]).astype(np.float32)\n        label = np.reshape(label, (1,))\n        yield (image, label)\n      else:\n        return\n\n  def input_fn(mode, input_context=None):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      # Note: Spark is responsible for sharding/repeating/shuffling the data via RDD\n      ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([28, 28, 1]), tf.TensorShape([1])))\n      return ds.batch(BATCH_SIZE)\n    else:\n      raise Exception(""I\'m evaluating: mode={}, input_context={}"".format(mode, input_context))\n\n      def scale(image, label):\n        image = tf.cast(image, tf.float32) / 255.0\n        return image, label\n\n      mnist = tfds.load(name=\'mnist\', with_info=True, as_supervised=True)\n      ds = mnist[\'test\']\n      if input_context:\n        ds = ds.shard(input_context.num_input_pipelines, input_context.input_pipeline_id)\n      return ds.map(scale).batch(BATCH_SIZE)\n\n  def serving_input_receiver_fn():\n    features = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name=\'features\')\n    receiver_tensors = {\'conv2d_input\': features}\n    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)\n\n  def model_fn(features, labels, mode):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    logits = model(features, training=False)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      predictions = {\'logits\': logits}\n      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n        learning_rate=LEARNING_RATE)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n    loss = tf.reduce_sum(input_tensor=loss) * (1. / BATCH_SIZE)\n    if mode == tf.estimator.ModeKeys.EVAL:\n      return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        loss=loss,\n        train_op=optimizer.minimize(\n            loss, tf.compat.v1.train.get_or_create_global_step()))\n\n  config = tf.estimator.RunConfig(train_distribute=strategy, save_checkpoints_steps=100)\n\n  classifier = tf.estimator.Estimator(\n      model_fn=model_fn, model_dir=args.model_dir, config=config)\n\n  # exporter = tf.estimator.FinalExporter(""serving"", serving_input_receiver_fn=serving_input_receiver_fn)\n\n  # Note: MultiWorkerMirroredStrategy (CollectiveAllReduceStrategy) is synchronous,\n  # so we need to ensure that all workers complete training before any of them run out of data from the RDD.\n  # And given that Spark RDD partitions (and partition sizes) can be non-evenly divisible by num_workers,\n  # we\'ll just stop training at 90% of the total expected number of steps.\n  steps = 60000 * args.epochs / args.batch_size\n  steps_per_worker = steps / ctx.num_workers\n  max_steps_per_worker = steps_per_worker * 0.9\n\n  tf.estimator.train_and_evaluate(\n      classifier,\n      train_spec=tf.estimator.TrainSpec(input_fn=input_fn, max_steps=max_steps_per_worker, hooks=[StopFeedHook(tf_feed)]),\n      eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n      # eval_spec=tf.estimator.EvalSpec(input_fn=input_fn, exporters=exporter)\n  )\n\n  if ctx.job_name == \'chief\':\n    print(""Exporting saved_model to {}"".format(args.export_dir))\n    classifier.export_saved_model(args.export_dir, serving_input_receiver_fn)\n\n\nif __name__ == ""__main__"":\n\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n  import argparse\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_estimator""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--images_labels"", help=""path to MNIST images and labels in parallelized format"")\n  parser.add_argument(""--learning_rate"", help=""learning rate"", type=float, default=1e-3)\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  # create RDD of input data\n  def parse(ln):\n    vec = [int(x) for x in ln.split(\',\')]\n    return (vec[1:], vec[0])\n\n  images_labels = sc.textFile(args.images_labels).map(parse)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.SPARK, log_dir=args.model_dir, master_node=\'chief\')\n  cluster.train(images_labels, args.epochs)\n  cluster.shutdown(grace_secs=60)  # allow time for the chief to export model after data feeding\n'"
examples/mnist/estimator/mnist_spark_streaming.py,30,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator\n\n\ndef main_fun(args, ctx):\n  import numpy as np\n  import tensorflow as tf\n  import tensorflow_datasets as tfds\n  from tensorflowonspark import TFNode\n\n  tfds.disable_progress_bar()\n\n  BUFFER_SIZE = args.buffer_size\n  BATCH_SIZE = args.batch_size\n  LEARNING_RATE = args.learning_rate\n\n  tf_feed = TFNode.DataFeed(ctx.mgr)\n\n  def rdd_generator():\n    while not tf_feed.should_stop():\n      batch = tf_feed.next_batch(1)\n      if len(batch) > 0:\n        example = batch[0]\n        image = np.array(example[0]).astype(np.float32) / 255.0\n        image = np.reshape(image, (28, 28, 1))\n        label = np.array(example[1]).astype(np.float32)\n        label = np.reshape(label, (1,))\n        yield (image, label)\n      else:\n        return\n\n  def input_fn(mode, input_context=None):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      # Note: Spark is responsible for feeding data via streaming RDD\n      ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([28, 28, 1]), tf.TensorShape([1])))\n      return ds.batch(BATCH_SIZE)\n    else:\n      raise Exception(""I\'m evaluating: mode={}, input_context={}"".format(mode, input_context))\n\n      def scale(image, label):\n        image = tf.cast(image, tf.float32) / 255.0\n        return image, label\n\n      mnist = tfds.load(name=\'mnist\', with_info=True, as_supervised=True)\n      ds = mnist[\'test\']\n      if input_context:\n        ds = ds.shard(input_context.num_input_pipelines, input_context.input_pipeline_id)\n      return ds.map(scale).batch(BATCH_SIZE)\n\n  def serving_input_receiver_fn():\n    features = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name=\'features\')\n    receiver_tensors = {\'conv2d_input\': features}\n    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)\n\n  def model_fn(features, labels, mode):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    logits = model(features, training=False)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      predictions = {\'logits\': logits}\n      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n        learning_rate=LEARNING_RATE)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n    loss = tf.reduce_sum(input_tensor=loss) * (1. / BATCH_SIZE)\n    if mode == tf.estimator.ModeKeys.EVAL:\n      return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        loss=loss,\n        train_op=optimizer.minimize(\n            loss, tf.compat.v1.train.get_or_create_global_step()))\n\n  # Note: the original example used MultiWorkerMirroredStrategy which is a synchronous training strategy.\n  # Since streaming data arrives irregularly, we must use the asynchronous ParameterServerStrategy\n  # to allow data to be processed as it arrives and to avoid deadlocks.\n  # strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n  strategy = tf.distribute.experimental.ParameterServerStrategy()\n  config = tf.estimator.RunConfig(train_distribute=strategy, save_checkpoints_steps=100)\n\n  classifier = tf.estimator.Estimator(\n      model_fn=model_fn, model_dir=args.model_dir, config=config)\n\n  # exporter = tf.estimator.FinalExporter(""serving"", serving_input_receiver_fn=serving_input_receiver_fn)\n\n  tf.estimator.train_and_evaluate(\n      classifier,\n      train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n      eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n      # eval_spec=tf.estimator.EvalSpec(input_fn=input_fn, exporters=exporter)\n  )\n\n  if ctx.job_name == \'chief\':\n    print(""Exporting saved_model to {}"".format(args.export_dir))\n    classifier.export_saved_model(args.export_dir, serving_input_receiver_fn)\n\n\nif __name__ == ""__main__"":\n\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from pyspark.streaming import StreamingContext\n  from tensorflowonspark import TFCluster\n  import argparse\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_estimator""))\n  ssc = StreamingContext(sc, 60)  # group data into intervals of one minute\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--images_labels"", help=""path to MNIST images and labels in parallelized format"")\n  parser.add_argument(""--learning_rate"", help=""learning rate"", type=float, default=1e-3)\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  # create RDD of input data\n  def parse(ln):\n    vec = [int(x) for x in ln.split(\',\')]\n    return (vec[1:], vec[0])\n\n  stream = ssc.textFileStream(args.images_labels)\n  images_labels = stream.map(parse)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=1, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.SPARK, log_dir=args.model_dir, master_node=\'chief\')\n  cluster.train(images_labels, feed_timeout=86400)  # extend feed timeout to 24hrs for streaming data to arrive\n  ssc.start()\n  cluster.shutdown(ssc)\n'"
examples/mnist/estimator/mnist_tf.py,29,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator\n\n\ndef main_fun(args, ctx):\n  import tensorflow_datasets as tfds\n  import tensorflow as tf\n\n  BUFFER_SIZE = args.buffer_size\n  BATCH_SIZE = args.batch_size\n  LEARNING_RATE = args.learning_rate\n\n  def input_fn(mode, input_context=None):\n    datasets, info = tfds.load(name=\'mnist\',\n                                  with_info=True,\n                                  as_supervised=True)\n    mnist_dataset = (datasets[\'train\'] if mode == tf.estimator.ModeKeys.TRAIN else\n                     datasets[\'test\'])\n\n    def scale(image, label):\n      image = tf.cast(image, tf.float32)\n      image /= 255\n      return image, label\n\n    if input_context:\n      mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\n                                          input_context.input_pipeline_id)\n    return mnist_dataset.repeat(args.epochs).map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n\n  def serving_input_receiver_fn():\n    features = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name=\'features\')\n    receiver_tensors = {\'conv2d_input\': features}\n    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)\n\n  def model_fn(features, labels, mode):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10)\n    ])\n    logits = model(features, training=False)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      predictions = {\'logits\': logits}\n      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n        learning_rate=LEARNING_RATE)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n    loss = tf.reduce_sum(input_tensor=loss) * (1. / BATCH_SIZE)\n    if mode == tf.estimator.ModeKeys.EVAL:\n      return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        loss=loss,\n        train_op=optimizer.minimize(\n            loss, tf.compat.v1.train.get_or_create_global_step()))\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n  config = tf.estimator.RunConfig(train_distribute=strategy, save_checkpoints_steps=100)\n\n  classifier = tf.estimator.Estimator(\n      model_fn=model_fn, model_dir=args.model_dir, config=config)\n\n  # exporter = tf.estimator.FinalExporter(""serving"", serving_input_receiver_fn=serving_input_receiver_fn)\n\n  tf.estimator.train_and_evaluate(\n      classifier,\n      train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n      eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n      # eval_spec=tf.estimator.EvalSpec(input_fn=input_fn, exporters=exporter)\n  )\n\n  if ctx.job_name == \'chief\':\n    print(""========== exporting saved_model to {}"".format(args.export_dir))\n    classifier.export_saved_model(args.export_dir, serving_input_receiver_fn)\n\n\nif __name__ == ""__main__"":\n  # tf.app.run()\n\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n  import argparse\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_estimator""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--learning_rate"", help=""learning rate"", type=float, default=1e-4)\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.TENSORFLOW, log_dir=args.model_dir, master_node=\'chief\', eval_node=True)\n  cluster.shutdown(grace_secs=60)\n'"
examples/mnist/keras/mnist_inference.py,13,"b'# Copyright 2018 Yahoo Inc.\n# Licensed under the terms of the Apache 2.0 license.\n# Please see LICENSE file in the project root for terms.\n\n# This example demonstrates how to leverage Spark for parallel inferencing from a SavedModel.\n#\n# Normally, you can use TensorFlowOnSpark to just form a TensorFlow cluster for training and inferencing.\n# However, in some situations, you may have a SavedModel without the original code for defining the inferencing\n# graph.  In these situations, we can use Spark to instantiate a single-node TensorFlow instance on each executor,\n# where each executor can independently load the model and inference on input data.\n#\n# Note: this particular example demonstrates use of `tf.data.Dataset` to read the input data for inferencing,\n# but it could also be adapted to just use an RDD of TFRecords from Spark.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport numpy as np\nimport tensorflow as tf\n\n\ndef inference(args, ctx):\n\n  # load saved_model\n  saved_model = tf.saved_model.load(args.export_dir, tags=\'serve\')\n  predict = saved_model.signatures[\'serving_default\']\n\n  # parse function for TFRecords\n  def parse_tfr(example_proto):\n    feature_def = {""label"": tf.io.FixedLenFeature(1, tf.int64),\n                   ""image"": tf.io.FixedLenFeature(784, tf.int64)}\n    features = tf.io.parse_single_example(serialized=example_proto, features=feature_def)\n    image = tf.cast(features[\'image\'], dtype=tf.float32) / 255.0\n    image = tf.reshape(image, [28, 28, 1])\n    label = tf.cast(features[\'label\'], dtype=tf.float32)\n    return (image, label)\n\n  # define a new tf.data.Dataset (for inferencing)\n  ds = tf.data.Dataset.list_files(""{}/part-*"".format(args.images_labels), shuffle=False)\n  ds = ds.shard(ctx.num_workers, ctx.worker_num)\n  ds = ds.interleave(tf.data.TFRecordDataset)\n  ds = ds.map(parse_tfr)\n  ds = ds.batch(10)\n\n  # create an output file per spark worker for the predictions\n  tf.io.gfile.makedirs(args.output)\n  output_file = tf.io.gfile.GFile(""{}/part-{:05d}"".format(args.output, ctx.worker_num), mode=\'w\')\n\n  for batch in ds:\n    predictions = predict(conv2d_input=batch[0])\n    labels = np.reshape(batch[1], -1).astype(np.int)\n    preds = np.argmax(predictions[\'dense_1\'], axis=1)\n    for x in zip(labels, preds):\n      output_file.write(""{} {}\\n"".format(x[0], x[1]))\n\n  output_file.close()\n\n\nif __name__ == \'__main__\':\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFParallel\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_inference""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster (for S with labelspark Standalone)"", type=int, default=num_executors)\n  parser.add_argument(\'--images_labels\', type=str, help=\'Directory for input images with labels\')\n  parser.add_argument(""--export_dir"", help=""HDFS path to export model"", type=str, default=""mnist_export"")\n  parser.add_argument(""--output"", help=""HDFS path to save predictions"", type=str, default=""predictions"")\n  args, _ = parser.parse_known_args()\n  print(""args: {}"".format(args))\n\n  # Running single-node TF instances on each executor\n  TFParallel.run(sc, inference, args, args.cluster_size)\n'"
examples/mnist/keras/mnist_pipeline.py,13,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_keras\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  import numpy as np\n  import tensorflow as tf\n  from tensorflowonspark import compat, TFNode\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  def build_and_compile_cnn_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    model.compile(\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n        metrics=[\'accuracy\'])\n    return model\n\n  # single node\n  # single_worker_model = build_and_compile_cnn_model()\n  # single_worker_model.fit(x=train_datasets, epochs=3)\n\n  tf_feed = TFNode.DataFeed(ctx.mgr, False)\n\n  def rdd_generator():\n    while not tf_feed.should_stop():\n      batch = tf_feed.next_batch(1)\n      if len(batch) > 0:\n        example = batch[0]\n        image = np.array(example[0]).astype(np.float32) / 255.0\n        image = np.reshape(image, (28, 28, 1))\n        label = np.array(example[1]).astype(np.float32)\n        label = np.reshape(label, (1,))\n        yield (image, label)\n      else:\n        return\n\n  ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([28, 28, 1]), tf.TensorShape([1])))\n  ds = ds.batch(args.batch_size)\n\n  # this fails\n  # callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=args.model_dir)]\n  tf.io.gfile.makedirs(args.model_dir)\n  filepath = args.model_dir + ""/weights-{epoch:04d}""\n  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_weights_only=True)]\n\n  with strategy.scope():\n    multi_worker_model = build_and_compile_cnn_model()\n\n  # Note: MultiWorkerMirroredStrategy (CollectiveAllReduceStrategy) is synchronous,\n  # so we need to ensure that all workers complete training before any of them run out of data from the RDD.\n  # And given that Spark RDD partitions (and partition sizes) can be non-evenly divisible by num_workers,\n  # we\'ll just stop training at 90% of the total expected number of steps.\n  steps_per_epoch = 60000 / args.batch_size\n  steps_per_epoch_per_worker = steps_per_epoch / ctx.num_workers\n  max_steps_per_worker = steps_per_epoch_per_worker * 0.9\n\n  multi_worker_model.fit(x=ds, epochs=args.epochs, steps_per_epoch=max_steps_per_worker, callbacks=callbacks)\n\n  from tensorflow_estimator.python.estimator.export import export_lib\n  export_dir = export_lib.get_timestamped_export_dir(args.export_dir)\n  compat.export_saved_model(multi_worker_model, export_dir, ctx.job_name == \'chief\')\n\n  # terminating feed tells spark to skip processing further partitions\n  tf_feed.terminate()\n\n\nif __name__ == \'__main__\':\n  import argparse\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from pyspark.sql import SparkSession\n  from pyspark.sql.functions import udf\n  from pyspark.sql.types import IntegerType\n  from tensorflowonspark import dfutil\n  from tensorflowonspark.pipeline import TFEstimator, TFModel\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_keras""))\n  spark = SparkSession(sc)\n\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--format"", help=""example format: (csv|tfr)"", choices=[""csv"", ""tfr""], default=""csv"")\n  parser.add_argument(""--images_labels"", help=""path to MNIST images and labels in parallelized format"")\n  parser.add_argument(""--mode"", help=""train|inference"", choices=[""train"", ""inference""], default=""train"")\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--output"", help=""HDFS path to save predictions"", type=str, default=""predictions"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  if args.format == \'tfr\':\n    # load TFRecords as a DataFrame\n    df = dfutil.loadTFRecords(sc, args.images_labels)\n  else:  # args.format == \'csv\':\n    # create RDD of input data\n    def parse(ln):\n      vec = [int(x) for x in ln.split(\',\')]\n      return (vec[1:], vec[0])\n\n    images_labels = sc.textFile(args.images_labels).map(parse)\n    df = spark.createDataFrame(images_labels, [\'image\', \'label\'])\n\n  df.show()\n\n  if args.mode == \'train\':\n    estimator = TFEstimator(main_fun, args) \\\n        .setInputMapping({\'image\': \'image\', \'label\': \'label\'}) \\\n        .setModelDir(args.model_dir) \\\n        .setExportDir(args.export_dir) \\\n        .setClusterSize(args.cluster_size) \\\n        .setTensorboard(args.tensorboard) \\\n        .setEpochs(args.epochs) \\\n        .setBatchSize(args.batch_size) \\\n        .setGraceSecs(60)\n    model = estimator.fit(df)\n  else:  # args.mode == \'inference\':\n    # using a trained/exported model\n    model = TFModel(args) \\\n        .setInputMapping({\'image\': \'conv2d_input\'}) \\\n        .setOutputMapping({\'dense_1\': \'prediction\'}) \\\n        .setSignatureDefKey(\'serving_default\') \\\n        .setExportDir(args.export_dir) \\\n        .setBatchSize(args.batch_size)\n\n    def argmax_fn(l):\n      return max(range(len(l)), key=lambda i: l[i])\n\n    argmax = udf(argmax_fn, IntegerType())\n\n    preds = model.transform(df).withColumn(\'argmax\', argmax(\'prediction\'))\n    preds.show()\n    preds.write.json(args.output)\n'"
examples/mnist/keras/mnist_spark.py,13,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_keras\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  import numpy as np\n  import tensorflow as tf\n  from tensorflowonspark import compat, TFNode\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  def build_and_compile_cnn_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    model.compile(\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n        metrics=[\'accuracy\'])\n    return model\n\n  # single node\n  # single_worker_model = build_and_compile_cnn_model()\n  # single_worker_model.fit(x=train_datasets, epochs=3)\n\n  tf_feed = TFNode.DataFeed(ctx.mgr, False)\n\n  def rdd_generator():\n    while not tf_feed.should_stop():\n      batch = tf_feed.next_batch(1)\n      if len(batch) > 0:\n        example = batch[0]\n        image = np.array(example[0]).astype(np.float32) / 255.0\n        image = np.reshape(image, (28, 28, 1))\n        label = np.array(example[1]).astype(np.float32)\n        label = np.reshape(label, (1,))\n        yield (image, label)\n      else:\n        return\n\n  ds = tf.data.Dataset.from_generator(rdd_generator, (tf.float32, tf.float32), (tf.TensorShape([28, 28, 1]), tf.TensorShape([1])))\n  ds = ds.batch(args.batch_size)\n\n  # this fails\n  # callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=args.model_dir)]\n  tf.io.gfile.makedirs(args.model_dir)\n  filepath = args.model_dir + ""/weights-{epoch:04d}""\n  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_weights_only=True)]\n\n  with strategy.scope():\n    multi_worker_model = build_and_compile_cnn_model()\n\n  # Note: MultiWorkerMirroredStrategy (CollectiveAllReduceStrategy) is synchronous,\n  # so we need to ensure that all workers complete training before any of them run out of data from the RDD.\n  # And given that Spark RDD partitions (and partition sizes) can be non-evenly divisible by num_workers,\n  # we\'ll just stop training at 90% of the total expected number of steps.\n  steps_per_epoch = 60000 / args.batch_size\n  steps_per_epoch_per_worker = steps_per_epoch / ctx.num_workers\n  max_steps_per_worker = steps_per_epoch_per_worker * 0.9\n\n  multi_worker_model.fit(x=ds, epochs=args.epochs, steps_per_epoch=max_steps_per_worker, callbacks=callbacks)\n\n  from tensorflow_estimator.python.estimator.export import export_lib\n  export_dir = export_lib.get_timestamped_export_dir(args.export_dir)\n  compat.export_saved_model(multi_worker_model, export_dir, ctx.job_name == \'chief\')\n\n  # terminating feed tells spark to skip processing further partitions\n  tf_feed.terminate()\n\n\nif __name__ == \'__main__\':\n  import argparse\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_keras""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--images_labels"", help=""path to MNIST images and labels in parallelized format"")\n  parser.add_argument(""--model_dir"", help=""path to save checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  # create RDD of input data\n  def parse(ln):\n    vec = [int(x) for x in ln.split(\',\')]\n    return (vec[1:], vec[0])\n\n  images_labels = sc.textFile(args.images_labels).map(parse)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.SPARK, master_node=\'chief\')\n  # Note: need to feed extra data to ensure that each worker receives sufficient data to complete epochs\n  # to compensate for variability in partition sizes and spark scheduling\n  cluster.train(images_labels, args.epochs)\n  cluster.shutdown()\n'"
examples/mnist/keras/mnist_tf.py,17,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_keras\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  import tensorflow_datasets as tfds\n  import tensorflow as tf\n  from tensorflowonspark import compat\n\n  tfds.disable_progress_bar()\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  BUFFER_SIZE = args.buffer_size\n  BATCH_SIZE = args.batch_size\n  NUM_WORKERS = args.cluster_size\n\n  # Scaling MNIST data from (0, 255] to (0., 1.]\n  def scale(image, label):\n    return tf.cast(image, tf.float32) / 255, label\n\n  # workaround for https://github.com/tensorflow/datasets/issues/1405\n  datasets = tfds.load(name=\'mnist\', split=\'train\', as_supervised=True)\n  options = tf.data.Options()\n  options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n  train_datasets_unbatched = datasets.with_options(options).repeat().map(scale).shuffle(BUFFER_SIZE)\n\n  def build_and_compile_cnn_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    model.compile(\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n        metrics=[\'accuracy\'])\n    return model\n\n  # single node\n  # single_worker_model = build_and_compile_cnn_model()\n  # single_worker_model.fit(x=train_datasets, epochs=3)\n\n  # Here the batch size scales up by number of workers since\n  # `tf.data.Dataset.batch` expects the global batch size. Previously we used 64,\n  # and now this becomes 128.\n  GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n  train_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)\n\n  # this fails\n  # callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=args.model_dir)]\n  tf.io.gfile.makedirs(args.model_dir)\n  filepath = args.model_dir + ""/weights-{epoch:04d}""\n  callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_weights_only=True),\n    tf.keras.callbacks.TensorBoard(log_dir=args.model_dir)\n  ]\n\n  with strategy.scope():\n    multi_worker_model = build_and_compile_cnn_model()\n  multi_worker_model.fit(x=train_datasets, epochs=args.epochs, steps_per_epoch=args.steps_per_epoch, callbacks=callbacks)\n\n  from tensorflow_estimator.python.estimator.export import export_lib\n  export_dir = export_lib.get_timestamped_export_dir(args.export_dir)\n  compat.export_saved_model(multi_worker_model, export_dir, ctx.job_name == \'chief\')\n\n\nif __name__ == \'__main__\':\n  import argparse\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_keras""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--model_dir"", help=""path to save model/checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--steps_per_epoch"", help=""number of steps per epoch"", type=int, default=469)\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.TENSORFLOW, master_node=\'chief\', log_dir=args.model_dir)\n  cluster.shutdown()\n'"
examples/mnist/keras/mnist_tf_ds.py,24,"b'# Adapted from: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_keras\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\n\ndef main_fun(args, ctx):\n  """"""Example demonstrating loading TFRecords directly from disk (e.g. HDFS) without tensorflow_datasets.""""""\n  import tensorflow as tf\n  from tensorflowonspark import compat\n\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n\n  BUFFER_SIZE = args.buffer_size\n  BATCH_SIZE = args.batch_size\n  NUM_WORKERS = args.cluster_size\n\n  # parser for TFRecords downloaded by tensorflow_datasets\n  # these are images + labels, where the images are just serialized PNGs\n  def parse_tfds(x):\n    feature_def = {""label"": tf.io.FixedLenFeature(1, tf.int64), ""image"": tf.io.VarLenFeature(tf.string)}\n    example = tf.io.parse_single_example(x, feature_def)\n    image = tf.io.decode_image(example[\'image\'].values[0]) / 255\n    image.set_shape([28, 28, 1])     # fix for https://github.com/tensorflow/tensorflow/issues/24520\n    label = example[\'label\']\n    return (image, label)\n\n  # parser for TFRecords generated by ${TFoS_HOME}/examples/mnist/mnist_data_setup.py\n  # these are images + labels, where the images are a flattened arrays of ints\n  def parse_tfos(example_proto):\n    feature_def = {""label"": tf.io.FixedLenFeature(10, tf.int64),\n                   ""image"": tf.io.FixedLenFeature(28 * 28 * 1, tf.int64)}\n    features = tf.io.parse_single_example(example_proto, feature_def)\n    image = tf.cast(features[\'image\'], tf.float32) / 255\n    image = tf.reshape(image, (28, 28, 1))\n    label = tf.math.argmax(features[\'label\'], output_type=tf.int32)\n    return (image, label)\n\n  # Dataset for input data\n  # tfds: /path/to/tensorflow_datasets/mnist/1.0.0/mnist-train.tfrecord*\n  # tfos: /path/to/mnist/tfr/train/part-r-*\n  image_pattern = ctx.absolute_path(args.images_labels)\n\n  ds = tf.data.Dataset.list_files(image_pattern)\n  ds = ds.repeat(args.epochs).shuffle(BUFFER_SIZE)\n  ds = ds.interleave(tf.data.TFRecordDataset)\n\n  if args.data_format == \'tfds\':\n    train_datasets_unbatched = ds.map(parse_tfds)\n  else:  # \'tfos\'\n    train_datasets_unbatched = ds.map(parse_tfos)\n\n  def build_and_compile_cnn_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, activation=\'relu\', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation=\'relu\'),\n        tf.keras.layers.Dense(10, activation=\'softmax\')\n    ])\n    model.compile(\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n        metrics=[\'accuracy\'])\n    return model\n\n  # single node\n  # single_worker_model = build_and_compile_cnn_model()\n  # single_worker_model.fit(x=train_datasets, epochs=3)\n\n  # Here the batch size scales up by number of workers since\n  # `tf.data.Dataset.batch` expects the global batch size. Previously we used 64,\n  # and now this becomes 128.\n  GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n  train_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)\n\n  # this fails\n  # callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=args.model_dir)]\n  tf.io.gfile.makedirs(args.model_dir)\n  filepath = args.model_dir + ""/weights-{epoch:04d}""\n  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_weights_only=True)]\n\n  # Note: if you part files have an uneven number of records, you may see an ""Out of Range"" exception\n  # at less than the expected number of steps_per_epoch, because the executor with least amount of records will finish first.\n  steps_per_epoch = 60000 / GLOBAL_BATCH_SIZE\n\n  with strategy.scope():\n    multi_worker_model = build_and_compile_cnn_model()\n  multi_worker_model.fit(x=train_datasets, epochs=args.epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)\n\n  from tensorflow_estimator.python.estimator.export import export_lib\n  export_dir = export_lib.get_timestamped_export_dir(args.export_dir)\n  compat.export_saved_model(multi_worker_model, export_dir, ctx.job_name == \'chief\')\n\n\nif __name__ == \'__main__\':\n  import argparse\n  from pyspark.context import SparkContext\n  from pyspark.conf import SparkConf\n  from tensorflowonspark import TFCluster\n\n  sc = SparkContext(conf=SparkConf().setAppName(""mnist_keras""))\n  executors = sc._conf.get(""spark.executor.instances"")\n  num_executors = int(executors) if executors is not None else 1\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(""--batch_size"", help=""number of records per batch"", type=int, default=64)\n  parser.add_argument(""--buffer_size"", help=""size of shuffle buffer"", type=int, default=10000)\n  parser.add_argument(""--cluster_size"", help=""number of nodes in the cluster"", type=int, default=num_executors)\n  parser.add_argument(""--data_format"", help=""data format (tfos|tfds)"", type=str, choices=[""tfos"", ""tfds""], default=""tfos"")\n  parser.add_argument(""--epochs"", help=""number of epochs"", type=int, default=3)\n  parser.add_argument(""--images_labels"", help=""HDFS path to MNIST image_label files in parallelized format"")\n  parser.add_argument(""--model_dir"", help=""path to save model/checkpoint"", default=""mnist_model"")\n  parser.add_argument(""--export_dir"", help=""path to export saved_model"", default=""mnist_export"")\n  parser.add_argument(""--tensorboard"", help=""launch tensorboard process"", action=""store_true"")\n\n  args = parser.parse_args()\n  print(""args:"", args)\n\n  cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.TENSORFLOW, master_node=\'chief\')\n  cluster.shutdown()\n'"
