file_path,api_count,code
projects/chinese-character-recognition/chinese_character_recognition_bn.py,70,"b'# with batch norm\r\n\r\nimport os\r\nimport random\r\nimport tensorflow.contrib.slim as slim\r\nimport time\r\nimport logging\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport pickle\r\nfrom PIL import Image\r\nfrom tensorflow.python.ops import control_flow_ops\r\n\r\nos.environ[\'CUDA_VISIBLE_DEVICES\']=\'1\'\r\n\r\nlogger = logging.getLogger(\'Training a chinese write char recognition\')\r\nlogger.setLevel(logging.INFO)\r\n# formatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\r\nch = logging.StreamHandler()\r\nch.setLevel(logging.INFO)\r\nlogger.addHandler(ch)\r\n\r\n# \xe8\xae\xbe\xe7\xbd\xae\xe5\x85\xa8\xe5\xb1\x80\xe5\x8f\x98\xe9\x87\x8f\r\ntf.app.flags.DEFINE_boolean(\'random_flip_up_down\', False, ""Whether to random flip up down"")\r\ntf.app.flags.DEFINE_boolean(\'random_brightness\', True, ""whether to adjust brightness"")\r\ntf.app.flags.DEFINE_boolean(\'random_contrast\', True, ""whether to random constrast"")\r\n\r\ntf.app.flags.DEFINE_integer(\'charset_size\', 3755, ""Choose the first `charset_size` characters only."")\r\ntf.app.flags.DEFINE_integer(\'image_size\', 64, ""Needs to provide same value as in training."")\r\ntf.app.flags.DEFINE_boolean(\'gray\', True, ""whether to change the rbg to gray"")\r\ntf.app.flags.DEFINE_integer(\'max_steps\', 16002, \'the max training steps \')\r\ntf.app.flags.DEFINE_integer(\'eval_steps\', 100, ""the step num to eval"")\r\ntf.app.flags.DEFINE_integer(\'save_steps\', 500, ""the steps to save"")\r\n\r\ntf.app.flags.DEFINE_string(\'checkpoint_dir\', \'./checkpoint/\', \'the checkpoint dir\')\r\ntf.app.flags.DEFINE_string(\'train_data_dir\', \'./data/train/\', \'the train dataset dir\')\r\ntf.app.flags.DEFINE_string(\'test_data_dir\', \'./data/test/\', \'the test dataset dir\')\r\ntf.app.flags.DEFINE_string(\'log_dir\', \'./log/\', \'the logging dir\')\r\n\r\ntf.app.flags.DEFINE_boolean(\'restore\', False, \'whether to restore from checkpoint\')\r\ntf.app.flags.DEFINE_boolean(\'epoch\', 1, \'Number of epoches\')\r\ntf.app.flags.DEFINE_integer(\'batch_size\', 128, \'Validation batch size\')\r\ntf.app.flags.DEFINE_string(\'mode\', \'train\', \'Running mode. One of {""train"", ""valid"", ""test""}\')\r\n\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\n\r\nclass DataIterator:\r\n    def __init__(self, data_dir):\r\n        # Set FLAGS.charset_size to a small value if available computation power is limited.\r\n        truncate_path = data_dir + (\'%05d\' % FLAGS.charset_size)\r\n        print(truncate_path)\r\n        self.image_names = []\r\n        for root, sub_folder, file_list in os.walk(data_dir):\r\n            if root < truncate_path:\r\n                self.image_names += [os.path.join(root, file_path) for file_path in file_list]\r\n        random.shuffle(self.image_names)\r\n        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\r\n\r\n    @property\r\n    def size(self):\r\n        return len(self.labels)\r\n\r\n    @staticmethod\r\n    def data_augmentation(images):\r\n        if FLAGS.random_flip_up_down:\r\n            images = tf.image.random_flip_up_down(images)\r\n        if FLAGS.random_brightness:\r\n            images = tf.image.random_brightness(images, max_delta=0.3)\r\n        if FLAGS.random_contrast:\r\n            images = tf.image.random_contrast(images, 0.8, 1.2)\r\n        return images\r\n\r\n    def input_pipeline(self, batch_size, num_epochs=None, aug=False):\r\n        images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\r\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\r\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\r\n\r\n        labels = input_queue[1]\r\n        images_content = tf.read_file(input_queue[0])\r\n        images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\r\n        if aug:\r\n            images = self.data_augmentation(images)\r\n        new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\r\n        images = tf.image.resize_images(images, new_size)\r\n        image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\r\n                                                          min_after_dequeue=10000)\r\n        # print \'image_batch\', image_batch.get_shape()\r\n        return image_batch, label_batch\r\n\r\n\r\ndef build_graph(top_k):\r\n    keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name=\'keep_prob\')\r\n    images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name=\'image_batch\')\r\n    labels = tf.placeholder(dtype=tf.int64, shape=[None], name=\'label_batch\')\r\n    is_training = tf.placeholder(dtype=tf.bool, shape=[], name=\'train_flag\')\r\n    with tf.device(\'/gpu:1\'):\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                            normalizer_fn=slim.batch_norm,\r\n                            normalizer_params={\'is_training\': is_training}):\r\n            conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding=\'SAME\', scope=\'conv3_1\')\r\n            max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding=\'SAME\', scope=\'pool1\')\r\n            conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding=\'SAME\', scope=\'conv3_2\')\r\n            max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding=\'SAME\', scope=\'pool2\')\r\n            conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding=\'SAME\', scope=\'conv3_3\')\r\n            max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding=\'SAME\', scope=\'pool3\')\r\n            conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding=\'SAME\', scope=\'conv3_4\')\r\n            conv3_5 = slim.conv2d(conv3_4, 512, [3, 3], padding=\'SAME\', scope=\'conv3_5\')\r\n            max_pool_4 = slim.max_pool2d(conv3_5, [2, 2], [2, 2], padding=\'SAME\', scope=\'pool4\')\r\n\r\n            flatten = slim.flatten(max_pool_4)\r\n            fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\r\n                                       activation_fn=tf.nn.relu, scope=\'fc1\')\r\n            logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size, activation_fn=None,\r\n                                          scope=\'fc2\')\r\n        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\r\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\r\n\r\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n        if update_ops:\r\n            updates = tf.group(*update_ops)\r\n            loss = control_flow_ops.with_dependencies([updates], loss)\r\n\r\n        global_step = tf.get_variable(""step"", [], initializer=tf.constant_initializer(0.0), trainable=False)\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\r\n        train_op = slim.learning.create_train_op(loss, optimizer, global_step=global_step)\r\n        probabilities = tf.nn.softmax(logits)\r\n\r\n        tf.summary.scalar(\'loss\', loss)\r\n        tf.summary.scalar(\'accuracy\', accuracy)\r\n        merged_summary_op = tf.summary.merge_all()\r\n        predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\r\n        accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\r\n\r\n    return {\'images\': images,\r\n            \'labels\': labels,\r\n            \'keep_prob\': keep_prob,\r\n            \'top_k\': top_k,\r\n            \'global_step\': global_step,\r\n            \'train_op\': train_op,\r\n            \'loss\': loss,\r\n            \'is_training\': is_training,\r\n            \'accuracy\': accuracy,\r\n            \'accuracy_top_k\': accuracy_in_top_k,\r\n            \'merged_summary_op\': merged_summary_op,\r\n            \'predicted_distribution\': probabilities,\r\n            \'predicted_index_top_k\': predicted_index_top_k,\r\n            \'predicted_val_top_k\': predicted_val_top_k}\r\n\r\n\r\ndef train():\r\n    logger.info(\'Begin training\')\r\n    train_feeder = DataIterator(data_dir=\'./data/train/\')\r\n    test_feeder = DataIterator(data_dir=\'./data/test/\')\r\n    model_name = \'chinese-rec-model\'\r\n    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True)) as sess:\r\n        train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\r\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\r\n        graph = build_graph(top_k=1)\r\n        saver = tf.train.Saver()\r\n        sess.run(tf.global_variables_initializer())\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        train_writer = tf.summary.FileWriter(FLAGS.log_dir + \'/train\', sess.graph)\r\n        test_writer = tf.summary.FileWriter(FLAGS.log_dir + \'/val\')\r\n        start_step = 0\r\n        if FLAGS.restore:\r\n            ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\r\n            if ckpt:\r\n                saver.restore(sess, ckpt)\r\n                print(""restore from the checkpoint {0}"".format(ckpt))\r\n                start_step += int(ckpt.split(\'-\')[-1])\r\n\r\n        logger.info(\':::Training Start:::\')\r\n        try:\r\n            i = 0\r\n            while not coord.should_stop():\r\n                i += 1\r\n                start_time = time.time()\r\n                train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\r\n                feed_dict = {graph[\'images\']: train_images_batch,\r\n                             graph[\'labels\']: train_labels_batch,\r\n                             graph[\'keep_prob\']: 0.8,\r\n                             graph[\'is_training\']: True}\r\n                _, loss_val, train_summary, step = sess.run(\r\n                    [graph[\'train_op\'], graph[\'loss\'], graph[\'merged_summary_op\'], graph[\'global_step\']],\r\n                    feed_dict=feed_dict)\r\n                train_writer.add_summary(train_summary, step)\r\n                end_time = time.time()\r\n                logger.info(""the step {0} takes {1} loss {2}"".format(step, end_time - start_time, loss_val))\r\n                if step > FLAGS.max_steps:\r\n                    break\r\n                if step % FLAGS.eval_steps == 1:\r\n                    test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\r\n                    feed_dict = {graph[\'images\']: test_images_batch,\r\n                                 graph[\'labels\']: test_labels_batch,\r\n                                 graph[\'keep_prob\']: 1.0,\r\n                                 graph[\'is_training\']: False}\r\n                    accuracy_test, test_summary = sess.run([graph[\'accuracy\'], graph[\'merged_summary_op\']],\r\n                                                           feed_dict=feed_dict)\r\n                    if step > 300:\r\n                        test_writer.add_summary(test_summary, step)\r\n                    logger.info(\'===============Eval a batch=======================\')\r\n                    logger.info(\'the step {0} test accuracy: {1}\'\r\n                                .format(step, accuracy_test))\r\n                    logger.info(\'===============Eval a batch=======================\')\r\n                if step % FLAGS.save_steps == 1:\r\n                    logger.info(\'Save the ckpt of {0}\'.format(step))\r\n                    saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name),\r\n                               global_step=graph[\'global_step\'])\r\n        except tf.errors.OutOfRangeError:\r\n            logger.info(\'==================Train Finished================\')\r\n            saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name), global_step=graph[\'global_step\'])\r\n        finally:\r\n            coord.request_stop()\r\n        coord.join(threads)\r\n\r\n\r\ndef validation():\r\n    print(\'Begin validation\')\r\n    test_feeder = DataIterator(data_dir=\'./data/test/\')\r\n\r\n    final_predict_val = []\r\n    final_predict_index = []\r\n    groundtruth = []\r\n\r\n    with tf.Session() as sess:\r\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size, num_epochs=1)\r\n        graph = build_graph(top_k=3)\r\n        saver = tf.train.Saver()\r\n\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())  # initialize test_feeder\'s inside state\r\n\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\r\n        if ckpt:\r\n            saver.restore(sess, ckpt)\r\n            print(""restore from the checkpoint {0}"".format(ckpt))\r\n\r\n        logger.info(\':::Start validation:::\')\r\n        try:\r\n            i = 0\r\n            acc_top_1, acc_top_k = 0.0, 0.0\r\n            while not coord.should_stop():\r\n                i += 1\r\n                start_time = time.time()\r\n                test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\r\n                feed_dict = {graph[\'images\']: test_images_batch,\r\n                             graph[\'labels\']: test_labels_batch,\r\n                             graph[\'keep_prob\']: 1.0,\r\n                             graph[\'is_training\']: False}\r\n                batch_labels, probs, indices, acc_1, acc_k = sess.run([graph[\'labels\'],\r\n                                                                       graph[\'predicted_val_top_k\'],\r\n                                                                       graph[\'predicted_index_top_k\'],\r\n                                                                       graph[\'accuracy\'],\r\n                                                                       graph[\'accuracy_top_k\']], feed_dict=feed_dict)\r\n                final_predict_val += probs.tolist()\r\n                final_predict_index += indices.tolist()\r\n                groundtruth += batch_labels.tolist()\r\n                acc_top_1 += acc_1\r\n                acc_top_k += acc_k\r\n                end_time = time.time()\r\n                logger.info(""the batch {0} takes {1} seconds, accuracy = {2}(top_1) {3}(top_k)""\r\n                            .format(i, end_time - start_time, acc_1, acc_k))\r\n\r\n        except tf.errors.OutOfRangeError:\r\n            logger.info(\'==================Validation Finished================\')\r\n            acc_top_1 = acc_top_1 * FLAGS.batch_size / test_feeder.size\r\n            acc_top_k = acc_top_k * FLAGS.batch_size / test_feeder.size\r\n            logger.info(\'top 1 accuracy {0} top k accuracy {1}\'.format(acc_top_1, acc_top_k))\r\n        finally:\r\n            coord.request_stop()\r\n        coord.join(threads)\r\n    return {\'prob\': final_predict_val, \'indices\': final_predict_index, \'groundtruth\': groundtruth}\r\n\r\n\r\ndef inference(image):\r\n    print(\'inference\')\r\n    temp_image = Image.open(image).convert(\'L\')\r\n    temp_image = temp_image.resize((FLAGS.image_size, FLAGS.image_size), Image.ANTIALIAS)\r\n    temp_image = np.asarray(temp_image) / 255.0\r\n    temp_image = temp_image.reshape([-1, 64, 64, 1])\r\n    with tf.Session() as sess:\r\n        logger.info(\'========start inference============\')\r\n        # images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1])\r\n        # Pass a shadow label 0. This label will not affect the computation graph.\r\n        graph = build_graph(top_k=3)\r\n        saver = tf.train.Saver()\r\n        ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\r\n        if ckpt:\r\n            saver.restore(sess, ckpt)\r\n        predict_val, predict_index = sess.run([graph[\'predicted_val_top_k\'], graph[\'predicted_index_top_k\']],\r\n                                              feed_dict={graph[\'images\']: temp_image,\r\n                                                         graph[\'keep_prob\']: 1.0,\r\n                                                         graph[\'is_training\']: False})\r\n    return predict_val, predict_index\r\n\r\n\r\ndef main(_):\r\n    print(FLAGS.mode)\r\n    if FLAGS.mode == ""train"":\r\n        train()\r\n    elif FLAGS.mode == \'validation\':\r\n        dct = validation()\r\n        result_file = \'result.dict\'\r\n        logger.info(\'Write result into {0}\'.format(result_file))\r\n        with open(result_file, \'wb\') as f:\r\n            pickle.dump(dct, f)\r\n        logger.info(\'Write file ends\')\r\n    elif FLAGS.mode == \'inference\':\r\n        image_path = \'./data/test/00190/13320.png\'\r\n        final_predict_val, final_predict_index = inference(image_path)\r\n        logger.info(\'the result info label {0} predict index {1} predict_val {2}\'.format(190, final_predict_index,\r\n                                                                                         final_predict_val))\r\n\r\nif __name__ == ""__main__"":\r\n    tf.app.run()'"
projects/mnist-handwritten-digit-recognition/mnist_softmax.py,14,"b'# !/usr/bin/python\n# -*- coding:utf-8 -*-  \n# @author: Shengjia Yan\n# @date: 2018-01-09 Tuesday\n# @email: i@yanshengjia.com\n# Copyright 2018 Shengjia Yan. All Rights Reserved.\n\n""""""A very simple MNIST classifier.\n\nSee extensive documentation at\nhttps://www.tensorflow.org/get_started/mnist/beginners\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport argparse\nimport sys\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\n\nFLAGS = None\n\n\ndef main(_):\n    # Import data\n    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n\n    # Create the model\n    x = tf.placeholder(tf.float32, [None, 784])\n    W = tf.Variable(tf.zeros([784, 10]))\n    b = tf.Variable(tf.zeros([10]))\n    y = tf.matmul(x, W) + b\n\n    # Define loss and optimizer\n    y_ = tf.placeholder(tf.float32, [None, 10])\n\n    # The raw formulation of cross-entropy,\n    #\n    #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)), reduction_indices=[1]))\n    #\n    # can be numerically unstable.\n    #\n    # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n    # outputs of \'y\', and then average across the batch.\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n    sess = tf.InteractiveSession()\n    tf.global_variables_initializer().run()\n\n    # Train\n    for _ in range(1000):\n        batch_xs, batch_ys = mnist.train.next_batch(100)\n        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\n    # Test trained model\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data_dir\', type=str, default=\'/tmp/tensorflow/mnist/input_data\', help=\'Directory for storing input data\')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)'"
