file_path,api_count,code
main.py,6,"b'import tensorflow as tf\nfrom model import DTN\nfrom solver import Solver\n\nflags = tf.app.flags\nflags.DEFINE_string(\'mode\', \'train\', ""\'pretrain\', \'train\' or \'eval\'"")\nflags.DEFINE_string(\'model_save_path\', \'model\', ""directory for saving the model"")\nflags.DEFINE_string(\'sample_save_path\', \'sample\', ""directory for saving the sampled images"")\nFLAGS = flags.FLAGS\n\ndef main(_):\n    \n    model = DTN(mode=FLAGS.mode, learning_rate=0.0003)\n    solver = Solver(model, batch_size=100, pretrain_iter=20000, train_iter=2000, sample_iter=100, \n                    svhn_dir=\'svhn\', mnist_dir=\'mnist\', model_save_path=FLAGS.model_save_path, sample_save_path=FLAGS.sample_save_path)\n    \n    # create directories if not exist\n    if not tf.gfile.Exists(FLAGS.model_save_path):\n        tf.gfile.MakeDirs(FLAGS.model_save_path)\n    if not tf.gfile.Exists(FLAGS.sample_save_path):\n        tf.gfile.MakeDirs(FLAGS.sample_save_path)\n    \n    if FLAGS.mode == \'pretrain\':\n        solver.pretrain()\n    elif FLAGS.mode == \'train\':\n        solver.train()\n    else:\n        solver.eval()\n        \nif __name__ == \'__main__\':\n    tf.app.run()'"
model.py,57,"b'import tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n\nclass DTN(object):\n    """"""Domain Transfer Network\n    """"""\n    def __init__(self, mode=\'train\', learning_rate=0.0003):\n        self.mode = mode\n        self.learning_rate = learning_rate\n        \n    def content_extractor(self, images, reuse=False):\n        # images: (batch, 32, 32, 3) or (batch, 32, 32, 1)\n        \n        if images.get_shape()[3] == 1:\n            # For mnist dataset, replicate the gray scale image 3 times.\n            images = tf.image.grayscale_to_rgb(images)\n        \n        with tf.variable_scope(\'content_extractor\', reuse=reuse):\n            with slim.arg_scope([slim.conv2d], padding=\'SAME\', activation_fn=None,\n                                 stride=2,  weights_initializer=tf.contrib.layers.xavier_initializer()):\n                with slim.arg_scope([slim.batch_norm], decay=0.95, center=True, scale=True, \n                                    activation_fn=tf.nn.relu, is_training=(self.mode==\'train\' or self.mode==\'pretrain\')):\n                    \n                    net = slim.conv2d(images, 64, [3, 3], scope=\'conv1\')   # (batch_size, 16, 16, 64)\n                    net = slim.batch_norm(net, scope=\'bn1\')\n                    net = slim.conv2d(net, 128, [3, 3], scope=\'conv2\')     # (batch_size, 8, 8, 128)\n                    net = slim.batch_norm(net, scope=\'bn2\')\n                    net = slim.conv2d(net, 256, [3, 3], scope=\'conv3\')     # (batch_size, 4, 4, 256)\n                    net = slim.batch_norm(net, scope=\'bn3\')\n                    net = slim.conv2d(net, 128, [4, 4], padding=\'VALID\', scope=\'conv4\')   # (batch_size, 1, 1, 128)\n                    net = slim.batch_norm(net, activation_fn=tf.nn.tanh, scope=\'bn4\')\n                    if self.mode == \'pretrain\':\n                        net = slim.conv2d(net, 10, [1, 1], padding=\'VALID\', scope=\'out\')\n                        net = slim.flatten(net)\n                    return net\n                \n    def generator(self, inputs, reuse=False):\n        # inputs: (batch, 1, 1, 128)\n        with tf.variable_scope(\'generator\', reuse=reuse):\n            with slim.arg_scope([slim.conv2d_transpose], padding=\'SAME\', activation_fn=None,           \n                                 stride=2, weights_initializer=tf.contrib.layers.xavier_initializer()):\n                with slim.arg_scope([slim.batch_norm], decay=0.95, center=True, scale=True, \n                                     activation_fn=tf.nn.relu, is_training=(self.mode==\'train\')):\n\n                    net = slim.conv2d_transpose(inputs, 512, [4, 4], padding=\'VALID\', scope=\'conv_transpose1\')   # (batch_size, 4, 4, 512)\n                    net = slim.batch_norm(net, scope=\'bn1\')\n                    net = slim.conv2d_transpose(net, 256, [3, 3], scope=\'conv_transpose2\')  # (batch_size, 8, 8, 256)\n                    net = slim.batch_norm(net, scope=\'bn2\')\n                    net = slim.conv2d_transpose(net, 128, [3, 3], scope=\'conv_transpose3\')  # (batch_size, 16, 16, 128)\n                    net = slim.batch_norm(net, scope=\'bn3\')\n                    net = slim.conv2d_transpose(net, 1, [3, 3], activation_fn=tf.nn.tanh, scope=\'conv_transpose4\')   # (batch_size, 32, 32, 1)\n                    return net\n    \n    def discriminator(self, images, reuse=False):\n        # images: (batch, 32, 32, 1)\n        with tf.variable_scope(\'discriminator\', reuse=reuse):\n            with slim.arg_scope([slim.conv2d], padding=\'SAME\', activation_fn=None,\n                                 stride=2,  weights_initializer=tf.contrib.layers.xavier_initializer()):\n                with slim.arg_scope([slim.batch_norm], decay=0.95, center=True, scale=True, \n                                    activation_fn=tf.nn.relu, is_training=(self.mode==\'train\')):\n                    \n                    net = slim.conv2d(images, 128, [3, 3], activation_fn=tf.nn.relu, scope=\'conv1\')   # (batch_size, 16, 16, 128)\n                    net = slim.batch_norm(net, scope=\'bn1\')\n                    net = slim.conv2d(net, 256, [3, 3], scope=\'conv2\')   # (batch_size, 8, 8, 256)\n                    net = slim.batch_norm(net, scope=\'bn2\')\n                    net = slim.conv2d(net, 512, [3, 3], scope=\'conv3\')   # (batch_size, 4, 4, 512)\n                    net = slim.batch_norm(net, scope=\'bn3\')\n                    net = slim.conv2d(net, 1, [4, 4], padding=\'VALID\', scope=\'conv4\')   # (batch_size, 1, 1, 1)\n                    net = slim.flatten(net)\n                    return net\n                \n    def build_model(self):\n        \n        if self.mode == \'pretrain\':\n            self.images = tf.placeholder(tf.float32, [None, 32, 32, 3], \'svhn_images\')\n            self.labels = tf.placeholder(tf.int64, [None], \'svhn_labels\')\n            \n            # logits and accuracy\n            self.logits = self.content_extractor(self.images)\n            self.pred = tf.argmax(self.logits, 1)\n            self.correct_pred = tf.equal(self.pred, self.labels)\n            self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n\n            # loss and train op\n            self.loss = slim.losses.sparse_softmax_cross_entropy(self.logits, self.labels)\n            self.optimizer = tf.train.AdamOptimizer(self.learning_rate) \n            self.train_op = slim.learning.create_train_op(self.loss, self.optimizer)\n            \n            # summary op\n            loss_summary = tf.summary.scalar(\'classification_loss\', self.loss)\n            accuracy_summary = tf.summary.scalar(\'accuracy\', self.accuracy)\n            self.summary_op = tf.summary.merge([loss_summary, accuracy_summary])\n\n        elif self.mode == \'eval\':\n            self.images = tf.placeholder(tf.float32, [None, 32, 32, 3], \'svhn_images\')\n\n            # source domain (svhn to mnist)\n            self.fx = self.content_extractor(self.images)\n            self.sampled_images = self.generator(self.fx)\n\n        elif self.mode == \'train\':\n            self.src_images = tf.placeholder(tf.float32, [None, 32, 32, 3], \'svhn_images\')\n            self.trg_images = tf.placeholder(tf.float32, [None, 32, 32, 1], \'mnist_images\')\n            \n            # source domain (svhn to mnist)\n            self.fx = self.content_extractor(self.src_images)\n            self.fake_images = self.generator(self.fx)\n            self.logits = self.discriminator(self.fake_images)\n            self.fgfx = self.content_extractor(self.fake_images, reuse=True)\n\n            # loss\n            self.d_loss_src = slim.losses.sigmoid_cross_entropy(self.logits, tf.zeros_like(self.logits))\n            self.g_loss_src = slim.losses.sigmoid_cross_entropy(self.logits, tf.ones_like(self.logits))\n            self.f_loss_src = tf.reduce_mean(tf.square(self.fx - self.fgfx)) * 15.0\n            \n            # optimizer\n            self.d_optimizer_src = tf.train.AdamOptimizer(self.learning_rate)\n            self.g_optimizer_src = tf.train.AdamOptimizer(self.learning_rate)\n            self.f_optimizer_src = tf.train.AdamOptimizer(self.learning_rate)\n            \n            t_vars = tf.trainable_variables()\n            d_vars = [var for var in t_vars if \'discriminator\' in var.name]\n            g_vars = [var for var in t_vars if \'generator\' in var.name]\n            f_vars = [var for var in t_vars if \'content_extractor\' in var.name]\n            \n            # train op\n            with tf.name_scope(\'source_train_op\'):\n                self.d_train_op_src = slim.learning.create_train_op(self.d_loss_src, self.d_optimizer_src, variables_to_train=d_vars)\n                self.g_train_op_src = slim.learning.create_train_op(self.g_loss_src, self.g_optimizer_src, variables_to_train=g_vars)\n                self.f_train_op_src = slim.learning.create_train_op(self.f_loss_src, self.f_optimizer_src, variables_to_train=f_vars)\n            \n            # summary op\n            d_loss_src_summary = tf.summary.scalar(\'src_d_loss\', self.d_loss_src)\n            g_loss_src_summary = tf.summary.scalar(\'src_g_loss\', self.g_loss_src)\n            f_loss_src_summary = tf.summary.scalar(\'src_f_loss\', self.f_loss_src)\n            origin_images_summary = tf.summary.image(\'src_origin_images\', self.src_images)\n            sampled_images_summary = tf.summary.image(\'src_sampled_images\', self.fake_images)\n            self.summary_op_src = tf.summary.merge([d_loss_src_summary, g_loss_src_summary, \n                                                    f_loss_src_summary, origin_images_summary, \n                                                    sampled_images_summary])\n            \n            # target domain (mnist)\n            self.fx = self.content_extractor(self.trg_images, reuse=True)\n            self.reconst_images = self.generator(self.fx, reuse=True)\n            self.logits_fake = self.discriminator(self.reconst_images, reuse=True)\n            self.logits_real = self.discriminator(self.trg_images, reuse=True)\n            \n            # loss\n            self.d_loss_fake_trg = slim.losses.sigmoid_cross_entropy(self.logits_fake, tf.zeros_like(self.logits_fake))\n            self.d_loss_real_trg = slim.losses.sigmoid_cross_entropy(self.logits_real, tf.ones_like(self.logits_real))\n            self.d_loss_trg = self.d_loss_fake_trg + self.d_loss_real_trg\n            self.g_loss_fake_trg = slim.losses.sigmoid_cross_entropy(self.logits_fake, tf.ones_like(self.logits_fake))\n            self.g_loss_const_trg = tf.reduce_mean(tf.square(self.trg_images - self.reconst_images)) * 15.0\n            self.g_loss_trg = self.g_loss_fake_trg + self.g_loss_const_trg\n            \n            # optimizer\n            self.d_optimizer_trg = tf.train.AdamOptimizer(self.learning_rate)\n            self.g_optimizer_trg = tf.train.AdamOptimizer(self.learning_rate)\n\n            # train op\n            with tf.name_scope(\'target_train_op\'):\n                self.d_train_op_trg = slim.learning.create_train_op(self.d_loss_trg, self.d_optimizer_trg, variables_to_train=d_vars)\n                self.g_train_op_trg = slim.learning.create_train_op(self.g_loss_trg, self.g_optimizer_trg, variables_to_train=g_vars)\n            \n            # summary op\n            d_loss_fake_trg_summary = tf.summary.scalar(\'trg_d_loss_fake\', self.d_loss_fake_trg)\n            d_loss_real_trg_summary = tf.summary.scalar(\'trg_d_loss_real\', self.d_loss_real_trg)\n            d_loss_trg_summary = tf.summary.scalar(\'trg_d_loss\', self.d_loss_trg)\n            g_loss_fake_trg_summary = tf.summary.scalar(\'trg_g_loss_fake\', self.g_loss_fake_trg)\n            g_loss_const_trg_summary = tf.summary.scalar(\'trg_g_loss_const\', self.g_loss_const_trg)\n            g_loss_trg_summary = tf.summary.scalar(\'trg_g_loss\', self.g_loss_trg)\n            origin_images_summary = tf.summary.image(\'trg_origin_images\', self.trg_images)\n            sampled_images_summary = tf.summary.image(\'trg_reconstructed_images\', self.reconst_images)\n            self.summary_op_trg = tf.summary.merge([d_loss_trg_summary, g_loss_trg_summary, \n                                                    d_loss_fake_trg_summary, d_loss_real_trg_summary,\n                                                    g_loss_fake_trg_summary, g_loss_const_trg_summary,\n                                                    origin_images_summary, sampled_images_summary])\n            for var in tf.trainable_variables():\n                tf.summary.histogram(var.op.name, var)\n            '"
prepro.py,0,"b'import numpy as np\nimport pickle\nfrom PIL import Image\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n\ndef resize_images(image_arrays, size=[32, 32]):\n    # convert float type to integer \n    image_arrays = (image_arrays * 255).astype(\'uint8\')\n    \n    resized_image_arrays = np.zeros([image_arrays.shape[0]]+size)\n    for i, image_array in enumerate(image_arrays):\n        image = Image.fromarray(image_array)\n        resized_image = image.resize(size=size, resample=Image.ANTIALIAS)\n        \n        resized_image_arrays[i] = np.asarray(resized_image)\n    \n    return np.expand_dims(resized_image_arrays, 3)  \n\ndef save_pickle(data, path):\n    with open(path, \'wb\') as f:\n        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n        print (\'Saved %s..\' %path)\n\ndef main():\n    mnist = input_data.read_data_sets(train_dir=\'mnist\')\n\n    train = {\'X\': resize_images(mnist.train.images.reshape(-1, 28, 28)),\n             \'y\': mnist.train.labels}\n    \n    test = {\'X\': resize_images(mnist.test.images.reshape(-1, 28, 28)),\n            \'y\': mnist.test.labels}\n        \n    save_pickle(train, \'mnist/train.pkl\')\n    save_pickle(test, \'mnist/test.pkl\')\n    \n    \nif __name__ == ""__main__"":\n    main()\n    '"
solver.py,15,"b""import tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\nimport pickle\nimport os\nimport scipy.io\nimport scipy.misc\n\n\nclass Solver(object):\n\n    def __init__(self, model, batch_size=100, pretrain_iter=20000, train_iter=2000, sample_iter=100, \n                 svhn_dir='svhn', mnist_dir='mnist', log_dir='logs', sample_save_path='sample', \n                 model_save_path='model', pretrained_model='model/svhn_model-20000', test_model='model/dtn-1800'):\n        \n        self.model = model\n        self.batch_size = batch_size\n        self.pretrain_iter = pretrain_iter\n        self.train_iter = train_iter\n        self.sample_iter = sample_iter\n        self.svhn_dir = svhn_dir\n        self.mnist_dir = mnist_dir\n        self.log_dir = log_dir\n        self.sample_save_path = sample_save_path\n        self.model_save_path = model_save_path\n        self.pretrained_model = pretrained_model\n        self.test_model = test_model\n        self.config = tf.ConfigProto()\n        self.config.gpu_options.allow_growth=True\n\n    def load_svhn(self, image_dir, split='train'):\n        print ('loading svhn image dataset..')\n        \n        if self.model.mode == 'pretrain':\n            image_file = 'extra_32x32.mat' if split=='train' else 'test_32x32.mat'\n        else:\n            image_file = 'train_32x32.mat' if split=='train' else 'test_32x32.mat'\n            \n        image_dir = os.path.join(image_dir, image_file)\n        svhn = scipy.io.loadmat(image_dir)\n        images = np.transpose(svhn['X'], [3, 0, 1, 2]) / 127.5 - 1\n        labels = svhn['y'].reshape(-1)\n        labels[np.where(labels==10)] = 0\n        print ('finished loading svhn image dataset..!')\n        return images, labels\n\n    def load_mnist(self, image_dir, split='train'):\n        print ('loading mnist image dataset..')\n        image_file = 'train.pkl' if split=='train' else 'test.pkl'\n        image_dir = os.path.join(image_dir, image_file)\n        with open(image_dir, 'rb') as f:\n            mnist = pickle.load(f)\n        images = mnist['X'] / 127.5 - 1\n        labels = mnist['y']\n        print ('finished loading mnist image dataset..!')\n        return images, labels\n\n    def merge_images(self, sources, targets, k=10):\n        _, h, w, _ = sources.shape\n        row = int(np.sqrt(self.batch_size))\n        merged = np.zeros([row*h, row*w*2, 3])\n\n        for idx, (s, t) in enumerate(zip(sources, targets)):\n            i = idx // row\n            j = idx % row\n            merged[i*h:(i+1)*h, (j*2)*h:(j*2+1)*h, :] = s\n            merged[i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h, :] = t\n        return merged\n\n    def pretrain(self):\n        # load svhn dataset\n        train_images, train_labels = self.load_svhn(self.svhn_dir, split='train')\n        test_images, test_labels = self.load_svhn(self.svhn_dir, split='test')\n\n        # build a graph\n        model = self.model\n        model.build_model()\n        \n        with tf.Session(config=self.config) as sess:\n            tf.global_variables_initializer().run()\n            saver = tf.train.Saver()\n            summary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n\n            for step in range(self.pretrain_iter+1):\n                i = step % int(train_images.shape[0] / self.batch_size)\n                batch_images = train_images[i*self.batch_size:(i+1)*self.batch_size]\n                batch_labels = train_labels[i*self.batch_size:(i+1)*self.batch_size] \n                feed_dict = {model.images: batch_images, model.labels: batch_labels}\n                sess.run(model.train_op, feed_dict) \n\n                if (step+1) % 10 == 0:\n                    summary, l, acc = sess.run([model.summary_op, model.loss, model.accuracy], feed_dict)\n                    rand_idxs = np.random.permutation(test_images.shape[0])[:self.batch_size]\n                    test_acc, _ = sess.run(fetches=[model.accuracy, model.loss], \n                                           feed_dict={model.images: test_images[rand_idxs], \n                                                      model.labels: test_labels[rand_idxs]})\n                    summary_writer.add_summary(summary, step)\n                    print ('Step: [%d/%d] loss: [%.6f] train acc: [%.2f] test acc [%.2f]' \\\n                               %(step+1, self.pretrain_iter, l, acc, test_acc))\n\n                if (step+1) % 1000 == 0:  \n                    saver.save(sess, os.path.join(self.model_save_path, 'svhn_model'), global_step=step+1) \n                    print ('svhn_model-%d saved..!' %(step+1))\n\n    def train(self):\n        # load svhn dataset\n        svhn_images, _ = self.load_svhn(self.svhn_dir, split='train')\n        mnist_images, _ = self.load_mnist(self.mnist_dir, split='train')\n\n        # build a graph\n        model = self.model\n        model.build_model()\n\n        # make directory if not exists\n        if tf.gfile.Exists(self.log_dir):\n            tf.gfile.DeleteRecursively(self.log_dir)\n        tf.gfile.MakeDirs(self.log_dir)\n\n        with tf.Session(config=self.config) as sess:\n            # initialize G and D\n            tf.global_variables_initializer().run()\n            # restore variables of F\n            print ('loading pretrained model F..')\n            variables_to_restore = slim.get_model_variables(scope='content_extractor')\n            restorer = tf.train.Saver(variables_to_restore)\n            restorer.restore(sess, self.pretrained_model)\n            summary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n            saver = tf.train.Saver()\n\n            print ('start training..!')\n            f_interval = 15\n            for step in range(self.train_iter+1):\n                \n                i = step % int(svhn_images.shape[0] / self.batch_size)\n                # train the model for source domain S\n                src_images = svhn_images[i*self.batch_size:(i+1)*self.batch_size]\n                feed_dict = {model.src_images: src_images}\n                \n                sess.run(model.d_train_op_src, feed_dict) \n                sess.run([model.g_train_op_src], feed_dict)\n                sess.run([model.g_train_op_src], feed_dict) \n                sess.run([model.g_train_op_src], feed_dict) \n                sess.run([model.g_train_op_src], feed_dict) \n                sess.run([model.g_train_op_src], feed_dict) \n                sess.run([model.g_train_op_src], feed_dict)\n                \n                if step > 1600:\n                    f_interval = 30\n                \n                if i % f_interval == 0:\n                    sess.run(model.f_train_op_src, feed_dict)\n                \n                if (step+1) % 10 == 0:\n                    summary, dl, gl, fl = sess.run([model.summary_op_src, \\\n                        model.d_loss_src, model.g_loss_src, model.f_loss_src], feed_dict)\n                    summary_writer.add_summary(summary, step)\n                    print ('[Source] step: [%d/%d] d_loss: [%.6f] g_loss: [%.6f] f_loss: [%.6f]' \\\n                               %(step+1, self.train_iter, dl, gl, fl))\n                \n                # train the model for target domain T\n                j = step % int(mnist_images.shape[0] / self.batch_size)\n                trg_images = mnist_images[j*self.batch_size:(j+1)*self.batch_size]\n                feed_dict = {model.src_images: src_images, model.trg_images: trg_images}\n                sess.run(model.d_train_op_trg, feed_dict)\n                sess.run(model.d_train_op_trg, feed_dict)\n                sess.run(model.g_train_op_trg, feed_dict)\n                sess.run(model.g_train_op_trg, feed_dict)\n                sess.run(model.g_train_op_trg, feed_dict)\n                sess.run(model.g_train_op_trg, feed_dict)\n\n                if (step+1) % 10 == 0:\n                    summary, dl, gl = sess.run([model.summary_op_trg, \\\n                        model.d_loss_trg, model.g_loss_trg], feed_dict)\n                    summary_writer.add_summary(summary, step)\n                    print ('[Target] step: [%d/%d] d_loss: [%.6f] g_loss: [%.6f]' \\\n                               %(step+1, self.train_iter, dl, gl))\n\n                if (step+1) % 200 == 0:\n                    saver.save(sess, os.path.join(self.model_save_path, 'dtn'), global_step=step+1)\n                    print ('model/dtn-%d saved' %(step+1))\n                \n    def eval(self):\n        # build model\n        model = self.model\n        model.build_model()\n\n        # load svhn dataset\n        svhn_images, _ = self.load_svhn(self.svhn_dir)\n\n        with tf.Session(config=self.config) as sess:\n            # load trained parameters\n            print ('loading test model..')\n            saver = tf.train.Saver()\n            saver.restore(sess, self.test_model)\n\n            print ('start sampling..!')\n            for i in range(self.sample_iter):\n                # train model for source domain S\n                batch_images = svhn_images[i*self.batch_size:(i+1)*self.batch_size]\n                feed_dict = {model.images: batch_images}\n                sampled_batch_images = sess.run(model.sampled_images, feed_dict)\n\n                # merge and save source images and sampled target images\n                merged = self.merge_images(batch_images, sampled_batch_images)\n                path = os.path.join(self.sample_save_path, 'sample-%d-to-%d.png' %(i*self.batch_size, (i+1)*self.batch_size))\n                scipy.misc.imsave(path, merged)\n                print ('saved %s' %path)"""
