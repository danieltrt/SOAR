file_path,api_count,code
convert.py,2,"b""from absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport numpy as np\nfrom yolov3_tf2.models import YoloV3, YoloV3Tiny\nfrom yolov3_tf2.utils import load_darknet_weights\nimport tensorflow as tf\n\nflags.DEFINE_string('weights', './data/yolov3.weights', 'path to weights file')\nflags.DEFINE_string('output', './checkpoints/yolov3.tf', 'path to output')\nflags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\nflags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n\n\ndef main(_argv):\n    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n    if len(physical_devices) > 0:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n    if FLAGS.tiny:\n        yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n    else:\n        yolo = YoloV3(classes=FLAGS.num_classes)\n    yolo.summary()\n    logging.info('model created')\n\n    load_darknet_weights(yolo, FLAGS.weights, FLAGS.tiny)\n    logging.info('weights loaded')\n\n    img = np.random.random((1, 320, 320, 3)).astype(np.float32)\n    output = yolo(img)\n    logging.info('sanity check passed')\n\n    yolo.save_weights(FLAGS.output)\n    logging.info('weights saved')\n\n\nif __name__ == '__main__':\n    try:\n        app.run(main)\n    except SystemExit:\n        pass\n"""
detect.py,4,"b""import time\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny\n)\nfrom yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\nfrom yolov3_tf2.utils import draw_outputs\n\nflags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\nflags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n                    'path to weights file')\nflags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\nflags.DEFINE_integer('size', 416, 'resize images to')\nflags.DEFINE_string('image', './data/girl.png', 'path to input image')\nflags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\nflags.DEFINE_string('output', './output.jpg', 'path to output image')\nflags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n\n\ndef main(_argv):\n    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n    for physical_device in physical_devices:\n        tf.config.experimental.set_memory_growth(physical_device, True)\n\n    if FLAGS.tiny:\n        yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n    else:\n        yolo = YoloV3(classes=FLAGS.num_classes)\n\n    yolo.load_weights(FLAGS.weights).expect_partial()\n    logging.info('weights loaded')\n\n    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n    logging.info('classes loaded')\n\n    if FLAGS.tfrecord:\n        dataset = load_tfrecord_dataset(\n            FLAGS.tfrecord, FLAGS.classes, FLAGS.size)\n        dataset = dataset.shuffle(512)\n        img_raw, _label = next(iter(dataset.take(1)))\n    else:\n        img_raw = tf.image.decode_image(\n            open(FLAGS.image, 'rb').read(), channels=3)\n\n    img = tf.expand_dims(img_raw, 0)\n    img = transform_images(img, FLAGS.size)\n\n    t1 = time.time()\n    boxes, scores, classes, nums = yolo(img)\n    t2 = time.time()\n    logging.info('time: {}'.format(t2 - t1))\n\n    logging.info('detections:')\n    for i in range(nums[0]):\n        logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n                                           np.array(scores[0][i]),\n                                           np.array(boxes[0][i])))\n\n    img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n    img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n    cv2.imwrite(FLAGS.output, img)\n    logging.info('output saved to: {}'.format(FLAGS.output))\n\n\nif __name__ == '__main__':\n    try:\n        app.run(main)\n    except SystemExit:\n        pass\n"""
detect_video.py,3,"b'import time\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport cv2\nimport tensorflow as tf\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny\n)\nfrom yolov3_tf2.dataset import transform_images\nfrom yolov3_tf2.utils import draw_outputs\n\n\nflags.DEFINE_string(\'classes\', \'./data/coco.names\', \'path to classes file\')\nflags.DEFINE_string(\'weights\', \'./checkpoints/yolov3.tf\',\n                    \'path to weights file\')\nflags.DEFINE_boolean(\'tiny\', False, \'yolov3 or yolov3-tiny\')\nflags.DEFINE_integer(\'size\', 416, \'resize images to\')\nflags.DEFINE_string(\'video\', \'./data/video.mp4\',\n                    \'path to video file or number for webcam)\')\nflags.DEFINE_string(\'output\', None, \'path to output video\')\nflags.DEFINE_string(\'output_format\', \'XVID\', \'codec used in VideoWriter when saving video to file\')\nflags.DEFINE_integer(\'num_classes\', 80, \'number of classes in the model\')\n\n\ndef main(_argv):\n    physical_devices = tf.config.experimental.list_physical_devices(\'GPU\')\n    for physical_device in physical_devices:\n        tf.config.experimental.set_memory_growth(physical_device, True)\n\n    if FLAGS.tiny:\n        yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n    else:\n        yolo = YoloV3(classes=FLAGS.num_classes)\n\n    yolo.load_weights(FLAGS.weights)\n    logging.info(\'weights loaded\')\n\n    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n    logging.info(\'classes loaded\')\n\n    times = []\n\n    try:\n        vid = cv2.VideoCapture(int(FLAGS.video))\n    except:\n        vid = cv2.VideoCapture(FLAGS.video)\n\n    out = None\n\n    if FLAGS.output:\n        # by default VideoCapture returns float instead of int\n        width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = int(vid.get(cv2.CAP_PROP_FPS))\n        codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)\n        out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))\n\n    while True:\n        _, img = vid.read()\n\n        if img is None:\n            logging.warning(""Empty Frame"")\n            time.sleep(0.1)\n            continue\n\n        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_in = tf.expand_dims(img_in, 0)\n        img_in = transform_images(img_in, FLAGS.size)\n\n        t1 = time.time()\n        boxes, scores, classes, nums = yolo.predict(img_in)\n        t2 = time.time()\n        times.append(t2-t1)\n        times = times[-20:]\n\n        img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n        img = cv2.putText(img, ""Time: {:.2f}ms"".format(sum(times)/len(times)*1000), (0, 30),\n                          cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n        if FLAGS.output:\n            out.write(img)\n        cv2.imshow(\'output\', img)\n        if cv2.waitKey(1) == ord(\'q\'):\n            break\n\n    cv2.destroyAllWindows()\n\n\nif __name__ == \'__main__\':\n    try:\n        app.run(main)\n    except SystemExit:\n        pass\n'"
setup.py,0,"b""from setuptools import setup\n\nsetup(name='yolov3_tf2',\n      version='0.1',\n      url='https://github.com/zzh8829/yolov3-tf2',\n      author='Zihao Zhang',\n      author_email='zzh8829@gmail.com',\n      packages=['yolov3_tf2'])"""
train.py,11,"b'from absl import app, flags, logging\nfrom absl.flags import FLAGS\n\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.callbacks import (\n    ReduceLROnPlateau,\n    EarlyStopping,\n    ModelCheckpoint,\n    TensorBoard\n)\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny, YoloLoss,\n    yolo_anchors, yolo_anchor_masks,\n    yolo_tiny_anchors, yolo_tiny_anchor_masks\n)\nfrom yolov3_tf2.utils import freeze_all\nimport yolov3_tf2.dataset as dataset\n\nflags.DEFINE_string(\'dataset\', \'\', \'path to dataset\')\nflags.DEFINE_string(\'val_dataset\', \'\', \'path to validation dataset\')\nflags.DEFINE_boolean(\'tiny\', False, \'yolov3 or yolov3-tiny\')\nflags.DEFINE_string(\'weights\', \'./checkpoints/yolov3.tf\',\n                    \'path to weights file\')\nflags.DEFINE_string(\'classes\', \'./data/coco.names\', \'path to classes file\')\nflags.DEFINE_enum(\'mode\', \'fit\', [\'fit\', \'eager_fit\', \'eager_tf\'],\n                  \'fit: model.fit, \'\n                  \'eager_fit: model.fit(run_eagerly=True), \'\n                  \'eager_tf: custom GradientTape\')\nflags.DEFINE_enum(\'transfer\', \'none\',\n                  [\'none\', \'darknet\', \'no_output\', \'frozen\', \'fine_tune\'],\n                  \'none: Training from scratch, \'\n                  \'darknet: Transfer darknet, \'\n                  \'no_output: Transfer all but output, \'\n                  \'frozen: Transfer and freeze all, \'\n                  \'fine_tune: Transfer all and freeze darknet only\')\nflags.DEFINE_integer(\'size\', 416, \'image size\')\nflags.DEFINE_integer(\'epochs\', 2, \'number of epochs\')\nflags.DEFINE_integer(\'batch_size\', 8, \'batch size\')\nflags.DEFINE_float(\'learning_rate\', 1e-3, \'learning rate\')\nflags.DEFINE_integer(\'num_classes\', 80, \'number of classes in the model\')\nflags.DEFINE_integer(\'weights_num_classes\', None, \'specify num class for `weights` file if different, \'\n                     \'useful in transfer learning with different number of classes\')\n\n\ndef main(_argv):\n    physical_devices = tf.config.experimental.list_physical_devices(\'GPU\')\n    for physical_device in physical_devices:\n        tf.config.experimental.set_memory_growth(physical_device, True)\n\n    if FLAGS.tiny:\n        model = YoloV3Tiny(FLAGS.size, training=True,\n                           classes=FLAGS.num_classes)\n        anchors = yolo_tiny_anchors\n        anchor_masks = yolo_tiny_anchor_masks\n    else:\n        model = YoloV3(FLAGS.size, training=True, classes=FLAGS.num_classes)\n        anchors = yolo_anchors\n        anchor_masks = yolo_anchor_masks\n\n    train_dataset = dataset.load_fake_dataset()\n    if FLAGS.dataset:\n        train_dataset = dataset.load_tfrecord_dataset(\n            FLAGS.dataset, FLAGS.classes, FLAGS.size)\n    train_dataset = train_dataset.shuffle(buffer_size=512)\n    train_dataset = train_dataset.batch(FLAGS.batch_size)\n    train_dataset = train_dataset.map(lambda x, y: (\n        dataset.transform_images(x, FLAGS.size),\n        dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))\n    train_dataset = train_dataset.prefetch(\n        buffer_size=tf.data.experimental.AUTOTUNE)\n\n    val_dataset = dataset.load_fake_dataset()\n    if FLAGS.val_dataset:\n        val_dataset = dataset.load_tfrecord_dataset(\n            FLAGS.val_dataset, FLAGS.classes, FLAGS.size)\n    val_dataset = val_dataset.batch(FLAGS.batch_size)\n    val_dataset = val_dataset.map(lambda x, y: (\n        dataset.transform_images(x, FLAGS.size),\n        dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))\n\n    # Configure the model for transfer learning\n    if FLAGS.transfer == \'none\':\n        pass  # Nothing to do\n    elif FLAGS.transfer in [\'darknet\', \'no_output\']:\n        # Darknet transfer is a special case that works\n        # with incompatible number of classes\n\n        # reset top layers\n        if FLAGS.tiny:\n            model_pretrained = YoloV3Tiny(\n                FLAGS.size, training=True, classes=FLAGS.weights_num_classes or FLAGS.num_classes)\n        else:\n            model_pretrained = YoloV3(\n                FLAGS.size, training=True, classes=FLAGS.weights_num_classes or FLAGS.num_classes)\n        model_pretrained.load_weights(FLAGS.weights)\n\n        if FLAGS.transfer == \'darknet\':\n            model.get_layer(\'yolo_darknet\').set_weights(\n                model_pretrained.get_layer(\'yolo_darknet\').get_weights())\n            freeze_all(model.get_layer(\'yolo_darknet\'))\n\n        elif FLAGS.transfer == \'no_output\':\n            for l in model.layers:\n                if not l.name.startswith(\'yolo_output\'):\n                    l.set_weights(model_pretrained.get_layer(\n                        l.name).get_weights())\n                    freeze_all(l)\n\n    else:\n        # All other transfer require matching classes\n        model.load_weights(FLAGS.weights)\n        if FLAGS.transfer == \'fine_tune\':\n            # freeze darknet and fine tune other layers\n            darknet = model.get_layer(\'yolo_darknet\')\n            freeze_all(darknet)\n        elif FLAGS.transfer == \'frozen\':\n            # freeze everything\n            freeze_all(model)\n\n    optimizer = tf.keras.optimizers.Adam(lr=FLAGS.learning_rate)\n    loss = [YoloLoss(anchors[mask], classes=FLAGS.num_classes)\n            for mask in anchor_masks]\n\n    if FLAGS.mode == \'eager_tf\':\n        # Eager mode is great for debugging\n        # Non eager graph mode is recommended for real training\n        avg_loss = tf.keras.metrics.Mean(\'loss\', dtype=tf.float32)\n        avg_val_loss = tf.keras.metrics.Mean(\'val_loss\', dtype=tf.float32)\n\n        for epoch in range(1, FLAGS.epochs + 1):\n            for batch, (images, labels) in enumerate(train_dataset):\n                with tf.GradientTape() as tape:\n                    outputs = model(images, training=True)\n                    regularization_loss = tf.reduce_sum(model.losses)\n                    pred_loss = []\n                    for output, label, loss_fn in zip(outputs, labels, loss):\n                        pred_loss.append(loss_fn(label, output))\n                    total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n\n                grads = tape.gradient(total_loss, model.trainable_variables)\n                optimizer.apply_gradients(\n                    zip(grads, model.trainable_variables))\n\n                logging.info(""{}_train_{}, {}, {}"".format(\n                    epoch, batch, total_loss.numpy(),\n                    list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n                avg_loss.update_state(total_loss)\n\n            for batch, (images, labels) in enumerate(val_dataset):\n                outputs = model(images)\n                regularization_loss = tf.reduce_sum(model.losses)\n                pred_loss = []\n                for output, label, loss_fn in zip(outputs, labels, loss):\n                    pred_loss.append(loss_fn(label, output))\n                total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n\n                logging.info(""{}_val_{}, {}, {}"".format(\n                    epoch, batch, total_loss.numpy(),\n                    list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n                avg_val_loss.update_state(total_loss)\n\n            logging.info(""{}, train: {}, val: {}"".format(\n                epoch,\n                avg_loss.result().numpy(),\n                avg_val_loss.result().numpy()))\n\n            avg_loss.reset_states()\n            avg_val_loss.reset_states()\n            model.save_weights(\n                \'checkpoints/yolov3_train_{}.tf\'.format(epoch))\n    else:\n        model.compile(optimizer=optimizer, loss=loss,\n                      run_eagerly=(FLAGS.mode == \'eager_fit\'))\n\n        callbacks = [\n            ReduceLROnPlateau(verbose=1),\n            EarlyStopping(patience=3, verbose=1),\n            ModelCheckpoint(\'checkpoints/yolov3_train_{epoch}.tf\',\n                            verbose=1, save_weights_only=True),\n            TensorBoard(log_dir=\'logs\')\n        ]\n\n        history = model.fit(train_dataset,\n                            epochs=FLAGS.epochs,\n                            callbacks=callbacks,\n                            validation_data=val_dataset)\n\n\nif __name__ == \'__main__\':\n    try:\n        app.run(main)\n    except SystemExit:\n        pass\n'"
tools/export_tflite.py,4,"b'import time\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny\n)\nfrom yolov3_tf2.dataset import transform_images\n\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.util import nest\n\nflags.DEFINE_string(\'weights\', \'./checkpoints/yolov3.tf\',\n                    \'path to weights file\')\nflags.DEFINE_boolean(\'tiny\', False, \'yolov3 or yolov3-tiny\')\nflags.DEFINE_string(\'output\', \'./checkpoints/yolov3.tflite\',\n                    \'path to saved_model\')\nflags.DEFINE_string(\'classes\', \'./data/coco.names\', \'path to classes file\')\nflags.DEFINE_string(\'image\', \'./data/girl.png\', \'path to input image\')\nflags.DEFINE_integer(\'num_classes\', 80, \'number of classes in the model\')\nflags.DEFINE_integer(\'size\', 416, \'image size\')\n\n# TODO: This is broken DOES NOT WORK !!\ndef main(_argv):\n    if FLAGS.tiny:\n        yolo = YoloV3Tiny(size=FLAGS.size, classes=FLAGS.num_classes)\n    else:\n        yolo = YoloV3(size=FLAGS.size, classes=FLAGS.num_classes)\n\n    yolo.load_weights(FLAGS.weights)\n    logging.info(\'weights loaded\')\n\n    converter = tf.lite.TFLiteConverter.from_keras_model(yolo)\n    tflite_model = converter.convert()\n    open(FLAGS.output, \'wb\').write(tflite_model)\n    logging.info(""model saved to: {}"".format(FLAGS.output))\n\n    interpreter = tf.lite.Interpreter(model_path=FLAGS.output)\n    interpreter.allocate_tensors()\n    logging.info(\'tflite model loaded\')\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n    logging.info(\'classes loaded\')\n\n    img = tf.image.decode_image(open(FLAGS.image, \'rb\').read(), channels=3)\n    img = tf.expand_dims(img, 0)\n    img = transform_images(img, 416)\n\n    t1 = time.time()\n    outputs = interpreter.set_tensor(input_details[0][\'index\'], img)\n\n    interpreter.invoke()\n\n    output_data = interpreter.get_tensor(output_details[0][\'index\'])\n\n    print(output_data)\n\nif __name__ == \'__main__\':\n    app.run(main)\n'"
tools/export_tfserving.py,5,"b'import time\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny\n)\nfrom yolov3_tf2.dataset import transform_images\n\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.util import nest\n\nflags.DEFINE_string(\'weights\', \'./checkpoints/yolov3.tf\',\n                    \'path to weights file\')\nflags.DEFINE_boolean(\'tiny\', False, \'yolov3 or yolov3-tiny\')\nflags.DEFINE_string(\'output\', \'./serving/yolov3/1\', \'path to saved_model\')\nflags.DEFINE_string(\'classes\', \'./data/coco.names\', \'path to classes file\')\nflags.DEFINE_string(\'image\', \'./data/girl.png\', \'path to input image\')\nflags.DEFINE_integer(\'num_classes\', 80, \'number of classes in the model\')\n\n\ndef main(_argv):\n    if FLAGS.tiny:\n        yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n    else:\n        yolo = YoloV3(classes=FLAGS.num_classes)\n\n    yolo.load_weights(FLAGS.weights)\n    logging.info(\'weights loaded\')\n\n    tf.saved_model.save(yolo, FLAGS.output)\n    logging.info(""model saved to: {}"".format(FLAGS.output))\n\n    model = tf.saved_model.load(FLAGS.output)\n    infer = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n    logging.info(infer.structured_outputs)\n\n    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n    logging.info(\'classes loaded\')\n\n    img = tf.image.decode_image(open(FLAGS.image, \'rb\').read(), channels=3)\n    img = tf.expand_dims(img, 0)\n    img = transform_images(img, 416)\n\n    t1 = time.time()\n    outputs = infer(img)\n    boxes, scores, classes, nums = outputs[""yolo_nms""], outputs[\n        ""yolo_nms_1""], outputs[""yolo_nms_2""], outputs[""yolo_nms_3""]\n    t2 = time.time()\n    logging.info(\'time: {}\'.format(t2 - t1))\n\n    logging.info(\'detections:\')\n    for i in range(nums[0]):\n        logging.info(\'\\t{}, {}, {}\'.format(class_names[int(classes[0][i])],\n                                           scores[0][i].numpy(),\n                                           boxes[0][i].numpy()))\n\n\nif __name__ == \'__main__\':\n    try:\n        app.run(main)\n    except SystemExit:\n        pass\n'"
tools/visualize_dataset.py,0,"b""import time\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom yolov3_tf2.models import (\n    YoloV3, YoloV3Tiny\n)\nfrom yolov3_tf2.dataset import load_tfrecord_dataset, transform_images\nfrom yolov3_tf2.utils import draw_outputs\n\nflags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\nflags.DEFINE_integer('size', 416, 'resize images to')\nflags.DEFINE_string(\n    'dataset', './data/voc2012_train.tfrecord', 'path to dataset')\nflags.DEFINE_string('output', './output.jpg', 'path to output image')\n\n\ndef main(_argv):\n    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n    logging.info('classes loaded')\n\n    dataset = load_tfrecord_dataset(FLAGS.dataset, FLAGS.classes, FLAGS.size)\n    dataset = dataset.shuffle(512)\n\n    for image, labels in dataset.take(1):\n        boxes = []\n        scores = []\n        classes = []\n        for x1, y1, x2, y2, label in labels:\n            if x1 == 0 and x2 == 0:\n                continue\n\n            boxes.append((x1, y1, x2, y2))\n            scores.append(1)\n            classes.append(label)\n        nums = [len(boxes)]\n        boxes = [boxes]\n        scores = [scores]\n        classes = [classes]\n\n        logging.info('labels:')\n        for i in range(nums[0]):\n            logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n                                               np.array(scores[0][i]),\n                                               np.array(boxes[0][i])))\n\n        img = cv2.cvtColor(image.numpy(), cv2.COLOR_RGB2BGR)\n        img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n        cv2.imwrite(FLAGS.output, img)\n        logging.info('output saved to: {}'.format(FLAGS.output))\n\n\nif __name__ == '__main__':\n    app.run(main)\n"""
tools/voc2012.py,18,"b'import time\nimport os\nimport hashlib\n\nfrom absl import app, flags, logging\nfrom absl.flags import FLAGS\nimport tensorflow as tf\nimport lxml.etree\nimport tqdm\n\nflags.DEFINE_string(\'data_dir\', \'./data/voc2012_raw/VOCdevkit/VOC2012/\',\n                    \'path to raw PASCAL VOC dataset\')\nflags.DEFINE_enum(\'split\', \'train\', [\n                  \'train\', \'val\'], \'specify train or val spit\')\nflags.DEFINE_string(\'output_file\', \'./data/voc2012_train.tfrecord\', \'outpot dataset\')\nflags.DEFINE_string(\'classes\', \'./data/voc2012.names\', \'classes file\')\n\n\ndef build_example(annotation, class_map):\n    img_path = os.path.join(\n        FLAGS.data_dir, \'JPEGImages\', annotation[\'filename\'])\n    img_raw = open(img_path, \'rb\').read()\n    key = hashlib.sha256(img_raw).hexdigest()\n\n    width = int(annotation[\'size\'][\'width\'])\n    height = int(annotation[\'size\'][\'height\'])\n\n    xmin = []\n    ymin = []\n    xmax = []\n    ymax = []\n    classes = []\n    classes_text = []\n    truncated = []\n    views = []\n    difficult_obj = []\n    if \'object\' in annotation:\n        for obj in annotation[\'object\']:\n            difficult = bool(int(obj[\'difficult\']))\n            difficult_obj.append(int(difficult))\n\n            xmin.append(float(obj[\'bndbox\'][\'xmin\']) / width)\n            ymin.append(float(obj[\'bndbox\'][\'ymin\']) / height)\n            xmax.append(float(obj[\'bndbox\'][\'xmax\']) / width)\n            ymax.append(float(obj[\'bndbox\'][\'ymax\']) / height)\n            classes_text.append(obj[\'name\'].encode(\'utf8\'))\n            classes.append(class_map[obj[\'name\']])\n            truncated.append(int(obj[\'truncated\']))\n            views.append(obj[\'pose\'].encode(\'utf8\'))\n\n    example = tf.train.Example(features=tf.train.Features(feature={\n        \'image/height\': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        \'image/width\': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        \'image/filename\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n            annotation[\'filename\'].encode(\'utf8\')])),\n        \'image/source_id\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n            annotation[\'filename\'].encode(\'utf8\')])),\n        \'image/key/sha256\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode(\'utf8\')])),\n        \'image/encoded\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n        \'image/format\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\'jpeg\'.encode(\'utf8\')])),\n        \'image/object/bbox/xmin\': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n        \'image/object/bbox/xmax\': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n        \'image/object/bbox/ymin\': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n        \'image/object/bbox/ymax\': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n        \'image/object/class/text\': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n        \'image/object/class/label\': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n        \'image/object/difficult\': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult_obj)),\n        \'image/object/truncated\': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n        \'image/object/view\': tf.train.Feature(bytes_list=tf.train.BytesList(value=views)),\n    }))\n    return example\n\n\ndef parse_xml(xml):\n    if not len(xml):\n        return {xml.tag: xml.text}\n    result = {}\n    for child in xml:\n        child_result = parse_xml(child)\n        if child.tag != \'object\':\n            result[child.tag] = child_result[child.tag]\n        else:\n            if child.tag not in result:\n                result[child.tag] = []\n            result[child.tag].append(child_result[child.tag])\n    return {xml.tag: result}\n\n\ndef main(_argv):\n    class_map = {name: idx for idx, name in enumerate(\n        open(FLAGS.classes).read().splitlines())}\n    logging.info(""Class mapping loaded: %s"", class_map)\n\n    writer = tf.io.TFRecordWriter(FLAGS.output_file)\n    image_list = open(os.path.join(\n        FLAGS.data_dir, \'ImageSets\', \'Main\', \'aeroplane_%s.txt\' % FLAGS.split)).read().splitlines()\n    logging.info(""Image list loaded: %d"", len(image_list))\n    for image in tqdm.tqdm(image_list):\n        name, _ = image.split()\n        annotation_xml = os.path.join(\n            FLAGS.data_dir, \'Annotations\', name + \'.xml\')\n        annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n        annotation = parse_xml(annotation_xml)[\'annotation\']\n        tf_example = build_example(annotation, class_map)\n        writer.write(tf_example.SerializeToString())\n    writer.close()\n    logging.info(""Done"")\n\n\nif __name__ == \'__main__\':\n    app.run(main)\n'"
yolov3_tf2/__init__.py,0,b''
yolov3_tf2/dataset.py,64,"b'import tensorflow as tf\nfrom absl.flags import FLAGS\n\n@tf.function\ndef transform_targets_for_output(y_true, grid_size, anchor_idxs):\n    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))\n    N = tf.shape(y_true)[0]\n\n    # y_true_out: (N, grid, grid, anchors, [x, y, w, h, obj, class])\n    y_true_out = tf.zeros(\n        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n\n    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n\n    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n    idx = 0\n    for i in tf.range(N):\n        for j in tf.range(tf.shape(y_true)[1]):\n            if tf.equal(y_true[i][j][2], 0):\n                continue\n            anchor_eq = tf.equal(\n                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n\n            if tf.reduce_any(anchor_eq):\n                box = y_true[i][j][0:4]\n                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\n\n                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\n\n                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)\n                indexes = indexes.write(\n                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n                updates = updates.write(\n                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\n                idx += 1\n\n    # tf.print(indexes.stack())\n    # tf.print(updates.stack())\n\n    return tf.tensor_scatter_nd_update(\n        y_true_out, indexes.stack(), updates.stack())\n\n\ndef transform_targets(y_train, anchors, anchor_masks, size):\n    y_outs = []\n    grid_size = size // 32\n\n    # calculate anchor index for true boxes\n    anchors = tf.cast(anchors, tf.float32)\n    anchor_area = anchors[..., 0] * anchors[..., 1]\n    box_wh = y_train[..., 2:4] - y_train[..., 0:2]\n    box_wh = tf.tile(tf.expand_dims(box_wh, -2),\n                     (1, 1, tf.shape(anchors)[0], 1))\n    box_area = box_wh[..., 0] * box_wh[..., 1]\n    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\n        tf.minimum(box_wh[..., 1], anchors[..., 1])\n    iou = intersection / (box_area + anchor_area - intersection)\n    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n\n    y_train = tf.concat([y_train, anchor_idx], axis=-1)\n\n    for anchor_idxs in anchor_masks:\n        y_outs.append(transform_targets_for_output(\n            y_train, grid_size, anchor_idxs))\n        grid_size *= 2\n\n    return tuple(y_outs)\n\n\ndef transform_images(x_train, size):\n    x_train = tf.image.resize(x_train, (size, size))\n    x_train = x_train / 255\n    return x_train\n\n\n# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md#conversion-script-outline-conversion-script-outline\n# Commented out fields are not required in our project\nIMAGE_FEATURE_MAP = {\n    # \'image/width\': tf.io.FixedLenFeature([], tf.int64),\n    # \'image/height\': tf.io.FixedLenFeature([], tf.int64),\n    # \'image/filename\': tf.io.FixedLenFeature([], tf.string),\n    # \'image/source_id\': tf.io.FixedLenFeature([], tf.string),\n    # \'image/key/sha256\': tf.io.FixedLenFeature([], tf.string),\n    \'image/encoded\': tf.io.FixedLenFeature([], tf.string),\n    # \'image/format\': tf.io.FixedLenFeature([], tf.string),\n    \'image/object/bbox/xmin\': tf.io.VarLenFeature(tf.float32),\n    \'image/object/bbox/ymin\': tf.io.VarLenFeature(tf.float32),\n    \'image/object/bbox/xmax\': tf.io.VarLenFeature(tf.float32),\n    \'image/object/bbox/ymax\': tf.io.VarLenFeature(tf.float32),\n    \'image/object/class/text\': tf.io.VarLenFeature(tf.string),\n    # \'image/object/class/label\': tf.io.VarLenFeature(tf.int64),\n    # \'image/object/difficult\': tf.io.VarLenFeature(tf.int64),\n    # \'image/object/truncated\': tf.io.VarLenFeature(tf.int64),\n    # \'image/object/view\': tf.io.VarLenFeature(tf.string),\n}\n\n\ndef parse_tfrecord(tfrecord, class_table, size):\n    x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n    x_train = tf.image.decode_jpeg(x[\'image/encoded\'], channels=3)\n    x_train = tf.image.resize(x_train, (size, size))\n\n    class_text = tf.sparse.to_dense(\n        x[\'image/object/class/text\'], default_value=\'\')\n    labels = tf.cast(class_table.lookup(class_text), tf.float32)\n    y_train = tf.stack([tf.sparse.to_dense(x[\'image/object/bbox/xmin\']),\n                        tf.sparse.to_dense(x[\'image/object/bbox/ymin\']),\n                        tf.sparse.to_dense(x[\'image/object/bbox/xmax\']),\n                        tf.sparse.to_dense(x[\'image/object/bbox/ymax\']),\n                        labels], axis=1)\n\n    paddings = [[0, FLAGS.yolo_max_boxes - tf.shape(y_train)[0]], [0, 0]]\n    y_train = tf.pad(y_train, paddings)\n\n    return x_train, y_train\n\n\ndef load_tfrecord_dataset(file_pattern, class_file, size=416):\n    LINE_NUMBER = -1  # TODO: use tf.lookup.TextFileIndex.LINE_NUMBER\n    class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n        class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=""\\n""), -1)\n\n    files = tf.data.Dataset.list_files(file_pattern)\n    dataset = files.flat_map(tf.data.TFRecordDataset)\n    return dataset.map(lambda x: parse_tfrecord(x, class_table, size))\n\n\ndef load_fake_dataset():\n    x_train = tf.image.decode_jpeg(\n        open(\'./data/girl.png\', \'rb\').read(), channels=3)\n    x_train = tf.expand_dims(x_train, axis=0)\n\n    labels = [\n        [0.18494931, 0.03049111, 0.9435849,  0.96302897, 0],\n        [0.01586703, 0.35938117, 0.17582396, 0.6069674, 56],\n        [0.09158827, 0.48252046, 0.26967454, 0.6403017, 67]\n    ] + [[0, 0, 0, 0, 0]] * 5\n    y_train = tf.convert_to_tensor(labels, tf.float32)\n    y_train = tf.expand_dims(y_train, axis=0)\n\n    return tf.data.Dataset.from_tensor_slices((x_train, y_train))\n'"
yolov3_tf2/models.py,47,"b""from absl import flags\nfrom absl.flags import FLAGS\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import (\n    Add,\n    Concatenate,\n    Conv2D,\n    Input,\n    Lambda,\n    LeakyReLU,\n    MaxPool2D,\n    UpSampling2D,\n    ZeroPadding2D,\n    BatchNormalization,\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.losses import (\n    binary_crossentropy,\n    sparse_categorical_crossentropy\n)\nfrom .utils import broadcast_iou\n\nflags.DEFINE_integer('yolo_max_boxes', 100,\n                     'maximum number of boxes per image')\nflags.DEFINE_float('yolo_iou_threshold', 0.5, 'iou threshold')\nflags.DEFINE_float('yolo_score_threshold', 0.5, 'score threshold')\n\nyolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n                         (59, 119), (116, 90), (156, 198), (373, 326)],\n                        np.float32) / 416\nyolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n\nyolo_tiny_anchors = np.array([(10, 14), (23, 27), (37, 58),\n                              (81, 82), (135, 169),  (344, 319)],\n                             np.float32) / 416\nyolo_tiny_anchor_masks = np.array([[3, 4, 5], [0, 1, 2]])\n\n\ndef DarknetConv(x, filters, size, strides=1, batch_norm=True):\n    if strides == 1:\n        padding = 'same'\n    else:\n        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n        padding = 'valid'\n    x = Conv2D(filters=filters, kernel_size=size,\n               strides=strides, padding=padding,\n               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n    if batch_norm:\n        x = BatchNormalization()(x)\n        x = LeakyReLU(alpha=0.1)(x)\n    return x\n\n\ndef DarknetResidual(x, filters):\n    prev = x\n    x = DarknetConv(x, filters // 2, 1)\n    x = DarknetConv(x, filters, 3)\n    x = Add()([prev, x])\n    return x\n\n\ndef DarknetBlock(x, filters, blocks):\n    x = DarknetConv(x, filters, 3, strides=2)\n    for _ in range(blocks):\n        x = DarknetResidual(x, filters)\n    return x\n\n\ndef Darknet(name=None):\n    x = inputs = Input([None, None, 3])\n    x = DarknetConv(x, 32, 3)\n    x = DarknetBlock(x, 64, 1)\n    x = DarknetBlock(x, 128, 2)  # skip connection\n    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\n    x = x_61 = DarknetBlock(x, 512, 8)\n    x = DarknetBlock(x, 1024, 4)\n    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n\n\ndef DarknetTiny(name=None):\n    x = inputs = Input([None, None, 3])\n    x = DarknetConv(x, 16, 3)\n    x = MaxPool2D(2, 2, 'same')(x)\n    x = DarknetConv(x, 32, 3)\n    x = MaxPool2D(2, 2, 'same')(x)\n    x = DarknetConv(x, 64, 3)\n    x = MaxPool2D(2, 2, 'same')(x)\n    x = DarknetConv(x, 128, 3)\n    x = MaxPool2D(2, 2, 'same')(x)\n    x = x_8 = DarknetConv(x, 256, 3)  # skip connection\n    x = MaxPool2D(2, 2, 'same')(x)\n    x = DarknetConv(x, 512, 3)\n    x = MaxPool2D(2, 1, 'same')(x)\n    x = DarknetConv(x, 1024, 3)\n    return tf.keras.Model(inputs, (x_8, x), name=name)\n\n\ndef YoloConv(filters, name=None):\n    def yolo_conv(x_in):\n        if isinstance(x_in, tuple):\n            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n            x, x_skip = inputs\n\n            # concat with skip connection\n            x = DarknetConv(x, filters, 1)\n            x = UpSampling2D(2)(x)\n            x = Concatenate()([x, x_skip])\n        else:\n            x = inputs = Input(x_in.shape[1:])\n\n        x = DarknetConv(x, filters, 1)\n        x = DarknetConv(x, filters * 2, 3)\n        x = DarknetConv(x, filters, 1)\n        x = DarknetConv(x, filters * 2, 3)\n        x = DarknetConv(x, filters, 1)\n        return Model(inputs, x, name=name)(x_in)\n    return yolo_conv\n\n\ndef YoloConvTiny(filters, name=None):\n    def yolo_conv(x_in):\n        if isinstance(x_in, tuple):\n            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n            x, x_skip = inputs\n\n            # concat with skip connection\n            x = DarknetConv(x, filters, 1)\n            x = UpSampling2D(2)(x)\n            x = Concatenate()([x, x_skip])\n        else:\n            x = inputs = Input(x_in.shape[1:])\n            x = DarknetConv(x, filters, 1)\n\n        return Model(inputs, x, name=name)(x_in)\n    return yolo_conv\n\n\ndef YoloOutput(filters, anchors, classes, name=None):\n    def yolo_output(x_in):\n        x = inputs = Input(x_in.shape[1:])\n        x = DarknetConv(x, filters * 2, 3)\n        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n                                            anchors, classes + 5)))(x)\n        return tf.keras.Model(inputs, x, name=name)(x_in)\n    return yolo_output\n\n\ndef yolo_boxes(pred, anchors, classes):\n    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\n    grid_size = tf.shape(pred)[1:3]\n    box_xy, box_wh, objectness, class_probs = tf.split(\n        pred, (2, 2, 1, classes), axis=-1)\n\n    box_xy = tf.sigmoid(box_xy)\n    objectness = tf.sigmoid(objectness)\n    class_probs = tf.sigmoid(class_probs)\n    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n\n    # !!! grid[x][y] == (y, x)\n    grid = tf.meshgrid(tf.range(grid_size[1]), tf.range(grid_size[0]))\n    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n\n    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n        tf.cast(grid_size, tf.float32)\n    box_wh = tf.exp(box_wh) * anchors\n\n    box_x1y1 = box_xy - box_wh / 2\n    box_x2y2 = box_xy + box_wh / 2\n    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n\n    return bbox, objectness, class_probs, pred_box\n\n\ndef yolo_nms(outputs, anchors, masks, classes):\n    # boxes, conf, type\n    b, c, t = [], [], []\n\n    for o in outputs:\n        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n\n    bbox = tf.concat(b, axis=1)\n    confidence = tf.concat(c, axis=1)\n    class_probs = tf.concat(t, axis=1)\n\n    scores = confidence * class_probs\n    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n        scores=tf.reshape(\n            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n        max_output_size_per_class=FLAGS.yolo_max_boxes,\n        max_total_size=FLAGS.yolo_max_boxes,\n        iou_threshold=FLAGS.yolo_iou_threshold,\n        score_threshold=FLAGS.yolo_score_threshold\n    )\n\n    return boxes, scores, classes, valid_detections\n\n\ndef YoloV3(size=None, channels=3, anchors=yolo_anchors,\n           masks=yolo_anchor_masks, classes=80, training=False):\n    x = inputs = Input([size, size, channels], name='input')\n\n    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n\n    x = YoloConv(512, name='yolo_conv_0')(x)\n    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n\n    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n\n    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n\n    if training:\n        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n\n    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n                     name='yolo_boxes_0')(output_0)\n    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n                     name='yolo_boxes_1')(output_1)\n    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n                     name='yolo_boxes_2')(output_2)\n\n    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n\n    return Model(inputs, outputs, name='yolov3')\n\n\ndef YoloV3Tiny(size=None, channels=3, anchors=yolo_tiny_anchors,\n               masks=yolo_tiny_anchor_masks, classes=80, training=False):\n    x = inputs = Input([size, size, channels], name='input')\n\n    x_8, x = DarknetTiny(name='yolo_darknet')(x)\n\n    x = YoloConvTiny(256, name='yolo_conv_0')(x)\n    output_0 = YoloOutput(256, len(masks[0]), classes, name='yolo_output_0')(x)\n\n    x = YoloConvTiny(128, name='yolo_conv_1')((x, x_8))\n    output_1 = YoloOutput(128, len(masks[1]), classes, name='yolo_output_1')(x)\n\n    if training:\n        return Model(inputs, (output_0, output_1), name='yolov3')\n\n    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n                     name='yolo_boxes_0')(output_0)\n    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n                     name='yolo_boxes_1')(output_1)\n    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n                     name='yolo_nms')((boxes_0[:3], boxes_1[:3]))\n    return Model(inputs, outputs, name='yolov3_tiny')\n\n\ndef YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n    def yolo_loss(y_true, y_pred):\n        # 1. transform all pred outputs\n        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n            y_pred, anchors, classes)\n        pred_xy = pred_xywh[..., 0:2]\n        pred_wh = pred_xywh[..., 2:4]\n\n        # 2. transform all true outputs\n        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n        true_box, true_obj, true_class_idx = tf.split(\n            y_true, (4, 1, 1), axis=-1)\n        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n\n        # give higher weights to small boxes\n        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n\n        # 3. inverting the pred box equations\n        grid_size = tf.shape(y_true)[1]\n        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n            tf.cast(grid, tf.float32)\n        true_wh = tf.math.log(true_wh / anchors)\n        true_wh = tf.where(tf.math.is_inf(true_wh),\n                           tf.zeros_like(true_wh), true_wh)\n\n        # 4. calculate all masks\n        obj_mask = tf.squeeze(true_obj, -1)\n        # ignore false positive when iou is over threshold\n        best_iou = tf.map_fn(\n            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n            (pred_box, true_box, obj_mask),\n            tf.float32)\n        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n\n        # 5. calculate all losses\n        xy_loss = obj_mask * box_loss_scale * \\\n            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n        wh_loss = obj_mask * box_loss_scale * \\\n            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n        obj_loss = binary_crossentropy(true_obj, pred_obj)\n        obj_loss = obj_mask * obj_loss + \\\n            (1 - obj_mask) * ignore_mask * obj_loss\n        # TODO: use binary_crossentropy instead\n        class_loss = obj_mask * sparse_categorical_crossentropy(\n            true_class_idx, pred_class)\n\n        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n\n        return xy_loss + wh_loss + obj_loss + class_loss\n    return yolo_loss\n"""
yolov3_tf2/utils.py,11,"b'from absl import logging\nimport numpy as np\nimport tensorflow as tf\nimport cv2\n\nYOLOV3_LAYER_LIST = [\n    \'yolo_darknet\',\n    \'yolo_conv_0\',\n    \'yolo_output_0\',\n    \'yolo_conv_1\',\n    \'yolo_output_1\',\n    \'yolo_conv_2\',\n    \'yolo_output_2\',\n]\n\nYOLOV3_TINY_LAYER_LIST = [\n    \'yolo_darknet\',\n    \'yolo_conv_0\',\n    \'yolo_output_0\',\n    \'yolo_conv_1\',\n    \'yolo_output_1\',\n]\n\n\ndef load_darknet_weights(model, weights_file, tiny=False):\n    wf = open(weights_file, \'rb\')\n    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n\n    if tiny:\n        layers = YOLOV3_TINY_LAYER_LIST\n    else:\n        layers = YOLOV3_LAYER_LIST\n\n    for layer_name in layers:\n        sub_model = model.get_layer(layer_name)\n        for i, layer in enumerate(sub_model.layers):\n            if not layer.name.startswith(\'conv2d\'):\n                continue\n            batch_norm = None\n            if i + 1 < len(sub_model.layers) and \\\n                    sub_model.layers[i + 1].name.startswith(\'batch_norm\'):\n                batch_norm = sub_model.layers[i + 1]\n\n            logging.info(""{}/{} {}"".format(\n                sub_model.name, layer.name, \'bn\' if batch_norm else \'bias\'))\n\n            filters = layer.filters\n            size = layer.kernel_size[0]\n            in_dim = layer.get_input_shape_at(0)[-1]\n\n            if batch_norm is None:\n                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n            else:\n                # darknet [beta, gamma, mean, variance]\n                bn_weights = np.fromfile(\n                    wf, dtype=np.float32, count=4 * filters)\n                # tf [gamma, beta, mean, variance]\n                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n\n            # darknet shape (out_dim, in_dim, height, width)\n            conv_shape = (filters, in_dim, size, size)\n            conv_weights = np.fromfile(\n                wf, dtype=np.float32, count=np.product(conv_shape))\n            # tf shape (height, width, in_dim, out_dim)\n            conv_weights = conv_weights.reshape(\n                conv_shape).transpose([2, 3, 1, 0])\n\n            if batch_norm is None:\n                layer.set_weights([conv_weights, conv_bias])\n            else:\n                layer.set_weights([conv_weights])\n                batch_norm.set_weights(bn_weights)\n\n    assert len(wf.read()) == 0, \'failed to read all data\'\n    wf.close()\n\n\ndef broadcast_iou(box_1, box_2):\n    # box_1: (..., (x1, y1, x2, y2))\n    # box_2: (N, (x1, y1, x2, y2))\n\n    # broadcast boxes\n    box_1 = tf.expand_dims(box_1, -2)\n    box_2 = tf.expand_dims(box_2, 0)\n    # new_shape: (..., N, (x1, y1, x2, y2))\n    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n    box_1 = tf.broadcast_to(box_1, new_shape)\n    box_2 = tf.broadcast_to(box_2, new_shape)\n\n    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n    int_area = int_w * int_h\n    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n        (box_1[..., 3] - box_1[..., 1])\n    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n        (box_2[..., 3] - box_2[..., 1])\n    return int_area / (box_1_area + box_2_area - int_area)\n\n\ndef draw_outputs(img, outputs, class_names):\n    boxes, objectness, classes, nums = outputs\n    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n    wh = np.flip(img.shape[0:2])\n    for i in range(nums):\n        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n        img = cv2.putText(img, \'{} {:.4f}\'.format(\n            class_names[int(classes[i])], objectness[i]),\n            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n    return img\n\n\ndef draw_labels(x, y, class_names):\n    img = x.numpy()\n    boxes, classes = tf.split(y, (4, 1), axis=-1)\n    classes = classes[..., 0]\n    wh = np.flip(img.shape[0:2])\n    for i in range(len(boxes)):\n        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n        img = cv2.putText(img, class_names[classes[i]],\n                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n                          1, (0, 0, 255), 2)\n    return img\n\n\ndef freeze_all(model, frozen=True):\n    model.trainable = not frozen\n    if isinstance(model, tf.keras.Model):\n        for l in model.layers:\n            freeze_all(l, frozen)\n'"
