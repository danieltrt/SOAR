file_path,api_count,code
deform_conv_v2.py,18,"b'import torch\nfrom torch import nn\n\n\nclass DeformConv2d(nn.Module):\n    def __init__(self, inc, outc, kernel_size=3, padding=1, stride=1, bias=None, modulation=False):\n        """"""\n        Args:\n            modulation (bool, optional): If True, Modulated Defomable Convolution (Deformable ConvNets v2).\n        """"""\n        super(DeformConv2d, self).__init__()\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.stride = stride\n        self.zero_padding = nn.ZeroPad2d(padding)\n        self.conv = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n\n        self.p_conv = nn.Conv2d(inc, 2*kernel_size*kernel_size, kernel_size=3, padding=1, stride=stride)\n        nn.init.constant_(self.p_conv.weight, 0)\n        self.p_conv.register_backward_hook(self._set_lr)\n\n        self.modulation = modulation\n        if modulation:\n            self.m_conv = nn.Conv2d(inc, kernel_size*kernel_size, kernel_size=3, padding=1, stride=stride)\n            nn.init.constant_(self.m_conv.weight, 0)\n            self.m_conv.register_backward_hook(self._set_lr)\n\n    @staticmethod\n    def _set_lr(module, grad_input, grad_output):\n        grad_input = (grad_input[i] * 0.1 for i in range(len(grad_input)))\n        grad_output = (grad_output[i] * 0.1 for i in range(len(grad_output)))\n\n    def forward(self, x):\n        offset = self.p_conv(x)\n        if self.modulation:\n            m = torch.sigmoid(self.m_conv(x))\n\n        dtype = offset.data.type()\n        ks = self.kernel_size\n        N = offset.size(1) // 2\n\n        if self.padding:\n            x = self.zero_padding(x)\n\n        # (b, 2N, h, w)\n        p = self._get_p(offset, dtype)\n\n        # (b, h, w, 2N)\n        p = p.contiguous().permute(0, 2, 3, 1)\n        q_lt = p.detach().floor()\n        q_rb = q_lt + 1\n\n        q_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2)-1), torch.clamp(q_lt[..., N:], 0, x.size(3)-1)], dim=-1).long()\n        q_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2)-1), torch.clamp(q_rb[..., N:], 0, x.size(3)-1)], dim=-1).long()\n        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], dim=-1)\n        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], dim=-1)\n\n        # clip p\n        p = torch.cat([torch.clamp(p[..., :N], 0, x.size(2)-1), torch.clamp(p[..., N:], 0, x.size(3)-1)], dim=-1)\n\n        # bilinear kernel (b, h, w, N)\n        g_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\n        g_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\n        g_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\n        g_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\n\n        # (b, c, h, w, N)\n        x_q_lt = self._get_x_q(x, q_lt, N)\n        x_q_rb = self._get_x_q(x, q_rb, N)\n        x_q_lb = self._get_x_q(x, q_lb, N)\n        x_q_rt = self._get_x_q(x, q_rt, N)\n\n        # (b, c, h, w, N)\n        x_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\n                   g_rb.unsqueeze(dim=1) * x_q_rb + \\\n                   g_lb.unsqueeze(dim=1) * x_q_lb + \\\n                   g_rt.unsqueeze(dim=1) * x_q_rt\n\n        # modulation\n        if self.modulation:\n            m = m.contiguous().permute(0, 2, 3, 1)\n            m = m.unsqueeze(dim=1)\n            m = torch.cat([m for _ in range(x_offset.size(1))], dim=1)\n            x_offset *= m\n\n        x_offset = self._reshape_x_offset(x_offset, ks)\n        out = self.conv(x_offset)\n\n        return out\n\n    def _get_p_n(self, N, dtype):\n        p_n_x, p_n_y = torch.meshgrid(\n            torch.arange(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1),\n            torch.arange(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1))\n        # (2N, 1)\n        p_n = torch.cat([torch.flatten(p_n_x), torch.flatten(p_n_y)], 0)\n        p_n = p_n.view(1, 2*N, 1, 1).type(dtype)\n\n        return p_n\n\n    def _get_p_0(self, h, w, N, dtype):\n        p_0_x, p_0_y = torch.meshgrid(\n            torch.arange(1, h*self.stride+1, self.stride),\n            torch.arange(1, w*self.stride+1, self.stride))\n        p_0_x = torch.flatten(p_0_x).view(1, 1, h, w).repeat(1, N, 1, 1)\n        p_0_y = torch.flatten(p_0_y).view(1, 1, h, w).repeat(1, N, 1, 1)\n        p_0 = torch.cat([p_0_x, p_0_y], 1).type(dtype)\n\n        return p_0\n\n    def _get_p(self, offset, dtype):\n        N, h, w = offset.size(1)//2, offset.size(2), offset.size(3)\n\n        # (1, 2N, 1, 1)\n        p_n = self._get_p_n(N, dtype)\n        # (1, 2N, h, w)\n        p_0 = self._get_p_0(h, w, N, dtype)\n        p = p_0 + p_n + offset\n        return p\n\n    def _get_x_q(self, x, q, N):\n        b, h, w, _ = q.size()\n        padded_w = x.size(3)\n        c = x.size(1)\n        # (b, c, h*w)\n        x = x.contiguous().view(b, c, -1)\n\n        # (b, h, w, N)\n        index = q[..., :N]*padded_w + q[..., N:]  # offset_x*w + offset_y\n        # (b, c, h*w*N)\n        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n\n        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\n\n        return x_offset\n\n    @staticmethod\n    def _reshape_x_offset(x_offset, ks):\n        b, c, h, w, N = x_offset.size()\n        x_offset = torch.cat([x_offset[..., s:s+ks].contiguous().view(b, c, h, w*ks) for s in range(0, N, ks)], dim=-1)\n        x_offset = x_offset.contiguous().view(b, c, h*ks, w*ks)\n\n        return x_offset\n'"
scaled_mnist_train.py,7,"b'import os\nimport argparse\nimport numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\nimport joblib\nfrom collections import OrderedDict\nfrom datetime import datetime\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom utils import *\nfrom scaled_mnist.dataset import ScaledMNIST\nimport scaled_mnist.archs as archs\n\narch_names = archs.__dict__.keys()\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--name\', default=None,\n                        help=\'model name: (default: arch+timestamp)\')\n    parser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'ScaledMNISTNet\',\n                        choices=arch_names,\n                        help=\'model architecture: \' +\n                            \' | \'.join(arch_names) +\n                            \' (default: ScaledMNISTNet)\')\n    parser.add_argument(\'--deform\', default=True, type=str2bool,\n                        help=\'use deform conv\')\n    parser.add_argument(\'--modulation\', default=True, type=str2bool,\n                        help=\'use modulated deform conv\')\n    parser.add_argument(\'--min-deform-layer\', default=3, type=int,\n                        help=\'minimum number of layer using deform conv\')\n    parser.add_argument(\'--epochs\', default=10, type=int, metavar=\'N\',\n                        help=\'number of total epochs to run\')\n    parser.add_argument(\'--optimizer\', default=\'SGD\',\n                        choices=[\'Adam\', \'SGD\'],\n                        help=\'loss: \' +\n                            \' | \'.join([\'Adam\', \'SGD\']) +\n                            \' (default: Adam)\')\n    parser.add_argument(\'--lr\', \'--learning-rate\', default=1e-2, type=float,\n                        metavar=\'LR\', help=\'initial learning rate\')\n    parser.add_argument(\'--momentum\', default=0.5, type=float,\n                        help=\'momentum\')\n    parser.add_argument(\'--weight-decay\', default=1e-4, type=float,\n                        help=\'weight decay\')\n    parser.add_argument(\'--nesterov\', default=False, type=str2bool,\n                        help=\'nesterov\')\n\n    args = parser.parse_args()\n\n    return args\n\n\ndef train(args, train_loader, model, criterion, optimizer, epoch, scheduler=None):\n    losses = AverageMeter()\n    scores = AverageMeter()\n\n    model.train()\n\n    for i, (input, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        input = input.cuda()\n        target = target.cuda()\n\n        output = model(input)\n        loss = criterion(output, target)\n\n        acc = accuracy(output, target)[0]\n\n        losses.update(loss.item(), input.size(0))\n        scores.update(acc.item(), input.size(0))\n\n        # compute gradient and do optimizing step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    log = OrderedDict([\n        (\'loss\', losses.avg),\n        (\'acc\', scores.avg),\n    ])\n\n    return log\n\n\ndef validate(args, val_loader, model, criterion):\n    losses = AverageMeter()\n    scores = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        for i, (input, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n            input = input.cuda()\n            target = target.cuda()\n\n            output = model(input)\n            loss = criterion(output, target)\n\n            acc = accuracy(output, target)[0]\n\n            losses.update(loss.item(), input.size(0))\n            scores.update(acc.item(), input.size(0))\n\n    log = OrderedDict([\n        (\'loss\', losses.avg),\n        (\'acc\', scores.avg),\n    ])\n\n    return log\n\n\ndef main():\n    args = parse_args()\n\n    if args.name is None:\n        args.name = \'%s\' %args.arch\n        if args.deform:\n            args.name += \'_wDCN\'\n            if args.modulation:\n                args.name += \'v2\'\n            args.name += \'_c%d-4\' %args.min_deform_layer\n\n    if not os.path.exists(\'models/%s\' %args.name):\n        os.makedirs(\'models/%s\' %args.name)\n\n    print(\'Config -----\')\n    for arg in vars(args):\n        print(\'%s: %s\' %(arg, getattr(args, arg)))\n    print(\'------------\')\n\n    with open(\'models/%s/args.txt\' %args.name, \'w\') as f:\n        for arg in vars(args):\n            print(\'%s: %s\' %(arg, getattr(args, arg)), file=f)\n\n    joblib.dump(args, \'models/%s/args.pkl\' %args.name)\n\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    cudnn.benchmark = True\n\n    # data loading code\n    transform_train = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n\n    train_set = ScaledMNIST(\n        train=True,\n        transform=transform_train)\n    train_loader = torch.utils.data.DataLoader(\n        train_set,\n        batch_size=32,\n        shuffle=True,\n        num_workers=8)\n\n    test_set = ScaledMNIST(\n        train=False,\n        transform=transform_train)\n    test_loader = torch.utils.data.DataLoader(\n        test_set,\n        batch_size=32,\n        shuffle=False,\n        num_workers=8)\n\n    num_classes = 10\n\n    # create model\n    model = archs.__dict__[args.arch](args, num_classes)\n    model = model.cuda()\n\n    print(model)\n\n    if args.optimizer == \'Adam\':\n        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n    elif args.optimizer == \'SGD\':\n        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr,\n            momentum=args.momentum, weight_decay=args.weight_decay, nesterov=args.nesterov)\n\n    log = pd.DataFrame(index=[], columns=[\n        \'epoch\', \'lr\', \'loss\', \'acc\', \'val_loss\', \'val_acc\'\n    ])\n\n    best_acc = 0\n    for epoch in range(args.epochs):\n        print(\'Epoch [%d/%d]\' %(epoch, args.epochs))\n\n        # train for one epoch\n        train_log = train(args, train_loader, model, criterion, optimizer, epoch)\n        # evaluate on validation set\n        val_log = validate(args, test_loader, model, criterion)\n\n        print(\'loss %.4f - acc %.4f - val_loss %.4f - val_acc %.4f\'\n            %(train_log[\'loss\'], train_log[\'acc\'], val_log[\'loss\'], val_log[\'acc\']))\n\n        tmp = pd.Series([\n            epoch,\n            1e-1,\n            train_log[\'loss\'],\n            train_log[\'acc\'],\n            val_log[\'loss\'],\n            val_log[\'acc\'],\n        ], index=[\'epoch\', \'lr\', \'loss\', \'acc\', \'val_loss\', \'val_acc\'])\n\n        log = log.append(tmp, ignore_index=True)\n        log.to_csv(\'models/%s/log.csv\' %args.name, index=False)\n\n        if val_log[\'acc\'] > best_acc:\n            torch.save(model.state_dict(), \'models/%s/model.pth\' %args.name)\n            best_acc = val_log[\'acc\']\n            print(""=> saved best model"")\n\n    print(""best val_acc: %f"" %best_acc)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,1,"b'import random\nimport math\nfrom PIL import Image\nimport numpy as np\n\nimport torch\n\n\ndef str2bool(v):\n    if v.lower() in [\'true\', 1]:\n        return True\n    elif v.lower() in [\'false\', 0]:\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\'Boolean value expected.\')\n\n\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the accuracy over the k top predictions for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n'"
scaled_mnist/archs.py,1,"b'# -*- coding: utf-8 -*-\nimport numpy as np\n\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torch\nfrom torchvision import models\nimport torchvision\n\nfrom deform_conv_v2 import *\n\n\nclass ScaledMNISTNet(nn.Module):\n    def __init__(self, args, num_classes):\n        super().__init__()\n\n        self.relu = nn.ReLU(inplace=True)\n        self.sigmoid = nn.Sigmoid()\n        self.pool = nn.MaxPool2d((2, 2))\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n\n        features = []\n        inplanes = 1\n        outplanes = 32\n        for i in range(4):\n            if args.deform and args.min_deform_layer <= i+1:\n                features.append(DeformConv2d(inplanes, outplanes, 3, padding=1, bias=False, modulation=args.modulation))\n            else:\n                features.append(nn.Conv2d(inplanes, outplanes, 3, padding=1, bias=False))\n            features.append(nn.BatchNorm2d(outplanes))\n            features.append(self.relu)\n            if i == 1:\n                features.append(self.pool)\n            inplanes = outplanes\n            outplanes *= 2\n        self.features = nn.Sequential(*features)\n\n        self.fc = nn.Linear(256, 10)\n\n    def forward(self, input):\n        x = self.features(input)\n        x = self.avg_pool(x)\n        x = x.view(x.shape[0], -1)\n        output = self.fc(x)\n\n        return output\n'"
scaled_mnist/dataset.py,1,"b'from torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom matplotlib import pyplot as plt\nimport cv2\nimport numpy as np\nimport random\nimport scipy.ndimage as ndi\nfrom tqdm import tqdm\nimport os\nfrom PIL import Image\n\n\nclass ScaledMNIST(Dataset):\n    def __init__(self, train=True, transform=None, target_transform=None):\n        self.transform = transform\n        self.target_transform = target_transform\n        self.train = train  # training set or test set\n\n        if not os.path.exists(\'input/scaled_mnist_train.npz\'):\n            train_dataset = datasets.MNIST(\'~/data\', train=True, download=True)\n            train_imgs, train_labels = train_dataset.train_data.numpy(), train_dataset.train_labels.numpy()\n\n            scaled_train_imgs = []\n            for i in tqdm(range(len(train_imgs))):\n                img = np.pad(train_imgs[i], 14, \'constant\')\n                img = random_zoom(img[:,:,np.newaxis], (0.5, 1.5))\n                scaled_train_imgs.append(img[:,:,0])\n            scaled_train_imgs = np.array(scaled_train_imgs)\n\n            np.savez(\'input/scaled_mnist_train.npz\', images=scaled_train_imgs, labels=train_labels)\n\n        if not os.path.exists(\'input/scaled_mnist_test.npz\'):\n            test_dataset = datasets.MNIST(\'~/data\', train=False, download=True)\n            test_imgs, test_labels = test_dataset.test_data.numpy(), test_dataset.test_labels.numpy()\n\n            scaled_test_imgs = []\n            for i in tqdm(range(len(test_imgs))):\n                img = np.pad(test_imgs[i], 14, \'constant\')\n                img = random_zoom(img[:,:,np.newaxis], (0.5, 1.5))\n                scaled_test_imgs.append(img[:,:,0])\n            scaled_test_imgs = np.array(scaled_test_imgs)\n\n            np.savez(\'input/scaled_mnist_test.npz\', images=scaled_test_imgs, labels=test_labels)\n\n        if self.train:\n            scaled_mnist_train = np.load(\'input/scaled_mnist_train.npz\')\n            self.train_data = scaled_mnist_train[\'images\']\n            self.train_labels = scaled_mnist_train[\'labels\']\n        else:\n            scaled_mnist_test = np.load(\'input/scaled_mnist_test.npz\')\n            self.test_data = scaled_mnist_test[\'images\']\n            self.test_labels = scaled_mnist_test[\'labels\']\n\n    def __getitem__(self, index):\n        """"""\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        """"""\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img, mode=\'L\')\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self):\n        if self.train:\n            return len(self.train_data)\n        else:\n            return len(self.test_data)\n\n\ndef transform_matrix_offset_center(matrix, x, y):\n    o_x = float(x) / 2 + 0.5\n    o_y = float(y) / 2 + 0.5\n    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n    return transform_matrix\n\n\ndef apply_transform(x, transform_matrix, channel_axis=0,\n                    fill_mode=\'nearest\', cval=0.):\n    x = np.rollaxis(x, channel_axis, 0)\n    final_affine_matrix = transform_matrix[:2, :2]\n    final_offset = transform_matrix[:2, 2]\n    channel_images = [ndi.interpolation.affine_transform(\n        x_channel,\n        final_affine_matrix,\n        final_offset,\n        order=0,\n        mode=fill_mode,\n        cval=cval) for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x\n\n\ndef random_zoom(X, zoom_range, row_axis=0, col_axis=1, channel_axis=2,\n                fill_mode=\'nearest\', cval=0.):\n    if len(zoom_range) != 2:\n        raise ValueError(\'`zoom_range` should be a tuple or list of two floats. \'\n                         \'Received arg: \', zoom_range)\n\n    z = np.random.uniform(zoom_range[0], zoom_range[1])\n    zoom_matrix = np.array([[z, 0, 0],\n                            [0, z, 0],\n                            [0, 0, 1]])\n\n    h, w = X.shape[row_axis], X.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n    X = apply_transform(X, transform_matrix, channel_axis, fill_mode, cval)\n\n    return X\n'"
