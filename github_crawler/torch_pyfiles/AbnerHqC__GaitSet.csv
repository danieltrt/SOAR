file_path,api_count,code
config.py,0,"b'conf = {\n    ""WORK_PATH"": ""./work"",\n    ""CUDA_VISIBLE_DEVICES"": ""0,1,2,3"",\n    ""data"": {\n        \'dataset_path\': ""your_dataset_path"",\n        \'resolution\': \'64\',\n        \'dataset\': \'CASIA-B\',\n        # In CASIA-B, data of subject #5 is incomplete.\n        # Thus, we ignore it in training.\n        # For more detail, please refer to\n        # function: utils.data_loader.load_data\n        \'pid_num\': 73,\n        \'pid_shuffle\': False,\n    },\n    ""model"": {\n        \'hidden_dim\': 256,\n        \'lr\': 1e-4,\n        \'hard_or_full_trip\': \'full\',\n        \'batch_size\': (8, 16),\n        \'restore_iter\': 0,\n        \'total_iter\': 80000,\n        \'margin\': 0.2,\n        \'num_workers\': 3,\n        \'frame_num\': 30,\n        \'model_name\': \'GaitSet\',\n    },\n}\n'"
pretreatment.py,0,"b'# -*- coding: utf-8 -*-\n# @Author  : Abner\n# @Time    : 2018/12/19\n\nimport os\nfrom scipy import misc as scisc\nimport cv2\nimport numpy as np\nfrom warnings import warn\nfrom time import sleep\nimport argparse\n\nfrom multiprocessing import Pool\nfrom multiprocessing import TimeoutError as MP_TimeoutError\n\nSTART = ""START""\nFINISH = ""FINISH""\nWARNING = ""WARNING""\nFAIL = ""FAIL""\n\n\ndef boolean_string(s):\n    if s.upper() not in {\'FALSE\', \'TRUE\'}:\n        raise ValueError(\'Not a valid boolean string\')\n    return s.upper() == \'TRUE\'\n\n\nparser = argparse.ArgumentParser(description=\'Test\')\nparser.add_argument(\'--input_path\', default=\'\', type=str,\n                    help=\'Root path of raw dataset.\')\nparser.add_argument(\'--output_path\', default=\'\', type=str,\n                    help=\'Root path for output.\')\nparser.add_argument(\'--log_file\', default=\'./pretreatment.log\', type=str,\n                    help=\'Log file path. Default: ./pretreatment.log\')\nparser.add_argument(\'--log\', default=False, type=boolean_string,\n                    help=\'If set as True, all logs will be saved. \'\n                         \'Otherwise, only warnings and errors will be saved.\'\n                         \'Default: False\')\nparser.add_argument(\'--worker_num\', default=1, type=int,\n                    help=\'How many subprocesses to use for data pretreatment. \'\n                         \'Default: 1\')\nopt = parser.parse_args()\n\nINPUT_PATH = opt.input_path\nOUTPUT_PATH = opt.output_path\nIF_LOG = opt.log\nLOG_PATH = opt.log_file\nWORKERS = opt.worker_num\n\nT_H = 64\nT_W = 64\n\n\ndef log2str(pid, comment, logs):\n    str_log = \'\'\n    if type(logs) is str:\n        logs = [logs]\n    for log in logs:\n        str_log += ""# JOB %d : --%s-- %s\\n"" % (\n            pid, comment, log)\n    return str_log\n\n\ndef log_print(pid, comment, logs):\n    str_log = log2str(pid, comment, logs)\n    if comment in [WARNING, FAIL]:\n        with open(LOG_PATH, \'a\') as log_f:\n            log_f.write(str_log)\n    if comment in [START, FINISH]:\n        if pid % 500 != 0:\n            return\n    print(str_log, end=\'\')\n\n\ndef cut_img(img, seq_info, frame_name, pid):\n    # A silhouette contains too little white pixels\n    # might be not valid for identification.\n    if img.sum() <= 10000:\n        message = \'seq:%s, frame:%s, no data, %d.\' % (\n            \'-\'.join(seq_info), frame_name, img.sum())\n        warn(message)\n        log_print(pid, WARNING, message)\n        return None\n    # Get the top and bottom point\n    y = img.sum(axis=1)\n    y_top = (y != 0).argmax(axis=0)\n    y_btm = (y != 0).cumsum(axis=0).argmax(axis=0)\n    img = img[y_top:y_btm + 1, :]\n    # As the height of a person is larger than the width,\n    # use the height to calculate resize ratio.\n    _r = img.shape[1] / img.shape[0]\n    _t_w = int(T_H * _r)\n    img = cv2.resize(img, (_t_w, T_H), interpolation=cv2.INTER_CUBIC)\n    # Get the median of x axis and regard it as the x center of the person.\n    sum_point = img.sum()\n    sum_column = img.sum(axis=0).cumsum()\n    x_center = -1\n    for i in range(sum_column.size):\n        if sum_column[i] > sum_point / 2:\n            x_center = i\n            break\n    if x_center < 0:\n        message = \'seq:%s, frame:%s, no center.\' % (\n            \'-\'.join(seq_info), frame_name)\n        warn(message)\n        log_print(pid, WARNING, message)\n        return None\n    h_T_W = int(T_W / 2)\n    left = x_center - h_T_W\n    right = x_center + h_T_W\n    if left <= 0 or right >= img.shape[1]:\n        left += h_T_W\n        right += h_T_W\n        _ = np.zeros((img.shape[0], h_T_W))\n        img = np.concatenate([_, img, _], axis=1)\n    img = img[:, left:right]\n    return img.astype(\'uint8\')\n\n\ndef cut_pickle(seq_info, pid):\n    seq_name = \'-\'.join(seq_info)\n    log_print(pid, START, seq_name)\n    seq_path = os.path.join(INPUT_PATH, *seq_info)\n    out_dir = os.path.join(OUTPUT_PATH, *seq_info)\n    frame_list = os.listdir(seq_path)\n    frame_list.sort()\n    count_frame = 0\n    for _frame_name in frame_list:\n        frame_path = os.path.join(seq_path, _frame_name)\n        img = cv2.imread(frame_path)[:, :, 0]\n        img = cut_img(img, seq_info, _frame_name, pid)\n        if img is not None:\n            # Save the cut img\n            save_path = os.path.join(out_dir, _frame_name)\n            scisc.imsave(save_path, img)\n            count_frame += 1\n    # Warn if the sequence contains less than 5 frames\n    if count_frame < 5:\n        message = \'seq:%s, less than 5 valid data.\' % (\n            \'-\'.join(seq_info))\n        warn(message)\n        log_print(pid, WARNING, message)\n\n    log_print(pid, FINISH,\n              \'Contain %d valid frames. Saved to %s.\'\n              % (count_frame, out_dir))\n\n\npool = Pool(WORKERS)\nresults = list()\npid = 0\n\nprint(\'Pretreatment Start.\\n\'\n      \'Input path: %s\\n\'\n      \'Output path: %s\\n\'\n      \'Log file: %s\\n\'\n      \'Worker num: %d\' % (\n          INPUT_PATH, OUTPUT_PATH, LOG_PATH, WORKERS))\n\nid_list = os.listdir(INPUT_PATH)\nid_list.sort()\n# Walk the input path\nfor _id in id_list:\n    seq_type = os.listdir(os.path.join(INPUT_PATH, _id))\n    seq_type.sort()\n    for _seq_type in seq_type:\n        view = os.listdir(os.path.join(INPUT_PATH, _id, _seq_type))\n        view.sort()\n        for _view in view:\n            seq_info = [_id, _seq_type, _view]\n            out_dir = os.path.join(OUTPUT_PATH, *seq_info)\n            os.makedirs(out_dir)\n            results.append(\n                pool.apply_async(\n                    cut_pickle,\n                    args=(seq_info, pid)))\n            sleep(0.02)\n            pid += 1\n\npool.close()\nunfinish = 1\nwhile unfinish > 0:\n    unfinish = 0\n    for i, res in enumerate(results):\n        try:\n            res.get(timeout=0.1)\n        except Exception as e:\n            if type(e) == MP_TimeoutError:\n                unfinish += 1\n                continue\n            else:\n                print(\'\\n\\n\\nERROR OCCUR: PID ##%d##, ERRORTYPE: %s\\n\\n\\n\',\n                      i, type(e))\n                raise e\npool.join()\n'"
test.py,0,"b""from datetime import datetime\nimport numpy as np\nimport argparse\n\nfrom model.initialization import initialization\nfrom model.utils import evaluation\nfrom config import conf\n\n\ndef boolean_string(s):\n    if s.upper() not in {'FALSE', 'TRUE'}:\n        raise ValueError('Not a valid boolean string')\n    return s.upper() == 'TRUE'\n\n\nparser = argparse.ArgumentParser(description='Test')\nparser.add_argument('--iter', default='80000', type=int,\n                    help='iter: iteration of the checkpoint to load. Default: 80000')\nparser.add_argument('--batch_size', default='1', type=int,\n                    help='batch_size: batch size for parallel test. Default: 1')\nparser.add_argument('--cache', default=False, type=boolean_string,\n                    help='cache: if set as TRUE all the test data will be loaded at once'\n                         ' before the transforming start. Default: FALSE')\nopt = parser.parse_args()\n\n\n# Exclude identical-view cases\ndef de_diag(acc, each_angle=False):\n    result = np.sum(acc - np.diag(np.diag(acc)), 1) / 10.0\n    if not each_angle:\n        result = np.mean(result)\n    return result\n\n\nm = initialization(conf, test=opt.cache)[0]\n\n# load model checkpoint of iteration opt.iter\nprint('Loading the model of iteration %d...' % opt.iter)\nm.load(opt.iter)\nprint('Transforming...')\ntime = datetime.now()\ntest = m.transform('test', opt.batch_size)\nprint('Evaluating...')\nacc = evaluation(test, conf['data'])\nprint('Evaluation complete. Cost:', datetime.now() - time)\n\n# Print rank-1 accuracy of the best model\n# e.g.\n# ===Rank-1 (Include identical-view cases)===\n# NM: 95.405,     BG: 88.284,     CL: 72.041\nfor i in range(1):\n    print('===Rank-%d (Include identical-view cases)===' % (i + 1))\n    print('NM: %.3f,\\tBG: %.3f,\\tCL: %.3f' % (\n        np.mean(acc[0, :, :, i]),\n        np.mean(acc[1, :, :, i]),\n        np.mean(acc[2, :, :, i])))\n\n# Print rank-1 accuracy of the best model\xef\xbc\x8cexcluding identical-view cases\n# e.g.\n# ===Rank-1 (Exclude identical-view cases)===\n# NM: 94.964,     BG: 87.239,     CL: 70.355\nfor i in range(1):\n    print('===Rank-%d (Exclude identical-view cases)===' % (i + 1))\n    print('NM: %.3f,\\tBG: %.3f,\\tCL: %.3f' % (\n        de_diag(acc[0, :, :, i]),\n        de_diag(acc[1, :, :, i]),\n        de_diag(acc[2, :, :, i])))\n\n# Print rank-1 accuracy of the best model (Each Angle)\n# e.g.\n# ===Rank-1 of each angle (Exclude identical-view cases)===\n# NM: [90.80 97.90 99.40 96.90 93.60 91.70 95.00 97.80 98.90 96.80 85.80]\n# BG: [83.80 91.20 91.80 88.79 83.30 81.00 84.10 90.00 92.20 94.45 79.00]\n# CL: [61.40 75.40 80.70 77.30 72.10 70.10 71.50 73.50 73.50 68.40 50.00]\nnp.set_printoptions(precision=2, floatmode='fixed')\nfor i in range(1):\n    print('===Rank-%d of each angle (Exclude identical-view cases)===' % (i + 1))\n    print('NM:', de_diag(acc[0, :, :, i], True))\n    print('BG:', de_diag(acc[1, :, :, i], True))\n    print('CL:', de_diag(acc[2, :, :, i], True))\n"""
train.py,0,"b'from model.initialization import initialization\nfrom config import conf\nimport argparse\n\n\ndef boolean_string(s):\n    if s.upper() not in {\'FALSE\', \'TRUE\'}:\n        raise ValueError(\'Not a valid boolean string\')\n    return s.upper() == \'TRUE\'\n\n\nparser = argparse.ArgumentParser(description=\'Train\')\nparser.add_argument(\'--cache\', default=True, type=boolean_string,\n                    help=\'cache: if set as TRUE all the training data will be loaded at once\'\n                         \' before the training start. Default: TRUE\')\nopt = parser.parse_args()\n\nm = initialization(conf, train=opt.cache)[0]\n\nprint(""Training START"")\nm.fit()\nprint(""Training COMPLETE"")\n'"
model/__init__.py,0,b'# -*- coding: utf-8 -*-\n# @Author  : admin\n# @Time    : 2018/11/16\n\n'
model/initialization.py,0,"b'# -*- coding: utf-8 -*-\n# @Author  : admin\n# @Time    : 2018/11/15\nimport os\nfrom copy import deepcopy\n\nimport numpy as np\n\nfrom .utils import load_data\nfrom .model import Model\n\n\ndef initialize_data(config, train=False, test=False):\n    print(""Initializing data source..."")\n    train_source, test_source = load_data(**config[\'data\'], cache=(train or test))\n    if train:\n        print(""Loading training data..."")\n        train_source.load_all_data()\n    if test:\n        print(""Loading test data..."")\n        test_source.load_all_data()\n    print(""Data initialization complete."")\n    return train_source, test_source\n\n\ndef initialize_model(config, train_source, test_source):\n    print(""Initializing model..."")\n    data_config = config[\'data\']\n    model_config = config[\'model\']\n    model_param = deepcopy(model_config)\n    model_param[\'train_source\'] = train_source\n    model_param[\'test_source\'] = test_source\n    model_param[\'train_pid_num\'] = data_config[\'pid_num\']\n    batch_size = int(np.prod(model_config[\'batch_size\']))\n    model_param[\'save_name\'] = \'_\'.join(map(str,[\n        model_config[\'model_name\'],\n        data_config[\'dataset\'],\n        data_config[\'pid_num\'],\n        data_config[\'pid_shuffle\'],\n        model_config[\'hidden_dim\'],\n        model_config[\'margin\'],\n        batch_size,\n        model_config[\'hard_or_full_trip\'],\n        model_config[\'frame_num\'],\n    ]))\n\n    m = Model(**model_param)\n    print(""Model initialization complete."")\n    return m, model_param[\'save_name\']\n\n\ndef initialization(config, train=False, test=False):\n    print(""Initialzing..."")\n    WORK_PATH = config[\'WORK_PATH\']\n    os.chdir(WORK_PATH)\n    os.environ[""CUDA_VISIBLE_DEVICES""] = config[""CUDA_VISIBLE_DEVICES""]\n    train_source, test_source = initialize_data(config, train, test)\n    return initialize_model(config, train_source, test_source)'"
model/model.py,10,"b""import math\nimport os\nimport os.path as osp\nimport random\nimport sys\nfrom datetime import datetime\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.autograd as autograd\nimport torch.optim as optim\nimport torch.utils.data as tordata\n\nfrom .network import TripletLoss, SetNet\nfrom .utils import TripletSampler\n\n\nclass Model:\n    def __init__(self,\n                 hidden_dim,\n                 lr,\n                 hard_or_full_trip,\n                 margin,\n                 num_workers,\n                 batch_size,\n                 restore_iter,\n                 total_iter,\n                 save_name,\n                 train_pid_num,\n                 frame_num,\n                 model_name,\n                 train_source,\n                 test_source,\n                 img_size=64):\n\n        self.save_name = save_name\n        self.train_pid_num = train_pid_num\n        self.train_source = train_source\n        self.test_source = test_source\n\n        self.hidden_dim = hidden_dim\n        self.lr = lr\n        self.hard_or_full_trip = hard_or_full_trip\n        self.margin = margin\n        self.frame_num = frame_num\n        self.num_workers = num_workers\n        self.batch_size = batch_size\n        self.model_name = model_name\n        self.P, self.M = batch_size\n\n        self.restore_iter = restore_iter\n        self.total_iter = total_iter\n\n        self.img_size = img_size\n\n        self.encoder = SetNet(self.hidden_dim).float()\n        self.encoder = nn.DataParallel(self.encoder)\n        self.triplet_loss = TripletLoss(self.P * self.M, self.hard_or_full_trip, self.margin).float()\n        self.triplet_loss = nn.DataParallel(self.triplet_loss)\n        self.encoder.cuda()\n        self.triplet_loss.cuda()\n\n        self.optimizer = optim.Adam([\n            {'params': self.encoder.parameters()},\n        ], lr=self.lr)\n\n        self.hard_loss_metric = []\n        self.full_loss_metric = []\n        self.full_loss_num = []\n        self.dist_list = []\n        self.mean_dist = 0.01\n\n        self.sample_type = 'all'\n\n    def collate_fn(self, batch):\n        batch_size = len(batch)\n        feature_num = len(batch[0][0])\n        seqs = [batch[i][0] for i in range(batch_size)]\n        frame_sets = [batch[i][1] for i in range(batch_size)]\n        view = [batch[i][2] for i in range(batch_size)]\n        seq_type = [batch[i][3] for i in range(batch_size)]\n        label = [batch[i][4] for i in range(batch_size)]\n        batch = [seqs, view, seq_type, label, None]\n\n        def select_frame(index):\n            sample = seqs[index]\n            frame_set = frame_sets[index]\n            if self.sample_type == 'random':\n                frame_id_list = random.choices(frame_set, k=self.frame_num)\n                _ = [feature.loc[frame_id_list].values for feature in sample]\n            else:\n                _ = [feature.values for feature in sample]\n            return _\n\n        seqs = list(map(select_frame, range(len(seqs))))\n\n        if self.sample_type == 'random':\n            seqs = [np.asarray([seqs[i][j] for i in range(batch_size)]) for j in range(feature_num)]\n        else:\n            gpu_num = min(torch.cuda.device_count(), batch_size)\n            batch_per_gpu = math.ceil(batch_size / gpu_num)\n            batch_frames = [[\n                                len(frame_sets[i])\n                                for i in range(batch_per_gpu * _, batch_per_gpu * (_ + 1))\n                                if i < batch_size\n                                ] for _ in range(gpu_num)]\n            if len(batch_frames[-1]) != batch_per_gpu:\n                for _ in range(batch_per_gpu - len(batch_frames[-1])):\n                    batch_frames[-1].append(0)\n            max_sum_frame = np.max([np.sum(batch_frames[_]) for _ in range(gpu_num)])\n            seqs = [[\n                        np.concatenate([\n                                           seqs[i][j]\n                                           for i in range(batch_per_gpu * _, batch_per_gpu * (_ + 1))\n                                           if i < batch_size\n                                           ], 0) for _ in range(gpu_num)]\n                    for j in range(feature_num)]\n            seqs = [np.asarray([\n                                   np.pad(seqs[j][_],\n                                          ((0, max_sum_frame - seqs[j][_].shape[0]), (0, 0), (0, 0)),\n                                          'constant',\n                                          constant_values=0)\n                                   for _ in range(gpu_num)])\n                    for j in range(feature_num)]\n            batch[4] = np.asarray(batch_frames)\n\n        batch[0] = seqs\n        return batch\n\n    def fit(self):\n        if self.restore_iter != 0:\n            self.load(self.restore_iter)\n\n        self.encoder.train()\n        self.sample_type = 'random'\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = self.lr\n        triplet_sampler = TripletSampler(self.train_source, self.batch_size)\n        train_loader = tordata.DataLoader(\n            dataset=self.train_source,\n            batch_sampler=triplet_sampler,\n            collate_fn=self.collate_fn,\n            num_workers=self.num_workers)\n\n        train_label_set = list(self.train_source.label_set)\n        train_label_set.sort()\n\n        _time1 = datetime.now()\n        for seq, view, seq_type, label, batch_frame in train_loader:\n            self.restore_iter += 1\n            self.optimizer.zero_grad()\n\n            for i in range(len(seq)):\n                seq[i] = self.np2var(seq[i]).float()\n            if batch_frame is not None:\n                batch_frame = self.np2var(batch_frame).int()\n\n            feature, label_prob = self.encoder(*seq, batch_frame)\n\n            target_label = [train_label_set.index(l) for l in label]\n            target_label = self.np2var(np.array(target_label)).long()\n\n            triplet_feature = feature.permute(1, 0, 2).contiguous()\n            triplet_label = target_label.unsqueeze(0).repeat(triplet_feature.size(0), 1)\n            (full_loss_metric, hard_loss_metric, mean_dist, full_loss_num\n             ) = self.triplet_loss(triplet_feature, triplet_label)\n            if self.hard_or_full_trip == 'hard':\n                loss = hard_loss_metric.mean()\n            elif self.hard_or_full_trip == 'full':\n                loss = full_loss_metric.mean()\n\n            self.hard_loss_metric.append(hard_loss_metric.mean().data.cpu().numpy())\n            self.full_loss_metric.append(full_loss_metric.mean().data.cpu().numpy())\n            self.full_loss_num.append(full_loss_num.mean().data.cpu().numpy())\n            self.dist_list.append(mean_dist.mean().data.cpu().numpy())\n\n            if loss > 1e-9:\n                loss.backward()\n                self.optimizer.step()\n\n            if self.restore_iter % 1000 == 0:\n                print(datetime.now() - _time1)\n                _time1 = datetime.now()\n\n            if self.restore_iter % 100 == 0:\n                self.save()\n                print('iter {}:'.format(self.restore_iter), end='')\n                print(', hard_loss_metric={0:.8f}'.format(np.mean(self.hard_loss_metric)), end='')\n                print(', full_loss_metric={0:.8f}'.format(np.mean(self.full_loss_metric)), end='')\n                print(', full_loss_num={0:.8f}'.format(np.mean(self.full_loss_num)), end='')\n                self.mean_dist = np.mean(self.dist_list)\n                print(', mean_dist={0:.8f}'.format(self.mean_dist), end='')\n                print(', lr=%f' % self.optimizer.param_groups[0]['lr'], end='')\n                print(', hard or full=%r' % self.hard_or_full_trip)\n                sys.stdout.flush()\n                self.hard_loss_metric = []\n                self.full_loss_metric = []\n                self.full_loss_num = []\n                self.dist_list = []\n\n            # Visualization using t-SNE\n            # if self.restore_iter % 500 == 0:\n            #     pca = TSNE(2)\n            #     pca_feature = pca.fit_transform(feature.view(feature.size(0), -1).data.cpu().numpy())\n            #     for i in range(self.P):\n            #         plt.scatter(pca_feature[self.M * i:self.M * (i + 1), 0],\n            #                     pca_feature[self.M * i:self.M * (i + 1), 1], label=label[self.M * i])\n            #\n            #     plt.show()\n\n            if self.restore_iter == self.total_iter:\n                break\n\n    def ts2var(self, x):\n        return autograd.Variable(x).cuda()\n\n    def np2var(self, x):\n        return self.ts2var(torch.from_numpy(x))\n\n    def transform(self, flag, batch_size=1):\n        self.encoder.eval()\n        source = self.test_source if flag == 'test' else self.train_source\n        self.sample_type = 'all'\n        data_loader = tordata.DataLoader(\n            dataset=source,\n            batch_size=batch_size,\n            sampler=tordata.sampler.SequentialSampler(source),\n            collate_fn=self.collate_fn,\n            num_workers=self.num_workers)\n\n        feature_list = list()\n        view_list = list()\n        seq_type_list = list()\n        label_list = list()\n\n        for i, x in enumerate(data_loader):\n            seq, view, seq_type, label, batch_frame = x\n            for j in range(len(seq)):\n                seq[j] = self.np2var(seq[j]).float()\n            if batch_frame is not None:\n                batch_frame = self.np2var(batch_frame).int()\n            # print(batch_frame, np.sum(batch_frame))\n\n            feature, _ = self.encoder(*seq, batch_frame)\n            n, num_bin, _ = feature.size()\n            feature_list.append(feature.view(n, -1).data.cpu().numpy())\n            view_list += view\n            seq_type_list += seq_type\n            label_list += label\n\n        return np.concatenate(feature_list, 0), view_list, seq_type_list, label_list\n\n    def save(self):\n        os.makedirs(osp.join('checkpoint', self.model_name), exist_ok=True)\n        torch.save(self.encoder.state_dict(),\n                   osp.join('checkpoint', self.model_name,\n                            '{}-{:0>5}-encoder.ptm'.format(\n                                self.save_name, self.restore_iter)))\n        torch.save(self.optimizer.state_dict(),\n                   osp.join('checkpoint', self.model_name,\n                            '{}-{:0>5}-optimizer.ptm'.format(\n                                self.save_name, self.restore_iter)))\n\n    # restore_iter: iteration index of the checkpoint to load\n    def load(self, restore_iter):\n        self.encoder.load_state_dict(torch.load(osp.join(\n            'checkpoint', self.model_name,\n            '{}-{:0>5}-encoder.ptm'.format(self.save_name, restore_iter))))\n        self.optimizer.load_state_dict(torch.load(osp.join(\n            'checkpoint', self.model_name,\n            '{}-{:0>5}-optimizer.ptm'.format(self.save_name, restore_iter))))\n"""
model/network/__init__.py,0,b'from .triplet import TripletLoss\nfrom .gaitset import SetNet'
model/network/basic_blocks.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False, **kwargs)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return F.leaky_relu(x, inplace=True)\n\n\nclass SetBlock(nn.Module):\n    def __init__(self, forward_block, pooling=False):\n        super(SetBlock, self).__init__()\n        self.forward_block = forward_block\n        self.pooling = pooling\n        if pooling:\n            self.pool2d = nn.MaxPool2d(2)\n    def forward(self, x):\n        n, s, c, h, w = x.size()\n        x = self.forward_block(x.view(-1,c,h,w))\n        if self.pooling:\n            x = self.pool2d(x)\n        _, c, h, w = x.size()\n        return x.view(n, s, c, h ,w)\n'"
model/network/gaitset.py,11,"b'import torch\nimport torch.nn as nn\nimport numpy as np\n\nfrom .basic_blocks import SetBlock, BasicConv2d\n\n\nclass SetNet(nn.Module):\n    def __init__(self, hidden_dim):\n        super(SetNet, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.batch_frame = None\n\n        _set_in_channels = 1\n        _set_channels = [32, 64, 128]\n        self.set_layer1 = SetBlock(BasicConv2d(_set_in_channels, _set_channels[0], 5, padding=2))\n        self.set_layer2 = SetBlock(BasicConv2d(_set_channels[0], _set_channels[0], 3, padding=1), True)\n        self.set_layer3 = SetBlock(BasicConv2d(_set_channels[0], _set_channels[1], 3, padding=1))\n        self.set_layer4 = SetBlock(BasicConv2d(_set_channels[1], _set_channels[1], 3, padding=1), True)\n        self.set_layer5 = SetBlock(BasicConv2d(_set_channels[1], _set_channels[2], 3, padding=1))\n        self.set_layer6 = SetBlock(BasicConv2d(_set_channels[2], _set_channels[2], 3, padding=1))\n\n        _gl_in_channels = 32\n        _gl_channels = [64, 128]\n        self.gl_layer1 = BasicConv2d(_gl_in_channels, _gl_channels[0], 3, padding=1)\n        self.gl_layer2 = BasicConv2d(_gl_channels[0], _gl_channels[0], 3, padding=1)\n        self.gl_layer3 = BasicConv2d(_gl_channels[0], _gl_channels[1], 3, padding=1)\n        self.gl_layer4 = BasicConv2d(_gl_channels[1], _gl_channels[1], 3, padding=1)\n        self.gl_pooling = nn.MaxPool2d(2)\n\n        self.bin_num = [1, 2, 4, 8, 16]\n        self.fc_bin = nn.ParameterList([\n            nn.Parameter(\n                nn.init.xavier_uniform_(\n                    torch.zeros(sum(self.bin_num) * 2, 128, hidden_dim)))])\n\n        for m in self.modules():\n            if isinstance(m, (nn.Conv2d, nn.Conv1d)):\n                nn.init.xavier_uniform_(m.weight.data)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight.data)\n                nn.init.constant(m.bias.data, 0.0)\n            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n                nn.init.normal(m.weight.data, 1.0, 0.02)\n                nn.init.constant(m.bias.data, 0.0)\n\n    def frame_max(self, x):\n        if self.batch_frame is None:\n            return torch.max(x, 1)\n        else:\n            _tmp = [\n                torch.max(x[:, self.batch_frame[i]:self.batch_frame[i + 1], :, :, :], 1)\n                for i in range(len(self.batch_frame) - 1)\n                ]\n            max_list = torch.cat([_tmp[i][0] for i in range(len(_tmp))], 0)\n            arg_max_list = torch.cat([_tmp[i][1] for i in range(len(_tmp))], 0)\n            return max_list, arg_max_list\n\n    def frame_median(self, x):\n        if self.batch_frame is None:\n            return torch.median(x, 1)\n        else:\n            _tmp = [\n                torch.median(x[:, self.batch_frame[i]:self.batch_frame[i + 1], :, :, :], 1)\n                for i in range(len(self.batch_frame) - 1)\n                ]\n            median_list = torch.cat([_tmp[i][0] for i in range(len(_tmp))], 0)\n            arg_median_list = torch.cat([_tmp[i][1] for i in range(len(_tmp))], 0)\n            return median_list, arg_median_list\n\n    def forward(self, silho, batch_frame=None):\n        # n: batch_size, s: frame_num, k: keypoints_num, c: channel\n        if batch_frame is not None:\n            batch_frame = batch_frame[0].data.cpu().numpy().tolist()\n            _ = len(batch_frame)\n            for i in range(len(batch_frame)):\n                if batch_frame[-(i + 1)] != 0:\n                    break\n                else:\n                    _ -= 1\n            batch_frame = batch_frame[:_]\n            frame_sum = np.sum(batch_frame)\n            if frame_sum < silho.size(1):\n                silho = silho[:, :frame_sum, :, :]\n            self.batch_frame = [0] + np.cumsum(batch_frame).tolist()\n        n = silho.size(0)\n        x = silho.unsqueeze(2)\n        del silho\n\n        x = self.set_layer1(x)\n        x = self.set_layer2(x)\n        gl = self.gl_layer1(self.frame_max(x)[0])\n        gl = self.gl_layer2(gl)\n        gl = self.gl_pooling(gl)\n\n        x = self.set_layer3(x)\n        x = self.set_layer4(x)\n        gl = self.gl_layer3(gl + self.frame_max(x)[0])\n        gl = self.gl_layer4(gl)\n\n        x = self.set_layer5(x)\n        x = self.set_layer6(x)\n        x = self.frame_max(x)[0]\n        gl = gl + x\n\n        feature = list()\n        n, c, h, w = gl.size()\n        for num_bin in self.bin_num:\n            z = x.view(n, c, num_bin, -1)\n            z = z.mean(3) + z.max(3)[0]\n            feature.append(z)\n            z = gl.view(n, c, num_bin, -1)\n            z = z.mean(3) + z.max(3)[0]\n            feature.append(z)\n        feature = torch.cat(feature, 2).permute(2, 0, 1).contiguous()\n\n        feature = feature.matmul(self.fc_bin[0])\n        feature = feature.permute(1, 0, 2).contiguous()\n\n        return feature, None\n'"
model/network/triplet.py,10,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass TripletLoss(nn.Module):\n    def __init__(self, batch_size, hard_or_full, margin):\n        super(TripletLoss, self).__init__()\n        self.batch_size = batch_size\n        self.margin = margin\n\n    def forward(self, feature, label):\n        # feature: [n, m, d], label: [n, m]\n        n, m, d = feature.size()\n        hp_mask = (label.unsqueeze(1) == label.unsqueeze(2)).byte().view(-1)\n        hn_mask = (label.unsqueeze(1) != label.unsqueeze(2)).byte().view(-1)\n\n        dist = self.batch_dist(feature)\n        mean_dist = dist.mean(1).mean(1)\n        dist = dist.view(-1)\n        # hard\n        hard_hp_dist = torch.max(torch.masked_select(dist, hp_mask).view(n, m, -1), 2)[0]\n        hard_hn_dist = torch.min(torch.masked_select(dist, hn_mask).view(n, m, -1), 2)[0]\n        hard_loss_metric = F.relu(self.margin + hard_hp_dist - hard_hn_dist).view(n, -1)\n\n        hard_loss_metric_mean = torch.mean(hard_loss_metric, 1)\n\n        # non-zero full\n        full_hp_dist = torch.masked_select(dist, hp_mask).view(n, m, -1, 1)\n        full_hn_dist = torch.masked_select(dist, hn_mask).view(n, m, 1, -1)\n        full_loss_metric = F.relu(self.margin + full_hp_dist - full_hn_dist).view(n, -1)\n\n        full_loss_metric_sum = full_loss_metric.sum(1)\n        full_loss_num = (full_loss_metric != 0).sum(1).float()\n\n        full_loss_metric_mean = full_loss_metric_sum / full_loss_num\n        full_loss_metric_mean[full_loss_num == 0] = 0\n\n        return full_loss_metric_mean, hard_loss_metric_mean, mean_dist, full_loss_num\n\n    def batch_dist(self, x):\n        x2 = torch.sum(x ** 2, 2)\n        dist = x2.unsqueeze(2) + x2.unsqueeze(2).transpose(1, 2) - 2 * torch.matmul(x, x.transpose(1, 2))\n        dist = torch.sqrt(F.relu(dist))\n        return dist\n'"
model/utils/__init__.py,0,b'from .data_loader import load_data\nfrom .data_set import DataSet\nfrom .evaluator import evaluation\nfrom .sampler import TripletSampler'
model/utils/data_loader.py,0,"b""import os\nimport os.path as osp\n\nimport numpy as np\n\nfrom .data_set import DataSet\n\n\ndef load_data(dataset_path, resolution, dataset, pid_num, pid_shuffle, cache=True):\n    seq_dir = list()\n    view = list()\n    seq_type = list()\n    label = list()\n\n    for _label in sorted(list(os.listdir(dataset_path))):\n        # In CASIA-B, data of subject #5 is incomplete.\n        # Thus, we ignore it in training.\n        if dataset == 'CASIA-B' and _label == '005':\n            continue\n        label_path = osp.join(dataset_path, _label)\n        for _seq_type in sorted(list(os.listdir(label_path))):\n            seq_type_path = osp.join(label_path, _seq_type)\n            for _view in sorted(list(os.listdir(seq_type_path))):\n                _seq_dir = osp.join(seq_type_path, _view)\n                seqs = os.listdir(_seq_dir)\n                if len(seqs) > 0:\n                    seq_dir.append([_seq_dir])\n                    label.append(_label)\n                    seq_type.append(_seq_type)\n                    view.append(_view)\n\n    pid_fname = osp.join('partition', '{}_{}_{}.npy'.format(\n        dataset, pid_num, pid_shuffle))\n    if not osp.exists(pid_fname):\n        pid_list = sorted(list(set(label)))\n        if pid_shuffle:\n            np.random.shuffle(pid_list)\n        pid_list = [pid_list[0:pid_num], pid_list[pid_num:]]\n        os.makedirs('partition', exist_ok=True)\n        np.save(pid_fname, pid_list)\n\n    pid_list = np.load(pid_fname)\n    train_list = pid_list[0]\n    test_list = pid_list[1]\n    train_source = DataSet(\n        [seq_dir[i] for i, l in enumerate(label) if l in train_list],\n        [label[i] for i, l in enumerate(label) if l in train_list],\n        [seq_type[i] for i, l in enumerate(label) if l in train_list],\n        [view[i] for i, l in enumerate(label)\n         if l in train_list],\n        cache, resolution)\n    test_source = DataSet(\n        [seq_dir[i] for i, l in enumerate(label) if l in test_list],\n        [label[i] for i, l in enumerate(label) if l in test_list],\n        [seq_type[i] for i, l in enumerate(label) if l in test_list],\n        [view[i] for i, l in enumerate(label)\n         if l in test_list],\n        cache, resolution)\n\n    return train_source, test_source\n"""
model/utils/data_set.py,1,"b""import torch.utils.data as tordata\nimport numpy as np\nimport os.path as osp\nimport os\nimport pickle\nimport cv2\nimport xarray as xr\n\n\nclass DataSet(tordata.Dataset):\n    def __init__(self, seq_dir, label, seq_type, view, cache, resolution):\n        self.seq_dir = seq_dir\n        self.view = view\n        self.seq_type = seq_type\n        self.label = label\n        self.cache = cache\n        self.resolution = int(resolution)\n        self.cut_padding = int(float(resolution)/64*10)\n        self.data_size = len(self.label)\n        self.data = [None] * self.data_size\n        self.frame_set = [None] * self.data_size\n\n        self.label_set = set(self.label)\n        self.seq_type_set = set(self.seq_type)\n        self.view_set = set(self.view)\n        _ = np.zeros((len(self.label_set),\n                      len(self.seq_type_set),\n                      len(self.view_set))).astype('int')\n        _ -= 1\n        self.index_dict = xr.DataArray(\n            _,\n            coords={'label': sorted(list(self.label_set)),\n                    'seq_type': sorted(list(self.seq_type_set)),\n                    'view': sorted(list(self.view_set))},\n            dims=['label', 'seq_type', 'view'])\n\n        for i in range(self.data_size):\n            _label = self.label[i]\n            _seq_type = self.seq_type[i]\n            _view = self.view[i]\n            self.index_dict.loc[_label, _seq_type, _view] = i\n\n    def load_all_data(self):\n        for i in range(self.data_size):\n            self.load_data(i)\n\n    def load_data(self, index):\n        return self.__getitem__(index)\n\n    def __loader__(self, path):\n        return self.img2xarray(\n            path)[:, :, self.cut_padding:-self.cut_padding].astype(\n            'float32') / 255.0\n\n    def __getitem__(self, index):\n        # pose sequence sampling\n        if not self.cache:\n            data = [self.__loader__(_path) for _path in self.seq_dir[index]]\n            frame_set = [set(feature.coords['frame'].values.tolist()) for feature in data]\n            frame_set = list(set.intersection(*frame_set))\n        elif self.data[index] is None:\n            data = [self.__loader__(_path) for _path in self.seq_dir[index]]\n            frame_set = [set(feature.coords['frame'].values.tolist()) for feature in data]\n            frame_set = list(set.intersection(*frame_set))\n            self.data[index] = data\n            self.frame_set[index] = frame_set\n        else:\n            data = self.data[index]\n            frame_set = self.frame_set[index]\n\n        return data, frame_set, self.view[\n            index], self.seq_type[index], self.label[index],\n\n    def img2xarray(self, flie_path):\n        imgs = sorted(list(os.listdir(flie_path)))\n        frame_list = [np.reshape(\n            cv2.imread(osp.join(flie_path, _img_path)),\n            [self.resolution, self.resolution, -1])[:, :, 0]\n                      for _img_path in imgs\n                      if osp.isfile(osp.join(flie_path, _img_path))]\n        num_list = list(range(len(frame_list)))\n        data_dict = xr.DataArray(\n            frame_list,\n            coords={'frame': num_list},\n            dims=['frame', 'img_y', 'img_x'],\n        )\n        return data_dict\n\n    def __len__(self):\n        return len(self.label)\n"""
model/utils/evaluator.py,6,"b""import torch\nimport torch.nn.functional as F\nimport numpy as np\n\n\ndef cuda_dist(x, y):\n    x = torch.from_numpy(x).cuda()\n    y = torch.from_numpy(y).cuda()\n    dist = torch.sum(x ** 2, 1).unsqueeze(1) + torch.sum(y ** 2, 1).unsqueeze(\n        1).transpose(0, 1) - 2 * torch.matmul(x, y.transpose(0, 1))\n    dist = torch.sqrt(F.relu(dist))\n    return dist\n\n\ndef evaluation(data, config):\n    dataset = config['dataset'].split('-')[0]\n    feature, view, seq_type, label = data\n    label = np.array(label)\n    view_list = list(set(view))\n    view_list.sort()\n    view_num = len(view_list)\n    sample_num = len(feature)\n\n    probe_seq_dict = {'CASIA': [['nm-05', 'nm-06'], ['bg-01', 'bg-02'], ['cl-01', 'cl-02']],\n                      'OUMVLP': [['00']]}\n    gallery_seq_dict = {'CASIA': [['nm-01', 'nm-02', 'nm-03', 'nm-04']],\n                        'OUMVLP': [['01']]}\n\n    num_rank = 5\n    acc = np.zeros([len(probe_seq_dict[dataset]), view_num, view_num, num_rank])\n    for (p, probe_seq) in enumerate(probe_seq_dict[dataset]):\n        for gallery_seq in gallery_seq_dict[dataset]:\n            for (v1, probe_view) in enumerate(view_list):\n                for (v2, gallery_view) in enumerate(view_list):\n                    gseq_mask = np.isin(seq_type, gallery_seq) & np.isin(view, [gallery_view])\n                    gallery_x = feature[gseq_mask, :]\n                    gallery_y = label[gseq_mask]\n\n                    pseq_mask = np.isin(seq_type, probe_seq) & np.isin(view, [probe_view])\n                    probe_x = feature[pseq_mask, :]\n                    probe_y = label[pseq_mask]\n\n                    dist = cuda_dist(probe_x, gallery_x)\n                    idx = dist.sort(1)[1].cpu().numpy()\n                    acc[p, v1, v2, :] = np.round(\n                        np.sum(np.cumsum(np.reshape(probe_y, [-1, 1]) == gallery_y[idx[:, 0:num_rank]], 1) > 0,\n                               0) * 100 / dist.shape[0], 2)\n\n    return acc\n"""
model/utils/sampler.py,1,"b'import torch.utils.data as tordata\nimport random\n\n\nclass TripletSampler(tordata.sampler.Sampler):\n    def __init__(self, dataset, batch_size):\n        self.dataset = dataset\n        self.batch_size = batch_size\n\n    def __iter__(self):\n        while (True):\n            sample_indices = list()\n            pid_list = random.sample(\n                list(self.dataset.label_set),\n                self.batch_size[0])\n            for pid in pid_list:\n                _index = self.dataset.index_dict.loc[pid, :, :].values\n                _index = _index[_index > 0].flatten().tolist()\n                _index = random.choices(\n                    _index,\n                    k=self.batch_size[1])\n                sample_indices += _index\n            yield sample_indices\n\n    def __len__(self):\n        return self.dataset.data_size\n'"
work/OUMVLP_network/basic_blocks.py,4,"b'import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nclass BasicConv2d(nn.Module):\r\n    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\r\n        super(BasicConv2d, self).__init__()\r\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False, **kwargs)\r\n\r\n    def forward(self, x):\r\n        x = self.conv(x)\r\n        return F.leaky_relu(x, inplace=True)\r\n\r\n\r\nclass SetBlock(nn.Module):\r\n    def __init__(self, forward_block, pooling=False):\r\n        super(SetBlock, self).__init__()\r\n        self.forward_block = forward_block\r\n        self.pooling = pooling\r\n        if pooling:\r\n            self.pool2d = nn.MaxPool2d(2)\r\n    def forward(self, x):\r\n        n, s, c, h, w = x.size()\r\n        x = self.forward_block(x.view(-1,c,h,w))\r\n        if self.pooling:\r\n            x = self.pool2d(x)\r\n        _, c, h, w = x.size()\r\n        return x.view(n, s, c, h ,w)\r\n\r\n\r\nclass HPM(nn.Module):\r\n    def __init__(self, in_dim, out_dim, bin_level_num=5):\r\n        super(HPM, self).__init__()\r\n        self.bin_num = [2**i for i in range(bin_level_num)]\r\n        self.fc_bin = nn.ParameterList([\r\n            nn.Parameter(\r\n                nn.init.xavier_uniform(\r\n                    torch.zeros(sum(self.bin_num), in_dim, out_dim)))])\r\n    def forward(self, x):\r\n        feature = list()\r\n        n, c, h, w = x.size()\r\n        for num_bin in self.bin_num:\r\n            z = x.view(n, c, num_bin, -1)\r\n            z = z.mean(3)+z.max(3)[0]\r\n            feature.append(z)\r\n        feature = torch.cat(feature, 2).permute(2, 0, 1).contiguous()\r\n        \r\n        feature = feature.matmul(self.fc_bin[0])\r\n        return feature.permute(1, 0, 2).contiguous()'"
work/OUMVLP_network/gaitset.py,5,"b'class SetNet(nn.Module):\r\n    def __init__(self, hidden_dim):\r\n        super(SetNet, self).__init__()\r\n        self.hidden_dim = hidden_dim\r\n        self.batch_frame = None\r\n        \r\n        _in_channels = 1\r\n        _channels = [64,128,256]\r\n        self.set_layer1 = SetBlock(BasicConv2d(_in_channels, _channels[0], 5, padding=2))\r\n        self.set_layer2 = SetBlock(BasicConv2d(_channels[0], _channels[0], 3, padding=1), True)\r\n        self.set_layer3 = SetBlock(BasicConv2d(_channels[0], _channels[1], 3, padding=1))\r\n        self.set_layer4 = SetBlock(BasicConv2d(_channels[1], _channels[1], 3, padding=1), True)\r\n        self.set_layer5 = SetBlock(BasicConv2d(_channels[1], _channels[2], 3, padding=1))\r\n        self.set_layer6 = SetBlock(BasicConv2d(_channels[2], _channels[2], 3, padding=1))\r\n        \r\n        self.gl_layer1 = BasicConv2d(_channels[0], _channels[1], 3, padding=1)\r\n        self.gl_layer2 = BasicConv2d(_channels[1], _channels[1], 3, padding=1)\r\n        self.gl_layer3 = BasicConv2d(_channels[1], _channels[2], 3, padding=1)\r\n        self.gl_layer4 = BasicConv2d(_channels[2], _channels[2], 3, padding=1)\r\n        self.gl_pooling = nn.MaxPool2d(2)\r\n        \r\n        self.gl_hpm = HPM(_channels[-1], hidden_dim)\r\n        self.x_hpm = HPM(_channels[-1], hidden_dim)\r\n        \r\n        for m in self.modules():\r\n            if isinstance(m, (nn.Conv2d, nn.Conv1d)):\r\n                nn.init.xavier_uniform(m.weight.data)\r\n            elif isinstance(m, nn.Linear):\r\n                nn.init.xavier_uniform(m.weight.data)\r\n                nn.init.constant(m.bias.data, 0.0)\r\n            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\r\n                nn.init.normal(m.weight.data, 1.0, 0.02)\r\n                nn.init.constant(m.bias.data, 0.0)\r\n                    \r\n\r\n    def frame_max(self, x):\r\n        if self.batch_frame is None:\r\n            return torch.max(x, 1)\r\n        else:\r\n            _tmp = [\r\n                torch.max(x[:, self.batch_frame[i]:self.batch_frame[i+1], :, :, :], 1)\r\n                for i in range(len(self.batch_frame)-1)\r\n            ]\r\n            max_list = torch.cat([_tmp[i][0] for i in range(len(_tmp))], 0)\r\n            arg_max_list = torch.cat([_tmp[i][1] for i in range(len(_tmp))], 0)\r\n            return max_list, arg_max_list\r\n\r\n                \r\n    def forward(self, silho, batch_frame=None):\r\n        silho = silho/255\r\n        # n: batch_size, s: frame_num, k: keypoints_num, c: channel\r\n        if batch_frame is not None:\r\n            batch_frame = batch_frame[0].data.cpu().numpy().tolist()\r\n            _ = len(batch_frame)\r\n            for i in range(len(batch_frame)):\r\n                if batch_frame[-(i+1)] != 0:\r\n                    break\r\n                else:\r\n                    _ -= 1\r\n            batch_frame = batch_frame[:_]\r\n            frame_sum = np.sum(batch_frame)\r\n            if frame_sum < silho.size(1):\r\n                silho = silho[:, :frame_sum,:,:]\r\n            self.batch_frame = [0]+np.cumsum(batch_frame).tolist()\r\n        n = silho.size(0)\r\n        x = silho.unsqueeze(2)\r\n        del silho\r\n        \r\n        x = self.set_layer1(x)\r\n        x = self.set_layer2(x)\r\n        gl = self.gl_layer1(self.frame_max(x)[0])\r\n        gl = self.gl_layer2(gl)\r\n        gl = self.gl_pooling(gl)\r\n        \r\n        x = self.set_layer3(x)\r\n        x = self.set_layer4(x)\r\n        gl = self.gl_layer3(gl+self.frame_max(x)[0])\r\n        gl = self.gl_layer4(gl)\r\n        \r\n        x = self.set_layer5(x)\r\n        x = self.set_layer6(x)\r\n        x = self.frame_max(x)[0]\r\n        gl = gl+x\r\n        \r\n        gl_f = self.gl_hpm(gl)\r\n        x_f = self.x_hpm(x)\r\n        \r\n        return torch.cat([gl_f, x_f], 1), None'"
