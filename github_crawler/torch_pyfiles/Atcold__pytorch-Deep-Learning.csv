file_path,api_count,code
extra/plot_lib.py,4,"b""from matplotlib import pyplot as plt\nimport numpy as np\nimport torch\nfrom IPython.display import HTML, display\n\n\ndef set_default(figsize=(10, 10), dpi=100):\n    plt.style.use(['dark_background', 'bmh'])\n    plt.rc('axes', facecolor='k')\n    plt.rc('figure', facecolor='k')\n    plt.rc('figure', figsize=figsize, dpi=dpi)\n\n\ndef plot_data(X, y, d=0, auto=False, zoom=1):\n    X = X.cpu()\n    y = y.cpu()\n    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=20, cmap=plt.cm.Spectral)\n    plt.axis('square')\n    plt.axis(np.array((-1.1, 1.1, -1.1, 1.1)) * zoom)\n    if auto is True: plt.axis('equal')\n    plt.axis('off')\n\n    _m, _c = 0, '.15'\n    plt.axvline(0, ymin=_m, color=_c, lw=1, zorder=0)\n    plt.axhline(0, xmin=_m, color=_c, lw=1, zorder=0)\n\n\ndef plot_model(X, y, model):\n    model.cpu()\n    mesh = np.arange(-1.1, 1.1, 0.01)\n    xx, yy = np.meshgrid(mesh, mesh)\n    with torch.no_grad():\n        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float()\n        Z = model(data).detach()\n    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.3)\n    plot_data(X, y)\n\n\ndef show_scatterplot(X, colors, title=''):\n    colors = colors.cpu().numpy()\n    X = X.cpu().numpy()\n    plt.figure()\n    plt.axis('equal')\n    plt.scatter(X[:, 0], X[:, 1], c=colors, s=30)\n    # plt.grid(True)\n    plt.title(title)\n    plt.axis('off')\n\n\ndef plot_bases(bases, width=0.04):\n    bases = bases.cpu()\n    bases[2:] -= bases[:2]\n    plt.arrow(*bases[0], *bases[2], width=width, color=(1,0,0), zorder=10, alpha=1., length_includes_head=True)\n    plt.arrow(*bases[1], *bases[3], width=width, color=(0,1,0), zorder=10, alpha=1., length_includes_head=True)\n\n\ndef show_mat(mat, vect, prod, threshold=-1):\n    # Subplot grid definition\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=False, sharey=True,\n                                        gridspec_kw={'width_ratios':[5,1,1]})\n    # Plot matrices\n    cax1 = ax1.matshow(mat.numpy(), clim=(-1, 1))\n    ax2.matshow(vect.numpy(), clim=(-1, 1))\n    cax3 = ax3.matshow(prod.numpy(), clim=(threshold, 1))\n\n    # Set titles\n    ax1.set_title(f'A: {mat.size(0)} \\u00D7 {mat.size(1)}')\n    ax2.set_title(f'a^(i): {vect.numel()}')\n    ax3.set_title(f'p: {prod.numel()}')\n\n    # Remove xticks for vectors\n    ax2.set_xticks(tuple())\n    ax3.set_xticks(tuple())\n    \n    # Plot colourbars\n    fig.colorbar(cax1, ax=ax2)\n    fig.colorbar(cax3, ax=ax3)\n\n    # Fix y-axis limits\n    ax1.set_ylim(bottom=max(len(prod), len(vect)) - 0.5)\n\n\ncolors = dict(\n    aqua='#8dd3c7',\n    yellow='#ffffb3',\n    lavender='#bebada',\n    red='#fb8072',\n    blue='#80b1d3',\n    orange='#fdb462',\n    green='#b3de69',\n    pink='#fccde5',\n    grey='#d9d9d9',\n    violet='#bc80bd',\n    unk1='#ccebc5',\n    unk2='#ffed6f',\n)\n\n\ndef _cstr(s, color='black'):\n    if s == ' ':\n        return f'<text style=color:#000;padding-left:10px;background-color:{color}> </text>'\n    else:\n        return f'<text style=color:#000;background-color:{color}>{s} </text>'\n\n# print html\ndef _print_color(t):\n    display(HTML(''.join([_cstr(ti, color=ci) for ti, ci in t])))\n\n# get appropriate color for value\ndef _get_clr(value):\n    colors = ('#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n              '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n              '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n              '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e')\n    value = int((value * 100) / 5)\n    if value == len(colors): value -= 1  # fixing bugs...\n    return colors[value]\n\ndef _visualise_values(output_values, result_list):\n    text_colours = []\n    for i in range(len(output_values)):\n        text = (result_list[i], _get_clr(output_values[i]))\n        text_colours.append(text)\n    _print_color(text_colours)\n\ndef print_colourbar():\n    color_range = torch.linspace(-2.5, 2.5, 20)\n    to_print = [(f'{x:.2f}', _get_clr((x+2.5)/5)) for x in color_range]\n    _print_color(to_print)\n\n\n# Let's only focus on the last time step for now\n# First, the cell state (Long term memory)\ndef plot_state(data, state, b, decoder):\n    actual_data = decoder(data[b, :, :].numpy())\n    seq_len = len(actual_data)\n    seq_len_w_pad = len(state)\n    for s in range(state.size(2)):\n        states = torch.sigmoid(state[:, b, s])\n        _visualise_values(states[seq_len_w_pad - seq_len:], list(actual_data))"""
res/plot_lib.py,4,"b""from matplotlib import pyplot as plt\nimport numpy as np\nimport torch\nfrom IPython.display import HTML, display\n\n\ndef set_default(figsize=(10, 10), dpi=100):\n    plt.style.use(['dark_background', 'bmh'])\n    plt.rc('axes', facecolor='k')\n    plt.rc('figure', facecolor='k')\n    plt.rc('figure', figsize=figsize, dpi=dpi)\n\n\ndef plot_data(X, y, d=0, auto=False, zoom=1):\n    X = X.cpu()\n    y = y.cpu()\n    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=20, cmap=plt.cm.Spectral)\n    plt.axis('square')\n    plt.axis(np.array((-1.1, 1.1, -1.1, 1.1)) * zoom)\n    if auto is True: plt.axis('equal')\n    plt.axis('off')\n\n    _m, _c = 0, '.15'\n    plt.axvline(0, ymin=_m, color=_c, lw=1, zorder=0)\n    plt.axhline(0, xmin=_m, color=_c, lw=1, zorder=0)\n\n\ndef plot_model(X, y, model):\n    model.cpu()\n    mesh = np.arange(-1.1, 1.1, 0.01)\n    xx, yy = np.meshgrid(mesh, mesh)\n    with torch.no_grad():\n        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float()\n        Z = model(data).detach()\n    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.3)\n    plot_data(X, y)\n\n\ndef show_scatterplot(X, colors, title=''):\n    colors = colors.cpu().numpy()\n    X = X.cpu().numpy()\n    plt.figure()\n    plt.axis('equal')\n    plt.scatter(X[:, 0], X[:, 1], c=colors, s=30)\n    # plt.grid(True)\n    plt.title(title)\n    plt.axis('off')\n\n\ndef plot_bases(bases, width=0.04):\n    bases = bases.cpu()\n    bases[2:] -= bases[:2]\n    plt.arrow(*bases[0], *bases[2], width=width, color=(1,0,0), zorder=10, alpha=1., length_includes_head=True)\n    plt.arrow(*bases[1], *bases[3], width=width, color=(0,1,0), zorder=10, alpha=1., length_includes_head=True)\n\n\ndef show_mat(mat, vect, prod, threshold=-1):\n    # Subplot grid definition\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=False, sharey=True,\n                                        gridspec_kw={'width_ratios':[5,1,1]})\n    # Plot matrices\n    cax1 = ax1.matshow(mat.numpy(), clim=(-1, 1))\n    ax2.matshow(vect.numpy(), clim=(-1, 1))\n    cax3 = ax3.matshow(prod.numpy(), clim=(threshold, 1))\n\n    # Set titles\n    ax1.set_title(f'A: {mat.size(0)} \\u00D7 {mat.size(1)}')\n    ax2.set_title(f'a^(i): {vect.numel()}')\n    ax3.set_title(f'p: {prod.numel()}')\n\n    # Remove xticks for vectors\n    ax2.set_xticks(tuple())\n    ax3.set_xticks(tuple())\n    \n    # Plot colourbars\n    fig.colorbar(cax1, ax=ax2)\n    fig.colorbar(cax3, ax=ax3)\n\n    # Fix y-axis limits\n    ax1.set_ylim(bottom=max(len(prod), len(vect)) - 0.5)\n\n\ncolors = dict(\n    aqua='#8dd3c7',\n    yellow='#ffffb3',\n    lavender='#bebada',\n    red='#fb8072',\n    blue='#80b1d3',\n    orange='#fdb462',\n    green='#b3de69',\n    pink='#fccde5',\n    grey='#d9d9d9',\n    violet='#bc80bd',\n    unk1='#ccebc5',\n    unk2='#ffed6f',\n)\n\n\ndef _cstr(s, color='black'):\n    if s == ' ':\n        return f'<text style=color:#000;padding-left:10px;background-color:{color}> </text>'\n    else:\n        return f'<text style=color:#000;background-color:{color}>{s} </text>'\n\n# print html\ndef _print_color(t):\n    display(HTML(''.join([_cstr(ti, color=ci) for ti, ci in t])))\n\n# get appropriate color for value\ndef _get_clr(value):\n    colors = ('#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n              '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n              '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n              '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e')\n    value = int((value * 100) / 5)\n    if value == len(colors): value -= 1  # fixing bugs...\n    return colors[value]\n\ndef _visualise_values(output_values, result_list):\n    text_colours = []\n    for i in range(len(output_values)):\n        text = (result_list[i], _get_clr(output_values[i]))\n        text_colours.append(text)\n    _print_color(text_colours)\n\ndef print_colourbar():\n    color_range = torch.linspace(-2.5, 2.5, 20)\n    to_print = [(f'{x:.2f}', _get_clr((x+2.5)/5)) for x in color_range]\n    _print_color(to_print)\n\n\n# Let's only focus on the last time step for now\n# First, the cell state (Long term memory)\ndef plot_state(data, state, b, decoder):\n    actual_data = decoder(data[b, :, :].numpy())\n    seq_len = len(actual_data)\n    seq_len_w_pad = len(state)\n    for s in range(state.size(2)):\n        states = torch.sigmoid(state[:, b, s])\n        _visualise_values(states[seq_len_w_pad - seq_len:], list(actual_data))"""
res/sequential_tasks.py,0,"b'import numpy as np\nimport six\n\ndef pad_sequences(sequences, maxlen=None, dtype=\'int32\',\n                  padding=\'pre\', truncating=\'pre\', value=0.):\n    if not hasattr(sequences, \'__len__\'):\n        raise ValueError(\'`sequences` must be iterable.\')\n    lengths = []\n    for x in sequences:\n        if not hasattr(x, \'__len__\'):\n            raise ValueError(\'`sequences` must be a list of iterables. \'\n                             \'Found non-iterable: \' + str(x))\n        lengths.append(len(x))\n\n    num_samples = len(sequences)\n    if maxlen is None:\n        maxlen = np.max(lengths)\n\n    # take the sample shape from the first non empty sequence\n    # checking for consistency in the main loop below.\n    sample_shape = tuple()\n    for s in sequences:\n        if len(s) > 0:\n            sample_shape = np.asarray(s).shape[1:]\n            break\n\n    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(dtype, np.unicode_)\n    if isinstance(value, six.string_types) and dtype != object and not is_dtype_str:\n        raise ValueError(""`dtype` {} is not compatible with `value`\'s type: {}\\n""\n                         ""You should set `dtype=object` for variable length strings.""\n                         .format(dtype, type(value)))\n\n    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n    for idx, s in enumerate(sequences):\n        if not len(s):\n            continue  # empty list/array was found\n        if truncating == \'pre\':\n            trunc = s[-maxlen:]\n        elif truncating == \'post\':\n            trunc = s[:maxlen]\n        else:\n            raise ValueError(\'Truncating type ""%s"" \'\n                             \'not understood\' % truncating)\n\n        # check `trunc` has expected shape\n        trunc = np.asarray(trunc, dtype=dtype)\n        if trunc.shape[1:] != sample_shape:\n            raise ValueError(\'Shape of sample %s of sequence at position %s \'\n                             \'is different from expected shape %s\' %\n                             (trunc.shape[1:], idx, sample_shape))\n\n        if padding == \'post\':\n            x[idx, :len(trunc)] = trunc\n        elif padding == \'pre\':\n            x[idx, -len(trunc):] = trunc\n        else:\n            raise ValueError(\'Padding type ""%s"" not understood\' % padding)\n    return x\n\ndef to_categorical(y, num_classes=None, dtype=\'float32\'):\n    y = np.array(y, dtype=\'int\')\n    input_shape = y.shape\n    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n        input_shape = tuple(input_shape[:-1])\n    y = y.ravel()\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    categorical = np.zeros((n, num_classes), dtype=dtype)\n    categorical[np.arange(n), y] = 1\n    output_shape = input_shape + (num_classes,)\n    categorical = np.reshape(categorical, output_shape)\n    return categorical\n\nclass EchoData():\n\n    def __init__(self, series_length=40000, batch_size=32,\n                 echo_step=3, truncated_length=10, seed=None):\n\n        self.series_length = series_length\n        self.truncated_length = truncated_length\n        self.n_batches = series_length//truncated_length\n\n        self.echo_step = echo_step\n        self.batch_size = batch_size\n        if seed is not None:\n            np.random.seed(seed)\n        self.x_batch = None\n        self.y_batch = None\n        self.x_chunks = []\n        self.y_chunks = []\n        self.generate_new_series()\n        self.prepare_batches()\n\n    def __getitem__(self, index):\n        if index == 0:\n            self.generate_new_series()\n            self.prepare_batches()\n        return self.x_chunks[index], self.y_chunks[index]\n\n    def __len__(self):\n        return self.n_batches\n\n    def generate_new_series(self):\n        x = np.random.choice(\n            2,\n            size=(self.batch_size, self.series_length),\n            p=[0.5, 0.5])\n        y = np.roll(x, self.echo_step, axis=1)\n        y[:, 0:self.echo_step] = 0\n        self.x_batch = x\n        self.y_batch = y\n\n    def prepare_batches(self):\n        x = np.expand_dims(self.x_batch, axis=-1)\n        y = np.expand_dims(self.y_batch, axis=-1)\n        self.x_chunks = np.split(x, self.n_batches, axis=1)\n        self.y_chunks = np.split(y, self.n_batches, axis=1)\n\nclass TemporalOrderExp6aSequence():\n    """"""\n    From Hochreiter&Schmidhuber(1997):\n\n        The goal is to classify sequences. Elements and targets are represented locally\n        (input vectors with only one non-zero bit). The sequence starts with an E, ends\n        with a B (the ""trigger symbol"") and otherwise consists of randomly chosen symbols\n        from the set {a, b, c, d} except for two elements at positions t1 and t2 that are\n        either X or Y . The sequence length is randomly chosen between 100 and 110, t1 is\n        randomly chosen between 10 and 20, and t2 is randomly chosen between 50 and 60.\n        There are 4 sequence classes Q, R, S, U which depend on the temporal order of X and Y.\n        The rules are:\n            X, X -> Q,\n            X, Y -> R,\n            Y , X -> S,\n            Y , Y -> U.\n\n    """"""\n\n    def __init__(self, length_range=(100, 111), t1_range=(10, 21), t2_range=(50, 61),\n                 batch_size=32, seed=None):\n\n        self.classes = [\'Q\', \'R\', \'S\', \'U\']\n        self.n_classes = len(self.classes)\n\n        self.relevant_symbols = [\'X\', \'Y\']\n        self.distraction_symbols = [\'a\', \'b\', \'c\', \'d\']\n        self.start_symbol = \'B\'\n        self.end_symbol = \'E\'\n\n        self.length_range = length_range\n        self.t1_range = t1_range\n        self.t2_range = t2_range\n        self.batch_size = batch_size\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        all_symbols = self.relevant_symbols + self.distraction_symbols + \\\n                      [self.start_symbol] + [self.end_symbol]\n        self.n_symbols = len(all_symbols)\n        self.s_to_idx = {s: n for n, s in enumerate(all_symbols)}\n        self.idx_to_s = {n: s for n, s in enumerate(all_symbols)}\n\n        self.c_to_idx = {c: n for n, c in enumerate(self.classes)}\n        self.idx_to_c = {n: c for n, c in enumerate(self.classes)}\n\n    def generate_pair(self):\n        length = np.random.randint(self.length_range[0], self.length_range[1])\n        t1 = np.random.randint(self.t1_range[0], self.t1_range[1])\n        t2 = np.random.randint(self.t2_range[0], self.t2_range[1])\n\n        x = np.random.choice(self.distraction_symbols, length)\n        x[0] = self.start_symbol\n        x[-1] = self.end_symbol\n\n        y = np.random.choice(self.classes)\n        if y == \'Q\':\n            x[t1], x[t2] = self.relevant_symbols[0], self.relevant_symbols[0]\n        elif y == \'R\':\n            x[t1], x[t2] = self.relevant_symbols[0], self.relevant_symbols[1]\n        elif y == \'S\':\n            x[t1], x[t2] = self.relevant_symbols[1], self.relevant_symbols[0]\n        else:\n            x[t1], x[t2] = self.relevant_symbols[1], self.relevant_symbols[1]\n\n        return \'\'.join(x), y\n\n    # encoding/decoding single instance version\n\n    def encode_x(self, x):\n        idx_x = [self.s_to_idx[s] for s in x]\n        return to_categorical(idx_x, num_classes=self.n_symbols)\n\n    def encode_y(self, y):\n        idx_y = self.c_to_idx[y]\n        return to_categorical(idx_y, num_classes=self.n_classes)\n\n    def decode_x(self, x):\n        x = x[np.sum(x, axis=1) > 0]    # remove padding\n        return \'\'.join([self.idx_to_s[pos] for pos in np.argmax(x, axis=1)])\n\n    def decode_y(self, y):\n        return self.idx_to_c[np.argmax(y)]\n\n    # encoding/decoding batch versions\n\n    def encode_x_batch(self, x_batch):\n        return pad_sequences([self.encode_x(x) for x in x_batch],\n                             maxlen=self.length_range[1])\n\n    def encode_y_batch(self, y_batch):\n        return np.array([self.encode_y(y) for y in y_batch])\n\n    def decode_x_batch(self, x_batch):\n        return [self.decode_x(x) for x in x_batch]\n\n    def decode_y_batch(self, y_batch):\n        return [self.idx_to_c[pos] for pos in np.argmax(y_batch, axis=1)]\n\n    def __len__(self):\n        """""" Let\'s assume 1000 sequences as the size of data. """"""\n        return int(1000. / self.batch_size)\n\n    def __getitem__(self, index):\n        batch_x, batch_y = [], []\n        for _ in range(self.batch_size):\n            x, y = self.generate_pair()\n            batch_x.append(x)\n            batch_y.append(y)\n        return self.encode_x_batch(batch_x), self.encode_y_batch(batch_y)\n\n    class DifficultyLevel:\n        """""" On HARD, settings are identical to the original settings from the \'97 paper.""""""\n        EASY, NORMAL, MODERATE, HARD, NIGHTMARE = range(5)\n\n    @staticmethod\n    def get_predefined_generator(difficulty_level, batch_size=32, seed=8382):\n        EASY = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n        NORMAL = TemporalOrderExp6aSequence.DifficultyLevel.NORMAL\n        MODERATE = TemporalOrderExp6aSequence.DifficultyLevel.MODERATE\n        HARD = TemporalOrderExp6aSequence.DifficultyLevel.HARD\n\n        if difficulty_level == EASY:\n            length_range = (7, 9)\n            t1_range = (1, 3)\n            t2_range = (4, 6)\n        elif difficulty_level == NORMAL:\n            length_range = (30, 41)\n            t1_range = (2, 6)\n            t2_range = (20, 28)\n        elif difficulty_level == MODERATE:\n            length_range = (60, 81)\n            t1_range = (10, 21)\n            t2_range = (45, 55)\n        elif difficulty_level == HARD:\n            length_range = (100, 111)\n            t1_range = (10, 21)\n            t2_range = (50, 61)\n        else:\n            length_range = (300, 501)\n            t1_range = (10, 81)\n            t2_range = (250, 291)\n        return TemporalOrderExp6aSequence(length_range, t1_range, t2_range,\n                                          batch_size, seed)\n    '"
extra/utils/optim.py,7,"b'from torch.optim import Optimizer\nimport math\nimport torch\nimport numpy as np\nimport matplotlib\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\n\nclass Optim(Optimizer):\n   \n    def __init__(self, params, defaults):\n        super(Optim, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        """"""Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                self.my_step(p, self.state[p], group)\n        return loss\n    \n    def my_step(self, p, state, group):\n      raise NotImplementedError\n\nplt.ioff() #(interactive mode)\n\nA = torch.tensor([[1.0, 0.0,], [0.0, 5.0]])\nb = torch.tensor([0.0, 0.0])\n\ndef objective(x, y):\n    xy = torch.tensor([x, y])\n    return (0.5 * xy @ (A @ xy) + b @ xy).item()\n\ndelta = 0.025\nx = np.arange(-0.5, 1.5, delta)\ny = np.arange(-8, 1.8, delta)\nX, Y = np.meshgrid(x, y)\nZ = np.copy(X)\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        Z[i, j] = objective(X[i,j], Y[i,j])\n\nw = torch.tensor([1.0, 1.0])\nw.requires_grad_()\n\ndef output(opt, nsteps = 10, noise=0.0, fname=""example.png""):\n    torch.manual_seed(42)\n    w.data[0] = 1.0\n    w.data[1] = 1.0\n\n    xopt = []\n    yopt = []\n\n    for i in range(nsteps):\n        xopt.append(w[0].item())\n        yopt.append(w[1].item())\n\n        def obj():\n            if noise > 0.0:\n                bnoise = torch.normal(b, noise)\n            else:\n                bnoise = b\n            loss = 0.5 * w @ (A @ w) + bnoise @ w\n            opt.zero_grad()\n            loss.backward()\n            return loss\n\n        opt.step(closure=obj)\n\n    fig, ax = plt.subplots(figsize=(3,6))\n    plt.axis(\'equal\')\n    CS = ax.contour(X, Y, Z, levels=[0.01 , 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6])\n    ax.clabel(CS, fontsize=7)\n\n    ax.plot(0, 0, \'.\', color=\'blue\')\n    ax.plot(xopt, yopt, \'-\', color=\'red\')\n    ax.plot(xopt, yopt, \'.\', color=\'black\')\n    plt.ylim([-1.5, 1.5])\n    plt.xlim([-0.6, 1.1])\n\n    # fig.savefig(fname, bbox_inches=\'tight\', pad_inches=0)\n    fig.canvas.draw()\n    plt.show()\n\n'"
