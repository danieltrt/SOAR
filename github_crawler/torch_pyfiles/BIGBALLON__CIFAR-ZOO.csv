file_path,api_count,code
train.py,6,"b'# -*-coding:utf-8-*-\nimport argparse\nimport logging\nimport yaml\nimport time\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom easydict import EasyDict\nfrom models import *\n\nfrom utils import Logger, count_parameters, data_augmentation, \\\n    load_checkpoint, get_data_loader, mixup_data, mixup_criterion, \\\n    save_checkpoint, adjust_learning_rate, get_current_lr\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR Dataset Training\')\nparser.add_argument(\'--work-path\', required=True, type=str)\nparser.add_argument(\'--resume\', action=\'store_true\',\n                    help=\'resume from checkpoint\')\n\nargs = parser.parse_args()\nlogger = Logger(log_file_name=args.work_path + \'/log.txt\',\n                log_level=logging.DEBUG, logger_name=""CIFAR"").get_log()\n\n\ndef train(train_loader, net, criterion, optimizer, epoch, device):\n    global writer\n\n    start = time.time()\n    net.train()\n\n    train_loss = 0\n    correct = 0\n    total = 0\n    logger.info("" === Epoch: [{}/{}] === "".format(epoch + 1, config.epochs))\n\n    for batch_index, (inputs, targets) in enumerate(train_loader):\n        # move tensor to GPU\n        inputs, targets = inputs.to(device), targets.to(device)\n        if config.mixup:\n            inputs, targets_a, targets_b, lam = mixup_data(\n                inputs, targets, config.mixup_alpha, device)\n\n            outputs = net(inputs)\n            loss = mixup_criterion(\n                criterion, outputs, targets_a, targets_b, lam)\n        else:\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n        # zero the gradient buffers\n        optimizer.zero_grad()\n        # backward\n        loss.backward()\n        # update weight\n        optimizer.step()\n\n        # count the loss and acc\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        if config.mixup:\n            correct += (lam * predicted.eq(targets_a).sum().item()\n                        + (1 - lam) * predicted.eq(targets_b).sum().item())\n        else:\n            correct += predicted.eq(targets).sum().item()\n\n        if (batch_index + 1) % 100 == 0:\n            logger.info(""   == step: [{:3}/{}], train loss: {:.3f} | train acc: {:6.3f}% | lr: {:.6f}"".format(\n                batch_index + 1, len(train_loader),\n                train_loss / (batch_index + 1), 100.0 * correct / total, get_current_lr(optimizer)))\n\n    logger.info(""   == step: [{:3}/{}], train loss: {:.3f} | train acc: {:6.3f}% | lr: {:.6f}"".format(\n        batch_index + 1, len(train_loader),\n        train_loss / (batch_index + 1), 100.0 * correct / total, get_current_lr(optimizer)))\n\n    end = time.time()\n    logger.info(""   == cost time: {:.4f}s"".format(end - start))\n    train_loss = train_loss / (batch_index + 1)\n    train_acc = correct / total\n\n    writer.add_scalar(\'train_loss\', train_loss, global_step=epoch)\n    writer.add_scalar(\'train_acc\', train_acc, global_step=epoch)\n\n    return train_loss, train_acc\n\n\ndef test(test_loader, net, criterion, optimizer, epoch, device):\n    global best_prec, writer\n\n    net.eval()\n\n    test_loss = 0\n    correct = 0\n    total = 0\n\n    logger.info("" === Validate ==="".format(epoch + 1, config.epochs))\n\n    with torch.no_grad():\n        for batch_index, (inputs, targets) in enumerate(test_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    logger.info(""   == test loss: {:.3f} | test acc: {:6.3f}%"".format(\n        test_loss / (batch_index + 1), 100.0 * correct / total))\n    test_loss = test_loss / (batch_index + 1)\n    test_acc = correct / total\n    writer.add_scalar(\'test_loss\', test_loss, global_step=epoch)\n    writer.add_scalar(\'test_acc\', test_acc, global_step=epoch)\n    # Save checkpoint.\n    acc = 100. * correct / total\n    state = {\n        \'state_dict\': net.state_dict(),\n        \'best_prec\': best_prec,\n        \'last_epoch\': epoch,\n        \'optimizer\': optimizer.state_dict(),\n    }\n    is_best = acc > best_prec\n    save_checkpoint(state, is_best, args.work_path + \'/\' + config.ckpt_name)\n    if is_best:\n        best_prec = acc\n\n\ndef main():\n    global args, config, last_epoch, best_prec, writer\n    writer = SummaryWriter(log_dir=args.work_path + \'/event\')\n\n    # read config from yaml file\n    with open(args.work_path + \'/config.yaml\') as f:\n        config = yaml.load(f)\n    # convert to dict\n    config = EasyDict(config)\n    logger.info(config)\n\n    # define netowrk\n    net = get_model(config)\n    logger.info(net)\n    logger.info("" == total parameters: "" + str(count_parameters(net)))\n\n    # CPU or GPU\n    device = \'cuda\' if config.use_gpu else \'cpu\'\n    # data parallel for multiple-GPU\n    if device == \'cuda\':\n        net = torch.nn.DataParallel(net)\n        cudnn.benchmark = True\n\n    net.to(device)\n\n    # define loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(\n        net.parameters(),\n        config.lr_scheduler.base_lr,\n        momentum=config.optimize.momentum,\n        weight_decay=config.optimize.weight_decay,\n        nesterov=config.optimize.nesterov)\n\n    # resume from a checkpoint\n    last_epoch = -1\n    best_prec = 0\n    if args.work_path:\n        ckpt_file_name = args.work_path + \'/\' + config.ckpt_name + \'.pth.tar\'\n        if args.resume:\n            best_prec, last_epoch = load_checkpoint(\n                ckpt_file_name, net, optimizer=optimizer)\n\n    # load training data, do data augmentation and get data loader\n    transform_train = transforms.Compose(\n        data_augmentation(config))\n\n    transform_test = transforms.Compose(\n        data_augmentation(config, is_train=False))\n\n    train_loader, test_loader = get_data_loader(\n        transform_train, transform_test, config)\n\n    logger.info(""            =======  Training  =======\\n"")\n    for epoch in range(last_epoch + 1, config.epochs):\n        lr = adjust_learning_rate(optimizer, epoch, config)\n        writer.add_scalar(\'learning_rate\', lr, epoch)\n        train(train_loader, net, criterion, optimizer, epoch, device)\n        if epoch == 0 or (\n                epoch + 1) % config.eval_freq == 0 or epoch == config.epochs - 1:\n            test(test_loader, net, criterion, optimizer, epoch, device)\n    writer.close()\n    logger.info(\n        ""======== Training Finished.   best_test_acc: {:.3f}% ========"".format(best_prec))\n\n\nif __name__ == ""__main__"":\n    main()\n'"
utils.py,6,"b'# -*-coding:utf-8-*-\nimport os\nimport math\nimport shutil\nimport logging\nimport numpy as np\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n\n\nclass Logger(object):\n    def __init__(self, log_file_name, log_level, logger_name):\n        self.__logger = logging.getLogger(logger_name)\n        self.__logger.setLevel(log_level)\n        file_handler = logging.FileHandler(log_file_name)\n        console_handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            \'[%(asctime)s] - [%(filename)s line:%(lineno)d] : %(message)s\')\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n        self.__logger.addHandler(file_handler)\n        self.__logger.addHandler(console_handler)\n\n    def get_log(self):\n        return self.__logger\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef data_augmentation(config, is_train=True):\n    aug = []\n    if is_train:\n        # random crop\n        if config.augmentation.random_crop:\n            aug.append(transforms.RandomCrop(config.input_size, padding=4))\n        # horizontal filp\n        if config.augmentation.random_horizontal_filp:\n            aug.append(transforms.RandomHorizontalFlip())\n\n    aug.append(transforms.ToTensor())\n    # normalize  [- mean / std]\n    if config.augmentation.normalize:\n        if config.dataset == \'cifar10\':\n            aug.append(transforms.Normalize(\n                (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)))\n        else:\n            aug.append(transforms.Normalize(\n                (0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)))\n\n    if is_train and config.augmentation.cutout:\n        # cutout\n        aug.append(Cutout(n_holes=config.augmentation.holes,\n                          length=config.augmentation.length))\n    return aug\n\n\ndef save_checkpoint(state, is_best, filename):\n    torch.save(state, filename + \'.pth.tar\')\n    if is_best:\n        shutil.copyfile(filename + \'.pth.tar\', filename + \'_best.pth.tar\')\n\n\ndef load_checkpoint(path, model, optimizer=None):\n    if os.path.isfile(path):\n        logging.info(""=== loading checkpoint \'{}\' ==="".format(path))\n\n        checkpoint = torch.load(path)\n        model.load_state_dict(checkpoint[\'state_dict\'], strict=False)\n\n        if optimizer is not None:\n            best_prec = checkpoint[\'best_prec\']\n            last_epoch = checkpoint[\'last_epoch\']\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            logging.info(""=== done. also loaded optimizer from "" +\n                         ""checkpoint \'{}\' (epoch {}) ==="".format(\n                             path, last_epoch + 1))\n            return best_prec, last_epoch\n\n\ndef get_data_loader(transform_train, transform_test, config):\n    assert config.dataset == \'cifar10\' or config.dataset == \'cifar100\'\n    if config.dataset == ""cifar10"":\n        trainset = torchvision.datasets.CIFAR10(\n            root=config.data_path, train=True,\n            download=True, transform=transform_train)\n\n        testset = torchvision.datasets.CIFAR10(\n            root=config.data_path, train=False,\n            download=True, transform=transform_test)\n    else:\n        trainset = torchvision.datasets.CIFAR100(\n            root=config.data_path, train=True,\n            download=True, transform=transform_train)\n\n        testset = torchvision.datasets.CIFAR100(\n            root=config.data_path, train=False,\n            download=True, transform=transform_test)\n\n    train_loader = torch.utils.data.DataLoader(\n        trainset, batch_size=config.batch_size,\n        shuffle=True, num_workers=config.workers)\n\n    test_loader = torch.utils.data.DataLoader(\n        testset, batch_size=config.test_batch,\n        shuffle=False, num_workers=config.workers)\n    return train_loader, test_loader\n\n\ndef mixup_data(x, y, alpha, device):\n    \'\'\'Returns mixed inputs, pairs of targets, and lambda\'\'\'\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\ndef get_current_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\'lr\']\n\n\ndef adjust_learning_rate(optimizer, epoch, config):\n    lr = get_current_lr(optimizer)\n    if config.lr_scheduler.type == \'STEP\':\n        if epoch in config.lr_scheduler.lr_epochs:\n            lr *= config.lr_scheduler.lr_mults\n    elif config.lr_scheduler.type == \'COSINE\':\n        ratio = epoch / config.epochs\n        lr = config.lr_scheduler.min_lr + \\\n            (config.lr_scheduler.base_lr - config.lr_scheduler.min_lr) * \\\n            (1.0 + math.cos(math.pi * ratio)) / 2.0\n    elif config.lr_scheduler.type == \'HTD\':\n        ratio = epoch / config.epochs\n        lr = config.lr_scheduler.min_lr + \\\n            (config.lr_scheduler.base_lr - config.lr_scheduler.min_lr) * \\\n            (1.0 - math.tanh(\n                config.lr_scheduler.lower_bound\n                + (config.lr_scheduler.upper_bound\n                   - config.lr_scheduler.lower_bound)\n                * ratio)\n             ) / 2.0\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n'"
models/__init__.py,0,b'# -*-coding:utf-8-*-\nfrom .lenet import *\nfrom .alexnet import *\nfrom .vgg import *\nfrom .resnet import *\nfrom .preresnet import *\nfrom .senet import *\nfrom .resnext import *\nfrom .densenet import *\nfrom .shake_shake import *\nfrom .sknet import *\nfrom .genet import *\nfrom .cbam_resnext import *\n\n\ndef get_model(config):\n    return globals()[config.architecture](config.num_classes)\n'
models/alexnet.py,1,"b""# -*-coding:utf-8-*-\nimport torch.nn as nn\n\n\n__all__ = ['alexnet']\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.fc = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\ndef alexnet(num_classes):\n    return AlexNet(num_classes=num_classes)\n"""
models/cbam_resnext.py,8,"b""# -*-coding:utf-8-*-\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['cbam_resnext29_8x64d', 'cbam_resnext29_16x64d']\n\n\nclass BasicConv(nn.Module):\n    def __init__(\n            self,\n            in_planes,\n            out_planes,\n            kernel_size,\n            stride=1,\n            padding=0,\n            dilation=1,\n            groups=1,\n            relu=True,\n            bn=True,\n            bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(\n            in_planes,\n            out_planes,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            dilation=dilation,\n            groups=groups,\n            bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n                                 momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\n\nclass ChannelGate(nn.Module):\n    def __init__(\n        self,\n        gate_channels,\n        reduction_ratio=16,\n        pool_types=[\n            'avg',\n            'max']):\n        super(ChannelGate, self).__init__()\n        self.gate_channels = gate_channels\n        self.mlp = nn.Sequential(\n            Flatten(),\n            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n            nn.ReLU(),\n            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n        )\n        self.pool_types = pool_types\n\n    def forward(self, x):\n        channel_att_sum = None\n        for pool_type in self.pool_types:\n            if pool_type == 'avg':\n                avg_pool = F.avg_pool2d(\n                    x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(avg_pool)\n            elif pool_type == 'max':\n                max_pool = F.max_pool2d(\n                    x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(max_pool)\n            elif pool_type == 'lp':\n                lp_pool = F.lp_pool2d(\n                    x, 2, (x.size(2), x.size(3)), stride=(\n                        x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(lp_pool)\n            elif pool_type == 'lse':\n                # LSE pool only\n                lse_pool = logsumexp_2d(x)\n                channel_att_raw = self.mlp(lse_pool)\n\n            if channel_att_sum is None:\n                channel_att_sum = channel_att_raw\n            else:\n                channel_att_sum = channel_att_sum + channel_att_raw\n\n        scale = torch.sigmoid(channel_att_sum).unsqueeze(\n            2).unsqueeze(3).expand_as(x)\n        return x * scale\n\n\ndef logsumexp_2d(tensor):\n    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n    return outputs\n\n\nclass ChannelPool(nn.Module):\n    def forward(self, x):\n        return torch.cat(\n            (torch.max(\n                x, 1)[0].unsqueeze(1), torch.mean(\n                x, 1).unsqueeze(1)), dim=1)\n\n\nclass SpatialGate(nn.Module):\n    def __init__(self):\n        super(SpatialGate, self).__init__()\n        kernel_size = 7\n        self.compress = ChannelPool()\n        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(\n            kernel_size - 1) // 2, relu=False)\n\n    def forward(self, x):\n        x_compress = self.compress(x)\n        x_out = self.spatial(x_compress)\n        scale = torch.sigmoid(x_out)  # broadcasting\n        return x * scale\n\n\nclass CBAM(nn.Module):\n    def __init__(\n            self,\n            gate_channels,\n            reduction_ratio=16,\n            pool_types=[\n                'avg',\n                'max'],\n            no_spatial=False):\n        super(CBAM, self).__init__()\n        self.ChannelGate = ChannelGate(\n            gate_channels, reduction_ratio, pool_types)\n        self.no_spatial = no_spatial\n        if not no_spatial:\n            self.SpatialGate = SpatialGate()\n\n    def forward(self, x):\n        x_out = self.ChannelGate(x)\n        if not self.no_spatial:\n            x_out = self.SpatialGate(x_out)\n        return x_out\n\n\nclass Bottleneck(nn.Module):\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            stride,\n            cardinality,\n            base_width,\n            expansion):\n\n        super(Bottleneck, self).__init__()\n        width_ratio = out_channels / (expansion * 64.)\n        D = cardinality * int(base_width * width_ratio)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.cbam_module = CBAM(out_channels)\n\n        self.conv_reduce = nn.Conv2d(\n            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(\n            D,\n            D,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=cardinality,\n            bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(\n            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\n                'shortcut_conv',\n                nn.Conv2d(\n                    in_channels,\n                    out_channels,\n                    kernel_size=1,\n                    stride=stride,\n                    padding=0,\n                    bias=False))\n            self.shortcut.add_module(\n                'shortcut_bn', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        out = self.conv_reduce.forward(x)\n        out = self.relu(self.bn_reduce.forward(out))\n        out = self.conv_conv.forward(out)\n        out = self.relu(self.bn.forward(out))\n        out = self.conv_expand.forward(out)\n        out = self.bn_expand.forward(out)\n\n        residual = self.shortcut.forward(x)\n\n        out = self.cbam_module(out) + residual\n        out = self.relu(out)\n        return out\n\n\nclass SeResNeXt(nn.Module):\n    def __init__(\n            self,\n            cardinality,\n            depth,\n            num_classes,\n            base_width,\n            expansion=4):\n        super(SeResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.base_width = base_width\n        self.expansion = expansion\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.expansion, 128 *\n                       self.expansion, 256 * self.expansion]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n        self.fc = nn.Linear(self.stages[3], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        in_channels,\n                        out_channels,\n                        pool_stride,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n            else:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        out_channels,\n                        out_channels,\n                        1,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, self.stages[3])\n        return self.fc(x)\n\n\ndef cbam_resnext29_8x64d(num_classes):\n    return SeResNeXt(\n        cardinality=8,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n\n\ndef cbam_resnext29_16x64d(num_classes):\n    return SeResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n"""
models/densenet.py,3,"b""# -*-coding:utf-8-*-\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['densenet100bc', 'densenet190bc']\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, in_planes, growth_rate):\n        super(Bottleneck, self).__init__()\n        self.bn_1 = nn.BatchNorm2d(in_planes)\n        self.conv_1 = nn.Conv2d(in_planes, 4 * growth_rate,\n                                kernel_size=1, bias=False)\n        self.bn_2 = nn.BatchNorm2d(4 * growth_rate)\n        self.conv_2 = nn.Conv2d(4 * growth_rate, growth_rate,\n                                kernel_size=3, padding=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv_1(F.relu(self.bn_1(x)))\n        out = self.conv_2(F.relu(self.bn_2(out)))\n        out = torch.cat([out, x], 1)\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, in_planes, out_planes):\n        super(Transition, self).__init__()\n        self.bn = nn.BatchNorm2d(in_planes)\n        self.conv = nn.Conv2d(in_planes, out_planes,\n                              kernel_size=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv(F.relu(self.bn(x)))\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n    def __init__(\n            self, block, depth, growth_rate=12, reduction=0.5, num_classes=10):\n        super(DenseNet, self).__init__()\n        self.growth_rate = growth_rate\n\n        nblocks = (depth - 4) // 6\n        num_planes = 2 * growth_rate\n        self.conv_1 = nn.Conv2d(\n            3, num_planes, kernel_size=3, padding=1, bias=False)\n\n        self.dense1 = self._make_dense_layers(block, num_planes, nblocks)\n        num_planes += nblocks * growth_rate\n        out_planes = int(math.floor(num_planes * reduction))\n        self.trans_1 = Transition(num_planes, out_planes)\n        num_planes = out_planes\n\n        self.dense2 = self._make_dense_layers(block, num_planes, nblocks)\n        num_planes += nblocks * growth_rate\n        out_planes = int(math.floor(num_planes * reduction))\n        self.trans_2 = Transition(num_planes, out_planes)\n        num_planes = out_planes\n\n        self.dense_3 = self._make_dense_layers(block, num_planes, nblocks)\n        num_planes += nblocks * growth_rate\n\n        self.bn = nn.BatchNorm2d(num_planes)\n        self.fc = nn.Linear(num_planes, num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_dense_layers(self, block, in_planes, nblock):\n        layers = []\n        for _ in range(nblock):\n            layers.append(block(in_planes, self.growth_rate))\n            in_planes += self.growth_rate\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv_1(x)\n        out = self.trans_1(self.dense1(out))\n        out = self.trans_2(self.dense2(out))\n        out = self.dense_3(out)\n        out = F.avg_pool2d(F.relu(self.bn(out)), 8)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\n\ndef densenet100bc(num_classes):\n    return DenseNet(\n        Bottleneck,\n        depth=100,\n        growth_rate=12,\n        num_classes=num_classes\n    )\n\n\ndef densenet190bc(num_classes):\n    return DenseNet(\n        Bottleneck,\n        depth=190,\n        growth_rate=40,\n        num_classes=num_classes\n    )\n"""
models/genet.py,3,"b""# -*-coding:utf-8-*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['ge_resnext29_8x64d', 'ge_resnext29_16x64d']\n\n\nclass Downblock(nn.Module):\n    def __init__(self, channels, kernel_size):\n        super(Downblock, self).__init__()\n\n        self.dwconv = nn.Conv2d(channels, channels, groups=channels, stride=1,\n                                kernel_size=kernel_size, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(channels)\n\n    def forward(self, x):\n        x = self.dwconv(x)\n        x = self.bn(x)\n        return x\n\n\nclass GEModule(nn.Module):\n    def __init__(self, in_planes, out_planes, spatial):\n        super(GEModule, self).__init__()\n        self.downop = Downblock(out_planes, kernel_size=spatial)\n\n        self.mlp = nn.Sequential(\n            nn.Conv2d(\n                out_planes,\n                out_planes // 16,\n                kernel_size=1,\n                padding=0,\n                bias=False),\n            nn.ReLU(),\n            nn.Conv2d(\n                out_planes // 16,\n                out_planes,\n                kernel_size=1,\n                padding=0,\n                bias=False))\n\n    def forward(self, x):\n        # Down, up, sigmoid\n        out = self.downop(x)\n        out = self.mlp(out)\n        shape_in = out.shape[-1]\n        out = F.interpolate(out, shape_in)\n        out = torch.sigmoid(out)\n        out = x * out\n        return out\n\n\nclass Bottleneck(nn.Module):\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            stride,\n            spatial,\n            cardinality,\n            base_width,\n            expansion):\n\n        super(Bottleneck, self).__init__()\n        width_ratio = out_channels / (expansion * 64.)\n        D = cardinality * int(base_width * width_ratio)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.ge_module = GEModule(in_channels, out_channels, spatial)\n\n        self.conv_reduce = nn.Conv2d(\n            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(\n            D,\n            D,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=cardinality,\n            bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(\n            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\n                'shortcut_conv',\n                nn.Conv2d(\n                    in_channels,\n                    out_channels,\n                    kernel_size=1,\n                    stride=stride,\n                    padding=0,\n                    bias=False))\n            self.shortcut.add_module(\n                'shortcut_bn', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        out = self.conv_reduce.forward(x)\n        out = self.relu(self.bn_reduce.forward(out))\n        out = self.conv_conv.forward(out)\n        out = self.relu(self.bn.forward(out))\n        out = self.conv_expand.forward(out)\n        out = self.bn_expand.forward(out)\n\n        residual = self.shortcut.forward(x)\n\n        out = self.ge_module(out) + residual\n        out = self.relu(out)\n        return out\n\n\nclass GeResNeXt(nn.Module):\n    def __init__(\n            self,\n            cardinality,\n            depth,\n            num_classes,\n            base_width,\n            expansion=4):\n        super(GeResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.base_width = base_width\n        self.expansion = expansion\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.expansion, 128 *\n                       self.expansion, 256 * self.expansion]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\n            'stage_1', self.stages[0], self.stages[1], 32, 1)\n        self.stage_2 = self.block(\n            'stage_2', self.stages[1], self.stages[2], 16, 2)\n        self.stage_3 = self.block(\n            'stage_3', self.stages[2], self.stages[3], 8, 2)\n        self.fc = nn.Linear(self.stages[3], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def block(self, name, in_channels, out_channels, spatial, pool_stride=2):\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        in_channels,\n                        out_channels,\n                        pool_stride,\n                        spatial,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n            else:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        out_channels,\n                        out_channels,\n                        1,\n                        spatial,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, self.stages[3])\n        return self.fc(x)\n\n\ndef ge_resnext29_8x64d(num_classes):\n    return GeResNeXt(\n        cardinality=8,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n\n\ndef ge_resnext29_16x64d(num_classes):\n    return GeResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n"""
models/lenet.py,2,"b""# -*-coding:utf-8-*-\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['lenet']\n\n\nclass LeNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(LeNet, self).__init__()\n        self.conv_1 = nn.Conv2d(3, 6, 5)\n        self.conv_2 = nn.Conv2d(6, 16, 5)\n        self.fc_1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc_2 = nn.Linear(120, 84)\n        self.fc_3 = nn.Linear(84, num_classes)\n\n    def forward(self, x):\n        out = F.relu(self.conv_1(x))\n        out = F.max_pool2d(out, 2)\n        out = F.relu(self.conv_2(out))\n        out = F.max_pool2d(out, 2)\n        out = out.view(out.size(0), -1)\n        out = F.relu(self.fc_1(out))\n        out = F.relu(self.fc_2(out))\n        out = self.fc_3(out)\n        return out\n\n\ndef lenet(num_classes):\n    return LeNet(num_classes=num_classes)\n"""
models/preresnet.py,1,"b'# -*-coding:utf-8-*-\n\nimport torch.nn as nn\n\n\n__all__ = [\'preresnet20\', \'preresnet32\', \'preresnet44\',\n           \'preresnet56\', \'preresnet110\', \'preresnet1202\']\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn_1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv_1 = conv3x3(inplanes, planes, stride)\n        self.bn_2 = nn.BatchNorm2d(planes)\n        self.conv_2 = conv3x3(planes, planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn_1(x)\n        out = self.relu(out)\n        out = self.conv_1(out)\n\n        out = self.bn_2(out)\n        out = self.relu(out)\n        out = self.conv_2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn_1 = nn.BatchNorm2d(inplanes)\n        self.conv_1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn_2 = nn.BatchNorm2d(planes)\n        self.conv_2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                                padding=1, bias=False)\n        self.bn_3 = nn.BatchNorm2d(planes)\n        self.conv_3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn_1(x)\n        out = self.relu(out)\n        out = self.conv_1(out)\n\n        out = self.bn_2(out)\n        out = self.relu(out)\n        out = self.conv_2(out)\n\n        out = self.bn_3(out)\n        out = self.relu(out)\n        out = self.conv_3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000, block_name=\'BasicBlock\'):\n        super(PreResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == \'basicblock\':\n            assert (\n                depth - 2) % 6 == 0, ""When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202""\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \'bottleneck\':\n            assert (\n                depth - 2) % 9 == 0, ""When use bottleneck, depth should be 9n+2 e.g. 20, 29, 47, 56, 110, 1199""\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\'block_name shoule be Basicblock or Bottleneck\')\n\n        self.inplanes = 16\n        self.conv_1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                                bias=False)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv_1(x)   # 32x32\n\n        x = self.layer1(x)   # 32x32\n        x = self.layer2(x)   # 16x16\n        x = self.layer3(x)   # 8x8\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef preresnet20(num_classes):\n    return PreResNet(depth=20, num_classes=num_classes)\n\n\ndef preresnet32(num_classes):\n    return PreResNet(depth=32, num_classes=num_classes)\n\n\ndef preresnet44(num_classes):\n    return PreResNet(depth=44, num_classes=num_classes)\n\n\ndef preresnet56(num_classes):\n    return PreResNet(depth=56, num_classes=num_classes)\n\n\ndef preresnet110(num_classes):\n    return PreResNet(depth=110, num_classes=num_classes)\n\n\ndef preresnet1202(num_classes):\n    return PreResNet(depth=1202, num_classes=num_classes)\n'"
models/resnet.py,1,"b'# -*-coding:utf-8-*-\n\nimport torch.nn as nn\n\n__all__ = [\'resnet20\', \'resnet32\', \'resnet44\',\n           \'resnet56\', \'resnet110\', \'resnet1202\']\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv_1 = conv3x3(inplanes, planes, stride)\n        self.bn_1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv_2 = conv3x3(planes, planes)\n        self.bn_2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv_1(x)\n        out = self.bn_1(out)\n        out = self.relu(out)\n\n        out = self.conv_2(out)\n        out = self.bn_2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv_1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(planes)\n        self.conv_2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                                padding=1, bias=False)\n        self.bn_2 = nn.BatchNorm2d(planes)\n        self.conv_3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn_3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv_1(x)\n        out = self.bn_1(out)\n        out = self.relu(out)\n\n        out = self.conv_2(out)\n        out = self.bn_2(out)\n        out = self.relu(out)\n\n        out = self.conv_3(out)\n        out = self.bn_3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, num_classes, block_name=\'BasicBlock\'):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name == \'BasicBlock\':\n            assert (\n                depth - 2) % 6 == 0, \'depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\'\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name == \'Bottleneck\':\n            assert (\n                depth - 2) % 9 == 0, \'depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\'\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\'block_name shoule be Basicblock or Bottleneck\')\n\n        self.inplanes = 16\n        self.conv_1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                                bias=False)\n        self.bn_1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.stage_1 = self._make_layer(block, 16, n)\n        self.stage_2 = self._make_layer(block, 32, n, stride=2)\n        self.stage_3 = self._make_layer(block, 64, n, stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                # nn.init.xavier_normal(m.weight.data)\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv_1(x)\n        x = self.bn_1(x)\n        x = self.relu(x)     # 32x32\n\n        x = self.stage_1(x)  # 32x32\n        x = self.stage_2(x)  # 16x16\n        x = self.stage_3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet20(num_classes):\n    return ResNet(depth=20, num_classes=num_classes)\n\n\ndef resnet32(num_classes):\n    return ResNet(depth=32, num_classes=num_classes)\n\n\ndef resnet44(num_classes):\n    return ResNet(depth=44, num_classes=num_classes)\n\n\ndef resnet56(num_classes):\n    return ResNet(depth=56, num_classes=num_classes)\n\n\ndef resnet110(num_classes):\n    return ResNet(depth=110, num_classes=num_classes)\n\n\ndef resnet1202(num_classes):\n    return ResNet(depth=1202, num_classes=num_classes)\n'"
models/resnext.py,2,"b'# -*-coding:utf-8-*-\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = [\'resnext29_8x64d\', \'resnext29_16x64d\']\n\n\nclass Bottleneck(nn.Module):\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            stride,\n            cardinality,\n            base_width,\n            expansion):\n\n        super(Bottleneck, self).__init__()\n        width_ratio = out_channels / (expansion * 64.)\n        D = cardinality * int(base_width * width_ratio)\n\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv_reduce = nn.Conv2d(\n            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(\n            D,\n            D,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=cardinality,\n            bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(\n            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\n                \'shortcut_conv\',\n                nn.Conv2d(\n                    in_channels,\n                    out_channels,\n                    kernel_size=1,\n                    stride=stride,\n                    padding=0,\n                    bias=False))\n            self.shortcut.add_module(\n                \'shortcut_bn\', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        out = self.conv_reduce.forward(x)\n        out = self.relu(self.bn_reduce.forward(out))\n        out = self.conv_conv.forward(out)\n        out = self.relu(self.bn.forward(out))\n        out = self.conv_expand.forward(out)\n        out = self.bn_expand.forward(out)\n        residual = self.shortcut.forward(x)\n        return self.relu(residual + out)\n\n\nclass ResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the Cifar dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n\n    def __init__(\n            self,\n            cardinality,\n            depth,\n            num_classes,\n            base_width,\n            expansion=4):\n        """""" Constructor\n        Args:\n            cardinality: number of convolution groups.\n            depth: number of layers.\n            num_classes: number of classes\n            base_width: base number of channels in each group.\n            expansion: factor to adjust the channel dimensionality\n        """"""\n        super(ResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.base_width = base_width\n        self.expansion = expansion\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.expansion, 128 *\n                       self.expansion, 256 * self.expansion]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\'stage_1\', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block(\'stage_2\', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block(\'stage_3\', self.stages[2], self.stages[3], 2)\n        self.fc = nn.Linear(self.stages[3], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = \'%s_bottleneck_%d\' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        in_channels,\n                        out_channels,\n                        pool_stride,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n            else:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        out_channels,\n                        out_channels,\n                        1,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, self.stages[3])\n        return self.fc(x)\n\n\ndef resnext29_8x64d(num_classes):\n    return ResNeXt(\n        cardinality=8,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n\n\ndef resnext29_16x64d(num_classes):\n    return ResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n'"
models/senet.py,2,"b""# -*-coding:utf-8-*-\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['se_resnext29_8x64d', 'se_resnext29_16x64d']\n\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction=16):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc_1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n                              padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc_2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n                              padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        original = x\n        x = self.avg_pool(x)\n        x = self.fc_1(x)\n        x = self.relu(x)\n        x = self.fc_2(x)\n        x = self.sigmoid(x)\n        return original * x\n\n\nclass Bottleneck(nn.Module):\n\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            stride,\n            cardinality,\n            base_width,\n            expansion):\n\n        super(Bottleneck, self).__init__()\n        width_ratio = out_channels / (expansion * 64.)\n        D = cardinality * int(base_width * width_ratio)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(out_channels)\n\n        self.conv_reduce = nn.Conv2d(\n            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(\n            D,\n            D,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=cardinality,\n            bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(\n            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\n                'shortcut_conv',\n                nn.Conv2d(\n                    in_channels,\n                    out_channels,\n                    kernel_size=1,\n                    stride=stride,\n                    padding=0,\n                    bias=False))\n            self.shortcut.add_module(\n                'shortcut_bn', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        out = self.conv_reduce.forward(x)\n        out = self.relu(self.bn_reduce.forward(out))\n        out = self.conv_conv.forward(out)\n        out = self.relu(self.bn.forward(out))\n        out = self.conv_expand.forward(out)\n        out = self.bn_expand.forward(out)\n\n        residual = self.shortcut.forward(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n        return out\n\n\nclass SeResNeXt(nn.Module):\n    def __init__(\n            self,\n            cardinality,\n            depth,\n            num_classes,\n            base_width,\n            expansion=4):\n        super(SeResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.base_width = base_width\n        self.expansion = expansion\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.expansion, 128 *\n                       self.expansion, 256 * self.expansion]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n        self.fc = nn.Linear(self.stages[3], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        in_channels,\n                        out_channels,\n                        pool_stride,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n            else:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        out_channels,\n                        out_channels,\n                        1,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, x.size(3), 1)\n        x = x.view(-1, self.stages[3])\n        return self.fc(x)\n\n\ndef se_resnext29_8x64d(num_classes):\n    return SeResNeXt(\n        cardinality=8,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n\n\ndef se_resnext29_16x64d(num_classes):\n    return SeResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64)\n"""
models/shake_shake.py,7,"b""# -*-coding:utf-8-*-\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n\n__all__ = ['shake_resnet26_2x32d', 'shake_resnet26_2x64d']\n\n\nclass ShakeShake(torch.autograd.Function):\n\n    @staticmethod\n    def forward(ctx, x1, x2, training=True):\n        if training:\n            alpha = torch.cuda.FloatTensor(x1.size(0)).uniform_()\n            alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x1)\n        else:\n            alpha = 0.5\n        return alpha * x1 + (1 - alpha) * x2\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_()\n        beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n        beta = Variable(beta)\n\n        return beta * grad_output, (1 - beta) * grad_output, None\n\n\nclass Shortcut(nn.Module):\n\n    def __init__(self, in_ch, out_ch, stride):\n        super(Shortcut, self).__init__()\n        self.stride = stride\n        self.conv1 = nn.Conv2d(in_ch, out_ch // 2, 1,\n                               stride=1, padding=0, bias=False)\n        self.conv2 = nn.Conv2d(in_ch, out_ch // 2, 1,\n                               stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(out_ch)\n\n    def forward(self, x):\n        h = F.relu(x)\n\n        h1 = F.avg_pool2d(h, 1, self.stride)\n        h1 = self.conv1(h1)\n\n        h2 = F.avg_pool2d(F.pad(h, (-1, 1, -1, 1)), 1, self.stride)\n        h2 = self.conv2(h2)\n\n        h = torch.cat((h1, h2), 1)\n        return self.bn(h)\n\n\nclass ShakeBlock(nn.Module):\n\n    def __init__(self, in_ch, out_ch, stride=1):\n        super(ShakeBlock, self).__init__()\n        self.equal_io = in_ch == out_ch\n        self.shortcut = self.equal_io and None or Shortcut(\n            in_ch, out_ch, stride=stride)\n\n        self.branch1 = self._make_branch(in_ch, out_ch, stride)\n        self.branch2 = self._make_branch(in_ch, out_ch, stride)\n\n    def forward(self, x):\n        h1 = self.branch1(x)\n        h2 = self.branch2(x)\n        h = ShakeShake.apply(h1, h2, self.training)\n        h0 = x if self.equal_io else self.shortcut(x)\n        return h + h0\n\n    def _make_branch(self, in_ch, out_ch, stride=1):\n        return nn.Sequential(\n            nn.ReLU(inplace=False),\n            nn.Conv2d(in_ch, out_ch, 3, padding=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=False),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1, stride=1, bias=False),\n            nn.BatchNorm2d(out_ch))\n\n\nclass ShakeResNet(nn.Module):\n\n    def __init__(self, depth, base_width, num_classes):\n        super(ShakeResNet, self).__init__()\n        n_units = (depth - 2) / 6\n\n        in_chs = [16, base_width, base_width * 2, base_width * 4]\n        self.in_chs = in_chs\n\n        self.conv_1 = nn.Conv2d(3, in_chs[0], 3, padding=1)\n        self.bn_1 = nn.BatchNorm2d(in_chs[0])\n\n        self.stage_1 = self._make_layer(n_units, in_chs[0], in_chs[1])\n        self.stage_2 = self._make_layer(n_units, in_chs[1], in_chs[2], 2)\n        self.stage_3 = self._make_layer(n_units, in_chs[2], in_chs[3], 2)\n        self.fc_out = nn.Linear(in_chs[3], num_classes)\n\n        # Initialize paramters\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = self.conv_1(x)\n        out = self.bn_1(out)\n        out = self.stage_1(out)\n        out = self.stage_2(out)\n        out = self.stage_3(out)\n        out = F.relu(out)\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.in_chs[3])\n        out = self.fc_out(out)\n        return out\n\n    def _make_layer(self, n_units, in_ch, out_ch, stride=1):\n        layers = []\n        for _ in range(int(n_units)):\n            layers.append(ShakeBlock(in_ch, out_ch, stride=stride))\n            in_ch, stride = out_ch, 1\n        return nn.Sequential(*layers)\n\n\ndef shake_resnet26_2x32d(num_classes):\n    return ShakeResNet(depth=26, base_width=32, num_classes=num_classes)\n\n\ndef shake_resnet26_2x64d(num_classes):\n    return ShakeResNet(depth=26, base_width=64, num_classes=num_classes)\n"""
models/sknet.py,5,"b'# -*-coding:utf-8-*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = [\'sk_resnext29_16x32d\', \'sk_resnext29_16x64d\']\n\n\nclass SKConv(nn.Module):\n    def __init__(self, features, M, G, r, stride=1, L=32):\n        """""" Constructor\n        Args:\n            features: input channel dimensionality.\n            M: the number of branchs.\n            G: num of convolution groups.\n            r: the radio for compute d, the length of z.\n            stride: stride, default 1.\n            L: the minimum dim of the vector z in paper, default 32.\n        """"""\n        super(SKConv, self).__init__()\n        d = max(int(features / r), L)\n        self.convs = nn.ModuleList([])\n        for i in range(M):\n            self.convs.append(nn.Sequential(\n                nn.Conv2d(features, features, kernel_size=1 + i * 2,\n                          stride=stride, padding=i, groups=G),\n                nn.BatchNorm2d(features),\n                nn.ReLU(inplace=False)\n            ))\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(features, d)\n        self.fcs = nn.ModuleList([])\n        for i in range(M):\n            self.fcs.append(\n                nn.Linear(d, features)\n            )\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        for i, conv in enumerate(self.convs):\n            fea = conv(x).unsqueeze_(dim=1)\n            if i == 0:\n                feas = fea\n            else:\n                feas = torch.cat([feas, fea], dim=1)\n        fea_U = torch.sum(feas, dim=1)\n        fea_s = self.gap(fea_U).squeeze_()\n        fea_z = self.fc(fea_s)\n        for i, fc in enumerate(self.fcs):\n            vector = fc(fea_z).unsqueeze_(dim=1)\n            if i == 0:\n                attention_vectors = vector\n            else:\n                attention_vectors = torch.cat(\n                    [attention_vectors, vector], dim=1)\n        attention_vectors = self.softmax(attention_vectors)\n        attention_vectors = attention_vectors.unsqueeze(-1).unsqueeze(-1)\n        fea_v = (feas * attention_vectors).sum(dim=1)\n        return fea_v\n\n\nclass Bottleneck(nn.Module):\n\n    def __init__(\n        self, in_channels, out_channels, stride, cardinality,\n        base_width, expansion, M, r, L\n    ):\n        super(Bottleneck, self).__init__()\n        width_ratio = out_channels / (expansion * 64.)\n        D = cardinality * int(base_width * width_ratio)\n\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv_reduce = nn.Conv2d(\n            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n\n        self.conv_sk = SKConv(D, M, cardinality, r, stride=stride, L=L)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(\n            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\n                \'shortcut_conv\',\n                nn.Conv2d(\n                    in_channels, out_channels, kernel_size=1, stride=stride,\n                    padding=0, bias=False\n                )\n            )\n            self.shortcut.add_module(\n                \'shortcut_bn\', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        out = self.conv_reduce.forward(x)\n        out = self.relu(self.bn_reduce.forward(out))\n        out = self.conv_sk.forward(out)\n        out = self.relu(self.bn.forward(out))\n        out = self.conv_expand.forward(out)\n        out = self.bn_expand.forward(out)\n        residual = self.shortcut.forward(x)\n        return self.relu(residual + out)\n\n\nclass SkResNeXt(nn.Module):\n    def __init__(\n            self, cardinality, depth, num_classes, base_width, expansion=4,\n            M=2, r=32, L=32\n    ):\n        super(SkResNeXt, self).__init__()\n        self.M = M\n        self.r = r\n        self.L = L\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.base_width = base_width\n        self.expansion = expansion\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.expansion, 128 *\n                       self.expansion, 256 * self.expansion]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\'stage_1\', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block(\'stage_2\', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block(\'stage_3\', self.stages[2], self.stages[3], 2)\n        self.fc = nn.Linear(self.stages[3], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = \'%s_bottleneck_%d\' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        in_channels,\n                        out_channels,\n                        pool_stride,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion,\n                        self.M,\n                        self.r,\n                        self.L)\n                )\n            else:\n                block.add_module(\n                    name_,\n                    Bottleneck(\n                        out_channels,\n                        out_channels,\n                        1,\n                        self.cardinality,\n                        self.base_width,\n                        self.expansion,\n                        self.M, self.r, self.L\n                    )\n                )\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, self.stages[3])\n        return self.fc(x)\n\n\ndef sk_resnext29_16x32d(num_classes):\n    return SkResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=32\n    )\n\n\ndef sk_resnext29_16x64d(num_classes):\n    return SkResNeXt(\n        cardinality=16,\n        depth=29,\n        num_classes=num_classes,\n        base_width=64\n    )\n'"
models/vgg.py,1,"b""# -*-coding:utf-8-*-\nimport torch.nn as nn\n\n__all__ = ['vgg11', 'vgg13', 'vgg16', 'vgg19']\n\ncfg = {\n    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M',\n          512, 512, 'M'],\n    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512,\n          512, 512, 'M', 512, 512, 512, 'M'],\n    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512,\n          512, 'M', 512, 512, 512, 512, 'M'],\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=10):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Linear(512, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ndef vgg11(num_classes):\n    return VGG(make_layers(cfg['A'], batch_norm=True), num_classes)\n\n\ndef vgg13(num_classes):\n    return VGG(make_layers(cfg['B'], batch_norm=True), num_classes)\n\n\ndef vgg16(num_classes):\n    return VGG(make_layers(cfg['D'], batch_norm=True), num_classes)\n\n\ndef vgg19(num_classes):\n    return VGG(make_layers(cfg['E'], batch_norm=True), num_classes)\n"""
