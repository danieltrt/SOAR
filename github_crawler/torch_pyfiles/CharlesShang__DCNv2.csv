file_path,api_count,code
__init__.py,0,b''
dcn_v2.py,11,"b'#!/usr/bin/env python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport math\nimport torch\nfrom torch import nn\nfrom torch.autograd import Function\nfrom torch.nn.modules.utils import _pair\nfrom torch.autograd.function import once_differentiable\n\nimport _ext as _backend\n\n\nclass _DCNv2(Function):\n    @staticmethod\n    def forward(ctx, input, offset, mask, weight, bias,\n                stride, padding, dilation, deformable_groups):\n        ctx.stride = _pair(stride)\n        ctx.padding = _pair(padding)\n        ctx.dilation = _pair(dilation)\n        ctx.kernel_size = _pair(weight.shape[2:4])\n        ctx.deformable_groups = deformable_groups\n        output = _backend.dcn_v2_forward(input, weight, bias,\n                                         offset, mask,\n                                         ctx.kernel_size[0], ctx.kernel_size[1],\n                                         ctx.stride[0], ctx.stride[1],\n                                         ctx.padding[0], ctx.padding[1],\n                                         ctx.dilation[0], ctx.dilation[1],\n                                         ctx.deformable_groups)\n        ctx.save_for_backward(input, offset, mask, weight, bias)\n        return output\n\n    @staticmethod\n    @once_differentiable\n    def backward(ctx, grad_output):\n        input, offset, mask, weight, bias = ctx.saved_tensors\n        grad_input, grad_offset, grad_mask, grad_weight, grad_bias = \\\n            _backend.dcn_v2_backward(input, weight,\n                                     bias,\n                                     offset, mask,\n                                     grad_output,\n                                     ctx.kernel_size[0], ctx.kernel_size[1],\n                                     ctx.stride[0], ctx.stride[1],\n                                     ctx.padding[0], ctx.padding[1],\n                                     ctx.dilation[0], ctx.dilation[1],\n                                     ctx.deformable_groups)\n\n        return grad_input, grad_offset, grad_mask, grad_weight, grad_bias,\\\n            None, None, None, None,\n\n\ndcn_v2_conv = _DCNv2.apply\n\n\nclass DCNv2(nn.Module):\n\n    def __init__(self, in_channels, out_channels,\n                 kernel_size, stride, padding, dilation=1, deformable_groups=1):\n        super(DCNv2, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = _pair(kernel_size)\n        self.stride = _pair(stride)\n        self.padding = _pair(padding)\n        self.dilation = _pair(dilation)\n        self.deformable_groups = deformable_groups\n\n        self.weight = nn.Parameter(torch.Tensor(\n            out_channels, in_channels, *self.kernel_size))\n        self.bias = nn.Parameter(torch.Tensor(out_channels))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        n = self.in_channels\n        for k in self.kernel_size:\n            n *= k\n        stdv = 1. / math.sqrt(n)\n        self.weight.data.uniform_(-stdv, stdv)\n        self.bias.data.zero_()\n\n    def forward(self, input, offset, mask):\n        assert 2 * self.deformable_groups * self.kernel_size[0] * self.kernel_size[1] == \\\n            offset.shape[1]\n        assert self.deformable_groups * self.kernel_size[0] * self.kernel_size[1] == \\\n            mask.shape[1]\n        return dcn_v2_conv(input, offset, mask,\n                           self.weight,\n                           self.bias,\n                           self.stride,\n                           self.padding,\n                           self.dilation,\n                           self.deformable_groups)\n\n\nclass DCN(DCNv2):\n\n    def __init__(self, in_channels, out_channels,\n                 kernel_size, stride, padding,\n                 dilation=1, deformable_groups=1):\n        super(DCN, self).__init__(in_channels, out_channels,\n                                  kernel_size, stride, padding, dilation, deformable_groups)\n\n        channels_ = self.deformable_groups * 3 * self.kernel_size[0] * self.kernel_size[1]\n        self.conv_offset_mask = nn.Conv2d(self.in_channels,\n                                          channels_,\n                                          kernel_size=self.kernel_size,\n                                          stride=self.stride,\n                                          padding=self.padding,\n                                          bias=True)\n        self.init_offset()\n\n    def init_offset(self):\n        self.conv_offset_mask.weight.data.zero_()\n        self.conv_offset_mask.bias.data.zero_()\n\n    def forward(self, input):\n        out = self.conv_offset_mask(input)\n        o1, o2, mask = torch.chunk(out, 3, dim=1)\n        offset = torch.cat((o1, o2), dim=1)\n        mask = torch.sigmoid(mask)\n        return dcn_v2_conv(input, offset, mask,\n                           self.weight, self.bias,\n                           self.stride,\n                           self.padding,\n                           self.dilation,\n                           self.deformable_groups)\n\n\n\nclass _DCNv2Pooling(Function):\n    @staticmethod\n    def forward(ctx, input, rois, offset,\n                spatial_scale,\n                pooled_size,\n                output_dim,\n                no_trans,\n                group_size=1,\n                part_size=None,\n                sample_per_part=4,\n                trans_std=.0):\n        ctx.spatial_scale = spatial_scale\n        ctx.no_trans = int(no_trans)\n        ctx.output_dim = output_dim\n        ctx.group_size = group_size\n        ctx.pooled_size = pooled_size\n        ctx.part_size = pooled_size if part_size is None else part_size\n        ctx.sample_per_part = sample_per_part\n        ctx.trans_std = trans_std\n\n        output, output_count = \\\n            _backend.dcn_v2_psroi_pooling_forward(input, rois, offset,\n                                                  ctx.no_trans, ctx.spatial_scale,\n                                                  ctx.output_dim, ctx.group_size,\n                                                  ctx.pooled_size, ctx.part_size,\n                                                  ctx.sample_per_part, ctx.trans_std)\n        ctx.save_for_backward(input, rois, offset, output_count)\n        return output\n\n    @staticmethod\n    @once_differentiable\n    def backward(ctx, grad_output):\n        input, rois, offset, output_count = ctx.saved_tensors\n        grad_input, grad_offset = \\\n            _backend.dcn_v2_psroi_pooling_backward(grad_output,\n                                                   input,\n                                                   rois,\n                                                   offset,\n                                                   output_count,\n                                                   ctx.no_trans,\n                                                   ctx.spatial_scale,\n                                                   ctx.output_dim,\n                                                   ctx.group_size,\n                                                   ctx.pooled_size,\n                                                   ctx.part_size,\n                                                   ctx.sample_per_part,\n                                                   ctx.trans_std)\n\n        return grad_input, None, grad_offset, \\\n            None, None, None, None, None, None, None, None\n\n\ndcn_v2_pooling = _DCNv2Pooling.apply\n\n\nclass DCNv2Pooling(nn.Module):\n\n    def __init__(self,\n                 spatial_scale,\n                 pooled_size,\n                 output_dim,\n                 no_trans,\n                 group_size=1,\n                 part_size=None,\n                 sample_per_part=4,\n                 trans_std=.0):\n        super(DCNv2Pooling, self).__init__()\n        self.spatial_scale = spatial_scale\n        self.pooled_size = pooled_size\n        self.output_dim = output_dim\n        self.no_trans = no_trans\n        self.group_size = group_size\n        self.part_size = pooled_size if part_size is None else part_size\n        self.sample_per_part = sample_per_part\n        self.trans_std = trans_std\n\n    def forward(self, input, rois, offset):\n        assert input.shape[1] == self.output_dim\n        if self.no_trans:\n            offset = input.new()\n        return dcn_v2_pooling(input, rois, offset,\n                              self.spatial_scale,\n                              self.pooled_size,\n                              self.output_dim,\n                              self.no_trans,\n                              self.group_size,\n                              self.part_size,\n                              self.sample_per_part,\n                              self.trans_std)\n\n\nclass DCNPooling(DCNv2Pooling):\n\n    def __init__(self,\n                 spatial_scale,\n                 pooled_size,\n                 output_dim,\n                 no_trans,\n                 group_size=1,\n                 part_size=None,\n                 sample_per_part=4,\n                 trans_std=.0,\n                 deform_fc_dim=1024):\n        super(DCNPooling, self).__init__(spatial_scale,\n                                         pooled_size,\n                                         output_dim,\n                                         no_trans,\n                                         group_size,\n                                         part_size,\n                                         sample_per_part,\n                                         trans_std)\n\n        self.deform_fc_dim = deform_fc_dim\n\n        if not no_trans:\n            self.offset_mask_fc = nn.Sequential(\n                nn.Linear(self.pooled_size * self.pooled_size *\n                          self.output_dim, self.deform_fc_dim),\n                nn.ReLU(inplace=True),\n                nn.Linear(self.deform_fc_dim, self.deform_fc_dim),\n                nn.ReLU(inplace=True),\n                nn.Linear(self.deform_fc_dim, self.pooled_size *\n                          self.pooled_size * 3)\n            )\n            self.offset_mask_fc[4].weight.data.zero_()\n            self.offset_mask_fc[4].bias.data.zero_()\n\n    def forward(self, input, rois):\n        offset = input.new()\n\n        if not self.no_trans:\n\n            # do roi_align first\n            n = rois.shape[0]\n            roi = dcn_v2_pooling(input, rois, offset,\n                                 self.spatial_scale,\n                                 self.pooled_size,\n                                 self.output_dim,\n                                 True,  # no trans\n                                 self.group_size,\n                                 self.part_size,\n                                 self.sample_per_part,\n                                 self.trans_std)\n\n            # build mask and offset\n            offset_mask = self.offset_mask_fc(roi.view(n, -1))\n            offset_mask = offset_mask.view(\n                n, 3, self.pooled_size, self.pooled_size)\n            o1, o2, mask = torch.chunk(offset_mask, 3, dim=1)\n            offset = torch.cat((o1, o2), dim=1)\n            mask = torch.sigmoid(mask)\n\n            # do pooling with offset and mask\n            return dcn_v2_pooling(input, rois, offset,\n                                  self.spatial_scale,\n                                  self.pooled_size,\n                                  self.output_dim,\n                                  self.no_trans,\n                                  self.group_size,\n                                  self.part_size,\n                                  self.sample_per_part,\n                                  self.trans_std) * mask\n        # only roi_align\n        return dcn_v2_pooling(input, rois, offset,\n                              self.spatial_scale,\n                              self.pooled_size,\n                              self.output_dim,\n                              self.no_trans,\n                              self.group_size,\n                              self.part_size,\n                              self.sample_per_part,\n                              self.trans_std)\n'"
setup.py,5,"b'#!/usr/bin/env python\n\nimport os\nimport glob\n\nimport torch\n\nfrom torch.utils.cpp_extension import CUDA_HOME\nfrom torch.utils.cpp_extension import CppExtension\nfrom torch.utils.cpp_extension import CUDAExtension\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nrequirements = [""torch"", ""torchvision""]\n\n\ndef get_extensions():\n    this_dir = os.path.dirname(os.path.abspath(__file__))\n    extensions_dir = os.path.join(this_dir, ""src"")\n\n    main_file = glob.glob(os.path.join(extensions_dir, ""*.cpp""))\n    source_cpu = glob.glob(os.path.join(extensions_dir, ""cpu"", ""*.cpp""))\n    source_cuda = glob.glob(os.path.join(extensions_dir, ""cuda"", ""*.cu""))\n    \n    os.environ[""CC""] = ""g++""\n    sources = main_file + source_cpu\n    extension = CppExtension\n    extra_compile_args = {""cxx"": []}\n    define_macros = []\n\n    \n    if torch.cuda.is_available() and CUDA_HOME is not None:\n        extension = CUDAExtension\n        sources += source_cuda\n        define_macros += [(""WITH_CUDA"", None)]\n        extra_compile_args[""nvcc""] = [\n            ""-DCUDA_HAS_FP16=1"",\n            ""-D__CUDA_NO_HALF_OPERATORS__"",\n            ""-D__CUDA_NO_HALF_CONVERSIONS__"",\n            ""-D__CUDA_NO_HALF2_OPERATORS__"",\n        ]\n    else:\n        #raise NotImplementedError(\'Cuda is not available\')\n        pass\n    \n\n    sources = [os.path.join(extensions_dir, s) for s in sources]\n    include_dirs = [extensions_dir]\n    ext_modules = [\n        extension(\n            ""_ext"",\n            sources,\n            include_dirs=include_dirs,\n            define_macros=define_macros,\n            extra_compile_args=extra_compile_args,\n        )\n    ]\n    return ext_modules\n\nsetup(\n    name=""DCNv2"",\n    version=""0.1"",\n    author=""charlesshang"",\n    url=""https://github.com/charlesshang/DCNv2"",\n    description=""deformable convolutional networks"",\n    packages=find_packages(exclude=(""configs"", ""tests"",)),\n    # install_requires=requirements,\n    ext_modules=get_extensions(),\n    cmdclass={""build_ext"": torch.utils.cpp_extension.BuildExtension},\n)'"
testcpu.py,37,"b'#!/usr/bin/env python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport time\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import gradcheck\n\nfrom dcn_v2 import dcn_v2_conv, DCNv2, DCN\nfrom dcn_v2 import dcn_v2_pooling, DCNv2Pooling, DCNPooling\n\ndeformable_groups = 1\nN, inC, inH, inW = 2, 2, 4, 4\noutC = 2\nkH, kW = 3, 3\n\n\ndef conv_identify(weight, bias):\n    weight.data.zero_()\n    bias.data.zero_()\n    o, i, h, w = weight.shape\n    y = h//2\n    x = w//2\n    for p in range(i):\n        for q in range(o):\n            if p == q:\n                weight.data[q, p, y, x] = 1.0\n\n\ndef check_zero_offset():\n    conv_offset = nn.Conv2d(inC, deformable_groups * 2 * kH * kW,\n                            kernel_size=(kH, kW),\n                            stride=(1, 1),\n                            padding=(1, 1),\n                            bias=True)\n\n    conv_mask = nn.Conv2d(inC, deformable_groups * 1 * kH * kW,\n                          kernel_size=(kH, kW),\n                          stride=(1, 1),\n                          padding=(1, 1),\n                          bias=True)\n\n    dcn_v2 = DCNv2(inC, outC, (kH, kW),\n                   stride=1, padding=1, dilation=1,\n                   deformable_groups=deformable_groups)\n\n    conv_offset.weight.data.zero_()\n    conv_offset.bias.data.zero_()\n    conv_mask.weight.data.zero_()\n    conv_mask.bias.data.zero_()\n    conv_identify(dcn_v2.weight, dcn_v2.bias)\n\n    input = torch.randn(N, inC, inH, inW)\n    offset = conv_offset(input)\n    mask = conv_mask(input)\n    mask = torch.sigmoid(mask)\n    output = dcn_v2(input, offset, mask)\n    output *= 2\n    d = (input - output).abs().max()\n    if d < 1e-10:\n        print(\'Zero offset passed\')\n    else:\n        print(\'Zero offset failed\')\n        print(input)\n        print(output)\n\ndef check_gradient_dconv():\n\n    input = torch.rand(N, inC, inH, inW) * 0.01\n    input.requires_grad = True\n\n    offset = torch.randn(N, deformable_groups * 2 * kW * kH, inH, inW) * 2\n    # offset.data.zero_()\n    # offset.data -= 0.5\n    offset.requires_grad = True\n\n    mask = torch.rand(N, deformable_groups * 1 * kW * kH, inH, inW)\n    # mask.data.zero_()\n    mask.requires_grad = True\n    mask = torch.sigmoid(mask)\n\n    weight = torch.randn(outC, inC, kH, kW)\n    weight.requires_grad = True\n\n    bias = torch.rand(outC)\n    bias.requires_grad = True\n\n    stride = 1\n    padding = 1\n    dilation = 1\n\n    print(\'check_gradient_dconv: \',\n          gradcheck(dcn_v2_conv, (input, offset, mask, weight, bias,\n                    stride, padding, dilation, deformable_groups),\n                    eps=1e-3, atol=1e-4, rtol=1e-2))\n\n\ndef check_pooling_zero_offset():\n\n    input = torch.randn(2, 16, 64, 64).zero_()\n    input[0, :, 16:26, 16:26] = 1.\n    input[1, :, 10:20, 20:30] = 2.\n    rois = torch.tensor([\n        [0, 65, 65, 103, 103],\n        [1, 81, 41, 119, 79],\n    ]).float()\n    pooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                           pooled_size=7,\n                           output_dim=16,\n                           no_trans=True,\n                           group_size=1,\n                           trans_std=0.0)\n\n    out = pooling(input, rois, input.new())\n    s = \', \'.join([\'%f\' % out[i, :, :, :].mean().item()\n                   for i in range(rois.shape[0])])\n    print(s)\n\n    dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                            pooled_size=7,\n                            output_dim=16,\n                            no_trans=False,\n                            group_size=1,\n                            trans_std=0.0)\n    offset = torch.randn(20, 2, 7, 7).zero_()\n    dout = dpooling(input, rois, offset)\n    s = \', \'.join([\'%f\' % dout[i, :, :, :].mean().item()\n                   for i in range(rois.shape[0])])\n    print(s)\n\n\ndef check_gradient_dpooling():\n    input = torch.randn(2, 3, 5, 5) * 0.01\n    N = 4\n    batch_inds = torch.randint(2, (N, 1)).float()\n    x = torch.rand((N, 1)).float() * 15\n    y = torch.rand((N, 1)).float() * 15\n    w = torch.rand((N, 1)).float() * 10\n    h = torch.rand((N, 1)).float() * 10\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n    offset = torch.randn(N, 2, 3, 3)\n    input.requires_grad = True\n    offset.requires_grad = True\n\n    spatial_scale = 1.0 / 4\n    pooled_size = 3\n    output_dim = 3\n    no_trans = 0\n    group_size = 1\n    trans_std = 0.0\n    sample_per_part = 4\n    part_size = pooled_size\n\n    print(\'check_gradient_dpooling:\',\n          gradcheck(dcn_v2_pooling, (input, rois, offset,\n                                     spatial_scale,\n                                     pooled_size,\n                                     output_dim,\n                                     no_trans,\n                                     group_size,\n                                     part_size,\n                                     sample_per_part,\n                                     trans_std),\n                    eps=1e-4))\n\n\ndef example_dconv():\n    input = torch.randn(2, 64, 128, 128)\n    # wrap all things (offset and mask) in DCN\n    dcn = DCN(64, 64, kernel_size=(3, 3), stride=1,\n              padding=1, deformable_groups=2)\n    # print(dcn.weight.shape, input.shape)\n    output = dcn(input)\n    targert = output.new(*output.size())\n    targert.data.uniform_(-0.01, 0.01)\n    error = (targert - output).mean()\n    error.backward()\n    print(output.shape)\n\n\ndef example_dpooling():\n    input = torch.randn(2, 32, 64, 64)\n    batch_inds = torch.randint(2, (20, 1)).float()\n    x = torch.randint(256, (20, 1)).float()\n    y = torch.randint(256, (20, 1)).float()\n    w = torch.randint(64, (20, 1)).float()\n    h = torch.randint(64, (20, 1)).float()\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n    offset = torch.randn(20, 2, 7, 7)\n    input.requires_grad = True\n    offset.requires_grad = True\n\n    # normal roi_align\n    pooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                           pooled_size=7,\n                           output_dim=32,\n                           no_trans=True,\n                           group_size=1,\n                           trans_std=0.1)\n\n    # deformable pooling\n    dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                            pooled_size=7,\n                            output_dim=32,\n                            no_trans=False,\n                            group_size=1,\n                            trans_std=0.1)\n\n    out = pooling(input, rois, offset)\n    dout = dpooling(input, rois, offset)\n    print(out.shape)\n    print(dout.shape)\n\n    target_out = out.new(*out.size())\n    target_out.data.uniform_(-0.01, 0.01)\n    target_dout = dout.new(*dout.size())\n    target_dout.data.uniform_(-0.01, 0.01)\n    e = (target_out - out).mean()\n    e.backward()\n    e = (target_dout - dout).mean()\n    e.backward()\n\n\ndef example_mdpooling():\n    input = torch.randn(2, 32, 64, 64)\n    input.requires_grad = True\n    batch_inds = torch.randint(2, (20, 1)).float()\n    x = torch.randint(256, (20, 1)).float()\n    y = torch.randint(256, (20, 1)).float()\n    w = torch.randint(64, (20, 1)).float()\n    h = torch.randint(64, (20, 1)).float()\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n\n    # mdformable pooling (V2)\n    dpooling = DCNPooling(spatial_scale=1.0 / 4,\n                          pooled_size=7,\n                          output_dim=32,\n                          no_trans=False,\n                          group_size=1,\n                          trans_std=0.1,\n                          deform_fc_dim=1024)\n\n    dout = dpooling(input, rois)\n    target = dout.new(*dout.size())\n    target.data.uniform_(-0.1, 0.1)\n    error = (target - dout).mean()\n    error.backward()\n    print(dout.shape)\n\n\nif __name__ == \'__main__\':\n\n    example_dconv()\n    example_dpooling()\n    example_mdpooling()\n\n    check_pooling_zero_offset()\n    # zero offset check\n    if inC == outC:\n        check_zero_offset()\n\n    check_gradient_dpooling()\n    check_gradient_dconv()\n    # """"""\n    # ****** Note: backward is not reentrant error may not be a serious problem,\n    # ****** since the max error is less than 1e-7,\n    # ****** Still looking for what trigger this problem\n    # """"""\n'"
testcuda.py,37,"b'#!/usr/bin/env python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport time\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import gradcheck\n\nfrom dcn_v2 import dcn_v2_conv, DCNv2, DCN\nfrom dcn_v2 import dcn_v2_pooling, DCNv2Pooling, DCNPooling\n\ndeformable_groups = 1\nN, inC, inH, inW = 2, 2, 4, 4\noutC = 2\nkH, kW = 3, 3\n\n\ndef conv_identify(weight, bias):\n    weight.data.zero_()\n    bias.data.zero_()\n    o, i, h, w = weight.shape\n    y = h//2\n    x = w//2\n    for p in range(i):\n        for q in range(o):\n            if p == q:\n                weight.data[q, p, y, x] = 1.0\n\n\ndef check_zero_offset():\n    conv_offset = nn.Conv2d(inC, deformable_groups * 2 * kH * kW,\n                            kernel_size=(kH, kW),\n                            stride=(1, 1),\n                            padding=(1, 1),\n                            bias=True).cuda()\n\n    conv_mask = nn.Conv2d(inC, deformable_groups * 1 * kH * kW,\n                          kernel_size=(kH, kW),\n                          stride=(1, 1),\n                          padding=(1, 1),\n                          bias=True).cuda()\n\n    dcn_v2 = DCNv2(inC, outC, (kH, kW),\n                   stride=1, padding=1, dilation=1,\n                   deformable_groups=deformable_groups).cuda()\n\n    conv_offset.weight.data.zero_()\n    conv_offset.bias.data.zero_()\n    conv_mask.weight.data.zero_()\n    conv_mask.bias.data.zero_()\n    conv_identify(dcn_v2.weight, dcn_v2.bias)\n\n    input = torch.randn(N, inC, inH, inW).cuda()\n    offset = conv_offset(input)\n    mask = conv_mask(input)\n    mask = torch.sigmoid(mask)\n    output = dcn_v2(input, offset, mask)\n    output *= 2\n    d = (input - output).abs().max()\n    if d < 1e-10:\n        print(\'Zero offset passed\')\n    else:\n        print(\'Zero offset failed\')\n        print(input)\n        print(output)\n\ndef check_gradient_dconv():\n\n    input = torch.rand(N, inC, inH, inW).cuda() * 0.01\n    input.requires_grad = True\n\n    offset = torch.randn(N, deformable_groups * 2 * kW * kH, inH, inW).cuda() * 2\n    # offset.data.zero_()\n    # offset.data -= 0.5\n    offset.requires_grad = True\n\n    mask = torch.rand(N, deformable_groups * 1 * kW * kH, inH, inW).cuda()\n    # mask.data.zero_()\n    mask.requires_grad = True\n    mask = torch.sigmoid(mask)\n\n    weight = torch.randn(outC, inC, kH, kW).cuda()\n    weight.requires_grad = True\n\n    bias = torch.rand(outC).cuda()\n    bias.requires_grad = True\n\n    stride = 1\n    padding = 1\n    dilation = 1\n\n    print(\'check_gradient_dconv: \',\n          gradcheck(dcn_v2_conv, (input, offset, mask, weight, bias,\n                    stride, padding, dilation, deformable_groups),\n                    eps=1e-3, atol=1e-4, rtol=1e-2))\n\n\ndef check_pooling_zero_offset():\n\n    input = torch.randn(2, 16, 64, 64).cuda().zero_()\n    input[0, :, 16:26, 16:26] = 1.\n    input[1, :, 10:20, 20:30] = 2.\n    rois = torch.tensor([\n        [0, 65, 65, 103, 103],\n        [1, 81, 41, 119, 79],\n    ]).cuda().float()\n    pooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                           pooled_size=7,\n                           output_dim=16,\n                           no_trans=True,\n                           group_size=1,\n                           trans_std=0.0).cuda()\n\n    out = pooling(input, rois, input.new())\n    s = \', \'.join([\'%f\' % out[i, :, :, :].mean().item()\n                   for i in range(rois.shape[0])])\n    print(s)\n\n    dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                            pooled_size=7,\n                            output_dim=16,\n                            no_trans=False,\n                            group_size=1,\n                            trans_std=0.0).cuda()\n    offset = torch.randn(20, 2, 7, 7).cuda().zero_()\n    dout = dpooling(input, rois, offset)\n    s = \', \'.join([\'%f\' % dout[i, :, :, :].mean().item()\n                   for i in range(rois.shape[0])])\n    print(s)\n\n\ndef check_gradient_dpooling():\n    input = torch.randn(2, 3, 5, 5).cuda() * 0.01\n    N = 4\n    batch_inds = torch.randint(2, (N, 1)).cuda().float()\n    x = torch.rand((N, 1)).cuda().float() * 15\n    y = torch.rand((N, 1)).cuda().float() * 15\n    w = torch.rand((N, 1)).cuda().float() * 10\n    h = torch.rand((N, 1)).cuda().float() * 10\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n    offset = torch.randn(N, 2, 3, 3).cuda()\n    input.requires_grad = True\n    offset.requires_grad = True\n\n    spatial_scale = 1.0 / 4\n    pooled_size = 3\n    output_dim = 3\n    no_trans = 0\n    group_size = 1\n    trans_std = 0.0\n    sample_per_part = 4\n    part_size = pooled_size\n\n    print(\'check_gradient_dpooling:\',\n          gradcheck(dcn_v2_pooling, (input, rois, offset,\n                                     spatial_scale,\n                                     pooled_size,\n                                     output_dim,\n                                     no_trans,\n                                     group_size,\n                                     part_size,\n                                     sample_per_part,\n                                     trans_std),\n                    eps=1e-4))\n\n\ndef example_dconv():\n    input = torch.randn(2, 64, 128, 128).cuda()\n    # wrap all things (offset and mask) in DCN\n    dcn = DCN(64, 64, kernel_size=(3, 3), stride=1,\n              padding=1, deformable_groups=2).cuda()\n    # print(dcn.weight.shape, input.shape)\n    output = dcn(input)\n    targert = output.new(*output.size())\n    targert.data.uniform_(-0.01, 0.01)\n    error = (targert - output).mean()\n    error.backward()\n    print(output.shape)\n\n\ndef example_dpooling():\n    input = torch.randn(2, 32, 64, 64).cuda()\n    batch_inds = torch.randint(2, (20, 1)).cuda().float()\n    x = torch.randint(256, (20, 1)).cuda().float()\n    y = torch.randint(256, (20, 1)).cuda().float()\n    w = torch.randint(64, (20, 1)).cuda().float()\n    h = torch.randint(64, (20, 1)).cuda().float()\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n    offset = torch.randn(20, 2, 7, 7).cuda()\n    input.requires_grad = True\n    offset.requires_grad = True\n\n    # normal roi_align\n    pooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                           pooled_size=7,\n                           output_dim=32,\n                           no_trans=True,\n                           group_size=1,\n                           trans_std=0.1).cuda()\n\n    # deformable pooling\n    dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,\n                            pooled_size=7,\n                            output_dim=32,\n                            no_trans=False,\n                            group_size=1,\n                            trans_std=0.1).cuda()\n\n    out = pooling(input, rois, offset)\n    dout = dpooling(input, rois, offset)\n    print(out.shape)\n    print(dout.shape)\n\n    target_out = out.new(*out.size())\n    target_out.data.uniform_(-0.01, 0.01)\n    target_dout = dout.new(*dout.size())\n    target_dout.data.uniform_(-0.01, 0.01)\n    e = (target_out - out).mean()\n    e.backward()\n    e = (target_dout - dout).mean()\n    e.backward()\n\n\ndef example_mdpooling():\n    input = torch.randn(2, 32, 64, 64).cuda()\n    input.requires_grad = True\n    batch_inds = torch.randint(2, (20, 1)).cuda().float()\n    x = torch.randint(256, (20, 1)).cuda().float()\n    y = torch.randint(256, (20, 1)).cuda().float()\n    w = torch.randint(64, (20, 1)).cuda().float()\n    h = torch.randint(64, (20, 1)).cuda().float()\n    rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)\n\n    # mdformable pooling (V2)\n    dpooling = DCNPooling(spatial_scale=1.0 / 4,\n                          pooled_size=7,\n                          output_dim=32,\n                          no_trans=False,\n                          group_size=1,\n                          trans_std=0.1,\n                          deform_fc_dim=1024).cuda()\n\n    dout = dpooling(input, rois)\n    target = dout.new(*dout.size())\n    target.data.uniform_(-0.1, 0.1)\n    error = (target - dout).mean()\n    error.backward()\n    print(dout.shape)\n\n\nif __name__ == \'__main__\':\n\n    example_dconv()\n    example_dpooling()\n    example_mdpooling()\n\n    check_pooling_zero_offset()\n    # zero offset check\n    if inC == outC:\n        check_zero_offset()\n\n    check_gradient_dpooling()\n    check_gradient_dconv()\n    # """"""\n    # ****** Note: backward is not reentrant error may not be a serious problem,\n    # ****** since the max error is less than 1e-7,\n    # ****** Still looking for what trigger this problem\n    # """"""\n'"
