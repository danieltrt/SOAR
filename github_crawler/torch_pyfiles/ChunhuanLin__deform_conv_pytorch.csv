file_path,api_count,code
deform_conv.py,13,"b""from torch.autograd import Variable, Function\nimport torch\nfrom torch import nn\nimport numpy as np\n\n\nclass DeformConv2D(nn.Module):\n    def __init__(self, inc, outc, kernel_size=3, padding=1, bias=None):\n        super(DeformConv2D, self).__init__()\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.zero_padding = nn.ZeroPad2d(padding)\n        self.conv_kernel = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n\n    def forward(self, x, offset):\n        dtype = offset.data.type()\n        ks = self.kernel_size\n        N = offset.size(1) // 2\n\n        # Change offset's order from [x1, x2, ..., y1, y2, ...] to [x1, y1, x2, y2, ...]\n        # Codes below are written to make sure same results of MXNet implementation.\n        # You can remove them, and it won't influence the module's performance.\n        offsets_index = Variable(torch.cat([torch.arange(0, 2*N, 2), torch.arange(1, 2*N+1, 2)]), requires_grad=False).type_as(x).long()\n        offsets_index = offsets_index.unsqueeze(dim=0).unsqueeze(dim=-1).unsqueeze(dim=-1).expand(*offset.size())\n        offset = torch.gather(offset, dim=1, index=offsets_index)\n        # ------------------------------------------------------------------------\n\n        if self.padding:\n            x = self.zero_padding(x)\n\n        # (b, 2N, h, w)\n        p = self._get_p(offset, dtype)\n\n        # (b, h, w, 2N)\n        p = p.contiguous().permute(0, 2, 3, 1)\n        q_lt = Variable(p.data, requires_grad=False).floor()\n        q_rb = q_lt + 1\n\n        q_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2)-1), torch.clamp(q_lt[..., N:], 0, x.size(3)-1)], dim=-1).long()\n        q_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2)-1), torch.clamp(q_rb[..., N:], 0, x.size(3)-1)], dim=-1).long()\n        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], -1)\n        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], -1)\n\n        # (b, h, w, N)\n        mask = torch.cat([p[..., :N].lt(self.padding)+p[..., :N].gt(x.size(2)-1-self.padding),\n                          p[..., N:].lt(self.padding)+p[..., N:].gt(x.size(3)-1-self.padding)], dim=-1).type_as(p)\n        mask = mask.detach()\n        floor_p = p - (p - torch.floor(p))\n        p = p*(1-mask) + floor_p*mask\n        p = torch.cat([torch.clamp(p[..., :N], 0, x.size(2)-1), torch.clamp(p[..., N:], 0, x.size(3)-1)], dim=-1)\n\n        # bilinear kernel (b, h, w, N)\n        g_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\n        g_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\n        g_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\n        g_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\n\n        # (b, c, h, w, N)\n        x_q_lt = self._get_x_q(x, q_lt, N)\n        x_q_rb = self._get_x_q(x, q_rb, N)\n        x_q_lb = self._get_x_q(x, q_lb, N)\n        x_q_rt = self._get_x_q(x, q_rt, N)\n\n        # (b, c, h, w, N)\n        x_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\n                   g_rb.unsqueeze(dim=1) * x_q_rb + \\\n                   g_lb.unsqueeze(dim=1) * x_q_lb + \\\n                   g_rt.unsqueeze(dim=1) * x_q_rt\n\n        x_offset = self._reshape_x_offset(x_offset, ks)\n        out = self.conv_kernel(x_offset)\n\n        return out\n\n    def _get_p_n(self, N, dtype):\n        p_n_x, p_n_y = np.meshgrid(range(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1),\n                          range(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1), indexing='ij')\n        # (2N, 1)\n        p_n = np.concatenate((p_n_x.flatten(), p_n_y.flatten()))\n        p_n = np.reshape(p_n, (1, 2*N, 1, 1))\n        p_n = Variable(torch.from_numpy(p_n).type(dtype), requires_grad=False)\n\n        return p_n\n\n    @staticmethod\n    def _get_p_0(h, w, N, dtype):\n        p_0_x, p_0_y = np.meshgrid(range(1, h+1), range(1, w+1), indexing='ij')\n        p_0_x = p_0_x.flatten().reshape(1, 1, h, w).repeat(N, axis=1)\n        p_0_y = p_0_y.flatten().reshape(1, 1, h, w).repeat(N, axis=1)\n        p_0 = np.concatenate((p_0_x, p_0_y), axis=1)\n        p_0 = Variable(torch.from_numpy(p_0).type(dtype), requires_grad=False)\n\n        return p_0\n\n    def _get_p(self, offset, dtype):\n        N, h, w = offset.size(1)//2, offset.size(2), offset.size(3)\n\n        # (1, 2N, 1, 1)\n        p_n = self._get_p_n(N, dtype)\n        # (1, 2N, h, w)\n        p_0 = self._get_p_0(h, w, N, dtype)\n        p = p_0 + p_n + offset\n        return p\n\n    def _get_x_q(self, x, q, N):\n        b, h, w, _ = q.size()\n        padded_w = x.size(3)\n        c = x.size(1)\n        # (b, c, h*w)\n        x = x.contiguous().view(b, c, -1)\n\n        # (b, h, w, N)\n        index = q[..., :N]*padded_w + q[..., N:]  # offset_x*w + offset_y\n        # (b, c, h*w*N)\n        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n\n        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\n\n        return x_offset\n\n    @staticmethod\n    def _reshape_x_offset(x_offset, ks):\n        b, c, h, w, N = x_offset.size()\n        x_offset = torch.cat([x_offset[..., s:s+ks].contiguous().view(b, c, h, w*ks) for s in range(0, N, ks)], dim=-1)\n        x_offset = x_offset.contiguous().view(b, c, h*ks, w*ks)\n\n        return x_offset"""
demo.py,12,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nfrom deform_conv import DeformConv2D\n\nfrom time import time\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for training (default: 32)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=32, metavar=\'N\',\n                    help=\'input batch size for testing (default: 32)\')\nparser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.5, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./MNIST\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./MNIST\', train=False, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\nclass DeformNet(nn.Module):\n    def __init__(self):\n        super(DeformNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n\n        self.offsets = nn.Conv2d(128, 18, kernel_size=3, padding=1)\n        self.conv4 = DeformConv2D(128, 128, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(128)\n\n        self.classifier = nn.Linear(128, 10)\n\n    def forward(self, x):\n        # convs\n        x = F.relu(self.conv1(x))\n        x = self.bn1(x)\n        x = F.relu(self.conv2(x))\n        x = self.bn2(x)\n        x = F.relu(self.conv3(x))\n        x = self.bn3(x)\n        # deformable convolution\n        offsets = self.offsets(x)\n        x = F.relu(self.conv4(x, offsets))\n        x = self.bn4(x)\n\n        x = F.avg_pool2d(x, kernel_size=28, stride=1).view(x.size(0), -1)\n        x = self.classifier(x)\n\n        return F.log_softmax(x, dim=1)\n\n\nclass PlainNet(nn.Module):\n    def __init__(self):\n        super(PlainNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n\n        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(128)\n\n        self.classifier = nn.Linear(128, 10)\n\n    def forward(self, x):\n        # convs\n        x = F.relu(self.conv1(x))\n        x = self.bn1(x)\n        x = F.relu(self.conv2(x))\n        x = self.bn2(x)\n        x = F.relu(self.conv3(x))\n        x = self.bn3(x)\n        x = F.relu(self.conv4(x))\n        x = self.bn4(x)\n\n        x = F.avg_pool2d(x, kernel_size=28, stride=1).view(x.size(0), -1)\n        x = self.classifier(x)\n\n        return F.log_softmax(x, dim=1)\n\nmodel = DeformNet()\n\n\ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        nn.init.xavier_uniform(m.weight, gain=nn.init.calculate_gain(\'relu\'))\n        if m.bias is not None:\n            m.bias.data = torch.FloatTensor(m.bias.shape[0]).zero_()\n\n\ndef init_conv_offset(m):\n    m.weight.data = torch.zeros_like(m.weight.data)\n    if m.bias is not None:\n        m.bias.data = torch.FloatTensor(m.bias.shape[0]).zero_()\n\n\nmodel.apply(init_weights)\nmodel.offsets.apply(init_conv_offset)\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = Variable(data), Variable(target)\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    since = time()\n    train(epoch)\n    iter = time() - since\n    print(""Spends {}s for each training epoch"".format(iter/args.epochs))\n    test()\n'"
