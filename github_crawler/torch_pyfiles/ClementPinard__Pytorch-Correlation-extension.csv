file_path,api_count,code
benchmark.py,6,"b""from __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport time\n\nimport torch\nfrom spatial_correlation_sampler import SpatialCorrelationSampler\nfrom tqdm import trange\n\nTIME_SCALES = {'s': 1, 'ms': 1000, 'us': 1000000}\n\nparser = argparse.ArgumentParser()\nparser.add_argument('backend', choices=['cpu', 'cuda'], default='cuda')\nparser.add_argument('-b', '--batch-size', type=int, default=16)\nparser.add_argument('-k', '--kernel-size', type=int, default=3)\nparser.add_argument('--patch', type=int, default=3)\nparser.add_argument('--patch_dilation', type=int, default=2)\nparser.add_argument('-c', '--channel', type=int, default=64)\nparser.add_argument('--height', type=int, default=100)\nparser.add_argument('-w', '--width', type=int, default=100)\nparser.add_argument('-s', '--stride', type=int, default=2)\nparser.add_argument('-p', '--pad', type=int, default=1)\nparser.add_argument('--scale', choices=['s', 'ms', 'us'], default='us')\nparser.add_argument('-r', '--runs', type=int, default=100)\nparser.add_argument('-d', '--dtype', choices=['half', 'float', 'double'])\n\nargs = parser.parse_args()\n\ndevice = torch.device(args.backend)\n\nif args.dtype == 'half':\n    dtype = torch.float16\nelif args.dtype == 'float':\n    dtype = torch.float32\nelse:\n    dtype = torch.float64\n\n\ninput1 = torch.randn(args.batch_size,\n                     args.channel,\n                     args.height,\n                     args.width,\n                     dtype=dtype,\n                     device=device,\n                     requires_grad=True)\ninput2 = torch.randn_like(input1)\n\ncorrelation_sampler = SpatialCorrelationSampler(\n    args.kernel_size,\n    args.patch,\n    args.stride,\n    args.pad,\n    args.patch_dilation)\n\n# Force CUDA initialization\noutput = correlation_sampler(input1, input2)\nprint(output.size())\noutput.mean().backward()\nforward_min = float('inf')\nforward_time = 0\nbackward_min = float('inf')\nbackward_time = 0\nfor _ in trange(args.runs):\n    correlation_sampler.zero_grad()\n\n    start = time.time()\n    output = correlation_sampler(input1, input2)\n    elapsed = time.time() - start\n    forward_min = min(forward_min, elapsed)\n    forward_time += elapsed\n    output = output.mean()\n\n    start = time.time()\n    (output.mean()).backward()\n    elapsed = time.time() - start\n    backward_min = min(backward_min, elapsed)\n    backward_time += elapsed\n\nscale = TIME_SCALES[args.scale]\nforward_min *= scale\nbackward_min *= scale\nforward_average = forward_time / args.runs * scale\nbackward_average = backward_time / args.runs * scale\n\nprint('Forward: {0:.3f}/{1:.3f} {4} | Backward {2:.3f}/{3:.3f} {4}'.format(\n    forward_min, forward_average, backward_min, backward_average,\n    args.scale))\n"""
check.py,4,"b'from __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport numpy as np\nimport torch\n\nfrom spatial_correlation_sampler import SpatialCorrelationSampler\n\n\ndef check_equal(first, second, verbose):\n    if verbose:\n        print()\n    for i, (x, y) in enumerate(zip(first, second)):\n        x = x.cpu().detach().numpy()\n        y = y.cpu().detach().numpy()\n        if verbose:\n            print(""x = {}"".format(x.flatten()))\n            print(""y = {}"".format(y.flatten()))\n            print(\'-\' * 80)\n        np.testing.assert_allclose(x, y, err_msg=""Index: {}"".format(i))\n\n\ndef zero_grad(variables):\n    for variable in variables:\n        variable.grad.zero_()\n\n\ndef get_grads(variables):\n    return [var.grad.clone() for var in variables]\n\n\ndef check_forward(input1, input2, correlation_sampler, verbose):\n    cpu_values = correlation_sampler(input1, input2)\n    cuda_values = correlation_sampler(input1.to(device), input2.to(device))\n\n    print(\'Forward: CPU vs. CUDA ... \', end=\'\')\n    check_equal(cpu_values, cuda_values, verbose)\n    print(\'Ok\')\n\n\ndef check_backward(input1, input2, correlation_sampler, verbose):\n    cpu_values = correlation_sampler(input1, input2)\n    cpu_values.sum().backward()\n    grad_cpu = get_grads([input1, input2])\n\n    zero_grad([input1, input2])\n\n    cuda_values = correlation_sampler(input1.to(device), input2.to(device))\n    cuda_values.sum().backward()\n    grad_cuda = get_grads([input1, input2])\n\n    print(\'Backward: CPU vs. CUDA ... \', end=\'\')\n    check_equal(grad_cpu, grad_cuda, verbose)\n    print(\'Ok\')\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'direction\', choices=[\'forward\', \'backward\'], nargs=\'+\')\nparser.add_argument(\'-b\', \'--batch-size\', type=int, default=1)\nparser.add_argument(\'-k\', \'--kernel-size\', type=int, default=3)\nparser.add_argument(\'--patch\', type=int, default=3)\nparser.add_argument(\'--patch_dilation\', type=int, default=2)\nparser.add_argument(\'-c\', \'--channel\', type=int, default=10)\nparser.add_argument(\'--height\', type=int, default=10)\nparser.add_argument(\'-w\', \'--width\', type=int, default=10)\nparser.add_argument(\'-s\', \'--stride\', type=int, default=2)\nparser.add_argument(\'-p\', \'--pad\', type=int, default=5)\nparser.add_argument(\'-v\', \'--verbose\', action=\'store_true\')\nargs = parser.parse_args()\n\nassert(torch.cuda.is_available()), ""no comparison to make""\ndevice = torch.device(""cuda"")\n\ninput1 = torch.randn(args.batch_size,\n                     args.channel,\n                     args.height,\n                     args.width).double()\ninput2 = torch.randn(args.batch_size,\n                     args.channel,\n                     args.height,\n                     args.width).double()\ninput1.requires_grad = True\ninput2.requires_grad = True\n\ncorrelation_sampler = SpatialCorrelationSampler(\n    args.kernel_size,\n    args.patch,\n    args.stride,\n    args.pad,\n    args.patch_dilation)\n\nif \'forward\' in args.direction:\n    check_forward(input1, input2, correlation_sampler, args.verbose)\n\nif \'backward\' in args.direction:\n    check_backward(input1, input2, correlation_sampler, args.verbose)\n'"
grad_check.py,8,"b""import argparse\nimport torch\n# torch.set_printoptions(precision=1, threshold=10000)\nfrom torch.autograd import gradcheck\nfrom spatial_correlation_sampler import SpatialCorrelationSampler\n\nparser = argparse.ArgumentParser()\nparser.add_argument('backend', choices=['cpu', 'cuda'], default='cuda')\nparser.add_argument('-b', '--batch-size', type=int, default=2)\nparser.add_argument('-k', '--kernel-size', type=int, default=3)\nparser.add_argument('--patch', type=int, default=3)\nparser.add_argument('--patch_dilation', type=int, default=2)\nparser.add_argument('-c', '--channel', type=int, default=2)\nparser.add_argument('--height', type=int, default=10)\nparser.add_argument('-w', '--width', type=int, default=10)\nparser.add_argument('-s', '--stride', type=int, default=2)\nparser.add_argument('-p', '--pad', type=int, default=1)\n\nargs = parser.parse_args()\n\ninput1 = torch.ones(args.batch_size,\n                    args.channel,\n                    args.height,\n                    args.width,\n                    dtype=torch.float64,\n                    device=torch.device(args.backend))\ninput2 = torch.ones(args.batch_size,\n                    args.channel,\n                    args.height,\n                    args.width,\n                    dtype=torch.float64,\n                    device=torch.device(args.backend))\n\ninput1.requires_grad = True\ninput2.requires_grad = True\n\ncorrelation_sampler = SpatialCorrelationSampler(args.kernel_size,\n                                                args.patch,\n                                                args.stride,\n                                                args.pad,\n                                                args.patch_dilation)\n\n\nif gradcheck(correlation_sampler, [input1, input2]):\n    print('Ok')\n"""
setup.py,1,"b'from setuptools import setup\nfrom torch.utils.cpp_extension import BuildExtension, CUDAExtension, CppExtension\nfrom os.path import join\n\nCPU_ONLY = False\nproject_root = \'Correlation_Module\'\n\nsource_files = [\'correlation.cpp\', \'correlation_sampler.cpp\']\n\nwith open(""README.md"", ""r"") as fh:\n    long_description = fh.read()\n\n\ndef launch_setup():\n    if CPU_ONLY:\n        Extension = CppExtension\n        macro = []\n    else:\n        Extension = CUDAExtension\n        source_files.append(\'correlation_cuda_kernel.cu\')\n        macro = [(""USE_CUDA"", None)]\n\n    sources = [join(project_root, file) for file in source_files]\n\n    setup(\n        name=\'spatial_correlation_sampler\',\n        version=""0.2.0"",\n        author=""Cl\xc3\xa9ment Pinard"",\n        author_email=""clement.pinard@ensta-paristech.fr"",\n        description=""Correlation module for pytorch"",\n        long_description=long_description,\n        long_description_content_type=""text/markdown"",\n        url=""https://github.com/ClementPinard/Pytorch-Correlation-extension"",\n        install_requires=[\'torch>=1.1\', \'numpy\'],\n        ext_modules=[\n            Extension(\'spatial_correlation_sampler_backend\',\n                      sources,\n                      define_macros=macro,\n                      extra_compile_args={\'cxx\': [\'-fopenmp\'], \'nvcc\':[]},\n                      extra_link_args=[\'-lgomp\'])\n        ],\n        package_dir={\'\': project_root},\n        packages=[\'spatial_correlation_sampler\'],\n        cmdclass={\n            \'build_ext\': BuildExtension\n        },\n        classifiers=[\n            ""Programming Language :: Python :: 3"",\n            ""License :: OSI Approved :: MIT License"",\n            ""Operating System :: POSIX :: Linux"",\n            ""Intended Audience :: Science/Research"",\n            ""Topic :: Scientific/Engineering :: Artificial Intelligence""\n        ])\n\n\nif __name__ == \'__main__\':\n    launch_setup()\n'"
setup_cpu.py,0,b'import setup\n\nsetup.CPU_ONLY = True\nsetup.launch_setup()\n'
Correlation_Module/spatial_correlation_sampler/__init__.py,0,"b'from .spatial_correlation_sampler import SpatialCorrelationSampler, spatial_correlation_sample'"
Correlation_Module/spatial_correlation_sampler/spatial_correlation_sampler.py,3,"b'from torch import nn\nfrom torch.autograd import Function\nfrom torch.autograd.function import once_differentiable\nfrom torch.nn.modules.utils import _pair\n\nimport spatial_correlation_sampler_backend as correlation\n\n\ndef spatial_correlation_sample(input1,\n                               input2,\n                               kernel_size=1,\n                               patch_size=1,\n                               stride=1,\n                               padding=0,\n                               dilation_patch=1):\n    """"""Apply spatial correlation sampling on from input1 to input2,\n\n    Every parameter except input1 and input2 can be either single int\n    or a pair of int. For more information about Spatial Correlation\n    Sampling, see this page.\n    https://lmb.informatik.uni-freiburg.de/Publications/2015/DFIB15/\n\n    Args:\n        input1 : The first parameter.\n        input2 : The second parameter.\n        kernel_size : total size of your correlation kernel, in pixels\n        patch_size : total size of your patch, determining how many\n            different shifts will be applied\n        stride : stride of the spatial sampler, will modify output\n            height and width\n        padding : padding applied to input1 and input2 before applying\n            the correlation sampling, will modify output height and width\n        dilation_patch : step for every shift in patch\n\n    Returns:\n        Tensor: Result of correlation sampling\n\n    """"""\n    return SpatialCorrelationSamplerFunction.apply(input1, input2,\n                                                   kernel_size, patch_size,\n                                                   stride, padding, dilation_patch)\n\n\nclass SpatialCorrelationSamplerFunction(Function):\n\n    @staticmethod\n    def forward(ctx,\n                input1,\n                input2,\n                kernel_size=1,\n                patch_size=1,\n                stride=1,\n                padding=0,\n                dilation_patch=1):\n\n        ctx.save_for_backward(input1, input2)\n        kH, kW = ctx.kernel_size = _pair(kernel_size)\n        patchH, patchW = ctx.patch_size = _pair(patch_size)\n        padH, padW = ctx.padding = _pair(padding)\n        dilation_patchH, dilation_patchW = ctx.dilation_patch = _pair(dilation_patch)\n        dH, dW = ctx.stride = _pair(stride)\n\n        output = correlation.forward(input1, input2,\n                                     kH, kW, patchH, patchW,\n                                     padH, padW, dilation_patchH, dilation_patchW,\n                                     dH, dW)\n\n        return output\n\n    @staticmethod\n    @once_differentiable\n    def backward(ctx, grad_output):\n        input1, input2 = ctx.saved_variables\n\n        kH, kW = ctx.kernel_size\n        patchH, patchW = ctx.patch_size\n        padH, padW = ctx.padding\n        dilation_patchH, dilation_patchW = ctx.dilation_patch\n        dH, dW = ctx.stride\n\n        grad_input1, grad_input2 = correlation.backward(input1, input2, grad_output,\n                                                        kH, kW, patchH, patchW,\n                                                        padH, padW,\n                                                        dilation_patchH, dilation_patchW,\n                                                        dH, dW)\n        return grad_input1, grad_input2, None, None, None, None, None\n\n\nclass SpatialCorrelationSampler(nn.Module):\n    def __init__(self, kernel_size=1, patch_size=1, stride=1, padding=0, dilation=1, dilation_patch=1):\n        super(SpatialCorrelationSampler, self).__init__()\n        self.kernel_size = kernel_size\n        self.patch_size = patch_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.dilation_patch = dilation_patch\n\n    def forward(self, input1, input2):\n        return SpatialCorrelationSamplerFunction.apply(input1, input2, self.kernel_size,\n                                                       self.patch_size, self.stride,\n                                                       self.padding, self.dilation_patch)\n'"
