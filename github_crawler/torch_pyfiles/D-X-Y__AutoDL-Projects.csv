file_path,api_count,code
exps-tf/GDAS.py,0,"b""# [D-X-Y]\n# Run GDAS\n# CUDA_VISIBLE_DEVICES=0 python exps-tf/GDAS.py\n# Run DARTS\n# CUDA_VISIBLE_DEVICES=0 python exps-tf/GDAS.py --tau_max -1 --tau_min -1 --epochs 50\n#\nimport os, sys, math, time, random, argparse\nimport tensorflow as tf\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\n\n# self-lib\nfrom tf_models import get_cell_based_tiny_net\nfrom tf_optimizers import SGDW, AdamW\nfrom config_utils import dict2config\nfrom log_utils import time_string\nfrom models import CellStructure\n\n\ndef pre_process(image_a, label_a, image_b, label_b):\n  def standard_func(image):\n    x = tf.pad(image, [[4, 4], [4, 4], [0, 0]])\n    x = tf.image.random_crop(x, [32, 32, 3])\n    x = tf.image.random_flip_left_right(x)\n    return x\n  return standard_func(image_a), label_a, standard_func(image_b), label_b\n\n\nclass CosineAnnealingLR(object):\n  def __init__(self, warmup_epochs, epochs, initial_lr, min_lr):\n    self.warmup_epochs = warmup_epochs\n    self.epochs = epochs\n    self.initial_lr = initial_lr\n    self.min_lr = min_lr\n\n  def get_lr(self, epoch):\n    if epoch < self.warmup_epochs:\n      lr = self.min_lr + (epoch/self.warmup_epochs) * (self.initial_lr-self.min_lr)\n    elif epoch >= self.epochs:\n      lr = self.min_lr\n    else:\n      lr = self.min_lr + (self.initial_lr-self.min_lr) * 0.5 * (1 + math.cos(math.pi * epoch / self.epochs))\n    return lr\n      \n\n\ndef main(xargs):\n  cifar10 = tf.keras.datasets.cifar10\n\n  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n  x_train, x_test = x_train / 255.0, x_test / 255.0\n  x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n\n  # Add a channels dimension\n  all_indexes = list(range(x_train.shape[0]))\n  random.shuffle(all_indexes)\n  s_train_idxs, s_valid_idxs = all_indexes[::2], all_indexes[1::2]\n  search_train_x, search_train_y = x_train[s_train_idxs], y_train[s_train_idxs]\n  search_valid_x, search_valid_y = x_train[s_valid_idxs], y_train[s_valid_idxs]\n  #x_train, x_test = x_train[..., tf.newaxis], x_test[..., tf.newaxis]\n  \n  # Use tf.data\n  #train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)\n  search_ds = tf.data.Dataset.from_tensor_slices((search_train_x, search_train_y, search_valid_x, search_valid_y))\n  search_ds = search_ds.map(pre_process).shuffle(1000).batch(64)\n\n  test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n\n  # Create an instance of the model\n  config = dict2config({'name': 'GDAS',\n                        'C'   : xargs.channel, 'N': xargs.num_cells, 'max_nodes': xargs.max_nodes,\n                        'num_classes': 10, 'space': 'nas-bench-201', 'affine': True}, None)\n  model = get_cell_based_tiny_net(config)\n  num_iters_per_epoch = int(tf.data.experimental.cardinality(search_ds).numpy())\n  #lr_schedular = tf.keras.experimental.CosineDecay(xargs.w_lr_max, num_iters_per_epoch*xargs.epochs, xargs.w_lr_min / xargs.w_lr_max)\n  lr_schedular = CosineAnnealingLR(0, xargs.epochs, xargs.w_lr_max, xargs.w_lr_min)\n  # Choose optimizer\n  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n  w_optimizer = SGDW(learning_rate=xargs.w_lr_max, weight_decay=xargs.w_weight_decay, momentum=xargs.w_momentum, nesterov=True)\n  a_optimizer = AdamW(learning_rate=xargs.arch_learning_rate, weight_decay=xargs.arch_weight_decay, beta_1=0.5, beta_2=0.999, epsilon=1e-07)\n  #w_optimizer = tf.keras.optimizers.SGD(learning_rate=0.025, momentum=0.9, nesterov=True)\n  #a_optimizer = tf.keras.optimizers.AdamW(learning_rate=xargs.arch_learning_rate, beta_1=0.5, beta_2=0.999, epsilon=1e-07)\n  ####\n  # metrics\n  train_loss = tf.keras.metrics.Mean(name='train_loss')\n  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n  valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n  valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n  test_loss = tf.keras.metrics.Mean(name='test_loss')\n  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n  \n  @tf.function\n  def search_step(train_images, train_labels, valid_images, valid_labels, tf_tau):\n    # optimize weights\n    with tf.GradientTape() as tape:\n      predictions = model(train_images, tf_tau, True)\n      w_loss = loss_object(train_labels, predictions)\n    net_w_param = model.get_weights()\n    gradients = tape.gradient(w_loss, net_w_param)\n    w_optimizer.apply_gradients(zip(gradients, net_w_param))\n    train_loss(w_loss)\n    train_accuracy(train_labels, predictions)\n    # optimize alphas\n    with tf.GradientTape() as tape:\n      predictions = model(valid_images, tf_tau, True)\n      a_loss = loss_object(valid_labels, predictions)\n    net_a_param = model.get_alphas()\n    gradients = tape.gradient(a_loss, net_a_param)\n    a_optimizer.apply_gradients(zip(gradients, net_a_param))\n    valid_loss(a_loss)\n    valid_accuracy(valid_labels, predictions)\n\n  # TEST\n  @tf.function\n  def test_step(images, labels):\n    predictions = model(images)\n    t_loss = loss_object(labels, predictions)\n\n    test_loss(t_loss)\n    test_accuracy(labels, predictions)\n\n  print('{:} start searching with {:} epochs ({:} batches per epoch).'.format(time_string(), xargs.epochs, num_iters_per_epoch))\n\n  for epoch in range(xargs.epochs):\n    # Reset the metrics at the start of the next epoch\n    train_loss.reset_states() ; train_accuracy.reset_states()\n    test_loss.reset_states()  ; test_accuracy.reset_states()\n    cur_tau = xargs.tau_max - (xargs.tau_max-xargs.tau_min) * epoch / (xargs.epochs-1)\n    tf_tau  = tf.cast(cur_tau, dtype=tf.float32, name='tau')\n    cur_lr  = lr_schedular.get_lr(epoch)\n    tf.keras.backend.set_value(w_optimizer.lr, cur_lr)\n\n    for trn_imgs, trn_labels, val_imgs, val_labels in search_ds:\n      search_step(trn_imgs, trn_labels, val_imgs, val_labels, tf_tau)\n    genotype = model.genotype()\n    genotype = CellStructure(genotype)\n\n    #for test_images, test_labels in test_ds:\n    #  test_step(test_images, test_labels)\n\n    cur_lr = float(tf.keras.backend.get_value(w_optimizer.lr))\n    template = '{:} Epoch {:03d}/{:03d}, Train-Loss: {:.3f}, Train-Accuracy: {:.2f}%, Valid-Loss: {:.3f}, Valid-Accuracy: {:.2f}% | tau={:.3f} | lr={:.6f}'\n    print(template.format(time_string(), epoch+1, xargs.epochs,\n                          train_loss.result(),\n                          train_accuracy.result()*100,\n                          valid_loss.result(),\n                          valid_accuracy.result()*100,\n                          cur_tau,\n                          cur_lr))\n    print('{:} genotype : {:}\\n{:}\\n'.format(time_string(), genotype, model.get_np_alphas()))\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser(description='NAS-Bench-201', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  # training details\n  parser.add_argument('--epochs'            , type=int  ,   default= 250  ,   help='')\n  parser.add_argument('--tau_max'           , type=float,   default= 10   ,   help='')\n  parser.add_argument('--tau_min'           , type=float,   default= 0.1  ,   help='')\n  parser.add_argument('--w_lr_max'          , type=float,   default= 0.025,   help='')\n  parser.add_argument('--w_lr_min'          , type=float,   default= 0.001,   help='')\n  parser.add_argument('--w_weight_decay'    , type=float,   default=0.0005,   help='')\n  parser.add_argument('--w_momentum'        , type=float,   default= 0.9  ,   help='')\n  parser.add_argument('--arch_learning_rate', type=float,   default=0.0003,   help='')\n  parser.add_argument('--arch_weight_decay' , type=float,   default=0.001,    help='')\n  # marco structure\n  parser.add_argument('--channel'           , type=int  ,   default=16,       help='')\n  parser.add_argument('--num_cells'         , type=int  ,   default= 5,       help='')\n  parser.add_argument('--max_nodes'         , type=int  ,   default= 4,       help='')\n  args = parser.parse_args()\n  main( args )\n"""
exps-tf/test-invH.py,0,"b""import os, sys, math, time, random, argparse\nimport tensorflow as tf\nfrom pathlib import Path\n\n\ndef test_a():\n  x = tf.Variable([[1.], [2.], [4.0]])\n  with tf.GradientTape(persistent=True) as g:\n    trn = tf.math.exp(tf.math.reduce_sum(x))\n    val = tf.math.cos(tf.math.reduce_sum(x))\n    dT_dx = g.gradient(trn, x)\n    dV_dx = g.gradient(val, x)\n    hess_vector = g.gradient(dT_dx, x, output_gradients=dV_dx)\n  print ('calculate ok : {:}'.format(hess_vector))\n\ndef test_b():\n  cce = tf.keras.losses.SparseCategoricalCrossentropy()\n  L1 = tf.convert_to_tensor([0, 1, 2])\n  L2 = tf.convert_to_tensor([2, 0, 1])\n  B = tf.Variable([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n  with tf.GradientTape(persistent=True) as g:\n    trn = cce(L1, B)\n    val = cce(L2, B)\n    dT_dx = g.gradient(trn, B)\n    dV_dx = g.gradient(val, B)\n    hess_vector = g.gradient(dT_dx, B, output_gradients=dV_dx)\n  print ('calculate ok : {:}'.format(hess_vector))\n\ndef test_c():\n  cce = tf.keras.losses.CategoricalCrossentropy()\n  L1 = tf.convert_to_tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n  L2 = tf.convert_to_tensor([[0., 0., 1.], [0., 1., 0.], [1., 0., 0.]])\n  B = tf.Variable([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n  with tf.GradientTape(persistent=True) as g:\n    trn = cce(L1, B)\n    val = cce(L2, B)\n    dT_dx = g.gradient(trn, B)\n    dV_dx = g.gradient(val, B)\n    hess_vector = g.gradient(dT_dx, B, output_gradients=dV_dx)\n  print ('calculate ok : {:}'.format(hess_vector))\n\nif __name__ == '__main__':\n  print(tf.__version__)\n  test_c()\n  #test_b()\n  #test_a()\n"""
exps/KD-main.py,15,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, obtain_cls_kd_args as obtain_args\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint\nfrom procedures   import get_optim_scheduler, get_procedures\nfrom datasets     import get_datasets\nfrom models       import obtain_model, load_net_from_checkpoint\nfrom utils        import get_model_infos\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\n\n\ndef main(args):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = True\n  #torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( args.workers )\n  \n  prepare_seed(args.rand_seed)\n  logger = prepare_logger(args)\n  \n  train_data, valid_data, xshape, class_num = get_datasets(args.dataset, args.data_path, args.cutout_length)\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True , num_workers=args.workers, pin_memory=True)\n  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n  # get configures\n  model_config = load_config(args.model_config, {\'class_num\': class_num}, logger)\n  optim_config = load_config(args.optim_config,\n                                {\'class_num\': class_num, \'KD_alpha\': args.KD_alpha, \'KD_temperature\': args.KD_temperature},\n                                logger)\n\n  # load checkpoint\n  teacher_base = load_net_from_checkpoint(args.KD_checkpoint)\n  teacher      = torch.nn.DataParallel(teacher_base).cuda()\n\n  base_model   = obtain_model(model_config)\n  flop, param  = get_model_infos(base_model, xshape)\n  logger.log(\'Student ====>>>>:\\n{:}\'.format(base_model))\n  logger.log(\'Teacher ====>>>>:\\n{:}\'.format(teacher_base))\n  logger.log(\'model information : {:}\'.format(base_model.get_message()))\n  logger.log(\'-\'*50)\n  logger.log(\'Params={:.2f} MB, FLOPs={:.2f} M ... = {:.2f} G\'.format(param, flop, flop/1e3))\n  logger.log(\'-\'*50)\n  logger.log(\'train_data : {:}\'.format(train_data))\n  logger.log(\'valid_data : {:}\'.format(valid_data))\n  optimizer, scheduler, criterion = get_optim_scheduler(base_model.parameters(), optim_config)\n  logger.log(\'optimizer  : {:}\'.format(optimizer))\n  logger.log(\'scheduler  : {:}\'.format(scheduler))\n  logger.log(\'criterion  : {:}\'.format(criterion))\n  \n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(base_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\'] + 1\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    optimizer.load_state_dict ( checkpoint[\'optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    max_bytes        = checkpoint[\'max_bytes\']\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  elif args.resume is not None:\n    assert Path(args.resume).exists(), \'Can not find the resume file : {:}\'.format(args.resume)\n    checkpoint  = torch.load( args.resume )\n    start_epoch = checkpoint[\'epoch\'] + 1\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    optimizer.load_state_dict ( checkpoint[\'optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    max_bytes        = checkpoint[\'max_bytes\']\n    logger.log(""=> loading checkpoint from \'{:}\' start with {:}-th epoch."".format(args.resume, start_epoch))\n  elif args.init_model is not None:\n    assert Path(args.init_model).exists(), \'Can not find the initialization file : {:}\'.format(args.init_model)\n    checkpoint  = torch.load( args.init_model )\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    start_epoch, valid_accuracies, max_bytes = 0, {\'best\': -1}, {}\n    logger.log(\'=> initialize the model from {:}\'.format( args.init_model ))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, max_bytes = 0, {\'best\': -1}, {}\n\n  train_func, valid_func = get_procedures(args.procedure)\n  \n  total_epoch = optim_config.epochs + optim_config.warmup\n  # Main Training and Evaluation Loop\n  start_time  = time.time()\n  epoch_time  = AverageMeter()\n  for epoch in range(start_epoch, total_epoch):\n    scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch), True) )\n    epoch_str = \'epoch={:03d}/{:03d}\'.format(epoch, total_epoch)\n    LRs       = scheduler.get_lr()\n    find_best = False\n\n    logger.log(\'\\n***{:s}*** start {:s} {:s}, LR=[{:.6f} ~ {:.6f}], scheduler={:}\'.format(time_string(), epoch_str, need_time, min(LRs), max(LRs), scheduler))\n    \n    # train for one epoch\n    train_loss, train_acc1, train_acc5 = train_func(train_loader, teacher, network, criterion, scheduler, optimizer, optim_config, epoch_str, args.print_freq, logger)\n    # log the results    \n    logger.log(\'***{:s}*** TRAIN [{:}] loss = {:.6f}, accuracy-1 = {:.2f}, accuracy-5 = {:.2f}\'.format(time_string(), epoch_str, train_loss, train_acc1, train_acc5))\n\n    # evaluate the performance\n    if (epoch % args.eval_frequency == 0) or (epoch + 1 == total_epoch):\n      logger.log(\'-\'*150)\n      valid_loss, valid_acc1, valid_acc5 = valid_func(valid_loader, teacher, network, criterion, optim_config, epoch_str, args.print_freq_eval, logger)\n      valid_accuracies[epoch] = valid_acc1\n      logger.log(\'***{:s}*** VALID [{:}] loss = {:.6f}, accuracy@1 = {:.2f}, accuracy@5 = {:.2f} | Best-Valid-Acc@1={:.2f}, Error@1={:.2f}\'.format(time_string(), epoch_str, valid_loss, valid_acc1, valid_acc5, valid_accuracies[\'best\'], 100-valid_accuracies[\'best\']))\n      if valid_acc1 > valid_accuracies[\'best\']:\n        valid_accuracies[\'best\'] = valid_acc1\n        find_best                = True\n        logger.log(\'Currently, the best validation accuracy found at {:03d}-epoch :: acc@1={:.2f}, acc@5={:.2f}, error@1={:.2f}, error@5={:.2f}, save into {:}.\'.format(epoch, valid_acc1, valid_acc5, 100-valid_acc1, 100-valid_acc5, model_best_path))\n      num_bytes = torch.cuda.max_memory_cached( next(network.parameters()).device ) * 1.0\n      logger.log(\'[GPU-Memory-Usage on {:} is {:} bytes, {:.2f} KB, {:.2f} MB, {:.2f} GB.]\'.format(next(network.parameters()).device, int(num_bytes), num_bytes / 1e3, num_bytes / 1e6, num_bytes / 1e9))\n      max_bytes[epoch] = num_bytes\n    if epoch % 10 == 0: torch.cuda.empty_cache()\n\n    # save checkpoint\n    save_path = save_checkpoint({\n          \'epoch\'        : epoch,\n          \'args\'         : deepcopy(args),\n          \'max_bytes\'    : deepcopy(max_bytes),\n          \'FLOP\'         : flop,\n          \'PARAM\'        : param,\n          \'valid_accuracies\': deepcopy(valid_accuracies),\n          \'model-config\' : model_config._asdict(),\n          \'optim-config\' : optim_config._asdict(),\n          \'base-model\'   : base_model.state_dict(),\n          \'scheduler\'    : scheduler.state_dict(),\n          \'optimizer\'    : optimizer.state_dict(),\n          }, model_base_path, logger)\n    if find_best: copy_checkpoint(model_base_path, model_best_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*200)\n  logger.log(\'||| Params={:.2f} MB, FLOPs={:.2f} M ... = {:.2f} G\'.format(param, flop, flop/1e3))\n  logger.log(\'Finish training/validation in {:} with Max-GPU-Memory of {:.2f} MB, and save final checkpoint into {:}\'.format(convert_secs2time(epoch_time.sum, True), max(v for k, v in max_bytes.items()) / 1e6, logger.path(\'info\')))\n  logger.log(\'-\'*200 + \'\\n\')\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  args = obtain_args()\n  main(args)\n'"
exps/basic-eval.py,5,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport os, sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config\nfrom procedures   import get_procedures, get_optim_scheduler\nfrom datasets     import get_datasets\nfrom models       import obtain_model\nfrom utils        import get_model_infos\nfrom log_utils    import PrintLogger, time_string\n\n\nassert torch.cuda.is_available(), \'torch.cuda is not available\'\n\n\ndef main(args):\n\n  assert os.path.isdir ( args.data_path ) , \'invalid data-path : {:}\'.format(args.data_path)\n  assert os.path.isfile( args.checkpoint ), \'invalid checkpoint : {:}\'.format(args.checkpoint)\n\n  checkpoint = torch.load( args.checkpoint )\n  xargs      = checkpoint[\'args\']\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, args.data_path, xargs.cutout_length)\n  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=xargs.batch_size, shuffle=False, num_workers=xargs.workers, pin_memory=True)\n\n  logger       = PrintLogger()\n  model_config = dict2config(checkpoint[\'model-config\'], logger)\n  base_model   = obtain_model(model_config)\n  flop, param  = get_model_infos(base_model, xshape)\n  logger.log(\'model ====>>>>:\\n{:}\'.format(base_model))\n  logger.log(\'model information : {:}\'.format(base_model.get_message()))\n  logger.log(\'-\'*50)\n  logger.log(\'Params={:.2f} MB, FLOPs={:.2f} M ... = {:.2f} G\'.format(param, flop, flop/1e3))\n  logger.log(\'-\'*50)\n  logger.log(\'valid_data : {:}\'.format(valid_data))\n  optim_config = dict2config(checkpoint[\'optim-config\'], logger)\n  _, _, criterion = get_optim_scheduler(base_model.parameters(), optim_config)\n  logger.log(\'criterion  : {:}\'.format(criterion))\n  base_model.load_state_dict( checkpoint[\'base-model\'] )\n  _, valid_func = get_procedures(xargs.procedure)\n  logger.log(\'initialize the CNN done, evaluate it using {:}\'.format(valid_func))\n  network = torch.nn.DataParallel(base_model).cuda()\n  \n  try:\n    valid_loss, valid_acc1, valid_acc5 = valid_func(valid_loader, network, criterion, optim_config, \'pure-evaluation\', xargs.print_freq_eval, logger)\n  except:\n    _, valid_func = get_procedures(\'basic\')\n    valid_loss, valid_acc1, valid_acc5 = valid_func(valid_loader, network, criterion, optim_config, \'pure-evaluation\', xargs.print_freq_eval, logger)\n  \n  num_bytes = torch.cuda.max_memory_cached( next(network.parameters()).device ) * 1.0\n  logger.log(\'***{:s}*** EVALUATION loss = {:.6f}, accuracy@1 = {:.2f}, accuracy@5 = {:.2f}, error@1 = {:.2f}, error@5 = {:.2f}\'.format(time_string(), valid_loss, valid_acc1, valid_acc5, 100-valid_acc1, 100-valid_acc5))\n  logger.log(\'[GPU-Memory-Usage on {:} is {:} bytes, {:.2f} KB, {:.2f} MB, {:.2f} GB.]\'.format(next(network.parameters()).device, int(num_bytes), num_bytes / 1e3, num_bytes / 1e6, num_bytes / 1e9))\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Evaluate-CNN"")\n  parser.add_argument(\'--data_path\',         type=str,   help=\'Path to dataset.\')\n  parser.add_argument(\'--checkpoint\',        type=str,   help=\'Choose between Cifar10/100 and ImageNet.\')\n  args = parser.parse_args()\n  main(args)\n'"
exps/basic-main.py,14,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, obtain_basic_args as obtain_args\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint\nfrom procedures   import get_optim_scheduler, get_procedures\nfrom datasets     import get_datasets\nfrom models       import obtain_model\nfrom nas_infer_model import obtain_nas_infer_model\nfrom utils        import get_model_infos\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\n\n\ndef main(args):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = True\n  #torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( args.workers )\n  \n  prepare_seed(args.rand_seed)\n  logger = prepare_logger(args)\n  \n  train_data, valid_data, xshape, class_num = get_datasets(args.dataset, args.data_path, args.cutout_length)\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True , num_workers=args.workers, pin_memory=True)\n  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n  # get configures\n  model_config = load_config(args.model_config, {\'class_num\': class_num}, logger)\n  optim_config = load_config(args.optim_config, {\'class_num\': class_num}, logger)\n\n  if args.model_source == \'normal\':\n    base_model   = obtain_model(model_config)\n  elif args.model_source == \'nas\':\n    base_model   = obtain_nas_infer_model(model_config, args.extra_model_path)\n  elif args.model_source == \'autodl-searched\':\n    base_model   = obtain_model(model_config, args.extra_model_path)\n  else:\n    raise ValueError(\'invalid model-source : {:}\'.format(args.model_source))\n  flop, param  = get_model_infos(base_model, xshape)\n  logger.log(\'model ====>>>>:\\n{:}\'.format(base_model))\n  logger.log(\'model information : {:}\'.format(base_model.get_message()))\n  logger.log(\'-\'*50)\n  logger.log(\'Params={:.2f} MB, FLOPs={:.2f} M ... = {:.2f} G\'.format(param, flop, flop/1e3))\n  logger.log(\'-\'*50)\n  logger.log(\'train_data : {:}\'.format(train_data))\n  logger.log(\'valid_data : {:}\'.format(valid_data))\n  optimizer, scheduler, criterion = get_optim_scheduler(base_model.parameters(), optim_config)\n  logger.log(\'optimizer  : {:}\'.format(optimizer))\n  logger.log(\'scheduler  : {:}\'.format(scheduler))\n  logger.log(\'criterion  : {:}\'.format(criterion))\n  \n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(base_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_infox  = torch.load(last_info)\n    start_epoch = last_infox[\'epoch\'] + 1\n    last_checkpoint_path = last_infox[\'last_checkpoint\']\n    if not last_checkpoint_path.exists():\n      logger.log(\'Does not find {:}, try another path\'.format(last_checkpoint_path))\n      last_checkpoint_path = last_info.parent / last_checkpoint_path.parent.name / last_checkpoint_path.name\n    checkpoint  = torch.load( last_checkpoint_path )\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    optimizer.load_state_dict ( checkpoint[\'optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    max_bytes        = checkpoint[\'max_bytes\']\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  elif args.resume is not None:\n    assert Path(args.resume).exists(), \'Can not find the resume file : {:}\'.format(args.resume)\n    checkpoint  = torch.load( args.resume )\n    start_epoch = checkpoint[\'epoch\'] + 1\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    optimizer.load_state_dict ( checkpoint[\'optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    max_bytes        = checkpoint[\'max_bytes\']\n    logger.log(""=> loading checkpoint from \'{:}\' start with {:}-th epoch."".format(args.resume, start_epoch))\n  elif args.init_model is not None:\n    assert Path(args.init_model).exists(), \'Can not find the initialization file : {:}\'.format(args.init_model)\n    checkpoint  = torch.load( args.init_model )\n    base_model.load_state_dict( checkpoint[\'base-model\'] )\n    start_epoch, valid_accuracies, max_bytes = 0, {\'best\': -1}, {}\n    logger.log(\'=> initialize the model from {:}\'.format( args.init_model ))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, max_bytes = 0, {\'best\': -1}, {}\n\n  train_func, valid_func = get_procedures(args.procedure)\n  \n  total_epoch = optim_config.epochs + optim_config.warmup\n  # Main Training and Evaluation Loop\n  start_time  = time.time()\n  epoch_time  = AverageMeter()\n  for epoch in range(start_epoch, total_epoch):\n    scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch), True) )\n    epoch_str = \'epoch={:03d}/{:03d}\'.format(epoch, total_epoch)\n    LRs       = scheduler.get_lr()\n    find_best = False\n    # set-up drop-out ratio\n    if hasattr(base_model, \'update_drop_path\'): base_model.update_drop_path(model_config.drop_path_prob * epoch / total_epoch)\n    logger.log(\'\\n***{:s}*** start {:s} {:s}, LR=[{:.6f} ~ {:.6f}], scheduler={:}\'.format(time_string(), epoch_str, need_time, min(LRs), max(LRs), scheduler))\n    \n    # train for one epoch\n    train_loss, train_acc1, train_acc5 = train_func(train_loader, network, criterion, scheduler, optimizer, optim_config, epoch_str, args.print_freq, logger)\n    # log the results    \n    logger.log(\'***{:s}*** TRAIN [{:}] loss = {:.6f}, accuracy-1 = {:.2f}, accuracy-5 = {:.2f}\'.format(time_string(), epoch_str, train_loss, train_acc1, train_acc5))\n\n    # evaluate the performance\n    if (epoch % args.eval_frequency == 0) or (epoch + 1 == total_epoch):\n      logger.log(\'-\'*150)\n      valid_loss, valid_acc1, valid_acc5 = valid_func(valid_loader, network, criterion, optim_config, epoch_str, args.print_freq_eval, logger)\n      valid_accuracies[epoch] = valid_acc1\n      logger.log(\'***{:s}*** VALID [{:}] loss = {:.6f}, accuracy@1 = {:.2f}, accuracy@5 = {:.2f} | Best-Valid-Acc@1={:.2f}, Error@1={:.2f}\'.format(time_string(), epoch_str, valid_loss, valid_acc1, valid_acc5, valid_accuracies[\'best\'], 100-valid_accuracies[\'best\']))\n      if valid_acc1 > valid_accuracies[\'best\']:\n        valid_accuracies[\'best\'] = valid_acc1\n        find_best                = True\n        logger.log(\'Currently, the best validation accuracy found at {:03d}-epoch :: acc@1={:.2f}, acc@5={:.2f}, error@1={:.2f}, error@5={:.2f}, save into {:}.\'.format(epoch, valid_acc1, valid_acc5, 100-valid_acc1, 100-valid_acc5, model_best_path))\n      num_bytes = torch.cuda.max_memory_cached( next(network.parameters()).device ) * 1.0\n      logger.log(\'[GPU-Memory-Usage on {:} is {:} bytes, {:.2f} KB, {:.2f} MB, {:.2f} GB.]\'.format(next(network.parameters()).device, int(num_bytes), num_bytes / 1e3, num_bytes / 1e6, num_bytes / 1e9))\n      max_bytes[epoch] = num_bytes\n    if epoch % 10 == 0: torch.cuda.empty_cache()\n\n    # save checkpoint\n    save_path = save_checkpoint({\n          \'epoch\'        : epoch,\n          \'args\'         : deepcopy(args),\n          \'max_bytes\'    : deepcopy(max_bytes),\n          \'FLOP\'         : flop,\n          \'PARAM\'        : param,\n          \'valid_accuracies\': deepcopy(valid_accuracies),\n          \'model-config\' : model_config._asdict(),\n          \'optim-config\' : optim_config._asdict(),\n          \'base-model\'   : base_model.state_dict(),\n          \'scheduler\'    : scheduler.state_dict(),\n          \'optimizer\'    : optimizer.state_dict(),\n          }, model_base_path, logger)\n    if find_best: copy_checkpoint(model_base_path, model_best_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*200)\n  logger.log(\'Finish training/validation in {:} with Max-GPU-Memory of {:.2f} MB, and save final checkpoint into {:}\'.format(convert_secs2time(epoch_time.sum, True), max(v for k, v in max_bytes.items()) / 1e6, logger.path(\'info\')))\n  logger.log(\'-\'*200 + \'\\n\')\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  args = obtain_args()\n  main(args)\n'"
exps/prepare.py,1,"b'# python exps/prepare.py --name cifar10     --root $TORCH_HOME/cifar.python --save ./data/cifar10.split.pth\n# python exps/prepare.py --name cifar100    --root $TORCH_HOME/cifar.python --save ./data/cifar100.split.pth\n# python exps/prepare.py --name imagenet-1k --root $TORCH_HOME/ILSVRC2012   --save ./data/imagenet-1k.split.pth\nimport sys, time, torch, random, argparse\nfrom collections import defaultdict\nimport os.path as osp\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\nimport torchvision\nimport torchvision.datasets as dset\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nparser = argparse.ArgumentParser(description=\'Prepare splits for searching\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--name\' , type=str,    help=\'The dataset name.\')\nparser.add_argument(\'--root\' , type=str,    help=\'The directory to the dataset.\')\nparser.add_argument(\'--save\' , type=str,    help=\'The save path.\')\nparser.add_argument(\'--ratio\', type=float,  help=\'The save path.\')\nargs = parser.parse_args()\n\ndef main():\n  save_path = Path(args.save)\n  save_dir  = save_path.parent\n  name      = args.name\n  save_dir.mkdir(parents=True, exist_ok=True)\n  assert not save_path.exists(), \'{:} already exists\'.format(save_path)\n  print (\'torchvision version : {:}\'.format(torchvision.__version__))\n\n  if name == \'cifar10\':\n    dataset = dset.CIFAR10 (args.root, train=True)\n  elif name == \'cifar100\':\n    dataset = dset.CIFAR100(args.root, train=True)\n  elif name == \'imagenet-1k\':\n    dataset = dset.ImageFolder(osp.join(args.root, \'train\'))\n  else: raise TypeError(""Unknow dataset : {:}"".format(name))\n\n  if hasattr(dataset, \'targets\'):\n    targets = dataset.targets\n  elif hasattr(dataset, \'train_labels\'):\n    targets = dataset.train_labels\n  elif hasattr(dataset, \'imgs\'):\n    targets = [x[1] for x in dataset.imgs]\n  else:\n    raise ValueError(\'invalid pattern\')\n  print (\'There are {:} samples in this dataset.\'.format( len(targets) ))\n\n  class2index = defaultdict(list)\n  train, valid = [], []\n  random.seed(111)\n  for index, cls in enumerate(targets):\n    class2index[cls].append( index )\n  classes = sorted( list(class2index.keys()) )\n  for cls in classes:\n    xlist = class2index[cls]\n    xtrain = random.sample(xlist, int(len(xlist)*args.ratio))\n    xvalid = list(set(xlist) - set(xtrain))\n    train += xtrain\n    valid += xvalid\n  train.sort()\n  valid.sort()\n  ## for statistics\n  class2numT, class2numV = defaultdict(int), defaultdict(int)\n  for index in train:\n    class2numT[ targets[index] ] += 1\n  for index in valid:\n    class2numV[ targets[index] ] += 1\n  class2numT, class2numV = dict(class2numT), dict(class2numV)\n  torch.save({\'train\': train,\n              \'valid\': valid,\n              \'class2numTrain\': class2numT,\n              \'class2numValid\': class2numV}, save_path)\n  print (\'-\'*80)\n\nif __name__ == \'__main__\':\n  main()\n'"
exps/search-shape.py,17,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nfrom os      import path as osp\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport numpy as np\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nprint (\'lib_dir : {:}\'.format(lib_dir))\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, configure2str, obtain_search_single_args as obtain_args\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint\nfrom procedures   import get_optim_scheduler, get_procedures\nfrom datasets     import get_datasets, SearchDataset\nfrom models       import obtain_search_model, obtain_model, change_key\nfrom utils        import get_model_infos\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\n\n\ndef main(args):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = True\n  #torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( args.workers )\n  \n  prepare_seed(args.rand_seed)\n  logger = prepare_logger(args)\n  \n  # prepare dataset\n  train_data, valid_data, xshape, class_num = get_datasets(args.dataset, args.data_path, args.cutout_length)\n  #train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True , num_workers=args.workers, pin_memory=True)\n  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n\n  split_file_path = Path(args.split_path)\n  assert split_file_path.exists(), \'{:} does not exist\'.format(split_file_path)\n  split_info      = torch.load(split_file_path)\n\n  train_split, valid_split = split_info[\'train\'], split_info[\'valid\']\n  assert len( set(train_split).intersection( set(valid_split) ) ) == 0, \'There should be 0 element that belongs to both train and valid\'\n  assert len(train_split) + len(valid_split) == len(train_data), \'{:} + {:} vs {:}\'.format(len(train_split), len(valid_split), len(train_data))\n  search_dataset  = SearchDataset(args.dataset, train_data, train_split, valid_split)\n  \n  search_train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size,\n                      sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split), pin_memory=True, num_workers=args.workers)\n  search_valid_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size,\n                      sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), pin_memory=True, num_workers=args.workers)\n  search_loader       = torch.utils.data.DataLoader(search_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True, sampler=None)\n  # get configures\n  model_config = load_config(args.model_config, {\'class_num\': class_num, \'search_mode\': args.search_shape}, logger)\n\n  # obtain the model\n  search_model = obtain_search_model(model_config)\n  MAX_FLOP, param  = get_model_infos(search_model, xshape)\n  optim_config = load_config(args.optim_config, {\'class_num\': class_num, \'FLOP\': MAX_FLOP}, logger)\n  logger.log(\'Model Information : {:}\'.format(search_model.get_message()))\n  logger.log(\'MAX_FLOP = {:} M\'.format(MAX_FLOP))\n  logger.log(\'Params   = {:} M\'.format(param))\n  logger.log(\'train_data : {:}\'.format(train_data))\n  logger.log(\'search-data: {:}\'.format(search_dataset))\n  logger.log(\'search_train_loader : {:} samples\'.format( len(train_split) ))\n  logger.log(\'search_valid_loader : {:} samples\'.format( len(valid_split) ))\n  base_optimizer, scheduler, criterion = get_optim_scheduler(search_model.base_parameters(), optim_config)\n  arch_optimizer = torch.optim.Adam(search_model.arch_parameters(), lr=optim_config.arch_LR, betas=(0.5, 0.999), weight_decay=optim_config.arch_decay)\n  logger.log(\'base-optimizer : {:}\'.format(base_optimizer))\n  logger.log(\'arch-optimizer : {:}\'.format(arch_optimizer))\n  logger.log(\'scheduler      : {:}\'.format(scheduler))\n  logger.log(\'criterion      : {:}\'.format(criterion))\n  \n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  # load checkpoint\n  if last_info.exists() or (args.resume is not None and osp.isfile(args.resume)): # automatically resume from previous checkpoint\n    if args.resume is not None and osp.isfile(args.resume):\n      resume_path = Path(args.resume)\n    elif last_info.exists():\n      resume_path = last_info\n    else: raise ValueError(\'Something is wrong.\')\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(resume_path))\n    checkpoint  = torch.load(resume_path)\n    if \'last_checkpoint\' in checkpoint:\n      last_checkpoint_path = checkpoint[\'last_checkpoint\']\n      if not last_checkpoint_path.exists():\n        logger.log(\'Does not find {:}, try another path\'.format(last_checkpoint_path))\n        last_checkpoint_path = resume_path.parent / last_checkpoint_path.parent.name / last_checkpoint_path.name\n      assert last_checkpoint_path.exists(), \'can not find the checkpoint from {:}\'.format(last_checkpoint_path)\n      checkpoint = torch.load( last_checkpoint_path )\n    start_epoch = checkpoint[\'epoch\'] + 1\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    base_optimizer.load_state_dict ( checkpoint[\'base_optimizer\'] )\n    arch_optimizer.load_state_dict ( checkpoint[\'arch_optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    arch_genotypes   = checkpoint[\'arch_genotypes\']\n    discrepancies    = checkpoint[\'discrepancies\']\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(resume_path, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:} or resume : {:}"".format(last_info, args.resume))\n    start_epoch, valid_accuracies, arch_genotypes, discrepancies = 0, {\'best\': -1}, {}, {}\n\n  # main procedure\n  train_func, valid_func = get_procedures(args.procedure)\n  total_epoch = optim_config.epochs + optim_config.warmup\n  start_time, epoch_time = time.time(), AverageMeter()\n  for epoch in range(start_epoch, total_epoch):\n    scheduler.update(epoch, 0.0)\n    search_model.set_tau(args.gumbel_tau_max, args.gumbel_tau_min, epoch*1.0/total_epoch)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch), True) )\n    epoch_str = \'epoch={:03d}/{:03d}\'.format(epoch, total_epoch)\n    LRs       = scheduler.get_lr()\n    find_best = False\n   \n    logger.log(\'\\n***{:s}*** start {:s} {:s}, LR=[{:.6f} ~ {:.6f}], scheduler={:}, tau={:}, FLOP={:.2f}\'.format(time_string(), epoch_str, need_time, min(LRs), max(LRs), scheduler, search_model.tau, MAX_FLOP))\n\n    # train for one epoch\n    train_base_loss, train_arch_loss, train_acc1, train_acc5 = train_func(search_loader, network, criterion, scheduler, base_optimizer, arch_optimizer, optim_config, \\\n                                                                                {\'epoch-str\'  : epoch_str,        \'FLOP-exp\': MAX_FLOP * args.FLOP_ratio,\n                                                                                 \'FLOP-weight\': args.FLOP_weight, \'FLOP-tolerant\': MAX_FLOP * args.FLOP_tolerant}, args.print_freq, logger)\n    # log the results\n    logger.log(\'***{:s}*** TRAIN [{:}] base-loss = {:.6f}, arch-loss = {:.6f}, accuracy-1 = {:.2f}, accuracy-5 = {:.2f}\'.format(time_string(), epoch_str, train_base_loss, train_arch_loss, train_acc1, train_acc5))\n    cur_FLOP, genotype = search_model.get_flop(\'genotype\', model_config._asdict(), None)\n    arch_genotypes[epoch]  = genotype\n    arch_genotypes[\'last\'] = genotype\n    logger.log(\'[{:}] genotype : {:}\'.format(epoch_str, genotype))\n    arch_info, discrepancy = search_model.get_arch_info()\n    logger.log(arch_info)\n    discrepancies[epoch]   = discrepancy\n    logger.log(\'[{:}] FLOP : {:.2f} MB, ratio : {:.4f}, Expected-ratio : {:.4f}, Discrepancy : {:.3f}\'.format(epoch_str, cur_FLOP, cur_FLOP/MAX_FLOP, args.FLOP_ratio, np.mean(discrepancy)))\n\n    #if cur_FLOP/MAX_FLOP > args.FLOP_ratio:\n    #  init_flop_weight = init_flop_weight * args.FLOP_decay\n    #else:\n    #  init_flop_weight = init_flop_weight / args.FLOP_decay\n    \n    # evaluate the performance\n    if (epoch % args.eval_frequency == 0) or (epoch + 1 == total_epoch):\n      logger.log(\'-\'*150)\n      valid_loss, valid_acc1, valid_acc5 = valid_func(search_valid_loader, network, criterion, epoch_str, args.print_freq_eval, logger)\n      valid_accuracies[epoch] = valid_acc1\n      logger.log(\'***{:s}*** VALID [{:}] loss = {:.6f}, accuracy@1 = {:.2f}, accuracy@5 = {:.2f} | Best-Valid-Acc@1={:.2f}, Error@1={:.2f}\'.format(time_string(), epoch_str, valid_loss, valid_acc1, valid_acc5, valid_accuracies[\'best\'], 100-valid_accuracies[\'best\']))\n      if valid_acc1 > valid_accuracies[\'best\']:\n        valid_accuracies[\'best\'] = valid_acc1\n        arch_genotypes[\'best\']   = genotype\n        find_best                = True\n        logger.log(\'Currently, the best validation accuracy found at {:03d}-epoch :: acc@1={:.2f}, acc@5={:.2f}, error@1={:.2f}, error@5={:.2f}, save into {:}.\'.format(epoch, valid_acc1, valid_acc5, 100-valid_acc1, 100-valid_acc5, model_best_path))\n\n    # save checkpoint\n    save_path = save_checkpoint({\n          \'epoch\'        : epoch,\n          \'args\'         : deepcopy(args),\n          \'valid_accuracies\': deepcopy(valid_accuracies),\n          \'model-config\' : model_config._asdict(),\n          \'optim-config\' : optim_config._asdict(),\n          \'search_model\' : search_model.state_dict(),\n          \'scheduler\'    : scheduler.state_dict(),\n          \'base_optimizer\': base_optimizer.state_dict(),\n          \'arch_optimizer\': arch_optimizer.state_dict(),\n          \'arch_genotypes\': arch_genotypes,\n          \'discrepancies\' : discrepancies,\n          }, model_base_path, logger)\n    if find_best: copy_checkpoint(model_base_path, model_best_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    \n\n  logger.log(\'\')\n  logger.log(\'-\'*100)\n  last_config_path = logger.path(\'log\') / \'seed-{:}-last.config\'.format(args.rand_seed)\n  configure2str(arch_genotypes[\'last\'], str(last_config_path))\n  logger.log(\'save the last config int {:} :\\n{:}\'.format(last_config_path, arch_genotypes[\'last\']))\n\n  best_arch, valid_acc = arch_genotypes[\'best\'], valid_accuracies[\'best\']\n  for key, config in arch_genotypes.items():\n    if key == \'last\': continue\n    FLOP_ratio = config[\'estimated_FLOP\'] / MAX_FLOP\n    if abs(FLOP_ratio - args.FLOP_ratio) <= args.FLOP_tolerant:\n      if valid_acc < valid_accuracies[key]:\n        best_arch, valid_acc = config, valid_accuracies[key]\n  print(\'Best-Arch : {:}\\nRatio={:}, Valid-ACC={:}\'.format(best_arch, best_arch[\'estimated_FLOP\'] / MAX_FLOP, valid_acc))\n  best_config_path = logger.path(\'log\') / \'seed-{:}-best.config\'.format(args.rand_seed)\n  configure2str(best_arch, str(best_config_path))\n  logger.log(\'save the last config int {:} :\\n{:}\'.format(best_config_path, best_arch))\n  logger.log(\'\\n\' + \'-\'*200)\n  logger.log(\'Finish training/validation in {:}, and save final checkpoint into {:}\'.format(convert_secs2time(epoch_time.sum, True), logger.path(\'info\')))\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  args = obtain_args()\n  main(args)\n'"
exps/search-transformable.py,19,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#######################################################################\n# Network Pruning via Transformable Architecture Search, NeurIPS 2019 #\n#######################################################################\nimport sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nfrom os      import path as osp\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport numpy as np\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, configure2str, obtain_search_args as obtain_args\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint\nfrom procedures   import get_optim_scheduler, get_procedures\nfrom datasets     import get_datasets, SearchDataset\nfrom models       import obtain_search_model, obtain_model, change_key\nfrom utils        import get_model_infos\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\n\n\ndef main(args):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = True\n  #torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( args.workers )\n  \n  prepare_seed(args.rand_seed)\n  logger = prepare_logger(args)\n  \n  # prepare dataset\n  train_data, valid_data, xshape, class_num = get_datasets(args.dataset, args.data_path, args.cutout_length)\n  #train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True , num_workers=args.workers, pin_memory=True)\n  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n\n  split_file_path = Path(args.split_path)\n  assert split_file_path.exists(), \'{:} does not exist\'.format(split_file_path)\n  split_info      = torch.load(split_file_path)\n\n  train_split, valid_split = split_info[\'train\'], split_info[\'valid\']\n  assert len( set(train_split).intersection( set(valid_split) ) ) == 0, \'There should be 0 element that belongs to both train and valid\'\n  assert len(train_split) + len(valid_split) == len(train_data), \'{:} + {:} vs {:}\'.format(len(train_split), len(valid_split), len(train_data))\n  search_dataset  = SearchDataset(args.dataset, train_data, train_split, valid_split)\n  \n  search_train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size,\n                      sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split), pin_memory=True, num_workers=args.workers)\n  search_valid_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size,\n                      sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), pin_memory=True, num_workers=args.workers)\n  search_loader       = torch.utils.data.DataLoader(search_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True, sampler=None)\n  # get configures\n  if args.ablation_num_select is None or args.ablation_num_select <= 0:\n    model_config = load_config(args.model_config, {\'class_num\': class_num, \'search_mode\': \'shape\'}, logger)\n  else:\n    model_config = load_config(args.model_config, {\'class_num\': class_num, \'search_mode\': \'ablation\', \'num_random_select\': args.ablation_num_select}, logger)\n\n  # obtain the model\n  search_model = obtain_search_model(model_config)\n  MAX_FLOP, param  = get_model_infos(search_model, xshape)\n  optim_config = load_config(args.optim_config, {\'class_num\': class_num, \'FLOP\': MAX_FLOP}, logger)\n  logger.log(\'Model Information : {:}\'.format(search_model.get_message()))\n  logger.log(\'MAX_FLOP = {:} M\'.format(MAX_FLOP))\n  logger.log(\'Params   = {:} M\'.format(param))\n  logger.log(\'train_data : {:}\'.format(train_data))\n  logger.log(\'search-data: {:}\'.format(search_dataset))\n  logger.log(\'search_train_loader : {:} samples\'.format( len(train_split) ))\n  logger.log(\'search_valid_loader : {:} samples\'.format( len(valid_split) ))\n  base_optimizer, scheduler, criterion = get_optim_scheduler(search_model.base_parameters(), optim_config)\n  arch_optimizer = torch.optim.Adam(search_model.arch_parameters(optim_config.arch_LR), lr=optim_config.arch_LR, betas=(0.5, 0.999), weight_decay=optim_config.arch_decay)\n  logger.log(\'base-optimizer : {:}\'.format(base_optimizer))\n  logger.log(\'arch-optimizer : {:}\'.format(arch_optimizer))\n  logger.log(\'scheduler      : {:}\'.format(scheduler))\n  logger.log(\'criterion      : {:}\'.format(criterion))\n  \n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  # load checkpoint\n  if last_info.exists() or (args.resume is not None and osp.isfile(args.resume)): # automatically resume from previous checkpoint\n    if args.resume is not None and osp.isfile(args.resume):\n      resume_path = Path(args.resume)\n    elif last_info.exists():\n      resume_path = last_info\n    else: raise ValueError(\'Something is wrong.\')\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(resume_path))\n    checkpoint  = torch.load(resume_path)\n    if \'last_checkpoint\' in checkpoint:\n      last_checkpoint_path = checkpoint[\'last_checkpoint\']\n      if not last_checkpoint_path.exists():\n        logger.log(\'Does not find {:}, try another path\'.format(last_checkpoint_path))\n        last_checkpoint_path = resume_path.parent / last_checkpoint_path.parent.name / last_checkpoint_path.name\n      assert last_checkpoint_path.exists(), \'can not find the checkpoint from {:}\'.format(last_checkpoint_path)\n      checkpoint = torch.load( last_checkpoint_path )\n    start_epoch = checkpoint[\'epoch\'] + 1\n    #for key, value in checkpoint[\'search_model\'].items():\n    #  print(\'K {:} = Shape={:}\'.format(key, value.shape))\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    scheduler.load_state_dict ( checkpoint[\'scheduler\'] )\n    base_optimizer.load_state_dict ( checkpoint[\'base_optimizer\'] )\n    arch_optimizer.load_state_dict ( checkpoint[\'arch_optimizer\'] )\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    arch_genotypes   = checkpoint[\'arch_genotypes\']\n    discrepancies    = checkpoint[\'discrepancies\']\n    max_bytes        = checkpoint[\'max_bytes\']\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(resume_path, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:} or resume : {:}"".format(last_info, args.resume))\n    start_epoch, valid_accuracies, arch_genotypes, discrepancies, max_bytes = 0, {\'best\': -1}, {}, {}, {}\n\n  # main procedure\n  train_func, valid_func = get_procedures(args.procedure)\n  total_epoch = optim_config.epochs + optim_config.warmup\n  start_time, epoch_time = time.time(), AverageMeter()\n  for epoch in range(start_epoch, total_epoch):\n    scheduler.update(epoch, 0.0)\n    search_model.set_tau(args.gumbel_tau_max, args.gumbel_tau_min, epoch*1.0/total_epoch)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch), True) )\n    epoch_str = \'epoch={:03d}/{:03d}\'.format(epoch, total_epoch)\n    LRs       = scheduler.get_lr()\n    find_best = False\n   \n    logger.log(\'\\n***{:s}*** start {:s} {:s}, LR=[{:.6f} ~ {:.6f}], scheduler={:}, tau={:}, FLOP={:.2f}\'.format(time_string(), epoch_str, need_time, min(LRs), max(LRs), scheduler, search_model.tau, MAX_FLOP))\n\n    # train for one epoch\n    train_base_loss, train_arch_loss, train_acc1, train_acc5 = train_func(search_loader, network, criterion, scheduler, base_optimizer, arch_optimizer, optim_config, \\\n                                                                                {\'epoch-str\'  : epoch_str,        \'FLOP-exp\': MAX_FLOP * args.FLOP_ratio,\n                                                                                 \'FLOP-weight\': args.FLOP_weight, \'FLOP-tolerant\': MAX_FLOP * args.FLOP_tolerant}, args.print_freq, logger)\n    # log the results\n    logger.log(\'***{:s}*** TRAIN [{:}] base-loss = {:.6f}, arch-loss = {:.6f}, accuracy-1 = {:.2f}, accuracy-5 = {:.2f}\'.format(time_string(), epoch_str, train_base_loss, train_arch_loss, train_acc1, train_acc5))\n    cur_FLOP, genotype = search_model.get_flop(\'genotype\', model_config._asdict(), None)\n    arch_genotypes[epoch]  = genotype\n    arch_genotypes[\'last\'] = genotype\n    logger.log(\'[{:}] genotype : {:}\'.format(epoch_str, genotype))\n    # save the configuration\n    configure2str(genotype, str( logger.path(\'log\') / \'seed-{:}-temp.config\'.format(args.rand_seed) ))\n    arch_info, discrepancy = search_model.get_arch_info()\n    logger.log(arch_info)\n    discrepancies[epoch]   = discrepancy\n    logger.log(\'[{:}] FLOP : {:.2f} MB, ratio : {:.4f}, Expected-ratio : {:.4f}, Discrepancy : {:.3f}\'.format(epoch_str, cur_FLOP, cur_FLOP/MAX_FLOP, args.FLOP_ratio, np.mean(discrepancy)))\n\n    #if cur_FLOP/MAX_FLOP > args.FLOP_ratio:\n    #  init_flop_weight = init_flop_weight * args.FLOP_decay\n    #else:\n    #  init_flop_weight = init_flop_weight / args.FLOP_decay\n    \n    # evaluate the performance\n    if (epoch % args.eval_frequency == 0) or (epoch + 1 == total_epoch):\n      logger.log(\'-\'*150)\n      valid_loss, valid_acc1, valid_acc5 = valid_func(search_valid_loader, network, criterion, epoch_str, args.print_freq_eval, logger)\n      valid_accuracies[epoch] = valid_acc1\n      logger.log(\'***{:s}*** VALID [{:}] loss = {:.6f}, accuracy@1 = {:.2f}, accuracy@5 = {:.2f} | Best-Valid-Acc@1={:.2f}, Error@1={:.2f}\'.format(time_string(), epoch_str, valid_loss, valid_acc1, valid_acc5, valid_accuracies[\'best\'], 100-valid_accuracies[\'best\']))\n      if valid_acc1 > valid_accuracies[\'best\']:\n        valid_accuracies[\'best\'] = valid_acc1\n        arch_genotypes[\'best\']   = genotype\n        find_best                = True\n        logger.log(\'Currently, the best validation accuracy found at {:03d}-epoch :: acc@1={:.2f}, acc@5={:.2f}, error@1={:.2f}, error@5={:.2f}, save into {:}.\'.format(epoch, valid_acc1, valid_acc5, 100-valid_acc1, 100-valid_acc5, model_best_path))\n      # log the GPU memory usage\n      #num_bytes = torch.cuda.max_memory_allocated( next(network.parameters()).device ) * 1.0\n      num_bytes = torch.cuda.max_memory_cached( next(network.parameters()).device ) * 1.0\n      logger.log(\'[GPU-Memory-Usage on {:} is {:} bytes, {:.2f} KB, {:.2f} MB, {:.2f} GB.]\'.format(next(network.parameters()).device, int(num_bytes), num_bytes / 1e3, num_bytes / 1e6, num_bytes / 1e9))\n      max_bytes[epoch] = num_bytes\n\n    # save checkpoint\n    save_path = save_checkpoint({\n          \'epoch\'        : epoch,\n          \'args\'         : deepcopy(args),\n          \'max_bytes\'    : deepcopy(max_bytes),\n          \'valid_accuracies\': deepcopy(valid_accuracies),\n          \'model-config\' : model_config._asdict(),\n          \'optim-config\' : optim_config._asdict(),\n          \'search_model\' : search_model.state_dict(),\n          \'scheduler\'    : scheduler.state_dict(),\n          \'base_optimizer\': base_optimizer.state_dict(),\n          \'arch_optimizer\': arch_optimizer.state_dict(),\n          \'arch_genotypes\': arch_genotypes,\n          \'discrepancies\' : discrepancies,\n          }, model_base_path, logger)\n    if find_best: copy_checkpoint(model_base_path, model_best_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    \n\n  logger.log(\'\')\n  logger.log(\'-\'*100)\n  last_config_path = logger.path(\'log\') / \'seed-{:}-last.config\'.format(args.rand_seed)\n  configure2str(arch_genotypes[\'last\'], str(last_config_path))\n  logger.log(\'save the last config int {:} :\\n{:}\'.format(last_config_path, arch_genotypes[\'last\']))\n\n  best_arch, valid_acc = arch_genotypes[\'best\'], valid_accuracies[\'best\']\n  for key, config in arch_genotypes.items():\n    if key == \'last\': continue\n    FLOP_ratio = config[\'estimated_FLOP\'] / MAX_FLOP\n    if abs(FLOP_ratio - args.FLOP_ratio) <= args.FLOP_tolerant:\n      if valid_acc <= valid_accuracies[key]:\n        best_arch, valid_acc = config, valid_accuracies[key]\n  print(\'Best-Arch : {:}\\nRatio={:}, Valid-ACC={:}\'.format(best_arch, best_arch[\'estimated_FLOP\'] / MAX_FLOP, valid_acc))\n  best_config_path = logger.path(\'log\') / \'seed-{:}-best.config\'.format(args.rand_seed)\n  configure2str(best_arch, str(best_config_path))\n  logger.log(\'save the last config int {:} :\\n{:}\'.format(best_config_path, best_arch))\n  logger.log(\'\\n\' + \'-\'*200)\n  logger.log(\'Finish training/validation in {:} with Max-GPU-Memory of {:.2f} GB, and save final checkpoint into {:}\'.format(convert_secs2time(epoch_time.sum, True), max(v for k, v in max_bytes.items()) / 1e9, logger.path(\'info\')))\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  args = obtain_args()\n  main(args)\n'"
exps/NAS-Bench-201/check.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\n# python exps/NAS-Bench-201/check.py --base_str C16-N5-LESS\n#####################################################\nimport sys, time, argparse, collections\nimport torch\nfrom pathlib import Path\nfrom collections import defaultdict\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\n\n\ndef check_files(save_dir, meta_file, basestr):\n  meta_infos = torch.load(meta_file, map_location='cpu')\n  meta_archs = meta_infos['archs']\n  meta_num_archs = meta_infos['total']\n  assert meta_num_archs == len(meta_archs), 'invalid number of archs : {:} vs {:}'.format(meta_num_archs, len(meta_archs))\n\n  sub_model_dirs = sorted(list(save_dir.glob('*-*-{:}'.format(basestr))))\n  print ('{:} find {:} directories used to save checkpoints'.format(time_string(), len(sub_model_dirs)))\n  \n  subdir2archs, num_evaluated_arch = collections.OrderedDict(), 0\n  num_seeds = defaultdict(lambda: 0)\n  for index, sub_dir in enumerate(sub_model_dirs):\n    xcheckpoints = list(sub_dir.glob('arch-*-seed-*.pth'))\n    #xcheckpoints = list(sub_dir.glob('arch-*-seed-0777.pth')) + list(sub_dir.glob('arch-*-seed-0888.pth')) + list(sub_dir.glob('arch-*-seed-0999.pth'))\n    arch_indexes = set()\n    for checkpoint in xcheckpoints:\n      temp_names = checkpoint.name.split('-')\n      assert len(temp_names) == 4 and temp_names[0] == 'arch' and temp_names[2] == 'seed', 'invalid checkpoint name : {:}'.format(checkpoint.name)\n      arch_indexes.add( temp_names[1] )\n    subdir2archs[sub_dir] = sorted(list(arch_indexes))\n    num_evaluated_arch   += len(arch_indexes)\n    # count number of seeds for each architecture\n    for arch_index in arch_indexes:\n      num_seeds[ len(list(sub_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))) ] += 1\n  print('There are {:5d} architectures that have been evaluated ({:} in total, {:} ckps in total).'.format(num_evaluated_arch, meta_num_archs, sum(k*v for k, v in num_seeds.items())))\n  for key in sorted( list( num_seeds.keys() ) ): print ('There are {:5d} architectures that are evaluated {:} times.'.format(num_seeds[key], key))\n\n  dir2ckps, dir2ckp_exists = dict(), dict()\n  start_time, epoch_time = time.time(), AverageMeter()\n  for IDX, (sub_dir, arch_indexes) in enumerate(subdir2archs.items()):\n    if basestr == 'C16-N5':\n      seeds = [777, 888, 999]\n    elif basestr == 'C16-N5-LESS':\n      seeds = [111, 777]\n    else:\n      raise ValueError('Invalid base str : {:}'.format(basestr))\n    numrs = defaultdict(lambda: 0)\n    all_checkpoints, all_ckp_exists = [], []\n    for arch_index in arch_indexes:\n      checkpoints = ['arch-{:}-seed-{:04d}.pth'.format(arch_index, seed) for seed in seeds]\n      ckp_exists  = [(sub_dir/x).exists() for x in checkpoints]\n      arch_index  = int(arch_index)\n      assert 0 <= arch_index < len(meta_archs), 'invalid arch-index {:} (not found in meta_archs)'.format(arch_index)\n      all_checkpoints += checkpoints\n      all_ckp_exists  += ckp_exists\n      numrs[sum(ckp_exists)] += 1\n    dir2ckps[ str(sub_dir) ]       = all_checkpoints\n    dir2ckp_exists[ str(sub_dir) ] = all_ckp_exists\n    # measure time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    numrstr = ', '.join( ['{:}: {:03d}'.format(x, numrs[x]) for x in sorted(numrs.keys())] )\n    print('{:} load [{:2d}/{:2d}] [{:03d} archs] [{:04d}->{:04d} ckps] {:} done, need {:}. {:}'.format(time_string(), IDX+1, len(subdir2archs), len(arch_indexes), len(all_checkpoints), sum(all_ckp_exists), sub_dir, convert_secs2time(epoch_time.avg * (len(subdir2archs)-IDX-1), True), numrstr))\n\n\nif __name__ == '__main__':\n\n  parser = argparse.ArgumentParser(description='NAS Benchmark 201', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--base_save_dir', type=str, default='./output/NAS-BENCH-201-4', help='The base-name of folder to save checkpoints and log.')\n  parser.add_argument('--meta_path',     type=str, default='./output/NAS-BENCH-201-4/meta-node-4.pth', help='The meta file path.')\n  parser.add_argument('--base_str',      type=str, default='C16-N5',                   help='The basic string.')\n  args = parser.parse_args()\n\n  save_dir = Path(args.base_save_dir)\n  meta_path = Path(args.meta_path)\n  assert save_dir.exists(),  'invalid save dir path : {:}'.format(save_dir)\n  assert meta_path.exists(), 'invalid saved meta path : {:}'.format(meta_path)\n  print ('check NAS-Bench-201 in {:}'.format(save_dir))\n\n  check_files(save_dir, meta_path, args.base_str)\n"""
exps/NAS-Bench-201/dist-setup.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\n# [2020.02.25] Initialize the API as v1.1\n# [2020.03.09] Upgrade the API to v1.2\n# [2020.03.16] Upgrade the API to v1.3\nimport os\nfrom setuptools import setup\n\n\ndef read(fname=\'README.md\'):\n  with open(os.path.join(os.path.dirname(__file__), fname), encoding=\'utf-8\') as cfile:\n    return cfile.read()\n\n\nsetup(\n    name = ""nas_bench_201"",\n    version = ""1.3"",\n    author = ""Xuanyi Dong"",\n    author_email = ""dongxuanyi888@gmail.com"",\n    description = ""API for NAS-Bench-201 (a benchmark for neural architecture search)."",\n    license = ""MIT"",\n    keywords = ""NAS Dataset API DeepLearning"",\n    url = ""https://github.com/D-X-Y/NAS-Bench-201"",\n    packages=[\'nas_201_api\'],\n    long_description=read(\'README.md\'),\n    long_description_content_type=\'text/markdown\',\n    classifiers=[\n        ""Programming Language :: Python"",\n        ""Topic :: Database"",\n        ""Topic :: Scientific/Engineering :: Artificial Intelligence"",\n        ""License :: OSI Approved :: MIT License"",\n    ],\n)\n'"
exps/NAS-Bench-201/functions.py,4,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\nimport time, torch\nfrom procedures   import prepare_seed, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom config_utils import dict2config\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net\n\n\n__all__ = [\'evaluate_for_seed\', \'pure_evaluate\']\n\n\ndef pure_evaluate(xloader, network, criterion=torch.nn.CrossEntropyLoss()):\n  data_time, batch_time, batch = AverageMeter(), AverageMeter(), None\n  losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  latencies = []\n  network.eval()\n  with torch.no_grad():\n    end = time.time()\n    for i, (inputs, targets) in enumerate(xloader):\n      targets = targets.cuda(non_blocking=True)\n      inputs  = inputs.cuda(non_blocking=True)\n      data_time.update(time.time() - end)\n      # forward\n      features, logits = network(inputs)\n      loss             = criterion(logits, targets)\n      batch_time.update(time.time() - end)\n      if batch is None or batch == inputs.size(0):\n        batch = inputs.size(0)\n        latencies.append( batch_time.val - data_time.val )\n      # record loss and accuracy\n      prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n      losses.update(loss.item(),  inputs.size(0))\n      top1.update  (prec1.item(), inputs.size(0))\n      top5.update  (prec5.item(), inputs.size(0))\n      end = time.time()\n  if len(latencies) > 2: latencies = latencies[1:]\n  return losses.avg, top1.avg, top5.avg, latencies\n\n\n\ndef procedure(xloader, network, criterion, scheduler, optimizer, mode):\n  losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  if mode == \'train\'  : network.train()\n  elif mode == \'valid\': network.eval()\n  else: raise ValueError(""The mode is not right : {:}"".format(mode))\n\n  data_time, batch_time, end = AverageMeter(), AverageMeter(), time.time()\n  for i, (inputs, targets) in enumerate(xloader):\n    if mode == \'train\': scheduler.update(None, 1.0 * i / len(xloader))\n\n    targets = targets.cuda(non_blocking=True)\n    if mode == \'train\': optimizer.zero_grad()\n    # forward\n    features, logits = network(inputs)\n    loss             = criterion(logits, targets)\n    # backward\n    if mode == \'train\':\n      loss.backward()\n      optimizer.step()\n    # record loss and accuracy\n    prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n    losses.update(loss.item(),  inputs.size(0))\n    top1.update  (prec1.item(), inputs.size(0))\n    top5.update  (prec5.item(), inputs.size(0))\n    # count time\n    batch_time.update(time.time() - end)\n    end = time.time()\n  return losses.avg, top1.avg, top5.avg, batch_time.sum\n\n\n\ndef evaluate_for_seed(arch_config, config, arch, train_loader, valid_loaders, seed, logger):\n\n  prepare_seed(seed) # random seed\n  net = get_cell_based_tiny_net(dict2config({\'name\': \'infer.tiny\',\n                                             \'C\': arch_config[\'channel\'], \'N\': arch_config[\'num_cells\'],\n                                             \'genotype\': arch, \'num_classes\': config.class_num}\n                                            , None)\n                                 )\n  #net = TinyNetwork(arch_config[\'channel\'], arch_config[\'num_cells\'], arch, config.class_num)\n  flop, param  = get_model_infos(net, config.xshape)\n  logger.log(\'Network : {:}\'.format(net.get_message()), False)\n  logger.log(\'{:} Seed-------------------------- {:} --------------------------\'.format(time_string(), seed))\n  logger.log(\'FLOP = {:} MB, Param = {:} MB\'.format(flop, param))\n  # train and valid\n  optimizer, scheduler, criterion = get_optim_scheduler(net.parameters(), config)\n  network, criterion = torch.nn.DataParallel(net).cuda(), criterion.cuda()\n  # start training\n  start_time, epoch_time, total_epoch = time.time(), AverageMeter(), config.epochs + config.warmup\n  train_losses, train_acc1es, train_acc5es, valid_losses, valid_acc1es, valid_acc5es = {}, {}, {}, {}, {}, {}\n  train_times , valid_times = {}, {}\n  for epoch in range(total_epoch):\n    scheduler.update(epoch, 0.0)\n\n    train_loss, train_acc1, train_acc5, train_tm = procedure(train_loader, network, criterion, scheduler, optimizer, \'train\')\n    train_losses[epoch] = train_loss\n    train_acc1es[epoch] = train_acc1 \n    train_acc5es[epoch] = train_acc5\n    train_times [epoch] = train_tm\n    with torch.no_grad():\n      for key, xloder in valid_loaders.items():\n        valid_loss, valid_acc1, valid_acc5, valid_tm = procedure(xloder  , network, criterion,      None,      None, \'valid\')\n        valid_losses[\'{:}@{:}\'.format(key,epoch)] = valid_loss\n        valid_acc1es[\'{:}@{:}\'.format(key,epoch)] = valid_acc1 \n        valid_acc5es[\'{:}@{:}\'.format(key,epoch)] = valid_acc5\n        valid_times [\'{:}@{:}\'.format(key,epoch)] = valid_tm\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch-1), True) )\n    logger.log(\'{:} {:} epoch={:03d}/{:03d} :: Train [loss={:.5f}, acc@1={:.2f}%, acc@5={:.2f}%] Valid [loss={:.5f}, acc@1={:.2f}%, acc@5={:.2f}%]\'.format(time_string(), need_time, epoch, total_epoch, train_loss, train_acc1, train_acc5, valid_loss, valid_acc1, valid_acc5))\n  info_seed = {\'flop\' : flop,\n               \'param\': param,\n               \'channel\'     : arch_config[\'channel\'],\n               \'num_cells\'   : arch_config[\'num_cells\'],\n               \'config\'      : config._asdict(),\n               \'total_epoch\' : total_epoch ,\n               \'train_losses\': train_losses,\n               \'train_acc1es\': train_acc1es,\n               \'train_acc5es\': train_acc5es,\n               \'train_times\' : train_times,\n               \'valid_losses\': valid_losses,\n               \'valid_acc1es\': valid_acc1es,\n               \'valid_acc5es\': valid_acc5es,\n               \'valid_times\' : valid_times,\n               \'net_state_dict\': net.state_dict(),\n               \'net_string\'  : \'{:}\'.format(net),\n               \'finish-train\': True\n              }\n  return info_seed\n'"
exps/NAS-Bench-201/main.py,24,"b""###############################################################\n# NAS-Bench-201, ICLR 2020 (https://arxiv.org/abs/2001.00326) #\n###############################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08           #\n###############################################################\nimport os, sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config\nfrom procedures   import save_checkpoint, copy_checkpoint\nfrom procedures   import get_machine_info\nfrom datasets     import get_datasets\nfrom log_utils    import Logger, AverageMeter, time_string, convert_secs2time\nfrom models       import CellStructure, CellArchitectures, get_search_spaces\nfrom functions    import evaluate_for_seed\n\n\ndef evaluate_all_datasets(arch, datasets, xpaths, splits, use_less, seed, arch_config, workers, logger):\n  machine_info, arch_config = get_machine_info(), deepcopy(arch_config)\n  all_infos = {'info': machine_info}\n  all_dataset_keys = []\n  # look all the datasets\n  for dataset, xpath, split in zip(datasets, xpaths, splits):\n    # train valid data\n    train_data, valid_data, xshape, class_num = get_datasets(dataset, xpath, -1)\n    # load the configuration\n    if dataset == 'cifar10' or dataset == 'cifar100':\n      if use_less: config_path = 'configs/nas-benchmark/LESS.config'\n      else       : config_path = 'configs/nas-benchmark/CIFAR.config'\n      split_info  = load_config('configs/nas-benchmark/cifar-split.txt', None, None)\n    elif dataset.startswith('ImageNet16'):\n      if use_less: config_path = 'configs/nas-benchmark/LESS.config'\n      else       : config_path = 'configs/nas-benchmark/ImageNet-16.config'\n      split_info  = load_config('configs/nas-benchmark/{:}-split.txt'.format(dataset), None, None)\n    else:\n      raise ValueError('invalid dataset : {:}'.format(dataset))\n    config = load_config(config_path, \\\n                            {'class_num': class_num,\n                             'xshape'   : xshape}, \\\n                            logger)\n    # check whether use splited validation set\n    if bool(split):\n      assert dataset == 'cifar10'\n      ValLoaders = {'ori-test': torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)}\n      assert len(train_data) == len(split_info.train) + len(split_info.valid), 'invalid length : {:} vs {:} + {:}'.format(len(train_data), len(split_info.train), len(split_info.valid))\n      train_data_v2 = deepcopy(train_data)\n      train_data_v2.transform = valid_data.transform\n      valid_data = train_data_v2\n      # data loader\n      train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(split_info.train), num_workers=workers, pin_memory=True)\n      valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(split_info.valid), num_workers=workers, pin_memory=True)\n      ValLoaders['x-valid'] = valid_loader\n    else:\n      # data loader\n      train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, shuffle=True , num_workers=workers, pin_memory=True)\n      valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n      if dataset == 'cifar10':\n        ValLoaders = {'ori-test': valid_loader}\n      elif dataset == 'cifar100':\n        cifar100_splits = load_config('configs/nas-benchmark/cifar100-test-split.txt', None, None)\n        ValLoaders = {'ori-test': valid_loader,\n                      'x-valid' : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xvalid), num_workers=workers, pin_memory=True),\n                      'x-test'  : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xtest ), num_workers=workers, pin_memory=True)\n                     }\n      elif dataset == 'ImageNet16-120':\n        imagenet16_splits = load_config('configs/nas-benchmark/imagenet-16-120-test-split.txt', None, None)\n        ValLoaders = {'ori-test': valid_loader,\n                      'x-valid' : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet16_splits.xvalid), num_workers=workers, pin_memory=True),\n                      'x-test'  : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet16_splits.xtest ), num_workers=workers, pin_memory=True)\n                     }\n      else:\n        raise ValueError('invalid dataset : {:}'.format(dataset))\n\n    dataset_key = '{:}'.format(dataset)\n    if bool(split): dataset_key = dataset_key + '-valid'\n    logger.log('Evaluate ||||||| {:10s} ||||||| Train-Num={:}, Valid-Num={:}, Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}'.format(dataset_key, len(train_data), len(valid_data), len(train_loader), len(valid_loader), config.batch_size))\n    logger.log('Evaluate ||||||| {:10s} ||||||| Config={:}'.format(dataset_key, config))\n    for key, value in ValLoaders.items():\n      logger.log('Evaluate ---->>>> {:10s} with {:} batchs'.format(key, len(value)))\n    results = evaluate_for_seed(arch_config, config, arch, train_loader, ValLoaders, seed, logger)\n    all_infos[dataset_key] = results\n    all_dataset_keys.append( dataset_key )\n  all_infos['all_dataset_keys'] = all_dataset_keys\n  return all_infos\n\n\ndef main(save_dir, workers, datasets, xpaths, splits, use_less, srange, arch_index, seeds, cover_mode, meta_info, arch_config):\n  assert torch.cuda.is_available(), 'CUDA is not available.'\n  torch.backends.cudnn.enabled   = True\n  #torch.backends.cudnn.benchmark = True\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( workers )\n\n  assert len(srange) == 2 and 0 <= srange[0] <= srange[1], 'invalid srange : {:}'.format(srange)\n  \n  if use_less:\n    sub_dir = Path(save_dir) / '{:06d}-{:06d}-C{:}-N{:}-LESS'.format(srange[0], srange[1], arch_config['channel'], arch_config['num_cells'])\n  else:\n    sub_dir = Path(save_dir) / '{:06d}-{:06d}-C{:}-N{:}'.format(srange[0], srange[1], arch_config['channel'], arch_config['num_cells'])\n  logger  = Logger(str(sub_dir), 0, False)\n\n  all_archs = meta_info['archs']\n  assert srange[1] < meta_info['total'], 'invalid range : {:}-{:} vs. {:}'.format(srange[0], srange[1], meta_info['total'])\n  assert arch_index == -1 or srange[0] <= arch_index <= srange[1], 'invalid range : {:} vs. {:} vs. {:}'.format(srange[0], arch_index, srange[1])\n  if arch_index == -1:\n    to_evaluate_indexes = list(range(srange[0], srange[1]+1))\n  else:\n    to_evaluate_indexes = [arch_index]\n  logger.log('xargs : seeds      = {:}'.format(seeds))\n  logger.log('xargs : arch_index = {:}'.format(arch_index))\n  logger.log('xargs : cover_mode = {:}'.format(cover_mode))\n  logger.log('-'*100)\n\n  logger.log('Start evaluating range =: {:06d} vs. {:06d} vs. {:06d} / {:06d} with cover-mode={:}'.format(srange[0], arch_index, srange[1], meta_info['total'], cover_mode))\n  for i, (dataset, xpath, split) in enumerate(zip(datasets, xpaths, splits)):\n    logger.log('--->>> Evaluate {:}/{:} : dataset={:9s}, path={:}, split={:}'.format(i, len(datasets), dataset, xpath, split))\n  logger.log('--->>> architecture config : {:}'.format(arch_config))\n  \n\n  start_time, epoch_time = time.time(), AverageMeter()\n  for i, index in enumerate(to_evaluate_indexes):\n    arch = all_archs[index]\n    logger.log('\\n{:} evaluate {:06d}/{:06d} ({:06d}/{:06d})-th architecture [seeds={:}] {:}'.format('-'*15, i, len(to_evaluate_indexes), index, meta_info['total'], seeds, '-'*15))\n    #logger.log('{:} {:} {:}'.format('-'*15, arch.tostr(), '-'*15))\n    logger.log('{:} {:} {:}'.format('-'*15, arch, '-'*15))\n  \n    # test this arch on different datasets with different seeds\n    has_continue = False\n    for seed in seeds:\n      to_save_name = sub_dir / 'arch-{:06d}-seed-{:04d}.pth'.format(index, seed)\n      if to_save_name.exists():\n        if cover_mode:\n          logger.log('Find existing file : {:}, remove it before evaluation'.format(to_save_name))\n          os.remove(str(to_save_name))\n        else         :\n          logger.log('Find existing file : {:}, skip this evaluation'.format(to_save_name))\n          has_continue = True\n          continue\n      results = evaluate_all_datasets(CellStructure.str2structure(arch), \\\n                                        datasets, xpaths, splits, use_less, seed, \\\n                                        arch_config, workers, logger)\n      torch.save(results, to_save_name)\n      logger.log('{:} --evaluate-- {:06d}/{:06d} ({:06d}/{:06d})-th seed={:} done, save into {:}'.format('-'*15, i, len(to_evaluate_indexes), index, meta_info['total'], seed, to_save_name))\n    # measure elapsed time\n    if not has_continue: epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    need_time = 'Time Left: {:}'.format( convert_secs2time(epoch_time.avg * (len(to_evaluate_indexes)-i-1), True) )\n    logger.log('This arch costs : {:}'.format( convert_secs2time(epoch_time.val, True) ))\n    logger.log('{:}'.format('*'*100))\n    logger.log('{:}   {:74s}   {:}'.format('*'*10, '{:06d}/{:06d} ({:06d}/{:06d})-th done, left {:}'.format(i, len(to_evaluate_indexes), index, meta_info['total'], need_time), '*'*10))\n    logger.log('{:}'.format('*'*100))\n\n  logger.close()\n\n\ndef train_single_model(save_dir, workers, datasets, xpaths, splits, use_less, seeds, model_str, arch_config):\n  assert torch.cuda.is_available(), 'CUDA is not available.'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.deterministic = True\n  #torch.backends.cudnn.benchmark = True\n  torch.set_num_threads( workers )\n  \n  save_dir = Path(save_dir) / 'specifics' / '{:}-{:}-{:}-{:}'.format('LESS' if use_less else 'FULL', model_str, arch_config['channel'], arch_config['num_cells'])\n  logger   = Logger(str(save_dir), 0, False)\n  if model_str in CellArchitectures:\n    arch   = CellArchitectures[model_str]\n    logger.log('The model string is found in pre-defined architecture dict : {:}'.format(model_str))\n  else:\n    try:\n      arch = CellStructure.str2structure(model_str)\n    except:\n      raise ValueError('Invalid model string : {:}. It can not be found or parsed.'.format(model_str))\n  assert arch.check_valid_op(get_search_spaces('cell', 'full')), '{:} has the invalid op.'.format(arch)\n  logger.log('Start train-evaluate {:}'.format(arch.tostr()))\n  logger.log('arch_config : {:}'.format(arch_config))\n\n  start_time, seed_time = time.time(), AverageMeter()\n  for _is, seed in enumerate(seeds):\n    logger.log('\\nThe {:02d}/{:02d}-th seed is {:} ----------------------<.>----------------------'.format(_is, len(seeds), seed))\n    to_save_name = save_dir / 'seed-{:04d}.pth'.format(seed)\n    if to_save_name.exists():\n      logger.log('Find the existing file {:}, directly load!'.format(to_save_name))\n      checkpoint = torch.load(to_save_name)\n    else:\n      logger.log('Does not find the existing file {:}, train and evaluate!'.format(to_save_name))\n      checkpoint = evaluate_all_datasets(arch, datasets, xpaths, splits, use_less, seed, arch_config, workers, logger)\n      torch.save(checkpoint, to_save_name)\n    # log information\n    logger.log('{:}'.format(checkpoint['info']))\n    all_dataset_keys = checkpoint['all_dataset_keys']\n    for dataset_key in all_dataset_keys:\n      logger.log('\\n{:} dataset : {:} {:}'.format('-'*15, dataset_key, '-'*15))\n      dataset_info = checkpoint[dataset_key]\n      #logger.log('Network ==>\\n{:}'.format( dataset_info['net_string'] ))\n      logger.log('Flops = {:} MB, Params = {:} MB'.format(dataset_info['flop'], dataset_info['param']))\n      logger.log('config : {:}'.format(dataset_info['config']))\n      logger.log('Training State (finish) = {:}'.format(dataset_info['finish-train']))\n      last_epoch = dataset_info['total_epoch'] - 1\n      train_acc1es, train_acc5es = dataset_info['train_acc1es'], dataset_info['train_acc5es']\n      valid_acc1es, valid_acc5es = dataset_info['valid_acc1es'], dataset_info['valid_acc5es']\n      logger.log('Last Info : Train = Acc@1 {:.2f}% Acc@5 {:.2f}% Error@1 {:.2f}%, Test = Acc@1 {:.2f}% Acc@5 {:.2f}% Error@1 {:.2f}%'.format(train_acc1es[last_epoch], train_acc5es[last_epoch], 100-train_acc1es[last_epoch], valid_acc1es[last_epoch], valid_acc5es[last_epoch], 100-valid_acc1es[last_epoch]))\n    # measure elapsed time\n    seed_time.update(time.time() - start_time)\n    start_time = time.time()\n    need_time = 'Time Left: {:}'.format( convert_secs2time(seed_time.avg * (len(seeds)-_is-1), True) )\n    logger.log('\\n<<<***>>> The {:02d}/{:02d}-th seed is {:} <finish> other procedures need {:}'.format(_is, len(seeds), seed, need_time))\n  logger.close()\n\n\ndef generate_meta_info(save_dir, max_node, divide=40):\n  aa_nas_bench_ss = get_search_spaces('cell', 'nas-bench-201')\n  archs = CellStructure.gen_all(aa_nas_bench_ss, max_node, False)\n  print ('There are {:} archs vs {:}.'.format(len(archs), len(aa_nas_bench_ss) ** ((max_node-1)*max_node/2)))\n\n  random.seed( 88 ) # please do not change this line for reproducibility\n  random.shuffle( archs )\n  # to test fixed-random shuffle \n  #print ('arch [0] : {:}\\n---->>>>   {:}'.format( archs[0], archs[0].tostr() ))\n  #print ('arch [9] : {:}\\n---->>>>   {:}'.format( archs[9], archs[9].tostr() ))\n  assert archs[0  ].tostr() == '|avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|', 'please check the 0-th architecture : {:}'.format(archs[0])\n  assert archs[9  ].tostr() == '|avg_pool_3x3~0|+|none~0|none~1|+|skip_connect~0|none~1|nor_conv_3x3~2|', 'please check the 9-th architecture : {:}'.format(archs[9])\n  assert archs[123].tostr() == '|avg_pool_3x3~0|+|avg_pool_3x3~0|nor_conv_1x1~1|+|none~0|avg_pool_3x3~1|nor_conv_3x3~2|', 'please check the 123-th architecture : {:}'.format(archs[123])\n  total_arch = len(archs)\n  \n  num = 50000\n  indexes_5W = list(range(num))\n  random.seed( 1021 )\n  random.shuffle( indexes_5W )\n  train_split = sorted( list(set(indexes_5W[:num//2])) )\n  valid_split = sorted( list(set(indexes_5W[num//2:])) )\n  assert len(train_split) + len(valid_split) == num\n  assert train_split[0] == 0 and train_split[10] == 26 and train_split[111] == 203 and valid_split[0] == 1 and valid_split[10] == 18 and valid_split[111] == 242, '{:} {:} {:} - {:} {:} {:}'.format(train_split[0], train_split[10], train_split[111], valid_split[0], valid_split[10], valid_split[111])\n  splits = {num: {'train': train_split, 'valid': valid_split} }\n\n  info = {'archs' : [x.tostr() for x in archs],\n          'total' : total_arch,\n          'max_node' : max_node,\n          'splits': splits}\n\n  save_dir = Path(save_dir)\n  save_dir.mkdir(parents=True, exist_ok=True)\n  save_name = save_dir / 'meta-node-{:}.pth'.format(max_node)\n  assert not save_name.exists(), '{:} already exist'.format(save_name)\n  torch.save(info, save_name)\n  print ('save the meta file into {:}'.format(save_name))\n\n  script_name_full = save_dir / 'BENCH-201-N{:}.opt-full.script'.format(max_node)\n  script_name_less = save_dir / 'BENCH-201-N{:}.opt-less.script'.format(max_node)\n  full_file = open(str(script_name_full), 'w')\n  less_file = open(str(script_name_less), 'w')\n  gaps = total_arch // divide\n  for start in range(0, total_arch, gaps):\n    xend = min(start+gaps, total_arch)\n    full_file.write('bash ./scripts-search/NAS-Bench-201/train-models.sh 0 {:5d} {:5d} -1 \\'777 888 999\\'\\n'.format(start, xend-1))\n    less_file.write('bash ./scripts-search/NAS-Bench-201/train-models.sh 1 {:5d} {:5d} -1 \\'777 888 999\\'\\n'.format(start, xend-1))\n  print ('save the training script into {:} and {:}'.format(script_name_full, script_name_less))\n  full_file.close()\n  less_file.close()\n\n  script_name = save_dir / 'meta-node-{:}.cal-script.txt'.format(max_node)\n  macro = 'OMP_NUM_THREADS=6 CUDA_VISIBLE_DEVICES=0'\n  with open(str(script_name), 'w') as cfile:\n    for start in range(0, total_arch, gaps):\n      xend = min(start+gaps, total_arch)\n      cfile.write('{:} python exps/NAS-Bench-201/statistics.py --mode cal --target_dir {:06d}-{:06d}-C16-N5\\n'.format(macro, start, xend-1))\n  print ('save the post-processing script into {:}'.format(script_name))\n\n\nif __name__ == '__main__':\n  #mode_choices = ['meta', 'new', 'cover'] + ['specific-{:}'.format(_) for _ in CellArchitectures.keys()]\n  #parser = argparse.ArgumentParser(description='Algorithm-Agnostic NAS Benchmark', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser = argparse.ArgumentParser(description='NAS-Bench-201', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--mode'   ,     type=str,   required=True,  help='The script mode.')\n  parser.add_argument('--save_dir',    type=str,                   help='Folder to save checkpoints and log.')\n  parser.add_argument('--max_node',    type=int,                   help='The maximum node in a cell.')\n  # use for train the model\n  parser.add_argument('--workers',     type=int,   default=8,      help='number of data loading workers (default: 2)')\n  parser.add_argument('--srange' ,     type=int,   nargs='+',      help='The range of models to be evaluated')\n  parser.add_argument('--arch_index',  type=int,   default=-1,     help='The architecture index to be evaluated (cover mode).')\n  parser.add_argument('--datasets',    type=str,   nargs='+',      help='The applied datasets.')\n  parser.add_argument('--xpaths',      type=str,   nargs='+',      help='The root path for this dataset.')\n  parser.add_argument('--splits',      type=int,   nargs='+',      help='The root path for this dataset.')\n  parser.add_argument('--use_less',    type=int,   default=0, choices=[0,1], help='Using the less-training-epoch config.')\n  parser.add_argument('--seeds'  ,     type=int,   nargs='+',      help='The range of models to be evaluated')\n  parser.add_argument('--channel',     type=int,                   help='The number of channels.')\n  parser.add_argument('--num_cells',   type=int,                   help='The number of cells in one stage.')\n  args = parser.parse_args()\n\n  assert args.mode in ['meta', 'new', 'cover'] or args.mode.startswith('specific-'), 'invalid mode : {:}'.format(args.mode)\n\n  if args.mode == 'meta':\n    generate_meta_info(args.save_dir, args.max_node)\n  elif args.mode.startswith('specific'):\n    assert len(args.mode.split('-')) == 2, 'invalid mode : {:}'.format(args.mode)\n    model_str = args.mode.split('-')[1]\n    train_single_model(args.save_dir, args.workers, args.datasets, args.xpaths, args.splits, args.use_less>0, \\\n                         tuple(args.seeds), model_str, {'channel': args.channel, 'num_cells': args.num_cells})\n  else:\n    meta_path = Path(args.save_dir) / 'meta-node-{:}.pth'.format(args.max_node)\n    assert meta_path.exists(), '{:} does not exist.'.format(meta_path)\n    meta_info = torch.load( meta_path )\n    # check whether args is ok\n    assert len(args.srange) == 2 and args.srange[0] <= args.srange[1], 'invalid length of srange args: {:}'.format(args.srange)\n    assert len(args.seeds) > 0, 'invalid length of seeds args: {:}'.format(args.seeds)\n    assert len(args.datasets) == len(args.xpaths) == len(args.splits), 'invalid infos : {:} vs {:} vs {:}'.format(len(args.datasets), len(args.xpaths), len(args.splits))\n    assert args.workers > 0, 'invalid number of workers : {:}'.format(args.workers)\n  \n    main(args.save_dir, args.workers, args.datasets, args.xpaths, args.splits, args.use_less>0, \\\n           tuple(args.srange), args.arch_index, tuple(args.seeds), \\\n           args.mode == 'cover', meta_info, \\\n           {'channel': args.channel, 'num_cells': args.num_cells})\n"""
exps/NAS-Bench-201/show-best.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020.01 #\n################################################################################################\n# python exps/NAS-Bench-201/show-best.py --api_path $HOME/.torch/NAS-Bench-201-v1_0-e61699.pth #\n################################################################################################\nimport sys, argparse\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom nas_201_api  import NASBench201API as API\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Analysis of NAS-Bench-201"")\n  parser.add_argument(\'--api_path\',  type=str, default=None,                                         help=\'The path to the NAS-Bench-201 benchmark file.\')\n  args = parser.parse_args()\n\n  meta_file = Path(args.api_path)\n  assert meta_file.exists(), \'invalid path for api : {:}\'.format(meta_file)\n\n  api = API(str(meta_file))\n\n  # This will show the results of the best architecture based on the validation set of each dataset.\n  arch_index, accuracy = api.find_best(\'cifar10-valid\', \'x-valid\', None, None, False)\n  print(\'FOR CIFAR-010, using the hyper-parameters with 200 training epochs :::\')\n  print(\'arch-index={:5d}, arch={:}\'.format(arch_index, api.arch(arch_index)))\n  api.show(arch_index)\n  print(\'\')\n\n  arch_index, accuracy = api.find_best(\'cifar100\', \'x-valid\', None, None, False)\n  print(\'FOR CIFAR-100, using the hyper-parameters with 200 training epochs :::\')\n  print(\'arch-index={:5d}, arch={:}\'.format(arch_index, api.arch(arch_index)))\n  api.show(arch_index)\n  print(\'\')\n\n  arch_index, accuracy = api.find_best(\'ImageNet16-120\', \'x-valid\', None, None, False)\n  print(\'FOR ImageNet16-120, using the hyper-parameters with 200 training epochs :::\')\n  print(\'arch-index={:5d}, arch={:}\'.format(arch_index, api.arch(arch_index)))\n  api.show(arch_index)\n  print(\'\')\n'"
exps/NAS-Bench-201/statistics-v2.py,8,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\nimport os, sys, time, argparse, collections\nimport numpy as np\nimport torch\nfrom pathlib import Path\nfrom collections import defaultdict, OrderedDict\nfrom typing import Dict, Any, Text, List\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom config_utils import dict2config\n# NAS-Bench-201 related module or function\nfrom models       import CellStructure, get_cell_based_tiny_net\nfrom nas_201_api  import NASBench201API, ArchResults, ResultsCount\nfrom procedures   import bench_pure_evaluate as pure_evaluate, get_nas_bench_loaders\n\napi = NASBench201API('{:}/.torch/NAS-Bench-201-v1_0-e61699.pth'.format(os.environ['HOME']))\n\ndef create_result_count(used_seed: int, dataset: Text, arch_config: Dict[Text, Any],\n                        results: Dict[Text, Any], dataloader_dict: Dict[Text, Any]) -> ResultsCount:\n  xresult = ResultsCount(dataset, results['net_state_dict'], results['train_acc1es'], results['train_losses'],\n                         results['param'], results['flop'], arch_config, used_seed, results['total_epoch'], None)\n  net_config = dict2config({'name': 'infer.tiny', 'C': arch_config['channel'], 'N': arch_config['num_cells'], 'genotype': CellStructure.str2structure(arch_config['arch_str']), 'num_classes':arch_config['class_num']}, None)\n  network = get_cell_based_tiny_net(net_config)\n  network.load_state_dict(xresult.get_net_param())\n  if 'train_times' in results: # new version\n    xresult.update_train_info(results['train_acc1es'], results['train_acc5es'], results['train_losses'], results['train_times'])\n    xresult.update_eval(results['valid_acc1es'], results['valid_losses'], results['valid_times'])\n  else:\n    if dataset == 'cifar10-valid':\n      xresult.update_OLD_eval('x-valid' , results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format('cifar10', 'test')], network.cuda())\n      xresult.update_OLD_eval('ori-test', {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      xresult.update_latency(latencies)\n    elif dataset == 'cifar10':\n      xresult.update_OLD_eval('ori-test', results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset, 'test')], network.cuda())\n      xresult.update_latency(latencies)\n    elif dataset == 'cifar100' or dataset == 'ImageNet16-120':\n      xresult.update_OLD_eval('ori-test', results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset, 'valid')], network.cuda())\n      xresult.update_OLD_eval('x-valid', {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset,  'test')], network.cuda())\n      xresult.update_OLD_eval('x-test' , {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      xresult.update_latency(latencies)\n    else:\n      raise ValueError('invalid dataset name : {:}'.format(dataset))\n  return xresult\n  \n\n\ndef account_one_arch(arch_index: int, arch_str: Text, checkpoints: List[Text],\n                     datasets: List[Text], dataloader_dict: Dict[Text, Any]) -> ArchResults:\n  information = ArchResults(arch_index, arch_str)\n\n  for checkpoint_path in checkpoints:\n    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n    used_seed  = checkpoint_path.name.split('-')[-1].split('.')[0]\n    ok_dataset = 0\n    for dataset in datasets:\n      if dataset not in checkpoint:\n        print('Can not find {:} in arch-{:} from {:}'.format(dataset, arch_index, checkpoint_path))\n        continue\n      else:\n        ok_dataset += 1\n      results     = checkpoint[dataset]\n      assert results['finish-train'], 'This {:} arch seed={:} does not finish train on {:} ::: {:}'.format(arch_index, used_seed, dataset, checkpoint_path)\n      arch_config = {'channel': results['channel'], 'num_cells': results['num_cells'], 'arch_str': arch_str, 'class_num': results['config']['class_num']}\n      \n      xresult = create_result_count(used_seed, dataset, arch_config, results, dataloader_dict)\n      information.update(dataset, int(used_seed), xresult)\n    if ok_dataset == 0: raise ValueError('{:} does not find any data'.format(checkpoint_path))\n  return information\n\n\ndef correct_time_related_info(arch_index: int, arch_info_full: ArchResults, arch_info_less: ArchResults):\n  # calibrate the latency based on NAS-Bench-201-v1_0-e61699.pth\n  cifar010_latency = (api.get_latency(arch_index, 'cifar10-valid', False) + api.get_latency(arch_index, 'cifar10', False)) / 2\n  arch_info_full.reset_latency('cifar10-valid', None, cifar010_latency)\n  arch_info_full.reset_latency('cifar10', None, cifar010_latency)\n  arch_info_less.reset_latency('cifar10-valid', None, cifar010_latency)\n  arch_info_less.reset_latency('cifar10', None, cifar010_latency)\n\n  cifar100_latency = api.get_latency(arch_index, 'cifar100', False)\n  arch_info_full.reset_latency('cifar100', None, cifar100_latency)\n  arch_info_less.reset_latency('cifar100', None, cifar100_latency)\n\n  image_latency = api.get_latency(arch_index, 'ImageNet16-120', False)\n  arch_info_full.reset_latency('ImageNet16-120', None, image_latency)\n  arch_info_less.reset_latency('ImageNet16-120', None, image_latency)\n\n  train_per_epoch_time = list(arch_info_less.query('cifar10-valid', 777).train_times.values())\n  train_per_epoch_time = sum(train_per_epoch_time) / len(train_per_epoch_time)\n  eval_ori_test_time, eval_x_valid_time = [], []\n  for key, value in arch_info_less.query('cifar10-valid', 777).eval_times.items():\n    if key.startswith('ori-test@'):\n      eval_ori_test_time.append(value)\n    elif key.startswith('x-valid@'):\n      eval_x_valid_time.append(value)\n    else: raise ValueError('-- {:} --'.format(key))\n  eval_ori_test_time, eval_x_valid_time = float(np.mean(eval_ori_test_time)), float(np.mean(eval_x_valid_time))\n  nums = {'ImageNet16-120-train': 151700, 'ImageNet16-120-valid': 3000, 'ImageNet16-120-test': 6000,\n          'cifar10-valid-train': 25000, 'cifar10-valid-valid': 25000,\n          'cifar10-train': 50000, 'cifar10-test': 10000,\n          'cifar100-train': 50000, 'cifar100-test': 10000, 'cifar100-valid': 5000}\n  eval_per_sample = (eval_ori_test_time + eval_x_valid_time) / (nums['cifar10-valid-valid'] + nums['cifar10-test'])\n  for arch_info in [arch_info_less, arch_info_full]:\n    arch_info.reset_pseudo_train_times('cifar10-valid', None,\n                                       train_per_epoch_time / nums['cifar10-valid-train'] * nums['cifar10-valid-train'])\n    arch_info.reset_pseudo_train_times('cifar10', None,\n                                       train_per_epoch_time / nums['cifar10-valid-train'] * nums['cifar10-train'])\n    arch_info.reset_pseudo_train_times('cifar100', None,\n                                       train_per_epoch_time / nums['cifar10-valid-train'] * nums['cifar100-train'])\n    arch_info.reset_pseudo_train_times('ImageNet16-120', None,\n                                       train_per_epoch_time / nums['cifar10-valid-train'] * nums['ImageNet16-120-train'])\n    arch_info.reset_pseudo_eval_times('cifar10-valid', None, 'x-valid', eval_per_sample*nums['cifar10-valid-valid'])\n    arch_info.reset_pseudo_eval_times('cifar10-valid', None, 'ori-test', eval_per_sample * nums['cifar10-test'])\n    arch_info.reset_pseudo_eval_times('cifar10', None, 'ori-test', eval_per_sample * nums['cifar10-test'])\n    arch_info.reset_pseudo_eval_times('cifar100', None, 'x-valid', eval_per_sample * nums['cifar100-valid'])\n    arch_info.reset_pseudo_eval_times('cifar100', None, 'x-test', eval_per_sample * nums['cifar100-valid'])\n    arch_info.reset_pseudo_eval_times('cifar100', None, 'ori-test', eval_per_sample * nums['cifar100-test'])\n    arch_info.reset_pseudo_eval_times('ImageNet16-120', None, 'x-valid', eval_per_sample * nums['ImageNet16-120-valid'])\n    arch_info.reset_pseudo_eval_times('ImageNet16-120', None, 'x-test', eval_per_sample * nums['ImageNet16-120-valid'])\n    arch_info.reset_pseudo_eval_times('ImageNet16-120', None, 'ori-test', eval_per_sample * nums['ImageNet16-120-test'])\n  # arch_info_full.debug_test()\n  # arch_info_less.debug_test()\n  # import pdb; pdb.set_trace()\n  return arch_info_full, arch_info_less\n\n\ndef simplify(save_dir, meta_file, basestr, target_dir):\n  meta_infos     = torch.load(meta_file, map_location='cpu')\n  meta_archs     = meta_infos['archs']  # a list of architecture strings\n  meta_num_archs = meta_infos['total']\n  assert meta_num_archs == len(meta_archs), 'invalid number of archs : {:} vs {:}'.format(meta_num_archs, len(meta_archs))\n\n  sub_model_dirs = sorted(list(save_dir.glob('*-*-{:}'.format(basestr))))\n  print ('{:} find {:} directories used to save checkpoints'.format(time_string(), len(sub_model_dirs)))\n  \n  subdir2archs, num_evaluated_arch = collections.OrderedDict(), 0\n  num_seeds = defaultdict(lambda: 0)\n  for index, sub_dir in enumerate(sub_model_dirs):\n    xcheckpoints = list(sub_dir.glob('arch-*-seed-*.pth'))\n    arch_indexes = set()\n    for checkpoint in xcheckpoints:\n      temp_names = checkpoint.name.split('-')\n      assert len(temp_names) == 4 and temp_names[0] == 'arch' and temp_names[2] == 'seed', 'invalid checkpoint name : {:}'.format(checkpoint.name)\n      arch_indexes.add( temp_names[1] )\n    subdir2archs[sub_dir] = sorted(list(arch_indexes))\n    num_evaluated_arch   += len(arch_indexes)\n    # count number of seeds for each architecture\n    for arch_index in arch_indexes:\n      num_seeds[ len(list(sub_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))) ] += 1\n  print('{:} There are {:5d} architectures that have been evaluated ({:} in total).'.format(time_string(), num_evaluated_arch, meta_num_archs))\n  for key in sorted( list( num_seeds.keys() ) ): print ('{:} There are {:5d} architectures that are evaluated {:} times.'.format(time_string(), num_seeds[key], key))\n\n  dataloader_dict = get_nas_bench_loaders( 6 )\n  to_save_simply = save_dir / 'simplifies'\n  to_save_allarc = save_dir / 'simplifies' / 'architectures'\n  if not to_save_simply.exists(): to_save_simply.mkdir(parents=True, exist_ok=True)\n  if not to_save_allarc.exists(): to_save_allarc.mkdir(parents=True, exist_ok=True)\n\n  assert (save_dir / target_dir) in subdir2archs, 'can not find {:}'.format(target_dir)\n  arch2infos, datasets = {}, ('cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120')\n  evaluated_indexes    = set()\n  target_full_dir      = save_dir / target_dir\n  target_less_dir      = save_dir / '{:}-LESS'.format(target_dir)\n  arch_indexes         = subdir2archs[ target_full_dir ]\n  num_seeds            = defaultdict(lambda: 0)\n  end_time             = time.time()\n  arch_time            = AverageMeter()\n  for idx, arch_index in enumerate(arch_indexes):\n    checkpoints = list(target_full_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))\n    ckps_less   = list(target_less_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))\n    # create the arch info for each architecture\n    try:\n      arch_info_full = account_one_arch(arch_index, meta_archs[int(arch_index)], checkpoints, datasets, dataloader_dict)\n      arch_info_less = account_one_arch(arch_index, meta_archs[int(arch_index)], ckps_less, datasets, dataloader_dict)\n      num_seeds[ len(checkpoints) ] += 1\n    except:\n      print('Loading {:} failed, : {:}'.format(arch_index, checkpoints))\n      continue\n    assert int(arch_index) not in evaluated_indexes, 'conflict arch-index : {:}'.format(arch_index)\n    assert 0 <= int(arch_index) < len(meta_archs), 'invalid arch-index {:} (not found in meta_archs)'.format(arch_index)\n    arch_info = {'full': arch_info_full, 'less': arch_info_less}\n    evaluated_indexes.add(int(arch_index))\n    arch2infos[int(arch_index)] = arch_info\n    # to correct the latency and training_time info.\n    arch_info_full, arch_info_less = correct_time_related_info(int(arch_index), arch_info_full, arch_info_less)\n    to_save_data = OrderedDict(full=arch_info_full.state_dict(), less=arch_info_less.state_dict())\n    torch.save(to_save_data, to_save_allarc / '{:}-FULL.pth'.format(arch_index))\n    arch_info['full'].clear_params()\n    arch_info['less'].clear_params()\n    torch.save(to_save_data, to_save_allarc / '{:}-SIMPLE.pth'.format(arch_index))\n    # measure elapsed time\n    arch_time.update(time.time() - end_time)\n    end_time  = time.time()\n    need_time = '{:}'.format( convert_secs2time(arch_time.avg * (len(arch_indexes)-idx-1), True) )\n    print('{:} {:} [{:03d}/{:03d}] : {:} still need {:}'.format(time_string(), target_dir, idx, len(arch_indexes), arch_index, need_time))\n  # measure time\n  xstrs = ['{:}:{:03d}'.format(key, num_seeds[key]) for key in sorted( list( num_seeds.keys() ) ) ]\n  print('{:} {:} done : {:}'.format(time_string(), target_dir, xstrs))\n  final_infos = {'meta_archs' : meta_archs,\n                 'total_archs': meta_num_archs,\n                 'basestr'    : basestr,\n                 'arch2infos' : arch2infos,\n                 'evaluated_indexes': evaluated_indexes}\n  save_file_name = to_save_simply / '{:}.pth'.format(target_dir)\n  torch.save(final_infos, save_file_name)\n  print ('Save {:} / {:} architecture results into {:}.'.format(len(evaluated_indexes), meta_num_archs, save_file_name))\n\n\ndef merge_all(save_dir, meta_file, basestr):\n  meta_infos     = torch.load(meta_file, map_location='cpu')\n  meta_archs     = meta_infos['archs']\n  meta_num_archs = meta_infos['total']\n  assert meta_num_archs == len(meta_archs), 'invalid number of archs : {:} vs {:}'.format(meta_num_archs, len(meta_archs))\n\n  sub_model_dirs = sorted(list(save_dir.glob('*-*-{:}'.format(basestr))))\n  print ('{:} find {:} directories used to save checkpoints'.format(time_string(), len(sub_model_dirs)))\n  for index, sub_dir in enumerate(sub_model_dirs):\n    arch_info_files = sorted( list(sub_dir.glob('arch-*-seed-*.pth') ) )\n    print ('The {:02d}/{:02d}-th directory : {:} : {:} runs.'.format(index, len(sub_model_dirs), sub_dir, len(arch_info_files)))\n  \n  arch2infos, evaluated_indexes = dict(), set()\n  for IDX, sub_dir in enumerate(sub_model_dirs):\n    ckp_path = sub_dir.parent / 'simplifies' / '{:}.pth'.format(sub_dir.name)\n    if ckp_path.exists():\n      sub_ckps = torch.load(ckp_path, map_location='cpu')\n      assert sub_ckps['total_archs'] == meta_num_archs and sub_ckps['basestr'] == basestr\n      xarch2infos = sub_ckps['arch2infos']\n      xevalindexs = sub_ckps['evaluated_indexes']\n      for eval_index in xevalindexs:\n        assert eval_index not in evaluated_indexes and eval_index not in arch2infos\n        #arch2infos[eval_index] = xarch2infos[eval_index].state_dict()\n        arch2infos[eval_index] = {'full': xarch2infos[eval_index]['full'].state_dict(),\n                                  'less': xarch2infos[eval_index]['less'].state_dict()}\n        evaluated_indexes.add( eval_index )\n      print ('{:} [{:03d}/{:03d}] merge data from {:} with {:} models.'.format(time_string(), IDX, len(sub_model_dirs), ckp_path, len(xevalindexs)))\n    else:\n      raise ValueError('Can not find {:}'.format(ckp_path))\n      #print ('{:} [{:03d}/{:03d}] can not find {:}, skip.'.format(time_string(), IDX, len(subdir2archs), ckp_path))\n\n  evaluated_indexes = sorted( list( evaluated_indexes ) )\n  print ('Finally, there are {:} architectures that have been trained and evaluated.'.format(len(evaluated_indexes)))\n\n  to_save_simply = save_dir / 'simplifies'\n  if not to_save_simply.exists(): to_save_simply.mkdir(parents=True, exist_ok=True)\n  final_infos = {'meta_archs' : meta_archs,\n                 'total_archs': meta_num_archs,\n                 'arch2infos' : arch2infos,\n                 'evaluated_indexes': evaluated_indexes}\n  save_file_name = to_save_simply / '{:}-final-infos.pth'.format(basestr)\n  torch.save(final_infos, save_file_name)\n  print ('Save {:} / {:} architecture results into {:}.'.format(len(evaluated_indexes), meta_num_archs, save_file_name))\n\n\nif __name__ == '__main__':\n\n  parser = argparse.ArgumentParser(description='NAS-BENCH-201', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--mode'         ,  type=str, choices=['cal', 'merge'],            help='The running mode for this script.')\n  parser.add_argument('--base_save_dir',  type=str, default='./output/NAS-BENCH-201-4',  help='The base-name of folder to save checkpoints and log.')\n  parser.add_argument('--target_dir'   ,  type=str,                                      help='The target directory.')\n  parser.add_argument('--max_node'     ,  type=int, default=4,                           help='The maximum node in a cell.')\n  parser.add_argument('--channel'      ,  type=int, default=16,                          help='The number of channels.')\n  parser.add_argument('--num_cells'    ,  type=int, default=5,                           help='The number of cells in one stage.')\n  args = parser.parse_args()\n  \n  save_dir  = Path(args.base_save_dir)\n  meta_path = save_dir / 'meta-node-{:}.pth'.format(args.max_node)\n  assert save_dir.exists(),  'invalid save dir path : {:}'.format(save_dir)\n  assert meta_path.exists(), 'invalid saved meta path : {:}'.format(meta_path)\n  print ('start the statistics of our nas-benchmark from {:} using {:}.'.format(save_dir, args.target_dir))\n  basestr   = 'C{:}-N{:}'.format(args.channel, args.num_cells)\n  \n  if args.mode == 'cal':\n    simplify(save_dir, meta_path, basestr, args.target_dir)\n  elif args.mode == 'merge':\n    merge_all(save_dir, meta_path, basestr)\n  else:\n    raise ValueError('invalid mode : {:}'.format(args.mode))\n"""
exps/NAS-Bench-201/statistics.py,19,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\nimport os, sys, time, argparse, collections\nfrom copy import deepcopy\nimport torch\nfrom pathlib import Path\nfrom collections import defaultdict\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom config_utils import load_config, dict2config\nfrom datasets     import get_datasets\n# NAS-Bench-201 related module or function\nfrom models       import CellStructure, get_cell_based_tiny_net\nfrom nas_201_api  import ArchResults, ResultsCount\nfrom procedures   import bench_pure_evaluate as pure_evaluate\n\n\ndef create_result_count(used_seed, dataset, arch_config, results, dataloader_dict):\n  xresult     = ResultsCount(dataset, results['net_state_dict'], results['train_acc1es'], results['train_losses'], \\\n                               results['param'], results['flop'], arch_config, used_seed, results['total_epoch'], None)\n\n  net_config = dict2config({'name': 'infer.tiny', 'C': arch_config['channel'], 'N': arch_config['num_cells'], 'genotype': CellStructure.str2structure(arch_config['arch_str']), 'num_classes':arch_config['class_num']}, None)\n  network = get_cell_based_tiny_net(net_config)\n  network.load_state_dict(xresult.get_net_param())\n  if 'train_times' in results: # new version\n    xresult.update_train_info(results['train_acc1es'], results['train_acc5es'], results['train_losses'], results['train_times'])\n    xresult.update_eval(results['valid_acc1es'], results['valid_losses'], results['valid_times'])\n  else:\n    if dataset == 'cifar10-valid':\n      xresult.update_OLD_eval('x-valid' , results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format('cifar10', 'test')], network.cuda())\n      xresult.update_OLD_eval('ori-test', {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      xresult.update_latency(latencies)\n    elif dataset == 'cifar10':\n      xresult.update_OLD_eval('ori-test', results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset, 'test')], network.cuda())\n      xresult.update_latency(latencies)\n    elif dataset == 'cifar100' or dataset == 'ImageNet16-120':\n      xresult.update_OLD_eval('ori-test', results['valid_acc1es'], results['valid_losses'])\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset, 'valid')], network.cuda())\n      xresult.update_OLD_eval('x-valid', {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      loss, top1, top5, latencies = pure_evaluate(dataloader_dict['{:}@{:}'.format(dataset,  'test')], network.cuda())\n      xresult.update_OLD_eval('x-test' , {results['total_epoch']-1: top1}, {results['total_epoch']-1: loss})\n      xresult.update_latency(latencies)\n    else:\n      raise ValueError('invalid dataset name : {:}'.format(dataset))\n  return xresult\n  \n\n\ndef account_one_arch(arch_index, arch_str, checkpoints, datasets, dataloader_dict):\n  information = ArchResults(arch_index, arch_str)\n\n  for checkpoint_path in checkpoints:\n    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n    used_seed  = checkpoint_path.name.split('-')[-1].split('.')[0]\n    for dataset in datasets:\n      assert dataset in checkpoint, 'Can not find {:} in arch-{:} from {:}'.format(dataset, arch_index, checkpoint_path)\n      results     = checkpoint[dataset]\n      assert results['finish-train'], 'This {:} arch seed={:} does not finish train on {:} ::: {:}'.format(arch_index, used_seed, dataset, checkpoint_path)\n      arch_config = {'channel': results['channel'], 'num_cells': results['num_cells'], 'arch_str': arch_str, 'class_num': results['config']['class_num']}\n      \n      xresult = create_result_count(used_seed, dataset, arch_config, results, dataloader_dict)\n      information.update(dataset, int(used_seed), xresult)\n  return information\n\n\ndef GET_DataLoaders(workers):\n\n  torch.set_num_threads(workers)\n\n  root_dir  = (Path(__file__).parent / '..' / '..').resolve()\n  torch_dir = Path(os.environ['TORCH_HOME'])\n  # cifar\n  cifar_config_path = root_dir / 'configs' / 'nas-benchmark' / 'CIFAR.config'\n  cifar_config = load_config(cifar_config_path, None, None)\n  print ('{:} Create data-loader for all datasets'.format(time_string()))\n  print ('-'*200)\n  TRAIN_CIFAR10, VALID_CIFAR10, xshape, class_num = get_datasets('cifar10', str(torch_dir/'cifar.python'), -1)\n  print ('original CIFAR-10 : {:} training images and {:} test images : {:} input shape : {:} number of classes'.format(len(TRAIN_CIFAR10), len(VALID_CIFAR10), xshape, class_num))\n  cifar10_splits = load_config(root_dir / 'configs' / 'nas-benchmark' / 'cifar-split.txt', None, None)\n  assert cifar10_splits.train[:10] == [0, 5, 7, 11, 13, 15, 16, 17, 20, 24] and cifar10_splits.valid[:10] == [1, 2, 3, 4, 6, 8, 9, 10, 12, 14]\n  temp_dataset = deepcopy(TRAIN_CIFAR10)\n  temp_dataset.transform = VALID_CIFAR10.transform\n  # data loader\n  trainval_cifar10_loader = torch.utils.data.DataLoader(TRAIN_CIFAR10, batch_size=cifar_config.batch_size, shuffle=True , num_workers=workers, pin_memory=True)\n  train_cifar10_loader    = torch.utils.data.DataLoader(TRAIN_CIFAR10, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar10_splits.train), num_workers=workers, pin_memory=True)\n  valid_cifar10_loader    = torch.utils.data.DataLoader(temp_dataset , batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar10_splits.valid), num_workers=workers, pin_memory=True)\n  test__cifar10_loader    = torch.utils.data.DataLoader(VALID_CIFAR10, batch_size=cifar_config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n  print ('CIFAR-10  : trval-loader has {:3d} batch with {:} per batch'.format(len(trainval_cifar10_loader), cifar_config.batch_size))\n  print ('CIFAR-10  : train-loader has {:3d} batch with {:} per batch'.format(len(train_cifar10_loader), cifar_config.batch_size))\n  print ('CIFAR-10  : valid-loader has {:3d} batch with {:} per batch'.format(len(valid_cifar10_loader), cifar_config.batch_size))\n  print ('CIFAR-10  : test--loader has {:3d} batch with {:} per batch'.format(len(test__cifar10_loader), cifar_config.batch_size))\n  print ('-'*200)\n  # CIFAR-100\n  TRAIN_CIFAR100, VALID_CIFAR100, xshape, class_num = get_datasets('cifar100', str(torch_dir/'cifar.python'), -1)\n  print ('original CIFAR-100: {:} training images and {:} test images : {:} input shape : {:} number of classes'.format(len(TRAIN_CIFAR100), len(VALID_CIFAR100), xshape, class_num))\n  cifar100_splits = load_config(root_dir / 'configs' / 'nas-benchmark' / 'cifar100-test-split.txt', None, None)\n  assert cifar100_splits.xvalid[:10] == [1, 3, 4, 5, 8, 10, 13, 14, 15, 16] and cifar100_splits.xtest[:10] == [0, 2, 6, 7, 9, 11, 12, 17, 20, 24]\n  train_cifar100_loader = torch.utils.data.DataLoader(TRAIN_CIFAR100, batch_size=cifar_config.batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n  valid_cifar100_loader = torch.utils.data.DataLoader(VALID_CIFAR100, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xvalid), num_workers=workers, pin_memory=True)\n  test__cifar100_loader = torch.utils.data.DataLoader(VALID_CIFAR100, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xtest) , num_workers=workers, pin_memory=True)\n  print ('CIFAR-100  : train-loader has {:3d} batch'.format(len(train_cifar100_loader)))\n  print ('CIFAR-100  : valid-loader has {:3d} batch'.format(len(valid_cifar100_loader)))\n  print ('CIFAR-100  : test--loader has {:3d} batch'.format(len(test__cifar100_loader)))\n  print ('-'*200)\n\n  imagenet16_config_path = 'configs/nas-benchmark/ImageNet-16.config'\n  imagenet16_config = load_config(imagenet16_config_path, None, None)\n  TRAIN_ImageNet16_120, VALID_ImageNet16_120, xshape, class_num = get_datasets('ImageNet16-120', str(torch_dir/'cifar.python'/'ImageNet16'), -1)\n  print ('original TRAIN_ImageNet16_120: {:} training images and {:} test images : {:} input shape : {:} number of classes'.format(len(TRAIN_ImageNet16_120), len(VALID_ImageNet16_120), xshape, class_num))\n  imagenet_splits = load_config(root_dir / 'configs' / 'nas-benchmark' / 'imagenet-16-120-test-split.txt', None, None)\n  assert imagenet_splits.xvalid[:10] == [1, 2, 3, 6, 7, 8, 9, 12, 16, 18] and imagenet_splits.xtest[:10] == [0, 4, 5, 10, 11, 13, 14, 15, 17, 20]\n  train_imagenet_loader = torch.utils.data.DataLoader(TRAIN_ImageNet16_120, batch_size=imagenet16_config.batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n  valid_imagenet_loader = torch.utils.data.DataLoader(VALID_ImageNet16_120, batch_size=imagenet16_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet_splits.xvalid), num_workers=workers, pin_memory=True)\n  test__imagenet_loader = torch.utils.data.DataLoader(VALID_ImageNet16_120, batch_size=imagenet16_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet_splits.xtest) , num_workers=workers, pin_memory=True)\n  print ('ImageNet-16-120  : train-loader has {:3d} batch with {:} per batch'.format(len(train_imagenet_loader), imagenet16_config.batch_size))\n  print ('ImageNet-16-120  : valid-loader has {:3d} batch with {:} per batch'.format(len(valid_imagenet_loader), imagenet16_config.batch_size))\n  print ('ImageNet-16-120  : test--loader has {:3d} batch with {:} per batch'.format(len(test__imagenet_loader), imagenet16_config.batch_size))\n\n  # 'cifar10', 'cifar100', 'ImageNet16-120'\n  loaders = {'cifar10@trainval': trainval_cifar10_loader,\n             'cifar10@train'   : train_cifar10_loader,\n             'cifar10@valid'   : valid_cifar10_loader,\n             'cifar10@test'    : test__cifar10_loader,\n             'cifar100@train'  : train_cifar100_loader,\n             'cifar100@valid'  : valid_cifar100_loader,\n             'cifar100@test'   : test__cifar100_loader,\n             'ImageNet16-120@train': train_imagenet_loader,\n             'ImageNet16-120@valid': valid_imagenet_loader,\n             'ImageNet16-120@test' : test__imagenet_loader}\n  return loaders\n\n\ndef simplify(save_dir, meta_file, basestr, target_dir):\n  meta_infos     = torch.load(meta_file, map_location='cpu')\n  meta_archs     = meta_infos['archs'] # a list of architecture strings\n  meta_num_archs = meta_infos['total']\n  meta_max_node  = meta_infos['max_node']\n  assert meta_num_archs == len(meta_archs), 'invalid number of archs : {:} vs {:}'.format(meta_num_archs, len(meta_archs))\n\n  sub_model_dirs = sorted(list(save_dir.glob('*-*-{:}'.format(basestr))))\n  print ('{:} find {:} directories used to save checkpoints'.format(time_string(), len(sub_model_dirs)))\n  \n  subdir2archs, num_evaluated_arch = collections.OrderedDict(), 0\n  num_seeds = defaultdict(lambda: 0)\n  for index, sub_dir in enumerate(sub_model_dirs):\n    xcheckpoints = list(sub_dir.glob('arch-*-seed-*.pth'))\n    arch_indexes = set()\n    for checkpoint in xcheckpoints:\n      temp_names = checkpoint.name.split('-')\n      assert len(temp_names) == 4 and temp_names[0] == 'arch' and temp_names[2] == 'seed', 'invalid checkpoint name : {:}'.format(checkpoint.name)\n      arch_indexes.add( temp_names[1] )\n    subdir2archs[sub_dir] = sorted(list(arch_indexes))\n    num_evaluated_arch   += len(arch_indexes)\n    # count number of seeds for each architecture\n    for arch_index in arch_indexes:\n      num_seeds[ len(list(sub_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))) ] += 1\n  print('{:} There are {:5d} architectures that have been evaluated ({:} in total).'.format(time_string(), num_evaluated_arch, meta_num_archs))\n  for key in sorted( list( num_seeds.keys() ) ): print ('{:} There are {:5d} architectures that are evaluated {:} times.'.format(time_string(), num_seeds[key], key))\n\n  dataloader_dict = GET_DataLoaders( 6 )\n\n  to_save_simply = save_dir / 'simplifies'\n  to_save_allarc = save_dir / 'simplifies' / 'architectures'\n  if not to_save_simply.exists(): to_save_simply.mkdir(parents=True, exist_ok=True)\n  if not to_save_allarc.exists(): to_save_allarc.mkdir(parents=True, exist_ok=True)\n\n  assert (save_dir / target_dir) in subdir2archs, 'can not find {:}'.format(target_dir)\n  arch2infos, datasets = {}, ('cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120')\n  evaluated_indexes    = set()\n  target_directory     = save_dir / target_dir\n  target_less_dir      = save_dir / '{:}-LESS'.format(target_dir)\n  arch_indexes         = subdir2archs[ target_directory ]\n  num_seeds            = defaultdict(lambda: 0)\n  end_time             = time.time()\n  arch_time            = AverageMeter()\n  for idx, arch_index in enumerate(arch_indexes):\n    checkpoints = list(target_directory.glob('arch-{:}-seed-*.pth'.format(arch_index)))\n    ckps_less   = list(target_less_dir.glob('arch-{:}-seed-*.pth'.format(arch_index)))\n    # create the arch info for each architecture\n    try:\n      arch_info_full = account_one_arch(arch_index, meta_archs[int(arch_index)], checkpoints, datasets, dataloader_dict)\n      arch_info_less = account_one_arch(arch_index, meta_archs[int(arch_index)], ckps_less, ['cifar10-valid'], dataloader_dict)\n      num_seeds[ len(checkpoints) ] += 1\n    except:\n      print('Loading {:} failed, : {:}'.format(arch_index, checkpoints))\n      continue\n    assert int(arch_index) not in evaluated_indexes, 'conflict arch-index : {:}'.format(arch_index)\n    assert 0 <= int(arch_index) < len(meta_archs), 'invalid arch-index {:} (not found in meta_archs)'.format(arch_index)\n    arch_info = {'full': arch_info_full, 'less': arch_info_less}\n    evaluated_indexes.add( int(arch_index) )\n    arch2infos[int(arch_index)] = arch_info\n    torch.save({'full': arch_info_full.state_dict(),\n                'less': arch_info_less.state_dict()}, to_save_allarc / '{:}-FULL.pth'.format(arch_index))\n    arch_info['full'].clear_params()\n    arch_info['less'].clear_params()\n    torch.save({'full': arch_info_full.state_dict(),\n                'less': arch_info_less.state_dict()}, to_save_allarc / '{:}-SIMPLE.pth'.format(arch_index))\n    # measure elapsed time\n    arch_time.update(time.time() - end_time)\n    end_time  = time.time()\n    need_time = '{:}'.format( convert_secs2time(arch_time.avg * (len(arch_indexes)-idx-1), True) )\n    print('{:} {:} [{:03d}/{:03d}] : {:} still need {:}'.format(time_string(), target_dir, idx, len(arch_indexes), arch_index, need_time))\n  # measure time\n  xstrs = ['{:}:{:03d}'.format(key, num_seeds[key]) for key in sorted( list( num_seeds.keys() ) ) ]\n  print('{:} {:} done : {:}'.format(time_string(), target_dir, xstrs))\n  final_infos = {'meta_archs' : meta_archs,\n                 'total_archs': meta_num_archs,\n                 'basestr'    : basestr,\n                 'arch2infos' : arch2infos,\n                 'evaluated_indexes': evaluated_indexes}\n  save_file_name = to_save_simply / '{:}.pth'.format(target_dir)\n  torch.save(final_infos, save_file_name)\n  print ('Save {:} / {:} architecture results into {:}.'.format(len(evaluated_indexes), meta_num_archs, save_file_name))\n\n\ndef merge_all(save_dir, meta_file, basestr):\n  meta_infos     = torch.load(meta_file, map_location='cpu')\n  meta_archs     = meta_infos['archs']\n  meta_num_archs = meta_infos['total']\n  meta_max_node  = meta_infos['max_node']\n  assert meta_num_archs == len(meta_archs), 'invalid number of archs : {:} vs {:}'.format(meta_num_archs, len(meta_archs))\n\n  sub_model_dirs = sorted(list(save_dir.glob('*-*-{:}'.format(basestr))))\n  print ('{:} find {:} directories used to save checkpoints'.format(time_string(), len(sub_model_dirs)))\n  for index, sub_dir in enumerate(sub_model_dirs):\n    arch_info_files = sorted( list(sub_dir.glob('arch-*-seed-*.pth') ) )\n    print ('The {:02d}/{:02d}-th directory : {:} : {:} runs.'.format(index, len(sub_model_dirs), sub_dir, len(arch_info_files)))\n  \n  arch2infos, evaluated_indexes = dict(), set()\n  for IDX, sub_dir in enumerate(sub_model_dirs):\n    ckp_path = sub_dir.parent / 'simplifies' / '{:}.pth'.format(sub_dir.name)\n    if ckp_path.exists():\n      sub_ckps = torch.load(ckp_path, map_location='cpu')\n      assert sub_ckps['total_archs'] == meta_num_archs and sub_ckps['basestr'] == basestr\n      xarch2infos = sub_ckps['arch2infos']\n      xevalindexs = sub_ckps['evaluated_indexes']\n      for eval_index in xevalindexs:\n        assert eval_index not in evaluated_indexes and eval_index not in arch2infos\n        #arch2infos[eval_index] = xarch2infos[eval_index].state_dict()\n        arch2infos[eval_index] = {'full': xarch2infos[eval_index]['full'].state_dict(),\n                                  'less': xarch2infos[eval_index]['less'].state_dict()}\n        evaluated_indexes.add( eval_index )\n      print ('{:} [{:03d}/{:03d}] merge data from {:} with {:} models.'.format(time_string(), IDX, len(sub_model_dirs), ckp_path, len(xevalindexs)))\n    else:\n      raise ValueError('Can not find {:}'.format(ckp_path))\n      #print ('{:} [{:03d}/{:03d}] can not find {:}, skip.'.format(time_string(), IDX, len(subdir2archs), ckp_path))\n\n  evaluated_indexes = sorted( list( evaluated_indexes ) )\n  print ('Finally, there are {:} architectures that have been trained and evaluated.'.format(len(evaluated_indexes)))\n\n  to_save_simply = save_dir / 'simplifies'\n  if not to_save_simply.exists(): to_save_simply.mkdir(parents=True, exist_ok=True)\n  final_infos = {'meta_archs' : meta_archs,\n                 'total_archs': meta_num_archs,\n                 'arch2infos' : arch2infos,\n                 'evaluated_indexes': evaluated_indexes}\n  save_file_name = to_save_simply / '{:}-final-infos.pth'.format(basestr)\n  torch.save(final_infos, save_file_name)\n  print ('Save {:} / {:} architecture results into {:}.'.format(len(evaluated_indexes), meta_num_archs, save_file_name))\n\n\nif __name__ == '__main__':\n\n  parser = argparse.ArgumentParser(description='NAS-BENCH-201', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--mode'         ,  type=str, choices=['cal', 'merge'],            help='The running mode for this script.')\n  parser.add_argument('--base_save_dir',  type=str, default='./output/NAS-BENCH-201-4',  help='The base-name of folder to save checkpoints and log.')\n  parser.add_argument('--target_dir'   ,  type=str,                                      help='The target directory.')\n  parser.add_argument('--max_node'     ,  type=int, default=4,                           help='The maximum node in a cell.')\n  parser.add_argument('--channel'      ,  type=int, default=16,                          help='The number of channels.')\n  parser.add_argument('--num_cells'    ,  type=int, default=5,                           help='The number of cells in one stage.')\n  args = parser.parse_args()\n  \n  save_dir  = Path(args.base_save_dir)\n  meta_path = save_dir / 'meta-node-{:}.pth'.format(args.max_node)\n  assert save_dir.exists(),  'invalid save dir path : {:}'.format(save_dir)\n  assert meta_path.exists(), 'invalid saved meta path : {:}'.format(meta_path)\n  print ('start the statistics of our nas-benchmark from {:} using {:}.'.format(save_dir, args.target_dir))\n  basestr   = 'C{:}-N{:}'.format(args.channel, args.num_cells)\n  \n  if args.mode == 'cal':\n    simplify(save_dir, meta_path, basestr, args.target_dir)\n  elif args.mode == 'merge':\n    merge_all(save_dir, meta_path, basestr)\n  else:\n    raise ValueError('invalid mode : {:}'.format(args.mode))"""
exps/NAS-Bench-201/test-correlation.py,1,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n########################################################\n# python exps/NAS-Bench-201/test-correlation.py --api_path $HOME/.torch/NAS-Bench-201-v1_0-e61699.pth\n########################################################\nimport sys, argparse\nimport numpy as np\nfrom copy import deepcopy\nfrom tqdm import tqdm\nimport torch\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom log_utils    import time_string\nfrom models       import CellStructure\nfrom nas_201_api  import NASBench201API as API\n\n\ndef check_unique_arch(meta_file):\n  api = API(str(meta_file))\n  arch_strs = deepcopy(api.meta_archs)\n  xarchs = [CellStructure.str2structure(x) for x in arch_strs]\n  def get_unique_matrix(archs, consider_zero):\n    UniquStrs = [arch.to_unique_str(consider_zero) for arch in archs]\n    print (\'{:} create unique-string ({:}/{:}) done\'.format(time_string(), len(set(UniquStrs)), len(UniquStrs)))\n    Unique2Index = dict()\n    for index, xstr in enumerate(UniquStrs):\n      if xstr not in Unique2Index: Unique2Index[xstr] = list()\n      Unique2Index[xstr].append( index )\n    sm_matrix = torch.eye(len(archs)).bool()\n    for _, xlist in Unique2Index.items():\n      for i in xlist:\n        for j in xlist:\n          sm_matrix[i,j] = True\n    unique_ids, unique_num = [-1 for _ in archs], 0\n    for i in range(len(unique_ids)):\n      if unique_ids[i] > -1: continue\n      neighbours = sm_matrix[i].nonzero().view(-1).tolist()\n      for nghb in neighbours:\n        assert unique_ids[nghb] == -1, \'impossible\'\n        unique_ids[nghb] = unique_num\n      unique_num += 1\n    return sm_matrix, unique_ids, unique_num\n\n  print (\'There are {:} valid-archs\'.format( sum(arch.check_valid() for arch in xarchs) ))\n  sm_matrix, uniqueIDs, unique_num = get_unique_matrix(xarchs, None)\n  print (\'{:} There are {:} unique architectures (considering nothing).\'.format(time_string(), unique_num))\n  sm_matrix, uniqueIDs, unique_num = get_unique_matrix(xarchs, False)\n  print (\'{:} There are {:} unique architectures (not considering zero).\'.format(time_string(), unique_num))\n  sm_matrix, uniqueIDs, unique_num = get_unique_matrix(xarchs,  True)\n  print (\'{:} There are {:} unique architectures (considering zero).\'.format(time_string(), unique_num))\n\n\ndef check_cor_for_bandit(meta_file, test_epoch, use_less_or_not, is_rand=True, need_print=False):\n  if isinstance(meta_file, API):\n    api = meta_file\n  else:\n    api = API(str(meta_file))\n  cifar10_currs     = []\n  cifar10_valid     = []\n  cifar10_test      = []\n  cifar100_valid    = []\n  cifar100_test     = []\n  imagenet_test     = []\n  imagenet_valid    = []\n  for idx, arch in enumerate(api):\n    results = api.get_more_info(idx, \'cifar10-valid\' , test_epoch-1, use_less_or_not, is_rand)\n    cifar10_currs.append( results[\'valid-accuracy\'] )\n    # --->>>>>\n    results = api.get_more_info(idx, \'cifar10-valid\' , None, False, is_rand)\n    cifar10_valid.append( results[\'valid-accuracy\'] )\n    results = api.get_more_info(idx, \'cifar10\'       , None, False, is_rand)\n    cifar10_test.append( results[\'test-accuracy\'] )\n    results = api.get_more_info(idx, \'cifar100\'      , None, False, is_rand)\n    cifar100_test.append( results[\'test-accuracy\'] )\n    cifar100_valid.append( results[\'valid-accuracy\'] )\n    results = api.get_more_info(idx, \'ImageNet16-120\', None, False, is_rand)\n    imagenet_test.append( results[\'test-accuracy\'] )\n    imagenet_valid.append( results[\'valid-accuracy\'] )\n  def get_cor(A, B):\n    return float(np.corrcoef(A, B)[0,1])\n  cors = []\n  for basestr, xlist in zip([\'C-010-V\', \'C-010-T\', \'C-100-V\', \'C-100-T\', \'I16-V\', \'I16-T\'], [cifar10_valid, cifar10_test, cifar100_valid, cifar100_test, imagenet_valid, imagenet_test]):\n    correlation = get_cor(cifar10_currs, xlist)\n    if need_print: print (\'With {:3d}/{:}-epochs-training, the correlation between cifar10-valid and {:} is : {:}\'.format(test_epoch, \'012\' if use_less_or_not else \'200\', basestr, correlation))\n    cors.append( correlation )\n    #print (\'With {:3d}/200-epochs-training, the correlation between cifar10-valid and {:} is : {:}\'.format(test_epoch, basestr, get_cor(cifar10_valid_200, xlist)))\n    #print(\'-\'*200)\n  #print(\'*\'*230)\n  return cors\n\n\ndef check_cor_for_bandit_v2(meta_file, test_epoch, use_less_or_not, is_rand):\n  corrs = []\n  for i in tqdm(range(100)):\n    x = check_cor_for_bandit(meta_file, test_epoch, use_less_or_not, is_rand, False)\n    corrs.append( x )\n  #xstrs = [\'CIFAR-010\', \'C-100-V\', \'C-100-T\', \'I16-V\', \'I16-T\']\n  xstrs = [\'C-010-V\', \'C-010-T\', \'C-100-V\', \'C-100-T\', \'I16-V\', \'I16-T\']\n  correlations = np.array(corrs)\n  print(\'------>>>>>>>> {:03d}/{:} >>>>>>>> ------\'.format(test_epoch, \'012\' if use_less_or_not else \'200\'))\n  for idx, xstr in enumerate(xstrs):\n    print (\'{:8s} ::: mean={:.4f}, std={:.4f} :: {:.4f}\\\\pm{:.4f}\'.format(xstr, correlations[:,idx].mean(), correlations[:,idx].std(), correlations[:,idx].mean(), correlations[:,idx].std()))\n  print(\'\')\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Analysis of NAS-Bench-201"")\n  parser.add_argument(\'--save_dir\',  type=str, default=\'./output/search-cell-nas-bench-201/visuals\', help=\'The base-name of folder to save checkpoints and log.\')\n  parser.add_argument(\'--api_path\',  type=str, default=None,                                         help=\'The path to the NAS-Bench-201 benchmark file.\')\n  args = parser.parse_args()\n\n  vis_save_dir = Path(args.save_dir)\n  vis_save_dir.mkdir(parents=True, exist_ok=True)\n  meta_file = Path(args.api_path)\n  assert meta_file.exists(), \'invalid path for api : {:}\'.format(meta_file)\n\n  #check_unique_arch(meta_file)\n  api = API(str(meta_file))\n  #for iepoch in [11, 25, 50, 100, 150, 175, 200]:\n  #  check_cor_for_bandit(api,  6, iepoch)\n  #  check_cor_for_bandit(api, 12, iepoch)\n  check_cor_for_bandit_v2(api,   6,  True, True)\n  check_cor_for_bandit_v2(api,  12,  True, True)\n  check_cor_for_bandit_v2(api,  12, False, True)\n  check_cor_for_bandit_v2(api,  24, False, True)\n  check_cor_for_bandit_v2(api, 100, False, True)\n  check_cor_for_bandit_v2(api, 150, False, True)\n  check_cor_for_bandit_v2(api, 175, False, True)\n  check_cor_for_bandit_v2(api, 200, False, True)\n  print(\'----\')\n'"
exps/NAS-Bench-201/test-weights.py,1,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n###############################################################################################\n# Before run these commands, the files must be properly put.\n# python exps/NAS-Bench-201/test-weights.py --base_path $HOME/.torch/NAS-Bench-201-v1_0-e61699\n# python exps/NAS-Bench-201/test-weights.py --base_path $HOME/.torch/NAS-Bench-201-v1_1-096897 --dataset cifar10-valid --use_12 1 --use_valid 1\n# bash ./scripts-search/NAS-Bench-201/test-weights.sh cifar10-valid 1\n###############################################################################################\nimport os, gc, sys, math, argparse, psutil\nimport numpy as np\nimport torch\nfrom pathlib import Path\nfrom collections import OrderedDict\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom nas_201_api import NASBench201API as API\nfrom log_utils import time_string\nfrom models import get_cell_based_tiny_net\nfrom utils import weight_watcher\n\n\ndef get_cor(A, B):\n  return float(np.corrcoef(A, B)[0,1])\n\n\ndef tostr(accdict, norms):\n  xstr = []\n  for key, accs in accdict.items():\n    cor = get_cor(accs, norms)\n    xstr.append(\'{:}: {:.3f}\'.format(key, cor))\n  return \' \'.join(xstr)\n\n\ndef evaluate(api, weight_dir, data: str, use_12epochs_result: bool):\n  print(\'\\nEvaluate dataset={:}\'.format(data))\n  norms, process = [], psutil.Process(os.getpid())\n  final_val_accs = OrderedDict({\'cifar10\': [], \'cifar100\': [], \'ImageNet16-120\': []})\n  final_test_accs = OrderedDict({\'cifar10\': [], \'cifar100\': [], \'ImageNet16-120\': []})\n  for idx in range(len(api)):\n    # info = api.get_more_info(idx, data, use_12epochs_result=use_12epochs_result, is_random=False)\n    # import pdb; pdb.set_trace()\n    for key in [\'cifar10-valid\', \'cifar10\', \'cifar100\', \'ImageNet16-120\']:\n      info = api.get_more_info(idx, key, use_12epochs_result=False, is_random=False)\n      if key == \'cifar10-valid\':\n        final_val_accs[\'cifar10\'].append(info[\'valid-accuracy\'])\n      elif key == \'cifar10\':\n        final_test_accs[\'cifar10\'].append(info[\'test-accuracy\'])\n      else:\n        final_test_accs[key].append(info[\'test-accuracy\'])\n        final_val_accs[key].append(info[\'valid-accuracy\'])\n    config = api.get_net_config(idx, data)\n    net = get_cell_based_tiny_net(config)\n    api.reload(weight_dir, idx)\n    params = api.get_net_param(idx, data, None, use_12epochs_result=use_12epochs_result)\n    cur_norms = []\n    for seed, param in params.items():\n      with torch.no_grad():\n        net.load_state_dict(param)\n        _, summary = weight_watcher.analyze(net, alphas=False)\n        cur_norms.append(-summary[\'lognorm\'])\n    cur_norm = float(np.mean(cur_norms))\n    if math.isnan(cur_norm):\n      print (\'  IGNORE {:} due to nan.\'.format(idx))\n      continue\n    norms.append(cur_norm)\n    api.clear_params(idx, None)\n    if idx % 200 == 199 or idx + 1 == len(api):\n      head = \'{:05d}/{:05d}\'.format(idx, len(api))\n      stem_val = tostr(final_val_accs, norms)\n      stem_test = tostr(final_test_accs, norms)\n      print(\'{:} {:} {:} with {:} epochs ({:.2f} MB memory)\'.format(time_string(), head, data, 12 if use_12epochs_result else 200, process.memory_info().rss / 1e6))\n      print(\'  [Valid] -->>  {:}\'.format(stem_val))\n      print(\'  [Test.] -->>  {:}\'.format(stem_test))\n      gc.collect()\n\n\ndef main(meta_file: str, weight_dir, save_dir, xdata, use_12epochs_result):\n  api = API(meta_file)\n  datasets = [\'cifar10-valid\', \'cifar10\', \'cifar100\', \'ImageNet16-120\']\n  print(time_string() + \' \' + \'=\'*50)\n  for data in datasets:\n    nums = api.statistics(data, True)\n    total = sum([k*v for k, v in nums.items()])\n    print(\'Using 012 epochs, trained on {:20s} : {:} trials in total ({:}).\'.format(data, total, nums))\n  print(time_string() + \' \' + \'=\'*50)\n  for data in datasets:\n    nums = api.statistics(data, False)\n    total = sum([k*v for k, v in nums.items()])\n    print(\'Using 200 epochs, trained on {:20s} : {:} trials in total ({:}).\'.format(data, total, nums))\n  print(time_string() + \' \' + \'=\'*50)\n\n  #evaluate(api, weight_dir, \'cifar10-valid\', False, True)\n  evaluate(api, weight_dir, xdata, use_12epochs_result)\n  \n  print(\'{:} finish this test.\'.format(time_string()))\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Analysis of NAS-Bench-201"")\n  parser.add_argument(\'--save_dir\',   type=str, default=\'./output/search-cell-nas-bench-201/visuals\', help=\'The base-name of folder to save checkpoints and log.\')\n  parser.add_argument(\'--base_path\',  type=str, default=None, help=\'The path to the NAS-Bench-201 benchmark file and weight dir.\')\n  parser.add_argument(\'--dataset\'  ,  type=str, default=None, help=\'.\')\n  parser.add_argument(\'--use_12\'   ,  type=int, default=None, help=\'.\')\n  args = parser.parse_args()\n\n  save_dir = Path(args.save_dir)\n  save_dir.mkdir(parents=True, exist_ok=True)\n  meta_file = Path(args.base_path + \'.pth\')\n  weight_dir = Path(args.base_path + \'-archive\')\n  assert meta_file.exists(), \'invalid path for api : {:}\'.format(meta_file)\n  assert weight_dir.exists() and weight_dir.is_dir(), \'invalid path for weight dir : {:}\'.format(weight_dir)\n\n  main(str(meta_file), weight_dir, save_dir, args.dataset, bool(args.use_12))\n\n'"
exps/NAS-Bench-201/visualize.py,14,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\n# python exps/NAS-Bench-201/visualize.py --api_path $HOME/.torch/NAS-Bench-201-v1_0-e61699.pth\n#####################################################\nimport sys, argparse\nfrom tqdm import tqdm\nfrom collections import OrderedDict\nimport numpy as np\nimport torch\nfrom pathlib import Path\nfrom collections import defaultdict\nimport matplotlib\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom log_utils    import time_string\nfrom nas_201_api  import NASBench201API as API\n\n\n\ndef calculate_correlation(*vectors):\n  matrix = []\n  for i, vectori in enumerate(vectors):\n    x = []\n    for j, vectorj in enumerate(vectors):\n      x.append( np.corrcoef(vectori, vectorj)[0,1] )\n    matrix.append( x )\n  return np.array(matrix)\n\n\n\ndef visualize_relative_ranking(vis_save_dir):\n  print (\'\\n\' + \'-\'*100)\n  cifar010_cache_path = vis_save_dir / \'{:}-cache-info.pth\'.format(\'cifar10\')\n  cifar100_cache_path = vis_save_dir / \'{:}-cache-info.pth\'.format(\'cifar100\')\n  imagenet_cache_path = vis_save_dir / \'{:}-cache-info.pth\'.format(\'ImageNet16-120\')\n  cifar010_info = torch.load(cifar010_cache_path)\n  cifar100_info = torch.load(cifar100_cache_path)\n  imagenet_info = torch.load(imagenet_cache_path)\n  indexes       = list(range(len(cifar010_info[\'params\'])))\n\n  print (\'{:} start to visualize relative ranking\'.format(time_string()))\n  # maximum accuracy with ResNet-level params 11472\n  x_010_accs    = [ cifar010_info[\'test_accs\'][i] if cifar010_info[\'params\'][i] <= cifar010_info[\'params\'][11472] else -1 for i in indexes]\n  x_100_accs    = [ cifar100_info[\'test_accs\'][i] if cifar100_info[\'params\'][i] <= cifar100_info[\'params\'][11472] else -1 for i in indexes]\n  x_img_accs    = [ imagenet_info[\'test_accs\'][i] if imagenet_info[\'params\'][i] <= imagenet_info[\'params\'][11472] else -1 for i in indexes]\n \n  cifar010_ord_indexes = sorted(indexes, key=lambda i: cifar010_info[\'test_accs\'][i])\n  cifar100_ord_indexes = sorted(indexes, key=lambda i: cifar100_info[\'test_accs\'][i])\n  imagenet_ord_indexes = sorted(indexes, key=lambda i: imagenet_info[\'test_accs\'][i])\n\n  cifar100_labels, imagenet_labels = [], []\n  for idx in cifar010_ord_indexes:\n    cifar100_labels.append( cifar100_ord_indexes.index(idx) )\n    imagenet_labels.append( imagenet_ord_indexes.index(idx) )\n  print (\'{:} prepare data done.\'.format(time_string()))\n\n  dpi, width, height = 300, 2600, 2600\n  figsize = width / float(dpi), height / float(dpi)\n  LabelSize, LegendFontsize = 18, 18\n  resnet_scale, resnet_alpha = 120, 0.5\n\n  fig = plt.figure(figsize=figsize)\n  ax  = fig.add_subplot(111)\n  plt.xlim(min(indexes), max(indexes))\n  plt.ylim(min(indexes), max(indexes))\n  #plt.ylabel(\'y\').set_rotation(0)\n  plt.yticks(np.arange(min(indexes), max(indexes), max(indexes)//6), fontsize=LegendFontsize, rotation=\'vertical\')\n  plt.xticks(np.arange(min(indexes), max(indexes), max(indexes)//6), fontsize=LegendFontsize)\n  #ax.scatter(indexes, cifar100_labels, marker=\'^\', s=0.5, c=\'tab:green\', alpha=0.8, label=\'CIFAR-100\')\n  #ax.scatter(indexes, imagenet_labels, marker=\'*\', s=0.5, c=\'tab:red\'  , alpha=0.8, label=\'ImageNet-16-120\')\n  #ax.scatter(indexes, indexes        , marker=\'o\', s=0.5, c=\'tab:blue\' , alpha=0.8, label=\'CIFAR-10\')\n  ax.scatter(indexes, cifar100_labels, marker=\'^\', s=0.5, c=\'tab:green\', alpha=0.8)\n  ax.scatter(indexes, imagenet_labels, marker=\'*\', s=0.5, c=\'tab:red\'  , alpha=0.8)\n  ax.scatter(indexes, indexes        , marker=\'o\', s=0.5, c=\'tab:blue\' , alpha=0.8)\n  ax.scatter([-1], [-1], marker=\'o\', s=100, c=\'tab:blue\' , label=\'CIFAR-10\')\n  ax.scatter([-1], [-1], marker=\'^\', s=100, c=\'tab:green\', label=\'CIFAR-100\')\n  ax.scatter([-1], [-1], marker=\'*\', s=100, c=\'tab:red\'  , label=\'ImageNet-16-120\')\n  plt.grid(zorder=0)\n  ax.set_axisbelow(True)\n  plt.legend(loc=0, fontsize=LegendFontsize)\n  ax.set_xlabel(\'architecture ranking in CIFAR-10\', fontsize=LabelSize)\n  ax.set_ylabel(\'architecture ranking\', fontsize=LabelSize)\n  save_path = (vis_save_dir / \'relative-rank.pdf\').resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  save_path = (vis_save_dir / \'relative-rank.png\').resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n\n  # calculate correlation\n  sns_size = 15\n  CoRelMatrix = calculate_correlation(cifar010_info[\'valid_accs\'], cifar010_info[\'test_accs\'], cifar100_info[\'valid_accs\'], cifar100_info[\'test_accs\'], imagenet_info[\'valid_accs\'], imagenet_info[\'test_accs\'])\n  fig = plt.figure(figsize=figsize)\n  plt.axis(\'off\')\n  h = sns.heatmap(CoRelMatrix, annot=True, annot_kws={\'size\':sns_size}, fmt=\'.3f\', linewidths=0.5)  \n  save_path = (vis_save_dir / \'co-relation-all.pdf\').resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n\n  # calculate correlation\n  acc_bars = [92, 93]\n  for acc_bar in acc_bars:\n    selected_indexes = []\n    for i, acc in enumerate(cifar010_info[\'test_accs\']):\n      if acc > acc_bar: selected_indexes.append( i )\n    print (\'select {:} architectures\'.format(len(selected_indexes)))\n    cifar010_valid_accs = np.array(cifar010_info[\'valid_accs\'])[ selected_indexes ]\n    cifar010_test_accs  = np.array(cifar010_info[\'test_accs\']) [ selected_indexes ]\n    cifar100_valid_accs = np.array(cifar100_info[\'valid_accs\'])[ selected_indexes ]\n    cifar100_test_accs  = np.array(cifar100_info[\'test_accs\']) [ selected_indexes ]\n    imagenet_valid_accs = np.array(imagenet_info[\'valid_accs\'])[ selected_indexes ]\n    imagenet_test_accs  = np.array(imagenet_info[\'test_accs\']) [ selected_indexes ]\n    CoRelMatrix = calculate_correlation(cifar010_valid_accs, cifar010_test_accs, cifar100_valid_accs, cifar100_test_accs, imagenet_valid_accs, imagenet_test_accs)\n    fig = plt.figure(figsize=figsize)\n    plt.axis(\'off\')\n    h = sns.heatmap(CoRelMatrix, annot=True, annot_kws={\'size\':sns_size}, fmt=\'.3f\', linewidths=0.5)\n    save_path = (vis_save_dir / \'co-relation-top-{:}.pdf\'.format(len(selected_indexes))).resolve()\n    fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n    print (\'{:} save into {:}\'.format(time_string(), save_path))\n  plt.close(\'all\')\n\n\n\ndef visualize_info(meta_file, dataset, vis_save_dir):\n  print (\'{:} start to visualize {:} information\'.format(time_string(), dataset))\n  cache_file_path = vis_save_dir / \'{:}-cache-info.pth\'.format(dataset)\n  if not cache_file_path.exists():\n    print (\'Do not find cache file : {:}\'.format(cache_file_path))\n    nas_bench = API(str(meta_file))\n    params, flops, train_accs, valid_accs, test_accs, otest_accs = [], [], [], [], [], []\n    for index in range( len(nas_bench) ):\n      info = nas_bench.query_by_index(index, use_12epochs_result=False)\n      resx = info.get_comput_costs(dataset) ; flop, param = resx[\'flops\'], resx[\'params\']\n      if dataset == \'cifar10\':\n        res = info.get_metrics(\'cifar10\', \'train\')         ; train_acc = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10-valid\', \'x-valid\') ; valid_acc = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10\', \'ori-test\')      ; test_acc  = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10\', \'ori-test\')      ; otest_acc = res[\'accuracy\']\n      else:\n        res = info.get_metrics(dataset, \'train\')    ; train_acc = res[\'accuracy\']\n        res = info.get_metrics(dataset, \'x-valid\')  ; valid_acc = res[\'accuracy\']\n        res = info.get_metrics(dataset, \'x-test\')   ; test_acc  = res[\'accuracy\']\n        res = info.get_metrics(dataset, \'ori-test\') ; otest_acc = res[\'accuracy\']\n      if index == 11472: # resnet\n        resnet = {\'params\':param, \'flops\': flop, \'index\': 11472, \'train_acc\': train_acc, \'valid_acc\': valid_acc, \'test_acc\': test_acc, \'otest_acc\': otest_acc}\n      flops.append( flop )\n      params.append( param )\n      train_accs.append( train_acc )\n      valid_accs.append( valid_acc )\n      test_accs.append( test_acc )\n      otest_accs.append( otest_acc )\n    #resnet = {\'params\': 0.559, \'flops\': 78.56, \'index\': 11472, \'train_acc\': 99.99, \'valid_acc\': 90.84, \'test_acc\': 93.97}\n    info = {\'params\': params, \'flops\': flops, \'train_accs\': train_accs, \'valid_accs\': valid_accs, \'test_accs\': test_accs, \'otest_accs\': otest_accs}\n    info[\'resnet\'] = resnet\n    torch.save(info, cache_file_path)\n  else:\n    print (\'Find cache file : {:}\'.format(cache_file_path))\n    info = torch.load(cache_file_path)\n    params, flops, train_accs, valid_accs, test_accs, otest_accs = info[\'params\'], info[\'flops\'], info[\'train_accs\'], info[\'valid_accs\'], info[\'test_accs\'], info[\'otest_accs\']\n    resnet = info[\'resnet\']\n  print (\'{:} collect data done.\'.format(time_string()))\n\n  indexes = list(range(len(params)))\n  dpi, width, height = 300, 2600, 2600\n  figsize = width / float(dpi), height / float(dpi)\n  LabelSize, LegendFontsize = 22, 22\n  resnet_scale, resnet_alpha = 120, 0.5\n\n  fig = plt.figure(figsize=figsize)\n  ax  = fig.add_subplot(111)\n  plt.xticks(np.arange(0, 1.6, 0.3), fontsize=LegendFontsize)\n  if dataset == \'cifar10\':\n    plt.ylim(50, 100)\n    plt.yticks(np.arange(50, 101, 10), fontsize=LegendFontsize)\n  elif dataset == \'cifar100\':\n    plt.ylim(25,  75)\n    plt.yticks(np.arange(25, 76, 10), fontsize=LegendFontsize)\n  else:\n    plt.ylim(0, 50)\n    plt.yticks(np.arange(0, 51, 10), fontsize=LegendFontsize)\n  ax.scatter(params, valid_accs, marker=\'o\', s=0.5, c=\'tab:blue\') \n  ax.scatter([resnet[\'params\']], [resnet[\'valid_acc\']], marker=\'*\', s=resnet_scale, c=\'tab:orange\', label=\'resnet\', alpha=0.4) \n  plt.grid(zorder=0)\n  ax.set_axisbelow(True)\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  ax.set_xlabel(\'#parameters (MB)\', fontsize=LabelSize)\n  ax.set_ylabel(\'the validation accuracy (%)\', fontsize=LabelSize)\n  save_path = (vis_save_dir / \'{:}-param-vs-valid.pdf\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  save_path = (vis_save_dir / \'{:}-param-vs-valid.png\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n\n  fig = plt.figure(figsize=figsize)\n  ax  = fig.add_subplot(111)\n  plt.xticks(np.arange(0, 1.6, 0.3), fontsize=LegendFontsize)\n  if dataset == \'cifar10\':\n    plt.ylim(50, 100)\n    plt.yticks(np.arange(50, 101, 10), fontsize=LegendFontsize)\n  elif dataset == \'cifar100\':\n    plt.ylim(25,  75)\n    plt.yticks(np.arange(25, 76, 10), fontsize=LegendFontsize)\n  else:\n    plt.ylim(0, 50)\n    plt.yticks(np.arange(0, 51, 10), fontsize=LegendFontsize)\n  ax.scatter(params,  test_accs, marker=\'o\', s=0.5, c=\'tab:blue\')\n  ax.scatter([resnet[\'params\']], [resnet[\'test_acc\']], marker=\'*\', s=resnet_scale, c=\'tab:orange\', label=\'resnet\', alpha=resnet_alpha)\n  plt.grid()\n  ax.set_axisbelow(True)\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  ax.set_xlabel(\'#parameters (MB)\', fontsize=LabelSize)\n  ax.set_ylabel(\'the test accuracy (%)\', fontsize=LabelSize)\n  save_path = (vis_save_dir / \'{:}-param-vs-test.pdf\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  save_path = (vis_save_dir / \'{:}-param-vs-test.png\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n\n  fig = plt.figure(figsize=figsize)\n  ax  = fig.add_subplot(111)\n  plt.xticks(np.arange(0, 1.6, 0.3), fontsize=LegendFontsize)\n  if dataset == \'cifar10\':\n    plt.ylim(50, 100)\n    plt.yticks(np.arange(50, 101, 10), fontsize=LegendFontsize)\n  elif dataset == \'cifar100\':\n    plt.ylim(20, 100)\n    plt.yticks(np.arange(20, 101, 10), fontsize=LegendFontsize)\n  else:\n    plt.ylim(25,  76)\n    plt.yticks(np.arange(25,  76, 10), fontsize=LegendFontsize)\n  ax.scatter(params, train_accs, marker=\'o\', s=0.5, c=\'tab:blue\')\n  ax.scatter([resnet[\'params\']], [resnet[\'train_acc\']], marker=\'*\', s=resnet_scale, c=\'tab:orange\', label=\'resnet\', alpha=resnet_alpha)\n  plt.grid()\n  ax.set_axisbelow(True)\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  ax.set_xlabel(\'#parameters (MB)\', fontsize=LabelSize)\n  ax.set_ylabel(\'the trarining accuracy (%)\', fontsize=LabelSize)\n  save_path = (vis_save_dir / \'{:}-param-vs-train.pdf\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  save_path = (vis_save_dir / \'{:}-param-vs-train.png\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n\n  fig = plt.figure(figsize=figsize)\n  ax  = fig.add_subplot(111)\n  plt.xlim(0, max(indexes))\n  plt.xticks(np.arange(min(indexes), max(indexes), max(indexes)//5), fontsize=LegendFontsize)\n  if dataset == \'cifar10\':\n    plt.ylim(50, 100)\n    plt.yticks(np.arange(50, 101, 10), fontsize=LegendFontsize)\n  elif dataset == \'cifar100\':\n    plt.ylim(25,  75)\n    plt.yticks(np.arange(25, 76, 10), fontsize=LegendFontsize)\n  else:\n    plt.ylim(0, 50)\n    plt.yticks(np.arange(0, 51, 10), fontsize=LegendFontsize)\n  ax.scatter(indexes, test_accs, marker=\'o\', s=0.5, c=\'tab:blue\')\n  ax.scatter([resnet[\'index\']], [resnet[\'test_acc\']], marker=\'*\', s=resnet_scale, c=\'tab:orange\', label=\'resnet\', alpha=resnet_alpha)\n  plt.grid()\n  ax.set_axisbelow(True)\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  ax.set_xlabel(\'architecture ID\', fontsize=LabelSize)\n  ax.set_ylabel(\'the test accuracy (%)\', fontsize=LabelSize)\n  save_path = (vis_save_dir / \'{:}-test-over-ID.pdf\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n  save_path = (vis_save_dir / \'{:}-test-over-ID.png\'.format(dataset)).resolve()\n  fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n  print (\'{:} save into {:}\'.format(time_string(), save_path))\n  plt.close(\'all\')\n\n\n\ndef visualize_rank_over_time(meta_file, vis_save_dir):\n  print (\'\\n\' + \'-\'*150)\n  vis_save_dir.mkdir(parents=True, exist_ok=True)\n  print (\'{:} start to visualize rank-over-time into {:}\'.format(time_string(), vis_save_dir))\n  cache_file_path = vis_save_dir / \'rank-over-time-cache-info.pth\'\n  if not cache_file_path.exists():\n    print (\'Do not find cache file : {:}\'.format(cache_file_path))\n    nas_bench = API(str(meta_file))\n    print (\'{:} load nas_bench done\'.format(time_string()))\n    params, flops, train_accs, valid_accs, test_accs, otest_accs = [], [], defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list)\n    #for iepoch in range(200): for index in range( len(nas_bench) ):\n    for index in tqdm(range(len(nas_bench))):\n      info = nas_bench.query_by_index(index, use_12epochs_result=False)\n      for iepoch in range(200):\n        res = info.get_metrics(\'cifar10\'      , \'train\'   , iepoch) ; train_acc = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10-valid\', \'x-valid\' , iepoch) ; valid_acc = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10\'      , \'ori-test\', iepoch) ; test_acc  = res[\'accuracy\']\n        res = info.get_metrics(\'cifar10\'      , \'ori-test\', iepoch) ; otest_acc = res[\'accuracy\']\n        train_accs[iepoch].append( train_acc )\n        valid_accs[iepoch].append( valid_acc )\n        test_accs [iepoch].append( test_acc )\n        otest_accs[iepoch].append( otest_acc )\n        if iepoch == 0:\n          res = info.get_comput_costs(\'cifar10\') ; flop, param = res[\'flops\'], res[\'params\']\n          flops.append( flop )\n          params.append( param )\n    info = {\'params\': params, \'flops\': flops, \'train_accs\': train_accs, \'valid_accs\': valid_accs, \'test_accs\': test_accs, \'otest_accs\': otest_accs}\n    torch.save(info, cache_file_path)\n  else:\n    print (\'Find cache file : {:}\'.format(cache_file_path))\n    info = torch.load(cache_file_path)\n    params, flops, train_accs, valid_accs, test_accs, otest_accs = info[\'params\'], info[\'flops\'], info[\'train_accs\'], info[\'valid_accs\'], info[\'test_accs\'], info[\'otest_accs\']\n  print (\'{:} collect data done.\'.format(time_string()))\n  #selected_epochs = [0, 100, 150, 180, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\n  selected_epochs = list( range(200) )\n  x_xtests = test_accs[199]\n  indexes  = list(range(len(x_xtests)))\n  ord_idxs = sorted(indexes, key=lambda i: x_xtests[i])\n  for sepoch in selected_epochs:\n    x_valids = valid_accs[sepoch]\n    valid_ord_idxs = sorted(indexes, key=lambda i: x_valids[i])\n    valid_ord_lbls = []\n    for idx in ord_idxs:\n      valid_ord_lbls.append( valid_ord_idxs.index(idx) )\n    # labeled data\n    dpi, width, height = 300, 2600, 2600\n    figsize = width / float(dpi), height / float(dpi)\n    LabelSize, LegendFontsize = 18, 18\n\n    fig = plt.figure(figsize=figsize)\n    ax  = fig.add_subplot(111)\n    plt.xlim(min(indexes), max(indexes))\n    plt.ylim(min(indexes), max(indexes))\n    plt.yticks(np.arange(min(indexes), max(indexes), max(indexes)//6), fontsize=LegendFontsize, rotation=\'vertical\')\n    plt.xticks(np.arange(min(indexes), max(indexes), max(indexes)//6), fontsize=LegendFontsize)\n    ax.scatter(indexes, valid_ord_lbls, marker=\'^\', s=0.5, c=\'tab:green\', alpha=0.8)\n    ax.scatter(indexes, indexes       , marker=\'o\', s=0.5, c=\'tab:blue\' , alpha=0.8)\n    ax.scatter([-1], [-1], marker=\'^\', s=100, c=\'tab:green\', label=\'CIFAR-10 validation\')\n    ax.scatter([-1], [-1], marker=\'o\', s=100, c=\'tab:blue\' , label=\'CIFAR-10 test\')\n    plt.grid(zorder=0)\n    ax.set_axisbelow(True)\n    plt.legend(loc=\'upper left\', fontsize=LegendFontsize)\n    ax.set_xlabel(\'architecture ranking in the final test accuracy\', fontsize=LabelSize)\n    ax.set_ylabel(\'architecture ranking in the validation set\', fontsize=LabelSize)\n    save_path = (vis_save_dir / \'time-{:03d}.pdf\'.format(sepoch)).resolve()\n    fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n    save_path = (vis_save_dir / \'time-{:03d}.png\'.format(sepoch)).resolve()\n    fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\', format=\'png\')\n    print (\'{:} save into {:}\'.format(time_string(), save_path))\n    plt.close(\'all\')\n\n\n\ndef write_video(save_dir):\n  import cv2\n  video_save_path = save_dir / \'time.avi\'\n  print (\'{:} start create video for {:}\'.format(time_string(), video_save_path))\n  images = sorted( list( save_dir.glob(\'time-*.png\') ) )\n  ximage = cv2.imread(str(images[0]))\n  #shape  = (ximage.shape[1], ximage.shape[0])\n  shape  = (1000, 1000)\n  #writer = cv2.VideoWriter(str(video_save_path), cv2.VideoWriter_fourcc(*""MJPG""), 25, shape)\n  writer = cv2.VideoWriter(str(video_save_path), cv2.VideoWriter_fourcc(*""MJPG""), 5, shape)\n  for idx, image in enumerate(images):\n    ximage = cv2.imread(str(image))\n    _image = cv2.resize(ximage, shape)\n    writer.write(_image)\n  writer.release()\n  print (\'write video [{:} frames] into {:}\'.format(len(images), video_save_path))\n\n\n\ndef plot_results_nas_v2(api, dataset_xset_a, dataset_xset_b, root, file_name, y_lims):\n  #print (\'root-path={:}, dataset={:}, xset={:}\'.format(root, dataset, xset))\n  print (\'root-path : {:} and {:}\'.format(dataset_xset_a, dataset_xset_b))\n  checkpoints = [\'./output/search-cell-nas-bench-201/R-EA-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/REINFORCE-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/RAND-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/BOHB-cifar10/results.pth\'\n                ]\n  legends, indexes = [\'REA\', \'REINFORCE\', \'RANDOM\', \'BOHB\'], None\n  All_Accs_A, All_Accs_B = OrderedDict(), OrderedDict()\n  for legend, checkpoint in zip(legends, checkpoints):\n    all_indexes = torch.load(checkpoint, map_location=\'cpu\')\n    accuracies_A, accuracies_B = [], []\n    accuracies = []\n    for x in all_indexes:\n      info = api.arch2infos_full[ x ]\n      metrics = info.get_metrics(dataset_xset_a[0], dataset_xset_a[1], None, False)\n      accuracies_A.append( metrics[\'accuracy\'] )\n      metrics = info.get_metrics(dataset_xset_b[0], dataset_xset_b[1], None, False)\n      accuracies_B.append( metrics[\'accuracy\'] )\n      accuracies.append( (accuracies_A[-1], accuracies_B[-1]) )\n    if indexes is None: indexes = list(range(len(all_indexes)))\n    accuracies = sorted(accuracies)\n    All_Accs_A[legend] = [x[0] for x in accuracies]\n    All_Accs_B[legend] = [x[1] for x in accuracies]\n\n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 28\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  x_axis = np.arange(0, 600)\n  plt.xlim(0, max(indexes))\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = 100, y_lims[2]\n  plt.xticks(np.arange(0, max(indexes), interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The index of runs\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  for idx, legend in enumerate(legends):\n    plt.plot(indexes, All_Accs_B[legend], color=color_set[idx], linestyle=\'--\', label=\'{:}\'.format(legend), lw=1, alpha=0.5)\n    plt.plot(indexes, All_Accs_A[legend], color=color_set[idx], linestyle=\'-\', lw=1)\n    for All_Accs in [All_Accs_A, All_Accs_B]:\n      print (\'{:} : mean = {:}, std = {:} :: {:.2f}$\\\\pm${:.2f}\'.format(legend, np.mean(All_Accs[legend]), np.std(All_Accs[legend]), np.mean(All_Accs[legend]), np.std(All_Accs[legend])))\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  save_path = root / \'{:}\'.format(file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\n\n\ndef plot_results_nas(api, dataset, xset, root, file_name, y_lims):\n  print (\'root-path={:}, dataset={:}, xset={:}\'.format(root, dataset, xset))\n  checkpoints = [\'./output/search-cell-nas-bench-201/R-EA-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/REINFORCE-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/RAND-cifar10/results.pth\',\n                 \'./output/search-cell-nas-bench-201/BOHB-cifar10/results.pth\'\n                ]\n  legends, indexes = [\'REA\', \'REINFORCE\', \'RANDOM\', \'BOHB\'], None\n  All_Accs = OrderedDict()\n  for legend, checkpoint in zip(legends, checkpoints):\n    all_indexes = torch.load(checkpoint, map_location=\'cpu\')\n    accuracies  = []\n    for x in all_indexes:\n      info = api.arch2infos_full[ x ]\n      metrics = info.get_metrics(dataset, xset, None, False)\n      accuracies.append( metrics[\'accuracy\'] )\n    if indexes is None: indexes = list(range(len(all_indexes)))\n    All_Accs[legend] = sorted(accuracies)\n  \n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 28\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  x_axis = np.arange(0, 600)\n  plt.xlim(0, max(indexes))\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = 100, y_lims[2]\n  plt.xticks(np.arange(0, max(indexes), interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The index of runs\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  for idx, legend in enumerate(legends):\n    plt.plot(indexes, All_Accs[legend], color=color_set[idx], linestyle=\'-\', label=\'{:}\'.format(legend), lw=2)\n    print (\'{:} : mean = {:}, std = {:} :: {:.2f}$\\\\pm${:.2f}\'.format(legend, np.mean(All_Accs[legend]), np.std(All_Accs[legend]), np.mean(All_Accs[legend]), np.std(All_Accs[legend])))\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  save_path = root / \'{:}-{:}-{:}\'.format(dataset, xset, file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\ndef just_show(api):\n  xtimes = {\'RSPS\'    : [8082.5, 7794.2, 8144.7],\n            \'DARTS-V1\': [11582.1, 11347.0, 11948.2],\n            \'DARTS-V2\': [35694.7, 36132.7, 35518.0],\n            \'GDAS\'    : [31334.1, 31478.6, 32016.7],\n            \'SETN\'    : [33528.8, 33831.5, 35058.3],\n            \'ENAS\'    : [14340.2, 13817.3, 14018.9]}\n  for xkey, xlist in xtimes.items():\n    xlist = np.array(xlist)\n    print (\'{:4s} : mean-time={:.2f} s\'.format(xkey, xlist.mean()))\n\n  xpaths = {\'RSPS\'    : \'output/search-cell-nas-bench-201/RANDOM-NAS-cifar10/checkpoint/\',\n            \'DARTS-V1\': \'output/search-cell-nas-bench-201/DARTS-V1-cifar10/checkpoint/\',\n            \'DARTS-V2\': \'output/search-cell-nas-bench-201/DARTS-V2-cifar10/checkpoint/\',\n            \'GDAS\'    : \'output/search-cell-nas-bench-201/GDAS-cifar10/checkpoint/\',\n            \'SETN\'    : \'output/search-cell-nas-bench-201/SETN-cifar10/checkpoint/\',\n            \'ENAS\'    : \'output/search-cell-nas-bench-201/ENAS-cifar10/checkpoint/\',\n           }\n  xseeds = {\'RSPS\'    : [5349, 59613, 5983],\n            \'DARTS-V1\': [11416, 72873, 81184],\n            \'DARTS-V2\': [43330, 79405, 79423],\n            \'GDAS\'    : [19677, 884, 95950],\n            \'SETN\'    : [20518, 61817, 89144],\n            \'ENAS\'    : [3231, 34238, 96929],\n           }\n\n  def get_accs(xdata, index=-1):\n    if index == -1:\n      epochs = xdata[\'epoch\']\n      genotype = xdata[\'genotypes\'][epochs-1]\n      index = api.query_index_by_arch(genotype)\n    pairs = [(\'cifar10-valid\', \'x-valid\'), (\'cifar10\', \'ori-test\'), (\'cifar100\', \'x-valid\'), (\'cifar100\', \'x-test\'), (\'ImageNet16-120\', \'x-valid\'), (\'ImageNet16-120\', \'x-test\')]\n    xresults = []\n    for dataset, xset in pairs:\n      metrics = api.arch2infos_full[index].get_metrics(dataset, xset, None, False)\n      xresults.append( metrics[\'accuracy\'] )\n    return xresults\n\n  for xkey in xpaths.keys():\n    all_paths = [ \'{:}/seed-{:}-basic.pth\'.format(xpaths[xkey], seed) for seed in xseeds[xkey] ]\n    all_datas = [torch.load(xpath) for xpath in all_paths]\n    accyss = [get_accs(xdatas) for xdatas in all_datas]\n    accyss = np.array( accyss )\n    print(\'\\nxkey = {:}\'.format(xkey))\n    for i in range(accyss.shape[1]): print(\'---->>>> {:.2f}$\\\\pm${:.2f}\'.format(accyss[:,i].mean(), accyss[:,i].std()))\n\n  print(\'\\n{:}\'.format(get_accs(None, 11472))) # resnet\n  pairs = [(\'cifar10-valid\', \'x-valid\'), (\'cifar10\', \'ori-test\'), (\'cifar100\', \'x-valid\'), (\'cifar100\', \'x-test\'), (\'ImageNet16-120\', \'x-valid\'), (\'ImageNet16-120\', \'x-test\')]\n  for dataset, metric_on_set in pairs:\n    arch_index, highest_acc = api.find_best(dataset, metric_on_set)\n    print (\'[{:10s}-{:10s} ::: index={:5d}, accuracy={:.2f}\'.format(dataset, metric_on_set, arch_index, highest_acc))\n\n\ndef show_nas_sharing_w(api, dataset, subset, vis_save_dir, sufix, file_name, y_lims, x_maxs):\n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 28\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  #x_maxs = 250\n  plt.xlim(0, x_maxs+1)\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = x_maxs // 5, y_lims[2]\n  plt.xticks(np.arange(0, x_maxs+1, interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The searching epoch\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  xpaths = {\'RSPS\'    : \'output/search-cell-nas-bench-201/RANDOM-NAS-cifar10-{:}/checkpoint/\'.format(sufix), \n            \'DARTS-V1\': \'output/search-cell-nas-bench-201/DARTS-V1-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'DARTS-V2\': \'output/search-cell-nas-bench-201/DARTS-V2-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'GDAS\'    : \'output/search-cell-nas-bench-201/GDAS-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'SETN\'    : \'output/search-cell-nas-bench-201/SETN-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'ENAS\'    : \'output/search-cell-nas-bench-201/ENAS-cifar10-{:}/checkpoint/\'.format(sufix),\n           }\n  """"""\n  xseeds = {\'RSPS\'    : [5349, 59613, 5983],\n            \'DARTS-V1\': [11416, 72873, 81184, 28640],\n            \'DARTS-V2\': [43330, 79405, 79423],\n            \'GDAS\'    : [19677, 884, 95950],\n            \'SETN\'    : [20518, 61817, 89144],\n            \'ENAS\'    : [3231, 34238, 96929],\n           }\n  """"""\n  xseeds = {\'RSPS\'    : [23814, 28015, 95809],\n            \'DARTS-V1\': [48349, 80877, 81920],\n            \'DARTS-V2\': [61712, 7941 , 87041] ,\n            \'GDAS\'    : [72818, 72996, 78877],\n            \'SETN\'    : [26985, 55206, 95404],\n            \'ENAS\'    : [21792, 36605, 45029]\n           }\n\n\n  def get_accs(xdata):\n    epochs, xresults = xdata[\'epoch\'], []\n    if -1 in xdata[\'genotypes\']:\n      metrics = api.arch2infos_full[ api.query_index_by_arch(xdata[\'genotypes\'][-1]) ].get_metrics(dataset, subset, None, False)\n    else:\n      metrics = api.arch2infos_full[ api.random() ].get_metrics(dataset, subset, None, False)\n    xresults.append( metrics[\'accuracy\'] )\n    for iepoch in range(epochs):\n      genotype = xdata[\'genotypes\'][iepoch]\n      index = api.query_index_by_arch(genotype)\n      metrics = api.arch2infos_full[index].get_metrics(dataset, subset, None, False)\n      xresults.append( metrics[\'accuracy\'] )\n    return xresults\n\n  if x_maxs == 50:\n    xox, xxxstrs = \'v2\', [\'DARTS-V1\', \'DARTS-V2\']\n  elif x_maxs == 250:\n    xox, xxxstrs = \'v1\', [\'RSPS\', \'GDAS\', \'SETN\', \'ENAS\']\n  else: raise ValueError(\'invalid x_maxs={:}\'.format(x_maxs))\n\n  for idx, method in enumerate(xxxstrs):\n    xkey = method\n    all_paths = [ \'{:}/seed-{:}-basic.pth\'.format(xpaths[xkey], seed) for seed in xseeds[xkey] ]\n    all_datas = [torch.load(xpath, map_location=\'cpu\') for xpath in all_paths]\n    accyss = [get_accs(xdatas) for xdatas in all_datas]\n    accyss = np.array( accyss )\n    epochs = list(range(accyss.shape[1]))\n    plt.plot(epochs, [accyss[:,i].mean() for i in epochs], color=color_set[idx], linestyle=\'-\', label=\'{:}\'.format(method), lw=2)\n    plt.fill_between(epochs, [accyss[:,i].mean()-accyss[:,i].std() for i in epochs], [accyss[:,i].mean()+accyss[:,i].std() for i in epochs], alpha=0.2, color=color_set[idx])\n  #plt.legend(loc=4, fontsize=LegendFontsize)\n  plt.legend(loc=0, fontsize=LegendFontsize)\n  save_path = vis_save_dir / \'{:}.pdf\'.format(file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\n\ndef show_nas_sharing_w_v2(api, data_sub_a, data_sub_b, vis_save_dir, sufix, file_name, y_lims, x_maxs):\n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 28\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  #x_maxs = 250\n  plt.xlim(0, x_maxs+1)\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = x_maxs // 5, y_lims[2]\n  plt.xticks(np.arange(0, x_maxs+1, interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The searching epoch\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  xpaths = {\'RSPS\'    : \'output/search-cell-nas-bench-201/RANDOM-NAS-cifar10-{:}/checkpoint/\'.format(sufix), \n            \'DARTS-V1\': \'output/search-cell-nas-bench-201/DARTS-V1-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'DARTS-V2\': \'output/search-cell-nas-bench-201/DARTS-V2-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'GDAS\'    : \'output/search-cell-nas-bench-201/GDAS-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'SETN\'    : \'output/search-cell-nas-bench-201/SETN-cifar10-{:}/checkpoint/\'.format(sufix),\n            \'ENAS\'    : \'output/search-cell-nas-bench-201/ENAS-cifar10-{:}/checkpoint/\'.format(sufix),\n           }\n  """"""\n  xseeds = {\'RSPS\'    : [5349, 59613, 5983],\n            \'DARTS-V1\': [11416, 72873, 81184, 28640],\n            \'DARTS-V2\': [43330, 79405, 79423],\n            \'GDAS\'    : [19677, 884, 95950],\n            \'SETN\'    : [20518, 61817, 89144],\n            \'ENAS\'    : [3231, 34238, 96929],\n           }\n  """"""\n  xseeds = {\'RSPS\'    : [23814, 28015, 95809],\n            \'DARTS-V1\': [48349, 80877, 81920],\n            \'DARTS-V2\': [61712, 7941 , 87041] ,\n            \'GDAS\'    : [72818, 72996, 78877],\n            \'SETN\'    : [26985, 55206, 95404],\n            \'ENAS\'    : [21792, 36605, 45029]\n           }\n\n\n  def get_accs(xdata, dataset, subset):\n    epochs, xresults = xdata[\'epoch\'], []\n    if -1 in xdata[\'genotypes\']:\n      metrics = api.arch2infos_full[ api.query_index_by_arch(xdata[\'genotypes\'][-1]) ].get_metrics(dataset, subset, None, False)\n    else:\n      metrics = api.arch2infos_full[ api.random() ].get_metrics(dataset, subset, None, False)\n    xresults.append( metrics[\'accuracy\'] )\n    for iepoch in range(epochs):\n      genotype = xdata[\'genotypes\'][iepoch]\n      index = api.query_index_by_arch(genotype)\n      metrics = api.arch2infos_full[index].get_metrics(dataset, subset, None, False)\n      xresults.append( metrics[\'accuracy\'] )\n    return xresults\n\n  if x_maxs == 50:\n    xox, xxxstrs = \'v2\', [\'DARTS-V1\', \'DARTS-V2\']\n  elif x_maxs == 250:\n    xox, xxxstrs = \'v1\', [\'RSPS\', \'GDAS\', \'SETN\', \'ENAS\']\n  else: raise ValueError(\'invalid x_maxs={:}\'.format(x_maxs))\n\n  for idx, method in enumerate(xxxstrs):\n    xkey = method\n    all_paths = [ \'{:}/seed-{:}-basic.pth\'.format(xpaths[xkey], seed) for seed in xseeds[xkey] ]\n    all_datas = [torch.load(xpath, map_location=\'cpu\') for xpath in all_paths]\n    accyss_A = np.array( [get_accs(xdatas, data_sub_a[0], data_sub_a[1]) for xdatas in all_datas] )\n    accyss_B = np.array( [get_accs(xdatas, data_sub_b[0], data_sub_b[1]) for xdatas in all_datas] )\n    epochs = list(range(accyss_A.shape[1]))\n    for j, accyss in enumerate([accyss_A, accyss_B]):\n      if x_maxs == 50:\n        color, line = color_set[idx*2+j], \'-\' if j==0 else \'--\'\n      elif x_maxs == 250:\n        color, line = color_set[idx], \'-\' if j==0 else \'--\'\n      else: raise ValueError(\'invalid x-maxs={:}\'.format(x_maxs))\n      plt.plot(epochs, [accyss[:,i].mean() for i in epochs], color=color, linestyle=line, label=\'{:} ({:})\'.format(method, \'VALID\' if j == 0 else \'TEST\'), lw=2, alpha=0.9)\n      plt.fill_between(epochs, [accyss[:,i].mean()-accyss[:,i].std() for i in epochs], [accyss[:,i].mean()+accyss[:,i].std() for i in epochs], alpha=0.2, color=color)\n      setname = data_sub_a if j == 0 else data_sub_b\n      print(\'{:} -- {:} ---- {:.2f}$\\\\pm${:.2f}\'.format(method, setname, accyss[:,-1].mean(), accyss[:,-1].std()))\n  #plt.legend(loc=4, fontsize=LegendFontsize)\n  plt.legend(loc=0, fontsize=LegendFontsize)\n  save_path = vis_save_dir / \'{:}-{:}\'.format(xox, file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\ndef show_reinforce(api, root, dataset, xset, file_name, y_lims):\n  print (\'root-path={:}, dataset={:}, xset={:}\'.format(root, dataset, xset))\n  LRs = [\'0.01\', \'0.02\', \'0.1\', \'0.2\', \'0.5\']\n  checkpoints = [\'./output/search-cell-nas-bench-201/REINFORCE-cifar10-{:}/results.pth\'.format(x) for x in LRs]\n  acc_lr_dict, indexes = {}, None\n  for lr, checkpoint in zip(LRs, checkpoints):\n    all_indexes, accuracies = torch.load(checkpoint, map_location=\'cpu\'), []\n    for x in all_indexes:\n      info = api.arch2infos_full[ x ]\n      metrics = info.get_metrics(dataset, xset, None, False)\n      accuracies.append( metrics[\'accuracy\'] )\n    if indexes is None: indexes = list(range(len(accuracies)))\n    acc_lr_dict[lr] = np.array( sorted(accuracies) )\n    print (\'LR={:.3f}, mean={:}, std={:}\'.format(float(lr), acc_lr_dict[lr].mean(), acc_lr_dict[lr].std()))\n  \n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 22\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  x_axis = np.arange(0, 600)\n  plt.xlim(0, max(indexes))\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = 100, y_lims[2]\n  plt.xticks(np.arange(0, max(indexes), interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The index of runs\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  for idx, LR in enumerate(LRs):\n    legend = \'LR={:.2f}\'.format(float(LR))\n    #color, linestyle = color_set[idx // 2], \'-\' if idx % 2 == 0 else \'-.\'\n    color, linestyle = color_set[idx], \'-\'\n    plt.plot(indexes, acc_lr_dict[LR], color=color, linestyle=linestyle, label=legend, lw=2, alpha=0.8)\n    print (\'{:} : mean = {:}, std = {:} :: {:.2f}$\\\\pm${:.2f}\'.format(legend, np.mean(acc_lr_dict[LR]), np.std(acc_lr_dict[LR]), np.mean(acc_lr_dict[LR]), np.std(acc_lr_dict[LR])))\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  save_path = root / \'{:}-{:}-{:}.pdf\'.format(dataset, xset, file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\n\ndef show_rea(api, root, dataset, xset, file_name, y_lims):\n  print (\'root-path={:}, dataset={:}, xset={:}\'.format(root, dataset, xset))\n  SSs = [3, 5, 10]\n  checkpoints = [\'./output/search-cell-nas-bench-201/R-EA-cifar10-SS{:}/results.pth\'.format(x) for x in SSs]\n  acc_ss_dict, indexes = {}, None\n  for ss, checkpoint in zip(SSs, checkpoints):\n    all_indexes, accuracies = torch.load(checkpoint, map_location=\'cpu\'), []\n    for x in all_indexes:\n      info = api.arch2infos_full[ x ]\n      metrics = info.get_metrics(dataset, xset, None, False)\n      accuracies.append( metrics[\'accuracy\'] )\n    if indexes is None: indexes = list(range(len(accuracies)))\n    acc_ss_dict[ss] = np.array( sorted(accuracies) )\n    print (\'Sample-Size={:2d}, mean={:}, std={:}\'.format(ss, acc_ss_dict[ss].mean(), acc_ss_dict[ss].std()))\n  \n  color_set = [\'r\', \'b\', \'g\', \'c\', \'m\', \'y\', \'k\']\n  dpi, width, height = 300, 3400, 2600\n  LabelSize, LegendFontsize = 28, 22\n  figsize = width / float(dpi), height / float(dpi)\n  fig = plt.figure(figsize=figsize)\n  x_axis = np.arange(0, 600)\n  plt.xlim(0, max(indexes))\n  plt.ylim(y_lims[0], y_lims[1])\n  interval_x, interval_y = 100, y_lims[2]\n  plt.xticks(np.arange(0, max(indexes), interval_x), fontsize=LegendFontsize)\n  plt.yticks(np.arange(y_lims[0],y_lims[1], interval_y), fontsize=LegendFontsize)\n  plt.grid()\n  plt.xlabel(\'The index of runs\', fontsize=LabelSize)\n  plt.ylabel(\'The accuracy (%)\', fontsize=LabelSize)\n\n  for idx, ss in enumerate(SSs):\n    legend = \'sample-size={:2d}\'.format(ss)\n    #color, linestyle = color_set[idx // 2], \'-\' if idx % 2 == 0 else \'-.\'\n    color, linestyle = color_set[idx], \'-\'\n    plt.plot(indexes, acc_ss_dict[ss], color=color, linestyle=linestyle, label=legend, lw=2, alpha=0.8)\n    print (\'{:} : mean = {:}, std = {:} :: {:.2f}$\\\\pm${:.2f}\'.format(legend, np.mean(acc_ss_dict[ss]), np.std(acc_ss_dict[ss]), np.mean(acc_ss_dict[ss]), np.std(acc_ss_dict[ss])))\n  plt.legend(loc=4, fontsize=LegendFontsize)\n  save_path = root / \'{:}-{:}-{:}.pdf\'.format(dataset, xset, file_name)\n  print(\'save figure into {:}\\n\'.format(save_path))\n  fig.savefig(str(save_path), dpi=dpi, bbox_inches=\'tight\', format=\'pdf\')\n\n\nif __name__ == \'__main__\':\n\n  parser = argparse.ArgumentParser(description=\'NAS-Bench-201\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument(\'--save_dir\',  type=str, default=\'./output/search-cell-nas-bench-201/visuals\', help=\'The base-name of folder to save checkpoints and log.\')\n  parser.add_argument(\'--api_path\',  type=str, default=None,                                         help=\'The path to the NAS-Bench-201 benchmark file.\')\n  args = parser.parse_args()\n  \n  vis_save_dir = Path(args.save_dir)\n  vis_save_dir.mkdir(parents=True, exist_ok=True)\n  meta_file = Path(args.api_path)\n  assert meta_file.exists(), \'invalid path for api : {:}\'.format(meta_file)\n  #visualize_rank_over_time(str(meta_file), vis_save_dir / \'over-time\')\n  #write_video(vis_save_dir / \'over-time\')\n  #visualize_info(str(meta_file), \'cifar10\' , vis_save_dir)\n  #visualize_info(str(meta_file), \'cifar100\', vis_save_dir)\n  #visualize_info(str(meta_file), \'ImageNet16-120\', vis_save_dir)\n  #visualize_relative_ranking(vis_save_dir)\n\n  api = API(args.api_path)\n  #show_reinforce(api, vis_save_dir, \'cifar10-valid\' , \'x-valid\', \'REINFORCE-CIFAR-10\', (85, 92, 2))\n  #show_rea      (api, vis_save_dir, \'cifar10-valid\' , \'x-valid\', \'REA-CIFAR-10\', (88, 92, 1))\n\n  #plot_results_nas_v2(api, (\'cifar10-valid\' , \'x-valid\'), (\'cifar10\'       , \'ori-test\'), vis_save_dir, \'nas-com-v2-cifar010.pdf\', (85,95, 1))\n  #plot_results_nas_v2(api, (\'cifar100\'      , \'x-valid\'), (\'cifar100\'      , \'x-test\'  ), vis_save_dir, \'nas-com-v2-cifar100.pdf\', (60,75, 3))\n  #plot_results_nas_v2(api, (\'ImageNet16-120\', \'x-valid\'), (\'ImageNet16-120\', \'x-test\'  ), vis_save_dir, \'nas-com-v2-imagenet.pdf\', (35,48, 2))\n\n  show_nas_sharing_w_v2(api, (\'cifar10-valid\' , \'x-valid\'), (\'cifar10\'       , \'ori-test\') , vis_save_dir, \'BN0\', \'BN0-DARTS-CIFAR010.pdf\', (0, 100,10), 50)\n  show_nas_sharing_w_v2(api, (\'cifar100\'      , \'x-valid\'), (\'cifar100\'      , \'x-test\'  ) , vis_save_dir, \'BN0\', \'BN0-DARTS-CIFAR100.pdf\', (0, 100,10), 50)\n  show_nas_sharing_w_v2(api, (\'ImageNet16-120\', \'x-valid\'), (\'ImageNet16-120\', \'x-test\'  ) , vis_save_dir, \'BN0\', \'BN0-DARTS-ImageNet.pdf\', (0, 100,10), 50)\n\n  show_nas_sharing_w_v2(api, (\'cifar10-valid\' , \'x-valid\'), (\'cifar10\'       , \'ori-test\') , vis_save_dir, \'BN0\', \'BN0-OTHER-CIFAR010.pdf\', (0, 100,10), 250)\n  show_nas_sharing_w_v2(api, (\'cifar100\'      , \'x-valid\'), (\'cifar100\'      , \'x-test\'  ) , vis_save_dir, \'BN0\', \'BN0-OTHER-CIFAR100.pdf\', (0, 100,10), 250)\n  show_nas_sharing_w_v2(api, (\'ImageNet16-120\', \'x-valid\'), (\'ImageNet16-120\', \'x-test\'  ) , vis_save_dir, \'BN0\', \'BN0-OTHER-ImageNet.pdf\', (0, 100,10), 250)\n\n  show_nas_sharing_w(api, \'cifar10-valid\' , \'x-valid\' , vis_save_dir, \'BN0\', \'BN0-XX-CIFAR010-VALID.pdf\', (0, 100,10), 250)\n  show_nas_sharing_w(api, \'cifar10\'       , \'ori-test\', vis_save_dir, \'BN0\', \'BN0-XX-CIFAR010-TEST.pdf\' , (0, 100,10), 250)\n  import pdb; pdb.set_trace()\n  """"""\n  for x_maxs in [50, 250]:\n    show_nas_sharing_w(api, \'cifar10-valid\' , \'x-valid\' , vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n    show_nas_sharing_w(api, \'cifar10\'       , \'ori-test\', vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n    show_nas_sharing_w(api, \'cifar100\'      , \'x-valid\' , vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n    show_nas_sharing_w(api, \'cifar100\'      , \'x-test\'  , vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n    show_nas_sharing_w(api, \'ImageNet16-120\', \'x-valid\' , vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n    show_nas_sharing_w(api, \'ImageNet16-120\', \'x-test\'  , vis_save_dir, \'nas-plot.pdf\', (0, 100,10), x_maxs)\n  \n  show_nas_sharing_w_v2(api, (\'cifar10-valid\' , \'x-valid\'), (\'cifar10\'       , \'ori-test\') , vis_save_dir, \'DARTS-CIFAR010.pdf\', (0, 100,10), 50)\n  just_show(api)\n  plot_results_nas(api, \'cifar10-valid\' , \'x-valid\' , vis_save_dir, \'nas-com.pdf\', (85,95, 1))\n  plot_results_nas(api, \'cifar10\'       , \'ori-test\', vis_save_dir, \'nas-com.pdf\', (85,95, 1))\n  plot_results_nas(api, \'cifar100\'      , \'x-valid\' , vis_save_dir, \'nas-com.pdf\', (55,75, 3))\n  plot_results_nas(api, \'cifar100\'      , \'x-test\'  , vis_save_dir, \'nas-com.pdf\', (55,75, 3))\n  plot_results_nas(api, \'ImageNet16-120\', \'x-valid\' , vis_save_dir, \'nas-com.pdf\', (35,50, 3))\n  plot_results_nas(api, \'ImageNet16-120\', \'x-test\'  , vis_save_dir, \'nas-com.pdf\', (35,50, 3))\n  """"""\n'"
exps/NAS-Bench-201/xshape-file.py,2,"b""###############################################################\n# NAS-Bench-201, ICLR 2020 (https://arxiv.org/abs/2001.00326) #\n###############################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020.01           #\n###############################################################\n# Usage: python exps/NAS-Bench-201/xshape-file.py --mode check\n###############################################################\nimport os, sys, time, torch, argparse\nfrom typing import List, Text, Dict, Any\nfrom shutil import copyfile\nfrom collections import defaultdict\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import dict2config, load_config\nfrom procedures   import bench_evaluate_for_seed\nfrom procedures   import get_machine_info\nfrom datasets     import get_datasets\nfrom log_utils    import Logger, AverageMeter, time_string, convert_secs2time\n\n\ndef obtain_valid_ckp(save_dir: Text, total: int):\n  possible_seeds = [777, 888]\n  seed2ckps = defaultdict(list)\n  miss2ckps = defaultdict(list)\n  for i in range(total):\n    for seed in possible_seeds:\n      path = os.path.join(save_dir, 'arch-{:06d}-seed-{:04d}.pth'.format(i, seed))\n      if os.path.exists(path):\n        seed2ckps[seed].append(i)\n      else:\n        miss2ckps[seed].append(i)\n  for seed, xlist in seed2ckps.items():\n    print('[{:}] [seed={:}] has {:}/{:}'.format(save_dir, seed, len(xlist), total))\n  return dict(seed2ckps), dict(miss2ckps)\n    \n\ndef copy_data(source_dir, target_dir, meta_path):\n  target_dir = Path(target_dir)\n  target_dir.mkdir(parents=True, exist_ok=True)\n  miss2ckps = torch.load(meta_path)['miss2ckps']\n  s2t = {}\n  for seed, xlist in miss2ckps.items():\n    for i in xlist:\n      file_name = 'arch-{:06d}-seed-{:04d}.pth'.format(i, seed)\n      source_path = os.path.join(source_dir, file_name)\n      target_path = os.path.join(target_dir, file_name)\n      if os.path.exists(source_path):\n        s2t[source_path] = target_path\n  print('Map from {:} to {:}, find {:} missed ckps.'.format(source_dir, target_dir, len(s2t)))\n  for s, t in s2t.items():\n    copyfile(s, t)\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser(description='NAS-Bench-X', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--mode',        type=str, required=True, choices=['check', 'copy'], help='The script mode.')\n  parser.add_argument('--save_dir',    type=str, default='output/NAS-BENCH-202', help='Folder to save checkpoints and log.')\n  parser.add_argument('--check_N',     type=int, default=32768,  help='For safety.')\n  # use for train the model\n  args = parser.parse_args()\n  possible_configs = ['01', '12', '90']\n  if args.mode == 'check':\n    for config in possible_configs:\n      cur_save_dir = '{:}/raw-data-{:}'.format(args.save_dir, config)\n      seed2ckps, miss2ckps = obtain_valid_ckp(cur_save_dir, args.check_N)\n      torch.save(dict(seed2ckps=seed2ckps, miss2ckps=miss2ckps), '{:}/meta-{:}.pth'.format(args.save_dir, config))\n  elif args.mode == 'copy':\n    for config in possible_configs:\n      cur_save_dir = '{:}/raw-data-{:}'.format(args.save_dir, config)\n      cur_copy_dir = '{:}/copy-{:}'.format(args.save_dir, config)\n      cur_meta_path = '{:}/meta-{:}.pth'.format(args.save_dir, config)\n      if os.path.exists(cur_meta_path):\n        copy_data(cur_save_dir, cur_copy_dir, cur_meta_path)\n      else:\n        print('Do not find : {:}'.format(cur_meta_path))\n  else:\n    raise ValueError('invalid mode : {:}'.format(args.mode))\n"""
exps/NAS-Bench-201/xshapes.py,16,"b'###############################################################\n# NAS-Bench-201, ICLR 2020 (https://arxiv.org/abs/2001.00326) #\n###############################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08           #\n###############################################################\nimport os, sys, time, torch, argparse\nfrom typing import List, Text, Dict, Any\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import dict2config, load_config\nfrom procedures   import bench_evaluate_for_seed\nfrom procedures   import get_machine_info\nfrom datasets     import get_datasets\nfrom log_utils    import Logger, AverageMeter, time_string, convert_secs2time\n\n\ndef evaluate_all_datasets(channels: Text, datasets: List[Text], xpaths: List[Text],\n                          splits: List[Text], config_path: Text, seed: int, workers: int, logger):\n  machine_info = get_machine_info()\n  all_infos = {\'info\': machine_info}\n  all_dataset_keys = []\n  # look all the dataset\n  for dataset, xpath, split in zip(datasets, xpaths, splits):\n    # the train and valid data\n    train_data, valid_data, xshape, class_num = get_datasets(dataset, xpath, -1)\n    # load the configuration\n    if dataset == \'cifar10\' or dataset == \'cifar100\':\n      split_info  = load_config(\'configs/nas-benchmark/cifar-split.txt\', None, None)\n    elif dataset.startswith(\'ImageNet16\'):\n      split_info  = load_config(\'configs/nas-benchmark/{:}-split.txt\'.format(dataset), None, None)\n    else:\n      raise ValueError(\'invalid dataset : {:}\'.format(dataset))\n    config = load_config(config_path, dict(class_num=class_num, xshape=xshape), logger)\n    # check whether use the splitted validation set\n    if bool(split):\n      assert dataset == \'cifar10\'\n      ValLoaders = {\'ori-test\': torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)}\n      assert len(train_data) == len(split_info.train) + len(split_info.valid), \'invalid length : {:} vs {:} + {:}\'.format(len(train_data), len(split_info.train), len(split_info.valid))\n      train_data_v2 = deepcopy(train_data)\n      train_data_v2.transform = valid_data.transform\n      valid_data = train_data_v2\n      # data loader\n      train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(split_info.train), num_workers=workers, pin_memory=True)\n      valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(split_info.valid), num_workers=workers, pin_memory=True)\n      ValLoaders[\'x-valid\'] = valid_loader\n    else:\n      # data loader\n      train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, shuffle=True , num_workers=workers, pin_memory=True)\n      valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n      if dataset == \'cifar10\':\n        ValLoaders = {\'ori-test\': valid_loader}\n      elif dataset == \'cifar100\':\n        cifar100_splits = load_config(\'configs/nas-benchmark/cifar100-test-split.txt\', None, None)\n        ValLoaders = {\'ori-test\': valid_loader,\n                      \'x-valid\' : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xvalid), num_workers=workers, pin_memory=True),\n                      \'x-test\'  : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xtest ), num_workers=workers, pin_memory=True)\n                     }\n      elif dataset == \'ImageNet16-120\':\n        imagenet16_splits = load_config(\'configs/nas-benchmark/imagenet-16-120-test-split.txt\', None, None)\n        ValLoaders = {\'ori-test\': valid_loader,\n                      \'x-valid\' : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet16_splits.xvalid), num_workers=workers, pin_memory=True),\n                      \'x-test\'  : torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet16_splits.xtest ), num_workers=workers, pin_memory=True)\n                     }\n      else:\n        raise ValueError(\'invalid dataset : {:}\'.format(dataset))\n\n    dataset_key = \'{:}\'.format(dataset)\n    if bool(split): dataset_key = dataset_key + \'-valid\'\n    logger.log(\'Evaluate ||||||| {:10s} ||||||| Train-Num={:}, Valid-Num={:}, Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(dataset_key, len(train_data), len(valid_data), len(train_loader), len(valid_loader), config.batch_size))\n    logger.log(\'Evaluate ||||||| {:10s} ||||||| Config={:}\'.format(dataset_key, config))\n    for key, value in ValLoaders.items():\n      logger.log(\'Evaluate ---->>>> {:10s} with {:} batchs\'.format(key, len(value)))\n    # arch-index= 9930, arch=|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n    # this genotype is the architecture with the highest accuracy on CIFAR-100 validation set\n    genotype = \'|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\'\n    arch_config = dict2config(dict(name=\'infer.shape.tiny\', channels=channels, genotype=genotype, num_classes=class_num), None)\n    results = bench_evaluate_for_seed(arch_config, config, train_loader, ValLoaders, seed, logger)\n    all_infos[dataset_key] = results\n    all_dataset_keys.append( dataset_key )\n  all_infos[\'all_dataset_keys\'] = all_dataset_keys\n  return all_infos\n\n\ndef main(save_dir: Path, workers: int, datasets: List[Text], xpaths: List[Text],\n         splits: List[int], seeds: List[int], nets: List[str], opt_config: Dict[Text, Any],\n         to_evaluate_indexes: tuple, cover_mode: bool):\n\n  log_dir = save_dir / \'logs\'\n  log_dir.mkdir(parents=True, exist_ok=True)\n  logger = Logger(str(log_dir), os.getpid(), False)\n\n  logger.log(\'xargs : seeds      = {:}\'.format(seeds))\n  logger.log(\'xargs : cover_mode = {:}\'.format(cover_mode))\n  logger.log(\'-\' * 100)\n\n  logger.log(\n    \'Start evaluating range =: {:06d} - {:06d}\'.format(min(to_evaluate_indexes), max(to_evaluate_indexes))\n   +\'({:} in total) / {:06d} with cover-mode={:}\'.format(len(to_evaluate_indexes), len(nets), cover_mode))\n  for i, (dataset, xpath, split) in enumerate(zip(datasets, xpaths, splits)):\n    logger.log(\n      \'--->>> Evaluate {:}/{:} : dataset={:9s}, path={:}, split={:}\'.format(i, len(datasets), dataset, xpath, split))\n  logger.log(\'--->>> optimization config : {:}\'.format(opt_config))\n  #to_evaluate_indexes = list(range(srange[0], srange[1] + 1))\n\n  start_time, epoch_time = time.time(), AverageMeter()\n  for i, index in enumerate(to_evaluate_indexes):\n    channelstr = nets[index]\n    logger.log(\'\\n{:} evaluate {:06d}/{:06d} ({:06d}/{:06d})-th arch [seeds={:}] {:}\'.format(time_string(), i,\n                       len(to_evaluate_indexes), index, len(nets), seeds, \'-\' * 15))\n    logger.log(\'{:} {:} {:}\'.format(\'-\' * 15, channelstr, \'-\' * 15))\n\n    # test this arch on different datasets with different seeds\n    has_continue = False\n    for seed in seeds:\n      to_save_name = save_dir / \'arch-{:06d}-seed-{:04d}.pth\'.format(index, seed)\n      if to_save_name.exists():\n        if cover_mode:\n          logger.log(\'Find existing file : {:}, remove it before evaluation\'.format(to_save_name))\n          os.remove(str(to_save_name))\n        else:\n          logger.log(\'Find existing file : {:}, skip this evaluation\'.format(to_save_name))\n          has_continue = True\n          continue\n      results = evaluate_all_datasets(channelstr, datasets, xpaths, splits, opt_config, seed, workers, logger)\n      torch.save(results, to_save_name)\n      logger.log(\'\\n{:} evaluate {:06d}/{:06d} ({:06d}/{:06d})-th arch [seeds={:}]  ===>>> {:}\'.format(time_string(), i,\n                    len(to_evaluate_indexes), index, len(nets), seeds, to_save_name))\n    # measure elapsed time\n    if not has_continue: epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    need_time = \'Time Left: {:}\'.format(convert_secs2time(epoch_time.avg * (len(to_evaluate_indexes) - i - 1), True))\n    logger.log(\'This arch costs : {:}\'.format(convert_secs2time(epoch_time.val, True)))\n    logger.log(\'{:}\'.format(\'*\' * 100))\n    logger.log(\'{:}   {:74s}   {:}\'.format(\'*\' * 10, \'{:06d}/{:06d} ({:06d}/{:06d})-th done, left {:}\'.format(i, len(\n      to_evaluate_indexes), index, len(nets), need_time), \'*\' * 10))\n    logger.log(\'{:}\'.format(\'*\' * 100))\n\n  logger.close()\n\n\ndef traverse_net(candidates: List[int], N: int):\n  nets = [\'\']\n  for i in range(N):\n    new_nets = []\n    for net in nets:\n      for C in candidates:\n        new_nets.append(str(C) if net == \'\' else ""{:}:{:}"".format(net,C))\n    nets = new_nets\n  return nets\n\n\ndef filter_indexes(xlist, mode, save_dir, seeds):\n  all_indexes = []\n  for index in xlist:\n    if mode == \'cover\':\n      all_indexes.append(index)\n    else:\n      for seed in seeds:\n        temp_path = save_dir / \'arch-{:06d}-seed-{:04d}.pth\'.format(index, seed)\n        if not temp_path.exists():\n          all_indexes.append(index)\n          break\n  print(\'{:} [FILTER-INDEXES] : there are {:}/{:} architectures in total\'.format(time_string(), len(all_indexes), len(xlist)))\n\n  SLURM_PROCID, SLURM_NTASKS = \'SLURM_PROCID\', \'SLURM_NTASKS\'\n  if SLURM_PROCID in os.environ and  SLURM_NTASKS in os.environ:  # run on the slurm\n    proc_id, ntasks = int(os.environ[SLURM_PROCID]), int(os.environ[SLURM_NTASKS])\n    assert 0 <= proc_id < ntasks, \'invalid proc_id {:} vs ntasks {:}\'.format(proc_id, ntasks)\n    scales = [int(float(i)/ntasks*len(all_indexes)) for i in range(ntasks)] + [len(all_indexes)]\n    per_job = []\n    for i in range(ntasks):\n      xs, xe = min(max(scales[i],0), len(all_indexes)-1), min(max(scales[i+1]-1,0), len(all_indexes)-1)\n      per_job.append((xs, xe))\n    for i, srange in enumerate(per_job):\n      print(\'  -->> {:2d}/{:02d} : {:}\'.format(i, ntasks, srange))\n    current_range = per_job[proc_id]\n    all_indexes = [all_indexes[i] for i in range(current_range[0], current_range[1]+1)]\n    # set the device id\n    device = proc_id % torch.cuda.device_count()\n    torch.cuda.set_device(device)\n    print(\'  set the device id = {:}\'.format(device))\n  print(\'{:} [FILTER-INDEXES] : after filtering there are {:} architectures in total\'.format(time_string(), len(all_indexes)))\n  return all_indexes\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(description=\'NAS-Bench-X\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument(\'--mode\',        type=str, required=True, choices=[\'new\', \'cover\'], help=\'The script mode.\')\n  parser.add_argument(\'--save_dir\',    type=str, default=\'output/NAS-BENCH-202\', help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--candidateC\',  type=int, nargs=\'+\', default=[8, 16, 24, 32, 40, 48, 56, 64], help=\'.\')\n  parser.add_argument(\'--num_layers\',  type=int, default=5,      help=\'The number of layers in a network.\')\n  parser.add_argument(\'--check_N\',     type=int, default=32768,  help=\'For safety.\')\n  # use for train the model\n  parser.add_argument(\'--workers\',     type=int, default=8,      help=\'The number of data loading workers (default: 2)\')\n  parser.add_argument(\'--srange\' ,     type=str, required=True,  help=\'The range of models to be evaluated\')\n  parser.add_argument(\'--datasets\',    type=str, nargs=\'+\',      help=\'The applied datasets.\')\n  parser.add_argument(\'--xpaths\',      type=str, nargs=\'+\',      help=\'The root path for this dataset.\')\n  parser.add_argument(\'--splits\',      type=int, nargs=\'+\',      help=\'The root path for this dataset.\')\n  parser.add_argument(\'--hyper\',       type=str, default=\'12\', choices=[\'01\', \'12\', \'90\'], help=\'The tag for hyper-parameters.\')\n  parser.add_argument(\'--seeds\'  ,     type=int, nargs=\'+\',      help=\'The range of models to be evaluated\')\n  args = parser.parse_args()\n\n  nets = traverse_net(args.candidateC, args.num_layers)\n  if len(nets) != args.check_N: raise ValueError(\'Pre-num-check failed : {:} vs {:}\'.format(len(nets), args.check_N))\n\n  opt_config = \'./configs/nas-benchmark/hyper-opts/{:}E.config\'.format(args.hyper)\n  if not os.path.isfile(opt_config): raise ValueError(\'{:} is not a file.\'.format(opt_config))\n  save_dir = Path(args.save_dir) / \'raw-data-{:}\'.format(args.hyper)\n  save_dir.mkdir(parents=True, exist_ok=True)\n  if not isinstance(args.srange, str):\n    raise ValueError(\'Invalid scheme for {:}\'.format(args.srange))\n  srangestr = """".join(args.srange.split())\n  to_evaluate_indexes = set()\n  for srange in srangestr.split(\',\'):\n    srange = srange.split(\'-\')\n    if len(srange) != 2: raise ValueError(\'invalid srange : {:}\'.format(srange))\n    assert len(srange[0]) == len(srange[1]) == 5, \'invalid srange : {:}\'.format(srange)\n    srange = (int(srange[0]), int(srange[1]))\n    if not (0 <= srange[0] <= srange[1] < args.check_N):\n      raise ValueError(\'{:} vs {:} vs {:}\'.format(srange[0], srange[1], args.check_N))\n    for i in range(srange[0], srange[1]+1):\n      to_evaluate_indexes.add(i)\n\n  assert len(args.seeds) > 0, \'invalid length of seeds args: {:}\'.format(args.seeds)\n  if not (len(args.datasets) == len(args.xpaths) == len(args.splits)):\n    raise ValueError(\'invalid infos : {:} vs {:} vs {:}\'.format(len(args.datasets), len(args.xpaths), len(args.splits)))\n  assert args.workers > 0, \'invalid number of workers : {:}\'.format(args.workers)\n\n  target_indexes = filter_indexes(to_evaluate_indexes, args.mode, save_dir, args.seeds)\n  \n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled = True\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads(args.workers)\n\n  main(save_dir, args.workers, args.datasets, args.xpaths, args.splits, tuple(args.seeds), nets, opt_config, target_indexes, args.mode == \'cover\')\n\n'"
exps/algos/BOHB.py,8,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n###################################################################\n# BOHB: Robust and Efficient Hyperparameter Optimization at Scale #\n# required to install hpbandster ##################################\n# bash ./scripts-search/algos/BOHB.sh -1         ##################\n###################################################################\nimport os, sys, time, random, argparse\nfrom copy import deepcopy\nfrom pathlib import Path\nimport torch\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config\nfrom datasets     import get_datasets, SearchDataset\nfrom procedures   import prepare_seed, prepare_logger\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom nas_201_api  import NASBench201API as API\nfrom models       import CellStructure, get_search_spaces\n# BOHB: Robust and Efficient Hyperparameter Optimization at Scale, ICML 2018\nimport ConfigSpace\nfrom hpbandster.optimizers.bohb import BOHB\nimport hpbandster.core.nameserver as hpns\nfrom hpbandster.core.worker import Worker\n\n\ndef get_configuration_space(max_nodes, search_space):\n  cs = ConfigSpace.ConfigurationSpace()\n  #edge2index   = {}\n  for i in range(1, max_nodes):\n    for j in range(i):\n      node_str = \'{:}<-{:}\'.format(i, j)\n      cs.add_hyperparameter(ConfigSpace.CategoricalHyperparameter(node_str, search_space))\n  return cs\n\n\ndef config2structure_func(max_nodes):\n  def config2structure(config):\n    genotypes = []\n    for i in range(1, max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = \'{:}<-{:}\'.format(i, j)\n        op_name = config[node_str]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return CellStructure( genotypes )\n  return config2structure\n\n\nclass MyWorker(Worker):\n\n  def __init__(self, *args, convert_func=None, dataname=None, nas_bench=None, time_budget=None, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.convert_func   = convert_func\n    self._dataname      = dataname\n    self._nas_bench     = nas_bench\n    self.time_budget    = time_budget\n    self.seen_archs     = []\n    self.sim_cost_time  = 0\n    self.real_cost_time = 0\n    self.is_end         = False\n\n  def get_the_best(self):\n    assert len(self.seen_archs) > 0\n    best_index, best_acc = -1, None\n    for arch_index in self.seen_archs:\n      info = self._nas_bench.get_more_info(arch_index, self._dataname, None, True, True)\n      vacc = info[\'valid-accuracy\']\n      if best_acc is None or best_acc < vacc:\n        best_acc = vacc\n        best_index = arch_index\n    assert best_index != -1\n    return best_index\n\n  def compute(self, config, budget, **kwargs):\n    start_time = time.time()\n    structure  = self.convert_func( config )\n    arch_index = self._nas_bench.query_index_by_arch( structure )\n    info       = self._nas_bench.get_more_info(arch_index, self._dataname, None, True, True)\n    cur_time   = info[\'train-all-time\'] + info[\'valid-per-time\']\n    cur_vacc   = info[\'valid-accuracy\']\n    self.real_cost_time += (time.time() - start_time)\n    if self.sim_cost_time + cur_time <= self.time_budget and not self.is_end:\n      self.sim_cost_time += cur_time\n      self.seen_archs.append( arch_index )\n      return ({\'loss\': 100 - float(cur_vacc),\n               \'info\': {\'seen-arch\'     : len(self.seen_archs),\n                        \'sim-test-time\' : self.sim_cost_time,\n                        \'current-arch\'  : arch_index}\n            })\n    else:\n      self.is_end = True\n      return ({\'loss\': 100,\n               \'info\': {\'seen-arch\'     : len(self.seen_archs),\n                        \'sim-test-time\' : self.sim_cost_time,\n                        \'current-arch\'  : None}\n            })\n\n\ndef main(xargs, nas_bench):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  if xargs.dataset == \'cifar10\':\n    dataname = \'cifar10-valid\'\n  else:\n    dataname = xargs.dataset\n  if xargs.data_path is not None:\n    train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n    split_Fpath = \'configs/nas-benchmark/cifar-split.txt\'\n    cifar_split = load_config(split_Fpath, None, None)\n    train_split, valid_split = cifar_split.train, cifar_split.valid\n    logger.log(\'Load split file from {:}\'.format(split_Fpath))\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n    # To split data\n    train_data_v2 = deepcopy(train_data)\n    train_data_v2.transform = valid_data.transform\n    valid_data    = train_data_v2\n    search_data   = SearchDataset(xargs.dataset, train_data, train_split, valid_split)\n    # data loader\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split) , num_workers=xargs.workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=xargs.workers, pin_memory=True)\n    logger.log(\'||||||| {:10s} ||||||| Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(train_loader), len(valid_loader), config.batch_size))\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': train_loader, \'valid_loader\': valid_loader}\n  else:\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, None, logger)\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': None, \'valid_loader\': None}\n\n  # nas dataset load\n  assert xargs.arch_nas_dataset is not None and os.path.isfile(xargs.arch_nas_dataset)\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  cs = get_configuration_space(xargs.max_nodes, search_space)\n\n  config2structure = config2structure_func(xargs.max_nodes)\n  hb_run_id = \'0\'\n\n  NS = hpns.NameServer(run_id=hb_run_id, host=\'localhost\', port=0)\n  ns_host, ns_port = NS.start()\n  num_workers = 1\n\n  #nas_bench = AANASBenchAPI(xargs.arch_nas_dataset)\n  #logger.log(\'{:} Create NAS-BENCH-API DONE\'.format(time_string()))\n  workers = []\n  for i in range(num_workers):\n    w = MyWorker(nameserver=ns_host, nameserver_port=ns_port, convert_func=config2structure, dataname=dataname, nas_bench=nas_bench, time_budget=xargs.time_budget, run_id=hb_run_id, id=i)\n    w.run(background=True)\n    workers.append(w)\n\n  start_time = time.time()\n  bohb = BOHB(configspace=cs,\n            run_id=hb_run_id,\n            eta=3, min_budget=12, max_budget=200,\n            nameserver=ns_host,\n            nameserver_port=ns_port,\n            num_samples=xargs.num_samples,\n            random_fraction=xargs.random_fraction, bandwidth_factor=xargs.bandwidth_factor,\n            ping_interval=10, min_bandwidth=xargs.min_bandwidth)\n  \n  results = bohb.run(xargs.n_iters, min_n_workers=num_workers)\n\n  bohb.shutdown(shutdown_workers=True)\n  NS.shutdown()\n\n  real_cost_time = time.time() - start_time\n\n  id2config = results.get_id2config_mapping()\n  incumbent = results.get_incumbent_id()\n  logger.log(\'Best found configuration: {:} within {:.3f} s\'.format(id2config[incumbent][\'config\'], real_cost_time))\n  best_arch = config2structure( id2config[incumbent][\'config\'] )\n\n  info = nas_bench.query_by_arch( best_arch )\n  if info is None: logger.log(\'Did not find this architecture : {:}.\'.format(best_arch))\n  else           : logger.log(\'{:}\'.format(info))\n  logger.log(\'-\'*100)\n\n  logger.log(\'workers : {:.1f}s with {:} archs\'.format(workers[0].time_budget, len(workers[0].seen_archs)))\n  logger.close()\n  return logger.log_dir, nas_bench.query_index_by_arch( best_arch ), real_cost_time\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Regularized Evolution Algorithm"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--time_budget\',        type=int,   help=\'The total time cost budge for searching (in seconds).\')\n  # BOHB\n  parser.add_argument(\'--strategy\', default=""sampling"",  type=str, nargs=\'?\', help=\'optimization strategy for the acquisition function\')\n  parser.add_argument(\'--min_bandwidth\',    default=.3,  type=float, nargs=\'?\', help=\'minimum bandwidth for KDE\')\n  parser.add_argument(\'--num_samples\',      default=64,  type=int, nargs=\'?\', help=\'number of samples for the acquisition function\')\n  parser.add_argument(\'--random_fraction\',  default=.33, type=float, nargs=\'?\', help=\'fraction of random configurations\')\n  parser.add_argument(\'--bandwidth_factor\', default=3,   type=int, nargs=\'?\', help=\'factor multiplied to the bandwidth\')\n  parser.add_argument(\'--n_iters\',          default=100, type=int, nargs=\'?\', help=\'number of iterations for optimization method\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  #if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  if args.arch_nas_dataset is None or not os.path.isfile(args.arch_nas_dataset):\n    nas_bench = None\n  else:\n    print (\'{:} build NAS-Benchmark-API from {:}\'.format(time_string(), args.arch_nas_dataset))\n    nas_bench = API(args.arch_nas_dataset)\n  if args.rand_seed < 0:\n    save_dir, all_indexes, num, all_times = None, [], 500, []\n    for i in range(num):\n      print (\'{:} : {:03d}/{:03d}\'.format(time_string(), i, num))\n      args.rand_seed = random.randint(1, 100000)\n      save_dir, index, ctime = main(args, nas_bench)\n      all_indexes.append( index ) \n      all_times.append( ctime )\n    print (\'\\n average time : {:.3f} s\'.format(sum(all_times)/len(all_times)))\n    torch.save(all_indexes, save_dir / \'results.pth\')\n  else:\n    main(args, nas_bench)\n'"
exps/algos/DARTS-V1.py,12,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n########################################################\n# DARTS: Differentiable Architecture Search, ICLR 2019 #\n########################################################\nimport sys, time, random, argparse\nfrom copy import deepcopy\nimport torch\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef search_func(xloader, network, criterion, scheduler, w_optimizer, a_optimizer, epoch_str, print_freq, logger, gradient_clip):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.train()\n  end = time.time()\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    w_optimizer.zero_grad()\n    _, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    if gradient_clip > 0: torch.nn.utils.clip_grad_norm_(network.parameters(), gradient_clip)\n    w_optimizer.step()\n    # record\n    base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(),  base_inputs.size(0))\n    base_top1.update  (base_prec1.item(), base_inputs.size(0))\n    base_top5.update  (base_prec5.item(), base_inputs.size(0))\n\n    # update the architecture-weight\n    a_optimizer.zero_grad()\n    _, logits = network(arch_inputs)\n    arch_loss = criterion(logits, arch_targets)\n    arch_loss.backward()\n    a_optimizer.step()\n    # record\n    arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n    arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n    arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n    arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*SEARCH* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n      Astr = \'Arch [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=arch_losses, top1=arch_top1, top5=arch_top5)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr + \' \' + Astr)\n  return base_losses.avg, base_top1.avg, base_top5.avg\n\n\ndef valid_func(xloader, network, criterion):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.eval()\n  end = time.time()\n  with torch.no_grad():\n    for step, (arch_inputs, arch_targets) in enumerate(xloader):\n      arch_targets = arch_targets.cuda(non_blocking=True)\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # prediction\n      _, logits = network(arch_inputs)\n      arch_loss = criterion(logits, arch_targets)\n      # record\n      arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n      arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n      arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n      arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n  return arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  #config_path = \'configs/nas-benchmark/algos/DARTS.config\'\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  search_loader, _, valid_loader = get_nas_search_loaders(train_data, valid_data, xargs.dataset, \'configs/nas-benchmark/\', config.batch_size, xargs.workers)\n  logger.log(\'||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  if xargs.model_config is None:\n    model_config = dict2config({\'name\': \'DARTS-V1\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                                \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                                \'space\'    : search_space,\n                                \'affine\'   : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  else:\n    model_config = load_config(xargs.model_config, {\'num_classes\': class_num, \'space\'    : search_space,\n                                                    \'affine\'     : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  search_model = get_cell_based_tiny_net(model_config)\n  logger.log(\'search-model :\\n{:}\'.format(search_model))\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.get_weights(), config)\n  a_optimizer = torch.optim.Adam(search_model.get_alphas(), lr=xargs.arch_learning_rate, betas=(0.5, 0.999), weight_decay=xargs.arch_weight_decay)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'a-optimizer : {:}\'.format(a_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  flop, param  = get_model_infos(search_model, xshape)\n  #logger.log(\'{:}\'.format(search_model))\n  logger.log(\'FLOP = {:.2f} M, Params = {:.2f} MB\'.format(flop, param))\n  if xargs.arch_nas_dataset is None:\n    api = None\n  else:\n    api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    a_optimizer.load_state_dict ( checkpoint[\'a_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, genotypes = 0, {\'best\': -1}, {-1: search_model.genotype()}\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, LR={:}\'.format(epoch_str, need_time, min(w_scheduler.get_lr())))\n\n    search_w_loss, search_w_top1, search_w_top5 = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, a_optimizer, epoch_str, xargs.print_freq, logger, xargs.gradient_clip)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n    valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    logger.log(\'[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    # check the best accuracy\n    valid_accuracies[epoch] = valid_a_top1\n    if valid_a_top1 > valid_accuracies[\'best\']:\n      valid_accuracies[\'best\'] = valid_a_top1\n      genotypes[\'best\']        = search_model.genotype()\n      find_best = True\n    else: find_best = False\n\n    genotypes[epoch] = search_model.genotype()\n    logger.log(\'<<<--->>> The {:}-th epoch : {:}\'.format(epoch_str, genotypes[epoch]))\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'search_model\': search_model.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'a_optimizer\' : a_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    if find_best:\n      logger.log(\'<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\'.format(epoch_str, valid_a_top1))\n      copy_checkpoint(model_base_path, model_best_path, logger)\n    with torch.no_grad():\n      #logger.log(\'arch-parameters :\\n{:}\'.format( nn.functional.softmax(search_model.arch_parameters, dim=-1).cpu() ))\n      logger.log(\'{:}\'.format(search_model.show_alphas()))\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*100)\n  logger.log(\'DARTS-V1 : run {:} epochs, cost {:.1f} s, last-geno is {:}.\'.format(total_epoch, search_time.sum, genotypes[total_epoch-1]))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(genotypes[total_epoch-1]) ))\n  logger.close()\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""DARTS first order"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The config path.\')\n  parser.add_argument(\'--model_config\',       type=str,   help=\'The path of the model configuration. When this arg is set, it will cover max_nodes / channels / num_cells.\')\n  parser.add_argument(\'--gradient_clip\',      type=float, default=5, help=\'\')\n  # architecture leraning rate\n  parser.add_argument(\'--arch_learning_rate\', type=float, default=3e-4, help=\'learning rate for arch encoding\')\n  parser.add_argument(\'--arch_weight_decay\',  type=float, default=1e-3, help=\'weight decay for arch encoding\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/DARTS-V2.py,19,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n########################################################\n# DARTS: Differentiable Architecture Search, ICLR 2019 #\n########################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef _concat(xs):\n  return torch.cat([x.view(-1) for x in xs])\n\n\ndef _hessian_vector_product(vector, network, criterion, base_inputs, base_targets, r=1e-2):\n  R = r / _concat(vector).norm()\n  for p, v in zip(network.module.get_weights(), vector):\n    p.data.add_(R, v)\n  _, logits = network(base_inputs)\n  loss = criterion(logits, base_targets)\n  grads_p = torch.autograd.grad(loss, network.module.get_alphas())\n\n  for p, v in zip(network.module.get_weights(), vector):\n    p.data.sub_(2*R, v)\n  _, logits = network(base_inputs)\n  loss = criterion(logits, base_targets)\n  grads_n = torch.autograd.grad(loss, network.module.get_alphas())\n\n  for p, v in zip(network.module.get_weights(), vector):\n    p.data.add_(R, v)\n  return [(x-y).div_(2*R) for x, y in zip(grads_p, grads_n)]\n\n\ndef backward_step_unrolled(network, criterion, base_inputs, base_targets, w_optimizer, arch_inputs, arch_targets):\n  # _compute_unrolled_model\n  _, logits = network(base_inputs)\n  loss = criterion(logits, base_targets)\n  LR, WD, momentum = w_optimizer.param_groups[0][\'lr\'], w_optimizer.param_groups[0][\'weight_decay\'], w_optimizer.param_groups[0][\'momentum\']\n  with torch.no_grad():\n    theta = _concat(network.module.get_weights())\n    try:\n      moment = _concat(w_optimizer.state[v][\'momentum_buffer\'] for v in network.module.get_weights())\n      moment = moment.mul_(momentum)\n    except:\n      moment = torch.zeros_like(theta)\n    dtheta = _concat(torch.autograd.grad(loss, network.module.get_weights())) + WD*theta\n    params = theta.sub(LR, moment+dtheta)\n  unrolled_model = deepcopy(network)\n  model_dict  = unrolled_model.state_dict()\n  new_params, offset = {}, 0\n  for k, v in network.named_parameters():\n    if \'arch_parameters\' in k: continue\n    v_length = np.prod(v.size())\n    new_params[k] = params[offset: offset+v_length].view(v.size())\n    offset += v_length\n  model_dict.update(new_params)\n  unrolled_model.load_state_dict(model_dict)\n\n  unrolled_model.zero_grad()\n  _, unrolled_logits = unrolled_model(arch_inputs)\n  unrolled_loss = criterion(unrolled_logits, arch_targets)\n  unrolled_loss.backward()\n\n  dalpha = unrolled_model.module.arch_parameters.grad\n  vector = [v.grad.data for v in unrolled_model.module.get_weights()]\n  [implicit_grads] = _hessian_vector_product(vector, network, criterion, base_inputs, base_targets)\n  \n  dalpha.data.sub_(LR, implicit_grads.data)\n\n  if network.module.arch_parameters.grad is None:\n    network.module.arch_parameters.grad = deepcopy( dalpha )\n  else:\n    network.module.arch_parameters.grad.data.copy_( dalpha.data )\n  return unrolled_loss.detach(), unrolled_logits.detach()\n  \n\ndef search_func(xloader, network, criterion, scheduler, w_optimizer, a_optimizer, epoch_str, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.train()\n  end = time.time()\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    # update the architecture-weight\n    a_optimizer.zero_grad()\n    arch_loss, arch_logits = backward_step_unrolled(network, criterion, base_inputs, base_targets, w_optimizer, arch_inputs, arch_targets)\n    a_optimizer.step()\n    # record\n    arch_prec1, arch_prec5 = obtain_accuracy(arch_logits.data, arch_targets.data, topk=(1, 5))\n    arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n    arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n    arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n    \n    # update the weights\n    w_optimizer.zero_grad()\n    _, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    torch.nn.utils.clip_grad_norm_(network.parameters(), 5)\n    w_optimizer.step()\n    # record\n    base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(),  base_inputs.size(0))\n    base_top1.update  (base_prec1.item(), base_inputs.size(0))\n    base_top5.update  (base_prec5.item(), base_inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*SEARCH* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n      Astr = \'Arch [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=arch_losses, top1=arch_top1, top5=arch_top5)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr + \' \' + Astr)\n  return base_losses.avg, base_top1.avg, base_top5.avg\n\n\ndef valid_func(xloader, network, criterion):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.eval()\n  end = time.time()\n  with torch.no_grad():\n    for step, (arch_inputs, arch_targets) in enumerate(xloader):\n      arch_targets = arch_targets.cuda(non_blocking=True)\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # prediction\n      _, logits = network(arch_inputs)\n      arch_loss = criterion(logits, arch_targets)\n      # record\n      arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n      arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n      arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n      arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n  return arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  search_loader, _, valid_loader = get_nas_search_loaders(train_data, valid_data, xargs.dataset, \'configs/nas-benchmark/\', config.batch_size, xargs.workers)\n  logger.log(\'||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  model_config = dict2config({\'name\': \'DARTS-V2\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                              \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                              \'space\'    : search_space,\n                              \'affine\'   : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  search_model = get_cell_based_tiny_net(model_config)\n  logger.log(\'search-model :\\n{:}\'.format(search_model))\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.get_weights(), config)\n  a_optimizer = torch.optim.Adam(search_model.get_alphas(), lr=xargs.arch_learning_rate, betas=(0.5, 0.999), weight_decay=xargs.arch_weight_decay)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'a-optimizer : {:}\'.format(a_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  flop, param  = get_model_infos(search_model, xshape)\n  #logger.log(\'{:}\'.format(search_model))\n  logger.log(\'FLOP = {:.2f} M, Params = {:.2f} MB\'.format(flop, param))\n  if xargs.arch_nas_dataset is None:\n    api = None\n  else:\n    api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    a_optimizer.load_state_dict ( checkpoint[\'a_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, genotypes = 0, {\'best\': -1}, {-1: search_model.genotype()}\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    min_LR    = min(w_scheduler.get_lr())\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, LR={:}\'.format(epoch_str, need_time, min_LR))\n\n    search_w_loss, search_w_top1, search_w_top5 = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, a_optimizer, epoch_str, xargs.print_freq, logger)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n    valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    logger.log(\'[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    # check the best accuracy\n    valid_accuracies[epoch] = valid_a_top1\n    if valid_a_top1 > valid_accuracies[\'best\']:\n      valid_accuracies[\'best\'] = valid_a_top1\n      genotypes[\'best\']        = search_model.genotype()\n      find_best = True\n    else: find_best = False\n\n    genotypes[epoch] = search_model.genotype()\n    logger.log(\'<<<--->>> The {:}-th epoch : {:}\'.format(epoch_str, genotypes[epoch]))\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'search_model\': search_model.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'a_optimizer\' : a_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    if find_best:\n      logger.log(\'<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\'.format(epoch_str, valid_a_top1))\n      copy_checkpoint(model_base_path, model_best_path, logger)\n    with torch.no_grad():\n      logger.log(\'arch-parameters :\\n{:}\'.format( nn.functional.softmax(search_model.arch_parameters, dim=-1).cpu() ))\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*100)\n  # check the performance from the architecture dataset\n  logger.log(\'DARTS-V2 : run {:} epochs, cost {:.1f} s, last-geno is {:}.\'.format(total_epoch, search_time.sum, genotypes[total_epoch-1]))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(genotypes[total_epoch-1]) ))\n  logger.close()\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""DARTS Second Order"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The config path.\')\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  # architecture leraning rate\n  parser.add_argument(\'--arch_learning_rate\', type=float, default=3e-4, help=\'learning rate for arch encoding\')\n  parser.add_argument(\'--arch_weight_decay\',  type=float, default=1e-3, help=\'weight decay for arch encoding\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/ENAS.py,16,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n##########################################################################\n# Efficient Neural Architecture Search via Parameters Sharing, ICML 2018 #\n##########################################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef train_shared_cnn(xloader, shared_cnn, controller, criterion, scheduler, optimizer, epoch_str, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  losses, top1s, top5s, xend = AverageMeter(), AverageMeter(), AverageMeter(), time.time()\n  \n  shared_cnn.train()\n  controller.eval()\n\n  for step, (inputs, targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    targets = targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - xend)\n    \n    with torch.no_grad():\n      _, _, sampled_arch = controller()\n\n    optimizer.zero_grad()\n    shared_cnn.module.update_arch(sampled_arch)\n    _, logits = shared_cnn(inputs)\n    loss      = criterion(logits, targets)\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(shared_cnn.parameters(), 5)\n    optimizer.step()\n    # record\n    prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n    losses.update(loss.item(),  inputs.size(0))\n    top1s.update (prec1.item(), inputs.size(0))\n    top5s.update (prec5.item(), inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - xend)\n    xend = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*Train-Shared-CNN* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'[Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=losses, top1=top1s, top5=top5s)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr)\n  return losses.avg, top1s.avg, top5s.avg\n\n\ndef train_controller(xloader, shared_cnn, controller, criterion, optimizer, config, epoch_str, print_freq, logger):\n  # config. (containing some necessary arg)\n  #   baseline: The baseline score (i.e. average val_acc) from the previous epoch\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  GradnormMeter, LossMeter, ValAccMeter, EntropyMeter, BaselineMeter, RewardMeter, xend = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), time.time()\n  \n  shared_cnn.eval()\n  controller.train()\n  controller.zero_grad()\n  #for step, (inputs, targets) in enumerate(xloader):\n  loader_iter = iter(xloader)\n  for step in range(config.ctl_train_steps * config.ctl_num_aggre):\n    try:\n      inputs, targets = next(loader_iter)\n    except:\n      loader_iter = iter(xloader)\n      inputs, targets = next(loader_iter)\n    targets = targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - xend)\n    \n    log_prob, entropy, sampled_arch = controller()\n    with torch.no_grad():\n      shared_cnn.module.update_arch(sampled_arch)\n      _, logits = shared_cnn(inputs)\n      val_top1, val_top5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n      val_top1  = val_top1.view(-1) / 100\n    reward = val_top1 + config.ctl_entropy_w * entropy\n    if config.baseline is None:\n      baseline = val_top1\n    else:\n      baseline = config.baseline - (1 - config.ctl_bl_dec) * (config.baseline - reward)\n   \n    loss = -1 * log_prob * (reward - baseline)\n    \n    # account\n    RewardMeter.update(reward.item())\n    BaselineMeter.update(baseline.item())\n    ValAccMeter.update(val_top1.item()*100)\n    LossMeter.update(loss.item())\n    EntropyMeter.update(entropy.item())\n  \n    # Average gradient over controller_num_aggregate samples\n    loss = loss / config.ctl_num_aggre\n    loss.backward(retain_graph=True)\n\n    # measure elapsed time\n    batch_time.update(time.time() - xend)\n    xend = time.time()\n    if (step+1) % config.ctl_num_aggre == 0:\n      grad_norm = torch.nn.utils.clip_grad_norm_(controller.parameters(), 5.0)\n      GradnormMeter.update(grad_norm)\n      optimizer.step()\n      controller.zero_grad()\n\n    if step % print_freq == 0:\n      Sstr = \'*Train-Controller* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, config.ctl_train_steps * config.ctl_num_aggre)\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'[Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Reward {reward.val:.2f} ({reward.avg:.2f})] Baseline {basel.val:.2f} ({basel.avg:.2f})\'.format(loss=LossMeter, top1=ValAccMeter, reward=RewardMeter, basel=BaselineMeter)\n      Estr = \'Entropy={:.4f} ({:.4f})\'.format(EntropyMeter.val, EntropyMeter.avg)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr + \' \' + Estr)\n\n  return LossMeter.avg, ValAccMeter.avg, BaselineMeter.avg, RewardMeter.avg, baseline.item()\n\n\ndef get_best_arch(controller, shared_cnn, xloader, n_samples=10):\n  with torch.no_grad():\n    controller.eval()\n    shared_cnn.eval()\n    archs, valid_accs = [], []\n    loader_iter = iter(xloader)\n    for i in range(n_samples):\n      try:\n        inputs, targets = next(loader_iter)\n      except:\n        loader_iter = iter(xloader)\n        inputs, targets = next(loader_iter)\n\n      _, _, sampled_arch = controller()\n      arch = shared_cnn.module.update_arch(sampled_arch)\n      _, logits = shared_cnn(inputs)\n      val_top1, val_top5 = obtain_accuracy(logits.cpu().data, targets.data, topk=(1, 5))\n\n      archs.append( arch )\n      valid_accs.append( val_top1.item() )\n\n    best_idx = np.argmax(valid_accs)\n    best_arch, best_valid_acc = archs[best_idx], valid_accs[best_idx]\n    return best_arch, best_valid_acc\n\n\ndef valid_func(xloader, network, criterion):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.eval()\n  end = time.time()\n  with torch.no_grad():\n    for step, (arch_inputs, arch_targets) in enumerate(xloader):\n      arch_targets = arch_targets.cuda(non_blocking=True)\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # prediction\n      _, logits = network(arch_inputs)\n      arch_loss = criterion(logits, arch_targets)\n      # record\n      arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n      arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n      arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n      arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n  return arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, test_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  logger.log(\'use config from : {:}\'.format(xargs.config_path))\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  _, train_loader, valid_loader = get_nas_search_loaders(train_data, test_data, xargs.dataset, \'configs/nas-benchmark/\', config.batch_size, xargs.workers)\n  # since ENAS will train the controller on valid-loader, we need to use train transformation for valid-loader\n  valid_loader.dataset.transform = deepcopy(train_loader.dataset.transform)\n  if hasattr(valid_loader.dataset, \'transforms\'):\n    valid_loader.dataset.transforms = deepcopy(train_loader.dataset.transforms)\n  # data loader\n  logger.log(\'||||||| {:10s} ||||||| Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(train_loader), len(valid_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  model_config = dict2config({\'name\': \'ENAS\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                              \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                              \'space\'    : search_space,\n                              \'affine\'   : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  shared_cnn = get_cell_based_tiny_net(model_config)\n  controller = shared_cnn.create_controller()\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(shared_cnn.parameters(), config)\n  a_optimizer = torch.optim.Adam(controller.parameters(), lr=config.controller_lr, betas=config.controller_betas, eps=config.controller_eps)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'a-optimizer : {:}\'.format(a_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  #flop, param  = get_model_infos(shared_cnn, xshape)\n  #logger.log(\'{:}\'.format(shared_cnn))\n  #logger.log(\'FLOP = {:.2f} M, Params = {:.2f} MB\'.format(flop, param))\n  logger.log(\'search-space : {:}\'.format(search_space))\n  if xargs.arch_nas_dataset is None:\n    api = None\n  else:\n    api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n  shared_cnn, controller, criterion = torch.nn.DataParallel(shared_cnn).cuda(), controller.cuda(), criterion.cuda()\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    baseline    = checkpoint[\'baseline\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    shared_cnn.load_state_dict( checkpoint[\'shared_cnn\'] )\n    controller.load_state_dict( checkpoint[\'controller\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    a_optimizer.load_state_dict ( checkpoint[\'a_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, genotypes, baseline = 0, {\'best\': -1}, {}, None\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, LR={:}, baseline={:}\'.format(epoch_str, need_time, min(w_scheduler.get_lr()), baseline))\n\n    cnn_loss, cnn_top1, cnn_top5 = train_shared_cnn(train_loader, shared_cnn, controller, criterion, w_scheduler, w_optimizer, epoch_str, xargs.print_freq, logger)\n    logger.log(\'[{:}] shared-cnn : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, cnn_loss, cnn_top1, cnn_top5))\n    ctl_loss, ctl_acc, ctl_baseline, ctl_reward, baseline \\\n                                 = train_controller(valid_loader, shared_cnn, controller, criterion, a_optimizer, \\\n                                                        dict2config({\'baseline\': baseline,\n                                                                     \'ctl_train_steps\': xargs.controller_train_steps, \'ctl_num_aggre\': xargs.controller_num_aggregate,\n                                                                     \'ctl_entropy_w\': xargs.controller_entropy_weight, \n                                                                     \'ctl_bl_dec\'   : xargs.controller_bl_dec}, None), \\\n                                                        epoch_str, xargs.print_freq, logger)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] controller : loss={:.2f}, accuracy={:.2f}%, baseline={:.2f}, reward={:.2f}, current-baseline={:.4f}, time-cost={:.1f} s\'.format(epoch_str, ctl_loss, ctl_acc, ctl_baseline, ctl_reward, baseline, search_time.sum))\n    best_arch, _ = get_best_arch(controller, shared_cnn, valid_loader)\n    shared_cnn.module.update_arch(best_arch)\n    _, best_valid_acc, _ = valid_func(valid_loader, shared_cnn, criterion)\n\n    genotypes[epoch] = best_arch\n    # check the best accuracy\n    valid_accuracies[epoch] = best_valid_acc\n    if best_valid_acc > valid_accuracies[\'best\']:\n      valid_accuracies[\'best\'] = best_valid_acc\n      genotypes[\'best\']        = best_arch\n      find_best = True\n    else: find_best = False\n\n    logger.log(\'<<<--->>> The {:}-th epoch : {:}\'.format(epoch_str, genotypes[epoch]))\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'baseline\'    : baseline,\n                \'shared_cnn\'  : shared_cnn.state_dict(),\n                \'controller\'  : controller.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'a_optimizer\' : a_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    if find_best:\n      logger.log(\'<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\'.format(epoch_str, best_valid_acc))\n      copy_checkpoint(model_base_path, model_best_path, logger)\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*100)\n  logger.log(\'During searching, the best architecture is {:}\'.format(genotypes[\'best\']))\n  logger.log(\'Its accuracy is {:.2f}%\'.format(valid_accuracies[\'best\']))\n  logger.log(\'Randomly select {:} architectures and select the best.\'.format(xargs.controller_num_samples))\n  start_time = time.time()\n  final_arch, _ = get_best_arch(controller, shared_cnn, valid_loader, xargs.controller_num_samples)\n  search_time.update(time.time() - start_time)\n  shared_cnn.module.update_arch(final_arch)\n  final_loss, final_top1, final_top5 = valid_func(valid_loader, shared_cnn, criterion)\n  logger.log(\'The Selected Final Architecture : {:}\'.format(final_arch))\n  logger.log(\'Loss={:.3f}, Accuracy@1={:.2f}%, Accuracy@5={:.2f}%\'.format(final_loss, final_top1, final_top5))\n  logger.log(\'ENAS : run {:} epochs, cost {:.1f} s, last-geno is {:}.\'.format(total_epoch, search_time.sum, final_arch))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(final_arch) ))\n  logger.close()\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""ENAS"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The config file to train ENAS.\')\n  parser.add_argument(\'--controller_train_steps\',    type=int,     help=\'.\')\n  parser.add_argument(\'--controller_num_aggregate\',  type=int,     help=\'.\')\n  parser.add_argument(\'--controller_entropy_weight\', type=float,   help=\'The weight for the entropy of the controller.\')\n  parser.add_argument(\'--controller_bl_dec\'        , type=float,   help=\'.\')\n  parser.add_argument(\'--controller_num_samples\'   , type=int,     help=\'.\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/GDAS.py,11,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n###########################################################################\n# Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019 #\n###########################################################################\nimport sys, time, random, argparse\nfrom copy import deepcopy\nimport torch\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef search_func(xloader, network, criterion, scheduler, w_optimizer, a_optimizer, epoch_str, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.train()\n  end = time.time()\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    w_optimizer.zero_grad()\n    _, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    torch.nn.utils.clip_grad_norm_(network.parameters(), 5)\n    w_optimizer.step()\n    # record\n    base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(),  base_inputs.size(0))\n    base_top1.update  (base_prec1.item(), base_inputs.size(0))\n    base_top5.update  (base_prec5.item(), base_inputs.size(0))\n\n    # update the architecture-weight\n    a_optimizer.zero_grad()\n    _, logits = network(arch_inputs)\n    arch_loss = criterion(logits, arch_targets)\n    arch_loss.backward()\n    a_optimizer.step()\n    # record\n    arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n    arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n    arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n    arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*SEARCH* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n      Astr = \'Arch [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=arch_losses, top1=arch_top1, top5=arch_top5)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr + \' \' + Astr)\n  return base_losses.avg, base_top1.avg, base_top5.avg, arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  #config_path = \'configs/nas-benchmark/algos/GDAS.config\'\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  search_loader, _, valid_loader = get_nas_search_loaders(train_data, valid_data, xargs.dataset, \'configs/nas-benchmark/\', config.batch_size, xargs.workers)\n  logger.log(\'||||||| {:10s} ||||||| Search-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(search_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  if xargs.model_config is None:\n    model_config = dict2config({\'name\': \'GDAS\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                                \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                                \'space\'    : search_space,\n                                \'affine\'   : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  else:\n    model_config = load_config(xargs.model_config, {\'num_classes\': class_num, \'space\'    : search_space,\n                                                    \'affine\'     : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  search_model = get_cell_based_tiny_net(model_config)\n  logger.log(\'search-model :\\n{:}\'.format(search_model))\n  logger.log(\'model-config : {:}\'.format(model_config))\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.get_weights(), config)\n  a_optimizer = torch.optim.Adam(search_model.get_alphas(), lr=xargs.arch_learning_rate, betas=(0.5, 0.999), weight_decay=xargs.arch_weight_decay)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'a-optimizer : {:}\'.format(a_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  flop, param  = get_model_infos(search_model, xshape)\n  logger.log(\'FLOP = {:.2f} M, Params = {:.2f} MB\'.format(flop, param))\n  logger.log(\'search-space [{:} ops] : {:}\'.format(len(search_space), search_space))\n  if xargs.arch_nas_dataset is None:\n    api = None\n  else:\n    api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    a_optimizer.load_state_dict ( checkpoint[\'a_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, genotypes = 0, {\'best\': -1}, {-1: search_model.genotype()}\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    search_model.set_tau( xargs.tau_max - (xargs.tau_max-xargs.tau_min) * epoch / (total_epoch-1) )\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, tau={:}, LR={:}\'.format(epoch_str, need_time, search_model.get_tau(), min(w_scheduler.get_lr())))\n\n    search_w_loss, search_w_top1, search_w_top5, valid_a_loss , valid_a_top1 , valid_a_top5 \\\n              = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, a_optimizer, epoch_str, xargs.print_freq, logger)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n    logger.log(\'[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss , valid_a_top1 , valid_a_top5 ))\n    # check the best accuracy\n    valid_accuracies[epoch] = valid_a_top1\n    if valid_a_top1 > valid_accuracies[\'best\']:\n      valid_accuracies[\'best\'] = valid_a_top1\n      genotypes[\'best\']        = search_model.genotype()\n      find_best = True\n    else: find_best = False\n\n    genotypes[epoch] = search_model.genotype()\n    logger.log(\'<<<--->>> The {:}-th epoch : {:}\'.format(epoch_str, genotypes[epoch]))\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'search_model\': search_model.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'a_optimizer\' : a_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    if find_best:\n      logger.log(\'<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\'.format(epoch_str, valid_a_top1))\n      copy_checkpoint(model_base_path, model_best_path, logger)\n    with torch.no_grad():\n      logger.log(\'{:}\'.format(search_model.show_alphas()))\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*100)\n  # check the performance from the architecture dataset\n  logger.log(\'GDAS : run {:} epochs, cost {:.1f} s, last-geno is {:}.\'.format(total_epoch, search_time.sum, genotypes[total_epoch-1]))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(genotypes[total_epoch-1]) ))\n  logger.close()\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""GDAS"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The path of the configuration.\')\n  parser.add_argument(\'--model_config\',       type=str,   help=\'The path of the model configuration. When this arg is set, it will cover max_nodes / channels / num_cells.\')\n  # architecture leraning rate\n  parser.add_argument(\'--arch_learning_rate\', type=float, default=3e-4, help=\'learning rate for arch encoding\')\n  parser.add_argument(\'--arch_weight_decay\',  type=float, default=1e-3, help=\'weight decay for arch encoding\')\n  parser.add_argument(\'--tau_min\',            type=float,               help=\'The minimum tau for Gumbel\')\n  parser.add_argument(\'--tau_max\',            type=float,               help=\'The maximum tau for Gumbel\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/RANDOM-NAS.py,11,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n##############################################################################\n# Random Search and Reproducibility for Neural Architecture Search, UAI 2019 #\n##############################################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef search_func(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.train()\n  end = time.time()\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    network.module.random_genotype( True )\n    w_optimizer.zero_grad()\n    _, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    nn.utils.clip_grad_norm_(network.parameters(), 5)\n    w_optimizer.step()\n    # record\n    base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(),  base_inputs.size(0))\n    base_top1.update  (base_prec1.item(), base_inputs.size(0))\n    base_top5.update  (base_prec5.item(), base_inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*SEARCH* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr)\n  return base_losses.avg, base_top1.avg, base_top5.avg\n\n\ndef valid_func(xloader, network, criterion):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  network.eval()\n  end = time.time()\n  with torch.no_grad():\n    for step, (arch_inputs, arch_targets) in enumerate(xloader):\n      arch_targets = arch_targets.cuda(non_blocking=True)\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # prediction\n\n      network.module.random_genotype( True )\n      _, logits = network(arch_inputs)\n      arch_loss = criterion(logits, arch_targets)\n      # record\n      arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n      arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n      arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n      arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n  return arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef search_find_best(xloader, network, n_samples):\n  with torch.no_grad():\n    network.eval()\n    archs, valid_accs = [], []\n    #print (\'obtain the top-{:} architectures\'.format(n_samples))\n    loader_iter = iter(xloader)\n    for i in range(n_samples):\n      arch = network.module.random_genotype( True )\n      try:\n        inputs, targets = next(loader_iter)\n      except:\n        loader_iter = iter(xloader)\n        inputs, targets = next(loader_iter)\n\n      _, logits = network(inputs)\n      val_top1, val_top5 = obtain_accuracy(logits.cpu().data, targets.data, topk=(1, 5))\n\n      archs.append( arch )\n      valid_accs.append( val_top1.item() )\n\n    best_idx = np.argmax(valid_accs)\n    best_arch, best_valid_acc = archs[best_idx], valid_accs[best_idx]\n    return best_arch, best_valid_acc\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  search_loader, _, valid_loader = get_nas_search_loaders(train_data, valid_data, xargs.dataset, \'configs/nas-benchmark/\', \\\n                                        (config.batch_size, config.test_batch_size), xargs.workers)\n  logger.log(\'||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  model_config = dict2config({\'name\': \'RANDOM\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                              \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                              \'space\'    : search_space,\n                              \'affine\'   : False, \'track_running_stats\': bool(xargs.track_running_stats)}, None)\n  search_model = get_cell_based_tiny_net(model_config)\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.parameters(), config)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  if xargs.arch_nas_dataset is None: api = None\n  else                             : api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    start_epoch, valid_accuracies, genotypes = 0, {\'best\': -1}, {}\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, LR={:}\'.format(epoch_str, need_time, min(w_scheduler.get_lr())))\n\n    # selected_arch = search_find_best(valid_loader, network, criterion, xargs.select_num)\n    search_w_loss, search_w_top1, search_w_top5 = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, epoch_str, xargs.print_freq, logger)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n    valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    logger.log(\'[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    cur_arch, cur_valid_acc = search_find_best(valid_loader, network, xargs.select_num)\n    logger.log(\'[{:}] find-the-best : {:}, accuracy@1={:.2f}%\'.format(epoch_str, cur_arch, cur_valid_acc))\n    genotypes[epoch] = cur_arch\n    # check the best accuracy\n    valid_accuracies[epoch] = valid_a_top1\n    if valid_a_top1 > valid_accuracies[\'best\']:\n      valid_accuracies[\'best\'] = valid_a_top1\n      find_best = True\n    else: find_best = False\n\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'search_model\': search_model.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    if find_best:\n      logger.log(\'<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\'.format(epoch_str, valid_a_top1))\n      copy_checkpoint(model_base_path, model_best_path, logger)\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  logger.log(\'\\n\' + \'-\'*200)\n  logger.log(\'Pre-searching costs {:.1f} s\'.format(search_time.sum))\n  start_time = time.time()\n  best_arch, best_acc = search_find_best(valid_loader, network, xargs.select_num)\n  search_time.update(time.time() - start_time)\n  logger.log(\'RANDOM-NAS finds the best one : {:} with accuracy={:.2f}%, with {:.1f} s.\'.format(best_arch, best_acc, search_time.sum))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(best_arch) ))\n  logger.close()\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Random search for NAS."")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The path to the configuration.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--select_num\',         type=int,   help=\'The number of selected architectures to evaluate.\')\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/RANDOM.py,9,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n##############################################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np, collections\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, SearchDataset\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_search_spaces\nfrom nas_201_api  import NASBench201API as API\nfrom R_EA         import train_and_eval, random_architecture_func\n\n\ndef main(xargs, nas_bench):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  if xargs.dataset == \'cifar10\':\n    dataname = \'cifar10-valid\'\n  else:\n    dataname = xargs.dataset\n  if xargs.data_path is not None:\n    train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n    split_Fpath = \'configs/nas-benchmark/cifar-split.txt\'\n    cifar_split = load_config(split_Fpath, None, None)\n    train_split, valid_split = cifar_split.train, cifar_split.valid\n    logger.log(\'Load split file from {:}\'.format(split_Fpath))\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n    # To split data\n    train_data_v2 = deepcopy(train_data)\n    train_data_v2.transform = valid_data.transform\n    valid_data    = train_data_v2\n    search_data   = SearchDataset(xargs.dataset, train_data, train_split, valid_split)\n    # data loader\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split) , num_workers=xargs.workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=xargs.workers, pin_memory=True)\n    logger.log(\'||||||| {:10s} ||||||| Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(train_loader), len(valid_loader), config.batch_size))\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': train_loader, \'valid_loader\': valid_loader}\n  else:\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, None, logger)\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': None, \'valid_loader\': None}\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  random_arch = random_architecture_func(xargs.max_nodes, search_space)\n  #x =random_arch() ; y = mutate_arch(x)\n  x_start_time = time.time()\n  logger.log(\'{:} use nas_bench : {:}\'.format(time_string(), nas_bench))\n  best_arch, best_acc, total_time_cost, history = None, -1, 0, []\n  #for idx in range(xargs.random_num):\n  while total_time_cost < xargs.time_budget:\n    arch = random_arch()\n    accuracy, cost_time = train_and_eval(arch, nas_bench, extra_info, dataname)\n    if total_time_cost + cost_time > xargs.time_budget: break\n    else: total_time_cost += cost_time\n    history.append(arch)\n    if best_arch is None or best_acc < accuracy:\n      best_acc, best_arch = accuracy, arch\n    logger.log(\'[{:03d}] : {:} : accuracy = {:.2f}%\'.format(len(history), arch, accuracy))\n  logger.log(\'{:} best arch is {:}, accuracy = {:.2f}%, visit {:} archs with {:.1f} s (real-cost = {:.3f} s).\'.format(time_string(), best_arch, best_acc, len(history), total_time_cost, time.time()-x_start_time))\n  \n  info = nas_bench.query_by_arch( best_arch )\n  if info is None: logger.log(\'Did not find this architecture : {:}.\'.format(best_arch))\n  else           : logger.log(\'{:}\'.format(info))\n  logger.log(\'-\'*100)\n  logger.close()\n  return logger.log_dir, nas_bench.query_index_by_arch( best_arch )\n\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Regularized Evolution Algorithm"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  #parser.add_argument(\'--random_num\',         type=int,   help=\'The number of random selected architectures.\')\n  parser.add_argument(\'--time_budget\',        type=int,   help=\'The total time cost budge for searching (in seconds).\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  #if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  if args.arch_nas_dataset is None or not os.path.isfile(args.arch_nas_dataset):\n    nas_bench = None\n  else:\n    print (\'{:} build NAS-Benchmark-API from {:}\'.format(time_string(), args.arch_nas_dataset))\n    nas_bench = API(args.arch_nas_dataset)\n  if args.rand_seed < 0:\n    save_dir, all_indexes, num = None, [], 500\n    for i in range(num):\n      print (\'{:} : {:03d}/{:03d}\'.format(time_string(), i, num))\n      args.rand_seed = random.randint(1, 100000)\n      save_dir, index = main(args, nas_bench)\n      all_indexes.append( index )\n    torch.save(all_indexes, save_dir / \'results.pth\')\n  else:\n    main(args, nas_bench)\n'"
exps/algos/R_EA.py,9,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n##################################################################\n# Regularized Evolution for Image Classifier Architecture Search #\n##################################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np, collections\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, SearchDataset\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom nas_201_api  import NASBench201API as API\nfrom models       import CellStructure, get_search_spaces\n\n\nclass Model(object):\n\n  def __init__(self):\n    self.arch = None\n    self.accuracy = None\n    \n  def __str__(self):\n    """"""Prints a readable version of this bitstring.""""""\n    return \'{:}\'.format(self.arch)\n  \n\n# This function is to mimic the training and evaluatinig procedure for a single architecture `arch`.\n# The time_cost is calculated as the total training time for a few (e.g., 12 epochs) plus the evaluation time for one epoch.\n# For use_012_epoch_training = True, the architecture is trained for 12 epochs, with LR being decaded from 0.1 to 0.\n#       In this case, the LR schedular is converged.\n# For use_012_epoch_training = False, the architecture is planed to be trained for 200 epochs, but we early stop its procedure.\n#       \ndef train_and_eval(arch, nas_bench, extra_info, dataname=\'cifar10-valid\', use_012_epoch_training=True):\n\n  if use_012_epoch_training and nas_bench is not None:\n    arch_index = nas_bench.query_index_by_arch( arch )\n    assert arch_index >= 0, \'can not find this arch : {:}\'.format(arch)\n    info = nas_bench.get_more_info(arch_index, dataname, None, True)\n    valid_acc, time_cost = info[\'valid-accuracy\'], info[\'train-all-time\'] + info[\'valid-per-time\']\n    #_, valid_acc = info.get_metrics(\'cifar10-valid\', \'x-valid\' , 25, True) # use the validation accuracy after 25 training epochs\n  elif not use_012_epoch_training and nas_bench is not None:\n    # Please contact me if you want to use the following logic, because it has some potential issues.\n    # Please use `use_012_epoch_training=False` for cifar10 only.\n    # It did return values for cifar100 and ImageNet16-120, but it has some potential issues. (Please email me for more details)\n    arch_index, nepoch = nas_bench.query_index_by_arch( arch ), 25\n    assert arch_index >= 0, \'can not find this arch : {:}\'.format(arch)\n    xoinfo = nas_bench.get_more_info(arch_index, \'cifar10-valid\', None, True)\n    xocost = nas_bench.get_cost_info(arch_index, \'cifar10-valid\', False)\n    info = nas_bench.get_more_info(arch_index, dataname, nepoch, False, True) # use the validation accuracy after 25 training epochs, which is used in our ICLR submission (not the camera ready).\n    cost = nas_bench.get_cost_info(arch_index, dataname, False)\n    # The following codes are used to estimate the time cost.\n    # When we build NAS-Bench-201, architectures are trained on different machines and we can not use that time record.\n    # When we create checkpoints for converged_LR, we run all experiments on 1080Ti, and thus the time for each architecture can be fairly compared.\n    nums = {\'ImageNet16-120-train\': 151700, \'ImageNet16-120-valid\': 3000,\n            \'cifar10-valid-train\' : 25000,  \'cifar10-valid-valid\' : 25000,\n            \'cifar100-train\'      : 50000,  \'cifar100-valid\'      : 5000}\n    estimated_train_cost = xoinfo[\'train-per-time\'] / nums[\'cifar10-valid-train\'] * nums[\'{:}-train\'.format(dataname)] / xocost[\'latency\'] * cost[\'latency\'] * nepoch\n    estimated_valid_cost = xoinfo[\'valid-per-time\'] / nums[\'cifar10-valid-valid\'] * nums[\'{:}-valid\'.format(dataname)] / xocost[\'latency\'] * cost[\'latency\']\n    try:\n      valid_acc, time_cost = info[\'valid-accuracy\'], estimated_train_cost + estimated_valid_cost\n    except:\n      valid_acc, time_cost = info[\'valtest-accuracy\'], estimated_train_cost + estimated_valid_cost\n  else:\n    # train a model from scratch.\n    raise ValueError(\'NOT IMPLEMENT YET\')\n  return valid_acc, time_cost\n\n\ndef random_architecture_func(max_nodes, op_names):\n  # return a random architecture\n  def random_architecture():\n    genotypes = []\n    for i in range(1, max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = \'{:}<-{:}\'.format(i, j)\n        op_name  = random.choice( op_names )\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return CellStructure( genotypes )\n  return random_architecture\n\n\ndef mutate_arch_func(op_names):\n  """"""Computes the architecture for a child of the given parent architecture.\n  The parent architecture is cloned and mutated to produce the child architecture. The child architecture is mutated by randomly switch one operation to another.\n  """"""\n  def mutate_arch_func(parent_arch):\n    child_arch = deepcopy( parent_arch )\n    node_id = random.randint(0, len(child_arch.nodes)-1)\n    node_info = list( child_arch.nodes[node_id] )\n    snode_id = random.randint(0, len(node_info)-1)\n    xop = random.choice( op_names )\n    while xop == node_info[snode_id][0]:\n      xop = random.choice( op_names )\n    node_info[snode_id] = (xop, node_info[snode_id][1])\n    child_arch.nodes[node_id] = tuple( node_info )\n    return child_arch\n  return mutate_arch_func\n\n\ndef regularized_evolution(cycles, population_size, sample_size, time_budget, random_arch, mutate_arch, nas_bench, extra_info, dataname):\n  """"""Algorithm for regularized evolution (i.e. aging evolution).\n  \n  Follows ""Algorithm 1"" in Real et al. ""Regularized Evolution for Image\n  Classifier Architecture Search"".\n  \n  Args:\n    cycles: the number of cycles the algorithm should run for.\n    population_size: the number of individuals to keep in the population.\n    sample_size: the number of individuals that should participate in each tournament.\n    time_budget: the upper bound of searching cost\n\n  Returns:\n    history: a list of `Model` instances, representing all the models computed\n        during the evolution experiment.\n  """"""\n  population = collections.deque()\n  history, total_time_cost = [], 0  # Not used by the algorithm, only used to report results.\n\n  # Initialize the population with random models.\n  while len(population) < population_size:\n    model = Model()\n    model.arch = random_arch()\n    model.accuracy, time_cost = train_and_eval(model.arch, nas_bench, extra_info, dataname)\n    population.append(model)\n    history.append(model)\n    total_time_cost += time_cost\n\n  # Carry out evolution in cycles. Each cycle produces a model and removes\n  # another.\n  #while len(history) < cycles:\n  while total_time_cost < time_budget:\n    # Sample randomly chosen models from the current population.\n    start_time, sample = time.time(), []\n    while len(sample) < sample_size:\n      # Inefficient, but written this way for clarity. In the case of neural\n      # nets, the efficiency of this line is irrelevant because training neural\n      # nets is the rate-determining step.\n      candidate = random.choice(list(population))\n      sample.append(candidate)\n\n    # The parent is the best model in the sample.\n    parent = max(sample, key=lambda i: i.accuracy)\n\n    # Create the child model and store it.\n    child = Model()\n    child.arch = mutate_arch(parent.arch)\n    total_time_cost += time.time() - start_time\n    child.accuracy, time_cost = train_and_eval(child.arch, nas_bench, extra_info, dataname)\n    if total_time_cost + time_cost > time_budget: # return\n      return history, total_time_cost\n    else:\n      total_time_cost += time_cost\n    population.append(child)\n    history.append(child)\n\n    # Remove the oldest model.\n    population.popleft()\n  return history, total_time_cost\n\n\ndef main(xargs, nas_bench):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  if xargs.dataset == \'cifar10\':\n    dataname = \'cifar10-valid\'\n  else:\n    dataname = xargs.dataset\n  if xargs.data_path is not None:\n    train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n    split_Fpath = \'configs/nas-benchmark/cifar-split.txt\'\n    cifar_split = load_config(split_Fpath, None, None)\n    train_split, valid_split = cifar_split.train, cifar_split.valid\n    logger.log(\'Load split file from {:}\'.format(split_Fpath))\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n    # To split data\n    train_data_v2 = deepcopy(train_data)\n    train_data_v2.transform = valid_data.transform\n    valid_data    = train_data_v2\n    search_data   = SearchDataset(xargs.dataset, train_data, train_split, valid_split)\n    # data loader\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split) , num_workers=xargs.workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=xargs.workers, pin_memory=True)\n    logger.log(\'||||||| {:10s} ||||||| Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(train_loader), len(valid_loader), config.batch_size))\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': train_loader, \'valid_loader\': valid_loader}\n  else:\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, None, logger)\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': None, \'valid_loader\': None}\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  random_arch = random_architecture_func(xargs.max_nodes, search_space)\n  mutate_arch = mutate_arch_func(search_space)\n  #x =random_arch() ; y = mutate_arch(x)\n  x_start_time = time.time()\n  logger.log(\'{:} use nas_bench : {:}\'.format(time_string(), nas_bench))\n  logger.log(\'-\'*30 + \' start searching with the time budget of {:} s\'.format(xargs.time_budget))\n  history, total_cost = regularized_evolution(xargs.ea_cycles, xargs.ea_population, xargs.ea_sample_size, xargs.time_budget, random_arch, mutate_arch, nas_bench if args.ea_fast_by_api else None, extra_info, dataname)\n  logger.log(\'{:} regularized_evolution finish with history of {:} arch with {:.1f} s (real-cost={:.2f} s).\'.format(time_string(), len(history), total_cost, time.time()-x_start_time))\n  best_arch = max(history, key=lambda i: i.accuracy)\n  best_arch = best_arch.arch\n  logger.log(\'{:} best arch is {:}\'.format(time_string(), best_arch))\n  \n  info = nas_bench.query_by_arch( best_arch )\n  if info is None: logger.log(\'Did not find this architecture : {:}.\'.format(best_arch))\n  else           : logger.log(\'{:}\'.format(info))\n  logger.log(\'-\'*100)\n  logger.close()\n  return logger.log_dir, nas_bench.query_index_by_arch( best_arch )\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Regularized Evolution Algorithm"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--ea_cycles\',          type=int,   help=\'The number of cycles in EA.\')\n  parser.add_argument(\'--ea_population\',      type=int,   help=\'The population size in EA.\')\n  parser.add_argument(\'--ea_sample_size\',     type=int,   help=\'The sample size in EA.\')\n  parser.add_argument(\'--ea_fast_by_api\',     type=int,   help=\'Use our API to speed up the experiments or not.\')\n  parser.add_argument(\'--time_budget\',        type=int,   help=\'The total time cost budge for searching (in seconds).\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   default=-1,   help=\'manual seed\')\n  args = parser.parse_args()\n  #if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  args.ea_fast_by_api = args.ea_fast_by_api > 0\n\n  if args.arch_nas_dataset is None or not os.path.isfile(args.arch_nas_dataset):\n    nas_bench = None\n  else:\n    print (\'{:} build NAS-Benchmark-API from {:}\'.format(time_string(), args.arch_nas_dataset))\n    nas_bench = API(args.arch_nas_dataset)\n  if args.rand_seed < 0:\n    save_dir, all_indexes, num = None, [], 500\n    for i in range(num):\n      print (\'{:} : {:03d}/{:03d}\'.format(time_string(), i, num))\n      args.rand_seed = random.randint(1, 100000)\n      save_dir, index = main(args, nas_bench)\n      all_indexes.append( index )\n    torch.save(all_indexes, save_dir / \'results.pth\')\n  else:\n    main(args, nas_bench)\n'"
exps/algos/SETN.py,13,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n######################################################################################\n# One-Shot Neural Architecture Search via Self-Evaluated Template Network, ICCV 2019 #\n######################################################################################\nimport sys, time, random, argparse\nimport numpy as np\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, get_nas_search_loaders\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net, get_search_spaces\nfrom nas_201_api  import NASBench201API as API\n\n\ndef search_func(xloader, network, criterion, scheduler, w_optimizer, a_optimizer, epoch_str, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  end = time.time()\n  network.train()\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n    scheduler.update(None, 1.0 * step / len(xloader))\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    sampled_arch = network.module.dync_genotype(True)\n    network.module.set_cal_mode(\'dynamic\', sampled_arch)\n    #network.module.set_cal_mode( \'urs\' )\n    network.zero_grad()\n    _, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    w_optimizer.step()\n    # record\n    base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(),  base_inputs.size(0))\n    base_top1.update  (base_prec1.item(), base_inputs.size(0))\n    base_top5.update  (base_prec5.item(), base_inputs.size(0))\n\n    # update the architecture-weight\n    network.module.set_cal_mode( \'joint\' )\n    network.zero_grad()\n    _, logits = network(arch_inputs)\n    arch_loss = criterion(logits, arch_targets)\n    arch_loss.backward()\n    a_optimizer.step()\n    # record\n    arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n    arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n    arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n    arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if step % print_freq == 0 or step + 1 == len(xloader):\n      Sstr = \'*SEARCH* \' + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(epoch_str, step, len(xloader))\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Wstr = \'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n      Astr = \'Arch [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\'.format(loss=arch_losses, top1=arch_top1, top5=arch_top5)\n      logger.log(Sstr + \' \' + Tstr + \' \' + Wstr + \' \' + Astr)\n      #print (nn.functional.softmax(network.module.arch_parameters, dim=-1))\n      #print (network.module.arch_parameters)\n  return base_losses.avg, base_top1.avg, base_top5.avg, arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef get_best_arch(xloader, network, n_samples):\n  with torch.no_grad():\n    network.eval()\n    archs, valid_accs = network.module.return_topK(n_samples), []\n    #print (\'obtain the top-{:} architectures\'.format(n_samples))\n    loader_iter = iter(xloader)\n    for i, sampled_arch in enumerate(archs):\n      network.module.set_cal_mode(\'dynamic\', sampled_arch)\n      try:\n        inputs, targets = next(loader_iter)\n      except:\n        loader_iter = iter(xloader)\n        inputs, targets = next(loader_iter)\n\n      _, logits = network(inputs)\n      val_top1, val_top5 = obtain_accuracy(logits.cpu().data, targets.data, topk=(1, 5))\n\n      valid_accs.append(val_top1.item())\n\n    best_idx = np.argmax(valid_accs)\n    best_arch, best_valid_acc = archs[best_idx], valid_accs[best_idx]\n    return best_arch, best_valid_acc\n\n\ndef valid_func(xloader, network, criterion):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  end = time.time()\n  with torch.no_grad():\n    network.eval()\n    for step, (arch_inputs, arch_targets) in enumerate(xloader):\n      arch_targets = arch_targets.cuda(non_blocking=True)\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # prediction\n      _, logits = network(arch_inputs)\n      arch_loss = criterion(logits, arch_targets)\n      # record\n      arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n      arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n      arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n      arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n  return arch_losses.avg, arch_top1.avg, arch_top5.avg\n\n\ndef main(xargs):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n  search_loader, _, valid_loader = get_nas_search_loaders(train_data, valid_data, xargs.dataset, \'configs/nas-benchmark/\', \\\n                                        (config.batch_size, config.test_batch_size), xargs.workers)\n  logger.log(\'||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n  logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  if xargs.model_config is None:\n    model_config = dict2config(\n      dict(name=\'SETN\', C=xargs.channel, N=xargs.num_cells, max_nodes=xargs.max_nodes, num_classes=class_num,\n           space=search_space, affine=False, track_running_stats=bool(xargs.track_running_stats)), None)\n  else:\n    model_config = load_config(xargs.model_config, dict(num_classes=class_num, space=search_space, affine=False,\n                                                        track_running_stats=bool(xargs.track_running_stats)), None)\n  logger.log(\'search space : {:}\'.format(search_space))\n  search_model = get_cell_based_tiny_net(model_config)\n  \n  w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.get_weights(), config)\n  a_optimizer = torch.optim.Adam(search_model.get_alphas(), lr=xargs.arch_learning_rate, betas=(0.5, 0.999), weight_decay=xargs.arch_weight_decay)\n  logger.log(\'w-optimizer : {:}\'.format(w_optimizer))\n  logger.log(\'a-optimizer : {:}\'.format(a_optimizer))\n  logger.log(\'w-scheduler : {:}\'.format(w_scheduler))\n  logger.log(\'criterion   : {:}\'.format(criterion))\n  flop, param  = get_model_infos(search_model, xshape)\n  logger.log(\'FLOP = {:.2f} M, Params = {:.2f} MB\'.format(flop, param))\n  logger.log(\'search-space : {:}\'.format(search_space))\n  if xargs.arch_nas_dataset is None:\n    api = None\n  else:\n    api = API(xargs.arch_nas_dataset)\n  logger.log(\'{:} create API = {:} done\'.format(time_string(), api))\n\n  last_info, model_base_path, model_best_path = logger.path(\'info\'), logger.path(\'model\'), logger.path(\'best\')\n  network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n\n  if last_info.exists(): # automatically resume from previous checkpoint\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start"".format(last_info))\n    last_info   = torch.load(last_info)\n    start_epoch = last_info[\'epoch\']\n    checkpoint  = torch.load(last_info[\'last_checkpoint\'])\n    genotypes   = checkpoint[\'genotypes\']\n    valid_accuracies = checkpoint[\'valid_accuracies\']\n    search_model.load_state_dict( checkpoint[\'search_model\'] )\n    w_scheduler.load_state_dict ( checkpoint[\'w_scheduler\'] )\n    w_optimizer.load_state_dict ( checkpoint[\'w_optimizer\'] )\n    a_optimizer.load_state_dict ( checkpoint[\'a_optimizer\'] )\n    logger.log(""=> loading checkpoint of the last-info \'{:}\' start with {:}-th epoch."".format(last_info, start_epoch))\n  else:\n    logger.log(""=> do not find the last-info file : {:}"".format(last_info))\n    init_genotype, _ = get_best_arch(valid_loader, network, xargs.select_num)\n    start_epoch, valid_accuracies, genotypes = 0, {\'best\': -1}, {-1: init_genotype}\n\n  # start training\n  start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n  for epoch in range(start_epoch, total_epoch):\n    w_scheduler.update(epoch, 0.0)\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n    epoch_str = \'{:03d}-{:03d}\'.format(epoch, total_epoch)\n    logger.log(\'\\n[Search the {:}-th epoch] {:}, LR={:}\'.format(epoch_str, need_time, min(w_scheduler.get_lr())))\n\n    search_w_loss, search_w_top1, search_w_top5, search_a_loss, search_a_top1, search_a_top5 \\\n                = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, a_optimizer, epoch_str, xargs.print_freq, logger)\n    search_time.update(time.time() - start_time)\n    logger.log(\'[{:}] search [base] : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n    logger.log(\'[{:}] search [arch] : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, search_a_loss, search_a_top1, search_a_top5))\n\n    genotype, temp_accuracy = get_best_arch(valid_loader, network, xargs.select_num)\n    network.module.set_cal_mode(\'dynamic\', genotype)\n    valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    logger.log(\'[{:}] evaluate : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}% | {:}\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5, genotype))\n    #search_model.set_cal_mode(\'urs\')\n    #valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    #logger.log(\'[{:}] URS---evaluate : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    #search_model.set_cal_mode(\'joint\')\n    #valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    #logger.log(\'[{:}] JOINT-evaluate : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    #search_model.set_cal_mode(\'select\')\n    #valid_a_loss , valid_a_top1 , valid_a_top5  = valid_func(valid_loader, network, criterion)\n    #logger.log(\'[{:}] Selec-evaluate : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\'.format(epoch_str, valid_a_loss, valid_a_top1, valid_a_top5))\n    # check the best accuracy\n    valid_accuracies[epoch] = valid_a_top1\n\n    genotypes[epoch] = genotype\n    logger.log(\'<<<--->>> The {:}-th epoch : {:}\'.format(epoch_str, genotypes[epoch]))\n    # save checkpoint\n    save_path = save_checkpoint({\'epoch\' : epoch + 1,\n                \'args\'  : deepcopy(xargs),\n                \'search_model\': search_model.state_dict(),\n                \'w_optimizer\' : w_optimizer.state_dict(),\n                \'a_optimizer\' : a_optimizer.state_dict(),\n                \'w_scheduler\' : w_scheduler.state_dict(),\n                \'genotypes\'   : genotypes,\n                \'valid_accuracies\' : valid_accuracies},\n                model_base_path, logger)\n    last_info = save_checkpoint({\n          \'epoch\': epoch + 1,\n          \'args\' : deepcopy(args),\n          \'last_checkpoint\': save_path,\n          }, logger.path(\'info\'), logger)\n    with torch.no_grad():\n      logger.log(\'{:}\'.format(search_model.show_alphas()))\n    if api is not None: logger.log(\'{:}\'.format(api.query_by_arch( genotypes[epoch] )))\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n\n  # the final post procedure : count the time\n  start_time = time.time()\n  genotype, temp_accuracy = get_best_arch(valid_loader, network, xargs.select_num)\n  search_time.update(time.time() - start_time)\n  network.module.set_cal_mode(\'dynamic\', genotype)\n  valid_a_loss , valid_a_top1 , valid_a_top5 = valid_func(valid_loader, network, criterion)\n  logger.log(\'Last : the gentotype is : {:}, with the validation accuracy of {:.3f}%.\'.format(genotype, valid_a_top1))\n\n  logger.log(\'\\n\' + \'-\'*100)\n  # check the performance from the architecture dataset\n  logger.log(\'SETN : run {:} epochs, cost {:.1f} s, last-geno is {:}.\'.format(total_epoch, search_time.sum, genotype))\n  if api is not None: logger.log(\'{:}\'.format( api.query_by_arch(genotype) ))\n  logger.close()\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""SETN"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--select_num\',         type=int,   help=\'The number of selected architectures to evaluate.\')\n  parser.add_argument(\'--track_running_stats\',type=int,   choices=[0,1],help=\'Whether use track_running_stats or not in the BN layer.\')\n  parser.add_argument(\'--config_path\',        type=str,   help=\'The path of the configuration.\')\n  # architecture leraning rate\n  parser.add_argument(\'--arch_learning_rate\', type=float, default=3e-4, help=\'learning rate for arch encoding\')\n  parser.add_argument(\'--arch_weight_decay\',  type=float, default=1e-3, help=\'weight decay for arch encoding\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   help=\'manual seed\')\n  args = parser.parse_args()\n  if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  main(args)\n'"
exps/algos/reinforce.py,14,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n#####################################################################################################\n# modified from https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py #\n#####################################################################################################\nimport os, sys, time, glob, random, argparse\nimport numpy as np, collections\nfrom copy import deepcopy\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nfrom torch.distributions import Categorical\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom config_utils import load_config, dict2config, configure2str\nfrom datasets     import get_datasets, SearchDataset\nfrom procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom nas_201_api  import NASBench201API as API\nfrom models       import CellStructure, get_search_spaces\nfrom R_EA import train_and_eval\n\n\nclass Policy(nn.Module):\n\n  def __init__(self, max_nodes, search_space):\n    super(Policy, self).__init__()\n    self.max_nodes    = max_nodes\n    self.search_space = deepcopy(search_space)\n    self.edge2index   = {}\n    for i in range(1, max_nodes):\n      for j in range(i):\n        node_str = \'{:}<-{:}\'.format(i, j)\n        self.edge2index[ node_str ] = len(self.edge2index)\n    self.arch_parameters = nn.Parameter( 1e-3*torch.randn(len(self.edge2index), len(search_space)) )\n\n  def generate_arch(self, actions):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = \'{:}<-{:}\'.format(i, j)\n        op_name  = self.search_space[ actions[ self.edge2index[ node_str ] ] ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return CellStructure( genotypes )\n\n  def genotype(self):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = \'{:}<-{:}\'.format(i, j)\n        with torch.no_grad():\n          weights = self.arch_parameters[ self.edge2index[node_str] ]\n          op_name = self.search_space[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return CellStructure( genotypes )\n    \n  def forward(self):\n    alphas  = nn.functional.softmax(self.arch_parameters, dim=-1)\n    return alphas\n\n\nclass ExponentialMovingAverage(object):\n  """"""Class that maintains an exponential moving average.""""""\n\n  def __init__(self, momentum):\n    self._numerator   = 0\n    self._denominator = 0\n    self._momentum    = momentum\n\n  def update(self, value):\n    self._numerator = self._momentum * self._numerator + (1 - self._momentum) * value\n    self._denominator = self._momentum * self._denominator + (1 - self._momentum)\n\n  def value(self):\n    """"""Return the current value of the moving average""""""\n    return self._numerator / self._denominator\n\n\ndef select_action(policy):\n  probs = policy()\n  m = Categorical(probs)\n  action = m.sample()\n  #policy.saved_log_probs.append(m.log_prob(action))\n  return m.log_prob(action), action.cpu().tolist()\n\n\ndef main(xargs, nas_bench):\n  assert torch.cuda.is_available(), \'CUDA is not available.\'\n  torch.backends.cudnn.enabled   = True\n  torch.backends.cudnn.benchmark = False\n  torch.backends.cudnn.deterministic = True\n  torch.set_num_threads( xargs.workers )\n  prepare_seed(xargs.rand_seed)\n  logger = prepare_logger(args)\n\n  if xargs.dataset == \'cifar10\':\n    dataname = \'cifar10-valid\'\n  else:\n    dataname = xargs.dataset\n  if xargs.data_path is not None:\n    train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n    split_Fpath = \'configs/nas-benchmark/cifar-split.txt\'\n    cifar_split = load_config(split_Fpath, None, None)\n    train_split, valid_split = cifar_split.train, cifar_split.valid\n    logger.log(\'Load split file from {:}\'.format(split_Fpath))\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, {\'class_num\': class_num, \'xshape\': xshape}, logger)\n    # To split data\n    train_data_v2 = deepcopy(train_data)\n    train_data_v2.transform = valid_data.transform\n    valid_data    = train_data_v2\n    search_data   = SearchDataset(xargs.dataset, train_data, train_split, valid_split)\n    # data loader\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split) , num_workers=xargs.workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=xargs.workers, pin_memory=True)\n    logger.log(\'||||||| {:10s} ||||||| Train-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\'.format(xargs.dataset, len(train_loader), len(valid_loader), config.batch_size))\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n    extra_info = {\'config\': config, \'train_loader\': train_loader, \'valid_loader\': valid_loader}\n  else:\n    config_path = \'configs/nas-benchmark/algos/R-EA.config\'\n    config = load_config(config_path, None, logger)\n    extra_info = {\'config\': config, \'train_loader\': None, \'valid_loader\': None}\n    logger.log(\'||||||| {:10s} ||||||| Config={:}\'.format(xargs.dataset, config))\n  \n  \n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  policy    = Policy(xargs.max_nodes, search_space)\n  optimizer = torch.optim.Adam(policy.parameters(), lr=xargs.learning_rate)\n  #optimizer = torch.optim.SGD(policy.parameters(), lr=xargs.learning_rate)\n  eps       = np.finfo(np.float32).eps.item()\n  baseline  = ExponentialMovingAverage(xargs.EMA_momentum)\n  logger.log(\'policy    : {:}\'.format(policy))\n  logger.log(\'optimizer : {:}\'.format(optimizer))\n  logger.log(\'eps       : {:}\'.format(eps))\n\n  # nas dataset load\n  logger.log(\'{:} use nas_bench : {:}\'.format(time_string(), nas_bench))\n\n  # REINFORCE\n  # attempts = 0\n  x_start_time = time.time()\n  logger.log(\'Will start searching with time budget of {:} s.\'.format(xargs.time_budget))\n  total_steps, total_costs, trace = 0, 0, []\n  #for istep in range(xargs.RL_steps):\n  while total_costs < xargs.time_budget:\n    start_time = time.time()\n    log_prob, action = select_action( policy )\n    arch   = policy.generate_arch( action )\n    reward, cost_time = train_and_eval(arch, nas_bench, extra_info, dataname)\n    trace.append( (reward, arch) )\n    # accumulate time\n    if total_costs + cost_time < xargs.time_budget:\n      total_costs += cost_time\n    else: break\n\n    baseline.update(reward)\n    # calculate loss\n    policy_loss = ( -log_prob * (reward - baseline.value()) ).sum()\n    optimizer.zero_grad()\n    policy_loss.backward()\n    optimizer.step()\n    # accumulate time\n    total_costs += time.time() - start_time\n    total_steps += 1\n    logger.log(\'step [{:3d}] : average-reward={:.3f} : policy_loss={:.4f} : {:}\'.format(total_steps, baseline.value(), policy_loss.item(), policy.genotype()))\n    #logger.log(\'----> {:}\'.format(policy.arch_parameters))\n    #logger.log(\'\')\n\n  # best_arch = policy.genotype() # first version\n  best_arch = max(trace, key=lambda x: x[0])[1]\n  logger.log(\'REINFORCE finish with {:} steps and {:.1f} s (real cost={:.3f}).\'.format(total_steps, total_costs, time.time()-x_start_time))\n  info = nas_bench.query_by_arch( best_arch )\n  if info is None: logger.log(\'Did not find this architecture : {:}.\'.format(best_arch))\n  else           : logger.log(\'{:}\'.format(info))\n  logger.log(\'-\'*100)\n  logger.close()\n  return logger.log_dir, nas_bench.query_index_by_arch( best_arch )\n  \n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser(""Regularized Evolution Algorithm"")\n  parser.add_argument(\'--data_path\',          type=str,   help=\'Path to dataset\')\n  parser.add_argument(\'--dataset\',            type=str,   choices=[\'cifar10\', \'cifar100\', \'ImageNet16-120\'], help=\'Choose between Cifar10/100 and ImageNet-16.\')\n  # channels and number-of-cells\n  parser.add_argument(\'--search_space_name\',  type=str,   help=\'The search space name.\')\n  parser.add_argument(\'--max_nodes\',          type=int,   help=\'The maximum number of nodes.\')\n  parser.add_argument(\'--channel\',            type=int,   help=\'The number of channels.\')\n  parser.add_argument(\'--num_cells\',          type=int,   help=\'The number of cells in one stage.\')\n  parser.add_argument(\'--learning_rate\',      type=float, help=\'The learning rate for REINFORCE.\')\n  #parser.add_argument(\'--RL_steps\',           type=int,   help=\'The steps for REINFORCE.\')\n  parser.add_argument(\'--EMA_momentum\',       type=float, help=\'The momentum value for EMA.\')\n  parser.add_argument(\'--time_budget\',        type=int,   help=\'The total time cost budge for searching (in seconds).\')\n  # log\n  parser.add_argument(\'--workers\',            type=int,   default=2,    help=\'number of data loading workers (default: 2)\')\n  parser.add_argument(\'--save_dir\',           type=str,   help=\'Folder to save checkpoints and log.\')\n  parser.add_argument(\'--arch_nas_dataset\',   type=str,   help=\'The path to load the architecture dataset (tiny-nas-benchmark).\')\n  parser.add_argument(\'--print_freq\',         type=int,   help=\'print frequency (default: 200)\')\n  parser.add_argument(\'--rand_seed\',          type=int,   default=-1,   help=\'manual seed\')\n  args = parser.parse_args()\n  #if args.rand_seed is None or args.rand_seed < 0: args.rand_seed = random.randint(1, 100000)\n  if args.arch_nas_dataset is None or not os.path.isfile(args.arch_nas_dataset):\n    nas_bench = None\n  else:\n    print (\'{:} build NAS-Benchmark-API from {:}\'.format(time_string(), args.arch_nas_dataset))\n    nas_bench = API(args.arch_nas_dataset)\n  if args.rand_seed < 0:\n    save_dir, all_indexes, num = None, [], 500\n    for i in range(num):\n      print (\'{:} : {:03d}/{:03d}\'.format(time_string(), i, num))\n      args.rand_seed = random.randint(1, 100000)\n      save_dir, index = main(args, nas_bench)\n      all_indexes.append( index )\n    torch.save(all_indexes, save_dir / \'results.pth\')\n  else:\n    main(args, nas_bench)\n'"
exps/experimental/test-flops.py,0,"b""import sys, time, random, argparse\nfrom copy import deepcopy\nimport torchvision.models as models\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\n\nfrom utils import get_model_infos\n#from models.ImageNet_MobileNetV2 import MobileNetV2\nfrom torchvision.models.mobilenet import MobileNetV2\n\ndef main(width_mult):\n  # model = MobileNetV2(1001, width_mult, 32, 1280, 'InvertedResidual', 0.2)\n  model = MobileNetV2(width_mult=width_mult)\n  print(model)\n  flops, params = get_model_infos(model, (2, 3, 224, 224))\n  print('FLOPs : {:}'.format(flops))\n  print('Params : {:}'.format(params))\n  print('-'*50)\n\n\nif __name__ == '__main__':\n  main(1.0)\n  main(1.4)\n"""
exps/experimental/test-resnest.py,3,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020.06 #\n#####################################################\n# python exps/experimental/test-resnest.py\n#####################################################\nimport sys, time, torch, random, argparse\nfrom PIL     import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom copy    import deepcopy\nfrom pathlib import Path\n\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\nfrom utils        import get_model_infos\n\ntorch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n\nfor model_name, xshape in [('resnest50', (1,3,224,224)),\n                           ('resnest101', (1,3,256,256)),\n                           ('resnest200', (1,3,320,320)),\n                           ('resnest269', (1,3,416,416))]:\n  # net = torch.hub.load('zhanghang1989/ResNeSt', model_name, pretrained=True)\n  net = torch.hub.load('zhanghang1989/ResNeSt', model_name, pretrained=False)\n  print('Model : {:}, input shape : {:}'.format(model_name, xshape))\n  flops, param  = get_model_infos(net, xshape)\n  print('flops  : {:.3f}M'.format(flops))\n  print('params : {:.3f}M'.format(param))\n"""
exps/experimental/test-ww.py,0,"b""import sys, time, random, argparse\nfrom copy import deepcopy\nimport torchvision.models as models\nfrom pathlib import Path\nlib_dir = (Path(__file__).parent / '..' / '..' / 'lib').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\n\nfrom utils import weight_watcher\n\n\ndef main():\n  # model = models.vgg19_bn(pretrained=True)\n  # _, summary = weight_watcher.analyze(model, alphas=False)\n  # for key, value in summary.items():\n  #   print('{:10s} : {:}'.format(key, value))\n\n  _, summary = weight_watcher.analyze(models.vgg13(pretrained=True), alphas=False)\n  print('vgg-13 : {:}'.format(summary['lognorm']))\n  _, summary = weight_watcher.analyze(models.vgg13_bn(pretrained=True), alphas=False)\n  print('vgg-13-BN : {:}'.format(summary['lognorm']))\n  _, summary = weight_watcher.analyze(models.vgg16(pretrained=True), alphas=False)\n  print('vgg-16 : {:}'.format(summary['lognorm']))\n  _, summary = weight_watcher.analyze(models.vgg16_bn(pretrained=True), alphas=False)\n  print('vgg-16-BN : {:}'.format(summary['lognorm']))\n  _, summary = weight_watcher.analyze(models.vgg19(pretrained=True), alphas=False)\n  print('vgg-19 : {:}'.format(summary['lognorm']))\n  _, summary = weight_watcher.analyze(models.vgg19_bn(pretrained=True), alphas=False)\n  print('vgg-19-BN : {:}'.format(summary['lognorm']))\n\n\nif __name__ == '__main__':\n  main()"""
exps/vis/test.py,10,"b'# python ./exps/vis/test.py\nimport os, sys, random\nfrom pathlib import Path\nfrom copy import deepcopy\nimport torch\nimport numpy as np\nfrom collections import OrderedDict\nlib_dir = (Path(__file__).parent / \'..\' / \'..\' / \'lib\').resolve()\nif str(lib_dir) not in sys.path: sys.path.insert(0, str(lib_dir))\n\nfrom nas_201_api import NASBench201API as API\n\ndef test_nas_api():\n  from nas_201_api import ArchResults\n  xdata   = torch.load(\'/home/dxy/FOR-RELEASE/NAS-Projects/output/NAS-BENCH-201-4/simplifies/architectures/000157-FULL.pth\')\n  for key in [\'full\', \'less\']:\n    print (\'\\n------------------------- {:} -------------------------\'.format(key))\n    archRes = ArchResults.create_from_state_dict(xdata[key])\n    print(archRes)\n    print(archRes.arch_idx_str())\n    print(archRes.get_dataset_names())\n    print(archRes.get_comput_costs(\'cifar10-valid\'))\n    # get the metrics\n    print(archRes.get_metrics(\'cifar10-valid\', \'x-valid\', None, False))\n    print(archRes.get_metrics(\'cifar10-valid\', \'x-valid\', None,  True))\n    print(archRes.query(\'cifar10-valid\', 777))\n\n\nOPS    = [\'skip-connect\', \'conv-1x1\', \'conv-3x3\', \'pool-3x3\']\nCOLORS = [\'chartreuse\'  , \'cyan\'    , \'navyblue\', \'chocolate1\']\n\ndef plot(filename):\n  from graphviz import Digraph\n  g = Digraph(\n      format=\'png\',\n      edge_attr=dict(fontsize=\'20\', fontname=""times""),\n      node_attr=dict(style=\'filled\', shape=\'rect\', align=\'center\', fontsize=\'20\', height=\'0.5\', width=\'0.5\', penwidth=\'2\', fontname=""times""),\n      engine=\'dot\')\n  g.body.extend([\'rankdir=LR\'])\n\n  steps = 5\n  for i in range(0, steps):\n    if i == 0:\n      g.node(str(i), fillcolor=\'darkseagreen2\')\n    elif i+1 == steps:\n      g.node(str(i), fillcolor=\'palegoldenrod\')\n    else: g.node(str(i), fillcolor=\'lightblue\')\n\n  for i in range(1, steps):\n    for xin in range(i):\n      op_i = random.randint(0, len(OPS)-1)\n      #g.edge(str(xin), str(i), label=OPS[op_i], fillcolor=COLORS[op_i])\n      g.edge(str(xin), str(i), label=OPS[op_i], color=COLORS[op_i], fillcolor=COLORS[op_i])\n      #import pdb; pdb.set_trace()\n  g.render(filename, cleanup=True, view=False)\n\n\ndef test_auto_grad():\n  class Net(torch.nn.Module):\n    def __init__(self, iS):\n      super(Net, self).__init__()\n      self.layer = torch.nn.Linear(iS, 1)\n    def forward(self, inputs):\n      outputs = self.layer(inputs)\n      outputs = torch.exp(outputs)\n      return outputs.mean()\n  net = Net(10)\n  inputs = torch.rand(256, 10)\n  loss = net(inputs)\n  first_order_grads = torch.autograd.grad(loss, net.parameters(), retain_graph=True, create_graph=True)\n  first_order_grads = torch.cat([x.view(-1) for x in first_order_grads])\n  second_order_grads = []\n  for grads in  first_order_grads:\n    s_grads = torch.autograd.grad(grads, net.parameters())\n    second_order_grads.append( s_grads )\n\n\ndef test_one_shot_model(ckpath, use_train):\n  from models import get_cell_based_tiny_net, get_search_spaces\n  from datasets import get_datasets, SearchDataset\n  from config_utils import load_config, dict2config\n  from utils.nas_utils import evaluate_one_shot\n  use_train = int(use_train) > 0\n  #ckpath = \'output/search-cell-nas-bench-201/DARTS-V1-cifar10/checkpoint/seed-11416-basic.pth\'\n  #ckpath = \'output/search-cell-nas-bench-201/DARTS-V1-cifar10/checkpoint/seed-28640-basic.pth\'\n  print (\'ckpath : {:}\'.format(ckpath))\n  ckp = torch.load(ckpath)\n  xargs = ckp[\'args\']\n  train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n  #config = load_config(xargs.config_path, {\'class_num\': class_num, \'xshape\': xshape}, None)\n  config = load_config(\'./configs/nas-benchmark/algos/DARTS.config\', {\'class_num\': class_num, \'xshape\': xshape}, None)\n  if xargs.dataset == \'cifar10\':\n    cifar_split = load_config(\'configs/nas-benchmark/cifar-split.txt\', None, None)\n    xvalid_data = deepcopy(train_data)\n    xvalid_data.transform = valid_data.transform\n    valid_loader= torch.utils.data.DataLoader(xvalid_data, batch_size=2048, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar_split.valid), num_workers=12, pin_memory=True)\n  else: raise ValueError(\'invalid dataset : {:}\'.format(xargs.dataseet))\n  search_space = get_search_spaces(\'cell\', xargs.search_space_name)\n  model_config = dict2config({\'name\': \'SETN\', \'C\': xargs.channel, \'N\': xargs.num_cells,\n                              \'max_nodes\': xargs.max_nodes, \'num_classes\': class_num,\n                              \'space\'    : search_space,\n                              \'affine\'   : False, \'track_running_stats\': True}, None)\n  search_model = get_cell_based_tiny_net(model_config)\n  search_model.load_state_dict( ckp[\'search_model\'] )\n  search_model = search_model.cuda()\n  api = API(\'/home/dxy/.torch/NAS-Bench-201-v1_0-e61699.pth\')\n  archs, probs, accuracies = evaluate_one_shot(search_model, valid_loader, api, use_train)\n\n\nif __name__ == \'__main__\':\n  #test_nas_api()\n  #for i in range(200): plot(\'{:04d}\'.format(i))\n  #test_auto_grad()\n  test_one_shot_model(sys.argv[1], sys.argv[2])\n'"
lib/config_utils/__init__.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom .configure_utils    import load_config, dict2config, configure2str\nfrom .basic_args         import obtain_basic_args\nfrom .attention_args     import obtain_attention_args\nfrom .random_baseline    import obtain_RandomSearch_args\nfrom .cls_kd_args        import obtain_cls_kd_args\nfrom .cls_init_args      import obtain_cls_init_args\nfrom .search_single_args import obtain_search_single_args\nfrom .search_args        import obtain_search_args\n# for network pruning\nfrom .pruning_args       import obtain_pruning_args\n'"
lib/config_utils/attention_args.py,0,"b""import random, argparse\nfrom .share_args import add_shared_args\n\ndef obtain_attention_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--att_channel' ,     type=int,                   help='.')\n  parser.add_argument('--att_spatial' ,     type=str,                   help='.')\n  parser.add_argument('--att_active'  ,     type=str,                   help='.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  return args\n"""
lib/config_utils/basic_args.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020 #\n##################################################\nimport random, argparse\nfrom .share_args import add_shared_args\n\ndef obtain_basic_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--model_source',     type=str,  default='normal',help='The source of model defination.')\n  parser.add_argument('--extra_model_path', type=str,  default=None,    help='The extra model ckp file (help to indicate the searched architecture).')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,  default=2,       help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  return args\n"""
lib/config_utils/cls_init_args.py,0,"b""import random, argparse\nfrom .share_args import add_shared_args\n\ndef obtain_cls_init_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--init_checkpoint',  type=str,                   help='The checkpoint path to the initial model.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  return args\n"""
lib/config_utils/cls_kd_args.py,0,"b""import random, argparse\nfrom .share_args import add_shared_args\n\ndef obtain_cls_kd_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--KD_checkpoint',    type=str,                   help='The teacher checkpoint in knowledge distillation.')\n  parser.add_argument('--KD_alpha'    ,     type=float,                 help='The alpha parameter in knowledge distillation.')\n  parser.add_argument('--KD_temperature',   type=float,                 help='The temperature parameter in knowledge distillation.')\n  #parser.add_argument('--KD_feature',       type=float,                 help='Knowledge distillation at the feature level.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  return args\n"""
lib/config_utils/configure_utils.py,0,"b'# Copyright (c) Facebook, Inc. and its affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n#\nimport os, json\nfrom os import path as osp\nfrom pathlib import Path\nfrom collections import namedtuple\n\nsupport_types = (\'str\', \'int\', \'bool\', \'float\', \'none\')\n\n\ndef convert_param(original_lists):\n  assert isinstance(original_lists, list), \'The type is not right : {:}\'.format(original_lists)\n  ctype, value = original_lists[0], original_lists[1]\n  assert ctype in support_types, \'Ctype={:}, support={:}\'.format(ctype, support_types)\n  is_list = isinstance(value, list)\n  if not is_list: value = [value]\n  outs = []\n  for x in value:\n    if ctype == \'int\':\n      x = int(x)\n    elif ctype == \'str\':\n      x = str(x)\n    elif ctype == \'bool\':\n      x = bool(int(x))\n    elif ctype == \'float\':\n      x = float(x)\n    elif ctype == \'none\':\n      if x.lower() != \'none\':\n        raise ValueError(\'For the none type, the value must be none instead of {:}\'.format(x))\n      x = None\n    else:\n      raise TypeError(\'Does not know this type : {:}\'.format(ctype))\n    outs.append(x)\n  if not is_list: outs = outs[0]\n  return outs\n\n\ndef load_config(path, extra, logger):\n  path = str(path)\n  if hasattr(logger, \'log\'): logger.log(path)\n  assert os.path.exists(path), \'Can not find {:}\'.format(path)\n  # Reading data back\n  with open(path, \'r\') as f:\n    data = json.load(f)\n  content = { k: convert_param(v) for k,v in data.items()}\n  assert extra is None or isinstance(extra, dict), \'invalid type of extra : {:}\'.format(extra)\n  if isinstance(extra, dict): content = {**content, **extra}\n  Arguments = namedtuple(\'Configure\', \' \'.join(content.keys()))\n  content   = Arguments(**content)\n  if hasattr(logger, \'log\'): logger.log(\'{:}\'.format(content))\n  return content\n\n\ndef configure2str(config, xpath=None):\n  if not isinstance(config, dict):\n    config = config._asdict()\n  def cstring(x):\n    return ""\\""{:}\\"""".format(x)\n  def gtype(x):\n    if isinstance(x, list): x = x[0]\n    if isinstance(x, str)  : return \'str\'\n    elif isinstance(x, bool) : return \'bool\'\n    elif isinstance(x, int): return \'int\'\n    elif isinstance(x, float): return \'float\'\n    elif x is None           : return \'none\'\n    else: raise ValueError(\'invalid : {:}\'.format(x))\n  def cvalue(x, xtype):\n    if isinstance(x, list): is_list = True\n    else:\n      is_list, x = False, [x]\n    temps = []\n    for temp in x:\n      if xtype == \'bool\'  : temp = cstring(int(temp))\n      elif xtype == \'none\': temp = cstring(\'None\')\n      else                : temp = cstring(temp)\n      temps.append( temp )\n    if is_list:\n      return ""[{:}]"".format( \', \'.join( temps ) )\n    else:\n      return temps[0]\n\n  xstrings = []\n  for key, value in config.items():\n    xtype  = gtype(value)\n    string = \'  {:20s} : [{:8s}, {:}]\'.format(cstring(key), cstring(xtype), cvalue(value, xtype))\n    xstrings.append(string)\n  Fstring = \'{\\n\' + \',\\n\'.join(xstrings) + \'\\n}\'\n  if xpath is not None:\n    parent = Path(xpath).resolve().parent\n    parent.mkdir(parents=True, exist_ok=True)\n    if osp.isfile(xpath): os.remove(xpath)\n    with open(xpath, ""w"") as text_file:\n      text_file.write(\'{:}\'.format(Fstring))\n  return Fstring\n\n\ndef dict2config(xdict, logger):\n  assert isinstance(xdict, dict), \'invalid type : {:}\'.format( type(xdict) )\n  Arguments = namedtuple(\'Configure\', \' \'.join(xdict.keys()))\n  content   = Arguments(**xdict)\n  if hasattr(logger, \'log\'): logger.log(\'{:}\'.format(content))\n  return content\n'"
lib/config_utils/pruning_args.py,0,"b""import os, sys, time, random, argparse\nfrom .share_args import add_shared_args\n\ndef obtain_pruning_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--keep_ratio'  ,     type=float,                 help='The left channel ratio compared to the original network.')\n  parser.add_argument('--model_version',    type=str,                   help='The network version.')\n  parser.add_argument('--KD_alpha'    ,     type=float,                 help='The alpha parameter in knowledge distillation.')\n  parser.add_argument('--KD_temperature',   type=float,                 help='The temperature parameter in knowledge distillation.')\n  parser.add_argument('--Regular_W_feat',   type=float,                 help='The .')\n  parser.add_argument('--Regular_W_conv',   type=float,                 help='The .')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,  default=2,       help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  assert args.keep_ratio > 0 and args.keep_ratio <= 1, 'invalid keep ratio : {:}'.format(args.keep_ratio)\n  return args\n"""
lib/config_utils/random_baseline.py,0,"b""import os, sys, time, random, argparse\nfrom .share_args import add_shared_args\n\n\ndef obtain_RandomSearch_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'      ,     type=str,                   help='Resume path.')\n  parser.add_argument('--init_model'  ,     type=str,                   help='The initialization model path.')\n  parser.add_argument('--expect_flop',      type=float,                 help='The expected flop keep ratio.')\n  parser.add_argument('--arch_nums'   ,     type=int,                   help='The maximum number of running random arch generating..')\n  parser.add_argument('--model_config',     type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config',     type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--random_mode', type=str, choices=['random', 'fix'], help='The path to the optimizer configuration')\n  parser.add_argument('--procedure'   ,     type=str,                   help='The procedure basic prefix.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size',       type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  #assert args.flop_ratio_min < args.flop_ratio_max, 'flop-ratio {:} vs {:}'.format(args.flop_ratio_min, args.flop_ratio_max)\n  return args\n"""
lib/config_utils/search_args.py,0,"b""import os, sys, time, random, argparse\nfrom .share_args import add_shared_args\n\n\ndef obtain_search_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'        ,   type=str,                   help='Resume path.')\n  parser.add_argument('--model_config'  ,   type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config'  ,   type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--split_path'    ,   type=str,                   help='The split file path.')\n  #parser.add_argument('--arch_para_pure',   type=int,                   help='The architecture-parameter pure or not.')\n  parser.add_argument('--gumbel_tau_max',   type=float,                 help='The maximum tau for Gumbel.')\n  parser.add_argument('--gumbel_tau_min',   type=float,                 help='The minimum tau for Gumbel.')\n  parser.add_argument('--procedure'     ,   type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--FLOP_ratio'    ,   type=float,                 help='The expected FLOP ratio.')\n  parser.add_argument('--FLOP_weight'   ,   type=float,                 help='The loss weight for FLOP.')\n  parser.add_argument('--FLOP_tolerant' ,   type=float,                 help='The tolerant range for FLOP.')\n  # ablation studies\n  parser.add_argument('--ablation_num_select', type=int,                help='The number of randomly selected channels.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size'    ,   type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  assert args.gumbel_tau_max is not None and args.gumbel_tau_min is not None\n  assert args.FLOP_tolerant is not None and args.FLOP_tolerant > 0, 'invalid FLOP_tolerant : {:}'.format(FLOP_tolerant)\n  #assert args.arch_para_pure is not None, 'arch_para_pure is not None: {:}'.format(args.arch_para_pure)\n  #args.arch_para_pure = bool(args.arch_para_pure)\n  return args\n"""
lib/config_utils/search_single_args.py,0,"b""import os, sys, time, random, argparse\nfrom .share_args import add_shared_args\n\n\ndef obtain_search_single_args():\n  parser = argparse.ArgumentParser(description='Train a classification model on typical image classification datasets.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n  parser.add_argument('--resume'        ,   type=str,                   help='Resume path.')\n  parser.add_argument('--model_config'  ,   type=str,                   help='The path to the model configuration')\n  parser.add_argument('--optim_config'  ,   type=str,                   help='The path to the optimizer configuration')\n  parser.add_argument('--split_path'    ,   type=str,                   help='The split file path.')\n  parser.add_argument('--search_shape'  ,   type=str,                   help='The shape to be searched.')\n  #parser.add_argument('--arch_para_pure',   type=int,                   help='The architecture-parameter pure or not.')\n  parser.add_argument('--gumbel_tau_max',   type=float,                 help='The maximum tau for Gumbel.')\n  parser.add_argument('--gumbel_tau_min',   type=float,                 help='The minimum tau for Gumbel.')\n  parser.add_argument('--procedure'     ,   type=str,                   help='The procedure basic prefix.')\n  parser.add_argument('--FLOP_ratio'    ,   type=float,                 help='The expected FLOP ratio.')\n  parser.add_argument('--FLOP_weight'   ,   type=float,                 help='The loss weight for FLOP.')\n  parser.add_argument('--FLOP_tolerant' ,   type=float,                 help='The tolerant range for FLOP.')\n  add_shared_args( parser )\n  # Optimization options\n  parser.add_argument('--batch_size'    ,   type=int,   default=2,      help='Batch size for training.')\n  args = parser.parse_args()\n\n  if args.rand_seed is None or args.rand_seed < 0:\n    args.rand_seed = random.randint(1, 100000)\n  assert args.save_dir is not None, 'save-path argument can not be None'\n  assert args.gumbel_tau_max is not None and args.gumbel_tau_min is not None\n  assert args.FLOP_tolerant is not None and args.FLOP_tolerant > 0, 'invalid FLOP_tolerant : {:}'.format(FLOP_tolerant)\n  #assert args.arch_para_pure is not None, 'arch_para_pure is not None: {:}'.format(args.arch_para_pure)\n  #args.arch_para_pure = bool(args.arch_para_pure)\n  return args\n"""
lib/config_utils/share_args.py,0,"b""import os, sys, time, random, argparse\n\ndef add_shared_args( parser ):\n  # Data Generation\n  parser.add_argument('--dataset',          type=str,                   help='The dataset name.')\n  parser.add_argument('--data_path',        type=str,                   help='The dataset name.')\n  parser.add_argument('--cutout_length',    type=int,                   help='The cutout length, negative means not use.')\n  # Printing\n  parser.add_argument('--print_freq',       type=int,   default=100,    help='print frequency (default: 200)')\n  parser.add_argument('--print_freq_eval',  type=int,   default=100,    help='print frequency (default: 200)')\n  # Checkpoints\n  parser.add_argument('--eval_frequency',   type=int,   default=1,      help='evaluation frequency (default: 200)')\n  parser.add_argument('--save_dir',         type=str,                   help='Folder to save checkpoints and log.')\n  # Acceleration\n  parser.add_argument('--workers',          type=int,   default=8,      help='number of data loading workers (default: 8)')\n  # Random Seed\n  parser.add_argument('--rand_seed',        type=int,   default=-1,     help='manual seed')\n"""
lib/datasets/DownsampledImageNet.py,1,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, hashlib, torch\nimport numpy as np\nfrom PIL import Image\nimport torch.utils.data as data\nif sys.version_info[0] == 2:\n  import cPickle as pickle\nelse:\n  import pickle\n\n\ndef calculate_md5(fpath, chunk_size=1024 * 1024):\n  md5 = hashlib.md5()\n  with open(fpath, 'rb') as f:\n    for chunk in iter(lambda: f.read(chunk_size), b''):\n      md5.update(chunk)\n  return md5.hexdigest()\n\n\ndef check_md5(fpath, md5, **kwargs):\n  return md5 == calculate_md5(fpath, **kwargs)\n\n\ndef check_integrity(fpath, md5=None):\n  if not os.path.isfile(fpath): return False\n  if md5 is None: return True\n  else          : return check_md5(fpath, md5)\n\n\nclass ImageNet16(data.Dataset):\n  # http://image-net.org/download-images\n  # A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets\n  # https://arxiv.org/pdf/1707.08819.pdf\n  \n  train_list = [\n        ['train_data_batch_1', '27846dcaa50de8e21a7d1a35f30f0e91'],\n        ['train_data_batch_2', 'c7254a054e0e795c69120a5727050e3f'],\n        ['train_data_batch_3', '4333d3df2e5ffb114b05d2ffc19b1e87'],\n        ['train_data_batch_4', '1620cdf193304f4a92677b695d70d10f'],\n        ['train_data_batch_5', '348b3c2fdbb3940c4e9e834affd3b18d'],\n        ['train_data_batch_6', '6e765307c242a1b3d7d5ef9139b48945'],\n        ['train_data_batch_7', '564926d8cbf8fc4818ba23d2faac7564'],\n        ['train_data_batch_8', 'f4755871f718ccb653440b9dd0ebac66'],\n        ['train_data_batch_9', 'bb6dd660c38c58552125b1a92f86b5d4'],\n        ['train_data_batch_10','8f03f34ac4b42271a294f91bf480f29b'],\n    ]\n  valid_list = [\n        ['val_data', '3410e3017fdaefba8d5073aaa65e4bd6'],\n    ]\n\n  def __init__(self, root, train, transform, use_num_of_class_only=None):\n    self.root      = root\n    self.transform = transform\n    self.train     = train  # training set or valid set\n    if not self._check_integrity(): raise RuntimeError('Dataset not found or corrupted.')\n\n    if self.train: downloaded_list = self.train_list\n    else         : downloaded_list = self.valid_list\n    self.data    = []\n    self.targets = []\n  \n    # now load the picked numpy arrays\n    for i, (file_name, checksum) in enumerate(downloaded_list):\n      file_path = os.path.join(self.root, file_name)\n      #print ('Load {:}/{:02d}-th : {:}'.format(i, len(downloaded_list), file_path))\n      with open(file_path, 'rb') as f:\n        if sys.version_info[0] == 2:\n          entry = pickle.load(f)\n        else:\n          entry = pickle.load(f, encoding='latin1')\n        self.data.append(entry['data'])\n        self.targets.extend(entry['labels'])\n    self.data = np.vstack(self.data).reshape(-1, 3, 16, 16)\n    self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n    if use_num_of_class_only is not None:\n      assert isinstance(use_num_of_class_only, int) and use_num_of_class_only > 0 and use_num_of_class_only < 1000, 'invalid use_num_of_class_only : {:}'.format(use_num_of_class_only)\n      new_data, new_targets = [], []\n      for I, L in zip(self.data, self.targets):\n        if 1 <= L <= use_num_of_class_only:\n          new_data.append( I )\n          new_targets.append( L )\n      self.data    = new_data\n      self.targets = new_targets\n    #    self.mean.append(entry['mean'])\n    #self.mean = np.vstack(self.mean).reshape(-1, 3, 16, 16)\n    #self.mean = np.mean(np.mean(np.mean(self.mean, axis=0), axis=1), axis=1)\n    #print ('Mean : {:}'.format(self.mean))\n    #temp      = self.data - np.reshape(self.mean, (1, 1, 1, 3))\n    #std_data  = np.std(temp, axis=0)\n    #std_data  = np.mean(np.mean(std_data, axis=0), axis=0)\n    #print ('Std  : {:}'.format(std_data))\n\n  def __getitem__(self, index):\n    img, target = self.data[index], self.targets[index] - 1\n\n    img = Image.fromarray(img)\n\n    if self.transform is not None:\n      img = self.transform(img)\n\n    return img, target\n\n  def __len__(self):\n    return len(self.data)\n\n  def _check_integrity(self):\n    root = self.root\n    for fentry in (self.train_list + self.valid_list):\n      filename, md5 = fentry[0], fentry[1]\n      fpath = os.path.join(root, filename)\n      if not check_integrity(fpath, md5):\n        return False\n    return True\n\n#\nif __name__ == '__main__':\n  train = ImageNet16('/data02/dongxuanyi/.torch/cifar.python/ImageNet16', True , None) \n  valid = ImageNet16('/data02/dongxuanyi/.torch/cifar.python/ImageNet16', False, None) \n\n  print ( len(train) )\n  print ( len(valid) )\n  image, label = train[111]\n  trainX = ImageNet16('/data02/dongxuanyi/.torch/cifar.python/ImageNet16', True , None, 200)\n  validX = ImageNet16('/data02/dongxuanyi/.torch/cifar.python/ImageNet16', False , None, 200)\n  print ( len(trainX) )\n  print ( len(validX) )\n  #import pdb; pdb.set_trace()\n"""
lib/datasets/LandmarkDataset.py,14,"b""# Copyright (c) Facebook, Inc. and its affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n#\nfrom os import path as osp\nfrom copy import deepcopy as copy\nfrom tqdm import tqdm\nimport warnings, time, random, numpy as np\n\nfrom pts_utils import generate_label_map\nfrom xvision import denormalize_points\nfrom xvision import identity2affine, solve2theta, affine2image\nfrom .dataset_utils import pil_loader\nfrom .landmark_utils import PointMeta2V\nfrom .augmentation_utils import CutOut\nimport torch\nimport torch.utils.data as data\n\n\nclass LandmarkDataset(data.Dataset):\n\n  def __init__(self, transform, sigma, downsample, heatmap_type, shape, use_gray, mean_file, data_indicator, cache_images=None):\n\n    self.transform    = transform\n    self.sigma        = sigma\n    self.downsample   = downsample\n    self.heatmap_type = heatmap_type\n    self.dataset_name = data_indicator\n    self.shape        = shape # [H,W]\n    self.use_gray     = use_gray\n    assert transform is not None, 'transform : {:}'.format(transform)\n    self.mean_file    = mean_file\n    if mean_file is None:\n      self.mean_data  = None\n      warnings.warn('LandmarkDataset initialized with mean_data = None')\n    else:\n      assert osp.isfile(mean_file), '{:} is not a file.'.format(mean_file)\n      self.mean_data  = torch.load(mean_file)\n    self.reset()\n    self.cutout       = None\n    self.cache_images = cache_images\n    print ('The general dataset initialization done : {:}'.format(self))\n    warnings.simplefilter( 'once' )\n\n\n  def __repr__(self):\n    return ('{name}(point-num={NUM_PTS}, shape={shape}, sigma={sigma}, heatmap_type={heatmap_type}, length={length}, cutout={cutout}, dataset={dataset_name}, mean={mean_file})'.format(name=self.__class__.__name__, **self.__dict__))\n\n\n  def set_cutout(self, length):\n    if length is not None and length >= 1:\n      self.cutout = CutOut( int(length) )\n    else: self.cutout = None\n\n\n  def reset(self, num_pts=-1, boxid='default', only_pts=False):\n    self.NUM_PTS = num_pts\n    if only_pts: return\n    self.length  = 0\n    self.datas   = []\n    self.labels  = []\n    self.NormDistances = []\n    self.BOXID = boxid\n    if self.mean_data is None:\n      self.mean_face = None\n    else:\n      self.mean_face = torch.Tensor(self.mean_data[boxid].copy().T)\n      assert (self.mean_face >= -1).all() and (self.mean_face <= 1).all(), 'mean-{:}-face : {:}'.format(boxid, self.mean_face)\n    #assert self.dataset_name is not None, 'The dataset name is None'\n\n\n  def __len__(self):\n    assert len(self.datas) == self.length, 'The length is not correct : {}'.format(self.length)\n    return self.length\n\n\n  def append(self, data, label, distance):\n    assert osp.isfile(data), 'The image path is not a file : {:}'.format(data)\n    self.datas.append( data )             ;  self.labels.append( label )\n    self.NormDistances.append( distance )\n    self.length = self.length + 1\n\n\n  def load_list(self, file_lists, num_pts, boxindicator, normalizeL, reset):\n    if reset: self.reset(num_pts, boxindicator)\n    else    : assert self.NUM_PTS == num_pts and self.BOXID == boxindicator, 'The number of point is inconsistance : {:} vs {:}'.format(self.NUM_PTS, num_pts)\n    if isinstance(file_lists, str): file_lists = [file_lists]\n    samples = []\n    for idx, file_path in enumerate(file_lists):\n      print (':::: load list {:}/{:} : {:}'.format(idx, len(file_lists), file_path))\n      xdata = torch.load(file_path)\n      if isinstance(xdata, list)  : data = xdata          # image or video dataset list\n      elif isinstance(xdata, dict): data = xdata['datas'] # multi-view dataset list\n      else: raise ValueError('Invalid Type Error : {:}'.format( type(xdata) ))\n      samples = samples + data\n    # samples is a dict, where the key is the image-path and the value is the annotation\n    # each annotation is a dict, contains 'points' (3,num_pts), and various box\n    print ('GeneralDataset-V2 : {:} samples'.format(len(samples)))\n\n    #for index, annotation in enumerate(samples):\n    for index in tqdm( range( len(samples) ) ):\n      annotation = samples[index]\n      image_path  = annotation['current_frame']\n      points, box = annotation['points'], annotation['box-{:}'.format(boxindicator)]\n      label = PointMeta2V(self.NUM_PTS, points, box, image_path, self.dataset_name)\n      if normalizeL is None: normDistance = None\n      else                 : normDistance = annotation['normalizeL-{:}'.format(normalizeL)]\n      self.append(image_path, label, normDistance)\n\n    assert len(self.datas) == self.length, 'The length and the data is not right {} vs {}'.format(self.length, len(self.datas))\n    assert len(self.labels) == self.length, 'The length and the labels is not right {} vs {}'.format(self.length, len(self.labels))\n    assert len(self.NormDistances) == self.length, 'The length and the NormDistances is not right {} vs {}'.format(self.length, len(self.NormDistance))\n    print ('Load data done for LandmarkDataset, which has {:} images.'.format(self.length))\n\n\n  def __getitem__(self, index):\n    assert index >= 0 and index < self.length, 'Invalid index : {:}'.format(index)\n    if self.cache_images is not None and self.datas[index] in self.cache_images:\n      image = self.cache_images[ self.datas[index] ].clone()\n    else:\n      image = pil_loader(self.datas[index], self.use_gray)\n    target = self.labels[index].copy()\n    return self._process_(image, target, index)\n\n\n  def _process_(self, image, target, index):\n\n    # transform the image and points\n    image, target, theta = self.transform(image, target)\n    (C, H, W), (height, width) = image.size(), self.shape\n\n    # obtain the visiable indicator vector\n    if target.is_none(): nopoints = True\n    else               : nopoints = False\n    if index == -1: __path = None\n    else          : __path = self.datas[index]\n    if isinstance(theta, list) or isinstance(theta, tuple):\n      affineImage, heatmaps, mask, norm_trans_points, THETA, transpose_theta = [], [], [], [], [], []\n      for _theta in theta:\n        _affineImage, _heatmaps, _mask, _norm_trans_points, _theta, _transpose_theta \\\n          = self.__process_affine(image, target, _theta, nopoints, 'P[{:}]@{:}'.format(index, __path))\n        affineImage.append(_affineImage)\n        heatmaps.append(_heatmaps)\n        mask.append(_mask)\n        norm_trans_points.append(_norm_trans_points)\n        THETA.append(_theta)\n        transpose_theta.append(_transpose_theta)\n      affineImage, heatmaps, mask, norm_trans_points, THETA, transpose_theta = \\\n          torch.stack(affineImage), torch.stack(heatmaps), torch.stack(mask), torch.stack(norm_trans_points), torch.stack(THETA), torch.stack(transpose_theta)\n    else:\n      affineImage, heatmaps, mask, norm_trans_points, THETA, transpose_theta = self.__process_affine(image, target, theta, nopoints, 'S[{:}]@{:}'.format(index, __path))\n\n    torch_index = torch.IntTensor([index])\n    torch_nopoints = torch.ByteTensor( [ nopoints ] )\n    torch_shape = torch.IntTensor([H,W])\n\n    return affineImage, heatmaps, mask, norm_trans_points, THETA, transpose_theta, torch_index, torch_nopoints, torch_shape\n\n  \n  def __process_affine(self, image, target, theta, nopoints, aux_info=None):\n    image, target, theta = image.clone(), target.copy(), theta.clone()\n    (C, H, W), (height, width) = image.size(), self.shape\n    if nopoints: # do not have label\n      norm_trans_points = torch.zeros((3, self.NUM_PTS))\n      heatmaps          = torch.zeros((self.NUM_PTS+1, height//self.downsample, width//self.downsample))\n      mask              = torch.ones((self.NUM_PTS+1, 1, 1), dtype=torch.uint8)\n      transpose_theta   = identity2affine(False)\n    else:\n      norm_trans_points = apply_affine2point(target.get_points(), theta, (H,W))\n      norm_trans_points = apply_boundary(norm_trans_points)\n      real_trans_points = norm_trans_points.clone()\n      real_trans_points[:2, :] = denormalize_points(self.shape, real_trans_points[:2,:])\n      heatmaps, mask = generate_label_map(real_trans_points.numpy(), height//self.downsample, width//self.downsample, self.sigma, self.downsample, nopoints, self.heatmap_type) # H*W*C\n      heatmaps = torch.from_numpy(heatmaps.transpose((2, 0, 1))).type(torch.FloatTensor)\n      mask     = torch.from_numpy(mask.transpose((2, 0, 1))).type(torch.ByteTensor)\n      if self.mean_face is None:\n        #warnings.warn('In LandmarkDataset use identity2affine for transpose_theta because self.mean_face is None.')\n        transpose_theta = identity2affine(False)\n      else:\n        if torch.sum(norm_trans_points[2,:] == 1) < 3:\n          warnings.warn('In LandmarkDataset after transformation, no visiable point, using identity instead. Aux: {:}'.format(aux_info))\n          transpose_theta = identity2affine(False)\n        else:\n          transpose_theta = solve2theta(norm_trans_points, self.mean_face.clone())\n\n    affineImage = affine2image(image, theta, self.shape)\n    if self.cutout is not None: affineImage = self.cutout( affineImage )\n\n    return affineImage, heatmaps, mask, norm_trans_points, theta, transpose_theta\n"""
lib/datasets/SearchDatasetWrap.py,1,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport torch, copy, random\nimport torch.utils.data as data\n\n\nclass SearchDataset(data.Dataset):\n\n  def __init__(self, name, data, train_split, valid_split, check=True):\n    self.datasetname = name\n    if isinstance(data, (list, tuple)): # new type of SearchDataset\n      assert len(data) == 2, 'invalid length: {:}'.format( len(data) )\n      self.train_data  = data[0]\n      self.valid_data  = data[1]\n      self.train_split = train_split.copy()\n      self.valid_split = valid_split.copy()\n      self.mode_str    = 'V2' # new mode \n    else:\n      self.mode_str    = 'V1' # old mode \n      self.data        = data\n      self.train_split = train_split.copy()\n      self.valid_split = valid_split.copy()\n      if check:\n        intersection = set(train_split).intersection(set(valid_split))\n        assert len(intersection) == 0, 'the splitted train and validation sets should have no intersection'\n    self.length      = len(self.train_split)\n\n  def __repr__(self):\n    return ('{name}(name={datasetname}, train={tr_L}, valid={val_L}, version={ver})'.format(name=self.__class__.__name__, datasetname=self.datasetname, tr_L=len(self.train_split), val_L=len(self.valid_split), ver=self.mode_str))\n\n  def __len__(self):\n    return self.length\n\n  def __getitem__(self, index):\n    assert index >= 0 and index < self.length, 'invalid index = {:}'.format(index)\n    train_index = self.train_split[index]\n    valid_index = random.choice( self.valid_split )\n    if self.mode_str == 'V1':\n      train_image, train_label = self.data[train_index]\n      valid_image, valid_label = self.data[valid_index]\n    elif self.mode_str == 'V2':\n      train_image, train_label = self.train_data[train_index]\n      valid_image, valid_label = self.valid_data[valid_index]\n    else: raise ValueError('invalid mode : {:}'.format(self.mode_str))\n    return train_image, train_label, valid_image, valid_label\n"""
lib/datasets/__init__.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom .get_dataset_with_transform import get_datasets, get_nas_search_loaders\nfrom .SearchDatasetWrap import SearchDataset\n'"
lib/datasets/get_dataset_with_transform.py,10,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, torch\nimport os.path as osp\nimport numpy as np\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom copy import deepcopy\nfrom PIL import Image\n\nfrom .DownsampledImageNet import ImageNet16\nfrom .SearchDatasetWrap import SearchDataset\nfrom config_utils import load_config\n\n\nDataset2Class = {\'cifar10\' : 10,\n                 \'cifar100\': 100,\n                 \'imagenet-1k-s\':1000,\n                 \'imagenet-1k\' : 1000,\n                 \'ImageNet16\'  : 1000,\n                 \'ImageNet16-150\': 150,\n                 \'ImageNet16-120\': 120,\n                 \'ImageNet16-200\': 200}\n\n\nclass CUTOUT(object):\n\n  def __init__(self, length):\n    self.length = length\n\n  def __repr__(self):\n    return (\'{name}(length={length})\'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def __call__(self, img):\n    h, w = img.size(1), img.size(2)\n    mask = np.ones((h, w), np.float32)\n    y = np.random.randint(h)\n    x = np.random.randint(w)\n\n    y1 = np.clip(y - self.length // 2, 0, h)\n    y2 = np.clip(y + self.length // 2, 0, h)\n    x1 = np.clip(x - self.length // 2, 0, w)\n    x2 = np.clip(x + self.length // 2, 0, w)\n\n    mask[y1: y2, x1: x2] = 0.\n    mask = torch.from_numpy(mask)\n    mask = mask.expand_as(img)\n    img *= mask\n    return img\n\n\nimagenet_pca = {\n    \'eigval\': np.asarray([0.2175, 0.0188, 0.0045]),\n    \'eigvec\': np.asarray([\n        [-0.5675, 0.7192, 0.4009],\n        [-0.5808, -0.0045, -0.8140],\n        [-0.5836, -0.6948, 0.4203],\n    ])\n}\n\n\nclass Lighting(object):\n  def __init__(self, alphastd,\n         eigval=imagenet_pca[\'eigval\'],\n         eigvec=imagenet_pca[\'eigvec\']):\n    self.alphastd = alphastd\n    assert eigval.shape == (3,)\n    assert eigvec.shape == (3, 3)\n    self.eigval = eigval\n    self.eigvec = eigvec\n\n  def __call__(self, img):\n    if self.alphastd == 0.:\n      return img\n    rnd = np.random.randn(3) * self.alphastd\n    rnd = rnd.astype(\'float32\')\n    v = rnd\n    old_dtype = np.asarray(img).dtype\n    v = v * self.eigval\n    v = v.reshape((3, 1))\n    inc = np.dot(self.eigvec, v).reshape((3,))\n    img = np.add(img, inc)\n    if old_dtype == np.uint8:\n      img = np.clip(img, 0, 255)\n    img = Image.fromarray(img.astype(old_dtype), \'RGB\')\n    return img\n\n  def __repr__(self):\n    return self.__class__.__name__ + \'()\'\n\n\ndef get_datasets(name, root, cutout):\n\n  if name == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std  = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif name == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std  = [x / 255 for x in [68.2, 65.4, 70.4]]\n  elif name.startswith(\'imagenet-1k\'):\n    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n  elif name.startswith(\'ImageNet16\'):\n    mean = [x / 255 for x in [122.68, 116.66, 104.01]]\n    std  = [x / 255 for x in [63.22,  61.26 , 65.09]]\n  else:\n    raise TypeError(""Unknow dataset : {:}"".format(name))\n\n  # Data Argumentation\n  if name == \'cifar10\' or name == \'cifar100\':\n    lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize(mean, std)]\n    if cutout > 0 : lists += [CUTOUT(cutout)]\n    train_transform = transforms.Compose(lists)\n    test_transform  = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n    xshape = (1, 3, 32, 32)\n  elif name.startswith(\'ImageNet16\'):\n    lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(16, padding=2), transforms.ToTensor(), transforms.Normalize(mean, std)]\n    if cutout > 0 : lists += [CUTOUT(cutout)]\n    train_transform = transforms.Compose(lists)\n    test_transform  = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n    xshape = (1, 3, 16, 16)\n  elif name == \'tiered\':\n    lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(80, padding=4), transforms.ToTensor(), transforms.Normalize(mean, std)]\n    if cutout > 0 : lists += [CUTOUT(cutout)]\n    train_transform = transforms.Compose(lists)\n    test_transform  = transforms.Compose([transforms.CenterCrop(80), transforms.ToTensor(), transforms.Normalize(mean, std)])\n    xshape = (1, 3, 32, 32)\n  elif name.startswith(\'imagenet-1k\'):\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    if name == \'imagenet-1k\':\n      xlists    = [transforms.RandomResizedCrop(224)]\n      xlists.append(\n        transforms.ColorJitter(\n        brightness=0.4,\n        contrast=0.4,\n        saturation=0.4,\n        hue=0.2))\n      xlists.append( Lighting(0.1))\n    elif name == \'imagenet-1k-s\':\n      xlists    = [transforms.RandomResizedCrop(224, scale=(0.2, 1.0))]\n    else: raise ValueError(\'invalid name : {:}\'.format(name))\n    xlists.append( transforms.RandomHorizontalFlip(p=0.5) )\n    xlists.append( transforms.ToTensor() )\n    xlists.append( normalize )\n    train_transform = transforms.Compose(xlists)\n    test_transform  = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize])\n    xshape = (1, 3, 224, 224)\n  else:\n    raise TypeError(""Unknow dataset : {:}"".format(name))\n\n  if name == \'cifar10\':\n    train_data = dset.CIFAR10 (root, train=True , transform=train_transform, download=True)\n    test_data  = dset.CIFAR10 (root, train=False, transform=test_transform , download=True)\n    assert len(train_data) == 50000 and len(test_data) == 10000\n  elif name == \'cifar100\':\n    train_data = dset.CIFAR100(root, train=True , transform=train_transform, download=True)\n    test_data  = dset.CIFAR100(root, train=False, transform=test_transform , download=True)\n    assert len(train_data) == 50000 and len(test_data) == 10000\n  elif name.startswith(\'imagenet-1k\'):\n    train_data = dset.ImageFolder(osp.join(root, \'train\'), train_transform)\n    test_data  = dset.ImageFolder(osp.join(root, \'val\'),   test_transform)\n    assert len(train_data) == 1281167 and len(test_data) == 50000, \'invalid number of images : {:} & {:} vs {:} & {:}\'.format(len(train_data), len(test_data), 1281167, 50000)\n  elif name == \'ImageNet16\':\n    train_data = ImageNet16(root, True , train_transform)\n    test_data  = ImageNet16(root, False, test_transform)\n    assert len(train_data) == 1281167 and len(test_data) == 50000\n  elif name == \'ImageNet16-120\':\n    train_data = ImageNet16(root, True , train_transform, 120)\n    test_data  = ImageNet16(root, False, test_transform , 120)\n    assert len(train_data) == 151700 and len(test_data) == 6000\n  elif name == \'ImageNet16-150\':\n    train_data = ImageNet16(root, True , train_transform, 150)\n    test_data  = ImageNet16(root, False, test_transform , 150)\n    assert len(train_data) == 190272 and len(test_data) == 7500\n  elif name == \'ImageNet16-200\':\n    train_data = ImageNet16(root, True , train_transform, 200)\n    test_data  = ImageNet16(root, False, test_transform , 200)\n    assert len(train_data) == 254775 and len(test_data) == 10000\n  else: raise TypeError(""Unknow dataset : {:}"".format(name))\n  \n  class_num = Dataset2Class[name]\n  return train_data, test_data, xshape, class_num\n\n\ndef get_nas_search_loaders(train_data, valid_data, dataset, config_root, batch_size, workers):\n  if isinstance(batch_size, (list,tuple)):\n    batch, test_batch = batch_size\n  else:\n    batch, test_batch = batch_size, batch_size\n  if dataset == \'cifar10\':\n    #split_Fpath = \'configs/nas-benchmark/cifar-split.txt\'\n    cifar_split = load_config(\'{:}/cifar-split.txt\'.format(config_root), None, None)\n    train_split, valid_split = cifar_split.train, cifar_split.valid # search over the proposed training and validation set\n    #logger.log(\'Load split file from {:}\'.format(split_Fpath))      # they are two disjoint groups in the original CIFAR-10 training set\n    # To split data\n    xvalid_data  = deepcopy(train_data)\n    if hasattr(xvalid_data, \'transforms\'): # to avoid a print issue\n      xvalid_data.transforms = valid_data.transform\n    xvalid_data.transform  = deepcopy( valid_data.transform )\n    search_data   = SearchDataset(dataset, train_data, train_split, valid_split)\n    # data loader\n    search_loader = torch.utils.data.DataLoader(search_data, batch_size=batch, shuffle=True , num_workers=workers, pin_memory=True)\n    train_loader  = torch.utils.data.DataLoader(train_data , batch_size=batch, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_split), num_workers=workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(xvalid_data, batch_size=test_batch, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=workers, pin_memory=True)\n  elif dataset == \'cifar100\':\n    cifar100_test_split = load_config(\'{:}/cifar100-test-split.txt\'.format(config_root), None, None)\n    search_train_data = train_data\n    search_valid_data = deepcopy(valid_data) ; search_valid_data.transform = train_data.transform\n    search_data   = SearchDataset(dataset, [search_train_data,search_valid_data], list(range(len(search_train_data))), cifar100_test_split.xvalid)\n    search_loader = torch.utils.data.DataLoader(search_data, batch_size=batch, shuffle=True , num_workers=workers, pin_memory=True)\n    train_loader  = torch.utils.data.DataLoader(train_data , batch_size=batch, shuffle=True , num_workers=workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data , batch_size=test_batch, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_test_split.xvalid), num_workers=workers, pin_memory=True)\n  elif dataset == \'ImageNet16-120\':\n    imagenet_test_split = load_config(\'{:}/imagenet-16-120-test-split.txt\'.format(config_root), None, None)\n    search_train_data = train_data\n    search_valid_data = deepcopy(valid_data) ; search_valid_data.transform = train_data.transform\n    search_data   = SearchDataset(dataset, [search_train_data,search_valid_data], list(range(len(search_train_data))), imagenet_test_split.xvalid)\n    search_loader = torch.utils.data.DataLoader(search_data, batch_size=batch, shuffle=True , num_workers=workers, pin_memory=True)\n    train_loader  = torch.utils.data.DataLoader(train_data , batch_size=batch, shuffle=True , num_workers=workers, pin_memory=True)\n    valid_loader  = torch.utils.data.DataLoader(valid_data , batch_size=test_batch, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet_test_split.xvalid), num_workers=workers, pin_memory=True)\n  else:\n    raise ValueError(\'invalid dataset : {:}\'.format(dataset))\n  return search_loader, train_loader, valid_loader\n\n#if __name__ == \'__main__\':\n#  train_data, test_data, xshape, class_num = dataset = get_datasets(\'cifar10\', \'/data02/dongxuanyi/.torch/cifar.python/\', -1)\n#  import pdb; pdb.set_trace()\n'"
lib/datasets/test_utils.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os\n\n\ndef test_imagenet_data(imagenet):\n  total_length = len(imagenet)\n  assert total_length == 1281166 or total_length == 50000, 'The length of ImageNet is wrong : {}'.format(total_length)\n  map_id = {}\n  for index in range(total_length):\n    path, target = imagenet.imgs[index]\n    folder, image_name = os.path.split(path)\n    _, folder = os.path.split(folder)\n    if folder not in map_id:\n      map_id[folder] = target\n    else:\n      assert map_id[folder] == target, 'Class : {} is not {}'.format(folder, target)\n    assert image_name.find(folder) == 0, '{} is wrong.'.format(path)\n  print ('Check ImageNet Dataset OK')\n"""
lib/log_utils/__init__.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\n# every package does not rely on pytorch or tensorflow\n# I tried to list all dependency here: os, sys, time, numpy, (possibly) matplotlib\nfrom .logger       import Logger, PrintLogger\nfrom .meter        import AverageMeter\nfrom .time_utils   import time_for_file, time_string, time_string_short, time_print, convert_secs2time\n'"
lib/log_utils/logger.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom pathlib import Path\nimport importlib, warnings\nimport os, sys, time, numpy as np\nif sys.version_info.major == 2: # Python 2.x\n  from StringIO import StringIO as BIO\nelse:                           # Python 3.x\n  from io import BytesIO as BIO\n\nif importlib.util.find_spec(\'tensorflow\'):\n  import tensorflow as tf\n\n\nclass PrintLogger(object):\n  \n  def __init__(self):\n    """"""Create a summary writer logging to log_dir.""""""\n    self.name = \'PrintLogger\'\n\n  def log(self, string):\n    print (string)\n\n  def close(self):\n    print (\'-\'*30 + \' close printer \' + \'-\'*30)\n\n\nclass Logger(object):\n  \n  def __init__(self, log_dir, seed, create_model_dir=True, use_tf=False):\n    """"""Create a summary writer logging to log_dir.""""""\n    self.seed      = int(seed)\n    self.log_dir   = Path(log_dir)\n    self.model_dir = Path(log_dir) / \'checkpoint\'\n    self.log_dir.mkdir  (parents=True, exist_ok=True)\n    if create_model_dir:\n      self.model_dir.mkdir(parents=True, exist_ok=True)\n    #self.meta_dir.mkdir(mode=0o775, parents=True, exist_ok=True)\n\n    self.use_tf  = bool(use_tf)\n    self.tensorboard_dir = self.log_dir / (\'tensorboard-{:}\'.format(time.strftime( \'%d-%h\', time.gmtime(time.time()) )))\n    #self.tensorboard_dir = self.log_dir / (\'tensorboard-{:}\'.format(time.strftime( \'%d-%h-at-%H:%M:%S\', time.gmtime(time.time()) )))\n    self.logger_path = self.log_dir / \'seed-{:}-T-{:}.log\'.format(self.seed, time.strftime(\'%d-%h-at-%H-%M-%S\', time.gmtime(time.time())))\n    self.logger_file = open(self.logger_path, \'w\')\n\n    if self.use_tf:\n      self.tensorboard_dir.mkdir(mode=0o775, parents=True, exist_ok=True)\n      self.writer = tf.summary.FileWriter(str(self.tensorboard_dir))\n    else:\n      self.writer = None\n\n  def __repr__(self):\n    return (\'{name}(dir={log_dir}, use-tf={use_tf}, writer={writer})\'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def path(self, mode):\n    valids = (\'model\', \'best\', \'info\', \'log\')\n    if   mode == \'model\': return self.model_dir / \'seed-{:}-basic.pth\'.format(self.seed)\n    elif mode == \'best\' : return self.model_dir / \'seed-{:}-best.pth\'.format(self.seed)\n    elif mode == \'info\' : return self.log_dir / \'seed-{:}-last-info.pth\'.format(self.seed)\n    elif mode == \'log\'  : return self.log_dir\n    else: raise TypeError(\'Unknow mode = {:}, valid modes = {:}\'.format(mode, valids))\n\n  def extract_log(self):\n    return self.logger_file\n\n  def close(self):\n    self.logger_file.close()\n    if self.writer is not None:\n      self.writer.close()\n\n  def log(self, string, save=True, stdout=False):\n    if stdout:\n      sys.stdout.write(string); sys.stdout.flush()\n    else:\n      print (string)\n    if save:\n      self.logger_file.write(\'{:}\\n\'.format(string))\n      self.logger_file.flush()\n\n  def scalar_summary(self, tags, values, step):\n    """"""Log a scalar variable.""""""\n    if not self.use_tf:\n      warnings.warn(\'Do set use-tensorflow installed but call scalar_summary\')\n    else:\n      assert isinstance(tags, list) == isinstance(values, list), \'Type : {:} vs {:}\'.format(type(tags), type(values))\n      if not isinstance(tags, list):\n        tags, values = [tags], [values]\n      for tag, value in zip(tags, values):\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n        self.writer.add_summary(summary, step)\n        self.writer.flush()\n\n  def image_summary(self, tag, images, step):\n    """"""Log a list of images.""""""\n    import scipy\n    if not self.use_tf:\n      warnings.warn(\'Do set use-tensorflow installed but call scalar_summary\')\n      return\n\n    img_summaries = []\n    for i, img in enumerate(images):\n      # Write the image to a string\n      try:\n        s = StringIO()\n      except:\n        s = BytesIO()\n      scipy.misc.toimage(img).save(s, format=""png"")\n\n      # Create an Image object\n      img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n                     height=img.shape[0],\n                     width=img.shape[1])\n      # Create a Summary value\n      img_summaries.append(tf.Summary.Value(tag=\'{}/{}\'.format(tag, i), image=img_sum))\n\n    # Create and write Summary\n    summary = tf.Summary(value=img_summaries)\n    self.writer.add_summary(summary, step)\n    self.writer.flush()\n    \n  def histo_summary(self, tag, values, step, bins=1000):\n    """"""Log a histogram of the tensor of values.""""""\n    if not self.use_tf: raise ValueError(\'Do not have tensorflow\')\n    import tensorflow as tf\n\n    # Create a histogram using numpy\n    counts, bin_edges = np.histogram(values, bins=bins)\n\n    # Fill the fields of the histogram proto\n    hist = tf.HistogramProto()\n    hist.min = float(np.min(values))\n    hist.max = float(np.max(values))\n    hist.num = int(np.prod(values.shape))\n    hist.sum = float(np.sum(values))\n    hist.sum_squares = float(np.sum(values**2))\n\n    # Drop the start of the first bin\n    bin_edges = bin_edges[1:]\n\n    # Add bin edges and counts\n    for edge in bin_edges:\n      hist.bucket_limit.append(edge)\n    for c in counts:\n      hist.bucket.append(c)\n\n    # Create and write Summary\n    summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n    self.writer.add_summary(summary, step)\n    self.writer.flush()\n'"
lib/log_utils/meter.py,0,"b'import numpy as np\n\n\nclass AverageMeter(object):     \n  """"""Computes and stores the average and current value""""""    \n  def __init__(self):   \n    self.reset()\n  \n  def reset(self):\n    self.val   = 0.0\n    self.avg   = 0.0\n    self.sum   = 0.0\n    self.count = 0.0\n  \n  def update(self, val, n=1): \n    self.val = val    \n    self.sum += val * n     \n    self.count += n\n    self.avg = self.sum / self.count    \n\n  def __repr__(self):\n    return (\'{name}(val={val}, avg={avg}, count={count})\'.format(name=self.__class__.__name__, **self.__dict__))\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0, \'total_epoch should be greater than 0 vs {:}\'.format(total_epoch)\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == self.epoch_accuracy[idx, 1]\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n\n  def plot_curve(self, save_path):\n    import matplotlib\n    matplotlib.use(\'agg\')\n    import matplotlib.pyplot as plt\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 100 \n    width, height = 1600, 1000\n    legend_fontsize = 10\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n'"
lib/log_utils/time_utils.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport time, sys\nimport numpy as np\n\ndef time_for_file():\n  ISOTIMEFORMAT=\'%d-%h-at-%H-%M-%S\'\n  return \'{:}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{:}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef time_string_short():\n  ISOTIMEFORMAT=\'%Y%m%d\'\n  string = \'{:}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef time_print(string, is_print=True):\n  if (is_print):\n    print(\'{} : {}\'.format(time_string(), string))\n\ndef convert_secs2time(epoch_time, return_str=False):    \n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)  \n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  if return_str:\n    str = \'[{:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n    return str\n  else:\n    return need_hour, need_mins, need_secs\n\ndef print_log(print_string, log):\n  #if isinstance(log, Logger): log.log(\'{:}\'.format(print_string))\n  if hasattr(log, \'log\'): log.log(\'{:}\'.format(print_string))\n  else:\n    print(""{:}"".format(print_string))\n    if log is not None:\n      log.write(\'{:}\\n\'.format(print_string))\n      log.flush()\n'"
lib/models/CifarDenseNet.py,4,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .initialization import initialize_resnet\n\n\nclass Bottleneck(nn.Module):\n  def __init__(self, nChannels, growthRate):\n    super(Bottleneck, self).__init__()\n    interChannels = 4*growthRate\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1, bias=False)\n    self.bn2 = nn.BatchNorm2d(interChannels)\n    self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3, padding=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = self.conv2(F.relu(self.bn2(out)))\n    out = torch.cat((x, out), 1)\n    return out\n\n\nclass SingleLayer(nn.Module):\n  def __init__(self, nChannels, growthRate):\n    super(SingleLayer, self).__init__()\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3, padding=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = torch.cat((x, out), 1)\n    return out\n\n\nclass Transition(nn.Module):\n  def __init__(self, nChannels, nOutChannels):\n    super(Transition, self).__init__()\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = F.avg_pool2d(out, 2)\n    return out\n\n\nclass DenseNet(nn.Module):\n  def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n    super(DenseNet, self).__init__()\n\n    if bottleneck:  nDenseBlocks = int( (depth-4) / 6 )\n    else         :  nDenseBlocks = int( (depth-4) / 3 )\n\n    self.message = 'CifarDenseNet : block : {:}, depth : {:}, reduction : {:}, growth-rate = {:}, class = {:}'.format('bottleneck' if bottleneck else 'basic', depth, reduction, growthRate, nClasses)\n\n    nChannels = 2*growthRate\n    self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1, bias=False)\n\n    self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n    nOutChannels = int(math.floor(nChannels*reduction))\n    self.trans1 = Transition(nChannels, nOutChannels)\n\n    nChannels = nOutChannels\n    self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n    nOutChannels = int(math.floor(nChannels*reduction))\n    self.trans2 = Transition(nChannels, nOutChannels)\n\n    nChannels = nOutChannels\n    self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n\n    self.act = nn.Sequential(\n                  nn.BatchNorm2d(nChannels), nn.ReLU(inplace=True),\n                  nn.AvgPool2d(8))\n    self.fc  = nn.Linear(nChannels, nClasses)\n\n    self.apply(initialize_resnet)\n\n  def get_message(self):\n    return self.message\n\n  def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n    layers = []\n    for i in range(int(nDenseBlocks)):\n      if bottleneck:\n        layers.append(Bottleneck(nChannels, growthRate))\n      else:\n        layers.append(SingleLayer(nChannels, growthRate))\n      nChannels += growthRate\n    return nn.Sequential(*layers)\n\n  def forward(self, inputs):\n    out = self.conv1( inputs )\n    out = self.trans1(self.dense1(out))\n    out = self.trans2(self.dense2(out))\n    out = self.dense3(out)\n    features = self.act(out)\n    features = features.view(features.size(0), -1)\n    out = self.fc(features)\n    return features, out\n"""
lib/models/CifarResNet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .initialization import initialize_resnet\nfrom .SharedUtils    import additive_func\n\n\nclass Downsample(nn.Module):  \n\n  def __init__(self, nIn, nOut, stride):\n    super(Downsample, self).__init__() \n    assert stride == 2 and nOut == 2*nIn, \'stride:{} IO:{},{}\'.format(stride, nIn, nOut)\n    self.in_dim  = nIn\n    self.out_dim = nOut\n    self.avg  = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)   \n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=1, stride=1, padding=0, bias=False)\n\n  def forward(self, x):\n    x   = self.avg(x)\n    out = self.conv(x)\n    return out\n\n\nclass ConvBNReLU(nn.Module):\n  \n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, relu):\n    super(ConvBNReLU, self).__init__()\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, bias=bias)\n    self.bn   = nn.BatchNorm2d(nOut)\n    if relu: self.relu = nn.ReLU(inplace=True)\n    else   : self.relu = None\n    self.out_dim = nOut\n    self.num_conv = 1\n\n  def forward(self, x):\n    conv = self.conv( x )\n    bn   = self.bn( conv )\n    if self.relu: return self.relu( bn )\n    else        : return bn\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, False)\n    if stride == 2:\n      self.downsample = Downsample(inplanes, planes, stride)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, False)\n    else:\n      self.downsample = None\n    self.out_dim = planes\n    self.num_conv = 2\n\n  def forward(self, inputs):\n\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = additive_func(residual, basicblock)\n    return F.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1, 1, 0, False, False)\n    if stride == 2:\n      self.downsample = Downsample(inplanes, planes*self.expansion, stride)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, False)\n    else:\n      self.downsample = None\n    self.out_dim = planes * self.expansion\n    self.num_conv = 3\n\n  def forward(self, inputs):\n\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = additive_func(residual, bottleneck)\n    return F.relu(out, inplace=True)\n\n\n\nclass CifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, num_classes, zero_init_residual):\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n\n    self.message     = \'CifarResNet : Block : {:}, Depth : {:}, Layers for each block : {:}\'.format(block_name, depth, layer_blocks)\n    self.num_classes = num_classes\n    self.channels    = [16]\n    self.layers      = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, True) ] )\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(module.out_dim, num_classes)\n    assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n\n    self.apply(initialize_resnet)\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, ResNetBasicblock):\n          nn.init.constant_(m.conv_b.bn.weight, 0)\n        elif isinstance(m, ResNetBottleneck):\n          nn.init.constant_(m.conv_1x4.bn.weight, 0)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/CifarWideResNet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .initialization import initialize_resnet\n\n\nclass WideBasicblock(nn.Module):\n  def __init__(self, inplanes, planes, stride, dropout=False):\n    super(WideBasicblock, self).__init__()\n\n    self.bn_a = nn.BatchNorm2d(inplanes)\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n    self.bn_b = nn.BatchNorm2d(planes)\n    if dropout:\n      self.dropout = nn.Dropout2d(p=0.5, inplace=True)\n    else:\n      self.dropout = None\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n    if inplanes != planes:\n      self.downsample = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, padding=0, bias=False)\n    else:\n      self.downsample = None\n\n  def forward(self, x):\n\n    basicblock = self.bn_a(x)\n    basicblock = F.relu(basicblock)\n    basicblock = self.conv_a(basicblock)\n\n    basicblock = self.bn_b(basicblock)\n    basicblock = F.relu(basicblock)\n    if self.dropout is not None:\n      basicblock = self.dropout(basicblock)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      x = self.downsample(x)\n    \n    return x + basicblock\n\n\nclass CifarWideResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, depth, widen_factor, num_classes, dropout):\n    super(CifarWideResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 4) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 4) // 6\n    print (\'CifarPreResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n    self.dropout = dropout\n    self.conv_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n\n    self.message  = \'Wide ResNet : depth={:}, widen_factor={:}, class={:}\'.format(depth, widen_factor, num_classes)\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(WideBasicblock, 16*widen_factor, layer_blocks, 1)\n    self.stage_2 = self._make_layer(WideBasicblock, 32*widen_factor, layer_blocks, 2)\n    self.stage_3 = self._make_layer(WideBasicblock, 64*widen_factor, layer_blocks, 2)\n    self.lastact = nn.Sequential(nn.BatchNorm2d(64*widen_factor), nn.ReLU(inplace=True))\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*widen_factor, num_classes)\n\n    self.apply(initialize_resnet)\n\n  def get_message(self):\n    return self.message\n\n  def _make_layer(self, block, planes, blocks, stride):\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, self.dropout))\n    self.inplanes = planes\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes, 1, self.dropout))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_3x3(x)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.lastact(x)\n    x = self.avgpool(x)\n    features = x.view(x.size(0), -1)\n    outs     = self.classifier(features)\n    return features, outs\n'"
lib/models/ImageNet_MobileNetV2.py,0,"b""# MobileNetV2: Inverted Residuals and Linear Bottlenecks, CVPR 2018\nfrom torch import nn\nfrom .initialization import initialize_resnet\n\n\nclass ConvBNReLU(nn.Module):\n  def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n    super(ConvBNReLU, self).__init__()\n    padding = (kernel_size - 1) // 2\n    self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False)\n    self.bn   = nn.BatchNorm2d(out_planes)\n    self.relu = nn.ReLU6(inplace=True)\n  \n  def forward(self, x):\n    out = self.conv( x )\n    out = self.bn  ( out )\n    out = self.relu( out )\n    return out\n\n\nclass InvertedResidual(nn.Module):\n  def __init__(self, inp, oup, stride, expand_ratio):\n    super(InvertedResidual, self).__init__()\n    self.stride = stride\n    assert stride in [1, 2]\n\n    hidden_dim = int(round(inp * expand_ratio))\n    self.use_res_connect = self.stride == 1 and inp == oup\n\n    layers = []\n    if expand_ratio != 1:\n      # pw\n      layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n    layers.extend([\n      # dw\n      ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n      # pw-linear\n      nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n      nn.BatchNorm2d(oup),\n    ])\n    self.conv = nn.Sequential(*layers)\n\n  def forward(self, x):\n    if self.use_res_connect:\n      return x + self.conv(x)\n    else:\n      return self.conv(x)\n\n\nclass MobileNetV2(nn.Module):\n  def __init__(self, num_classes, width_mult, input_channel, last_channel, block_name, dropout):\n    super(MobileNetV2, self).__init__()\n    if block_name == 'InvertedResidual':\n      block = InvertedResidual\n    else:\n      raise ValueError('invalid block name : {:}'.format(block_name))\n    inverted_residual_setting = [\n      # t, c,  n, s\n      [1, 16 , 1, 1],\n      [6, 24 , 2, 2],\n      [6, 32 , 3, 2],\n      [6, 64 , 4, 2],\n      [6, 96 , 3, 1],\n      [6, 160, 3, 2],\n      [6, 320, 1, 1],\n    ]\n\n    # building first layer\n    input_channel = int(input_channel * width_mult)\n    self.last_channel = int(last_channel * max(1.0, width_mult))\n    features = [ConvBNReLU(3, input_channel, stride=2)]\n    # building inverted residual blocks\n    for t, c, n, s in inverted_residual_setting:\n      output_channel = int(c * width_mult)\n      for i in range(n):\n        stride = s if i == 0 else 1\n        features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n        input_channel = output_channel\n    # building last several layers\n    features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n    # make it nn.Sequential\n    self.features = nn.Sequential(*features)\n\n    # building classifier\n    self.classifier = nn.Sequential(\n      nn.Dropout(dropout),\n      nn.Linear(self.last_channel, num_classes),\n    )\n    self.message = 'MobileNetV2 : width_mult={:}, in-C={:}, last-C={:}, block={:}, dropout={:}'.format(width_mult, input_channel, last_channel, block_name, dropout)\n\n    # weight initialization\n    self.apply( initialize_resnet )\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    features = self.features(inputs)\n    vectors  = features.mean([2, 3])\n    predicts = self.classifier(vectors)\n    return features, predicts\n"""
lib/models/ImageNet_ResNet.py,1,"b""# Deep Residual Learning for Image Recognition, CVPR 2016\nimport torch.nn as nn\nfrom .initialization import initialize_resnet\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1):\n  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, groups=groups, bias=False)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n  expansion = 1\n\n  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64):\n    super(BasicBlock, self).__init__()\n    if groups != 1 or base_width != 64:\n      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n    self.conv1 = conv3x3(inplanes, planes, stride)\n    self.bn1   = nn.BatchNorm2d(planes)\n    self.relu  = nn.ReLU(inplace=True)\n    self.conv2 = conv3x3(planes, planes)\n    self.bn2   = nn.BatchNorm2d(planes)\n    self.downsample = downsample\n    self.stride = stride\n\n  def forward(self, x):\n    identity = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n\n    if self.downsample is not None:\n      identity = self.downsample(x)\n\n    out += identity\n    out = self.relu(out)\n\n    return out\n\n\nclass Bottleneck(nn.Module):\n  expansion = 4\n\n  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64):\n    super(Bottleneck, self).__init__()\n    width = int(planes * (base_width / 64.)) * groups\n    # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n    self.conv1 = conv1x1(inplanes, width)\n    self.bn1   = nn.BatchNorm2d(width)\n    self.conv2 = conv3x3(width, width, stride, groups)\n    self.bn2   = nn.BatchNorm2d(width)\n    self.conv3 = conv1x1(width, planes * self.expansion)\n    self.bn3   = nn.BatchNorm2d(planes * self.expansion)\n    self.relu  = nn.ReLU(inplace=True)\n    self.downsample = downsample\n    self.stride = stride\n\n  def forward(self, x):\n    identity = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n    out = self.relu(out)\n\n    out = self.conv3(out)\n    out = self.bn3(out)\n\n    if self.downsample is not None:\n      identity = self.downsample(x)\n\n    out += identity\n    out = self.relu(out)\n\n    return out\n\n\nclass ResNet(nn.Module):\n\n  def __init__(self, block_name, layers, deep_stem, num_classes, zero_init_residual, groups, width_per_group):\n    super(ResNet, self).__init__()\n\n    #planes = [int(width_per_group * groups * 2 ** i) for i in range(4)]\n    if block_name == 'BasicBlock'  : block= BasicBlock\n    elif block_name == 'Bottleneck': block= Bottleneck\n    else                           : raise ValueError('invalid block-name : {:}'.format(block_name))\n\n    if not deep_stem:\n      self.conv = nn.Sequential(\n                   nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n                   nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n    else:\n      self.conv = nn.Sequential(\n                   nn.Conv2d(           3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n                   nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n                   nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n                   nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n                   nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n                   nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n    self.inplanes = 64\n    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n    self.layer1 = self._make_layer(block, 64 , layers[0], stride=1, groups=groups, base_width=width_per_group)\n    self.layer2 = self._make_layer(block, 128, layers[1], stride=2, groups=groups, base_width=width_per_group)\n    self.layer3 = self._make_layer(block, 256, layers[2], stride=2, groups=groups, base_width=width_per_group)\n    self.layer4 = self._make_layer(block, 512, layers[3], stride=2, groups=groups, base_width=width_per_group)\n    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n    self.fc      = nn.Linear(512 * block.expansion, num_classes)\n    self.message = 'block = {:}, layers = {:}, deep_stem = {:}, num_classes = {:}'.format(block, layers, deep_stem, num_classes)\n\n    self.apply( initialize_resnet )\n\n    # Zero-initialize the last BN in each residual branch,\n    # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n    # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, Bottleneck):\n          nn.init.constant_(m.bn3.weight, 0)\n        elif isinstance(m, BasicBlock):\n          nn.init.constant_(m.bn2.weight, 0)\n\n  def _make_layer(self, block, planes, blocks, stride, groups, base_width):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      if stride == 2:\n        downsample = nn.Sequential(\n          nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n          conv1x1(self.inplanes, planes * block.expansion, 1),\n          nn.BatchNorm2d(planes * block.expansion),\n        )\n      elif stride == 1:\n        downsample = nn.Sequential(\n          conv1x1(self.inplanes, planes * block.expansion, stride),\n          nn.BatchNorm2d(planes * block.expansion),\n        )\n      else: raise ValueError('invalid stride [{:}] for downsample'.format(stride))\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample, groups, base_width))\n    self.inplanes = planes * block.expansion\n    for _ in range(1, blocks):\n      layers.append(block(self.inplanes, planes, 1, None, groups, base_width))\n\n    return nn.Sequential(*layers)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = self.maxpool(x)\n\n    x = self.layer1(x)\n    x = self.layer2(x)\n    x = self.layer3(x)\n    x = self.layer4(x)\n\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.fc(features)\n\n    return features, logits\n"""
lib/models/SharedUtils.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch\nimport torch.nn as nn\n\n\ndef additive_func(A, B):\n  assert A.dim() == B.dim() and A.size(0) == B.size(0), '{:} vs {:}'.format(A.size(), B.size())\n  C = min(A.size(1), B.size(1))\n  if A.size(1) == B.size(1):\n    return A + B\n  elif A.size(1) < B.size(1):\n    out = B.clone()\n    out[:,:C] += A\n    return out\n  else:\n    out = A.clone()\n    out[:,:C] += B\n    return out\n\n\ndef change_key(key, value):\n  def func(m):\n    if hasattr(m, key):\n      setattr(m, key, value)\n  return func\n\n\ndef parse_channel_info(xstring):\n  blocks = xstring.split(' ')\n  blocks = [x.split('-') for x in blocks]\n  blocks = [[int(_) for _ in x] for x in blocks]\n  return blocks\n"""
lib/models/__init__.py,2,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom os import path as osp\nfrom typing import List, Text\nimport torch\n\n__all__ = [\'change_key\', \'get_cell_based_tiny_net\', \'get_search_spaces\', \'get_cifar_models\', \'get_imagenet_models\', \\\n           \'obtain_model\', \'obtain_search_model\', \'load_net_from_checkpoint\', \\\n           \'CellStructure\', \'CellArchitectures\'\n           ]\n\n# useful modules\nfrom config_utils import dict2config\nfrom .SharedUtils import change_key\nfrom .cell_searchs import CellStructure, CellArchitectures\n\n\n# Cell-based NAS Models\ndef get_cell_based_tiny_net(config):\n  if isinstance(config, dict): config = dict2config(config, None) # to support the argument being a dict\n  super_type = getattr(config, \'super_type\', \'basic\')\n  group_names = [\'DARTS-V1\', \'DARTS-V2\', \'GDAS\', \'SETN\', \'ENAS\', \'RANDOM\']\n  if super_type == \'basic\' and config.name in group_names:\n    from .cell_searchs import nas201_super_nets as nas_super_nets\n    try:\n      return nas_super_nets[config.name](config.C, config.N, config.max_nodes, config.num_classes, config.space, config.affine, config.track_running_stats)\n    except:\n      return nas_super_nets[config.name](config.C, config.N, config.max_nodes, config.num_classes, config.space)\n  elif super_type == \'nasnet-super\':\n    from .cell_searchs import nasnet_super_nets as nas_super_nets\n    return nas_super_nets[config.name](config.C, config.N, config.steps, config.multiplier, \\\n                    config.stem_multiplier, config.num_classes, config.space, config.affine, config.track_running_stats)\n  elif config.name == \'infer.tiny\':\n    from .cell_infers import TinyNetwork\n    if hasattr(config, \'genotype\'):\n      genotype = config.genotype\n    elif hasattr(config, \'arch_str\'):\n      genotype = CellStructure.str2structure(config.arch_str)\n    else: raise ValueError(\'Can not find genotype from this config : {:}\'.format(config))\n    return TinyNetwork(config.C, config.N, genotype, config.num_classes)\n  elif config.name == \'infer.shape.tiny\':\n    from .shape_infers import DynamicShapeTinyNet\n    if isinstance(config.channels, str):\n      channels = tuple([int(x) for x in config.channels.split(\':\')])\n    else: channels = config.channels\n    genotype = CellStructure.str2structure(config.genotype)\n    return DynamicShapeTinyNet(channels, genotype, config.num_classes)\n  elif config.name == \'infer.nasnet-cifar\':\n    from .cell_infers import NASNetonCIFAR\n    raise NotImplementedError\n  else:\n    raise ValueError(\'invalid network name : {:}\'.format(config.name))\n\n\n# obtain the search space, i.e., a dict mapping the operation name into a python-function for this op\ndef get_search_spaces(xtype, name) -> List[Text]:\n  if xtype == \'cell\':\n    from .cell_operations import SearchSpaceNames\n    assert name in SearchSpaceNames, \'invalid name [{:}] in {:}\'.format(name, SearchSpaceNames.keys())\n    return SearchSpaceNames[name]\n  else:\n    raise ValueError(\'invalid search-space type is {:}\'.format(xtype))\n\n\ndef get_cifar_models(config, extra_path=None):\n  super_type = getattr(config, \'super_type\', \'basic\')\n  if super_type == \'basic\':\n    from .CifarResNet      import CifarResNet\n    from .CifarDenseNet    import DenseNet\n    from .CifarWideResNet  import CifarWideResNet\n    if config.arch == \'resnet\':\n      return CifarResNet(config.module, config.depth, config.class_num, config.zero_init_residual)\n    elif config.arch == \'densenet\':\n      return DenseNet(config.growthRate, config.depth, config.reduction, config.class_num, config.bottleneck)\n    elif config.arch == \'wideresnet\':\n      return CifarWideResNet(config.depth, config.wide_factor, config.class_num, config.dropout)\n    else:\n      raise ValueError(\'invalid module type : {:}\'.format(config.arch))\n  elif super_type.startswith(\'infer\'):\n    from .shape_infers import InferWidthCifarResNet\n    from .shape_infers import InferDepthCifarResNet\n    from .shape_infers import InferCifarResNet\n    from .cell_infers import NASNetonCIFAR\n    assert len(super_type.split(\'-\')) == 2, \'invalid super_type : {:}\'.format(super_type)\n    infer_mode = super_type.split(\'-\')[1]\n    if infer_mode == \'width\':\n      return InferWidthCifarResNet(config.module, config.depth, config.xchannels, config.class_num, config.zero_init_residual)\n    elif infer_mode == \'depth\':\n      return InferDepthCifarResNet(config.module, config.depth, config.xblocks, config.class_num, config.zero_init_residual)\n    elif infer_mode == \'shape\':\n      return InferCifarResNet(config.module, config.depth, config.xblocks, config.xchannels, config.class_num, config.zero_init_residual)\n    elif infer_mode == \'nasnet.cifar\':\n      genotype = config.genotype\n      if extra_path is not None:  # reload genotype by extra_path\n        if not osp.isfile(extra_path): raise ValueError(\'invalid extra_path : {:}\'.format(extra_path))\n        xdata = torch.load(extra_path)\n        current_epoch = xdata[\'epoch\']\n        genotype = xdata[\'genotypes\'][current_epoch-1]\n      C = config.C if hasattr(config, \'C\') else config.ichannel\n      N = config.N if hasattr(config, \'N\') else config.layers\n      return NASNetonCIFAR(C, N, config.stem_multi, config.class_num, genotype, config.auxiliary)\n    else:\n      raise ValueError(\'invalid infer-mode : {:}\'.format(infer_mode))\n  else:\n    raise ValueError(\'invalid super-type : {:}\'.format(super_type))\n\n\ndef get_imagenet_models(config):\n  super_type = getattr(config, \'super_type\', \'basic\')\n  if super_type == \'basic\':\n    from .ImageNet_ResNet import ResNet\n    from .ImageNet_MobileNetV2 import MobileNetV2\n    if config.arch == \'resnet\':\n      return ResNet(config.block_name, config.layers, config.deep_stem, config.class_num, config.zero_init_residual, config.groups, config.width_per_group)\n    elif config.arch == \'mobilenet_v2\':\n      return MobileNetV2(config.class_num, config.width_multi, config.input_channel, config.last_channel, \'InvertedResidual\', config.dropout)\n    else:\n      raise ValueError(\'invalid arch : {:}\'.format( config.arch ))\n  elif super_type.startswith(\'infer\'): # NAS searched architecture\n    assert len(super_type.split(\'-\')) == 2, \'invalid super_type : {:}\'.format(super_type)\n    infer_mode = super_type.split(\'-\')[1]\n    if infer_mode == \'shape\':\n      from .shape_infers import InferImagenetResNet\n      from .shape_infers import InferMobileNetV2\n      if config.arch == \'resnet\':\n        return InferImagenetResNet(config.block_name, config.layers, config.xblocks, config.xchannels, config.deep_stem, config.class_num, config.zero_init_residual)\n      elif config.arch == ""MobileNetV2"":\n        return InferMobileNetV2(config.class_num, config.xchannels, config.xblocks, config.dropout)\n      else:\n        raise ValueError(\'invalid arch-mode : {:}\'.format(config.arch))\n    else:\n      raise ValueError(\'invalid infer-mode : {:}\'.format(infer_mode))\n  else:\n    raise ValueError(\'invalid super-type : {:}\'.format(super_type))\n\n\n# Try to obtain the network by config.\ndef obtain_model(config, extra_path=None):\n  if config.dataset == \'cifar\':\n    return get_cifar_models(config, extra_path)\n  elif config.dataset == \'imagenet\':\n    return get_imagenet_models(config)\n  else:\n    raise ValueError(\'invalid dataset in the model config : {:}\'.format(config))\n\n\ndef obtain_search_model(config):\n  if config.dataset == \'cifar\':\n    if config.arch == \'resnet\':\n      from .shape_searchs import SearchWidthCifarResNet\n      from .shape_searchs import SearchDepthCifarResNet\n      from .shape_searchs import SearchShapeCifarResNet\n      if config.search_mode == \'width\':\n        return SearchWidthCifarResNet(config.module, config.depth, config.class_num)\n      elif config.search_mode == \'depth\':\n        return SearchDepthCifarResNet(config.module, config.depth, config.class_num)\n      elif config.search_mode == \'shape\':\n        return SearchShapeCifarResNet(config.module, config.depth, config.class_num)\n      else: raise ValueError(\'invalid search mode : {:}\'.format(config.search_mode))\n    elif config.arch == \'simres\':\n      from .shape_searchs import SearchWidthSimResNet\n      if config.search_mode == \'width\':\n        return SearchWidthSimResNet(config.depth, config.class_num)\n      else: raise ValueError(\'invalid search mode : {:}\'.format(config.search_mode))\n    else:\n      raise ValueError(\'invalid arch : {:} for dataset [{:}]\'.format(config.arch, config.dataset))\n  elif config.dataset == \'imagenet\':\n    from .shape_searchs import SearchShapeImagenetResNet\n    assert config.search_mode == \'shape\', \'invalid search-mode : {:}\'.format( config.search_mode )\n    if config.arch == \'resnet\':\n      return SearchShapeImagenetResNet(config.block_name, config.layers, config.deep_stem, config.class_num)\n    else:\n      raise ValueError(\'invalid model config : {:}\'.format(config))\n  else:\n    raise ValueError(\'invalid dataset in the model config : {:}\'.format(config))\n\n\ndef load_net_from_checkpoint(checkpoint):\n  assert osp.isfile(checkpoint), \'checkpoint {:} does not exist\'.format(checkpoint)\n  checkpoint   = torch.load(checkpoint)\n  model_config = dict2config(checkpoint[\'model-config\'], None)\n  model        = obtain_model(model_config)\n  model.load_state_dict(checkpoint[\'base-model\'])\n  return model\n'"
lib/models/cell_operations.py,9,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport torch\nimport torch.nn as nn\n\n__all__ = ['OPS', 'ResNetBasicblock', 'SearchSpaceNames']\n\nOPS = {\n  'none'         : lambda C_in, C_out, stride, affine, track_running_stats: Zero(C_in, C_out, stride),\n  'avg_pool_3x3' : lambda C_in, C_out, stride, affine, track_running_stats: POOLING(C_in, C_out, stride, 'avg', affine, track_running_stats),\n  'max_pool_3x3' : lambda C_in, C_out, stride, affine, track_running_stats: POOLING(C_in, C_out, stride, 'max', affine, track_running_stats),\n  'nor_conv_7x7' : lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(C_in, C_out, (7,7), (stride,stride), (3,3), (1,1), affine, track_running_stats),\n  'nor_conv_3x3' : lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(C_in, C_out, (3,3), (stride,stride), (1,1), (1,1), affine, track_running_stats),\n  'nor_conv_1x1' : lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(C_in, C_out, (1,1), (stride,stride), (0,0), (1,1), affine, track_running_stats),\n  'dua_sepc_3x3' : lambda C_in, C_out, stride, affine, track_running_stats: DualSepConv(C_in, C_out, (3,3), (stride,stride), (1,1), (1,1), affine, track_running_stats),\n  'dua_sepc_5x5' : lambda C_in, C_out, stride, affine, track_running_stats: DualSepConv(C_in, C_out, (5,5), (stride,stride), (2,2), (1,1), affine, track_running_stats),\n  'dil_sepc_3x3' : lambda C_in, C_out, stride, affine, track_running_stats: SepConv(C_in, C_out, (3,3), (stride,stride), (2,2), (2,2), affine, track_running_stats),\n  'dil_sepc_5x5' : lambda C_in, C_out, stride, affine, track_running_stats: SepConv(C_in, C_out, (5,5), (stride,stride), (4,4), (2,2), affine, track_running_stats),\n  'skip_connect' : lambda C_in, C_out, stride, affine, track_running_stats: Identity() if stride == 1 and C_in == C_out else FactorizedReduce(C_in, C_out, stride, affine, track_running_stats),\n}\n\nCONNECT_NAS_BENCHMARK = ['none', 'skip_connect', 'nor_conv_3x3']\nNAS_BENCH_201         = ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\nDARTS_SPACE           = ['none', 'skip_connect', 'dua_sepc_3x3', 'dua_sepc_5x5', 'dil_sepc_3x3', 'dil_sepc_5x5', 'avg_pool_3x3', 'max_pool_3x3']\n\nSearchSpaceNames = {'connect-nas'  : CONNECT_NAS_BENCHMARK,\n                    'nas-bench-201': NAS_BENCH_201,\n                    'darts'        : DARTS_SPACE}\n\n\nclass ReLUConvBN(nn.Module):\n\n  def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine, track_running_stats=True):\n    super(ReLUConvBN, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_out, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats)\n    )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass SepConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine, track_running_stats=True):\n    super(SepConv, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats),\n      )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass DualSepConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine, track_running_stats=True):\n    super(DualSepConv, self).__init__()\n    self.op_a = SepConv(C_in, C_in , kernel_size, stride, padding, dilation, affine, track_running_stats)\n    self.op_b = SepConv(C_in, C_out, kernel_size, 1, padding, dilation, affine, track_running_stats)\n\n  def forward(self, x):\n    x = self.op_a(x)\n    x = self.op_b(x)\n    return x\n\n\nclass ResNetBasicblock(nn.Module):\n\n  def __init__(self, inplanes, planes, stride, affine=True):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, 'invalid stride {:}'.format(stride)\n    self.conv_a = ReLUConvBN(inplanes, planes, 3, stride, 1, 1, affine)\n    self.conv_b = ReLUConvBN(  planes, planes, 3,      1, 1, 1, affine)\n    if stride == 2:\n      self.downsample = nn.Sequential(\n                           nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n                           nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, padding=0, bias=False))\n    elif inplanes != planes:\n      self.downsample = ReLUConvBN(inplanes, planes, 1, 1, 0, 1, affine)\n    else:\n      self.downsample = None\n    self.in_dim  = inplanes\n    self.out_dim = planes\n    self.stride  = stride\n    self.num_conv = 2\n\n  def extra_repr(self):\n    string = '{name}(inC={in_dim}, outC={out_dim}, stride={stride})'.format(name=self.__class__.__name__, **self.__dict__)\n    return string\n\n  def forward(self, inputs):\n\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    return residual + basicblock\n\n\nclass POOLING(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, mode, affine=True, track_running_stats=True):\n    super(POOLING, self).__init__()\n    if C_in == C_out:\n      self.preprocess = None\n    else:\n      self.preprocess = ReLUConvBN(C_in, C_out, 1, 1, 0, 1, affine, track_running_stats)\n    if mode == 'avg'  : self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n    elif mode == 'max': self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n    else              : raise ValueError('Invalid mode={:} in POOLING'.format(mode))\n\n  def forward(self, inputs):\n    if self.preprocess: x = self.preprocess(inputs)\n    else              : x = inputs\n    return self.op(x)\n\n\nclass Identity(nn.Module):\n\n  def __init__(self):\n    super(Identity, self).__init__()\n\n  def forward(self, x):\n    return x\n\n\nclass Zero(nn.Module):\n\n  def __init__(self, C_in, C_out, stride):\n    super(Zero, self).__init__()\n    self.C_in   = C_in\n    self.C_out  = C_out\n    self.stride = stride\n    self.is_zero = True\n\n  def forward(self, x):\n    if self.C_in == self.C_out:\n      if self.stride == 1: return x.mul(0.)\n      else               : return x[:,:,::self.stride,::self.stride].mul(0.)\n    else:\n      shape = list(x.shape)\n      shape[1] = self.C_out\n      zeros = x.new_zeros(shape, dtype=x.dtype, device=x.device)\n      return zeros\n\n  def extra_repr(self):\n    return 'C_in={C_in}, C_out={C_out}, stride={stride}'.format(**self.__dict__)\n\n\nclass FactorizedReduce(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, affine, track_running_stats):\n    super(FactorizedReduce, self).__init__()\n    self.stride = stride\n    self.C_in   = C_in  \n    self.C_out  = C_out  \n    self.relu   = nn.ReLU(inplace=False)\n    if stride == 2:\n      #assert C_out % 2 == 0, 'C_out : {:}'.format(C_out)\n      C_outs = [C_out // 2, C_out - C_out // 2]\n      self.convs = nn.ModuleList()\n      for i in range(2):\n        self.convs.append( nn.Conv2d(C_in, C_outs[i], 1, stride=stride, padding=0, bias=False) )\n      self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n    elif stride == 1:\n      self.conv = nn.Conv2d(C_in, C_out, 1, stride=stride, padding=0, bias=False)\n    else:\n      raise ValueError('Invalid stride : {:}'.format(stride))\n    self.bn = nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats)\n\n  def forward(self, x):\n    if self.stride == 2:\n      x = self.relu(x)\n      y = self.pad(x)\n      out = torch.cat([self.convs[0](x), self.convs[1](y[:,:,1:,1:])], dim=1)\n    else:\n      out = self.conv(x)\n    out = self.bn(out)\n    return out\n\n  def extra_repr(self):\n    return 'C_in={C_in}, C_out={C_out}, stride={stride}'.format(**self.__dict__)\n\n\n# Auto-ReID: Searching for a Part-Aware ConvNet for Person Re-Identification, ICCV 2019\nclass PartAwareOp(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, part=4):\n    super().__init__()\n    self.part   = 4\n    self.hidden = C_in // 3\n    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n    self.local_conv_list = nn.ModuleList()\n    for i in range(self.part):\n      self.local_conv_list.append(\n            nn.Sequential(nn.ReLU(), nn.Conv2d(C_in, self.hidden, 1), nn.BatchNorm2d(self.hidden, affine=True))\n            )\n    self.W_K = nn.Linear(self.hidden, self.hidden)\n    self.W_Q = nn.Linear(self.hidden, self.hidden)\n\n    if stride == 2  : self.last = FactorizedReduce(C_in + self.hidden, C_out, 2)\n    elif stride == 1: self.last = FactorizedReduce(C_in + self.hidden, C_out, 1)\n    else:             raise ValueError('Invalid Stride : {:}'.format(stride))\n\n  def forward(self, x):\n    batch, C, H, W = x.size()\n    assert H >= self.part, 'input size too small : {:} vs {:}'.format(x.shape, self.part)\n    IHs = [0]\n    for i in range(self.part): IHs.append( min(H, int((i+1)*(float(H)/self.part))) )\n    local_feat_list = []\n    for i in range(self.part):\n      feature = x[:, :, IHs[i]:IHs[i+1], :]\n      xfeax   = self.avg_pool(feature)\n      xfea    = self.local_conv_list[i]( xfeax )\n      local_feat_list.append( xfea )\n    part_feature = torch.cat(local_feat_list, dim=2).view(batch, -1, self.part)\n    part_feature = part_feature.transpose(1,2).contiguous()\n    part_K       = self.W_K(part_feature)\n    part_Q       = self.W_Q(part_feature).transpose(1,2).contiguous()\n    weight_att   = torch.bmm(part_K, part_Q)\n    attention    = torch.softmax(weight_att, dim=2)\n    aggreateF    = torch.bmm(attention, part_feature).transpose(1,2).contiguous()\n    features = []\n    for i in range(self.part):\n      feature = aggreateF[:, :, i:i+1].expand(batch, self.hidden, IHs[i+1]-IHs[i])\n      feature = feature.view(batch, self.hidden, IHs[i+1]-IHs[i], 1)\n      features.append( feature )\n    features  = torch.cat(features, dim=2).expand(batch, self.hidden, H, W)\n    final_fea = torch.cat((x,features), dim=1)\n    outputs   = self.last( final_fea )\n    return outputs\n\n\n# Searching for A Robust Neural Architecture in Four GPU Hours\nclass GDAS_Reduction_Cell(nn.Module):\n\n  def __init__(self, C_prev_prev, C_prev, C, reduction_prev, multiplier, affine, track_running_stats):\n    super(GDAS_Reduction_Cell, self).__init__()\n    if reduction_prev:\n      self.preprocess0 = FactorizedReduce(C_prev_prev, C, 2, affine, track_running_stats)\n    else:\n      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, 1, affine, track_running_stats)\n    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, 1, affine, track_running_stats)\n    self.multiplier  = multiplier\n\n    self.reduction = True\n    self.ops1 = nn.ModuleList(\n                  [nn.Sequential(\n                      nn.ReLU(inplace=False),\n                      nn.Conv2d(C, C, (1, 3), stride=(1, 2), padding=(0, 1), groups=8, bias=False),\n                      nn.Conv2d(C, C, (3, 1), stride=(2, 1), padding=(1, 0), groups=8, bias=False),\n                      nn.BatchNorm2d(C, affine=True),\n                      nn.ReLU(inplace=False),\n                      nn.Conv2d(C, C, 1, stride=1, padding=0, bias=False),\n                      nn.BatchNorm2d(C, affine=True)),\n                   nn.Sequential(\n                      nn.ReLU(inplace=False),\n                      nn.Conv2d(C, C, (1, 3), stride=(1, 2), padding=(0, 1), groups=8, bias=False),\n                      nn.Conv2d(C, C, (3, 1), stride=(2, 1), padding=(1, 0), groups=8, bias=False),\n                      nn.BatchNorm2d(C, affine=True),\n                      nn.ReLU(inplace=False),\n                      nn.Conv2d(C, C, 1, stride=1, padding=0, bias=False),\n                      nn.BatchNorm2d(C, affine=True))])\n\n    self.ops2 = nn.ModuleList(\n                  [nn.Sequential(\n                      nn.MaxPool2d(3, stride=1, padding=1),\n                      nn.BatchNorm2d(C, affine=True)),\n                   nn.Sequential(\n                      nn.MaxPool2d(3, stride=2, padding=1),\n                      nn.BatchNorm2d(C, affine=True))])\n\n  def forward(self, s0, s1, drop_prob = -1):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    X0 = self.ops1[0] (s0)\n    X1 = self.ops1[1] (s1)\n    if self.training and drop_prob > 0.:\n      X0, X1 = drop_path(X0, drop_prob), drop_path(X1, drop_prob)\n\n    #X2 = self.ops2[0] (X0+X1)\n    X2 = self.ops2[0] (s0)\n    X3 = self.ops2[1] (s1)\n    if self.training and drop_prob > 0.:\n      X2, X3 = drop_path(X2, drop_prob), drop_path(X3, drop_prob)\n    return torch.cat([X0, X1, X2, X3], dim=1)\n"""
lib/models/clone_weights.py,2,"b""import torch\nimport torch.nn as nn\n\n\ndef copy_conv(module, init):\n  assert isinstance(module, nn.Conv2d), 'invalid module : {:}'.format(module)\n  assert isinstance(init  , nn.Conv2d), 'invalid module : {:}'.format(init)\n  new_i, new_o = module.in_channels, module.out_channels\n  module.weight.copy_( init.weight.detach()[:new_o, :new_i] )\n  if module.bias is not None:\n    module.bias.copy_( init.bias.detach()[:new_o] )\n\ndef copy_bn  (module, init):\n  assert isinstance(module, nn.BatchNorm2d), 'invalid module : {:}'.format(module)\n  assert isinstance(init  , nn.BatchNorm2d), 'invalid module : {:}'.format(init)\n  num_features = module.num_features\n  if module.weight is not None:\n    module.weight.copy_( init.weight.detach()[:num_features] )\n  if module.bias is not None:\n    module.bias.copy_( init.bias.detach()[:num_features] )\n  if module.running_mean is not None:\n    module.running_mean.copy_( init.running_mean.detach()[:num_features] )\n  if module.running_var  is not None:\n    module.running_var.copy_( init.running_var.detach()[:num_features] )\n\ndef copy_fc  (module, init):\n  assert isinstance(module, nn.Linear), 'invalid module : {:}'.format(module)\n  assert isinstance(init  , nn.Linear), 'invalid module : {:}'.format(init)\n  new_i, new_o = module.in_features, module.out_features\n  module.weight.copy_( init.weight.detach()[:new_o, :new_i] )\n  if module.bias is not None:\n    module.bias.copy_( init.bias.detach()[:new_o] )\n\ndef copy_base(module, init):\n  assert type(module).__name__ in ['ConvBNReLU', 'Downsample'], 'invalid module : {:}'.format(module)\n  assert type(  init).__name__ in ['ConvBNReLU', 'Downsample'], 'invalid module : {:}'.format(  init)\n  if module.conv is not None:\n    copy_conv(module.conv, init.conv)\n  if module.bn is not None:\n    copy_bn  (module.bn, init.bn)\n\ndef copy_basic(module, init):\n  copy_base(module.conv_a, init.conv_a)\n  copy_base(module.conv_b, init.conv_b)\n  if module.downsample is not None:\n    if init.downsample is not None:\n      copy_base(module.downsample, init.downsample)\n    #else:\n    # import pdb; pdb.set_trace()\n\n\ndef init_from_model(network, init_model):\n  with torch.no_grad():\n    copy_fc(network.classifier, init_model.classifier)\n    for base, target in zip(init_model.layers, network.layers):\n      assert type(base).__name__  == type(target).__name__, 'invalid type : {:} vs {:}'.format(base, target)\n      if type(base).__name__ == 'ConvBNReLU':\n        copy_base(target, base)\n      elif type(base).__name__ == 'ResNetBasicblock':\n        copy_basic(target, base)\n      else:\n        raise ValueError('unknown type name : {:}'.format( type(base).__name__ ))\n"""
lib/models/initialization.py,1,"b""import torch\nimport torch.nn as nn\n\n\ndef initialize_resnet(m):\n  if isinstance(m, nn.Conv2d):\n    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    if m.bias is not None:\n      nn.init.constant_(m.bias, 0)\n  elif isinstance(m, nn.BatchNorm2d):\n    nn.init.constant_(m.weight, 1)\n    if m.bias is not None:\n      nn.init.constant_(m.bias, 0)\n  elif isinstance(m, nn.Linear):\n    nn.init.normal_(m.weight, 0, 0.01)\n    nn.init.constant_(m.bias, 0)\n\n\n"""
lib/nas_201_api/__init__.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\nfrom .api import NASBench201API\nfrom .api import ArchResults, ResultsCount\n\n# NAS_BENCH_201_API_VERSION=""v1.1""  # [2020.02.25]\n# NAS_BENCH_201_API_VERSION=""v1.2""  # [2020.03.09]\nNAS_BENCH_201_API_VERSION=""v1.3""  # [2020.03.16]\n'"
lib/nas_201_api/api.py,3,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n############################################################################################\n# NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search, ICLR 2020 #\n############################################################################################\n# The history of benchmark files:\n# [2020.02.25] NAS-Bench-201-v1_0-e61699.pth : 6219 architectures are trained once, 1621 architectures are trained twice, 7785 architectures are trained three times. `LESS` only supports CIFAR10-VALID.\n# [2020.03.16] NAS-Bench-201-v1_1-096897.pth : 2225 architectures are trained once, 5439 archiitectures are trained twice, 7961 architectures are trained three times on all training sets. For the hyper-parameters with the total epochs of 12, each model is trained on CIFAR-10, CIFAR-100, ImageNet16-120 once, and is trained on CIFAR-10-VALID twice.\n#\n# I\'m still actively enhancing this benchmark. Please feel free to contact me if you have any question w.r.t. NAS-Bench-201.\n#\nimport os, copy, random, torch, numpy as np\nfrom pathlib import Path\nfrom typing import List, Text, Union, Dict\nfrom collections import OrderedDict, defaultdict\n\n\ndef print_information(information, extra_info=None, show=False):\n  dataset_names = information.get_dataset_names()\n  strings = [information.arch_str, \'datasets : {:}, extra-info : {:}\'.format(dataset_names, extra_info)]\n  def metric2str(loss, acc):\n    return \'loss = {:.3f}, top1 = {:.2f}%\'.format(loss, acc)\n\n  for ida, dataset in enumerate(dataset_names):\n    metric = information.get_compute_costs(dataset)\n    flop, param, latency = metric[\'flops\'], metric[\'params\'], metric[\'latency\']\n    str1 = \'{:14s} FLOP={:6.2f} M, Params={:.3f} MB, latency={:} ms.\'.format(dataset, flop, param, \'{:.2f}\'.format(latency*1000) if latency is not None and latency > 0 else None)\n    train_info = information.get_metrics(dataset, \'train\')\n    if dataset == \'cifar10-valid\':\n      valid_info = information.get_metrics(dataset, \'x-valid\')\n      str2 = \'{:14s} train : [{:}], valid : [{:}]\'.format(dataset, metric2str(train_info[\'loss\'], train_info[\'accuracy\']), metric2str(valid_info[\'loss\'], valid_info[\'accuracy\']))\n    elif dataset == \'cifar10\':\n      test__info = information.get_metrics(dataset, \'ori-test\')\n      str2 = \'{:14s} train : [{:}], test  : [{:}]\'.format(dataset, metric2str(train_info[\'loss\'], train_info[\'accuracy\']), metric2str(test__info[\'loss\'], test__info[\'accuracy\']))\n    else:\n      valid_info = information.get_metrics(dataset, \'x-valid\')\n      test__info = information.get_metrics(dataset, \'x-test\')\n      str2 = \'{:14s} train : [{:}], valid : [{:}], test : [{:}]\'.format(dataset, metric2str(train_info[\'loss\'], train_info[\'accuracy\']), metric2str(valid_info[\'loss\'], valid_info[\'accuracy\']), metric2str(test__info[\'loss\'], test__info[\'accuracy\']))\n    strings += [str1, str2]\n  if show: print(\'\\n\'.join(strings))\n  return strings\n\n""""""\nThis is the class for API of NAS-Bench-201.\n""""""\nclass NASBench201API(object):\n\n  """""" The initialization function that takes the dataset file path (or a dict loaded from that path) as input. """"""\n  def __init__(self, file_path_or_dict: Union[Text, Dict], verbose: bool=True):\n    self.filename = None\n    if isinstance(file_path_or_dict, str) or isinstance(file_path_or_dict, Path):\n      file_path_or_dict = str(file_path_or_dict)\n      if verbose: print(\'try to create the NAS-Bench-201 api from {:}\'.format(file_path_or_dict))\n      assert os.path.isfile(file_path_or_dict), \'invalid path : {:}\'.format(file_path_or_dict)\n      self.filename = Path(file_path_or_dict).name\n      file_path_or_dict = torch.load(file_path_or_dict, map_location=\'cpu\')\n    elif isinstance(file_path_or_dict, dict):\n      file_path_or_dict = copy.deepcopy( file_path_or_dict )\n    else: raise ValueError(\'invalid type : {:} not in [str, dict]\'.format(type(file_path_or_dict)))\n    assert isinstance(file_path_or_dict, dict), \'It should be a dict instead of {:}\'.format(type(file_path_or_dict))\n    self.verbose = verbose # [TODO] a flag indicating whether to print more logs\n    keys = (\'meta_archs\', \'arch2infos\', \'evaluated_indexes\')\n    for key in keys: assert key in file_path_or_dict, \'Can not find key[{:}] in the dict\'.format(key)\n    self.meta_archs = copy.deepcopy( file_path_or_dict[\'meta_archs\'] )\n    self.arch2infos_less = OrderedDict()\n    self.arch2infos_full = OrderedDict()\n    for xkey in sorted(list(file_path_or_dict[\'arch2infos\'].keys())):\n      all_info = file_path_or_dict[\'arch2infos\'][xkey]\n      self.arch2infos_less[xkey] = ArchResults.create_from_state_dict( all_info[\'less\'] )\n      self.arch2infos_full[xkey] = ArchResults.create_from_state_dict( all_info[\'full\'] )\n    self.evaluated_indexes = sorted(list(file_path_or_dict[\'evaluated_indexes\']))\n    self.archstr2index = {}\n    for idx, arch in enumerate(self.meta_archs):\n      #assert arch.tostr() not in self.archstr2index, \'This [{:}]-th arch {:} already in the dict ({:}).\'.format(idx, arch, self.archstr2index[arch.tostr()])\n      assert arch not in self.archstr2index, \'This [{:}]-th arch {:} already in the dict ({:}).\'.format(idx, arch, self.archstr2index[arch])\n      self.archstr2index[ arch ] = idx\n\n  def __getitem__(self, index: int):\n    return copy.deepcopy( self.meta_archs[index] )\n\n  def __len__(self):\n    return len(self.meta_archs)\n\n  def __repr__(self):\n    return (\'{name}({num}/{total} architectures, file={filename})\'.format(name=self.__class__.__name__, num=len(self.evaluated_indexes), total=len(self.meta_archs), filename=self.filename))\n\n  def random(self):\n    """"""Return a random index of all architectures.""""""\n    return random.randint(0, len(self.meta_archs)-1)\n\n  # This function is used to query the index of an architecture in the search space.\n  # The input arch can be an architecture string such as \'|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|skip_connect~2|\'\n  # or an instance that has the \'tostr\' function that can generate the architecture string.\n  # This function will return the index.\n  #   If return -1, it means this architecture is not in the search space.\n  #   Otherwise, it will return an int in [0, the-number-of-candidates-in-the-search-space).\n  def query_index_by_arch(self, arch):\n    if isinstance(arch, str):\n      if arch in self.archstr2index: arch_index = self.archstr2index[ arch ]\n      else                         : arch_index = -1\n    elif hasattr(arch, \'tostr\'):\n      if arch.tostr() in self.archstr2index: arch_index = self.archstr2index[ arch.tostr() ]\n      else                                 : arch_index = -1\n    else: arch_index = -1\n    return arch_index\n\n  def reload(self, archive_root: Text, index: int):\n    """"""Overwrite all information of the \'index\'-th architecture in the search space.\n         It will load its data from \'archive_root\'.\n    """"""\n    assert os.path.isdir(archive_root), \'invalid directory : {:}\'.format(archive_root)\n    xfile_path = os.path.join(archive_root, \'{:06d}-FULL.pth\'.format(index))\n    assert 0 <= index < len(self.meta_archs), \'invalid index of {:}\'.format(index)\n    assert os.path.isfile(xfile_path), \'invalid data path : {:}\'.format(xfile_path)\n    xdata = torch.load(xfile_path, map_location=\'cpu\')\n    assert isinstance(xdata, dict) and \'full\' in xdata and \'less\' in xdata, \'invalid format of data in {:}\'.format(xfile_path)\n    if index in self.arch2infos_less: del self.arch2infos_less[index]\n    if index in self.arch2infos_full: del self.arch2infos_full[index]\n    self.arch2infos_less[index] = ArchResults.create_from_state_dict( xdata[\'less\'] )\n    self.arch2infos_full[index] = ArchResults.create_from_state_dict( xdata[\'full\'] )\n\n  def clear_params(self, index: int, use_12epochs_result: Union[bool, None]):\n    """"""Remove the architecture\'s weights to save memory.\n    :arg\n      index: the index of the target architecture\n      use_12epochs_result: a flag to controll how to clear the parameters.\n        -- None: clear all the weights in both `less` and `full`, which indicates the training hyper-parameters.\n        -- True: clear all the weights in arch2infos_less, which by default is 12-epoch-training result.\n        -- False: clear all the weights in arch2infos_full, which by default is 200-epoch-training result.\n    """"""\n    if use_12epochs_result is None:\n      self.arch2infos_less[index].clear_params()\n      self.arch2infos_full[index].clear_params()\n    else:\n      if use_12epochs_result: arch2infos = self.arch2infos_less\n      else                  : arch2infos = self.arch2infos_full\n      arch2infos[index].clear_params()\n  \n  # This function is used to query the information of a specific archiitecture\n  # \'arch\' can be an architecture index or an architecture string\n  # When use_12epochs_result=True, the hyper-parameters used to train a model are in \'configs/nas-benchmark/CIFAR.config\'\n  # When use_12epochs_result=False, the hyper-parameters used to train a model are in \'configs/nas-benchmark/LESS.config\'\n  # The difference between these two configurations are the number of training epochs, which is 200 in CIFAR.config and 12 in LESS.config.\n  def query_by_arch(self, arch, use_12epochs_result=False):\n    if isinstance(arch, int):\n      arch_index = arch\n    else:\n      arch_index = self.query_index_by_arch(arch)\n    if arch_index == -1: return None # the following two lines are used to support few training epochs\n    if use_12epochs_result: arch2infos = self.arch2infos_less\n    else                  : arch2infos = self.arch2infos_full\n    if arch_index in arch2infos:\n      strings = print_information(arch2infos[ arch_index ], \'arch-index={:}\'.format(arch_index))\n      return \'\\n\'.join(strings)\n    else:\n      print (\'Find this arch-index : {:}, but this arch is not evaluated.\'.format(arch_index))\n      return None\n\n  # This \'query_by_index\' function is used to query information with the training of 12 epochs or 200 epochs.\n  # ------\n  # If use_12epochs_result=True, we train the model by 12 epochs (see config in configs/nas-benchmark/LESS.config)\n  # If use_12epochs_result=False, we train the model by 200 epochs (see config in configs/nas-benchmark/CIFAR.config)\n  # ------\n  # If dataname is None, return the ArchResults\n  # else, return a dict with all trials on that dataset (the key is the seed)\n  # Options are \'cifar10-valid\', \'cifar10\', \'cifar100\', \'ImageNet16-120\'.\n  #  -- cifar10-valid : training the model on the CIFAR-10 training set.\n  #  -- cifar10 : training the model on the CIFAR-10 training + validation set.\n  #  -- cifar100 : training the model on the CIFAR-100 training set.\n  #  -- ImageNet16-120 : training the model on the ImageNet16-120 training set.\n  def query_by_index(self, arch_index: int, dataname: Union[None, Text] = None,\n                     use_12epochs_result: bool = False):\n    if use_12epochs_result: basestr, arch2infos = \'12epochs\' , self.arch2infos_less\n    else                  : basestr, arch2infos = \'200epochs\', self.arch2infos_full\n    assert arch_index in arch2infos, \'arch_index [{:}] does not in arch2info with {:}\'.format(arch_index, basestr)\n    archInfo = copy.deepcopy( arch2infos[ arch_index ] )\n    if dataname is None: return archInfo\n    else:\n      assert dataname in archInfo.get_dataset_names(), \'invalid dataset-name : {:}\'.format(dataname)\n      info = archInfo.query(dataname)\n      return info\n\n  def query_meta_info_by_index(self, arch_index, use_12epochs_result=False):\n    if use_12epochs_result: basestr, arch2infos = \'12epochs\' , self.arch2infos_less\n    else                  : basestr, arch2infos = \'200epochs\', self.arch2infos_full\n    assert arch_index in arch2infos, \'arch_index [{:}] does not in arch2info with {:}\'.format(arch_index, basestr)\n    archInfo = copy.deepcopy( arch2infos[ arch_index ] )\n    return archInfo\n\n  def find_best(self, dataset, metric_on_set, FLOP_max=None, Param_max=None, use_12epochs_result=False):\n    """"""Find the architecture with the highest accuracy based on some constraints.""""""\n    if use_12epochs_result: basestr, arch2infos = \'12epochs\' , self.arch2infos_less\n    else                  : basestr, arch2infos = \'200epochs\', self.arch2infos_full\n    best_index, highest_accuracy = -1, None\n    for i, idx in enumerate(self.evaluated_indexes):\n      info = arch2infos[idx].get_compute_costs(dataset)\n      flop, param, latency = info[\'flops\'], info[\'params\'], info[\'latency\']\n      if FLOP_max  is not None and flop  > FLOP_max : continue\n      if Param_max is not None and param > Param_max: continue\n      xinfo = arch2infos[idx].get_metrics(dataset, metric_on_set)\n      loss, accuracy = xinfo[\'loss\'], xinfo[\'accuracy\']\n      if best_index == -1:\n        best_index, highest_accuracy = idx, accuracy\n      elif highest_accuracy < accuracy:\n        best_index, highest_accuracy = idx, accuracy\n    return best_index, highest_accuracy\n\n  def arch(self, index: int):\n    """"""Return the topology structure of the `index`-th architecture.""""""\n    assert 0 <= index < len(self.meta_archs), \'invalid index : {:} vs. {:}.\'.format(index, len(self.meta_archs))\n    return copy.deepcopy(self.meta_archs[index])\n\n  def get_net_param(self, index, dataset, seed, use_12epochs_result=False):\n    """"""\n      This function is used to obtain the trained weights of the `index`-th architecture on `dataset` with the seed of `seed`\n      Args [seed]:\n        -- None : return a dict containing the trained weights of all trials, where each key is a seed and its corresponding value is the weights.\n        -- a interger : return the weights of a specific trial, whose seed is this interger.\n      Args [use_12epochs_result]:\n        -- True : train the model by 12 epochs\n        -- False : train the model by 200 epochs\n    """"""\n    if use_12epochs_result: arch2infos = self.arch2infos_less\n    else: arch2infos = self.arch2infos_full\n    arch_result = arch2infos[index]\n    return arch_result.get_net_param(dataset, seed)\n\n  def get_net_config(self, index: int, dataset: Text):\n    """"""\n      This function is used to obtain the configuration for the `index`-th architecture on `dataset`.\n      Args [dataset] (4 possible options):\n        -- cifar10-valid : training the model on the CIFAR-10 training set.\n        -- cifar10 : training the model on the CIFAR-10 training + validation set.\n        -- cifar100 : training the model on the CIFAR-100 training set.\n        -- ImageNet16-120 : training the model on the ImageNet16-120 training set.\n      This function will return a dict.\n      ========= Some examlpes for using this function:\n      config = api.get_net_config(128, \'cifar10\')\n    """"""\n    archresult = self.arch2infos_full[index]\n    all_results = archresult.query(dataset, None)\n    if len(all_results) == 0: raise ValueError(\'can not find one valid trial for the {:}-th architecture on {:}\'.format(index, dataset))\n    for seed, result in all_results.items():\n      return result.get_config(None)\n      #print (\'SEED [{:}] : {:}\'.format(seed, result))\n    raise ValueError(\'Impossible to reach here!\')\n\n  def get_cost_info(self, index: int, dataset: Text, use_12epochs_result: bool = False) -> Dict[Text, float]:\n    """"""To obtain the cost metric for the `index`-th architecture on a dataset.""""""\n    if use_12epochs_result: arch2infos = self.arch2infos_less\n    else: arch2infos = self.arch2infos_full\n    arch_result = arch2infos[index]\n    return arch_result.get_compute_costs(dataset)\n\n  def get_latency(self, index: int, dataset: Text, use_12epochs_result: bool = False) -> float:\n    """"""\n    To obtain the latency of the network (by default it will return the latency with the batch size of 256).\n    :param index: the index of the target architecture\n    :param dataset: the dataset name (cifar10-valid, cifar10, cifar100, ImageNet16-120)\n    :return: return a float value in seconds\n    """"""\n    cost_dict = self.get_cost_info(index, dataset, use_12epochs_result)\n    return cost_dict[\'latency\']\n\n  # obtain the metric for the `index`-th architecture\n  # `dataset` indicates the dataset:\n  #   \'cifar10-valid\'  : using the proposed train set of CIFAR-10 as the training set\n  #   \'cifar10\'        : using the proposed train+valid set of CIFAR-10 as the training set\n  #   \'cifar100\'       : using the proposed train set of CIFAR-100 as the training set\n  #   \'ImageNet16-120\' : using the proposed train set of ImageNet-16-120 as the training set\n  # `iepoch` indicates the index of training epochs from 0 to 11/199.\n  #   When iepoch=None, it will return the metric for the last training epoch\n  #   When iepoch=11, it will return the metric for the 11-th training epoch (starting from 0)\n  # `use_12epochs_result` indicates different hyper-parameters for training\n  #   When use_12epochs_result=True, it trains the network with 12 epochs and the LR decayed from 0.1 to 0 within 12 epochs\n  #   When use_12epochs_result=False, it trains the network with 200 epochs and the LR decayed from 0.1 to 0 within 200 epochs\n  # `is_random`\n  #   When is_random=True, the performance of a random architecture will be returned\n  #   When is_random=False, the performanceo of all trials will be averaged.\n  def get_more_info(self, index: int, dataset, iepoch=None, use_12epochs_result=False, is_random=True):\n    if use_12epochs_result: basestr, arch2infos = \'12epochs\' , self.arch2infos_less\n    else                  : basestr, arch2infos = \'200epochs\', self.arch2infos_full\n    archresult = arch2infos[index]\n    # if randomly select one trial, select the seed at first\n    if isinstance(is_random, bool) and is_random:\n      seeds = archresult.get_dataset_seeds(dataset)\n      is_random = random.choice(seeds)\n    # collect the training information\n    train_info = archresult.get_metrics(dataset, \'train\', iepoch=iepoch, is_random=is_random)\n    total = train_info[\'iepoch\'] + 1\n    xinfo = {\'train-loss\'    : train_info[\'loss\'],\n             \'train-accuracy\': train_info[\'accuracy\'],\n             \'train-per-time\': train_info[\'all_time\'] / total,\n             \'train-all-time\': train_info[\'all_time\']}\n    # collect the evaluation information\n    if dataset == \'cifar10-valid\':\n      valid_info = archresult.get_metrics(dataset, \'x-valid\', iepoch=iepoch, is_random=is_random)\n      try:\n        test_info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n      except:\n        test_info = None\n      valtest_info = None\n    else:\n      try: # collect results on the proposed test set\n        if dataset == \'cifar10\':\n          test_info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n        else:\n          test_info = archresult.get_metrics(dataset, \'x-test\', iepoch=iepoch, is_random=is_random)\n      except:\n        test_info = None\n      try: # collect results on the proposed validation set\n        valid_info = archresult.get_metrics(dataset, \'x-valid\', iepoch=iepoch, is_random=is_random)\n      except:\n        valid_info = None\n      try:\n        if dataset != \'cifar10\':\n          valtest_info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n        else:\n          valtest_info = None\n      except:\n        valtest_info = None\n    if valid_info is not None:\n      xinfo[\'valid-loss\'] = valid_info[\'loss\']\n      xinfo[\'valid-accuracy\'] = valid_info[\'accuracy\']\n      xinfo[\'valid-per-time\'] = valid_info[\'all_time\'] / total\n      xinfo[\'valid-all-time\'] = valid_info[\'all_time\']\n    if test_info is not None:\n      xinfo[\'test-loss\'] = test_info[\'loss\']\n      xinfo[\'test-accuracy\'] = test_info[\'accuracy\']\n      xinfo[\'test-per-time\'] = test_info[\'all_time\'] / total\n      xinfo[\'test-all-time\'] = test_info[\'all_time\']\n    if valtest_info is not None:\n      xinfo[\'valtest-loss\'] = valtest_info[\'loss\']\n      xinfo[\'valtest-accuracy\'] = valtest_info[\'accuracy\']\n      xinfo[\'valtest-per-time\'] = valtest_info[\'all_time\'] / total\n      xinfo[\'valtest-all-time\'] = valtest_info[\'all_time\']\n    return xinfo\n  """""" # The following logic is deprecated after March 15 2020, where the benchmark file upgrades from NAS-Bench-201-v1_0-e61699.pth to NAS-Bench-201-v1_1-096897.pth.\n  def get_more_info(self, index: int, dataset, iepoch=None, use_12epochs_result=False, is_random=True):\n    if use_12epochs_result: basestr, arch2infos = \'12epochs\' , self.arch2infos_less\n    else                  : basestr, arch2infos = \'200epochs\', self.arch2infos_full\n    archresult = arch2infos[index]\n    # if randomly select one trial, select the seed at first\n    if isinstance(is_random, bool) and is_random:\n      seeds = archresult.get_dataset_seeds(dataset)\n      is_random = random.choice(seeds)\n    if dataset == \'cifar10-valid\':\n      train_info = archresult.get_metrics(dataset, \'train\'   , iepoch=iepoch, is_random=is_random)\n      valid_info = archresult.get_metrics(dataset, \'x-valid\' , iepoch=iepoch, is_random=is_random)\n      try:\n        test__info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n      except:\n        test__info = None\n      total      = train_info[\'iepoch\'] + 1\n      xifo = {\'train-loss\'    : train_info[\'loss\'],\n              \'train-accuracy\': train_info[\'accuracy\'],\n              \'train-per-time\': None if train_info[\'all_time\'] is None else train_info[\'all_time\'] / total,\n              \'train-all-time\': train_info[\'all_time\'],\n              \'valid-loss\'    : valid_info[\'loss\'],\n              \'valid-accuracy\': valid_info[\'accuracy\'],\n              \'valid-all-time\': valid_info[\'all_time\'],\n              \'valid-per-time\': None if valid_info[\'all_time\'] is None else valid_info[\'all_time\'] / total}\n      if test__info is not None:\n        xifo[\'test-loss\']     = test__info[\'loss\']\n        xifo[\'test-accuracy\'] = test__info[\'accuracy\']\n      return xifo\n    else:\n      train_info = archresult.get_metrics(dataset, \'train\'   , iepoch=iepoch, is_random=is_random)\n      try:\n        if dataset == \'cifar10\':\n          test__info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n        else:\n          test__info = archresult.get_metrics(dataset, \'x-test\', iepoch=iepoch, is_random=is_random)\n      except:\n        test__info = None\n      try:\n        valid_info = archresult.get_metrics(dataset, \'x-valid\', iepoch=iepoch, is_random=is_random)\n      except:\n        valid_info = None\n      try:\n        est_valid_info = archresult.get_metrics(dataset, \'ori-test\', iepoch=iepoch, is_random=is_random)\n      except:\n        est_valid_info = None\n      xifo = {\'train-loss\'    : train_info[\'loss\'],\n              \'train-accuracy\': train_info[\'accuracy\']}\n      if test__info is not None:\n        xifo[\'test-loss\'] = test__info[\'loss\'],\n        xifo[\'test-accuracy\'] = test__info[\'accuracy\']\n      if valid_info is not None:\n        xifo[\'valid-loss\'] = valid_info[\'loss\']\n        xifo[\'valid-accuracy\'] = valid_info[\'accuracy\']\n      if est_valid_info is not None:\n        xifo[\'est-valid-loss\'] = est_valid_info[\'loss\']\n        xifo[\'est-valid-accuracy\'] = est_valid_info[\'accuracy\']\n      return xifo\n  """"""\n\n  def show(self, index: int = -1) -> None:\n    """"""\n    This function will print the information of a specific (or all) architecture(s).\n\n    :param index: If the index < 0: it will loop for all architectures and print their information one by one.\n                  else: it will print the information of the \'index\'-th archiitecture.\n    :return: nothing\n    """"""\n    if index < 0: # show all architectures\n      print(self)\n      for i, idx in enumerate(self.evaluated_indexes):\n        print(\'\\n\' + \'-\' * 10 + \' The ({:5d}/{:5d}) {:06d}-th architecture! \'.format(i, len(self.evaluated_indexes), idx) + \'-\'*10)\n        print(\'arch : {:}\'.format(self.meta_archs[idx]))\n        strings = print_information(self.arch2infos_full[idx])\n        print(\'>\' * 40 + \' {:03d} epochs \'.format(self.arch2infos_full[idx].get_total_epoch()) + \'>\' * 40)\n        print(\'\\n\'.join(strings))\n        strings = print_information(self.arch2infos_less[idx])\n        print(\'>\' * 40 + \' {:03d} epochs \'.format(self.arch2infos_less[idx].get_total_epoch()) + \'>\' * 40)\n        print(\'\\n\'.join(strings))\n        print(\'<\' * 40 + \'------------\' + \'<\' * 40)\n    else:\n      if 0 <= index < len(self.meta_archs):\n        if index not in self.evaluated_indexes: print(\'The {:}-th architecture has not been evaluated or not saved.\'.format(index))\n        else:\n          strings = print_information(self.arch2infos_full[index])\n          print(\'>\' * 40 + \' {:03d} epochs \'.format(self.arch2infos_full[index].get_total_epoch()) + \'>\' * 40)\n          print(\'\\n\'.join(strings))\n          strings = print_information(self.arch2infos_less[index])\n          print(\'>\' * 40 + \' {:03d} epochs \'.format(self.arch2infos_less[index].get_total_epoch()) + \'>\' * 40)\n          print(\'\\n\'.join(strings))\n          print(\'<\' * 40 + \'------------\' + \'<\' * 40)\n      else:\n        print(\'This index ({:}) is out of range (0~{:}).\'.format(index, len(self.meta_archs)))\n\n  def statistics(self, dataset: Text, use_12epochs_result: bool) -> Dict[int, int]:\n    """"""\n    This function will count the number of total trials.\n    """"""\n    valid_datasets = [\'cifar10-valid\', \'cifar10\', \'cifar100\', \'ImageNet16-120\']\n    if dataset not in valid_datasets:\n      raise ValueError(\'{:} not in {:}\'.format(dataset, valid_datasets))\n    if use_12epochs_result: arch2infos = self.arch2infos_less\n    else                  : arch2infos = self.arch2infos_full\n    nums = defaultdict(lambda: 0)\n    for index in range(len(self)):\n      archInfo = arch2infos[index]\n      dataset_seed = archInfo.dataset_seed\n      if dataset not in dataset_seed:\n        nums[0] += 1\n      else:\n        nums[len(dataset_seed[dataset])] += 1\n    return dict(nums)\n\n  @staticmethod\n  def str2lists(arch_str: Text) -> List[tuple]:\n    """"""\n    This function shows how to read the string-based architecture encoding.\n      It is the same as the `str2structure` func in `AutoDL-Projects/lib/models/cell_searchs/genotypes.py`\n\n    :param\n      arch_str: the input is a string indicates the architecture topology, such as\n                    |nor_conv_1x1~0|+|none~0|none~1|+|none~0|none~1|skip_connect~2|\n    :return: a list of tuple, contains multiple (op, input_node_index) pairs.\n\n    :usage\n      arch = api.str2lists( \'|nor_conv_1x1~0|+|none~0|none~1|+|none~0|none~1|skip_connect~2|\' )\n      print (\'there are {:} nodes in this arch\'.format(len(arch)+1)) # arch is a list\n      for i, node in enumerate(arch):\n        print(\'the {:}-th node is the sum of these {:} nodes with op: {:}\'.format(i+1, len(node), node))\n    """"""\n    node_strs = arch_str.split(\'+\')\n    genotypes = []\n    for i, node_str in enumerate(node_strs):\n      inputs = list(filter(lambda x: x != \'\', node_str.split(\'|\')))\n      for xinput in inputs: assert len(xinput.split(\'~\')) == 2, \'invalid input length : {:}\'.format(xinput)\n      inputs = ( xi.split(\'~\') for xi in inputs )\n      input_infos = tuple( (op, int(IDX)) for (op, IDX) in inputs)\n      genotypes.append( input_infos )\n    return genotypes\n\n  @staticmethod\n  def str2matrix(arch_str: Text,\n                 search_space: List[Text] = [\'none\', \'skip_connect\', \'nor_conv_1x1\', \'nor_conv_3x3\', \'avg_pool_3x3\']) -> np.ndarray:\n    """"""\n    This func shows how to convert the string-based architecture encoding to the encoding strategy in NAS-Bench-101.\n\n    :param\n      arch_str: the input is a string indicates the architecture topology, such as\n                    |nor_conv_1x1~0|+|none~0|none~1|+|none~0|none~1|skip_connect~2|\n      search_space: a list of operation string, the default list is the search space for NAS-Bench-201\n        the default value should be be consistent with this line https://github.com/D-X-Y/AutoDL-Projects/blob/master/lib/models/cell_operations.py#L24\n    :return\n      the numpy matrix (2-D np.ndarray) representing the DAG of this architecture topology\n    :usage\n      matrix = api.str2matrix( \'|nor_conv_1x1~0|+|none~0|none~1|+|none~0|none~1|skip_connect~2|\' )\n      This matrix is 4-by-4 matrix representing a cell with 4 nodes (only the lower left triangle is useful).\n         [ [0, 0, 0, 0],  # the first line represents the input (0-th) node\n           [2, 0, 0, 0],  # the second line represents the 1-st node, is calculated by 2-th-op( 0-th-node )\n           [0, 0, 0, 0],  # the third line represents the 2-nd node, is calculated by 0-th-op( 0-th-node ) + 0-th-op( 1-th-node )\n           [0, 0, 1, 0] ] # the fourth line represents the 3-rd node, is calculated by 0-th-op( 0-th-node ) + 0-th-op( 1-th-node ) + 1-th-op( 2-th-node )\n      In NAS-Bench-201 search space, 0-th-op is \'none\', 1-th-op is \'skip_connect\',\n         2-th-op is \'nor_conv_1x1\', 3-th-op is \'nor_conv_3x3\', 4-th-op is \'avg_pool_3x3\'.\n    :(NOTE)\n      If a node has two input-edges from the same node, this function does not work. One edge will be overlapped.\n    """"""\n    node_strs = arch_str.split(\'+\')\n    num_nodes = len(node_strs) + 1\n    matrix = np.zeros((num_nodes, num_nodes))\n    for i, node_str in enumerate(node_strs):\n      inputs = list(filter(lambda x: x != \'\', node_str.split(\'|\')))\n      for xinput in inputs: assert len(xinput.split(\'~\')) == 2, \'invalid input length : {:}\'.format(xinput)\n      for xi in inputs:\n        op, idx = xi.split(\'~\')\n        if op not in search_space: raise ValueError(\'this op ({:}) is not in {:}\'.format(op, search_space))\n        op_idx, node_idx = search_space.index(op), int(idx)\n        matrix[i+1, node_idx] = op_idx\n    return matrix\n\n\nclass ArchResults(object):\n\n  def __init__(self, arch_index, arch_str):\n    self.arch_index   = int(arch_index)\n    self.arch_str     = copy.deepcopy(arch_str)\n    self.all_results  = dict()\n    self.dataset_seed = dict()\n    self.clear_net_done = False\n\n  def get_compute_costs(self, dataset):\n    x_seeds = self.dataset_seed[dataset]\n    results = [self.all_results[ (dataset, seed) ] for seed in x_seeds]\n\n    flops     = [result.flop for result in results]\n    params    = [result.params for result in results]\n    latencies = [result.get_latency() for result in results]\n    latencies = [x for x in latencies if x > 0]\n    mean_latency = np.mean(latencies) if len(latencies) > 0 else None\n    time_infos = defaultdict(list)\n    for result in results:\n      time_info = result.get_times()\n      for key, value in time_info.items(): time_infos[key].append( value )\n     \n    info = {\'flops\'  : np.mean(flops),\n            \'params\' : np.mean(params),\n            \'latency\': mean_latency}\n    for key, value in time_infos.items():\n      if len(value) > 0 and value[0] is not None:\n        info[key] = np.mean(value)\n      else: info[key] = None\n    return info\n\n  def get_metrics(self, dataset, setname, iepoch=None, is_random=False):\n    """"""\n      This `get_metrics` function is used to obtain obtain the loss, accuracy, etc information on a specific dataset.\n      If not specify, each set refer to the proposed split in NAS-Bench-201 paper.\n      If some args return None or raise error, then it is not avaliable.\n      ========================================\n      Args [dataset] (4 possible options):\n        -- cifar10-valid : training the model on the CIFAR-10 training set.\n        -- cifar10 : training the model on the CIFAR-10 training + validation set.\n        -- cifar100 : training the model on the CIFAR-100 training set.\n        -- ImageNet16-120 : training the model on the ImageNet16-120 training set.\n      Args [setname] (each dataset has different setnames):\n        -- When dataset = cifar10-valid, you can use \'train\', \'x-valid\', \'ori-test\'\n        ------ \'train\' : the metric on the training set.\n        ------ \'x-valid\' : the metric on the validation set.\n        ------ \'ori-test\' : the metric on the test set.\n        -- When dataset = cifar10, you can use \'train\', \'ori-test\'.\n        ------ \'train\' : the metric on the training + validation set.\n        ------ \'ori-test\' : the metric on the test set.\n        -- When dataset = cifar100 or ImageNet16-120, you can use \'train\', \'ori-test\', \'x-valid\', \'x-test\'\n        ------ \'train\' : the metric on the training set.\n        ------ \'x-valid\' : the metric on the validation set.\n        ------ \'x-test\' : the metric on the test set.\n        ------ \'ori-test\' : the metric on the validation + test set.\n      Args [iepoch] (None or an integer in [0, the-number-of-total-training-epochs)\n        ------ None : return the metric after the last training epoch.\n        ------ an integer i : return the metric after the i-th training epoch.\n      Args [is_random]:\n        ------ True : return the metric of a randomly selected trial.\n        ------ False : return the averaged metric of all avaliable trials.\n        ------ an integer indicating the \'seed\' value : return the metric of a specific trial (whose random seed is \'is_random\').\n    """"""\n    x_seeds = self.dataset_seed[dataset]\n    results = [self.all_results[ (dataset, seed) ] for seed in x_seeds]\n    infos   = defaultdict(list)\n    for result in results:\n      if setname == \'train\':\n        info = result.get_train(iepoch)\n      else:\n        info = result.get_eval(setname, iepoch)\n      for key, value in info.items(): infos[key].append( value )\n    return_info = dict()\n    if isinstance(is_random, bool) and is_random: # randomly select one\n      index = random.randint(0, len(results)-1)\n      for key, value in infos.items(): return_info[key] = value[index]\n    elif isinstance(is_random, bool) and not is_random: # average\n      for key, value in infos.items():\n        if len(value) > 0 and value[0] is not None:\n          return_info[key] = np.mean(value)\n        else: return_info[key] = None\n    elif isinstance(is_random, int): # specify the seed\n      if is_random not in x_seeds: raise ValueError(\'can not find random seed ({:}) from {:}\'.format(is_random, x_seeds))\n      index = x_seeds.index(is_random)\n      for key, value in infos.items(): return_info[key] = value[index]\n    else:\n      raise ValueError(\'invalid value for is_random: {:}\'.format(is_random))\n    return return_info\n\n  def show(self, is_print=False):\n    return print_information(self, None, is_print)\n\n  def get_dataset_names(self):\n    return list(self.dataset_seed.keys())\n\n  def get_dataset_seeds(self, dataset):\n    return copy.deepcopy( self.dataset_seed[dataset] )\n\n  def get_net_param(self, dataset: Text, seed: Union[None, int] =None):\n    """"""\n    This function will return the trained network\'s weights on the \'dataset\'.\n    :arg\n      dataset: one of \'cifar10-valid\', \'cifar10\', \'cifar100\', and \'ImageNet16-120\'.\n      seed: an integer indicates the seed value or None that indicates returing all trials.\n    """"""\n    if seed is None:\n      x_seeds = self.dataset_seed[dataset]\n      return {seed: self.all_results[(dataset, seed)].get_net_param() for seed in x_seeds}\n    else:\n      return self.all_results[(dataset, seed)].get_net_param()\n\n  def reset_latency(self, dataset: Text, seed: Union[None, Text], latency: float) -> None:\n    """"""This function is used to reset the latency in all corresponding ResultsCount(s).""""""\n    if seed is None:\n      for seed in self.dataset_seed[dataset]:\n        self.all_results[(dataset, seed)].update_latency([latency])\n    else:\n      self.all_results[(dataset, seed)].update_latency([latency])\n\n  def reset_pseudo_train_times(self, dataset: Text, seed: Union[None, Text], estimated_per_epoch_time: float) -> None:\n    """"""This function is used to reset the train-times in all corresponding ResultsCount(s).""""""\n    if seed is None:\n      for seed in self.dataset_seed[dataset]:\n        self.all_results[(dataset, seed)].reset_pseudo_train_times(estimated_per_epoch_time)\n    else:\n      self.all_results[(dataset, seed)].reset_pseudo_train_times(estimated_per_epoch_time)\n\n  def reset_pseudo_eval_times(self, dataset: Text, seed: Union[None, Text], eval_name: Text, estimated_per_epoch_time: float) -> None:\n    """"""This function is used to reset the eval-times in all corresponding ResultsCount(s).""""""\n    if seed is None:\n      for seed in self.dataset_seed[dataset]:\n        self.all_results[(dataset, seed)].reset_pseudo_eval_times(eval_name, estimated_per_epoch_time)\n    else:\n      self.all_results[(dataset, seed)].reset_pseudo_eval_times(eval_name, estimated_per_epoch_time)\n\n  def get_latency(self, dataset: Text) -> float:\n    """"""Get the latency of a model on the target dataset. [Timestamp: 2020.03.09]""""""\n    latencies = []\n    for seed in self.dataset_seed[dataset]:\n      latency = self.all_results[(dataset, seed)].get_latency()\n      if not isinstance(latency, float) or latency <= 0:\n        raise ValueError(\'invalid latency of {:} for {:} with {:}\'.format(dataset))\n      latencies.append(latency)\n    return sum(latencies) / len(latencies)\n\n  def get_total_epoch(self, dataset=None):\n    """"""Return the total number of training epochs.""""""\n    if dataset is None:\n      epochss = []\n      for xdata, x_seeds in self.dataset_seed.items():\n        epochss += [self.all_results[(xdata, seed)].get_total_epoch() for seed in x_seeds]\n    elif isinstance(dataset, str):\n      x_seeds = self.dataset_seed[dataset]\n      epochss = [self.all_results[(dataset, seed)].get_total_epoch() for seed in x_seeds]\n    else:\n      raise ValueError(\'invalid dataset={:}\'.format(dataset))\n    if len(set(epochss)) > 1: raise ValueError(\'Each trial mush have the same number of training epochs : {:}\'.format(epochss))\n    return epochss[-1]\n\n  def query(self, dataset, seed=None):\n    """"""Return the ResultsCount object (containing all information of a single trial) for \'dataset\' and \'seed\'""""""\n    if seed is None:\n      x_seeds = self.dataset_seed[dataset]\n      return {seed: self.all_results[(dataset, seed)] for seed in x_seeds}\n    else:\n      return self.all_results[(dataset, seed)]\n\n  def arch_idx_str(self):\n    return \'{:06d}\'.format(self.arch_index)\n\n  def update(self, dataset_name, seed, result):\n    if dataset_name not in self.dataset_seed:\n      self.dataset_seed[dataset_name] = []\n    assert seed not in self.dataset_seed[dataset_name], \'{:}-th arch alreadly has this seed ({:}) on {:}\'.format(self.arch_index, seed, dataset_name)\n    self.dataset_seed[ dataset_name ].append( seed )\n    self.dataset_seed[ dataset_name ] = sorted( self.dataset_seed[ dataset_name ] )\n    assert (dataset_name, seed) not in self.all_results\n    self.all_results[ (dataset_name, seed) ] = result\n    self.clear_net_done = False\n\n  def state_dict(self):\n    state_dict = dict()\n    for key, value in self.__dict__.items():\n      if key == \'all_results\': # contain the class of ResultsCount\n        xvalue = dict()\n        assert isinstance(value, dict), \'invalid type of value for {:} : {:}\'.format(key, type(value))\n        for _k, _v in value.items():\n          assert isinstance(_v, ResultsCount), \'invalid type of value for {:}/{:} : {:}\'.format(key, _k, type(_v))\n          xvalue[_k] = _v.state_dict()\n      else:\n        xvalue = value\n      state_dict[key] = xvalue\n    return state_dict\n\n  def load_state_dict(self, state_dict):\n    new_state_dict = dict()\n    for key, value in state_dict.items():\n      if key == \'all_results\': # to convert to the class of ResultsCount\n        xvalue = dict()\n        assert isinstance(value, dict), \'invalid type of value for {:} : {:}\'.format(key, type(value))\n        for _k, _v in value.items():\n          xvalue[_k] = ResultsCount.create_from_state_dict(_v)\n      else: xvalue = value\n      new_state_dict[key] = xvalue\n    self.__dict__.update(new_state_dict)\n\n  @staticmethod\n  def create_from_state_dict(state_dict_or_file):\n    x = ArchResults(-1, -1)\n    if isinstance(state_dict_or_file, str): # a file path\n      state_dict = torch.load(state_dict_or_file, map_location=\'cpu\')\n    elif isinstance(state_dict_or_file, dict):\n      state_dict = state_dict_or_file\n    else:\n      raise ValueError(\'invalid type of state_dict_or_file : {:}\'.format(type(state_dict_or_file)))\n    x.load_state_dict(state_dict)\n    return x\n\n  # This function is used to clear the weights saved in each \'result\'\n  # This can help reduce the memory footprint.\n  def clear_params(self):\n    for key, result in self.all_results.items():\n      del result.net_state_dict\n      result.net_state_dict = None\n    self.clear_net_done = True\n\n  def debug_test(self):\n    """"""This function is used for me to debug and test, which will call most methods.""""""\n    all_dataset = [\'cifar10-valid\', \'cifar10\', \'cifar100\', \'ImageNet16-120\']\n    for dataset in all_dataset:\n      print(\'---->>>> {:}\'.format(dataset))\n      print(\'The latency on {:} is {:} s\'.format(dataset, self.get_latency(dataset)))\n      for seed in self.dataset_seed[dataset]:\n        result = self.all_results[(dataset, seed)]\n        print(\'  ==>> result = {:}\'.format(result))\n        print(\'  ==>> cost = {:}\'.format(result.get_times()))\n\n  def __repr__(self):\n    return (\'{name}(arch-index={index}, arch={arch}, {num} runs, clear={clear})\'.format(name=self.__class__.__name__, index=self.arch_index, arch=self.arch_str, num=len(self.all_results), clear=self.clear_net_done))\n\n\n""""""\nThis class (ResultsCount) is used to save the information of one trial for a single architecture.\nI did not write much comment for this class, because it is the lowest-level class in NAS-Bench-201 API, which will be rarely called.\nIf you have any question regarding this class, please open an issue or email me.\n""""""\nclass ResultsCount(object):\n\n  def __init__(self, name, state_dict, train_accs, train_losses, params, flop, arch_config, seed, epochs, latency):\n    self.name           = name\n    self.net_state_dict = state_dict\n    self.train_acc1es = copy.deepcopy(train_accs)\n    self.train_acc5es = None\n    self.train_losses = copy.deepcopy(train_losses)\n    self.train_times  = None\n    self.arch_config  = copy.deepcopy(arch_config)\n    self.params     = params\n    self.flop       = flop\n    self.seed       = seed\n    self.epochs     = epochs\n    self.latency    = latency\n    # evaluation results\n    self.reset_eval()\n\n  def update_train_info(self, train_acc1es, train_acc5es, train_losses, train_times) -> None:\n    self.train_acc1es = train_acc1es\n    self.train_acc5es = train_acc5es\n    self.train_losses = train_losses\n    self.train_times  = train_times\n\n  def reset_pseudo_train_times(self, estimated_per_epoch_time: float) -> None:\n    """"""Assign the training times.""""""\n    train_times = OrderedDict()\n    for i in range(self.epochs):\n      train_times[i] = estimated_per_epoch_time\n    self.train_times = train_times\n\n  def reset_pseudo_eval_times(self, eval_name: Text, estimated_per_epoch_time: float) -> None:\n    """"""Assign the evaluation times.""""""\n    if eval_name not in self.eval_names: raise ValueError(\'invalid eval name : {:}\'.format(eval_name))\n    for i in range(self.epochs):\n      self.eval_times[\'{:}@{:}\'.format(eval_name,i)] = estimated_per_epoch_time\n\n  def reset_eval(self):\n    self.eval_names  = []\n    self.eval_acc1es = {}\n    self.eval_times  = {}\n    self.eval_losses = {}\n\n  def update_latency(self, latency):\n    self.latency = copy.deepcopy( latency )\n\n  def get_latency(self) -> float:\n    """"""Return the latency value in seconds. -1 represents not avaliable ; otherwise it should be a float value""""""\n    if self.latency is None: return -1.0\n    else: return sum(self.latency) / len(self.latency)\n\n  def update_eval(self, accs, losses, times):  # new version\n    data_names = set([x.split(\'@\')[0] for x in accs.keys()])\n    for data_name in data_names:\n      assert data_name not in self.eval_names, \'{:} has already been added into eval-names\'.format(data_name)\n      self.eval_names.append( data_name )\n      for iepoch in range(self.epochs):\n        xkey = \'{:}@{:}\'.format(data_name, iepoch)\n        self.eval_acc1es[ xkey ] = accs[ xkey ]\n        self.eval_losses[ xkey ] = losses[ xkey ]\n        self.eval_times [ xkey ] = times[ xkey ]\n\n  def update_OLD_eval(self, name, accs, losses): # old version\n    assert name not in self.eval_names, \'{:} has already added\'.format(name)\n    self.eval_names.append( name )\n    for iepoch in range(self.epochs):\n      if iepoch in accs:\n        self.eval_acc1es[\'{:}@{:}\'.format(name,iepoch)] = accs[iepoch]\n        self.eval_losses[\'{:}@{:}\'.format(name,iepoch)] = losses[iepoch]\n\n  def __repr__(self):\n    num_eval = len(self.eval_names)\n    set_name = \'[\' + \', \'.join(self.eval_names) + \']\'\n    return (\'{name}({xname}, arch={arch}, FLOP={flop:.2f}M, Param={param:.3f}MB, seed={seed}, {num_eval} eval-sets: {set_name})\'.format(name=self.__class__.__name__, xname=self.name, arch=self.arch_config[\'arch_str\'], flop=self.flop, param=self.params, seed=self.seed, num_eval=num_eval, set_name=set_name))\n\n  def get_total_epoch(self):\n    return copy.deepcopy(self.epochs)\n\n  def get_times(self):\n    """"""Obtain the information regarding both training and evaluation time.""""""\n    if self.train_times is not None and isinstance(self.train_times, dict):\n      train_times = list( self.train_times.values() )\n      time_info = {\'T-train@epoch\': np.mean(train_times), \'T-train@total\': np.sum(train_times)}\n    else:\n      time_info = {\'T-train@epoch\':                 None, \'T-train@total\':               None }\n    for name in self.eval_names:\n      try:\n        xtimes = [self.eval_times[\'{:}@{:}\'.format(name,i)] for i in range(self.epochs)]\n        time_info[\'T-{:}@epoch\'.format(name)] = np.mean(xtimes)\n        time_info[\'T-{:}@total\'.format(name)] = np.sum(xtimes)\n      except:\n        time_info[\'T-{:}@epoch\'.format(name)] = None\n        time_info[\'T-{:}@total\'.format(name)] = None\n    return time_info\n\n  def get_eval_set(self):\n    return self.eval_names\n\n  # get the training information\n  def get_train(self, iepoch=None):\n    if iepoch is None: iepoch = self.epochs-1\n    assert 0 <= iepoch < self.epochs, \'invalid iepoch={:} < {:}\'.format(iepoch, self.epochs)\n    if self.train_times is not None:\n      xtime = self.train_times[iepoch]\n      atime = sum([self.train_times[i] for i in range(iepoch+1)])\n    else: xtime, atime = None, None\n    return {\'iepoch\'  : iepoch,\n            \'loss\'    : self.train_losses[iepoch],\n            \'accuracy\': self.train_acc1es[iepoch],\n            \'cur_time\': xtime,\n            \'all_time\': atime}\n\n  def get_eval(self, name, iepoch=None):\n    """"""Get the evaluation information ; there could be multiple evaluation sets (identified by the \'name\' argument).""""""\n    if iepoch is None: iepoch = self.epochs-1\n    assert 0 <= iepoch < self.epochs, \'invalid iepoch={:} < {:}\'.format(iepoch, self.epochs)\n    if isinstance(self.eval_times,dict) and len(self.eval_times) > 0:\n      xtime = self.eval_times[\'{:}@{:}\'.format(name,iepoch)]\n      atime = sum([self.eval_times[\'{:}@{:}\'.format(name,i)] for i in range(iepoch+1)])\n    else: xtime, atime = None, None\n    return {\'iepoch\'  : iepoch,\n            \'loss\'    : self.eval_losses[\'{:}@{:}\'.format(name,iepoch)],\n            \'accuracy\': self.eval_acc1es[\'{:}@{:}\'.format(name,iepoch)],\n            \'cur_time\': xtime,\n            \'all_time\': atime}\n\n  def get_net_param(self, clone=False):\n    if clone: return copy.deepcopy(self.net_state_dict)\n    else: return self.net_state_dict\n\n  def get_config(self, str2structure):\n    """"""This function is used to obtain the config dict for this architecture.""""""\n    if str2structure is None:\n      return {\'name\': \'infer.tiny\', \'C\': self.arch_config[\'channel\'],\n              \'N\'   : self.arch_config[\'num_cells\'],\n              \'arch_str\': self.arch_config[\'arch_str\'], \'num_classes\': self.arch_config[\'class_num\']}\n    else:\n      return {\'name\': \'infer.tiny\', \'C\': self.arch_config[\'channel\'],\n              \'N\'   : self.arch_config[\'num_cells\'],\n              \'genotype\': str2structure(self.arch_config[\'arch_str\']), \'num_classes\': self.arch_config[\'class_num\']}\n\n  def state_dict(self):\n    _state_dict = {key: value for key, value in self.__dict__.items()}\n    return _state_dict\n\n  def load_state_dict(self, state_dict):\n    self.__dict__.update(state_dict)\n\n  @staticmethod\n  def create_from_state_dict(state_dict):\n    x = ResultsCount(None, None, None, None, None, None, None, None, None, None)\n    x.load_state_dict(state_dict)\n    return x\n'"
lib/nas_infer_model/__init__.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\n# I write this package to make AutoDL-Projects to be compatible with the old GDAS projects.\n# Ideally, this package will be merged into lib/models/cell_infers in future.\n# Currently, this package is used to reproduce the results in GDAS (Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019).\n##################################################\n\nimport os, torch\n\ndef obtain_nas_infer_model(config, extra_model_path=None):\n  \n  if config.arch == 'dxys':\n    from .DXYs import CifarNet, ImageNet, Networks\n    from .DXYs import build_genotype_from_dict\n    if config.genotype is None:\n      if extra_model_path is not None and not os.path.isfile(extra_model_path):\n        raise ValueError('When genotype in confiig is None, extra_model_path must be set as a path instead of {:}'.format(extra_model_path))\n      xdata = torch.load(extra_model_path)\n      current_epoch = xdata['epoch']\n      genotype_dict = xdata['genotypes'][current_epoch-1]\n      genotype = build_genotype_from_dict(genotype_dict)\n    else:\n      genotype = Networks[config.genotype]\n    if config.dataset == 'cifar':\n      return CifarNet(config.ichannel, config.layers, config.stem_multi, config.auxiliary, genotype, config.class_num)\n    elif config.dataset == 'imagenet':\n      return ImageNet(config.ichannel, config.layers, config.auxiliary, genotype, config.class_num)\n    else: raise ValueError('invalid dataset : {:}'.format(config.dataset))\n  else:\n    raise ValueError('invalid nas arch type : {:}'.format(config.arch))\n"""
lib/nas_infer_model/operations.py,3,"b""##############################################################################################\n# This code is copied and modified from Hanxiao Liu's work (https://github.com/quark0/darts) #\n##############################################################################################\nimport torch\nimport torch.nn as nn\n\nOPS = {\n  'none'         : lambda C_in, C_out, stride, affine: Zero(stride),\n  'avg_pool_3x3' : lambda C_in, C_out, stride, affine: POOLING(C_in, C_out, stride, 'avg'),\n  'max_pool_3x3' : lambda C_in, C_out, stride, affine: POOLING(C_in, C_out, stride, 'max'),\n  'nor_conv_7x7' : lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, (7,7), (stride,stride), (3,3), affine),\n  'nor_conv_3x3' : lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, (3,3), (stride,stride), (1,1), affine),\n  'nor_conv_1x1' : lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, (1,1), (stride,stride), (0,0), affine),\n  'skip_connect' : lambda C_in, C_out, stride, affine: Identity() if stride == 1 and C_in == C_out else FactorizedReduce(C_in, C_out, stride, affine),\n  'sep_conv_3x3' : lambda C_in, C_out, stride, affine: SepConv(C_in, C_out, 3, stride, 1, affine=affine),\n  'sep_conv_5x5' : lambda C_in, C_out, stride, affine: SepConv(C_in, C_out, 5, stride, 2, affine=affine),\n  'sep_conv_7x7' : lambda C_in, C_out, stride, affine: SepConv(C_in, C_out, 7, stride, 3, affine=affine),\n  'dil_conv_3x3' : lambda C_in, C_out, stride, affine: DilConv(C_in, C_out, 3, stride, 2, 2, affine=affine),\n  'dil_conv_5x5' : lambda C_in, C_out, stride, affine: DilConv(C_in, C_out, 5, stride, 4, 2, affine=affine),\n  'conv_7x1_1x7' : lambda C_in, C_out, stride, affine: Conv717(C_in, C_out, stride, affine),\n  'conv_3x1_1x3' : lambda C_in, C_out, stride, affine: Conv313(C_in, C_out, stride, affine)\n}\n\n\nclass POOLING(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, mode):\n    super(POOLING, self).__init__()\n    if C_in == C_out:\n      self.preprocess = None\n    else:\n      self.preprocess = ReLUConvBN(C_in, C_out, 1, 1, 0)\n    if mode == 'avg'  : self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n    elif mode == 'max': self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n\n  def forward(self, inputs):\n    if self.preprocess is not None:\n      x = self.preprocess(inputs)\n    else: x = inputs\n    return self.op(x)\n\n\nclass Conv313(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, affine):\n    super(Conv313, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in , C_out, (1,3), stride=(1, stride), padding=(0, 1), bias=False),\n      nn.Conv2d(C_out, C_out, (3,1), stride=(stride, 1), padding=(1, 0), bias=False),\n      nn.BatchNorm2d(C_out, affine=affine)\n    )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass Conv717(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, affine):\n    super(Conv717, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in , C_out, (1,7), stride=(1, stride), padding=(0, 3), bias=False),\n      nn.Conv2d(C_out, C_out, (7,1), stride=(stride, 1), padding=(3, 0), bias=False),\n      nn.BatchNorm2d(C_out, affine=affine)\n    )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass ReLUConvBN(nn.Module):\n\n  def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n    super(ReLUConvBN, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_out, kernel_size, stride=stride, padding=padding, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine)\n    )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass DilConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine=True):\n    super(DilConv, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in,  kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine),\n      )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass SepConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n    super(SepConv, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_in, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_in, affine=affine),\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=     1, padding=padding, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine),\n      )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass Identity(nn.Module):\n\n  def __init__(self):\n    super(Identity, self).__init__()\n\n  def forward(self, x):\n    return x\n\n\nclass Zero(nn.Module):\n\n  def __init__(self, stride):\n    super(Zero, self).__init__()\n    self.stride = stride\n\n  def forward(self, x):\n    if self.stride == 1:\n      return x.mul(0.)\n    return x[:,:,::self.stride,::self.stride].mul(0.)\n\n  def extra_repr(self):\n    return 'stride={stride}'.format(**self.__dict__)\n\n\nclass FactorizedReduce(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, affine=True):\n    super(FactorizedReduce, self).__init__()\n    self.stride = stride\n    self.C_in   = C_in  \n    self.C_out  = C_out  \n    self.relu   = nn.ReLU(inplace=False)\n    if stride == 2:\n      #assert C_out % 2 == 0, 'C_out : {:}'.format(C_out)\n      C_outs = [C_out // 2, C_out - C_out // 2]\n      self.convs = nn.ModuleList()\n      for i in range(2):\n        self.convs.append( nn.Conv2d(C_in, C_outs[i], 1, stride=stride, padding=0, bias=False) )\n      self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n    elif stride == 4:\n      assert C_out % 4 == 0, 'C_out : {:}'.format(C_out)\n      self.convs = nn.ModuleList()\n      for i in range(4):\n        self.convs.append( nn.Conv2d(C_in, C_out // 4, 1, stride=stride, padding=0, bias=False) )\n      self.pad = nn.ConstantPad2d((0, 3, 0, 3), 0)\n    else:\n      raise ValueError('Invalid stride : {:}'.format(stride))\n    \n    self.bn = nn.BatchNorm2d(C_out, affine=affine)\n\n  def forward(self, x):\n    x = self.relu(x)\n    y = self.pad(x)\n    if self.stride == 2:\n      out = torch.cat([self.convs[0](x), self.convs[1](y[:,:,1:,1:])], dim=1)\n    else:\n      out = torch.cat([self.convs[0](x),            self.convs[1](y[:,:,1:-2,1:-2]),\n                       self.convs[2](y[:,:,2:-1,2:-1]), self.convs[3](y[:,:,3:,3:])], dim=1)\n    out = self.bn(out)\n    return out\n\n  def extra_repr(self):\n    return 'C_in={C_in}, C_out={C_out}, stride={stride}'.format(**self.__dict__)\n"""
lib/procedures/__init__.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom .starts     import prepare_seed, prepare_logger, get_machine_info, save_checkpoint, copy_checkpoint\nfrom .optimizers import get_optim_scheduler\nfrom .funcs_nasbench import evaluate_for_seed as bench_evaluate_for_seed\nfrom .funcs_nasbench import pure_evaluate as bench_pure_evaluate\nfrom .funcs_nasbench import get_nas_bench_loaders\n\ndef get_procedures(procedure):\n  from .basic_main     import basic_train, basic_valid\n  from .search_main    import search_train, search_valid\n  from .search_main_v2 import search_train_v2\n  from .simple_KD_main import simple_KD_train, simple_KD_valid\n\n  train_funcs = {'basic' : basic_train, \\\n                 'search': search_train,'Simple-KD': simple_KD_train, \\\n                 'search-v2': search_train_v2}\n  valid_funcs = {'basic' : basic_valid, \\\n                 'search': search_valid,'Simple-KD': simple_KD_valid, \\\n                 'search-v2': search_valid}\n  \n  train_func  = train_funcs[procedure]\n  valid_func  = valid_funcs[procedure]\n  return train_func, valid_func\n"""
lib/procedures/basic_main.py,1,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, time, torch\nfrom log_utils import AverageMeter, time_string\nfrom utils     import obtain_accuracy\n\n\ndef basic_train(xloader, network, criterion, scheduler, optimizer, optim_config, extra_info, print_freq, logger):\n  loss, acc1, acc5 = procedure(xloader, network, criterion, scheduler, optimizer, \'train\', optim_config, extra_info, print_freq, logger)\n  return loss, acc1, acc5\n\n\ndef basic_valid(xloader, network, criterion, optim_config, extra_info, print_freq, logger):\n  with torch.no_grad():\n    loss, acc1, acc5 = procedure(xloader, network, criterion, None, None, \'valid\', None, extra_info, print_freq, logger)\n  return loss, acc1, acc5\n\n\ndef procedure(xloader, network, criterion, scheduler, optimizer, mode, config, extra_info, print_freq, logger):\n  data_time, batch_time, losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n  if mode == \'train\':\n    network.train()\n  elif mode == \'valid\':\n    network.eval()\n  else: raise ValueError(""The mode is not right : {:}"".format(mode))\n  \n  #logger.log(\'[{:5s}] config ::  auxiliary={:}, message={:}\'.format(mode, config.auxiliary if hasattr(config, \'auxiliary\') else -1, network.module.get_message()))\n  logger.log(\'[{:5s}] config ::  auxiliary={:}\'.format(mode, config.auxiliary if hasattr(config, \'auxiliary\') else -1))\n  end = time.time()\n  for i, (inputs, targets) in enumerate(xloader):\n    if mode == \'train\': scheduler.update(None, 1.0 * i / len(xloader))\n    # measure data loading time\n    data_time.update(time.time() - end)\n    # calculate prediction and loss\n    targets = targets.cuda(non_blocking=True)\n\n    if mode == \'train\': optimizer.zero_grad()\n\n    features, logits = network(inputs)\n    if isinstance(logits, list):\n      assert len(logits) == 2, \'logits must has {:} items instead of {:}\'.format(2, len(logits))\n      logits, logits_aux = logits\n    else:\n      logits, logits_aux = logits, None\n    loss             = criterion(logits, targets)\n    if config is not None and hasattr(config, \'auxiliary\') and config.auxiliary > 0:\n      loss_aux = criterion(logits_aux, targets)\n      loss += config.auxiliary * loss_aux\n    \n    if mode == \'train\':\n      loss.backward()\n      optimizer.step()\n\n    # record\n    prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n    losses.update(loss.item(),  inputs.size(0))\n    top1.update  (prec1.item(), inputs.size(0))\n    top5.update  (prec5.item(), inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if i % print_freq == 0 or (i+1) == len(xloader):\n      Sstr = \' {:5s} \'.format(mode.upper()) + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(extra_info, i, len(xloader))\n      if scheduler is not None:\n        Sstr += \' {:}\'.format(scheduler.get_min_info())\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Lstr = \'Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})\'.format(loss=losses, top1=top1, top5=top5)\n      Istr = \'Size={:}\'.format(list(inputs.size()))\n      logger.log(Sstr + \' \' + Tstr + \' \' + Lstr + \' \' + Istr)\n\n  logger.log(\' **{mode:5s}** Prec@1 {top1.avg:.2f} Prec@5 {top5.avg:.2f} Error@1 {error1:.2f} Error@5 {error5:.2f} Loss:{loss:.3f}\'.format(mode=mode.upper(), top1=top1, top5=top5, error1=100-top1.avg, error5=100-top5.avg, loss=losses.avg))\n  return losses.avg, top1.avg, top5.avg\n'"
lib/procedures/funcs_nasbench.py,18,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.08 #\n#####################################################\nimport os, time, copy, torch, pathlib\n\nimport datasets\nfrom config_utils import load_config\nfrom procedures   import prepare_seed, get_optim_scheduler\nfrom utils        import get_model_infos, obtain_accuracy\nfrom log_utils    import AverageMeter, time_string, convert_secs2time\nfrom models       import get_cell_based_tiny_net\n\n\n__all__ = [\'evaluate_for_seed\', \'pure_evaluate\', \'get_nas_bench_loaders\']\n\n\ndef pure_evaluate(xloader, network, criterion=torch.nn.CrossEntropyLoss()):\n  data_time, batch_time, batch = AverageMeter(), AverageMeter(), None\n  losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  latencies, device = [], torch.cuda.current_device()\n  network.eval()\n  with torch.no_grad():\n    end = time.time()\n    for i, (inputs, targets) in enumerate(xloader):\n      targets = targets.cuda(device=device, non_blocking=True)\n      inputs  = inputs.cuda(device=device, non_blocking=True)\n      data_time.update(time.time() - end)\n      # forward\n      features, logits = network(inputs)\n      loss             = criterion(logits, targets)\n      batch_time.update(time.time() - end)\n      if batch is None or batch == inputs.size(0):\n        batch = inputs.size(0)\n        latencies.append( batch_time.val - data_time.val )\n      # record loss and accuracy\n      prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n      losses.update(loss.item(),  inputs.size(0))\n      top1.update  (prec1.item(), inputs.size(0))\n      top5.update  (prec5.item(), inputs.size(0))\n      end = time.time()\n  if len(latencies) > 2: latencies = latencies[1:]\n  return losses.avg, top1.avg, top5.avg, latencies\n\n\n\ndef procedure(xloader, network, criterion, scheduler, optimizer, mode: str):\n  losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter()\n  if mode == \'train\'  : network.train()\n  elif mode == \'valid\': network.eval()\n  else: raise ValueError(""The mode is not right : {:}"".format(mode))\n  device = torch.cuda.current_device()\n  data_time, batch_time, end = AverageMeter(), AverageMeter(), time.time()\n  for i, (inputs, targets) in enumerate(xloader):\n    if mode == \'train\': scheduler.update(None, 1.0 * i / len(xloader))\n\n    targets = targets.cuda(device=device, non_blocking=True)\n    if mode == \'train\': optimizer.zero_grad()\n    # forward\n    features, logits = network(inputs)\n    loss             = criterion(logits, targets)\n    # backward\n    if mode == \'train\':\n      loss.backward()\n      optimizer.step()\n    # record loss and accuracy\n    prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n    losses.update(loss.item(),  inputs.size(0))\n    top1.update  (prec1.item(), inputs.size(0))\n    top5.update  (prec5.item(), inputs.size(0))\n    # count time\n    batch_time.update(time.time() - end)\n    end = time.time()\n  return losses.avg, top1.avg, top5.avg, batch_time.sum\n\n\ndef evaluate_for_seed(arch_config, opt_config, train_loader, valid_loaders, seed: int, logger):\n\n  prepare_seed(seed) # random seed\n  net = get_cell_based_tiny_net(arch_config)\n  #net = TinyNetwork(arch_config[\'channel\'], arch_config[\'num_cells\'], arch, config.class_num)\n  flop, param  = get_model_infos(net, opt_config.xshape)\n  logger.log(\'Network : {:}\'.format(net.get_message()), False)\n  logger.log(\'{:} Seed-------------------------- {:} --------------------------\'.format(time_string(), seed))\n  logger.log(\'FLOP = {:} MB, Param = {:} MB\'.format(flop, param))\n  # train and valid\n  optimizer, scheduler, criterion = get_optim_scheduler(net.parameters(), opt_config)\n  default_device = torch.cuda.current_device()\n  network = torch.nn.DataParallel(net, device_ids=[default_device]).cuda(device=default_device)\n  criterion = criterion.cuda(device=default_device)\n  # start training\n  start_time, epoch_time, total_epoch = time.time(), AverageMeter(), opt_config.epochs + opt_config.warmup\n  train_losses, train_acc1es, train_acc5es, valid_losses, valid_acc1es, valid_acc5es = {}, {}, {}, {}, {}, {}\n  train_times , valid_times, lrs = {}, {}, {}\n  for epoch in range(total_epoch):\n    scheduler.update(epoch, 0.0)\n    lr = min(scheduler.get_lr())\n    train_loss, train_acc1, train_acc5, train_tm = procedure(train_loader, network, criterion, scheduler, optimizer, \'train\')\n    train_losses[epoch] = train_loss\n    train_acc1es[epoch] = train_acc1 \n    train_acc5es[epoch] = train_acc5\n    train_times [epoch] = train_tm\n    lrs[epoch] = lr\n    with torch.no_grad():\n      for key, xloder in valid_loaders.items():\n        valid_loss, valid_acc1, valid_acc5, valid_tm = procedure(xloder  , network, criterion,      None,      None, \'valid\')\n        valid_losses[\'{:}@{:}\'.format(key,epoch)] = valid_loss\n        valid_acc1es[\'{:}@{:}\'.format(key,epoch)] = valid_acc1 \n        valid_acc5es[\'{:}@{:}\'.format(key,epoch)] = valid_acc5\n        valid_times [\'{:}@{:}\'.format(key,epoch)] = valid_tm\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    need_time = \'Time Left: {:}\'.format( convert_secs2time(epoch_time.avg * (total_epoch-epoch-1), True) )\n    logger.log(\'{:} {:} epoch={:03d}/{:03d} :: Train [loss={:.5f}, acc@1={:.2f}%, acc@5={:.2f}%] Valid [loss={:.5f}, acc@1={:.2f}%, acc@5={:.2f}%], lr={:}\'.format(time_string(), need_time, epoch, total_epoch, train_loss, train_acc1, train_acc5, valid_loss, valid_acc1, valid_acc5, lr))\n  info_seed = {\'flop\' : flop,\n               \'param\': param,\n               \'arch_config\' : arch_config._asdict(),\n               \'opt_config\'  : opt_config._asdict(),\n               \'total_epoch\' : total_epoch ,\n               \'train_losses\': train_losses,\n               \'train_acc1es\': train_acc1es,\n               \'train_acc5es\': train_acc5es,\n               \'train_times\' : train_times,\n               \'valid_losses\': valid_losses,\n               \'valid_acc1es\': valid_acc1es,\n               \'valid_acc5es\': valid_acc5es,\n               \'valid_times\' : valid_times,\n               \'learning_rates\': lrs,\n               \'net_state_dict\': net.state_dict(),\n               \'net_string\'  : \'{:}\'.format(net),\n               \'finish-train\': True\n              }\n  return info_seed\n\n\ndef get_nas_bench_loaders(workers):\n\n  torch.set_num_threads(workers)\n\n  root_dir  = (pathlib.Path(__file__).parent / \'..\' / \'..\').resolve()\n  torch_dir = pathlib.Path(os.environ[\'TORCH_HOME\'])\n  # cifar\n  cifar_config_path = root_dir / \'configs\' / \'nas-benchmark\' / \'CIFAR.config\'\n  cifar_config = load_config(cifar_config_path, None, None)\n  get_datasets = datasets.get_datasets  # a function to return the dataset\n  break_line = \'-\' * 150\n  print (\'{:} Create data-loader for all datasets\'.format(time_string()))\n  print (break_line)\n  TRAIN_CIFAR10, VALID_CIFAR10, xshape, class_num = get_datasets(\'cifar10\', str(torch_dir/\'cifar.python\'), -1)\n  print (\'original CIFAR-10 : {:} training images and {:} test images : {:} input shape : {:} number of classes\'.format(len(TRAIN_CIFAR10), len(VALID_CIFAR10), xshape, class_num))\n  cifar10_splits = load_config(root_dir / \'configs\' / \'nas-benchmark\' / \'cifar-split.txt\', None, None)\n  assert cifar10_splits.train[:10] == [0, 5, 7, 11, 13, 15, 16, 17, 20, 24] and cifar10_splits.valid[:10] == [1, 2, 3, 4, 6, 8, 9, 10, 12, 14]\n  temp_dataset = copy.deepcopy(TRAIN_CIFAR10)\n  temp_dataset.transform = VALID_CIFAR10.transform\n  # data loader\n  trainval_cifar10_loader = torch.utils.data.DataLoader(TRAIN_CIFAR10, batch_size=cifar_config.batch_size, shuffle=True , num_workers=workers, pin_memory=True)\n  train_cifar10_loader    = torch.utils.data.DataLoader(TRAIN_CIFAR10, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar10_splits.train), num_workers=workers, pin_memory=True)\n  valid_cifar10_loader    = torch.utils.data.DataLoader(temp_dataset , batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar10_splits.valid), num_workers=workers, pin_memory=True)\n  test__cifar10_loader    = torch.utils.data.DataLoader(VALID_CIFAR10, batch_size=cifar_config.batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n  print (\'CIFAR-10  : trval-loader has {:3d} batch with {:} per batch\'.format(len(trainval_cifar10_loader), cifar_config.batch_size))\n  print (\'CIFAR-10  : train-loader has {:3d} batch with {:} per batch\'.format(len(train_cifar10_loader), cifar_config.batch_size))\n  print (\'CIFAR-10  : valid-loader has {:3d} batch with {:} per batch\'.format(len(valid_cifar10_loader), cifar_config.batch_size))\n  print (\'CIFAR-10  : test--loader has {:3d} batch with {:} per batch\'.format(len(test__cifar10_loader), cifar_config.batch_size))\n  print (break_line)\n  # CIFAR-100\n  TRAIN_CIFAR100, VALID_CIFAR100, xshape, class_num = get_datasets(\'cifar100\', str(torch_dir/\'cifar.python\'), -1)\n  print (\'original CIFAR-100: {:} training images and {:} test images : {:} input shape : {:} number of classes\'.format(len(TRAIN_CIFAR100), len(VALID_CIFAR100), xshape, class_num))\n  cifar100_splits = load_config(root_dir / \'configs\' / \'nas-benchmark\' / \'cifar100-test-split.txt\', None, None)\n  assert cifar100_splits.xvalid[:10] == [1, 3, 4, 5, 8, 10, 13, 14, 15, 16] and cifar100_splits.xtest[:10] == [0, 2, 6, 7, 9, 11, 12, 17, 20, 24]\n  train_cifar100_loader = torch.utils.data.DataLoader(TRAIN_CIFAR100, batch_size=cifar_config.batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n  valid_cifar100_loader = torch.utils.data.DataLoader(VALID_CIFAR100, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xvalid), num_workers=workers, pin_memory=True)\n  test__cifar100_loader = torch.utils.data.DataLoader(VALID_CIFAR100, batch_size=cifar_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(cifar100_splits.xtest) , num_workers=workers, pin_memory=True)\n  print (\'CIFAR-100  : train-loader has {:3d} batch\'.format(len(train_cifar100_loader)))\n  print (\'CIFAR-100  : valid-loader has {:3d} batch\'.format(len(valid_cifar100_loader)))\n  print (\'CIFAR-100  : test--loader has {:3d} batch\'.format(len(test__cifar100_loader)))\n  print (break_line)\n\n  imagenet16_config_path = \'configs/nas-benchmark/ImageNet-16.config\'\n  imagenet16_config = load_config(imagenet16_config_path, None, None)\n  TRAIN_ImageNet16_120, VALID_ImageNet16_120, xshape, class_num = get_datasets(\'ImageNet16-120\', str(torch_dir/\'cifar.python\'/\'ImageNet16\'), -1)\n  print (\'original TRAIN_ImageNet16_120: {:} training images and {:} test images : {:} input shape : {:} number of classes\'.format(len(TRAIN_ImageNet16_120), len(VALID_ImageNet16_120), xshape, class_num))\n  imagenet_splits = load_config(root_dir / \'configs\' / \'nas-benchmark\' / \'imagenet-16-120-test-split.txt\', None, None)\n  assert imagenet_splits.xvalid[:10] == [1, 2, 3, 6, 7, 8, 9, 12, 16, 18] and imagenet_splits.xtest[:10] == [0, 4, 5, 10, 11, 13, 14, 15, 17, 20]\n  train_imagenet_loader = torch.utils.data.DataLoader(TRAIN_ImageNet16_120, batch_size=imagenet16_config.batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n  valid_imagenet_loader = torch.utils.data.DataLoader(VALID_ImageNet16_120, batch_size=imagenet16_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet_splits.xvalid), num_workers=workers, pin_memory=True)\n  test__imagenet_loader = torch.utils.data.DataLoader(VALID_ImageNet16_120, batch_size=imagenet16_config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(imagenet_splits.xtest) , num_workers=workers, pin_memory=True)\n  print (\'ImageNet-16-120  : train-loader has {:3d} batch with {:} per batch\'.format(len(train_imagenet_loader), imagenet16_config.batch_size))\n  print (\'ImageNet-16-120  : valid-loader has {:3d} batch with {:} per batch\'.format(len(valid_imagenet_loader), imagenet16_config.batch_size))\n  print (\'ImageNet-16-120  : test--loader has {:3d} batch with {:} per batch\'.format(len(test__imagenet_loader), imagenet16_config.batch_size))\n\n  # \'cifar10\', \'cifar100\', \'ImageNet16-120\'\n  loaders = {\'cifar10@trainval\': trainval_cifar10_loader,\n             \'cifar10@train\'   : train_cifar10_loader,\n             \'cifar10@valid\'   : valid_cifar10_loader,\n             \'cifar10@test\'    : test__cifar10_loader,\n             \'cifar100@train\'  : train_cifar100_loader,\n             \'cifar100@valid\'  : valid_cifar100_loader,\n             \'cifar100@test\'   : test__cifar100_loader,\n             \'ImageNet16-120@train\': train_imagenet_loader,\n             \'ImageNet16-120@valid\': valid_imagenet_loader,\n             \'ImageNet16-120@test\' : test__imagenet_loader}\n  return loaders'"
lib/procedures/optimizers.py,6,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport math, torch\nimport torch.nn as nn\nfrom bisect import bisect_right\nfrom torch.optim import Optimizer\n\n\nclass _LRScheduler(object):\n\n  def __init__(self, optimizer, warmup_epochs, epochs):\n    if not isinstance(optimizer, Optimizer):\n      raise TypeError('{:} is not an Optimizer'.format(type(optimizer).__name__))\n    self.optimizer = optimizer\n    for group in optimizer.param_groups:\n      group.setdefault('initial_lr', group['lr'])\n    self.base_lrs = list(map(lambda group: group['initial_lr'], optimizer.param_groups))\n    self.max_epochs = epochs\n    self.warmup_epochs  = warmup_epochs\n    self.current_epoch  = 0\n    self.current_iter   = 0\n\n  def extra_repr(self):\n    return ''\n\n  def __repr__(self):\n    return ('{name}(warmup={warmup_epochs}, max-epoch={max_epochs}, current::epoch={current_epoch}, iter={current_iter:.2f}'.format(name=self.__class__.__name__, **self.__dict__)\n              + ', {:})'.format(self.extra_repr()))\n\n  def state_dict(self):\n    return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}\n\n  def load_state_dict(self, state_dict):\n    self.__dict__.update(state_dict)\n\n  def get_lr(self):\n    raise NotImplementedError\n\n  def get_min_info(self):\n    lrs = self.get_lr()\n    return '#LR=[{:.6f}~{:.6f}] epoch={:03d}, iter={:4.2f}#'.format(min(lrs), max(lrs), self.current_epoch, self.current_iter)\n\n  def get_min_lr(self):\n    return min( self.get_lr() )\n\n  def update(self, cur_epoch, cur_iter):\n    if cur_epoch is not None:\n      assert isinstance(cur_epoch, int) and cur_epoch>=0, 'invalid cur-epoch : {:}'.format(cur_epoch)\n      self.current_epoch = cur_epoch\n    if cur_iter is not None:\n      assert isinstance(cur_iter, float) and cur_iter>=0, 'invalid cur-iter : {:}'.format(cur_iter)\n      self.current_iter  = cur_iter\n    for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n      param_group['lr'] = lr\n\n\n\nclass CosineAnnealingLR(_LRScheduler):\n\n  def __init__(self, optimizer, warmup_epochs, epochs, T_max, eta_min):\n    self.T_max = T_max\n    self.eta_min = eta_min\n    super(CosineAnnealingLR, self).__init__(optimizer, warmup_epochs, epochs)\n\n  def extra_repr(self):\n    return 'type={:}, T-max={:}, eta-min={:}'.format('cosine', self.T_max, self.eta_min)\n\n  def get_lr(self):\n    lrs = []\n    for base_lr in self.base_lrs:\n      if self.current_epoch >= self.warmup_epochs and self.current_epoch < self.max_epochs:\n        last_epoch = self.current_epoch - self.warmup_epochs\n        #if last_epoch < self.T_max:\n        #if last_epoch < self.max_epochs:\n        lr = self.eta_min + (base_lr - self.eta_min) * (1 + math.cos(math.pi * last_epoch / self.T_max)) / 2\n        #else:\n        #  lr = self.eta_min + (base_lr - self.eta_min) * (1 + math.cos(math.pi * (self.T_max-1.0) / self.T_max)) / 2\n      elif self.current_epoch >= self.max_epochs:\n        lr = self.eta_min\n      else:\n        lr = (self.current_epoch / self.warmup_epochs + self.current_iter / self.warmup_epochs) * base_lr\n      lrs.append( lr )\n    return lrs\n\n\n\nclass MultiStepLR(_LRScheduler):\n\n  def __init__(self, optimizer, warmup_epochs, epochs, milestones, gammas):\n    assert len(milestones) == len(gammas), 'invalid {:} vs {:}'.format(len(milestones), len(gammas))\n    self.milestones = milestones\n    self.gammas     = gammas\n    super(MultiStepLR, self).__init__(optimizer, warmup_epochs, epochs)\n\n  def extra_repr(self):\n    return 'type={:}, milestones={:}, gammas={:}, base-lrs={:}'.format('multistep', self.milestones, self.gammas, self.base_lrs)\n\n  def get_lr(self):\n    lrs = []\n    for base_lr in self.base_lrs:\n      if self.current_epoch >= self.warmup_epochs:\n        last_epoch = self.current_epoch - self.warmup_epochs\n        idx = bisect_right(self.milestones, last_epoch)\n        lr = base_lr\n        for x in self.gammas[:idx]: lr *= x\n      else:\n        lr = (self.current_epoch / self.warmup_epochs + self.current_iter / self.warmup_epochs) * base_lr\n      lrs.append( lr )\n    return lrs\n\n\nclass ExponentialLR(_LRScheduler):\n\n  def __init__(self, optimizer, warmup_epochs, epochs, gamma):\n    self.gamma      = gamma\n    super(ExponentialLR, self).__init__(optimizer, warmup_epochs, epochs)\n\n  def extra_repr(self):\n    return 'type={:}, gamma={:}, base-lrs={:}'.format('exponential', self.gamma, self.base_lrs)\n\n  def get_lr(self):\n    lrs = []\n    for base_lr in self.base_lrs:\n      if self.current_epoch >= self.warmup_epochs:\n        last_epoch = self.current_epoch - self.warmup_epochs\n        assert last_epoch >= 0, 'invalid last_epoch : {:}'.format(last_epoch)\n        lr = base_lr * (self.gamma ** last_epoch)\n      else:\n        lr = (self.current_epoch / self.warmup_epochs + self.current_iter / self.warmup_epochs) * base_lr\n      lrs.append( lr )\n    return lrs\n\n\nclass LinearLR(_LRScheduler):\n\n  def __init__(self, optimizer, warmup_epochs, epochs, max_LR, min_LR):\n    self.max_LR = max_LR\n    self.min_LR = min_LR\n    super(LinearLR, self).__init__(optimizer, warmup_epochs, epochs)\n\n  def extra_repr(self):\n    return 'type={:}, max_LR={:}, min_LR={:}, base-lrs={:}'.format('LinearLR', self.max_LR, self.min_LR, self.base_lrs)\n\n  def get_lr(self):\n    lrs = []\n    for base_lr in self.base_lrs:\n      if self.current_epoch >= self.warmup_epochs:\n        last_epoch = self.current_epoch - self.warmup_epochs\n        assert last_epoch >= 0, 'invalid last_epoch : {:}'.format(last_epoch)\n        ratio = (self.max_LR - self.min_LR) * last_epoch / self.max_epochs / self.max_LR\n        lr = base_lr * (1-ratio)\n      else:\n        lr = (self.current_epoch / self.warmup_epochs + self.current_iter / self.warmup_epochs) * base_lr\n      lrs.append( lr )\n    return lrs\n\n\n\nclass CrossEntropyLabelSmooth(nn.Module):\n\n  def __init__(self, num_classes, epsilon):\n    super(CrossEntropyLabelSmooth, self).__init__()\n    self.num_classes = num_classes\n    self.epsilon = epsilon\n    self.logsoftmax = nn.LogSoftmax(dim=1)\n\n  def forward(self, inputs, targets):\n    log_probs = self.logsoftmax(inputs)\n    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n    loss = (-targets * log_probs).mean(0).sum()\n    return loss\n\n\n\ndef get_optim_scheduler(parameters, config):\n  assert hasattr(config, 'optim') and hasattr(config, 'scheduler') and hasattr(config, 'criterion'), 'config must have optim / scheduler / criterion keys instead of {:}'.format(config)\n  if config.optim == 'SGD':\n    optim = torch.optim.SGD(parameters, config.LR, momentum=config.momentum, weight_decay=config.decay, nesterov=config.nesterov)\n  elif config.optim == 'RMSprop':\n    optim = torch.optim.RMSprop(parameters, config.LR, momentum=config.momentum, weight_decay=config.decay)\n  else:\n    raise ValueError('invalid optim : {:}'.format(config.optim))\n\n  if config.scheduler == 'cos':\n    T_max = getattr(config, 'T_max', config.epochs)\n    scheduler = CosineAnnealingLR(optim, config.warmup, config.epochs, T_max, config.eta_min)\n  elif config.scheduler == 'multistep':\n    scheduler = MultiStepLR(optim, config.warmup, config.epochs, config.milestones, config.gammas)\n  elif config.scheduler == 'exponential':\n    scheduler = ExponentialLR(optim, config.warmup, config.epochs, config.gamma)\n  elif config.scheduler == 'linear':\n    scheduler = LinearLR(optim, config.warmup, config.epochs, config.LR, config.LR_min)\n  else:\n    raise ValueError('invalid scheduler : {:}'.format(config.scheduler))\n\n  if config.criterion == 'Softmax':\n    criterion = torch.nn.CrossEntropyLoss()\n  elif config.criterion == 'SmoothSoftmax':\n    criterion = CrossEntropyLabelSmooth(config.class_num, config.label_smooth)\n  else:\n    raise ValueError('invalid criterion : {:}'.format(config.criterion))\n  return optim, scheduler, criterion\n"""
lib/procedures/search_main.py,4,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, time, torch\nfrom log_utils import AverageMeter, time_string\nfrom utils     import obtain_accuracy\nfrom models    import change_key\n\n\ndef get_flop_loss(expected_flop, flop_cur, flop_need, flop_tolerant):\n  expected_flop = torch.mean( expected_flop )\n\n  if flop_cur < flop_need - flop_tolerant:   # Too Small FLOP\n    loss = - torch.log( expected_flop )\n  #elif flop_cur > flop_need + flop_tolerant: # Too Large FLOP\n  elif flop_cur > flop_need: # Too Large FLOP\n    loss = torch.log( expected_flop )\n  else: # Required FLOP\n    loss = None\n  if loss is None: return 0, 0\n  else           : return loss, loss.item()\n\n\ndef search_train(search_loader, network, criterion, scheduler, base_optimizer, arch_optimizer, optim_config, extra_info, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, arch_losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n  arch_cls_losses, arch_flop_losses = AverageMeter(), AverageMeter()\n  epoch_str, flop_need, flop_weight, flop_tolerant = extra_info['epoch-str'], extra_info['FLOP-exp'], extra_info['FLOP-weight'], extra_info['FLOP-tolerant']\n\n  network.train()\n  logger.log('[Search] : {:}, FLOP-Require={:.2f} MB, FLOP-WEIGHT={:.2f}'.format(epoch_str, flop_need, flop_weight))\n  end = time.time()\n  network.apply( change_key('search_mode', 'search') )\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(search_loader):\n    scheduler.update(None, 1.0 * step / len(search_loader))\n    # calculate prediction and loss\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    base_optimizer.zero_grad()\n    logits, expected_flop = network(base_inputs)\n    #network.apply( change_key('search_mode', 'basic') )\n    #features, logits = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    base_optimizer.step()\n    # record\n    prec1, prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(), base_inputs.size(0))\n    top1.update       (prec1.item(), base_inputs.size(0))\n    top5.update       (prec5.item(), base_inputs.size(0))\n\n    # update the architecture\n    arch_optimizer.zero_grad()\n    logits, expected_flop = network(arch_inputs)\n    flop_cur  = network.module.get_flop('genotype', None, None)\n    flop_loss, flop_loss_scale = get_flop_loss(expected_flop, flop_cur, flop_need, flop_tolerant)\n    acls_loss = criterion(logits, arch_targets)\n    arch_loss = acls_loss + flop_loss * flop_weight\n    arch_loss.backward()\n    arch_optimizer.step()\n  \n    # record\n    arch_losses.update(arch_loss.item(), arch_inputs.size(0))\n    arch_flop_losses.update(flop_loss_scale, arch_inputs.size(0))\n    arch_cls_losses.update (acls_loss.item(), arch_inputs.size(0))\n    \n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n    if step % print_freq == 0 or (step+1) == len(search_loader):\n      Sstr = '**TRAIN** ' + time_string() + ' [{:}][{:03d}/{:03d}]'.format(epoch_str, step, len(search_loader))\n      Tstr = 'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})'.format(batch_time=batch_time, data_time=data_time)\n      Lstr = 'Base-Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})'.format(loss=base_losses, top1=top1, top5=top5)\n      Vstr = 'Acls-loss {aloss.val:.3f} ({aloss.avg:.3f}) FLOP-Loss {floss.val:.3f} ({floss.avg:.3f}) Arch-Loss {loss.val:.3f} ({loss.avg:.3f})'.format(aloss=arch_cls_losses, floss=arch_flop_losses, loss=arch_losses)\n      logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Vstr)\n      #Istr = 'Bsz={:} Asz={:}'.format(list(base_inputs.size()), list(arch_inputs.size()))\n      #logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Vstr + ' ' + Istr)\n      #print(network.module.get_arch_info())\n      #print(network.module.width_attentions[0])\n      #print(network.module.width_attentions[1])\n\n  logger.log(' **TRAIN** Prec@1 {top1.avg:.2f} Prec@5 {top5.avg:.2f} Error@1 {error1:.2f} Error@5 {error5:.2f} Base-Loss:{baseloss:.3f}, Arch-Loss={archloss:.3f}'.format(top1=top1, top5=top5, error1=100-top1.avg, error5=100-top5.avg, baseloss=base_losses.avg, archloss=arch_losses.avg))\n  return base_losses.avg, arch_losses.avg, top1.avg, top5.avg\n\n\n\ndef search_valid(xloader, network, criterion, extra_info, print_freq, logger):\n  data_time, batch_time, losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n\n  network.eval()\n  network.apply( change_key('search_mode', 'search') )\n  end = time.time()\n  #logger.log('Starting evaluating {:}'.format(epoch_info))\n  with torch.no_grad():\n    for i, (inputs, targets) in enumerate(xloader):\n      # measure data loading time\n      data_time.update(time.time() - end)\n      # calculate prediction and loss\n      targets = targets.cuda(non_blocking=True)\n\n      logits, expected_flop = network(inputs)\n      loss             = criterion(logits, targets)\n      # record\n      prec1, prec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n      losses.update(loss.item(),  inputs.size(0))\n      top1.update  (prec1.item(), inputs.size(0))\n      top5.update  (prec5.item(), inputs.size(0))\n\n      # measure elapsed time\n      batch_time.update(time.time() - end)\n      end = time.time()\n\n      if i % print_freq == 0 or (i+1) == len(xloader):\n        Sstr = '**VALID** ' + time_string() + ' [{:}][{:03d}/{:03d}]'.format(extra_info, i, len(xloader))\n        Tstr = 'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})'.format(batch_time=batch_time, data_time=data_time)\n        Lstr = 'Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})'.format(loss=losses, top1=top1, top5=top5)\n        Istr = 'Size={:}'.format(list(inputs.size()))\n        logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Istr)\n\n  logger.log(' **VALID** Prec@1 {top1.avg:.2f} Prec@5 {top5.avg:.2f} Error@1 {error1:.2f} Error@5 {error5:.2f} Loss:{loss:.3f}'.format(top1=top1, top5=top5, error1=100-top1.avg, error5=100-top5.avg, loss=losses.avg))\n \n  return losses.avg, top1.avg, top5.avg\n"""
lib/procedures/search_main_v2.py,4,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, time, torch\nfrom log_utils import AverageMeter, time_string\nfrom utils     import obtain_accuracy\nfrom models    import change_key\n\n\ndef get_flop_loss(expected_flop, flop_cur, flop_need, flop_tolerant):\n  expected_flop = torch.mean( expected_flop )\n\n  if flop_cur < flop_need - flop_tolerant:   # Too Small FLOP\n    loss = - torch.log( expected_flop )\n  #elif flop_cur > flop_need + flop_tolerant: # Too Large FLOP\n  elif flop_cur > flop_need: # Too Large FLOP\n    loss = torch.log( expected_flop )\n  else: # Required FLOP\n    loss = None\n  if loss is None: return 0, 0\n  else           : return loss, loss.item()\n\n\ndef search_train_v2(search_loader, network, criterion, scheduler, base_optimizer, arch_optimizer, optim_config, extra_info, print_freq, logger):\n  data_time, batch_time = AverageMeter(), AverageMeter()\n  base_losses, arch_losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n  arch_cls_losses, arch_flop_losses = AverageMeter(), AverageMeter()\n  epoch_str, flop_need, flop_weight, flop_tolerant = extra_info['epoch-str'], extra_info['FLOP-exp'], extra_info['FLOP-weight'], extra_info['FLOP-tolerant']\n\n  network.train()\n  logger.log('[Search] : {:}, FLOP-Require={:.2f} MB, FLOP-WEIGHT={:.2f}'.format(epoch_str, flop_need, flop_weight))\n  end = time.time()\n  network.apply( change_key('search_mode', 'search') )\n  for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(search_loader):\n    scheduler.update(None, 1.0 * step / len(search_loader))\n    # calculate prediction and loss\n    base_targets = base_targets.cuda(non_blocking=True)\n    arch_targets = arch_targets.cuda(non_blocking=True)\n    # measure data loading time\n    data_time.update(time.time() - end)\n    \n    # update the weights\n    base_optimizer.zero_grad()\n    logits, expected_flop = network(base_inputs)\n    base_loss = criterion(logits, base_targets)\n    base_loss.backward()\n    base_optimizer.step()\n    # record\n    prec1, prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n    base_losses.update(base_loss.item(), base_inputs.size(0))\n    top1.update       (prec1.item(), base_inputs.size(0))\n    top5.update       (prec5.item(), base_inputs.size(0))\n\n    # update the architecture\n    arch_optimizer.zero_grad()\n    logits, expected_flop = network(arch_inputs)\n    flop_cur  = network.module.get_flop('genotype', None, None)\n    flop_loss, flop_loss_scale = get_flop_loss(expected_flop, flop_cur, flop_need, flop_tolerant)\n    acls_loss = criterion(logits, arch_targets)\n    arch_loss = acls_loss + flop_loss * flop_weight\n    arch_loss.backward()\n    arch_optimizer.step()\n  \n    # record\n    arch_losses.update(arch_loss.item(), arch_inputs.size(0))\n    arch_flop_losses.update(flop_loss_scale, arch_inputs.size(0))\n    arch_cls_losses.update (acls_loss.item(), arch_inputs.size(0))\n    \n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n    if step % print_freq == 0 or (step+1) == len(search_loader):\n      Sstr = '**TRAIN** ' + time_string() + ' [{:}][{:03d}/{:03d}]'.format(epoch_str, step, len(search_loader))\n      Tstr = 'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})'.format(batch_time=batch_time, data_time=data_time)\n      Lstr = 'Base-Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})'.format(loss=base_losses, top1=top1, top5=top5)\n      Vstr = 'Acls-loss {aloss.val:.3f} ({aloss.avg:.3f}) FLOP-Loss {floss.val:.3f} ({floss.avg:.3f}) Arch-Loss {loss.val:.3f} ({loss.avg:.3f})'.format(aloss=arch_cls_losses, floss=arch_flop_losses, loss=arch_losses)\n      logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Vstr)\n      #num_bytes = torch.cuda.max_memory_allocated( next(network.parameters()).device ) * 1.0\n      #logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Vstr + ' GPU={:.2f}MB'.format(num_bytes/1e6))\n      #Istr = 'Bsz={:} Asz={:}'.format(list(base_inputs.size()), list(arch_inputs.size()))\n      #logger.log(Sstr + ' ' + Tstr + ' ' + Lstr + ' ' + Vstr + ' ' + Istr)\n      #print(network.module.get_arch_info())\n      #print(network.module.width_attentions[0])\n      #print(network.module.width_attentions[1])\n\n  logger.log(' **TRAIN** Prec@1 {top1.avg:.2f} Prec@5 {top5.avg:.2f} Error@1 {error1:.2f} Error@5 {error5:.2f} Base-Loss:{baseloss:.3f}, Arch-Loss={archloss:.3f}'.format(top1=top1, top5=top5, error1=100-top1.avg, error5=100-top5.avg, baseloss=base_losses.avg, archloss=arch_losses.avg))\n  return base_losses.avg, arch_losses.avg, top1.avg, top5.avg\n"""
lib/procedures/simple_KD_main.py,3,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport os, sys, time, torch\nimport torch.nn.functional as F\n# our modules\nfrom log_utils import AverageMeter, time_string\nfrom utils     import obtain_accuracy\n\n\ndef simple_KD_train(xloader, teacher, network, criterion, scheduler, optimizer, optim_config, extra_info, print_freq, logger):\n  loss, acc1, acc5 = procedure(xloader, teacher, network, criterion, scheduler, optimizer, \'train\', optim_config, extra_info, print_freq, logger)\n  return loss, acc1, acc5\n\ndef simple_KD_valid(xloader, teacher, network, criterion, optim_config, extra_info, print_freq, logger):\n  with torch.no_grad():\n    loss, acc1, acc5 = procedure(xloader, teacher, network, criterion, None, None, \'valid\', optim_config, extra_info, print_freq, logger)\n  return loss, acc1, acc5\n\n\ndef loss_KD_fn(criterion, student_logits, teacher_logits, studentFeatures, teacherFeatures, targets, alpha, temperature):\n  basic_loss = criterion(student_logits, targets) * (1. - alpha)\n  log_student= F.log_softmax(student_logits / temperature, dim=1)\n  sof_teacher= F.softmax    (teacher_logits / temperature, dim=1)\n  KD_loss    = F.kl_div(log_student, sof_teacher, reduction=\'batchmean\') * (alpha * temperature * temperature)\n  return basic_loss + KD_loss\n\n\ndef procedure(xloader, teacher, network, criterion, scheduler, optimizer, mode, config, extra_info, print_freq, logger):\n  data_time, batch_time, losses, top1, top5 = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n  Ttop1, Ttop5 = AverageMeter(), AverageMeter()\n  if mode == \'train\':\n    network.train()\n  elif mode == \'valid\':\n    network.eval()\n  else: raise ValueError(""The mode is not right : {:}"".format(mode))\n  teacher.eval()\n  \n  logger.log(\'[{:5s}] config :: auxiliary={:}, KD :: [alpha={:.2f}, temperature={:.2f}]\'.format(mode, config.auxiliary if hasattr(config, \'auxiliary\') else -1, config.KD_alpha, config.KD_temperature))\n  end = time.time()\n  for i, (inputs, targets) in enumerate(xloader):\n    if mode == \'train\': scheduler.update(None, 1.0 * i / len(xloader))\n    # measure data loading time\n    data_time.update(time.time() - end)\n    # calculate prediction and loss\n    targets = targets.cuda(non_blocking=True)\n\n    if mode == \'train\': optimizer.zero_grad()\n\n    student_f, logits = network(inputs)\n    if isinstance(logits, list):\n      assert len(logits) == 2, \'logits must has {:} items instead of {:}\'.format(2, len(logits))\n      logits, logits_aux = logits\n    else:\n      logits, logits_aux = logits, None\n    with torch.no_grad():\n      teacher_f, teacher_logits = teacher(inputs)\n\n    loss             = loss_KD_fn(criterion, logits, teacher_logits, student_f, teacher_f, targets, config.KD_alpha, config.KD_temperature)\n    if config is not None and hasattr(config, \'auxiliary\') and config.auxiliary > 0:\n      loss_aux = criterion(logits_aux, targets)\n      loss += config.auxiliary * loss_aux\n    \n    if mode == \'train\':\n      loss.backward()\n      optimizer.step()\n\n    # record\n    sprec1, sprec5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n    losses.update(loss.item(),   inputs.size(0))\n    top1.update  (sprec1.item(), inputs.size(0))\n    top5.update  (sprec5.item(), inputs.size(0))\n    # teacher\n    tprec1, tprec5 = obtain_accuracy(teacher_logits.data, targets.data, topk=(1, 5))\n    Ttop1.update (tprec1.item(), inputs.size(0))\n    Ttop5.update (tprec5.item(), inputs.size(0))\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    if i % print_freq == 0 or (i+1) == len(xloader):\n      Sstr = \' {:5s} \'.format(mode.upper()) + time_string() + \' [{:}][{:03d}/{:03d}]\'.format(extra_info, i, len(xloader))\n      if scheduler is not None:\n        Sstr += \' {:}\'.format(scheduler.get_min_info())\n      Tstr = \'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\'.format(batch_time=batch_time, data_time=data_time)\n      Lstr = \'Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})\'.format(loss=losses, top1=top1, top5=top5)\n      Lstr+= \' Teacher : acc@1={:.2f}, acc@5={:.2f}\'.format(Ttop1.avg, Ttop5.avg)\n      Istr = \'Size={:}\'.format(list(inputs.size()))\n      logger.log(Sstr + \' \' + Tstr + \' \' + Lstr + \' \' + Istr)\n\n  logger.log(\' **{:5s}** accuracy drop :: @1={:.2f}, @5={:.2f}\'.format(mode.upper(), Ttop1.avg - top1.avg, Ttop5.avg - top5.avg))\n  logger.log(\' **{mode:5s}** Prec@1 {top1.avg:.2f} Prec@5 {top5.avg:.2f} Error@1 {error1:.2f} Error@5 {error5:.2f} Loss:{loss:.3f}\'.format(mode=mode.upper(), top1=top1, top5=top5, error1=100-top1.avg, error5=100-top5.avg, loss=losses.avg))\n  return losses.avg, top1.avg, top5.avg\n'"
lib/procedures/starts.py,12,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport os, sys, torch, random, PIL, copy, numpy as np\nfrom os import path as osp\nfrom shutil  import copyfile\n\n\ndef prepare_seed(rand_seed):\n  random.seed(rand_seed)\n  np.random.seed(rand_seed)\n  torch.manual_seed(rand_seed)\n  torch.cuda.manual_seed(rand_seed)\n  torch.cuda.manual_seed_all(rand_seed)\n\n\ndef prepare_logger(xargs):\n  args = copy.deepcopy( xargs )\n  from log_utils import Logger\n  logger = Logger(args.save_dir, args.rand_seed)\n  logger.log(\'Main Function with logger : {:}\'.format(logger))\n  logger.log(\'Arguments : -------------------------------\')\n  for name, value in args._get_kwargs():\n    logger.log(\'{:16} : {:}\'.format(name, value))\n  logger.log(""Python  Version  : {:}"".format(sys.version.replace(\'\\n\', \' \')))\n  logger.log(""Pillow  Version  : {:}"".format(PIL.__version__))\n  logger.log(""PyTorch Version  : {:}"".format(torch.__version__))\n  logger.log(""cuDNN   Version  : {:}"".format(torch.backends.cudnn.version()))\n  logger.log(""CUDA available   : {:}"".format(torch.cuda.is_available()))\n  logger.log(""CUDA GPU numbers : {:}"".format(torch.cuda.device_count()))\n  logger.log(""CUDA_VISIBLE_DEVICES : {:}"".format(os.environ[\'CUDA_VISIBLE_DEVICES\'] if \'CUDA_VISIBLE_DEVICES\' in os.environ else \'None\'))\n  return logger\n\n\ndef get_machine_info():\n  info = ""Python  Version  : {:}"".format(sys.version.replace(\'\\n\', \' \'))\n  info+= ""\\nPillow  Version  : {:}"".format(PIL.__version__)\n  info+= ""\\nPyTorch Version  : {:}"".format(torch.__version__)\n  info+= ""\\ncuDNN   Version  : {:}"".format(torch.backends.cudnn.version())\n  info+= ""\\nCUDA available   : {:}"".format(torch.cuda.is_available())\n  info+= ""\\nCUDA GPU numbers : {:}"".format(torch.cuda.device_count())\n  if \'CUDA_VISIBLE_DEVICES\' in os.environ:\n    info+= ""\\nCUDA_VISIBLE_DEVICES={:}"".format(os.environ[\'CUDA_VISIBLE_DEVICES\'])\n  else:\n    info+= ""\\nDoes not set CUDA_VISIBLE_DEVICES""\n  return info\n\n\ndef save_checkpoint(state, filename, logger):\n  if osp.isfile(filename):\n    if hasattr(logger, \'log\'): logger.log(\'Find {:} exist, delete is at first before saving\'.format(filename))\n    os.remove(filename)\n  torch.save(state, filename)\n  assert osp.isfile(filename), \'save filename : {:} failed, which is not found.\'.format(filename)\n  if hasattr(logger, \'log\'): logger.log(\'save checkpoint into {:}\'.format(filename))\n  return filename\n\n\ndef copy_checkpoint(src, dst, logger):\n  if osp.isfile(dst):\n    if hasattr(logger, \'log\'): logger.log(\'Find {:} exist, delete is at first before saving\'.format(dst))\n    os.remove(dst)\n  copyfile(src, dst)\n  if hasattr(logger, \'log\'): logger.log(\'copy the file from {:} into {:}\'.format(src, dst))\n'"
lib/tf_models/__init__.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport torch\nfrom os import path as osp\n\n__all__ = ['get_cell_based_tiny_net', 'get_search_spaces']\n\n\n# the cell-based NAS models\ndef get_cell_based_tiny_net(config):\n  group_names = ['GDAS', 'DARTS']\n  if config.name in group_names:\n    from .cell_searchs import nas_super_nets\n    from .cell_operations import SearchSpaceNames\n    if isinstance(config.space, str): search_space = SearchSpaceNames[config.space]\n    else: search_space = config.space\n    return nas_super_nets[config.name](\n                  config.C, config.N, config.max_nodes,\n                  config.num_classes, search_space, config.affine)\n  else:\n    raise ValueError('invalid network name : {:}'.format(config.name))\n\n\n# obtain the search space, i.e., a dict mapping the operation name into a python-function for this op\ndef get_search_spaces(xtype, name):\n  if xtype == 'cell':\n    from .cell_operations import SearchSpaceNames\n    assert name in SearchSpaceNames, 'invalid name [{:}] in {:}'.format(name, SearchSpaceNames.keys())\n    return SearchSpaceNames[name]\n  else:\n    raise ValueError('invalid search-space type is {:}'.format(xtype))\n"""
lib/tf_models/cell_operations.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport tensorflow as tf\n\n__all__ = [\'OPS\', \'ResNetBasicblock\', \'SearchSpaceNames\']\n\nOPS = {\n  \'none\'        : lambda C_in, C_out, stride, affine: Zero(C_in, C_out, stride),\n  \'avg_pool_3x3\': lambda C_in, C_out, stride, affine: POOLING(C_in, C_out, stride, \'avg\', affine),\n  \'nor_conv_1x1\': lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, 1, stride, affine),\n  \'nor_conv_3x3\': lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, 3, stride, affine),\n  \'nor_conv_5x5\': lambda C_in, C_out, stride, affine: ReLUConvBN(C_in, C_out, 5, stride, affine),\n  \'skip_connect\': lambda C_in, C_out, stride, affine: Identity(C_in, C_out, stride) if stride == 1 and C_in == C_out else FactorizedReduce(C_in, C_out, stride, affine)\n}\n\nNAS_BENCH_201         = [\'none\', \'skip_connect\', \'nor_conv_1x1\', \'nor_conv_3x3\', \'avg_pool_3x3\']\n\nSearchSpaceNames = {\n                    \'nas-bench-201\': NAS_BENCH_201,\n                   }\n\n\nclass POOLING(tf.keras.layers.Layer):\n\n  def __init__(self, C_in, C_out, stride, mode, affine):\n    super(POOLING, self).__init__()\n    if C_in == C_out:\n      self.preprocess = None\n    else:\n      self.preprocess = ReLUConvBN(C_in, C_out, 1, 1, affine)\n    if mode == \'avg\'  : self.op = tf.keras.layers.AvgPool2D((3,3), strides=stride, padding=\'same\')\n    elif mode == \'max\': self.op = tf.keras.layers.MaxPool2D((3,3), strides=stride, padding=\'same\')\n    else              : raise ValueError(\'Invalid mode={:} in POOLING\'.format(mode))\n\n  def call(self, inputs, training):\n    if self.preprocess: x = self.preprocess(inputs)\n    else              : x = inputs\n    return self.op(x)\n\n\nclass Identity(tf.keras.layers.Layer):\n  def __init__(self, C_in, C_out, stride):\n    super(Identity, self).__init__()\n    if C_in != C_out or stride != 1:\n      self.layer = tf.keras.layers.Conv2D(C_out, 3, stride, padding=\'same\', use_bias=False)\n    else:\n      self.layer = None\n  \n  def call(self, inputs, training):\n    x = inputs\n    if self.layer is not None:\n      x = self.layer(x)\n    return x\n\n\n\nclass Zero(tf.keras.layers.Layer):\n  def __init__(self, C_in, C_out, stride):\n    super(Zero, self).__init__()\n    if C_in != C_out:\n      self.layer = tf.keras.layers.Conv2D(C_out, 1, stride, padding=\'same\', use_bias=False)\n    elif stride != 1:\n      self.layer = tf.keras.layers.AvgPool2D((stride,stride), None, padding=""same"")\n    else:\n      self.layer = None\n  \n  def call(self, inputs, training):\n    x = tf.zeros_like(inputs)\n    if self.layer is not None:\n      x = self.layer(x)\n    return x\n\n\nclass ReLUConvBN(tf.keras.layers.Layer):\n  def __init__(self, C_in, C_out, kernel_size, strides, affine):\n    super(ReLUConvBN, self).__init__()\n    self.C_in = C_in\n    self.relu = tf.keras.activations.relu\n    self.conv = tf.keras.layers.Conv2D(C_out, kernel_size, strides, padding=\'same\', use_bias=False)\n    self.bn   = tf.keras.layers.BatchNormalization(center=affine, scale=affine)\n  \n  def call(self, inputs, training):\n    x = self.relu(inputs)\n    x = self.conv(x)\n    x = self.bn(x, training)\n    return x\n\n\nclass FactorizedReduce(tf.keras.layers.Layer):\n  def __init__(self, C_in, C_out, stride, affine):\n    assert output_filters % 2 == 0, (\'Need even number of filters when using this factorized reduction.\')\n    self.stride == stride\n    self.relu   = tf.keras.activations.relu\n    if stride == 1:\n      self.layer = tf.keras.Sequential([\n                          tf.keras.layers.Conv2D(C_out, 1, strides, padding=\'same\', use_bias=False),\n                          tf.keras.layers.BatchNormalization(center=affine, scale=affine)])\n    elif stride == 2:\n      stride_spec = [1, stride, stride, 1] # data_format == \'NHWC\'\n      self.layer1 = tf.keras.layers.Conv2D(C_out//2, 1, strides, padding=\'same\', use_bias=False)\n      self.layer2 = tf.keras.layers.Conv2D(C_out//2, 1, strides, padding=\'same\', use_bias=False)\n      self.bn     = tf.keras.layers.BatchNormalization(center=affine, scale=affine)\n    else:\n      raise ValueError(\'invalid stride={:}\'.format(stride))\n\n  def call(self, inputs, training):\n    x = self.relu(inputs)\n    if self.stride == 1:\n      return self.layer(x, training)\n    else:\n      path1 = x\n      path2 = tf.pad(x, [[0, 0], [0, 1], [0, 1], [0, 0]])[:, 1:, 1:, :] # data_format == \'NHWC\'\n      x1 = self.layer1(path1)\n      x2 = self.layer2(path2)\n      final_path = tf.concat(values=[x1, x2], axis=3)\n      return self.bn(final_path)\n\n\nclass ResNetBasicblock(tf.keras.layers.Layer):\n\n  def __init__(self, inplanes, planes, stride, affine=True):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ReLUConvBN(inplanes, planes, 3, stride, affine)\n    self.conv_b = ReLUConvBN(  planes, planes, 3,      1, affine)\n    if stride == 2:\n      self.downsample = tf.keras.Sequential([\n                                tf.keras.layers.AvgPool2D((stride,stride), None, padding=""same""),\n                                tf.keras.layers.Conv2D(planes, 1, 1, padding=\'same\', use_bias=False)])\n    elif inplanes != planes:\n      self.downsample = ReLUConvBN(inplanes, planes, 1, stride, affine)\n    else:\n      self.downsample = None\n    self.addition = tf.keras.layers.Add()\n    self.in_dim  = inplanes\n    self.out_dim = planes\n    self.stride  = stride\n    self.num_conv = 2\n\n  def call(self, inputs, training):\n\n    basicblock = self.conv_a(inputs, training)\n    basicblock = self.conv_b(basicblock, training)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    return self.addition([residual, basicblock])\n'"
lib/tf_optimizers/__init__.py,0,"b'from .weight_decay_optimizers import AdamW, SGDW\n'"
lib/tf_optimizers/weight_decay_optimizers.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Base class to make optimizers weight decay ready.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\nclass DecoupledWeightDecayExtension(object):\n    """"""This class allows to extend optimizers with decoupled weight decay.\n\n    It implements the decoupled weight decay described by Loshchilov & Hutter\n    (https://arxiv.org/pdf/1711.05101.pdf), in which the weight decay is\n    decoupled from the optimization steps w.r.t. to the loss function.\n    For SGD variants, this simplifies hyperparameter search since it decouples\n    the settings of weight decay and learning rate.\n    For adaptive gradient algorithms, it regularizes variables with large\n    gradients more than L2 regularization would, which was shown to yield\n    better training loss and generalization error in the paper above.\n\n    This class alone is not an optimizer but rather extends existing\n    optimizers with decoupled weight decay. We explicitly define the two\n    examples used in the above paper (SGDW and AdamW), but in general this\n    can extend any OptimizerX by using\n    `extend_with_decoupled_weight_decay(\n        OptimizerX, weight_decay=weight_decay)`.\n    In order for it to work, it must be the first class the Optimizer with\n    weight decay inherits from, e.g.\n\n    ```python\n    class AdamW(DecoupledWeightDecayExtension, tf.keras.optimizers.Adam):\n      def __init__(self, weight_decay, *args, **kwargs):\n        super(AdamW, self).__init__(weight_decay, *args, **kwargs).\n    ```\n\n    Note: this extension decays weights BEFORE applying the update based\n    on the gradient, i.e. this extension only has the desired behaviour for\n    optimizers which do not depend on the value of\'var\' in the update step!\n\n    Note: when applying a decay to the learning rate, be sure to manually apply\n    the decay to the `weight_decay` as well. For example:\n\n    ```python\n    step = tf.Variable(0, trainable=False)\n    schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n        [10000, 15000], [1e-0, 1e-1, 1e-2])\n    # lr and wd can be a function or a tensor\n    lr = 1e-1 * schedule(step)\n    wd = lambda: 1e-4 * schedule(step)\n\n    # ...\n\n    optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n    ```\n    """"""\n\n    def __init__(self, weight_decay, **kwargs):\n        """"""Extension class that adds weight decay to an optimizer.\n\n        Args:\n            weight_decay: A `Tensor` or a floating point value, the factor by\n                which a variable is decayed in the update step.\n            **kwargs: Optional list or tuple or set of `Variable` objects to\n                decay.\n        """"""\n        wd = kwargs.pop(\'weight_decay\', weight_decay)\n        super(DecoupledWeightDecayExtension, self).__init__(**kwargs)\n        self._decay_var_list = None  # is set in minimize or apply_gradients\n        self._set_hyper(\'weight_decay\', wd)\n\n    def get_config(self):\n        config = super(DecoupledWeightDecayExtension, self).get_config()\n        config.update({\n            \'weight_decay\':\n            self._serialize_hyperparameter(\'weight_decay\'),\n        })\n        return config\n\n    def minimize(self,\n                 loss,\n                 var_list,\n                 grad_loss=None,\n                 name=None,\n                 decay_var_list=None):\n        """"""Minimize `loss` by updating `var_list`.\n\n        This method simply computes gradient using `tf.GradientTape` and calls\n        `apply_gradients()`. If you want to process the gradient before\n        applying then call `tf.GradientTape` and `apply_gradients()` explicitly\n        instead of using this function.\n\n        Args:\n            loss: A callable taking no arguments which returns the value to\n                minimize.\n            var_list: list or tuple of `Variable` objects to update to\n                minimize `loss`, or a callable returning the list or tuple of\n                `Variable` objects. Use callable when the variable list would\n                otherwise be incomplete before `minimize` since the variables\n                are created at the first time `loss` is called.\n            grad_loss: Optional. A `Tensor` holding the gradient computed for\n                `loss`.\n            decay_var_list: Optional list of variables to be decayed. Defaults\n                to all variables in var_list.\n            name: Optional name for the returned operation.\n        Returns:\n            An Operation that updates the variables in `var_list`.  If\n            `global_step` was not `None`, that operation also increments\n            `global_step`.\n        Raises:\n            ValueError: If some of the variables are not `Variable` objects.\n        """"""\n        self._decay_var_list = set(decay_var_list) if decay_var_list else False\n        return super(DecoupledWeightDecayExtension, self).minimize(\n            loss, var_list=var_list, grad_loss=grad_loss, name=name)\n\n    def apply_gradients(self, grads_and_vars, name=None, decay_var_list=None):\n        """"""Apply gradients to variables.\n\n        This is the second part of `minimize()`. It returns an `Operation` that\n        applies gradients.\n\n        Args:\n            grads_and_vars: List of (gradient, variable) pairs.\n            name: Optional name for the returned operation.  Default to the\n                name passed to the `Optimizer` constructor.\n            decay_var_list: Optional list of variables to be decayed. Defaults\n                to all variables in var_list.\n        Returns:\n            An `Operation` that applies the specified gradients. If\n            `global_step` was not None, that operation also increments\n            `global_step`.\n        Raises:\n            TypeError: If `grads_and_vars` is malformed.\n            ValueError: If none of the variables have gradients.\n        """"""\n        self._decay_var_list = set(decay_var_list) if decay_var_list else False\n        return super(DecoupledWeightDecayExtension, self).apply_gradients(\n            grads_and_vars, name=name)\n\n    def _decay_weights_op(self, var):\n        if not self._decay_var_list or var in self._decay_var_list:\n            return var.assign_sub(\n                self._get_hyper(\'weight_decay\', var.dtype) * var,\n                self._use_locking)\n        return tf.no_op()\n\n    def _decay_weights_sparse_op(self, var, indices):\n        if not self._decay_var_list or var in self._decay_var_list:\n            update = (-self._get_hyper(\'weight_decay\', var.dtype) * tf.gather(\n                var, indices))\n            return self._resource_scatter_add(var, indices, update)\n        return tf.no_op()\n\n    # Here, we overwrite the apply functions that the base optimizer calls.\n    # super().apply_x resolves to the apply_x function of the BaseOptimizer.\n\n    def _resource_apply_dense(self, grad, var):\n        with tf.control_dependencies([self._decay_weights_op(var)]):\n            return super(DecoupledWeightDecayExtension,\n                         self)._resource_apply_dense(grad, var)\n\n    def _resource_apply_sparse(self, grad, var, indices):\n        decay_op = self._decay_weights_sparse_op(var, indices)\n        with tf.control_dependencies([decay_op]):\n            return super(DecoupledWeightDecayExtension,\n                         self)._resource_apply_sparse(grad, var, indices)\n\n\ndef extend_with_decoupled_weight_decay(base_optimizer):\n    """"""Factory function returning an optimizer class with decoupled weight\n    decay.\n\n    Returns an optimizer class. An instance of the returned class computes the\n    update step of `base_optimizer` and additionally decays the weights.\n    E.g., the class returned by\n    `extend_with_decoupled_weight_decay(tf.keras.optimizers.Adam)` is\n    equivalent to `tfa.optimizers.AdamW`.\n\n    The API of the new optimizer class slightly differs from the API of the\n    base optimizer:\n    - The first argument to the constructor is the weight decay rate.\n    - `minimize` and `apply_gradients` accept the optional keyword argument\n      `decay_var_list`, which specifies the variables that should be decayed.\n      If `None`, all variables that are optimized are decayed.\n\n    Usage example:\n    ```python\n    # MyAdamW is a new class\n    MyAdamW = extend_with_decoupled_weight_decay(tf.keras.optimizers.Adam)\n    # Create a MyAdamW object\n    optimizer = MyAdamW(weight_decay=0.001, learning_rate=0.001)\n    # update var1, var2 but only decay var1\n    optimizer.minimize(loss, var_list=[var1, var2], decay_variables=[var1])\n\n    Note: this extension decays weights BEFORE applying the update based\n    on the gradient, i.e. this extension only has the desired behaviour for\n    optimizers which do not depend on the value of \'var\' in the update step!\n\n    Note: when applying a decay to the learning rate, be sure to manually apply\n    the decay to the `weight_decay` as well. For example:\n\n    ```python\n    step = tf.Variable(0, trainable=False)\n    schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n        [10000, 15000], [1e-0, 1e-1, 1e-2])\n    # lr and wd can be a function or a tensor\n    lr = 1e-1 * schedule(step)\n    wd = lambda: 1e-4 * schedule(step)\n\n    # ...\n\n    optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n    ```\n\n    Note: you might want to register your own custom optimizer using\n    `tf.keras.utils.get_custom_objects()`.\n\n    Args:\n        base_optimizer: An optimizer class that inherits from\n            tf.optimizers.Optimizer.\n\n    Returns:\n        A new optimizer class that inherits from DecoupledWeightDecayExtension\n        and base_optimizer.\n    """"""\n\n    class OptimizerWithDecoupledWeightDecay(DecoupledWeightDecayExtension,\n                                            base_optimizer):\n        """"""Base_optimizer with decoupled weight decay.\n\n        This class computes the update step of `base_optimizer` and\n        additionally decays the variable with the weight decay being\n        decoupled from the optimization steps w.r.t. to the loss\n        function, as described by Loshchilov & Hutter\n        (https://arxiv.org/pdf/1711.05101.pdf). For SGD variants, this\n        simplifies hyperparameter search since it decouples the settings\n        of weight decay and learning rate. For adaptive gradient\n        algorithms, it regularizes variables with large gradients more\n        than L2 regularization would, which was shown to yield better\n        training loss and generalization error in the paper above.\n        """"""\n\n        def __init__(self, weight_decay, *args, **kwargs):\n            # super delegation is necessary here\n            super(OptimizerWithDecoupledWeightDecay, self).__init__(\n                weight_decay, *args, **kwargs)\n\n    return OptimizerWithDecoupledWeightDecay\n\n\nclass SGDW(DecoupledWeightDecayExtension, tf.keras.optimizers.SGD):\n    """"""Optimizer that implements the Momentum algorithm with weight_decay.\n\n    This is an implementation of the SGDW optimizer described in ""Decoupled\n    Weight Decay Regularization"" by Loshchilov & Hutter\n    (https://arxiv.org/abs/1711.05101)\n    ([pdf])(https://arxiv.org/pdf/1711.05101.pdf).\n    It computes the update step of `tf.keras.optimizers.SGD` and additionally\n    decays the variable. Note that this is different from adding\n    L2 regularization on the variables to the loss. Decoupling the weight decay\n    from other hyperparameters (in particular the learning rate) simplifies\n    hyperparameter search.\n\n    For further information see the documentation of the SGD Optimizer.\n\n    This optimizer can also be instantiated as\n    ```python\n    extend_with_decoupled_weight_decay(tf.keras.optimizers.SGD,\n                                       weight_decay=weight_decay)\n    ```\n\n    Note: when applying a decay to the learning rate, be sure to manually apply\n    the decay to the `weight_decay` as well. For example:\n\n    ```python\n    step = tf.Variable(0, trainable=False)\n    schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n        [10000, 15000], [1e-0, 1e-1, 1e-2])\n    # lr and wd can be a function or a tensor\n    lr = 1e-1 * schedule(step)\n    wd = lambda: 1e-4 * schedule(step)\n\n    # ...\n\n    optimizer = tfa.optimizers.SGDW(\n        learning_rate=lr, weight_decay=wd, momentum=0.9)\n    ```\n    """"""\n\n    def __init__(self,\n                 weight_decay,\n                 learning_rate=0.001,\n                 momentum=0.0,\n                 nesterov=False,\n                 name=\'SGDW\',\n                 **kwargs):\n        """"""Construct a new SGDW optimizer.\n\n        For further information see the documentation of the SGD Optimizer.\n\n        Args:\n            learning_rate: float hyperparameter >= 0. Learning rate.\n            momentum: float hyperparameter >= 0 that accelerates SGD in the\n                relevant direction and dampens oscillations.\n            nesterov: boolean. Whether to apply Nesterov momentum.\n            name: Optional name prefix for the operations created when applying\n                gradients.  Defaults to \'SGD\'.\n            **kwargs: keyword arguments. Allowed to be {`clipnorm`,\n                `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by\n                norm; `clipvalue` is clip gradients by value, `decay` is\n                included for backward compatibility to allow time inverse decay\n                of learning rate. `lr` is included for backward compatibility,\n                recommended to use `learning_rate` instead.\n        """"""\n        super(SGDW, self).__init__(\n            weight_decay,\n            learning_rate=learning_rate,\n            momentum=momentum,\n            nesterov=nesterov,\n            name=name,\n            **kwargs)\n\n\nclass AdamW(DecoupledWeightDecayExtension, tf.keras.optimizers.Adam):\n    """"""Optimizer that implements the Adam algorithm with weight decay.\n\n    This is an implementation of the AdamW optimizer described in ""Decoupled\n    Weight Decay Regularization"" by Loshchilov & Hutter\n    (https://arxiv.org/abs/1711.05101)\n    ([pdf])(https://arxiv.org/pdf/1711.05101.pdf).\n\n    It computes the update step of `tf.keras.optimizers.Adam` and additionally\n    decays the variable. Note that this is different from adding L2\n    regularization on the variables to the loss: it regularizes variables with\n    large gradients more than L2 regularization would, which was shown to yield\n    better training loss and generalization error in the paper above.\n\n    For further information see the documentation of the Adam Optimizer.\n\n    This optimizer can also be instantiated as\n    ```python\n    extend_with_decoupled_weight_decay(tf.keras.optimizers.Adam,\n                                       weight_decay=weight_decay)\n    ```\n\n    Note: when applying a decay to the learning rate, be sure to manually apply\n    the decay to the `weight_decay` as well. For example:\n\n    ```python\n    step = tf.Variable(0, trainable=False)\n    schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n        [10000, 15000], [1e-0, 1e-1, 1e-2])\n    # lr and wd can be a function or a tensor\n    lr = 1e-1 * schedule(step)\n    wd = lambda: 1e-4 * schedule(step)\n\n    # ...\n\n    optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n    ```\n    """"""\n\n    def __init__(self,\n                 weight_decay,\n                 learning_rate=0.001,\n                 beta_1=0.9,\n                 beta_2=0.999,\n                 epsilon=1e-07,\n                 amsgrad=False,\n                 name=""AdamW"",\n                 **kwargs):\n        """"""Construct a new AdamW optimizer.\n\n        For further information see the documentation of the Adam Optimizer.\n\n        Args:\n            weight_decay: A Tensor or a floating point value. The weight decay.\n            learning_rate: A Tensor or a floating point value. The learning\n                rate.\n            beta_1: A float value or a constant float tensor. The exponential\n                decay rate for the 1st moment estimates.\n            beta_2: A float value or a constant float tensor. The exponential\n                decay rate for the 2nd moment estimates.\n            epsilon: A small constant for numerical stability. This epsilon is\n                ""epsilon hat"" in the Kingma and Ba paper (in the formula just\n                before Section 2.1), not the epsilon in Algorithm 1 of the\n                paper.\n            amsgrad: boolean. Whether to apply AMSGrad variant of this\n                algorithm from the paper ""On the Convergence of Adam and\n                beyond"".\n            name: Optional name for the operations created when applying\n                gradients. Defaults to ""AdamW"".\n            **kwargs: keyword arguments. Allowed to be {`clipnorm`,\n                `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by\n                norm; `clipvalue` is clip gradients by value, `decay` is\n                included for backward compatibility to allow time inverse decay\n                of learning rate. `lr` is included for backward compatibility,\n                recommended to use `learning_rate` instead.\n        """"""\n        super(AdamW, self).__init__(\n            weight_decay,\n            learning_rate=learning_rate,\n            beta_1=beta_1,\n            beta_2=beta_2,\n            epsilon=epsilon,\n            amsgrad=amsgrad,\n            name=name,\n            **kwargs)\n'"
lib/utils/__init__.py,0,"b'from .evaluation_utils import obtain_accuracy\nfrom .gpu_manager      import GPUManager\nfrom .flop_benchmark   import get_model_infos\nfrom .affine_utils     import normalize_points, denormalize_points\nfrom .affine_utils     import identity2affine, solve2theta, affine2image\n'"
lib/utils/affine_utils.py,19,"b""# functions for affine transformation\nimport math, torch\nimport numpy as np\nimport torch.nn.functional as F\n\ndef identity2affine(full=False):\n  if not full:\n    parameters = torch.zeros((2,3))\n    parameters[0, 0] = parameters[1, 1] = 1\n  else:\n    parameters = torch.zeros((3,3))\n    parameters[0, 0] = parameters[1, 1] = parameters[2, 2] = 1\n  return parameters\n\ndef normalize_L(x, L):\n  return -1. + 2. * x / (L-1)\n\ndef denormalize_L(x, L):\n  return (x + 1.0) / 2.0 * (L-1)\n\ndef crop2affine(crop_box, W, H):\n  assert len(crop_box) == 4, 'Invalid crop-box : {:}'.format(crop_box)\n  parameters = torch.zeros(3,3)\n  x1, y1 = normalize_L(crop_box[0], W), normalize_L(crop_box[1], H)\n  x2, y2 = normalize_L(crop_box[2], W), normalize_L(crop_box[3], H)\n  parameters[0,0] = (x2-x1)/2\n  parameters[0,2] = (x2+x1)/2\n\n  parameters[1,1] = (y2-y1)/2\n  parameters[1,2] = (y2+y1)/2\n  parameters[2,2] = 1\n  return parameters\n\ndef scale2affine(scalex, scaley):\n  parameters = torch.zeros(3,3)\n  parameters[0,0] = scalex\n  parameters[1,1] = scaley\n  parameters[2,2] = 1\n  return parameters\n \ndef offset2affine(offx, offy):\n  parameters = torch.zeros(3,3)\n  parameters[0,0] = parameters[1,1] = parameters[2,2] = 1\n  parameters[0,2] = offx\n  parameters[1,2] = offy\n  return parameters\n\ndef horizontalmirror2affine():\n  parameters = torch.zeros(3,3)\n  parameters[0,0] = -1\n  parameters[1,1] = parameters[2,2] = 1\n  return parameters\n\n# clockwise rotate image = counterclockwise rotate the rectangle\n# degree is between [0, 360]\ndef rotate2affine(degree):\n  assert degree >= 0 and degree <= 360, 'Invalid degree : {:}'.format(degree)\n  degree = degree / 180 * math.pi\n  parameters = torch.zeros(3,3)\n  parameters[0,0] =  math.cos(-degree)\n  parameters[0,1] = -math.sin(-degree)\n  parameters[1,0] =  math.sin(-degree)\n  parameters[1,1] =  math.cos(-degree)\n  parameters[2,2] = 1\n  return parameters\n\n# shape is a tuple [H, W]\ndef normalize_points(shape, points):\n  assert (isinstance(shape, tuple) or isinstance(shape, list)) and len(shape) == 2, 'invalid shape : {:}'.format(shape)  \n  assert isinstance(points, torch.Tensor) and (points.shape[0] == 2), 'points are wrong : {:}'.format(points.shape)\n  (H, W), points = shape, points.clone()\n  points[0, :] = normalize_L(points[0,:], W)\n  points[1, :] = normalize_L(points[1,:], H)\n  return points\n\n# shape is a tuple [H, W]\ndef normalize_points_batch(shape, points):\n  assert (isinstance(shape, tuple) or isinstance(shape, list)) and len(shape) == 2, 'invalid shape : {:}'.format(shape)  \n  assert isinstance(points, torch.Tensor) and (points.size(-1) == 2), 'points are wrong : {:}'.format(points.shape)\n  (H, W), points = shape, points.clone()\n  x = normalize_L(points[...,0], W)\n  y = normalize_L(points[...,1], H)\n  return torch.stack((x,y), dim=-1)\n\n# shape is a tuple [H, W]\ndef denormalize_points(shape, points):\n  assert (isinstance(shape, tuple) or isinstance(shape, list)) and len(shape) == 2, 'invalid shape : {:}'.format(shape)  \n  assert isinstance(points, torch.Tensor) and (points.shape[0] == 2), 'points are wrong : {:}'.format(points.shape)\n  (H, W), points = shape, points.clone()\n  points[0, :] = denormalize_L(points[0,:], W)\n  points[1, :] = denormalize_L(points[1,:], H)\n  return points\n\n# shape is a tuple [H, W]\ndef denormalize_points_batch(shape, points):\n  assert (isinstance(shape, tuple) or isinstance(shape, list)) and len(shape) == 2, 'invalid shape : {:}'.format(shape)  \n  assert isinstance(points, torch.Tensor) and (points.shape[-1] == 2), 'points are wrong : {:}'.format(points.shape)\n  (H, W), points = shape, points.clone()\n  x = denormalize_L(points[...,0], W)\n  y = denormalize_L(points[...,1], H)\n  return torch.stack((x,y), dim=-1)\n\n# make target * theta = source\ndef solve2theta(source, target):\n  source, target = source.clone(), target.clone()\n  oks = source[2, :] == 1\n  assert torch.sum(oks).item() >= 3, 'valid points : {:} is short'.format(oks)\n  if target.size(0) == 2: target = torch.cat((target, oks.unsqueeze(0).float()), dim=0)\n  source, target = source[:, oks], target[:, oks]\n  source, target = source.transpose(1,0), target.transpose(1,0)\n  assert source.size(1) == target.size(1) == 3\n  #X, residual, rank, s = np.linalg.lstsq(target.numpy(), source.numpy())\n  #theta = torch.Tensor(X.T[:2, :])\n  X_, qr = torch.gels(source, target)\n  theta = X_[:3, :2].transpose(1, 0)\n  return theta\n\n# shape = [H,W]\ndef affine2image(image, theta, shape):\n  C, H, W = image.size()\n  theta = theta[:2, :].unsqueeze(0)\n  grid_size = torch.Size([1, C, shape[0], shape[1]])\n  grid  = F.affine_grid(theta, grid_size)\n  affI  = F.grid_sample(image.unsqueeze(0), grid, mode='bilinear', padding_mode='border')\n  return affI.squeeze(0)\n"""
lib/utils/evaluation_utils.py,0,"b'import torch\n\ndef obtain_accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n'"
lib/utils/flop_benchmark.py,16,"b'import torch\nimport torch.nn as nn\nimport numpy as np\n\n\ndef count_parameters_in_MB(model):\n  if isinstance(model, nn.Module):\n    return np.sum(np.prod(v.size()) for v in model.parameters())/1e6\n  else:\n    return np.sum(np.prod(v.size()) for v in model)/1e6\n\n\ndef get_model_infos(model, shape):\n  #model = copy.deepcopy( model )\n\n  model = add_flops_counting_methods(model)\n  #model = model.cuda()\n  model.eval()\n\n  #cache_inputs = torch.zeros(*shape).cuda()\n  #cache_inputs = torch.zeros(*shape)\n  cache_inputs = torch.rand(*shape)\n  if next(model.parameters()).is_cuda: cache_inputs = cache_inputs.cuda()\n  #print_log(\'In the calculating function : cache input size : {:}\'.format(cache_inputs.size()), log)\n  with torch.no_grad():\n    _____ = model(cache_inputs)\n  FLOPs = compute_average_flops_cost( model ) / 1e6\n  Param = count_parameters_in_MB(model)\n\n  if hasattr(model, \'auxiliary_param\'):\n    aux_params = count_parameters_in_MB(model.auxiliary_param()) \n    print (\'The auxiliary params of this model is : {:}\'.format(aux_params))\n    print (\'We remove the auxiliary params from the total params ({:}) when counting\'.format(Param))\n    Param = Param - aux_params\n  \n  #print_log(\'FLOPs : {:} MB\'.format(FLOPs), log)\n  torch.cuda.empty_cache()\n  model.apply( remove_hook_function )\n  return FLOPs, Param\n\n\n# ---- Public functions\ndef add_flops_counting_methods( model ):\n  model.__batch_counter__ = 0\n  add_batch_counter_hook_function( model )\n  model.apply( add_flops_counter_variable_or_reset )\n  model.apply( add_flops_counter_hook_function )\n  return model\n\n\n\ndef compute_average_flops_cost(model):\n  """"""\n  A method that will be available after add_flops_counting_methods() is called on a desired net object.\n  Returns current mean flops consumption per image.\n  """"""\n  batches_count = model.__batch_counter__\n  flops_sum = 0\n  #or isinstance(module, torch.nn.AvgPool2d) or isinstance(module, torch.nn.MaxPool2d) \\\n  for module in model.modules():\n    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) \\\n      or isinstance(module, torch.nn.Conv1d) \\\n      or hasattr(module, \'calculate_flop_self\'):\n      flops_sum += module.__flops__\n  return flops_sum / batches_count\n\n\n# ---- Internal functions\ndef pool_flops_counter_hook(pool_module, inputs, output):\n  batch_size = inputs[0].size(0)\n  kernel_size = pool_module.kernel_size\n  out_C, output_height, output_width = output.shape[1:]\n  assert out_C == inputs[0].size(1), \'{:} vs. {:}\'.format(out_C, inputs[0].size())\n\n  overall_flops = batch_size * out_C * output_height * output_width * kernel_size * kernel_size\n  pool_module.__flops__ += overall_flops\n\n\ndef self_calculate_flops_counter_hook(self_module, inputs, output):\n  overall_flops = self_module.calculate_flop_self(inputs[0].shape, output.shape)\n  self_module.__flops__ += overall_flops\n\n\ndef fc_flops_counter_hook(fc_module, inputs, output):\n  batch_size = inputs[0].size(0)\n  xin, xout = fc_module.in_features, fc_module.out_features\n  assert xin == inputs[0].size(1) and xout == output.size(1), \'IO=({:}, {:})\'.format(xin, xout)\n  overall_flops = batch_size * xin * xout\n  if fc_module.bias is not None:\n    overall_flops += batch_size * xout\n  fc_module.__flops__ += overall_flops\n\n\ndef conv1d_flops_counter_hook(conv_module, inputs, outputs):\n  batch_size   = inputs[0].size(0)\n  outL         = outputs.shape[-1]\n  [kernel]     = conv_module.kernel_size\n  in_channels  = conv_module.in_channels\n  out_channels = conv_module.out_channels\n  groups       = conv_module.groups\n  conv_per_position_flops = kernel * in_channels * out_channels / groups\n  \n  active_elements_count = batch_size * outL \n  overall_flops = conv_per_position_flops * active_elements_count\n\n  if conv_module.bias is not None:\n    overall_flops += out_channels * active_elements_count\n  conv_module.__flops__ += overall_flops\n\n\ndef conv2d_flops_counter_hook(conv_module, inputs, output):\n  batch_size = inputs[0].size(0)\n  output_height, output_width = output.shape[2:]\n  \n  kernel_height, kernel_width = conv_module.kernel_size\n  in_channels  = conv_module.in_channels\n  out_channels = conv_module.out_channels\n  groups       = conv_module.groups\n  conv_per_position_flops = kernel_height * kernel_width * in_channels * out_channels / groups\n  \n  active_elements_count = batch_size * output_height * output_width\n  overall_flops = conv_per_position_flops * active_elements_count\n    \n  if conv_module.bias is not None:\n    overall_flops += out_channels * active_elements_count\n  conv_module.__flops__ += overall_flops\n\n  \ndef batch_counter_hook(module, inputs, output):\n  # Can have multiple inputs, getting the first one\n  inputs = inputs[0]\n  batch_size = inputs.shape[0]\n  module.__batch_counter__ += batch_size\n\n\ndef add_batch_counter_hook_function(module):\n  if not hasattr(module, \'__batch_counter_handle__\'):\n    handle = module.register_forward_hook(batch_counter_hook)\n    module.__batch_counter_handle__ = handle\n\n  \ndef add_flops_counter_variable_or_reset(module):\n  if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) \\\n    or isinstance(module, torch.nn.Conv1d) \\\n    or isinstance(module, torch.nn.AvgPool2d) or isinstance(module, torch.nn.MaxPool2d) \\\n    or hasattr(module, \'calculate_flop_self\'):\n    module.__flops__ = 0\n\n\ndef add_flops_counter_hook_function(module):\n  if isinstance(module, torch.nn.Conv2d):\n    if not hasattr(module, \'__flops_handle__\'):\n      handle = module.register_forward_hook(conv2d_flops_counter_hook)\n      module.__flops_handle__ = handle\n  elif isinstance(module, torch.nn.Conv1d):\n    if not hasattr(module, \'__flops_handle__\'):\n      handle = module.register_forward_hook(conv1d_flops_counter_hook)\n      module.__flops_handle__ = handle\n  elif isinstance(module, torch.nn.Linear):\n    if not hasattr(module, \'__flops_handle__\'):\n      handle = module.register_forward_hook(fc_flops_counter_hook)\n      module.__flops_handle__ = handle\n  elif isinstance(module, torch.nn.AvgPool2d) or isinstance(module, torch.nn.MaxPool2d):\n    if not hasattr(module, \'__flops_handle__\'):\n      handle = module.register_forward_hook(pool_flops_counter_hook)\n      module.__flops_handle__ = handle\n  elif hasattr(module, \'calculate_flop_self\'): # self-defined module\n    if not hasattr(module, \'__flops_handle__\'):\n      handle = module.register_forward_hook(self_calculate_flops_counter_hook)\n      module.__flops_handle__ = handle\n\n\ndef remove_hook_function(module):\n  hookers = [\'__batch_counter_handle__\', \'__flops_handle__\']\n  for hooker in hookers:\n    if hasattr(module, hooker):\n      handle = getattr(module, hooker)\n      handle.remove()\n  keys = [\'__flops__\', \'__batch_counter__\', \'__flops__\'] + hookers\n  for ckey in keys:\n    if hasattr(module, ckey): delattr(module, ckey)\n'"
lib/utils/gpu_manager.py,0,"b'import os\n\nclass GPUManager():\n  queries = (\'index\', \'gpu_name\', \'memory.free\', \'memory.used\', \'memory.total\', \'power.draw\', \'power.limit\')\n\n  def __init__(self):\n    all_gpus = self.query_gpu(False)\n\n  def get_info(self, ctype):\n    cmd = \'nvidia-smi --query-gpu={} --format=csv,noheader\'.format(ctype)\n    lines = os.popen(cmd).readlines()\n    lines = [line.strip(\'\\n\') for line in lines]\n    return lines\n\n  def query_gpu(self, show=True):\n    num_gpus = len( self.get_info(\'index\') )\n    all_gpus = [ {} for i in range(num_gpus) ]\n    for query in self.queries:\n      infos = self.get_info(query)\n      for idx, info in enumerate(infos):\n        all_gpus[idx][query] = info\n\n    if \'CUDA_VISIBLE_DEVICES\' in os.environ:\n      CUDA_VISIBLE_DEVICES = os.environ[\'CUDA_VISIBLE_DEVICES\'].split(\',\')\n      selected_gpus = []\n      for idx, CUDA_VISIBLE_DEVICE in enumerate(CUDA_VISIBLE_DEVICES):\n        find = False\n        for gpu in all_gpus:\n          if gpu[\'index\'] == CUDA_VISIBLE_DEVICE:\n            assert not find, \'Duplicate cuda device index : {}\'.format(CUDA_VISIBLE_DEVICE)\n            find = True\n            selected_gpus.append( gpu.copy() )\n            selected_gpus[-1][\'index\'] = \'{}\'.format(idx)\n        assert find, \'Does not find the device : {}\'.format(CUDA_VISIBLE_DEVICE)\n      all_gpus = selected_gpus\n    \n    if show:\n      allstrings = \'\'\n      for gpu in all_gpus:\n        string = \'| \'\n        for query in self.queries:\n          if query.find(\'memory\') == 0: xinfo = \'{:>9}\'.format(gpu[query])\n          else:                         xinfo = gpu[query]\n          string = string + query + \' : \' + xinfo + \' | \'\n        allstrings = allstrings + string + \'\\n\'\n      return allstrings\n    else:\n      return all_gpus\n\n  def select_by_memory(self, numbers=1):\n    all_gpus = self.query_gpu(False)\n    assert numbers <= len(all_gpus), \'Require {} gpus more than you have\'.format(numbers)\n    alls = []\n    for idx, gpu in enumerate(all_gpus):\n      free_memory = gpu[\'memory.free\']\n      free_memory = free_memory.split(\' \')[0]\n      free_memory = int(free_memory)\n      index = gpu[\'index\']\n      alls.append((free_memory, index))\n    alls.sort(reverse = True)\n    alls = [ int(alls[i][1]) for i in range(numbers) ]\n    return sorted(alls)\n\n""""""\nif __name__ == \'__main__\':\n  manager = GPUManager()\n  manager.query_gpu(True)\n  indexes = manager.select_by_memory(3)\n  print (indexes)\n""""""\n'"
lib/utils/nas_utils.py,3,"b""# This file is for experimental usage\nimport torch, random\nimport numpy as np\nfrom copy import deepcopy\nimport torch.nn as nn\n\n# from utils  import obtain_accuracy\nfrom models import CellStructure\nfrom log_utils import time_string\n\ndef evaluate_one_shot(model, xloader, api, cal_mode, seed=111):\n  weights = deepcopy(model.state_dict())\n  model.train(cal_mode)\n  with torch.no_grad():\n    logits = nn.functional.log_softmax(model.arch_parameters, dim=-1)\n    archs = CellStructure.gen_all(model.op_names, model.max_nodes, False)\n    probs, accuracies, gt_accs_10_valid, gt_accs_10_test = [], [], [], []\n    loader_iter = iter(xloader)\n    random.seed(seed)\n    random.shuffle(archs)\n    for idx, arch in enumerate(archs):\n      arch_index = api.query_index_by_arch( arch )\n      metrics = api.get_more_info(arch_index, 'cifar10-valid', None, False, False)\n      gt_accs_10_valid.append( metrics['valid-accuracy'] )\n      metrics = api.get_more_info(arch_index, 'cifar10', None, False, False)\n      gt_accs_10_test.append( metrics['test-accuracy'] )\n      select_logits = []\n      for i, node_info in enumerate(arch.nodes):\n        for op, xin in node_info:\n          node_str = '{:}<-{:}'.format(i+1, xin)\n          op_index = model.op_names.index(op)\n          select_logits.append( logits[model.edge2index[node_str], op_index] )\n      cur_prob = sum(select_logits).item()\n      probs.append( cur_prob )\n    cor_prob_valid = np.corrcoef(probs, gt_accs_10_valid)[0,1]\n    cor_prob_test  = np.corrcoef(probs, gt_accs_10_test )[0,1]\n    print ('{:} correlation for probabilities : {:.6f} on CIFAR-10 validation and {:.6f} on CIFAR-10 test'.format(time_string(), cor_prob_valid, cor_prob_test))\n      \n    for idx, arch in enumerate(archs):\n      model.set_cal_mode('dynamic', arch)\n      try:\n        inputs, targets = next(loader_iter)\n      except:\n        loader_iter = iter(xloader)\n        inputs, targets = next(loader_iter)\n      _, logits = model(inputs.cuda())\n      _, preds  = torch.max(logits, dim=-1)\n      correct = (preds == targets.cuda() ).float()\n      accuracies.append( correct.mean().item() )\n      if idx != 0 and (idx % 500 == 0 or idx + 1 == len(archs)):\n        cor_accs_valid = np.corrcoef(accuracies, gt_accs_10_valid[:idx+1])[0,1]\n        cor_accs_test  = np.corrcoef(accuracies, gt_accs_10_test [:idx+1])[0,1]\n        print ('{:} {:05d}/{:05d} mode={:5s}, correlation : accs={:.5f} for CIFAR-10 valid, {:.5f} for CIFAR-10 test.'.format(time_string(), idx, len(archs), 'Train' if cal_mode else 'Eval', cor_accs_valid, cor_accs_test))\n  model.load_state_dict(weights)\n  return archs, probs, accuracies\n"""
lib/utils/weight_watcher.py,1,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2020.03 #\n#####################################################\n# Reformulate the codes in https://github.com/CalculatedContent/WeightWatcher\n#####################################################\nimport numpy as np\nfrom typing import List\nimport torch.nn as nn\nfrom collections import OrderedDict\nfrom sklearn.decomposition import TruncatedSVD\n\n\ndef available_module_types():\n  return (nn.Conv2d, nn.Linear)\n\n\ndef get_conv2D_Wmats(tensor: np.ndarray) -> List[np.ndarray]:\n  """"""\n  Extract W slices from a 4 index conv2D tensor of shape: (N,M,i,j) or (M,N,i,j).\n  Return ij (N x M) matrices\n  """"""\n  mats = []\n  N, M, imax, jmax = tensor.shape\n  assert N + M >= imax + jmax, \'invalid tensor shape detected: {}x{} (NxM), {}x{} (i,j)\'.format(N, M, imax, jmax)\n  for i in range(imax):\n    for j in range(jmax):\n      w = tensor[:, :, i, j]\n      if N < M: w = w.T\n      mats.append(w)\n  return mats\n\n\ndef glorot_norm_check(W, N, M, rf_size, lower=0.5, upper=1.5):\n  """"""Check if this layer needs Glorot Normalization Fix""""""\n\n  kappa = np.sqrt(2 / ((N + M) * rf_size))\n  norm = np.linalg.norm(W)\n\n  check1 = norm / np.sqrt(N * M)\n  check2 = norm / (kappa * np.sqrt(N * M))\n\n  if (rf_size > 1) and (check2 > lower) and (check2 < upper):\n    return check2, True\n  elif (check1 > lower) & (check1 < upper):\n    return check1, True\n  else:\n    if rf_size > 1: return check2, False\n    else: return check1, False\n\ndef glorot_norm_fix(w, n, m, rf_size):\n  """"""Apply Glorot Normalization Fix.""""""\n  kappa = np.sqrt(2 / ((n + m) * rf_size))\n  w = w / kappa\n  return w\n\n\ndef analyze_weights(weights, min_size, max_size, alphas, lognorms, spectralnorms, softranks, normalize, glorot_fix):\n  results = OrderedDict()\n  count = len(weights)\n  if count == 0: return results\n\n  for i, weight in enumerate(weights):\n    M, N = np.min(weight.shape), np.max(weight.shape)\n    Q = N / M\n    results[i] = cur_res = OrderedDict(N=N, M=M, Q=Q)\n    check, checkTF = glorot_norm_check(weight, N, M, count)\n    cur_res[\'check\'] = check\n    cur_res[\'checkTF\'] = checkTF\n    # assume receptive field size is count\n    if glorot_fix:\n      weight = glorot_norm_fix(weight, N, M, count)\n    else:\n      # probably never needed since we always fix for glorot\n      weight = weight * np.sqrt(count / 2.0)\n\n    if spectralnorms:  # spectralnorm is the max eigenvalues\n      svd = TruncatedSVD(n_components=1, n_iter=7, random_state=10)\n      svd.fit(weight)\n      sv = svd.singular_values_\n      sv_max = np.max(sv)\n      if normalize:\n        evals = sv * sv / N\n      else:\n        evals = sv * sv\n      lambda0 = evals[0]\n      cur_res[""spectralnorm""] = lambda0\n      cur_res[""logspectralnorm""] = np.log10(lambda0)\n    else:\n      lambda0 = None\n\n    if M < min_size:\n      summary = ""Weight matrix {}/{} ({},{}): Skipping: too small (<{})"".format(i + 1, count, M, N, min_size)\n      cur_res[""summary""] = summary\n      continue\n    elif max_size > 0 and M > max_size:\n      summary = ""Weight matrix {}/{} ({},{}): Skipping: too big (testing) (>{})"".format(i + 1, count, M, N, max_size)\n      cur_res[""summary""] = summary\n      continue\n    else:\n      summary = []\n    if alphas:\n      import powerlaw\n      svd = TruncatedSVD(n_components=M - 1, n_iter=7, random_state=10)\n      svd.fit(weight.astype(float))\n      sv = svd.singular_values_\n      if normalize: evals = sv * sv / N\n      else: evals = sv * sv\n\n      lambda_max = np.max(evals)\n      fit = powerlaw.Fit(evals, xmax=lambda_max, verbose=False)\n      alpha = fit.alpha\n      cur_res[""alpha""] = alpha\n      D = fit.D\n      cur_res[""D""] = D\n      cur_res[""lambda_min""] = np.min(evals)\n      cur_res[""lambda_max""] = lambda_max\n      alpha_weighted = alpha * np.log10(lambda_max)\n      cur_res[""alpha_weighted""] = alpha_weighted\n      tolerance = lambda_max * M * np.finfo(np.max(sv)).eps\n      cur_res[""rank_loss""] = np.count_nonzero(sv > tolerance, axis=-1)\n\n      logpnorm = np.log10(np.sum([ev ** alpha for ev in evals]))\n      cur_res[""logpnorm""] = logpnorm\n\n      summary.append(\n        ""Weight matrix {}/{} ({},{}): Alpha: {}, Alpha Weighted: {}, D: {}, pNorm {}"".format(i + 1, count, M, N, alpha,\n                                                                                             alpha_weighted, D,\n                                                                                             logpnorm))\n\n    if lognorms:\n      norm = np.linalg.norm(weight)  # Frobenius Norm\n      cur_res[""norm""] = norm\n      lognorm = np.log10(norm)\n      cur_res[""lognorm""] = lognorm\n\n      X = np.dot(weight.T, weight)\n      if normalize: X = X / N\n      normX = np.linalg.norm(X)  # Frobenius Norm\n      cur_res[""normX""] = normX\n      lognormX = np.log10(normX)\n      cur_res[""lognormX""] = lognormX\n\n      summary.append(\n        ""Weight matrix {}/{} ({},{}): LogNorm: {} ; LogNormX: {}"".format(i + 1, count, M, N, lognorm, lognormX))\n\n      if softranks:\n        softrank = norm ** 2 / sv_max ** 2\n        softranklog = np.log10(softrank)\n        softranklogratio = lognorm / np.log10(sv_max)\n        cur_res[""softrank""] = softrank\n        cur_res[""softranklog""] = softranklog\n        cur_res[""softranklogratio""] = softranklogratio\n        summary += ""{}. Softrank: {}. Softrank log: {}. Softrank log ratio: {}"".format(summary, softrank, softranklog,\n                                                                                       softranklogratio)\n    cur_res[""summary""] = ""\\n"".join(summary)\n  return results\n\n\ndef compute_details(results):\n  """"""\n  Return a pandas data frame.\n  """"""\n  final_summary = OrderedDict()\n\n  metrics = {\n    # key in ""results"" : pretty print name\n    ""check"": ""Check"",\n    ""checkTF"": ""CheckTF"",\n    ""norm"": ""Norm"",\n    ""lognorm"": ""LogNorm"",\n    ""normX"": ""Norm X"",\n    ""lognormX"": ""LogNorm X"",\n    ""alpha"": ""Alpha"",\n    ""alpha_weighted"": ""Alpha Weighted"",\n    ""spectralnorm"": ""Spectral Norm"",\n    ""logspectralnorm"": ""Log Spectral Norm"",\n    ""softrank"": ""Softrank"",\n    ""softranklog"": ""Softrank Log"",\n    ""softranklogratio"": ""Softrank Log Ratio"",\n    ""sigma_mp"": ""Marchenko-Pastur (MP) fit sigma"",\n    ""numofSpikes"": ""Number of spikes per MP fit"",\n    ""ratio_numofSpikes"": ""aka, percent_mass, Number of spikes / total number of evals"",\n    ""softrank_mp"": ""Softrank for MP fit"",\n    ""logpnorm"": ""alpha pNorm""\n  }\n\n  metrics_stats = []\n  for metric in metrics:\n    metrics_stats.append(""{}_min"".format(metric))\n    metrics_stats.append(""{}_max"".format(metric))\n    metrics_stats.append(""{}_avg"".format(metric))\n\n    metrics_stats.append(""{}_compound_min"".format(metric))\n    metrics_stats.append(""{}_compound_max"".format(metric))\n    metrics_stats.append(""{}_compound_avg"".format(metric))\n\n  columns = [""layer_id"", ""layer_type"", ""N"", ""M"", ""layer_count"", ""slice"",\n             ""slice_count"", ""level"", ""comment""] + [*metrics] + metrics_stats\n\n  metrics_values = {}\n  metrics_values_compound = {}\n\n  for metric in metrics:\n    metrics_values[metric] = []\n    metrics_values_compound[metric] = []\n\n  layer_count = 0\n  for layer_id, result in results.items():\n    layer_count += 1\n\n    layer_type = np.NAN\n    if ""layer_type"" in result:\n      layer_type = str(result[""layer_type""]).replace(""LAYER_TYPE."", """")\n\n    compounds = {}  # temp var\n    for metric in metrics:\n      compounds[metric] = []\n\n    slice_count, Ntotal, Mtotal = 0, 0, 0\n    for slice_id, summary in result.items():\n      if not str(slice_id).isdigit():\n        continue\n      slice_count += 1\n\n      N = np.NAN\n      if ""N"" in summary:\n        N = summary[""N""]\n        Ntotal += N\n\n      M = np.NAN\n      if ""M"" in summary:\n        M = summary[""M""]\n        Mtotal += M\n\n      data = {""layer_id"": layer_id, ""layer_type"": layer_type, ""N"": N, ""M"": M, ""slice"": slice_id, ""level"": ""SLICE"",\n              ""comment"": ""Slice level""}\n      for metric in metrics:\n        if metric in summary:\n          value = summary[metric]\n          if value is not None:\n            metrics_values[metric].append(value)\n            compounds[metric].append(value)\n            data[metric] = value\n\n    data = {""layer_id"": layer_id, ""layer_type"": layer_type, ""N"": Ntotal, ""M"": Mtotal, ""slice_count"": slice_count,\n            ""level"": ""LAYER"", ""comment"": ""Layer level""}\n    # Compute the compound value over the slices\n    for metric, value in compounds.items():\n      count = len(value)\n      if count == 0:\n        continue\n\n      compound = np.mean(value)\n      metrics_values_compound[metric].append(compound)\n      data[metric] = compound\n\n  data = {""layer_count"": layer_count, ""level"": ""NETWORK"", ""comment"": ""Network Level""}\n  for metric, metric_name in metrics.items():\n    if metric not in metrics_values or len(metrics_values[metric]) == 0:\n      continue\n\n    values = metrics_values[metric]\n    minimum = min(values)\n    maximum = max(values)\n    avg = np.mean(values)\n    final_summary[metric] = avg\n    # print(""{}: min: {}, max: {}, avg: {}"".format(metric_name, minimum, maximum, avg))\n    data[""{}_min"".format(metric)] = minimum\n    data[""{}_max"".format(metric)] = maximum\n    data[""{}_avg"".format(metric)] = avg\n\n    values = metrics_values_compound[metric]\n    minimum = min(values)\n    maximum = max(values)\n    avg = np.mean(values)\n    final_summary[""{}_compound"".format(metric)] = avg\n    # print(""{} compound: min: {}, max: {}, avg: {}"".format(metric_name, minimum, maximum, avg))\n    data[""{}_compound_min"".format(metric)] = minimum\n    data[""{}_compound_max"".format(metric)] = maximum\n    data[""{}_compound_avg"".format(metric)] = avg\n\n  return final_summary\n\n\ndef analyze(model: nn.Module, min_size=50, max_size=0,\n            alphas: bool = False, lognorms: bool = True, spectralnorms: bool = False,\n            softranks: bool = False, normalize: bool = False, glorot_fix: bool = False):\n  """"""\n  Analyze the weight matrices of a model.\n  :param model: A PyTorch model\n  :param min_size: The minimum weight matrix size to analyze.\n  :param max_size: The maximum weight matrix size to analyze (0 = no limit).\n  :param alphas: Compute the power laws (alpha) of the weight matrices.\n    Time consuming so disabled by default (use lognorm if you want speed)\n  :param lognorms: Compute the log norms of the weight matrices.\n  :param spectralnorms: Compute the spectral norm (max eigenvalue) of the weight matrices.\n  :param softranks: Compute the soft norm (i.e. StableRank) of the weight matrices.\n  :param normalize: Normalize or not.\n  :param glorot_fix:\n  :return: (a dict of all layers\' results, a dict of the summarized info)\n  """"""\n  names, modules = [], []\n  for name, module in model.named_modules():\n    if isinstance(module, available_module_types()):\n      names.append(name)\n      modules.append(module)\n  # print(\'There are {:} layers to be analyzed in this model.\'.format(len(modules)))\n  all_results = OrderedDict()\n  for index, module in enumerate(modules):\n    if isinstance(module, nn.Linear):\n      weights = [module.weight.cpu().detach().numpy()]\n    else:\n      weights = get_conv2D_Wmats(module.weight.cpu().detach().numpy())\n    results = analyze_weights(weights, min_size, max_size, alphas, lognorms, spectralnorms, softranks, normalize, glorot_fix)\n    results[\'id\'] = index\n    results[\'type\'] = type(module)\n    all_results[index] = results\n  summary = compute_details(all_results)\n  return all_results, summary'"
lib/datasets/landmark_utils/__init__.py,0,"b'from .point_meta import PointMeta2V, apply_affine2point, apply_boundary\n'"
lib/datasets/landmark_utils/point_meta.py,12,"b""# Copyright (c) Facebook, Inc. and its affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n#\nimport copy, math, torch, numpy as np\nfrom xvision import normalize_points\nfrom xvision import denormalize_points\n\n\nclass PointMeta():\n  # points    : 3 x num_pts (x, y, oculusion)\n  # image_size: original [width, height]\n  def __init__(self, num_point, points, box, image_path, dataset_name):\n\n    self.num_point = num_point\n    if box is not None:\n      assert (isinstance(box, tuple) or isinstance(box, list)) and len(box) == 4\n      self.box = torch.Tensor(box)\n    else: self.box = None\n    if points is None:\n      self.points = points\n    else:\n      assert len(points.shape) == 2 and points.shape[0] == 3 and points.shape[1] == self.num_point, 'The shape of point is not right : {}'.format( points )\n      self.points = torch.Tensor(points.copy())\n    self.image_path = image_path\n    self.datasets = dataset_name\n\n  def __repr__(self):\n    if self.box is None: boxstr = 'None'\n    else               : boxstr = 'box=[{:.1f}, {:.1f}, {:.1f}, {:.1f}]'.format(*self.box.tolist())\n    return ('{name}(points={num_point}, '.format(name=self.__class__.__name__, **self.__dict__) + boxstr + ')')\n\n  def get_box(self, return_diagonal=False):\n    if self.box is None: return None\n    if not return_diagonal:\n      return self.box.clone()\n    else:\n      W = (self.box[2]-self.box[0]).item()\n      H = (self.box[3]-self.box[1]).item()\n      return math.sqrt(H*H+W*W)\n\n  def get_points(self, ignore_indicator=False):\n    if ignore_indicator: last = 2\n    else               : last = 3\n    if self.points is not None: return self.points.clone()[:last, :]\n    else                      : return torch.zeros((last, self.num_point))\n\n  def is_none(self):\n    #assert self.box is not None, 'The box should not be None'\n    return self.points is None\n    #if self.box is None: return True\n    #else               : return self.points is None\n\n  def copy(self):\n    return copy.deepcopy(self)\n\n  def visiable_pts_num(self):\n    with torch.no_grad():\n      ans = self.points[2,:] > 0\n      ans = torch.sum(ans)\n      ans = ans.item()\n    return ans\n  \n  def special_fun(self, indicator):\n    if indicator == '68to49': # For 300W or 300VW, convert the default 68 points to 49 points.\n      assert self.num_point == 68, 'num-point must be 68 vs. {:}'.format(self.num_point)\n      self.num_point = 49\n      out = torch.ones((68), dtype=torch.uint8)\n      out[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,60,64]] = 0\n      if self.points is not None: self.points = self.points.clone()[:, out]\n    else:\n      raise ValueError('Invalid indicator : {:}'.format( indicator ))\n\n  def apply_horizontal_flip(self):\n    #self.points[0, :] = width - self.points[0, :] - 1\n    # Mugsy spefic or Synthetic\n    if self.datasets.startswith('HandsyROT'):\n      ori = np.array(list(range(0, 42)))\n      pos = np.array(list(range(21,42)) + list(range(0,21)))\n      self.points[:, pos] = self.points[:, ori]\n    elif self.datasets.startswith('face68'):\n      ori = np.array(list(range(0, 68)))\n      pos = np.array([17,16,15,14,13,12,11,10, 9, 8,7,6,5,4,3,2,1, 27,26,25,24,23,22,21,20,19,18, 28,29,30,31, 36,35,34,33,32, 46,45,44,43,48,47, 40,39,38,37,42,41, 55,54,53,52,51,50,49,60,59,58,57,56,65,64,63,62,61,68,67,66])-1\n      self.points[:, ori] = self.points[:, pos]\n    else:\n      raise ValueError('Does not support {:}'.format(self.datasets))\n\n\n\n# shape = (H,W)\ndef apply_affine2point(points, theta, shape):\n  assert points.size(0) == 3, 'invalid points shape : {:}'.format(points.size())\n  with torch.no_grad():\n    ok_points = points[2,:] == 1\n    assert torch.sum(ok_points).item() > 0, 'there is no visiable point'\n    points[:2,:] = normalize_points(shape, points[:2,:])\n\n    norm_trans_points = ok_points.unsqueeze(0).repeat(3, 1).float()\n\n    trans_points, ___ = torch.gesv(points[:, ok_points], theta)\n\n    norm_trans_points[:, ok_points] = trans_points\n    \n  return norm_trans_points\n\n\n\ndef apply_boundary(norm_trans_points):\n  with torch.no_grad():\n    norm_trans_points = norm_trans_points.clone()\n    oks = torch.stack((norm_trans_points[0]>-1, norm_trans_points[0]<1, norm_trans_points[1]>-1, norm_trans_points[1]<1, norm_trans_points[2]>0))\n    oks = torch.sum(oks, dim=0) == 5\n    norm_trans_points[2, :] = oks\n  return norm_trans_points\n"""
lib/models/cell_infers/__init__.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nfrom .tiny_network import TinyNetwork\nfrom .nasnet_cifar import NASNetonCIFAR\n'"
lib/models/cell_infers/cells.py,2,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\n\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import OPS\n\n\n# Cell for NAS-Bench-201\nclass InferCell(nn.Module):\n\n  def __init__(self, genotype, C_in, C_out, stride):\n    super(InferCell, self).__init__()\n\n    self.layers  = nn.ModuleList()\n    self.node_IN = []\n    self.node_IX = []\n    self.genotype = deepcopy(genotype)\n    for i in range(1, len(genotype)):\n      node_info = genotype[i-1]\n      cur_index = []\n      cur_innod = []\n      for (op_name, op_in) in node_info:\n        if op_in == 0:\n          layer = OPS[op_name](C_in , C_out, stride, True, True)\n        else:\n          layer = OPS[op_name](C_out, C_out,      1, True, True)\n        cur_index.append( len(self.layers) )\n        cur_innod.append( op_in )\n        self.layers.append( layer )\n      self.node_IX.append( cur_index )\n      self.node_IN.append( cur_innod )\n    self.nodes   = len(genotype)\n    self.in_dim  = C_in\n    self.out_dim = C_out\n\n  def extra_repr(self):\n    string = \'info :: nodes={nodes}, inC={in_dim}, outC={out_dim}\'.format(**self.__dict__)\n    laystr = []\n    for i, (node_layers, node_innods) in enumerate(zip(self.node_IX,self.node_IN)):\n      y = [\'I{:}-L{:}\'.format(_ii, _il) for _il, _ii in zip(node_layers, node_innods)]\n      x = \'{:}<-({:})\'.format(i+1, \',\'.join(y))\n      laystr.append( x )\n    return string + \', [{:}]\'.format( \' | \'.join(laystr) ) + \', {:}\'.format(self.genotype.tostr())\n\n  def forward(self, inputs):\n    nodes = [inputs]\n    for i, (node_layers, node_innods) in enumerate(zip(self.node_IX,self.node_IN)):\n      node_feature = sum( self.layers[_il](nodes[_ii]) for _il, _ii in zip(node_layers, node_innods) )\n      nodes.append( node_feature )\n    return nodes[-1]\n\n\n\n# Learning Transferable Architectures for Scalable Image Recognition, CVPR 2018\nclass NASNetInferCell(nn.Module):\n\n  def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev, affine, track_running_stats):\n    super(NASNetInferCell, self).__init__()\n    self.reduction = reduction\n    if reduction_prev: self.preprocess0 = OPS[\'skip_connect\'](C_prev_prev, C, 2, affine, track_running_stats)\n    else             : self.preprocess0 = OPS[\'nor_conv_1x1\'](C_prev_prev, C, 1, affine, track_running_stats)\n    self.preprocess1 = OPS[\'nor_conv_1x1\'](C_prev, C, 1, affine, track_running_stats)\n\n    if not reduction:\n      nodes, concats = genotype[\'normal\'], genotype[\'normal_concat\']\n    else:\n      nodes, concats = genotype[\'reduce\'], genotype[\'reduce_concat\']\n    self._multiplier = len(concats)\n    self._concats = concats\n    self._steps = len(nodes)\n    self._nodes = nodes\n    self.edges = nn.ModuleDict()\n    for i, node in enumerate(nodes):\n      for in_node in node:\n        name, j = in_node[0], in_node[1]\n        stride = 2 if reduction and j < 2 else 1\n        node_str = \'{:}<-{:}\'.format(i+2, j)\n        self.edges[node_str] = OPS[name](C, C, stride, affine, track_running_stats)\n\n  # [TODO] to support drop_prob in this function..\n  def forward(self, s0, s1, unused_drop_prob):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    states = [s0, s1]\n    for i, node in enumerate(self._nodes):\n      clist = []\n      for in_node in node:\n        name, j = in_node[0], in_node[1]\n        node_str = \'{:}<-{:}\'.format(i+2, j)\n        op = self.edges[ node_str ]\n        clist.append( op(states[j]) )\n      states.append( sum(clist) )\n    return torch.cat([states[x] for x in self._concats], dim=1)\n\n\nclass AuxiliaryHeadCIFAR(nn.Module):\n\n  def __init__(self, C, num_classes):\n    """"""assuming input size 8x8""""""\n    super(AuxiliaryHeadCIFAR, self).__init__()\n    self.features = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.AvgPool2d(5, stride=3, padding=0, count_include_pad=False), # image size = 2 x 2\n      nn.Conv2d(C, 128, 1, bias=False),\n      nn.BatchNorm2d(128),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(128, 768, 2, bias=False),\n      nn.BatchNorm2d(768),\n      nn.ReLU(inplace=True)\n    )\n    self.classifier = nn.Linear(768, num_classes)\n\n  def forward(self, x):\n    x = self.features(x)\n    x = self.classifier(x.view(x.size(0),-1))\n    return x\n'"
lib/models/cell_infers/nasnet_cifar.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom .cells import NASNetInferCell as InferCell, AuxiliaryHeadCIFAR\n\n\n# The macro structure is based on NASNet\nclass NASNetonCIFAR(nn.Module):\n\n  def __init__(self, C, N, stem_multiplier, num_classes, genotype, auxiliary, affine=True, track_running_stats=True):\n    super(NASNetonCIFAR, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C*stem_multiplier, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C*stem_multiplier))\n  \n    # config for each layer\n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * (N-1) + [C*4 ] + [C*4  ] * (N-1)\n    layer_reductions = [False] * N + [True] + [False] * (N-1) + [True] + [False] * (N-1)\n\n    C_prev_prev, C_prev, C_curr, reduction_prev = C*stem_multiplier, C*stem_multiplier, C, False\n    self.auxiliary_index = None\n    self.auxiliary_head  = None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = InferCell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev, affine, track_running_stats)\n      self.cells.append( cell )\n      C_prev_prev, C_prev, reduction_prev = C_prev, cell._multiplier*C_curr, reduction\n      if reduction and C_curr == C*4 and auxiliary:\n        self.auxiliary_head = AuxiliaryHeadCIFAR(C_prev, num_classes)\n        self.auxiliary_index = index\n    self._Layer     = len(self.cells)\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.drop_path_prob = -1\n\n  def update_drop_path(self, drop_path_prob):\n    self.drop_path_prob = drop_path_prob\n\n  def auxiliary_param(self):\n    if self.auxiliary_head is None: return []\n    else: return list( self.auxiliary_head.parameters() )\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, inputs):\n    stem_feature, logits_aux = self.stem(inputs), None\n    cell_results = [stem_feature, stem_feature]\n    for i, cell in enumerate(self.cells):\n      cell_feature = cell(cell_results[-2], cell_results[-1], self.drop_path_prob)\n      cell_results.append( cell_feature )\n      if self.auxiliary_index is not None and i == self.auxiliary_index and self.training:\n        logits_aux = self.auxiliary_head( cell_results[-1] )\n    out = self.lastact(cell_results[-1])\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n    if logits_aux is None: return out, logits\n    else: return out, [logits, logits_aux]\n"""
lib/models/cell_infers/tiny_network.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch.nn as nn\nfrom ..cell_operations import ResNetBasicblock\nfrom .cells import InferCell\n\n\n# The macro structure for architectures in NAS-Bench-201\nclass TinyNetwork(nn.Module):\n\n  def __init__(self, C, N, genotype, num_classes):\n    super(TinyNetwork, self).__init__()\n    self._C               = C\n    self._layerN          = N\n\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev = C\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2, True)\n      else:\n        cell = InferCell(genotype, C_prev, C_curr, 1)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self._Layer= len(self.cells)\n\n    self.lastact = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, inputs):\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/__init__.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\n# The macro structure is defined in NAS-Bench-201\nfrom .search_model_darts    import TinyNetworkDarts\nfrom .search_model_gdas     import TinyNetworkGDAS\nfrom .search_model_setn     import TinyNetworkSETN\nfrom .search_model_enas     import TinyNetworkENAS\nfrom .search_model_random   import TinyNetworkRANDOM\nfrom .genotypes             import Structure as CellStructure, architectures as CellArchitectures\n# NASNet-based macro structure\nfrom .search_model_gdas_nasnet import NASNetworkGDAS\nfrom .search_model_darts_nasnet import NASNetworkDARTS\n\n\nnas201_super_nets = {\'DARTS-V1\': TinyNetworkDarts,\n                     ""DARTS-V2"": TinyNetworkDarts,\n                     ""GDAS"": TinyNetworkGDAS,\n                     ""SETN"": TinyNetworkSETN,\n                     ""ENAS"": TinyNetworkENAS,\n                     ""RANDOM"": TinyNetworkRANDOM}\n\nnasnet_super_nets = {""GDAS"": NASNetworkGDAS,\n                     ""DARTS"": NASNetworkDARTS}\n'"
lib/models/cell_searchs/_test_module.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport torch\nfrom search_model_enas_utils import Controller\n\ndef main():\n  controller = Controller(6, 4)\n  predictions = controller()\n\nif __name__ == '__main__':\n  main()\n"""
lib/models/cell_searchs/genotypes.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom copy import deepcopy\n\n\n\ndef get_combination(space, num):\n  combs = []\n  for i in range(num):\n    if i == 0:\n      for func in space:\n        combs.append( [(func, i)] )\n    else:\n      new_combs = []\n      for string in combs:\n        for func in space:\n          xstring = string + [(func, i)]\n          new_combs.append( xstring )\n      combs = new_combs\n  return combs\n  \n\n\nclass Structure:\n\n  def __init__(self, genotype):\n    assert isinstance(genotype, list) or isinstance(genotype, tuple), 'invalid class of genotype : {:}'.format(type(genotype))\n    self.node_num = len(genotype) + 1\n    self.nodes    = []\n    self.node_N   = []\n    for idx, node_info in enumerate(genotype):\n      assert isinstance(node_info, list) or isinstance(node_info, tuple), 'invalid class of node_info : {:}'.format(type(node_info))\n      assert len(node_info) >= 1, 'invalid length : {:}'.format(len(node_info))\n      for node_in in node_info:\n        assert isinstance(node_in, list) or isinstance(node_in, tuple), 'invalid class of in-node : {:}'.format(type(node_in))\n        assert len(node_in) == 2 and node_in[1] <= idx, 'invalid in-node : {:}'.format(node_in)\n      self.node_N.append( len(node_info) )\n      self.nodes.append( tuple(deepcopy(node_info)) )\n\n  def tolist(self, remove_str):\n    # convert this class to the list, if remove_str is 'none', then remove the 'none' operation.\n    # note that we re-order the input node in this function\n    # return the-genotype-list and success [if unsuccess, it is not a connectivity]\n    genotypes = []\n    for node_info in self.nodes:\n      node_info = list( node_info )\n      node_info = sorted(node_info, key=lambda x: (x[1], x[0]))\n      node_info = tuple(filter(lambda x: x[0] != remove_str, node_info))\n      if len(node_info) == 0: return None, False\n      genotypes.append( node_info )\n    return genotypes, True\n\n  def node(self, index):\n    assert index > 0 and index <= len(self), 'invalid index={:} < {:}'.format(index, len(self))\n    return self.nodes[index]\n\n  def tostr(self):\n    strings = []\n    for node_info in self.nodes:\n      string = '|'.join([x[0]+'~{:}'.format(x[1]) for x in node_info])\n      string = '|{:}|'.format(string)\n      strings.append( string )\n    return '+'.join(strings)\n\n  def check_valid(self):\n    nodes = {0: True}\n    for i, node_info in enumerate(self.nodes):\n      sums = []\n      for op, xin in node_info:\n        if op == 'none' or nodes[xin] is False: x = False\n        else: x = True\n        sums.append( x )\n      nodes[i+1] = sum(sums) > 0\n    return nodes[len(self.nodes)]\n\n  def to_unique_str(self, consider_zero=False):\n    # this is used to identify the isomorphic cell, which rerquires the prior knowledge of operation\n    # two operations are special, i.e., none and skip_connect\n    nodes = {0: '0'}\n    for i_node, node_info in enumerate(self.nodes):\n      cur_node = []\n      for op, xin in node_info:\n        if consider_zero is None:\n          x = '('+nodes[xin]+')' + '@{:}'.format(op)\n        elif consider_zero:\n          if op == 'none' or nodes[xin] == '#': x = '#' # zero\n          elif op == 'skip_connect': x = nodes[xin]\n          else: x = '('+nodes[xin]+')' + '@{:}'.format(op)\n        else:\n          if op == 'skip_connect': x = nodes[xin]\n          else: x = '('+nodes[xin]+')' + '@{:}'.format(op)\n        cur_node.append(x)\n      nodes[i_node+1] = '+'.join( sorted(cur_node) )\n    return nodes[ len(self.nodes) ]\n\n  def check_valid_op(self, op_names):\n    for node_info in self.nodes:\n      for inode_edge in node_info:\n        #assert inode_edge[0] in op_names, 'invalid op-name : {:}'.format(inode_edge[0])\n        if inode_edge[0] not in op_names: return False\n    return True\n\n  def __repr__(self):\n    return ('{name}({node_num} nodes with {node_info})'.format(name=self.__class__.__name__, node_info=self.tostr(), **self.__dict__))\n\n  def __len__(self):\n    return len(self.nodes) + 1\n\n  def __getitem__(self, index):\n    return self.nodes[index]\n\n  @staticmethod\n  def str2structure(xstr):\n    assert isinstance(xstr, str), 'must take string (not {:}) as input'.format(type(xstr))\n    nodestrs = xstr.split('+')\n    genotypes = []\n    for i, node_str in enumerate(nodestrs):\n      inputs = list(filter(lambda x: x != '', node_str.split('|')))\n      for xinput in inputs: assert len(xinput.split('~')) == 2, 'invalid input length : {:}'.format(xinput)\n      inputs = ( xi.split('~') for xi in inputs )\n      input_infos = tuple( (op, int(IDX)) for (op, IDX) in inputs)\n      genotypes.append( input_infos )\n    return Structure( genotypes )\n\n  @staticmethod\n  def str2fullstructure(xstr, default_name='none'):\n    assert isinstance(xstr, str), 'must take string (not {:}) as input'.format(type(xstr))\n    nodestrs = xstr.split('+')\n    genotypes = []\n    for i, node_str in enumerate(nodestrs):\n      inputs = list(filter(lambda x: x != '', node_str.split('|')))\n      for xinput in inputs: assert len(xinput.split('~')) == 2, 'invalid input length : {:}'.format(xinput)\n      inputs = ( xi.split('~') for xi in inputs )\n      input_infos = list( (op, int(IDX)) for (op, IDX) in inputs)\n      all_in_nodes= list(x[1] for x in input_infos)\n      for j in range(i):\n        if j not in all_in_nodes: input_infos.append((default_name, j))\n      node_info = sorted(input_infos, key=lambda x: (x[1], x[0]))\n      genotypes.append( tuple(node_info) )\n    return Structure( genotypes )\n\n  @staticmethod\n  def gen_all(search_space, num, return_ori):\n    assert isinstance(search_space, list) or isinstance(search_space, tuple), 'invalid class of search-space : {:}'.format(type(search_space))\n    assert num >= 2, 'There should be at least two nodes in a neural cell instead of {:}'.format(num)\n    all_archs = get_combination(search_space, 1)\n    for i, arch in enumerate(all_archs):\n      all_archs[i] = [ tuple(arch) ]\n  \n    for inode in range(2, num):\n      cur_nodes = get_combination(search_space, inode)\n      new_all_archs = []\n      for previous_arch in all_archs:\n        for cur_node in cur_nodes:\n          new_all_archs.append( previous_arch + [tuple(cur_node)] )\n      all_archs = new_all_archs\n    if return_ori:\n      return all_archs\n    else:\n      return [Structure(x) for x in all_archs]\n\n\n\nResNet_CODE = Structure(\n  [(('nor_conv_3x3', 0), ), # node-1 \n   (('nor_conv_3x3', 1), ), # node-2\n   (('skip_connect', 0), ('skip_connect', 2))] # node-3\n  )\n\nAllConv3x3_CODE = Structure(\n  [(('nor_conv_3x3', 0), ), # node-1 \n   (('nor_conv_3x3', 0), ('nor_conv_3x3', 1)), # node-2\n   (('nor_conv_3x3', 0), ('nor_conv_3x3', 1), ('nor_conv_3x3', 2))] # node-3\n  )\n\nAllFull_CODE = Structure(\n  [(('skip_connect', 0), ('nor_conv_1x1', 0), ('nor_conv_3x3', 0), ('avg_pool_3x3', 0)), # node-1 \n   (('skip_connect', 0), ('nor_conv_1x1', 0), ('nor_conv_3x3', 0), ('avg_pool_3x3', 0), ('skip_connect', 1), ('nor_conv_1x1', 1), ('nor_conv_3x3', 1), ('avg_pool_3x3', 1)), # node-2\n   (('skip_connect', 0), ('nor_conv_1x1', 0), ('nor_conv_3x3', 0), ('avg_pool_3x3', 0), ('skip_connect', 1), ('nor_conv_1x1', 1), ('nor_conv_3x3', 1), ('avg_pool_3x3', 1), ('skip_connect', 2), ('nor_conv_1x1', 2), ('nor_conv_3x3', 2), ('avg_pool_3x3', 2))] # node-3\n  )\n\nAllConv1x1_CODE = Structure(\n  [(('nor_conv_1x1', 0), ), # node-1 \n   (('nor_conv_1x1', 0), ('nor_conv_1x1', 1)), # node-2\n   (('nor_conv_1x1', 0), ('nor_conv_1x1', 1), ('nor_conv_1x1', 2))] # node-3\n  )\n\nAllIdentity_CODE = Structure(\n  [(('skip_connect', 0), ), # node-1 \n   (('skip_connect', 0), ('skip_connect', 1)), # node-2\n   (('skip_connect', 0), ('skip_connect', 1), ('skip_connect', 2))] # node-3\n  )\n\narchitectures = {'resnet'  : ResNet_CODE,\n                 'all_c3x3': AllConv3x3_CODE,\n                 'all_c1x1': AllConv1x1_CODE,\n                 'all_idnt': AllIdentity_CODE,\n                 'all_full': AllFull_CODE}\n"""
lib/models/cell_searchs/search_cells.py,4,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, random, torch\nimport warnings\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom copy import deepcopy\nfrom ..cell_operations import OPS\n\n\n# This module is used for NAS-Bench-201, represents a small search space with a complete DAG\nclass NAS201SearchCell(nn.Module):\n\n  def __init__(self, C_in, C_out, stride, max_nodes, op_names, affine=False, track_running_stats=True):\n    super(NAS201SearchCell, self).__init__()\n\n    self.op_names  = deepcopy(op_names)\n    self.edges     = nn.ModuleDict()\n    self.max_nodes = max_nodes\n    self.in_dim    = C_in\n    self.out_dim   = C_out\n    for i in range(1, max_nodes):\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        if j == 0:\n          xlists = [OPS[op_name](C_in , C_out, stride, affine, track_running_stats) for op_name in op_names]\n        else:\n          xlists = [OPS[op_name](C_in , C_out,      1, affine, track_running_stats) for op_name in op_names]\n        self.edges[ node_str ] = nn.ModuleList( xlists )\n    self.edge_keys  = sorted(list(self.edges.keys()))\n    self.edge2index = {key:i for i, key in enumerate(self.edge_keys)}\n    self.num_edges  = len(self.edges)\n\n  def extra_repr(self):\n    string = 'info :: {max_nodes} nodes, inC={in_dim}, outC={out_dim}'.format(**self.__dict__)\n    return string\n\n  def forward(self, inputs, weightss):\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      inter_nodes = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights  = weightss[ self.edge2index[node_str] ]\n        inter_nodes.append( sum( layer(nodes[j]) * w for layer, w in zip(self.edges[node_str], weights) ) )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n  # GDAS\n  def forward_gdas(self, inputs, hardwts, index):\n    nodes   = [inputs]\n    for i in range(1, self.max_nodes):\n      inter_nodes = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights  = hardwts[ self.edge2index[node_str] ]\n        argmaxs  = index[ self.edge2index[node_str] ].item()\n        weigsum  = sum( weights[_ie] * edge(nodes[j]) if _ie == argmaxs else weights[_ie] for _ie, edge in enumerate(self.edges[node_str]) )\n        inter_nodes.append( weigsum )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n  # joint\n  def forward_joint(self, inputs, weightss):\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      inter_nodes = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights  = weightss[ self.edge2index[node_str] ]\n        #aggregation = sum( layer(nodes[j]) * w for layer, w in zip(self.edges[node_str], weights) ) / weights.numel()\n        aggregation = sum( layer(nodes[j]) * w for layer, w in zip(self.edges[node_str], weights) )\n        inter_nodes.append( aggregation )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n  # uniform random sampling per iteration, SETN\n  def forward_urs(self, inputs):\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      while True: # to avoid select zero for all ops\n        sops, has_non_zero = [], False\n        for j in range(i):\n          node_str   = '{:}<-{:}'.format(i, j)\n          candidates = self.edges[node_str]\n          select_op  = random.choice(candidates)\n          sops.append( select_op )\n          if not hasattr(select_op, 'is_zero') or select_op.is_zero is False: has_non_zero=True\n        if has_non_zero: break\n      inter_nodes = []\n      for j, select_op in enumerate(sops):\n        inter_nodes.append( select_op(nodes[j]) )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n  # select the argmax\n  def forward_select(self, inputs, weightss):\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      inter_nodes = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights  = weightss[ self.edge2index[node_str] ]\n        inter_nodes.append( self.edges[node_str][ weights.argmax().item() ]( nodes[j] ) )\n        #inter_nodes.append( sum( layer(nodes[j]) * w for layer, w in zip(self.edges[node_str], weights) ) )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n  # forward with a specific structure\n  def forward_dynamic(self, inputs, structure):\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      cur_op_node = structure.nodes[i-1]\n      inter_nodes = []\n      for op_name, j in cur_op_node:\n        node_str = '{:}<-{:}'.format(i, j)\n        op_index = self.op_names.index( op_name )\n        inter_nodes.append( self.edges[node_str][op_index]( nodes[j] ) )\n      nodes.append( sum(inter_nodes) )\n    return nodes[-1]\n\n\n\nclass MixedOp(nn.Module):\n\n  def __init__(self, space, C, stride, affine, track_running_stats):\n    super(MixedOp, self).__init__()\n    self._ops = nn.ModuleList()\n    for primitive in space:\n      op = OPS[primitive](C, C, stride, affine, track_running_stats)\n      self._ops.append(op)\n\n  def forward_gdas(self, x, weights, index):\n    return self._ops[index](x) * weights[index]\n\n  def forward_darts(self, x, weights):\n    return sum(w * op(x) for w, op in zip(weights, self._ops))\n\n\n# Learning Transferable Architectures for Scalable Image Recognition, CVPR 2018\nclass NASNetSearchCell(nn.Module):\n\n  def __init__(self, space, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, affine, track_running_stats):\n    super(NASNetSearchCell, self).__init__()\n    self.reduction = reduction\n    self.op_names  = deepcopy(space)\n    if reduction_prev: self.preprocess0 = OPS['skip_connect'](C_prev_prev, C, 2, affine, track_running_stats)\n    else             : self.preprocess0 = OPS['nor_conv_1x1'](C_prev_prev, C, 1, affine, track_running_stats)\n    self.preprocess1 = OPS['nor_conv_1x1'](C_prev, C, 1, affine, track_running_stats)\n    self._steps = steps\n    self._multiplier = multiplier\n\n    self._ops = nn.ModuleList()\n    self.edges     = nn.ModuleDict()\n    for i in range(self._steps):\n      for j in range(2+i):\n        node_str = '{:}<-{:}'.format(i, j)  # indicate the edge from node-(j) to node-(i+2)\n        stride = 2 if reduction and j < 2 else 1\n        op = MixedOp(space, C, stride, affine, track_running_stats)\n        self.edges[ node_str ] = op\n    self.edge_keys  = sorted(list(self.edges.keys()))\n    self.edge2index = {key:i for i, key in enumerate(self.edge_keys)}\n    self.num_edges  = len(self.edges)\n\n  def forward_gdas(self, s0, s1, weightss, indexs):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    states = [s0, s1]\n    for i in range(self._steps):\n      clist = []\n      for j, h in enumerate(states):\n        node_str = '{:}<-{:}'.format(i, j)\n        op = self.edges[ node_str ]\n        weights = weightss[ self.edge2index[node_str] ]\n        index   = indexs[ self.edge2index[node_str] ].item()\n        clist.append( op.forward_gdas(h, weights, index) )\n      states.append( sum(clist) )\n\n    return torch.cat(states[-self._multiplier:], dim=1)\n\n  def forward_darts(self, s0, s1, weightss):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    states = [s0, s1]\n    for i in range(self._steps):\n      clist = []\n      for j, h in enumerate(states):\n        node_str = '{:}<-{:}'.format(i, j)\n        op = self.edges[ node_str ]\n        weights = weightss[ self.edge2index[node_str] ]\n        clist.append( op.forward_darts(h, weights) )\n      states.append( sum(clist) )\n\n    return torch.cat(states[-self._multiplier:], dim=1)\n"""
lib/models/cell_searchs/search_model_darts.py,4,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n########################################################\n# DARTS: Differentiable Architecture Search, ICLR 2019 #\n########################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\nfrom .genotypes        import Structure\n\n\nclass TinyNetworkDarts(nn.Module):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine, track_running_stats):\n    super(TinyNetworkDarts, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine, track_running_stats)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n\n  def get_weights(self):\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def get_alphas(self):\n    return [self.arch_parameters]\n\n  def show_alphas(self):\n    with torch.no_grad():\n      return 'arch-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_parameters, dim=-1).cpu() )\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, Max-Nodes={max_nodes}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def genotype(self):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        with torch.no_grad():\n          weights = self.arch_parameters[ self.edge2index[node_str] ]\n          op_name = self.op_names[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return Structure( genotypes )\n\n  def forward(self, inputs):\n    alphas  = nn.functional.softmax(self.arch_parameters, dim=-1)\n\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if isinstance(cell, SearchCell):\n        feature = cell(feature, alphas)\n      else:\n        feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_darts_nasnet.py,9,"b""####################\n# DARTS, ICLR 2019 #\n####################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom typing import List, Text, Dict\nfrom .search_cells import NASNetSearchCell as SearchCell\n\n\n# The macro structure is based on NASNet\nclass NASNetworkDARTS(nn.Module):\n\n  def __init__(self, C: int, N: int, steps: int, multiplier: int, stem_multiplier: int,\n               num_classes: int, search_space: List[Text], affine: bool, track_running_stats: bool):\n    super(NASNetworkDARTS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self._steps    = steps\n    self._multiplier = multiplier\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C*stem_multiplier, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C*stem_multiplier))\n  \n    # config for each layer\n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * (N-1) + [C*4 ] + [C*4  ] * (N-1)\n    layer_reductions = [False] * N + [True] + [False] * (N-1) + [True] + [False] * (N-1)\n\n    num_edge, edge2index = None, None\n    C_prev_prev, C_prev, C_curr, reduction_prev = C*stem_multiplier, C*stem_multiplier, C, False\n\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = SearchCell(search_space, steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev, affine, track_running_stats)\n      if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n      else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev_prev, C_prev, reduction_prev = C_prev, multiplier*C_curr, reduction\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_normal_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.arch_reduce_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n\n  def get_weights(self) -> List[torch.nn.Parameter]:\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def get_alphas(self) -> List[torch.nn.Parameter]:\n    return [self.arch_normal_parameters, self.arch_reduce_parameters]\n\n  def show_alphas(self) -> Text:\n    with torch.no_grad():\n      A = 'arch-normal-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_normal_parameters, dim=-1).cpu() )\n      B = 'arch-reduce-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_reduce_parameters, dim=-1).cpu() )\n    return '{:}\\n{:}'.format(A, B)\n\n  def get_message(self) -> Text:\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self) -> Text:\n    return ('{name}(C={_C}, N={_layerN}, steps={_steps}, multiplier={_multiplier}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def genotype(self) -> Dict[Text, List]:\n    def _parse(weights):\n      gene = []\n      for i in range(self._steps):\n        edges = []\n        for j in range(2+i):\n          node_str = '{:}<-{:}'.format(i, j)\n          ws = weights[ self.edge2index[node_str] ]\n          for k, op_name in enumerate(self.op_names):\n            if op_name == 'none': continue\n            edges.append( (op_name, j, ws[k]) )\n        edges = sorted(edges, key=lambda x: -x[-1])\n        selected_edges = edges[:2]\n        gene.append( tuple(selected_edges) )\n      return gene\n    with torch.no_grad():\n      gene_normal = _parse(torch.softmax(self.arch_normal_parameters, dim=-1).cpu().numpy())\n      gene_reduce = _parse(torch.softmax(self.arch_reduce_parameters, dim=-1).cpu().numpy())\n    return {'normal': gene_normal, 'normal_concat': list(range(2+self._steps-self._multiplier, self._steps+2)),\n            'reduce': gene_reduce, 'reduce_concat': list(range(2+self._steps-self._multiplier, self._steps+2))}\n\n  def forward(self, inputs):\n\n    normal_w = nn.functional.softmax(self.arch_normal_parameters, dim=1)\n    reduce_w = nn.functional.softmax(self.arch_reduce_parameters, dim=1)\n\n    s0 = s1 = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if cell.reduction: ww = reduce_w\n      else             : ww = normal_w\n      s0, s1 = s1, cell.forward_darts(s0, s1, ww)\n    out = self.lastact(s1)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_enas.py,1,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##########################################################################\n# Efficient Neural Architecture Search via Parameters Sharing, ICML 2018 #\n##########################################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\nfrom .genotypes        import Structure\nfrom .search_model_enas_utils import Controller\n\n\nclass TinyNetworkENAS(nn.Module):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine, track_running_stats):\n    super(TinyNetworkENAS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine, track_running_stats)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    # to maintain the sampled architecture\n    self.sampled_arch = None\n\n  def update_arch(self, _arch):\n    if _arch is None:\n      self.sampled_arch = None\n    elif isinstance(_arch, Structure):\n      self.sampled_arch = _arch\n    elif isinstance(_arch, (list, tuple)):\n      genotypes = []\n      for i in range(1, self.max_nodes):\n        xlist = []\n        for j in range(i):\n          node_str = '{:}<-{:}'.format(i, j)\n          op_index = _arch[ self.edge2index[node_str] ]\n          op_name  = self.op_names[ op_index ]\n          xlist.append((op_name, j))\n        genotypes.append( tuple(xlist) )\n      self.sampled_arch = Structure(genotypes)\n    else:\n      raise ValueError('invalid type of input architecture : {:}'.format(_arch))\n    return self.sampled_arch\n    \n  def create_controller(self):\n    return Controller(len(self.edge2index), len(self.op_names))\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, Max-Nodes={max_nodes}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, inputs):\n\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if isinstance(cell, SearchCell):\n        feature = cell.forward_dynamic(feature, self.sampled_arch)\n      else: feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_enas_utils.py,5,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##########################################################################\n# Efficient Neural Architecture Search via Parameters Sharing, ICML 2018 #\n##########################################################################\nimport torch\nimport torch.nn as nn\nfrom torch.distributions.categorical import Categorical\n\nclass Controller(nn.Module):\n  # we refer to https://github.com/TDeVries/enas_pytorch/blob/master/models/controller.py\n  def __init__(self, num_edge, num_ops, lstm_size=32, lstm_num_layers=2, tanh_constant=2.5, temperature=5.0):\n    super(Controller, self).__init__()\n    # assign the attributes\n    self.num_edge  = num_edge\n    self.num_ops   = num_ops\n    self.lstm_size = lstm_size\n    self.lstm_N    = lstm_num_layers\n    self.tanh_constant = tanh_constant\n    self.temperature   = temperature\n    # create parameters\n    self.register_parameter('input_vars', nn.Parameter(torch.Tensor(1, 1, lstm_size)))\n    self.w_lstm = nn.LSTM(input_size=self.lstm_size, hidden_size=self.lstm_size, num_layers=self.lstm_N)\n    self.w_embd = nn.Embedding(self.num_ops, self.lstm_size)\n    self.w_pred = nn.Linear(self.lstm_size, self.num_ops)\n\n    nn.init.uniform_(self.input_vars         , -0.1, 0.1)\n    nn.init.uniform_(self.w_lstm.weight_hh_l0, -0.1, 0.1)\n    nn.init.uniform_(self.w_lstm.weight_ih_l0, -0.1, 0.1)\n    nn.init.uniform_(self.w_embd.weight      , -0.1, 0.1)\n    nn.init.uniform_(self.w_pred.weight      , -0.1, 0.1)\n\n  def forward(self):\n\n    inputs, h0 = self.input_vars, None\n    log_probs, entropys, sampled_arch = [], [], []\n    for iedge in range(self.num_edge):\n      outputs, h0 = self.w_lstm(inputs, h0)\n      \n      logits = self.w_pred(outputs)\n      logits = logits / self.temperature\n      logits = self.tanh_constant * torch.tanh(logits)\n      # distribution\n      op_distribution = Categorical(logits=logits)\n      op_index    = op_distribution.sample()\n      sampled_arch.append( op_index.item() )\n\n      op_log_prob = op_distribution.log_prob(op_index)\n      log_probs.append( op_log_prob.view(-1) )\n      op_entropy  = op_distribution.entropy()\n      entropys.append( op_entropy.view(-1) )\n      \n      # obtain the input embedding for the next step\n      inputs = self.w_embd(op_index)\n    return torch.sum(torch.cat(log_probs)), torch.sum(torch.cat(entropys)), sampled_arch\n"""
lib/models/cell_searchs/search_model_gdas.py,7,"b""###########################################################################\n# Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019 #\n###########################################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\nfrom .genotypes        import Structure\n\n\nclass TinyNetworkGDAS(nn.Module):\n\n  #def __init__(self, C, N, max_nodes, num_classes, search_space, affine=False, track_running_stats=True):\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine, track_running_stats):\n    super(TinyNetworkGDAS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine, track_running_stats)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.tau        = 10\n\n  def get_weights(self):\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def set_tau(self, tau):\n    self.tau = tau\n\n  def get_tau(self):\n    return self.tau\n\n  def get_alphas(self):\n    return [self.arch_parameters]\n\n  def show_alphas(self):\n    with torch.no_grad():\n      return 'arch-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_parameters, dim=-1).cpu() )\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, Max-Nodes={max_nodes}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def genotype(self):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        with torch.no_grad():\n          weights = self.arch_parameters[ self.edge2index[node_str] ]\n          op_name = self.op_names[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return Structure( genotypes )\n\n  def forward(self, inputs):\n    while True:\n      gumbels = -torch.empty_like(self.arch_parameters).exponential_().log()\n      logits  = (self.arch_parameters.log_softmax(dim=1) + gumbels) / self.tau\n      probs   = nn.functional.softmax(logits, dim=1)\n      index   = probs.max(-1, keepdim=True)[1]\n      one_h   = torch.zeros_like(logits).scatter_(-1, index, 1.0)\n      hardwts = one_h - probs.detach() + probs\n      if (torch.isinf(gumbels).any()) or (torch.isinf(probs).any()) or (torch.isnan(probs).any()):\n        continue\n      else: break\n\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if isinstance(cell, SearchCell):\n        feature = cell.forward_gdas(feature, hardwts, index)\n      else:\n        feature = cell(feature)\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_gdas_nasnet.py,10,"b""###########################################################################\n# Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019 #\n###########################################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom .search_cells import NASNetSearchCell as SearchCell\n\n\n# The macro structure is based on NASNet\nclass NASNetworkGDAS(nn.Module):\n\n  def __init__(self, C, N, steps, multiplier, stem_multiplier, num_classes, search_space, affine, track_running_stats):\n    super(NASNetworkGDAS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self._steps    = steps\n    self._multiplier = multiplier\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C*stem_multiplier, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C*stem_multiplier))\n  \n    # config for each layer\n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * (N-1) + [C*4 ] + [C*4  ] * (N-1)\n    layer_reductions = [False] * N + [True] + [False] * (N-1) + [True] + [False] * (N-1)\n\n    num_edge, edge2index = None, None\n    C_prev_prev, C_prev, C_curr, reduction_prev = C*stem_multiplier, C*stem_multiplier, C, False\n\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = SearchCell(search_space, steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev, affine, track_running_stats)\n      if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n      else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev_prev, C_prev, reduction_prev = C_prev, multiplier*C_curr, reduction\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_normal_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.arch_reduce_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.tau        = 10\n\n  def get_weights(self):\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def set_tau(self, tau):\n    self.tau = tau\n\n  def get_tau(self):\n    return self.tau\n\n  def get_alphas(self):\n    return [self.arch_normal_parameters, self.arch_reduce_parameters]\n\n  def show_alphas(self):\n    with torch.no_grad():\n      A = 'arch-normal-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_normal_parameters, dim=-1).cpu() )\n      B = 'arch-reduce-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_reduce_parameters, dim=-1).cpu() )\n    return '{:}\\n{:}'.format(A, B)\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N={_layerN}, steps={_steps}, multiplier={_multiplier}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def genotype(self):\n    def _parse(weights):\n      gene = []\n      for i in range(self._steps):\n        edges = []\n        for j in range(2+i):\n          node_str = '{:}<-{:}'.format(i, j)\n          ws = weights[ self.edge2index[node_str] ]\n          for k, op_name in enumerate(self.op_names):\n            if op_name == 'none': continue\n            edges.append( (op_name, j, ws[k]) )\n        edges = sorted(edges, key=lambda x: -x[-1])\n        selected_edges = edges[:2]\n        gene.append( tuple(selected_edges) )\n      return gene\n    with torch.no_grad():\n      gene_normal = _parse(torch.softmax(self.arch_normal_parameters, dim=-1).cpu().numpy())\n      gene_reduce = _parse(torch.softmax(self.arch_reduce_parameters, dim=-1).cpu().numpy())\n    return {'normal': gene_normal, 'normal_concat': list(range(2+self._steps-self._multiplier, self._steps+2)),\n            'reduce': gene_reduce, 'reduce_concat': list(range(2+self._steps-self._multiplier, self._steps+2))}\n\n  def forward(self, inputs):\n    def get_gumbel_prob(xins):\n      while True:\n        gumbels = -torch.empty_like(xins).exponential_().log()\n        logits  = (xins.log_softmax(dim=1) + gumbels) / self.tau\n        probs   = nn.functional.softmax(logits, dim=1)\n        index   = probs.max(-1, keepdim=True)[1]\n        one_h   = torch.zeros_like(logits).scatter_(-1, index, 1.0)\n        hardwts = one_h - probs.detach() + probs\n        if (torch.isinf(gumbels).any()) or (torch.isinf(probs).any()) or (torch.isnan(probs).any()):\n          continue\n        else: break\n      return hardwts, index\n\n    normal_hardwts, normal_index = get_gumbel_prob(self.arch_normal_parameters)\n    reduce_hardwts, reduce_index = get_gumbel_prob(self.arch_reduce_parameters)\n\n    s0 = s1 = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if cell.reduction: hardwts, index = reduce_hardwts, reduce_index\n      else             : hardwts, index = normal_hardwts, normal_index\n      s0, s1 = s1, cell.forward_gdas(s0, s1, hardwts, index)\n    out = self.lastact(s1)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_random.py,1,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##############################################################################\n# Random Search and Reproducibility for Neural Architecture Search, UAI 2019 # \n##############################################################################\nimport torch, random\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\nfrom .genotypes        import Structure\n\n\nclass TinyNetworkRANDOM(nn.Module):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine, track_running_stats):\n    super(TinyNetworkRANDOM, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine, track_running_stats)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_cache = None\n    \n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, Max-Nodes={max_nodes}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def random_genotype(self, set_cache):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        op_name  = random.choice( self.op_names )\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    arch = Structure( genotypes )\n    if set_cache: self.arch_cache = arch\n    return arch\n\n  def forward(self, inputs):\n\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if isinstance(cell, SearchCell):\n        feature = cell.forward_dynamic(feature, self.arch_cache)\n      else: feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n    return out, logits\n"""
lib/models/cell_searchs/search_model_setn.py,7,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n######################################################################################\n# One-Shot Neural Architecture Search via Self-Evaluated Template Network, ICCV 2019 #\n######################################################################################\nimport torch, random\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\nfrom .genotypes        import Structure\n\n\nclass TinyNetworkSETN(nn.Module):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine, track_running_stats):\n    super(TinyNetworkSETN, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C))\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine, track_running_stats)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev = cell.out_dim\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.mode       = 'urs'\n    self.dynamic_cell = None\n    \n  def set_cal_mode(self, mode, dynamic_cell=None):\n    assert mode in ['urs', 'joint', 'select', 'dynamic']\n    self.mode = mode\n    if mode == 'dynamic': self.dynamic_cell = deepcopy( dynamic_cell )\n    else                : self.dynamic_cell = None\n\n  def get_cal_mode(self):\n    return self.mode\n\n  def get_weights(self):\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def get_alphas(self):\n    return [self.arch_parameters]\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, Max-Nodes={max_nodes}, N={_layerN}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def genotype(self):\n    genotypes = []\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        with torch.no_grad():\n          weights = self.arch_parameters[ self.edge2index[node_str] ]\n          op_name = self.op_names[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return Structure( genotypes )\n\n  def dync_genotype(self, use_random=False):\n    genotypes = []\n    with torch.no_grad():\n      alphas_cpu = nn.functional.softmax(self.arch_parameters, dim=-1)\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        if use_random:\n          op_name  = random.choice(self.op_names)\n        else:\n          weights  = alphas_cpu[ self.edge2index[node_str] ]\n          op_index = torch.multinomial(weights, 1).item()\n          op_name  = self.op_names[ op_index ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return Structure( genotypes )\n\n  def get_log_prob(self, arch):\n    with torch.no_grad():\n      logits = nn.functional.log_softmax(self.arch_parameters, dim=-1)\n    select_logits = []\n    for i, node_info in enumerate(arch.nodes):\n      for op, xin in node_info:\n        node_str = '{:}<-{:}'.format(i+1, xin)\n        op_index = self.op_names.index(op)\n        select_logits.append( logits[self.edge2index[node_str], op_index] )\n    return sum(select_logits).item()\n\n\n  def return_topK(self, K):\n    archs = Structure.gen_all(self.op_names, self.max_nodes, False)\n    pairs = [(self.get_log_prob(arch), arch) for arch in archs]\n    if K < 0 or K >= len(archs): K = len(archs)\n    sorted_pairs = sorted(pairs, key=lambda x: -x[0])\n    return_pairs = [sorted_pairs[_][1] for _ in range(K)]\n    return return_pairs\n\n\n  def forward(self, inputs):\n    alphas  = nn.functional.softmax(self.arch_parameters, dim=-1)\n    with torch.no_grad():\n      alphas_cpu = alphas.detach().cpu()\n\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      if isinstance(cell, SearchCell):\n        if self.mode == 'urs':\n          feature = cell.forward_urs(feature)\n        elif self.mode == 'select':\n          feature = cell.forward_select(feature, alphas_cpu)\n        elif self.mode == 'joint':\n          feature = cell.forward_joint(feature, alphas)\n        elif self.mode == 'dynamic':\n          feature = cell.forward_dynamic(feature, self.dynamic_cell)\n        else: raise ValueError('invalid mode={:}'.format(self.mode))\n      else: feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/cell_searchs/search_model_setn_nasnet.py,9,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n######################################################################################\n# One-Shot Neural Architecture Search via Self-Evaluated Template Network, ICCV 2019 #\n######################################################################################\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nfrom typing import List, Text, Dict\nfrom .search_cells     import NASNetSearchCell as SearchCell\n\n\n# The macro structure is based on NASNet\nclass NASNetworkSETN(nn.Module):\n\n  def __init__(self, C: int, N: int, steps: int, multiplier: int, stem_multiplier: int,\n               num_classes: int, search_space: List[Text], affine: bool, track_running_stats: bool):\n    super(NASNetworkSETN, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self._steps    = steps\n    self._multiplier = multiplier\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, C*stem_multiplier, kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(C*stem_multiplier))\n  \n    # config for each layer\n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * (N-1) + [C*4 ] + [C*4  ] * (N-1)\n    layer_reductions = [False] * N + [True] + [False] * (N-1) + [True] + [False] * (N-1)\n\n    num_edge, edge2index = None, None\n    C_prev_prev, C_prev, C_curr, reduction_prev = C*stem_multiplier, C*stem_multiplier, C, False\n\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = SearchCell(search_space, steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev, affine, track_running_stats)\n      if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n      else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      self.cells.append( cell )\n      C_prev_prev, C_prev, reduction_prev = C_prev, multiplier*C_curr, reduction\n    self.op_names   = deepcopy( search_space )\n    self._Layer     = len(self.cells)\n    self.edge2index = edge2index\n    self.lastact    = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.arch_normal_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.arch_reduce_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    self.mode = 'urs'\n    self.dynamic_cell = None\n\n  def set_cal_mode(self, mode, dynamic_cell=None):\n    assert mode in ['urs', 'joint', 'select', 'dynamic']\n    self.mode = mode\n    if mode == 'dynamic':\n      self.dynamic_cell = deepcopy(dynamic_cell)\n    else:\n      self.dynamic_cell = None\n\n  def get_weights(self):\n    xlist = list( self.stem.parameters() ) + list( self.cells.parameters() )\n    xlist+= list( self.lastact.parameters() ) + list( self.global_pooling.parameters() )\n    xlist+= list( self.classifier.parameters() )\n    return xlist\n\n  def get_alphas(self):\n    return [self.arch_normal_parameters, self.arch_reduce_parameters]\n\n  def show_alphas(self):\n    with torch.no_grad():\n      A = 'arch-normal-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_normal_parameters, dim=-1).cpu() )\n      B = 'arch-reduce-parameters :\\n{:}'.format( nn.functional.softmax(self.arch_reduce_parameters, dim=-1).cpu() )\n    return '{:}\\n{:}'.format(A, B)\n\n  def get_message(self):\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N={_layerN}, steps={_steps}, multiplier={_multiplier}, L={_Layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def dync_genotype(self, use_random=False):\n    genotypes = []\n    with torch.no_grad():\n      alphas_cpu = nn.functional.softmax(self.arch_parameters, dim=-1)\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        if use_random:\n          op_name  = random.choice(self.op_names)\n        else:\n          weights  = alphas_cpu[ self.edge2index[node_str] ]\n          op_index = torch.multinomial(weights, 1).item()\n          op_name  = self.op_names[ op_index ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return Structure( genotypes )\n\n  def genotype(self):\n    def _parse(weights):\n      gene = []\n      for i in range(self._steps):\n        edges = []\n        for j in range(2+i):\n          node_str = '{:}<-{:}'.format(i, j)\n          ws = weights[ self.edge2index[node_str] ]\n          for k, op_name in enumerate(self.op_names):\n            if op_name == 'none': continue\n            edges.append( (op_name, j, ws[k]) )\n        edges = sorted(edges, key=lambda x: -x[-1])\n        selected_edges = edges[:2]\n        gene.append( tuple(selected_edges) )\n      return gene\n    with torch.no_grad():\n      gene_normal = _parse(torch.softmax(self.arch_normal_parameters, dim=-1).cpu().numpy())\n      gene_reduce = _parse(torch.softmax(self.arch_reduce_parameters, dim=-1).cpu().numpy())\n    return {'normal': gene_normal, 'normal_concat': list(range(2+self._steps-self._multiplier, self._steps+2)),\n            'reduce': gene_reduce, 'reduce_concat': list(range(2+self._steps-self._multiplier, self._steps+2))}\n\n  def forward(self, inputs):\n    normal_hardwts = nn.functional.softmax(self.arch_normal_parameters, dim=-1)\n    reduce_hardwts = nn.functional.softmax(self.arch_reduce_parameters, dim=-1)\n\n    s0 = s1 = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      # [TODO]\n      raise NotImplementedError\n      if cell.reduction: hardwts, index = reduce_hardwts, reduce_index\n      else             : hardwts, index = normal_hardwts, normal_index\n      s0, s1 = s1, cell.forward_gdas(s0, s1, hardwts, index)\n    out = self.lastact(s1)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/shape_infers/InferCifarResNet.py,2,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..initialization import initialize_resnet\n\n\nclass ConvBNReLU(nn.Module):\n  \n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    else       : self.bn  = None\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n\n  def forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.bn  : out = self.bn( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  num_conv  = 2\n  expansion = 1\n  def __init__(self, iCs, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 3,\'invalid lengths of iCs : {:}\'.format(iCs)\n    \n    self.conv_a = ConvBNReLU(iCs[0], iCs[1], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(iCs[1], iCs[2], 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n      residual_in = iCs[2]\n    elif iCs[0] != iCs[2]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    #self.out_dim  = max(residual_in, iCs[2])\n    self.out_dim  = iCs[2]\n\n  def forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + basicblock\n    return F.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, iCs, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 4,\'invalid lengths of iCs : {:}\'.format(iCs)\n    self.conv_1x1 = ConvBNReLU(iCs[0], iCs[1], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(iCs[1], iCs[2], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(iCs[2], iCs[3], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=True , has_bn=False, has_relu=False)\n      residual_in     = iCs[3]\n    elif iCs[0] != iCs[3]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=False, has_bn=False, has_relu=False)\n      residual_in     = iCs[3]\n    else:\n      self.downsample = None\n    #self.out_dim = max(residual_in, iCs[3])\n    self.out_dim = iCs[3]\n\n  def forward(self, inputs):\n\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + bottleneck\n    return F.relu(out, inplace=True)\n\n\n\nclass InferCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, xblocks, xchannels, num_classes, zero_init_residual):\n    super(InferCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n    assert len(xblocks) == 3, \'invalid xblocks : {:}\'.format(xblocks)\n\n    self.message     = \'InferWidthCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes = num_classes\n    self.xchannels   = xchannels\n    self.layers      = nn.ModuleList( [ ConvBNReLU(xchannels[0], xchannels[1], 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    last_channel_idx = 1\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        num_conv = block.num_conv \n        iCs      = self.xchannels[last_channel_idx:last_channel_idx+num_conv+1]\n        stride   = 2 if stage > 0 and iL == 0 else 1\n        module   = block(iCs, stride)\n        last_channel_idx += num_conv\n        self.xchannels[last_channel_idx] = module.out_dim\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iCs={:}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iCs, module.out_dim, stride)\n        if iL + 1 == xblocks[stage]: # reach the maximum depth\n          out_channel = module.out_dim\n          for iiL in range(iL+1, layer_blocks):\n            last_channel_idx += num_conv\n          self.xchannels[last_channel_idx] = module.out_dim\n          break\n  \n    self.avgpool    = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(self.xchannels[-1], num_classes)\n    \n    self.apply(initialize_resnet)\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, ResNetBasicblock):\n          nn.init.constant_(m.conv_b.bn.weight, 0)\n        elif isinstance(m, ResNetBottleneck):\n          nn.init.constant_(m.conv_1x4.bn.weight, 0)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_infers/InferCifarResNet_depth.py,2,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..initialization import initialize_resnet\n\n\nclass ConvBNReLU(nn.Module):\n  \n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    else       : self.bn  = None\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n\n  def forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.bn  : out = self.bn( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  num_conv  = 2\n  expansion = 1\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    \n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim  = planes\n\n  def forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + basicblock\n    return F.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=True , has_bn=False, has_relu=False)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=False, has_bn=False, has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim = planes*self.expansion\n\n  def forward(self, inputs):\n\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + bottleneck\n    return F.relu(out, inplace=True)\n\n\n\nclass InferDepthCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, xblocks, num_classes, zero_init_residual):\n    super(InferDepthCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n    assert len(xblocks) == 3, \'invalid xblocks : {:}\'.format(xblocks)\n\n    self.message     = \'InferWidthCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes = num_classes\n    self.layers      = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    self.channels    = [16]\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        iC       = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride   = 2 if stage > 0 and iL == 0 else 1\n        module   = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, planes, module.out_dim, stride)\n        if iL + 1 == xblocks[stage]: # reach the maximum depth\n          break\n  \n    self.avgpool    = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(self.channels[-1], num_classes)\n    \n    self.apply(initialize_resnet)\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, ResNetBasicblock):\n          nn.init.constant_(m.conv_b.bn.weight, 0)\n        elif isinstance(m, ResNetBottleneck):\n          nn.init.constant_(m.conv_1x4.bn.weight, 0)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_infers/InferCifarResNet_width.py,2,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..initialization import initialize_resnet\n\n\nclass ConvBNReLU(nn.Module):\n  \n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    else       : self.bn  = None\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n\n  def forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.bn  : out = self.bn( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  num_conv  = 2\n  expansion = 1\n  def __init__(self, iCs, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 3,\'invalid lengths of iCs : {:}\'.format(iCs)\n    \n    self.conv_a = ConvBNReLU(iCs[0], iCs[1], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(iCs[1], iCs[2], 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n      residual_in = iCs[2]\n    elif iCs[0] != iCs[2]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    #self.out_dim  = max(residual_in, iCs[2])\n    self.out_dim  = iCs[2]\n\n  def forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + basicblock\n    return F.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, iCs, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 4,\'invalid lengths of iCs : {:}\'.format(iCs)\n    self.conv_1x1 = ConvBNReLU(iCs[0], iCs[1], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(iCs[1], iCs[2], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(iCs[2], iCs[3], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=True , has_bn=False, has_relu=False)\n      residual_in     = iCs[3]\n    elif iCs[0] != iCs[3]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=False, has_bn=False, has_relu=False)\n      residual_in     = iCs[3]\n    else:\n      self.downsample = None\n    #self.out_dim = max(residual_in, iCs[3])\n    self.out_dim = iCs[3]\n\n  def forward(self, inputs):\n\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + bottleneck\n    return F.relu(out, inplace=True)\n\n\n\nclass InferWidthCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, xchannels, num_classes, zero_init_residual):\n    super(InferWidthCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n\n    self.message     = \'InferWidthCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes = num_classes\n    self.xchannels   = xchannels\n    self.layers      = nn.ModuleList( [ ConvBNReLU(xchannels[0], xchannels[1], 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    last_channel_idx = 1\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        num_conv = block.num_conv \n        iCs      = self.xchannels[last_channel_idx:last_channel_idx+num_conv+1]\n        stride   = 2 if stage > 0 and iL == 0 else 1\n        module   = block(iCs, stride)\n        last_channel_idx += num_conv\n        self.xchannels[last_channel_idx] = module.out_dim\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iCs={:}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iCs, module.out_dim, stride)\n  \n    self.avgpool    = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(self.xchannels[-1], num_classes)\n    \n    self.apply(initialize_resnet)\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, ResNetBasicblock):\n          nn.init.constant_(m.conv_b.bn.weight, 0)\n        elif isinstance(m, ResNetBottleneck):\n          nn.init.constant_(m.conv_1x4.bn.weight, 0)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_infers/InferImagenetResNet.py,2,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..initialization import initialize_resnet\n\n\nclass ConvBNReLU(nn.Module):\n  \n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    else       : self.bn  = None\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n\n  def forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.bn  : out = self.bn( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  num_conv  = 2\n  expansion = 1\n  def __init__(self, iCs, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 3,\'invalid lengths of iCs : {:}\'.format(iCs)\n    \n    self.conv_a = ConvBNReLU(iCs[0], iCs[1], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(iCs[1], iCs[2], 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=True, has_bn=True, has_relu=False)\n      residual_in = iCs[2]\n    elif iCs[0] != iCs[2]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[2], 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    #self.out_dim  = max(residual_in, iCs[2])\n    self.out_dim  = iCs[2]\n\n  def forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + basicblock\n    return F.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, iCs, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    assert isinstance(iCs, tuple) or isinstance(iCs, list), \'invalid type of iCs : {:}\'.format( iCs )\n    assert len(iCs) == 4,\'invalid lengths of iCs : {:}\'.format(iCs)\n    self.conv_1x1 = ConvBNReLU(iCs[0], iCs[1], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(iCs[1], iCs[2], 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(iCs[2], iCs[3], 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    residual_in = iCs[0]\n    if stride == 2:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=True , has_bn=True, has_relu=False)\n      residual_in     = iCs[3]\n    elif iCs[0] != iCs[3]:\n      self.downsample = ConvBNReLU(iCs[0], iCs[3], 1, 1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n      residual_in     = iCs[3]\n    else:\n      self.downsample = None\n    #self.out_dim = max(residual_in, iCs[3])\n    self.out_dim = iCs[3]\n\n  def forward(self, inputs):\n\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(inputs)\n    else:\n      residual = inputs\n    out = residual + bottleneck\n    return F.relu(out, inplace=True)\n\n\n\nclass InferImagenetResNet(nn.Module):\n\n  def __init__(self, block_name, layers, xblocks, xchannels, deep_stem, num_classes, zero_init_residual):\n    super(InferImagenetResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'BasicBlock\':\n      block = ResNetBasicblock\n    elif block_name == \'Bottleneck\':\n      block = ResNetBottleneck\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n    assert len(xblocks) == len(layers), \'invalid layers : {:} vs xblocks : {:}\'.format(layers, xblocks)\n\n    self.message     = \'InferImagenetResNet : Depth : {:} -> {:}, Layers for each block : {:}\'.format(sum(layers)*block.num_conv, sum(xblocks)*block.num_conv, xblocks)\n    self.num_classes = num_classes\n    self.xchannels   = xchannels\n    if not deep_stem:\n      self.layers      = nn.ModuleList( [ ConvBNReLU(xchannels[0], xchannels[1], 7, 2, 3, False, has_avg=False, has_bn=True, has_relu=True) ] )\n      last_channel_idx = 1\n    else:\n      self.layers      = nn.ModuleList( [ ConvBNReLU(xchannels[0], xchannels[1], 3, 2, 1, False, has_avg=False, has_bn=True, has_relu=True)\n                                         ,ConvBNReLU(xchannels[1], xchannels[2], 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n      last_channel_idx = 2\n    self.layers.append( nn.MaxPool2d(kernel_size=3, stride=2, padding=1) )\n    for stage, layer_blocks in enumerate(layers):\n      for iL in range(layer_blocks):\n        num_conv = block.num_conv \n        iCs      = self.xchannels[last_channel_idx:last_channel_idx+num_conv+1]\n        stride   = 2 if stage > 0 and iL == 0 else 1\n        module   = block(iCs, stride)\n        last_channel_idx += num_conv\n        self.xchannels[last_channel_idx] = module.out_dim\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iCs={:}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iCs, module.out_dim, stride)\n        if iL + 1 == xblocks[stage]: # reach the maximum depth\n          out_channel = module.out_dim\n          for iiL in range(iL+1, layer_blocks):\n            last_channel_idx += num_conv\n          self.xchannels[last_channel_idx] = module.out_dim\n          break\n    assert last_channel_idx + 1 == len(self.xchannels), \'{:} vs {:}\'.format(last_channel_idx, len(self.xchannels))\n    self.avgpool    = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(self.xchannels[-1], num_classes)\n    \n    self.apply(initialize_resnet)\n    if zero_init_residual:\n      for m in self.modules():\n        if isinstance(m, ResNetBasicblock):\n          nn.init.constant_(m.conv_b.bn.weight, 0)\n        elif isinstance(m, ResNetBottleneck):\n          nn.init.constant_(m.conv_1x4.bn.weight, 0)\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_infers/InferMobileNetV2.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\n# MobileNetV2: Inverted Residuals and Linear Bottlenecks, CVPR 2018\nfrom torch import nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import parse_channel_info\n\n\nclass ConvBNReLU(nn.Module):\n  def __init__(self, in_planes, out_planes, kernel_size, stride, groups, has_bn=True, has_relu=True):\n    super(ConvBNReLU, self).__init__()\n    padding = (kernel_size - 1) // 2\n    self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False)\n    if has_bn: self.bn = nn.BatchNorm2d(out_planes)\n    else     : self.bn = None\n    if has_relu: self.relu = nn.ReLU6(inplace=True)\n    else       : self.relu = None\n  \n  def forward(self, x):\n    out = self.conv( x )\n    if self.bn:   out = self.bn  ( out )\n    if self.relu: out = self.relu( out )\n    return out\n\n\nclass InvertedResidual(nn.Module):\n  def __init__(self, channels, stride, expand_ratio, additive):\n    super(InvertedResidual, self).__init__()\n    self.stride = stride\n    assert stride in [1, 2], \'invalid stride : {:}\'.format(stride)\n    assert len(channels) in [2, 3], \'invalid channels : {:}\'.format(channels)\n\n    if len(channels) == 2:\n      layers = []\n    else:\n      layers = [ConvBNReLU(channels[0], channels[1], 1, 1, 1)]\n    layers.extend([\n      # dw\n      ConvBNReLU(channels[-2], channels[-2], 3, stride, channels[-2]),\n      # pw-linear\n      ConvBNReLU(channels[-2], channels[-1], 1, 1, 1, True, False),\n    ])\n    self.conv = nn.Sequential(*layers)\n    self.additive = additive\n    if self.additive and channels[0] != channels[-1]:\n      self.shortcut = ConvBNReLU(channels[0], channels[-1], 1, 1, 1, True, False)\n    else:\n      self.shortcut = None\n    self.out_dim  = channels[-1]\n\n  def forward(self, x):\n    out = self.conv(x)\n    # if self.additive: return additive_func(out, x)\n    if self.shortcut: return out + self.shortcut(x)\n    else            : return out\n\n\nclass InferMobileNetV2(nn.Module):\n  def __init__(self, num_classes, xchannels, xblocks, dropout):\n    super(InferMobileNetV2, self).__init__()\n    block = InvertedResidual\n    inverted_residual_setting = [\n      # t, c,  n, s\n      [1, 16 , 1, 1],\n      [6, 24 , 2, 2],\n      [6, 32 , 3, 2],\n      [6, 64 , 4, 2],\n      [6, 96 , 3, 1],\n      [6, 160, 3, 2],\n      [6, 320, 1, 1],\n    ]\n    assert len(inverted_residual_setting) == len(xblocks), \'invalid number of layers : {:} vs {:}\'.format(len(inverted_residual_setting), len(xblocks))\n    for block_num, ir_setting in zip(xblocks, inverted_residual_setting):\n      assert block_num <= ir_setting[2], \'{:} vs {:}\'.format(block_num, ir_setting)\n    xchannels = parse_channel_info(xchannels)\n    #for i, chs in enumerate(xchannels):\n    #  if i > 0: assert chs[0] == xchannels[i-1][-1], \'Layer[{:}] is invalid {:} vs {:}\'.format(i, xchannels[i-1], chs)\n    self.xchannels = xchannels\n    self.message     = \'InferMobileNetV2 : xblocks={:}\'.format(xblocks)\n    # building first layer\n    features = [ConvBNReLU(xchannels[0][0], xchannels[0][1], 3, 2, 1)]\n    last_channel_idx = 1\n\n    # building inverted residual blocks\n    for stage, (t, c, n, s) in enumerate(inverted_residual_setting):\n      for i in range(n):\n        stride = s if i == 0 else 1\n        additv = True if i > 0 else False\n        module = block(self.xchannels[last_channel_idx], stride, t, additv)\n        features.append(module)\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, Cs={:}, stride={:}, expand={:}, original-C={:}"".format(stage, i, n, len(features), self.xchannels[last_channel_idx], stride, t, c)\n        last_channel_idx += 1\n        if i + 1 == xblocks[stage]:\n          out_channel = module.out_dim\n          for iiL in range(i+1, n):\n            last_channel_idx += 1\n          self.xchannels[last_channel_idx][0] = module.out_dim\n          break\n    # building last several layers\n    features.append(ConvBNReLU(self.xchannels[last_channel_idx][0], self.xchannels[last_channel_idx][1], 1, 1, 1))\n    assert last_channel_idx + 2 == len(self.xchannels), \'{:} vs {:}\'.format(last_channel_idx, len(self.xchannels))\n    # make it nn.Sequential\n    self.features = nn.Sequential(*features)\n\n    # building classifier\n    self.classifier = nn.Sequential(\n      nn.Dropout(dropout),\n      nn.Linear(self.xchannels[last_channel_idx][1], num_classes),\n    )\n\n    # weight initialization\n    self.apply( initialize_resnet )\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    features = self.features(inputs)\n    vectors  = features.mean([2, 3])\n    predicts = self.classifier(vectors)\n    return features, predicts\n'"
lib/models/shape_infers/InferTinyCellNet.py,1,"b""#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nfrom typing import List, Text, Any\nimport torch.nn as nn\nfrom models.cell_operations import ResNetBasicblock\nfrom models.cell_infers.cells import InferCell\n\n\nclass DynamicShapeTinyNet(nn.Module):\n\n  def __init__(self, channels: List[int], genotype: Any, num_classes: int):\n    super(DynamicShapeTinyNet, self).__init__()\n    self._channels = channels\n    if len(channels) % 3 != 2:\n      raise ValueError('invalid number of layers : {:}'.format(len(channels)))\n    self._num_stage = N = len(channels) // 3\n\n    self.stem = nn.Sequential(\n                    nn.Conv2d(3, channels[0], kernel_size=3, padding=1, bias=False),\n                    nn.BatchNorm2d(channels[0]))\n\n    # layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    c_prev = channels[0]\n    self.cells = nn.ModuleList()\n    for index, (c_curr, reduction) in enumerate(zip(channels, layer_reductions)):\n      if reduction : cell = ResNetBasicblock(c_prev, c_curr, 2, True)\n      else         : cell = InferCell(genotype, c_prev, c_curr, 1)\n      self.cells.append( cell )\n      c_prev = cell.out_dim\n    self._num_layer = len(self.cells)\n\n    self.lastact = nn.Sequential(nn.BatchNorm2d(c_prev), nn.ReLU(inplace=True))\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(c_prev, num_classes)\n\n  def get_message(self) -> Text:\n    string = self.extra_repr()\n    for i, cell in enumerate(self.cells):\n      string += '\\n {:02d}/{:02d} :: {:}'.format(i, len(self.cells), cell.extra_repr())\n    return string\n\n  def extra_repr(self):\n    return ('{name}(C={_channels}, N={_num_stage}, L={_num_layer})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, inputs):\n    feature = self.stem(inputs)\n    for i, cell in enumerate(self.cells):\n      feature = cell(feature)\n\n    out = self.lastact(feature)\n    out = self.global_pooling( out )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    return out, logits\n"""
lib/models/shape_infers/__init__.py,0,"b'#####################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019.01 #\n#####################################################\nfrom .InferCifarResNet_width import InferWidthCifarResNet\nfrom .InferImagenetResNet import InferImagenetResNet\nfrom .InferCifarResNet_depth import InferDepthCifarResNet\nfrom .InferCifarResNet import InferCifarResNet\nfrom .InferMobileNetV2 import InferMobileNetV2\nfrom .InferTinyCellNet import DynamicShapeTinyNet'"
lib/models/shape_infers/shared_utils.py,0,"b""def parse_channel_info(xstring):\n  blocks = xstring.split(' ')\n  blocks = [x.split('-') for x in blocks]\n  blocks = [[int(_) for _ in x] for x in blocks]\n  return blocks\n"""
lib/models/shape_searchs/SearchCifarResNet.py,21,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nfrom collections import OrderedDict\nfrom bisect import bisect_right\nimport torch.nn as nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import additive_func\nfrom .SoftSelect      import select2withP, ChannelWiseInter\nfrom .SoftSelect      import linear_forward\nfrom .SoftSelect      import get_width_choices\n\n\ndef get_depth_choices(nDepth, return_num):\n  if nDepth == 2:\n    choices = (1, 2)\n  elif nDepth == 3:\n    choices = (1, 2, 3)\n  elif nDepth > 3:\n    choices = list(range(1, nDepth+1, 2))\n    if choices[-1] < nDepth: choices.append(nDepth)\n  else:\n    raise ValueError(\'invalid nDepth : {:}\'.format(nDepth))\n  if return_num: return len(choices)\n  else         : return choices\n  \n\ndef conv_forward(inputs, conv, choices):\n  iC = conv.in_channels\n  fill_size = list(inputs.size())\n  fill_size[1] = iC - fill_size[1]\n  filled  = torch.zeros(fill_size, device=inputs.device)\n  xinputs = torch.cat((inputs, filled), dim=1)\n  outputs = conv(xinputs)\n  selecteds = [outputs[:,:oC] for oC in choices]\n  return selecteds\n\n\nclass ConvBNReLU(nn.Module):\n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    self.InShape  = None\n    self.OutShape = None\n    self.choices  = get_width_choices(nOut)\n    self.register_buffer(\'choices_tensor\', torch.Tensor( self.choices ))\n\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    #if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    #else       : self.bn  = None\n    self.has_bn = has_bn\n    self.BNs  = nn.ModuleList()\n    for i, _out in enumerate(self.choices):\n      self.BNs.append(nn.BatchNorm2d(_out))\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n    self.in_dim   = nIn\n    self.out_dim  = nOut\n    self.search_mode = \'basic\'\n\n  def get_flops(self, channels, check_range=True, divide=1):\n    iC, oC = channels\n    if check_range: assert iC <= self.conv.in_channels and oC <= self.conv.out_channels, \'{:} vs {:}  |  {:} vs {:}\'.format(iC, self.conv.in_channels, oC, self.conv.out_channels)\n    assert isinstance(self.InShape, tuple) and len(self.InShape) == 2, \'invalid in-shape : {:}\'.format(self.InShape)\n    assert isinstance(self.OutShape, tuple) and len(self.OutShape) == 2, \'invalid out-shape : {:}\'.format(self.OutShape)\n    #conv_per_position_flops = self.conv.kernel_size[0] * self.conv.kernel_size[1] * iC * oC / self.conv.groups\n    conv_per_position_flops = (self.conv.kernel_size[0] * self.conv.kernel_size[1] * 1.0 / self.conv.groups)\n    all_positions = self.OutShape[0] * self.OutShape[1]\n    flops = (conv_per_position_flops * all_positions / divide) * iC * oC\n    if self.conv.bias is not None: flops += all_positions / divide\n    return flops\n\n  def get_range(self):\n    return [self.choices]\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, index, prob = tuple_inputs\n    index, prob = torch.squeeze(index).tolist(), torch.squeeze(prob)\n    probability = torch.squeeze(probability)\n    assert len(index) == 2, \'invalid length : {:}\'.format(index)\n    # compute expected flop\n    #coordinates   = torch.arange(self.x_range[0], self.x_range[1]+1).type_as(probability)\n    expected_outC = (self.choices_tensor * probability).sum()\n    expected_flop = self.get_flops([expected_inC, expected_outC], False, 1e6)\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    # convolutional layer\n    out_convs = conv_forward(out, self.conv, [self.choices[i] for i in index])\n    out_bns   = [self.BNs[idx](out_conv) for idx, out_conv in zip(index, out_convs)]\n    # merge\n    out_channel = max([x.size(1) for x in out_bns])\n    outA = ChannelWiseInter(out_bns[0], out_channel)\n    outB = ChannelWiseInter(out_bns[1], out_channel)\n    out  = outA * prob[0] + outB * prob[1]\n    #out = additive_func(out_bns[0]*prob[0], out_bns[1]*prob[1])\n\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    return out, expected_outC, expected_flop\n\n  def basic_forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.has_bn:out= self.BNs[-1]( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    if self.InShape is None:\n      self.InShape  = (inputs.size(-2), inputs.size(-1))\n      self.OutShape = (out.size(-2)   , out.size(-1))\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  num_conv  = 2\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_a.get_range() + self.conv_b.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 3, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_a.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_b.get_flops([channels[1], channels[2]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_C = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_C = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_C = channels[0] * channels[-1] * self.conv_b.OutShape[0] * self.conv_b.OutShape[1]\n    return flop_A + flop_B + flop_C\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 2 and probs.size(0) == 2 and probability.size(0) == 2\n    out_a, expected_inC_a, expected_flop_a = self.conv_a( (inputs, expected_inC  , probability[0], indexes[0], probs[0]) )\n    out_b, expected_inC_b, expected_flop_b = self.conv_b( (out_a , expected_inC_a, probability[1], indexes[1], probs[1]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[1], indexes[1], probs[1]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_b)\n    return nn.functional.relu(out, inplace=True), expected_inC_b, sum([expected_flop_a, expected_flop_b, expected_flop_c])\n\n  def basic_forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, basicblock)\n    return nn.functional.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1, 1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes * self.expansion\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_1x1.get_range() + self.conv_3x3.get_range() + self.conv_1x4.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 4, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_1x1.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_3x3.get_flops([channels[1], channels[2]])\n    flop_C = self.conv_1x4.get_flops([channels[2], channels[3]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_D = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_D = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_D = channels[0] * channels[-1] * self.conv_1x4.OutShape[0] * self.conv_1x4.OutShape[1]\n    return flop_A + flop_B + flop_C + flop_D\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def basic_forward(self, inputs):\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, bottleneck)\n    return nn.functional.relu(out, inplace=True)\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 3 and probs.size(0) == 3 and probability.size(0) == 3\n    out_1x1, expected_inC_1x1, expected_flop_1x1 = self.conv_1x1( (inputs, expected_inC    , probability[0], indexes[0], probs[0]) )\n    out_3x3, expected_inC_3x3, expected_flop_3x3 = self.conv_3x3( (out_1x1,expected_inC_1x1, probability[1], indexes[1], probs[1]) )\n    out_1x4, expected_inC_1x4, expected_flop_1x4 = self.conv_1x4( (out_3x3,expected_inC_3x3, probability[2], indexes[2], probs[2]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[2], indexes[2], probs[2]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_1x4)\n    return nn.functional.relu(out, inplace=True), expected_inC_1x4, sum([expected_flop_1x1, expected_flop_3x3, expected_flop_1x4, expected_flop_c])\n\n\nclass SearchShapeCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, num_classes):\n    super(SearchShapeCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n\n    self.message      = \'SearchShapeCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes  = num_classes\n    self.channels     = [16]\n    self.layers       = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    self.InShape      = None\n    self.depth_info   = OrderedDict()\n    self.depth_at_i   = OrderedDict()\n    for stage in range(3):\n      cur_block_choices = get_depth_choices(layer_blocks, False)\n      assert cur_block_choices[-1] == layer_blocks, \'stage={:}, {:} vs {:}\'.format(stage, cur_block_choices, layer_blocks)\n      self.message += ""\\nstage={:} ::: depth-block-choices={:} for {:} blocks."".format(stage, cur_block_choices, layer_blocks)\n      block_choices, xstart = [], len(self.layers)\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n        # added for depth\n        layer_index = len(self.layers) - 1\n        if iL + 1 in cur_block_choices: block_choices.append( layer_index )\n        if iL + 1 == layer_blocks:\n          self.depth_info[layer_index] = {\'choices\': block_choices,\n                                          \'stage\'  : stage,\n                                          \'xstart\' : xstart}\n    self.depth_info_list = []\n    for xend, info in self.depth_info.items():\n      self.depth_info_list.append( (xend, info) )\n      xstart, xstage = info[\'xstart\'], info[\'stage\']\n      for ilayer in range(xstart, xend+1):\n        idx = bisect_right(info[\'choices\'], ilayer-1)\n        self.depth_at_i[ilayer] = (xstage, idx)\n\n    self.avgpool     = nn.AvgPool2d(8)\n    self.classifier  = nn.Linear(module.out_dim, num_classes)\n    self.InShape     = None\n    self.tau         = -1\n    self.search_mode = \'basic\'\n    #assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n    \n    # parameters for width\n    self.Ranges = []\n    self.layer2indexRange = []\n    for i, layer in enumerate(self.layers):\n      start_index = len(self.Ranges)\n      self.Ranges += layer.get_range()\n      self.layer2indexRange.append( (start_index, len(self.Ranges)) )\n    assert len(self.Ranges) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(len(self.Ranges) + 1, depth)\n\n    self.register_parameter(\'width_attentions\', nn.Parameter(torch.Tensor(len(self.Ranges), get_width_choices(None))))\n    self.register_parameter(\'depth_attentions\', nn.Parameter(torch.Tensor(3, get_depth_choices(layer_blocks, True))))\n    nn.init.normal_(self.width_attentions, 0, 0.01)\n    nn.init.normal_(self.depth_attentions, 0, 0.01)\n    self.apply(initialize_resnet)\n\n  def arch_parameters(self, LR=None):\n    if LR is None:\n      return [self.width_attentions, self.depth_attentions]\n    else:\n      return [\n               {""params"": self.width_attentions, ""lr"": LR},\n               {""params"": self.depth_attentions, ""lr"": LR},\n             ]\n\n  def base_parameters(self):\n    return list(self.layers.parameters()) + list(self.avgpool.parameters()) + list(self.classifier.parameters())\n\n  def get_flop(self, mode, config_dict, extra_info):\n    if config_dict is not None: config_dict = config_dict.copy()\n    # select channels \n    channels = [3]\n    for i, weight in enumerate(self.width_attentions):\n      if mode == \'genotype\':\n        with torch.no_grad():\n          probe = nn.functional.softmax(weight, dim=0)\n          C = self.Ranges[i][ torch.argmax(probe).item() ]\n      elif mode == \'max\':\n        C = self.Ranges[i][-1]\n      elif mode == \'fix\':\n        C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n      elif mode == \'random\':\n        assert isinstance(extra_info, float), \'invalid extra_info : {:}\'.format(extra_info)\n        with torch.no_grad():\n          prob = nn.functional.softmax(weight, dim=0)\n          approximate_C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n          for j in range(prob.size(0)):\n            prob[j] = 1 / (abs(j - (approximate_C-self.Ranges[i][j])) + 0.2)\n          C = self.Ranges[i][ torch.multinomial(prob, 1, False).item() ]\n      else:\n        raise ValueError(\'invalid mode : {:}\'.format(mode))\n      channels.append( C )\n    # select depth\n    if mode == \'genotype\':\n      with torch.no_grad():\n        depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n        choices = torch.argmax(depth_probs, dim=1).cpu().tolist()\n    elif mode == \'max\' or mode == \'fix\':\n      choices = [depth_probs.size(1)-1 for _ in range(depth_probs.size(0))]\n    elif mode == \'random\':\n      with torch.no_grad():\n        depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n        choices = torch.multinomial(depth_probs, 1, False).cpu().tolist()\n    else:\n      raise ValueError(\'invalid mode : {:}\'.format(mode))\n    selected_layers = []\n    for choice, xvalue in zip(choices, self.depth_info_list):\n      xtemp = xvalue[1][\'choices\'][choice] - xvalue[1][\'xstart\'] + 1\n      selected_layers.append(xtemp)\n    flop = 0\n    for i, layer in enumerate(self.layers):\n      s, e = self.layer2indexRange[i]\n      xchl = tuple( channels[s:e+1] )\n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        if xatti <= choices[xstagei]: # leave this depth\n          flop+= layer.get_flops(xchl)\n        else:\n          flop+= 0 # do not use this layer\n      else:\n        flop+= layer.get_flops(xchl)\n    # the last fc layer\n    flop += channels[-1] * self.classifier.out_features\n    if config_dict is None:\n      return flop / 1e6\n    else:\n      config_dict[\'xchannels\']  = channels\n      config_dict[\'xblocks\']    = selected_layers\n      config_dict[\'super_type\'] = \'infer-shape\'\n      config_dict[\'estimated_FLOP\'] = flop / 1e6\n      return flop / 1e6, config_dict\n\n  def get_arch_info(self):\n    string = ""for depth and width, there are {:} + {:} attention probabilities."".format(len(self.depth_attentions), len(self.width_attentions))\n    string+= \'\\n{:}\'.format(self.depth_info)\n    discrepancy = []\n    with torch.no_grad():\n      for i, att in enumerate(self.depth_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.depth_attentions), \' \'.join(prob))\n        logt = [\'{:.4f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:17s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || discrepancy={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n      string += \'\\n-----------------------------------------------\'\n      for i, att in enumerate(self.width_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.width_attentions), \' \'.join(prob))\n        logt = [\'{:.3f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:52s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || dis={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n    return string, discrepancy\n\n  def set_tau(self, tau_max, tau_min, epoch_ratio):\n    assert epoch_ratio >= 0 and epoch_ratio <= 1, \'invalid epoch-ratio : {:}\'.format(epoch_ratio)\n    tau = tau_min + (tau_max-tau_min) * (1 + math.cos(math.pi * epoch_ratio)) / 2\n    self.tau = tau\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, inputs):\n    flop_width_probs = nn.functional.softmax(self.width_attentions, dim=1)\n    flop_depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n    flop_depth_probs = torch.flip( torch.cumsum( torch.flip(flop_depth_probs, [1]), 1 ), [1] )\n    selected_widths, selected_width_probs = select2withP(self.width_attentions, self.tau)\n    selected_depth_probs = select2withP(self.depth_attentions, self.tau, True)\n    with torch.no_grad():\n      selected_widths = selected_widths.cpu()\n\n    x, last_channel_idx, expected_inC, flops = inputs, 0, 3, []\n    feature_maps = []\n    for i, layer in enumerate(self.layers):\n      selected_w_index = selected_widths     [last_channel_idx: last_channel_idx+layer.num_conv]\n      selected_w_probs = selected_width_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      layer_prob       = flop_width_probs    [last_channel_idx: last_channel_idx+layer.num_conv]\n      x, expected_inC, expected_flop = layer( (x, expected_inC, layer_prob, selected_w_index, selected_w_probs) )\n      feature_maps.append( x )\n      last_channel_idx += layer.num_conv\n      if i in self.depth_info: # aggregate the information\n        choices = self.depth_info[i][\'choices\']\n        xstagei = self.depth_info[i][\'stage\']\n        #print (\'iL={:}, choices={:}, stage={:}, probs={:}\'.format(i, choices, xstagei, selected_depth_probs[xstagei].cpu().tolist()))\n        #for A, W in zip(choices, selected_depth_probs[xstagei]):\n        #  print(\'Size = {:}, W = {:}\'.format(feature_maps[A].size(), W))\n        possible_tensors = []\n        max_C = max( feature_maps[A].size(1) for A in choices )\n        for tempi, A in enumerate(choices):\n          xtensor = ChannelWiseInter(feature_maps[A], max_C)\n          #drop_ratio = 1-(tempi+1.0)/len(choices)\n          #xtensor = drop_path(xtensor, drop_ratio)\n          possible_tensors.append( xtensor )\n        weighted_sum = sum( xtensor * W for xtensor, W in zip(possible_tensors, selected_depth_probs[xstagei]) )\n        x = weighted_sum\n        \n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        x_expected_flop = flop_depth_probs[xstagei, xatti] * expected_flop\n      else:\n        x_expected_flop = expected_flop\n      flops.append( x_expected_flop )\n    flops.append( expected_inC * (self.classifier.out_features*1.0/1e6) )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = linear_forward(features, self.classifier)\n    return logits, torch.stack( [sum(flops)] )\n\n  def basic_forward(self, inputs):\n    if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1))\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_searchs/SearchCifarResNet_depth.py,10,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nfrom collections import OrderedDict\nfrom bisect import bisect_right\nimport torch.nn as nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import additive_func\nfrom .SoftSelect      import select2withP, ChannelWiseInter\nfrom .SoftSelect      import linear_forward\nfrom .SoftSelect      import get_width_choices\n\n\ndef get_depth_choices(nDepth, return_num):\n  if nDepth == 2:\n    choices = (1, 2)\n  elif nDepth == 3:\n    choices = (1, 2, 3)\n  elif nDepth > 3:\n    choices = list(range(1, nDepth+1, 2))\n    if choices[-1] < nDepth: choices.append(nDepth)\n  else:\n    raise ValueError(\'invalid nDepth : {:}\'.format(nDepth))\n  if return_num: return len(choices)\n  else         : return choices\n\n\n\nclass ConvBNReLU(nn.Module):\n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    self.InShape  = None\n    self.OutShape = None\n    self.choices  = get_width_choices(nOut)\n    self.register_buffer(\'choices_tensor\', torch.Tensor( self.choices ))\n\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    else       : self.bn  = None\n    if has_relu: self.relu = nn.ReLU(inplace=False)\n    else       : self.relu = None\n    self.in_dim   = nIn\n    self.out_dim  = nOut\n\n  def get_flops(self, divide=1):\n    iC, oC = self.in_dim, self.out_dim\n    assert iC <= self.conv.in_channels and oC <= self.conv.out_channels, \'{:} vs {:}  |  {:} vs {:}\'.format(iC, self.conv.in_channels, oC, self.conv.out_channels)\n    assert isinstance(self.InShape, tuple) and len(self.InShape) == 2, \'invalid in-shape : {:}\'.format(self.InShape)\n    assert isinstance(self.OutShape, tuple) and len(self.OutShape) == 2, \'invalid out-shape : {:}\'.format(self.OutShape)\n    #conv_per_position_flops = self.conv.kernel_size[0] * self.conv.kernel_size[1] * iC * oC / self.conv.groups\n    conv_per_position_flops = (self.conv.kernel_size[0] * self.conv.kernel_size[1] * 1.0 / self.conv.groups)\n    all_positions = self.OutShape[0] * self.OutShape[1]\n    flops = (conv_per_position_flops * all_positions / divide) * iC * oC\n    if self.conv.bias is not None: flops += all_positions / divide\n    return flops\n\n  def forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.bn  : out = self.bn( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    if self.InShape is None:\n      self.InShape  = (inputs.size(-2), inputs.size(-1))\n      self.OutShape = (out.size(-2)   , out.size(-1))\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  num_conv  = 2\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes\n    self.search_mode = \'basic\'\n\n  def get_flops(self, divide=1):\n    flop_A = self.conv_a.get_flops(divide)\n    flop_B = self.conv_b.get_flops(divide)\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_C = self.downsample.get_flops(divide)\n    else:\n      flop_C = 0\n    return flop_A + flop_B + flop_C\n\n  def forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, basicblock)\n    return nn.functional.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1, 1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes * self.expansion\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_1x1.get_range() + self.conv_3x3.get_range() + self.conv_1x4.get_range()\n\n  def get_flops(self, divide):\n    flop_A = self.conv_1x1.get_flops(divide)\n    flop_B = self.conv_3x3.get_flops(divide)\n    flop_C = self.conv_1x4.get_flops(divide)\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_D = self.downsample.get_flops(divide)\n    else:\n      flop_D = 0\n    return flop_A + flop_B + flop_C + flop_D\n\n  def forward(self, inputs):\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, bottleneck)\n    return nn.functional.relu(out, inplace=True)\n\n\nclass SearchDepthCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, num_classes):\n    super(SearchDepthCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n\n    self.message      = \'SearchShapeCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes  = num_classes\n    self.channels     = [16]\n    self.layers       = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    self.InShape      = None\n    self.depth_info   = OrderedDict()\n    self.depth_at_i   = OrderedDict()\n    for stage in range(3):\n      cur_block_choices = get_depth_choices(layer_blocks, False)\n      assert cur_block_choices[-1] == layer_blocks, \'stage={:}, {:} vs {:}\'.format(stage, cur_block_choices, layer_blocks)\n      self.message += ""\\nstage={:} ::: depth-block-choices={:} for {:} blocks."".format(stage, cur_block_choices, layer_blocks)\n      block_choices, xstart = [], len(self.layers)\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n        # added for depth\n        layer_index = len(self.layers) - 1\n        if iL + 1 in cur_block_choices: block_choices.append( layer_index )\n        if iL + 1 == layer_blocks:\n          self.depth_info[layer_index] = {\'choices\': block_choices,\n                                          \'stage\'  : stage,\n                                          \'xstart\' : xstart}\n    self.depth_info_list = []\n    for xend, info in self.depth_info.items():\n      self.depth_info_list.append( (xend, info) )\n      xstart, xstage = info[\'xstart\'], info[\'stage\']\n      for ilayer in range(xstart, xend+1):\n        idx = bisect_right(info[\'choices\'], ilayer-1)\n        self.depth_at_i[ilayer] = (xstage, idx)\n\n    self.avgpool     = nn.AvgPool2d(8)\n    self.classifier  = nn.Linear(module.out_dim, num_classes)\n    self.InShape     = None\n    self.tau         = -1\n    self.search_mode = \'basic\'\n    #assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n    \n\n    self.register_parameter(\'depth_attentions\', nn.Parameter(torch.Tensor(3, get_depth_choices(layer_blocks, True))))\n    nn.init.normal_(self.depth_attentions, 0, 0.01)\n    self.apply(initialize_resnet)\n\n  def arch_parameters(self):\n    return [self.depth_attentions]\n\n  def base_parameters(self):\n    return list(self.layers.parameters()) + list(self.avgpool.parameters()) + list(self.classifier.parameters())\n\n  def get_flop(self, mode, config_dict, extra_info):\n    if config_dict is not None: config_dict = config_dict.copy()\n    # select depth\n    if mode == \'genotype\':\n      with torch.no_grad():\n        depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n        choices = torch.argmax(depth_probs, dim=1).cpu().tolist()\n    elif mode == \'max\':\n      choices = [depth_probs.size(1)-1 for _ in range(depth_probs.size(0))]\n    elif mode == \'random\':\n      with torch.no_grad():\n        depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n        choices = torch.multinomial(depth_probs, 1, False).cpu().tolist()\n    else:\n      raise ValueError(\'invalid mode : {:}\'.format(mode))\n    selected_layers = []\n    for choice, xvalue in zip(choices, self.depth_info_list):\n      xtemp = xvalue[1][\'choices\'][choice] - xvalue[1][\'xstart\'] + 1\n      selected_layers.append(xtemp)\n    flop = 0\n    for i, layer in enumerate(self.layers):\n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        if xatti <= choices[xstagei]: # leave this depth\n          flop+= layer.get_flops()\n        else:\n          flop+= 0 # do not use this layer\n      else:\n        flop+= layer.get_flops()\n    # the last fc layer\n    flop += self.classifier.in_features * self.classifier.out_features\n    if config_dict is None:\n      return flop / 1e6\n    else:\n      config_dict[\'xblocks\']    = selected_layers\n      config_dict[\'super_type\'] = \'infer-depth\'\n      config_dict[\'estimated_FLOP\'] = flop / 1e6\n      return flop / 1e6, config_dict\n\n  def get_arch_info(self):\n    string = ""for depth, there are {:} attention probabilities."".format(len(self.depth_attentions))\n    string+= \'\\n{:}\'.format(self.depth_info)\n    discrepancy = []\n    with torch.no_grad():\n      for i, att in enumerate(self.depth_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.depth_attentions), \' \'.join(prob))\n        logt = [\'{:.4f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:17s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || discrepancy={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n    return string, discrepancy\n\n  def set_tau(self, tau_max, tau_min, epoch_ratio):\n    assert epoch_ratio >= 0 and epoch_ratio <= 1, \'invalid epoch-ratio : {:}\'.format(epoch_ratio)\n    tau = tau_min + (tau_max-tau_min) * (1 + math.cos(math.pi * epoch_ratio)) / 2\n    self.tau = tau\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, inputs):\n    flop_depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n    flop_depth_probs = torch.flip( torch.cumsum( torch.flip(flop_depth_probs, [1]), 1 ), [1] )\n    selected_depth_probs = select2withP(self.depth_attentions, self.tau, True)\n\n    x, flops = inputs, []\n    feature_maps = []\n    for i, layer in enumerate(self.layers):\n      layer_i = layer( x )\n      feature_maps.append( layer_i )\n      if i in self.depth_info: # aggregate the information\n        choices = self.depth_info[i][\'choices\']\n        xstagei = self.depth_info[i][\'stage\']\n        possible_tensors = []\n        for tempi, A in enumerate(choices):\n          xtensor = feature_maps[A]\n          possible_tensors.append( xtensor )\n        weighted_sum = sum( xtensor * W for xtensor, W in zip(possible_tensors, selected_depth_probs[xstagei]) )\n        x = weighted_sum\n      else:\n        x = layer_i\n       \n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        #print (\'layer-{:03d}, stage={:}, att={:}, prob={:}, flop={:}\'.format(i, xstagei, xatti, flop_depth_probs[xstagei, xatti].item(), layer.get_flops(1e6)))\n        x_expected_flop = flop_depth_probs[xstagei, xatti] * layer.get_flops(1e6)\n      else:\n        x_expected_flop = layer.get_flops(1e6)\n      flops.append( x_expected_flop )\n    flops.append( (self.classifier.in_features * self.classifier.out_features*1.0/1e6) )\n\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = linear_forward(features, self.classifier)\n    return logits, torch.stack( [sum(flops)] )\n\n  def basic_forward(self, inputs):\n    if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1))\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_searchs/SearchCifarResNet_width.py,15,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nimport torch.nn as nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import additive_func\nfrom .SoftSelect      import select2withP, ChannelWiseInter\nfrom .SoftSelect      import linear_forward\nfrom .SoftSelect      import get_width_choices as get_choices\n\n\ndef conv_forward(inputs, conv, choices):\n  iC = conv.in_channels\n  fill_size = list(inputs.size())\n  fill_size[1] = iC - fill_size[1]\n  filled  = torch.zeros(fill_size, device=inputs.device)\n  xinputs = torch.cat((inputs, filled), dim=1)\n  outputs = conv(xinputs)\n  selecteds = [outputs[:,:oC] for oC in choices]\n  return selecteds\n\n\nclass ConvBNReLU(nn.Module):\n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    self.InShape  = None\n    self.OutShape = None\n    self.choices  = get_choices(nOut)\n    self.register_buffer(\'choices_tensor\', torch.Tensor( self.choices ))\n\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    #if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    #else       : self.bn  = None\n    self.has_bn = has_bn\n    self.BNs  = nn.ModuleList()\n    for i, _out in enumerate(self.choices):\n      self.BNs.append(nn.BatchNorm2d(_out))\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n    self.in_dim   = nIn\n    self.out_dim  = nOut\n    self.search_mode = \'basic\'\n\n  def get_flops(self, channels, check_range=True, divide=1):\n    iC, oC = channels\n    if check_range: assert iC <= self.conv.in_channels and oC <= self.conv.out_channels, \'{:} vs {:}  |  {:} vs {:}\'.format(iC, self.conv.in_channels, oC, self.conv.out_channels)\n    assert isinstance(self.InShape, tuple) and len(self.InShape) == 2, \'invalid in-shape : {:}\'.format(self.InShape)\n    assert isinstance(self.OutShape, tuple) and len(self.OutShape) == 2, \'invalid out-shape : {:}\'.format(self.OutShape)\n    #conv_per_position_flops = self.conv.kernel_size[0] * self.conv.kernel_size[1] * iC * oC / self.conv.groups\n    conv_per_position_flops = (self.conv.kernel_size[0] * self.conv.kernel_size[1] * 1.0 / self.conv.groups)\n    all_positions = self.OutShape[0] * self.OutShape[1]\n    flops = (conv_per_position_flops * all_positions / divide) * iC * oC\n    if self.conv.bias is not None: flops += all_positions / divide\n    return flops\n\n  def get_range(self):\n    return [self.choices]\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, index, prob = tuple_inputs\n    index, prob = torch.squeeze(index).tolist(), torch.squeeze(prob)\n    probability = torch.squeeze(probability)\n    assert len(index) == 2, \'invalid length : {:}\'.format(index)\n    # compute expected flop\n    #coordinates   = torch.arange(self.x_range[0], self.x_range[1]+1).type_as(probability)\n    expected_outC = (self.choices_tensor * probability).sum()\n    expected_flop = self.get_flops([expected_inC, expected_outC], False, 1e6)\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    # convolutional layer\n    out_convs = conv_forward(out, self.conv, [self.choices[i] for i in index])\n    out_bns   = [self.BNs[idx](out_conv) for idx, out_conv in zip(index, out_convs)]\n    # merge\n    out_channel = max([x.size(1) for x in out_bns])\n    outA = ChannelWiseInter(out_bns[0], out_channel)\n    outB = ChannelWiseInter(out_bns[1], out_channel)\n    out  = outA * prob[0] + outB * prob[1]\n    #out = additive_func(out_bns[0]*prob[0], out_bns[1]*prob[1])\n\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    return out, expected_outC, expected_flop\n\n  def basic_forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.has_bn:out= self.BNs[-1]( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    if self.InShape is None:\n      self.InShape  = (inputs.size(-2), inputs.size(-1))\n      self.OutShape = (out.size(-2)   , out.size(-1))\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  num_conv  = 2\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_a.get_range() + self.conv_b.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 3, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_a.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_b.get_flops([channels[1], channels[2]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_C = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_C = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_C = channels[0] * channels[-1] * self.conv_b.OutShape[0] * self.conv_b.OutShape[1]\n    return flop_A + flop_B + flop_C\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 2 and probs.size(0) == 2 and probability.size(0) == 2\n    out_a, expected_inC_a, expected_flop_a = self.conv_a( (inputs, expected_inC  , probability[0], indexes[0], probs[0]) )\n    out_b, expected_inC_b, expected_flop_b = self.conv_b( (out_a , expected_inC_a, probability[1], indexes[1], probs[1]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[1], indexes[1], probs[1]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_b)\n    return nn.functional.relu(out, inplace=True), expected_inC_b, sum([expected_flop_a, expected_flop_b, expected_flop_c])\n\n  def basic_forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, basicblock)\n    return nn.functional.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1, 1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes * self.expansion\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_1x1.get_range() + self.conv_3x3.get_range() + self.conv_1x4.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 4, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_1x1.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_3x3.get_flops([channels[1], channels[2]])\n    flop_C = self.conv_1x4.get_flops([channels[2], channels[3]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_D = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_D = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_D = channels[0] * channels[-1] * self.conv_1x4.OutShape[0] * self.conv_1x4.OutShape[1]\n    return flop_A + flop_B + flop_C + flop_D\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def basic_forward(self, inputs):\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, bottleneck)\n    return nn.functional.relu(out, inplace=True)\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 3 and probs.size(0) == 3 and probability.size(0) == 3\n    out_1x1, expected_inC_1x1, expected_flop_1x1 = self.conv_1x1( (inputs, expected_inC    , probability[0], indexes[0], probs[0]) )\n    out_3x3, expected_inC_3x3, expected_flop_3x3 = self.conv_3x3( (out_1x1,expected_inC_1x1, probability[1], indexes[1], probs[1]) )\n    out_1x4, expected_inC_1x4, expected_flop_1x4 = self.conv_1x4( (out_3x3,expected_inC_3x3, probability[2], indexes[2], probs[2]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[2], indexes[2], probs[2]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_1x4)\n    return nn.functional.relu(out, inplace=True), expected_inC_1x4, sum([expected_flop_1x1, expected_flop_3x3, expected_flop_1x4, expected_flop_c])\n\n\nclass SearchWidthCifarResNet(nn.Module):\n\n  def __init__(self, block_name, depth, num_classes):\n    super(SearchWidthCifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'ResNetBasicblock\':\n      block = ResNetBasicblock\n      assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n      layer_blocks = (depth - 2) // 6\n    elif block_name == \'ResNetBottleneck\':\n      block = ResNetBottleneck\n      assert (depth - 2) % 9 == 0, \'depth should be one of 164\'\n      layer_blocks = (depth - 2) // 9\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n\n    self.message     = \'SearchWidthCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes = num_classes\n    self.channels    = [16]\n    self.layers      = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    self.InShape     = None\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n  \n    self.avgpool     = nn.AvgPool2d(8)\n    self.classifier  = nn.Linear(module.out_dim, num_classes)\n    self.InShape     = None\n    self.tau         = -1\n    self.search_mode = \'basic\'\n    #assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n    \n    # parameters for width\n    self.Ranges = []\n    self.layer2indexRange = []\n    for i, layer in enumerate(self.layers):\n      start_index = len(self.Ranges)\n      self.Ranges += layer.get_range()\n      self.layer2indexRange.append( (start_index, len(self.Ranges)) )\n    assert len(self.Ranges) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(len(self.Ranges) + 1, depth)\n\n    self.register_parameter(\'width_attentions\', nn.Parameter(torch.Tensor(len(self.Ranges), get_choices(None))))\n    nn.init.normal_(self.width_attentions, 0, 0.01)\n    self.apply(initialize_resnet)\n\n  def arch_parameters(self):\n    return [self.width_attentions]\n\n  def base_parameters(self):\n    return list(self.layers.parameters()) + list(self.avgpool.parameters()) + list(self.classifier.parameters())\n\n  def get_flop(self, mode, config_dict, extra_info):\n    if config_dict is not None: config_dict = config_dict.copy()\n    #weights = [F.softmax(x, dim=0) for x in self.width_attentions]\n    channels = [3]\n    for i, weight in enumerate(self.width_attentions):\n      if mode == \'genotype\':\n        with torch.no_grad():\n          probe = nn.functional.softmax(weight, dim=0)\n          C = self.Ranges[i][ torch.argmax(probe).item() ]\n      elif mode == \'max\':\n        C = self.Ranges[i][-1]\n      elif mode == \'fix\':\n        C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n      elif mode == \'random\':\n        assert isinstance(extra_info, float), \'invalid extra_info : {:}\'.format(extra_info)\n        with torch.no_grad():\n          prob = nn.functional.softmax(weight, dim=0)\n          approximate_C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n          for j in range(prob.size(0)):\n            prob[j] = 1 / (abs(j - (approximate_C-self.Ranges[i][j])) + 0.2)\n          C = self.Ranges[i][ torch.multinomial(prob, 1, False).item() ]\n      else:\n        raise ValueError(\'invalid mode : {:}\'.format(mode))\n      channels.append( C )\n    flop = 0\n    for i, layer in enumerate(self.layers):\n      s, e = self.layer2indexRange[i]\n      xchl = tuple( channels[s:e+1] )\n      flop+= layer.get_flops(xchl)\n    # the last fc layer\n    flop += channels[-1] * self.classifier.out_features\n    if config_dict is None:\n      return flop / 1e6\n    else:\n      config_dict[\'xchannels\']  = channels\n      config_dict[\'super_type\'] = \'infer-width\'\n      config_dict[\'estimated_FLOP\'] = flop / 1e6\n      return flop / 1e6, config_dict\n\n  def get_arch_info(self):\n    string = ""for width, there are {:} attention probabilities."".format(len(self.width_attentions))\n    discrepancy = []\n    with torch.no_grad():\n      for i, att in enumerate(self.width_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.width_attentions), \' \'.join(prob))\n        logt = [\'{:.3f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:52s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || dis={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n    return string, discrepancy\n\n  def set_tau(self, tau_max, tau_min, epoch_ratio):\n    assert epoch_ratio >= 0 and epoch_ratio <= 1, \'invalid epoch-ratio : {:}\'.format(epoch_ratio)\n    tau = tau_min + (tau_max-tau_min) * (1 + math.cos(math.pi * epoch_ratio)) / 2\n    self.tau = tau\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, inputs):\n    flop_probs = nn.functional.softmax(self.width_attentions, dim=1)\n    selected_widths, selected_probs = select2withP(self.width_attentions, self.tau)\n    with torch.no_grad():\n      selected_widths = selected_widths.cpu()\n\n    x, last_channel_idx, expected_inC, flops = inputs, 0, 3, []\n    for i, layer in enumerate(self.layers):\n      selected_w_index = selected_widths[last_channel_idx: last_channel_idx+layer.num_conv]\n      selected_w_probs = selected_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      layer_prob       = flop_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      x, expected_inC, expected_flop = layer( (x, expected_inC, layer_prob, selected_w_index, selected_w_probs) )\n      last_channel_idx += layer.num_conv\n      flops.append( expected_flop )\n    flops.append( expected_inC * (self.classifier.out_features*1.0/1e6) )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = linear_forward(features, self.classifier)\n    return logits, torch.stack( [sum(flops)] )\n\n  def basic_forward(self, inputs):\n    if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1))\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_searchs/SearchImagenetResNet.py,17,"b'import math, torch\nfrom collections import OrderedDict\nfrom bisect import bisect_right\nimport torch.nn as nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import additive_func\nfrom .SoftSelect      import select2withP, ChannelWiseInter\nfrom .SoftSelect      import linear_forward\nfrom .SoftSelect      import get_width_choices\n\n\ndef get_depth_choices(layers):\n  min_depth = min(layers)\n  info = {\'num\': min_depth}\n  for i, depth in enumerate(layers):\n    choices = []\n    for j in range(1, min_depth+1):\n      choices.append( int( float(depth)*j/min_depth ) )\n    info[i] = choices\n  return info\n\n\ndef conv_forward(inputs, conv, choices):\n  iC = conv.in_channels\n  fill_size = list(inputs.size())\n  fill_size[1] = iC - fill_size[1]\n  filled  = torch.zeros(fill_size, device=inputs.device)\n  xinputs = torch.cat((inputs, filled), dim=1)\n  outputs = conv(xinputs)\n  selecteds = [outputs[:,:oC] for oC in choices]\n  return selecteds\n\n\nclass ConvBNReLU(nn.Module):\n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu, last_max_pool=False):\n    super(ConvBNReLU, self).__init__()\n    self.InShape  = None\n    self.OutShape = None\n    self.choices  = get_width_choices(nOut)\n    self.register_buffer(\'choices_tensor\', torch.Tensor( self.choices ))\n\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    #if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    #else       : self.bn  = None\n    self.has_bn = has_bn\n    self.BNs  = nn.ModuleList()\n    for i, _out in enumerate(self.choices):\n      self.BNs.append(nn.BatchNorm2d(_out))\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n  \n    if last_max_pool: self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n    else            : self.maxpool = None\n    self.in_dim   = nIn\n    self.out_dim  = nOut\n    self.search_mode = \'basic\'\n\n  def get_flops(self, channels, check_range=True, divide=1):\n    iC, oC = channels\n    if check_range: assert iC <= self.conv.in_channels and oC <= self.conv.out_channels, \'{:} vs {:}  |  {:} vs {:}\'.format(iC, self.conv.in_channels, oC, self.conv.out_channels)\n    assert isinstance(self.InShape, tuple) and len(self.InShape) == 2, \'invalid in-shape : {:}\'.format(self.InShape)\n    assert isinstance(self.OutShape, tuple) and len(self.OutShape) == 2, \'invalid out-shape : {:}\'.format(self.OutShape)\n    #conv_per_position_flops = self.conv.kernel_size[0] * self.conv.kernel_size[1] * iC * oC / self.conv.groups\n    conv_per_position_flops = (self.conv.kernel_size[0] * self.conv.kernel_size[1] * 1.0 / self.conv.groups)\n    all_positions = self.OutShape[0] * self.OutShape[1]\n    flops = (conv_per_position_flops * all_positions / divide) * iC * oC\n    if self.conv.bias is not None: flops += all_positions / divide\n    return flops\n\n  def get_range(self):\n    return [self.choices]\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, index, prob = tuple_inputs\n    index, prob = torch.squeeze(index).tolist(), torch.squeeze(prob)\n    probability = torch.squeeze(probability)\n    assert len(index) == 2, \'invalid length : {:}\'.format(index)\n    # compute expected flop\n    #coordinates   = torch.arange(self.x_range[0], self.x_range[1]+1).type_as(probability)\n    expected_outC = (self.choices_tensor * probability).sum()\n    expected_flop = self.get_flops([expected_inC, expected_outC], False, 1e6)\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    # convolutional layer\n    out_convs = conv_forward(out, self.conv, [self.choices[i] for i in index])\n    out_bns   = [self.BNs[idx](out_conv) for idx, out_conv in zip(index, out_convs)]\n    # merge\n    out_channel = max([x.size(1) for x in out_bns])\n    outA = ChannelWiseInter(out_bns[0], out_channel)\n    outB = ChannelWiseInter(out_bns[1], out_channel)\n    out  = outA * prob[0] + outB * prob[1]\n    #out = additive_func(out_bns[0]*prob[0], out_bns[1]*prob[1])\n\n    if self.relu   : out = self.relu( out )\n    if self.maxpool: out = self.maxpool(out)\n    return out, expected_outC, expected_flop\n\n  def basic_forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.has_bn:out= self.BNs[-1]( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    if self.InShape is None:\n      self.InShape  = (inputs.size(-2), inputs.size(-1))\n      self.OutShape = (out.size(-2)   , out.size(-1))\n    if self.maxpool: out = self.maxpool(out)\n    return out\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  num_conv  = 2\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBasicblock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_a = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_b = ConvBNReLU(  planes, planes, 3,      1, 1, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=True, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True, has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_a.get_range() + self.conv_b.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 3, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_a.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_b.get_flops([channels[1], channels[2]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_C = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_C = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_C = channels[0] * channels[-1] * self.conv_b.OutShape[0] * self.conv_b.OutShape[1]\n    return flop_A + flop_B + flop_C\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 2 and probs.size(0) == 2 and probability.size(0) == 2\n    #import pdb; pdb.set_trace()\n    out_a, expected_inC_a, expected_flop_a = self.conv_a( (inputs, expected_inC  , probability[0], indexes[0], probs[0]) )\n    out_b, expected_inC_b, expected_flop_b = self.conv_b( (out_a , expected_inC_a, probability[1], indexes[1], probs[1]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[1], indexes[1], probs[1]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_b)\n    return nn.functional.relu(out, inplace=True), expected_inC_b, sum([expected_flop_a, expected_flop_b, expected_flop_c])\n\n  def basic_forward(self, inputs):\n    basicblock = self.conv_a(inputs)\n    basicblock = self.conv_b(basicblock)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, basicblock)\n    return nn.functional.relu(out, inplace=True)\n\n\n\nclass ResNetBottleneck(nn.Module):\n  expansion = 4\n  num_conv  = 3\n  def __init__(self, inplanes, planes, stride):\n    super(ResNetBottleneck, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv_1x1 = ConvBNReLU(inplanes, planes, 1,      1, 0, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_3x3 = ConvBNReLU(  planes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    self.conv_1x4 = ConvBNReLU(planes, planes*self.expansion, 1, 1, 0, False, has_avg=False, has_bn=True, has_relu=False)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=True, has_bn=True, has_relu=False)\n    elif inplanes != planes*self.expansion:\n      self.downsample = ConvBNReLU(inplanes, planes*self.expansion, 1, 1, 0, False, has_avg=False,has_bn=True, has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes * self.expansion\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv_1x1.get_range() + self.conv_3x3.get_range() + self.conv_1x4.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 4, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv_1x1.get_flops([channels[0], channels[1]])\n    flop_B = self.conv_3x3.get_flops([channels[1], channels[2]])\n    flop_C = self.conv_1x4.get_flops([channels[2], channels[3]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_D = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_D = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_D = channels[0] * channels[-1] * self.conv_1x4.OutShape[0] * self.conv_1x4.OutShape[1]\n    return flop_A + flop_B + flop_C + flop_D\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def basic_forward(self, inputs):\n    bottleneck = self.conv_1x1(inputs)\n    bottleneck = self.conv_3x3(bottleneck)\n    bottleneck = self.conv_1x4(bottleneck)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, bottleneck)\n    return nn.functional.relu(out, inplace=True)\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 3 and probs.size(0) == 3 and probability.size(0) == 3\n    out_1x1, expected_inC_1x1, expected_flop_1x1 = self.conv_1x1( (inputs, expected_inC    , probability[0], indexes[0], probs[0]) )\n    out_3x3, expected_inC_3x3, expected_flop_3x3 = self.conv_3x3( (out_1x1,expected_inC_1x1, probability[1], indexes[1], probs[1]) )\n    out_1x4, expected_inC_1x4, expected_flop_1x4 = self.conv_1x4( (out_3x3,expected_inC_3x3, probability[2], indexes[2], probs[2]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[2], indexes[2], probs[2]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out_1x4)\n    return nn.functional.relu(out, inplace=True), expected_inC_1x4, sum([expected_flop_1x1, expected_flop_3x3, expected_flop_1x4, expected_flop_c])\n\n\nclass SearchShapeImagenetResNet(nn.Module):\n\n  def __init__(self, block_name, layers, deep_stem, num_classes):\n    super(SearchShapeImagenetResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    if block_name == \'BasicBlock\':\n      block = ResNetBasicblock\n    elif block_name == \'Bottleneck\':\n      block = ResNetBottleneck\n    else:\n      raise ValueError(\'invalid block : {:}\'.format(block_name))\n    \n    self.message      = \'SearchShapeCifarResNet : Depth : {:} , Layers for each block : {:}\'.format(sum(layers)*block.num_conv, layers)\n    self.num_classes  = num_classes\n    if not deep_stem:\n      self.layers       = nn.ModuleList( [ ConvBNReLU(3, 64, 7, 2, 3, False, has_avg=False, has_bn=True, has_relu=True, last_max_pool=True) ] )\n      self.channels     = [64]\n    else:\n      self.layers       = nn.ModuleList( [ ConvBNReLU(3, 32, 3, 2, 1, False, has_avg=False, has_bn=True, has_relu=True)\n                                          ,ConvBNReLU(32,64, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True, last_max_pool=True) ] )\n      self.channels     = [32, 64]\n\n    meta_depth_info   = get_depth_choices(layers)\n    self.InShape      = None\n    self.depth_info   = OrderedDict()\n    self.depth_at_i   = OrderedDict()\n    for stage, layer_blocks in enumerate(layers):\n      cur_block_choices = meta_depth_info[stage]\n      assert cur_block_choices[-1] == layer_blocks, \'stage={:}, {:} vs {:}\'.format(stage, cur_block_choices, layer_blocks)\n      block_choices, xstart = [], len(self.layers)\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 64 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = block(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n        # added for depth\n        layer_index = len(self.layers) - 1\n        if iL + 1 in cur_block_choices: block_choices.append( layer_index )\n        if iL + 1 == layer_blocks:\n          self.depth_info[layer_index] = {\'choices\': block_choices,\n                                          \'stage\'  : stage,\n                                          \'xstart\' : xstart}\n    self.depth_info_list = []\n    for xend, info in self.depth_info.items():\n      self.depth_info_list.append( (xend, info) )\n      xstart, xstage = info[\'xstart\'], info[\'stage\']\n      for ilayer in range(xstart, xend+1):\n        idx = bisect_right(info[\'choices\'], ilayer-1)\n        self.depth_at_i[ilayer] = (xstage, idx)\n\n    self.avgpool     = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier  = nn.Linear(module.out_dim, num_classes)\n    self.InShape     = None\n    self.tau         = -1\n    self.search_mode = \'basic\'\n    #assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n    \n    # parameters for width\n    self.Ranges = []\n    self.layer2indexRange = []\n    for i, layer in enumerate(self.layers):\n      start_index = len(self.Ranges)\n      self.Ranges += layer.get_range()\n      self.layer2indexRange.append( (start_index, len(self.Ranges)) )\n\n    self.register_parameter(\'width_attentions\', nn.Parameter(torch.Tensor(len(self.Ranges), get_width_choices(None))))\n    self.register_parameter(\'depth_attentions\', nn.Parameter(torch.Tensor(len(layers), meta_depth_info[\'num\'])))\n    nn.init.normal_(self.width_attentions, 0, 0.01)\n    nn.init.normal_(self.depth_attentions, 0, 0.01)\n    self.apply(initialize_resnet)\n\n  def arch_parameters(self, LR=None):\n    if LR is None:\n      return [self.width_attentions, self.depth_attentions]\n    else:\n      return [\n               {""params"": self.width_attentions, ""lr"": LR},\n               {""params"": self.depth_attentions, ""lr"": LR},\n             ]\n\n  def base_parameters(self):\n    return list(self.layers.parameters()) + list(self.avgpool.parameters()) + list(self.classifier.parameters())\n\n  def get_flop(self, mode, config_dict, extra_info):\n    if config_dict is not None: config_dict = config_dict.copy()\n    # select channels \n    channels = [3]\n    for i, weight in enumerate(self.width_attentions):\n      if mode == \'genotype\':\n        with torch.no_grad():\n          probe = nn.functional.softmax(weight, dim=0)\n          C = self.Ranges[i][ torch.argmax(probe).item() ]\n      else:\n        raise ValueError(\'invalid mode : {:}\'.format(mode))\n      channels.append( C )\n    # select depth\n    if mode == \'genotype\':\n      with torch.no_grad():\n        depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n        choices = torch.argmax(depth_probs, dim=1).cpu().tolist()\n    else:\n      raise ValueError(\'invalid mode : {:}\'.format(mode))\n    selected_layers = []\n    for choice, xvalue in zip(choices, self.depth_info_list):\n      xtemp = xvalue[1][\'choices\'][choice] - xvalue[1][\'xstart\'] + 1\n      selected_layers.append(xtemp)\n    flop = 0\n    for i, layer in enumerate(self.layers):\n      s, e = self.layer2indexRange[i]\n      xchl = tuple( channels[s:e+1] )\n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        if xatti <= choices[xstagei]: # leave this depth\n          flop+= layer.get_flops(xchl)\n        else:\n          flop+= 0 # do not use this layer\n      else:\n        flop+= layer.get_flops(xchl)\n    # the last fc layer\n    flop += channels[-1] * self.classifier.out_features\n    if config_dict is None:\n      return flop / 1e6\n    else:\n      config_dict[\'xchannels\']  = channels\n      config_dict[\'xblocks\']    = selected_layers\n      config_dict[\'super_type\'] = \'infer-shape\'\n      config_dict[\'estimated_FLOP\'] = flop / 1e6\n      return flop / 1e6, config_dict\n\n  def get_arch_info(self):\n    string = ""for depth and width, there are {:} + {:} attention probabilities."".format(len(self.depth_attentions), len(self.width_attentions))\n    string+= \'\\n{:}\'.format(self.depth_info)\n    discrepancy = []\n    with torch.no_grad():\n      for i, att in enumerate(self.depth_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.depth_attentions), \' \'.join(prob))\n        logt = [\'{:.4f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:17s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || discrepancy={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n      string += \'\\n-----------------------------------------------\'\n      for i, att in enumerate(self.width_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.width_attentions), \' \'.join(prob))\n        logt = [\'{:.3f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:52s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || dis={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n    return string, discrepancy\n\n  def set_tau(self, tau_max, tau_min, epoch_ratio):\n    assert epoch_ratio >= 0 and epoch_ratio <= 1, \'invalid epoch-ratio : {:}\'.format(epoch_ratio)\n    tau = tau_min + (tau_max-tau_min) * (1 + math.cos(math.pi * epoch_ratio)) / 2\n    self.tau = tau\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, inputs):\n    flop_width_probs = nn.functional.softmax(self.width_attentions, dim=1)\n    flop_depth_probs = nn.functional.softmax(self.depth_attentions, dim=1)\n    flop_depth_probs = torch.flip( torch.cumsum( torch.flip(flop_depth_probs, [1]), 1 ), [1] )\n    selected_widths, selected_width_probs = select2withP(self.width_attentions, self.tau)\n    selected_depth_probs = select2withP(self.depth_attentions, self.tau, True)\n    with torch.no_grad():\n      selected_widths = selected_widths.cpu()\n\n    x, last_channel_idx, expected_inC, flops = inputs, 0, 3, []\n    feature_maps = []\n    for i, layer in enumerate(self.layers):\n      selected_w_index = selected_widths     [last_channel_idx: last_channel_idx+layer.num_conv]\n      selected_w_probs = selected_width_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      layer_prob       = flop_width_probs    [last_channel_idx: last_channel_idx+layer.num_conv]\n      x, expected_inC, expected_flop = layer( (x, expected_inC, layer_prob, selected_w_index, selected_w_probs) )\n      feature_maps.append( x )\n      last_channel_idx += layer.num_conv\n      if i in self.depth_info: # aggregate the information\n        choices = self.depth_info[i][\'choices\']\n        xstagei = self.depth_info[i][\'stage\']\n        #print (\'iL={:}, choices={:}, stage={:}, probs={:}\'.format(i, choices, xstagei, selected_depth_probs[xstagei].cpu().tolist()))\n        #for A, W in zip(choices, selected_depth_probs[xstagei]):\n        #  print(\'Size = {:}, W = {:}\'.format(feature_maps[A].size(), W))\n        possible_tensors = []\n        max_C = max( feature_maps[A].size(1) for A in choices )\n        for tempi, A in enumerate(choices):\n          xtensor = ChannelWiseInter(feature_maps[A], max_C)\n          possible_tensors.append( xtensor )\n        weighted_sum = sum( xtensor * W for xtensor, W in zip(possible_tensors, selected_depth_probs[xstagei]) )\n        x = weighted_sum\n        \n      if i in self.depth_at_i:\n        xstagei, xatti = self.depth_at_i[i]\n        x_expected_flop = flop_depth_probs[xstagei, xatti] * expected_flop\n      else:\n        x_expected_flop = expected_flop\n      flops.append( x_expected_flop )\n    flops.append( expected_inC * (self.classifier.out_features*1.0/1e6) )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = linear_forward(features, self.classifier)\n    return logits, torch.stack( [sum(flops)] )\n\n  def basic_forward(self, inputs):\n    if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1))\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_searchs/SearchSimResNet_width.py,15,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nimport torch.nn as nn\nfrom ..initialization import initialize_resnet\nfrom ..SharedUtils    import additive_func\nfrom .SoftSelect      import select2withP, ChannelWiseInter\nfrom .SoftSelect      import linear_forward\nfrom .SoftSelect      import get_width_choices as get_choices\n\n\ndef conv_forward(inputs, conv, choices):\n  iC = conv.in_channels\n  fill_size = list(inputs.size())\n  fill_size[1] = iC - fill_size[1]\n  filled  = torch.zeros(fill_size, device=inputs.device)\n  xinputs = torch.cat((inputs, filled), dim=1)\n  outputs = conv(xinputs)\n  selecteds = [outputs[:,:oC] for oC in choices]\n  return selecteds\n\n\nclass ConvBNReLU(nn.Module):\n  num_conv  = 1\n  def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu):\n    super(ConvBNReLU, self).__init__()\n    self.InShape  = None\n    self.OutShape = None\n    self.choices  = get_choices(nOut)\n    self.register_buffer(\'choices_tensor\', torch.Tensor( self.choices ))\n\n    if has_avg : self.avg = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n    else       : self.avg = None\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=kernel, stride=stride, padding=padding, dilation=1, groups=1, bias=bias)\n    #if has_bn  : self.bn  = nn.BatchNorm2d(nOut)\n    #else       : self.bn  = None\n    self.has_bn = has_bn\n    self.BNs  = nn.ModuleList()\n    for i, _out in enumerate(self.choices):\n      self.BNs.append(nn.BatchNorm2d(_out))\n    if has_relu: self.relu = nn.ReLU(inplace=True)\n    else       : self.relu = None\n    self.in_dim   = nIn\n    self.out_dim  = nOut\n    self.search_mode = \'basic\'\n\n  def get_flops(self, channels, check_range=True, divide=1):\n    iC, oC = channels\n    if check_range: assert iC <= self.conv.in_channels and oC <= self.conv.out_channels, \'{:} vs {:}  |  {:} vs {:}\'.format(iC, self.conv.in_channels, oC, self.conv.out_channels)\n    assert isinstance(self.InShape, tuple) and len(self.InShape) == 2, \'invalid in-shape : {:}\'.format(self.InShape)\n    assert isinstance(self.OutShape, tuple) and len(self.OutShape) == 2, \'invalid out-shape : {:}\'.format(self.OutShape)\n    #conv_per_position_flops = self.conv.kernel_size[0] * self.conv.kernel_size[1] * iC * oC / self.conv.groups\n    conv_per_position_flops = (self.conv.kernel_size[0] * self.conv.kernel_size[1] * 1.0 / self.conv.groups)\n    all_positions = self.OutShape[0] * self.OutShape[1]\n    flops = (conv_per_position_flops * all_positions / divide) * iC * oC\n    if self.conv.bias is not None: flops += all_positions / divide\n    return flops\n\n  def get_range(self):\n    return [self.choices]\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, index, prob = tuple_inputs\n    index, prob = torch.squeeze(index).tolist(), torch.squeeze(prob)\n    probability = torch.squeeze(probability)\n    assert len(index) == 2, \'invalid length : {:}\'.format(index)\n    # compute expected flop\n    #coordinates   = torch.arange(self.x_range[0], self.x_range[1]+1).type_as(probability)\n    expected_outC = (self.choices_tensor * probability).sum()\n    expected_flop = self.get_flops([expected_inC, expected_outC], False, 1e6)\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    # convolutional layer\n    out_convs = conv_forward(out, self.conv, [self.choices[i] for i in index])\n    out_bns   = [self.BNs[idx](out_conv) for idx, out_conv in zip(index, out_convs)]\n    # merge\n    out_channel = max([x.size(1) for x in out_bns])\n    outA = ChannelWiseInter(out_bns[0], out_channel)\n    outB = ChannelWiseInter(out_bns[1], out_channel)\n    out  = outA * prob[0] + outB * prob[1]\n    #out = additive_func(out_bns[0]*prob[0], out_bns[1]*prob[1])\n\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    return out, expected_outC, expected_flop\n\n  def basic_forward(self, inputs):\n    if self.avg : out = self.avg( inputs )\n    else        : out = inputs\n    conv = self.conv( out )\n    if self.has_bn:out= self.BNs[-1]( conv )\n    else        : out = conv\n    if self.relu: out = self.relu( out )\n    else        : out = out\n    if self.InShape is None:\n      self.InShape  = (inputs.size(-2), inputs.size(-1))\n      self.OutShape = (out.size(-2)   , out.size(-1))\n    return out\n\n\nclass SimBlock(nn.Module):\n  expansion = 1\n  num_conv  = 1\n  def __init__(self, inplanes, planes, stride):\n    super(SimBlock, self).__init__()\n    assert stride == 1 or stride == 2, \'invalid stride {:}\'.format(stride)\n    self.conv = ConvBNReLU(inplanes, planes, 3, stride, 1, False, has_avg=False, has_bn=True, has_relu=True)\n    if stride == 2:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=True, has_bn=False, has_relu=False)\n    elif inplanes != planes:\n      self.downsample = ConvBNReLU(inplanes, planes, 1, 1, 0, False, has_avg=False,has_bn=True , has_relu=False)\n    else:\n      self.downsample = None\n    self.out_dim     = planes\n    self.search_mode = \'basic\'\n\n  def get_range(self):\n    return self.conv.get_range()\n\n  def get_flops(self, channels):\n    assert len(channels) == 2, \'invalid channels : {:}\'.format(channels)\n    flop_A = self.conv.get_flops([channels[0], channels[1]])\n    if hasattr(self.downsample, \'get_flops\'):\n      flop_C = self.downsample.get_flops([channels[0], channels[-1]])\n    else:\n      flop_C = 0\n    if channels[0] != channels[-1] and self.downsample is None: # this short-cut will be added during the infer-train\n      flop_C = channels[0] * channels[-1] * self.conv.OutShape[0] * self.conv.OutShape[1]\n    return flop_A + flop_C\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\'   : return self.basic_forward(inputs)\n    elif self.search_mode == \'search\': return self.search_forward(inputs)\n    else: raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, tuple_inputs):\n    assert isinstance(tuple_inputs, tuple) and len(tuple_inputs) == 5, \'invalid type input : {:}\'.format( type(tuple_inputs) )\n    inputs, expected_inC, probability, indexes, probs = tuple_inputs\n    assert indexes.size(0) == 1 and probs.size(0) == 1 and probability.size(0) == 1, \'invalid size : {:}, {:}, {:}\'.format(indexes.size(), probs.size(), probability.size())\n    out, expected_next_inC, expected_flop = self.conv( (inputs, expected_inC  , probability[0], indexes[0], probs[0]) )\n    if self.downsample is not None:\n      residual, _, expected_flop_c = self.downsample( (inputs, expected_inC  , probability[-1], indexes[-1], probs[-1]) )\n    else:\n      residual, expected_flop_c = inputs, 0\n    out = additive_func(residual, out)\n    return nn.functional.relu(out, inplace=True), expected_next_inC, sum([expected_flop, expected_flop_c])\n\n  def basic_forward(self, inputs):\n    basicblock = self.conv(inputs)\n    if self.downsample is not None: residual = self.downsample(inputs)\n    else                          : residual = inputs\n    out = additive_func(residual, basicblock)\n    return nn.functional.relu(out, inplace=True)\n\n\n\nclass SearchWidthSimResNet(nn.Module):\n\n  def __init__(self, depth, num_classes):\n    super(SearchWidthSimResNet, self).__init__()\n\n    assert (depth - 2) % 3 == 0, \'depth should be one of 5, 8, 11, 14, ... instead of {:}\'.format(depth)\n    layer_blocks = (depth - 2) // 3\n    self.message     = \'SearchWidthSimResNet : Depth : {:} , Layers for each block : {:}\'.format(depth, layer_blocks)\n    self.num_classes = num_classes\n    self.channels    = [16]\n    self.layers      = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] )\n    self.InShape     = None\n    for stage in range(3):\n      for iL in range(layer_blocks):\n        iC     = self.channels[-1]\n        planes = 16 * (2**stage)\n        stride = 2 if stage > 0 and iL == 0 else 1\n        module = SimBlock(iC, planes, stride)\n        self.channels.append( module.out_dim )\n        self.layers.append  ( module )\n        self.message += ""\\nstage={:}, ilayer={:02d}/{:02d}, block={:03d}, iC={:3d}, oC={:3d}, stride={:}"".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride)\n  \n    self.avgpool     = nn.AvgPool2d(8)\n    self.classifier  = nn.Linear(module.out_dim, num_classes)\n    self.InShape     = None\n    self.tau         = -1\n    self.search_mode = \'basic\'\n    #assert sum(x.num_conv for x in self.layers) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(sum(x.num_conv for x in self.layers)+1, depth)\n    \n    # parameters for width\n    self.Ranges = []\n    self.layer2indexRange = []\n    for i, layer in enumerate(self.layers):\n      start_index = len(self.Ranges)\n      self.Ranges += layer.get_range()\n      self.layer2indexRange.append( (start_index, len(self.Ranges)) )\n    assert len(self.Ranges) + 1 == depth, \'invalid depth check {:} vs {:}\'.format(len(self.Ranges) + 1, depth)\n\n    self.register_parameter(\'width_attentions\', nn.Parameter(torch.Tensor(len(self.Ranges), get_choices(None))))\n    nn.init.normal_(self.width_attentions, 0, 0.01)\n    self.apply(initialize_resnet)\n\n  def arch_parameters(self):\n    return [self.width_attentions]\n\n  def base_parameters(self):\n    return list(self.layers.parameters()) + list(self.avgpool.parameters()) + list(self.classifier.parameters())\n\n  def get_flop(self, mode, config_dict, extra_info):\n    if config_dict is not None: config_dict = config_dict.copy()\n    #weights = [F.softmax(x, dim=0) for x in self.width_attentions]\n    channels = [3]\n    for i, weight in enumerate(self.width_attentions):\n      if mode == \'genotype\':\n        with torch.no_grad():\n          probe = nn.functional.softmax(weight, dim=0)\n          C = self.Ranges[i][ torch.argmax(probe).item() ]\n      elif mode == \'max\':\n        C = self.Ranges[i][-1]\n      elif mode == \'fix\':\n        C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n      elif mode == \'random\':\n        assert isinstance(extra_info, float), \'invalid extra_info : {:}\'.format(extra_info)\n        with torch.no_grad():\n          prob = nn.functional.softmax(weight, dim=0)\n          approximate_C = int( math.sqrt( extra_info ) * self.Ranges[i][-1] )\n          for j in range(prob.size(0)):\n            prob[j] = 1 / (abs(j - (approximate_C-self.Ranges[i][j])) + 0.2)\n          C = self.Ranges[i][ torch.multinomial(prob, 1, False).item() ]\n      else:\n        raise ValueError(\'invalid mode : {:}\'.format(mode))\n      channels.append( C )\n    flop = 0\n    for i, layer in enumerate(self.layers):\n      s, e = self.layer2indexRange[i]\n      xchl = tuple( channels[s:e+1] )\n      flop+= layer.get_flops(xchl)\n    # the last fc layer\n    flop += channels[-1] * self.classifier.out_features\n    if config_dict is None:\n      return flop / 1e6\n    else:\n      config_dict[\'xchannels\']  = channels\n      config_dict[\'super_type\'] = \'infer-width\'\n      config_dict[\'estimated_FLOP\'] = flop / 1e6\n      return flop / 1e6, config_dict\n\n  def get_arch_info(self):\n    string = ""for width, there are {:} attention probabilities."".format(len(self.width_attentions))\n    discrepancy = []\n    with torch.no_grad():\n      for i, att in enumerate(self.width_attentions):\n        prob = nn.functional.softmax(att, dim=0)\n        prob = prob.cpu() ; selc = prob.argmax().item() ; prob = prob.tolist()\n        prob = [\'{:.3f}\'.format(x) for x in prob]\n        xstring = \'{:03d}/{:03d}-th : {:}\'.format(i, len(self.width_attentions), \' \'.join(prob))\n        logt = [\'{:.3f}\'.format(x) for x in att.cpu().tolist()]\n        xstring += \'  ||  {:52s}\'.format(\' \'.join(logt))\n        prob = sorted( [float(x) for x in prob] )\n        disc = prob[-1] - prob[-2]\n        xstring += \'  || dis={:.2f} || select={:}/{:}\'.format(disc, selc, len(prob))\n        discrepancy.append( disc )\n        string += \'\\n{:}\'.format(xstring)\n    return string, discrepancy\n\n  def set_tau(self, tau_max, tau_min, epoch_ratio):\n    assert epoch_ratio >= 0 and epoch_ratio <= 1, \'invalid epoch-ratio : {:}\'.format(epoch_ratio)\n    tau = tau_min + (tau_max-tau_min) * (1 + math.cos(math.pi * epoch_ratio)) / 2\n    self.tau = tau\n\n  def get_message(self):\n    return self.message\n\n  def forward(self, inputs):\n    if self.search_mode == \'basic\':\n      return self.basic_forward(inputs)\n    elif self.search_mode == \'search\':\n      return self.search_forward(inputs)\n    else:\n      raise ValueError(\'invalid search_mode = {:}\'.format(self.search_mode))\n\n  def search_forward(self, inputs):\n    flop_probs = nn.functional.softmax(self.width_attentions, dim=1)\n    selected_widths, selected_probs = select2withP(self.width_attentions, self.tau)\n    with torch.no_grad():\n      selected_widths = selected_widths.cpu()\n\n    x, last_channel_idx, expected_inC, flops = inputs, 0, 3, []\n    for i, layer in enumerate(self.layers):\n      selected_w_index = selected_widths[last_channel_idx: last_channel_idx+layer.num_conv]\n      selected_w_probs = selected_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      layer_prob       = flop_probs[last_channel_idx: last_channel_idx+layer.num_conv]\n      x, expected_inC, expected_flop = layer( (x, expected_inC, layer_prob, selected_w_index, selected_w_probs) )\n      last_channel_idx += layer.num_conv\n      flops.append( expected_flop )\n    flops.append( expected_inC * (self.classifier.out_features*1.0/1e6) )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = linear_forward(features, self.classifier)\n    return logits, torch.stack( [sum(flops)] )\n\n  def basic_forward(self, inputs):\n    if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1))\n    x = inputs\n    for i, layer in enumerate(self.layers):\n      x = layer( x )\n    features = self.avgpool(x)\n    features = features.view(features.size(0), -1)\n    logits   = self.classifier(features)\n    return features, logits\n'"
lib/models/shape_searchs/SoftSelect.py,9,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, torch\nimport torch.nn as nn\n\n\ndef select2withP(logits, tau, just_prob=False, num=2, eps=1e-7):\n  if tau <= 0:\n    new_logits = logits\n    probs = nn.functional.softmax(new_logits, dim=1)\n  else       :\n    while True: # a trick to avoid the gumbels bug\n      gumbels = -torch.empty_like(logits).exponential_().log()\n      new_logits = (logits.log_softmax(dim=1) + gumbels) / tau\n      probs = nn.functional.softmax(new_logits, dim=1)\n      if (not torch.isinf(gumbels).any()) and (not torch.isinf(probs).any()) and (not torch.isnan(probs).any()): break\n\n  if just_prob: return probs\n\n  #with torch.no_grad(): # add eps for unexpected torch error\n  #  probs = nn.functional.softmax(new_logits, dim=1)\n  #  selected_index = torch.multinomial(probs + eps, 2, False)\n  with torch.no_grad(): # add eps for unexpected torch error\n    probs          = probs.cpu()\n    selected_index = torch.multinomial(probs + eps, num, False).to(logits.device)\n  selected_logit = torch.gather(new_logits, 1, selected_index)\n  selcted_probs  = nn.functional.softmax(selected_logit, dim=1)\n  return selected_index, selcted_probs\n\n\ndef ChannelWiseInter(inputs, oC, mode='v2'):\n  if mode == 'v1':\n    return ChannelWiseInterV1(inputs, oC)\n  elif mode == 'v2':\n    return ChannelWiseInterV2(inputs, oC)\n  else:\n    raise ValueError('invalid mode : {:}'.format(mode))\n\n\ndef ChannelWiseInterV1(inputs, oC):\n  assert inputs.dim() == 4, 'invalid dimension : {:}'.format(inputs.size())\n  def start_index(a, b, c):\n    return int( math.floor(float(a * c) / b) )\n  def end_index(a, b, c):\n    return int( math.ceil(float((a + 1) * c) / b) )\n  batch, iC, H, W = inputs.size()\n  outputs = torch.zeros((batch, oC, H, W), dtype=inputs.dtype, device=inputs.device)\n  if iC == oC: return inputs\n  for ot in range(oC):\n    istartT, iendT = start_index(ot, oC, iC), end_index(ot, oC, iC)\n    values = inputs[:, istartT:iendT].mean(dim=1) \n    outputs[:, ot, :, :] = values\n  return outputs\n\n\ndef ChannelWiseInterV2(inputs, oC):\n  assert inputs.dim() == 4, 'invalid dimension : {:}'.format(inputs.size())\n  batch, C, H, W = inputs.size()\n  if C == oC: return inputs\n  else      : return nn.functional.adaptive_avg_pool3d(inputs, (oC,H,W))\n  #inputs_5D = inputs.view(batch, 1, C, H, W)\n  #otputs_5D = nn.functional.interpolate(inputs_5D, (oC,H,W), None, 'area', None)\n  #otputs    = otputs_5D.view(batch, oC, H, W)\n  #otputs_5D = nn.functional.interpolate(inputs_5D, (oC,H,W), None, 'trilinear', False)\n  #return otputs\n\n\ndef linear_forward(inputs, linear):\n  if linear is None: return inputs\n  iC = inputs.size(1)\n  weight = linear.weight[:, :iC]\n  if linear.bias is None: bias = None\n  else                  : bias = linear.bias\n  return nn.functional.linear(inputs, weight, bias)\n\n\ndef get_width_choices(nOut):\n  xsrange = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n  if nOut is None:\n    return len(xsrange)\n  else:\n    Xs = [int(nOut * i) for i in xsrange]\n    #xs = [ int(nOut * i // 10) for i in range(2, 11)]\n    #Xs = [x for i, x in enumerate(xs) if i+1 == len(xs) or xs[i+1] > x+1]\n    Xs = sorted( list( set(Xs) ) )\n    return tuple(Xs)\n\n\ndef get_depth_choices(nDepth):\n  if nDepth is None:\n    return 3\n  else:\n    assert nDepth >= 3, 'nDepth should be greater than 2 vs {:}'.format(nDepth)\n    if nDepth == 1  : return (1, 1, 1)\n    elif nDepth == 2: return (1, 1, 2)\n    elif nDepth >= 3:\n      return (nDepth//3, nDepth*2//3, nDepth)\n    else:\n      raise ValueError('invalid Depth : {:}'.format(nDepth))\n\n\ndef drop_path(x, drop_prob):\n  if drop_prob > 0.:\n    keep_prob = 1. - drop_prob\n    mask = x.new_zeros(x.size(0), 1, 1, 1)\n    mask = mask.bernoulli_(keep_prob)\n    x = x * (mask / keep_prob)\n    #x.div_(keep_prob)\n    #x.mul_(mask)\n  return x\n"""
lib/models/shape_searchs/__init__.py,0,"b'##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom .SearchCifarResNet_width import SearchWidthCifarResNet\nfrom .SearchCifarResNet_depth import SearchDepthCifarResNet\nfrom .SearchCifarResNet       import SearchShapeCifarResNet\nfrom .SearchSimResNet_width   import SearchWidthSimResNet\nfrom .SearchImagenetResNet    import SearchShapeImagenetResNet\n'"
lib/models/shape_searchs/test.py,2,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport torch\nimport torch.nn as nn\nfrom SoftSelect import ChannelWiseInter\n\n\nif __name__ == '__main__':\n\n  tensors = torch.rand((16, 128, 7, 7))\n  \n  for oc in range(200, 210):\n    out_v1  = ChannelWiseInter(tensors, oc, 'v1')\n    out_v2  = ChannelWiseInter(tensors, oc, 'v2')\n    assert (out_v1 == out_v2).any().item() == 1\n  for oc in range(48, 160):\n    out_v1  = ChannelWiseInter(tensors, oc, 'v1')\n    out_v2  = ChannelWiseInter(tensors, oc, 'v2')\n    assert (out_v1 == out_v2).any().item() == 1\n"""
lib/nas_infer_model/DXYs/CifarNet.py,1,"b""import torch\nimport torch.nn as nn\nfrom .construct_utils import drop_path\nfrom .head_utils      import CifarHEAD, AuxiliaryHeadCIFAR\nfrom .base_cells      import InferCell\n\n\nclass NetworkCIFAR(nn.Module):\n\n  def __init__(self, C, N, stem_multiplier, auxiliary, genotype, num_classes):\n    super(NetworkCIFAR, self).__init__()\n    self._C               = C\n    self._layerN          = N\n    self._stem_multiplier = stem_multiplier\n\n    C_curr = self._stem_multiplier * C\n    self.stem = CifarHEAD(C_curr)\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n    block_indexs     = [0    ] * N + [-1  ] + [1    ] * N + [-1  ] + [2    ] * N\n    block2index      = {0:[], 1:[], 2:[]}\n\n    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n    reduction_prev, spatial, dims = False, 1, []\n    self.auxiliary_index = None\n    self.auxiliary_head  = None\n    self.cells = nn.ModuleList()\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = InferCell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n      reduction_prev = reduction\n      self.cells.append( cell )\n      C_prev_prev, C_prev = C_prev, cell._multiplier*C_curr\n      if reduction and C_curr == C*4:\n        if auxiliary:\n          self.auxiliary_head = AuxiliaryHeadCIFAR(C_prev, num_classes)\n          self.auxiliary_index = index\n\n      if reduction: spatial *= 2\n      dims.append( (C_prev, spatial) )\n      \n    self._Layer= len(self.cells)\n\n\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n    self.drop_path_prob = -1\n\n  def update_drop_path(self, drop_path_prob):\n    self.drop_path_prob = drop_path_prob\n\n  def auxiliary_param(self):\n    if self.auxiliary_head is None: return []\n    else: return list( self.auxiliary_head.parameters() )\n\n  def get_message(self):\n    return self.extra_repr()\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N={_layerN}, L={_Layer}, stem={_stem_multiplier}, drop-path={drop_path_prob})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, inputs):\n    stem_feature, logits_aux = self.stem(inputs), None\n    cell_results = [stem_feature, stem_feature]\n    for i, cell in enumerate(self.cells):\n      cell_feature = cell(cell_results[-2], cell_results[-1], self.drop_path_prob)\n      cell_results.append( cell_feature )\n\n      if self.auxiliary_index is not None and i == self.auxiliary_index and self.training:\n        logits_aux = self.auxiliary_head( cell_results[-1] )\n    out = self.global_pooling( cell_results[-1] )\n    out = out.view(out.size(0), -1)\n    logits = self.classifier(out)\n\n    if logits_aux is None: return out, logits\n    else                 : return out, [logits, logits_aux]\n"""
lib/nas_infer_model/DXYs/ImageNet.py,1,"b""import torch\nimport torch.nn as nn\nfrom .construct_utils import drop_path\nfrom .base_cells import InferCell\nfrom .head_utils import ImageNetHEAD, AuxiliaryHeadImageNet\n\n\nclass NetworkImageNet(nn.Module):\n\n  def __init__(self, C, N, auxiliary, genotype, num_classes):\n    super(NetworkImageNet, self).__init__()\n    self._C          = C\n    self._layerN     = N\n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4] * N\n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n    self.stem0 = nn.Sequential(\n      nn.Conv2d(3, C // 2, kernel_size=3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C // 2),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(C // 2, C, 3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C),\n    )\n\n    self.stem1 = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.Conv2d(C, C, 3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C),\n    )\n\n    C_prev_prev, C_prev, C_curr, reduction_prev = C, C, C, True\n\n    self.cells = nn.ModuleList()\n    self.auxiliary_index = None\n    for i, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell = InferCell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n      reduction_prev = reduction\n      self.cells += [cell]\n      C_prev_prev, C_prev = C_prev, cell._multiplier * C_curr\n      if reduction and C_curr == C*4:\n        C_to_auxiliary = C_prev\n        self.auxiliary_index = i\n  \n    self._NNN = len(self.cells)\n    if auxiliary:\n      self.auxiliary_head = AuxiliaryHeadImageNet(C_to_auxiliary, num_classes)\n    else:\n      self.auxiliary_head = None\n    self.global_pooling = nn.AvgPool2d(7)\n    self.classifier     = nn.Linear(C_prev, num_classes)\n    self.drop_path_prob = -1\n\n  def update_drop_path(self, drop_path_prob):\n    self.drop_path_prob = drop_path_prob\n\n  def extra_repr(self):\n    return ('{name}(C={_C}, N=[{_layerN}, {_NNN}], aux-index={auxiliary_index}, drop-path={drop_path_prob})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def get_message(self):\n    return self.extra_repr()\n\n  def auxiliary_param(self):\n    if self.auxiliary_head is None: return []\n    else: return list( self.auxiliary_head.parameters() )\n\n  def forward(self, inputs):\n    s0 = self.stem0(inputs)\n    s1 = self.stem1(s0)\n    logits_aux = None\n    for i, cell in enumerate(self.cells):\n      s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n      if i == self.auxiliary_index and self.auxiliary_head and self.training:\n        logits_aux = self.auxiliary_head(s1)\n    out = self.global_pooling(s1)\n    logits = self.classifier(out.view(out.size(0), -1))\n\n    if logits_aux is None: return out, logits\n    else                 : return out, [logits, logits_aux]\n"""
lib/nas_infer_model/DXYs/__init__.py,0,b'# Performance-Aware Template Network for One-Shot Neural Architecture Search\nfrom .CifarNet  import NetworkCIFAR as CifarNet\nfrom .ImageNet  import NetworkImageNet as ImageNet\nfrom .genotypes import Networks\nfrom .genotypes import build_genotype_from_dict\n'
lib/nas_infer_model/DXYs/base_cells.py,7,"b""import math\nfrom copy import deepcopy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .construct_utils import drop_path\nfrom ..operations import OPS, Identity, FactorizedReduce, ReLUConvBN\n\n\nclass MixedOp(nn.Module):\n\n  def __init__(self, C, stride, PRIMITIVES):\n    super(MixedOp, self).__init__()\n    self._ops = nn.ModuleList()\n    self.name2idx = {}\n    for idx, primitive in enumerate(PRIMITIVES):\n      op = OPS[primitive](C, C, stride, False)\n      self._ops.append(op)\n      assert primitive not in self.name2idx, '{:} has already in'.format(primitive)\n      self.name2idx[primitive] = idx\n\n  def forward(self, x, weights, op_name):\n    if op_name is None:\n      if weights is None:\n        return [op(x) for op in self._ops]\n      else:\n        return sum(w * op(x) for w, op in zip(weights, self._ops))\n    else:\n      op_index = self.name2idx[op_name]\n      return self._ops[op_index](x)\n\n\n\nclass SearchCell(nn.Module):\n\n  def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, PRIMITIVES, use_residual):\n    super(SearchCell, self).__init__()\n    self.reduction  = reduction\n    self.PRIMITIVES = deepcopy(PRIMITIVES)\n  \n    if reduction_prev:\n      self.preprocess0 = FactorizedReduce(C_prev_prev, C, 2, affine=False)\n    else:\n      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, affine=False)\n    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, affine=False)\n    self._steps        = steps\n    self._multiplier   = multiplier\n    self._use_residual = use_residual\n\n    self._ops = nn.ModuleList()\n    for i in range(self._steps):\n      for j in range(2+i):\n        stride = 2 if reduction and j < 2 else 1\n        op = MixedOp(C, stride, self.PRIMITIVES)\n        self._ops.append(op)\n\n  def extra_repr(self):\n    return ('{name}(residual={_use_residual}, steps={_steps}, multiplier={_multiplier})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, S0, S1, weights, connect, adjacency, drop_prob, modes):\n    if modes[0] is None:\n      if modes[1] == 'normal':\n        output = self.__forwardBoth(S0, S1, weights, connect, adjacency, drop_prob)\n      elif modes[1] == 'only_W':\n        output = self.__forwardOnlyW(S0, S1, drop_prob)\n    else:\n      test_genotype = modes[0]\n      if self.reduction: operations, concats = test_genotype.reduce, test_genotype.reduce_concat\n      else             : operations, concats = test_genotype.normal, test_genotype.normal_concat\n      s0, s1 = self.preprocess0(S0), self.preprocess1(S1)\n      states, offset = [s0, s1], 0\n      assert self._steps == len(operations), '{:} vs. {:}'.format(self._steps, len(operations))\n      for i, (opA, opB) in enumerate(operations):\n        A = self._ops[offset + opA[1]](states[opA[1]], None, opA[0])\n        B = self._ops[offset + opB[1]](states[opB[1]], None, opB[0])\n        state = A + B\n        offset += len(states)\n        states.append(state)\n      output = torch.cat([states[i] for i in concats], dim=1)\n    if self._use_residual and S1.size() == output.size():\n      return S1 + output\n    else: return output\n  \n  def __forwardBoth(self, S0, S1, weights, connect, adjacency, drop_prob):\n    s0, s1 = self.preprocess0(S0), self.preprocess1(S1)\n    states, offset = [s0, s1], 0\n    for i in range(self._steps):\n      clist = []\n      for j, h in enumerate(states):\n        x = self._ops[offset+j](h, weights[offset+j], None)\n        if self.training and drop_prob > 0.:\n          x = drop_path(x, math.pow(drop_prob, 1./len(states)))\n        clist.append( x )\n      connection = torch.mm(connect['{:}'.format(i)], adjacency[i]).squeeze(0)\n      state = sum(w * node for w, node in zip(connection, clist))\n      offset += len(states)\n      states.append(state)\n    return torch.cat(states[-self._multiplier:], dim=1)\n\n  def __forwardOnlyW(self, S0, S1, drop_prob):\n    s0, s1 = self.preprocess0(S0), self.preprocess1(S1)\n    states, offset = [s0, s1], 0\n    for i in range(self._steps):\n      clist = []\n      for j, h in enumerate(states):\n        xs = self._ops[offset+j](h, None, None)\n        clist += xs\n      if self.training and drop_prob > 0.:\n        xlist = [drop_path(x, math.pow(drop_prob, 1./len(states))) for x in clist]\n      else: xlist = clist\n      state = sum(xlist) * 2 / len(xlist)\n      offset += len(states)\n      states.append(state)\n    return torch.cat(states[-self._multiplier:], dim=1)\n\n\n\nclass InferCell(nn.Module):\n\n  def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev):\n    super(InferCell, self).__init__()\n    print(C_prev_prev, C_prev, C)\n\n    if reduction_prev is None:\n      self.preprocess0 = Identity()\n    elif reduction_prev:\n      self.preprocess0 = FactorizedReduce(C_prev_prev, C, 2)\n    else:\n      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0)\n    self.preprocess1   = ReLUConvBN(C_prev, C, 1, 1, 0)\n    \n    if reduction: step_ops, concat = genotype.reduce, genotype.reduce_concat\n    else        : step_ops, concat = genotype.normal, genotype.normal_concat\n    self._steps        = len(step_ops)\n    self._concat       = concat\n    self._multiplier   = len(concat)\n    self._ops          = nn.ModuleList()\n    self._indices      = []\n    for operations in step_ops:\n      for name, index in operations:\n        stride = 2 if reduction and index < 2 else 1\n        if reduction_prev is None and index == 0:\n          op = OPS[name](C_prev_prev, C, stride, True)\n        else:\n          op = OPS[name](C          , C, stride, True)\n        self._ops.append( op )\n        self._indices.append( index )\n\n  def extra_repr(self):\n    return ('{name}(steps={_steps}, concat={_concat})'.format(name=self.__class__.__name__, **self.__dict__))\n\n  def forward(self, S0, S1, drop_prob):\n    s0 = self.preprocess0(S0)\n    s1 = self.preprocess1(S1)\n\n    states = [s0, s1]\n    for i in range(self._steps):\n      h1 = states[self._indices[2*i]]\n      h2 = states[self._indices[2*i+1]]\n      op1 = self._ops[2*i]\n      op2 = self._ops[2*i+1]\n      h1 = op1(h1)\n      h2 = op2(h2)\n      if self.training and drop_prob > 0.:\n        if not isinstance(op1, Identity):\n          h1 = drop_path(h1, drop_prob)\n        if not isinstance(op2, Identity):\n          h2 = drop_path(h2, drop_prob)\n\n      state = h1 + h2\n      states += [state]\n    output = torch.cat([states[i] for i in self._concat], dim=1)\n    return output\n"""
lib/nas_infer_model/DXYs/construct_utils.py,4,"b""import torch\nimport torch.nn.functional as F\n\n\ndef drop_path(x, drop_prob):\n  if drop_prob > 0.:\n    keep_prob = 1. - drop_prob\n    mask = x.new_zeros(x.size(0), 1, 1, 1)\n    mask = mask.bernoulli_(keep_prob)\n    x = torch.div(x, keep_prob)\n    x.mul_(mask)\n  return x\n\n\ndef return_alphas_str(basemodel):\n  if hasattr(basemodel, 'alphas_normal'):\n    string = 'normal [{:}] : \\n-->>{:}'.format(basemodel.alphas_normal.size(), F.softmax(basemodel.alphas_normal, dim=-1) )\n  else: string = ''\n  if hasattr(basemodel, 'alphas_reduce'):\n    string = string + '\\nreduce : {:}'.format( F.softmax(basemodel.alphas_reduce, dim=-1) )\n\n  if hasattr(basemodel, 'get_adjacency'):\n    adjacency = basemodel.get_adjacency()\n    for i in range( len(adjacency) ):\n      weight = F.softmax( basemodel.connect_normal[str(i)], dim=-1 )\n      adj = torch.mm(weight, adjacency[i]).view(-1)\n      adj = ['{:3.3f}'.format(x) for x in adj.cpu().tolist()]\n      string = string + '\\nnormal--{:}-->{:}'.format(i, ', '.join(adj))\n    for i in range( len(adjacency) ):\n      weight = F.softmax( basemodel.connect_reduce[str(i)], dim=-1 )\n      adj = torch.mm(weight, adjacency[i]).view(-1)\n      adj = ['{:3.3f}'.format(x) for x in adj.cpu().tolist()]\n      string = string + '\\nreduce--{:}-->{:}'.format(i, ', '.join(adj))\n\n  if hasattr(basemodel, 'alphas_connect'):\n    weight = F.softmax(basemodel.alphas_connect, dim=-1).cpu()\n    ZERO = ['{:.3f}'.format(x) for x in weight[:,0].tolist()]\n    IDEN = ['{:.3f}'.format(x) for x in weight[:,1].tolist()]\n    string = string + '\\nconnect [{:}] : \\n ->{:}\\n ->{:}'.format( list(basemodel.alphas_connect.size()), ZERO, IDEN )\n  else:\n    string = string + '\\nconnect = None'\n  \n  if hasattr(basemodel, 'get_gcn_out'):\n    outputs = basemodel.get_gcn_out(True)\n    for i, output in enumerate(outputs):\n      string = string + '\\nnormal:[{:}] : {:}'.format(i, F.softmax(output, dim=-1) )\n\n  return string\n\n\ndef remove_duplicate_archs(all_archs):\n  archs = []\n  str_archs = ['{:}'.format(x) for x in all_archs]\n  for i, arch_x in enumerate(str_archs):\n    choose = True\n    for j in range(i):\n      if arch_x == str_archs[j]:\n        choose = False; break\n    if choose: archs.append(all_archs[i])\n  return archs\n"""
lib/nas_infer_model/DXYs/genotypes.py,0,"b""from collections import namedtuple\n\nGenotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat connectN connects')\n#Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n\nPRIMITIVES_small = [\n    'max_pool_3x3',\n    'avg_pool_3x3',\n    'skip_connect',\n    'sep_conv_3x3',\n    'sep_conv_5x5',\n    'conv_3x1_1x3',\n]\n\nPRIMITIVES_large = [\n    'max_pool_3x3',\n    'avg_pool_3x3',\n    'skip_connect',\n    'sep_conv_3x3',\n    'sep_conv_5x5',\n    'dil_conv_3x3',\n    'dil_conv_5x5',\n    'conv_3x1_1x3',\n]\n\nPRIMITIVES_huge = [\n    'skip_connect',\n    'nor_conv_1x1',\n    'max_pool_3x3',\n    'avg_pool_3x3',\n    'nor_conv_3x3',\n    'sep_conv_3x3',\n    'dil_conv_3x3',\n    'conv_3x1_1x3',\n    'sep_conv_5x5',\n    'dil_conv_5x5',\n    'sep_conv_7x7',\n    'conv_7x1_1x7',\n    'att_squeeze',\n]\n\nPRIMITIVES = {'small': PRIMITIVES_small,\n              'large': PRIMITIVES_large,\n              'huge' : PRIMITIVES_huge}\n\nNASNet = Genotype(\n  normal = [\n    (('sep_conv_5x5', 1), ('sep_conv_3x3', 0)),\n    (('sep_conv_5x5', 0), ('sep_conv_3x3', 0)),\n    (('avg_pool_3x3', 1), ('skip_connect', 0)),\n    (('avg_pool_3x3', 0), ('avg_pool_3x3', 0)),\n    (('sep_conv_3x3', 1), ('skip_connect', 1)),\n  ],\n  normal_concat = [2, 3, 4, 5, 6],\n  reduce = [\n    (('sep_conv_5x5', 1), ('sep_conv_7x7', 0)),\n    (('max_pool_3x3', 1), ('sep_conv_7x7', 0)),\n    (('avg_pool_3x3', 1), ('sep_conv_5x5', 0)),\n    (('skip_connect', 3), ('avg_pool_3x3', 2)),\n    (('sep_conv_3x3', 2), ('max_pool_3x3', 1)),\n  ],\n  reduce_concat = [4, 5, 6],\n  connectN=None, connects=None,\n)\n\nPNASNet = Genotype(\n  normal = [\n    (('sep_conv_5x5', 0), ('max_pool_3x3', 0)),\n    (('sep_conv_7x7', 1), ('max_pool_3x3', 1)),\n    (('sep_conv_5x5', 1), ('sep_conv_3x3', 1)),\n    (('sep_conv_3x3', 4), ('max_pool_3x3', 1)),\n    (('sep_conv_3x3', 0), ('skip_connect', 1)),\n  ],\n  normal_concat = [2, 3, 4, 5, 6],\n  reduce = [\n    (('sep_conv_5x5', 0), ('max_pool_3x3', 0)),\n    (('sep_conv_7x7', 1), ('max_pool_3x3', 1)),\n    (('sep_conv_5x5', 1), ('sep_conv_3x3', 1)),\n    (('sep_conv_3x3', 4), ('max_pool_3x3', 1)),\n    (('sep_conv_3x3', 0), ('skip_connect', 1)),\n  ],\n  reduce_concat = [2, 3, 4, 5, 6],\n  connectN=None, connects=None,\n)\n\n\nDARTS_V1 = Genotype(\n  normal=[\n    (('sep_conv_3x3', 1), ('sep_conv_3x3', 0)), # step 1\n    (('skip_connect', 0), ('sep_conv_3x3', 1)), # step 2\n    (('skip_connect', 0), ('sep_conv_3x3', 1)), # step 3\n    (('sep_conv_3x3', 0), ('skip_connect', 2))  # step 4\n  ],\n  normal_concat=[2, 3, 4, 5],\n  reduce=[\n    (('max_pool_3x3', 0), ('max_pool_3x3', 1)), # step 1\n    (('skip_connect', 2), ('max_pool_3x3', 0)), # step 2\n    (('max_pool_3x3', 0), ('skip_connect', 2)), # step 3\n    (('skip_connect', 2), ('avg_pool_3x3', 0))  # step 4\n  ],\n  reduce_concat=[2, 3, 4, 5],\n  connectN=None, connects=None,\n)\n\n# DARTS: Differentiable Architecture Search, ICLR 2019\nDARTS_V2 = Genotype(\n  normal=[\n    (('sep_conv_3x3', 0), ('sep_conv_3x3', 1)), # step 1\n    (('sep_conv_3x3', 0), ('sep_conv_3x3', 1)), # step 2\n    (('sep_conv_3x3', 1), ('skip_connect', 0)), # step 3\n    (('skip_connect', 0), ('dil_conv_3x3', 2))  # step 4\n  ],\n  normal_concat=[2, 3, 4, 5],\n  reduce=[\n    (('max_pool_3x3', 0), ('max_pool_3x3', 1)), # step 1\n    (('skip_connect', 2), ('max_pool_3x3', 1)), # step 2\n    (('max_pool_3x3', 0), ('skip_connect', 2)), # step 3\n    (('skip_connect', 2), ('max_pool_3x3', 1))  # step 4\n  ],\n  reduce_concat=[2, 3, 4, 5],\n  connectN=None, connects=None,\n)\n\n\n# One-Shot Neural Architecture Search via Self-Evaluated Template Network, ICCV 2019\nSETN = Genotype(\n  normal=[\n    (('skip_connect', 0), ('sep_conv_5x5', 1)),\n    (('sep_conv_5x5', 0), ('sep_conv_3x3', 1)),\n    (('sep_conv_5x5', 1), ('sep_conv_5x5', 3)),\n    (('max_pool_3x3', 1), ('conv_3x1_1x3', 4))],\n  normal_concat=[2, 3, 4, 5],\n  reduce=[\n    (('sep_conv_3x3', 0), ('sep_conv_5x5', 1)),\n    (('avg_pool_3x3', 0), ('sep_conv_5x5', 1)),\n    (('avg_pool_3x3', 0), ('sep_conv_5x5', 1)),\n    (('avg_pool_3x3', 0), ('skip_connect', 1))],\n  reduce_concat=[2, 3, 4, 5],\n  connectN=None, connects=None\n)\n\n\n# Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019\nGDAS_V1 = Genotype(\n  normal=[\n    (('skip_connect', 0), ('skip_connect', 1)),\n    (('skip_connect', 0), ('sep_conv_5x5', 2)),\n    (('sep_conv_3x3', 3), ('skip_connect', 0)),\n    (('sep_conv_5x5', 4), ('sep_conv_3x3', 3))],\n  normal_concat=[2, 3, 4, 5],\n  reduce=[\n    (('sep_conv_5x5', 0), ('sep_conv_3x3', 1)), \n    (('sep_conv_5x5', 2), ('sep_conv_5x5', 1)),\n    (('dil_conv_5x5', 2), ('sep_conv_3x3', 1)),\n    (('sep_conv_5x5', 0), ('sep_conv_5x5', 1))],\n  reduce_concat=[2, 3, 4, 5],\n  connectN=None, connects=None\n)\n\n\n\nNetworks = {'DARTS_V1': DARTS_V1,\n            'DARTS_V2': DARTS_V2,\n            'DARTS'   : DARTS_V2,\n            'NASNet'  : NASNet,\n            'GDAS_V1' : GDAS_V1,\n            'PNASNet' : PNASNet,\n            'SETN'    : SETN,\n           }\n\n# This function will return a Genotype from a dict.\ndef build_genotype_from_dict(xdict):\n  def remove_value(nodes):\n    return [tuple([(x[0], x[1]) for x in node]) for node in nodes]\n  genotype = Genotype(\n      normal=remove_value(xdict['normal']),\n      normal_concat=xdict['normal_concat'],\n      reduce=remove_value(xdict['reduce']),\n      reduce_concat=xdict['reduce_concat'],\n      connectN=None, connects=None\n      )\n  return genotype\n"""
lib/nas_infer_model/DXYs/head_utils.py,1,"b'import torch\nimport torch.nn as nn\n\n\nclass ImageNetHEAD(nn.Sequential):\n  def __init__(self, C, stride=2):\n    super(ImageNetHEAD, self).__init__()\n    self.add_module(\'conv1\', nn.Conv2d(3, C // 2, kernel_size=3, stride=2, padding=1, bias=False))\n    self.add_module(\'bn1\'  , nn.BatchNorm2d(C // 2))\n    self.add_module(\'relu1\', nn.ReLU(inplace=True))\n    self.add_module(\'conv2\', nn.Conv2d(C // 2, C, kernel_size=3, stride=stride, padding=1, bias=False))\n    self.add_module(\'bn2\'  , nn.BatchNorm2d(C))\n\n\nclass CifarHEAD(nn.Sequential):\n  def __init__(self, C):\n    super(CifarHEAD, self).__init__()\n    self.add_module(\'conv\', nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False))\n    self.add_module(\'bn\', nn.BatchNorm2d(C))\n\n\nclass AuxiliaryHeadCIFAR(nn.Module):\n\n  def __init__(self, C, num_classes):\n    """"""assuming input size 8x8""""""\n    super(AuxiliaryHeadCIFAR, self).__init__()\n    self.features = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.AvgPool2d(5, stride=3, padding=0, count_include_pad=False), # image size = 2 x 2\n      nn.Conv2d(C, 128, 1, bias=False),\n      nn.BatchNorm2d(128),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(128, 768, 2, bias=False),\n      nn.BatchNorm2d(768),\n      nn.ReLU(inplace=True)\n    )\n    self.classifier = nn.Linear(768, num_classes)\n\n  def forward(self, x):\n    x = self.features(x)\n    x = self.classifier(x.view(x.size(0),-1))\n    return x\n\n\nclass AuxiliaryHeadImageNet(nn.Module):\n\n  def __init__(self, C, num_classes):\n    """"""assuming input size 14x14""""""\n    super(AuxiliaryHeadImageNet, self).__init__()\n    self.features = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.AvgPool2d(5, stride=2, padding=0, count_include_pad=False),\n      nn.Conv2d(C, 128, 1, bias=False),\n      nn.BatchNorm2d(128),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(128, 768, 2, bias=False),\n      nn.BatchNorm2d(768),\n      nn.ReLU(inplace=True)\n    )\n    self.classifier = nn.Linear(768, num_classes)\n\n  def forward(self, x):\n    x = self.features(x)\n    x = self.classifier(x.view(x.size(0),-1))\n    return x\n'"
lib/tf_models/cell_searchs/__init__.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nfrom .search_model_gdas     import TinyNetworkGDAS\nfrom .search_model_darts    import TinyNetworkDARTS\n\nnas_super_nets = {'GDAS' : TinyNetworkGDAS,\n                  'DARTS': TinyNetworkDARTS}\n"""
lib/tf_models/cell_searchs/search_cells.py,0,"b""##################################################\n# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n##################################################\nimport math, random\nimport tensorflow as tf\nfrom copy import deepcopy\nfrom ..cell_operations import OPS\n\n\nclass NAS201SearchCell(tf.keras.layers.Layer):\n\n  def __init__(self, C_in, C_out, stride, max_nodes, op_names, affine=False):\n    super(NAS201SearchCell, self).__init__()\n\n    self.op_names  = deepcopy(op_names)\n    self.max_nodes = max_nodes\n    self.in_dim    = C_in\n    self.out_dim   = C_out\n    self.edge_keys = []\n    for i in range(1, max_nodes):\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        if j == 0:\n          xlists = [OPS[op_name](C_in , C_out, stride, affine) for op_name in op_names]\n        else:\n          xlists = [OPS[op_name](C_in , C_out,      1, affine) for op_name in op_names]\n        for k, op in enumerate(xlists):\n          setattr(self, '{:}.{:}'.format(node_str, k), op)\n        self.edge_keys.append( node_str )\n    self.edge_keys  = sorted(self.edge_keys)\n    self.edge2index = {key:i for i, key in enumerate(self.edge_keys)}\n    self.num_edges  = len(self.edge_keys)\n\n  def call(self, inputs, weightss, training):\n    w_lst = tf.split(weightss, self.num_edges, 0)\n    nodes = [inputs]\n    for i in range(1, self.max_nodes):\n      inter_nodes = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        edge_idx = self.edge2index[node_str]\n        op_outps = []\n        for k, op_name in enumerate(self.op_names):\n          op = getattr(self, '{:}.{:}'.format(node_str, k))\n          op_outps.append( op(nodes[j], training) )\n        stack_op_outs = tf.stack(op_outps, axis=-1)\n        weighted_sums = tf.math.multiply(stack_op_outs, w_lst[edge_idx])\n        inter_nodes.append( tf.math.reduce_sum(weighted_sums, axis=-1) )\n      nodes.append( tf.math.add_n(inter_nodes) )\n    return nodes[-1]\n"""
lib/tf_models/cell_searchs/search_model_darts.py,1,"b""import tensorflow as tf\nimport numpy as np\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\n\n\nclass TinyNetworkDARTS(tf.keras.Model):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine):\n    super(TinyNetworkDARTS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = tf.keras.Sequential([\n                    tf.keras.layers.Conv2D(16, 3, 1, padding='same', use_bias=False),\n                    tf.keras.layers.BatchNormalization()], name='stem')\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell_prefix = 'cell-{:03d}'.format(index)\n      #with tf.name_scope(cell_prefix) as scope:\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      C_prev = cell.out_dim\n      setattr(self, cell_prefix, cell)\n    self.num_layers = len(layer_reductions)\n    self.op_names   = deepcopy( search_space )\n    self.edge2index = edge2index\n    self.num_edge   = num_edge\n    self.lastact    = tf.keras.Sequential([\n                        tf.keras.layers.BatchNormalization(),\n                        tf.keras.layers.ReLU(),\n                        tf.keras.layers.GlobalAvgPool2D(),\n                        tf.keras.layers.Flatten(),\n                        tf.keras.layers.Dense(num_classes, activation='softmax')], name='lastact')\n    #self.arch_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    arch_init = tf.random_normal_initializer(mean=0, stddev=0.001)\n    self.arch_parameters = tf.Variable(initial_value=arch_init(shape=(num_edge, len(search_space)), dtype='float32'), trainable=True, name='arch-encoding')\n\n  def get_alphas(self):\n    xlist = self.trainable_variables\n    return [x for x in xlist if 'arch-encoding' in x.name]\n\n  def get_weights(self):\n    xlist = self.trainable_variables\n    return [x for x in xlist if 'arch-encoding' not in x.name]\n\n  def get_np_alphas(self):\n    arch_nps = self.arch_parameters.numpy()\n    arch_ops = np.exp(arch_nps) / np.sum(np.exp(arch_nps), axis=-1, keepdims=True)\n    return arch_ops\n\n  def genotype(self):\n    genotypes, arch_nps = [], self.arch_parameters.numpy()\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights = arch_nps[ self.edge2index[node_str] ]\n        op_name = self.op_names[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return genotypes\n\n  def call(self, inputs, training):\n    weightss = tf.nn.softmax(self.arch_parameters, axis=1)\n    feature = self.stem(inputs, training)\n    for idx in range(self.num_layers):\n      cell = getattr(self, 'cell-{:03d}'.format(idx))\n      if isinstance(cell, SearchCell):\n        feature = cell.call(feature, weightss, training)\n      else:\n        feature = cell(feature, training)\n    logits = self.lastact(feature, training)\n    return logits\n"""
lib/tf_models/cell_searchs/search_model_gdas.py,1,"b""###########################################################################\n# Searching for A Robust Neural Architecture in Four GPU Hours, CVPR 2019 #\n###########################################################################\nimport tensorflow as tf\nimport numpy as np\nfrom copy import deepcopy\nfrom ..cell_operations import ResNetBasicblock\nfrom .search_cells     import NAS201SearchCell as SearchCell\n\n\ndef sample_gumbel(shape, eps=1e-20):\n  U = tf.random.uniform(shape, minval=0, maxval=1)\n  return -tf.math.log(-tf.math.log(U + eps) + eps)\n\n\ndef gumbel_softmax(logits, temperature):\n  gumbel_softmax_sample = logits + sample_gumbel(tf.shape(logits))\n  y = tf.nn.softmax(gumbel_softmax_sample / temperature)\n  return y\n\n\nclass TinyNetworkGDAS(tf.keras.Model):\n\n  def __init__(self, C, N, max_nodes, num_classes, search_space, affine):\n    super(TinyNetworkGDAS, self).__init__()\n    self._C        = C\n    self._layerN   = N\n    self.max_nodes = max_nodes\n    self.stem = tf.keras.Sequential([\n                    tf.keras.layers.Conv2D(16, 3, 1, padding='same', use_bias=False),\n                    tf.keras.layers.BatchNormalization()], name='stem')\n  \n    layer_channels   = [C    ] * N + [C*2 ] + [C*2  ] * N + [C*4 ] + [C*4  ] * N    \n    layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n    C_prev, num_edge, edge2index = C, None, None\n    for index, (C_curr, reduction) in enumerate(zip(layer_channels, layer_reductions)):\n      cell_prefix = 'cell-{:03d}'.format(index)\n      #with tf.name_scope(cell_prefix) as scope:\n      if reduction:\n        cell = ResNetBasicblock(C_prev, C_curr, 2)\n      else:\n        cell = SearchCell(C_prev, C_curr, 1, max_nodes, search_space, affine)\n        if num_edge is None: num_edge, edge2index = cell.num_edges, cell.edge2index\n        else: assert num_edge == cell.num_edges and edge2index == cell.edge2index, 'invalid {:} vs. {:}.'.format(num_edge, cell.num_edges)\n      C_prev = cell.out_dim\n      setattr(self, cell_prefix, cell)\n    self.num_layers = len(layer_reductions)\n    self.op_names   = deepcopy( search_space )\n    self.edge2index = edge2index\n    self.num_edge   = num_edge\n    self.lastact    = tf.keras.Sequential([\n                        tf.keras.layers.BatchNormalization(),\n                        tf.keras.layers.ReLU(),\n                        tf.keras.layers.GlobalAvgPool2D(),\n                        tf.keras.layers.Flatten(),\n                        tf.keras.layers.Dense(num_classes, activation='softmax')], name='lastact')\n    #self.arch_parameters = nn.Parameter( 1e-3*torch.randn(num_edge, len(search_space)) )\n    arch_init = tf.random_normal_initializer(mean=0, stddev=0.001)\n    self.arch_parameters = tf.Variable(initial_value=arch_init(shape=(num_edge, len(search_space)), dtype='float32'), trainable=True, name='arch-encoding')\n\n  def get_alphas(self):\n    xlist = self.trainable_variables\n    return [x for x in xlist if 'arch-encoding' in x.name]\n\n  def get_weights(self):\n    xlist = self.trainable_variables\n    return [x for x in xlist if 'arch-encoding' not in x.name]\n\n  def get_np_alphas(self):\n    arch_nps = self.arch_parameters.numpy()\n    arch_ops = np.exp(arch_nps) / np.sum(np.exp(arch_nps), axis=-1, keepdims=True)\n    return arch_ops\n\n  def genotype(self):\n    genotypes, arch_nps = [], self.arch_parameters.numpy()\n    for i in range(1, self.max_nodes):\n      xlist = []\n      for j in range(i):\n        node_str = '{:}<-{:}'.format(i, j)\n        weights = arch_nps[ self.edge2index[node_str] ]\n        op_name = self.op_names[ weights.argmax().item() ]\n        xlist.append((op_name, j))\n      genotypes.append( tuple(xlist) )\n    return genotypes\n\n  # \n  def call(self, inputs, tau, training):\n    weightss = tf.cond(tau < 0, lambda: tf.nn.softmax(self.arch_parameters, axis=1),\n                                lambda: gumbel_softmax(tf.math.log_softmax(self.arch_parameters, axis=1), tau))\n    feature = self.stem(inputs, training)\n    for idx in range(self.num_layers):\n      cell = getattr(self, 'cell-{:03d}'.format(idx))\n      if isinstance(cell, SearchCell):\n        feature = cell.call(feature, weightss, training)\n      else:\n        feature = cell(feature, training)\n    logits = self.lastact(feature, training)\n    return logits\n"""
