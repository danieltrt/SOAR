file_path,api_count,code
setup.py,0,"b'import setuptools\n\nsetuptools.setup(\n    name=""torchdyn"",\n    version=""0.1.1"",\n    author=""DiffEqML"",\n    author_email=""polimic03@gmail.com, massaroli@robot.t.u-tokyo.ac.jp"",\n    description=""PyTorch package for all things neural differential equations"",\n    url=""https://github.com/Zymrael/torchdyn"",\n    packages=setuptools.find_packages(),\n    install_requires=[\'torch>=1.4.1\',\n                      \'pytorch-lightning>=0.7.3\',\n                      \'dgl>=0.4.1\',\n                      \'torchdiffeq>=0.0.1\'],\n    classifiers=[\n        ""Programming Language :: Python :: 3"",\n        ""License :: OSI Approved :: MIT License"",\n    ],\n    python_requires=\'>=3.6\',\n)'"
docs/conf.py,0,"b'# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'..\'))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'TorchDyn\'\ncopyright = \'2020, Stefano Massaroli & Michael Poli\'\nauthor = \'Stefano Massaroli & Michael Poli\'\n\n# The full version, including alpha/beta/rc tags\nrelease = \'0.1\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n\t\'sphinx.ext.autodoc\', \'sphinx.ext.coverage\', \'sphinx.ext.napoleon\',\n\t\'recommonmark\',\n\t\'nbsphinx\',\n\t\'sphinx.ext.viewcode\'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\n    # Slow\n    \'_build\', \'**.ipynb_checkpoints\',\n    \'tutorials/wip_tutorials\', \n    \'tutorials/lightning_logs\',\n    \'tutorials/__pycache__\'\n]\n\nautosummary_generate = True\nnapolean_use_rtype = False\n\n# -- Options for nbsphinx -----------------------------------------------------\n\n# Execute notebooks before conversion: \'always\', \'never\', \'auto\' (default)\n# We execute all notebooks, exclude the slow ones using \'exclude_patterns\'\nnbsphinx_execute = \'never\'\n\n\n\n# This is processed by Jinja2 and inserted before each notebook\nnbsphinx_prolog = r""""""\n{% set docname = \'docs/\' + env.doc2path(env.docname, base=None) %}\n.. only:: html\n    .. role:: raw-html(raw)\n        :format: html\n    .. nbinfo::\n        Interactive online version:\n        :raw-html:`<a href=""https://colab.research.google.com/github/google/jax/blob/master/{{ docname }}""><img alt=""Open In Colab"" src=""https://colab.research.google.com/assets/colab-badge.svg"" style=""vertical-align:text-bottom""></a>`\n    __ https://github.com/google/jax/blob/\n        {{ env.config.release }}/{{ docname }}\n""""""\n\n\n\n\n\n\n\n\n\n\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n#html_theme = \'alabaster\'\n\nhtml_theme = ""sphinx_rtd_theme""\n\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']'"
test/smoke_tests.py,7,"b'import torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport pytorch_lightning as pl\nimport sys\n\n\ndef train_traj_neural_de():\n    d = ToyDataset()\n    X, yn = d.generate(n_samples=512, dataset_type=\'moons\', noise=.4)\n\n    device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n\n    X_train = torch.Tensor(X).to(device)\n    y_train = torch.LongTensor(yn.long()).to(device)\n    train = data.TensorDataset(X_train, y_train)\n    trainloader = data.DataLoader(train, batch_size=len(X), shuffle=False)\n\n    class Learner(pl.LightningModule):\n        def __init__(self, model:nn.Module, settings:dict={}):\n            super().__init__()\n            defaults.update(settings)\n            self.settings = defaults\n            self.model = model\n            self.c = 0\n\n        def forward(self, x):\n            return self.model(x)\n\n        def training_step(self, batch, batch_idx):\n            x, y = batch      \n            y_hat = self.model(x)   \n            loss = nn.CrossEntropyLoss()(y_hat, y)\n            logs = {\'train_loss\': loss}\n            return {\'loss\': loss, \'log\': logs}   \n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters(), lr=0.005)\n\n        def train_dataloader(self):\n            return trainloader\n        \n    settings = {\'type\':\'classic\', \'controlled\':False, \'solver\':\'dopri5\'}\n\n    f = DEFunc(nn.Sequential(\n            nn.Linear(2, 64),\n            nn.Tanh(), \n            nn.Linear(64, 2)))\n\n    model = NeuralDE(f, settings).to(device)\n    \n    learn = Learner(model)\n    trainer = pl.Trainer(min_nb_epochs=10, max_nb_epochs=30)\n    trainer.fit(learn)\n    \n    s_span = torch.linspace(0,1,100)\n    trajectory = model.trajectory(X_train, s_span).detach().cpu()\n    print(""Test done"")\n    \nif __name__ == \'__main__\':\n  \n    sys.path.append(\'..\')\n    from torchdyn.models import *; from torchdyn.data_utils import *\n    from torchdyn import *\n    train_traj_neural_de()'"
torchdyn/__init__.py,0,b'from .adjoint import *\nfrom .learner import *\nfrom .plot import *\nfrom ._internals import *'
torchdyn/_internals.py,0,"b'""""""\nConflict manager for non-compatible Neural DE variants\n""""""\n\nclass conflict:\n    def __init__(self, c_type, c_settings, c_value):\n        self.conflict_type = c_type\n        self.conflict_settings = c_settings\n        self.conflict_value = c_value\n    \ndef NOT_ALLOWED_ARG(st:dict):\n    not_allowed = []\n    \n    ## non supported incompatibilities ##\n    conflict_type = \'not_supported\'\n    \n    if not st[\'backprop_style\']==\'autograd\' and st[\'type\']==\'stable\':\n        not_allowed.append(\n            conflict(\n                conflict_type, \n                \'back-propagation style and neural ODE type\',\n                [st[\'backprop_style\'], st[\'type\']]\n            )\n        )\n        \n    ## general API misuses ##\n    conflict_type = \'general\'\n    \n    # to add more conflicts\n    if st[\'type\'] not in [\'classic\', \'stable\']:\n        not_allowed.append(\n            conflict(\n                conflict_type, \n                \'neural ODE type\',\n                [st[\'type\']]\n            )\n        )\n    if st[\'backprop_style\'] not in [\'autograd\', \'adjoint\', \'integral_adjoint\']:\n        not_allowed.append(\n            conflict(\n                conflict_type, \n                \'back-propagation style\',\n                [st[\'backprop_style\']]\n            )\n        )    \n        \n# DEPRECATED: new s_span API\n#     if st[\'s_start\']==st[\'s_end\']:\n#         not_allowed.append(\n#             conflict(\n#                 conflict_type, \n#                 \'initial depth and final depth\',\n#                 [st[\'s_start\'], st[\'s_end\']]\n#             )\n#         )\n\n    if st[\'atol\']<=0:\n        not_allowed.append(\n            conflict(\n                conflict_type, \n                \'solver absolute tolerance\',\n                [st[\'atol\']]\n            )\n        )\n    if st[\'rtol\']<=0:\n        not_allowed.append(\n            conflict(\n                conflict_type, \n                \'solver relative tolerance\',\n                [st[\'rtol\']]\n            )\n        )\n    return not_allowed\n    \ndef compat_check(settings:dict):\n    conflicts = NOT_ALLOWED_ARG(settings)\n    n_conflicts = len(conflicts)\n    if not n_conflicts:\n        return 0\n\n    error_msg = \'\\n%d Errors Found\\n\' % n_conflicts\n    count = 1\n    \n    error_msg += \'General Errors:\\n\'\n    for c in conflicts:\n        if c.conflict_type == \'general\':\n            error_msg +=\'%d) Incompatible \'%count+c.conflict_settings+\': \'+str(c.conflict_value) +\'\\n\'\n            count+=1\n            \n    error_msg += \'Supported Functionalities Errors:\\n\' \n    for c in conflicts:\n        if c.conflict_type == \'not_supported\':\n            error_msg +=\'%d) \'%count+c.conflict_settings+\': \'+str(c.conflict_value) +\' not yet supported in torchdyn\'\n            count+=1\n    raise ValueError(error_msg)\n    return'"
torchdyn/adjoint.py,13,"b'""""""\nAdjoint template and variations of the adjoint technique\n""""""\n\nimport pdb\nimport torch\nimport torch.nn as nn\nfrom torchdiffeq._impl.misc import _flatten\nfrom torchdiffeq import odeint\n\n\nclass Adjoint(nn.Module):\n    """"""Adjoint class template.\n\n    :param integral: `True` if an *integral cost* (see **link alla pagina degli adj**) is specified\n    :type integral: bool\n    :param return_traj: `True` if we want to return the whole adjoint trajectory and not only the final point (loss gradient)\n    :type return_traj: bool\n    """"""\n    def __init__(self, integral:bool=False, return_traj:bool=False):\n        super().__init__()\n        self.integral, self.return_traj = integral, return_traj\n        self.autograd_func = self._define_autograd_adjoint()\n\n    def adjoint_dynamics(self, s, adjoint_state):\n        """""" Define the vector field of the augmented adjoint dynamics(as in [link]) to be then integrated **backward**. An `Adjoint` object is istantiated into the `NeuralDE` if the adjoint method for back-propagation was selected.\n\n        :param s: current depth\n        :type s: float\n        :param adjoint_state: tuple of four tensors constituting the *augmented adjoint state* to be integrated: `h` (hidden state of the neural ODE), `\xce\xbb` (Lagrange multiplier), `\xce\xbc` (loss gradient state), `s_adj` (adjoint state of the integration depth)\n        :type adjoint_state: tuple of tensors\n        """"""\n        h, \xce\xbb, \xce\xbc, s_adj = adjoint_state[0:4]\n        with torch.set_grad_enabled(True):\n            s = s.to(h.device).requires_grad_(True)\n            h = h.requires_grad_(True) #.detach()\n            f = self.func(s, h)\n            d\xce\xbbds = torch.autograd.grad(f, h, -\xce\xbb, allow_unused=True, retain_graph=True)[0]\n            # d\xce\xbcds is a tuple! of all self.f_params groups\n            d\xce\xbcds = torch.autograd.grad(f, self.f_params, -\xce\xbb, allow_unused=True, retain_graph=True)\n            if self.integral:\n                g = self.cost(s, h)\n                dgdh = torch.autograd.grad(g.sum(), h, allow_unused=True, retain_graph=True)[0]\n                d\xce\xbbds = d\xce\xbbds - dgdh   \n        ds_adjds = torch.tensor(0.).to(self.s_span)\n        d\xce\xbcds = torch.cat([el.flatten() for el in d\xce\xbcds]).to(d\xce\xbbds)\n        return (f, d\xce\xbbds, d\xce\xbcds, ds_adjds)\n  \n    def _init_adjoint_state(self, sol, *grad_output):\n        # check grad_output\n        if self.integral: \n            \xce\xbb0 = torch.zeros_like(grad_output[-1][0])\n        else:\n            \xce\xbb0 = grad_output[-1][0]\n        s_adj0 = torch.tensor(0.).to(self.s_span)\n        \xce\xbc0 = torch.zeros_like(self.flat_params)\n        \n        return (sol[-1], \xce\xbb0, \xce\xbc0, s_adj0)\n\n    def _define_autograd_adjoint(self):\n        class autograd_adjoint(torch.autograd.Function):\n            @staticmethod\n            def forward(ctx, h0, flat_params, s_span):        \n                with torch.no_grad():\n                    sol = odeint(self.func, h0, self.s_span, rtol=self.rtol, atol=self.atol, \n                                 method=self.method, options=self.options)\n                ctx.save_for_backward(self.s_span, self.flat_params, sol)\n                sol = sol if self.return_traj else sol[-1]; return sol\n\n            @staticmethod  \n            def backward(ctx, *grad_output):\n                s, flat_params, sol = ctx.saved_tensors\n                self.f_params = tuple(self.func.parameters())\n                with torch.no_grad():                       \n                    adj0 = self._init_adjoint_state(sol, grad_output) \n                    adj_sol = odeint(self.adjoint_dynamics, adj0, self.s_span.flip(0), \n                                   rtol=self.rtol, atol=self.atol, method=self.method, options=self.options)\n                \xce\xbb = adj_sol[1]\n                \xce\xbc = adj_sol[2]\n                return (\xce\xbb, \xce\xbc, None) \n        return autograd_adjoint\n  \n    def forward(self, func, h0, s_span, cost=None, rtol=1e-6, atol=1e-12, method=\'dopri5\', options={}):\n        if not isinstance(func, nn.Module):\n            raise ValueError(\'func is required to be an instance of nn.Module.\')\n        self.flat_params = _flatten(func.parameters()) ; self.s_span = s_span\n        self.func, self.cost = func, cost ; self.method, self.options = method, options\n        self.atol, self.rtol = atol, rtol ; \n        sol = self.autograd_func.apply(h0, self.flat_params, self.s_span)\n        return sol'"
torchdyn/learner.py,6,"b'""""""\nPyTorch Lightning Learner template to be used for training\n""""""\n\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\n\nclass Learner(pl.LightningModule):\n    """"""`Learner` following PyTorch Lightning templates. Handles training and validation routines. Refer to notebook\n        tutorials as well as PyTorch Lightning documentation for best practices.\n        \n    :param model: model to train and validate\n    :type model: nn.Module\n    """"""\n    def __init__(self, model:nn.Module):\n        super().__init__()\n        self.model = model\n    \n    def forward(self, x:torch.Tensor):\n        """"""Returns self.model(x)\n        :param x: input data\n        :type x: torch.Tensor\n        """"""\n        return self.model(x)\n    \n    def training_step(self, batch:torch.Tensor, batch_idx:int):\n        """"""Handles a training step with batch `batch`. User defined.\n         :param x: input data\n         :type x: torch.Tensor\n         :param x: input data\n         :type x: torch.Tensor\n         """"""\n        pass\n    \n    def configure_optimizers(self):\n        """"""Configures the optimizers to utilize for training. User defined.\n        """"""\n        pass\n\n    def train_dataloader(self):\n        """"""Configures the train dataloader to utilize for training. User defined.\n        """"""\n        pass'"
torchdyn/plot.py,20,"b'""""""\nGeneral plotting utilities\n""""""\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nimport matplotlib as mpl\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef plot_2d_boundary(model, X, y, mesh, num_classes=2, figsize=(8,4), alpha=0.8):\n    """"""Plots decision boundary of a 2-dimensional task\n    \n     :param model: model\n     :type model: nn.Module\n     :param X: input data\n     :type X: torch.Tensor\n     :param y: input labels\n     :type y: torch.Tensor\n     :param mesh: meshgrid of points to classify with `model`\n     :type mesh: torch.Tensor\n     :param num_classes: number of classes\n     :type num_classes: int\n     :param figsize: figure size\n     :type figsize: tuple(int, int)\n     :param alpha: alpha of figure\n     :type alpha: float\n     """"""\n    preds = torch.argmax(nn.Softmax(1)(model(mesh)), dim=1)\n    preds = preds.detach().cpu().reshape(mesh.size(0), mesh.size(1))\n    plt.figure(figsize=figsize)\n    plt.contourf(torch.linspace(0, mesh.size(0), mesh.size(0)), torch.linspace(0, mesh.size(1), mesh.size(1)),\n                 preds, cmap=\'winter\', alpha=alpha, levels=10)\n    for i in range(num_classes):\n        plt.scatter(X[y==i,0], X[y==i,1], alpha=alpha)\n        \n\ndef plot_2d_flows(trajectory, num_flows=2, figsize=(8,4), alpha=0.8):\n    """"""Plots data flows learned by a neural differential equation.\n    \n     :param trajectory: tensor of data flows. Assumed to be of dimensions `L, B, *` with `L`:length of trajectory, `B`:batch size, `*`:remaining dimensions.\n     :type trajectory: torch.Tensor\n     :param num_flows: number of data flows to visualize\n     :type num_flows: int\n     :param figsize: figure size\n     :type figsize: tuple(int, int)\n     :param alpha: alpha of figure\n     :type alpha: float\n     """"""\n    plt.figure(figsize=figsize)\n    plt.subplot(121)\n    plt.title(\'Dimension: 0\')\n    for i in range(num_flows):\n        plt.plot(trajectory[:,i,0], color=\'red\', alpha=alpha)\n    plt.subplot(122)\n    plt.title(\'Dimension: 1\')\n    for i in range(num_flows):\n        plt.plot(trajectory[:,i,1], color=\'blue\', alpha=alpha)\n        \n        \ndefaults_1D = {\'n_grid\':100, \'n_levels\':30, \'x_span\':[-1,1],\n            \'contour_alpha\':0.7, \'cmap\':\'winter\', \n            \'traj_color\':\'orange\', \'traj_alpha\':0.1,\n            \'device\':\'cuda:0\'}\n\ndef plot_traj_vf_1D(model, s_span, traj, device, x_span, n_grid,\n                    n_levels=30, contour_alpha=0.7, cmap=\'winter\', traj_color=\'orange\', traj_alpha=0.1):\n    """"""Plots 1D data flows.\n    \n     :param model: model\n     :type model: nn.Module\n     :param s_span: number of data flows to visualize\n     :type s_span: torch.Tensor\n     :param traj: figure size\n     :type traj: tuple(int, int)\n     :param device: alpha of figure\n     :type device: float\n     :param x_span: alpha of figure\n     :type x_span: float\n     :param n_grid: alpha of figure\n     :type n_grid: float\n     """"""\n    ss = torch.linspace(s_span[0], s_span[-1], n_grid)\n    xx = torch.linspace(x_span[0], x_span[-1], n_grid)\n    \n    S, X = torch.meshgrid(ss,xx)\n    \n    if model.settings[\'controlled\']:\n        ax = st[\'ax\']\n        u_traj = traj[0,:,0].repeat(traj.shape[1],1)\n        e = torch.abs(st[\'y\'].T - traj[:,:,0])\n        color = plt.cm.coolwarm(e)\n        for i in range(traj.shape[1]):\n            tr = ax.scatter(s_span, u_traj[:,i],traj[:,i,0],\n                        c=color[:,i],alpha=1, cmap=color[:,i],zdir=\'z\')\n        norm = mpl.colors.Normalize(e.min(),e.max())\n        plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=\'coolwarm\'),\n             label=\'Approximation Error\', orientation=\'horizontal\')\n        ax.set_xlabel(r""$s$ [depth]"");\n        ax.set_ylabel(r""$u$"");\n        ax.set_zlabel(r""$h(s)$"");\n        # make the panes transparent\n        ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n        ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n        ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n        # make the grid lines transparent\n        ax.xaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n        ax.yaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n        ax.zaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n        \n        \n    else:\n        U, V = torch.ones(n_grid, n_grid), torch.zeros(n_grid, n_grid)\n        for i in range(n_grid):\n            for j in range(n_grid):\n                V[i,j] = model.defunc(\n                            S[i,j].reshape(1,-1).to(device),\n                            X[i,j].reshape(1,-1).to(device)\n                            ).detach().cpu()\n        F = torch.sqrt(U**2 + V**2)\n        \n        plt.contourf(S,X,F,n_levels,cmap=cmap,alpha=contour_alpha)\n        plt.streamplot(S.T.numpy(),X.T.numpy(),\n                       U.T.numpy(),V.T.numpy(),\n                       color=\'black\',linewidth=1)\n        if not traj==None:\n            plt.plot(s_span, traj[:,:,0], \n                     color=traj_color,alpha=traj_alpha)\n            \n        plt.xlabel(r""$s$ [Depth]"")\n        plt.ylabel(r""$h(s)$"")\n            \n        return (S, X, U, V)\n\ndef plot_2D_depth_trajectory(s_span, trajectory, yn, n_lines):\n    color=[\'orange\', \'blue\']\n\n    fig = plt.figure(figsize=(8,2))\n    ax0 = fig.add_subplot(121)\n    ax1 = fig.add_subplot(122)\n    for i in range(n_lines):\n        ax0.plot(s_span, trajectory[:,i,0], color=color[int(yn[i])], alpha=.1);\n        ax1.plot(s_span, trajectory[:,i,1], color=color[int(yn[i])], alpha=.1);\n\n    ax0.set_xlabel(r""$s$ [Depth]"")\n    ax0.set_ylabel(r""$h_0(s)$"")\n    ax0.set_title(""Dimension 0"")\n    ax1.set_xlabel(r""$s$ [Depth]"")\n    ax1.set_ylabel(r""$h_1(s)$"")\n    ax1.set_title(""Dimension 1"")\n\n\ndef plot_2D_state_space(trajectory, yn, n_lines):\n    color=[\'orange\', \'blue\']\n\n    fig = plt.figure(figsize=(3,3))\n    ax = fig.add_subplot(111)\n    for i in range(n_lines):\n        ax.plot(trajectory[:,i,0], trajectory[:,i,1], color=color[int(yn[i])], alpha=.1);\n\n    ax.set_xlabel(r""$h_0$"")\n    ax.set_ylabel(r""$h_1$"")\n    ax.set_title(""Flows in the state-space"")\n    \ndef plot_2D_space_depth(s_span, trajectory, yn, n_lines):\n    colors = [\'orange\', \'blue\'] \n    fig = plt.figure(figsize=(6,3))\n    ax = Axes3D(fig)\n    for i in range(n_lines):\n        ax.plot(s_span, trajectory[:,i,0], trajectory[:,i,1], color=colors[yn[i].int()], alpha = .1)\n        ax.view_init(30, -110)\n\n    ax.set_xlabel(r""$s$ [Depth]"")\n    ax.set_ylabel(r""$h_0$"")\n    ax.set_zlabel(r""$h_1$"")\n    ax.set_title(""Flows in the space-depth"")\n    ax.xaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n    ax.yaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n    ax.zaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n    \ndef plot_static_vector_field(model, trajectory, t=0., N=50, device=\'cuda\'):\n    x = torch.linspace(trajectory[:,:,0].min(), trajectory[:,:,0].max(), N)\n    y = torch.linspace(trajectory[:,:,1].min(), trajectory[:,:,1].max(), N)\n    X, Y = torch.meshgrid(x,y)\n    U, V = torch.zeros(N,N), torch.zeros(N,N)\n\n    for i in range(N):\n        for j in range(N):\n            p = torch.cat([X[i,j].reshape(1,1), Y[i,j].reshape(1,1)],1).to(device)\n            O = model.defunc(t,p).detach().cpu()\n            U[i,j], V[i,j] = O[0,0], O[0,1]\n\n    fig = plt.figure(figsize=(3,3))\n    ax = fig.add_subplot(111)\n    ax.contourf(X, Y, torch.sqrt(U**2 + V**2), cmap=\'RdYlBu\')\n    ax.streamplot(X.T.numpy(),Y.T.numpy(),U.T.numpy(),V.T.numpy(), color=\'k\')\n    \n    ax.set_xlim([x.min(),x.max()])\n    ax.set_ylim([y.min(),y.max()])  \n    ax.set_xlabel(r""$h_0$"")\n    ax.set_ylabel(r""$h_1$"")\n    ax.set_title(""Learned Vector Field"")\n    \ndef plot_3D_dataset(X, yn):\n    colors = [\'orange\', \'blue\'] \n    fig = plt.figure(figsize=(4,4))\n    ax = Axes3D(fig)\n    for i in range(len(X)):\n        ax.scatter(X[:,0],X[:,1],X[:,2], color=colors[yn[i].int()], alpha = .1)\n    ax.set_xlabel(r""$h_0$"")\n    ax.set_ylabel(r""$h_1$"")\n    ax.set_zlabel(r""$h_2$"")\n    ax.set_title(""Data Points"")\n    ax.xaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n    ax.yaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n    ax.zaxis._axinfo[""grid""][\'color\'] =  (1,1,1,0)\n  '"
torchdyn/data_utils/__init__.py,0,b'from .static_datasets import *\n'
torchdyn/data_utils/static_datasets.py,10,"b'""""""\nClassification benchmark toy dataset generation\n""""""\n\nimport torch\nimport numpy as np\n\ndef randnsphere(dim, radius):\n    """"""Uniform sampling on a sphere of `dim` and `radius`\n\n    :param dim: dimension of the sphere\n    :type dim: int\n    :param radius: radius of the sphere\n    :type radius: float\n    """"""\n    v = torch.randn(dim)\n    inv_len = radius / torch.sqrt(torch.pow(v, 2).sum())\n    return v * inv_len\n\ndef generate_concentric_spheres(n_samples=100, noise=1e-4, dim=3, inner_radius=0.5, outer_radius=1):\n    """"""Creates a *concentric spheres* dataset of `n_samples` data points.\n\n    :param n_samples: number of data points in the generated dataset\n    :type n_samples: int\n    :param noise: standard deviation of noise magnitude added to each data point\n    :type noise: float\n    :param dim: dimension of the spheres\n    :type dim: float\n    :param inner_radius: radius of the inner sphere\n    :type inner_radius: float\n    :param outer_radius: radius of the outer sphere\n    :type outer_radius: float\n    """"""\n    X = torch.zeros((n_samples, dim))\n    y = torch.zeros(n_samples)\n    y[:n_samples // 2] = 1\n    samples = []\n    for i in range(n_samples // 2):\n        samples.append(randnsphere(dim, inner_radius)[None, :])\n    X[:n_samples // 2] = torch.cat(samples)\n    X[:n_samples // 2] += torch.zeros((n_samples // 2, dim)).normal_(0, std=noise)\n    samples = []\n    for i in range(n_samples // 2):\n        samples.append(randnsphere(dim, outer_radius)[None, :])\n    X[n_samples // 2:] = torch.cat(samples)\n    X[n_samples // 2:] += torch.zeros((n_samples // 2, dim)).normal_(0, std=noise)\n    return X, y\n\ndef generate_moons(n_samples=100, noise=1e-4, **kwargs):\n    """"""Creates a *moons* dataset of `n_samples` data points.\n\n    :param n_samples: number of data points in the generated dataset\n    :type n_samples: int\n    :param noise: standard deviation of noise magnitude added to each data point\n    :type noise: float\n    """"""\n    n_samples_out = n_samples // 2\n    n_samples_in = n_samples - n_samples_out\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - .5\n\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x),\n                   np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp),\n                   np.ones(n_samples_in, dtype=np.intp)])\n\n    if noise is not None:\n        X += np.random.rand(n_samples, 1) * noise\n\n    X, y = torch.Tensor(X), torch.Tensor(y)\n    return X, y\n\ndef generate_spirals(n_samples=100, noise=1e-4, **kwargs):\n    """"""Creates a *spirals* dataset of `n_samples` data points.\n\n    :param n_samples: number of data points in the generated dataset\n    :type n_samples: int\n    :param noise: standard deviation of noise magnitude added to each data point\n    :type noise: float\n    """"""\n    n = np.sqrt(np.random.rand(n_samples, 1)) * 780 * (2 * np.pi) / 360\n    d1x = -np.cos(n) * n + np.random.rand(n_samples, 1) * noise\n    d1y = np.sin(n) * n + np.random.rand(n_samples, 1) * noise\n    X, y = (np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y)))),\n            np.hstack((np.zeros(n_samples), np.ones(n_samples))))\n    X, y = torch.Tensor(X), torch.Tensor(y)\n    return X, y\n\nclass ToyDataset:\n    """"""Handles the generation of classification toy datasets""""""\n    def generate(self, n_samples, dataset_type, **kwargs):\n        """"""Handles the generation of classification toy datasets\n        :param n_samples: number of data points in the generated dataset\n        :type n_samples: int\n        :param dataset_type: {\'moons\', \'spirals\', \'spheres\'}\n        :type dataset_type: str\n        :param dim: if \'spheres\': dimension of the spheres\n        :type dim: float\n        :param inner_radius: if \'spheres\': radius of the inner sphere\n        :type inner_radius: float\n        :param outer_radius: if \'spheres\': radius of the outer sphere\n        :type outer_radius: float\n        """"""\n        if dataset_type == \'moons\':\n            return generate_moons(n_samples=n_samples, **kwargs)\n        elif dataset_type == \'spirals\':\n            return generate_spirals(n_samples=n_samples, **kwargs)\n        elif dataset_type == \'spheres\':\n            return generate_concentric_spheres(n_samples=n_samples, **kwargs)\n\n\n\n'"
torchdyn/models/__init__.py,0,b'from .defunc import *\nfrom .galerkin import *\nfrom .neuralde import *'
torchdyn/models/defunc.py,11,"b'import torch\nimport torch.nn as nn\n\nclass DEFuncTemplate(nn.Module):\n    """"""Differential Equation Function template.\n\n    :param model: neural network parametrizing the vector field\n    :type model: nn.Module\n    :param order: order of the differential equation\n    :type order: int\n    :param func_type: {\'stable\', \'higher_order\'}. Specifies special variants of the neural DE. Refer to the documentation for more information on the `stable` variant.\n    :type func_type: str\n    """"""\n    def __init__(self, model, order, func_type):\n        super().__init__()  \n        self.m, self.nfe, self.controlled = model, 0., False\n        self.func_type, self.order = func_type, order\n        \n    def forward(self, s, x):\n        self.nfe += 1\n        if self.controlled: x = torch.cat([x, self.u], 1)\n        if self.func_type == \'stable\': x = self.stable_forward(s, x)\n        if self.func_type == \'higher_order\' and self.order > 1: x = self.horder_forward(s, x)\n        else: x = self.m(x)\n        # save dxds for regularization purposes\n        self.dxds = x\n        return x\n        \n    def stable_forward(self, s, x):\n        with torch.set_grad_enabled(True):\n            x = torch.autograd.Variable(x, requires_grad=True)\n            energy = self.m(x)**2\n            grad = -torch.autograd.grad(energy.sum(1), x, create_graph=True)[0]\n            if self.controlled: grad = grad[:, :x.size(1)//2]\n        return grad\n    \n    def horder_forward(self, s, x):\n        x_new = []\n        size_order = x.size(1)//self.order\n        for i in range(self.order-1):\n            x_new.append(x[:, size_order*i:size_order*(i+1)])\n        x_new.append(self.m(x))\n        return torch.cat(x_new, 1).to(x)\n\n    \nclass DEFunc(DEFuncTemplate):\n    """"""General Differential Equation Function variant\n\n    :param model: neural network parametrizing the vector field\n    :type model: nn.Module\n    :param order: order of the differential equation\n    :type order: int\n    :param func_type: {\'stable\', \'higher_order\'}. Specifies special variants of the neural DE. Refer to the documentation for more information on the `stable` variant.\n    :type func_type: str\n    """"""\n    def __init__(self, model, order=1, func_type=\'classic\'):\n        super().__init__(model, order, func_type)  \n        \n    def forward(self, s, x):\n        idx_to_set = [el[0] if \'Depth\' in str(el[1]) else -1 for el in list(self.m.named_children())]\n        for idx in idx_to_set:\n            if int(idx) > -1: self.m[int(idx)]._set_s(s)\n        return super().forward(s, x)\n\nclass Augmenter(nn.Module):\n    """"""Augmentation class. Can handle several types of augmentation strategies for Neural DEs.\n\n    :param augment_dims: number of augmented dimensions to initialize\n    :type augment_dims: int\n    :param augment_idx: index of dimension to augment\n    :type augment_idx: int\n    :param augment_func: nn.Module applied to the input data of dimension `d` to determine the augmented initial condition of dimension `d + a`.\n                        `a` is defined implicitly in `augment_func` e.g. augment_func=nn.Linear(2, 5) augments a 2 dimensional input with 3 additional dimensions.\n    :type augment_func: nn.Module\n    """"""\n    def __init__(self, augment_dims: int = 5, augment_idx: int = 1, augment_func=None):\n        super().__init__()\n        self.augment_dims, self.augment_idx, self.augment_func = augment_dims, augment_idx, augment_func\n\n    def forward(self, x: torch.Tensor):\n        if not self.augment_func:\n            new_dims = list(x.shape)\n            new_dims[self.augment_idx] = self.augment_dims\n            x = torch.cat([x, torch.zeros(new_dims).to(x)],\n                          self.augment_idx)\n        else:\n            x = torch.cat([x, self.augment_func(x).to(x)],\n                          self.augment_idx)\n        return x\n\nclass DepthCat(nn.Module):\n    """"""Depth variable `s` concatenation module. Allows for easy concatenation of `s` each call of the numerical solver, at specified layers of the DEFunc.\n\n    :param idx_cat: index of the data dimension to concatenate `s` to.\n    :type idx_cat: int\n    """"""\n    def __init__(self, idx_cat=1):\n        super().__init__()\n        self.idx_cat = idx_cat\n    \n    def _set_s(self, s):\n        self.s = s\n        \n    def forward(self, x):\n        s_shape = list(x.shape); s_shape[self.idx_cat] = 1\n        self.s = self.s*torch.ones(s_shape).to(x)\n        return torch.cat([x, self.s], self.idx_cat).to(x)'"
torchdyn/models/galerkin.py,22,"b'import torch\nimport torch.nn as nn\nimport numpy as np\n\ndef FourierExpansion(n_range, s):\n    """"""Fourier eigenbasis expansion\n    """"""\n    s_n_range = 2*np.pi*s*n_range\n    basis = [torch.cos(s_n_range), torch.sin(s_n_range)]\n    return basis\n  \ndef PolyExpansion(n_range, s):\n    """"""Polynomial expansion\n    """"""\n    basis = [s**n_range]\n    return basis\n\n# can be slimmed down with template class (sharing assign_weights and reset_parameters) \nclass GalLinear(nn.Module):\n    """"""Linear Galerkin layer for depth--variant neural differential equations\n\n    :param in_features: input dimensions\n    :type in_features: int\n    :param out_features: output dimensions\n    :type out_features: int\n    :param expfunc: {\'FourierExpansion\', \'PolyExpansion\'}. Choice of eigenfunction expansion.\n    :type expfunc: str\n    :param n_harmonics: number of elements of the truncated eigenfunction expansion.\n    :type n_harmonics: int\n    :param n_eig: number of distinct eigenfunctions in the basis\n    :type n_eig: int\n    :param bias: include bias parameter vector in the layer computation\n    :type bias: bool\n    """"""\n    def __init__(self, in_features, out_features, expfunc=FourierExpansion, n_harmonics=10, n_eig=2, bias=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.expfunc = expfunc\n        self.n_eig = n_eig\n        self.n_harmonics = n_harmonics\n        self.weight = torch.Tensor(out_features, in_features)\n        if bias:\n            self.bias = torch.Tensor(out_features)\n        else:\n            self.register_parameter(\'bias\', None)         \n        self.coeffs = torch.nn.Parameter(torch.Tensor((in_features+1)*out_features, n_harmonics, n_eig))        \n        self.reset_parameters()  \n        \n    def reset_parameters(self):\n        torch.nn.init.zeros_(self.coeffs)\n        \n    def assign_weights(self, s):\n        n_range = torch.linspace(0, self.n_harmonics, self.n_harmonics).to(self.coeffs.device)\n        basis = self.expfunc(n_range, s)\n        B = []  \n        for i in range(self.n_eig):\n            Bin = torch.eye(self.n_harmonics).to(self.coeffs.device)\n            Bin[range(self.n_harmonics), range(self.n_harmonics)] = basis[i]\n            B.append(Bin)\n        B = torch.cat(B, 1).to(self.coeffs.device)\n        coeffs = torch.cat([self.coeffs[:,:,i] for i in range(self.n_eig)],1).transpose(0,1).to(self.coeffs.device) \n        X = torch.matmul(B, coeffs)\n        return X.sum(0)\n      \n    def forward(self, input):\n        s = input[-1,-1]\n        input = input[:,:-1]\n        w = self.assign_weights(s)\n        self.weight = w[0:self.in_features*self.out_features].reshape(self.out_features, self.in_features)\n        self.bias = w[self.in_features*self.out_features:(self.in_features+1)*self.out_features].reshape(self.out_features)\n        return torch.nn.functional.linear(input, self.weight, self.bias)\n    \nclass GalConv2d(nn.Module):\n    """"""2D convolutional Galerkin layer for depth--variant neural differential equations\n\n    :param in_channels: number of channels in the input image\n    :type in_channels: int\n    :param out_channels: number of channels produced by the convolution\n    :type out_channels: int\n    :param kernel_size: size of the convolving kernel\n    :type kernel_size: int\n    :param stride: stride of the convolution. Default: 1\n    :type stride: int\n    :param padding: zero-padding added to both sides of the input. Default: 0\n    :type padding: int\n    :param expfunc: {\'FourierExpansion\', \'PolyExpansion\'}. Choice of eigenfunction expansion.\n    :type expfunc: str\n    :param n_harmonics: number of elements of the truncated eigenfunction expansion.\n    :type n_harmonics: int\n    :param n_eig: number of distinct eigenfunctions in the basis\n    :type n_eig: int\n    :param bias: include bias parameter vector in the layer computation\n    :type bias: bool\n    """"""\n    __constants__ = [\'bias\', \'in_channels\', \'out_channels\', \'kernel_size\', \'stride\', \'padding\', \'n_harmonics\']\n\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, \n                 expfunc=FourierExpansion, n_harmonics=10, n_eig=2, bias=True):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.pad = padding\n        self.stride = stride\n        self.expfunc = expfunc\n        self.n_eig = n_eig\n        self.n_harmonics = n_harmonics\n        self.weight = torch.Tensor(out_channels, in_channels, kernel_size, kernel_size)\n        if bias:\n            self.bias = torch.Tensor(out_channels)\n        else:\n            self.register_parameter(\'bias\', None)\n\n        self.coeffs = torch.nn.Parameter(torch.Tensor(((out_channels)*in_channels*(kernel_size**2)+out_channels), n_harmonics, 2))\n\n        self.reset_parameters()\n        self.ic, self.oc, self.ks, self.nh = in_channels, out_channels, kernel_size, n_harmonics\n\n    def reset_parameters(self):\n        torch.nn.init.zeros_(self.coeffs)\n        \n    def assign_weights(self, s):\n        n_range = torch.linspace(0, self.n_harmonics, self.n_harmonics).to(self.coeffs.device)\n        basis = self.expfunc(n_range, s)\n        B = []  \n        for i in range(self.n_eig):\n            Bin = torch.eye(self.n_harmonics).to(self.coeffs.device)\n            Bin[range(self.n_harmonics), range(self.n_harmonics)] = basis[i]\n            B.append(Bin)\n        B = torch.cat(B, 1).to(self.coeffs.device)\n        coeffs = torch.cat([self.coeffs[:,:,i] for i in range(self.n_eig)],1).transpose(0,1).to(self.coeffs.device) \n        X = torch.matmul(B, coeffs)\n        return X.sum(0)\n\n    def forward(self, input):\n        s = input[-1,-1,0,0]\n        input = input[:,:-1]\n        w = self.assign_weights(s)\n        n = self.oc*self.ic*self.ks*self.ks\n        self.weight = w[0:n].reshape(self.oc, self.ic, self.ks, self.ks)\n        self.bias = w[n:].reshape(self.oc)\n        return torch.nn.functional.conv2d(input, self.weight, self.bias, stride=self.stride, padding=self.pad)'"
torchdyn/models/neuralde.py,12,"b'import torch\nimport torch.nn as nn\nimport torchdiffeq\nimport pytorch_lightning as pl\nfrom ..adjoint import Adjoint\nfrom .._internals import compat_check\n\ndefaults = {\'type\':\'classic\', \'controlled\':False, \'augment\':False, # model\n            \'backprop_style\':\'autograd\', \'cost\':None, # training \n            \'s_span\':torch.linspace(0, 1, 2), \'solver\':\'rk4\', \'atol\':1e-3, \'rtol\':1e-4, # solver params\n            \'return_traj\':False} \n\nclass NeuralDE(pl.LightningModule):\n    """"""General Neural DE template\n\n    :param func: function parametrizing the vector field.\n    :type func: nn.Module\n    :param settings: specifies parameters of the Neural DE. \n    :type settings: dict\n    """"""\n    def __init__(self, func:nn.Module, settings:dict):\n        super().__init__()\n        defaults.update(settings)\n        compat_check(defaults)\n        self.st = defaults ; self.defunc, self.defunc.func_type = func, self.st[\'type\']\n        self.defunc.controlled = self.st[\'controlled\']\n        self.s_span, self.return_traj = self.st[\'s_span\'], self.st[\'return_traj\']\n        \n        # check if integral\n        flag = (self.st[\'backprop_style\'] == \'integral_adjoint\')\n        self.adjoint = Adjoint(flag)\n        \n    def forward(self, x:torch.Tensor):\n        return self._odesolve(x)    \n\n    def _odesolve(self, x:torch.Tensor):\n        # TO DO: implement adaptive_depth check, insert here\n        \n        # assign control input and augment if necessary \n        if self.defunc.controlled: self.defunc.u = x \n        self.s_span = self.s_span.to(x)\n        \n        switcher = {\n        \'autograd\': self._autograd,\n        \'integral_autograd\': self._integral_autograd,\n        \'adjoint\': self._adjoint,\n        \'integral_adjoint\': self._integral_adjoint\n        }\n        odeint = switcher.get(self.st[\'backprop_style\'])\n        sol = odeint(x) if self.st[\'return_traj\'] else odeint(x)[-1]\n        return sol\n\n    def trajectory(self, x:torch.Tensor, s_span:torch.Tensor):\n        """"""Returns a data-flow trajectory at `s_span` points\n\n        :param x: input data\n        :type x: torch.Tensor\n        :param s_span: collections of points to evaluate the function at e.g torch.linspace(0, 1, 100) for a 100 point trajectory\n                       between 0 and 1\n        :type s_span: torch.Tensor\n        """"""\n        if self.defunc.controlled: self.defunc.u = x             \n        sol = torchdiffeq.odeint(self.defunc, x, s_span,\n                                 rtol=self.st[\'rtol\'], atol=self.st[\'atol\'], method=self.st[\'solver\'])        \n        return sol\n    \n    def backward_trajectory(self, x:torch.Tensor, s_span:torch.Tensor):\n        assert self.adjoint, \'Propagating backward dynamics only possible with Adjoint systems\'\n        # register hook\n        if self.defunc.controlled: self.defunc.u = x      \n        # set new s_span\n        self.adjoint.s_span = s_span ; x = x.requires_grad_(True)\n        sol = self(x)\n        sol.sum().backward()\n        return sol.grad\n\n    def _autograd(self, x):\n        return torchdiffeq.odeint(self.defunc, x, self.s_span, rtol=self.st[\'rtol\'], \n                                  atol=self.st[\'atol\'], method=self.st[\'solver\']) \n    def _adjoint(self, x):\n        return torchdiffeq.odeint_adjoint(self.defunc, x, self.s_span, rtol=self.st[\'rtol\'], \n                                          atol=self.st[\'atol\'], method=self.st[\'solver\'])\n    def _integral_adjoint(self, x):\n        assert self.st[\'cost\'], \'Cost nn.Module needs to be specified for integral adjoint\'\n        return self.adjoint(self.defunc, x, self.s_span, cost=self.st[\'cost\'],\n                            rtol=self.st[\'rtol\'], atol=self.st[\'atol\'], method=self.st[\'solver\'])\n    \n    def _integral_autograd(self, x):\n        assert self.st[\'cost\'], \'Cost nn.Module needs to be specified for integral adjoint\'\n        \xce\xbe0 = 0.*torch.ones(1).to(x.device)\n        \xce\xbe0 = \xce\xbe0.repeat(x.shape[0]).unsqueeze(1)\n        x = torch.cat([x,\xce\xbe0], 1)\n        return torchdiffeq.odeint(self._integral_autograd_defunc, x, self.s_span,\n                                rtol=self.st[\'rtol\'], atol=self.st[\'atol\'],method=self.st[\'solver\'])\n\n    def _integral_autograd_defunc(self, s, x):\n        x = x[:, :-1]\n        dxds = self.defunc(s, x)\n        d\xce\xbeds = self.settings[\'cost\'](s, x).repeat(x.shape[0]).unsqueeze(1)\n        return torch.cat([dxds,d\xce\xbeds], 1)\n            \n    def __repr__(self):\n        npar = sum([p.numel() for p in self.defunc.parameters()])\n        return f""Neural DE\\tType: {self.st[\'type\']}\\tControlled: {self.st[\'controlled\']}\\\n        \\nSolver: {self.st[\'solver\']}\\tIntegration interval: {self.st[\'s_span\'][0]} to {self.st[\'s_span\'][-1]}\\\n        \\nCost: {self.st[\'cost\']}\\tReturning trajectory: {self.st[\'return_traj\']}\\\n        \\nTolerances: relative {self.st[\'rtol\']} absolute {self.st[\'atol\']}\\\n        \\nFunction parametrizing vec. field:\\n {self.defunc}\\\n        \\n# parameters {npar}""'"
